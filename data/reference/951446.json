[
    {
        "link": "https://docs.docker.com/engine/install/debian",
        "document": "To get started with Docker Engine on Debian, make sure you meet the prerequisites, and then follow the installation steps.\n• If you use ufw or firewalld to manage firewall settings, be aware that when you expose container ports using Docker, these ports bypass your firewall rules. For more information, refer to Docker and ufw.\n• Docker is only compatible with and . Firewall rules created with are not supported on a system with Docker installed. Make sure that any firewall rulesets you use are created with or , and that you add them to the chain, see Packet filtering and firewalls.\n\nTo install Docker Engine, you need the 64-bit version of one of these Debian versions:\n\nDocker Engine for Debian is compatible with x86_64 (or amd64), armhf, arm64, and ppc64le (ppc64el) architectures.\n\nBefore you can install Docker Engine, you need to uninstall any conflicting packages.\n\nYour Linux distribution may provide unofficial Docker packages, which may conflict with the official packages provided by Docker. You must uninstall these packages before you install the official version of Docker Engine.\n\nThe unofficial packages to uninstall are:\n\nMoreover, Docker Engine depends on and . Docker Engine bundles these dependencies as one bundle: . If you have installed the or previously, uninstall them to avoid conflicts with the versions bundled with Docker Engine.\n\nRun the following command to uninstall all conflicting packages:\n\nmight report that you have none of these packages installed.\n\nImages, containers, volumes, and networks stored in aren't automatically removed when you uninstall Docker. If you want to start with a clean installation, and prefer to clean up any existing data, read the uninstall Docker Engine section.\n\nYou can install Docker Engine in different ways, depending on your needs:\n• None Docker Engine comes bundled with Docker Desktop for Linux. This is the easiest and quickest way to get started.\n• None Set up and install Docker Engine from Docker's repository.\n• None Use a convenience script. Only recommended for testing and development environments.\n\nBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n• None If you use a derivative distribution, such as Kali Linux, you may need to substitute the part of this command that's expected to print the version codename: Replace this part with the codename of the corresponding Debian release, such as .\n• None To install a specific version of Docker Engine, start by listing the available versions in the repository:\n• None Verify that the installation is successful by running the image: This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n\nYou have now successfully installed and started Docker Engine.\n\nTo upgrade Docker Engine, follow step 2 of the installation instructions, choosing the new version you want to install.\n\nIf you can't use Docker's repository to install Docker Engine, you can download the file for your release and install it manually. You need to download a new file each time you want to upgrade Docker Engine.\n• None Select your Debian version in the list.\n• None Go to and select the applicable architecture ( , , , or ).\n• None Download the following files for the Docker Engine, CLI, containerd, and Docker Compose packages:\n• None Install the packages. Update the paths in the following example to where you downloaded the Docker packages.\n• None Verify that the installation is successful by running the image: This command downloads a test image and runs it in a container. When the container runs, it prints a confirmation message and exits.\n\nYou have now successfully installed and started Docker Engine.\n\nTo upgrade Docker Engine, download the newer package files and repeat the installation procedure, pointing to the new files.\n\nDocker provides a convenience script at https://get.docker.com/ to install Docker into development environments non-interactively. The convenience script isn't recommended for production environments, but it's useful for creating a provisioning script tailored to your needs. Also refer to the install using the repository steps to learn about installation steps to install using the package repository. The source code for the script is open source, and you can find it in the repository on GitHub .\n\nAlways examine scripts downloaded from the internet before running them locally. Before installing, make yourself familiar with potential risks and limitations of the convenience script:\n• The script requires or privileges to run.\n• The script attempts to detect your Linux distribution and version and configure your package management system for you.\n• The script doesn't allow you to customize most installation parameters.\n• The script installs dependencies and recommendations without asking for confirmation. This may install a large number of packages, depending on the current configuration of your host machine.\n• By default, the script installs the latest stable release of Docker, containerd, and runc. When using this script to provision a machine, this may result in unexpected major version upgrades of Docker. Always test upgrades in a test environment before deploying to your production systems.\n• The script isn't designed to upgrade an existing Docker installation. When using the script to update an existing installation, dependencies may not be updated to the expected version, resulting in outdated versions.\n\nThis example downloads the script from https://get.docker.com/ and runs it to install the latest stable release of Docker on Linux:\n\nYou have now successfully installed and started Docker Engine. The service starts automatically on Debian based distributions. On based distributions, such as CentOS, Fedora, RHEL or SLES, you need to start it manually using the appropriate or command. As the message indicates, non-root users can't run Docker commands by default.\n\nDocker also provides a convenience script at https://test.docker.com/ to install pre-releases of Docker on Linux. This script is equal to the script at , but configures your package manager to use the test channel of the Docker package repository. The test channel includes both stable and pre-releases (beta versions, release-candidates) of Docker. Use this script to get early access to new releases, and to evaluate them in a testing environment before they're released as stable.\n\nTo install the latest version of Docker on Linux from the test channel, run:\n\nUpgrade Docker after using the convenience script\n\nIf you installed Docker using the convenience script, you should upgrade Docker using your package manager directly. There's no advantage to re-running the convenience script. Re-running it can cause issues if it attempts to re-install repositories which already exist on the host machine.\n• None Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:\n\nYou have to delete any edited configuration files manually."
    },
    {
        "link": "https://docs.docker.com/desktop/setup/install/linux/debian",
        "document": "This page contains information on how to install, launch, and upgrade Docker Desktop on a Debian distribution.\n\nTo install Docker Desktop successfully, you must:\n• None For a Gnome Desktop environment, you must also install AppIndicator and KStatusNotifierItem Gnome extensions .\n• None For non-Gnome Desktop environments, must be installed:\n• None Set up Docker's repository. See step one of Install using the repository.\n• None Download the latest DEB package . For checksums, see the Release notes.\n• None Install the package with apt as follows:\n\nBy default, Docker Desktop is installed at .\n\nThere are a few post-install configuration steps done through the post-install script contained in the deb package.\n• Sets the capability on the Docker Desktop binary to map privileged ports and set resource limits.\n• Adds a DNS name for Kubernetes to .\n• Creates a symlink from to . This is because the classic Docker CLI is installed at . The Docker Desktop installer also installs a Docker CLI binary that includes cloud-integration capabilities and is essentially a wrapper for the Compose CLI, at . The symlink ensures that the wrapper can access the classic Docker CLI.\n• None Navigate to the Docker Desktop application in your Gnome/KDE Desktop.\n• None Select Accept to continue. Docker Desktop starts after you accept the terms. Note that Docker Desktop won't run if you do not agree to the terms. You can choose to accept the terms at a later date by opening Docker Desktop. For more information, see Docker Desktop Subscription Service Agreement . It is recommended that you also read the FAQs .\n\nWhen Docker Desktop starts, it creates a dedicated context that the Docker CLI can use as a target and sets it as the current context in use. This is to avoid a clash with a local Docker Engine that may be running on the Linux host and using the default context. On shutdown, Docker Desktop resets the current context to the previous one.\n\nThe Docker Desktop installer updates Docker Compose and the Docker CLI binaries on the host. It installs Docker Compose V2 and gives users the choice to link it as docker-compose from the Settings panel. Docker Desktop installs the new Docker CLI binary that includes cloud-integration capabilities in and creates a symlink to the classic Docker CLI at .\n\nAfter you’ve successfully installed Docker Desktop, you can check the versions of these binaries by running the following commands:\n\nTo enable Docker Desktop to start on sign in, from the Docker menu, select Settings > General > Start Docker Desktop when you sign in to your computer.\n\nTo stop Docker Desktop, select the Docker menu icon to open the Docker menu and select Quit Docker Desktop.\n\nOnce a new version for Docker Desktop is released, the Docker UI shows a notification. You need to download the new package each time you want to upgrade Docker Desktop and run:\n• Explore Docker's subscriptions to see what Docker can offer you.\n• Take a look at the Docker workshop to learn how to build an image and run it as a containerized application.\n• Explore Docker Desktop and all its features.\n• Troubleshooting describes common problems, workarounds, how to run and submit diagnostics, and submit issues.\n• Release notes lists component updates, new features, and improvements associated with Docker Desktop releases.\n• Back up and restore data provides instructions on backing up and restoring data related to Docker."
    },
    {
        "link": "https://docs.docker.com/engine/install",
        "document": "This section describes how to install Docker Engine on Linux, also known as Docker CE. Docker Engine is also available for Windows, macOS, and Linux, through Docker Desktop. For instructions on how to install Docker Desktop, see: Overview of Docker Desktop.\n• If you use Debian derivatives such as \"BunsenLabs Linux\", \"Kali Linux\" or \"LMDE\" (Debian-based Mint) should follow the installation instructions for Debian, substitute the version of your distribution for the corresponding Debian release. Refer to the documentation of your distribution to find which Debian release corresponds with your derivative version.\n• Likewise, if you use Ubuntu derivatives such as \"Kubuntu\", \"Lubuntu\" or \"Xubuntu\" you should follow the installation instructions for Ubuntu, substituting the version of your distribution for the corresponding Ubuntu release. Refer to the documentation of your distribution to find which Ubuntu release corresponds with your derivative version.\n• Some Linux distributions provide a package of Docker Engine through their package repositories. These packages are built and maintained by the Linux distribution's package maintainers and may have differences in configuration or are built from modified source code. Docker isn't involved in releasing these packages and you should report any bugs or issues involving these packages to your Linux distribution's issue tracker.\n\nDocker provides binaries for manual installation of Docker Engine. These binaries are statically linked and you can use them on any Linux distribution.\n\nDocker Engine has two types of update channels, stable and test:\n• The stable channel gives you the latest versions released for general availability.\n• The test channel gives you pre-release versions that are ready for testing before general availability.\n\nUse the test channel with caution. Pre-release versions include experimental and early-access features that are subject to breaking changes.\n\nDocker Engine is an open source project, supported by the Moby project maintainers and community members. Docker doesn't provide support for Docker Engine. Docker provides support for Docker products, including Docker Desktop, which uses Docker Engine as one of its components.\n\nFor information about the open source project, refer to the Moby project website .\n\nPatch releases are always backward compatible with its major and minor version.\n\nDocker Engine is licensed under the Apache License, Version 2.0. See LICENSE for the full license text.\n\nIf you discover a security issue, we request that you bring it to our attention immediately.\n\nDO NOT file a public issue. Instead, submit your report privately to security@docker.com.\n\nSecurity reports are greatly appreciated, and Docker will publicly thank you for it.\n\nAfter setting up Docker, you can learn the basics with Getting started with Docker."
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-debian-10",
        "document": "Not using Debian 10 ?Choose a different version or distribution.\n\nDocker is an application that simplifies the process of managing application processes in containers. Containers let you run your applications in resource-isolated processes. They’re similar to virtual machines, but containers are more portable, more resource-friendly, and more dependent on the host operating system.\n\nFor a detailed introduction to the different components of a Docker container, check out The Docker Ecosystem: An Introduction to Common Components.\n\nIn this tutorial, you’ll install and use Docker Community Edition (CE) on Debian 10. You’ll install Docker itself, work with containers and images, and push an image to a Docker Repository.\n\nTo follow this tutorial, you will need the following:\n• One Debian 10 server set up by following the Debian 10 initial server setup guide, including a sudo non-root user and a firewall.\n• An account on Docker Hub if you wish to create your own images and push them to Docker Hub, as shown in Steps 7 and 8.\n\nThe Docker installation package available in the official Debian repository may not be the latest version. To ensure we get the latest version, we’ll install Docker from the official Docker repository. To do that, we’ll add a new package source, add the GPG key from Docker to ensure the downloads are valid, and then install the package.\n\nFirst, update your existing list of packages:\n\nNext, install a few prerequisite packages which let use packages over HTTPS:\n\nThen add the GPG key for the official Docker repository to your system:\n\nNext, update the package database with the Docker packages from the newly added repo:\n\nMake sure you are about to install from the Docker repo instead of the default Debian repo:\n\nYou’ll see output like this, although the version number for Docker may be different:\n\nNotice that is not installed, but the candidate for installation is from the Docker repository for Debian 10 ( ).\n\nDocker is now installed, the daemon started, and the process enabled to start on boot. Check that it’s running:\n\nThe output will be similar to the following, showing that the service is active and running:\n\nInstalling Docker gives you not just the Docker service (daemon) but also the command line utility, or the Docker client. We’ll explore how to use the command later in this tutorial.\n\nBy default, the command can only be run the root user or by a user in the docker group, which is automatically created during Docker’s installation process. If you attempt to run the command without prefixing it with or without being in the docker group, you’ll get an output like this:\n\nIf you want to avoid typing whenever you run the command, add your username to the group:\n\nTo apply the new group membership, log out of the server and back in, or type the following:\n\nYou will be prompted to enter your user’s password to continue.\n\nConfirm that your user is now added to the docker group by typing:\n\nIf you need to add a user to the group that you’re not logged in as, declare that username explicitly using:\n\nThe rest of this article assumes you are running the command as a user in the docker group. If you choose not to, please prepend the commands with .\n\nUsing consists of passing it a chain of options and commands followed by arguments. The syntax takes this form:\n\nTo view all available subcommands, type:\n\nAs of Docker 18, the complete list of available subcommands includes:\n\nTo view the options available to a specific command, type:\n\nTo view system-wide information about Docker, use:\n\nLet’s explore some of these commands. We’ll start by working with images.\n\nDocker containers are built from Docker images. By default, Docker pulls these images from Docker Hub, a Docker registry managed by Docker, the company behind the Docker project. Anyone can host their Docker images on Docker Hub, so most applications and Linux distributions you’ll need will have images hosted there.\n\nTo check whether you can access and download images from Docker Hub, type:\n\nThe output will indicate that Docker is working correctly:\n\nDocker was initially unable to find the image locally, so it downloaded the image from Docker Hub, which is the default repository. Once the image downloaded, Docker created a container from the image and the application within the container executed, displaying the message.\n\nYou can search for images available on Docker Hub by using the command with the subcommand. For example, to search for the Ubuntu image, type:\n\nThe script will crawl Docker Hub and return a listing of all images whose name match the search string. In this case, the output will be similar to this:\n\nIn the OFFICIAL column, OK indicates an image built and supported by the company behind the project. Once you’ve identified the image that you would like to use, you can download it to your computer using the subcommand.\n\nExecute the following command to download the official image to your computer:\n\nYou’ll see the following output:\n\nAfter an image has been downloaded, you can then run a container using the downloaded image with the subcommand. As you saw with the example, if an image has not been downloaded when is executed with the subcommand, the Docker client will first download the image, then run a container using it.\n\nTo see the images that have been downloaded to your computer, type:\n\nThe output should look similar to the following:\n\nAs you’ll see later in this tutorial, images that you use to run containers can be modified and used to generate new images, which may then be uploaded (pushed is the technical term) to Docker Hub or other Docker registries.\n\nLet’s look at how to run containers in more detail.\n\nThe container you ran in the previous step is an example of a container that runs and exits after emitting a test message. Containers can be much more useful than that, and they can be interactive. After all, they are similar to virtual machines, only more resource-friendly.\n\nAs an example, let’s run a container using the latest image of Ubuntu. The combination of the -i and -t switches gives you interactive shell access into the container:\n\nYour command prompt should change to reflect the fact that you’re now working inside the container and should take this form:\n\nNote the container id in the command prompt. In this example, it is . You’ll need that container ID later to identify the container when you want to remove it.\n\nNow you can run any command inside the container. For example, let’s update the package database inside the container. You don’t need to prefix any command with , because you’re operating inside the container as the root user:\n\nThen install any application in it. Let’s install Node.js:\n\nThis installs Node.js in the container from the official Ubuntu repository. When the installation finishes, verify that Node.js is installed:\n\nYou’ll see the version number displayed in your terminal:\n\nAny changes you make inside the container only apply to that container.\n\nTo exit the container, type at the prompt.\n\nLet’s look at managing the containers on our system next.\n\nAfter using Docker for a while, you’ll have many active (running) and inactive containers on your computer. To view the active ones, use:\n\nYou will see output similar to the following:\n\nIn this tutorial, you started two containers; one from the image and another from the image. Both containers are no longer running, but they still exist on your system.\n\nTo view all containers — active and inactive, run with the switch:\n\nYou’ll see output similar to this:\n\nTo view the latest container you created, pass it the switch:\n\nTo start a stopped container, use , followed by the container ID or the container’s name. Let’s start the Ubuntu-based container with the ID of :\n\nThe container will start, and you can use to see its status:\n\nTo stop a running container, use , followed by the container ID or name. This time, we’ll use the name that Docker assigned the container, which is :\n\nOnce you’ve decided you no longer need a container anymore, remove it with the command, again using either the container ID or the name. Use the command to find the container ID or name for the container associated with the image and remove it.\n\nYou can start a new container and give it a name using the switch. You can also use the switch to create a container that removes itself when it’s stopped. See the command for more information on these options and others.\n\nContainers can be turned into images which you can use to build new containers. Let’s look at how that works.\n\nStep 7 — Committing Changes in a Container to a Docker Image\n\nWhen you start up a Docker image, you can create, modify, and delete files just like you can with a virtual machine. The changes that you make will only apply to that container. You can start and stop it, but once you destroy it with the command, the changes will be lost for good.\n\nThis section shows you how to save the state of a container as a new Docker image.\n\nAfter installing Node.js inside the Ubuntu container, you now have a container running off an image, but the container is different from the image you used to create it. But you might want to reuse this Node.js container as the basis for new images later.\n\nThen commit the changes to a new Docker image instance using the following command.\n\nThe -m switch is for the commit message that helps you and others know what changes you made, while -a is used to specify the author. The is the one you noted earlier in the tutorial when you started the interactive Docker session. Unless you created additional repositories on Docker Hub, the is usually your Docker Hub username.\n\nFor example, for the user sammy, with the container ID of , the command would be:\n\nWhen you commit an image, the new image is saved locally on your computer. Later in this tutorial, you’ll learn how to push an image to a Docker registry like Docker Hub so others can access it.\n\nListing the Docker images again will show the new image, as well as the old one that it was derived from:\n\nYou’ll see output like this:\n\nIn this example, is the new image, which was derived from the existing image from Docker Hub. The size difference reflects the changes that were made. And in this example, the change was that NodeJS was installed. So next time you need to run a container using Ubuntu with NodeJS pre-installed, you can just use the new image.\n\nYou can also build Images from a , which lets you automate the installation of software in a new image. However, that’s outside the scope of this tutorial.\n\nNow let’s share the new image with others so they can create containers from it.\n\nThe next logical step after creating a new image from an existing image is to share it with a select few of your friends, the whole world on Docker Hub, or other Docker registry that you have access to. To push an image to Docker Hub or any other Docker registry, you must have an account there.\n\nThis section shows you how to push a Docker image to Docker Hub. To learn how to create your own private Docker registry, check out How To Set Up a Private Docker Registry on Ubuntu 18.04.\n\nTo push your image, first log into Docker Hub.\n\nYou’ll be prompted to authenticate using your Docker Hub password. If you specified the correct password, authentication should succeed.\n\nThen you may push your own image using:\n\nTo push the image to the sammy repository, the command would be:\n\nThe process may take some time to complete as it uploads the images, but when completed, the output will look like this:\n\nAfter pushing an image to a registry, it should be listed on your account’s dashboard, like that show in the image below.\n\nIf a push attempt results in an error of this sort, then you likely did not log in:\n\nLog in with and repeat the push attempt. Then verify that it exists on your Docker Hub repository page.\n\nYou can now use to pull the image to a new machine and use it to run a new container.\n\nIn this tutorial you installed Docker, worked with images and containers, and pushed a modified image to Docker Hub. Now that you know the basics, explore the other Docker tutorials in the DigitalOcean Community."
    },
    {
        "link": "https://phoenixnap.com/kb/install-docker-debian",
        "document": "Docker is a platform for creating, deploying, and managing self-contained software units called containers. By virtualizing the underlying operating system, Docker isolates containers from the rest of the host while allowing inter-container communication.\n\nIn this tutorial, you will learn how to install Docker on Debian.\n\nThe most efficient method for installing Docker on Debian is utilizing the official distribution repositories. For the most up-to-date packages, using the official Docker repository is recommended.\n\nAdditionally, it is possible to install Docker manually by downloading the necessary DEB packages. This method is convenient for users with air-gapped systems and no access to the Internet.\n\nThe following sections present all three methods for installing Docker on Debian.\n\nThe official Debian repositories contain recent Docker packages that are available for installation via the APT package manager. To ensure the packages are up-to-date:\n\n2. Install Docker by entering the following:\n\n3. Type Y and press Enter when prompted to start the installation.\n\nInstalling Docker from the official Docker repository ensures access to the latest stable version of the platform. Follow the steps below to install Docker on a Debian-based system:\n\n2. Download the tools that enable adding the Docker's official GPG key over HTTPS:\n\n4. Download the GPG key and place it in the directory created in the previous step:\n\n6. Add the signed Docker repository to the list of sources on the system:\n\nThe Docker repository appears in the output.\n\n8. Install the Docker packages by typing the following command:\n\nUsers who cannot install Docker from repositories can set it up manually via DEB packages. Proceed with the steps below to download and install Docker using this method:\n\n1. Navigate to the Debian distributions section on Docker's official website.\n\n2. Select the relevant version of Debian. The latest stable release is at the top of the list.\n\n3. Navigate to pool>stable and select the desired architecture.\n\nThe list of available packages appears.\n\n4. Download the latest versions of the containerd.io, docker-ce-cli, and docker-ce packages.\n\n5. Go to the directory with the downloaded files and install packages using the dpkg command. The examples below use the latest packages at the time of writing the article:\n\nUsing the docker run command, create and start a hello-world test container to ensure the container service has been configured correctly:\n\nThe command automatically downloads the hello-world image, creates a container based on it, and starts the container. The output confirms that the installation is working correctly.\n\nOnce you do not need Docker on your system, uninstall it with the following command:\n\nFor example, to uninstall docker-ce, type:\n\nThe command deletes the package. However, any additional files related to it, such as images, containers, and custom configuration files, remain on the system. Remove everything, including the Docker directory, with the rm command below:\n\nAfter following the steps of this article, you installed Docker on Debian, verified the installation, and learned how to remove Docker once it is no longer necessary.\n\nIf this is your first time working with Docker containers, read how to list, start, and stop Docker containers to get started."
    },
    {
        "link": "https://jumpcloud.com/blog/how-to-manage-apt-repositories-debian-ubuntu",
        "document": "Advanced Package Tool (APT) is the backbone of package management on Debian and Ubuntu systems. It simplifies the process of installing, updating, and removing software. APT works with repositories — designated locations that host packages and update information.\n\nMastering APT repository management ensures you have access to the software you need and that your system remains secure and up to date. This tutorial will guide you through how to manage APT repositories on Debian and Ubuntu systems.\n\nStep 1: Log In to Your Debian or Ubuntu Operating System\n\nIn our example, we will use Debian 12 but you are free to use any Debian or Ubuntu version.\n\nWe can log in to our server via a terminal or some SSH client installed on your local machine. If you’re using Linux or macOS, you can use the built-in terminal application or command line for this purpose. In case you are using the Windows operating system, you can use popular solutions such as PuTTY or Windows PowerShell with SSH.\n\nOpen the terminal or SSH client on your local machine and enter the username and IP address or hostname for your Debian or Ubuntu server.\n\nIn the terminal or SSH client, you can initiate the SSH connection by using the following command:\n\nIf you are connecting to the server for the first time, you will see a security warning about the authenticity of the host. Here you can verify that the displayed fingerprint matches the expected fingerprint by typing “yes” in the prompt.\n\nThe next prompt will ask you for the password, and after entering it, you will be logged into your system.\n\nAPT gets its packages from repositories defined in the /etc/apt/sources.list file and in the /etc/apt/sources.list.d/ directory. The sources.list file contains a list of “sources” or locations from which APT fetches packages. Each line in the file specifies a different source, starting with the type of archive (deb for binary packages and deb-src for source packages), followed by the URL of the repository, the distribution codename, and the repository sections.\n\nIn the screenshot above, we can see deb and deb-src packages belong to the bookworm distribution which is Debian 12, and the repository section main contains free and open source software officially supported by Debian. In the case we see the repository section called restricted, that is related to proprietary drivers.\n\nThe first step when adding custom repositories to our repository list is to make a backup of our current sources.list file.\n\nNext, we can open the sources.list file in our preferred text editor:\n\nThere we can paste the information about security-related repositories for our Debian version:\n\nWe can see that there are already repositories that are defined but we will add official ones for redundancy.\n\nPress Ctrl + W for writing changes and Ctrl + X to exit the file.\n\nNow we can run the following command:\n\nThis command will refresh the list of available updates and also include the repositories that we placed in our sources.list file.\n\nAs we can see in this example, the update command added a few packages that have pending updates.\n\nWe can check them by running the command:\n\nNext, we can add a new PPA or Personal Package Archives which are repositories designed for individual developers to deliver updates directly to users. This allows additional flexibility as you can often find some custom packages that are not available in official repositories.\n\nYou should research these archives and repositories thoroughly before installing them on your system since some of them could create errors and broken dependencies.\n\nWe can add the latest PHP version as part of ppa:ondrej/php for Debian. The first step is to import the GPG signing key.\n\nImporting GPG keys for APT repositories is crucial because it allows your package manager to verify the integrity and authenticity of the packages you download and install. It ensures that the packages have not been tampered with and are from a trusted source.\n\nThis command downloads the GPG key from the provided URL and saves it directly into the trusted.gpg.d directory, which is where APT looks for additional GPG keys beyond the default keyring.\n\nNext, we can add the repository:\n\nThis command adds a new source to the APT sources list for PHP packages provided by the “packages.sury.org” repository.\n\nNow we can sync the PPA with our local list, so we will run the update command again:\n\nNow we can install the latest PHP 8.3 version:\n\nWe can verify that our PHP version is installed by running the following command:\n\nRemoving a repository might be necessary if the source is no longer maintained, if it conflicts with other software sources, or if you no longer require the software provided by that repository. Disabling, on the other hand, does not remove the repository but temporarily turns it off, which can be useful for troubleshooting issues or testing the system without certain updates.\n\nUnderstanding how to effectively remove or disable repositories ensures that your system’s software sources remain reliable, up to date, and secure. This segment of the tutorial will delve into the practical steps and considerations for removing and disabling repositories on Debian and Ubuntu systems, ensuring that you are comfortable with this important segment of APT management.\n\nWe will look into disabling a repository first; this process is pretty straightforward. We need to comment on the line in our sources.list file.\n\nFirst, open sources.list file in your preferred text editor:\n\nHere, we need to comment out lines for repositories we want to exclude:\n\nTo remove the repository, the solution is to delete the line or lines completely from the sources.list file.\n\nIf we have custom PPAs that we want to remove, we can do so by first checking the sources.list.d directory where custom PPAs are stored.\n\nIn this example, we have our php.list that we installed previously, and there is one opencpn repository that is broken so we will remove it.\n\nWe can do so by removing the file directly:\n\nThe process is the same for any other custom PPA that is stored in the sources.list.d directory.\n\nAfter each repository is deleted, it is a good idea to run the update command again:\n\nAs we conclude our journey through managing APT repositories on Debian and Ubuntu systems, it’s imperative to recognize the balance between utilizing a rich ecosystem of software and maintaining the integrity and performance of your system.\n\nMastering the art of repository management — knowing how to add, remove, enable, and disable software sources — empowers you to customize your system to your needs while safeguarding against potential issues arising from incompatible or untrusted sources.\n\nThrough this tutorial, you’ve gained valuable insights into APT’s fundamental operations, learned to choose your sources carefully, and understood the significance of maintaining a clean and secure repository list. The repositories you choose to trust must be as crucial as the software you opt to install.\n\nBy applying the practices outlined here, you’re equipped to keep your system’s software management efficient and secure. As you move forward, continue to explore, validate sources, and keep your system’s health a top priority.\n\nIf you’d like to practice additional Debian or Ubuntu management skills, check out the following tutorials:\n• How to Configure AppArmor for Security on Debian or Ubuntu\n• How to Create Sudo Users for Debian\n• How to Get the Most Out of Ubuntu 23.04"
    },
    {
        "link": "https://wiki.debian.org/SecureApt",
        "document": "Debian uses strong cryptography to validate downloaded packages. This is commonly called \"secure apt\" (or \"apt-secure\") and was implemented in Apt version 0.6 in 2003, which Debian migrated to in 2005. Since the documentation (here and here) is fairly slim on how this all works from an administrator's point of view, this document will try to explain in detail how secure apt works and how to use it.\n\nThis article discusses things at a relatively high level. For details on the format of the files Debian repositories please refer to the DebianRepository/Format page. For detailed information on commands please refer to the man pages of the tools.\n\nHere are a few basic concepts that you'll need to understand for the rest of this document.\n\nA secure hash function (a type of checksum) is a method of taking a file and boiling it down to a reasonably short number that will uniquely identify the content of the file, even if people are deliberately trying to create a pair of different files with the same checksum or create a new file that matches a previous checksum. APT was originally designed around MD5 but people have since managed to construct collisions and so support for newer hash functions has been added.\n\nPublic key cryptography is based on pairs of keys, a public key and a private key. The public key is given out to the world; the private key must be kept a secret. Anyone possessing the public key can encrypt a message so that it can only be read by someone possessing the private key. It's also possible to use a private key to sign a file, not encrypt it. If a private key is used to sign a file, then anyone who has the public key can check that the file was signed by that key. Anyone who doesn't have the private key can't forge such a signature.\n\nThese keys are quite long numbers (at least 1024 bits, i.e. 256 or more hex digits and preferably a lot more), and to make them easier to work with they have a key id, which is a shorter, 8 or 16 digit number that can be used to refer to them. However care should be taken with key IDs, especially the short 8 character ID as it is possible to generate collisions.\n\napt-key is a program that is used to manage a keyring of OpenPGP keys for secure apt. The keyring is kept in the file /etc/apt/trusted.gpg (not to be confused with the related but not very interesting /etc/apt/trustdb.gpg). apt-key can be used to show the keys in the keyring, and to add or remove a key. In more recent Debian GNU/Linux versions (Wheezy, for example), the keyrings are stored in specific files all located in the /etc/apt/trusted.gpg.d directory. For example, that directory could contain the following files: debian-archive-squeeze-automatic.gpg or debian-archive-wheezy-automatic.gpg. Incidentally, both files are provided by the debian-archive-keyring package.\n\nA Debian archive contains a Release file, which is updated each time any of the packages in the archive change. Among other things, the Release file contains some checksums of other files in the archive. An excerpt of an example Release file:\n\nThese two checksums allow apt to verify that it has downloaded a correct copy of the Packages file, with a checksum that matches the one in the Release file. And when it downloads an individual package, it can also check its checksum against the content of the Packages file. If apt fails at either of these steps, it will abort.\n\nNone of this is new in secure apt, but it does provide the foundation. Notice that so far there is one file that apt doesn't have a way to check: The Release file. Secure apt is all about making apt verify the Release file before it does anything else with it, and plugging this hole, so that there is a chain of verification from the package that you are going to install all the way back to the provider of the package.\n\nTo plug the hole, secure apt adds an OpenPGP signature for the Release file. This is put in a file named Release.gpg that's shipped alongside the Release file. It looks something like this, although only an OpenPGP implementation actually looks at its contents normally:\n\nSecure apt always downloads Release.gpg files when it's downloading Release files, and if it cannot download the Release.gpg, or if the signature is bad, it will complain, and will make note that the Packages files that the Release file points to, and all the packages listed therein, are from an untrusted source. Here's how it looks during an apt-get update:\n\nNote that the second half of the long number is the key id of the key that apt doesn't know about, in this case that's 2D230C5F.\n\nIf you ignore that warning and try to install a package later, apt will warn again:\n\nIf you say Y here you have no way to know if the file you're getting is the package you're supposed to install, or if it's something else entirely that a black hat has arranged for you, containing a nasty surprise.\n\nIt's also worth noting that newer versions of the Debian installer use the same signed Release file mechanism during their debootstrap of the Debian base system, before apt is available, and that the installer even uses this system to verify pieces of itself that it downloads from the net. Also, Debian does not currently sign the Release files on its CDs; apt can be configured to always trust packages from CDs so this is not a large problem.\n\nSo the security of the whole system depends on there being a Release.gpg file, which signs a Release file, and of apt checking that signature using gpg. To check the signature, it has to know the public key of the person who signed the file. These keys are kept in apt's own keyring (/etc/apt/trusted.gpg), and managing the keys is where secure apt comes in.\n\nHere A428 5295 FC7B 1A81 6000 62A9 605C 66F0 0D6C 9793 is the key fingerprint, and notice that this key is only valid for a limited period. Debian occasionally rotates these keys as a last line of defense against some sort of security breach breaking a key.\n\nThat will make apt trust the official Debian archive, but if you add some other apt repository to /etc/apt/sources.list, you'll also have to give apt its key if you want apt to trust it. Once you have the key and have verified it, it's a simple matter of \"apt-key add file\" to add it. Getting the key and verifying it are the trickier part.\n\nFor other archives, there is not yet a standard location where you can find the key for a given apt repository. There's a rough standard of putting the key up on the web page for the repository or as a file in the repository itself, but no real standard, so you might have to hunt for it.\n\nThe current and the retired Debian archive \"signing\" keys are available from https://ftp-master.debian.org/keys.html.\n\nThe OpenPGP ecosystem has a standard way to distribute keys, using a keyserver that OpenPGP implementation can use to download a key from and add it to a keyring. For example with Sequoia-PGP:\n\nExternal/private repositories often provide their key in OpenPGP ASCII Armored (with the extension or ), this should be converted into OpenPGP binary format. Generally a key can be converted as:\n\nor in case of a specific URL you can use or to retrieve, convert and put the key into trusted keyring storage:\n\nBy adding a key to apt's keyring, you're telling apt to trust everything signed by the key, and this lets you know for sure that apt won't install anything not signed by the person who possesses the private key. But if you're sufficiently paranoid, you can see that this just pushes things up a level, now instead of having to worry if a package, or a Release file is valid, you can worry about whether you've actually gotten the right key. Is the information on https://ftp-master.debian.org/keys.html mentioned above correct or is this all some clever trap?\n\nIt's good to be paranoid in security, but verifying things from here is harder. OpenPGP has the concept of a chain of trust, which can start at someone you're sure of, who signs someone's key, who signs some other key, etc., until you get to the archive key. If you're sufficiently paranoid you'll want to check that your archive key is signed by a key that you can trust, with a trust chain that goes back to someone you know personally. If you want to do this, visit a Debian conference or perhaps a local LUG for a key signing.\n\nIf you can't afford this level of paranoia, do whatever feels appropriate to you when adding a new apt source and a new key. Maybe you'll want to mail the person providing the key and verify it, or maybe you're willing to take your chances with downloading it and assuming you got the real thing. The important thing is that by reducing the problem to what archive keys to trust, secure apt lets you be as careful and secure as it suits you to be.\n\nHere's a blog post with a procedure to verify the key's integrity. See also Securing Debian Manual, Chapter 7. Debian Security Infrastructure.\n\nSince secure apt was introduced, the keys used to sign the main Debian archive have changed a couple of times. Since secure apt is young, we don't have a great deal of experience with changing the key and there are still rough spots.\n\nIn January 2006, a new key for 2006 was made and the Release file began to be signed by it, but to try to avoid breaking systems that had the old 2005 key, the Release file was signed by that as well. The intent was that apt would accept one signature or the other depending on the key it had, but apt turned out to be buggy and refused to trust the file unless it had both keys and was able to check both signatures. This was fixed in apt version 0.6.43.1. There was also confusion about how the key was distributed to users who already had systems using secure apt; initially it was uploaded to the web site with no announcement and no real way to verify it and users were forced to download it by hand. This was fixed by the introduction of the debian-archive-keyring package, which manages apt keyring updates.\n\nIn late 2006, a new key was created that will be used to sign the archive for the lifetime of the Debian 4.0 release (until 2009-07-01). The archive began to be signed by this new key in addition to the yearly signing key for 2006. That was a bit confusing, because the key began to be used before it was announced and before debian-archive-keyring was updated to include it! Apt's warning message in this situation is slightly opaque to end users. There's obviously still room for improvement in how we roll out new keys. This new key does answer the question of how users of the 4.0 (etch) release will be able to validate their software for the lifetime of that release. This new key is also being used to sign other versions of Debian (like unstable).\n\nOn February 7th 2007, the 2006 key expired. Currently the only known breakage of this is that it broke rc1 of the etch installer, since the installer images only know about the 2006 key. Daily builds of the installer have the 2007 key and continue to work.\n\nMost recently, a new Etch stable release key has been added. This key is an offline key that will be used to sign releases of Etch (including point releases).\n\nThere are sometimes you want to manually check that a package hasn't been tampered since the time it was uploaded to the archive and the time you downloaded it. The apt system will take care of this procedure automatically, but in this section we will describe how to perform these safety tests manually.\n\nFirst, we're assuming you have downloaded the Release information from a trusted source (official Debian servers and mirrors). You'll need to check the Release file as the first step, for that you'll use the signature Release.gpg file, as in the following example.\n\nNote: You will have to import the public key for the archive, if it isn't in your keyring; and use your current distribution instead of \"sid\".\n\nAfter that you check the md5sums of the Packages file for each of the components. For example:\n\nFinally, we check the MD5 or SHA checksum of the package itself.\n• One not so obvious gotcha is that if your clock is very far off, secure apt will not work. If it's set to a date in the past, such as 1999, apt will fail with an unhelpful message such as this: Although apt-key list will make the problem plain: If it's set to a date too far in the future, apt will treat the keys as expired.\n• If apt gives a warning like this:\n• This means that the archive has begun to be signed by a new key, which your system does not know about. In this example, the new key is a dedicated key that will be used to sign the release of Debian 4.0. Since the archive was still signed by another key that apt knows about, this is just a warning, and once the system is fed the new key (by upgrading the debian-archive-keyring package), the warning will go away.\n• If you have the debsig-verify package installed, you might run into errors like this one: This actually has nothing to do with secure apt. debsig-verify checks for signatures embedded inside individual Debian packages. Since such signatures are not widely used (we use secure apt instead), it doesn't work very well to install this, and removing the debsig-verify package will fix the problem.\n• Publish the key fingerprint, that way your users will know what key they need to import in order to authenticate the files in the archive.\n\nWhenever the contents of the archive changes (new packages are added or removed) the archive maintainer has to follow the first two steps previously outlined.\n\nDon't be surprised if you attempt to and things do not work as expected. Additionally, trying to resolve the missing key with procedures on this page will fail too. If you encounter the issues, please file a bug report.\n\nBelow is a typical set of failures you will encounter using Debian Hurd as an example. Many ports fail the same way.\n\nDebian isn't Ubuntu and won't have sudo installed by default. It might be worth changing the usage of sudo, and making the examples use the root account explicitly -- SteveKemp\n\nGiven the failure modes I've seen from gpg --recv-keys, suggesting that a user run it as root doesn't seem wise to me. But I've never actually audited it either.. Despite sudo not being installed by default (in sarge), I think that most of the audience of this page are familiar with it, or can skip over it. -- JoeyHess\n\nDoes it make any sense to pre-install debian-server-keyring on every debian system? At least the user should be asked if s/he trusts this key. Until now (2006-01-07) the Debian Archive Automatic Signing Key is not in the strong set of keys. Thus is it not possible to test via pathfinders if there is a trust path from my key to the Debian Archive Automatic Signing Key. (See http://pgp.cs.uu.nl/ or http://www.lysator.liu.se/~jc/wotsap/search.html)\n\nYes, the debian-archive-keyring package will be our key upgrade path for all Debian systems, so it should be installed on all of them, and I assume will be in standard. -- JoeyHess\n\nI tried making a local repository using apt-move, serving machines running testing and stable. I could not use the same repository for both stable and testing due to incopatibilities between apt v5 and v6. You might highlight this when you get around to writing the bit about crating a repository. I could get v6 working for testing but not for sarge. --?MartinHodges\n\nWhat does it mean for md5sum to be broken? Since it's a checksum, I thought the only way it can be broken is that it fail to compute the proper checksum. I have a feeling some other meaning is intended. --?RossBoylan\n\n**it is broken as people were able to actually create a fake certificate that could sign anything and was trusted, they did this by finding a collision, they created a certificate that had the same md5 sum as the certificate they were issued, and where thereby able to give themselves right other than they were granted.--Scientes\n\nThe idea is that generating a checksum from a file is easy, but recreating a file from a checksum (or making another file generate the same checksum) is very hard (ideally, it would be impossible). \"md5sum is being broken\" means that that \"very hard\" path becomes quite possible. In other words, it is becoming (or maybe even has become) feasible to create a \"rogue\" Debian package that still generates the same checksum as the original true package. --JohnZaitseff\n\nDoes Secure APT cover the possibility that the archive machine itself is broken into? What is there to stop someone \"inserting\" a rogue version of a Debian package and simply regenerating the Packages and Release/Release.gpg files? I strongly suspect this has been considered, but this document does not mention it. Perhaps a link to appropriate documentation, if such exists? --JohnZaitseff\n\nYes, if this happens we can revoke the archive key, and introduce a new key for the new install of ftp-master and rollback of the archive to its last known good state that we'd have to do after such an incident. --JoeyHess\n\nIt might be worth linking to https://www.debian.org/doc/manuals/securing-debian-manual/deb-pack-sign.en.html#check-non-debian-releases as it explains briefly how to create the Release and Release.gpg files for repositories. --?JohnLamb\n\nI had a problem where apt gave the dreaded \"WARNING: The following packages cannot be authenticated\" message despite having debian-archive-keyring installed and having run \"apt-get update\". It turned out that my sources list contained instead of Apt found the packages file and could find all the debs, but it was not locating the Releases and Releases.gpg files. --AlexKing\n\nWould you add an explanation of why apt-get, apt-key, etc. might run into the GnuPG \"resource limit\" and how to fix it? This seems to result in the \"NO_PUBKEY\" warnings even if the respective keys are in the trustdb trusted.gpg. E.g.:\n\nNote: apt-key is in the process of being deprecated, at least for the managing of keys. Discussion in Debian bug 851774 ."
    },
    {
        "link": "https://labex.io/tutorials/linux-how-to-manage-and-secure-apt-repositories-on-linux-418179",
        "document": "APT (Advanced Package Tool) repositories are the primary source for installing and managing software packages on Debian-based Linux distributions, such as Ubuntu. These repositories are centralized collections of software packages that can be accessed and installed by users through the APT package management system.\n\nAt the core of an APT repository is the package index, which is a database that contains information about the available software packages, their versions, dependencies, and other metadata. This index allows the APT package manager to efficiently search, download, and install the desired packages on the user's system.\n\nAPT repositories can be categorized into different types, such as:\n• Official Repositories: These are the default repositories provided by the Linux distribution, which contain the core system packages and applications. They are typically well-maintained and secure.\n• Third-Party Repositories: These are repositories hosted by external sources, such as software vendors or community projects, that provide additional software packages not included in the official repositories.\n• Personal Repositories: Users or organizations can create their own APT repositories to host custom-built or modified software packages, making them available to a specific group of users.\n\nThe structure of an APT repository typically consists of several directories and files, including:\n• : This directory contains the distribution-specific information, such as release codenames, component names, and package metadata.\n• : This directory stores the actual package files, organized by component and package name.\n• : This is the main configuration file that tells the APT package manager where to find the available repositories.\n\nUnderstanding the structure and organization of APT repositories is crucial for effectively managing software packages on Debian-based Linux systems. By leveraging the power of these repositories, users can easily install, update, and remove software packages, ensuring a reliable and up-to-date system."
    },
    {
        "link": "https://serverfault.com/questions/111885/securely-restrict-access-to-a-private-debian-repository",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    },
    {
        "link": "https://unix.stackexchange.com/questions/332672/how-to-add-a-third-party-repo-and-key-in-debian",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    }
]