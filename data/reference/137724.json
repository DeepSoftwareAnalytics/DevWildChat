[
    {
        "link": "https://tip.golang.org/doc/go1.20",
        "document": "The latest Go release, version 1.20, arrives six months after Go 1.19. Most of its changes are in the implementation of the toolchain, runtime, and libraries. As always, the release maintains the Go 1 promise of compatibility. We expect almost all Go programs to continue to compile and run as before.\n\nChanges to the language\n\nGo 1.20 includes four changes to the language.\n\nGo 1.17 added conversions from slice to an array pointer. Go 1.20 extends this to allow conversions from a slice to an array: given a slice , can now be written instead of .\n\nThe package defines three new functions , , and . Along with Go 1.17’s , these functions now provide the complete ability to construct and deconstruct slice and string values, without depending on their exact representation.\n\nThe specification now defines that struct values are compared one field at a time, considering fields in the order they appear in the struct type definition, and stopping at the first mismatch. The specification could previously have been read as if all fields needed to be compared beyond the first mismatch. Similarly, the specification now defines that array values are compared one element at a time, in increasing index order. In both cases, the difference affects whether certain comparisons must panic. Existing programs are unchanged: the new spec wording describes what the implementations have always done.\n\nComparable types (such as ordinary interfaces) may now satisfy constraints, even if the type arguments are not strictly comparable (comparison may panic at runtime). This makes it possible to instantiate a type parameter constrained by (e.g., a type parameter for a user-defined generic map key) with a non-strictly comparable type argument such as an interface type, or a composite type containing an interface type.\n\nGo 1.20 is the last release that will run on any release of Windows 7, 8, Server 2008 and Server 2012. Go 1.21 will require at least Windows 10 or Server 2016.\n\nGo 1.20 is the last release that will run on macOS 10.13 High Sierra or 10.14 Mojave. Go 1.21 will require macOS 10.15 Catalina or later.\n\nGo 1.20 adds experimental support for FreeBSD on RISC-V ( , ).\n\nThe directory no longer stores pre-compiled package archives for the standard library: no longer writes them, the build no longer checks for them, and the Go distribution no longer ships them. Instead, packages in the standard library are built as needed and cached in the build cache, just like packages outside . This change reduces the size of the Go distribution and also avoids C toolchain skew for packages that use cgo.\n\nThe implementation of has been improved to make it more robust. Programs that run do not need any updates. Programs that invoke directly should now run the test binary with (for example, or ) instead of plain .\n\nA related change to is the addition of an event with set to at the beginning of each test program’s execution. When running multiple tests using the command, these start events are guaranteed to be emitted in the same order as the packages named on the command line.\n\nThe command now defines architecture feature build tags, such as , to allow selecting a package implementation file based on the presence or absence of a particular architecture feature. See for details.\n\nThe subcommands now accept to change directory to <dir> before performing the command, which may be useful for scripts that need to execute commands in multiple different modules.\n\nThe and commands no longer accept the flag, which has been deprecated since Go 1.16.\n\nThe command now accepts to skip directives matching .\n\nThe command now accepts to skip tests, subtests, or examples matching .\n\nWhen the main module is located within , no longer installs libraries for non- packages to , and no longer reports a field for such packages. (In module mode, compiled packages are stored in the build cache only, but a bug had caused the install targets to unexpectedly remain in effect.)\n\nThe , , and other build-related commands now support a flag that enables profile-guided optimization, which is described in more detail in the Compiler section below. The flag specifies the file path of the profile. Specifying causes the command to search for a file named in the main package’s directory and use it if present. This mode currently requires a single main package to be specified on the command line, but we plan to lift this restriction in a future release. Specifying turns off profile-guided optimization.\n\nThe , , and other build-related commands now support a flag that builds the specified target with code coverage instrumentation. This is described in more detail in the Cover section below.\n\nThe command now supports reading more types of Go binaries, most notably, Windows DLLs built with and Linux binaries without execute permission.\n\nThe command now disables by default on systems without a C toolchain. More specifically, when the environment variable is unset, the environment variable is unset, and the default C compiler (typically or ) is not found in the path, defaults to . As always, you can override the default by setting explicitly.\n\nThe most important effect of the default change is that when Go is installed on a system without a C compiler, it will now use pure Go builds for packages in the standard library that use cgo, instead of using pre-distributed package archives (which have been removed, as noted above) or attempting to use cgo and failing. This makes Go work better in some minimal container environments as well as on macOS, where pre-distributed package archives have not been used for cgo-based packages since Go 1.16.\n\nThe packages in the standard library that use cgo are , , and . On macOS, the and packages have been rewritten not to use cgo: the same code is now used for cgo and non-cgo builds as well as cross-compiled builds. On Windows, the and packages have never used cgo. On other systems, builds with cgo disabled will use a pure Go version of these packages.\n\nA consequence is that, on macOS, if Go code that uses the package is built with , linking the resulting archive into a C program requires passing when linking the C code.\n\nOn macOS, the race detector has been rewritten not to use cgo: race-detector-enabled programs can be built and run without Xcode. On Linux and other Unix systems, and on Windows, a host C toolchain is required to use the race detector.\n\nGo 1.20 supports collecting code coverage profiles for programs (applications and integration tests), as opposed to just unit tests.\n\nTo collect coverage data for a program, build it with ’s flag, then run the resulting binary with the environment variable set to an output directory for coverage profiles. See the ‘coverage for integration tests’ landing page for more on how to get started. For details on the design and implementation, see the proposal.\n\nThe tool now reports references to loop variables following a call to within subtest function bodies. Such references may observe the value of the variable from a different iteration (typically causing test cases to be skipped) or an invalid state due to unsynchronized concurrent access.\n\nThe tool also detects reference mistakes in more places. Previously it would only consider the last statement of the loop body, but now it recursively inspects the last statements within if, switch, and select statements.\n\nThe vet tool now reports use of the time format 2006-02-01 (yyyy-dd-mm) with and . This format does not appear in common date standards, but is frequently used by mistake when attempting to use the ISO 8601 date format (yyyy-mm-dd).\n\nSome of the garbage collector’s internal data structures were reorganized to be both more space and CPU efficient. This change reduces memory overheads and improves overall CPU performance by up to 2%.\n\nThe garbage collector behaves less erratically with respect to goroutine assists in some circumstances.\n\nGo 1.20 adds a new package containing APIs for writing coverage profile data at runtime from long-running and/or server programs that do not terminate via .\n\nGo 1.20 adds preview support for profile-guided optimization (PGO). PGO enables the toolchain to perform application- and workload-specific optimizations based on run-time profile information. Currently, the compiler supports pprof CPU profiles, which can be collected through usual means, such as the or packages. To enable PGO, pass the path of a pprof profile file via the flag to , as mentioned above. Go 1.20 uses PGO to more aggressively inline functions at hot call sites. Benchmarks for a representative set of Go programs show enabling profile-guided inlining optimization improves performance about 3–4%. See the PGO user guide for detailed documentation. We plan to add more profile-guided optimizations in future releases. Note that profile-guided optimization is a preview, so please use it with appropriate caution.\n\nThe Go 1.20 compiler upgraded its front-end to use a new way of handling the compiler’s internal data, which fixes several generic-types issues and enables type declarations within generic functions and methods.\n\nThe compiler now rejects anonymous interface cycles with a compiler error by default. These arise from tricky uses of embedded interfaces and have always had subtle correctness issues, yet we have no evidence that they’re actually used in practice. Assuming no reports from users adversely affected by this change, we plan to update the language specification for Go 1.22 to formally disallow them so tools authors can stop supporting them too.\n\nGo 1.18 and 1.19 saw regressions in build speed, largely due to the addition of support for generics and follow-on work. Go 1.20 improves build speeds by up to 10%, bringing it back in line with Go 1.17. Relative to Go 1.19, generated code performance is also generally slightly improved.\n\nOn Linux, the linker now selects the dynamic interpreter for or at link time.\n\nOn Windows, the Go linker now supports modern LLVM-based C toolchains.\n\nGo 1.20 uses and prefixes for compiler-generated symbols rather than and . This avoids confusion for user packages whose name starts with . The package understands this new naming convention for binaries built with Go 1.20 and newer.\n\nWhen building a Go release from source and is not set, previous versions of Go looked for a Go 1.4 or later bootstrap toolchain in the directory ( on Windows). Go 1.18 and Go 1.19 looked first for or before falling back to , in anticipation of requiring Go 1.17 for use when bootstrapping Go 1.20. Go 1.20 does require a Go 1.17 release for bootstrapping, but we realized that we should adopt the latest point release of the bootstrap toolchain, so it requires Go 1.17.13. Go 1.20 looks for or before falling back to (to support systems that hard-coded the path $HOME/go1.4 but have installed a newer Go toolchain there). In the future, we plan to move the bootstrap toolchain forward approximately once a year, and in particular we expect that Go 1.22 will require the final point release of Go 1.20 for bootstrap.\n\nGo 1.20 adds a new package to provide explicit support for Elliptic Curve Diffie-Hellman key exchanges over NIST curves and Curve25519.\n\nPrograms should use instead of the lower-level functionality in for ECDH, and third-party modules for more advanced use cases.\n\nGo 1.20 expands support for error wrapping to permit an error to wrap multiple other errors.\n\nAn error can wrap more than one error by providing an method that returns a .\n\nThe and functions have been updated to inspect multiply wrapped errors.\n\nThe function now supports multiple occurrences of the format verb, which will cause it to return an error that wraps all of those error operands.\n\nThe new function returns an error wrapping a list of errors.\n\nThe new type provides access to extended per-request functionality not handled by the interface.\n\nPreviously, we have added new per-request functionality by defining optional interfaces which a can implement, such as . These interfaces are not discoverable and clumsy to use.\n\nThe type provides a clearer, more discoverable way to add per-handler controls. Two such controls also added in Go 1.20 are and , which allow setting per-request read and write deadlines. For example:\n\nThe forwarding proxy includes a new hook function, superseding the previous hook.\n\nThe hook accepts a parameter, which includes both the inbound request received by the proxy and the outbound request that it will send. Unlike hooks, which only operate on the outbound request, this permits hooks to avoid certain scenarios where a malicious inbound request may cause headers added by the hook to be removed before forwarding. See issue #50580.\n\nThe method routes the outbound request to a provided destination and supersedes the function. Unlike , also sets the header of the outbound request.\n\nThe method sets the , , and headers of the outbound request. When using a , these headers are not added by default.\n\nAn example of a hook using these features is:\n\nno longer adds a header to forwarded requests when the incoming request does not have one.\n\nMinor changes to the library\n\nAs always, there are various minor changes and updates to the library, made with the Go 1 promise of compatibility in mind. There are also various performance improvements, not enumerated here.\n\nWhen the environment variable is set, method will now return the error for an entry with a file name that is an absolute path, refers to a location outside the current directory, contains invalid characters, or (on Windows) is a reserved name such as . A future version of Go may disable insecure paths by default.\n\nWhen the environment variable is set, will now return the error when opening an archive which contains any file name that is an absolute path, refers to a location outside the current directory, contains invalid characters, or (on Windows) is a reserved names such as . A future version of Go may disable insecure paths by default.\n\nReading from a directory file that contains file data will now return an error. The zip specification does not permit directory files to contain file data, so this change only affects reading from invalid archives.\n\nThe new and functions are like and but also report whether the string was trimmed.\n\nThe new function allocates a copy of a byte slice.\n\nThe new function provides a way to cancel a context with a given error. That error can be retrieved by calling the new function.\n\nWhen using supported curves, all operations are now implemented in constant time. This led to an increase in CPU time between 5% and 30%, mostly affecting P-384 and P-521.\n\nThe new method converts an to an .\n\nThe method and the function now support signing pre-hashed messages with Ed25519ph, indicated by an that returns . They also now support Ed25519ctx and Ed25519ph with context, indicated by setting the new field.\n\nThe new field allows configuring the MGF1 hash separately for OAEP decryption.\n\ncrypto/rsa now uses a new, safer, constant-time backend. This causes a CPU runtime increase for decryption operations between approximately 15% (RSA-2048 on amd64) and 45% (RSA-4096 on arm64), and more on 32-bit architectures. Encryption operations are approximately 20x slower than before (but still 5-10x faster than decryption). Performance is expected to improve in future releases. Programs must not modify or manually generate the fields of .\n\nThe new function XORs two byte slices together.\n\nParsed certificates are now shared across all clients actively using that certificate. The memory savings can be significant in programs that make many concurrent connections to a server or collection of servers sharing any part of their certificate chains.\n\nFor a handshake failure due to a certificate verification failure, the TLS client and server now return an error of the new type , which includes the presented certificates.\n\nand now support keys of type . and now support keys of type . Parsing NIST curve keys still returns values of type and . Use their new methods to convert to the types.\n\nThe new function allows a program to define a set of fallback root certificates in case an operating system verifier or standard platform root bundle is unavailable at runtime. It will most commonly be used with a new package, golang.org/x/crypto/x509roots/fallback, which will provide an up to date root bundle.\n\nAttempts to read from a section using or the reader returned by now return an error.\n\nAdditional constants are defined for use with LoongArch systems.\n\nAdditional constants are defined for use with PPC64 ELFv2 relocations.\n\nThe constant value for is corrected, from 61 to 62.\n\nDue to a change of Go’s symbol naming conventions, tools that process Go binaries should use Go 1.20’s package to transparently handle both old and new binaries.\n\nAdditional constants are defined for use with RISC-V systems.\n\nThe and functions will now return after reading a partial value, rather than .\n\nThe new method can be used to check for unclosed elements when finished encoding.\n\nThe decoder now rejects element and attribute names with more than one colon, such as , as well as namespaces that resolve to an empty string, such as .\n\nThe decoder now rejects elements that use different namespace prefixes in the opening and closing tag, even if those prefixes both denote the same namespace.\n\nThe new function returns an error wrapping a list of errors.\n\nThe function supports multiple occurrences of the format verb, returning an error that unwraps to the list of all arguments to .\n\nThe new function recovers the formatting directive corresponding to a , which can be useful in . implementations.\n\nThe new field records the position of the keyword in a range statement.\n\nThe new and fields record the position of the start and end of the entire source file.\n\nThe new method removes a file from a . Long-running programs can use this to release memory associated with files they no longer need.\n\nThe new function reports whether a type satisfies a constraint. This change aligns with the new language semantics that distinguish satisfying a constraint from implementing an interface.\n\nGo 1.20.3 and later disallow actions in ECMAScript 6 template literals. This behavior can be reverted by the setting.\n\nThe new wraps an underlying and provides , , and methods that adjust their effective file offset position by a fixed amount.\n\nThe new error terminates a immediately but successfully.\n\nThe math/big package’s wide scope and input-dependent timing make it ill-suited for implementing cryptography. The cryptography packages in the standard library no longer call non-trivial Int methods on attacker-controlled inputs. In the future, the determination of whether a bug in math/big is considered a security vulnerability will depend on its wider impact on the standard library.\n\nThe math/rand package now automatically seeds the global random number generator (used by top-level functions like and ) with a random value, and the top-level function has been deprecated. Programs that need a reproducible sequence of random numbers should prefer to allocate their own random source, using .\n\nPrograms that need the earlier consistent global seeding behavior can set in their environment.\n\nThe top-level function has been deprecated. In almost all cases, is more appropriate.\n\nThe function now allows duplicate parameter names, so long as the values of the names are the same.\n\nMethods of the type now wrap errors returned by the underlying .\n\nIn Go 1.19.8 and later, this package sets limits the size of the MIME data it processes to protect against malicious inputs. and limit the number of headers in a part to 10000 and limits the total number of headers in all to 10000. These limits may be adjusted with the setting. further limits the number of parts in a form to 1000. This limit may be adjusted with the setting.\n\nThe function now consistently returns the contents of a record when one exists. Previously on Unix systems and when using the pure Go resolver, would return an error if a record referred to a name that with no , , or record. This change modifies to match the previous behavior on Windows, allowing to succeed whenever a exists.\n\nnow includes the new flag , indicating an operationally active interface. An interface which is administratively configured but not active (for example, because the network cable is not connected) will have set but not .\n\nThe new field contains a callback function similar to the existing hook, that additionally accepts the dial context as a parameter. is ignored when is not nil.\n\nThe Go DNS resolver recognizes the resolver option. When is set in , the Go resolver will set the AD bit in DNS queries. The resolver does not make use of the AD bit in responses.\n\nDNS resolution will detect changes to and reload the file when it changes. Checks are made at most once every five seconds, matching the previous handling of and .\n\nThe new configuration setting allows disabling the default handler.\n\nThe new hook is called when a receives an HTTP response from a proxy for a request.\n\nThe HTTP server now accepts HEAD requests containing a body, rather than rejecting them as invalid.\n\nHTTP/2 stream errors returned by functions may be converted to a using .\n\nLeading and trailing spaces are trimmed from cookie names, rather than being rejected as invalid. For example, a cookie setting of “name =value” is now accepted as setting the cookie “name”.\n\nA with an empty Expires field is now considered valid. only checks Expires when it is set.\n\nThe new and functions are the equivalents of and .\n\nOn Windows, the name is no longer treated as a special case in and .\n\nOn Windows, now uses the file handle to retrieve attributes when the file is a directory. Previously it would use the path passed to , which may no longer be the file represented by the file handle if the file has been moved or replaced. This change modifies to open directories without the access, which match the behavior of regular files.\n\nOn Windows, now supports seeking to the beginning of a directory.\n\nThe new fields and specify the behavior of the when its associated is canceled or its process exits with I/O pipes still held open by a child process.\n\nThe new error terminates a immediately but successfully.\n\nThe new function reports whether a path is lexically local to a directory. For example, if is , then will refer to a file that is lexically within the subtree rooted at the current directory.\n\nThe new and methods can be used to compare two s for equality. reports whether is a valid operation for a given receiver.\n\nThe new method extends a slice to guarantee space for another elements.\n\nThe new method sets a value to be the zero value for its type.\n\nGo 1.18 introduced and methods. These are optimizations: is meant to be equivalent to . The implementations incorrectly omitted a check for use of unexported fields that was present in the unoptimized forms. Go 1.20 corrects these methods to include the unexported field check.\n\nGo 1.19.2 and Go 1.18.7 included a security fix to the regular expression parser, making it reject very large expressions that would consume too much memory. Because Go patch releases do not introduce new API, the parser returned in this case. Go 1.20 adds a more specific error, , which the parser now returns instead.\n\nGo 1.20 adds new marker type. Code generated by cgo will use to mark an incomplete C type.\n\nGo 1.20 adds new supported metrics, including the current setting ( ), the number of cgo calls executed ( ), total mutex block time ( ), and various measures of time spent in garbage collection.\n\nTime-based histogram metrics are now less precise, but take up much less memory.\n\nMutex profile samples are now pre-scaled, fixing an issue where old mutex profile samples would be scaled incorrectly if the sampling rate changed during execution.\n\nProfiles collected on Windows now include memory mapping information that fixes symbolization issues for position-independent binaries.\n\nThe garbage collector’s background sweeper now yields less frequently, resulting in many fewer extraneous events in execution traces.\n\nThe new and functions are like and but also report whether the string was trimmed.\n\nThe new methods , , and allow existing map entries to be updated atomically.\n\nOn FreeBSD, compatibility shims needed for FreeBSD 11 and earlier have been removed.\n\nOn Linux, additional constants are defined for use with the field.\n\nOn Linux, the new and fields provide a way to place a child process into a specific cgroup.\n\nThe new method reports the current elapsed time of the benchmark, which may be useful for calculating rates to report with .\n\nCalling from a function passed to was never well-defined, and will now panic.\n\nThe new time layout constants , , and provide names for three of the most common layout strings used in a survey of public Go source code.\n\nThe new method compares two times.\n\nnow ignores sub-nanosecond precision in its input, instead of reporting those digits as an error.\n\nThe method is now more strict about adherence to RFC 3339.\n\nThe new function appends the UTF-16 encoding of a given rune to a uint16 slice, analogous to ."
    },
    {
        "link": "https://pkg.go.dev/context",
        "document": "Package context defines the Context type, which carries deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes. Incoming requests to a server should create a Context, and outgoing calls to servers should accept a Context. The chain of function calls between them must propagate the Context, optionally replacing it with a derived Context created using WithCancel, WithDeadline, WithTimeout, or WithValue. A Context may be canceled to indicate that work done on its behalf should stop. A Context with a deadline is canceled after the deadline passes. When a Context is canceled, all Contexts derived from it are also canceled. The WithCancel, WithDeadline, and WithTimeout functions take a Context (the parent) and return a derived Context (the child) and a CancelFunc. Calling the CancelFunc directly cancels the child and its children, removes the parent's reference to the child, and stops any associated timers. Failing to call the CancelFunc leaks the child and its children until the parent is canceled. The go vet tool checks that CancelFuncs are used on all control-flow paths. The WithCancelCause, WithDeadlineCause, and WithTimeoutCause functions return a CancelCauseFunc, which takes an error and records it as the cancellation cause. Calling Cause on the canceled context or any of its children retrieves the cause. If no cause is specified, Cause(ctx) returns the same value as ctx.Err(). Programs that use Contexts should follow these rules to keep interfaces consistent across packages and enable static analysis tools to check context propagation: Do not store Contexts inside a struct type; instead, pass a Context explicitly to each function that needs it. This is discussed further in https://go.dev/blog/context-and-structs. The Context should be the first parameter, typically named ctx: Do not pass a nil Context, even if a function permits it. Pass context.TODO if you are unsure about which Context to use. Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions. The same Context may be passed to functions running in different goroutines; Contexts are safe for simultaneous use by multiple goroutines. See https://go.dev/blog/context for example code for a server that uses Contexts.\n\nAfterFunc arranges to call f in its own goroutine after ctx is canceled. If ctx is already canceled, AfterFunc calls f immediately in its own goroutine. Multiple calls to AfterFunc on a context operate independently; one does not replace another. Calling the returned stop function stops the association of ctx with f. It returns true if the call stopped f from being run. If stop returns false, either the context is canceled and f has been started in its own goroutine; or f was already stopped. The stop function does not wait for f to complete before returning. If the caller needs to know whether f is completed, it must coordinate with f explicitly. If ctx has a \"AfterFunc(func()) func() bool\" method, AfterFunc will use it to schedule the call. This example uses AfterFunc to define a function which waits on a sync.Cond, stopping the wait when a context is canceled. package main import ( \"context\" \"fmt\" \"sync\" \"time\" ) func main() { waitOnCond := func(ctx context.Context, cond *sync.Cond, conditionMet func() bool) error { stopf := context.AfterFunc(ctx, func() { // We need to acquire cond.L here to be sure that the Broadcast // below won't occur before the call to Wait, which would result // in a missed signal (and deadlock). cond.L.Lock() defer cond.L.Unlock() // If multiple goroutines are waiting on cond simultaneously, // we need to make sure we wake up exactly this one. // That means that we need to Broadcast to all of the goroutines, // which will wake them all up. // // If there are N concurrent calls to waitOnCond, each of the goroutines // will spuriously wake up O(N) other goroutines that aren't ready yet, // so this will cause the overall CPU cost to be O(N²). cond.Broadcast() }) defer stopf() // Since the wakeups are using Broadcast instead of Signal, this call to // Wait may unblock due to some other goroutine's context being canceled, // so to be sure that ctx is actually canceled we need to check it in a loop. for !conditionMet() { cond.Wait() if ctx.Err() != nil { return ctx.Err() } } return nil } cond := sync.NewCond(new(sync.Mutex)) var wg sync.WaitGroup for i := 0; i < 4; i++ { wg.Add(1) go func() { defer wg.Done() ctx, cancel := context.WithTimeout(context.Background(), 1*time.Millisecond) defer cancel() cond.L.Lock() defer cond.L.Unlock() err := waitOnCond(ctx, cond, func() bool { return false }) fmt.Println(err) }() } wg.Wait() } This example uses AfterFunc to define a function which reads from a net.Conn, stopping the read when a context is canceled. package main import ( \"context\" \"fmt\" \"net\" \"time\" ) func main() { readFromConn := func(ctx context.Context, conn net.Conn, b []byte) (n int, err error) { stopc := make(chan struct{}) stop := context.AfterFunc(ctx, func() { conn.SetReadDeadline(time.Now()) close(stopc) }) n, err = conn.Read(b) if !stop() { // The AfterFunc was started. // Wait for it to complete, and reset the Conn's deadline. <-stopc conn.SetReadDeadline(time.Time{}) return n, ctx.Err() } return n, err } listener, err := net.Listen(\"tcp\", \"localhost:0\") if err != nil { fmt.Println(err) return } defer listener.Close() conn, err := net.Dial(listener.Addr().Network(), listener.Addr().String()) if err != nil { fmt.Println(err) return } defer conn.Close() ctx, cancel := context.WithTimeout(context.Background(), 1*time.Millisecond) defer cancel() b := make([]byte, 1024) _, err = readFromConn(ctx, conn, b) fmt.Println(err) } This example uses AfterFunc to define a function which combines the cancellation signals of two Contexts. package main import ( \"context\" \"errors\" \"fmt\" ) func main() { // mergeCancel returns a context that contains the values of ctx, // and which is canceled when either ctx or cancelCtx is canceled. mergeCancel := func(ctx, cancelCtx context.Context) (context.Context, context.CancelFunc) { ctx, cancel := context.WithCancelCause(ctx) stop := context.AfterFunc(cancelCtx, func() { cancel(context.Cause(cancelCtx)) }) return ctx, func() { stop() cancel(context.Canceled) } } ctx1, cancel1 := context.WithCancelCause(context.Background()) defer cancel1(errors.New(\"ctx1 canceled\")) ctx2, cancel2 := context.WithCancelCause(context.Background()) mergedCtx, mergedCancel := mergeCancel(ctx1, ctx2) defer mergedCancel() cancel2(errors.New(\"ctx2 canceled\")) <-mergedCtx.Done() fmt.Println(context.Cause(mergedCtx)) } Cause returns a non-nil error explaining why c was canceled. The first cancellation of c or one of its parents sets the cause. If that cancellation happened via a call to CancelCauseFunc(err), then Cause returns err. Otherwise Cause(c) returns the same value as c.Err(). Cause returns nil if c has not been canceled yet. WithCancel returns a derived context that points to the parent context but has a new Done channel. The returned context's Done channel is closed when the returned cancel function is called or when the parent context's Done channel is closed, whichever happens first. Canceling this context releases resources associated with it, so code should call cancel as soon as the operations running in this Context complete. This example demonstrates the use of a cancelable context to prevent a goroutine leak. By the end of the example function, the goroutine started by gen will return without leaking. package main import ( \"context\" \"fmt\" ) func main() { // gen generates integers in a separate goroutine and // sends them to the returned channel. // The callers of gen need to cancel the context once // they are done consuming generated integers not to leak // the internal goroutine started by gen. gen := func(ctx context.Context) <-chan int { dst := make(chan int) n := 1 go func() { for { select { case <-ctx.Done(): return // returning not to leak the goroutine case dst <- n: n++ } } }() return dst } ctx, cancel := context.WithCancel(context.Background()) defer cancel() // cancel when we are finished consuming integers for n := range gen(ctx) { fmt.Println(n) if n == 5 { break } } } WithCancelCause behaves like WithCancel but returns a CancelCauseFunc instead of a CancelFunc. Calling cancel with a non-nil error (the \"cause\") records that error in ctx; it can then be retrieved using Cause(ctx). Calling cancel with nil sets the cause to Canceled. WithDeadline returns a derived context that points to the parent context but has the deadline adjusted to be no later than d. If the parent's deadline is already earlier than d, WithDeadline(parent, d) is semantically equivalent to parent. The returned [Context.Done] channel is closed when the deadline expires, when the returned cancel function is called, or when the parent context's Done channel is closed, whichever happens first. Canceling this context releases resources associated with it, so code should call cancel as soon as the operations running in this Context complete. This example passes a context with an arbitrary deadline to tell a blocking function that it should abandon its work as soon as it gets to it. d := time.Now().Add(shortDuration) ctx, cancel := context.WithDeadline(context.Background(), d) // Even though ctx will be expired, it is good practice to call its // cancellation function in any case. Failure to do so may keep the // context and its parent alive longer than necessary. defer cancel() select { case <-neverReady: fmt.Println(\"ready\") case <-ctx.Done(): fmt.Println(ctx.Err()) } WithDeadlineCause behaves like WithDeadline but also sets the cause of the returned Context when the deadline is exceeded. The returned CancelFunc does not set the cause. Canceling this context releases resources associated with it, so code should call cancel as soon as the operations running in this Context complete: This example passes a context with a timeout to tell a blocking function that it should abandon its work after the timeout elapses. // Pass a context with a timeout to tell a blocking function that it // should abandon its work after the timeout elapses. ctx, cancel := context.WithTimeout(context.Background(), shortDuration) defer cancel() select { case <-neverReady: fmt.Println(\"ready\") case <-ctx.Done(): fmt.Println(ctx.Err()) // prints \"context deadline exceeded\" } WithTimeoutCause behaves like WithTimeout but also sets the cause of the returned Context when the timeout expires. The returned CancelFunc does not set the cause.\n\nA CancelCauseFunc behaves like a CancelFunc but additionally sets the cancellation cause. This cause can be retrieved by calling Cause on the canceled Context or on any of its derived Contexts. If the context has already been canceled, CancelCauseFunc does not set the cause. For example, if childContext is derived from parentContext:\n• if parentContext is canceled with cause1 before childContext is canceled with cause2, then Cause(parentContext) == Cause(childContext) == cause1\n• if childContext is canceled with cause2 before parentContext is canceled with cause1, then Cause(parentContext) == cause1 and Cause(childContext) == cause2 A CancelFunc tells an operation to abandon its work. A CancelFunc does not wait for the work to stop. A CancelFunc may be called by multiple goroutines simultaneously. After the first call, subsequent calls to a CancelFunc do nothing. type Context interface { Deadline() (deadline time.Time, ok bool) Done() <-chan struct{} Err() error Value(key any) any } A Context carries a deadline, a cancellation signal, and other values across API boundaries. Context's methods may be called by multiple goroutines simultaneously. Background returns a non-nil, empty Context. It is never canceled, has no values, and has no deadline. It is typically used by the main function, initialization, and tests, and as the top-level Context for incoming requests. TODO returns a non-nil, empty Context. Code should use context.TODO when it's unclear which Context to use or it is not yet available (because the surrounding function has not yet been extended to accept a Context parameter). WithValue returns a derived context that points to the parent Context. In the derived context, the value associated with key is val. Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions. The provided key must be comparable and should not be of type string or any other built-in type to avoid collisions between packages using context. Users of WithValue should define their own types for keys. To avoid allocating when assigning to an interface{}, context keys often have concrete type struct{}. Alternatively, exported context key variables' static type should be a pointer or interface. This example demonstrates how a value can be passed to the context and also how to retrieve it if it exists. package main import ( \"context\" \"fmt\" ) func main() { type favContextKey string f := func(ctx context.Context, k favContextKey) { if v := ctx.Value(k); v != nil { fmt.Println(\"found value:\", v) return } fmt.Println(\"key not found:\", k) } k := favContextKey(\"language\") ctx := context.WithValue(context.Background(), k, \"Go\") f(ctx, k) f(ctx, favContextKey(\"color\")) } found value: Go key not found: color WithoutCancel returns a derived context that points to the parent context and is not canceled when parent is canceled. The returned context returns no Deadline or Err, and its Done channel is nil. Calling Cause on the returned context returns nil."
    },
    {
        "link": "https://medium.com/@jamal.kaksouri/the-complete-guide-to-context-in-golang-efficient-concurrency-management-43d722f6eaea",
        "document": "Concurrency is a fundamental aspect of Go programming, and effectively managing concurrent operations is crucial for building robust and efficient applications. One of the key features that aids in achieving this is the Context package in Golang. Context provides a mechanism to control the lifecycle, cancellation, and propagation of requests across multiple goroutines. In this comprehensive guide, we will delve into the depths of context in Golang, exploring its purpose, usage, and best practices with real-world examples from the software industry.\n• Best Practices for Using Context\n\nContext is a built-in package in the Go standard library that provides a powerful toolset for managing concurrent operations. It enables the propagation of cancellation signals, deadlines, and values across goroutines, ensuring that related operations can gracefully terminate when necessary. With context, you can create a hierarchy of goroutines and pass important information down the chain.\n\nConsider a scenario where you need to fetch data from multiple APIs concurrently. By using context, you can ensure that all the API requests are canceled if any of them exceeds a specified timeout.\n\nIn this example, we create a context with a timeout of 5 seconds. We then launch multiple goroutines to fetch data from different APIs concurrently. The function is used to create an HTTP request with the provided context. If any of the API requests exceed the timeout duration, the context's cancellation signal is propagated, canceling all other ongoing requests.\n\nTo create a context, you can use the function, which returns an empty, non-cancelable context as the root of the context tree. You can also create a context with a specific timeout or deadline using or functions.\n\nIn this example, we create a context with a timeout of 2 seconds and use it to simulate a time-consuming operation.\n\nIn this example, the function simulates a long-running task that takes 5 seconds to complete. However, since the context has a timeout of only 2 seconds, the operation is terminated prematurely, resulting in a timeout.\n\nOnce you have a context, you can propagate it to downstream functions or goroutines by passing it as an argument. This allows related operations to share the same context and be aware of its cancellation or other values.\n\nIn this example, we create a parent context and propagate it to multiple goroutines to perform concurrent tasks.\n\nIn this example, we create a parent context using . We then use to attach a user ID to the context. The context is then passed to the goroutine, which retrieves the user ID using .\n\nIn addition to propagating context, you can also retrieve values stored within the context. This allows you to access important data or parameters within the scope of a specific goroutine or function.\n\nIn this example, we create a context with user information and retrieve it in a downstream function.\n\nIn this example, we create a context using and store the user ID. The context is then passed to the function, where we retrieve the user ID using type assertion and use it for further processing.\n\nCancellation is an essential aspect of context management. It allows you to gracefully terminate operations and propagate cancellation signals to related goroutines. By canceling a context, you can avoid resource leaks and ensure the timely termination of concurrent operations.\n\nIn this example, we create a context and cancel it to stop ongoing operations.\n\nIn this example, we create a context using and defer the cancellation function. The goroutine continuously performs a task until the context is canceled. After 2 seconds, we call the cancel function to initiate the cancellation process. As a result, the goroutine detects the cancellation signal and terminates the task.\n\nSetting timeouts and deadlines is crucial when working with context in Golang. It ensures that operations complete within a specified timeframe and prevents potential bottlenecks or indefinite waits.\n\nIn this example, we create a context with a deadline and perform a task that exceeds the deadline.\n\nIn this example, we create a context with a deadline of 2 seconds using . The goroutine waits for the context to be canceled or for the deadline to be exceeded. After 3 seconds, we let the program exit, triggering the deadline exceeded error.\n\nContext plays a vital role in managing HTTP requests in Go. It allows you to control request cancellation, timeouts, and pass important values to downstream handlers.\n\nExample: Using Context in HTTP Requests\n\nIn this example, we make an HTTP request with a custom context and handle timeouts.\n\nIn this example, we create a context with a timeout of 2 seconds using . We then create an HTTP request with the custom context using . The context ensures that if the request takes longer than the specified timeout, it will be canceled.\n\nContext is also useful when dealing with database operations in Golang. It allows you to manage query cancellations, timeouts, and pass relevant data within the database transactions.\n\nExample: Using Context in Database Operations\n\nIn this example, we demonstrate how to use context with a PostgreSQL database operation.\n\nIn this example, we create a context with a timeout of 2 seconds using . We then open a connection to a PostgreSQL database using the function. When executing the database query with , the context ensures that the operation will be canceled if it exceeds the specified timeout.\n\n9. Best Practices for Using Context\n\nWhen working with context in Golang, it is essential to follow some best practices to ensure efficient and reliable concurrency management.\n\nExample: Implementing Best Practices for Context Usage\n\nHere are some best practices to consider:\n• Pass Context Explicitly: Always pass the context as an explicit argument to functions or goroutines instead of using global variables. This makes it easier to manage the context’s lifecycle and prevents potential data races.\n• Use context.TODO(): If you are unsure which context to use in a particular scenario, consider using . However, make sure to replace it with the appropriate context later.\n• Avoid Using context.Background(): Instead of using directly, create a specific context using or to manage its lifecycle and avoid resource leaks.\n• Prefer Cancel Over Timeout: Use for cancellation when possible, as it allows you to explicitly trigger cancellation when needed. is more suitable when you need an automatic cancellation mechanism.\n• Keep Context Size Small: Avoid storing large or unnecessary data in the context. Only include the data required for the specific operation.\n• Avoid Chaining Contexts: Chaining contexts can lead to confusion and make it challenging to manage the context hierarchy. Instead, propagate a single context throughout the application.\n• Be Mindful of Goroutine Leaks: Always ensure that goroutines associated with a context are properly closed or terminated to avoid goroutine leaks.\n\nContext in Golang is widely used in various real-world scenarios. Let’s explore some practical examples where context plays a crucial role.\n\nIn a microservices architecture, each service often relies on various external dependencies and communicates with other services. Context can be used to propagate important information, such as authentication tokens, request metadata, or tracing identifiers, throughout the service interactions.\n\nWeb servers handle multiple concurrent requests, and context helps manage the lifecycle of each request. Context can be used to set timeouts, propagate cancellation signals, and pass request-specific values to the different layers of a web server application.\n\nWhen writing test suites, context can be utilized to manage test timeouts, control test-specific configurations, and enable graceful termination of tests. Context allows tests to be canceled or skipped based on certain conditions, enhancing test control and flexibility.\n• Not propagating the context — Child functions need the context passed to them in order to honor cancelation. Don’t create contexts and keep them confined to one function.\n• Forgetting to call cancel — When done with a cancelable context, call the cancel function. This releases resources and stops any associated goroutines.\n• Leaking goroutines — Goroutines started with a context must check the Done channel to exit properly. Otherwise they risk leaking when the context is canceled.\n• Using basic context.Background for everything — Background lacks cancelation and timeouts. Use the WithCancel, WithTimeout, or WithDeadline functions to add control.\n• Passing nil contexts — Passing nil instead of a real context causes panics. Make sure context is never nil when passing it.\n• Checking context too early — Don’t check context conditions like Done() early in an operation. This risks canceling before the work starts.\n• Using blocking calls — Blocking calls like file/network IO should be wrapped to check context cancellation. This avoids hanging.\n• Overusing contexts — Contexts are best for request-scoped operations. For globally shared resources, traditional patterns may be better.\n• Assuming contexts have timeouts — The context.Background has no deadline. Add timeouts explicitly when needed.\n• Forgetting contexts expire — Don’t start goroutines with a context and assume they will run forever. The context may expire.\n\nContexts in Go are used to manage the lifecycle and cancellation signaling of goroutines and other operations. A root context is usually created, and child contexts can be derived from it. Child contexts inherit cancellation from their parent contexts.\n\nIf a goroutine is started with a context, but does not properly exit when that context is canceled, it can result in a goroutine leak. The goroutine will persist even though the operation it was handling has been canceled.\n\nHere is an example of a goroutine leak due to improper context handling:\n\nIn this example, the goroutine started with the context does not properly exit when that context is canceled. This will result in a goroutine leak, even though the main context is canceled.\n\nTo fix it, the goroutine needs to call the context’s Done() channel when the main context is canceled:\n\nNow the goroutine will cleanly exit when the parent context is canceled, avoiding the leak. Proper context propagation and lifetime management is key to preventing goroutine leaks in Go programs.\n\nSometimes we need using third-party packages. However, many third-party libraries and APIs do not natively support context. So when using such libraries, you need to take some additional steps to integrate context usage properly:\n• Wrap the third-party APIs you call in functions that accept a context parameter.\n• In the wrapper function, call the third-party API as normal.\n• Before calling the API, check if the context is done and return immediately if so. This propagates cancellation.\n• After calling the API, check if the context is done and return immediately if so. This provides early return on cancellation.\n• Make sure to call the API in a goroutine if it involves long-running work that could block.\n• Define reasonable defaults for context values like timeout and deadline, so the API call isn’t open-ended.\n\nThis provides context integration even with APIs that don’t natively support it. The key points are wrapping API calls, propagating cancellation, using goroutines, and setting reasonable defaults.\n\nManaging cleanup and finalization tasks is an important consideration in Go, especially when dealing with concurrency. The context package provides a useful tool for this through its function.\n\nallows you to schedule functions to run asynchronously after a context ends. This enables deferred cleanup routines that will execute reliably once some operation is complete.\n\nFor example, imagine we have an API server that needs to process incoming requests from a queue. We spawn goroutines to handle each request:\n\nBut we also want to make sure any pending requests are processed if handleRequests has to exit unexpectedly. This is where can help.\n\nWe can schedule a cleanup function to run after the context is cancelled:\n\nNow our cleanup logic will run after the context ends. But since we call stop(), it is canceled before executing.\n\nallows deferred execution tied to a context’s lifetime. This provides a robust way to build asynchronous applications with proper finalization.\n\nWhen using contexts with deadlines in Go, timeout errors are common — a context will routinely expire if an operation takes too long. But the generic “context deadline exceeded” error lacks detail on the source of the timeout.\n\nThis is where comes in handy. It allows you to associate a custom error cause with a context’s deadline:\n\nNow if the deadline is exceeded, the context’s Err() method will return:\n\nThis extra cause string gives critical context on the source of the timeout. Maybe it was due to a backend RPC call failing, or a network request timing out.\n\nWithout the cause, debugging the timeout requires piecing together where it came from based on call stacks and logs. But allows directly propagating the source of the timeout through the context.\n\nTimeouts tend to cascade through systems — a low-level timeout bubbles up to eventually become an HTTP 500. Maintaining visibility into the original cause is crucial for diagnosing these issues.\n\nenables this by letting you customize the deadline exceeded error with contextual details. The error can then be inspected at any level of the stack to understand the timeout source.\n\nManaging timeouts is an important aspect of writing reliable Go programs. When using context timeouts, the error “context deadline exceeded” is generic and lacks detail on the source of the timeout.\n\nThe function addresses this by allowing you to associate a custom error cause with a context’s timeout duration:\n\nNow if that ctx hits the timeout deadline, the context’s Err() will return:\n\nThis provides critical visibility into the source of the timeout when it propagates up a call stack. Maybe it was caused by a slow database query, or a backend RPC service timing out.\n\nWithout a customized cause, debugging timeouts requires piecing together logs and traces to determine where it originated. But allows directly encoding the source of the timeout into the context error.\n\nSome key benefits of using :\n• More context for handling and recovering from timeout errors\n\ngives more control over timeout errors to better handle them programmatically and debug them when issues arise.\n\nIn Go, contexts form parent-child relationships — a canceled parent context will propagate down and cancel all children. This allows canceling an entire tree of operations.\n\nHowever, sometimes you want to branch off a child context and detach it from the parent’s lifetime. This is useful when you have a goroutine or operation that needs to keep running independently, even if the parent context is canceled.\n\nFor example, consider a server handling incoming requests:\n\nIf the parent ctx is canceled, the handleRequest goroutines will be abruptly canceled as well. This may interrupt requests that are mid-flight.\n\nWe can use to ensure the handler goroutines finish:\n\nNow the parent can be canceled, but each handler finishes independently.\n\nlets you selectively extract parts of a context tree to isolate from cancelation. This provides more fine-grained control over concurrency when using contexts.\n\nIn conclusion, understanding and effectively using context in Golang is crucial for developing robust and efficient applications. Context provides a powerful tool for managing concurrency, controlling request lifecycles, and handling cancellations and timeouts.\n\nBy creating, propagating, and canceling contexts, you can ensure proper handling of concurrent operations, control resource utilization, and enhance the overall reliability of your applications.\n\nRemember to follow best practices when working with context and consider real-world scenarios where context can significantly improve the performance and reliability of your Golang applications.\n\nWith a strong grasp of context, you’ll be well-equipped to tackle complex concurrency challenges and build scalable and responsive software systems.\n\nQ1: Can I pass custom values in the context?\n\nYes, you can pass custom values in the context using the function. It allows you to associate key-value pairs with the context, enabling the sharing of specific data across different goroutines or functions.\n\nWhen a context is canceled or times out, the function returns an error explaining the reason for cancellation. You can handle this error and take appropriate actions based on your application's requirements.\n\nYes, you can create a hierarchy of contexts by using and passing the parent context as an argument. However, it's important to consider the potential complexity and overhead introduced by nested contexts, and ensure proper management of the context lifecycle.\n\nQ4: Is it possible to pass context through HTTP middleware?\n\nYes, you can pass context through HTTP middleware to propagate values, manage timeouts, or handle cancellation. Middleware intercepts incoming requests and can enrich the request context with additional information or modify the existing context.\n\nQ5: How does context help with graceful shutdowns?\n\nContext allows you to propagate cancellation signals to goroutines, enabling graceful shutdowns of concurrent operations. By canceling the context, you can signal goroutines to complete their tasks and release any resources they hold before terminating.\n\nI hope this comprehensive guide on context in Golang has provided you with a deep understanding of its importance and practical usage. By leveraging the power of context, you can write efficient, scalable, and robust Golang applications.\n\nThank you for reading!\n\nPlease note that the examples provided in this article are for illustrative purposes only and may require additional code and error handling in real-world scenarios."
    },
    {
        "link": "https://levelup.gitconnected.com/gos-context-package-demystified-types-examples-and-use-cases-18bd8e9a3e90",
        "document": "Concurrency is a core feature of the Go programming language, making it a popular choice for building scalable and efficient applications. However, managing concurrent operations, especially in a networked environment, can be challenging. This is where the `context` package in Go comes to the rescue. In this article, we’ll explore the Go `context` package in depth, covering its various types, their purposes, complete applied examples, applicability, and best practices.\n\nThe function returns an empty context that serves as a starting point for other context types. It is often used when no specific context is available or needed.\n• Setting the initial context in a function or application.\n• When there is no parent context to inherit from.\n• Use as the starting point when creating other context types.\n\nThe function creates a context with a cancellation signal. It allows you to gracefully cancel long-running operations when they are no longer needed, avoiding resource leaks and speeding up application shutdowns.\n• Cancelling background tasks, such as database queries or HTTP requests, upon user or system request.\n• Always defer the cancellation function to ensure it is called when the operation completes or when needed.\n\nThe function creates a context with a specified deadline. It is used to set time limits for operations, allowing you to handle timeouts gracefully.\n• Enforcing timeouts on operations that should complete within a certain time frame.\n• Always specify a clear deadline to avoid unexpected behavior.\n\nThe function creates a context with an associated key-value pair. It is used for passing request-scoped values down the call stack without modifying function signatures explicitly.\n• Passing information like request ID, user authentication, or configuration settings to functions without changing their signatures.\n• Storing and retrieving context-specific data in middleware or middleware-like patterns.\n• Use context values judiciously; avoid overusing them to prevent cluttered contexts.\n• Document the keys and values you use in your contexts.\n\nIn the realm of concurrent and networked applications, mastering the Go package is essential. It empowers you to manage the lifecycle of operations, gracefully handle cancellations and timeouts, and pass request-specific values with ease. By understanding the types of contexts available, their purposes, and adhering to best practices, you can write more robust, efficient, and responsive Go code. Incorporating context management into your Go applications will enhance their reliability and maintainability, making them well-suited for concurrent and networked scenarios."
    },
    {
        "link": "https://reddit.com/r/golang/comments/1830s2d/golang_context_guide_in_concurrent_programs",
        "document": "I wrote a simple blog about how to use `context.Context` in concurrent programs to notify the goroutines about context cancellation."
    },
    {
        "link": "https://reddit.com/r/golang/comments/187up0y/exploring_best_practices_and_optimization_in_go",
        "document": "I'm delving into optimization techniques in Go, and I've stumbled upon some practices that seem to be less efficient, particularly concerning slices and maps. However, I'm also interested in understanding optimization in a broader context within Go programming.\n\nTo kick things off, here are a couple of examples I've encountered:\n• This pattern repeatedly allocates a new slice inside a loop, potentially leading to performance issues due to continuous memory allocation and garbage collection.\n• Here, the growing slice might lead to synchronization issues with the slice header, affecting memory efficiency. By passing a pointer to the slice, modifications to the slice's inside the function are reflected outside as well, keeping the slice in sync.\n\nI'd love to see more examples or in-depth code snippets that illustrate these or other practices that might not be the most efficient in Go. Specifically, I'm seeking:\n• Additional code examples showcasing common but less efficient practices in Go.\n• Insights on how these practices might impact performance in real-world scenarios.\n• Recommendations for more efficient patterns or practices, not limited to slices and maps.\n\nIf you have any code samples, explanations, personal experiences, or even resources related to optimizing Go code, I would be grateful for your input. My goal is to better understand and apply efficient programming practices in Go.\n\nThanks in advance for sharing your knowledge and experiences!"
    },
    {
        "link": "https://labex.io/tutorials/go-how-to-optimize-map-memory-in-golang-437902",
        "document": "Maps are a fundamental data structure in Golang that provide key-value storage and efficient data retrieval. They are similar to hash tables or dictionaries in other programming languages, allowing you to store and access data using unique keys.\n\nThere are multiple ways to create maps in Golang:\n• Consider using sync.Map for concurrent access\n\nMaps in Golang provide a powerful and flexible way to store and manage key-value data, with efficient memory and performance characteristics. Understanding their basics is crucial for effective Golang programming."
    },
    {
        "link": "https://medium.com/@santoshcitpl/ultimate-golang-performance-optimization-guide-connect-infosoft-9c4c2b75b9f2",
        "document": "Golang is a popular programming language for cloud-based and server-side applications. Artificial intelligence, machine learning and data science are among the rapidly growing industries. You are well aware that Golang is a popular programming language for developing such applications. This blog post includes sure-fire Golang performance optimisation strategies that can help you scale your Golang application for greater efficiency and effectiveness.\n\nWe have the most anticipated patterns for your application to boost Golang performance. Everyone wants a quick app (a user wants rapid delivery and a developer wants fast performance), but an entrepreneur wants both!\n\nOptimizing the performance of Go (Golang) applications involves various techniques and considerations. Here’s an ultimate guide that covers essential practices for Golang performance optimization:\n\nTo begin, profile your application to detect performance bottlenecks. Go provides built-in profiling tools like the `pprof` package and the `go tool pprof` command-line tool. Profiling helps you understand which parts of your code consume the most time and resources.\n\nAnalyze your code for inefficient algorithms or data structures that can be optimized. Look for areas where you can replace slow operations with more efficient alternatives. Consider using appropriate data structures like maps, slices and arrays based on the specific requirements of your application.\n\nGo’s garbage collector (GC) handles memory management, but inefficient memory usage can impact performance. Avoid unnecessary allocations by reusing objects and minimizing the use of `make` and `new` operations. Be cautious with large data structures that could strain the GC. Use tools like the `sync.Pool` package to reuse objects and reduce overhead.\n\nLeverage Go’s concurrency features, such as goroutines and channels, to design concurrent and parallel programs. Identify sections of your code that can benefit from concurrent execution and partition work accordingly. However, be mindful of excessive goroutine creation, unnecessary locking, or contention that could introduce performance overhead.\n\n5. Use The Right Libraries and Packages:\n\nChoose libraries or packages that are well-optimized and have a good performance record. The Go ecosystem offers a wide range of third-party packages, so consider their performance characteristics before integrating them into your application.\n\nI/O operations, such as disk reads/writes or network communication, can be a bottleneck. Reduce the number of I/O operations by batching requests, using buffered I/O and employing techniques like connection pooling or caching.\n\nRegularly benchmark and test your code to measure performance improvements and regressions. Go provides the `testing` package and the `go test` command for writing and running tests. Use the built-in benchmarking tool (`go test -bench`) to identify performance changes and track progress.\n\nGo’s compiler (`gc`) applies various optimizations by default, but you can explore compiler flags to enable specific optimizations. For example, the `-N` flag disables optimizations, allowing you to compare the performance impact. The `-gcflags` flag allows you to pass custom compiler flags.\n\nApart from the built-in `pprof` package, you can use external profiling and tracing tools like `pprof`, `go-torch`, or `jaeger` to gain deeper insights into your application’s performance. These tools help identify hotspots, visualize performance data and trace requests across distributed systems.\n\nMonitor your production systems to identify performance issues in real-world scenarios. Use tools like monitoring services, log aggregation and performance analytics to gain visibility into your application’s behavior and detect performance anomalies.\n\nRemember that performance optimization is a continuous process. Regularly revisit your codebase, profile critical sections and benchmark to ensure your optimizations remain effective as your application evolves.\n\nLastly, it’s important to note that premature optimization can hinder development productivity. Focus on optimizing areas that truly impact performance and prioritize clarity, maintainability and correctness in your code.\n\nTAGS: Ultimate Golang Performance Optimization Guide, Looking for Golang Development Service Company in India, Looking for web development company, Looking for Dev Team in India, Custom Web App Development, ERP, CRM, Customer Relation Management Service, Bots / AI Development Services, Custom Plugin/Integration Service"
    },
    {
        "link": "https://stackoverflow.com/questions/73014496/golang-maps-hashmaps-optimizing-for-iteration-speed",
        "document": "When migrating a production NodeJS application to Golang I've noticed that iteration of GO's native Map is actually slower than Node.\n\nI've come up with an alternative solution that sacrifices removal/insertion speed with iteration speed instead, by exposing an array that can be iterated over and storing key=>index pairs inside a separate map.\n\nWhile this solution works, and has a significant performance increase, I was wondering if there is a better solution to this that I could look into.\n\nThe setup I have is that its very rare something is removed from the hashmaps, only additions and replacements are common for which this implementation 'works', albeit feels like a workaround more than an actual solution.\n\nThe maps are always indexed by an integer, holding arbitrary data.\n\nThe test code that was ran is:"
    },
    {
        "link": "https://reddit.com/r/golang/comments/hc6r4w/quick_tips_to_writing_highperformance_go",
        "document": "We all know the famous Knuth quote \"premature optimization is the root of all evil\" however it does not mean you are not allowed to make better decisions while writing code. Here are some simple rules I've collected and use when writing GO code.\n• pre-allocate arrays and maps, guess when you don't know the count\n• use arrays for data-structures over pointers\n• struct of arrays over array of structs for big data\n\nThese are some of the rules I keep in mind while building Super Graph a GraphQL to SQL compiler and they've help me build a fast and solid application. https://github.com/dosco/super-graph"
    },
    {
        "link": "https://prometheus.io/docs/guides/go-application",
        "document": "Prometheus has an official Go client library that you can use to instrument Go applications. In this guide, we'll create a simple Go application that exposes Prometheus metrics via HTTP.\n\nYou can install the , , and libraries necessary for the guide using :\n\nTo expose Prometheus metrics in a Go application, you need to provide a HTTP endpoint. You can use the library's HTTP as the handler function.\n\nThis minimal application, for example, would expose the default metrics for Go applications via :\n\nThe application above exposes only the default Go metrics. You can also register your own custom application-specific metrics. This example application exposes a counter that counts the number of operations that have been processed thus far. Every 2 seconds, the counter is incremented by one.\n\nIn the metrics output, you'll see the help text, type information, and current value of the counter:\n\nYou can configure a locally running Prometheus instance to scrape metrics from the application. Here's an example configuration:\n\nIn this guide we covered just a small handful of features available in the Prometheus Go client libraries. You can also expose other metrics types, such as gauges and histograms, non-global registries, functions for pushing metrics to Prometheus PushGateways, bridging Prometheus and Graphite, and more.\n\nIn this guide, you created two sample Go applications that expose metrics to Prometheus---one that exposes only the default Go metrics and one that also exposes a custom Prometheus counter---and configured a Prometheus instance to scrape metrics from those applications.\n\nThis documentation is open-source. Please help improve it by filing issues or pull requests."
    },
    {
        "link": "https://betterstack.com/community/guides/monitoring/prometheus-golang",
        "document": "This article offers a comprehensive guide to integrating Prometheus metrics in your Go application.\n\nIt covers essential concepts such as instrumenting your code with different metric types, tracking HTTP server activity, and efficiently exposing metrics for Prometheus to scrape.\n\nYou'll find the complete source code for this tutorial in this GitHub repository .\n\nLet's begin by setting up the demo project , which is a simple \"Hello World\" server. Clone the following GitHub repository to your local machine using the command below:\n\nNext, navigate to the project directory:\n\nThis project includes a file that defines two services:\n• None : This service runs the application on port 8000 and uses air to enable live reloading whenever files are changed.\n• None : This service runs the Prometheus server, configured using the file.\n\nBefore starting the services, rename the file to . This file contains basic configuration settings for the application:\n\nUse the following command to rename the file:\n\nNow, start both services in the background with this command:\n\nYou should observe output similar to this:\n\nTo verify the application is working, send a request to the root endpoint using :\n\nThis should return the following response:\n\nYou can also navigate to to view the Prometheus UI and confirm that your application is accessible:\n\nWith the services running successfully, we can proceed to integrate the Prometheus packages in the next step.\n\nBefore you can instrument your application with Prometheus, you need to install the necessary packages first:\n\nThis command installs the prometheus and promhttp packages. The former is the core library for defining and managing metrics, while the latter provides an HTTP handler for exposing metrics in a Prometheus-compatible format.\n\nTo integrate them into your Go application, modify your file as follows:\n\nThis imports the package which provides an HTTP handler that serves metrics in a format that Prometheus can scrape.\n\nIf you visit the in your browser, you will see the following output:\n\nBy default, Prometheus uses the global registry, which automatically registers standard Go runtime metrics and process metrics. While Prometheus gathers a wide range of default metrics, they're not usually essential for typical monitoring needs.\n\nTo disable these, you must create a custom registry and register only the metrics you care about. Then pass your custom registry to to expose only the metrics you explicitly register:\n\nSince we haven't explicitly registered any custom metrics, the route will return an empty response. In the following sections, you will instrument the Counter, Gauge, Histogram, and Summary metric in turn.\n\nLet's start with a rather basic metric that keeps track of the total number of HTTP requests made to the server. Since this number always goes up, it is best represented as a Counter.\n\nEdit your file to include the counter instrumentation:\n\nIn this snippet, the metric is created using a which is a Prometheus metric type that tracks a cumulative count of events and supports labels for categorization. The package also exposes a type, but it does not support using labels.\n\nThe struct specifies the metric's name, and provides a short description of its purpose. The metric is then labeled with HTTP status code, requested URL path, and the HTTP method like GET or POST.\n\nThese labels allow you to distinguish between different types of requests and provide detailed breakdowns for analysis when querying with PromQL later on.\n\nTo automatically increment the request count for all current and future HTTP routes, you created a function that wraps the existing HTTP handler. It uses a to capture the HTTP status code, which is not directly accessible during request handling.\n\nAfter processing the request with , the middleware extracts the HTTP method, path, and status code, then increments the counter using . This ensures that every HTTP request is counted and categorized by its attributes.\n\nFinally, the must be explicitly registered with the custom Prometheus registry, and the existing HTTP multiplexer ( ) is wrapped with the .\n\nBy doing this, every incoming HTTP request will pass through the middleware, ensuring that request counter metrics are updated as part of the request lifecycle.\n\nOnce you've saved the file, you may refresh the page a couple of times. You will see the following results:\n\nTo send a steady stream of requests to a route, you can use a benchmarking tool like wrk :\n\nYou can visit the Prometheus web interface at to see your metrics in action. Typing in the expression input and clicking Execute will display the raw metric values:\n\nYou can then switch to the Graph tab to see the counter increasing continually as long as the service continues to handle HTTP requests:\n\nLet's look at how to instrument a Gauge metric next.\n\nA Gauge represents a value that can go up or down, making it ideal for tracking values like active connections, queue sizes, or memory usage.\n\nIn this section, we'll use a Prometheus Gauge to monitor the number of active connections to the service.\n\nHere's what you need to add to your file:\n\nThe metric is created with to keep track of the number of active HTTP requests being processed at any given time. If you want to add labels, use instead.\n\nAt the start of the middleware function, the method is called to increment the gauge when a new HTTP request arrives.\n\nThe method is then used to simulate a delay of one second. In real-world scenarios, the time taken to process the request would depend on factors such as database queries, external API calls, and other business logic.\n\nFinally, once the request handler returns, the method is called to decrement the gauge, indicating that the has finished processing and is no longer active.\n\nEnsure to register the and save the file, then send some load to your server with:\n\nWhen you visit your metric endpoint, you'll see the following output:\n\nThis indicates that there are currently 407 active connections to the service.\n\nYou may query this metric and see the Graph tab to check how this number is changing over time.\n\nNext up, you'll instrument a Histogram metric to track the HTTP request latency for your routes.\n\nHistograms are helpful for tracking distributions of measurements, such as the duration of HTTP requests. In Prometheus, creating a Histogram metric is straightforward with the method:\n\nInstead of a fixed delay of one second, we've introduced a random delay between 0ms and 1s using so that you can observe a range of values.\n\nAfter the request is processed, the duration is calculated as the difference between the current and recorded start times. This value is then converted to seconds and recorded into the histogram.\n\nOnce the histogram is registered, it will be exposed at the endpoint. By generating some load to your endpoints, you'll see the following output in :\n\nEach line shows the cumulative count of requests completed in less than or equal to a specific duration. For example:\n\nThe default buckets for a histogram metric are:\n\nIf this doesn't make sense for your use case, you can define a custom bucket with:\n\nIn the Prometheus UI, you can use the following PromQL query to calculate the 99th percentile latency for HTTP requests over a 1-minute window:\n\nA Summary metric in Prometheus is useful for capturing pre-aggregated quantiles (e.g., median, 95th, or 99th percentile) and providing overall counts and sums for specific observations.\n\nA key feature of summaries is their ability to calculate quantiles directly on the client side, which makes them particularly valuable in scenarios where you need quantiles for individual instances and don't want to rely on Prometheus for these computations.\n\nWhile the histogram is usually preferred for tracking request latency, the Summary can be used for precomputing quantiles for response times of critical API endpoints where aggregation isn't required.\n\nHere's how to set it up:\n\nThe metric is used here to measure and monitor the latency of requests to the external API endpoint .\n\nThe field in the structure specifies the quantiles to calculate. Each quantile is associated with a tolerance value, which defines the allowable margin of error for the quantile calculation.\n• For , the actual quantile value may have up to a 5% error margin.\n• For , the margin of error is stricter at 1%.\n\nWhen choosing tolerances, keep in mind that lower values require more memory and processing power.\n\nIn handler, the duration for the request is calculated and recorded into the summary metric.\n\nOnce you've saved the file, send some requests to the endpoint:\n\nWhen you scrape your application metrics now, you'll see an output that looks like this:\n\nThis shows the shows precomputed quantiles (50th, 90th, and 99th percentiles) and overall statistics (sum and count) for request durations to .\n\nFrom the results, we can deduce that:\n• Half of all requests completed in less than or equal to 0.1095 seconds (about 110 milliseconds),\n• 90% of all requests completed in less than or equal to 0.1271 seconds (about 127 milliseconds),\n• and 99% of all requests completed in less than or equal to 0.5448 seconds (about 545 milliseconds).\n\nThis 0.99 quantile is much higher than the 0.9 quantile, which indicates the presence of a few slower requests.\n\nIn this tutorial, we explored the fundamentals of setting up and using Prometheus metrics in a Go application, covering key concepts such as defining and registering counters, gauges, histograms, and summaries.\n\nAs the next steps, consider integrating alerting with Prometheus Alertmanager or visualizing metrics using tools like Grafana and Better Stack.\n\nExploring advanced PromQL queries can also help you unlock powerful ways to analyze and act on your application's data.\n\nThanks for reading, and happy monitoring!"
    },
    {
        "link": "https://sentinelone.com/blog/prometheus-metrics-by-example",
        "document": ""
    },
    {
        "link": "https://medium.com/devbulls/prometheus-monitoring-with-golang-c0ec035a6e37",
        "document": "When developing software, the initial goal is often to deliver a Minimum Viable Product (MVP), and that’s perfectly fine for the early stages. However, this article is aimed at projects that have moved beyond the MVP phase and are now in production, where traffic is increasing, and stability becomes crucial.\n\nWhether your application is structured as a monolith or a distributed microservice architecture, the absence of robust monitoring and alerting mechanisms can lead to serious issues, including undetected failures or degraded performance.\n\nI will explore the critical role of monitoring and provide a step-by-step guide on integrating Prometheus into your Golang project.\n\nTwo words: Metrics and Alerting — that’s Prometheus in a nutshell. It’s an open-source system built to collect, store, and query time-series data, making it a go-to solution for monitoring and understanding your application’s performance.\n\nPrometheus uses four main types of metrics, each designed for a specific purpose in tracking and analyzing system health:\n\nA counter is a metric that keeps track of a value that only goes up (or resets to zero when restarted). It’s great for tracking things like the number of HTTP requests or total errors.\n\nExample: - A counter that tracks the total number of HTTP requests served.\n\nCaptures values that can fluctuate up or down. It’s used to track things like statuses, memory usage, or the number of active connections.\n\nExample: - A gauge that tracks the current memory usage.\n\nA histogram is a metric that tracks the distribution of values, showing how often different ranges of values occur. It’s useful for measuring things like request durations or response sizes.\n\nExample: - A histogram that measures the duration of HTTP requests, split into predefined buckets (e.g., 0.1s, 0.2s, etc.).\n\nSimilar to histograms but provides statistics like averages and percentiles.\n\nExample: - A summary that tracks the size of HTTP responses.\n\nEach metric in Prometheus has a unique name and can include a set of labels (key-value pairs) to distinguish different dimensions of the same metric. For example, an HTTP request counter might have labels for and to track different types of requests.\n\nIn this section, I will walk through the step-by-step process of integrating Prometheus into a Golang project. I will start by setting up basic metrics and exposing them for Prometheus to scrape, and then show how to connect the setup with Grafana for visualizing the collected data.\n\nTo begin, add the Prometheus client libraries to your project using the following commands:\n• Prometheus collects metrics by scraping a HTTP endpoint, but you can customize this path as needed. In Golang, you will need to define and expose your metrics through an HTTP server.\n• If you create metrics using the core package, you need to register them with a . If not registered, your metrics will not be exposed.\n• Then, use curl to check the metrics:\n• You should see the similar metrics output:\n\nTo set up Prometheus locally using Docker, follow these steps:\n• Inside configure basic Prometheus instance using the image. It maps port and uses the custom configuration file for scraping targets.\n• Create a configuration file , where you define your targets and scraping intervals. If you run your Golang server locally, use as the target; if it’s inside a Docker container, use the instead.\n• Run docker-compose, and then navigate to in your browser to check the status of your targets:\n\nTo visualize your metrics, set up Grafana using Docker:\n• Add a new data source and select Prometheus as the source. Enter the URL to connect to your Prometheus instance.\n• Use the Grafana UI to create a new dashboard and add panels to visualize your Prometheus metrics.\n\nMonitoring is essential for any software where stability and performance are priorities. Integrating Prometheus is a reliable way to ensure visibility into your system’s health. Additionally, combining it with OpenTelemetry is becoming increasingly popular for gaining even deeper insights into distributed systems."
    },
    {
        "link": "https://github.com/hashicorp/go-metrics",
        "document": "This library provides a package which can be used to instrument code, expose application metrics, and profile runtime performance in a flexible manner.\n\nThe package makes use of a interface to support delivery to any type of backend. Currently the following sinks are provided:\n• PrometheusSink: Sinks to a Prometheus metrics endpoint (exposed via HTTP for scrapes)\n• InmemSink : Provides in-memory aggregation, can be used to export stats\n• FanoutSink : Sinks to multiple sinks. Enables writing to multiple statsite instances for example.\n\nIn addition to the sinks, the can be used to catch a signal, and dump a formatted output of recent metrics. For example, when a process gets a SIGUSR1, it can dump to stderr recent performance metrics for debugging.\n\nMost metrics do have an equivalent ending with , such methods allow to push metrics with labels and use some features of underlying Sinks (ex: translated into Prometheus labels).\n\nSince some of these labels may increase the cardinality of metrics, the library allows filtering labels using a allow/block list filtering system which is global to all metrics.\n• If is not nil, then only labels specified in this value will be sent to underlying Sink, otherwise, all labels are sent by default.\n• If is not nil, any label specified in this value will not be sent to underlying Sinks.\n\nBy default, both and are nil, meaning that no tags are filtered at all, but it allows a user to globally block some tags with high cardinality at the application level.\n\nv0.5.0 of the library renamed the Go module from to . While this did not introduce any breaking changes to the API, the change did subtly break backwards compatibility.\n\nIn essence, Go treats a renamed module as entirely distinct and will happily compile both modules into the same binary. Due to most uses of the go-metrics library involving emitting metrics via the global metrics handler, having two global metrics handlers could cause a subset of metrics to be effectively lost. As an example, if your application configures go-metrics exporting via the namespace, then any metrics sent to go-metrics via the namespaced module will never get exported.\n\nEventually all usage of should be replaced with usage of . However, a single point-in-time coordinated update across all libraries that an application may depend on isn't always feasible. To facilitate migrations, a package has been introduced. This package and sub-packages are API compatible with . Libraries should be updated to use this package for emitting metrics via the global handlers. Internally, the package will route metrics to either or . This is achieved at a global level within an application via the use of Go build tags.\n• - Using this tag will cause metrics to be routed to\n• - Using this tag will cause all metrics to be routed to\n\nIf no build tag is specified, the default behavior is to use . The overall migration path would be as follows:\n• Upgrade libraries using to consume instead.\n• Update library dependencies of applications that use .\n• This doesn't need to be one big atomic update but can be slower due to the default behavior remaining unaltered.\n• At this point all metrics will still be emitted to\n• Update the application to use\n• Replace all application imports of with\n• Libraries are unaltered at this stage.\n• Instrument your build system to build with the tag.\n\nYour migration is effectively finished and your application is now exclusively using . A future release of the library will change the default behavior to use instead of . At that point in time, any application that needs more time before performing the migration must instrument their build system to include the tag. A subsequent release after that will eventually remove the compatibility layer all together. The rough timeline for this will be mid-2025 for changing the default behavior and then the end of 2025 for removal of the compatibility layer.\n\nHere is an example of using the package:\n\nHere is an example of setting up a signal handler:\n\nWhen a signal comes in, output like the following will be dumped to stderr:"
    }
]