[
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/createRadialGradient",
        "document": "This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015 .\n\nThe method of the Canvas 2D API creates a radial gradient using the size and coordinates of two circles.\n\nThis method returns a . To be applied to a shape, the gradient must first be assigned to the or properties.\n\nNote: Gradient coordinates are global, i.e., relative to the current coordinate space. When applied to a shape, the coordinates are NOT relative to the shape's coordinates."
    },
    {
        "link": "https://w3schools.com/jsref/canvas_createradialgradient.asp",
        "document": "The gradient object can be used to fill rectangles, circles, lines, text, etc.\n\nThe gradient object can be used as value to strokeStyle or fillStyle properties.\n\nThe element is an HTML5 standard (2014).\n\nis supported in all modern browsers:"
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D",
        "document": "This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015 . * Some parts of this feature may have varying levels of support.\n\nThe interface, part of the Canvas API, provides the 2D rendering context for the drawing surface of a element. It is used for drawing shapes, text, images, and other objects. The interface's properties and methods are described in the reference section of this page. The Canvas tutorial has more explanation, examples, and resources, as well. For , there is an equivalent interface that provides the rendering context. The offscreen rendering context inherits most of the same properties and methods as the and is described in more detail in the reference page.\n\nTo get a instance, you must first have an HTML element to work with: To get the canvas' 2D rendering context, call on the element, supplying as the argument: With the context in hand, you can draw anything you like. This code draws a house: The resulting drawing looks like this:\n\nThe following methods can be used to manipulate paths of objects. Starts a new path by emptying the list of sub-paths. Call this method when you want to create a new path. Causes the point of the pen to move back to the start of the current sub-path. It tries to draw a straight line from the current point to the start. If the shape has already been closed or has only one point, this function does nothing. Moves the starting point of a new sub-path to the (x, y) coordinates. Connects the last point in the current sub-path to the specified (x, y) coordinates with a straight line. Adds an arc to the current path with the given control points and radius, connected to the previous point by a straight line. Adds an elliptical arc to the current path. Creates a path for a rectangle at position (x, y) with a size that is determined by width and height. Creates a path for a rounded rectangle with a specified position, width, height, and corner radii.\n\nObjects in the rendering context have a current transformation matrix and methods to manipulate it. The transformation matrix is applied when creating the current default path, painting text, shapes and objects. The methods listed below remain for historical and compatibility reasons as objects are used in most parts of the API nowadays and will be used in the future instead. Retrieves the current transformation matrix being applied to the context. Adds a rotation to the transformation matrix. The angle argument represents a clockwise rotation angle and is expressed in radians. Adds a scaling transformation to the canvas units by x horizontally and by y vertically. Adds a translation transformation by moving the canvas and its origin x horizontally and y vertically on the grid. Multiplies the current transformation matrix with the matrix described by its arguments. Resets the current transform to the identity matrix, and then invokes the method with the same arguments. Resets the current transform by the identity matrix.\n\nThe rendering context contains a variety of drawing style states (attributes for line styles, fill styles, shadow styles, text styles). The following methods help you to work with that state: Saves the current drawing style state using a stack so you can revert any change you make to it using . Restores the drawing style state to the last element on the 'state stack' saved by . A read-only back-reference to the . Might be if it is not associated with a element. Returns an object containing the context attributes used by the browser. Context attributes can be requested when using to create the 2D context. Resets the rendering context, including the backing buffer, the drawing state stack, path, and styles. Returns if the rendering context was lost."
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/createLinearGradient",
        "document": "This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015 .\n\nThe method of the Canvas 2D API creates a gradient along the line connecting two given coordinates.\n\nThis method returns a linear . To be applied to a shape, the gradient must first be assigned to the or properties.\n\nNote: Gradient coordinates are global, i.e., relative to the current coordinate space. When applied to a shape, the coordinates are NOT relative to the shape's coordinates."
    },
    {
        "link": "https://stackoverflow.com/questions/33686518/javascript-canvas-apply-radial-gradient-to-segment",
        "document": "The canvas is very flexible. Almost anything is possible. This example draws the light being cast. But it can just as easily be the reverse. Draw the shadows as a gradient.\n\nIf you are after realism then instead of rendering a gradient for the lighting (or shadows) use the shape created to set a clipping area and then render a accurate lighting and shadow solution.\n\nWith lineTo and gradients you can create any shape and gradient you my wish. Also to get the best results use globalCompositeOperation as they have a large variety of filters.\n\nThe demo just shows how to mix a gradient and a shadow map. (Very basic no recursion implemented, and shadows are just approximations.)"
    },
    {
        "link": "https://stackoverflow.com/questions/24578261/smooth-zooming-in-canvas-via-button-instead-of-mousewheel",
        "document": "I am trying to implement something like a smooth zoom in a Canvas application.\n\nI am already able to zoom to a predefined zoom level using this:\n\nMost of the examples for smooth zomming pertain to mouse-wheel implementations but I would like to use a button instead that zooms to a pre-defined level and back.\n\nI have the impression that the implementantion has something to do with a FOR loop and some kind of adaptive delay that gets bigger as the loop count increases.\n\nI am using Paper.js as my canvas library but that should not be a factor in finding a solution."
    },
    {
        "link": "https://stackoverflow.com/questions/68649521/smooth-zooming-through-the-canvas",
        "document": "I have a zooming feature in my fabricjs app. The that runs zoom is just very similar to this: http://fabricjs.com/fabric-intro-part-5\n\nNow I would like to program a smooth zooming on mouse wheel - so that it zooms like here: https://mudin.github.io/indoorjs but I completely don't know where to start. I feel like I need to debounce somehow the handler for mouse wheel, because for now it happens whenever you wheel the mouse - is this the right direction? How to accomplish something like that?"
    },
    {
        "link": "https://medium.com/@Fjonan/performant-drag-and-zoom-using-fabric-js-3f320492f24b",
        "document": "This is how it feels to start your IDE sometimes. By Philip Swinburn How I got here I was working on a tool that allows to create seating plans (like for a theater or cinema hall) using the fantastic Fabric.js. The plan gets created in a backend and exported into JSON and loaded again for the client with some user facing logic like selecting seats for the cart. Now when trying to make this seating plan accessible to mobile devices the user naturally expects to be able to drag the plan around and pinch zoom in and out. Since the plans consists of hundreds of elements it quickly became apparent that moving the canvas content around using is performing poorly with clear stuttering and lagging, depending on the mobile browser used. FireFox was a lot slower than Chrome on my Fairphone 3+ but the performance was poor on both. It was even worse with zooming using which sometimes froze the browser for multiple seconds.\n\nIt should be common knowledge by now, that CSS is very performant. As Paul Irish wrote in 2012: […] gets the laptop element elevated onto it’s own layer on the GPU […] any 2D transform, 3D transform, or opacity changes can happen purely on the GPU which will stay extremely fast and still get us quick frame rates. So I build a demo comparing the two — CSS versus using Fabric.js own methods. Here is the result for drag using my CodePen comparison demo recorded with a 4x slowdown (Chrome DevTools > Performance > CPU: 4x slowdown): And since we can’t simulate pinching on desktop (yet) I recorded this in Chrome on my Fairphone 3+: Conclusion: CSS is so much smoother that it offsets any extra code we might have to write.\n\nIn the next sections I go over the details, what I struggled with so you don’t have to and some reasoning. I will not go into detail how to solve drag and zoom using Fabric.js only, you can find this however in this Stack Overflow answer of mine. Since we will move (= translate) the canvas around, we need to create a wrapper element that cuts of the overlap so from the users perspective it looks like we are dragging the content inside the canvas when we are actually moving the complete canvas around. ⚠️This means, we will need to draw the complete content at all times! This is the biggest drawback of this method and might already invalidate this solution for some but should be fine for most cases. So the HTML might look something like this: Fabric.js will create its own wrapper element which I access here using . This wrapper holds two canvas elements since this is how Fabric.js handles caching, you can find more details in the documentation. For us this is not relevant is for all intents and purposes what I labeled as “Canvas” in the image above and will refer to as “canvas” in this article.\n\nThis mouse could drag a lot of things, too. By Nikolett Emmert Using CSS will “promote” the canvas element to its own layer that is handled by the GPU directly. The GPU will not change and recalculate any pixels but just moving the layer around which is why it is so much more performant than recalculating and thereby redrawing every single pixel that has been changed on screen. You can imagine it like a new layer in an image editing tool that you move around instead of drawing every new image from scratch. We start by setting up the drag for mouse controls first and attach touch events later since they work a bit differently. const wrapper = document.querySelector('.canvas-wrapper')\n\nconst canvas = new fabric.Canvas(\"canvas\",{\n\n allowTouchScrolling: false,\n\n defaultCursor: 'grab',\n\n selection: false, // assuming we don't need element manipulation\n\n // …\n\n})\n\n\n\nlet lastPosX, \n\n lastPosY\n\n\n\ncanvas.on(\"mouse:down\", dragCanvasStart)\n\ncanvas.on(\"mouse:move\", dragCanvas) ℹ️ When you see in the code that’s because Fabric.js sends the event as the property to the callback function. Since we will use the same method later with touch events, this keeps compatibility. /**\n\n * Save reference point from which the interaction started\n\n */\n\nfunction dragCanvasStart(event) {\n\n const evt = event.e || event // fabricJS event or touch event\n\n \n\n // save the position you started dragging from\n\n lastPosX = evt.clientX\n\n lastPosY = evt.clientY\n\n}\n\n\n\n/**\n\n * Dragging the canvas\n\n */\n\nfunction dragCanvas(event) { \n\n const evt = event.e || event // fabricJS event or touch event\n\n\n\n // left mouse button is pressed if not a touch event\n\n if (1 !== evt.buttons && !(evt instanceof Touch)) {\n\n return\n\n }\n\n \n\n translateCanvas(evt)\n\n}\n\n\n\n/**\n\n * Convert movement to CSS translate which visually moves the canvas\n\n */\n\nfunction translateCanvas(event) { \n\n const transform = getTransformVals(canvas.wrapperEl)\n\n\n\n let offsetX = transform.translateX + (event.clientX - (lastPosX || 0))\n\n let offsetY = transform.translateY + (event.clientY - (lastPosY || 0))\n\n\n\n canvas.wrapperEl.style.transform = `translate(${tVals.translateX}px, ${tVals.translateY}px) scale(${transform.scaleX})`\n\n\n\n lastPosX = event.clientX\n\n lastPosY = event.clientY\n\n}\n\n\n\n/**\n\n * Get relevant style values for the given element\n\n * @see https://stackoverflow.com/a/64654744/13221239\n\n */\n\nfunction getTransformVals(element) {\n\n const style = window.getComputedStyle(element)\n\n const matrix = new DOMMatrixReadOnly(style.transform) \n\n return {\n\n scaleX: matrix.m11,\n\n scaleY: matrix.m22,\n\n translateX: matrix.m41,\n\n translateY: matrix.m42,\n\n width: element.getBoundingClientRect().width,\n\n height: element.getBoundingClientRect().height,\n\n }\n\n} So what happens here? We basically convert the mouse movement to an inline style on the canvas. On an instantiated Fabric.js canvas that could look like this: <section class=\"canvas-wrapper\" style=\"overflow:hidden; position:relative;\">\n\n <div style=\"transform: translate(82px, 96px) scale(1); /* … */\" data-fabric=\"wrapper\" class=\"canvas-container\" >\n\n <!-- Fabric.js will put two canvas elements here -->\n\n </div>\n\n</section> 💡In a first version I would re-calculate the canvas with the content moved by the values after the user stopped dragging but that resulted in weird behavior where visible content would disappear (since it was cut off after the update) or invisible content popping in (since it was now in the visible area) which is why I removed it and instead made sure to always draw the canvas with all content visible from the start which required no re-drawing at all. If you paid attention you noticed we set here. This is to keep any active zoom levels intact. More on that later.\n\nZooming with CSS we make use of which effectively scales the promoted layer up and down without changing any pixels. That is — just like — very fast since the GPU does not repaint any pixels but just scales them up or down. And this is how we set it up for mouse wheel: let touchZoom\n\n\n\ncanvas.on('mouse:wheel', zoomCanvasMouseWheel)\n\n\n\n/**\n\n * Zoom canvas when user used mouse wheel\n\n */\n\nfunction zoomCanvasMouseWheel(event) {\n\n const delta = event.e.deltaY\n\n let zoom = touchZoom\n\n\n\n zoom *= 0.999 ** delta\n\n const point = {x: event.e.offsetX, y: event.e.offsetY}\n\n\n\n scaleCanvas(zoom, point)\n\n debouncedScale2Zoom()\n\n}\n\n\n\n/**\n\n * Convert zoom to CSS scale which visually zooms the canvas\n\n */\n\nfunction scaleCanvas(zoom, aroundPoint) {\n\n const tVals = getTransformVals(canvas.wrapperEl)\n\n const scaleFactor = tVals.scaleX / touchZoom * zoom\n\n\n\n canvas.wrapperEl.style.transformOrigin = `${aroundPoint.x}px ${aroundPoint.y}px`\n\n canvas.wrapperEl.style.transform = `translate(${tVals.translateX}px, ${tVals.translateY}px) scale(${scaleFactor})`\n\n\n\n touchZoom = zoom\n\n} 💡Notice that we are setting the here. This is necessary so that the zoom happens around this point and there is no need to calculate the offset since the browser will take care of this for you. There is a bonus paragraph on how to make the visible later This code will however result in a blurry image when zooming in. So here we need to migrate the into canvas size and zoom to get a sharp image again. This is what will trigger after the user stopped scrolling (checkout lodash debounce for details). So make sure to import lodash so you can use : // after scaling transform the CSS to canvas zoom so it does not stay blurry\n\n// @see https://lodash.com/docs/4.17.15#debounce\n\nconst debouncedScale2Zoom = _.debounce(canvasScaleToZoom, 1000)\n\n\n\n/**\n\n * Converts CSS transform to Fabric.js zoom so the blurry image gets sharp \n\n */\n\nfunction canvasScaleToZoom() { \n\n const transform = getTransformVals(canvas.wrapperEl)\n\n const canvasBox = canvas.wrapperEl.getBoundingClientRect()\n\n const viewBox = wrapper.getBoundingClientRect()\n\n\n\n // calculate the offset of the canvas inside the wrapper\n\n const offsetX = canvasBox.x - viewBox.x\n\n const offsetY = canvasBox.y - viewBox.y\n\n\n\n // we resize the canvas to the scaled values\n\n canvas.setDimensions({height:transform.height, width:transform.width})\n\n canvas.setZoom(touchZoom)\n\n\n\n // and reset the transform values\n\n canvas.wrapperEl.style.transformOrigin = `0px 0px`\n\n canvas.wrapperEl.style.transform = `translate(${offsetX}px, ${offsetY}px) scale(1)`\n\n\n\n canvas.renderAll()\n\n} This function will basically reset the canvas size and set a zoom level to Fabric.js, recalculate the new offset since the will be reset to . The result is the blurry image from the scale becoming sharp again:\n\nNow for touch events we have to attach our own event listeners to our own wrapper so the events fire even if the user did not touch the canvas because it is dragged to the side. let pinchCenter,\n\n initialDistance\n\n\n\nwrapper.addEventListener('touchstart', (event) => {\n\n dragCanvasStart(event.targetTouches[0])\n\n pinchCanvasStart(event)\n\n})\n\n\n\nwrapper.addEventListener('touchmove', (event) => { \n\n dragCanvas(event.targetTouches[0])\n\n pinchCanvas(event)\n\n})\n\n\n\nwrapper.addEventListener('touchend', pinchCanvasEnd)\n\n\n\n/**\n\n * Save the distance between the touch points when starting the pinch\n\n */\n\nfunction pinchCanvasStart(event) {\n\n if (event.touches.length !== 2) {\n\n return\n\n }\n\n\n\n initialDistance = getPinchDistance(event.touches[0], event.touches[1])\n\n}\n\n\n\n/**\n\n * Start pinch-zooming the canvas\n\n */\n\nfunction pinchCanvas(event) {\n\n if (event.touches.length !== 2) {\n\n return\n\n }\n\n\n\n setPinchCenter(event.touches[0], event.touches[1])\n\n\n\n const currentDistance = getPinchDistance(event.touches[0], event.touches[1])\n\n let scale = (currentDistance / initialDistance).toFixed(2)\n\n scale = 1 + (scale - 1) / 20 // slows down scale from pinch\n\n\n\n scaleCanvas(scale * touchZoom, pinchCenter)\n\n}\n\n\n\n/**\n\n * Re-Draw the canvas after pinching ended\n\n */\n\nfunction pinchCanvasEnd(event) {\n\n if (2 > event.touches.length) {\n\n debouncedScale2Zoom()\n\n }\n\n} This connects touch events to our scale and transform methods. That’s it. 💡 converts the current scale value to its respective zoom value. Consider this example: current canvas zoom Level is ; current scale value is ; User zooms out to a scale of . So the new canvas zoom level is . This is needed since we reset the scale after each zoom back to . The rest are some helper functions: /**\n\n * Putting touch point coordinates into an object\n\n */\n\nfunction getPinchCoordinates(touch1, touch2) {\n\n return {\n\n x1: touch1.clientX,\n\n y1: touch1.clientY,\n\n x2: touch2.clientX,\n\n y2: touch2.clientY,\n\n }\n\n}\n\n\n\n/**\n\n * Returns the distance between two touch points\n\n */\n\nfunction getPinchDistance(touch1, touch2) {\n\n const coord = getPinchCoordinates(touch1, touch2)\n\n return Math.sqrt(Math.pow(coord.x2 - coord.x1, 2) + Math.pow(coord.y2 - coord.y1, 2))\n\n}\n\n\n\n/**\n\n * Pinch center around wich the canvas will be scaled/zoomed\n\n * takes into account the translation of the container element\n\n */\n\nfunction setPinchCenter(touch1, touch2) { \n\n const coord = getPinchCoordinates(touch1, touch2)\n\n\n\n const currentX = (coord.x1 + coord.x2) / 2\n\n const currentY = (coord.y1 + coord.y2) / 2\n\n\n\n const transform = getTransformVals(canvas.wrapperEl)\n\n \n\n pinchCenter = {\n\n x: currentX - transform.translateX,\n\n y: currentY - transform.translateY,\n\n } \n\n} And that’s it. So we are done.\n\nYour website when zooming the canvas right now on mobile probably. By Viggo Danielsen When creating I was so happy when it finally worked and I started testing it on my phone only to encounter multiple minute long freezes. I started digging and found out that these two lines of code trigger rather expensive calculations on all objects on the canvas: I thought my whole idea was doomed. So after some unsuccessful experimenting and digging I created an issue in the Fabric.js repository not hoping that anybody would react any time soon and mentally said goodbye to smooth zooming on mobile. But already one day later I got a reply containing this hugely helpful information: asturur: if you are using simple shapes that are a single draw call ( rect, circle, small polygon, ellipse, triangle ) and you are using only fill or only stroke, caching is at loss. So what I did is adding these two lines for every object created on the canvas: Now what took minutes only takes a few seconds if any (depending on the device). After our discussion on Github the Fabric.js caching documentation has been updated extensively. So huge thanks to asturur and all other maintainers involved!"
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Tutorial/Optimizing_canvas",
        "document": "The element is one of the most widely used tools for rendering 2D graphics on the web. However, when websites and apps push the Canvas API to its limits, performance begins to suffer. This article provides suggestions for optimizing your use of the canvas element to ensure that your graphics perform well.\n\nPre-render similar primitives or repeating objects on an offscreen canvas If you find yourself repeating some of the same drawing operations on each animation frame, consider offloading them to an offscreen canvas. You can then render the offscreen image to your primary canvas as often as needed, without unnecessarily repeating the steps needed to generate it in the first place.\n\nAvoid floating-point coordinates and use integers instead Sub-pixel rendering occurs when you render objects on a canvas without whole values. This forces the browser to do extra calculations to create the anti-aliasing effect. To avoid this, make sure to round all co-ordinates used in calls to using , for example.\n\nIn your application, you may find that some objects need to move or change frequently, while others remain relatively static. A possible optimization in this situation is to layer your items using multiple elements. For example, let's say you have a game with a UI on top, the gameplay action in the middle, and a static background on the bottom. In this case, you could split your game into three layers. The UI would change only upon user input, the gameplay layer would change with every new frame, and the background would remain generally unchanged.\n\nIf you have a static background image, you can draw it onto a plain element using the CSS property and position it under the canvas. This will negate the need to render the background to the canvas on every tick.\n\nCSS transforms are faster since they use the GPU. The best case is to not scale the canvas, or have a smaller canvas and scale up rather than a bigger canvas and scale down.\n\nYou may find that canvas items appear blurry on higher-resolution displays. While many solutions may exist, a simple first step is to scale the canvas size up and down simultaneously, using its attributes, styling, and its context's scale. // Get the DPR and size of the canvas const dpr = window.devicePixelRatio; const rect = canvas.getBoundingClientRect(); // Set the \"actual\" size of the canvas canvas.width = rect.width * dpr; canvas.height = rect.height * dpr; // Scale the context to ensure correct drawing operations ctx.scale(dpr, dpr); // Set the \"drawn\" size of the canvas canvas.style.width = `${rect.width}px`; canvas.style.height = `${rect.height}px`;"
    },
    {
        "link": "https://antv.vision/infinite-canvas-tutorial/guide/lesson-004",
        "document": "In this lesson you will learn the following:\n• Camera animation. Using Landmark transition between different camera states.\n\nWe can change the content displayed on the canvas by controlling the camera. Clicking and dragging the mouse allows for panning; holding down and dragging enables rotation around a specified point; using the mouse wheel allows for zooming in and out on a specified point. Pressing the button resets to the initial state with a smooth transition effect.\n\nThe camera describes the angle from which we view the world. The focalpoint and camera position both affect the final image. It is applicable to both 2D and 3D scenes. By controlling the camera, we can easily perform certain operations that previously required moving the entire canvas, and we can even achieve camera animations. The following diagram from WebGL 3D - Cameras shows the content of the XZ plane from a bird's-eye view. If you want to achieve the same visual effect, moving the camera (left image) as opposed to rotating all objects within the entire canvas (right image) is more intuitive and performs better in implementation. We will soon see this point:\n\nOur canvas is situated on the XY plane, and the camera observes it from outside the screen, inward. The following image is from: How to Create a Figma-like Infinite Canvas in WebGL. When we want to pan the canvas to the left, the corresponding camera movement is to pan to the right:\n\nLet's review the various stages of transforming an object from model space to screen space. In the previous lesson, we introduced model transformations. In this lesson, we will discuss projection transformations and camera transformations.\n\nLet's first review the transformation from pixel space to clip space that we covered before:\n\nIf we can complete it with a single projection transformation, the code would be much more streamlined. For example, we could directly multiply by the model transformation matrix on the left:\n\nThe 2D projection transformation is very easy to implement; you only need to provide and . Division by in the shader corresponds to and here:\n\nWe directly use the method provided by gl-matrix. If interested, you can view its source code, as the implementation is exactly the same. This method also needs to be called again to recalculate when the canvas is resized.\n\nHowever, we cannot pass the directly because of the alignment issue we mentioned in the last lesson. We need to add padding to the before passing it into the shader:\n\nFinally, we create the camera in sync with the canvas initialization. Subsequently, we can access it through :\n\nNow let's consider the issue of camera transformations, such as translation.\n\nCamera transformations can also be represented by matrices. After completing the transformations, we can use them in the shader as follows. Compared to computing and updating the model transformation matrix for each graphic, a global one-time update of the camera transformation matrix is more efficient:\n\nThe camera transformation matrix should be the inverse of the camera's transformation in the world coordinate system. As mentioned in the example at the beginning, when the camera moves to the right, it corresponds to the scene moving to the left. Here we use the method provided by gl-matrix to calculate the inverse matrix. At the same time, add other getters such as for subsequent use:\n\nIn the definition of an infinite canvas in infinitecanvas, \"extensibility\" is manifested through canvas-level translation:\n\nNow, let's implement basic camera functionality. Compared to a 3D camera, it's much simpler, supporting translation , rotation , and scaling . The reason for not using as the naming is because is more commonly used (for example, the OrthographicCamera.zoom in Three.js):\n\nWhen we translate the camera using , we need to recalculate the camera matrix:\n\nTry it out by dragging the Slider to move the camera:\n\nIt looks good. It would be even more intuitive if you could interact by dragging with the mouse.\n\nWe decide to implement this feature through a plugin:\n\nReferencing How to implement zoom from mouse in 2D WebGL, we convert the coordinates contained in the mouse event object from canvas coordinates to clip space coordinates:\n\nNext, we listen to the event and handle the subsequent and events, which are not global.\n\nWe need to record the following variables:\n• - the inverse matrix of the camera's projection matrix\n• - the current mouse position in world space, which is obtained by transforming the coordinates in NDC (Normalized Device Coordinates) space with the inverse of the camera's projection matrix\n\nWhen the mouse is released, unbind the event listeners which will ends the drag interaction.\n\nWhen the mouse moves, the camera is moved as well. Similarly, it needs to be converted to world space coordinates. Then, the current mouse position is subtracted from the mouse position saved during the previous , obtaining the distance moved.\n\nYou can try to drag canvas in the example at the top of this page.\n\nRotation is not an essential feature for the canvas, but a FigJam user once inquired in the forums about its support: Rotate canvas, as a slight rotation of the canvas aligns more with their usual usage habits.\n\nWe intend to facilitate canvas rotation by holding down the key while dragging the mouse. In the event listener, we can determine whether to enter rotation mode by checking KeyboardEvent: shiftKey:\n\nIn the camera rotation mode, the distance moved by the mouse will be taken as the angle of rotation. Next, we construct a transformation matrix for rotation around a specified point in the world coordinate system; this can be referenced from transform-origin. Then, this transformation is applied to the camera matrix, and finally, various parameters are extracted from the matrix:\n\nYou can return to the example at the top of the page and try holding down and dragging the canvas.\n\nIn an infinite canvas, aside from panning, zooming is also a very common operation, especially zooming around a specific point:\n\nListen to the event, first recording the position of the mouse before zooming. After zooming and updating the camera matrix, calculate the difference in positions. This difference is the distance the camera needs to move:\n\nSo far, we've been listening to MouseEvent. In the future, when we implement the event system, we will introduce PointerEvent. At that time, we will come back and modify the code for the event listener part of the plugin to make it support input devices like touch screens, etc.\n\nNow, let's move on to the next topic: how to make the movement of the camera more natural.\n\nMapbox provides flyTo - Mapbox method which can move between different locations smoothly. We will refer to WebGL Insights - 23.Designing Cameras for WebGL Applications to implement camera animations, allowing smooth transitions between any camera states.\n\nThe expected usage of the related API is as follows:\n• Create a , which can represent the current state of the camera, and can also set parameters such as position, rotation angle, and scale.\n• Make the camera transition from its current state to a specified , including a smooth transition effect during the process.\n\nCreating a is essentially just about simply storing camera parameters, which will be overwritten if the user provides them:\n\nWe use bezier-easing to implement Cubic Bézier easing functions：\n\nNow, let's design the API for switching to . Referencing the Web Animations API, we support the following parameters:\n• Callback at the frame duration the animation\n\nIf is passed in as , there is no animation effect; the camera parameters contained in the are used to update directly and trigger the end callback:\n\nAny ongoing animations should be stopped before starting a new one (if applicable). Next, we implement the logic for each frame during the animation process. If the exceeds, the animation should end immediately:\n\nUsing the previously defined easing function to obtain the time value, we then use for interpolation to derive the current camera parameters, which are finally applied to update the camera matrix:\n\nThere's a small optimization that can be made here: during the process, you can calculate the displacement of the camera position. If the distance is smaller than a certain threshold, there's no need to carry out the subsequent animation, and you can end it directly:\n\nGo back to the example at the top of the page and give it a try. Click the button to return the camera to its initial state."
    }
]