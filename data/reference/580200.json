[
    {
        "link": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html",
        "document": ""
    },
    {
        "link": "https://pandas.pydata.org/docs/reference/frame.html",
        "document": "Access a single value for a row/column pair by integer position. Access a group of rows and columns by label(s) or a boolean array. Insert column into DataFrame at specified location. Get the 'info axis' (see Indexing for more). Get item from object for given key (ex: DataFrame column). Whether each element in the DataFrame is contained in values. Replace values where the condition is False. Replace values where the condition is True. Query the columns of a DataFrame with a boolean expression. For more information on , , , and , see the indexing documentation.\n\nGet Addition of DataFrame and other, column-wise. Get Addition of dataframe and other, element-wise (binary operator ). Get Subtraction of dataframe and other, element-wise (binary operator ). Get Multiplication of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Integer division of dataframe and other, element-wise (binary operator ). Get Modulo of dataframe and other, element-wise (binary operator ). Get Exponential power of dataframe and other, element-wise (binary operator ). Compute the matrix multiplication between the DataFrame and other. Get Addition of dataframe and other, element-wise (binary operator ). Get Subtraction of dataframe and other, element-wise (binary operator ). Get Multiplication of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Integer division of dataframe and other, element-wise (binary operator ). Get Modulo of dataframe and other, element-wise (binary operator ). Get Exponential power of dataframe and other, element-wise (binary operator ). Get Less than of dataframe and other, element-wise (binary operator ). Get Greater than of dataframe and other, element-wise (binary operator ). Get Less than or equal to of dataframe and other, element-wise (binary operator ). Get Greater than or equal to of dataframe and other, element-wise (binary operator ). Get Not equal to of dataframe and other, element-wise (binary operator ). Get Equal to of dataframe and other, element-wise (binary operator ). Update null elements with value in the same location in .\n\nAlign two objects on their axes with the specified join method. Select values at particular time of day (e.g., 9:30AM). Select values between particular times of the day (e.g., 9:00-9:30 AM). Drop specified labels from rows or columns. Test whether two objects contain the same elements. Subset the dataframe rows or columns according to the specified index labels. Return index of first occurrence of maximum over requested axis. Return index of first occurrence of minimum over requested axis. Conform DataFrame to new index with optional filling logic. Return an object with matching indices as other object. Set the name of the axis for the index or columns. Reset the index, or a level of it. Return a random sample of items from an axis of object. Return the elements in the given positional indices along an axis. Truncate a Series or DataFrame before and after some index value.\n\n(DEPRECATED) Fill NA/NaN values by using the next valid observation to fill the gap. Fill NA/NaN values by using the next valid observation to fill the gap. Fill NA/NaN values by propagating the last valid observation to next valid. Fill NA/NaN values using the specified method. DataFrame.isnull is an alias for DataFrame.isna. DataFrame.notnull is an alias for DataFrame.notna. (DEPRECATED) Fill NA/NaN values by propagating the last valid observation to next valid. Replace values given in with .\n\nSort by the values along either axis. Sort object by labels (along an axis). Return the first rows ordered by in descending order. Return the first rows ordered by in ascending order. Stack the prescribed level(s) from columns to index. Transform each element of a list-like to a row, replicating index values. Return an xarray object from the pandas object. The transpose of the DataFrame.\n\nReturn the last row(s) without any NaNs before . Shift index by desired number of periods with an optional time . Return index for first non-NA value or None, if no non-NA value is found. Return index for last non-NA value or None, if no non-NA value is found. Cast to DatetimeIndex of timestamps, at beginning of period. Localize tz-naive index of a Series or DataFrame to target time zone.\n\nFlags refer to attributes of the pandas object. Properties of the dataset (like the date is was recorded, the URL it was accessed from, etc.) should be stored in ."
    },
    {
        "link": "https://pandas.pydata.org/docs/user_guide/10min.html",
        "document": "This is a short introduction to pandas, geared mainly for new users. You can see more complex recipes in the Cookbook.\n\nCustomarily, we import as follows:\n\nSee the Intro to data structures section. Creating a by passing a NumPy array with a datetime index using and labeled columns: Creating a by passing a dictionary of objects where the keys are the column labels and the values are the column values. The columns of the resulting have different dtypes: If you’re using IPython, tab completion for column names (as well as public attributes) is automatically enabled. Here’s a subset of the attributes that will be completed: As you can see, the columns , , , and are automatically tab completed. and are there as well; the rest of the attributes have been truncated for brevity.\n\nUse and to view the top and bottom rows of the frame respectively: Return a NumPy representation of the underlying data with without the index or column labels: NumPy arrays have one dtype for the entire array while pandas DataFrames have one dtype per column. When you call , pandas will find the NumPy dtype that can hold all of the dtypes in the DataFrame. If the common data type is , will require copying data.\n\nWhile standard Python / NumPy expressions for selecting and setting are intuitive and come in handy for interactive work, for production code, we recommend the optimized pandas data access methods, , , and . See the indexing documentation Indexing and Selecting Data and MultiIndex / Advanced Indexing. For a , passing a single label selects a columns and yields a equivalent to : See more in Selection by Label using or . For label slicing, both endpoints are included: For getting fast access to a scalar (equivalent to the prior method): See more in Selection by Position using or . Select via the position of the passed integers: For getting a value explicitly: For getting fast access to a scalar (equivalent to the prior method): Select rows where is greater than . Selecting values from a where a boolean condition is met: Setting a new column automatically aligns the data by the indexes: The result of the prior setting operations:\n\nFor NumPy data types, represents missing data. It is by default not included in computations. See the Missing Data section. Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data: drops any rows that have missing data: gets the boolean mask where values are :\n\nSee the Basic section on Binary Ops. Calculate the mean value for each column: Calculate the mean value for each row: Operating with another or with a different index or column will align the result with the union of the index or column labels. In addition, pandas automatically broadcasts along the specified dimension and will fill unaligned labels with . and applies a user defined function that reduces or broadcasts its result respectively. See more at Histogramming and Discretization. is equipped with a set of string processing methods in the attribute that make it easy to operate on each element of the array, as in the code snippet below. See more at Vectorized String Methods.\n\nBy “group by” we are referring to a process involving one or more of the following steps:\n• None Splitting the data into groups based on some criteria Grouping by a column label, selecting column labels, and then applying the function to the resulting groups:\n\nSee the sections on Hierarchical Indexing and Reshaping. The method “compresses” a level in the DataFrame’s columns: With a “stacked” DataFrame or Series (having a as the ), the inverse operation of is , which by default unstacks the last level: See the section on Pivot Tables. pivots a specifying the , and\n\npandas can include categorical data in a . For full docs, see the categorical introduction and the API documentation. Rename the categories to more meaningful names: Reorder the categories and simultaneously add the missing categories (methods under return a new by default): Sorting is per order in the categories, not lexical order: Grouping by a categorical column with also shows empty categories:\n\nIf you are attempting to perform a boolean operation on a or you might see an exception like: Traceback (most recent call last) in in : The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). See Comparisons and Gotchas for an explanation and what to do."
    },
    {
        "link": "https://pandas.pydata.org/pandas-docs/version/1.5/user_guide/index.html",
        "document": "The User Guide covers all of pandas by topic area. Each of the subsections introduces a topic (such as “working with missing data”), and discusses how pandas approaches the problem, with many examples throughout.\n\nUsers brand-new to pandas should start with 10 minutes to pandas.\n\nFor a high level summary of the pandas fundamentals, see Intro to data structures and Essential basic functionality.\n\nFurther information on any specific method can be obtained in the API reference.\n\nHow to read these guides# In these guides you will see input code inside code blocks such as: The first block is a standard python input, while in the second the indicates the input is inside a notebook. In Jupyter Notebooks the last line is printed and plots are shown inline."
    },
    {
        "link": "https://pandas.pydata.org/docs/whatsnew/index.html",
        "document": "This is the list of changes to pandas between each release. For full details, see the commit logs. For install and upgrade instructions, see Installation."
    },
    {
        "link": "https://stackoverflow.com/questions/70612835/how-to-handle-pandas-columns-where-elements-are-lists",
        "document": "I have loaded some JSON API data as a Pandas dataframe, as such, there are some columns that come out as lists. I also have some values.\n\nFirst and foremost I want to replace the NaN with a single word such as 'empty' but the rest of the data are already in list forms. I want to ultimately create a new column that operates on this structure and essentially turns it into a string since I will be using the strings to perform mapping logic later on.\n\nHere is some sample data and logic:\n\nAny ideas on how to handle the NaNs in a fashion that makes them still 'list-like'? I cant perform my lambda function on the column since NaNs are treated like a float.\n\nEDIT: Solution provided by @SimonHawe in the comments. Instead of using at all, the solution is to use if else within the lambda function to handle the NaN case."
    },
    {
        "link": "https://stackoverflow.com/questions/38307489/set-list-as-value-in-a-column-of-a-pandas-dataframe",
        "document": "Let's say I have a dataframe and I would like to create a new column filled with 0, I use:\n\nThis far, no problem. But if the value I want to use is a list, it doesn't work:\n\nI understand why this doesn't work (pandas is trying to assign one value of the list per cell of the column), but how can we avoid this behavior? (if it isn't clear I would like every cell of my new column to contain the same predefined list)\n\nNote: I also tried: , same problem"
    },
    {
        "link": "https://geeksforgeeks.org/create-a-pandas-dataframe-from-lists",
        "document": "Converting lists to DataFrames is crucial in data analysis, Pandas enabling you to perform sophisticated data manipulations and analyses with ease.\n\nHere we will discuss different ways to create a Pandas Dataframe from the lists:\n\nExample 1: To convert a list to a Pandas DataFrame, you can use the constructor. This function takes a list as input and creates a DataFrame with the same number of rows and columns as the input list.\n\nExample 2: To use lists in a dictionary to create a Pandas DataFrame, we Create a dictionary of lists and then Pass the dictionary to the constructor. Optionally, we can specify the column names for the DataFrame by passing a list of strings to the parameter of the constructor.\n\nTo create a Pandas DataFrame from lists using zip(). We can also use the function to zip together multiple lists to create a DataFrame with more columns.\n\nTo create a Pandas DataFrame using a multi-dimensional list with column names and dtypes specified. By specifying dtypes, we can ensure that the DataFrame is created with the correct data types.\n\nTo create a DataFrame using a multi-dimensional list, you can use the constructor. The constructor takes a list of lists as input and creates a DataFrame with the same number of rows and columns as the input list.\n\nCreate DataFrame from List with Index and Column Names\n\nTo create a DataFrame using a list with index and column names, you can use the constructor with the and parameters.\n\nHow to convert a list to a pandas DataFrame?\n\nHow to create a pandas DataFrame from a list of tuples?\n\nHow to convert a nested list to a DataFrame?\n\nHow to list DataFrames into one DataFrame in Pandas?"
    },
    {
        "link": "https://medium.com/towards-data-science/dealing-with-list-values-in-pandas-dataframes-a177e534f173",
        "document": "Problem 1: My Lists are Stored as Strings\n\nOne problem you will always encounter is that Pandas will read your lists as strings, not as lists.\n\nThis means that you can not even loop through the lists to count unique values or frequencies. Depending on how your lists are formatted in the dataframe, there is an easy or a more complex solution. In any case, you will simply be able to use the code I provide.\n\nDo your strings look like this: “[‘strawberry’, ‘apple’, ‘orange’]”?\n\nIn that case, there is a quick method using the apply() and eval() functions.\n\nDo your strings look like this: “[strawberry, apple, orange]”?\n\nThis one is tougher, because the eval() function will not work, as the list is lacking the inner quotation marks in order for it to be recognized as a list object. The quick and dirty solution is to simply add the quotation marks to the string and apply eval() afterward. Use this function:\n\nTo apply this to your dataframe, use this code:\n\nNote that in both cases, Pandas will still assign the series an “O” datatype, which is typically used for strings. But do not let this confuse you. You can check the actual datatype using:\n\nProblem 2: Getting Unique Values or Value Counts\n\nAfter this first step, our lists are finally recognized as such by Pandas. Still, we can not use the standard functions, because they are not made for list applications.\n\nAt least we could use loops for everything now. This method works with small datasets, but can get awfully slow with large ones. For example, I had to analyze taglists of up to 999 tags for around 500k music tracks. This means, that the inner loop would have had hundreds of millions of iterations, which would have taken many hours and probably crashed my computer. I will show you a cleaner and quicker way to do this in a minute. However, if you really want to use loops, here is the code:\n\nHere is the clean way that took me a while to figure out. If we conceptualize the favorite_fruits column as a 2D array, reducing its dimensions from 2 to 1 would allow us to apply the typical pandas functions again. For that, we use the explode() method and then apply value_counts():\n\nTo get unique values, just extract them from the results above chaining .index() onto it.\n\nAt this point, we can produce our first meaningful visualization.\n\nAt this point, things are getting advanced. If you are happy with the results we got before, you can stop here. However, a deeper level of analysis might be required for your research goal. Maybe you want to correlate all list elements with each other to compute similarity scores. E.g. do kids who eat bananas typically also like mangos? Or maybe you want to find out which fruit has been ranked as the top favorite fruit by the most kids. These questions can only be answered at a deeper level of analysis.\n\nFor this, I will introduce two useful methods. They differ in complexity, but also in what you can do with their results.\n\nThis is a shockingly easy and fast method I stumbled upon. And it is so useful! All you need is one line of code.\n\nAs you can see, this one-liner produced a dataframe where every list is split into its single elements. The columns indicate the order, in which the fruit was placed in the list. With this method, you will always get a dataframe with a shape of (n, len(longest_list)). In this case, two of the 10 children named five favorite fruits, which results a 10x5 dataframe.\n\nUsing this, we can find out which fruit was named most often as the number one favorite fruit.\n\nWe can see that bananas are most often kids’ absolute favorite fruit.\n\nAlternatively, we could target single fruits and find out how many times they were named at each position of the lists. This is the function I wrote for that:\n\nIf we apply it, we get:\n\nAs you can see, we can perform rank-based analyses very well with this approach. However, this method is near useless for other approaches. Because the columns do not represent a single tag, but a rank, most tag-based operations can not be done properly. For example, calculating the correlation between bananas and peaches is not possible with the dataframe we got from method 1. If that is your research goal, use the next method.\n\nThis method is more complex and requires more resources. The idea is that we create a dataframe where rows stay the same as before, but where every fruit is assigned its own column. If only kid #2 named bananas, the banana column would have a “True” value at row 2 and “False” values everywhere else (see Figure 6). I wrote a function that will perform this operation. It relies on looping, which means that it will take lots of time with large datasets. However, out of all the methods I tried, this was the most efficient way to do it.\n\nIf we now apply the function\n\nwe get this dataframe:\n\nFrom here, we can easily calculate correlations. Note that “correlation” is not really the correct term, because we are not using metric or ordinal, but binary data. If you want to be correct, use “association”. I will not.\n\nAgain, there are multiple ways to correlate the fruits. One straight forward way is the Pearson correlation coefficient, which can also be used for binary data. Pandas has a built-in function for this.\n\nAnother way is to simply count how many times a fruit was named alongside all other fruits. This can be solved using matrix multiplication. For this, we will need to convert the boolean dataframe to an integer based on first.\n\nThen, we can calculate the frequencies.\n\nAll we need to do now is add labels and transform it back to a dataframe.\n\nIf you are looking for a nice visualization, you can create a heatmap with the seaborn library.\n\nWith the Pearson matrix, we can easily build a fruit recommender system. For example, if you input that you like bananas, it will recommend you a maracuja, because those two have the highest correlation (0.67). You will be surprised by how powerful this simple approach is. I have used it successfully multiple times. If you want to do something like this with the frequency dataframe, you need to normalize the data first. However, that is a topic for another post."
    },
    {
        "link": "https://geeksforgeeks.org/creating-pandas-dataframe-using-list-of-lists",
        "document": "In this article, we will explore the Creating Pandas data frame using a list of lists. A Pandas DataFrame is a versatile 2-dimensional labeled data structure with columns that can contain different data types. It is widely utilized as one of the most common objects in the Pandas library. There are various methods for Creating a Pandas data frame using a list of lists, and we will specifically delve into the approach of utilizing a list of lists for this purpose.\n\nThere are various methods to create a Pandas data frame using a list of lists. Here, we are discussing some generally used methods that are following\n\nIn this example, we will create a list of lists and then pass it to the Pandas DataFrame function. Also, we will add the parameter of columns which will contain the column names.\n\nLet’s see another example with the same implementation as above.\n\nBelow code creates a Pandas DataFrame named from a list of lists, where missing values represented as are replaced with . It prints the resulting DataFrame containing information about individuals, including names, ages, and occupations.\n\nBelow code creates a Pandas DataFrame from a list of lists, converting the ‘Age’ column to numeric format and handling errors, with the result printed. The ‘Age’ values, initially a mix of numbers and strings, are corrected to numeric format.\n\nDoing some operations on dataframe like transpose. And also defining the Dataframe without column parameters and using df.columns() for the same.\n\nIn this example the below code uses pandas to create a DataFrame from a list of lists, assigns column names (‘Col_1’, ‘Col_2’, ‘Col_3’), prints the original DataFrame, transposes it, and prints the result. Transposing swaps rows and columns in the DataFrame."
    }
]