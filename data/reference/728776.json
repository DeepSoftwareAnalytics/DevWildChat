[
    {
        "link": "https://stackoverflow.com/questions/21067423/python-list-filtering-using-list-comprehension",
        "document": "I have a sorted list of values i need to filter such that the only values returned are not the same as the value to its left.\n\nFor example mylist=[1,2,2,3,3,3,3,6,7,9,9,11] would return [1,2,3,6,7,9,11].\n\nI've done this task using for and if loops but wondering if there is not a more elegant solution using list comprehensions."
    },
    {
        "link": "https://geeksforgeeks.org/filtering-elements-in-list-comprehension",
        "document": "List comprehensions are a powerful and concise way to create lists in Python. One of their notable features is the ability to filter elements based on certain conditions. In this article, we will delve into the art of filtering elements in list comprehensions, showcasing simple methods to enhance the readability and efficiency of your code.\n\nHere, expression is the operation performed on each item from the iterable that satisfies the specified condition. The if condition part is optional but crucial when it comes to filtering elements.\n\nBelow, are the example of Filtering Elements In List Comprehensions in Python.\n\nIn this example, below given code initializes a list of numbers from 1 to 10, uses a list comprehension to filter out even numbers, and then prints the resulting list of odd numbers: `[1, 3, 5, 7, 9]`.\n\nIn this example, given code initializes a list of numbers from 1 to 10, filters it using a list comprehension to include only elements greater than 3 and even, and then prints the resulting filtered list: `[4, 6, 8, 10]`.\n\nIn this example, below code initializes an original list of fruit names, filters it using a list comprehension to include only words with more than three characters.\n\nIn this example, below code creates an original list of numbers from 1 to 10, then uses the `filter()` function with a lambda expression to create a new list (`filtered_list`) containing only the odd numbers.\n\nIn Conclusion, leveraging list comprehensions for element filtering in Python not only streamlines code but also offers flexibility with concise and expressive syntax. These versatile constructs empower developers to efficiently handle various filtering scenarios, enhancing the overall readability and efficiency of Python programs."
    },
    {
        "link": "https://stackoverflow.com/questions/59864849/why-does-python-list-comprehension-filter-have-a-different-syntax-for-if-else",
        "document": "I have been sharpening my python programming skills over the past week and came across conditional filtering for list comprehension, which proves very useful. However, to add an else clause to the if filter, python requires a different syntax, as shown below:\n\nThe if-else clause had to be moved to the beginning of the list comprehension after the expression\n\nCan someone explain why this is so?\n\nThe question here if/else in a list comprehension? asks about how to do it, and that I know. My question is about why it is so."
    },
    {
        "link": "https://realpython.com/lessons/filtering-elements-list-comprehensions",
        "document": "Conditional statements can be added to Python list comprehensions in order to filter out data. In this lesson, you learned how to use filtering to produce a list of even squares. The returned data is the same as before except for the fact that only even squares are returned. All the logic for this operation is done in a single line.\n\nA list comprehension with a filter or conditional statement looks like this:\n\nThe next lesson will show you how to write this list comprehension using conventional loops."
    },
    {
        "link": "https://labex.io/tutorials/python-how-to-filter-list-with-conditions-419442",
        "document": "List filtering is a fundamental technique in Python that allows developers to selectively extract elements from a list based on specific conditions. This powerful method helps in data manipulation, cleaning, and processing.\n\nList comprehension provides a concise way to filter lists:\n\nThe function offers another approach to list filtering:\n• Use list comprehension for most filtering tasks\n\nBy understanding these basics, you'll be well-equipped to handle list filtering in your Python projects with LabEx's powerful learning resources."
    },
    {
        "link": "https://realpython.com/documenting-python-code",
        "document": "Welcome to your complete guide to documenting Python code. Whether you’re documenting a small script or a large project, whether you’re a beginner or a seasoned Pythonista, this guide will cover everything you need to know.\n\nWe’ve broken up this tutorial into four major sections:\n• Why Documenting Your Code Is So Important: An introduction to documentation and its importance\n• Commenting vs Documenting Code: An overview of the major differences between commenting and documenting, as well as the appropriate times and ways to use commenting\n• Documenting Your Python Code Base Using Docstrings: A deep dive into docstrings for classes, class methods, functions, modules, packages, and scripts, as well as what should be found within each one\n• Documenting Your Python Projects: The necessary elements and what they should contain for your Python projects\n\nFeel free to read through this tutorial from beginning to end or jump to a section you’re interested in. It was designed to work both ways.\n\nWhy Documenting Your Code Is So Important Hopefully, if you’re reading this tutorial, you already know the importance of documenting your code. But if not, then let me quote something Guido mentioned to me at a recent PyCon: “Code is more often read than written.” When you write code, you write it for two primary audiences: your users and your developers (including yourself). Both audiences are equally important. If you’re like me, you’ve probably opened up old codebases and wondered to yourself, “What in the world was I thinking?” If you’re having a problem reading your own code, imagine what your users or other developers are experiencing when they’re trying to use or contribute to your code. Conversely, I’m sure you’ve run into a situation where you wanted to do something in Python and found what looks like a great library that can get the job done. However, when you start using the library, you look for examples, write-ups, or even official documentation on how to do something specific and can’t immediately find the solution. After searching, you come to realize that the documentation is lacking or even worse, missing entirely. This is a frustrating feeling that deters you from using the library, no matter how great or efficient the code is. Daniele Procida summarized this situation best: “It doesn’t matter how good your software is, because if the documentation is not good enough, people will not use it.“ In this guide, you’ll learn from the ground up how to properly document your Python code from the smallest of scripts to the largest of Python projects to help prevent your users from ever feeling too frustrated to use or contribute to your project.\n\nBefore we can go into how to document your Python code, we need to distinguish documenting from commenting. In general, commenting is describing your code to/for developers. The intended main audience is the maintainers and developers of the Python code. In conjunction with well-written code, comments help to guide the reader to better understand your code and its purpose and design: “Code tells you how; Comments tell you why.” Documenting code is describing its use and functionality to your users. While it may be helpful in the development process, the main intended audience is the users. The following section describes how and when to comment your code. Comments are created in Python using the pound sign ( ) and should be brief statements no longer than a few sentences. Here’s a simple example: According to PEP 8, comments should have a maximum length of 72 characters. This is true even if your project changes the max line length to be greater than the recommended 80 characters. If a comment is going to be greater than the comment char limit, using multiple lines for the comment is appropriate: # A very long statement that just goes on and on and on and on and # never ends until after it's reached the 80 char limit\n• Planning and Reviewing: When you are developing new portions of your code, it may be appropriate to first use comments as a way of planning or outlining that section of code. Remember to remove these comments once the actual coding has been implemented and reviewed/tested:\n• Code Description: Comments can be used to explain the intent of specific sections of code:\n• Algorithmic Description: When algorithms are used, especially complicated ones, it can be useful to explain how the algorithm works or how it’s implemented within your code. It may also be appropriate to describe why a specific algorithm was selected over another.\n• Tagging: The use of tagging can be used to label specific sections of code where known issues or areas of improvement are located. Some examples are: , , and . # TODO: Add condition for when val is None Comments to your code should be kept brief and focused. Avoid using long comments when possible. Additionally, you should use the following four essential rules as suggested by Jeff Atwood:\n• Keep comments as close to the code being described as possible. Comments that aren’t near their describing code are frustrating to the reader and easily missed when updates are made.\n• Don’t use complex formatting (such as tables or ASCII figures). Complex formatting leads to distracting content and can be difficult to maintain over time.\n• Don’t include redundant information. Assume the reader of the code has a basic understanding of programming principles and language syntax.\n• Design your code to comment itself. The easiest way to understand code is by reading it. When you design your code using clear, easy-to-understand concepts, the reader will be able to quickly conceptualize your intent. Remember that comments are designed for the reader, including yourself, to help guide them in understanding the purpose and design of the software. Type hinting was added to Python 3.5 and is an additional form to help the readers of your code. In fact, it takes Jeff’s fourth suggestion from above to the next level. It allows the developer to design and explain portions of their code without commenting. Here’s a quick example: From examining the type hinting, you can immediately tell that the function expects the input to be of a type , or string. You can also tell that the expected output of the function will be of a type , or string, as well. While type hinting helps reduce comments, take into consideration that doing so may also make extra work when you are creating or updating your project documentation. You can learn more about type hinting and type checking from this video created by Dan Bader.\n\nNow that we’ve learned about commenting, let’s take a deep dive into documenting a Python code base. In this section, you’ll learn about docstrings and how to use them for documentation. This section is further divided into the following sub-sections:\n• Docstrings Background: A background on how docstrings work internally within Python\n• Docstring Types: The various docstring “types” (function, class, class method, module, package, and script)\n• Docstring Formats: The different docstring “formats” (Google, NumPy/SciPy, reStructuredText, and Epytext) Documenting your Python code is all centered on docstrings. These are built-in strings that, when configured correctly, can help your users and yourself with your project’s documentation. Along with docstrings, Python also has the built-in function that prints out the objects docstring to the console. Here’s a quick example: Help on class str in module builtins: | Create a new string object from the given object. If encoding or | errors are specified, then the object must expose a data buffer | that will be decoded using the given encoding and error handler. | Otherwise, returns the result of object.__str__() (if defined) How is this output generated? Since everything in Python is an object, you can examine the directory of the object using the command. Let’s do that and see what find: Within that directory output, there’s an interesting property, . If you examine that property, you’ll discover this: Create a new string object from the given object. If encoding or errors are specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.__str__() (if defined) Voilà! You’ve found where docstrings are stored within the object. This means that you can directly manipulate that property. However, there are restrictions for builtins: \"I'm a little string doc! Short and stout; here is my input and print me for my out\" File , line , in : Any other custom object can be manipulated: , is it me you're looking for?\" \"A simple function that says hello... Richie style\" Help on function say_hello in module __main__: A simple function that says hello... Richie style Python has one more feature that simplifies docstring creation. Instead of directly manipulating the property, the strategic placement of the string literal directly below the object will automatically set the value. Here’s what happens with the same example as above: \"\"\"A simple function that says hello... Richie style\"\"\" , is it me you're looking for?\" Help on function say_hello in module __main__: A simple function that says hello... Richie style There you go! Now you understand the background of docstrings. Now it’s time to learn about the different types of docstrings and what information they should contain. Docstring conventions are described within PEP 257. Their purpose is to provide your users with a brief overview of the object. They should be kept concise enough to be easy to maintain but still be elaborate enough for new users to understand their purpose and how to use the documented object. In all cases, the docstrings should use the triple-double quote ( ) string format. This should be done whether the docstring is multi-lined or not. At a bare minimum, a docstring should be a quick summary of whatever is it you’re describing and should be contained within a single line: \"\"\"This is a quick summary line used as a description of the object.\"\"\" Multi-lined docstrings are used to further elaborate on the object beyond the summary. All multi-lined docstrings have the following parts:\n• Any further elaboration for the docstring \"\"\"This is the summary line This is the further elaboration of the docstring. Within this section, you can elaborate further on details as appropriate for the situation. Notice that the summary and the elaboration is separated by a blank new # Notice the blank line above. Code should continue on this line. All docstrings should have the same max character length as comments (72 characters). Docstrings can be further broken up into three major categories: Class Docstrings are created for the class itself, as well as any class methods. The docstrings are placed immediately following the class or class method indented by one level: Class docstrings should contain the following information:\n• A brief summary of its purpose and behavior\n• Any public methods, along with a brief description\n• Anything related to the interface for subclassers, if the class is intended to be subclassed The class constructor parameters should be documented within the class method docstring. Individual methods should be documented using their individual docstrings. Class method docstrings should contain the following:\n• A brief description of what the method is and what it’s used for\n• Any arguments (both required and optional) that are passed including keyword arguments\n• Label any arguments that are considered optional or have a default value\n• Any side effects that occur when executing the method\n• Any exceptions that are raised\n• Any restrictions on when the method can be called Let’s take a simple example of a data class that represents an Animal. This class will contain a few class properties, instance properties, a , and a single instance method: A class used to represent an Animal a formatted string to print out what the animal says the sound that the animal makes the number of legs the animal has (default 4) Prints the animals name and what sound it makes The number of legs the animal (default is 4) \"\"\"Prints what the animals name is and what sound it makes. If the argument `sound` isn't passed in, the default Animal The sound the animal makes (default is None) If no sound is set for the animal or passed in as a Package docstrings should be placed at the top of the package’s file. This docstring should list the modules and sub-packages that are exported by the package. Module docstrings are similar to class docstrings. Instead of classes and class methods being documented, it’s now the module and any functions found within. Module docstrings are placed at the top of the file even before any imports. Module docstrings should include the following:\n• A brief description of the module and its purpose\n• A list of any classes, exception, functions, and any other objects exported by the module The docstring for a module function should include the same items as a class method:\n• A brief description of what the function is and what it’s used for\n• Any arguments (both required and optional) that are passed including keyword arguments\n• Label any arguments that are considered optional\n• Any side effects that occur when executing the function\n• Any exceptions that are raised\n• Any restrictions on when the function can be called Scripts are considered to be single file executables run from the console. Docstrings for scripts are placed at the top of the file and should be documented well enough for users to be able to have a sufficient understanding of how to use the script. It should be usable for its “usage” message, when the user incorrectly passes in a parameter or uses the option. If you use , then you can omit parameter-specific documentation, assuming it’s correctly been documented within the parameter of the function. It is recommended to use the for the parameter within ’s constructor. Check out our tutorial on Command-Line Parsing Libraries for more details on how to use and other common command line parsers. Finally, any custom or third-party imports should be listed within the docstrings to allow users to know which packages may be required for running the script. Here’s an example of a script that is used to simply print out the column headers of a spreadsheet: This script allows the user to print to the console all columns in the spreadsheet. It is assumed that the first row of the spreadsheet is the This tool accepts comma separated value files (.csv) as well as excel This script requires that `pandas` be installed within the Python environment you are running this script in. This file can also be imported as a module and contains the following * get_spreadsheet_cols - returns the column headers of the file * main - the main function of the script \"\"\"Gets and prints the spreadsheet's header columns The file location of the spreadsheet A flag used to print the columns to the console (default is a list of strings used that are the header columns \"The spreadsheet file to pring the columns of\" You may have noticed that, throughout the examples given in this tutorial, there has been specific formatting with common elements: , , and . There are specific docstrings formats that can be used to help docstring parsers and users have a familiar and known format. The formatting used within the examples in this tutorial are NumPy/SciPy-style docstrings. Some of the most common formats are the following: Official Python documentation standard; Not beginner friendly but feature rich The selection of the docstring format is up to you, but you should stick with the same format throughout your document/project. The following are examples of each type to give you an idea of how each documentation format looks. \"\"\"Gets and prints the spreadsheet's header columns file_loc (str): The file location of the spreadsheet print_cols (bool): A flag used to print the columns to the console \"\"\"Gets and prints the spreadsheet's header columns :param file_loc: The file location of the spreadsheet :param print_cols: A flag used to print the columns to the console \"\"\"Gets and prints the spreadsheet's header columns The file location of the spreadsheet A flag used to print the columns to the console (default is False) \"\"\"Gets and prints the spreadsheet's header columns @param file_loc: The file location of the spreadsheet @param print_cols: A flag used to print the columns to the console"
    },
    {
        "link": "https://docs.python.org/3/library/functions.html",
        "document": "The Python interpreter has a number of functions and types built into it that are always available. They are listed here in alphabetical order.\n\nOpen file and return a corresponding file object. If the file cannot be opened, an is raised. See Reading and Writing Files for more examples of how to use this function. file is a path-like object giving the pathname (absolute or relative to the current working directory) of the file to be opened or an integer file descriptor of the file to be wrapped. (If a file descriptor is given, it is closed when the returned I/O object is closed unless closefd is set to .) mode is an optional string that specifies the mode in which the file is opened. It defaults to which means open for reading in text mode. Other common values are for writing (truncating the file if it already exists), for exclusive creation, and for appending (which on some Unix systems, means that all writes append to the end of the file regardless of the current seek position). In text mode, if encoding is not specified the encoding used is platform-dependent: is called to get the current locale encoding. (For reading and writing raw bytes use binary mode and leave encoding unspecified.) The available modes are: open for writing, truncating the file first open for exclusive creation, failing if the file already exists open for writing, appending to the end of file if it exists The default mode is (open for reading text, a synonym of ). Modes and open and truncate the file. Modes and open the file with no truncation. As mentioned in the Overview, Python distinguishes between binary and text I/O. Files opened in binary mode (including in the mode argument) return contents as objects without any decoding. In text mode (the default, or when is included in the mode argument), the contents of the file are returned as , the bytes having been first decoded using a platform-dependent encoding or using the specified encoding if given. Python doesn’t depend on the underlying operating system’s notion of text files; all the processing is done by Python itself, and is therefore platform-independent. buffering is an optional integer used to set the buffering policy. Pass 0 to switch buffering off (only allowed in binary mode), 1 to select line buffering (only usable when writing in text mode), and an integer > 1 to indicate the size in bytes of a fixed-size chunk buffer. Note that specifying a buffer size this way applies for binary buffered I/O, but (i.e., files opened with ) would have another buffering. To disable buffering in , consider using the flag for . When no buffering argument is given, the default buffering policy works as follows:\n• None Binary files are buffered in fixed-size chunks; the size of the buffer is chosen using a heuristic trying to determine the underlying device’s “block size” and falling back on . On many systems, the buffer will typically be 4096 or 8192 bytes long.\n• None “Interactive” text files (files for which returns ) use line buffering. Other text files use the policy described above for binary files. encoding is the name of the encoding used to decode or encode the file. This should only be used in text mode. The default encoding is platform dependent (whatever returns), but any text encoding supported by Python can be used. See the module for the list of supported encodings. errors is an optional string that specifies how encoding and decoding errors are to be handled—this cannot be used in binary mode. A variety of standard error handlers are available (listed under Error Handlers), though any error handling name that has been registered with is also valid. The standard names include:\n• None to raise a exception if there is an encoding error. The default value of has the same effect.\n• None ignores errors. Note that ignoring encoding errors can lead to data loss.\n• None causes a replacement marker (such as ) to be inserted where there is malformed data.\n• None will represent any incorrect bytes as low surrogate code units ranging from U+DC80 to U+DCFF. These surrogate code units will then be turned back into the same bytes when the error handler is used when writing data. This is useful for processing files in an unknown encoding.\n• None is only supported when writing to a file. Characters not supported by the encoding are replaced with the appropriate XML character reference .\n• None (also only supported when writing) replaces unsupported characters with escape sequences. newline determines how to parse newline characters from the stream. It can be , , , , and . It works as follows:\n• None When reading input from the stream, if newline is , universal newlines mode is enabled. Lines in the input can end in , , or , and these are translated into before being returned to the caller. If it is , universal newlines mode is enabled, but line endings are returned to the caller untranslated. If it has any of the other legal values, input lines are only terminated by the given string, and the line ending is returned to the caller untranslated.\n• None When writing output to the stream, if newline is , any characters written are translated to the system default line separator, . If newline is or , no translation takes place. If newline is any of the other legal values, any characters written are translated to the given string. If closefd is and a file descriptor rather than a filename was given, the underlying file descriptor will be kept open when the file is closed. If a filename is given closefd must be (the default); otherwise, an error will be raised. A custom opener can be used by passing a callable as opener. The underlying file descriptor for the file object is then obtained by calling opener with (file, flags). opener must return an open file descriptor (passing as opener results in functionality similar to passing ). The following example uses the dir_fd parameter of the function to open a file relative to a given directory: 'This will be written to somedir/spamspam.txt' The type of file object returned by the function depends on the mode. When is used to open a file in a text mode ( , , , , etc.), it returns a subclass of (specifically ). When used to open a file in a binary mode with buffering, the returned class is a subclass of . The exact class varies: in read binary mode, it returns an ; in write binary and append binary modes, it returns an , and in read/write mode, it returns an . When buffering is disabled, the raw stream, a subclass of , , is returned. See also the file handling modules, such as , (where is declared), , , , and . The and arguments may have been modified or inferred from the original call.\n• None used to be raised, it is now an alias of .\n• None is now raised if the file opened in exclusive creation mode ( ) already exists.\n• None The file is now non-inheritable.\n• None If the system call is interrupted and the signal handler does not raise an exception, the function now retries the system call instead of raising an exception (see PEP 475 for the rationale).\n• None On Windows, opening a console buffer may return a subclass of other than . Changed in version 3.11: The mode has been removed.\n\nReturn a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing inherited methods that have been overridden in a class. The object_or_type determines the method resolution order to be searched. The search starts from the class right after the type. For example, if of object_or_type is and the value of type is , then searches . The attribute of the class corresponding to object_or_type lists the method resolution search order used by both and . The attribute is dynamic and can change whenever the inheritance hierarchy is updated. If the second argument is omitted, the super object returned is unbound. If the second argument is an object, must be true. If the second argument is a type, must be true (this is useful for classmethods). When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument ”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately enclosing function (typically ). (This means that zero-argument will not work as expected within nested functions, including generator expressions, which implicitly create nested functions.) There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer to parent classes without naming them explicitly, thus making the code more maintainable. This use closely parallels the use of super in other programming languages. The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This use case is unique to Python and is not found in statically compiled languages or languages that only support single inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes implement the same method. Good design dictates that such implementations have the same calling signature in every case (because the order of calls is determined at runtime, because that order adapts to changes in the class hierarchy, and because that order can include sibling classes that are unknown prior to runtime). For both use cases, a typical superclass call looks like this: # This does the same thing as: In addition to method lookups, also works for attribute lookups. One possible use case for this is calling descriptors in a parent or sibling class. Note that is implemented as part of the binding process for explicit dotted attribute lookups such as . It does so by implementing its own method for searching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, is undefined for implicit lookups using statements or operators such as . Also note that, aside from the zero argument form, is not limited to use inside methods. The two argument form specifies the arguments exactly and makes the appropriate references. The zero argument form only works inside a class definition, as the compiler fills in the necessary details to correctly retrieve the class being defined, as well as accessing the current instance for ordinary methods. For practical suggestions on how to design cooperative classes using , see guide to using super()."
    },
    {
        "link": "https://swimm.io/learn/code-documentation/documentation-in-python-methods-and-best-practices",
        "document": "What Is Documentation in Python?\n\nDocumentation in Python refers to the written text that accompanies a Python software project. This text explains the purpose and use of the code, making it easier for others (and often yourself in the future) to understand and maintain. Python documentation can come in many forms, from inline comments and docstrings within the code itself, to external documentation like user manuals and API references.\n\nPython is particularly well-suited for good documentation practices due to its clean, readable syntax and strong support for docstrings—in-code explanations of functions, methods, and classes. Even Python’s philosophy, expressed in the Zen of Python, encourages code readability and hence, good documentation.\n\nAnother meaning of the term “documentation in Python” is the official documentation of the Python language. Here is a link to the documentation for the latest version of Python 3.\n\nThis is part of a series of articles about code documentation\n\nWhy Documenting Your Python Code Is Important\n\nAs a project grows, keeping track of every piece of code becomes increasingly challenging. Well-written documentation serves as a map, guiding you or other developers through the codebase. It’s particularly useful when hunting down bugs or implementing new features. Without documentation, you’re effectively lost in a sea of code.\n\nFurthermore, documentation in Python also serves as a form of ‘defensive programming’. It helps catch and prevent errors. For instance, Python’s docstrings can include information about a function’s expected input and output types. This helps ensure that the function is used correctly, reducing the likelihood of bugs.\n\nDocumentation also plays a crucial role in onboarding new developers onto a project. Comprehensive documentation enables new developers to quickly understand the system’s architecture, the purpose of various parts of the code, and how they interact. This accelerates the onboarding process, reducing the time it takes for new developers to become productive members of the team.\n\nMoreover, well-documented code fosters an environment of self-reliance. New developers can consult the documentation to answer their questions, rather than relying on others. This not only speeds up their learning process but also minimizes disruptions to the rest of the team.\n\nIn a team setting, developers are often working on different parts of a project simultaneously. Good documentation ensures that everyone understands not just their own code, but the entire codebase. This shared understanding facilitates effective collaboration, preventing conflicts and misunderstandings.\n\nGood documentation also smoothens the code review process. Reviewers can refer to the documentation to better understand the code changes, enabling them to provide more valuable feedback. Consequently, this leads to higher code quality and fewer bugs.\n\nLastly, documentation plays a pivotal role in quality assurance. It provides a clear understanding of how the system is supposed to work, which is invaluable when testing. Testers can refer to the documentation to ensure that the system behaves as expected.\n\nIn addition, documentation can also guide the creation of automated tests. For instance, function docstrings can provide information about the expected inputs and outputs, which can be used to generate unit tests automatically. This not only improves the testing process but also helps maintain high code quality.\n\nRelated content: Read our guide to documentation as code\n\nOne of the simplest ways to document your Python code is through inline comments. These are brief notes written directly into the code, typically on the same line or directly above the code they refer to. Here is the syntax for comments in Python:\n\nInline comments are great for explaining the rationale behind certain code decisions, or for providing a quick summary of what a complex piece of code does.\n\nHowever, it’s important to use inline comments judiciously. Overuse can clutter the code and make it harder to read. As a general rule, your code should be self-explanatory. Use comments to explain the ‘why’ (the reasoning behind the code), not the ‘what’ (what the code is doing).\n\nDocstrings, or documentation strings, are a more powerful documentation tool in Python. They’re multi-line strings placed at the start of functions, classes, and modules that describe what these components do. Here is an example of the use of Docstrings:\n\nDocstrings can include information about the purpose of the function, its inputs and outputs, exceptions it may raise, and more.\n\nPython has a built-in help() function that can display the docstring for any function, class, or module. This makes docstrings a highly accessible form of documentation.\n\nPython 3.5 introduced optional type hints, which allow you to specify the expected type of function arguments and return values. Here is an example of type hints:\n\nIn the example above, the type hints, indicated by List[int] and Tuple[List[int], List[int]], inform the developer that the function expects a list of integers as an argument and will return a tuple of two lists of integers.\n\nThese type hints act as documentation and can also be used for type checking, either at runtime or statically (i.e., without running the code). Type checking can help catch certain types of bugs before the code is even run.\n\nDocumentation generators are tools that automatically create documentation from your code. In Python, the most popular documentation generator is Sphinx. It can generate documentation in various formats (including HTML and PDF) from reStructuredText, a lightweight markup language.\n\nSphinx can also auto-generate API documentation from your code’s docstrings. This makes it a powerful tool for creating comprehensive, professional-quality documentation with minimal effort.\n\nA good docstring should be clear, concise, and informative. It should quickly convey what the function does, without going into too much detail. Avoid jargon and complex language—your goal is to make the function’s purpose understandable to anyone who reads the docstring.\n\nIt’s also good practice to include information about the function’s inputs, outputs, and any exceptions it might raise. If your function has side effects (i.e., it changes some state outside its own scope), be sure to document these as well.\n\nExamples are a powerful way to illustrate how to use a function or class. They provide a concrete demonstration of the code in action, making it easier for others to understand how to use it. Including examples in your docstrings or external documentation can significantly improve their usefulness.\n\nWhen writing examples, ensure they are simple, clear, and representative of typical use cases. Avoid complex or contrived examples, as they can be confusing rather than helpful.\n\nExternal documentation is just as important as inline comments and docstrings. It provides a high-level overview of your project, including its architecture, dependencies, setup instructions, usage guide, and more.\n\nKeep your external documentation well-organized and easy to read. Use clear headings and subheadings, maintain a logical flow, and ensure it’s up-to-date. An out-of-date documentation can be worse than no documentation at all, as it can mislead users and developers.\n\nAs a rule of thumb, all public interfaces of your code should be documented. This includes all public functions, methods, classes, and modules. These are the parts of your code that other people will interact with, so it’s crucial that they understand how to use them.\n\nPrivate interfaces (i.e., parts of your code that are meant to be used only within their own module or class) don’t necessarily need to be documented, although it can still be helpful to do so.\n\nIf your project is intended for a global audience, consider localizing your documentation. This means translating it into multiple languages. While English is the lingua franca of the programming world, not all developers are comfortable with it. Providing localized documentation can make your project more accessible to a global audience.\n\nDocumentation in Python is an indispensable aspect of any software project. It not only enhances code maintainability, making it easier to navigate and understand, but also plays a crucial role in onboarding new developers. With comprehensive documentation, teams can collaborate more effectively, leading to higher code quality and improved productivity.\n\nSwimm’s solution, designed for distinguished engineers, staff engineers, developers, and DevOps teams, offers code-coupled documentation that adapts as code changes, simplifying the documentation process and enhancing the onboarding experience. By combining code knowledge with Swimm’s capabilities, you can elevate your Python project’s documentation to new heights, ensuring your team’s success and efficient coding practices."
    },
    {
        "link": "https://peps.python.org/pep-0008",
        "document": "This document gives coding conventions for the Python code comprising the standard library in the main Python distribution. Please see the companion informational PEP describing style guidelines for the C code in the C implementation of Python. This document and PEP 257 (Docstring Conventions) were adapted from Guido’s original Python Style Guide essay, with some additions from Barry’s style guide . This style guide evolves over time as additional conventions are identified and past conventions are rendered obsolete by changes in the language itself. Many projects have their own coding style guidelines. In the event of any conflicts, such project-specific guides take precedence for that project.\n\nA Foolish Consistency is the Hobgoblin of Little Minds One of Guido’s key insights is that code is read much more often than it is written. The guidelines provided here are intended to improve the readability of code and make it consistent across the wide spectrum of Python code. As PEP 20 says, “Readability counts”. A style guide is about consistency. Consistency with this style guide is important. Consistency within a project is more important. Consistency within one module or function is the most important. However, know when to be inconsistent – sometimes style guide recommendations just aren’t applicable. When in doubt, use your best judgment. Look at other examples and decide what looks best. And don’t hesitate to ask! In particular: do not break backwards compatibility just to comply with this PEP! Some other good reasons to ignore a particular guideline:\n• When applying the guideline would make the code less readable, even for someone who is used to reading code that follows this PEP.\n• To be consistent with surrounding code that also breaks it (maybe for historic reasons) – although this is also an opportunity to clean up someone else’s mess (in true XP style).\n• Because the code in question predates the introduction of the guideline and there is no other reason to be modifying that code.\n• When the code needs to remain compatible with older versions of Python that don’t support the feature recommended by the style guide.\n\nContinuation lines should align wrapped elements either vertically using Python’s implicit line joining inside parentheses, brackets and braces, or using a hanging indent . When using a hanging indent the following should be considered; there should be no arguments on the first line and further indentation should be used to clearly distinguish itself as a continuation line: # Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest. # Arguments on first line forbidden when not using vertical alignment. # Further indentation required as indentation is not distinguishable. The 4-space rule is optional for continuation lines. # Hanging indents *may* be indented to other than 4 spaces. When the conditional part of an -statement is long enough to require that it be written across multiple lines, it’s worth noting that the combination of a two character keyword (i.e. ), plus a single space, plus an opening parenthesis creates a natural 4-space indent for the subsequent lines of the multiline conditional. This can produce a visual conflict with the indented suite of code nested inside the -statement, which would also naturally be indented to 4 spaces. This PEP takes no explicit position on how (or whether) to further visually distinguish such conditional lines from the nested suite inside the -statement. Acceptable options in this situation include, but are not limited to: # Add a comment, which will provide some distinction in editors # Since both conditions are true, we can frobnicate. # Add some extra indentation on the conditional continuation line. The closing brace/bracket/parenthesis on multiline constructs may either line up under the first non-whitespace character of the last line of list, as in: or it may be lined up under the first character of the line that starts the multiline construct, as in: Tabs should be used solely to remain consistent with code that is already indented with tabs. Limit all lines to a maximum of 79 characters. For flowing long blocks of text with fewer structural restrictions (docstrings or comments), the line length should be limited to 72 characters. Limiting the required editor window width makes it possible to have several files open side by side, and works well when using code review tools that present the two versions in adjacent columns. The default wrapping in most tools disrupts the visual structure of the code, making it more difficult to understand. The limits are chosen to avoid wrapping in editors with the window width set to 80, even if the tool places a marker glyph in the final column when wrapping lines. Some web based tools may not offer dynamic line wrapping at all. Some teams strongly prefer a longer line length. For code maintained exclusively or primarily by a team that can reach agreement on this issue, it is okay to increase the line length limit up to 99 characters, provided that comments and docstrings are still wrapped at 72 characters. The Python standard library is conservative and requires limiting lines to 79 characters (and docstrings/comments to 72). The preferred way of wrapping long lines is by using Python’s implied line continuation inside parentheses, brackets and braces. Long lines can be broken over multiple lines by wrapping expressions in parentheses. These should be used in preference to using a backslash for line continuation. Backslashes may still be appropriate at times. For example, long, multiple -statements could not use implicit continuation before Python 3.10, so backslashes were acceptable for that case: Another such case is with statements. Make sure to indent the continued line appropriately. Should a Line Break Before or After a Binary Operator? For decades the recommended style was to break after binary operators. But this can hurt readability in two ways: the operators tend to get scattered across different columns on the screen, and each operator is moved away from its operand and onto the previous line. Here, the eye has to do extra work to tell which items are added and which are subtracted: # operators sit far away from their operands To solve this readability problem, mathematicians and their publishers follow the opposite convention. Donald Knuth explains the traditional rule in his Computers and Typesetting series: “Although formulas within a paragraph always break after binary operations and relations, displayed formulas always break before binary operations” . Following the tradition from mathematics usually results in more readable code: In Python code, it is permissible to break before or after a binary operator, as long as the convention is consistent locally. For new code Knuth’s style is suggested. Surround top-level function and class definitions with two blank lines. Extra blank lines may be used (sparingly) to separate groups of related functions. Blank lines may be omitted between a bunch of related one-liners (e.g. a set of dummy implementations). Use blank lines in functions, sparingly, to indicate logical sections. Python accepts the control-L (i.e. ^L) form feed character as whitespace; many tools treat these characters as page separators, so you may use them to separate pages of related sections of your file. Note, some editors and web-based code viewers may not recognize control-L as a form feed and will show another glyph in its place. Code in the core Python distribution should always use UTF-8, and should not have an encoding declaration. In the standard library, non-UTF-8 encodings should be used only for test purposes. Use non-ASCII characters sparingly, preferably only to denote places and human names. If using non-ASCII characters as data, avoid noisy Unicode characters like z̯̯͡a̧͎̺l̡͓̫g̹̲o̡̼̘ and byte order marks. All identifiers in the Python standard library MUST use ASCII-only identifiers, and SHOULD use English words wherever feasible (in many cases, abbreviations and technical terms are used which aren’t English). Open source projects with a global audience are encouraged to adopt a similar policy.\n• Imports should usually be on separate lines: It’s okay to say this though:\n• Imports are always put at the top of the file, just after any module comments and docstrings, and before module globals and constants. Imports should be grouped in the following order: You should put a blank line between each group of imports.\n• Absolute imports are recommended, as they are usually more readable and tend to be better behaved (or at least give better error messages) if the import system is incorrectly configured (such as when a directory inside a package ends up on ): However, explicit relative imports are an acceptable alternative to absolute imports, especially when dealing with complex package layouts where using absolute imports would be unnecessarily verbose: Standard library code should avoid complex package layouts and always use absolute imports.\n• When importing a class from a class-containing module, it’s usually okay to spell this: If this spelling causes local name clashes, then spell them explicitly: and use and .\n• Wildcard imports ( ) should be avoided, as they make it unclear which names are present in the namespace, confusing both readers and many automated tools. There is one defensible use case for a wildcard import, which is to republish an internal interface as part of a public API (for example, overwriting a pure Python implementation of an interface with the definitions from an optional accelerator module and exactly which definitions will be overwritten isn’t known in advance). When republishing names this way, the guidelines below regarding public and internal interfaces still apply. Module level “dunders” (i.e. names with two leading and two trailing underscores) such as , , , etc. should be placed after the module docstring but before any import statements except imports. Python mandates that future-imports must appear in the module before any other code except docstrings: \"\"\"This is the example module.\n\nWhen to Use Trailing Commas Trailing commas are usually optional, except they are mandatory when making a tuple of one element. For clarity, it is recommended to surround the latter in (technically redundant) parentheses: When trailing commas are redundant, they are often helpful when a version control system is used, when a list of values, arguments or imported items is expected to be extended over time. The pattern is to put each value (etc.) on a line by itself, always adding a trailing comma, and add the close parenthesis/bracket/brace on the next line. However it does not make sense to have a trailing comma on the same line as the closing delimiter (except in the above case of singleton tuples):\n\nThe naming conventions of Python’s library are a bit of a mess, so we’ll never get this completely consistent – nevertheless, here are the currently recommended naming standards. New modules and packages (including third party frameworks) should be written to these standards, but where an existing library has a different style, internal consistency is preferred. Names that are visible to the user as public parts of the API should follow conventions that reflect usage rather than implementation. There are a lot of different naming styles. It helps to be able to recognize what naming style is being used, independently from what they are used for. The following naming styles are commonly distinguished:\n• (or CapWords, or CamelCase – so named because of the bumpy look of its letters ). This is also sometimes known as StudlyCaps. Note: When using acronyms in CapWords, capitalize all the letters of the acronym. Thus HTTPServerError is better than HttpServerError. There’s also the style of using a short unique prefix to group related names together. This is not used much in Python, but it is mentioned for completeness. For example, the function returns a tuple whose items traditionally have names like , , and so on. (This is done to emphasize the correspondence with the fields of the POSIX system call struct, which helps programmers familiar with that.) The X11 library uses a leading X for all its public functions. In Python, this style is generally deemed unnecessary because attribute and method names are prefixed with an object, and function names are prefixed with a module name. In addition, the following special forms using leading or trailing underscores are recognized (these can generally be combined with any case convention):\n• : weak “internal use” indicator. E.g. does not import objects whose names start with an underscore.\n• : used by convention to avoid conflicts with Python keyword, e.g. :\n• : when naming a class attribute, invokes name mangling (inside class FooBar, becomes ; see below).\n• : “magic” objects or attributes that live in user-controlled namespaces. E.g. , or . Never invent such names; only use them as documented. Never use the characters ‘l’ (lowercase letter el), ‘O’ (uppercase letter oh), or ‘I’ (uppercase letter eye) as single character variable names. In some fonts, these characters are indistinguishable from the numerals one and zero. When tempted to use ‘l’, use ‘L’ instead. Identifiers used in the standard library must be ASCII compatible as described in the policy section of PEP 3131. Modules should have short, all-lowercase names. Underscores can be used in the module name if it improves readability. Python packages should also have short, all-lowercase names, although the use of underscores is discouraged. When an extension module written in C or C++ has an accompanying Python module that provides a higher level (e.g. more object oriented) interface, the C/C++ module has a leading underscore (e.g. ). Class names should normally use the CapWords convention. The naming convention for functions may be used instead in cases where the interface is documented and used primarily as a callable. Note that there is a separate convention for builtin names: most builtin names are single words (or two words run together), with the CapWords convention used only for exception names and builtin constants. Names of type variables introduced in PEP 484 should normally use CapWords preferring short names: , , . It is recommended to add suffixes or to the variables used to declare covariant or contravariant behavior correspondingly: Because exceptions should be classes, the class naming convention applies here. However, you should use the suffix “Error” on your exception names (if the exception actually is an error). (Let’s hope that these variables are meant for use inside one module only.) The conventions are about the same as those for functions. Modules that are designed for use via should use the mechanism to prevent exporting globals, or use the older convention of prefixing such globals with an underscore (which you might want to do to indicate these globals are “module non-public”). Function names should be lowercase, with words separated by underscores as necessary to improve readability. Variable names follow the same convention as function names. mixedCase is allowed only in contexts where that’s already the prevailing style (e.g. threading.py), to retain backwards compatibility. Always use for the first argument to instance methods. Always use for the first argument to class methods. If a function argument’s name clashes with a reserved keyword, it is generally better to append a single trailing underscore rather than use an abbreviation or spelling corruption. Thus is better than . (Perhaps better is to avoid such clashes by using a synonym.) Use the function naming rules: lowercase with words separated by underscores as necessary to improve readability. Use one leading underscore only for non-public methods and instance variables. To avoid name clashes with subclasses, use two leading underscores to invoke Python’s name mangling rules. Python mangles these names with the class name: if class Foo has an attribute named , it cannot be accessed by . (An insistent user could still gain access by calling .) Generally, double leading underscores should be used only to avoid name conflicts with attributes in classes designed to be subclassed. Note: there is some controversy about the use of __names (see below). Constants are usually defined on a module level and written in all capital letters with underscores separating words. Examples include and . Always decide whether a class’s methods and instance variables (collectively: “attributes”) should be public or non-public. If in doubt, choose non-public; it’s easier to make it public later than to make a public attribute non-public. Public attributes are those that you expect unrelated clients of your class to use, with your commitment to avoid backwards incompatible changes. Non-public attributes are those that are not intended to be used by third parties; you make no guarantees that non-public attributes won’t change or even be removed. We don’t use the term “private” here, since no attribute is really private in Python (without a generally unnecessary amount of work). Another category of attributes are those that are part of the “subclass API” (often called “protected” in other languages). Some classes are designed to be inherited from, either to extend or modify aspects of the class’s behavior. When designing such a class, take care to make explicit decisions about which attributes are public, which are part of the subclass API, and which are truly only to be used by your base class. With this in mind, here are the Pythonic guidelines:\n• Public attributes should have no leading underscores.\n• If your public attribute name collides with a reserved keyword, append a single trailing underscore to your attribute name. This is preferable to an abbreviation or corrupted spelling. (However, notwithstanding this rule, ‘cls’ is the preferred spelling for any variable or argument which is known to be a class, especially the first argument to a class method.) Note 1: See the argument name recommendation above for class methods.\n• For simple public data attributes, it is best to expose just the attribute name, without complicated accessor/mutator methods. Keep in mind that Python provides an easy path to future enhancement, should you find that a simple data attribute needs to grow functional behavior. In that case, use properties to hide functional implementation behind simple data attribute access syntax. Note 1: Try to keep the functional behavior side-effect free, although side-effects such as caching are generally fine. Note 2: Avoid using properties for computationally expensive operations; the attribute notation makes the caller believe that access is (relatively) cheap.\n• If your class is intended to be subclassed, and you have attributes that you do not want subclasses to use, consider naming them with double leading underscores and no trailing underscores. This invokes Python’s name mangling algorithm, where the name of the class is mangled into the attribute name. This helps avoid attribute name collisions should subclasses inadvertently contain attributes with the same name. Note 1: Note that only the simple class name is used in the mangled name, so if a subclass chooses both the same class name and attribute name, you can still get name collisions. Note 2: Name mangling can make certain uses, such as debugging and , less convenient. However the name mangling algorithm is well documented and easy to perform manually. Note 3: Not everyone likes name mangling. Try to balance the need to avoid accidental name clashes with potential use by advanced callers. Any backwards compatibility guarantees apply only to public interfaces. Accordingly, it is important that users be able to clearly distinguish between public and internal interfaces. Documented interfaces are considered public, unless the documentation explicitly declares them to be provisional or internal interfaces exempt from the usual backwards compatibility guarantees. All undocumented interfaces should be assumed to be internal. To better support introspection, modules should explicitly declare the names in their public API using the attribute. Setting to an empty list indicates that the module has no public API. Even with set appropriately, internal interfaces (packages, modules, classes, functions, attributes or other names) should still be prefixed with a single leading underscore. An interface is also considered internal if any containing namespace (package, module or class) is considered internal. Imported names should always be considered an implementation detail. Other modules must not rely on indirect access to such imported names unless they are an explicitly documented part of the containing module’s API, such as or a package’s module that exposes functionality from submodules.\n• Code should be written in a way that does not disadvantage other implementations of Python (PyPy, Jython, IronPython, Cython, Psyco, and such). For example, do not rely on CPython’s efficient implementation of in-place string concatenation for statements in the form or . This optimization is fragile even in CPython (it only works for some types) and isn’t present at all in implementations that don’t use refcounting. In performance sensitive parts of the library, the form should be used instead. This will ensure that concatenation occurs in linear time across various implementations.\n• Comparisons to singletons like None should always be done with or , never the equality operators. Also, beware of writing when you really mean if x is not None – e.g. when testing whether a variable or argument that defaults to None was set to some other value. The other value might have a type (such as a container) that could be false in a boolean context!\n• Use operator rather than . While both expressions are functionally identical, the former is more readable and preferred:\n• When implementing ordering operations with rich comparisons, it is best to implement all six operations ( , , , , , ) rather than relying on other code to only exercise a particular comparison. To minimize the effort involved, the decorator provides a tool to generate missing comparison methods. PEP 207 indicates that reflexivity rules are assumed by Python. Thus, the interpreter may swap with , with , and may swap the arguments of and . The and operations are guaranteed to use the operator and the function uses the operator. However, it is best to implement all six operations so that confusion doesn’t arise in other contexts.\n• Always use a def statement instead of an assignment statement that binds a lambda expression directly to an identifier: The first form means that the name of the resulting function object is specifically ‘f’ instead of the generic ‘<lambda>’. This is more useful for tracebacks and string representations in general. The use of the assignment statement eliminates the sole benefit a lambda expression can offer over an explicit def statement (i.e. that it can be embedded inside a larger expression)\n• Derive exceptions from rather than . Direct inheritance from is reserved for exceptions where catching them is almost always the wrong thing to do. Design exception hierarchies based on the distinctions that code catching the exceptions is likely to need, rather than the locations where the exceptions are raised. Aim to answer the question “What went wrong?” programmatically, rather than only stating that “A problem occurred” (see PEP 3151 for an example of this lesson being learned for the builtin exception hierarchy) Class naming conventions apply here, although you should add the suffix “Error” to your exception classes if the exception is an error. Non-error exceptions that are used for non-local flow control or other forms of signaling need no special suffix.\n• Use exception chaining appropriately. should be used to indicate explicit replacement without losing the original traceback. When deliberately replacing an inner exception (using ), ensure that relevant details are transferred to the new exception (such as preserving the attribute name when converting KeyError to AttributeError, or embedding the text of the original exception in the new exception message).\n• When catching exceptions, mention specific exceptions whenever possible instead of using a bare clause: A bare clause will catch SystemExit and KeyboardInterrupt exceptions, making it harder to interrupt a program with Control-C, and can disguise other problems. If you want to catch all exceptions that signal program errors, use (bare except is equivalent to ). A good rule of thumb is to limit use of bare ‘except’ clauses to two cases:\n• If the exception handler will be printing out or logging the traceback; at least the user will be aware that an error has occurred.\n• If the code needs to do some cleanup work, but then lets the exception propagate upwards with . can be a better way to handle this case.\n• When catching operating system errors, prefer the explicit exception hierarchy introduced in Python 3.3 over introspection of values.\n• Additionally, for all try/except clauses, limit the clause to the absolute minimum amount of code necessary. Again, this avoids masking bugs: # Will also catch KeyError raised by handle_value()\n• When a resource is local to a particular section of code, use a statement to ensure it is cleaned up promptly and reliably after use. A try/finally statement is also acceptable.\n• Context managers should be invoked through separate functions or methods whenever they do something other than acquire and release resources: The latter example doesn’t provide any information to indicate that the and methods are doing something other than closing the connection after a transaction. Being explicit is important in this case.\n• Be consistent in return statements. Either all return statements in a function should return an expression, or none of them should. If any return statement returns an expression, any return statements where no value is returned should explicitly state this as , and an explicit return statement should be present at the end of the function (if reachable):\n• Use and instead of string slicing to check for prefixes or suffixes. startswith() and endswith() are cleaner and less error prone:\n• Object type comparisons should always use isinstance() instead of comparing types directly:\n• For sequences, (strings, lists, tuples), use the fact that empty sequences are false:\n• Don’t write string literals that rely on significant trailing whitespace. Such trailing whitespace is visually indistinguishable and some editors (or more recently, reindent.py) will trim them.\n• Don’t compare boolean values to True or False using :\n• Use of the flow control statements / / within the finally suite of a , where the flow control statement would jump outside the finally suite, is discouraged. This is because such statements will implicitly cancel any active exception that is propagating through the finally suite: With the acceptance of PEP 484, the style rules for function annotations have changed.\n• Function annotations should use PEP 484 syntax (there are some formatting recommendations for annotations in the previous section).\n• The experimentation with annotation styles that was recommended previously in this PEP is no longer encouraged.\n• However, outside the stdlib, experiments within the rules of PEP 484 are now encouraged. For example, marking up a large third party library or application with PEP 484 style type annotations, reviewing how easy it was to add those annotations, and observing whether their presence increases code understandability.\n• The Python standard library should be conservative in adopting such annotations, but their use is allowed for new code and for big refactorings.\n• For code that wants to make a different use of function annotations it is recommended to put a comment of the form: near the top of the file; this tells type checkers to ignore all annotations. (More fine-grained ways of disabling complaints from type checkers can be found in PEP 484.)\n• Like linters, type checkers are optional, separate tools. Python interpreters by default should not issue any messages due to type checking and should not alter their behavior based on annotations.\n• Users who don’t want to use type checkers are free to ignore them. However, it is expected that users of third party library packages may want to run type checkers over those packages. For this purpose PEP 484 recommends the use of stub files: .pyi files that are read by the type checker in preference of the corresponding .py files. Stub files can be distributed with a library, or separately (with the library author’s permission) through the typeshed repo . PEP 526 introduced variable annotations. The style recommendations for them are similar to those on function annotations described above:\n• Annotations for module level variables, class and instance variables, and local variables should have a single space after the colon.\n• There should be no space before the colon.\n• If an assignment has a right hand side, then the equality sign should have exactly one space on both sides:\n• Although the PEP 526 is accepted for Python 3.6, the variable annotation syntax is the preferred syntax for stub files on all versions of Python (see PEP 484 for details)."
    },
    {
        "link": "https://w3schools.com/python/ref_func_all.asp",
        "document": "W3Schools offers a wide range of services and products for beginners and professionals, helping millions of people everyday to learn and master new skills."
    },
    {
        "link": "https://stackoverflow.com/questions/19070299/python-regex-match-exact-word",
        "document": "I am trying to match different expressions for addresses:\n\nI would like to match W. or E. (east) or Pl. for place ...etc\n\nIt is very simple using this regex\n\nYet python re module doesn't match anything when I input that"
    },
    {
        "link": "https://stackoverflow.com/questions/45244813/how-can-i-make-a-regex-match-the-entire-string",
        "document": "Suppose I have a string like . I want to test whether it matches a pattern like , where means one or more digit symbols.\n\nHow can I make it so that only the matches, and the doesn't? I tried using instead of but it didn't help."
    },
    {
        "link": "https://askpython.com/python/examples/matching-strings-using-regular-expressions",
        "document": "Regular expressions, also known as regex, are an incredibly powerful tool for searching and manipulating text. Python’s regex library, re, makes it easy to match exact strings and perform other types of text processing tasks. In this article, we will explore how to use the re library to match exact strings in Python, with good implementation examples.\n\nRegular expressions, often abbreviated as “regex,” are a powerful tool used in computer programming, text processing, and data validation to match, search, and manipulate text patterns. In essence, a regular expression is a sequence of characters that define a search pattern.\n\nThis pattern can be used to match a specific string, a set of strings that share a common format or structure, or even to identify and extract certain pieces of data from a larger dataset.\n\nThe syntax of regular expressions varies depending on the implementation and the specific task at hand, but it generally involves using a combination of characters and metacharacters that have special meanings when used in a certain way. Before starting with the Python regex module let’s see how to actually write regex using metacharacters or special sequences.\n\nSome of the common metacharacters used in regular expressions are:\n\nSpecial sequences do not match for the actual character in the string instead it tells the specific location in the search string where the match must occur. It makes it easier to write commonly used patterns.\n\nThe module in Python is an alternative regular expression engine that supports several advanced features, such as recursive patterns, atomic groups, and lookbehind assertions with variable-length patterns. To install the module, you can use , the Python package manager. Open a command prompt or terminal and enter the following command:\n\nFor detailed information about the module read: Official Documentation\n\nHow to match the entire string in a regular expression?\n\nLet’s get right into the different Python methods we can use to match strings using regular expressions.\n\nThe method searches the given string for a match to the specified regular expression pattern. To match an exact string, you can simply pass the string as the pattern. For example:\n\nThe method works like , but only matches the pattern at the beginning of the string. To match an exact string, you can use the and anchors to match the start and end of the string. For example:\n\nThe method matches the entire string against the pattern. To match an exact string, you can use the and anchors as with . For example:\n\nThe method finds all non-overlapping matches of the pattern in the string, and returns them as a list. To match an exact string, you can use the grouping operator to create a capturing group around the string, and then use a backreference to match the exact same string again. For example we have a text file given below:\n\nWe can read this file into a string variable using Python’s built-in and functions, and then use regular expressions to search for specific patterns of text within the file:\n\nIn this example, we first open the file using the function, read its contents using the method, and assign it to the variable. We then use the function to search for all non-overlapping occurrences of the word “text” in the string, using the regular expression pattern which matches the word “text” when it appears as a standalone word surrounded by word boundaries. Finally, we print the list of matches to the console.\n\nAlso read: How To Extract Emails From a Text File Using regex in Python\n\ncan be used to access the values of the Pandas series as strings and apply several methods to it. Pandas function is used to extract capture groups in the regex pat as columns in a DataFrame. To show the example first let’s create a dataframe:\n\nThe article explains regular expressions in Python and their usage to match and manipulate text strings. It covers the syntax and metacharacters used in regular expressions, and demonstrates how to use the module to perform various operations on strings, such as searching, replacing, and splitting."
    },
    {
        "link": "https://docs.python.org/3/howto/regex.html",
        "document": "Regular expressions (called REs, or regexes, or regex patterns) are essentially a tiny, highly specialized programming language embedded inside Python and made available through the module. Using this little language, you specify the rules for the set of possible strings that you want to match; this set might contain English sentences, or e-mail addresses, or TeX commands, or anything you like. You can then ask questions such as “Does this string match the pattern?”, or “Is there a match for the pattern anywhere in this string?”. You can also use REs to modify a string or to split it apart in various ways. Regular expression patterns are compiled into a series of bytecodes which are then executed by a matching engine written in C. For advanced use, it may be necessary to pay careful attention to how the engine will execute a given RE, and write the RE in a certain way in order to produce bytecode that runs faster. Optimization isn’t covered in this document, because it requires that you have a good understanding of the matching engine’s internals. The regular expression language is relatively small and restricted, so not all possible string processing tasks can be done using regular expressions. There are also tasks that can be done with regular expressions, but the expressions turn out to be very complicated. In these cases, you may be better off writing Python code to do the processing; while Python code will be slower than an elaborate regular expression, it will also probably be more understandable.\n\nWe’ll start by learning about the simplest possible regular expressions. Since regular expressions are used to operate on strings, we’ll begin with the most common task: matching characters. For a detailed explanation of the computer science underlying regular expressions (deterministic and non-deterministic finite automata), you can refer to almost any textbook on writing compilers. Most letters and characters will simply match themselves. For example, the regular expression will match the string exactly. (You can enable a case-insensitive mode that would let this RE match or as well; more about this later.) There are exceptions to this rule; some characters are special metacharacters, and don’t match themselves. Instead, they signal that some out-of-the-ordinary thing should be matched, or they affect other portions of the RE by repeating them or changing their meaning. Much of this document is devoted to discussing various metacharacters and what they do. Here’s a complete list of the metacharacters; their meanings will be discussed in the rest of this HOWTO. The first metacharacters we’ll look at are and . They’re used for specifying a character class, which is a set of characters that you wish to match. Characters can be listed individually, or a range of characters can be indicated by giving two characters and separating them by a . For example, will match any of the characters , , or ; this is the same as , which uses a range to express the same set of characters. If you wanted to match only lowercase letters, your RE would be . Metacharacters (except ) are not active inside classes. For example, will match any of the characters , , , or ; is usually a metacharacter, but inside a character class it’s stripped of its special nature. You can match the characters not listed within the class by complementing the set. This is indicated by including a as the first character of the class. For example, will match any character except . If the caret appears elsewhere in a character class, it does not have special meaning. For example: will match either a or a . Perhaps the most important metacharacter is the backslash, . As in Python string literals, the backslash can be followed by various characters to signal various special sequences. It’s also used to escape all the metacharacters so you can still match them in patterns; for example, if you need to match a or , you can precede them with a backslash to remove their special meaning: or . Some of the special sequences beginning with represent predefined sets of characters that are often useful, such as the set of digits, the set of letters, or the set of anything that isn’t whitespace. Let’s take an example: matches any alphanumeric character. If the regex pattern is expressed in bytes, this is equivalent to the class . If the regex pattern is a string, will match all the characters marked as letters in the Unicode database provided by the module. You can use the more restricted definition of in a string pattern by supplying the flag when compiling the regular expression. The following list of special sequences isn’t complete. For a complete list of sequences and expanded class definitions for Unicode string patterns, see the last part of Regular Expression Syntax in the Standard Library reference. In general, the Unicode versions match any character that’s in the appropriate category in the Unicode database. Matches any decimal digit; this is equivalent to the class . Matches any non-digit character; this is equivalent to the class . Matches any whitespace character; this is equivalent to the class . Matches any non-whitespace character; this is equivalent to the class . Matches any alphanumeric character; this is equivalent to the class . Matches any non-alphanumeric character; this is equivalent to the class . These sequences can be included inside a character class. For example, is a character class that will match any whitespace character, or or . The final metacharacter in this section is . It matches anything except a newline character, and there’s an alternate mode ( ) where it will match even a newline. is often used where you want to match “any character”. Being able to match varying sets of characters is the first thing regular expressions can do that isn’t already possible with the methods available on strings. However, if that was the only additional capability of regexes, they wouldn’t be much of an advance. Another capability is that you can specify that portions of the RE must be repeated a certain number of times. The first metacharacter for repeating things that we’ll look at is . doesn’t match the literal character ; instead, it specifies that the previous character can be matched zero or more times, instead of exactly once. For example, will match (0 characters), (1 ), (3 characters), and so forth. Repetitions such as are greedy; when repeating a RE, the matching engine will try to repeat it as many times as possible. If later portions of the pattern don’t match, the matching engine will then back up and try again with fewer repetitions. A step-by-step example will make this more obvious. Let’s consider the expression . This matches the letter , zero or more letters from the class , and finally ends with a . Now imagine matching this RE against the string . The engine matches , going as far as it can, which is to the end of the string. The engine tries to match , but the current position is at the end of the string, so it fails. Back up, so that matches one less character. Try again, but the current position is at the last character, which is a . Back up again, so that is only matching . Try again. This time the character at the current position is , so it succeeds. The end of the RE has now been reached, and it has matched . This demonstrates how the matching engine goes as far as it can at first, and if no match is found it will then progressively back up and retry the rest of the RE again and again. It will back up until it has tried zero matches for , and if that subsequently fails, the engine will conclude that the string doesn’t match the RE at all. Another repeating metacharacter is , which matches one or more times. Pay careful attention to the difference between and ; matches zero or more times, so whatever’s being repeated may not be present at all, while requires at least one occurrence. To use a similar example, will match (1 ), (3 s), but won’t match . There are two more repeating operators or quantifiers. The question mark character, , matches either once or zero times; you can think of it as marking something as being optional. For example, matches either or . The most complicated quantifier is , where m and n are decimal integers. This quantifier means there must be at least m repetitions, and at most n. For example, will match , , and . It won’t match , which has no slashes, or , which has four. You can omit either m or n; in that case, a reasonable value is assumed for the missing value. Omitting m is interpreted as a lower limit of 0, while omitting n results in an upper bound of infinity. The simplest case matches the preceding item exactly m times. For example, will only match . Readers of a reductionist bent may notice that the three other quantifiers can all be expressed using this notation. is the same as , is equivalent to , and is the same as . It’s better to use , , or when you can, simply because they’re shorter and easier to read.\n\nNow that we’ve looked at some simple regular expressions, how do we actually use them in Python? The module provides an interface to the regular expression engine, allowing you to compile REs into objects and then perform matches with them. Regular expressions are compiled into pattern objects, which have methods for various operations such as searching for pattern matches or performing string substitutions. also accepts an optional flags argument, used to enable various special features and syntax variations. We’ll go over the available settings later, but for now a single example will do: The RE is passed to as a string. REs are handled as strings because regular expressions aren’t part of the core Python language, and no special syntax was created for expressing them. (There are applications that don’t need REs at all, so there’s no need to bloat the language specification by including them.) Instead, the module is simply a C extension module included with Python, just like the or modules. Putting REs in strings keeps the Python language simpler, but has one disadvantage which is the topic of the next section. As stated earlier, regular expressions use the backslash character ( ) to indicate special forms or to allow special characters to be used without invoking their special meaning. This conflicts with Python’s usage of the same character for the same purpose in string literals. Let’s say you want to write a RE that matches the string , which might be found in a LaTeX file. To figure out what to write in the program code, start with the desired string to be matched. Next, you must escape any backslashes and other metacharacters by preceding them with a backslash, resulting in the string . The resulting string that must be passed to must be . However, to express this as a Python string literal, both backslashes must be escaped again. In short, to match a literal backslash, one has to write as the RE string, because the regular expression must be , and each backslash must be expressed as inside a regular Python string literal. In REs that feature backslashes repeatedly, this leads to lots of repeated backslashes and makes the resulting strings difficult to understand. The solution is to use Python’s raw string notation for regular expressions; backslashes are not handled in any special way in a string literal prefixed with , so is a two-character string containing and , while is a one-character string containing a newline. Regular expressions will often be written in Python code using this raw string notation. In addition, special escape sequences that are valid in regular expressions, but not valid as Python string literals, now result in a and will eventually become a , which means the sequences will be invalid if raw string notation or escaping the backslashes isn’t used. Once you have an object representing a compiled regular expression, what do you do with it? Pattern objects have several methods and attributes. Only the most significant ones will be covered here; consult the docs for a complete listing. Determine if the RE matches at the beginning of the string. Scan through a string, looking for any location where this RE matches. Find all substrings where the RE matches, and returns them as a list. Find all substrings where the RE matches, and returns them as an iterator. and return if no match can be found. If they’re successful, a match object instance is returned, containing information about the match: where it starts and ends, the substring it matched, and more. You can learn about this by interactively experimenting with the module. This HOWTO uses the standard Python interpreter for its examples. First, run the Python interpreter, import the module, and compile a RE: Now, you can try matching various strings against the RE . An empty string shouldn’t match at all, since means ‘one or more repetitions’. should return in this case, which will cause the interpreter to print no output. You can explicitly print the result of to make this clear. Now, let’s try it on a string that it should match, such as . In this case, will return a match object, so you should store the result in a variable for later use. Now you can query the match object for information about the matching string. Match object instances also have several methods and attributes; the most important ones are: Return the string matched by the RE Return the starting position of the match Return the ending position of the match Return a tuple containing the (start, end) positions of the match Trying these methods will soon clarify their meaning: returns the substring that was matched by the RE. and return the starting and ending index of the match. returns both start and end indexes in a single tuple. Since the method only checks if the RE matches at the start of a string, will always be zero. However, the method of patterns scans through the string, so the match may not start at zero in that case. In actual programs, the most common style is to store the match object in a variable, and then check if it was . This usually looks like: Two pattern methods return all of the matches for a pattern. returns a list of matching strings: The prefix, making the literal a raw string literal, is needed in this example because escape sequences in a normal “cooked” string literal that are not recognized by Python, as opposed to regular expressions, now result in a and will eventually become a . See The Backslash Plague. has to create the entire list before it can be returned as the result. The method returns a sequence of match object instances as an iterator: You don’t have to create a pattern object and call its methods; the module also provides top-level functions called , , , , and so forth. These functions take the same arguments as the corresponding pattern method with the RE string added as the first argument, and still return either or a match object instance. Under the hood, these functions simply create a pattern object for you and call the appropriate method on it. They also store the compiled object in a cache, so future calls using the same RE won’t need to parse the pattern again and again. Should you use these module-level functions, or should you get the pattern and call its methods yourself? If you’re accessing a regex within a loop, pre-compiling it will save a few function calls. Outside of loops, there’s not much difference thanks to the internal cache. Compilation flags let you modify some aspects of how regular expressions work. Flags are available in the module under two names, a long name such as and a short, one-letter form such as . (If you’re familiar with Perl’s pattern modifiers, the one-letter forms use the same letters; the short form of is , for example.) Multiple flags can be specified by bitwise OR-ing them; sets both the and flags, for example. Here’s a table of the available flags, followed by a more detailed explanation of each one. Makes several escapes like , , and match only on ASCII characters with the respective property. Enable verbose REs, which can be organized more cleanly and understandably. Perform case-insensitive matching; character class and literal strings will match letters by ignoring case. For example, will match lowercase letters, too. Full Unicode matching also works unless the flag is used to disable non-ASCII matches. When the Unicode patterns or are used in combination with the flag, they will match the 52 ASCII letters and 4 additional non-ASCII letters: ‘İ’ (U+0130, Latin capital letter I with dot above), ‘ı’ (U+0131, Latin small letter dotless i), ‘ſ’ (U+017F, Latin small letter long s) and ‘K’ (U+212A, Kelvin sign). will match , , , or (the latter is matched only in Unicode mode). This lowercasing doesn’t take the current locale into account; it will if you also set the flag. Make , , , and case-insensitive matching dependent on the current locale instead of the Unicode database. Locales are a feature of the C library intended to help in writing programs that take account of language differences. For example, if you’re processing encoded French text, you’d want to be able to write to match words, but only matches the character class in bytes patterns; it won’t match bytes corresponding to or . If your system is configured properly and a French locale is selected, certain C functions will tell the program that the byte corresponding to should also be considered a letter. Setting the flag when compiling a regular expression will cause the resulting compiled object to use these C functions for ; this is slower, but also enables to match French words as you’d expect. The use of this flag is discouraged in Python 3 as the locale mechanism is very unreliable, it only handles one “culture” at a time, and it only works with 8-bit locales. Unicode matching is already enabled by default in Python 3 for Unicode (str) patterns, and it is able to handle different locales/languages. Usually matches only at the beginning of the string, and matches only at the end of the string and immediately before the newline (if any) at the end of the string. When this flag is specified, matches at the beginning of the string and at the beginning of each line within the string, immediately following each newline. Similarly, the metacharacter matches either at the end of the string and at the end of each line (immediately preceding each newline). Makes the special character match any character at all, including a newline; without this flag, will match anything except a newline. Make , , , , and perform ASCII-only matching instead of full Unicode matching. This is only meaningful for Unicode patterns, and is ignored for byte patterns. This flag allows you to write regular expressions that are more readable by granting you more flexibility in how you can format them. When this flag has been specified, whitespace within the RE string is ignored, except when the whitespace is in a character class or preceded by an unescaped backslash; this lets you organize and indent the RE more clearly. This flag also lets you put comments within a RE that will be ignored by the engine; comments are marked by a that’s neither in a character class or preceded by an unescaped backslash. For example, here’s a RE that uses ; see how much easier it is to read? Without the verbose setting, the RE would look like this: In the above example, Python’s automatic concatenation of string literals has been used to break up the RE into smaller pieces, but it’s still more difficult to understand than the version using .\n\nSo far we’ve only covered a part of the features of regular expressions. In this section, we’ll cover some new metacharacters, and how to use groups to retrieve portions of the text that was matched. There are some metacharacters that we haven’t covered yet. Most of them will be covered in this section. Some of the remaining metacharacters to be discussed are zero-width assertions. They don’t cause the engine to advance through the string; instead, they consume no characters at all, and simply succeed or fail. For example, is an assertion that the current position is located at a word boundary; the position isn’t changed by the at all. This means that zero-width assertions should never be repeated, because if they match once at a given location, they can obviously be matched an infinite number of times. Alternation, or the “or” operator. If A and B are regular expressions, will match any string that matches either A or B. has very low precedence in order to make it work reasonably when you’re alternating multi-character strings. will match either or , not , a or an , and . To match a literal , use , or enclose it inside a character class, as in . Matches at the beginning of lines. Unless the flag has been set, this will only match at the beginning of the string. In mode, this also matches immediately after each newline within the string. For example, if you wish to match the word only at the beginning of a line, the RE to use is . Matches at the end of a line, which is defined as either the end of the string, or any location followed by a newline character. To match a literal , use or enclose it inside a character class, as in . Matches only at the start of the string. When not in mode, and are effectively the same. In mode, they’re different: still matches only at the beginning of the string, but may match at any location inside the string that follows a newline character. Matches only at the end of the string. Word boundary. This is a zero-width assertion that matches only at the beginning or end of a word. A word is defined as a sequence of alphanumeric characters, so the end of a word is indicated by whitespace or a non-alphanumeric character. The following example matches only when it’s a complete word; it won’t match when it’s contained inside another word. There are two subtleties you should remember when using this special sequence. First, this is the worst collision between Python’s string literals and regular expression sequences. In Python’s string literals, is the backspace character, ASCII value 8. If you’re not using raw strings, then Python will convert the to a backspace, and your RE won’t match as you expect it to. The following example looks the same as our previous RE, but omits the in front of the RE string. Second, inside a character class, where there’s no use for this assertion, represents the backspace character, for compatibility with Python’s string literals. Another zero-width assertion, this is the opposite of , only matching when the current position is not at a word boundary. Frequently you need to obtain more information than just whether the RE matched or not. Regular expressions are often used to dissect strings by writing a RE divided into several subgroups which match different components of interest. For example, an RFC-822 header line is divided into a header name and a value, separated by a , like this: This can be handled by writing a regular expression which matches an entire header line, and has one group which matches the header name, and another group which matches the header’s value. Groups are marked by the , metacharacters. and have much the same meaning as they do in mathematical expressions; they group together the expressions contained inside them, and you can repeat the contents of a group with a quantifier, such as , , , or . For example, will match zero or more repetitions of . Groups indicated with , also capture the starting and ending index of the text that they match; this can be retrieved by passing an argument to , , , and . Groups are numbered starting with 0. Group 0 is always present; it’s the whole RE, so match object methods all have group 0 as their default argument. Later we’ll see how to express groups that don’t capture the span of text that they match. Subgroups are numbered from left to right, from 1 upward. Groups can be nested; to determine the number, just count the opening parenthesis characters, going from left to right. can be passed multiple group numbers at a time, in which case it will return a tuple containing the corresponding values for those groups. The method returns a tuple containing the strings for all the subgroups, from 1 up to however many there are. Backreferences in a pattern allow you to specify that the contents of an earlier capturing group must also be found at the current location in the string. For example, will succeed if the exact contents of group 1 can be found at the current position, and fails otherwise. Remember that Python’s string literals also use a backslash followed by numbers to allow including arbitrary characters in a string, so be sure to use a raw string when incorporating backreferences in a RE. For example, the following RE detects doubled words in a string. 'Paris in the the spring' Backreferences like this aren’t often useful for just searching through a string — there are few text formats which repeat data in this way — but you’ll soon find out that they’re very useful when performing string substitutions. Elaborate REs may use many groups, both to capture substrings of interest, and to group and structure the RE itself. In complex REs, it becomes difficult to keep track of the group numbers. There are two features which help with this problem. Both of them use a common syntax for regular expression extensions, so we’ll look at that first. Perl 5 is well known for its powerful additions to standard regular expressions. For these new features the Perl developers couldn’t choose new single-keystroke metacharacters or new special sequences beginning with without making Perl’s regular expressions confusingly different from standard REs. If they chose as a new metacharacter, for example, old expressions would be assuming that was a regular character and wouldn’t have escaped it by writing or . The solution chosen by the Perl developers was to use as the extension syntax. immediately after a parenthesis was a syntax error because the would have nothing to repeat, so this didn’t introduce any compatibility problems. The characters immediately after the indicate what extension is being used, so is one thing (a positive lookahead assertion) and is something else (a non-capturing group containing the subexpression ). Python supports several of Perl’s extensions and adds an extension syntax to Perl’s extension syntax. If the first character after the question mark is a , you know that it’s an extension that’s specific to Python. Now that we’ve looked at the general extension syntax, we can return to the features that simplify working with groups in complex REs. Sometimes you’ll want to use a group to denote a part of a regular expression, but aren’t interested in retrieving the group’s contents. You can make this fact explicit by using a non-capturing group: , where you can replace the with any other regular expression. Except for the fact that you can’t retrieve the contents of what the group matched, a non-capturing group behaves exactly the same as a capturing group; you can put anything inside it, repeat it with a repetition metacharacter such as , and nest it within other groups (capturing or non-capturing). is particularly useful when modifying an existing pattern, since you can add new groups without changing how all the other groups are numbered. It should be mentioned that there’s no performance difference in searching between capturing and non-capturing groups; neither form is any faster than the other. A more significant feature is named groups: instead of referring to them by numbers, groups can be referenced by a name. The syntax for a named group is one of the Python-specific extensions: . name is, obviously, the name of the group. Named groups behave exactly like capturing groups, and additionally associate a name with a group. The match object methods that deal with capturing groups all accept either integers that refer to the group by number or strings that contain the desired group’s name. Named groups are still given numbers, so you can retrieve information about a group in two ways: Additionally, you can retrieve named groups as a dictionary with : Named groups are handy because they let you use easily remembered names, instead of having to remember numbers. Here’s an example RE from the module: It’s obviously much easier to retrieve , instead of having to remember to retrieve group 9. The syntax for backreferences in an expression such as refers to the number of the group. There’s naturally a variant that uses the group name instead of the number. This is another Python extension: indicates that the contents of the group called name should again be matched at the current point. The regular expression for finding doubled words, can also be written as : 'Paris in the the spring' Another zero-width assertion is the lookahead assertion. Lookahead assertions are available in both positive and negative form, and look like this: Positive lookahead assertion. This succeeds if the contained regular expression, represented here by , successfully matches at the current location, and fails otherwise. But, once the contained expression has been tried, the matching engine doesn’t advance at all; the rest of the pattern is tried right where the assertion started. Negative lookahead assertion. This is the opposite of the positive assertion; it succeeds if the contained expression doesn’t match at the current position in the string. To make this concrete, let’s look at a case where a lookahead is useful. Consider a simple pattern to match a filename and split it apart into a base name and an extension, separated by a . For example, in , is the base name, and is the filename’s extension. The pattern to match this is quite simple: Notice that the needs to be treated specially because it’s a metacharacter, so it’s inside a character class to only match that specific character. Also notice the trailing ; this is added to ensure that all the rest of the string must be included in the extension. This regular expression matches and and and . Now, consider complicating the problem a bit; what if you want to match filenames where the extension is not ? Some incorrect attempts: The first attempt above tries to exclude by requiring that the first character of the extension is not a . This is wrong, because the pattern also doesn’t match . The expression gets messier when you try to patch up the first solution by requiring one of the following cases to match: the first character of the extension isn’t ; the second character isn’t ; or the third character isn’t . This accepts and rejects , but it requires a three-letter extension and won’t accept a filename with a two-letter extension such as . We’ll complicate the pattern again in an effort to fix it. In the third attempt, the second and third letters are all made optional in order to allow matching extensions shorter than three characters, such as . The pattern’s getting really complicated now, which makes it hard to read and understand. Worse, if the problem changes and you want to exclude both and as extensions, the pattern would get even more complicated and confusing. A negative lookahead cuts through all this confusion: The negative lookahead means: if the expression doesn’t match at this point, try the rest of the pattern; if does match, the whole pattern will fail. The trailing is required to ensure that something like , where the extension only starts with , will be allowed. The makes sure that the pattern works when there are multiple dots in the filename. Excluding another filename extension is now easy; simply add it as an alternative inside the assertion. The following pattern excludes filenames that end in either or :\n\nUp to this point, we’ve simply performed searches against a static string. Regular expressions are also commonly used to modify strings in various ways, using the following pattern methods: Split the string into a list, splitting it wherever the RE matches Find all substrings where the RE matches, and replace them with a different string Does the same thing as , but returns the new string and the number of replacements The method of a pattern splits a string apart wherever the RE matches, returning a list of the pieces. It’s similar to the method of strings but provides much more generality in the delimiters that you can split by; string only supports splitting by whitespace or by a fixed string. As you’d expect, there’s a module-level function, too. Split string by the matches of the regular expression. If capturing parentheses are used in the RE, then their contents will also be returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits are performed. You can limit the number of splits made, by passing a value for maxsplit. When maxsplit is nonzero, at most maxsplit splits will be made, and the remainder of the string is returned as the final element of the list. In the following example, the delimiter is any sequence of non-alphanumeric characters. 'This is a test, short and sweet, of split().' ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', ''] 'This is a test, short and sweet, of split().' ['This', 'is', 'a', 'test, short and sweet, of split().'] Sometimes you’re not only interested in what the text between delimiters is, but also need to know what the delimiter was. If capturing parentheses are used in the RE, then their values are also returned as part of the list. Compare the following calls: The module-level function adds the RE to be used as the first argument, but is otherwise the same. Another common task is to find all the matches for a pattern, and replace them with a different string. The method takes a replacement value, which can be either a string or a function, and the string to be processed. Returns the string obtained by replacing the leftmost non-overlapping occurrences of the RE in string by the replacement replacement. If the pattern isn’t found, string is returned unchanged. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a non-negative integer. The default value of 0 means to replace all occurrences. Here’s a simple example of using the method. It replaces colour names with the word : The method does the same work, but returns a 2-tuple containing the new string value and the number of replacements that were performed: Empty matches are replaced only when they’re not adjacent to a previous empty match. If replacement is a string, any backslash escapes in it are processed. That is, is converted to a single newline character, is converted to a carriage return, and so forth. Unknown escapes such as are left alone. Backreferences, such as , are replaced with the substring matched by the corresponding group in the RE. This lets you incorporate portions of the original text in the resulting replacement string. This example matches the word followed by a string enclosed in , , and changes to : There’s also a syntax for referring to named groups as defined by the syntax. will use the substring matched by the group named , and uses the corresponding group number. is therefore equivalent to , but isn’t ambiguous in a replacement string such as . ( would be interpreted as a reference to group 20, not a reference to group 2 followed by the literal character .) The following substitutions are all equivalent, but use all three variations of the replacement string. replacement can also be a function, which gives you even more control. If replacement is a function, the function is called for every non-overlapping occurrence of pattern. On each call, the function is passed a match object argument for the match and can use this information to compute the desired replacement string and return it. In the following example, the replacement function translates decimals into hexadecimal: When using the module-level function, the pattern is passed as the first argument. The pattern may be provided as an object or as a string; if you need to specify regular expression flags, you must either use a pattern object as the first parameter, or use embedded modifiers in the pattern string, e.g. returns .\n\nRegular expressions are a powerful tool for some applications, but in some ways their behaviour isn’t intuitive and at times they don’t behave the way you may expect them to. This section will point out some of the most common pitfalls. Sometimes using the module is a mistake. If you’re matching a fixed string, or a single character class, and you’re not using any features such as the flag, then the full power of regular expressions may not be required. Strings have several methods for performing operations with fixed strings and they’re usually much faster, because the implementation is a single small C loop that’s been optimized for the purpose, instead of the large, more generalized regular expression engine. One example might be replacing a single fixed string with another one; for example, you might replace with . seems like the function to use for this, but consider the method. Note that will also replace inside words, turning into , but the naive RE would have done that, too. (To avoid performing the substitution on parts of words, the pattern would have to be , in order to require that have a word boundary on either side. This takes the job beyond ’s abilities.) Another common task is deleting every occurrence of a single character from a string or replacing it with another single character. You might do this with something like , but is capable of doing both tasks and will be faster than any regular expression operation can be. In short, before turning to the module, consider whether your problem can be solved with a faster and simpler string method. The function only checks if the RE matches at the beginning of the string while will scan forward through the string for a match. It’s important to keep this distinction in mind. Remember, will only report a successful match which will start at 0; if the match wouldn’t start at zero, will not report it. On the other hand, will scan forward through the string, reporting the first match it finds. Sometimes you’ll be tempted to keep using , and just add to the front of your RE. Resist this temptation and use instead. The regular expression compiler does some analysis of REs in order to speed up the process of looking for a match. One such analysis figures out what the first character of a match must be; for example, a pattern starting with must match starting with a . The analysis lets the engine quickly scan through the string looking for the starting character, only trying the full match if a is found. Adding defeats this optimization, requiring scanning to the end of the string and then backtracking to find a match for the rest of the RE. Use instead. When repeating a regular expression, as in , the resulting action is to consume as much of the pattern as possible. This fact often bites you when you’re trying to match a pair of balanced delimiters, such as the angle brackets surrounding an HTML tag. The naive pattern for matching a single HTML tag doesn’t work because of the greedy nature of . The RE matches the in , and the consumes the rest of the string. There’s still more left in the RE, though, and the can’t match at the end of the string, so the regular expression engine has to backtrack character by character until it finds a match for the . The final match extends from the in to the in , which isn’t what you want. In this case, the solution is to use the non-greedy quantifiers , , , or , which match as little text as possible. In the above example, the is tried immediately after the first matches, and when it fails, the engine advances a character at a time, retrying the at every step. This produces just the right result: By now you’ve probably noticed that regular expressions are a very compact notation, but they’re not terribly readable. REs of moderate complexity can become lengthy collections of backslashes, parentheses, and metacharacters, making them difficult to read and understand. For such REs, specifying the flag when compiling the regular expression can be helpful, because it allows you to format the regular expression more clearly. The flag has several effects. Whitespace in the regular expression that isn’t inside a character class is ignored. This means that an expression such as is equivalent to the less readable , but will still match the characters , , or a space. In addition, you can also put comments inside a RE; comments extend from a character to the next newline. When used with triple-quoted strings, this enables REs to be formatted more neatly: (?P<value>.*?) # The header's value -- *? used to This is far more readable than:"
    },
    {
        "link": "https://python-forum.io/thread-28582.html",
        "document": "The first line of code is supposed to find string A180, and shift down 9 rows and grab that value. My problem is, is that I also have A180X inside this file, so It's not grabbing the correct information cause its also finding A180X. \n\n \n\n The second Line I figured if I used ==String it would find the exact match and it does. My problem is, is when I add shift(9) I get an error 'str' object has no attribute 'shift'. Does anyone know how I can find the exact match but still use shift?\n\n \n\n Hello,The first line of code is supposed to find string A180, and shift down 9 rows and grab that value. My problem is, is that I also have A180X inside this file, so It's not grabbing the correct information cause its also finding A180X.The second Line I figured if I used ==String it would find the exact match and it does. My problem is, is when I add shift(9) I get an error 'str' object has no attribute 'shift'. Does anyone know how I can find the exact match but still use shift? \n\n In regex can use for a exact word match.\n\n Bye working code i mean this.\n\n Usage.\n\n Should tell that you use Pandas not all is familiar with the syntax,and if give a working code example is easier to help.In regex can usefor a exact word match.Bye working code i mean this.Usage. Should tell that you use Pandas not all is familiar with the syntax,and if give a working code example is easier to help.\n\n In regex can use for a exact word match.\n\n Bye working code i mean this.\n\n Usage.\n\n \n\n Hello,\n\n \n\n using (r'\\bA180\\b') only works if you put the actual word between \\b and \\b, I wouldn't be able to use that because my string is constantly changing throughout the loop. That's why I have .str.match(String). It might be A180 for the first loop, and then second loop around it might me A180X, next A170.\n\n Should tell that you use Pandas not all is familiar with the syntax,and if give a working code example is easier to help.\n\n In regex can use for a exact word match.\n\n Bye working code i mean this.\n\n Usage.\n\n \n\n Hello,\n\n \n\n using (r'\\bA180\\b') only works if you put the actual word between \\b and \\b, I wouldn't be able to use that because my string is constantly changing throughout the loop. That's why I have .str.match(String). It might be A180 for the first loop, and then second loop around it might me A180X, next A170. I have to many files to loop through to try and define each string individually. Hello,using (r'\\bA180\\b') only works if you put the actual word between \\b and \\b, I wouldn't be able to use that because my string is constantly changing throughout the loop. That's why I have .str.match(String). It might be A180 for the first loop, and then second loop around it might me A180X, next A170."
    }
]