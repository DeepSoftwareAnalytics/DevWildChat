[
    {
        "link": "https://stackoverflow.com/questions/22842289/generate-n-unique-random-numbers-within-a-range",
        "document": "I know how to generate a random number within a range in Python.\n\nAnd I know I can put this in a loop to generate n amount of these numbers\n\nHowever, I need to make sure each number in that list is unique. Other than a load of conditional statements, is there a straightforward way of generating n number of unique random numbers?\n\nThe important thing is that each number in the list is different to the others..\n\n[12, 5, 5, 1] = bad, because the number 5 occurs twice."
    },
    {
        "link": "https://stackoverflow.com/questions/40792345/generating-random-numbers-in-a-specific-range",
        "document": "Perhaps the easiest way to solve your problem is to think in terms of integers, not floating-point numbers.\n\nYou basically want possible random numbers like 0.01, 0.02, 0.03, ..., 0.09, 0.10.\n\nFirst you generate an integer between 1 to 10 inclusive, then you divide by 100.0 to get a floating-point number.\n\nHere is the code:"
    },
    {
        "link": "https://geeksforgeeks.org/generating-random-number-list-in-python",
        "document": "In Python, we often need to generate a list of random numbers for tasks such as simulations, testing etc. Python’s random module provides multiple ways to generate random numbers. For example, we might want to create a list of 5 random numbers ranging from 1 to 100. This article explores different methods to generate a random number list in Python.\n\nrandom.sample() method is ideal for generating a list of unique random numbers.\n• None random.sample() selects n unique random numbers from the specified range.\n• None It ensures that there are no duplicate values in the output.\n• None This method is efficient and concise when uniqueness is required.\n\nLet’s explore some more ways and see how we can generate random number list in Python.\n\nrandom.randint() function can be used in a list comprehension to generate random numbers, including duplicates.\n• None random.randint(1, 100) generates a random number in the range 1 to 100 (inclusive).\n• None The list comprehension runs the function n times to create the list.\n\nrandom.choices() function generates a list of random numbers, allowing duplicates and providing more control over probabilities.\n• None It allows for duplicate numbers in the output.\n• None This method is slightly less efficient than random.sample() but useful when duplicates are acceptable.\n\nIf we are working with large datasets or need high performance, NumPy provides an efficient way to generate random numbers.\n• None The size parameter determines the number of numbers generated.\n• None Converts the result to a Python list using .tolist().\n\nIf we need random numbers in a specific range, we can shuffle the range and slice it.\n• None randomizes the order of elements in a list.\n• None Slicing gives the desired number of random numbers.\n• None Suitable when the range and size are fixed."
    },
    {
        "link": "https://pythonprogramminglanguage.com/randon-numbers",
        "document": "In this article, I will explain the usage of the module in Python. As the name implies it allows you to generate random numbers.\n\nThis random module contains pseudo-random number generators for various distributions.\n\nThe function is one of them, it generates a number between 0 and 1.\n\nBut there are other like the functions and .\n\nLets start with the absolute basic random number generation. The function .\n\nThe function returns the next random float in the range [0.0, 1.0].\n\nTo use the function, call the method to generate a real (float) number between 0 and 1.\n\n\n\nThis outputs any number between 0 and 1. For most apps, you will need random integers instead of numbers between 0 and 1.\n\nThe function generates random integers for you. If you call the function, it returns a random integer such that .\n\nThe method to generates a whole number (integer). You can use to generate a random number between 0 and 50.\n\nTo generate random integers between 0 and 9, you can use the function .\n\nYou can use instead:\n\nChange the parameters of randint() to generate a number between 1 and 10.\n\nIf you want to generate a list of random number, you can do so by using a for loop.\n\nTo generate a list of 100 random numbers:\n\n\n\nBut this can be done in a much more compact way in Python, with a one liner.\n\nThe function to use is which shuffles the input list, in the example below it shuffles the created list .\n\nThat is to say, creates a list of numbers 1 to 100.\n\nThen the function shuffles that list in random order.\n\nYou can use the method to put the list in a random order. But you can also use it get random items from a list.\n\nIf you want 3 random items from the list, you add as second parameter of the method.\n\n\n\nIf you want to pick a random item, you can use the method. But this returns only one element.\n\nYou can use the method to shuffle the list order and then use the first index as random number.\n\nThe recommended way to do this is using the method, but all of these work.\n\nIf you are a Python beginner, then I highly recommend this book."
    },
    {
        "link": "https://quora.com/What-is-the-best-way-to-generate-a-random-number-between-two-numbers-in-Python",
        "document": "Something went wrong. Wait a moment and try again."
    },
    {
        "link": "https://stackoverflow.com/questions/7988494/efficient-way-to-generate-and-use-millions-of-random-numbers-in-python",
        "document": "Python builtin module, e.g. , , (some distributions also available, you probably want gaussian) does about 300K samples/s.\n\nSince you are doing numerical computation, you probably use anyway, that offers better performance if you cook random number one array at a time instead of one number at a time and wider choice of distributions. 60K/s * 1024 (array length), that's ~60M samples/s.\n\nYou can also read on Linux and OSX. my hw/sw (osx laptop) manages ~10MB/s.\n\nSurely there must be faster ways to generate random numbers en masse, e.g.:\n\nThis generates 200MB/s on a single core of i5-4670K\n\nCommon ciphers like aes and blowfish manage 112MB/s and 70MB/s on my stack. Furthermore modern processors make aes even faster up to some 700MB/s see this link to test runs on few hardware combinations. (edit: link broken). You could use weaker ECB mode, provided you feed distinct inputs into it, and achieve up to 3GB/s.\n\nStream cipher are better suited for the task, e.g. RC4 tops out at 300MB/s on my hardware, you may get best results from most popular ciphers as more effort was spent optimising those both and software."
    },
    {
        "link": "https://stackoverflow.com/questions/76318762/effective-approaches-for-optimizing-performance-with-large-datasets-in-python",
        "document": "I am currently working on a project that involves processing large datasets in Python. While I have managed to make it work, I am facing performance and efficiency challenges, especially when dealing with massive amounts of data.\n\nTo provide more context, let's assume I have a dataset with millions of records, and I need to perform complex computations or data transformations on it. Currently, my code takes a significant amount of time to process the data, and it seems to consume a considerable amount of memory, leading to potential memory errors or slowdowns.\n\nHere's a simplified example of my code structure:\n\nI would like to optimize my code and improve its efficiency when handling large datasets. Specifically, I am seeking advice on the following areas:\n\nMemory Management: What are the best practices for reducing memory usage when working with large datasets? Are there any techniques to minimize the memory footprint during data loading, processing, or storage?\n\nSpeeding up Processing: How can I accelerate the data processing tasks to improve overall performance? Are there any optimized functions or algorithms available that can handle large datasets more efficiently?\n\nAvoiding Bottlenecks: What are the common bottlenecks or performance limitations when working with large datasets in Python? Are there any specific areas of my code that could be potential bottlenecks, and how can I address them?\n\nI am open to leveraging popular libraries like pandas, NumPy, Dask, or any other relevant tools. Additionally, I am willing to explore alternative code structures, parallel processing techniques, or any other strategies that can significantly enhance the performance and efficiency of handling large datasets in Python.\n\nI would greatly appreciate any advice, suggestions, code examples, or references to relevant resources that can help me overcome these challenges and optimize my code for efficient large-scale data processing.\n\nThank you so much for your valuable assistance!"
    },
    {
        "link": "https://realpython.com/python-random",
        "document": "How random is random? This is a weird question to ask, but it is one of paramount importance in cases where information security is concerned. Whenever you’re generating random data, strings, or numbers in Python, it’s a good idea to have at least a rough idea of how that data was generated.\n\nHere, you’ll cover a handful of different options for generating random data in Python, and then build up to a comparison of each in terms of its level of security, versatility, purpose, and speed.\n\nI promise that this tutorial will not be a lesson in mathematics or cryptography, which I wouldn’t be well equipped to lecture on in the first place. You’ll get into just as much math as needed, and no more.\n\nFirst, a prominent disclaimer is necessary. Most random data generated with Python is not fully random in the scientific sense of the word. Rather, it is pseudorandom: generated with a pseudorandom number generator (PRNG), which is essentially any algorithm for generating seemingly random but still reproducible data. “True” random numbers can be generated by, you guessed it, a true random number generator (TRNG). One example is to repeatedly pick up a die off the floor, toss it in the air, and let it land how it may. Assuming that your toss is unbiased, you have truly no idea what number the die will land on. Rolling a die is a crude form of using hardware to generate a number that is not deterministic whatsoever. (Or, you can have the dice-o-matic do this for you.) TRNGs are out of the scope of this article but worth a mention nonetheless for comparison’s sake. PRNGs, usually done with software rather than hardware, work slightly differently. Here’s a concise description: They start with a random number, known as the seed, and then use an algorithm to generate a pseudo-random sequence of bits based on it. (Source) You’ve likely been told to “read the docs!” at some point. Well, those people are not wrong. Here’s a particularly notable snippet from the module’s documentation that you don’t want to miss: Warning: The pseudo-random generators of this module should not be used for security purposes. (Source) You’ve probably seen , , or the like, in Python. This function call is seeding the underlying random number generator used by Python’s module. It is what makes subsequent calls to generate random numbers deterministic: input A always produces output B. This blessing can also be a curse if it is used maliciously. Perhaps the terms “random” and “deterministic” seem like they cannot exist next to each other. To make that clearer, here’s an extremely trimmed down version of that iteratively creates a “random” number by using . is originally defined as a seed value and then morphs into a deterministic sequence of numbers based on that seed: Don’t take this example too literally, as it’s meant mainly to illustrate the concept. If you use the seed value 1234, the subsequent sequence of calls to should always be identical: You’ll see a more serious illustration of this shortly.\n\nIf you haven’t had enough with the “RNG” acronyms, let’s throw one more into the mix: a CSPRNG, or cryptographically secure PRNG. CSPRNGs are suitable for generating sensitive data such as passwords, authenticators, and tokens. Given a random string, there is realistically no way for Malicious Joe to determine what string came before or after that string in a sequence of random strings. One other term that you may see is entropy. In a nutshell, this refers to the amount of randomness introduced or desired. For example, one Python module that you’ll cover here defines , the number of bytes to return by default. The developers deem this to be “enough” bytes to be a sufficient amount of noise. Note: Through this tutorial, I assume that a byte refers to 8 bits, as it has since the 1960s, rather than some other unit of data storage. You are free to call this an octet if you so prefer. A key point about CSPRNGs is that they are still pseudorandom. They are engineered in some way that is internally deterministic, but they add some other variable or have some property that makes them “random enough” to prohibit backing into whatever function enforces determinism.\n\nProbably the most widely known tool for generating random data in Python is its module, which uses the Mersenne Twister PRNG algorithm as its core generator. Earlier, you touched briefly on , and now is a good time to see how it works. First, let’s build some random data without seeding. The function returns a random float in the interval [0.0, 1.0). The result will always be less than the right-hand endpoint (1.0). This is also known as a semi-open range: If you run this code yourself, I’ll bet my life savings that the numbers returned on your machine will be different. The default when you don’t seed the generator is to use your current system time or a “randomness source” from your OS if one is available. With , you can make results reproducible, and the chain of calls after will produce the same trail of data: Notice the repetition of “random” numbers. The sequence of random numbers becomes deterministic, or completely determined by the seed value, 444. Let’s take a look at some more basic functionality of . Above, you generated a random float. You can generate a random integer between two endpoints in Python with the function. This spans the full [x, y] interval and may include both endpoints: With , you can exclude the right-hand side of the interval, meaning the generated number always lies within [x, y) and will always be smaller than the right endpoint: If you need to generate random floats that lie within a specific [x, y] interval, you can use , which plucks from the continuous uniform distribution: To pick a random element from a non-empty sequence (like a list or a tuple), you can use . There is also for choosing multiple elements from a sequence with replacement (duplicates are possible): To mimic sampling without replacement, use : ['one', 'five', 'four', 'three'] You can randomize a sequence in-place using . This will modify the sequence object and randomize the order of elements: ['four', 'three', 'two', 'one', 'five'] If you’d rather not mutate the original list, you’ll need to make a copy first and then shuffle the copy. You can create copies of Python lists with the module, or just or , where is the list. Before moving on to generating random data with NumPy, let’s look at one more slightly involved application: generating a sequence of unique random strings of uniform length. It can help to think about the design of the function first. You need to choose from a “pool” of characters such as letters, numbers, and/or punctuation, combine these into a single string, and then check that this string has not already been generated. A Python works well for this type of membership testing: pool: Iterable of characters to choose from # Bind these methods outside of a loop joins the letters from into a single Python of length . This token is added to the set, which can’t contain duplicates, and the loop executes until the set has the number of elements that you specify. Resource: Python’s module contains a number of useful constants: , , , , and a handful of others. Let’s try this function out: For a fine-tuned version of this function, this Stack Overflow answer uses generator functions, name binding, and some other advanced tricks to make a faster, cryptographically secure version of above. One thing you might have noticed is that a majority of the functions from return a scalar value (a single , , or other object). If you wanted to generate a sequence of random numbers, one way to achieve that would be with a Python list comprehension: But there is another option that is specifically designed for this. You can think of NumPy’s own package as being like the standard library’s , but for NumPy arrays. (It also comes loaded with the ability to draw from a lot more statistical distributions.) Take note that uses its own PRNG that is separate from plain old . You won’t produce deterministically random NumPy arrays with a call to Python’s own : Without further ado, here are a few examples to whet your appetite: # `p` is the probability of choosing each element In the syntax for , the parameters are optional and indicate the shape of the final object. Here, creates a 2d array with 3 rows and 4 columns. The data will be i.i.d., meaning that each data point is drawn independent of the others. Note: If you’re looking to create normally distributed random numbers, then you’re in luck! How to Get Normally Distributed Random Numbers With NumPy can guide your way. Another common operation is to create a sequence of random Boolean values, or . One way to do this would be with . However, it’s actually about 4x faster to choose from and then view-cast these integers to their corresponding Boolean values: What about generating correlated data? Let’s say you want to simulate two correlated time series. One way of going about this is with NumPy’s function, which takes a covariance matrix into account. In other words, to draw from a single normally distributed random variable, you need to specify its mean and variance (or standard deviation). To sample from the multivariate normal distribution, you specify the means and covariance matrix, and you end up with multiple, correlated series of data that are each approximately normally distributed. However, rather than covariance, correlation is a measure that is more familiar and intuitive to most. It’s the covariance normalized by the product of standard deviations, and so you can also define covariance in terms of correlation and standard deviation: So, could you draw random samples from a multivariate normal distribution by specifying a correlation matrix and standard deviations? Yes, but you’ll need to get the above into matrix form first. Here, S is a vector of the standard deviations, P is their correlation matrix, and C is the resulting (square) covariance matrix: This can be expressed in NumPy as follows: Now, you can generate two time series that are correlated but still random: # -0.40 is the correlation between A and B, and the correlation # of a variable with itself is 1.0. # Standard deviations/means of A and B, respectively # `size` is the length of time series for 2d data # (500 months, days, and so on). You can think of as 500 pairs of inversely correlated data points. Here’s a sanity check that you can back into the original inputs, which approximate , , and from above: Before we move on to CSPRNGs, it might be helpful to summarize some functions and their counterparts: Sample from a normal distribution with mean and standard deviation Note: NumPy is specialized for building and manipulating large, multidimensional arrays. If you just need a single value, will suffice and will probably be faster as well. For small sequences, may even be faster too, because NumPy does come with some overhead. Now that you’ve covered two fundamental options for PRNGs, let’s move onto a few more secure adaptations.\n\n: About as Random as It Gets Python’s function is used by both and (both of which you’ll see here in a moment). Without getting into too much detail, generates operating-system-dependent random bytes that can safely be called cryptographically secure:\n• On Unix operating systems, it reads random bytes from the special file , which in turn “allow access to environmental noise collected from device drivers and other sources.” (Thank you, Wikipedia.) This is garbled information that is particular to your hardware and system state at an instance in time but at the same time sufficiently random.\n• On Windows, the C++ function is used. This function is still technically pseudorandom, but it works by generating a seed value from variables such as the process ID, memory status, and so on. With , there is no concept of manually seeding. While still technically pseudorandom, this function better aligns with how we think of randomness. The only argument is the number of bytes to return: Before we go any further, this might be a good time to delve into a mini-lesson on character encoding. Many people, including myself, have some type of allergic reaction when they see objects and a long line of characters. However, it’s useful to know how sequences such as above eventually get turned into strings or numbers. But how does this eventually get turned into a Python or sequence of numbers? First, recall one of the fundamental concepts of computing, which is that a byte is made up of 8 bits. You can think of a bit as a single digit that is either 0 or 1. A byte effectively chooses between 0 and 1 eight times, so both and could represent bytes. Try this, which makes use of Python f-strings introduced in Python 3.6, in your interpreter: This is equivalent to , with some special formatting. converts an integer to its binary representation as a string. Where does that leave us? Using above is not a random choice. (No pun intended.) Given that we are allowed 8 bits, each with 2 choices, there are possible bytes “combinations.” This means that each byte maps to an integer between 0 and 255. In other words, we would need more than 8 bits to express the integer 256. You can verify this by checking that is now 9, not 8. Okay, now let’s get back to the data type that you saw above, by constructing a sequence of the bytes that correspond to integers 0 through 255: If you call , you’ll get back to a Python list that runs from 0 to 255. But if you just print , you get an ugly looking sequence littered with backslashes: These backslashes are escape sequences, and represents the character with hex value . Some of the elements of are displayed literally (printable characters such as letters, numbers, and punctuation). Most are expressed with escapes. represents a keyboard’s backspace, while is a carriage return (part of a new line, on Windows systems). If you need a refresher on hexadecimal, Charles Petzold’s Code: The Hidden Language is a great place for that. Hex is a base-16 numbering system that, instead of using 0 through 9, uses 0 through 9 and a through f as its basic digits. Finally, let’s get back to where you started, with the sequence of random bytes . Hopefully this makes a little more sense now. Calling on a object gives a of hexadecimal numbers, with each corresponding to a decimal number from 0 through 255: One last question: how is 12 characters long above, even though is only 6 bytes? This is because two hexadecimal digits correspond precisely to a single byte. The version of will always be twice as long as far as our eyes are concerned. Even if the byte (such as ) does not need a full 8 bits to be represented, will always use two hex digits per byte, so the number 1 will be represented as rather than just . Mathematically, though, both of these are the same size. Technical Detail: What you’ve mainly dissected here is how a object becomes a Python . One other technicality is how produced by get converted to a in the interval [0.0, 1.0), as in the cryptographically secure version of . If you’re interested in exploring this further, this code snippet demonstrates how makes the initial conversion to an integer, using a base-256 numbering system. With that under your belt, let’s touch on a recently introduced module, , which makes generating secure tokens much more user-friendly. Introduced in Python 3.6 by one of the more colorful PEPs out there, the module is intended to be the de facto Python module for generating cryptographically secure random bytes and strings. You can check out the source code for the module, which is short and sweet at about 25 lines of code. is basically a wrapper around . It exports just a handful of functions for generating random numbers, bytes, and strings. Most of these examples should be fairly self-explanatory: Now, how about a concrete example? You’ve probably used URL shortener services like tinyurl.com or bit.ly that turn an unwieldy URL into something like https://bit.ly/2IcCp9u. Most shorteners don’t do any complicated hashing from input to output; they just generate a random string, make sure that string has not already been generated previously, and then tie that back to the input URL. Let’s say that after taking a look at the Root Zone Database, you’ve registered the site short.ly. Here’s a function to get you started with your service: Is this a full-fledged real illustration? No. I would wager that bit.ly does things in a slightly more advanced way than storing its gold mine in a global Python dictionary that is not persistent between sessions. Note: If you’d like to build a full-fledged URL shortener of your own, then check out Build a URL Shortener With FastAPI and Python. Hold On: One thing you may notice is that both of these results are of length 7 when you requested 5 bytes. Wait, I thought that you said the result would be twice as long? Well, not exactly, in this case. There is one more thing going on here: uses base64 encoding, where each character is 6 bits of data. (It’s 0 through 63, and corresponding characters. The characters are A-Z, a-z, 0-9, and +/.) If you originally specify a certain number of bytes , the resulting length from will be , which you can prove and investigate further if you’re curious. The bottom line here is that, while is really just a wrapper around existing Python functions, it can be your go-to when security is your foremost concern.\n\nOne last option for generating a random token is the function from Python’s module. A UUID is a Universally Unique IDentifier, a 128-bit sequence ( of length 32) designed to “guarantee uniqueness across space and time.” is one of the module’s most useful functions, and this function also uses : The nice thing is that all of ’s functions produce an instance of the class, which encapsulates the ID and has properties like , , and : You may also have seen some other variations: , , and . The key difference between these and is that those three functions all take some form of input and therefore don’t meet the definition of “random” to the extent that a Version 4 UUID does:\n• uses your machine’s host ID and current time by default. Because of the reliance on current time down to nanosecond resolution, this version is where UUID derives the claim “guaranteed uniqueness across time.”\n• and both take a namespace identifier and a name. The former uses an MD5 hash and the latter uses SHA-1. , conversely, is entirely pseudorandom (or random). It consists of getting 16 bytes via , converting this to a big-endian integer, and doing a number of bitwise operations to comply with the formal specification. Hopefully, by now you have a good idea of the distinction between different “types” of random data and how to create them. However, one other issue that might come to mind is that of collisions. In this case, a collision would simply refer to generating two matching UUIDs. What is the chance of that? Well, it is technically not zero, but perhaps it is close enough: there are or 340 undecillion possible values. So, I’ll leave it up to you to judge whether this is enough of a guarantee to sleep well. One common use of is in Django, which has a that is often used as a primary key in a model’s underlying relational database."
    },
    {
        "link": "https://medium.com/@learntocodetoday/11-expert-python-tips-for-working-with-large-datasets-b2048b0630e8",
        "document": "Python has become a go-to language for data analysis and manipulation due to its simplicity and robust libraries. However, working with large datasets can present significant challenges, from memory constraints to processing speed. This advanced guide offers 11 expert tips to optimize your Python code and make handling large datasets more efficient.\n• Pandas: While pandas is extremely powerful for data manipulation, it can be slower and more memory-intensive for large datasets.\n• NumPy: NumPy arrays are more memory-efficient and faster for numerical operations. Use NumPy for numerical data and reserve pandas for when you need advanced data manipulation capabilities.\n• Use Python’s built-in data structures like lists, sets, and dictionaries wisely. For instance, dictionaries are excellent for lookups but can be more memory-intensive than lists.\n\nGenerators allow you to iterate over data without loading the entire dataset into…"
    },
    {
        "link": "https://discuss.huggingface.co/t/strategy-for-generating-a-large-dataset/29063",
        "document": "allows to load datasets that are bigger than memory, and you can also use a python generator function to define a dataset. You can take a look at Dataset.from_generator\n\nAlthough your startegy doesn’t seem super efficient, because for each point you’d have to load a new file in memory to sample from it.\n\nYou may consider doing this instead:\n• choose how many vectors per file you want to sample. In your case you should end up with 1M vectors in total. You can run your analysis on this before generating the actual dataset.\n• open each file one by one and sample the corresponding amount of vectors to a dataset\n\nThis way you only load each file once in memory; it should save you a lot of time."
    }
]