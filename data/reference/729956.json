[
    {
        "link": "https://geeksforgeeks.org/deletion-in-an-avl-tree",
        "document": "We have discussed AVL insertion in the previous post. In this post, we will follow a similar approach for deletion.\n\nSteps to follow for deletion. \n\nTo make sure that the given tree remains AVL after every deletion, we must augment the standard BST delete operation to perform some re-balancing. Following are two basic operations that can be performed to re-balance a BST without violating the BST property (keys(left) < key(root) < keys(right)).\n\nLet w be the node to be deleted\n• None Starting from w, travel up and find the first unbalanced node. Let z be the first unbalanced node, y be the larger height child of z, and x be the larger height child of y. Note that the definitions of x and y are different from\n• None Re-balance the tree by performing appropriate rotations on the subtree rooted with z. There can be 4 possible cases that needs to be handled as x, y and z can be arranged in 4 ways. Following are the possible 4 arrangements:\n• None y is left child of z and x is left child of y (Left Left Case)\n• None y is left child of z and x is right child of y (Left Right Case)\n• None y is right child of z and x is right child of y (Right Right Case)\n• None y is right child of z and x is left child of y (Right Left Case)\n\nLike insertion, following are the operations to be performed in above mentioned 4 cases. Note that, unlike insertion, fixing the node z won’t fix the complete AVL tree. After fixing z, we may have to fix ancestors of z as well (See this video lecture for proof)\n\n\n\nUnlike insertion, in deletion, after we perform a rotation at z, we may have to perform a rotation at ancestors of z. Thus, we must continue to trace the path until we reach the root.\n\nA node with value 32 is being deleted. After deleting 32, we travel up and find the first unbalanced node which is 44. We mark it as z, its higher height child as y which is 62, and y’s higher height child as x which could be either 78 or 50 as both are of same height. We have considered 78. Now the case is Right Right, so we perform left rotation.\n\n\n\nFollowing is the implementation for AVL Tree Deletion. The following implementation uses the recursive BST delete as basis. In the recursive BST delete, after deletion, we get pointers to all ancestors one by one in bottom up manner. So we don’t need parent pointer (or reference) to travel up. The recursive code itself travels up and visits all the ancestors of the deleted node.\n• None The current node must be one of the ancestors of the deleted node. Update the height of the current node.\n• None Get the balance factor (left subtree height – right subtree height) of the current node.\n• None If balance factor is greater than 1, then the current node is unbalanced and we are either in Left Left case or Left Right case. To check whether it is Left Left case or Left Right case, get the balance factor of left subtree. If balance factor of the left subtree is greater than or equal to 0, then it is Left Left case, else Left Right case.\n• None If balance factor is less than -1, then the current node is unbalanced and we are either in Right Right case or Right Left case. To check whether it is Right Right case or Right Left case, get the balance factor of right subtree. If the balance factor of the right subtree is smaller than or equal to 0, then it is Right Right case, else Right Left case.\n\n// A utility function to get the height // 3. Get the balance factor of this // ancestor node to check whether this // If this node becomes unbalanced, then // return the node with minimum key value // found in that tree. Note that the entire // tree does not need to be searched. // loop down to find the leftmost leaf // given key from subtree with given root. // It returns root of the modified subtree. // If the key to be deleted is smaller // than the root's key, then it lies in // If the key to be deleted is greater // than the root's key, then it lies in // if key is same as root's key, then // this is the node to be deleted // node with only one child or no child // node with two children: Get the // If the tree had only one node then return // STEP 3: GET THE BALANCE FACTOR OF THIS // NODE (to check whether this node // If this node becomes unbalanced, then // Constructing tree given in the // C program to delete a node from AVL Tree // A utility function to get maximum of two integers // A utility function to get height of the tree // A utility function to get maximum of two integers /* Helper function that allocates a new node with the given key and // new node is initially added at leaf // A utility function to right rotate subtree rooted with y // See the diagram given above. // See the diagram given above. /* 3. Get the balance factor of this ancestor node to check whether this node became // If this node becomes unbalanced, then there are 4 cases node with minimum key value found in that tree. Note that the entire tree does not need to be /* loop down to find the leftmost leaf */ // Recursive function to delete a node with given key // from subtree with given root. It returns root of // If the key to be deleted is smaller than the // root's key, then it lies in left subtree // If the key to be deleted is greater than the // root's key, then it lies in right subtree // if key is same as root's key, then This is // the node to be deleted // node with only one child or no child // node with two children: Get the inorder // successor (smallest in the right subtree) // Copy the inorder successor's data to this node // If the tree had only one node then return // STEP 3: GET THE BALANCE FACTOR OF THIS NODE (to // check whether this node became unbalanced) // If this node becomes unbalanced, then there are 4 cases // The function also prints height of every node /* Constructing tree given in the above figure */ /* The constructed AVL Tree would be /* The AVL Tree after deletion of 10 // A utility function to get the height // 3. Get the balance factor of this node // to check whether this node became // If this node becomes unbalanced, then // return the node with minimum key value // loop down to find the leftmost leaf // given key from subtree with given root. // It returns root of the modified subtree. // If the key to be deleted is smaller // than the root's key, then it lies in // If the key to be deleted is greater // than the root's key, then it lies in // if key is same as root's key, then // this is the node to be deleted // node with only one child or no child // node with two children: Get the // If the tree had only one node then return // STEP 3: GET THE BALANCE FACTOR OF THIS // NODE (to check whether this node // If this node becomes unbalanced, then // Constructing tree given in the # 3. Get the balance factor of this node # to check whether this node became # If this node becomes unbalanced, then # loop down to find the leftmost leaf # If the key to be deleted is smaller # than the root's key, then it lies in # If the key to be deleted is greater # than the root's key, then it lies in # if key is same as root's key, then # this is the node to be deleted # node with only one child or no child # node with two children: Get the # If the tree had only one node then return # STEP 3: GET THE BALANCE FACTOR OF THIS # NODE (to check whether this node # If this node becomes unbalanced, then # Constructing tree given in the // 3. Get the balance factor of this node // to check whether this node became unbalanced // If this node becomes unbalanced, then there are 4 cases // loop down to find the leftmost leaf // If the key to be deleted is smaller // than the root's key, then it lies in // if key is same as root's key // node with only one child or no child // node with two children: Get the inorder successor // Copy the inorder successor's data to this node // If the tree had only one node then return // STEP 3: GET THE BALANCE FACTOR OF THIS NODE // If this node becomes unbalanced, then there are 4 cases // Constructing tree given in the above figure \"Preorder traversal of the constructed AVL tree is:\" // 3. Get the balance factor of this node // to check whether this node became unbalanced // If this node becomes unbalanced, then there are 4 cases // loop down to find the leftmost leaf // If the key to be deleted is smaller // than the root's key, then it lies in // if key is same as root's key // node with only one child or no child // Copy the contents of the non-empty child // node with two children: Get the inorder successor // Copy the inorder successor's data to this node // If the tree had only one node then return // STEP 3: GET THE BALANCE FACTOR OF THIS NODE // If this node becomes unbalanced, then there are 4 cases // Constructing tree given in the above figure \"Preorder traversal of the constructed AVL tree is:\"\n\nTime Complexity: The rotation operations (left and right rotate) take constant time as only few pointers are being changed there. Updating the height and getting the balance factor also take constant time. So the time complexity of AVL delete remains same as BST delete which is O(h) where h is height of the tree. Since AVL tree is balanced, the height is O(log n). So time complexity of AVL delete is O(log n). \n\nAuxiliary Space: O(log n) for recursion call stack as we have written a recursive method to delete\n• None When balancing factor goes beyond the range require rotations to be performed\n• None AVL tree are mostly used where search is more frequent compared to insert and delete operation."
    },
    {
        "link": "https://stackoverflow.com/questions/78202985/debugging-avl-tree-deletion-unbalanced-node-not-on-deletion-path",
        "document": "I'm working on implementing an AVL tree in C++, and I've run into a situation where, after deleting a node and rebalancing the tree, a node not directly on the path from the deleted node to the root becomes unbalanced. I've walked through my deletion and rebalancing algorithm, but I can't seem to identify the problem.\n\nHere's the initial AVL tree state before any operations:\n\nI want to delete the node with the value \"914\". According to my algorithm, I proceed with the deletion and then perform the necessary rotations to rebalance the tree. However, after the deletion and rebalancing process, I end up with an unbalanced node that wasn't a direct ancestor of the deleted node.\n\nHere's the tree after deletion and rebalancing operations:\n• balancing the node that replaces the deleted one:\n\nMy algorithm updates the heights and balances after every rotation, and it seems to follow the correct AVL deletion process. However, it ends up with node \"381\" being unbalanced, and I can't figure out why."
    },
    {
        "link": "https://stackoverflow.com/questions/4315625/c-removal-of-a-node-in-an-avl-tree",
        "document": "If the node was created using 'new' than it needs to be explicitly deleted, absolutely. They question will be where. If you are deleting the node, (the assumption is nobody else needs the contents of the node) then you should also delete the node itself after completing the nodes removal from the tree.\n\nNow, the reference to the node is another matter. If the reference is an artifact of a method argument definition, you don't have to do anything with it. The reference was created on the stack to help with the method call. If I remember my C++, references can never be null, which means never having to say you're sorry(bad joke), er never having to delete them.\n\n[EDIT] The OP says, \"Because I've passed in parameter a Node*&, but the successor is only a Node* in the function...)\" so I assumed you meant something like:\n\nwhich is then called using\n\nMy C++ is a bit rusty but the idea here is that 'n' is a pointer but the argument type of removeNode() is a reference to a pointer. The caller doesn't know that a reference is involved, it just passes 'n' expecting the arg type to be pointer-to-node (Node*). The compiler is creating the reference as a wrapper around the argument so only the callee is aware of the reference. Since the reference is created on the stack, it will be 'managed' properly when removeNode() returns. The node pointed to by 'n' still needs to be deleted, the question is which code should handle it.\n\nFirst thought would be for 'removeNode()' to do it. One problem is that it only has a reference to it and if you delete the pointer (the target of the reference) the reference will be null which is a bad idea / not allowed. Just thinking of the syntax to attempt it made me cringe.\n\nSo, have the client code to do it, like so:\n\nBasically, you need to have a plan for the scope of your node pointers. As long as it is consistent, you could do it in several different ways. If you wanted removeNode() to handle the deletion, then change the argument type to a pointer instead of a reference and document the call so the expectation is it both removes the node from the tree and deletes the memory as well."
    },
    {
        "link": "https://geeksforgeeks.org/cpp-program-to-implement-avl-tree",
        "document": "AVL Tree, named after its inventors Adelson-Velsky and Landis, is a self-balancing binary search tree. In an AVL tree, the heights of the two child subtrees of any node differ by at most one, which ensures that the tree remains approximately balanced, providing efficient search, insertion, and deletion operations.\n\nIn this article, we will learn about the implementation of AVL Tree in C++, its basic operation and its applications.\n\nWhat is an AVL Tree?\n\nAn AVL tree maintains balance by performing rotations during insertions and deletions to ensure the height difference between the left and right subtrees of any node is no more than one. This property guarantees that the tree's height remains O(logn), ensuring efficient operations.\n\nAn AVL Tree is a binary search tree with the following properties:\n• None The heights of the left and right subtrees of every node differ by at most one.\n• None Every subtree is an AVL tree.\n• None For every node, its balance factor (height of left subtree - height of right subtree) is -1, 0, or 1.\n\nImplementation of AVL Tree in C++\n\nAn AVL tree can be implemented using a binary tree structure where each node will have left and right pointers and key values to store the data but along with that, we will store the height for each node so that the balance factor can be calculated easily. The balance factor of a node will be calculated for each node as the difference between the heights of its left and right subtrees.\n\nWhen the balance factor for any node is not in the allowed limits, rotations are preformed to balance it.\n\nRotations are the most important part of the working of the AVL tree. They are responsible for maintaining the balance in the AVL tree. There are 4 types of rotations based on the 4 possible cases:\n\nThe Right Rotation (RR) is applied in an AVL tree when a node becomes unbalanced due to an insertion into the right subtree of its right child, leading to a Left Imbalance. To correct this imbalance, the unbalanced node is rotated 90° to the right (clockwise) along the top edge connected to its parent.\n\nThe Left Rotation (LL) is used to balance a node that becomes unbalanced due to an insertion into the left subtree of its left child, also resulting in a Left Imbalance. The solution is to rotate the unbalanced node 90° to the left (anti-clockwise) along the top edge connected to its parent.\n\nThe Left-Right Rotation (LR) is necessary when the left child of a node is right-heavy, creating a double imbalance. This situation is resolved by performing a left rotation on the left child, followed by a right rotation on the original node.\n\nThe Right-Left Rotation (RL) is used when the right child of a node is left-heavy. This imbalance is corrected by performing a right rotation on the right child, followed by a left rotation on the original node.\n\nRepresentation of AVL Tree in C++\n\nThe following diagram represents the structure of an AVL Tree where the balance factor of each node is 0 and the tree is balanced:\n\nTo represent an AVL Tree in C++, we will use a class AVLNode to define the node structure and a class AVLTree to implement the AVL tree operations. We will use the in order to keep the AVL tree generic so that it can store multiple data types.\n• key: represents the value stored inside the node.\n• left &right: are pointers to the left and right node.\n• height: represents the height of each subtree starting from each node.\n\nImplementation of Basic Operations of an AVL Tree in C++\n\nFollowing are the basic operations that are required to work with an AVL tree:\n\nThe following program demonstrates the implementation of AVL tree in C++:\n\n// Pointer to the right child // Height of the node in the tree // Constructor to initialize a node with a given key // Pointer to the root of the tree // function to get the height of a node // function to get the balance factor of a node // function to perform a right rotation on a subtree // function to insert a new key into the subtree rooted // Get the balance factor of this ancestor node // If this node becomes unbalanced, then there are 4 // function to find the node with the minimum key value // function to delete a key from the subtree rooted with // Node with only one child or no child // Get the balance factor of this node // If this node becomes unbalanced, then there are 4 // function to perform inorder traversal of the tree // function to search for a key in the subtree rooted // Function to insert a key into the AVL tree // Function to remove a key from the AVL tree // Function to search for a key in the AVL tree // Function to print the inorder traversal of the AVL // Print the inorder traversal of the AVL tree // Search for nodes in the AVL tree\n\nFollowing are some of the common applications of an AVL Tree:\n• Database Indexing: AVL trees are used in database systems for efficient indexing and quick data retrieval.\n• File Systems: Some file systems use AVL trees to maintain directory structures for fast file lookups.\n• Spatial Indexing: In computer graphics and computational geometry, AVL trees are used for spatial indexing of objects.\n• Network Routing Tables: AVL trees can be used to implement routing tables in network routers for efficient IP lookup.\n• Priority Queues: While not as common as heaps, AVL trees can be used to implement priority queues with efficient operations.\n• Symbol Tables in Compilers: Compilers often use AVL trees to implement symbol tables for fast insertion, deletion, and lookup of identifiers."
    },
    {
        "link": "https://medium.com/@amitai.turkel/exploring-the-power-of-avl-trees-balancing-data-structures-for-efficient-operations-b803044d2955",
        "document": "Exploring the Power of AVL Trees: Balancing Data Structures for Efficient Operations\n\nWhen discussing fundamental and practical data structures, the AVL tree is a topic that cannot be overlooked. Its widespread utility has made it a staple in various data platforms and a common subject in data-related interviews. Today, I’ll delve into the core operations required to maintain this data structure and shed light on scenarios where AVL trees prove invaluable.\n\nSo, what exactly is an AVL tree? First and foremost, it’s a type of binary search tree, where the left child’s value is greater than that of its parent, and the right child’s value is smaller. This rule applies to every vertex within the tree, essentially making each vertex a subtree that could potentially serve as the root of its own binary tree.\n\nSecondly, the binary search tree is engineered for balance. What does “balance” mean in this context? Picture a tree, and for each vertex, introduce a field called “bf,” denoting the balance factor. This factor quantifies the disparity between the depths of the right and left subtrees. got the idea?\n\nA balanced tree, in this context, implies that the balance factor is always within the range of -1 to 1. Why is this significant? The underlying idea is to ensure that when we navigate the tree, our various operations consistently have nearly equivalent worst-case depths. To achieve this, we strive to maintain uniform depths among the children of every vertex. Does this concept now appear clearer?\n\nBy preserving a balanced binary search tree, we can guarantee that the tree’s height, denoted as “h,” remains bounded by O(log(n)). So, an AVL tree is essentially a BST but with the added attribute of balance.\n\nNow, what does AVL offer us, and what are the costs associated with keeping the tree balanced? Let’s first explore the runtime characteristics, and then we’ll tackle the challenging aspect of how to maintain balance efficiently, ideally in O(1) time.\n\n- Search — O(log(n)): The AVL tree’s search operation works efficiently because of its inherent binary search tree (BST) property. As we traverse the tree, we compare the target value with the current node’s value. Based on the comparison, we can eliminate half of the remaining search space by choosing either the left or right subtree. This halving effect ensures that, on average, we reduce the search space by half with each comparison, leading to a logarithmic time complexity.\n\n- Tree Traversal — O(n): Tree traversal involves visiting every node in the tree. Since we need to examine all nodes once, the time complexity for traversing the entire tree is O(n).\n\n- Finding the Maximum Value — O(log(n)): In an AVL tree, the maximum value resides at the rightmost leaf. As we navigate down the right subtrees, we are essentially finding the highest value. The logarithmic time complexity arises because we only need to traverse the height of the tree to reach this leaf, and the AVL tree ensures the height is O(log(n)).\n\n- Finding the Minimum Value — O(log(n)): Similarly to finding the maximum value, the minimum value is located at the leftmost leaf of the tree. Since we traverse down the left subtrees, we are effectively seeking the smallest value. The O(log(n)) time complexity results from the AVL tree’s guarantee that the tree’s height is bounded by O(log(n)).\n\n- Insertion — O(log(n)): AVL tree insertion maintains balance by adhering to the BST property. When we insert a new node, we follow the BST rules to determine its position. After insertion, we check the balance factor of the ancestors of the newly inserted node and, if necessary, perform rotations to restore balance. These rotations are designed to keep the tree balanced, and the O(log(n)) complexity comes from the height of the tree.\n\n- Successor(x) — O(log(n)): Determining the successor of a node x involves examining its right subtree. If x has a right child, we find the rightmost node in this subtree, which is larger than x. If x lacks a right child, we traverse the tree upwards until we encounter a right turn, leading us to the predecessor(x). The logic behind this operation is rooted in the structure of the AVL tree, where the right subtree contains elements greater than the current node and the left subtree contains elements smaller than the current node. This design allows us to efficiently locate the successor.\n\n- Predecessor(x) — O(log(n)): Finding the predecessor of a node x is similar to finding the successor but in reverse. If x has a left child, we locate the leftmost node in this subtree, which is smaller than x. If x lacks a left child, we traverse the tree upwards until we encounter a left turn, leading us to the successor(x). The logic here is analogous to the successor operation, but we focus on the left subtree for elements smaller than the current node.\n\n- Deletion(x) — O(log(n)): Deletion in an AVL tree is complex due to the need to maintain balance. The logic behind the deletion operation involves several cases:\n\n 1. If x is a leaf node, we can safely remove it without affecting balance.\n\n 2. If x has only one child, we can replace x with that child, ensuring the BST property remains intact.\n\n 3. When x has two children, we replace x with its successor, which preserves both the BST property and balance. The successor is chosen because it has the next largest value, ensuring the tree remains ordered.\n\nNow, let’s delve into the intricacies of AVL tree maintenance, especially during insertion and deletion. We encounter a fascinating process known as “rebalancing,” which is crucial to ensure that our AVL tree maintains its balance even when we insert or delete nodes.\n\nConsider this scenario: during a modification operation, the height difference between two child subtrees changes. This change, as long as it remains less than 2, needs to be reflected by an adjustment in the balance information at the parent node. However, there are situations, particularly during insertions and deletions, where a temporary height difference of 2 may occur. In such cases, the parent subtree must undergo a process of rebalancing. This rebalancing act relies on a set of clever tools known as “tree rotations.”\n\nTree rotations are ingenious because they move keys only “vertically” within the tree, ensuring that the essential “horizontal” in-order sequence of the keys remains intact — a fundamental requirement for a binary search tree. The beauty of these rotations is that they restore balance without disrupting the order of the elements.\n\nLet’s delve into how this rebalancing magic unfolds:\n\nFirst, we have two basic rotation operations: right rotate and left rotate.\n\n- Right Rotate (RR): This rotation occurs when BF(V) = -2, and BF(V.left) is either 0 or -1. In this case, we fix it by using a left rotation on V.\n\n- Left Rotate (LL): This rotation occurs when BF(V) = 2, and BF(V.left) is either 0 or 1. In this case, we fix it by using a right rotation on V.\n\nThere are also two more complex rotation scenarios:\n\n- Right-Left Rotate (RL): This rotation occurs when BF(V) = -2, and BF(V.right) is 1. In this case, we fix it by using a right rotation on V.right (U in this case) and then a left rotation on V.\n\n- Left-Right Rotate (LR): This rotation occurs when BF(V) = 2, and BF(V.left)\n\nis 1. In this case, we fix it by using a left rotation on V.left and then a right rotation on V.\n\nThe beauty of these rotations is that their cost is constant, making them efficient tools for maintaining the balance of our AVL tree during runtime.\n\nNow, let’s provide a quick example of the usefulness of the AVL data structure.\n\nImagine you’re an education administrator, responsible for managing student records efficiently. One of your key tasks is to access individual student grades quickly. Now, handling all the student data in a straightforward manner can lead to significant delays in retrieving information. However, there’s a smart solution: leveraging the AVL data structure.\n\n1. School Hierarchy:\n\n — You create an AVL tree that represents the schools under your supervision. Each node in this tree corresponds to a school.\n\n — Within each school node, there’s a pointer to another AVL tree that maintains a list of classes offered in that school.\n\n — Inside the class AVL tree, every node points to an additional AVL tree containing student records for that particular class.\n\n — Finally, each student node within the class AVL tree has a pointer to yet another AVL tree holding that student’s grades for the specific class.\n\nThis hierarchical structure allows you to efficiently navigate through the educational system. Let’s break it down:\n\n- Starting at the top, you access the AVL tree representing schools.\n\n- Within the school node, you swiftly identify the class AVL tree for the desired class.\n\n- Inside the class AVL tree, locating the student’s record is a breeze.\n\n- Lastly, within the student node, you have access to their grades.\n\nBy employing the AVL data structure in this clever manner, you’ve significantly reduced the time it takes to retrieve a student’s grades. Moreover, this organized database can be adapted for various other educational purposes, making it a versatile and efficient tool for managing student information.\n\nIf you’d like to experiment with AVL trees, there’s a great simulator available that operates slightly differently from the description I provided earlier. However, it can be quite helpful in grasping the core concepts."
    },
    {
        "link": "https://geeksforgeeks.org/cpp-pointers",
        "document": "A pointer is a variable that stores the address of another variable. Pointers can be used with any data type, including basic types (e.g., int, char), arrays, and even user-defined types like classes and structures.\n\nA pointer can be declared in the same way as any other variable but with an asterisk symbol (*) as shown:\n\nHere, data_type is the type of data that the pointer is pointing to, and name is the name assigned to the pointer. The * symbol is also called dereference operator.\n\nIn the above statement, we create a pointer ptr that can store the address of an integer data. It is pronounced as “Pointer to Integer” or “Integer Pointer”\n\nThe addressof operator (&) determines the address of any variable in C++. This address can be assigned to the pointer variable to initialize it.\n\nIn the above statement, pointer ptr store the address of variable val using address-of operator (&). The pointer and the variable should be of same type, othewise type mismatch error occurs.\n\nThe process of accessing the value present at the memory address pointed by the pointer is called dereferencing. This is done with the help of dereferencing operator as shown:\n\nDirectly accessing the pointer will just give us the address that is stored in the pointer.\n\nThe below image demonstrates how pointer works.\n\nThe pointer can be modified to point to another memory address if its is of the same type.\n\nThe size of pointer in a system is equal for every pointer no matter what type of data it is pointing to. It does not depend on the type, but on operating system and CPU architecture. The size of pointers in C++ is\n\nThe logic is simple: pointers store the addresses of the memory and in a computer, the maximum width of a memory address is determined by the CPU architecture. For example, for a 64-bit CPU, the address will always be 64-bit wide. This can be verified using sizeof operator.\n\nAs we can see, both the pointers have same size. It’s a 64-bit system, so the size is 8 bytes.\n\nThere are 4 special types of pointers that used or referred to in different contexts:\n\nWhen a pointer is created, it just contains a random address that may or may not be valid. This type of pointer is called wild pointer.\n\nDereferencing this pointer may lead to errors such as segmentation faults. So, it is always recommended to initialize a pointer.\n\nA NULL pointer is a pointer that does not point to any valid memory location but NULL. It is often used to initialize a pointer when you do not want it to point to any object.\n\nThis is a special type of pointer available in C++ which represents the absence of type. Void pointers are pointers that point to a value that has no particular type. It also means that they can point to any data type.\n\nBut as the datatype is not known, the compiler also does not know how many bytes to access when the void pointer is dereferenced, so these pointers cannot be directly dereferenced. They have to be first converted into some other pointer type that points to a concrete data type before being dereferenced.\n\nA dangling pointer is a pointer that was pointing to the valid memory location earlier, but that memory has been taken from the program, and it is still pointing to it. This pointer behaves like a wild pointer and may lead to errors.\n\nIn C++, pointers and arrays are closely related. An array name acts like a constant pointer to the first element of the array. If we assign this value to a non-constant pointer of the same type, then we can access the elements of the array with this pointer using pointer arithmetic.\n\nPointer arithmetic refers to the operations that C++ allows on the pointers. They include:\n• Subtraction of Two Pointers of the Same Type\n\nWe can also have pointers that point to other pointers. This is called a double pointer, and it is useful when working with multi-level data structures like arrays of pointers or dynamic memory management.\n\nIn C++, a function pointer is used to point to functions, similar to how pointers are used to point to variables. It allows you to save the address of a function. Function pointers can be used to call a function indirectly, or they can be passed as arguments to another function, enabling dynamic function invocation and flexibility in function handling.\n\nA smart pointer is a wrapper class around a pointer that overloads operators like * and ->. Smart pointer objects resemble normal pointers, they have the added functionality of automatically deallocating and freeing the memory of the object when it is no longer needed, unlike regular pointers.\n\nUnderstanding the differences between pointers and references in C++. Both are used to refer to other variables, but they operate in different ways and have different behavior.\n\nPointers are a useful concept in C++ that allow direct access to memory addresses, providing greater control over memory and data manipulation. Below are some primary uses of pointers in C++:\n• Dynamic Memory Allocation: Pointers allow memory to be allocated dynamically at runtime using operators like new and delete. This enables the creation of objects or arrays whose sizes are determined during execution.\n• Implementing Data Structures: Pointers are used to implementing complex data structures such as linked lists, trees, and graphs, where elements are dynamically allocated and linked together.\n• Pass Arguments by Pointer: Pass the argument with their address and make changes in their value using pointer. So that the values get changed into the original argument.\n\nWhy are pointers important in C++?\n\nWhat is the size of a pointer in C++?\n\nWhy the type of the pointer is needed when all the pointers are of same size?\n\nWhat is a dangling pointer in C++?"
    },
    {
        "link": "https://programiz.com/cpp-programming/memory-management",
        "document": "C++ allows us to allocate the memory dynamically in run time. This is known as dynamic memory allocation.\n\nIn other programming languages such as Java and Python, the compiler automatically manages the memories allocated to variables. But this is not the case in C++.\n\nIn C++, we need to deallocate the dynamically allocated memory manually after we have no use for the variable.\n\nWe can allocate and then deallocate memory dynamically using the and operators respectively.\n\nWe can use the expression to allocate memory in run time. For example,\n\nHere, we have dynamically allocated memory for an variable using the expression.\n\nNotice that we have used the pointer to allocate the memory dynamically. This is because the expression returns the address of the memory location.\n\nWe can also allocate memory and initialize the value in the same step as:\n\nUsing this syntax avoids uninitialized pointers. Uninitialized pointers may cause undefined behavior when dereferenced. So this is the preferred syntax.\n\nThe syntax for using the expression is:\n\nOnce we no longer need to use a variable that we have declared dynamically, we can deallocate the memory occupied by the variable.\n\nFor this, we can use the expression. It returns the memory back to the operating system. This is known as memory deallocation.\n\nThe syntax for expression is:\n\nLet's look at an example.\n\nHere, we have dynamically allocated memory for an variable using the pointer .\n\nAfter printing the contents of , we deallocated the memory using .\n\nIt is a good practice to set pointer to after deallocating the memory to avoid undefined behavior if the pointer is dereferenced.\n\nNote: Not deallocating memory properly can cause memory leaks which in turn causes the program to consume a large amount of memory. Proper use of the expression is essential to prevent memory leaks and ensure efficient memory management.\n\nIn this program, we dynamically allocated memory to two variables of and types.\n\nAfter assigning values to them and printing them, we finally deallocate the memories using the expression.\n\nExample 2: C++ new and delete Expression for Arrays\n\nIn this program, we have asked the user to enter the number of students and store it in the variable.\n\nThen, we have allocated the memory dynamically for the array using .\n\nWe enter data into the array (and later print them) using pointer notation.\n\nAfter we no longer needed the array, we deallocated the array memory using the code:\n\nNotice the use of after . We use the square brackets in order to denote that the memory deallocation is that of an array.\n\nExample 3: C++ new and delete Expression for Objects\n\nIn this program, we have created a class that has a private variable .\n\nWe have initialized to in the default constructor and printed its value with the function .\n\nIn , we have created a object using the expression and use the pointer to point to its address.\n\nThe moment the object is created, the constructor initializes to .\n\nWe then call the function using the code:\n\nNotice the arrow operator . This operator is used to access class members using pointers.\n\nDynamic memory allocation has several advantages, such as:\n• Flexibility: Dynamic memory allocation allows us to allocate memory as needed during runtime. This flexibility is useful when the size of data structures is not known at compile time or when the size changes during program execution.\n• Data Structures: Data structures such as linked lists, trees, graphs, and resizable arrays (vectors in C++) often need to allocate memory dynamically to accommodate varying amounts of data.\n• Resource Management: We can allocate memory when needed and deallocate it when it's no longer required. This leads to better resource utilization.\n• Dynamic Arrays: In languages like C++, static arrays have fixed sizes determined at compile time. Dynamic memory allocation allows us to create arrays whose size can be determined during runtime."
    },
    {
        "link": "https://stackoverflow.com/questions/4719853/c-memory-management-of-reference-types",
        "document": "Sounds like you are approaching C++ from a managed language like C#. Things are a bit different in C++.\n\nWhat you describe as reference types does not exist in C++. Types in C++ are not 'reference types', nor are they 'value types'. They are just 'types'. Whether they are handled via references (or pointers) or by value depends entirely on the code that uses the type (not the definition of the type). By contrast, in languages like C#, the type declarer decides whether the type must be handled as reference or a value. C++ does have something called a reference but it has nothing to do with the things you describe. I'll mention C++ references at the end.\n\nNow, let's see if we can process the several parts of your question:\n\nMaybe. That would be true if you create the object like this, for example:\n\nBut not if you create the object like this:\n\nIn the latter, the object is allocated in the stack and there is no pointer or reference involved. You are manipulating it as a 'value type'.\n\nNow is a pointer (in the stack) to , which is also in the stack. See? No connection between the class definition and where objects of that class are stored. It depends on how you use the type. It's pretty common to have a combination of both stack and heap based objects of the same type.\n\nNo; arrays are just a set of objects of the same type/size placed in consecutive memory locations. The array can be allocated in the stack or in the heap, just like with individual objects.\n\nC and C++ don't place any distinct semantic on arrays (with one exception I'll mention in a second). Once they are allocated, they are just a bunch of objects that happen to be consecutive. It's up to your program to use array operations or direct pointer operations to access the individual members. That means:\n• is exactly identical to saying . In C, you can even say to and it means the same as (C++ however will complain because it has stricter type rules).\n• You can use array operators in pointers to objects that are not part of an array (and likely crash)\n• You can use ordinary pointer operations on elements on an array.\n• You can allocate a 'large' chunk of memory and 'make your own array' by interpreting smaller consecutive pieces of that memory as if they are members of an array of smaller objects (that's exactly what you get when you use malloc()).\n\nArrays are not types on their own right; they are just a convenient way to allocate multiple objects, and a way to do pointers that is more convenient in some circumstances.\n\nThe only exception that comes to my mind to this \"arrays are not special\" rule is the case arrays allocated in C++ via . When you allocate an array via , it leaves information (usually in the heap adjacent to the array, but that is not mandatory) about how many elements the array contained when it was allocated. Then, you must use the special operator to delete the array. finds and uses that extra bit of information to delete all of the elements of the array correctly.\n\nAs long as you do things correctly, yes.\n\nYes for , although using pointers to a different type when you call free() (other than a ) is a rather unusual thing to do. There are legitimate uses of such things, but they are advanced topics. You might want to have your designed looked at by an experienced developer to see if it really is an appropriate thing to do.\n\nis a different matter; if you use a pointer to a type different from what's stored in the buffer at the time you call delete, the behavior is \"undefined\" (a.k.a. you'll likely crash). That's because does more than what does; it also calls the object's destructor method, and the compiler relies on the type of the pointer to call the proper method. If you use the wrong pointer type, the wrong method will be called and who knows what will happen. You can potentially put something \"else\" in the buffer after you 'd it, but that might requires a non-trivial amount of work and is again an advanced topic.\n\nAlso note that you should never allocate with and free with , nor should you allocate with and free with . Make sure your methods are properly paired.\n\nIn C++, the canonical way to deal with that is that the class should have a destructor, and the destructor would take care of freeing the pointer member. In C you don't have a choice and you have to clear the pointer member by hand before clearing the outside pointer.\n\nThat all assumes that the object owns the contents pointed by the member pointer. In managed languages like C#, all objects are 'owned' by the runtime and deleted under control of the garbage collector, so you don't have to worry about it. In C++. who 'owns' objects pointed by member pointes is defined by the semantics of your program, not the language, and you have to pay attention to decide when is the right time to delete embedded objects. If you miss the right time to delete the object, you leak memory; if you delete it too soon, you get undefined behavior and crashes (when some code tries to use the object that has already been deleted).\n\nNow, a C++ reference is basically just a pointer with a bit of sugar-coating, intended to make certain kind of pointers easier to use. In in priciple, there is almost nothing that you can do with references that you cannot do in C++ by just using pointers; the few exceptions are advanced topics that I'll skip (I would have to look it up to give the topic justice and I don't have my resources at hand).\n\nFor your point of view a C++ reference is just a pointer that looks like a stack object.\n\nGiven your level of knowledge in C++ I might stay away from references for now, until you come to understand memory management in C/C++ a little better."
    },
    {
        "link": "https://cplusplus.com/forum/beginner/284953",
        "document": "Use the stack -- don't use new to get heap memory -- and the program will (quickly) run out of stack space and segfault.Use the heap -- AKA the freestore -- and you will have more memory possible to allocate. Though your OS isn't likely to allow your program to access all of your RAM, it should restrict the amount available for use for the process.How your OS handles a program gobbling up all the heap initially allocated to the process depends on the OS.Modern OSes are good at managing memory, programs when terminated free up the memory associated with the process.With that said, not having delete with each new is very poor programming. It pays to be neat.The C++ stdlib containers and smart pointers do the grunt work of managing memory for you so you don't have to worry about the details.Personally I would use one of the C++ stdlib containers instead of creating a custom container.If none of the container matched exactly what my requirement were I'd adapt one of the available containers to my needs.Instead of raw pointers using heap memory I'd use a smart pointer.If I were to use a C++ stdlib container there is no need to have a data member be a pointer, the containers automatically use heap memory for allocating the elements.But if I had a lot of -> access-a-data-member logic all over my code I'd go with a smart pointer.Though I'd design the code basics on paper before actually writing it so using a C++ container or smart pointer would already be baked into the design."
    },
    {
        "link": "https://stackoverflow.com/questions/28767839/memory-management-for-linked-list-and-tree-programs-in-c",
        "document": "I solve algoritm questions from sites like leetcode, hacker rank or cracking the coding interview. I do most if the questions in c++. So for most of them i have a node struct as below\n\nthen i have a function(s) which implements the algorithm\n\nand finally i create the nodes in the main\n\nI want to incorporate memory management in this kind of solutions. If i use c++11 shared_ptr do i need to provide a destructor ? if yes what should i write in the destructor ? But i found that shared_ptr makes code overly complex and un-understandbale for such small programs.\n\nIn general what is the best way to make solving such questions memory safe ?"
    }
]