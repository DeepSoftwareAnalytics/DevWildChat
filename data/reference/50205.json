[
    {
        "link": "https://docs.python.org/2/library/subprocess.html",
        "document": "The module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. This module intends to replace several older modules and functions:\n\nInformation about how this module can be used to replace the older functions can be found in the subprocess-replacements section.\n\nThe recommended way to launch subprocesses is to use the following convenience functions. For more advanced use cases when these do not meet your needs, use the underlying interface. Run the command described by args. Wait for command to complete, then return the attribute. The arguments shown above are merely the most common ones, described below in Frequently Used Arguments (hence the slightly odd notation in the abbreviated signature). The full function signature is the same as that of the constructor - this functions passes all supplied arguments directly through to that interface. Using can be a security hazard. See the warning under Frequently Used Arguments for details. Do not use or with this function as that can deadlock based on the child process output volume. Use with the method when you need pipes. Run command with arguments. Wait for command to complete. If the return code was zero then return, otherwise raise . The object will have the return code in the attribute. The arguments shown above are merely the most common ones, described below in Frequently Used Arguments (hence the slightly odd notation in the abbreviated signature). The full function signature is the same as that of the constructor - this functions passes all supplied arguments directly through to that interface. Using can be a security hazard. See the warning under Frequently Used Arguments for details. Do not use or with this function as that can deadlock based on the child process output volume. Use with the method when you need pipes. Run command with arguments and return its output as a byte string. If the return code was non-zero it raises a . The object will have the return code in the attribute and any output in the attribute. The arguments shown above are merely the most common ones, described below in Frequently Used Arguments (hence the slightly odd notation in the abbreviated signature). The full function signature is largely the same as that of the constructor, except that stdout is not permitted as it is used internally. All other supplied arguments are passed directly through to the constructor. To also capture standard error in the result, use : 'ls: non_existent_file: No such file or directory\n\n' Using can be a security hazard. See the warning under Frequently Used Arguments for details. Do not use with this function as that can deadlock based on the child process error volume. Use with the method when you need a stderr pipe. Special value that can be used as the stdin, stdout or stderr argument to and indicates that a pipe to the standard stream should be opened. Special value that can be used as the stderr argument to and indicates that standard error should go into the same handle as standard output. Exception raised when a process run by or returns a non-zero exit status. Command that was used to spawn the child process. Output of the child process if this exception is raised by . Otherwise, . To support a wide variety of use cases, the constructor (and the convenience functions) accept a large number of optional arguments. For most typical use cases, many of these arguments can be safely left at their default values. The arguments that are most commonly needed are: args is required for all calls and should be a string, or a sequence of program arguments. Providing a sequence of arguments is generally preferred, as it allows the module to take care of any required escaping and quoting of arguments (e.g. to permit spaces in file names). If passing a single string, either shell must be (see below) or else the string must simply name the program to be executed without specifying any arguments. stdin, stdout and stderr specify the executed program’s standard input, standard output and standard error file handles, respectively. Valid values are , an existing file descriptor (a positive integer), an existing file object, and . indicates that a new pipe to the child should be created. With the default settings of , no redirection will occur; the child’s file handles will be inherited from the parent. Additionally, stderr can be , which indicates that the stderr data from the child process should be captured into the same file handle as for stdout. When stdout or stderr are pipes and universal_newlines is then all line endings will be converted to as described for the universal newlines mode argument to . If shell is , the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of to a user’s home directory. However, note that Python itself offers implementations of many shell-like features (in particular, , , , , , and ). Executing shell commands that incorporate unsanitized input from an untrusted source makes a program vulnerable to shell injection, a serious security flaw which can result in arbitrary command execution. For this reason, the use of is strongly discouraged in cases where the command string is constructed from external input: \"What file would you like to display? What file would you like to display? disables all shell based features, but does not suffer from this vulnerability; see the Note in the constructor documentation for helpful hints in getting to work. When using , can be used to properly escape whitespace and shell metacharacters in strings that are going to be used to construct shell commands. These options, along with all of the other options, are described in more detail in the constructor documentation. The underlying process creation and management in this module is handled by the class. It offers a lot of flexibility so that developers are able to handle the less common cases not covered by the convenience functions. Execute a child program in a new process. On Unix, the class uses -like behavior to execute the child program. On Windows, the class uses the Windows function. The arguments to are as follows. args should be a sequence of program arguments or else a single string. By default, the program to execute is the first item in args if args is a sequence. If args is a string, the interpretation is platform-dependent and described below. See the shell and executable arguments for additional differences from the default behavior. Unless otherwise stated, it is recommended to pass args as a sequence. On Unix, if args is a string, the string is interpreted as the name or path of the program to execute. However, this can only be done if not passing arguments to the program. can be useful when determining the correct tokenization for args, especially in complex cases: Note in particular that options (such as -input) and arguments (such as eggs.txt) that are separated by whitespace in the shell go in separate list elements, while arguments that need quoting or backslash escaping when used in the shell (such as filenames containing spaces or the echo command shown above) are single list elements. On Windows, if args is a sequence, it will be converted to a string in a manner described in Converting an argument sequence to a string on Windows. This is because the underlying operates on strings. The shell argument (which defaults to ) specifies whether to use the shell as the program to execute. If shell is , it is recommended to pass args as a string rather than as a sequence. On Unix with , the shell defaults to . If args is a string, the string specifies the command to execute through the shell. This means that the string must be formatted exactly as it would be when typed at the shell prompt. This includes, for example, quoting or backslash escaping filenames with spaces in them. If args is a sequence, the first item specifies the command string, and any additional items will be treated as additional arguments to the shell itself. That is to say, does the equivalent of: On Windows with , the environment variable specifies the default shell. The only time you need to specify on Windows is when the command you wish to execute is built into the shell (e.g. dir or copy). You do not need to run a batch file or console-based executable. Passing can be a security hazard if combined with untrusted input. See the warning under Frequently Used Arguments for details. bufsize, if given, has the same meaning as the corresponding argument to the built-in open() function: means unbuffered, means line buffered, any other positive value means use a buffer of (approximately) that size. A negative bufsize means to use the system default, which usually means fully buffered. The default value for bufsize is (unbuffered). If you experience performance issues, it is recommended that you try to enable buffering by setting bufsize to either -1 or a large enough positive value (such as 4096). The executable argument specifies a replacement program to execute. It is very seldom needed. When , executable replaces the program to execute specified by args. However, the original args is still passed to the program. Most programs treat the program specified by args as the command name, which can then be different from the program actually executed. On Unix, the args name becomes the display name for the executable in utilities such as ps. If , on Unix the executable argument specifies a replacement shell for the default . stdin, stdout and stderr specify the executed program’s standard input, standard output and standard error file handles, respectively. Valid values are , an existing file descriptor (a positive integer), an existing file object, and . indicates that a new pipe to the child should be created. With the default settings of , no redirection will occur; the child’s file handles will be inherited from the parent. Additionally, stderr can be , which indicates that the stderr data from the child process should be captured into the same file handle as for stdout. If preexec_fn is set to a callable object, this object will be called in the child process just before the child is executed. (Unix only) If close_fds is true, all file descriptors except , and will be closed before the child process is executed. (Unix only). Or, on Windows, if close_fds is true then no handles will be inherited by the child process. Note that on Windows, you cannot set close_fds to true and also redirect the standard handles by setting stdin, stdout or stderr. If cwd is not , the child’s current directory will be changed to cwd before it is executed. Note that this directory is not considered when searching the executable, so you can’t specify the program’s path relative to cwd. If env is not , it must be a mapping that defines the environment variables for the new process; these are used instead of inheriting the current process’ environment, which is the default behavior. If specified, env must provide any variables required for the program to execute. On Windows, in order to run a side-by-side assembly the specified env must include a valid . If universal_newlines is , the file objects stdout and stderr are opened as text files in universal newlines mode. Lines may be terminated by any of , the Unix end-of-line convention, , the old Macintosh convention or , the Windows convention. All of these external representations are seen as by the Python program. This feature is only available if Python is built with universal newline support (the default). Also, the newlines attribute of the file objects , and are not updated by the communicate() method. If given, startupinfo will be a object, which is passed to the underlying function. creationflags, if given, can be or . (Windows only) Exceptions raised in the child process, before the new program has started to execute, will be re-raised in the parent. Additionally, the exception object will have one extra attribute called , which is a string containing traceback information from the child’s point of view. The most common exception raised is . This occurs, for example, when trying to execute a non-existent file. Applications should prepare for exceptions. A will be raised if is called with invalid arguments. and will raise if the called process returns a non-zero return code. Unlike some other popen functions, this implementation will never call a system shell implicitly. This means that all characters, including shell metacharacters, can safely be passed to child processes. Obviously, if the shell is invoked explicitly, then it is the application’s responsibility to ensure that all whitespace and metacharacters are quoted appropriately.\n\nInstances of the class have the following methods: Check if child process has terminated. Set and return attribute. Wait for child process to terminate. Set and return attribute. This will deadlock when using and/or and the child process generates enough output to a pipe such that it blocks waiting for the OS pipe buffer to accept more data. Use to avoid that. Interact with process: Send data to stdin. Read data from stdout and stderr, until end-of-file is reached. Wait for process to terminate. The optional input argument should be a string to be sent to the child process, or , if no data should be sent to the child. Note that if you want to send data to the process’s stdin, you need to create the Popen object with . Similarly, to get anything other than in the result tuple, you need to give and/or too. The data read is buffered in memory, so do not use this method if the data size is large or unlimited. Sends the signal signal to the child. On Windows, SIGTERM is an alias for . CTRL_C_EVENT and CTRL_BREAK_EVENT can be sent to processes started with a creationflags parameter which includes . Stop the child. On Posix OSs the method sends SIGTERM to the child. On Windows the Win32 API function is called to stop the child. Kills the child. On Posix OSs the function sends SIGKILL to the child. On Windows is an alias for . The following attributes are also available: Use rather than , or to avoid deadlocks due to any of the other OS pipe buffers filling up and blocking the child process. If the stdin argument was , this attribute is a file object that provides input to the child process. Otherwise, it is . If the stdout argument was , this attribute is a file object that provides output from the child process. Otherwise, it is . If the stderr argument was , this attribute is a file object that provides error output from the child process. Otherwise, it is . The process ID of the child process. Note that if you set the shell argument to , this is the process ID of the spawned shell. The child return code, set by and (and indirectly by ). A value indicates that the process hasn’t terminated yet. A negative value indicates that the child was terminated by signal (Unix only).\n\nIn this section, “a becomes b” means that b can be used as a replacement for a. All “a” functions in this section fail (more or less) silently if the executed program cannot be found; the “b” replacements raise instead. In addition, the replacements using will fail with a if the requested operation produces a non-zero return code. The output is still available as the attribute of the raised exception. In the following examples, we assume that the relevant functions have already been imported from the module. # Allow p1 to receive a SIGPIPE if p2 exits. The p1.stdout.close() call after starting the p2 is important in order for p1 to receive a SIGPIPE if p2 exits before p1. Alternatively, for trusted input, the shell’s own pipeline support may still be used directly:\n• None Calling the program through the shell is usually not required. A more realistic example would look like this: On Unix, os.popen2, os.popen3 and os.popen4 also accept a sequence as the command to execute, in which case arguments will be passed directly to the program without shell intervention. This usage can be replaced as follows: On Unix, popen2 also accepts a sequence as the command to execute, in which case arguments will be passed directly to the program without shell intervention. This usage can be replaced as follows: and basically work as , except that:\n• None raises an exception if the execution fails.\n• None the capturestderr argument is replaced with the stderr argument.\n• None and must be specified.\n• None popen2 closes all file descriptors by default, but you have to specify with ."
    },
    {
        "link": "https://datacamp.com/tutorial/python-subprocess",
        "document": "Let's now take a look at some Python subprocess examples.\n\nThe method is a convenient way to run a subprocess and wait for it to complete. It lets you choose the command to run and add options like arguments, environment variables, and input/output redirections. Once the subprocess is started, the method blocks until the subprocess completes and returns a object, which contains the return code and output of the subprocess.\n\nThe method takes several arguments, some of which are:\n• : The command to run and its arguments, passed as a list of strings.\n• : When set to True, will capture the standard output and standard error.\n• : When set to True, will return the stdout and stderr as string, otherwise as bytes.\n• : a boolean value that indicates whether to check the return code of the subprocess, if check is true and the return code is non-zero, then subprocess is raised.\n• : A value in seconds that specifies how long to wait for the subprocess to complete before timing out.\n• : A boolean value that indicates whether to run the command in a shell. This means that the command is passed as a string, and shell-specific features, such as wildcard expansion and variable substitution, can be used.\n\nThe method also returns a object, which contains the following attributes:\n• : The command and arguments that were run.\n• : The return code of the subprocess.\n• : The standard output of the subprocess, as a bytes object.\n• : The standard error of the subprocess, as a bytes object.\n\nLinux or mac users replace to and get rid of the argument.\n\nYou can also run a python script using the method. Let’s start by creating a simple Python script in file\n\nSave this file as . Now, you can use the module to run this file:\n\nFor simple use-cases, you can directly pass a python command in the function. Here is how:\n\nIn the list, the first element is a path to executable Python (your path may be different). The second element, is a Python tag that allows the user to write Python code as text to the command line. The third element, , is the Python command itself.\n\nExample 4: Using the check argument\n\nThe check argument is an optional argument of the function in the Python subprocess module. It is a boolean value that controls whether the function should check the return code of the command being run.\n\nWhen check is set to , the function will check the return code of the command and raise a exception if the return code is non-zero. The exception will have the return code, , , and as attributes.\n\nWhen check is set to (default), the function will not check the return code and will not raise an exception, even if the command fails.\n\nNotice that the command failed because does not exist. As opposed to when you set , your process won’t fail; instead, you will get the error message in .\n\nis a lower-level interface to running subprocesses, while is a higher-level wrapper around that is intended to be more convenient to use.\n\nallows you to start a new process and interact with its standard input, output, and error streams. It returns a handle to the running process that can be used to wait for the process to complete, check its return code, or terminate it.\n\nis a more convenient function that allows you to run a command and capture its output in a single call, without having to create a object and manage the streams yourself. It also allows you to specify various options for running the command, such as whether to raise an exception if the command fails.\n\nIn general, you should use if you just need to run a command and capture its output and if you need more control over the process, such as interacting with its input and output streams.\n\nThe class takes the same arguments as , including the args that specify the command to be run and other optional arguments such as , , , , , and . Also, the class has several methods that allow you to interact with the process, such as , , , , and .\n\nThis will run the command and create a new object, which is stored in the variable . The standard output and error of the command are captured using the method and stored in the variables output and errors, respectively.\n\nis useful when you want more control over the process, such as sending input to it, receiving output from it, or waiting for it to complete.\n\nis a function in the Python subprocess module that is used to run a command in a separate process and wait for it to complete. It returns the return code of the command, which is zero if the command was successful, and non-zero if it failed.\n\nThe function takes the same arguments as , including the args which specify the command to be run, and other optional arguments, such as , , , , , and .\n\nThe standard output and error of the command are sent to the same and as the parent process unless you redirect them using and arguments.\n\nThis will run the command in a separate process and wait for it to complete. The command's return code will be stored in the variable, which will be zero if the command was successful, and non-zero if it failed.\n\nis useful when you want to run a command and check the return code, but do not need to capture the output.\n\nis a function in the subprocess module that is similar to , but it only returns the standard output of the command, and raises a exception if the return code is non-zero.\n\nThe function takes the same arguments as , including the args which specify the command to be run, and other optional arguments, such as , , , , and .\n\nThe function returns the standard output of the command as a bytes object or string, if is passed.\n\nPython subprocess module provides a way to create and interact with child processes, which can be used to run other programs or commands. One of the features of the subprocess module is the ability to create pipes, which allow communication between the parent and child processes.\n\nA pipe is a unidirectional communication channel that connects one process's standard output to another's standard input. A pipe can connect the output of one command to the input of another, allowing the output of the first command to be used as input to the second command.\n\nPipes can be created using the subprocess module with the Popen class by specifying the stdout or stdin argument as .\n\nFor example, the following code creates a pipe that connects the output of the ls command to the input of the grep command, which filters the output to show only the lines that contain the word :\n\nIn this example, the class is used to create two child processes, one for the ls command and one for the grep command. The stdout of the ls command is connected to the stdin of the grep command using , which creates a pipe between the two processes. The method is used to send the output of the command to the command and retrieve the filtered output.\n\nThe Python module provides a powerful and flexible way to create and interact with child processes, allowing you to run other programs or issue commands from within your Python script. From simple commands like to more advanced features like pipes, redirecting input and output, and passing environment variables, the subprocess module has something to offer for almost every use case. It is a great way to automate repetitive tasks, run system commands, and even interact with other programming languages and platforms.\n\nWhile working with the subprocess module, it's important to remember that running external commands poses a security risk, especially when using the parameter or passing unsanitized input. It's always a good practice to use the function that allows you to specify various options for how the command should be run, such as whether to raise an exception if the command fails.\n\nIf you are interested in doing a deep dive into endless possibilities for command line automation through Python, check out our Command Line Automation in Python course. In this course, you will learn to write an automation code that will browse a filesystem, look for files that follow a pattern, and then determine whether files are duplicates in one of the numerous cases. After finishing the course, you'll be able to manage and interact with Unix processes as well as automate a variety of routine file system activities.\n\nBoost Your Team’s Python Skills with DataCamp for Business\n\nIf you or your team is looking to enhance your skills in Python and command line automation, consider exploring DataCamp for Business. DataCamp offers tailored learning solutions for teams of all sizes, helping businesses stay ahead in the rapidly evolving tech landscape. With DataCamp for Business, you can upskill your team with courses and custom learning tracks designed to build expertise in Python, automation, and other essential data science tools. Whether you're a startup or an enterprise, DataCamp for Business provides the resources and flexibility to achieve your team's learning goals. Request a demo today to learn more."
    },
    {
        "link": "https://docs.python.org/3/library/subprocess.html",
        "document": "The module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. This module intends to replace several older modules and functions:\n\nInformation about how the module can be used to replace these modules and functions can be found in the following sections.\n\nInstances of the class have the following methods: Check if child process has terminated. Set and return attribute. Otherwise, returns . Wait for child process to terminate. Set and return attribute. If the process does not terminate after timeout seconds, raise a exception. It is safe to catch this exception and retry the wait. This will deadlock when using or and the child process generates enough output to a pipe such that it blocks waiting for the OS pipe buffer to accept more data. Use when using pipes to avoid that. When the parameter is not , then (on POSIX) the function is implemented using a busy loop (non-blocking call and short sleeps). Use the module for an asynchronous wait: see . Interact with process: Send data to stdin. Read data from stdout and stderr, until end-of-file is reached. Wait for process to terminate and set the attribute. The optional input argument should be data to be sent to the child process, or , if no data should be sent to the child. If streams were opened in text mode, input must be a string. Otherwise, it must be bytes. returns a tuple . The data will be strings if streams were opened in text mode; otherwise, bytes. Note that if you want to send data to the process’s stdin, you need to create the Popen object with . Similarly, to get anything other than in the result tuple, you need to give and/or too. If the process does not terminate after timeout seconds, a exception will be raised. Catching this exception and retrying communication will not lose any output. The child process is not killed if the timeout expires, so in order to cleanup properly a well-behaved application should kill the child process and finish communication: The data read is buffered in memory, so do not use this method if the data size is large or unlimited. Sends the signal signal to the child. Do nothing if the process completed. On Windows, SIGTERM is an alias for . CTRL_C_EVENT and CTRL_BREAK_EVENT can be sent to processes started with a creationflags parameter which includes . Stop the child. On POSIX OSs the method sends to the child. On Windows the Win32 API function is called to stop the child. Kills the child. On POSIX OSs the function sends SIGKILL to the child. On Windows is an alias for . The following attributes are also set by the class for you to access. Reassigning them to new values is unsupported: The args argument as it was passed to – a sequence of program arguments or else a single string. If the stdin argument was , this attribute is a writeable stream object as returned by . If the encoding or errors arguments were specified or the text or universal_newlines argument was , the stream is a text stream, otherwise it is a byte stream. If the stdin argument was not , this attribute is . If the stdout argument was , this attribute is a readable stream object as returned by . Reading from the stream provides output from the child process. If the encoding or errors arguments were specified or the text or universal_newlines argument was , the stream is a text stream, otherwise it is a byte stream. If the stdout argument was not , this attribute is . If the stderr argument was , this attribute is a readable stream object as returned by . Reading from the stream provides error output from the child process. If the encoding or errors arguments were specified or the text or universal_newlines argument was , the stream is a text stream, otherwise it is a byte stream. If the stderr argument was not , this attribute is . Use rather than , or to avoid deadlocks due to any of the other OS pipe buffers filling up and blocking the child process. The process ID of the child process. Note that if you set the shell argument to , this is the process ID of the spawned shell. The child return code. Initially , is set by a call to the , , or methods if they detect that the process has terminated. A value indicates that the process hadn’t yet terminated at the time of the last method call. A negative value indicates that the child was terminated by signal (POSIX only).\n\nThe class and following constants are only available on Windows. Partial support of the Windows STARTUPINFO structure is used for creation. The following attributes can be set by passing them as keyword-only arguments. A bit field that determines whether certain attributes are used when the process creates a window. If specifies , this attribute is the standard input handle for the process. If is not specified, the default for standard input is the keyboard buffer. If specifies , this attribute is the standard output handle for the process. Otherwise, this attribute is ignored and the default for standard output is the console window’s buffer. If specifies , this attribute is the standard error handle for the process. Otherwise, this attribute is ignored and the default for standard error is the console window’s buffer. If specifies , this attribute can be any of the values that can be specified in the parameter for the ShowWindow function, except for . Otherwise, this attribute is ignored. is provided for this attribute. It is used when is called with . A dictionary of additional attributes for process creation as given in , see UpdateProcThreadAttribute. Sequence of handles that will be inherited. close_fds must be true if non-empty. The handles must be temporarily made inheritable by when passed to the constructor, else will be raised with Windows error (87). In a multithreaded process, use caution to avoid leaking handles that are marked inheritable when combining this feature with concurrent calls to other process creation functions that inherit all handles such as . This also applies to standard handle redirection, which temporarily creates inheritable handles. The module exposes the following constants. The standard input device. Initially, this is the console input buffer, . The standard output device. Initially, this is the active console screen buffer, . The standard error device. Initially, this is the active console screen buffer, . Hides the window. Another window will be activated. Specifies that the , , and attributes contain additional information. Specifies that the attribute contains additional information. A parameter to specify that the Working in Background mouse cursor will be displayed while a process is launching. This is the default behavior for GUI processes. A parameter to specify that the mouse cursor will not be changed when launching a process. The new process has a new console, instead of inheriting its parent’s console (the default). A parameter to specify that a new process group will be created. This flag is necessary for using on the subprocess. This flag is ignored if is specified. A parameter to specify that a new process will have an above average priority. A parameter to specify that a new process will have a below average priority. A parameter to specify that a new process will have a high priority. A parameter to specify that a new process will have an idle (lowest) priority. A parameter to specify that a new process will have a normal priority. (default) A parameter to specify that a new process will have realtime priority. You should almost never use REALTIME_PRIORITY_CLASS, because this interrupts system threads that manage mouse input, keyboard input, and background disk flushing. This class can be appropriate for applications that “talk” directly to hardware or that perform brief tasks that should have limited interruptions. A parameter to specify that a new process will not create a window. A parameter to specify that a new process will not inherit its parent’s console. This value cannot be used with CREATE_NEW_CONSOLE. A parameter to specify that a new process does not inherit the error mode of the calling process. Instead, the new process gets the default error mode. This feature is particularly useful for multithreaded shell applications that run with hard errors disabled. A parameter to specify that a new process is not associated with the job.\n\nPrior to Python 3.5, these three functions comprised the high level API to subprocess. You can now use in many cases, but lots of existing code calls these functions. Run the command described by args. Wait for command to complete, then return the attribute. Code needing to capture stdout or stderr should use instead: To suppress stdout or stderr, supply a value of . The arguments shown above are merely some common ones. The full function signature is the same as that of the constructor - this function passes all supplied arguments other than timeout directly through to that interface. Do not use or with this function. The child process will block if it generates enough output to a pipe to fill up the OS pipe buffer as the pipes are not being read from. Changed in version 3.12: Changed Windows shell search order for . The current directory and are replaced with and . As a result, dropping a malicious program named into a current directory no longer works. Run command with arguments. Wait for command to complete. If the return code was zero then return, otherwise raise . The object will have the return code in the attribute. If was unable to start the process it will propagate the exception that was raised. Code needing to capture stdout or stderr should use instead: To suppress stdout or stderr, supply a value of . The arguments shown above are merely some common ones. The full function signature is the same as that of the constructor - this function passes all supplied arguments other than timeout directly through to that interface. Do not use or with this function. The child process will block if it generates enough output to a pipe to fill up the OS pipe buffer as the pipes are not being read from. Changed in version 3.12: Changed Windows shell search order for . The current directory and are replaced with and . As a result, dropping a malicious program named into a current directory no longer works. Run command with arguments and return its output. If the return code was non-zero it raises a . The object will have the return code in the attribute and any output in the attribute. The arguments shown above are merely some common ones. The full function signature is largely the same as that of - most arguments are passed directly through to that interface. One API deviation from behavior exists: passing will behave the same as (or , depending on other arguments) rather than using the parent’s standard input file handle. By default, this function will return the data as encoded bytes. The actual encoding of the output data may depend on the command being invoked, so the decoding to text will often need to be handled at the application level. This behaviour may be overridden by setting text, encoding, errors, or universal_newlines to as described in Frequently Used Arguments and . To also capture standard error in the result, use : 'ls: non_existent_file: No such file or directory\n\n' Changed in version 3.4: Support for the input keyword argument was added. Changed in version 3.6: encoding and errors were added. See for details. Added in version 3.7: text was added as a more readable alias for universal_newlines. Changed in version 3.12: Changed Windows shell search order for . The current directory and are replaced with and . As a result, dropping a malicious program named into a current directory no longer works.\n\nIn this section, “a becomes b” means that b can be used as a replacement for a. All “a” functions in this section fail (more or less) silently if the executed program cannot be found; the “b” replacements raise instead. In addition, the replacements using will fail with a if the requested operation produces a non-zero return code. The output is still available as the attribute of the raised exception. In the following examples, we assume that the relevant functions have already been imported from the module. # Allow p1 to receive a SIGPIPE if p2 exits. The call after starting the p2 is important in order for p1 to receive a SIGPIPE if p2 exits before p1. Alternatively, for trusted input, the shell’s own pipeline support may still be used directly:\n• None Calling the program through the shell is usually not required.\n• None The return value is encoded differently to that of .\n• None The function ignores SIGINT and SIGQUIT signals while the command is running, but the caller must do this separately when using the module. A more realistic example would look like this: If the cmd argument to popen2 functions is a string, the command is executed through /bin/sh. If it is a list, the command is directly executed. and basically work as , except that:\n• None raises an exception if the execution fails.\n• None The capturestderr argument is replaced with the stderr argument.\n• None and must be specified.\n• None popen2 closes all file descriptors by default, but you have to specify with to guarantee this behavior on all platforms or past Python versions.\n\nConverting an argument sequence to a string on Windows¶ On Windows, an args sequence is converted to a string that can be parsed using the following rules (which correspond to the rules used by the MS C runtime):\n• None Arguments are delimited by white space, which is either a space or a tab.\n• None A string surrounded by double quotation marks is interpreted as a single argument, regardless of white space contained within. A quoted string can be embedded in an argument.\n• None A double quotation mark preceded by a backslash is interpreted as a literal double quotation mark.\n• None Backslashes are interpreted literally, unless they immediately precede a double quotation mark.\n• None If backslashes immediately precede a double quotation mark, every pair of backslashes is interpreted as a literal backslash. If the number of backslashes is odd, the last backslash escapes the next double quotation mark as described in rule 3. Module which provides function to parse and escape command lines. Disabling use of or ¶ On Linux, defaults to using the system call internally when it is safe to do so rather than . This greatly improves performance. If you ever encounter a presumed highly unusual situation where you need to prevent from being used by Python, you can set the attribute to a false value. Setting this has no impact on use of which could use internally within its libc implementation. There is a similar attribute if you need to prevent use of that. It is safe to set these to false on any Python version. They will have no effect on older versions when unsupported. Do not assume the attributes are available to read. Despite their names, a true value does not indicate that the corresponding function will be used, only that it may be. Please file issues any time you have to use these private knobs with a way to reproduce the issue you were seeing. Link to that issue from a comment in your code."
    },
    {
        "link": "https://realpython.com/python-subprocess",
        "document": "Python’s module allows you to run shell commands and manage external processes directly from your Python code. By using , you can execute shell commands like or , launch applications, and handle both input and output streams. This module provides tools for error handling and process communication, making it a flexible choice for integrating command-line operations into your Python projects.\n\nBy the end of this tutorial, you’ll understand that:\n• The Python module is used to run shell commands and manage external processes.\n• You run a shell command using by calling with the command as a list of arguments.\n• , , and differ in how they execute commands and handle process output and return codes.\n• is for parallel execution within Python, while manages external processes.\n• To execute multiple commands in sequence using , you can chain them by using pipes or running them consecutively.\n\nRead on to learn how to use Python’s module to automate shell tasks, manage processes, and integrate command-line operations into your applications.\n\nOnce you have the basics down, you’ll be exploring some practical ideas for how to leverage Python’s . You’ll also dip your toes into advanced usage of Python’s by experimenting with the underlying constructor.\n\nFirst off, you might be wondering why there’s a in the Python module name. And what exactly is a process, anyway? In this section, you’ll answer these questions. You’ll come away with a high-level mental model for thinking about processes. If you’re already familiar with processes, then you might want to skip directly to basic usage of the Python module. Whenever you use a computer, you’ll always be interacting with programs. A process is the operating system’s abstraction of a running program. So, using a computer always involve processes. Start menus, app bars, command-line interpreters, text editors, browsers, and more—every application comprises one or more processes. A typical operating system will report hundreds or even thousands of running processes, which you’ll get to explore shortly. However, central processing units (CPUs) typically only have a handful of cores, which means that they can only run a handful of instructions simultaneously. So, you may wonder how thousands of processes can appear to run at the same time. In short, the operating system is a marvelous multitasker—as it has to be. The CPU is the brain of a computer, but it operates at the nanosecond timescale. Most other components of a computer are far slower than the CPU. For instance, a magnetic hard disk read takes thousands of times longer than a typical CPU operation. If a process needs to write something to the hard drive, or wait for a response from a remote server, then the CPU would sit idle most of the time. Multitasking keeps the CPU busy. Part of what makes the operating system so great at multitasking is that it’s fantastically organized too. The operating system keeps track of processes in a process table or process control block. In this table, you’ll find the process’s file handles, security context, references to its address spaces, and more. The process table allows the operating system to abandon a particular process at will, because it has all the information it needs to come back and continue with the process at a later time. A process may be interrupted many thousands of times during execution, but the operating system always finds the exact point where it left off upon returning. An operating system doesn’t boot up with thousands of processes, though. Many of the processes you’re familiar with are started by you. In the next section, you’ll look into the lifetime of a process. Think of how you might start a Python application from the command line. This is an instance of your command-line process starting a Python process: The process that starts another process is referred to as the parent, and the new process is referred to as the child. The parent and child processes run mostly independently. Sometimes the child inherits specific resources or contexts from the parent. As you learned in Processes and the Operating System, information about processes is kept in a table. Each process keeps track of its parents, which allows the process hierarchy to be represented as a tree. You’ll be exploring your system’s process tree in the next section. Note: The precise mechanism for creating processes differs depending on the operating system. For a brief overview, the Wikipedia article on process management has a short section on process creation. For more details about the Windows mechanism, check out the win32 API documentation page on creating processes On UNIX-based systems, processes are typically created by using to copy the current process and then replacing the child process with one of the family of functions. The parent-child relationship between a process and its subprocess isn’t always the same. Sometimes the two processes will share specific resources, like inputs and outputs, but sometimes they won’t. Sometimes child processes live longer than the parent. A child outliving the parent can lead to orphaned or zombie processes, though more discussion about those is outside the scope of this tutorial. When a process has finished running, it’ll usually end. Every process, on exit, should return an integer. This integer is referred to as the return code or exit status. Zero is synonymous with success, while any other value is considered a failure. Different integers can be used to indicate the reason why a process has failed. In the same way that you can return a value from a function in Python, the operating system expects an integer return value from a process once it exits. This is why the canonical C function usually returns an integer: This example shows a minimal amount of C code necessary for the file to compile with without any warnings. It has a function that returns an integer. When this program runs, the operating system will interpret its execution as successful since it returns zero. So, what processes are running on your system right now? In the next section, you’ll explore some of the tools that you can use to take a peek at your system’s process tree. Being able to see what processes are running and how they’re structured will come in handy when visualizing how the module works. You may be curious to see what processes are running on your system right now. To do that, you can use platform-specific utilities to track them: There are many tools available for Windows, but one which is easy to get set up, is fast, and will show you the process tree without much effort is Process Hacker. You can install Process Hacker by going to the downloads page or with Chocolatey: Open the application, and you should immediately see the process tree. One of the native commands that you can use with PowerShell is , which lists the active processes on the command line. is a command prompt utility that does the same. The official Microsoft version of Process Hacker is part of the Sysinternals utilities, namely Process Monitor and Process Explorer. You also get PsList, which is a command-line utility similar to on UNIX. You can install Sysinternals by going to the downloads page or by using Chocolatey: You can also use the more basic, but classic, Task Manager—accessible by pressing + and selecting the Task Manager. For UNIX-based systems, there are many command-line utilities to choose from:\n• : The classic process and resource monitor, often installed by default. Once it’s running, to see the tree view, also called the forest view, press . The forest view may not work on the default macOS .\n• : More advanced and user-friendly version of .\n• : Another version of with more information, but more technical. On macOS, you also have the Activity Monitor application in your utilities. In the View menu, if you select All Processes, Hierarchically, you should be able to see your process tree. You can also explore the Python psutil library, which allows you to retrieve running process information on both Windows and UNIX-based systems. One universal attribute of process tracking across systems is that each process has a process identification number, or PID, which is a unique integer to identify the process within the context of the operating system. You’ll see this number on most of the utilities listed above. Along with the PID, it’s typical to see the resource usage, such as CPU percentage and amount of RAM that a particular process is using. This is the information that you look for if a program is hogging all your resources. The resource utilization of processes can be useful for developing or debugging scripts that use the module, even though you don’t need the PID, or any information about what resources processes are using in the code itself. While playing with the examples that are coming up, consider leaving a representation of the process tree open to see the new processes pop up. You now have a bird’s-eye view of processes. You’ll deepen your mental model throughout the tutorial, but now it’s time to see how to start your own processes with the Python module.\n\nIn this section, you’ll take a look at some of the most basic examples demonstrating the usage of the module. You’ll start by exploring a bare-bones command-line timer program with the function. If you want to follow along with the examples, then create a new folder. All the examples and programs can be saved in this folder. Navigate to this newly created folder on the command line in preparation for the examples coming up. All the code in this tutorial is standard library Python—with no external dependencies required—so a virtual environment isn’t necessary. To come to grips with the Python module, you’ll want a bare-bones program to run and experiment with. For this, you’ll use a program written in Python: The timer program uses to accept an integer as an argument. The integer represents the number of seconds that the timer should wait until exiting, which the program uses to achieve. It’ll play a small animation representing each passing second until it exits: It’s not much, but the key is that it serves as a cross-platform process that runs for a few seconds and which you can easily tinker with. You’ll be calling it with as if it were a separate executable. Note: Calling Python programs with the Python module doesn’t make much sense—there’s usually no need for other Python modules to be in separate processes since you can just import them. The main reason you’ll be using Python programs for most of the examples in this tutorial is that they’re cross-platform, and you most likely already have Python installed! You may be tempted to think that starting a new process could be a neat way to achieve concurrency, but that’s not the intended use case for the module. Maybe what you need are other Python modules dedicated to concurrency, covered in a later section. The module is mainly for calling programs other than Python. But, as you can see, you can call Python too if you want! For more discussion on the use cases of , check out the section where this is discussed in more depth, or one of the later examples. Okay, ready to get stuck in! Once you have the program ready, open a Python interactive session and call the timer with : With this code, you should’ve seen the animation playing right in the REPL. You imported and then called the function with a list of strings as the one and only argument. This is the parameter of the function. On executing , the timer process starts, and you can see its output in real time. Once it’s done, it returns an instance of the class. On the command line, you might be used to starting a program with a single string: However, with you need to pass the command as a sequence, as shown in the example. Each item in the sequence represents a token which is used for a system call to start a new process. Note: Calling isn’t the same as calling programs on the command line. The function makes a system call, foregoing the need for a shell. You’ll cover interaction with the shell in a later section. Shells typically do their own tokenization, which is why you just write the commands as one long string on the command line. With the Python module, though, you have to break up the command into tokens manually. For instance, executable names, flags, and arguments will each be one token. Note: You can use the module to help you out if you need, just bear in mind that it’s designed for POSIX compliant systems and may not work well in Windows environments: The function divides a typical command into the different tokens needed. The module can come in handy when it may be not obvious how to divide up more complex commands that have special characters, like spaces: You’ll note that the message, which contains spaces, is preserved as a single token, and the extra quotation marks are no longer needed. The extra quotation marks on the shell serve to group the token together, but since uses sequences, it’s always unambiguous which parts should be interpreted as one token. Now that you’re familiar with some of the very basics of starting new processes with the Python module, coming up you’ll see that you can run any kind of process, not just Python or text-based programs. The Use of to Run Any App With , you aren’t limited to text-based applications like the shell. You can call any application that you can with the Start menu or app bar, as long as you know the precise name or path of the program that you want to run: Depending on your Linux distribution, you may have a different text editor, such as , , , or . These commands should open up a text editor window. Usually won’t get returned until you close the editor window. Yet in the case of macOS, since you need to run the launcher process to launch TextEdit, the gets returned straight away. Launcher processes are in charge of launching a specific process and then ending. Sometimes programs, such as web browsers, have them built in. The mechanics of launcher processes is out of the scope of this tutorial, but suffice to say that they’re able to manipulate the operating system’s process tree to reassign parent-child relationships. Note: There are many problems that you might initially reach for to solve, but then you’ll find a specific module or library that solves it for you. This tends to be a theme with since it is quite a low-level utility. An example of something that you might want to do with is to open a web browser to a specific page. However, for that, it’s probably best to use the Python module . The module uses under the hood but handles all the finicky cross-platform and browser differences that you might encounter. Then again, can be a remarkably useful tool to get something done quickly. If you don’t need a full-fledged library, then can be your Swiss Army knife. It all depends on your use case. More discussion on this topic will come later. You’ve successfully started new processes using Python! That’s at its most basic. Next up, you’ll take a closer look at the object that’s returned from . When you use , the return value is an instance of the class. As the name suggests, returns the object only once the child process has ended. It has various attributes that can be helpful, such as the that were used for the process and the . To see this clearly, you can assign the result of to a variable, and then access its attributes such as : timer.py: error: the following arguments are required: time The process has a return code that indicates failure, but it doesn’t raise an exception. Typically, when a process fails, you’ll always want an exception to be raised, which you can do by passing in a argument: timer.py: error: the following arguments are required: time : There are various ways to deal with failures, some of which will be covered in the next section. The important point to note for now is that won’t necessarily raise an exception if the process fails unless you’ve passed in a argument. The also has a few attributes relating to input/output (I/O), which you’ll cover in more detail in the communicating with processes section. Before communicating with processes, though, you’ll learn how to handle errors when coding with .\n\nIntroduction to the Shell and Text-Based Programs With Some of the most popular use cases of the module are to interact with text-based programs, typically available on the shell. That’s why in this section, you’ll start to explore all the moving parts involved when interacting with text-based programs, and perhaps question if you need the shell at all! The shell is typically synonymous with the command-line interface or CLI, but this terminology isn’t entirely accurate. There are actually two separate processes that make up the typical command-line experience:\n• The interpreter, which is typically thought of as the whole CLI. Common interpreters are Bash on Linux, Zsh on macOS, or PowerShell on Windows. In this tutorial, the interpreter will be referred to as the shell.\n• The interface, which displays the output of the interpreter in a window and sends user keystrokes to the interpreter. The interface is a separate process from the shell, sometimes called a terminal emulator. When on the command line, it’s common to think that you’re interacting directly with the shell, but you’re really interacting with the interface. The interface takes care of sending your commands to the shell and displaying the shell’s output back to you. With this important distinction in mind, it’s time to turn your attention to what is actually doing. It’s common to think that calling is somehow the same as typing a command in a terminal interface, but there are important differences. While all new process are created with the same system calls, the context from which the system call is made is different. The function can make a system call directly and doesn’t need to go through the shell to do so: In fact, many programs that are thought of as shell programs, such as Git, are really just text-based programs that don’t need a shell to run. This is especially true of UNIX environments, where all of the familiar utilities like , , , and are actually separate executables that can be called directly: There are some tools that are specific to shells, though. Finding tools embedded within the shell is far more common on Windows shells like PowerShell, where commands like are part of the shell itself and not separate executables like they are in a UNIX environment: : [WinError 2] The system cannot find the file specified In PowerShell, is the default alias for , but calling that won’t work either because isn’t a separate executable—it’s part of PowerShell itself. The fact that many text-based programs can operate independently from the shell may make you wonder if you can cut out the middle process—namely, the shell—and use directly with the text-based programs typically associated with the shell. Use Cases for the Shell and There are a few common reasons why you might want to call the shell with the subprocess module:\n• When you know certain commands are only available via the shell, which is more common in Windows\n• When you’re experienced in writing shell scripts with a particular shell, so you want to leverage your ability there to do certain tasks while still working primarily in Python\n• When you’ve inherited a large shell script that might do nothing that Python couldn’t do, but would take a long time to reimplement in Python You might use the shell to wrap programs or to do some text processing. However, the syntax can be very cryptic when compared to Python. With Python, text processing workflows are easier to write, easier to maintain, generally more performant, and cross-platform to boot. So it’s well worth considering going without the shell. What often happens, though, is that you just don’t have the time or it’s not worth the effort to reimplement existing shell scripts in Python. In those cases, using for some sloppy Python isn’t a bad thing! Common reasons for using itself are similar in nature to using the shell with :\n• When you have to use or analyze a black box, or even a white box\n• When you want a wrapper for an application\n• When you need to launch another application\n• As an alternative to basic shell scripts Note: A black box could be a program that can be freely used but whose source code isn’t available, so there’s no way to know exactly what it does and no way to modify its internals. Similarly, a white box could be a program whose source code is available but can’t be changed. It could also be a program whose source code you could change, but its complexity means that it would take you a long time to get your head around it to be able to change it. In these cases, you can use to wrap your boxes of varying opacity, bypassing any need to change or reimplement things in Python. Often you’ll find that for use cases, there will be a dedicated library for that task. Later in the tutorial, you’ll examine a script that creates a Python project, complete with a virtual environment and a fully initialized Git repository. However, the Cookiecutter and Copier libraries already exist for that purpose. Even though specific libraries might be able to do your task, it may still be worth doing things with . For one, it might be much faster for you to execute what you already know how to do, rather than learning a new library. Additionally, if you’re sharing this script with friends or colleagues, it’s convenient if your script is pure Python without any other dependencies, especially if your script needs to go on minimal environments like servers or embedded systems. However, if you’re using instead of to read and write a few files with Bash, you might want to consider learning how to read and write with Python. Learning how to read and write files doesn’t take long, and it’ll definitely be worth it for such a common task. With that out of the way, it’s time to get familiar with the shell environments on both Windows and UNIX-based systems. To run a shell command using , the should contain the shell that you want to use, the flag to indicate that you want it to run a specific command, and the command that you’re passing in: Here a common shell command is demonstrated. It uses piped into to filter some of the entries. The shell is handy for this kind of operation because you can take advantage of the pipe operator ( ). You’ll cover pipes in more detail later. You can replace with the shell of your choice. The flag stands for command, but may be different depending on the shell that you’re using. This is almost the exact equivalent of what happens when you add the argument: The argument uses behind the scenes, so it’s almost the equivalent of the previous example. Note: On UNIX-based systems, the shell was traditionally the Bourne shell. That said, the Bourne shell is now quite old, so many operating systems use as a link to Bash or Dash. This can often be different from the shell used with the terminal interface that you interact with. For instance, since macOS Catalina, the default shell that you’ll find on the command-line app has changed from Bash to Zsh, yet often still points to Bash. Likewise, on Ubuntu, points to Dash, but the default that you typically interact with on the command-line application is still Bash. So, calling on your system may result in a different shell than what is found in this tutorial. Nevertheless, the examples should all still work. You’ll note that the token after should be one single token, with all the spaces included. Here you’re giving control to the shell to parse the command. If you were to include more tokens, this would be interpreted as more options to pass to the shell executable, not as additional commands to run inside the shell. In this section, you’ll cover basic use of the shell with in a Windows environment. To run a shell command using , the should contain the shell that you want to use, the flag to indicate that you want it to run a specific command, and the command that you’re passing in: Note that and both work. If you don’t have PowerShell Core, then you can call or . You’ll note that the token after should be one single token, with all the spaces included. Here you’re giving control to the shell to parse the command. If you were to include more tokens, this would be interpreted as more options to pass to the shell executable, not as additional commands to run inside the shell. If you need the Command Prompt, then the executable is or , and the flag to indicate that the following token is a command is : Volume in drive C has no label. This last example is the exact equivalent of calling with . Said in another way, using the argument is like prepending and to your argument list. Note: Windows’ evolution has been very different from that of UNIX-based systems. The most widely known shell is the Windows Command Prompt which is by now a legacy shell. The Command Prompt was made to emulate the pre-Windows MS-DOS environment. Many shell scripts, or batch scripts, were written for this environment which are still in use today. The function with the parameter will almost always end up using the Command Prompt. The module uses the Windows environment variable, which in almost all cases will point to , the Command Prompt. By now, there are so many programs that equate to that changing it would cause much breakage in unexpected places! So, changing is generally not advised. At this point, you should know about an important security concern that you’ll want to be aware of if you have user-facing elements in your Python program, regardless of the operating system. It’s a vulnerability that’s not confined to . Rather, it can be exploited in many different areas. If at any point you plan to get user input and somehow translate that to a call to , then you have to be very careful of injection attacks. That is, take into account potential malicious actors. There are many ways to cause havoc if you just let people run code on your machine. To use a very simplistic example, where you take user input and send it, unfiltered, to subprocess to run on the shell: You can imagine the intended use case is to wrap and add something to it. So the expected user behavior is to provide a path like . However, if a malicious actor realized what was happening, they could execute almost any code they wanted. Take the following, for instance, but be careful with this: C:\\RealPython; echo 'You could've been hacked: rm -Recurse -Force C:\\' Again, beware! These innocent-looking lines could try and delete everything on the system! In this case the malicious part is in quotes, so it won’t run, but if the quotes were not there, you’d be in trouble. The key part that does this is the call to with the relevant flags to recursively delete all files, folders, and subfolders, and it’ll work to force the deletion through. It can run the and potentially the as entirely separate commands by adding semicolons, which act as command separators allowing what would usually be multiple lines of code to run on one line. Running these malicious commands would cause irreparable damage to the file system, and would require reinstalling the operating system. So, beware! Luckily, the operating system wouldn’t let you do this to some particularly important files. The command would need to use in UNIX-based systems, or be run as an administrator in Windows to be completely successful in its mayhem. The command would probably delete a lot of important stuff before stopping, though. So, make sure that if you’re dynamically building user inputs to feed into a call, then you’re very careful! With that warning, coming up you’ll be covering using the outputs of commands and chaining commands together—in short, how to communicate with processes once they’ve started.\n\nYou’ve used the module to execute programs and send basic commands to the shell. But something important is still missing. For many tasks that you might want to use for, you might want to dynamically send inputs or use the outputs in your Python code later. To communicate with your process, you first should understand a little bit about how processes communicate in general, and then you’ll take a look at two examples to come to grips with the concepts. A stream at its most basic represents a sequence of elements that aren’t available all at once. When you read characters and lines from a file, you’re working with a stream in the form of a file object, which at its most basic is a file descriptor. File descriptors are often used for streams. So, it’s not uncommon to see the terms stream, file, and file-like used interchangeably. When processes are initialized, there are three special streams that a process makes use of. A process does the following: These are the standard streams—a cross-platform pattern for process communication. Sometimes the child process inherits these streams from the parent. This is what’s happening when you use in the REPL and are able to see the output of the command. The of the Python interpreter is inherited by the subprocess. When you’re in a REPL environment, you’re looking at a command-line interface process, complete with the three standard I/O streams. The interface has a shell process as a child process, which itself has a Python REPL as a child. In this situation, unless you specify otherwise, comes from the keyboard, while and are displayed on-screen. The interface, the shell, and the REPL share the streams: You can think of the standard I/O streams as byte dispensers. The subprocess fills up and , and you fill up . Then you read the bytes in and , and the subprocess reads from . As with a dispenser, you can stock before it gets linked up to a child process. The child process will then read from as and when it needs to. Once a process has read from a stream, though, the bytes are dispensed. You can’t go back and read them again: These three streams, or files, are the basis for communicating with your process. In the next section, you’ll start to see this in action by getting the output of a magic number generator program. Often, when using the module, you’ll want to use the output for something and not just display the output as you have been doing so far. In this section, you’ll use a magic number generator that outputs, well, a magic number. Imagine that the magic number generator is some obscure program, a black box, inherited across generations of sysadmins at your job. It outputs a magic number that you need for your secret calculations. You’ll read from the of and use it in your wrapper Python program: Okay, not really so magical. That said, it’s not the magic number generator that you’re interested in—it’s interacting with a hypothetical black box with that’s interesting. To grab the number generator’s output to use later, you can pass in a argument to : Passing a argument of to makes the output of the process available at the attribute of the completed process object. You’ll note that it’s returned as a bytes object, so you need to be mindful of encodings when reading it. Also note that the attribute of the is no longer a stream. The stream has been read, and it’s stored as a bytes object in the attribute. With the output available, you can use more than one subprocess to grab values and operate on them in your code: In this example, you start two magic number processes that fetch two magic numbers and then add them together. For now, you rely on the automatic decoding of the bytes object by the constructor. In the next section, though, you’ll learn how to decode and encode explicitly. Processes communicate in bytes, and you have a few different ways to deal with encoding and decoding these bytes. Beneath the surface, has a few ways of getting into text mode. Text mode means that will try to take care of encoding itself. To do that, it needs to know what character encoding to use. Most of the options for doing this in will try to use the default encoding. However, you generally want to be explicit about what encoding to use to prevent a bug that would be hard to find in the future. You can pass a argument for Python to take care of encodings using the default encoding. But, as mentioned, it’s always safer to specify the encodings explicitly using the argument, as not all systems work with the nearly universal UTF-8: If in text mode, the attribute on a is now a string and not a bytes object. You can also decode the bytes returned by calling the method on the attribute directly, without requiring text mode at all: There are other ways to put into text mode. You can also set a value for or , which will also put into text mode. This may seem redundant, but much of this is kept for backwards compatibility, seeing as the module has changed over the years. Now that you know how to read and decode the output of a process, it’s time to take a look at writing to the input of a process. In this section, you’ll use to interact with a command-line game. It’s a basic program that’s designed to test a human’s reaction time. With your knowledge of standard I/O streams, though, you’ll be able to hack it! The source code of the game makes use of the and module: The program starts, asks for the user to press enter, and then after a random amount of time will ask the user to press enter again. It measures from the time the message appears to the time the user presses enter, or at least that’s what the game developer thinks: The function will read from until it reaches a newline, which means an keystroke in this context. It returns everything it consumed from except the newline. With that knowledge, you can use to interact with this game: A reaction time of 0 milliseconds! Not bad! Considering the average human reaction time is around 270 milliseconds, your program is definitely superhuman. Note that the game rounds its output, so 0 milliseconds doesn’t mean it’s instantaneous. The argument passed to is a string consisting of two newlines. The parameter is set to , which puts into text mode. This sets up the process for it to receive the input you that give it. Before the program starts, is stocked, waiting for the program to consume the newlines it contains. One newline is consumed to start the game, and the next newline is consumed to react to . Now that you know what’s happening—namely that can be stocked, as it were—you can hack the program yourself without . If you start the game and then press a few times, that’ll stock up with a few newlines that the program will automatically consume once it gets to the line. So your reaction time is really only the time it takes for the reaction game to execute and consume an input: The game developer gets wise to this, though, and vows to release another version, which will guard against this exploit. In the meantime, you’ll peek a bit further under the hood of and learn about how it wires up the standard I/O streams.\n\nTo really understand subprocesses and the redirection of streams, you really need to understand pipes and what they are. This is especially true if you want to wire up two processes together, feeding one into another process’s , for instance. In this section, you’ll be coming to grips with pipes and how to use them with the module. A pipe, or pipeline, is a special stream that, instead of having one file handle as most files do, has two. One handle is read-only, and the other is write-only. The name is very descriptive—a pipe serves to pipe a byte stream from one process to another. It’s also buffered, so a process can write to it, and it’ll hold onto those bytes until it’s read, like a dispenser. You may be used to seeing pipes on the command line, as you did in the section on shells: This command tells the shell to create an process to list all the files in . The pipe operator ( ) tells the shell to create a pipe from the of the process and feed it into the of the process. The process filters out all the lines that don’t contain the string . Windows doesn’t have , but a rough equivalent of the same command would be as follows: However, on Windows PowerShell, things work very differently. As you learned in the Windows shell section of this tutorial, the different commands are not separate executables. Therefore, PowerShell is internally redirecting the output of one command into another without starting new processes. Note: If you don’t have access to a UNIX-based operating system but have Windows 10 or above, then you actually do have access to a UNIX-based operating system! Check out Windows Subsystem for Linux, which will give you access to a fully featured Linux shell. You can use pipes for different processes on PowerShell, though getting into the intricacies of which ones is outside the scope of this tutorial. For more information on PowerShell pipes, check out the documentation. So, for the rest of the pipe examples, only UNIX-based examples will be used, as the basic mechanism is the same for both systems. They’re not nearly as common on Windows, anyway. If you want to let the shell take care of piping processes into one another, then you can just pass the whole string as a command into : This way, you can let your chosen shell take care of piping one process into another, instead of trying to reimplement things in Python. This is a perfectly valid choice in certain situations. Later in the tutorial, you’ll also come to see that you can’t pipe processes directly with . For that, you’ll need the more complicated . Actual piping is demonstrated in Connecting Two Porcesses Together With Pipes, near the end of the tutorial. Whether you mean to pipe one process into another with the module or not, the module makes extensive use of pipes behind the scenes. The Python module uses pipes extensively to interact with the processes that it starts. In a previous example, you used the parameter to be able to access : is equivalent to explicitly setting the and parameters to the constant: The constant is nothing special. It’s just a number that indicates to that a pipe should be created. The function then creates a pipe to link up to the of the subprocess, which the function then reads into the object’s attribute. By the time it’s a , it’s no longer a pipe, but a bytes object that can be accessed multiple times. Note: Pipe buffers have a limited capacity. Depending on the system you are running on, you may easily run into that limit if you plan on holding large quantities of data in the buffer. To work around this limit, you can use normal files. You can also pass a file object to any of the standard stream parameters: You can’t pass a bytes object or a string directly to the argument, though. It needs to be something file-like. Note that the that gets returned first is from the call to which returns the new stream position, which in this case is the start of the stream. The parameter is similar to the parameter in that it’s a shortcut. Using the parameter will create a buffer to store the contents of , and then link the file up to the new process to serve as its . To actually link up two processes with a pipe from within is something that you can’t do with . Instead, you can delegate the plumbing to the shell, as you did earlier in the Introduction to the Shell and Text Based Programs with section. If you needed to link up different processes without delegating any of the work to the shell, then you could do that with the underlying constructor. You’ll cover in a later section. In the next section, though, you’ll be simulating a pipe with because in most cases, it’s not vital for processes to be linked up directly. Though you can’t actually link up two processes together with a pipe by using the function, at least not without delegating it to the shell, you can simulate piping by judicious use of the attribute. If you’re on a UNIX-based system where almost all typical shell commands are separate executables, then you can just set the of the second process to the attribute of the first : Here the attribute of the object of is set to the of the . It’s important that it’s set to rather than . This is because the attribute isn’t a file-like object. It’s a bytes object, so it can’t be used as an argument to . As an alternative, you can operate directly with files too, setting them to the standard stream parameters. When using files, you set the file object as the argument to , instead of using the parameter: As you learned in the previous section, for Windows PowerShell, doing something like this doesn’t make a whole lot of sense because most of the time, these utilities are part of PowerShell itself. Because you aren’t dealing with separate executables, piping becomes less of a necessity. However, the pattern for piping is still the same if something like this needs to be done. With most of the tools out the way, it’s now time to think about some practical applications for .\n\nWhen you have an issue that you want to solve with Python, sometimes the module is the easiest way to go, even though it may not be the most correct. Using is often tricky to get working across different platforms, and it has inherent dangers. But even though it may involve some sloppy Python, using can be a very quick and efficient way to solve a problem. As mentioned, for most tasks you can imagine doing with , there’s usually a library out there that’s dedicated to that specific task. The library will almost certainly use , and the developers will have worked hard to make the code reliable and to cover all the corner cases that can make using difficult. So, even though dedicated libraries exist, it can often be simpler to just use , especially if you’re in an environment where you need to limit your dependencies. In the following sections, you’ll be exploring a couple of practical ideas. Creating a New Project: An Example Say you often need to create new local projects, each complete with a virtual environment and initialized as a Git repository. You could reach for the Cookiecutter library, which is dedicated to that task, and that wouldn’t be a bad idea. However, using Cookiecutter would mean learning Cookiecutter. Imagine you didn’t have much time, and your environment was extremely minimal anyway—all you could really count on was Git and Python. In these cases, can quickly set up your project for you: This is a command-line tool that you can call to start a project. It’ll take care of creating a file and a file, and then it’ll run a few commands to create a virtual environment, initialize a git repository, and perform your first commit. It’s even cross-platform, opting to use to create the files and folders, which abstracts away the operating system differences. Could this be done with Cookiecutter? Could you use GitPython for the part? Could you use the module to create the virtual environment? Yes to all. But if you just need something quick and dirty, using commands you already know, then just using can be a great option. If you use Dropbox, you may not know that there’s a way to ignore files when syncing. For example, you can keep virtual environments in your project folder and use Dropbox to sync the code, but keep the virtual environment local. That said, it’s not as easy as adding a file. Rather, it involves adding special attributes to files, which can be done from the command line. These attributes are different between UNIX-like systems and Windows: There are some UNIX-based projects, like dropboxignore, that use shell scripts to make it easier to ignore files and folders. The code is relatively complex, and it won’t work on Windows. With the module, you can wrap the different shell commands quite easily to come up with your own utility: This is a simplified snippet from the author’s dotDropboxIgnore repository. The function detects the operating system with the module and returns an object that’s an abstraction around the system-specific shell. The code hasn’t implemented the behavior on macOS, so it raises a if it detects it’s running on macOS. The shell object allows you to call an method with a list of objects to set Dropbox to ignore those files. On the class, the constructor tests to see if PowerShell Core is available, and if not, will fall back to the older Windows PowerShell, which is installed by default on Windows 10. In the next section, you’ll review some of the other modules that might be interesting to keep in mind when deciding whether to use .\n\nAs mentioned, the underlying class for the whole module is the class and the constructor. Each function in calls the constructor under the hood. Using the constructor gives you lots of control over the newly started subprocesses. As a quick summary, is basically the class constructor, some setup, and then a call to the method on the newly initialized object. The method is a blocking method that returns the and data once the process has ended. The name of comes from a similar UNIX command that stands for pipe open. The command creates a pipe and then starts a new process that invokes the shell. The module, though, doesn’t automatically invoke the shell. The function is a blocking function, which means that interacting dynamically with a process isn’t possible with it. However, the constructor starts a new process and continues, leaving the process running in parallel. The developer of the reaction game that you were hacking earlier has released a new version of their game, one in which you can’t cheat by loading with newlines: \"A letter will appear on screen after a random amount of time, \"when it appears, type the letter as fast as possible \" \"Press enter when you are ready\" Now the program will display a random character, and you need to press that exact character to have the game register your reaction time: What’s to be done? First, you’ll need to come to grips with using with basic commands, and then you’ll find another way to exploit the reaction game. Using the constructor is very similar in appearance to using . If there’s an argument that you can pass to , then you’ll generally be able to pass it to . The fundamental difference is that it’s not a blocking call—rather than waiting until the process is finished, it’ll run the process in parallel. So you need to take this non-blocking nature into account if you want to read the new process’s output: This program calls the timer process in a context manager and assigns to a pipe. Then it runs the method on the object and reads its . The method is a basic method to check if a process is still running. If it is, then returns . Otherwise, it’ll return the process’s exit code. Then the program uses to try and read as many bytes as are available at . Note: If you put the object into text mode and then called on , the call to would be blocking until it reached a newline. In this case, a newline would coincide with the end of the timer program. This behavior isn’t desired in this situation. To read as many bytes as are available at that time, disregarding newlines, you need to read with . It’s important to note that is only available on byte streams, so you need to make sure to deal with encodings manually and not use text mode. The output of this program first prints because the process hasn’t yet finished. The program then prints what is available in so far, which is the starting message and the first character of the animation. After three seconds, the timer hasn’t finished, so you get again, along with two more characters of the animation. After another three seconds, the process has ended, so produces , and you get the final characters of the animation and : Output from poll: None Output from stdout: Starting timer of 5 seconds . Output from poll: None Output from stdout: .. Output from poll: 0 Output from stdout: ..Done! In this example, you’ve seen how the constructor works very differently from . In most cases, you don’t need this kind of fine-grained control. That said, in the next sections, you’ll see how you can pipe one process into another, and how you can hack the new reaction game. Connecting Two Processes Together With Pipes As mentioned in a previous section, if you need to connect processes together with pipes, you need to use the constructor. This is mainly because is a blocking call, so by the time the next process starts, the first one has ended, meaning that you can’t directly link up to its . This procedure will only be demonstrated for UNIX systems, because piping in Windows is far less common, as mentioned in the simulating a pipe section: In this example, the two processes are started in parallel. They are joined with a common pipe, and the loop takes care of reading the pipe at to output the lines. A key point to note is that in contrast to , which returns a object, the constructor returns a object. The standard stream attributes of a point to bytes objects or strings, but the same attributes of a object point to the actual streams. This allows you to communicate with processes as they’re running. Whether you really need to pipe processes into one another, though, is another matter. Ask yourself if there’s much to be lost by mediating the process with Python and using exclusively. There are some situations in which you really need , though, such as hacking the new version of the reaction time game. Now that you know you can use to interact with a process dynamically as it runs, it’s time to turn that knowledge toward exploiting the reaction time game again: With this script, you’re taking complete control of the buffering of a process, which is why you pass in arguments such as to the Python process and to . These arguments are to ensure that no extra buffering is taking place. The script works by using a function that’ll search for one of a list of strings by grabbing one character at a time from the process’s . As each character comes through, the script will search for the string. Note: To make this work on both Windows and UNIX-based systems, two strings are searched for: either or . The Windows-style carriage return along with the typical newline is required on Windows systems. After the script has found one of the target strings, which in this case is the sequence of characters before the target letter, it’ll then grab the next character and write that letter to the process’s followed by a newline: At one millisecond, it’s not quite as good as the original hack, but it’s still very much superhuman. Well done! With all this fun aside, interacting with processes using can be very tricky and is prone to errors. First, see if you can use exclusively before resorting to the constructor. If you really need to interact with processes at this level, the module has a high-level API to create and manage subprocesses. The subprocess functionality is intended for more complex uses of where you may need to orchestrate various processes. This might be the case if you’re performing complex processing of many image, video, or audio files, for example. If you’re using at this level, then you’re probably building a library."
    },
    {
        "link": "https://stackoverflow.com/questions/43085063/correct-use-of-subprocess-in-python-2-7",
        "document": "Not the answer but how to get to the answer. When programs don't behave, start testing your assumptions and printing information as you go. This example should reduce the possible problems. You should see some prints from this program. If not, it may have to do with how you run the program. I am assuming that you run from the command line where you can see standard and error prints from python and . If not, this will need updates.\n\nI then injected a file-not-found error and ran again"
    },
    {
        "link": "https://stackoverflow.com/questions/16573474/how-to-run-svn-commands-from-a-python-script",
        "document": "Gives you great access as far as i've tested it. Here's some examples: http://pysvn.tigris.org/docs/pysvn_prog_guide.html\n\nThe reason for why i'm saying as far as i've tested it is because i've moved over to Git.. but if i recall pysvn is (the only and) the best library for svn."
    },
    {
        "link": "https://stackoverflow.com/questions/73873754/python-subprocess-checkoutput-exception-using-svn-log",
        "document": "I have run in to an issue that I havent been able to resolve.\n\nI am trying to run a subversion command through python to process the results. I had this code running my dev system but when I run it on target system I get an exception in the subprocess module.\n\nWhy would this code produce different results on my two systems?\n\nI get the following exception:\n• None I tried to run the same subversion command on the command line and it executes as I expect. When I echo %ERRORLEVEL% it returns a status of 0. So Im lost as to what is happening differently on my target system.\n• None I tried investigating the python docs for the checkoutput() function and there appears to be no major updates between 3.6 and 3.9\n• None I tried investigating the Apache subversion release notes and didnt find any changes to the 'log' subcommand"
    },
    {
        "link": "http://sfriederichs.github.io/how-to/python3/svn/2020/07/13/SVN-with-Python.html",
        "document": "I have a tedious task to perform which involves reading information from SVN and updating a review checklist with the information. The ‘hard’ part of this whole process is the actual review. The ‘easy’ part is looking up the revision information, paths, file names, etc and putting them into the spreadsheet. Despite the fact that this is the ‘easy’ part it’s also very easy to mess up. This tedious copy and paste process has many steps, requires significant working memory and can be easily confusing. The worst part is that even if you do the ‘hard’ part well, you need to do the ‘easy’ part perfectly because if you mess up a revision or a path there’s no way to link the work you did to the actual artifact being reviewed.\n\nSo, why not create a script?\n\nPython can read SVN and filesystem information. It can read Excel files. It can write excel files. So, let’s just automate this whole thing.\n\nThis post will focus on the SVN aspects of the process. I have another that focuses on the Excel aspects.\n\nThere is a package called PySVN that handles the interface between Python and SVN. It’s a bit of fun, so buckle up.\n\nOn a Windows 10 PC using Python 3 (3.8.1) I did the following:\n\nIt’s really odd. I can’t find a lot about why pip isn’t working. That being said, it seems you just install it with an installer, from their website.\n\nThe download website is here.\n\nI’m downloading the version for Python 3.8.1 and WIndows 1 x64, which is here. Note: it’s the 1.14.0 version.\n\nIt brings me to SourceForge (ew) and the download starts.\n\nUh, where is it?\n\nOh look, Windows Defender says that it’s scard of this download. I tell it ‘no’. You will run it.\n\nAnyway, on to the actual installation.\n• Ready to Install - Everything looks good, I click ‘Install’\n• And then, it finishes. So I click ‘Finish’\n\nThe first thing I like to do with anything new is to do a ‘Hello World’ type script. In this case, my workflow depends on several things:\n• Getting the full SVN URL of files checked out on to my PC\n• Getting the last few log entries of files check out on my PC\n• Finding the last user to commit a file check out on my PC\n\nThe first thing that shows up when I google for ‘pysvn examples’ is this page.\n\nIt has quite a few little snippets that look rather tasty. Let’s see if I can find what I’m looking for.\n\nEh, no. I can’t. Dang. What else do we have?\n\nOne thing I have noticed over the years of using PySVN is that it has curiously few examples running around out there. Few StackOverflow questions, few blog posts, etc.\n\nOne of the first things you’ll need to do is specify a callback function to get a login to your SVN server. Not much will work without it. This is the documentation for implementing a callback, and below you’ll see I’ve generated a simple function to suffice for the callback and register it to the SVN client.\n\nThat at least runs without error, so I’ll move on to the next part.\n\nFYI, none of those entries above are my real password to anything.\n\nI think the function I need to use is the info2 function. Read more about it here.\n\nI need to pick a file, point info2 towards it, then see what it returns. Here’s the code I’m trying:\n\nWhat the docs say will be returned is this:\n\nHistorically, PySVN has a very confusing way of storing useful information. Actually getting the information you want out of what it returns is complicated. Here’s what comes out of the print statement:\n\nSee? That’s just kinda weird. A tuple inside a list? And the first item of the tuple is just the file path I passed to it? So, to access the PysvnInfo member, you have to do this:\n\nBut the second print statement prints this out:\n\nBrilliant. So, we start trying to figure out what’s in there. Supposedly it’s a dictionary, right? So we’ll try accessing some of the named members from the website. Like this:\n\nOkay, so I didn’t put the actual URL there, but take my word for it: it prints out the URL.\n\nIt should be easy to get the rest of the information that we want.\n\nIf you thought an SVN revision was just an integer number, raise your hand.\n\nTurns out - I’m wrong. An SVN revision (as far as PySVN is concerned) is a pysvn.Revision type.\n\nNow what, pray tell, is that?\n\nIf you’re interested in what the opt_revision_kind enumeration information is, look here:\n\nOkay, so what will print out if we try to access the revision code? We try like this:\n\nInteresting, but supposedly tehre were three elements: kinda, date and number. Can we access them or am I misunderstanding things?\n\nWell, that at least bears out the part about having three elements. Now at least I can access the specific parts of the revision information that I’m looking for.\n\nHowever, we must take into account a wrinkle with SVN: last-changed revision vs. current revision.\n\nCurrent revision is basically the most recent revision of the working copy. Imagine if you did an update on the root of a working copy - when it finished you’d see something like “Updated to revision xxxx”. Now, the working copy is considered to be at revision xxxx. However, many files within the working copy might not have been changed in revision xxxx - they have a ‘last-changed’ revision which will be lower than the working copy revision. When SVN says ‘Updated to revision xxxx’ what it’s saying is ‘all the files in this working copy are up-to-date as of revision xxxx’. If you pick a file that was last updated in say, revision 443 and tell SVN to check out that file at any revision later than 443, you’ll get the most up-to-date file. If you choose to check out a revision earlier than 443, you will not have the most up-to-date file. 443 would be the ‘last-changed revision’, while xxxx would be the ‘revision’.\n\nGenerally, the ‘revision’ isn’t very useful when you’re looking at individual files. Instead, you’ll want to go with the ‘last-changed revision’.\n\nIn order to print out the information for ‘rev’ vs. ‘last-changed-rev’, I would use this code:\n\nAnd you get this output:\n\nNot bad, now we can get all the revision information we want.\n\nI’m guessing that the author information is this one:\n\nAnd luckily, it’s just a string, so it should be easy to access like this:\n\nKeep in mind, the ‘author’ will be a username, not necessarily a full-fledged first and last name.\n\nNow we’re getting a bit farther. Most of the information I was looking for could be found with the info2 function, but I don’t see anything about the log in the info2 documentation, so it must be elsewhere.\n\nLook no further than this.\n\nAlright, so what does this mean practically?\n\nIt’s worth noting that retrieving the log takes a second - much more time than the info2 command took.\n\nOkie…. this file has two entries in its log when I look at it, so that must be theese. Let’s assume those are dictionaries as specified above and see if we can print out the information we want for each entry. Here’s the code I created:\n\nI had to include the datetime library to get the correct formatting function since the timestamp comes back in a float format. But overall, not too bad!\n\nI have a situation where I need to get the SVN information (URL, last changed revision) for a few files in a directory. This presents an interesting twist: in a working copy, not all files may be version controlled. There could be uncommitted files hanging around there - this means it’s important not to do a directory listing of files, but instead to do an SVN listing of files.\n\nTurns out there’s a useful command called ‘ls’. Ha. Imagine that. Let’s see what the documentation says about it.\n\nOh. Okay. Where’s that?\n\nYou pass it a path and it returns some information:\n\nSo, I whip this code up:\n\nWell, we’ve got a problem: the paths are relative repository paths, not complete URLs. The server name and protocol is not present, which is not what I want.\n\nThe question is: how do I get that?\n\nI could use the list command to get a list of files and then use the info2 command to get their URLs.\n\nWhen you list a directory, the first entry returned is the directory itself!\n\nNot really a problem, but if you’re expecting just the files, you’ll get in some trouble.\n\nAnyway, here’s the code to do get the full URL with the info2 command:\n\nOne of the sanity checks I’ll have to do is to make sure that I haven’t failed to commit changes I’ve made to my checklists before I close an issue.\n\nI think I’d like to change it to something that returns a list of files with uncommitted changes. Let’s look up the status function. Documentation is here.\n\nAlright, the big question is going to be what the path returns - local? Repo? URL?\n\nThe other big issue is that the example code only looks for status NOT normal. That could include more things than just normal or uncommitted changes.\n\nThis is the documentation for the pysvn_wc_status_kind type, reproduced here:\n\nOkay, so we can check for a variety of non-ideal status. Honestly, at this point, if any status is not ‘normal’ it pump the brakes, so I guess that guy was right….\n\nAnyway, here’s what I wrote for code:\n\nAnd it produced this:\n\nAnd all of the file paths were local working directory paths. Doesn’t really matter to me.\n\nIt’s worth noting, again, that the first entry was the entry for the directory, not a file within the directory.\n\nWell, once you’ve ascertained there are uncommitted changes, you’ll want to commit them.\n\nBut PySVN doesn’t use the verb ‘commit’ for this, it uses ‘checkin’.\n\nOnly big question is how to get the log message. I know there can be a log message callback, but I think I’ll just use a text input to do this.\n\nThe try/catch is there because I know that it’s possible that there will be circumstances the commit will fail - one I know of for sure is a pre-commit hook failing. However, I don’t know exactly what the exception will be and the documentation isn’t explicit on that, so I’m just catching a generic exception.\n\nYes, I know - that’s bad. But until that exception occurs I won’t know what to look for specifically. Or I could do more research. But I won’t right now.\n\nAlso, I’ve had issues using os.linesep within log messages, as well as ‘\\r\n\n’. The server I’m working on only wants the ‘\n\n’.\n\nIf you have a newly-created file, you’ll need to add it to your working copy and then commit to get the file into SVN. Here’s how you do it.\n\nThese are miscellaneous notes I’m keeping about using PySVN.\n\nOne of the interesting things about PySVN is that there’s only one SVN client on your PC - anywhere. That means if you’re messing around with the command-line SVN client and you try to run a Python script that uses the SVN client your Python script will have to wait for the command-line process to finish before it can start.\n\nOne important upshot of this is that you really can’t do multi-threaded access to the SVN client in Python. If you try, you’re gonna have a confusing and frustrating time.\n\nOnly ever access the SVN client from _one_ Python thread"
    },
    {
        "link": "https://perforce.com/blog/vcs/svn-commands-cheat-sheet",
        "document": ""
    },
    {
        "link": "https://tex.stackexchange.com/questions/161/latex-packages-for-use-with-revision-control",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    }
]