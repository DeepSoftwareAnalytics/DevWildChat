[
    {
        "link": "https://geeksforgeeks.org/segment-tree-efficient-implementation",
        "document": "Let us consider the following problem to understand Segment Trees without recursion.\n\nWe have an array arr[0 . . . n-1]. We should be able to,\n• None Find the sum of elements from index l to r where 0 <= l <= r <= n-1\n• None Change the value of a specified element of the array to a new value x. We need to do arr[i] = x where 0 <= i <= n-1.\n\nA simple solution is to run a loop from l to r and calculate the sum of elements in the given range. To update a value, simply do arr[i] = x. The first operation takes O(n) time and the second operation takes O(1) time.\n\n\n\nAnother solution is to create another array and store the sum from start to i at the ith index in this array. The sum of a given range can now be calculated in O(1) time, but the update operation takes O(n) time now. This works well if the number of query operations is large and there are very few updates.\n\nWhat if the number of queries and updates are equal? Can we perform both the operations in O(log n) time once given the array? We can use a Segment Tree to do both operations in O(Logn) time. We have discussed the complete implementation of segment trees in our previous post. In this post, we will discuss the easier and yet efficient implementation of segment trees than in the previous post.\n\nConsider the array and segment tree as shown below:\n\n\n\nYou can see from the above image that the original array is at the bottom and is 0-indexed with 16 elements. The tree contains a total of 31 nodes where the leaf nodes or the elements of the original array start from node 16. So, we can easily construct a segment tree for this array using a 2*N sized array where N is the number of elements in the original array. The leaf nodes will start from index N in this array and will go up to index (2*N – 1). Therefore, the element at index i in the original array will be at index (i + N) in the segment tree array. Now to calculate the parents, we will start from the index (N – 1) and move upward. For index i , the left child will be at (2 * i) and the right child will be at (2*i + 1) index. So the values at nodes at (2 * i) and (2*i + 1) are combined at i-th node to construct the tree. \n\nAs you can see in the above figure, we can query in this tree in an interval [L,R) with left index(L) included and right (R) excluded.\n\nWe will implement all of these multiplication and addition operations using bitwise operators.\n\nLet us have a look at the complete implementation:\n\n// function to get sum on interval [l, r) // loop to find the sum in the range // driver program to test the above function // function to get sum on // loop to find the sum in the range // This code is contributed by vt_m. # function to get sum on interval [l, r) # loop to find the sum in the range # This code is contributed by AnkitRai01 // function to get sum on // loop to find the sum in the range // This code is contributed by vt_m. // function to get sum on // loop to find the sum in the range\n\n\n\nYes! That is all. The complete implementation of the segment tree includes the query and update functions in a lower number of lines of code than the previous recursive one. Let us now understand how each of the functions works: \n\n\n\n1. The picture makes it clear that the leaf nodes are stored at i+n, so we can clearly insert all leaf nodes directly.\n\n2. The next step is to build the tree and it takes O(n) time. The parent always has its less index than its children, so we just process all the nodes in decreasing order, calculating the value of the parent node. If the code inside the build function to calculate parents seems confusing, then you can see this code. It is equivalent to that inside the build function.\n\n3. Updating a value at any position is also simple and the time taken will be proportional to the height of the tree. We only update values in the parents of the given node which is being changed. So to get the parent, we just go up to the parent node, which is p/2 or p>>1, for node p. p^1 turns (2*i) to (2*i + 1) and vice versa to get the second child of p.\n\n4. Computing the sum also works in O(log(n)) time. If we work through an interval of [3,11), we need to calculate only for nodes 19,26,12, and 5 in that order.\n\n\n\nThe idea behind the query function is whether we should include an element in the sum or whether we should include its parent. Let’s look at the image once again for proper understanding. Consider that L is the left border of an interval and R is the right border of the interval [L,R). It is clear from the image that if L is odd, then it means that it is the right child of its parent and our interval includes only L and not the parent. So we will simply include this node to sum and move to the parent of its next node by doing L = (L+1)/2. Now, if L is even, then it is the left child of its parent and the interval includes its parent also unless the right borders interfere. Similar conditions are applied to the right border also for faster computation. We will stop this iteration once the left and right borders meet.\n\nThe theoretical time complexities of both previous implementation and this implementation is the same, but practically, it is found to be much more efficient as there are no recursive calls. We simply iterate over the elements that we need. Also, this is very easy to implement."
    },
    {
        "link": "https://stackoverflow.com/questions/18800058/acm-how-to-use-segment-tree-to-count-how-many-elements-in-a-b-is-smaller-tha",
        "document": "I am quite new to segment tree and would like to make myself busy by doing some more exercise on segment tree.\n\nThe problem's actually more ACM like and have following conditions: There are n numbers and m operations, n,m<=10,000, each operation can be one of the following: 1. Update an interval by minus a number x, x can be different each time 2. Query an interval to find how many numbers in the interval is <= 0\n\nBuilding the segment tree and updating here is obviously can be done in O(nlog n) / O(log n) But I cannot figure out how to make a query in O(log n), can anyone give me some suggestions / hints? Any suggestions would be helpful! Thanks!\n• add x to all elements in [a,b], x can be different each time\n• Query number of elements in [a,b] is < C, C is given constant\n\nHow to make operation 1 & 2 both can be done in O(log n)?"
    },
    {
        "link": "https://stackoverflow.com/questions/58293297/sum-of-all-numbers-less-than-k-in-a-range-using-segment-tree",
        "document": "Below assumes the elements in your array are all positive\n\nhow about not maintaining segment tree for specific but resolving the query instead\n\nJust consider your segment tree.\n\nAt each node , you know:\n• the number of elements it covers:\n• For a given range query, get down to the corresponding node .\n• For that , is the sum of its two children's sum. For each of those given child with its elements covered: two possibilities\n• :all elements are less than k\n• :at least one element is greater or equal than\n\nSo first case, the child's sum is already valid, nothing more to do.\n\nSecond case, you have to explore the child and so forth until nothing more to do\n\nAt some point, (if you have an invalid element) you will reach a bottom of the tree: that very node (also an elem) is bad, and you backtrack that fact. When you get back to your node , you substract from all those bad leaf node's value you found."
    },
    {
        "link": "https://geeksforgeeks.org/counting-inversions-in-an-array-using-segment-tree",
        "document": "Given an array of integers arr, the task is to count the number of inversions in the array. \n\nIf A[i] > A[j] and i < j then the pair (A[i], A[j]) is part of an inversion.\n• Build a segment tree where each node will represent the total numbers present in the range of that node.\n• Let’s say the range of any node is [i, j], then the node will contain the count of numbers which are greater than or equal to i and less than or equal to j.\n• Leaf nodes will only be either 1 or 0 since range of the node will be 1.\n• Iterate through the array, let the number present at the index i is a[i]. We will find how many numbers are present in the segment tree in the range [a[i]+1, max] where max is the maximum element of the array and add it to the answer variable.\n• Then we will insert that number in the segment tree and continue till the last index of the array. This way for each element we are adding the numbers which appear before that element and are greater than that element i.e. they form an inversion pair.\n\nBelow is the implementation of the above approach:"
    },
    {
        "link": "https://cp-algorithms.com/data_structures/segment_tree.html",
        "document": "A Segment Tree is a data structure that stores information about array intervals as a tree. This allows answering range queries over an array efficiently, while still being flexible enough to allow quick modification of the array. This includes finding the sum of consecutive array elements $a[l \\dots r]$, or finding the minimum element in a such a range in $O(\\log n)$ time. Between answering such queries, the Segment Tree allows modifying the array by replacing one element, or even changing the elements of a whole subsegment (e.g. assigning all elements $a[l \\dots r]$ to any value, or adding a value to all element in the subsegment).\n\nIn general, a Segment Tree is a very flexible data structure, and a huge number of problems can be solved with it. Additionally, it is also possible to apply more complex operations and answer more complex queries (see Advanced versions of Segment Trees). In particular the Segment Tree can be easily generalized to larger dimensions. For instance, with a two-dimensional Segment Tree you can answer sum or minimum queries over some subrectangle of a given matrix in only $O(\\log^2 n)$ time.\n\nOne important property of Segment Trees is that they require only a linear amount of memory. The standard Segment Tree requires $4n$ vertices for working on an array of size $n$.\n\nTo start easy, we consider the simplest form of a Segment Tree. We want to answer sum queries efficiently. The formal definition of our task is: Given an array $a[0 \\dots n-1]$, the Segment Tree must be able to find the sum of elements between the indices $l$ and $r$ (i.e. computing the sum $\\sum_{i=l}^r a[i]$), and also handle changing values of the elements in the array (i.e. perform assignments of the form $a[i] = x$). The Segment Tree should be able to process both queries in $O(\\log n)$ time.\n\nThis is an improvement over the simpler approaches. A naive array implementation - just using a simple array - can update elements in $O(1)$, but requires $O(n)$ to compute each sum query. And precomputed prefix sums can compute sum queries in $O(1)$, but updating an array element requires $O(n)$ changes to the prefix sums.\n\nWe can take a divide-and-conquer approach when it comes to array segments. We compute and store the sum of the elements of the whole array, i.e. the sum of the segment $a[0 \\dots n-1]$. We then split the array into two halves $a[0 \\dots n/2-1]$ and $a[n/2 \\dots n-1]$ and compute the sum of each halve and store them. Each of these two halves in turn are split in half, and so on until all segments reach size $1$.\n\nWe can view these segments as forming a binary tree: the root of this tree is the segment $a[0 \\dots n-1]$, and each vertex (except leaf vertices) has exactly two child vertices. This is why the data structure is called \"Segment Tree\", even though in most implementations the tree is not constructed explicitly (see Implementation).\n\nHere is a visual representation of such a Segment Tree over the array $a = [1, 3, -2, 8, -7]$:\n\nFrom this short description of the data structure, we can already conclude that a Segment Tree only requires a linear number of vertices. The first level of the tree contains a single node (the root), the second level will contain two vertices, in the third it will contain four vertices, until the number of vertices reaches $n$. Thus the number of vertices in the worst case can be estimated by the sum $1 + 2 + 4 + \\dots + 2^{\\lceil\\log_2 n\\rceil} \\lt 2^{\\lceil\\log_2 n\\rceil + 1} \\lt 4n$.\n\nIt is worth noting that whenever $n$ is not a power of two, not all levels of the Segment Tree will be completely filled. We can see that behavior in the image. For now we can forget about this fact, but it will become important later during the implementation.\n\nThe height of the Segment Tree is $O(\\log n)$, because when going down from the root to the leaves the size of the segments decreases approximately by half.\n\nBefore constructing the segment tree, we need to decide:\n• the value that gets stored at each node of the segment tree. For example, in a sum segment tree, a node would store the sum of the elements in its range .\n• the merge operation that merges two siblings in a segment tree. For example, in a sum segment tree, the two nodes corresponding to the ranges and would be merged into a node corresponding to the range by adding the values of the two nodes.\n\nNote that a vertex is a \"leaf vertex\", if its corresponding segment covers only one value in the original array. It is present at the lowermost level of a segment tree. Its value would be equal to the (corresponding) element $a[i]$.\n\nNow, for construction of the segment tree, we start at the bottom level (the leaf vertices) and assign them their respective values. On the basis of these values, we can compute the values of the previous level, using the function. And on the basis of those, we can compute the values of the previous, and repeat the procedure until we reach the root vertex.\n\nIt is convenient to describe this operation recursively in the other direction, i.e., from the root vertex to the leaf vertices. The construction procedure, if called on a non-leaf vertex, does the following:\n• recursively construct the values of the two child vertices\n• merge the computed values of these children.\n\nWe start the construction at the root vertex, and hence, we are able to compute the entire segment tree.\n\nThe time complexity of this construction is $O(n)$, assuming that the merge operation is constant time (the merge operation gets called $n$ times, which is equal to the number of internal nodes in the segment tree).\n\nFor now we are going to answer sum queries. As an input we receive two integers $l$ and $r$, and we have to compute the sum of the segment $a[l \\dots r]$ in $O(\\log n)$ time.\n\nTo do this, we will traverse the Segment Tree and use the precomputed sums of the segments. Let's assume that we are currently at the vertex that covers the segment $a[tl \\dots tr]$. There are three possible cases.\n\nThe easiest case is when the segment $a[l \\dots r]$ is equal to the corresponding segment of the current vertex (i.e. $a[l \\dots r] = a[tl \\dots tr]$), then we are finished and can return the precomputed sum that is stored in the vertex.\n\nAlternatively the segment of the query can fall completely into the domain of either the left or the right child. Recall that the left child covers the segment $a[tl \\dots tm]$ and the right vertex covers the segment $a[tm + 1 \\dots tr]$ with $tm = (tl + tr) / 2$. In this case we can simply go to the child vertex, which corresponding segment covers the query segment, and execute the algorithm described here with that vertex.\n\nAnd then there is the last case, the query segment intersects with both children. In this case we have no other option as to make two recursive calls, one for each child. First we go to the left child, compute a partial answer for this vertex (i.e. the sum of values of the intersection between the segment of the query and the segment of the left child), then go to the right child, compute the partial answer using that vertex, and then combine the answers by adding them. In other words, since the left child represents the segment $a[tl \\dots tm]$ and the right child the segment $a[tm+1 \\dots tr]$, we compute the sum query $a[l \\dots tm]$ using the left child, and the sum query $a[tm+1 \\dots r]$ using the right child.\n\nSo processing a sum query is a function that recursively calls itself once with either the left or the right child (without changing the query boundaries), or twice, once for the left and once for the right child (by splitting the query into two subqueries). And the recursion ends, whenever the boundaries of the current query segment coincides with the boundaries of the segment of the current vertex. In that case the answer will be the precomputed value of the sum of this segment, which is stored in the tree.\n\nIn other words, the calculation of the query is a traversal of the tree, which spreads through all necessary branches of the tree, and uses the precomputed sum values of the segments in the tree.\n\nObviously we will start the traversal from the root vertex of the Segment Tree.\n\nThe procedure is illustrated in the following image. Again the array $a = [1, 3, -2, 8, -7]$ is used, and here we want to compute the sum $\\sum_{i=2}^4 a[i]$. The colored vertices will be visited, and we will use the precomputed values of the green vertices. This gives us the result $-2 + 1 = -1$.\n\nWhy is the complexity of this algorithm $O(\\log n)$? To show this complexity we look at each level of the tree. It turns out, that for each level we only visit not more than four vertices. And since the height of the tree is $O(\\log n)$, we receive the desired running time.\n\nWe can show that this proposition (at most four vertices each level) is true by induction. At the first level, we only visit one vertex, the root vertex, so here we visit less than four vertices. Now let's look at an arbitrary level. By induction hypothesis, we visit at most four vertices. If we only visit at most two vertices, the next level has at most four vertices. That is trivial, because each vertex can only cause at most two recursive calls. So let's assume that we visit three or four vertices in the current level. From those vertices, we will analyze the vertices in the middle more carefully. Since the sum query asks for the sum of a continuous subarray, we know that segments corresponding to the visited vertices in the middle will be completely covered by the segment of the sum query. Therefore these vertices will not make any recursive calls. So only the most left, and the most right vertex will have the potential to make recursive calls. And those will only create at most four recursive calls, so also the next level will satisfy the assertion. We can say that one branch approaches the left boundary of the query, and the second branch approaches the right one.\n\nTherefore we visit at most $4 \\log n$ vertices in total, and that is equal to a running time of $O(\\log n)$.\n\nIn conclusion the query works by dividing the input segment into several sub-segments for which all the sums are already precomputed and stored in the tree. And if we stop partitioning whenever the query segment coincides with the vertex segment, then we only need $O(\\log n)$ such segments, which gives the effectiveness of the Segment Tree.\n\nNow we want to modify a specific element in the array, let's say we want to do the assignment $a[i] = x$. And we have to rebuild the Segment Tree, such that it corresponds to the new, modified array.\n\nThis query is easier than the sum query. Each level of a Segment Tree forms a partition of the array. Therefore an element $a[i]$ only contributes to one segment from each level. Thus only $O(\\log n)$ vertices need to be updated.\n\nIt is easy to see, that the update request can be implemented using a recursive function. The function gets passed the current tree vertex, and it recursively calls itself with one of the two child vertices (the one that contains $a[i]$ in its segment), and after that recomputes its sum value, similar how it is done in the build method (that is as the sum of its two children).\n\nAgain here is a visualization using the same array. Here we perform the update $a[2] = 3$. The green vertices are the vertices that we visit and update.\n\nThe main consideration is how to store the Segment Tree. Of course we can define a $\\text{Vertex}$ struct and create objects, that store the boundaries of the segment, its sum and additionally also pointers to its child vertices. However, this requires storing a lot of redundant information in the form of pointers. We will use a simple trick to make this a lot more efficient by using an implicit data structure: Only storing the sums in an array. (A similar method is used for binary heaps). The sum of the root vertex at index 1, the sums of its two child vertices at indices 2 and 3, the sums of the children of those two vertices at indices 4 to 7, and so on. With 1-indexing, conveniently the left child of a vertex at index $i$ is stored at index $2i$, and the right one at index $2i + 1$. Equivalently, the parent of a vertex at index $i$ is stored at $i/2$ (integer division).\n\nThis simplifies the implementation a lot. We don't need to store the structure of the tree in memory. It is defined implicitly. We only need one array which contains the sums of all segments.\n\nAs noted before, we need to store at most $4n$ vertices. It might be less, but for convenience we always allocate an array of size $4n$. There will be some elements in the sum array, that will not correspond to any vertices in the actual tree, but this doesn't complicate the implementation.\n\nSo, we store the Segment Tree simply as an array $t[]$ with a size of four times the input size $n$:\n\nThe procedure for constructing the Segment Tree from a given array $a[]$ looks like this: it is a recursive function with the parameters $a[]$ (the input array), $v$ (the index of the current vertex), and the boundaries $tl$ and $tr$ of the current segment. In the main program this function will be called with the parameters of the root vertex: $v = 1$, $tl = 0$, and $tr = n - 1$.\n\nFurther the function for answering sum queries is also a recursive function, which receives as parameters information about the current vertex/segment (i.e. the index $v$ and the boundaries $tl$ and $tr$) and also the information about the boundaries of the query, $l$ and $r$. In order to simplify the code, this function always does two recursive calls, even if only one is necessary - in that case the superfluous recursive call will have $l > r$, and this can easily be caught using an additional check at the beginning of the function.\n\nFinally the update query. The function will also receive information about the current vertex/segment, and additionally also the parameter of the update query (i.e. the position of the element and its new value).\n\nMost people use the implementation from the previous section. If you look at the array you can see that it follows the numbering of the tree nodes in the order of a BFS traversal (level-order traversal). Using this traversal the children of vertex $v$ are $2v$ and $2v + 1$ respectively. However if $n$ is not a power of two, this method will skip some indices and leave some parts of the array unused. The memory consumption is limited by $4n$, even though a Segment Tree of an array of $n$ elements requires only $2n - 1$ vertices.\n\nHowever it can be reduced. We renumber the vertices of the tree in the order of an Euler tour traversal (pre-order traversal), and we write all these vertices next to each other.\n\nLet's look at a vertex at index $v$, and let it be responsible for the segment $[l, r]$, and let $mid = \\dfrac{l + r}{2}$. It is obvious that the left child will have the index $v + 1$. The left child is responsible for the segment $[l, mid]$, i.e. in total there will be $2 * (mid - l + 1) - 1$ vertices in the left child's subtree. Thus we can compute the index of the right child of $v$. The index will be $v + 2 * (mid - l + 1)$. By this numbering we achieve a reduction of the necessary memory to $2n$.\n\nA Segment Tree is a very flexible data structure, and allows variations and extensions in many different directions. Let's try to categorize them below.\n\nIt can be quite easy to change the Segment Tree in a direction, such that it computes different queries (e.g. computing the minimum / maximum instead of the sum), but it also can be very nontrivial.\n\nLet us slightly change the condition of the problem described above: instead of querying the sum, we will now make maximum queries.\n\nThe tree will have exactly the same structure as the tree described above. We only need to change the way $t[v]$ is computed in the $\\text{build}$ and $\\text{update}$ functions. $t[v]$ will now store the maximum of the corresponding segment. And we also need to change the calculation of the returned value of the $\\text{sum}$ function (replacing the summation by the maximum).\n\nOf course this problem can be easily changed into computing the minimum instead of the maximum.\n\nInstead of showing an implementation to this problem, the implementation will be given to a more complex version of this problem in the next section.\n\nFinding the maximum and the number of times it appears¶\n\nThis task is very similar to the previous one. In addition of finding the maximum, we also have to find the number of occurrences of the maximum.\n\nTo solve this problem, we store a pair of numbers at each vertex in the tree: In addition to the maximum we also store the number of occurrences of it in the corresponding segment. Determining the correct pair to store at $t[v]$ can still be done in constant time using the information of the pairs stored at the child vertices. Combining two such pairs should be done in a separate function, since this will be an operation that we will do while building the tree, while answering maximum queries and while performing modifications.\n\nIn this problem we want to compute the GCD / LCM of all numbers of given ranges of the array.\n\nThis interesting variation of the Segment Tree can be solved in exactly the same way as the Segment Trees we derived for sum / minimum / maximum queries: it is enough to store the GCD / LCM of the corresponding vertex in each vertex of the tree. Combining two vertices can be done by computing the GCD / LCM of both vertices.\n\nCounting the number of zeros, searching for the -th zero¶\n\nIn this problem we want to find the number of zeros in a given range, and additionally find the index of the $k$-th zero using a second function.\n\nAgain we have to change the store values of the tree a bit: This time we will store the number of zeros in each segment in $t[]$. It is pretty clear, how to implement the $\\text{build}$, $\\text{update}$ and $\\text{count_zero}$ functions, we can simply use the ideas from the sum query problem. Thus we solved the first part of the problem.\n\nNow we learn how to solve the problem of finding the $k$-th zero in the array $a[]$. To do this task, we will descend the Segment Tree, starting at the root vertex, and moving each time to either the left or the right child, depending on which segment contains the $k$-th zero. In order to decide to which child we need to go, it is enough to look at the number of zeros appearing in the segment corresponding to the left vertex. If this precomputed count is greater or equal to $k$, it is necessary to descend to the left child, and otherwise descent to the right child. Notice, if we chose the right child, we have to subtract the number of zeros of the left child from $k$.\n\nIn the implementation we can handle the special case, $a[]$ containing less than $k$ zeros, by returning -1.\n\nSearching for an array prefix with a given amount¶\n\nThe task is as follows: for a given value $x$ we have to quickly find smallest index $i$ such that the sum of the first $i$ elements of the array $a[]$ is greater or equal to $x$ (assuming that the array $a[]$ only contains non-negative values).\n\nThis task can be solved using binary search, computing the sum of the prefixes with the Segment Tree. However this will lead to a $O(\\log^2 n)$ solution.\n\nInstead we can use the same idea as in the previous section, and find the position by descending the tree: by moving each time to the left or the right, depending on the sum of the left child. Thus finding the answer in $O(\\log n)$ time.\n\nSearching for the first element greater than a given amount¶\n\nThe task is as follows: for a given value $x$ and a range $a[l \\dots r]$ find the smallest $i$ in the range $a[l \\dots r]$, such that $a[i]$ is greater than $x$.\n\nThis task can be solved using binary search over max prefix queries with the Segment Tree. However, this will lead to a $O(\\log^2 n)$ solution.\n\nInstead, we can use the same idea as in the previous sections, and find the position by descending the tree: by moving each time to the left or the right, depending on the maximum value of the left child. Thus finding the answer in $O(\\log n)$ time.\n\nHere again we receive a range $a[l \\dots r]$ for each query, this time we have to find a subsegment $a[l^\\prime \\dots r^\\prime]$ such that $l \\le l^\\prime$ and $r^\\prime \\le r$ and the sum of the elements of this segment is maximal. As before we also want to be able to modify individual elements of the array. The elements of the array can be negative, and the optimal subsegment can be empty (e.g. if all elements are negative).\n\nThis problem is a non-trivial usage of a Segment Tree. This time we will store four values for each vertex: the sum of the segment, the maximum prefix sum, the maximum suffix sum, and the sum of the maximal subsegment in it. In other words for each segment of the Segment Tree the answer is already precomputed as well as the answers for segments touching the left and the right boundaries of the segment.\n\nHow to build a tree with such data? Again we compute it in a recursive fashion: we first compute all four values for the left and the right child, and then combine those to archive the four values for the current vertex. Note the answer for the current vertex is either:\n• the answer of the left child, which means that the optimal subsegment is entirely placed in the segment of the left child\n• the answer of the right child, which means that the optimal subsegment is entirely placed in the segment of the right child\n• the sum of the maximum suffix sum of the left child and the maximum prefix sum of the right child, which means that the optimal subsegment intersects with both children.\n\nHence the answer to the current vertex is the maximum of these three values. Computing the maximum prefix / suffix sum is even easier. Here is the implementation of the $\\text{combine}$ function, which receives only data from the left and right child, and returns the data of the current vertex.\n\nUsing the $\\text{combine}$ function it is easy to build the Segment Tree. We can implement it in exactly the same way as in the previous implementations. To initialize the leaf vertices, we additionally create the auxiliary function $\\text{make_data}$, which will return a $\\text{data}$ object holding the information of a single value.\n\nIt only remains, how to compute the answer to a query. To answer it, we go down the tree as before, breaking the query into several subsegments that coincide with the segments of the Segment Tree, and combine the answers in them into a single answer for the query. Then it should be clear, that the work is exactly the same as in the simple Segment Tree, but instead of summing / minimizing / maximizing the values, we use the $\\text{combine}$ function.\n\nSaving the entire subarrays in each vertex¶\n\nThis is a separate subsection that stands apart from the others, because at each vertex of the Segment Tree we don't store information about the corresponding segment in compressed form (sum, minimum, maximum, ...), but store all elements of the segment. Thus the root of the Segment Tree will store all elements of the array, the left child vertex will store the first half of the array, the right vertex the second half, and so on.\n\nIn its simplest application of this technique we store the elements in sorted order. In more complex versions the elements are not stored in lists, but more advanced data structures (sets, maps, ...). But all these methods have the common factor, that each vertex requires linear memory (i.e. proportional to the length of the corresponding segment).\n\nThe first natural question, when considering these Segment Trees, is about memory consumption. Intuitively this might look like $O(n^2)$ memory, but it turns out that the complete tree will only need $O(n \\log n)$ memory. Why is this so? Quite simply, because each element of the array falls into $O(\\log n)$ segments (remember the height of the tree is $O(\\log n)$).\n\nSo in spite of the apparent extravagance of such a Segment Tree, it consumes only slightly more memory than the usual Segment Tree.\n\nSeveral typical applications of this data structure are described below. It is worth noting the similarity of these Segment Trees with 2D data structures (in fact this is a 2D data structure, but with rather limited capabilities).\n\nFind the smallest number greater or equal to a specified number. No modification queries.¶\n\nWe want to answer queries of the following form: for three given numbers $(l, r, x)$ we have to find the minimal number in the segment $a[l \\dots r]$ which is greater than or equal to $x$.\n\nWe construct a Segment Tree. In each vertex we store a sorted list of all numbers occurring in the corresponding segment, like described above. How to build such a Segment Tree as effectively as possible? As always we approach this problem recursively: let the lists of the left and right children already be constructed, and we want to build the list for the current vertex. From this view the operation is now trivial and can be accomplished in linear time: We only need to combine the two sorted lists into one, which can be done by iterating over them using two pointers. The C++ STL already has an implementation of this algorithm.\n\nBecause this structure of the Segment Tree and the similarities to the merge sort algorithm, the data structure is also often called \"Merge Sort Tree\".\n\nWe already know that the Segment Tree constructed in this way will require $O(n \\log n)$ memory. And thanks to this implementation its construction also takes $O(n \\log n)$ time, after all each list is constructed in linear time in respect to its size.\n\nNow consider the answer to the query. We will go down the tree, like in the regular Segment Tree, breaking our segment $a[l \\dots r]$ into several subsegments (into at most $O(\\log n)$ pieces). It is clear that the answer of the whole answer is the minimum of each of the subqueries. So now we only need to understand, how to respond to a query on one such subsegment that corresponds with some vertex of the tree.\n\nWe are at some vertex of the Segment Tree and we want to compute the answer to the query, i.e. find the minimum number greater that or equal to a given number $x$. Since the vertex contains the list of elements in sorted order, we can simply perform a binary search on this list and return the first number, greater than or equal to $x$.\n\nThus the answer to the query in one segment of the tree takes $O(\\log n)$ time, and the entire query is processed in $O(\\log^2 n)$.\n\nThe constant $\\text{INF}$ is equal to some large number that is bigger than all numbers in the array. Its usage means, that there is no number greater than or equal to $x$ in the segment. It has the meaning of \"there is no answer in the given interval\".\n\nFind the smallest number greater or equal to a specified number. With modification queries.¶\n\nThis task is similar to the previous. The last approach has a disadvantage, it was not possible to modify the array between answering queries. Now we want to do exactly this: a modification query will do the assignment $a[i] = y$.\n\nThe solution is similar to the solution of the previous problem, but instead of lists at each vertex of the Segment Tree, we will store a balanced list that allows you to quickly search for numbers, delete numbers, and insert new numbers. Since the array can contain a number repeated, the optimal choice is the data structure $\\text{multiset}$.\n\nThe construction of such a Segment Tree is done in pretty much the same way as in the previous problem, only now we need to combine $\\text{multiset}$s and not sorted lists. This leads to a construction time of $O(n \\log^2 n)$ (in general merging two red-black trees can be done in linear time, but the C++ STL doesn't guarantee this time complexity).\n\nThe $\\text{query}$ function is also almost equivalent, only now the $\\text{lower_bound}$ function of the $\\text{multiset}$ function should be called instead ($\\text{std::lower_bound}$ only works in $O(\\log n)$ time if used with random-access iterators).\n\nFinally the modification request. To process it, we must go down the tree, and modify all $\\text{multiset}$ from the corresponding segments that contain the affected element. We simply delete the old value of this element (but only one occurrence), and insert the new value.\n\nProcessing of this modification query also takes $O(\\log^2 n)$ time.\n\nFind the smallest number greater or equal to a specified number. Acceleration with \"fractional cascading\".¶\n\nWe have the same problem statement, we want to find the minimal number greater than or equal to $x$ in a segment, but this time in $O(\\log n)$ time. We will improve the time complexity using the technique \"fractional cascading\".\n\nFractional cascading is a simple technique that allows you to improve the running time of multiple binary searches, which are conducted at the same time. Our previous approach to the search query was, that we divide the task into several subtasks, each of which is solved with a binary search. Fractional cascading allows you to replace all of these binary searches with a single one.\n\nThe simplest and most obvious example of fractional cascading is the following problem: there are $k$ sorted lists of numbers, and we must find in each list the first number greater than or equal to the given number.\n\nInstead of performing a binary search for each list, we could merge all lists into one big sorted list. Additionally for each element $y$ we store a list of results of searching for $y$ in each of the $k$ lists. Therefore if we want to find the smallest number greater than or equal to $x$, we just need to perform one single binary search, and from the list of indices we can determine the smallest number in each list. This approach however requires $O(n \\cdot k)$ ($n$ is the length of the combined lists), which can be quite inefficient.\n\nFractional cascading reduces this memory complexity to $O(n)$ memory, by creating from the $k$ input lists $k$ new lists, in which each list contains the corresponding list and additionally also every second element of the following new list. Using this structure it is only necessary to store two indices, the index of the element in the original list, and the index of the element in the following new list. So this approach only uses $O(n)$ memory, and still can answer the queries using a single binary search.\n\nBut for our application we do not need the full power of fractional cascading. In our Segment Tree a vertex will contain the sorted list of all elements that occur in either the left or the right subtrees (like in the Merge Sort Tree). Additionally to this sorted list, we store two positions for each element. For an element $y$ we store the smallest index $i$, such that the $i$th element in the sorted list of the left child is greater or equal to $y$. And we store the smallest index $j$, such that the $j$th element in the sorted list of the right child is greater or equal to $y$. These values can be computed in parallel to the merging step when we build the tree.\n\nHow does this speed up the queries?\n\nRemember, in the normal solution we did a binary search in every node. But with this modification, we can avoid all except one.\n\nTo answer a query, we simply do a binary search in the root node. This gives us the smallest element $y \\ge x$ in the complete array, but it also gives us two positions. The index of the smallest element greater or equal $x$ in the left subtree, and the index of the smallest element $y$ in the right subtree. Notice that $\\ge y$ is the same as $\\ge x$, since our array doesn't contain any elements between $x$ and $y$. In the normal Merge Sort Tree solution we would compute these indices via binary search, but with the help of the precomputed values we can just look them up in $O(1)$. And we can repeat that until we visited all nodes that cover our query interval.\n\nTo summarize, as usual we touch $O(\\log n)$ nodes during a query. In the root node we do a binary search, and in all other nodes we only do constant work. This means the complexity for answering a query is $O(\\log n)$.\n\nBut notice, that this uses three times more memory than a normal Merge Sort Tree, which already uses a lot of memory ($O(n \\log n)$).\n\nIt is straightforward to apply this technique to a problem, that doesn't require any modification queries. The two positions are just integers and can easily be computed by counting when merging the two sorted sequences.\n\nIt it still possible to also allow modification queries, but that complicates the entire code. Instead of integers, you need to store the sorted array as , and instead of indices you need to store iterators. And you need to work very carefully, so that you increment or decrement the correct iterators during a modification query.\n\nThis technique implies a whole new class of possible applications. Instead of storing a $\\text{vector}$ or a $\\text{multiset}$ in each vertex, other data structures can be used: other Segment Trees (somewhat discussed in Generalization to higher dimensions), Fenwick Trees, Cartesian trees, etc.\n\nAll problems in the above sections discussed modification queries that only affected a single element of the array each. However the Segment Tree allows applying modification queries to an entire segment of contiguous elements, and perform the query in the same time $O(\\log n)$.\n\nWe begin by considering problems of the simplest form: the modification query should add a number $x$ to all numbers in the segment $a[l \\dots r]$. The second query, that we are supposed to answer, asked simply for the value of $a[i]$.\n\nTo make the addition query efficient, we store at each vertex in the Segment Tree how many we should add to all numbers in the corresponding segment. For example, if the query \"add 3 to the whole array $a[0 \\dots n-1]$\" comes, then we place the number 3 in the root of the tree. In general we have to place this number to multiple segments, which form a partition of the query segment. Thus we don't have to change all $O(n)$ values, but only $O(\\log n)$ many.\n\nIf now there comes a query that asks the current value of a particular array entry, it is enough to go down the tree and add up all values found along the way.\n\nSuppose now that the modification query asks to assign each element of a certain segment $a[l \\dots r]$ to some value $p$. As a second query we will again consider reading the value of the array $a[i]$.\n\nTo perform this modification query on a whole segment, you have to store at each vertex of the Segment Tree whether the corresponding segment is covered entirely with the same value or not. This allows us to make a \"lazy\" update: instead of changing all segments in the tree that cover the query segment, we only change some, and leave others unchanged. A marked vertex will mean, that every element of the corresponding segment is assigned to that value, and actually also the complete subtree should only contain this value. In a sense we are lazy and delay writing the new value to all those vertices. We can do this tedious task later, if this is necessary.\n\nSo after the modification query is executed, some parts of the tree become irrelevant - some modifications remain unfulfilled in it.\n\nFor example if a modification query \"assign a number to the whole array $a[0 \\dots n-1]$\" gets executed, in the Segment Tree only a single change is made - the number is placed in the root of the tree and this vertex gets marked. The remaining segments remain unchanged, although in fact the number should be placed in the whole tree.\n\nSuppose now that the second modification query says, that the first half of the array $a[0 \\dots n/2]$ should be assigned with some other number. To process this query we must assign each element in the whole left child of the root vertex with that number. But before we do this, we must first sort out the root vertex first. The subtlety here is that the right half of the array should still be assigned to the value of the first query, and at the moment there is no information for the right half stored.\n\nThe way to solve this is to push the information of the root to its children, i.e. if the root of the tree was assigned with any number, then we assign the left and the right child vertices with this number and remove the mark of the root. After that, we can assign the left child with the new value, without losing any necessary information.\n\nSummarizing we get: for any queries (a modification or reading query) during the descent along the tree we should always push information from the current vertex into both of its children. We can understand this in such a way, that when we descent the tree we apply delayed modifications, but exactly as much as necessary (so not to degrade the complexity of $O(\\log n)$).\n\nFor the implementation we need to make a $\\text{push}$ function, which will receive the current vertex, and it will push the information for its vertex to both its children. We will call this function at the beginning of the query functions (but we will not call it from the leaves, because there is no need to push information from them any further).\n\nNotice: the function $\\text{get}$ can also be implemented in a different way: do not make delayed updates, but immediately return the value $t[v]$ if $marked[v]$ is true.\n\nNow the modification query is to add a number to all elements in a range, and the reading query is to find the maximum in a range.\n\nSo for each vertex of the Segment Tree we have to store the maximum of the corresponding subsegment. The interesting part is how to recompute these values during a modification request.\n\nFor this purpose we keep store an additional value for each vertex. In this value we store the addends we haven't propagated to the child vertices. Before traversing to a child vertex, we call $\\text{push}$ and propagate the value to both children. We have to do this in both the $\\text{update}$ function and the $\\text{query}$ function.\n\nA Segment Tree can be generalized quite natural to higher dimensions. If in the one-dimensional case we split the indices of the array into segments, then in the two-dimensional we make an ordinary Segment Tree with respect to the first indices, and for each segment we build an ordinary Segment Tree with respect to the second indices.\n\nA matrix $a[0 \\dots n-1, 0 \\dots m-1]$ is given, and we have to find the sum (or minimum/maximum) on some submatrix $a[x_1 \\dots x_2, y_1 \\dots y_2]$, as well as perform modifications of individual matrix elements (i.e. queries of the form $a[x][y] = p$).\n\nSo we build a 2D Segment Tree: first the Segment Tree using the first coordinate ($x$), then the second ($y$).\n\nTo make the construction process more understandable, you can forget for a while that the matrix is two-dimensional, and only leave the first coordinate. We will construct an ordinary one-dimensional Segment Tree using only the first coordinate. But instead of storing a number in a segment, we store an entire Segment Tree: i.e. at this moment we remember that we also have a second coordinate; but because at this moment the first coordinate is already fixed to some interval $[l \\dots r]$, we actually work with such a strip $a[l \\dots r, 0 \\dots m-1]$ and for it we build a Segment Tree.\n\nHere is the implementation of the construction of a 2D Segment Tree. It actually represents two separate blocks: the construction of a Segment Tree along the $x$ coordinate ($\\text{build}_x$), and the $y$ coordinate ($\\text{build}_y$). For the leaf nodes in $\\text{build}_y$ we have to separate two cases: when the current segment of the first coordinate $[tlx \\dots trx]$ has length 1, and when it has a length greater than one. In the first case, we just take the corresponding value from the matrix, and in the second case we can combine the values of two Segment Trees from the left and the right son in the coordinate $x$.\n\nSuch a Segment Tree still uses a linear amount of memory, but with a larger constant: $16 n m$. It is clear that the described procedure $\\text{build}_x$ also works in linear time.\n\nNow we turn to processing of queries. We will answer to the two-dimensional query using the same principle: first break the query on the first coordinate, and then for every reached vertex, we call the corresponding Segment Tree of the second coordinate.\n\nThis function works in $O(\\log n \\log m)$ time, since it first descends the tree in the first coordinate, and for each traversed vertex in the tree it makes a query in the corresponding Segment Tree along the second coordinate.\n\nFinally we consider the modification query. We want to learn how to modify the Segment Tree in accordance with the change in the value of some element $a[x][y] = p$. It is clear, that the changes will occur only in those vertices of the first Segment Tree that cover the coordinate $x$ (and such will be $O(\\log n)$), and for Segment Trees corresponding to them the changes will only occurs at those vertices that covers the coordinate $y$ (and such will be $O(\\log m)$). Therefore the implementation will be not very different form the one-dimensional case, only now we first descend the first coordinate, and then the second.\n\nLet the problem be the following: there are $n$ points on the plane given by their coordinates $(x_i, y_i)$ and queries of the form \"count the number of points lying in the rectangle $((x_1, y_1), (x_2, y_2))$\". It is clear that in the case of such a problem it becomes unreasonably wasteful to construct a two-dimensional Segment Tree with $O(n^2)$ elements. Most on this memory will be wasted, since each single point can only get into $O(\\log n)$ segments of the tree along the first coordinate, and therefore the total \"useful\" size of all tree segments on the second coordinate is $O(n \\log n)$.\n\nSo we proceed as follows: at each vertex of the Segment Tree with respect to the first coordinate we store a Segment Tree constructed only by those second coordinates that occur in the current segment of the first coordinates. In other words, when constructing a Segment Tree inside some vertex with index $vx$ and the boundaries $tlx$ and $trx$, we only consider those points that fall into this interval $x \\in [tlx, trx]$, and build a Segment Tree just using them.\n\nThus we will achieve that each Segment Tree on the second coordinate will occupy exactly as much memory as it should. As a result, the total amount of memory will decrease to $O(n \\log n)$. We still can answer the queries in $O(\\log^2 n)$ time, we just have to make a binary search on the second coordinate, but this will not worsen the complexity.\n\nBut modification queries will be impossible with this structure: in fact if a new point appears, we have to add a new element in the middle of some Segment Tree along the second coordinate, which cannot be effectively done.\n\nIn conclusion we note that the two-dimensional Segment Tree contracted in the described way becomes practically equivalent to the modification of the one-dimensional Segment Tree (see Saving the entire subarrays in each vertex). In particular the two-dimensional Segment Tree is just a special case of storing a subarray in each vertex of the tree. It follows, that if you gave to abandon a two-dimensional Segment Tree due to the impossibility of executing a query, it makes sense to try to replace the nested Segment Tree with some more powerful data structure, for example a Cartesian tree.\n\nPreserving the history of its values (Persistent Segment Tree)¶\n\nA persistent data structure is a data structure that remembers it previous state for each modification. This allows to access any version of this data structure that interest us and execute a query on it.\n\nSegment Tree is a data structure that can be turned into a persistent data structure efficiently (both in time and memory consumption). We want to avoid copying the complete tree before each modification, and we don't want to loose the $O(\\log n)$ time behavior for answering range queries.\n\nIn fact, any change request in the Segment Tree leads to a change in the data of only $O(\\log n)$ vertices along the path starting from the root. So if we store the Segment Tree using pointers (i.e. a vertex stores pointers to the left and the right child vertices), then when performing the modification query, we simply need to create new vertices instead of changing the available vertices. Vertices that are not affected by the modification query can still be used by pointing the pointers to the old vertices. Thus for a modification query $O(\\log n)$ new vertices will be created, including a new root vertex of the Segment Tree, and the entire previous version of the tree rooted at the old root vertex will remain unchanged.\n\nLet's give an example implementation for the simplest Segment Tree: when there is only a query asking for sums, and modification queries of single elements.\n\nFor each modification of the Segment Tree we will receive a new root vertex. To quickly jump between two different versions of the Segment Tree, we need to store this roots in an array. To use a specific version of the Segment Tree we simply call the query using the appropriate root vertex.\n\nWith the approach described above almost any Segment Tree can be turned into a persistent data structure.\n\nThis time we have to answer queries of the form \"What is the $k$-th smallest element in the range $a[l \\dots r]$. This query can be answered using a binary search and a Merge Sort Tree, but the time complexity for a single query would be $O(\\log^3 n)$. We will accomplish the same task using a persistent Segment Tree in $O(\\log n)$.\n\nFirst we will discuss a solution for a simpler problem: We will only consider arrays in which the elements are bound by $0 \\le a[i] \\lt n$. And we only want to find the $k$-th smallest element in some prefix of the array $a$. It will be very easy to extent the developed ideas later for not restricted arrays and not restricted range queries. Note that we will be using 1 based indexing for $a$.\n\nWe will use a Segment Tree that counts all appearing numbers, i.e. in the Segment Tree we will store the histogram of the array. So the leaf vertices will store how often the values $0$, $1$, $\\dots$, $n-1$ will appear in the array, and the other vertices store how many numbers in some range are in the array. In other words we create a regular Segment Tree with sum queries over the histogram of the array. But instead of creating all $n$ Segment Trees for every possible prefix, we will create one persistent one, that will contain the same information. We will start with an empty Segment Tree (all counts will be $0$) pointed to by $root_0$, and add the elements $a[1]$, $a[2]$, $\\dots$, $a[n]$ one after another. For each modification we will receive a new root vertex, let's call $root_i$ the root of the Segment Tree after inserting the first $i$ elements of the array $a$. The Segment Tree rooted at $root_i$ will contain the histogram of the prefix $a[1 \\dots i]$. Using this Segment Tree we can find in $O(\\log n)$ time the position of the $k$-th element using the same technique discussed in Counting the number of zeros, searching for the $k$-th zero.\n\nNow to the not-restricted version of the problem.\n\nFirst for the restriction on the queries: Instead of only performing these queries over a prefix of $a$, we want to use any arbitrary segments $a[l \\dots r]$. Here we need a Segment Tree that represents the histogram of the elements in the range $a[l \\dots r]$. It is easy to see that such a Segment Tree is just the difference between the Segment Tree rooted at $root_{r}$ and the Segment Tree rooted at $root_{l-1}$, i.e. every vertex in the $[l \\dots r]$ Segment Tree can be computed with the vertex of the $root_{r}$ tree minus the vertex of the $root_{l-1}$ tree.\n\nIn the implementation of the $\\text{find_kth}$ function this can be handled by passing two vertex pointer and computing the count/sum of the current segment as difference of the two counts/sums of the vertices.\n\nHere are the modified $\\text{build}$, $\\text{update}$ and $\\text{find_kth}$ functions\n\nAs already written above, we need to store the root of the initial Segment Tree, and also all the roots after each update. Here is the code for building a persistent Segment Tree over an vector with elements in the range .\n\nNow to the restrictions on the array elements: We can actually transform any array to such an array by index compression. The smallest element in the array will gets assigned the value 0, the second smallest the value 1, and so forth. It is easy to generate lookup tables (e.g. using $\\text{map}$), that convert a value to its index and vice versa in $O(\\log n)$ time.\n\nPreviously, we considered cases when we have the ability to build the original segment tree. But what to do if the original size is filled with some default element, but its size does not allow you to completely build up to it in advance?\n\nWe can solve this problem by creating a segment tree lazily (incrementally). Initially, we will create only the root, and we will create the other vertexes only when we need them. In this case, we will use the implementation on pointers(before going to the vertex children, check whether they are created, and if not, create them). Each query has still only the complexity $O(\\log n)$, which is small enough for most use-cases (e.g. $\\log_2 10^9 \\approx 30$).\n\nIn this implementation we have two queries, adding a value to a position (initially all values are $0$), and computing the sum of all values in a range. will be the root vertex of the implicit tree.\n\nObviously this idea can be extended in lots of different ways. E.g. by adding support for range updates via lazy propagation.\n• Codeforces - Please, another Queries on Array? [Lazy propagation]\n• COCI - Deda [Last element smaller or equal to x / Binary search]"
    },
    {
        "link": "https://geeksforgeeks.org/segment-tree-efficient-implementation",
        "document": "Let us consider the following problem to understand Segment Trees without recursion.\n\nWe have an array arr[0 . . . n-1]. We should be able to,\n• None Find the sum of elements from index l to r where 0 <= l <= r <= n-1\n• None Change the value of a specified element of the array to a new value x. We need to do arr[i] = x where 0 <= i <= n-1.\n\nA simple solution is to run a loop from l to r and calculate the sum of elements in the given range. To update a value, simply do arr[i] = x. The first operation takes O(n) time and the second operation takes O(1) time.\n\n\n\nAnother solution is to create another array and store the sum from start to i at the ith index in this array. The sum of a given range can now be calculated in O(1) time, but the update operation takes O(n) time now. This works well if the number of query operations is large and there are very few updates.\n\nWhat if the number of queries and updates are equal? Can we perform both the operations in O(log n) time once given the array? We can use a Segment Tree to do both operations in O(Logn) time. We have discussed the complete implementation of segment trees in our previous post. In this post, we will discuss the easier and yet efficient implementation of segment trees than in the previous post.\n\nConsider the array and segment tree as shown below:\n\n\n\nYou can see from the above image that the original array is at the bottom and is 0-indexed with 16 elements. The tree contains a total of 31 nodes where the leaf nodes or the elements of the original array start from node 16. So, we can easily construct a segment tree for this array using a 2*N sized array where N is the number of elements in the original array. The leaf nodes will start from index N in this array and will go up to index (2*N – 1). Therefore, the element at index i in the original array will be at index (i + N) in the segment tree array. Now to calculate the parents, we will start from the index (N – 1) and move upward. For index i , the left child will be at (2 * i) and the right child will be at (2*i + 1) index. So the values at nodes at (2 * i) and (2*i + 1) are combined at i-th node to construct the tree. \n\nAs you can see in the above figure, we can query in this tree in an interval [L,R) with left index(L) included and right (R) excluded.\n\nWe will implement all of these multiplication and addition operations using bitwise operators.\n\nLet us have a look at the complete implementation:\n\n// function to get sum on interval [l, r) // loop to find the sum in the range // driver program to test the above function // function to get sum on // loop to find the sum in the range // This code is contributed by vt_m. # function to get sum on interval [l, r) # loop to find the sum in the range # This code is contributed by AnkitRai01 // function to get sum on // loop to find the sum in the range // This code is contributed by vt_m. // function to get sum on // loop to find the sum in the range\n\n\n\nYes! That is all. The complete implementation of the segment tree includes the query and update functions in a lower number of lines of code than the previous recursive one. Let us now understand how each of the functions works: \n\n\n\n1. The picture makes it clear that the leaf nodes are stored at i+n, so we can clearly insert all leaf nodes directly.\n\n2. The next step is to build the tree and it takes O(n) time. The parent always has its less index than its children, so we just process all the nodes in decreasing order, calculating the value of the parent node. If the code inside the build function to calculate parents seems confusing, then you can see this code. It is equivalent to that inside the build function.\n\n3. Updating a value at any position is also simple and the time taken will be proportional to the height of the tree. We only update values in the parents of the given node which is being changed. So to get the parent, we just go up to the parent node, which is p/2 or p>>1, for node p. p^1 turns (2*i) to (2*i + 1) and vice versa to get the second child of p.\n\n4. Computing the sum also works in O(log(n)) time. If we work through an interval of [3,11), we need to calculate only for nodes 19,26,12, and 5 in that order.\n\n\n\nThe idea behind the query function is whether we should include an element in the sum or whether we should include its parent. Let’s look at the image once again for proper understanding. Consider that L is the left border of an interval and R is the right border of the interval [L,R). It is clear from the image that if L is odd, then it means that it is the right child of its parent and our interval includes only L and not the parent. So we will simply include this node to sum and move to the parent of its next node by doing L = (L+1)/2. Now, if L is even, then it is the left child of its parent and the interval includes its parent also unless the right borders interfere. Similar conditions are applied to the right border also for faster computation. We will stop this iteration once the left and right borders meet.\n\nThe theoretical time complexities of both previous implementation and this implementation is the same, but practically, it is found to be much more efficient as there are no recursive calls. We simply iterate over the elements that we need. Also, this is very easy to implement."
    },
    {
        "link": "https://cp-algorithms.com/data_structures/segment_tree.html",
        "document": "A Segment Tree is a data structure that stores information about array intervals as a tree. This allows answering range queries over an array efficiently, while still being flexible enough to allow quick modification of the array. This includes finding the sum of consecutive array elements $a[l \\dots r]$, or finding the minimum element in a such a range in $O(\\log n)$ time. Between answering such queries, the Segment Tree allows modifying the array by replacing one element, or even changing the elements of a whole subsegment (e.g. assigning all elements $a[l \\dots r]$ to any value, or adding a value to all element in the subsegment).\n\nIn general, a Segment Tree is a very flexible data structure, and a huge number of problems can be solved with it. Additionally, it is also possible to apply more complex operations and answer more complex queries (see Advanced versions of Segment Trees). In particular the Segment Tree can be easily generalized to larger dimensions. For instance, with a two-dimensional Segment Tree you can answer sum or minimum queries over some subrectangle of a given matrix in only $O(\\log^2 n)$ time.\n\nOne important property of Segment Trees is that they require only a linear amount of memory. The standard Segment Tree requires $4n$ vertices for working on an array of size $n$.\n\nTo start easy, we consider the simplest form of a Segment Tree. We want to answer sum queries efficiently. The formal definition of our task is: Given an array $a[0 \\dots n-1]$, the Segment Tree must be able to find the sum of elements between the indices $l$ and $r$ (i.e. computing the sum $\\sum_{i=l}^r a[i]$), and also handle changing values of the elements in the array (i.e. perform assignments of the form $a[i] = x$). The Segment Tree should be able to process both queries in $O(\\log n)$ time.\n\nThis is an improvement over the simpler approaches. A naive array implementation - just using a simple array - can update elements in $O(1)$, but requires $O(n)$ to compute each sum query. And precomputed prefix sums can compute sum queries in $O(1)$, but updating an array element requires $O(n)$ changes to the prefix sums.\n\nWe can take a divide-and-conquer approach when it comes to array segments. We compute and store the sum of the elements of the whole array, i.e. the sum of the segment $a[0 \\dots n-1]$. We then split the array into two halves $a[0 \\dots n/2-1]$ and $a[n/2 \\dots n-1]$ and compute the sum of each halve and store them. Each of these two halves in turn are split in half, and so on until all segments reach size $1$.\n\nWe can view these segments as forming a binary tree: the root of this tree is the segment $a[0 \\dots n-1]$, and each vertex (except leaf vertices) has exactly two child vertices. This is why the data structure is called \"Segment Tree\", even though in most implementations the tree is not constructed explicitly (see Implementation).\n\nHere is a visual representation of such a Segment Tree over the array $a = [1, 3, -2, 8, -7]$:\n\nFrom this short description of the data structure, we can already conclude that a Segment Tree only requires a linear number of vertices. The first level of the tree contains a single node (the root), the second level will contain two vertices, in the third it will contain four vertices, until the number of vertices reaches $n$. Thus the number of vertices in the worst case can be estimated by the sum $1 + 2 + 4 + \\dots + 2^{\\lceil\\log_2 n\\rceil} \\lt 2^{\\lceil\\log_2 n\\rceil + 1} \\lt 4n$.\n\nIt is worth noting that whenever $n$ is not a power of two, not all levels of the Segment Tree will be completely filled. We can see that behavior in the image. For now we can forget about this fact, but it will become important later during the implementation.\n\nThe height of the Segment Tree is $O(\\log n)$, because when going down from the root to the leaves the size of the segments decreases approximately by half.\n\nBefore constructing the segment tree, we need to decide:\n• the value that gets stored at each node of the segment tree. For example, in a sum segment tree, a node would store the sum of the elements in its range .\n• the merge operation that merges two siblings in a segment tree. For example, in a sum segment tree, the two nodes corresponding to the ranges and would be merged into a node corresponding to the range by adding the values of the two nodes.\n\nNote that a vertex is a \"leaf vertex\", if its corresponding segment covers only one value in the original array. It is present at the lowermost level of a segment tree. Its value would be equal to the (corresponding) element $a[i]$.\n\nNow, for construction of the segment tree, we start at the bottom level (the leaf vertices) and assign them their respective values. On the basis of these values, we can compute the values of the previous level, using the function. And on the basis of those, we can compute the values of the previous, and repeat the procedure until we reach the root vertex.\n\nIt is convenient to describe this operation recursively in the other direction, i.e., from the root vertex to the leaf vertices. The construction procedure, if called on a non-leaf vertex, does the following:\n• recursively construct the values of the two child vertices\n• merge the computed values of these children.\n\nWe start the construction at the root vertex, and hence, we are able to compute the entire segment tree.\n\nThe time complexity of this construction is $O(n)$, assuming that the merge operation is constant time (the merge operation gets called $n$ times, which is equal to the number of internal nodes in the segment tree).\n\nFor now we are going to answer sum queries. As an input we receive two integers $l$ and $r$, and we have to compute the sum of the segment $a[l \\dots r]$ in $O(\\log n)$ time.\n\nTo do this, we will traverse the Segment Tree and use the precomputed sums of the segments. Let's assume that we are currently at the vertex that covers the segment $a[tl \\dots tr]$. There are three possible cases.\n\nThe easiest case is when the segment $a[l \\dots r]$ is equal to the corresponding segment of the current vertex (i.e. $a[l \\dots r] = a[tl \\dots tr]$), then we are finished and can return the precomputed sum that is stored in the vertex.\n\nAlternatively the segment of the query can fall completely into the domain of either the left or the right child. Recall that the left child covers the segment $a[tl \\dots tm]$ and the right vertex covers the segment $a[tm + 1 \\dots tr]$ with $tm = (tl + tr) / 2$. In this case we can simply go to the child vertex, which corresponding segment covers the query segment, and execute the algorithm described here with that vertex.\n\nAnd then there is the last case, the query segment intersects with both children. In this case we have no other option as to make two recursive calls, one for each child. First we go to the left child, compute a partial answer for this vertex (i.e. the sum of values of the intersection between the segment of the query and the segment of the left child), then go to the right child, compute the partial answer using that vertex, and then combine the answers by adding them. In other words, since the left child represents the segment $a[tl \\dots tm]$ and the right child the segment $a[tm+1 \\dots tr]$, we compute the sum query $a[l \\dots tm]$ using the left child, and the sum query $a[tm+1 \\dots r]$ using the right child.\n\nSo processing a sum query is a function that recursively calls itself once with either the left or the right child (without changing the query boundaries), or twice, once for the left and once for the right child (by splitting the query into two subqueries). And the recursion ends, whenever the boundaries of the current query segment coincides with the boundaries of the segment of the current vertex. In that case the answer will be the precomputed value of the sum of this segment, which is stored in the tree.\n\nIn other words, the calculation of the query is a traversal of the tree, which spreads through all necessary branches of the tree, and uses the precomputed sum values of the segments in the tree.\n\nObviously we will start the traversal from the root vertex of the Segment Tree.\n\nThe procedure is illustrated in the following image. Again the array $a = [1, 3, -2, 8, -7]$ is used, and here we want to compute the sum $\\sum_{i=2}^4 a[i]$. The colored vertices will be visited, and we will use the precomputed values of the green vertices. This gives us the result $-2 + 1 = -1$.\n\nWhy is the complexity of this algorithm $O(\\log n)$? To show this complexity we look at each level of the tree. It turns out, that for each level we only visit not more than four vertices. And since the height of the tree is $O(\\log n)$, we receive the desired running time.\n\nWe can show that this proposition (at most four vertices each level) is true by induction. At the first level, we only visit one vertex, the root vertex, so here we visit less than four vertices. Now let's look at an arbitrary level. By induction hypothesis, we visit at most four vertices. If we only visit at most two vertices, the next level has at most four vertices. That is trivial, because each vertex can only cause at most two recursive calls. So let's assume that we visit three or four vertices in the current level. From those vertices, we will analyze the vertices in the middle more carefully. Since the sum query asks for the sum of a continuous subarray, we know that segments corresponding to the visited vertices in the middle will be completely covered by the segment of the sum query. Therefore these vertices will not make any recursive calls. So only the most left, and the most right vertex will have the potential to make recursive calls. And those will only create at most four recursive calls, so also the next level will satisfy the assertion. We can say that one branch approaches the left boundary of the query, and the second branch approaches the right one.\n\nTherefore we visit at most $4 \\log n$ vertices in total, and that is equal to a running time of $O(\\log n)$.\n\nIn conclusion the query works by dividing the input segment into several sub-segments for which all the sums are already precomputed and stored in the tree. And if we stop partitioning whenever the query segment coincides with the vertex segment, then we only need $O(\\log n)$ such segments, which gives the effectiveness of the Segment Tree.\n\nNow we want to modify a specific element in the array, let's say we want to do the assignment $a[i] = x$. And we have to rebuild the Segment Tree, such that it corresponds to the new, modified array.\n\nThis query is easier than the sum query. Each level of a Segment Tree forms a partition of the array. Therefore an element $a[i]$ only contributes to one segment from each level. Thus only $O(\\log n)$ vertices need to be updated.\n\nIt is easy to see, that the update request can be implemented using a recursive function. The function gets passed the current tree vertex, and it recursively calls itself with one of the two child vertices (the one that contains $a[i]$ in its segment), and after that recomputes its sum value, similar how it is done in the build method (that is as the sum of its two children).\n\nAgain here is a visualization using the same array. Here we perform the update $a[2] = 3$. The green vertices are the vertices that we visit and update.\n\nThe main consideration is how to store the Segment Tree. Of course we can define a $\\text{Vertex}$ struct and create objects, that store the boundaries of the segment, its sum and additionally also pointers to its child vertices. However, this requires storing a lot of redundant information in the form of pointers. We will use a simple trick to make this a lot more efficient by using an implicit data structure: Only storing the sums in an array. (A similar method is used for binary heaps). The sum of the root vertex at index 1, the sums of its two child vertices at indices 2 and 3, the sums of the children of those two vertices at indices 4 to 7, and so on. With 1-indexing, conveniently the left child of a vertex at index $i$ is stored at index $2i$, and the right one at index $2i + 1$. Equivalently, the parent of a vertex at index $i$ is stored at $i/2$ (integer division).\n\nThis simplifies the implementation a lot. We don't need to store the structure of the tree in memory. It is defined implicitly. We only need one array which contains the sums of all segments.\n\nAs noted before, we need to store at most $4n$ vertices. It might be less, but for convenience we always allocate an array of size $4n$. There will be some elements in the sum array, that will not correspond to any vertices in the actual tree, but this doesn't complicate the implementation.\n\nSo, we store the Segment Tree simply as an array $t[]$ with a size of four times the input size $n$:\n\nThe procedure for constructing the Segment Tree from a given array $a[]$ looks like this: it is a recursive function with the parameters $a[]$ (the input array), $v$ (the index of the current vertex), and the boundaries $tl$ and $tr$ of the current segment. In the main program this function will be called with the parameters of the root vertex: $v = 1$, $tl = 0$, and $tr = n - 1$.\n\nFurther the function for answering sum queries is also a recursive function, which receives as parameters information about the current vertex/segment (i.e. the index $v$ and the boundaries $tl$ and $tr$) and also the information about the boundaries of the query, $l$ and $r$. In order to simplify the code, this function always does two recursive calls, even if only one is necessary - in that case the superfluous recursive call will have $l > r$, and this can easily be caught using an additional check at the beginning of the function.\n\nFinally the update query. The function will also receive information about the current vertex/segment, and additionally also the parameter of the update query (i.e. the position of the element and its new value).\n\nMost people use the implementation from the previous section. If you look at the array you can see that it follows the numbering of the tree nodes in the order of a BFS traversal (level-order traversal). Using this traversal the children of vertex $v$ are $2v$ and $2v + 1$ respectively. However if $n$ is not a power of two, this method will skip some indices and leave some parts of the array unused. The memory consumption is limited by $4n$, even though a Segment Tree of an array of $n$ elements requires only $2n - 1$ vertices.\n\nHowever it can be reduced. We renumber the vertices of the tree in the order of an Euler tour traversal (pre-order traversal), and we write all these vertices next to each other.\n\nLet's look at a vertex at index $v$, and let it be responsible for the segment $[l, r]$, and let $mid = \\dfrac{l + r}{2}$. It is obvious that the left child will have the index $v + 1$. The left child is responsible for the segment $[l, mid]$, i.e. in total there will be $2 * (mid - l + 1) - 1$ vertices in the left child's subtree. Thus we can compute the index of the right child of $v$. The index will be $v + 2 * (mid - l + 1)$. By this numbering we achieve a reduction of the necessary memory to $2n$.\n\nA Segment Tree is a very flexible data structure, and allows variations and extensions in many different directions. Let's try to categorize them below.\n\nIt can be quite easy to change the Segment Tree in a direction, such that it computes different queries (e.g. computing the minimum / maximum instead of the sum), but it also can be very nontrivial.\n\nLet us slightly change the condition of the problem described above: instead of querying the sum, we will now make maximum queries.\n\nThe tree will have exactly the same structure as the tree described above. We only need to change the way $t[v]$ is computed in the $\\text{build}$ and $\\text{update}$ functions. $t[v]$ will now store the maximum of the corresponding segment. And we also need to change the calculation of the returned value of the $\\text{sum}$ function (replacing the summation by the maximum).\n\nOf course this problem can be easily changed into computing the minimum instead of the maximum.\n\nInstead of showing an implementation to this problem, the implementation will be given to a more complex version of this problem in the next section.\n\nFinding the maximum and the number of times it appears¶\n\nThis task is very similar to the previous one. In addition of finding the maximum, we also have to find the number of occurrences of the maximum.\n\nTo solve this problem, we store a pair of numbers at each vertex in the tree: In addition to the maximum we also store the number of occurrences of it in the corresponding segment. Determining the correct pair to store at $t[v]$ can still be done in constant time using the information of the pairs stored at the child vertices. Combining two such pairs should be done in a separate function, since this will be an operation that we will do while building the tree, while answering maximum queries and while performing modifications.\n\nIn this problem we want to compute the GCD / LCM of all numbers of given ranges of the array.\n\nThis interesting variation of the Segment Tree can be solved in exactly the same way as the Segment Trees we derived for sum / minimum / maximum queries: it is enough to store the GCD / LCM of the corresponding vertex in each vertex of the tree. Combining two vertices can be done by computing the GCD / LCM of both vertices.\n\nCounting the number of zeros, searching for the -th zero¶\n\nIn this problem we want to find the number of zeros in a given range, and additionally find the index of the $k$-th zero using a second function.\n\nAgain we have to change the store values of the tree a bit: This time we will store the number of zeros in each segment in $t[]$. It is pretty clear, how to implement the $\\text{build}$, $\\text{update}$ and $\\text{count_zero}$ functions, we can simply use the ideas from the sum query problem. Thus we solved the first part of the problem.\n\nNow we learn how to solve the problem of finding the $k$-th zero in the array $a[]$. To do this task, we will descend the Segment Tree, starting at the root vertex, and moving each time to either the left or the right child, depending on which segment contains the $k$-th zero. In order to decide to which child we need to go, it is enough to look at the number of zeros appearing in the segment corresponding to the left vertex. If this precomputed count is greater or equal to $k$, it is necessary to descend to the left child, and otherwise descent to the right child. Notice, if we chose the right child, we have to subtract the number of zeros of the left child from $k$.\n\nIn the implementation we can handle the special case, $a[]$ containing less than $k$ zeros, by returning -1.\n\nSearching for an array prefix with a given amount¶\n\nThe task is as follows: for a given value $x$ we have to quickly find smallest index $i$ such that the sum of the first $i$ elements of the array $a[]$ is greater or equal to $x$ (assuming that the array $a[]$ only contains non-negative values).\n\nThis task can be solved using binary search, computing the sum of the prefixes with the Segment Tree. However this will lead to a $O(\\log^2 n)$ solution.\n\nInstead we can use the same idea as in the previous section, and find the position by descending the tree: by moving each time to the left or the right, depending on the sum of the left child. Thus finding the answer in $O(\\log n)$ time.\n\nSearching for the first element greater than a given amount¶\n\nThe task is as follows: for a given value $x$ and a range $a[l \\dots r]$ find the smallest $i$ in the range $a[l \\dots r]$, such that $a[i]$ is greater than $x$.\n\nThis task can be solved using binary search over max prefix queries with the Segment Tree. However, this will lead to a $O(\\log^2 n)$ solution.\n\nInstead, we can use the same idea as in the previous sections, and find the position by descending the tree: by moving each time to the left or the right, depending on the maximum value of the left child. Thus finding the answer in $O(\\log n)$ time.\n\nHere again we receive a range $a[l \\dots r]$ for each query, this time we have to find a subsegment $a[l^\\prime \\dots r^\\prime]$ such that $l \\le l^\\prime$ and $r^\\prime \\le r$ and the sum of the elements of this segment is maximal. As before we also want to be able to modify individual elements of the array. The elements of the array can be negative, and the optimal subsegment can be empty (e.g. if all elements are negative).\n\nThis problem is a non-trivial usage of a Segment Tree. This time we will store four values for each vertex: the sum of the segment, the maximum prefix sum, the maximum suffix sum, and the sum of the maximal subsegment in it. In other words for each segment of the Segment Tree the answer is already precomputed as well as the answers for segments touching the left and the right boundaries of the segment.\n\nHow to build a tree with such data? Again we compute it in a recursive fashion: we first compute all four values for the left and the right child, and then combine those to archive the four values for the current vertex. Note the answer for the current vertex is either:\n• the answer of the left child, which means that the optimal subsegment is entirely placed in the segment of the left child\n• the answer of the right child, which means that the optimal subsegment is entirely placed in the segment of the right child\n• the sum of the maximum suffix sum of the left child and the maximum prefix sum of the right child, which means that the optimal subsegment intersects with both children.\n\nHence the answer to the current vertex is the maximum of these three values. Computing the maximum prefix / suffix sum is even easier. Here is the implementation of the $\\text{combine}$ function, which receives only data from the left and right child, and returns the data of the current vertex.\n\nUsing the $\\text{combine}$ function it is easy to build the Segment Tree. We can implement it in exactly the same way as in the previous implementations. To initialize the leaf vertices, we additionally create the auxiliary function $\\text{make_data}$, which will return a $\\text{data}$ object holding the information of a single value.\n\nIt only remains, how to compute the answer to a query. To answer it, we go down the tree as before, breaking the query into several subsegments that coincide with the segments of the Segment Tree, and combine the answers in them into a single answer for the query. Then it should be clear, that the work is exactly the same as in the simple Segment Tree, but instead of summing / minimizing / maximizing the values, we use the $\\text{combine}$ function.\n\nSaving the entire subarrays in each vertex¶\n\nThis is a separate subsection that stands apart from the others, because at each vertex of the Segment Tree we don't store information about the corresponding segment in compressed form (sum, minimum, maximum, ...), but store all elements of the segment. Thus the root of the Segment Tree will store all elements of the array, the left child vertex will store the first half of the array, the right vertex the second half, and so on.\n\nIn its simplest application of this technique we store the elements in sorted order. In more complex versions the elements are not stored in lists, but more advanced data structures (sets, maps, ...). But all these methods have the common factor, that each vertex requires linear memory (i.e. proportional to the length of the corresponding segment).\n\nThe first natural question, when considering these Segment Trees, is about memory consumption. Intuitively this might look like $O(n^2)$ memory, but it turns out that the complete tree will only need $O(n \\log n)$ memory. Why is this so? Quite simply, because each element of the array falls into $O(\\log n)$ segments (remember the height of the tree is $O(\\log n)$).\n\nSo in spite of the apparent extravagance of such a Segment Tree, it consumes only slightly more memory than the usual Segment Tree.\n\nSeveral typical applications of this data structure are described below. It is worth noting the similarity of these Segment Trees with 2D data structures (in fact this is a 2D data structure, but with rather limited capabilities).\n\nFind the smallest number greater or equal to a specified number. No modification queries.¶\n\nWe want to answer queries of the following form: for three given numbers $(l, r, x)$ we have to find the minimal number in the segment $a[l \\dots r]$ which is greater than or equal to $x$.\n\nWe construct a Segment Tree. In each vertex we store a sorted list of all numbers occurring in the corresponding segment, like described above. How to build such a Segment Tree as effectively as possible? As always we approach this problem recursively: let the lists of the left and right children already be constructed, and we want to build the list for the current vertex. From this view the operation is now trivial and can be accomplished in linear time: We only need to combine the two sorted lists into one, which can be done by iterating over them using two pointers. The C++ STL already has an implementation of this algorithm.\n\nBecause this structure of the Segment Tree and the similarities to the merge sort algorithm, the data structure is also often called \"Merge Sort Tree\".\n\nWe already know that the Segment Tree constructed in this way will require $O(n \\log n)$ memory. And thanks to this implementation its construction also takes $O(n \\log n)$ time, after all each list is constructed in linear time in respect to its size.\n\nNow consider the answer to the query. We will go down the tree, like in the regular Segment Tree, breaking our segment $a[l \\dots r]$ into several subsegments (into at most $O(\\log n)$ pieces). It is clear that the answer of the whole answer is the minimum of each of the subqueries. So now we only need to understand, how to respond to a query on one such subsegment that corresponds with some vertex of the tree.\n\nWe are at some vertex of the Segment Tree and we want to compute the answer to the query, i.e. find the minimum number greater that or equal to a given number $x$. Since the vertex contains the list of elements in sorted order, we can simply perform a binary search on this list and return the first number, greater than or equal to $x$.\n\nThus the answer to the query in one segment of the tree takes $O(\\log n)$ time, and the entire query is processed in $O(\\log^2 n)$.\n\nThe constant $\\text{INF}$ is equal to some large number that is bigger than all numbers in the array. Its usage means, that there is no number greater than or equal to $x$ in the segment. It has the meaning of \"there is no answer in the given interval\".\n\nFind the smallest number greater or equal to a specified number. With modification queries.¶\n\nThis task is similar to the previous. The last approach has a disadvantage, it was not possible to modify the array between answering queries. Now we want to do exactly this: a modification query will do the assignment $a[i] = y$.\n\nThe solution is similar to the solution of the previous problem, but instead of lists at each vertex of the Segment Tree, we will store a balanced list that allows you to quickly search for numbers, delete numbers, and insert new numbers. Since the array can contain a number repeated, the optimal choice is the data structure $\\text{multiset}$.\n\nThe construction of such a Segment Tree is done in pretty much the same way as in the previous problem, only now we need to combine $\\text{multiset}$s and not sorted lists. This leads to a construction time of $O(n \\log^2 n)$ (in general merging two red-black trees can be done in linear time, but the C++ STL doesn't guarantee this time complexity).\n\nThe $\\text{query}$ function is also almost equivalent, only now the $\\text{lower_bound}$ function of the $\\text{multiset}$ function should be called instead ($\\text{std::lower_bound}$ only works in $O(\\log n)$ time if used with random-access iterators).\n\nFinally the modification request. To process it, we must go down the tree, and modify all $\\text{multiset}$ from the corresponding segments that contain the affected element. We simply delete the old value of this element (but only one occurrence), and insert the new value.\n\nProcessing of this modification query also takes $O(\\log^2 n)$ time.\n\nFind the smallest number greater or equal to a specified number. Acceleration with \"fractional cascading\".¶\n\nWe have the same problem statement, we want to find the minimal number greater than or equal to $x$ in a segment, but this time in $O(\\log n)$ time. We will improve the time complexity using the technique \"fractional cascading\".\n\nFractional cascading is a simple technique that allows you to improve the running time of multiple binary searches, which are conducted at the same time. Our previous approach to the search query was, that we divide the task into several subtasks, each of which is solved with a binary search. Fractional cascading allows you to replace all of these binary searches with a single one.\n\nThe simplest and most obvious example of fractional cascading is the following problem: there are $k$ sorted lists of numbers, and we must find in each list the first number greater than or equal to the given number.\n\nInstead of performing a binary search for each list, we could merge all lists into one big sorted list. Additionally for each element $y$ we store a list of results of searching for $y$ in each of the $k$ lists. Therefore if we want to find the smallest number greater than or equal to $x$, we just need to perform one single binary search, and from the list of indices we can determine the smallest number in each list. This approach however requires $O(n \\cdot k)$ ($n$ is the length of the combined lists), which can be quite inefficient.\n\nFractional cascading reduces this memory complexity to $O(n)$ memory, by creating from the $k$ input lists $k$ new lists, in which each list contains the corresponding list and additionally also every second element of the following new list. Using this structure it is only necessary to store two indices, the index of the element in the original list, and the index of the element in the following new list. So this approach only uses $O(n)$ memory, and still can answer the queries using a single binary search.\n\nBut for our application we do not need the full power of fractional cascading. In our Segment Tree a vertex will contain the sorted list of all elements that occur in either the left or the right subtrees (like in the Merge Sort Tree). Additionally to this sorted list, we store two positions for each element. For an element $y$ we store the smallest index $i$, such that the $i$th element in the sorted list of the left child is greater or equal to $y$. And we store the smallest index $j$, such that the $j$th element in the sorted list of the right child is greater or equal to $y$. These values can be computed in parallel to the merging step when we build the tree.\n\nHow does this speed up the queries?\n\nRemember, in the normal solution we did a binary search in every node. But with this modification, we can avoid all except one.\n\nTo answer a query, we simply do a binary search in the root node. This gives us the smallest element $y \\ge x$ in the complete array, but it also gives us two positions. The index of the smallest element greater or equal $x$ in the left subtree, and the index of the smallest element $y$ in the right subtree. Notice that $\\ge y$ is the same as $\\ge x$, since our array doesn't contain any elements between $x$ and $y$. In the normal Merge Sort Tree solution we would compute these indices via binary search, but with the help of the precomputed values we can just look them up in $O(1)$. And we can repeat that until we visited all nodes that cover our query interval.\n\nTo summarize, as usual we touch $O(\\log n)$ nodes during a query. In the root node we do a binary search, and in all other nodes we only do constant work. This means the complexity for answering a query is $O(\\log n)$.\n\nBut notice, that this uses three times more memory than a normal Merge Sort Tree, which already uses a lot of memory ($O(n \\log n)$).\n\nIt is straightforward to apply this technique to a problem, that doesn't require any modification queries. The two positions are just integers and can easily be computed by counting when merging the two sorted sequences.\n\nIt it still possible to also allow modification queries, but that complicates the entire code. Instead of integers, you need to store the sorted array as , and instead of indices you need to store iterators. And you need to work very carefully, so that you increment or decrement the correct iterators during a modification query.\n\nThis technique implies a whole new class of possible applications. Instead of storing a $\\text{vector}$ or a $\\text{multiset}$ in each vertex, other data structures can be used: other Segment Trees (somewhat discussed in Generalization to higher dimensions), Fenwick Trees, Cartesian trees, etc.\n\nAll problems in the above sections discussed modification queries that only affected a single element of the array each. However the Segment Tree allows applying modification queries to an entire segment of contiguous elements, and perform the query in the same time $O(\\log n)$.\n\nWe begin by considering problems of the simplest form: the modification query should add a number $x$ to all numbers in the segment $a[l \\dots r]$. The second query, that we are supposed to answer, asked simply for the value of $a[i]$.\n\nTo make the addition query efficient, we store at each vertex in the Segment Tree how many we should add to all numbers in the corresponding segment. For example, if the query \"add 3 to the whole array $a[0 \\dots n-1]$\" comes, then we place the number 3 in the root of the tree. In general we have to place this number to multiple segments, which form a partition of the query segment. Thus we don't have to change all $O(n)$ values, but only $O(\\log n)$ many.\n\nIf now there comes a query that asks the current value of a particular array entry, it is enough to go down the tree and add up all values found along the way.\n\nSuppose now that the modification query asks to assign each element of a certain segment $a[l \\dots r]$ to some value $p$. As a second query we will again consider reading the value of the array $a[i]$.\n\nTo perform this modification query on a whole segment, you have to store at each vertex of the Segment Tree whether the corresponding segment is covered entirely with the same value or not. This allows us to make a \"lazy\" update: instead of changing all segments in the tree that cover the query segment, we only change some, and leave others unchanged. A marked vertex will mean, that every element of the corresponding segment is assigned to that value, and actually also the complete subtree should only contain this value. In a sense we are lazy and delay writing the new value to all those vertices. We can do this tedious task later, if this is necessary.\n\nSo after the modification query is executed, some parts of the tree become irrelevant - some modifications remain unfulfilled in it.\n\nFor example if a modification query \"assign a number to the whole array $a[0 \\dots n-1]$\" gets executed, in the Segment Tree only a single change is made - the number is placed in the root of the tree and this vertex gets marked. The remaining segments remain unchanged, although in fact the number should be placed in the whole tree.\n\nSuppose now that the second modification query says, that the first half of the array $a[0 \\dots n/2]$ should be assigned with some other number. To process this query we must assign each element in the whole left child of the root vertex with that number. But before we do this, we must first sort out the root vertex first. The subtlety here is that the right half of the array should still be assigned to the value of the first query, and at the moment there is no information for the right half stored.\n\nThe way to solve this is to push the information of the root to its children, i.e. if the root of the tree was assigned with any number, then we assign the left and the right child vertices with this number and remove the mark of the root. After that, we can assign the left child with the new value, without losing any necessary information.\n\nSummarizing we get: for any queries (a modification or reading query) during the descent along the tree we should always push information from the current vertex into both of its children. We can understand this in such a way, that when we descent the tree we apply delayed modifications, but exactly as much as necessary (so not to degrade the complexity of $O(\\log n)$).\n\nFor the implementation we need to make a $\\text{push}$ function, which will receive the current vertex, and it will push the information for its vertex to both its children. We will call this function at the beginning of the query functions (but we will not call it from the leaves, because there is no need to push information from them any further).\n\nNotice: the function $\\text{get}$ can also be implemented in a different way: do not make delayed updates, but immediately return the value $t[v]$ if $marked[v]$ is true.\n\nNow the modification query is to add a number to all elements in a range, and the reading query is to find the maximum in a range.\n\nSo for each vertex of the Segment Tree we have to store the maximum of the corresponding subsegment. The interesting part is how to recompute these values during a modification request.\n\nFor this purpose we keep store an additional value for each vertex. In this value we store the addends we haven't propagated to the child vertices. Before traversing to a child vertex, we call $\\text{push}$ and propagate the value to both children. We have to do this in both the $\\text{update}$ function and the $\\text{query}$ function.\n\nA Segment Tree can be generalized quite natural to higher dimensions. If in the one-dimensional case we split the indices of the array into segments, then in the two-dimensional we make an ordinary Segment Tree with respect to the first indices, and for each segment we build an ordinary Segment Tree with respect to the second indices.\n\nA matrix $a[0 \\dots n-1, 0 \\dots m-1]$ is given, and we have to find the sum (or minimum/maximum) on some submatrix $a[x_1 \\dots x_2, y_1 \\dots y_2]$, as well as perform modifications of individual matrix elements (i.e. queries of the form $a[x][y] = p$).\n\nSo we build a 2D Segment Tree: first the Segment Tree using the first coordinate ($x$), then the second ($y$).\n\nTo make the construction process more understandable, you can forget for a while that the matrix is two-dimensional, and only leave the first coordinate. We will construct an ordinary one-dimensional Segment Tree using only the first coordinate. But instead of storing a number in a segment, we store an entire Segment Tree: i.e. at this moment we remember that we also have a second coordinate; but because at this moment the first coordinate is already fixed to some interval $[l \\dots r]$, we actually work with such a strip $a[l \\dots r, 0 \\dots m-1]$ and for it we build a Segment Tree.\n\nHere is the implementation of the construction of a 2D Segment Tree. It actually represents two separate blocks: the construction of a Segment Tree along the $x$ coordinate ($\\text{build}_x$), and the $y$ coordinate ($\\text{build}_y$). For the leaf nodes in $\\text{build}_y$ we have to separate two cases: when the current segment of the first coordinate $[tlx \\dots trx]$ has length 1, and when it has a length greater than one. In the first case, we just take the corresponding value from the matrix, and in the second case we can combine the values of two Segment Trees from the left and the right son in the coordinate $x$.\n\nSuch a Segment Tree still uses a linear amount of memory, but with a larger constant: $16 n m$. It is clear that the described procedure $\\text{build}_x$ also works in linear time.\n\nNow we turn to processing of queries. We will answer to the two-dimensional query using the same principle: first break the query on the first coordinate, and then for every reached vertex, we call the corresponding Segment Tree of the second coordinate.\n\nThis function works in $O(\\log n \\log m)$ time, since it first descends the tree in the first coordinate, and for each traversed vertex in the tree it makes a query in the corresponding Segment Tree along the second coordinate.\n\nFinally we consider the modification query. We want to learn how to modify the Segment Tree in accordance with the change in the value of some element $a[x][y] = p$. It is clear, that the changes will occur only in those vertices of the first Segment Tree that cover the coordinate $x$ (and such will be $O(\\log n)$), and for Segment Trees corresponding to them the changes will only occurs at those vertices that covers the coordinate $y$ (and such will be $O(\\log m)$). Therefore the implementation will be not very different form the one-dimensional case, only now we first descend the first coordinate, and then the second.\n\nLet the problem be the following: there are $n$ points on the plane given by their coordinates $(x_i, y_i)$ and queries of the form \"count the number of points lying in the rectangle $((x_1, y_1), (x_2, y_2))$\". It is clear that in the case of such a problem it becomes unreasonably wasteful to construct a two-dimensional Segment Tree with $O(n^2)$ elements. Most on this memory will be wasted, since each single point can only get into $O(\\log n)$ segments of the tree along the first coordinate, and therefore the total \"useful\" size of all tree segments on the second coordinate is $O(n \\log n)$.\n\nSo we proceed as follows: at each vertex of the Segment Tree with respect to the first coordinate we store a Segment Tree constructed only by those second coordinates that occur in the current segment of the first coordinates. In other words, when constructing a Segment Tree inside some vertex with index $vx$ and the boundaries $tlx$ and $trx$, we only consider those points that fall into this interval $x \\in [tlx, trx]$, and build a Segment Tree just using them.\n\nThus we will achieve that each Segment Tree on the second coordinate will occupy exactly as much memory as it should. As a result, the total amount of memory will decrease to $O(n \\log n)$. We still can answer the queries in $O(\\log^2 n)$ time, we just have to make a binary search on the second coordinate, but this will not worsen the complexity.\n\nBut modification queries will be impossible with this structure: in fact if a new point appears, we have to add a new element in the middle of some Segment Tree along the second coordinate, which cannot be effectively done.\n\nIn conclusion we note that the two-dimensional Segment Tree contracted in the described way becomes practically equivalent to the modification of the one-dimensional Segment Tree (see Saving the entire subarrays in each vertex). In particular the two-dimensional Segment Tree is just a special case of storing a subarray in each vertex of the tree. It follows, that if you gave to abandon a two-dimensional Segment Tree due to the impossibility of executing a query, it makes sense to try to replace the nested Segment Tree with some more powerful data structure, for example a Cartesian tree.\n\nPreserving the history of its values (Persistent Segment Tree)¶\n\nA persistent data structure is a data structure that remembers it previous state for each modification. This allows to access any version of this data structure that interest us and execute a query on it.\n\nSegment Tree is a data structure that can be turned into a persistent data structure efficiently (both in time and memory consumption). We want to avoid copying the complete tree before each modification, and we don't want to loose the $O(\\log n)$ time behavior for answering range queries.\n\nIn fact, any change request in the Segment Tree leads to a change in the data of only $O(\\log n)$ vertices along the path starting from the root. So if we store the Segment Tree using pointers (i.e. a vertex stores pointers to the left and the right child vertices), then when performing the modification query, we simply need to create new vertices instead of changing the available vertices. Vertices that are not affected by the modification query can still be used by pointing the pointers to the old vertices. Thus for a modification query $O(\\log n)$ new vertices will be created, including a new root vertex of the Segment Tree, and the entire previous version of the tree rooted at the old root vertex will remain unchanged.\n\nLet's give an example implementation for the simplest Segment Tree: when there is only a query asking for sums, and modification queries of single elements.\n\nFor each modification of the Segment Tree we will receive a new root vertex. To quickly jump between two different versions of the Segment Tree, we need to store this roots in an array. To use a specific version of the Segment Tree we simply call the query using the appropriate root vertex.\n\nWith the approach described above almost any Segment Tree can be turned into a persistent data structure.\n\nThis time we have to answer queries of the form \"What is the $k$-th smallest element in the range $a[l \\dots r]$. This query can be answered using a binary search and a Merge Sort Tree, but the time complexity for a single query would be $O(\\log^3 n)$. We will accomplish the same task using a persistent Segment Tree in $O(\\log n)$.\n\nFirst we will discuss a solution for a simpler problem: We will only consider arrays in which the elements are bound by $0 \\le a[i] \\lt n$. And we only want to find the $k$-th smallest element in some prefix of the array $a$. It will be very easy to extent the developed ideas later for not restricted arrays and not restricted range queries. Note that we will be using 1 based indexing for $a$.\n\nWe will use a Segment Tree that counts all appearing numbers, i.e. in the Segment Tree we will store the histogram of the array. So the leaf vertices will store how often the values $0$, $1$, $\\dots$, $n-1$ will appear in the array, and the other vertices store how many numbers in some range are in the array. In other words we create a regular Segment Tree with sum queries over the histogram of the array. But instead of creating all $n$ Segment Trees for every possible prefix, we will create one persistent one, that will contain the same information. We will start with an empty Segment Tree (all counts will be $0$) pointed to by $root_0$, and add the elements $a[1]$, $a[2]$, $\\dots$, $a[n]$ one after another. For each modification we will receive a new root vertex, let's call $root_i$ the root of the Segment Tree after inserting the first $i$ elements of the array $a$. The Segment Tree rooted at $root_i$ will contain the histogram of the prefix $a[1 \\dots i]$. Using this Segment Tree we can find in $O(\\log n)$ time the position of the $k$-th element using the same technique discussed in Counting the number of zeros, searching for the $k$-th zero.\n\nNow to the not-restricted version of the problem.\n\nFirst for the restriction on the queries: Instead of only performing these queries over a prefix of $a$, we want to use any arbitrary segments $a[l \\dots r]$. Here we need a Segment Tree that represents the histogram of the elements in the range $a[l \\dots r]$. It is easy to see that such a Segment Tree is just the difference between the Segment Tree rooted at $root_{r}$ and the Segment Tree rooted at $root_{l-1}$, i.e. every vertex in the $[l \\dots r]$ Segment Tree can be computed with the vertex of the $root_{r}$ tree minus the vertex of the $root_{l-1}$ tree.\n\nIn the implementation of the $\\text{find_kth}$ function this can be handled by passing two vertex pointer and computing the count/sum of the current segment as difference of the two counts/sums of the vertices.\n\nHere are the modified $\\text{build}$, $\\text{update}$ and $\\text{find_kth}$ functions\n\nAs already written above, we need to store the root of the initial Segment Tree, and also all the roots after each update. Here is the code for building a persistent Segment Tree over an vector with elements in the range .\n\nNow to the restrictions on the array elements: We can actually transform any array to such an array by index compression. The smallest element in the array will gets assigned the value 0, the second smallest the value 1, and so forth. It is easy to generate lookup tables (e.g. using $\\text{map}$), that convert a value to its index and vice versa in $O(\\log n)$ time.\n\nPreviously, we considered cases when we have the ability to build the original segment tree. But what to do if the original size is filled with some default element, but its size does not allow you to completely build up to it in advance?\n\nWe can solve this problem by creating a segment tree lazily (incrementally). Initially, we will create only the root, and we will create the other vertexes only when we need them. In this case, we will use the implementation on pointers(before going to the vertex children, check whether they are created, and if not, create them). Each query has still only the complexity $O(\\log n)$, which is small enough for most use-cases (e.g. $\\log_2 10^9 \\approx 30$).\n\nIn this implementation we have two queries, adding a value to a position (initially all values are $0$), and computing the sum of all values in a range. will be the root vertex of the implicit tree.\n\nObviously this idea can be extended in lots of different ways. E.g. by adding support for range updates via lazy propagation.\n• Codeforces - Please, another Queries on Array? [Lazy propagation]\n• COCI - Deda [Last element smaller or equal to x / Binary search]"
    },
    {
        "link": "https://codeforces.com/blog/entry/18051",
        "document": "This is my first attempt at writing something useful, so your suggestions are welcome.\n\nMost participants of programming contests are familiar with segment trees to some degree, especially having read this articles http://codeforces.com/blog/entry/15890, http://e-maxx.ru/algo/segment_tree (Russian only). If you're not — don't go there yet. I advise to read them after this article for the sake of examples, and to compare implementations and choose the one you like more (will be kinda obvious).\n\nLet's start with a brief explanation of segment trees. They are used when we have an array, perform some changes and queries on continuous segments. In the first example we'll consider 2 operations:\n• modify one element in the array;\n• find the sum of elements on some segment. .\n\nI like to visualize a segment tree in the following way: image link\n\nNotation is node_index: corresponding segment (left border included, right excluded). At the bottom row we have our array (0-indexed), the leaves of the tree. For now suppose it's length is a power of 2 (16 in the example), so we get perfect binary tree. When going up the tree we take pairs of nodes with indices (2 * i, 2 * i + 1) and combine their values in their parent with index i. This way when we're asked to find a sum on interval [3, 11), we need to sum up only values in the nodes 19, 5, 12 and 26 (marked with bold), not all 8 values inside the interval. Let's jump directly to implementation (in C++) to see how it works:\n\nThat's it! Fully operational example. Forget about those cumbersome recursive functions with 5 arguments!\n\nNow let's see why this works, and works very efficient.\n• None As you could notice from the picture, leaves are stored in continuous nodes with indices starting with n, element with index i corresponds to a node with index i + n. So we can read initial values directly into the tree where they belong.\n• None Before doing any queries we need to build the tree, which is quite straightforward and takes O(n) time. Since parent always has index less than its children, we just process all the internal nodes in decreasing order. In case you're confused by bit operations, the code in build() is equivalent to .\n• None Modifying an element is also quite straightforward and takes time proportional to the height of the tree, which is O(log(n)). We only need to update values in the parents of given node. So we just go up the tree knowing that parent of node p is p / 2 or , which means the same. turns 2 * i into 2 * i + 1 and vice versa, so it represents the second child of p's parent.\n• None Finding the sum also works in O(log(n)) time. To better understand it's logic you can go through example with interval [3, 11) and verify that result is composed exactly of values in nodes 19, 26, 12 and 5 (in that order).\n\nGeneral idea is the following. If l, the left interval border, is odd (which is equivalent to ) then l is the right child of its parent. Then our interval includes node l but doesn't include it's parent. So we add and move to the right of l's parent by setting l = (l + 1) / 2. If l is even, it is the left child, and the interval includes its parent as well (unless the right border interferes), so we just move to it by setting l = l / 2. Similar argumentation is applied to the right border. We stop once borders meet.\n\nNo recursion and no additional computations like finding the middle of the interval are involved, we just go through all the nodes we need, so this is very efficient.\n\nFor now we talked only about an array with size equal to some power of 2, so the binary tree was perfect. The next fact may be stunning, so prepare yourself.\n\nThe code above works for any size n.\n\nExplanation is much more complex than before, so let's focus first on the advantages it gives us.\n• Segment tree uses exactly memory, not like some other implementations offer.\n• Array elements are stored in continuous manner starting with index .\n• All operations are very efficient and easy to write.\n\nYou can skip the next section and just test the code to check that it's correct. But for those interested in some kind of explanation, here's how the tree for n = 13 looks like: image link\n\nIt's not actually a single tree any more, but a set of perfect binary trees: with root 2 and height 4, root 7 and height 2, root 12 and height 2, root 13 and height 1. Nodes denoted by dashes aren't ever used in query operations, so it doesn't matter what's stored there. Leaves seem to appear on different heights, but that can be fixed by cutting the tree before the node 13 and moving its right part to the left. I believe the resulting structure can be shown to be isomorphic to a part of larger perfect binary tree with respect to operations we perform, and this is why we get correct results.\n\nI won't bother with formal proof here, let's just go through the example with interval [0, 7). We have l = 13, r = 20, and borders change to l = 7, r = 10. Again , borders change to l = 4, r = 5, and suddenly nodes are at the same height. Now we have , borders change to l = 2, r = 2, so we're finished.\n\nSome people begin to struggle and invent something too complex when the operations are inverted, for example:\n• add a value to all elements in some interval;\n• compute an element at some position.\n\nBut all we need to do in this case is to switch the code in methods modify and query as follows:\n\nIf at some point after modifications we need to inspect all the elements in the array, we can push all the modifications to the leaves using the following code. After that we can just traverse elements starting with index n. This way we reduce the complexity from O(nlog(n)) to O(n) similarly to using build instead of n modifications.\n\nNote, however, that code above works only in case the order of modifications on a single element doesn't affect the result. Assignment, for example, doesn't satisfy this condition. Refer to section about lazy propagation for more information.\n\nFor now we considered only the simplest combiner function — addition. It is commutative, which means the order of operands doesn't matter, we have a + b = b + a. The same applies to min and max, so we can just change all occurrences of to one of those functions and be fine. But don't forget to initialize query result to infinity instead of 0.\n\nHowever, there are cases when the combiner isn't commutative, for example, in the problem 380C - Sereja and Brackets, tutorial available here http://codeforces.com/blog/entry/10363. Fortunately, our implementation can easily support that. We define structure and combine function for it. In method build we just change to this function. In modify we need to ensure the correct ordering of children, knowing that left child has even index. When answering the query, we note that nodes corresponding to the left border are processed from left to right, while the right border moves from right to left. We can express it in the code in the following way:\n\nNext we'll describe a technique to perform both range queries and range modifications, which is called lazy propagation. First, we need more variables:\n\nh is a height of the tree, the highest significant bit in n. is a delayed operation to be propagated to the children of node i when necessary (this should become clearer from the examples). Array size if only because we don't have to store this information for leaves — they don't have any children. This leads us to a total of 3 * n memory use.\n\nPreviously we could say that is a value corresponding to it's segment. Now it's not entirely true — first we need to apply all the delayed operations on the route from node i to the root of the tree (parents of node i). We assume that already includes , so that route starts not with i but with its direct parent.\n\nLet's get back to our first example with interval [3, 11), but now we want to modify all the elements inside this interval. In order to do that we modify and at the nodes 19, 5, 12 and 26. Later if we're asked for a value for example in node 22, we need to propagate modification from node 5 down the tree. Note that our modifications could affect values up the tree as well: node 19 affects nodes 9, 4, 2 and 1, node 5 affects 2 and 1. Next fact is critical for the complexity of our operations:\n\nModification on interval [l, r) affects values only in the parents of border leaves: and (except the values that compose the interval itself — the ones accessed in for loop).\n\nThe proof is simple. When processing the left border, the node we modify in our loop is always the right child of its parent. Then all the previous modifications were made in the subtree of the left child of the same parent. Otherwise we would process the parent instead of both its children. This means current direct parent is also a parent of leaf . Similar arguments apply to the right border.\n\nOK, enough words for now, I think it's time to look at concrete examples.\n\nThis is probably the simplest case. The code below is far from universal and not the most efficient, but it's a good place to start.\n\nLet's analyze it one method at a time. The first three are just helper methods user doesn't really need to know about.\n• None Now that we have 2 variables for every internal node, it's useful to write a method to apply changes to both of them. p < n checks if p is not a leaf. Important property of our operations is that if we increase all the elements in some interval by one value, maximum will increase by the same value.\n• None build is designed to update all the parents of a given node.\n• None push propagates changes from all the parents of a given node down the tree starting from the root. This parents are exactly the prefixes of p in binary notation, that's why we use binary shifts to calculate them.\n\nNow we're ready to look at main methods.\n• None As explained above, we process increment request using our familiar loop and then updating everything else we need by calling build.\n• None To answer the query, we use the same loop as earlier, but before that we need to push all the changes to the nodes we'll be using. Similarly to build, it's enough to push changes from the parents of border leaves.\n\nIt's easy to see that all operations above take O(log(n)) time.\n\nAgain, this is the simplest case because of two reasons:\n• when updating a node, we don't need to know the length of interval it represents.\n\nWe'll show how to take that into account in the next example.\n\nThis example is inspired by problem Timus 2042\n\nAgain, we'll start with helper functions. Now we have more of them:\n\nThese are just simple O(1) functions to calculate value at node p and to apply a change to the node. But there are two thing to explain:\n• None We suppose there's a value we never use for modification, in our case it's 0. In case there's no such value — we would create additional boolean array and refer to it instead of checking .\n• None Now we have additional parameter k, which stands for the lenght of the interval corresponding to node p. We will use this name consistently in the code to preserve this meaning. Obviously, it's impossible to calculate the sum without this parameter. We can avoid passing this parameter if we precalculate this value for every node in a separate array or calculate it from the node index on the fly, but I'll show you a way to avoid using extra memory or calculations.\n\nNext we need to update build and push methods. Note that we have two versions of them: one we introduces earlier that processes the whole tree in O(n), and one from the last example that processes just the parents of one leaf in O(log(n)). We can easily combine that functionality into one method and get even more.\n\nBoth this methods work on any interval in O(log(n) + |r - l|) time. If we want to transform some interval in the tree, we can write code like this:\n\nLet's explain how they work. First, note that we change our interval to closed by doing in order to calculate parents properly. Since we process our tree level by level, is't easy to maintain current interval level, which is always a power of 2. build goes bottom to top, so we initialize k to 2 (not to 1, because we don't calculate anything for the leaves but start with their direct parents) and double it on each level. push goes top to bottom, so k's initial value depends here on the height of the tree and is divided by 2 on each level.\n\nMain methods don't change much from the last example, but modify has 2 things to notice:\n• Because the order of modifications is important, we need to make sure there are no old changes on the paths from the root to all the nodes we're going to update. This is done by calling push first as we did in query.\n• We need to maintain the value of .\n\nOne could notice that we do 3 passed in modify over almost the same nodes: 1 down the tree in push, then 2 up the tree. We can eliminate the last pass and calculate new values only where it's necessary, but the code gets more complicated:\n\nBoolean flags denote if we already performed any changes to the left and to the right. Let's look at an example: image link\n• , we call calc(14) — first node to the right of current interval is exactly the parent of last modified node;\n• , we call calc(7) and then apply(5) and apply(6);\n• , so the first loop finishes.\n\nNow you should see the point of doing , because we still need to calculate new values in nodes 2, 3 and then 1. End condition is because it's possible to get l = 1, r = 1 after the first loop, so we need to update the root, but results in l = 0.\n\nCompared to previous implementation, we avoid unnecessary calls calc(10), calc(5) and duplicate call to calc(1)."
    },
    {
        "link": "https://geeksforgeeks.org/segment-tree-range-minimum-query",
        "document": "We have introduced a segment tree with a simple example in the previous post. In this post, the Range Minimum Query problem is discussed as another example where a Segment Tree can be used. The following is the problem statement:\n\nWe have an array arr[0 . . . n-1]. We should be able to efficiently find the minimum value from index q (query start) to q (query end) where 0 <= q <= q <= n-1. \n\n \n\nA simple solution is to run a loop from q to q and find the minimum element in the given range. This solution takes O(n) time in the worst case. \n\nAnother solution is to create a 2D array where an entry [i, j] stores the minimum value in range arr[i..j]. The minimum of a given range can now be calculated in O(1) time, but preprocessing takes O(n2) time. Also, this approach needs O(n2) extra space which may become huge for large input arrays.\n\nSegment tree can be used to do preprocessing and query in moderate time. With a segment tree, preprocessing time is O(n) and the time complexity for a range minimum query is O(log n). The extra space required is O(n) to store the segment tree.\n\nConstruction of Segment Tree from given array\n\nAll levels of the constructed segment tree will be completely filled except the last level. Also, the tree will be a Full Binary Tree because we always divide segments in two halves at every level. Since the constructed tree is always full binary tree with n leaves, there will be n – 1 internal nodes. So total number of nodes will be 2 * n – 1. \n\nHeight of the segment tree will be ?log?n?. Since the tree is represented using array and relation between parent and child indexes must be maintained, size of memory allocated for segment tree will be 2 * 2?log n? – 1.\n\nQuery for minimum value of given range\n\nOnce the tree is constructed, how to do range minimum query using the constructed segment tree. Following is algorithm to get the minimum. // q –> query start index, q –> query end index\n\nint RMQ(node, q , q ) {\n\n if range of node is within q and q \n\n return value in node\n\n else if range of node is completely outside q and q \n\n return INFINITE\n\n else\n\n return min ( RMQ(node’s left child, q , q ), RMQ (node’s right child, q , q ) )\n\n}\n\n// A utility function to get minimum of two numbers // A utility function to get the // A recursive function to get the // minimum value in a given range of array // index --> Index of current node in the tree // If segment of this node is a part of given range // then return the min of the segment // If segment of this node if outside the range // If a part of this segment // overlaps with the given range // If there is one element in array, // store it in current node of // If there are more than one elements, // then recur for left and right subtrees // and store the minimum of two values in this node // A utility function to get minimum of two numbers // A utility function to get the // A recursive function to get the // minimum value in a given range of array // index --> Index of current node in the tree // If segment of this node is a part of given range // then return the min of the segment // If segment of this node if outside the range // If a part of this segment // overlaps with the given range // If there is one element in array, // store it in current node of // If there are more than one elements, // then recur for left and right subtrees // and store the minimum of two values in this node \"Minimum of values in range [%d, %d] is = %d // A utility function to get minimum of two numbers // A utility function to get the // A recursive function to get the // minimum value in a given range of array // If segment of this node is a part of given range // then return the min of the segment // If segment of this node is outside the range // If a part of this segment // overlaps with the given range // If there is one element in array, // store it in current node of // If there are more than one elements, // then recur for left and right subtrees // and store the minimum of two values in this node # A utility function to get minimum of two numbers # A utility function to get the # A recursive function to get the # minimum value in a given range of array # If segment of this node is a part of given range # then return the min of the segment # If segment of this node is outside the range # If a part of this segment # overlaps with the given range # If there is one element in array, # store it in current node of # If there are more than one elements, # then recur for left and right subtrees # and store the minimum of two values in this node // A utility function to get minimum of two numbers // A utility function to get the // A recursive function to get the // minimum value in a given range of array // If segment of this node is a part of given range // then return the min of the segment // If segment of this node is outside the range // If a part of this segment // overlaps with the given range // If there is one element in array, // store it in current node of // If there are more than one elements, // then recur for left and right subtrees // and store the minimum of two values in this node // A utility function to get minimum of two numbers // A utility function to get the // A recursive function to get the // minimum value in a given range of array // If segment of this node is a part of given range // then return the min of the segment // If segment of this node is outside the range // If a part of this segment // overlaps with the given range // If there is one element in array, // store it in current node of // If there are more than one elements, // then recur for left and right subtrees // and store the minimum of two values in this node\n• None Tree Construction: Time Complexity for tree construction is O(n). There are total 2n-1 nodes, and value of every node is calculated only once in tree construction.\n• None Query: Time complexity for each query is O(log n). To query a range minimum, we process at most two nodes at every level and number of levels is O(log n).\n\nAuxiliary Space: O(n), since n extra space has been taken."
    },
    {
        "link": "https://medium.com/@zdf2424/demystifying-segment-trees-an-efficient-solution-for-range-queries-6ec666c5bde4",
        "document": "Data lies at the heart of any application and as software engineers we are constantly challenged to optimize data manipulation and efficiently extract valuable insights. This is where Segment Trees come into play.\n\nA Segment Tree is a data structure designed to handle range queries and updates on dynamic sets. At its core, it breaks down an array into smaller segments, allowing us to perform aggregate operations within specified intervals efficiently.\n\nThey play a pivotal role in a number of real-world scenarios. From database management to image processing and GIS applications, the ability to quickly compute sums, minimums, maximums, and more within specific ranges makes Segment Trees a critical asset for optimizing performance and resource management.\n\nLet’s say we are given an array and we want to support two features — update & query:\n\nNaive Approach: We could update the array in constant time and query naively by iterating through every element in the range and calculating the total sum which would be a O(n) operation. And as n gets larger, this may not be efficient.\n\nBetter Approach: Lets create a tree based on ranges in the array and update & query using this tree.\n\nHere each node represents the left and right indices of the subarray. The root node is the entire array, the left child is the left half of the root node’s indices and the right child is the right half of the root node’s indices.\n\nThe main goal of this tree is to efficiently query sums based on an index range, so naturally the base case (leaf node) would be if the subarray size is 1. So let’s update our tree.\n\nIn our implementation, build tree will take O(n) time.\n\nLet’s say we want to update index 3 to be the value 4. In our tree we would want to go to the leaf node that represents index 3. We could use a form of binary search to do this efficiently in O(log(n)) time.\n\nKeep in mind that once we update the leaf node, we would need to propagate that new value all the way back up the tree (i.e update the sums of the appropriate parent nodes).\n\nNow let’s say we want to get the sum of the range from index 2 to 4. We can do so in O(log(n)) time by traversing the tree until we hit the entire range we are querying.\n\nHopefully by now you can see the power of Segment Trees and how to implement them. Not only is this data structure a great tool to have in your toolbox, but also incredibly applicable in every day life.\n\nThanks for reading and feel free to follow or connect with me on Linkedin and Github. If you have any suggestions on what you would like me to write about next, feel free to leave a comment!"
    }
]