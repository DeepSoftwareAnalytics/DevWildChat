[
    {
        "link": "https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers",
        "document": "This is a list of TCP and UDP port numbers used by protocols for operation of network applications. The Transmission Control Protocol (TCP) and the User Datagram Protocol (UDP) only need one port for bidirectional traffic. TCP usually uses port numbers that match the services of the corresponding UDP implementations, if they exist, and vice versa.\n\nThe Internet Assigned Numbers Authority (IANA) is responsible for maintaining the official assignments of port numbers for specific uses,[1] However, many unofficial uses of both well-known and registered port numbers occur in practice. Similarly, many of the official assignments refer to protocols that were never or are no longer in common use. This article lists port numbers and their associated protocols that have experienced significant uptake.\n\nThe port numbers in the range from 0 to 1023 (0 to 210 − 1) are the well-known ports or system ports.[3] They are used by system processes that provide widely used types of network services. On Unix-like operating systems, a process must execute with superuser privileges to be able to bind a network socket to an IP address using one of the well-known ports.[5]\n\nThe range of port numbers from 1024 to 49151 (210 to 215 + 214 − 1) are the registered ports. They are assigned by IANA for specific service upon application by a requesting entity.[2] On most systems, registered ports can be used without superuser privileges.\n\nThe range 49152–65535 (215 + 214 to 216 − 1), 16 384 ports, contains dynamic or private ports that cannot be registered with IANA.[484] This range is used for private or customized services, for temporary purposes, and for automatic allocation of ephemeral ports."
    },
    {
        "link": "https://cloudflare.com/learning/network-layer/what-is-a-computer-port",
        "document": "A port is a virtual point where network connections start and end. Ports are software-based and managed by a computer's operating system. Each port is associated with a specific process or service. Ports allow computers to easily differentiate between different kinds of traffic: emails go to a different port than webpages, for instance, even though both reach a computer over the same Internet connection.\n\nPorts are standardized across all network-connected devices, with each port assigned a number. Most ports are reserved for certain protocols — for example, all Hypertext Transfer Protocol (HTTP) messages go to port 80. While IP addresses enable messages to go to and from specific devices, port numbers allow targeting of specific services or applications within those devices.\n\nHow do ports make network connections more efficient?\n\nVastly different types of data flow to and from a computer over the same network connection. The use of ports helps computers understand what to do with the data they receive.\n\nSuppose Bob transfers an MP3 audio recording to Alice using the File Transfer Protocol (FTP). If Alice's computer passed the MP3 file data to Alice's email application, the email application would not know how to interpret it. But because Bob's file transfer uses the port designated for FTP (port 21), Alice's computer is able to receive and store the file.\n\nMeanwhile, Alice's computer can simultaneously load HTTP webpages using port 80, even though both the webpage files and the MP3 sound file flow to Alice's computer over the same WiFi connection.\n\nAre ports part of the network layer?\n\nThe OSI model is a conceptual model of how the Internet works. It divides different Internet services and processes into 7 layers. These layers are:\n\nPorts are a transport layer (layer 4) concept. Only a transport protocol such as the Transmission Control Protocol (TCP) or User Datagram Protocol (UDP) can indicate which port a packet should go to. TCP and UDP headers have a section for indicating port numbers. Network layer protocols — for instance, the Internet Protocol (IP) — are unaware of what port is in use in a given network connection. In a standard IP header, there is no place to indicate which port the data packet should go to. IP headers only indicate the destination IP address, not the port number at that IP address.\n\nUsually, the inability to indicate the port at the network layer has no impact on networking processes, since network layer protocols are almost always used in conjunction with a transport layer protocol. However, this does impact the functionality of testing software, which is software that \"pings\" IP addresses using Internet Control Message Protocol (ICMP) packets. ICMP is a network layer protocol that can ping networked devices — but without the ability to ping specific ports, network administrators cannot test specific services within those devices.\n\nSome ping software, such as My Traceroute, offers the option to send UDP packets. UDP is a transport layer protocol that can specify a particular port, as opposed to ICMP, which cannot specify a port. By adding a UDP header to ICMP packets, network administrators can test specific ports within a networked device.\n\nWhy do firewalls sometimes block specific ports?\n\nA firewall is a network security system that blocks or allows network traffic based on a set of security rules. Firewalls usually sit between a trusted network and an untrusted network; often the untrusted network is the Internet. For example, office networks often use a firewall to protect their network from online threats.\n\nSome attackers try to send malicious traffic to random ports in the hopes that those ports have been left \"open,\" meaning they are able to receive traffic. This action is somewhat like a car thief walking down the street and trying the doors of parked vehicles, hoping one of them is unlocked. For this reason, firewalls should be configured to block network traffic directed at most of the available ports. There is no legitimate reason for the vast majority of the available ports to receive traffic.\n\nProperly configured firewalls block traffic to all ports by default except for a few predetermined ports known to be in common use. For instance, a corporate firewall could only leave open ports 25 (email), 80 (web traffic), 443 (web traffic), and a few others, allowing internal employees to use these essential services, then block the rest of the 65,000+ ports.\n\nAs a more specific example, attackers sometimes attempt to exploit vulnerabilities in the RDP protocol by sending attack traffic to port 3389. To stop these attacks, a firewall may block port 3389 by default. Since this port is only used for remote desktop connections, such a rule has little impact on day-to-day business operations unless employees need to work remotely.\n\nWhat are the different port numbers?\n\nThere are 65,535 possible port numbers, although not all are in common use. Some of the most commonly used ports, along with their associated networking protocol, are:\n• Ports 20 and 21: File Transfer Protocol (FTP). FTP is for transferring files between a client and a server.\n• Port 22: Secure Shell (SSH). SSH is one of many tunneling protocols that create secure network connections.\n• Port 25: Historically, Simple Mail Transfer Protocol (SMTP). SMTP is used for email.\n• Port 53: Domain Name System (DNS). DNS is an essential process for the modern Internet; it matches human-readable domain names to machine-readable IP addresses, enabling users to load websites and applications without memorizing a long list of IP addresses.\n• Port 80: Hypertext Transfer Protocol (HTTP). HTTP is the protocol that makes the World Wide Web possible.\n• Port 123: Network Time Protocol (NTP). NTP allows computer clocks to sync with each other, a process that is essential for encryption.\n• Port 179: Border Gateway Protocol (BGP). BGP is essential for establishing efficient routes between the large networks that make up the Internet (these large networks are called autonomous systems). Autonomous systems use BGP to broadcast which IP addresses they control.\n• Port 443: HTTP Secure (HTTPS). HTTPS is the secure and encrypted version of HTTP. All HTTPS web traffic goes to port 443. Network services that use HTTPS for encryption, such as DNS over HTTPS, also connect at this port.\n• Port 500: Internet Security Association and Key Management Protocol (ISAKMP), which is part of the process of setting up secure IPsec connections.\n• Port 3389: Remote Desktop Protocol (RDP). RDP enables users to remotely connect to their desktop computers from another device.\n\nThe Internet Assigned Numbers Authority (IANA) maintains the full list of port numbers and protocols assigned to them."
    },
    {
        "link": "https://blog.netwrix.com/common-ports",
        "document": "Think of a port as a virtual gateway that a specific service, process, or application on your computer uses for network communication. Each port is assigned a unique number, allowing different types of traffic to be directed to the appropriate software. For example, your email might use one port, while your web browsing uses another. When combined with an IP address, a port number creates a complete socket address, enabling precise routing of data to and from your computer across the network\n\nThe role of ports in network communication\n\nPorts help computers sort the network traffic they receive, ensuring that different types of traffic are directed to the correct applications. Ports allow different services or applications on the same device to communicate with each other and with external systems.\n\nNetwork ports are categorized into three main ranges, each serving distinct purposes in network communication. Most ports are permanently assigned as Well-Known Ports or Registered Ports. By the Internet Assigned Numbers Authority (IANA). The IANA is responsible for the global coordination of port number assignments and maintains the official registry of port number assignments.\n\nWell-Known/System Ports (0-1023): The Well-Known or System Ports, ranging from 0 to 1023, are reserved for common, widely used services. These are only used by system processes, operating systems and default applications. These common network ports include HTTP (80), HTTPS (443), SMTP (25), and SSH (22).\n\nRegistered Ports (1024-49151): Thees ports are used by applications or services that are less common but still require specific ports to function properly.Important port numbers in this range include Remote Desktop Protocol (3389), Xbox LIVE and Games for Windows (3074) and IBM Lotus Notes/Domino (1352).\n\nDynamic/Private Ports (49152-65535): These ports are used for temporary or short-lived connections and are not assigned to specific services. They’re often employed as source ports for outgoing connections and can be used by any process.\n\nTCP UDP are two different protocols that use ports to manage network communications. The main difference between them lies in how they handle data transmission. Think of the options for sending a letter. TCP is like sending a registered letter that requires confirmation of receipt and to ensure ordered delivery. UDP, on the other hand, is akin to dropping a letter in a mailbox. While it may be cheaper and faster, it offers no guarantee of delivery or order. TCP prioritizes reliability, while UDP favors speed and efficiency.\n\nThese protocols are part of the transport layer in the OSI model, which directs how data is transmitted between devices.\n\nTCP, or Transmission Control Protocol, is connection oriented. This means it establishes a connection before sending data and ensures that all packets arrive in the correct order and without errors. This makes TCP reliable but can slow down the communication process. It is commonly used for applications where accuracy is crucial, such as web browsing, email, and file transfers.\n\nUDP, or User Datagram Protocol, is connectionless and does not establish a connection before sending data. It sends packets without checking if they arrive correctly or in order, which makes UDP faster and more efficient. This speed is beneficial for real-time applications like online gaming, video streaming, and voice calls where timely delivery is more important than perfect accuracy.\n\nWhen to use TCP vs. UDP ports\n\nTCP (Transmission Control Protocol) ports are best used when:\n• Reliability is crucial and you need to ensure all data arrives intact and in order.\n• Speed is more important than perfect reliability.\n• Real-time applications are involved, such as live streaming, online gaming, or VoIP.\n\n\n\nTCP is generally used for applications requiring reliable, ordered data transmission. The most common TCP ports include:\n\nUDP is preferred for applications prioritizing speed and low latency over perfect reliability. Common UDP ports include:\n• DNS (port 53): Domain Name System used for domain name resolution\n• VoIP (port 56): Voice over Internet Protocol used for phone conversations\n\nBelow is a list of the 15 most common ports and protocols in numerical order showing which protocol they use.\n• 8080 (TCP) – Alternative HTTP port, often used for web proxies\n\nCommon Ports and Protocols in Daily Use\n\nThink of how you contact the people you communicate the most on your cell phone. You connect to them by the contact’s name in your phone, not thinking about the phone number that is assigned to them. All the common things you do on your computer such as web browsing or sending an email use ports behind the scenes as well. These ports act like invisible channels, directing different types of internet traffic to the right applications. Just as you don’t need to remember phone numbers, you don’t have to think about common port numbers when using the internet. The system automatically uses the appropriate ports for each service, ensuring smooth communication between your computer and various online services.\n\nUse cases for HTTP, HTTPS, FTP, and SMTP\n\nWe all spend most of our time on the internet when on our computing devices. You open a web browser and begin to surf the internet using HTTP on port 80. You begin to shop for an item and use the HTTPS protocol to secure the purchase transaction using port 443. You then send an email to a friend using SMTP on port 25. You then transfer a file to a local server on your corporate network using FTP on port 21. Each of these actions were performed on a dedicated channel or port.\n\nBoth HTTP and HTTPS are used for web traffic. Unlike HTTP that sends data in plain text, HTTPS ensures that sensitive information like passwords, credit card details, and personal data remains confidential. This encryption ensures privacy and data integrity. HTTPS provides authentication through digital certificates. When a user connects to a website via Port 443, the server presents its SSL/TLS certificate. This certificate, issued by a trusted Certificate Authority, verifies the website’s identity, helping users confirm they’re connecting to the legitimate site and not a malicious impersonator.\n\n\n\nNetwork managers have a vast IT estate that they must monitor and manage to keep their networks optimized and secure. Some of the common ports they use every day include:\n• Port 3389 (RDP): Used for remotely accessing Windows desktops and servers. It enables administrators to control and manage Windows machines remotely as if they were sitting in front of the device.\n• Port 22 (SSH): Provides secure remote access to network devices like switches and routers. It is the standard port for encrypted command-line access to network equipment and Linux systems.\n• Port 123 (NTP): Ensures time synchronization across all network devices, servers, and workstations. This port is crucial for maintaining accurate and consistent timestamps throughout the network.\n• Ports 389 and 636: Port 389 is used for standard LDAP (Lightweight Directory Access Protocol) connections to access directory services like Windows Active Directory. Port 636 is used for LDAPS (LDAP over SSL/TLS), providing secure, encrypted access to those same directory services.\n• Port 161/162 (SNMP): These ports are used for Simple Network Management Protocol. SNMP facilitates network device monitoring and management by allowing administrators to query devices for information (via port 161), make configuration changes, and receive alerts about network events or issues (via port 162). SNMP is used for maintaining, troubleshooting, and optimizing network performance across a wide range of devices including routers, switches, servers, and other networked equipment.\n\nSome ports are more secure than others, but no port is completely safe from compromise. Here are some of the potential security risks for popular ports you use every day.\n• Ports 80 and 443 (HTTP/HTTPS): Vulnerable to web attacks like cross-site scripting (XSS), SQL injections, and DDoS attacks.\n• Port 445 (SMB): Known for the EternalBlue vulnerability, exploited in the WannaCry ransomware attack.\n\nAt the very least, your network should be protected by a perimeter firewall. By default, a firewall closes ports for all incoming traffic and opens all ports for outgoing traffic. Every time a port is opened on the firewall it creates a potential entry point for attackers, thus increasing the attack surface of your network. Open ports can also reveal valuable information about the network infrastructure and services, aiding attackers in reconnaissance effort. Outgoing common open ports can be exploited for data exfiltration or to send malicious emails. Open ports aren’t just an issue for perimeter security, however. Open ports on your local servers can enable lateral movement for attackers and facilitate the spread of malware.\n\nBelow is a list of security initiatives you should take to secure port traffic in your network.\n• Conduct frequent port scans using tools like Nmap or vulnerability scanners to identify open ports, associated services, and potential vulnerabilities. Maintain an up-to-date inventory of all open ports and their purposes.\n• Conduct Regular Vulnerability Assessments and Penetration Testing focused on open ports to identify potential weaknesses in port security\n• Enable local firewalls on all your servers and only open the ports required for essential services and applications on those machines.\n• Implement access control lists (ACLs) to restrict access to specific ports from authorized sources only. This should be done on routers and servers.\n• Always use a secure protocol when possible, such as HTTPS instead of HTTP and SFTP instead of FTP.\n• Implement Strong Authentication using multi-factor authentication for accessing critical services. Implement SH keys instead of passwords where possible and regularly rotate credentials while enforcing strong password policies.\n• Monitor and Log Port Activities: Set up comprehensive logging for all port access attempts (both successful and unsuccessful) and regularly review these logs to identify suspicious activities or unauthorized access attempts.\n• Port 53 (DNS): Domain Name System for name resolution\n• Port 8080 (HTTP Alternate): Commonly used for web proxies and caching\n\nWhile every network utilizes many of the well-known system ports, the registered ports used will vary according to the applications deployed by your organization. More examples of commonly used registered ports include:\n\nDynamic ports fall within a range of 49152-65535 and are typically used on the client side of a connection. In some cases, the dynamic port range can be configured to meet specific network requirements. These ports can either be specifically assigned by an operating system or can be randomized within the dynamic range. Dynamic ports are assigned temporarily and are released back to the pool when the connection is closed.\n\nA classic example of dynamic ports in use is Network Address Translation (NAT). Workstations in a large organization are routed out the firewall to the internet. As outgoing packets pass through the firewall or NAT device, it changes the source IP address from the private IP to a public IP. Of course, there are not enough public IP addresses for each device to have a unique address. This is where dynamic ports come into play. The source is assigned a dynamic port, with each outgoing request receiving a different port number. All ports are stored in a NAT table to consistently translate packets from the same internal host and port to the same external IP and port. This is how return traffic is matched with the source devices.\n\nCommon applications that utilize dynamic ports include the following:\n• Web browsers: When you open multiple tabs or windows, each connection may use a different dynamic port.\n• Email clients: Email applications often use dynamic ports for outgoing connections.\n• Instant messaging applications: Apps like Skype and WhatsApp use dynamic ports for peer-to-peer connections.\n• File transfer applications: Secure FTP clients, torrent clients, and cloud storage sync tools often use dynamic ports for data transfer.\n• Online gaming: Many multiplayer games use dynamic ports for player-to-player connections or game server communications.\n• Remote desktop applications: Tools like TeamViewer or VNC viewers use dynamic ports for outgoing connections.\n• VoIP applications: Voice over IP software often uses dynamic ports for call setup and audio transmission.\n• Streaming media players: When streaming content, media players may use dynamic ports for data reception.\n• Database clients: Applications connecting to remote databases may use dynamic ports for outgoing connections.\n• VMware: A port is created and assigned to a VM when the VM is powered on connected to the network.\n\nBy default, a perimeter firewall blocks all incoming traffic from the Internet. If your organization hosts web facing applications, websites, email servers or data transfer sites, you will need to utilize port forwarding. Port forwarding allows specific incoming traffic to reach internal devices by mapping external ports on the router’s public IP address to a specific internal IP address and port. When incoming traffic arrives on the specified external port, the router forwards it to the designated internal device.\n\nPort scanning allows administrators and security professionals to gain a comprehensive understanding of their network infrastructure by identifying open ports, active services, and potential vulnerabilities. Regular port scanning can help ensure compliance with various security standards and regulations. Beyond security, port scanning aids in network troubleshooting, performance optimization, and change management by providing a clear picture of the network’s current state. Some port scanning tools include Nmap, Netcat, and Angry IP Scanner. One of the most basic TCP Connect Scanning techniques involves attempting to complete a full TCP three-way handshake with the target system. Another simple way is to simply send UDP packets to detect open UDP ports.\n\nYour applications, workloads and users all depend on ports to operate correctly. While an application or service needs an open port to operate, an open port also creates a vulnerability that a threat actor can exploit. This is why a proper understanding of ports is so important for network management and security. Familiarity with the ports assigned to commonly used services and applications can aid in troubleshooting and maintaining a robust security posture. By balancing the need for accessibility with prudent security measures, network administrators can ensure optimal performance while minimizing potential risks to their infrastructure.\n\nWhat are the most common ports?\n\nWhether you are an IT professional, an executive power user, or a personal computer user, these ports will be essential for your daily activities.\n\nWhat is the most common port found?\n\nThe web is the most widely used application for users today, primarily relying on HTTP (Port 80) and HTTPS (Port 443) for communication. HTTP is the standard protocol for unencrypted web traffic, while HTTPS serves as the secure version, encrypting data to protect it during transmission.\n\nWhat is the TCP port 444?\n\n\n\nSNPP runs over TCP port 444 and allows pagers to receive messages via the Internet.\n\nTCP port 135 is primarily used for the RPC (Remote Procedure Call) Endpoint Mapper service. This port helps computers recognize and locate available services on other machines within the network, facilitating remote access and management in Windows systems\n\nWhat are commonly used port numbers?\n\nStandard port numbers, also known as well-known ports, are typically in the range of 0 to 1023. These ports are assigned by the Internet Assigned Numbers Authority (IANA) for specific services and protocols.\n\nWhat are the 3 types of port numbers?\n\nThere are three main types of port numbers:\n• Well-Known Ports (0-1023) that are reserved for reserved for standard services and protocols. They are assigned and controlled by IANA (Internet Assigned Numbers Authority). It includes things such as HTTP (80), HTTPS (443), FTP (21), SSH (22), and SMTP (25).\n• Registered Ports (1024-49151) are assigned by IANA to specific services upon request from software developers or vendors. Examples include MySQL (3306), PostgreSQL (5432), and RDP (3389).\n• Dynamic/Private Ports (49152-65535) are used for temporary connections and are not assigned to specific services.\n\nHTTPS uses the Transmission Control Protocol (TCP) for HTTPS traffic on port 443. Web traffic requires TCP to ensure the reliable, orderly delivery of data. HTTPS provides secure web communications for users.\n\nWhat are the most used ports in networking?\n\nWhile most networks rely on numerous ports, the most common ports used in a networking environment:"
    },
    {
        "link": "https://examcollection.com/certification-training/network-plus-overview-of-common-tcp-and-udp-default-ports.html",
        "document": "TCP is the abbreviation of \"Transfer Control Protocol\" whereas UDP is the abbreviation of \"User Datagram Protocol\". TCP and UDP are both the main protocols which are used during the Transport layer of a TCP/IP Model. Both of these protocols are involved in the process of transmission of data. While UDP is used in situations where the volume of data is large and security of data is not of much significance, TCP is used in those situations where security of data is one of the main issues.\n\nWhile the transfer of data, the existence of ports is a matter of high significance. Each data packet comes with a port number associated with it. This enables the protocols to decide that what are the requirements of the data packets and to which port are they supposed to be directed. In fact, the existence of ports is crucial to make sure that data packets reach their desired destinations accurately. In addition to this, there are a lot of other features such as the security of data packets which is catered by the different types of ports. The versatility of these TCP and UDP ports available enables you to select the most appropriate one for your task according to your requirement.\n\nFollowing are some of the common TCP and UDP default ports.\n\nSMTP is known as the Simple Mail Transfer Protocol. It is associated with the TCP port number 25. The primary purpose of this protocol is to make sure that email messages are communicated over the network securely. This port usually comes into being during the Application layer. Not only does this protocol carry out the task of delivering messages within networks, i can also successfully deliver messages between different networks. This makes it one of the most important ports for the communication of messages over the network due to the security and it provides along with other features. However, you do not have the privilege to download the emails in order to read them; it is just intended for the purpose of transferring them over the network.\n\nPort 80 is associated with HTTP, Hypertext Transfer Protocol. It comes under the category of a TCP protocol. It is one of the most famous and widely used ports in the world. The main purpose of port 80 is to allow the browser to connect to the web pages on the internet. Port 80 basically expects or waits for the web client to ask for a connection. Once this connection has been made, you will get the privilege to connect to the World Wide Web and get access to various web pages out there. In fact, HTTP - 80 is one of the most important ports associated with the TCP protocol. Moreover, this port is generally used during the application layer of the TCP/IP Model.\n\nHTTPS - 443 is also associated with the TCP protocol. HTTPS port 443 also lets you connect to the internet by establishing a connection between the webpages and the browser. This lets you connect to the World Wide Web. However, this port has an added feature of security to it, which HTTP port 80 does not have. This port is intended for establishing secure connections to make sure that the data is transmitted over a secure network. The use receives a warning if the browser is trying to access a webpage which is not secure. This port comes into being during the application layer. It basically encrypts and authenticates the network packets before transferring them over the network to increase the security. This feature of security is introduced by the use of SSL, which can also be referred to as Secure Socket Layer.\n\nFTP is the abbreviation of \"File Transfer Protocol\". The purpose of FTP is to transfer files over the internet. It basically lays down all the rules which are to be followed during the transfer of data. Due to the concern of security, it also asks for authentication by the user before the transfer of data. It is associated with the TCP protocol and corresponds to two ports, port 20 and 21. Both of these ports function during the application layer.\n\nPort 20 performs the task of forwarding and transferring of data. It takes over the task of transferring FTP data when it is in active mode.\n\nPort 21 performs the task of signaling for FTP. It listens to all of the commands and provides a flow control for data. It is quite essential for maintaining the flow of data.\n\nTELNET port 23 comes under the category of TCP Protocols. Its main function is to establish a connection between a server and a remote computer. It establishes a connection once the authentication method has been approved. However, this port is not suitable to establish secure connections and does not cater to the concern of security. It enables the remote connection of a computer to be established with routers and switches as well. It makes use of a virtual terminal protocol to make a connection with the server. It comes into existence during the application layer of the TCP/IP protocol.\n\nIMAP is the abbreviation of 'Internet Message Access Protocol'. The IMAP -143 Port lies under the category of TCP protocol. The primary purpose of this port is to retrieve emails from a remote server without having the need to download the email. You have the liberty to access the emails from anywhere by connecting to the server and viewing your email after providing authentication. This opportunity has been provided to you because of the existence of this port. It reserves a virtual memory for the email which enables you to read it by connecting to the server. However, you may also download the mail if you wish to. It also provides you the ability to search for your messages from a bunch of them to get to your desired one. IMAP 143 Port generally operates at the Application Layer of a TCP/IP Model. In addition to this, it also makes sure that the data remain secure during this connection.\n\nRDP is also known as the 'Remote Desktop Protocol'. It operates on the port 3389 of the TCP protocol. This port has been developed by Microsoft. It enables you to establish a connection with a remote computer. With the help of this connection, you get the liberty to control the desktop of this remote computer. This will provide you the ease to access you home desktop system from anywhere in the world just by proper authentication. In order to connect to your remote computer, you will have to forward the connection to the TCP Port 3389 which will then make available to you all the files which you have kept on your remote computer. However, since this port have been developed by Microsoft, it is essential to have a Windows operating system running on your computer in order to access it remotely. Please keep in mind that you might have to do manual settings in order to remotely access your desktop using this port. It operates on the Application layer of the TCP/IP Model. It is used worldwide for the purpose of accessing your desktop remotely.\n\nSSH is also referred to as 'Secure Shell'. It operates on the port number 22 of the TCP protocol. It carries out the task of remotely connecting to a remote server or host. It allows you to execute a number of commands and move your files remotely as well. However, it is one of the most secure ways of accessing your files remotely. Using this port, you can remotely connect to a computer and move your files with ease. This port sends the data over the network in an encrypted form which adds an extra layer of security on it. In addition to this, only authorized people will be able to remotely log on to their systems using the Port 22 which makes sure that the information does not get into unauthorized hands. It provides the chance to move files within networks as well as gives the privilege to move files between different networks securely. It operates at the Application Layer of the TCP/IP Model and is considered as one of the most secure and reliable ports for accessing files remotely.\n\nDNS is referred to as 'Domain Name System'. It operates on the port 53 of TCP and UDP protocols. DNS makes use of relational databases to link the host names of the computers or networks to their respective IP Addresses. The port 53 waits for requests from DHCP to transfer the data over the network. It operates on the Application Layer of the TCP/IP Model.\n\nTCP protocol is used by the Zone Transfer function of the DNS server. Once the connection is established, the zone data will be sent by the server using the TCP 53 port. However, when the query has to be transferred from the client computer, it will be sent using the port 53 on UDP protocol. However, if no response is received from the server within 5 seconds, the DNS query will be sent using the port 53 of TCP Protocol.\n\nDHCP is also known as 'Dynamic Host Configuration Protocol'. It basically runs on the UDP protocol. The basic purpose of DHCP is to assign IP Address related information to the clients on a network automatically. This information may comprise of subnet mask, IP Address etc. Many of the devices are automatically configured to look for IP Addresses using DHCP when they connect on a network. It makes it quite reliable to assign all the devices on a network with automatically produced IP Addresses. It generally operates on the Application layer of the TCP/IP Model. DHCP basically makes use of 2 ports; Port 67 and Port 68.\n\nUDP Port 67 performs the task of accepting address requests from DHCP and sending the data to the server. On the other hand, UDP Port 68 performs the task of responding to all the requests of DHCP and forwarding data to the client.\n\nPOP3 is also referred to as Post Office Protocol Version 3. It operates on the port 110 of TCP Protocol. It allows the email messages to be retrieved from the SMTP servers. Using this port, you can download the messages from the server and then read them. However, this means that you will not be able to access the messages and read them without downloading them. Furthermore, the messages are also deleted from the server once they are downloaded. However, this port does not cater to the issue of security. The authentication details transferred over the network are not encrypted and sent in plain text. This means that any hacker can easily intercept this information and misuse it. Port 110 generally operates on the Application layer of the TCP/IP Model.\n\nWe have discussed some of the most common and widely used Ports above. We have seen how each of these ports are either related to the UDP protocol or TCP protocol and are used at the Transport or Application layer. All of these ports perform different tasks and different processes. While we have some ports where our data can be sent securely, there are some others where the transfer of data is of more significance than its security. We can also combine different protocols to add the feature of security. For example, SSL can be added to HTTPS port to add a feature of security to it. Considering the uses and applications of these ports, it is important to realize their significance in the process of transmission of data over a network. Not only do they help you to transfer data, they also let you enjoy some other facilities as well. In fact, it is not wrong to say that networking will not be complete without the existence of these TCP and UDP Ports."
    },
    {
        "link": "https://geeksforgeeks.org/50-common-ports-you-should-know",
        "document": "Port number is a 16-bit numerical value that ranges from 0 to 65535. Well-known port (0-1023), registered port (1024-49151), and dynamic port is three types of port number space. (49152-65535).\n\nThese ports can be opened and used by software applications and operating system services to send and receive data over networks (LAN or WAN) that employ certain protocols (eg TCP, UDP).\n\nFor example, we use 80 for HTTP-web-based plain-text surfing and 443 for HTTPS-web-based encrypted websites in our daily work.\n\nTo conclude, a port is a logical form to identify system activities or various network services used to create local or network-based communications.\n\nWhat are the functions of ports?\n\nWhen interacting over the Internet, TCP and UDP protocols make connections, recompile data packages after the transfer, and then deliver them to applications on the recipient’s device. For this handover to work, the operating system must install and open the gateway for the transfer. Each door has a unique code number. After transmission, the receiving system uses the port number to determine where the data should be sent. The port numbers of the sender and receiver are always included in the data packet.\n\nPorts are assigned sequential numbers from 0 to 65535. Some of these codes are standardized, meaning they are assigned to certain uses. Since code numbers are universally recognized and permanently assigned, these standard ports are also known as well-known ports. Registered ports are those that organizations or software developers have registered for their applications. Registration is handled by the Internet Assigned Numbers Authority (IANA). A diverse selection of dynamically assigned port numbers is also available. For example, when viewing websites, browsers use these ports. After that, the port number is free again.\n\nWhy is it important to know these ports?\n\nAny security researcher, bug bounty hunter, or anyone working with service configuration would benefit from this. Knowing how to do more thorough scans such as version detection or known vulnerabilities for ancient services that are still operating in the infrastructure, especially when using tools like Nmap, is handy when getting to know these protocols and services.\n\nThe most 50 significant ports are listed here:\n\nThe following are some of the most common service names, transport protocol names, and port numbers used to differentiate between specific services that employ TCP, UDP, DCCP, and SCTP.\n\nSimple Mail Transfer Protocol, used for email routing between mail servers Hypertext Transfer Protocol (HTTP) uses TCP in versions 1.x and 2. HTTP/3 uses QUIC, a transport protocol on top of UDP Microsoft EPMAP (End Point Mapper), also known as DCE/RPC Locator service, used to remotely manage services including DHCP server, DNS server, and WINS. Also used by DCOM NetBIOS Name Service, used for name registration and resolution Hypertext Transfer Protocol Secure (HTTPS) uses TCP in versions 1.x and 2. HTTP/3 uses QUIC, a transport protocol on top of UDP. HTTP RPC Ep Map, Remote procedure call over Hypertext Transfer Protocol, often used by Distributed Component Object Model services and Microsoft Exchange Server Microsoft operating systems tend to allocate one or more unsuspected, publicly exposed services (probably DCOM, but who knows) among the first handful of ports immediately above the end of the service port range (1024+). Oracle database listening for insecure client connections to the listener, replaces port 1521 Oracle database listening for SSL client connections to the listener BitTorrent is part of the full range of ports used most often BitTorrent is part of the full range of ports used most often PDL Data Stream, used for printing to certain network printers."
    },
    {
        "link": "https://ietf.org/rfc/rfc793.txt",
        "document": ""
    },
    {
        "link": "https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers",
        "document": "This is a list of TCP and UDP port numbers used by protocols for operation of network applications. The Transmission Control Protocol (TCP) and the User Datagram Protocol (UDP) only need one port for bidirectional traffic. TCP usually uses port numbers that match the services of the corresponding UDP implementations, if they exist, and vice versa.\n\nThe Internet Assigned Numbers Authority (IANA) is responsible for maintaining the official assignments of port numbers for specific uses,[1] However, many unofficial uses of both well-known and registered port numbers occur in practice. Similarly, many of the official assignments refer to protocols that were never or are no longer in common use. This article lists port numbers and their associated protocols that have experienced significant uptake.\n\nThe port numbers in the range from 0 to 1023 (0 to 210 − 1) are the well-known ports or system ports.[3] They are used by system processes that provide widely used types of network services. On Unix-like operating systems, a process must execute with superuser privileges to be able to bind a network socket to an IP address using one of the well-known ports.[5]\n\nThe range of port numbers from 1024 to 49151 (210 to 215 + 214 − 1) are the registered ports. They are assigned by IANA for specific service upon application by a requesting entity.[2] On most systems, registered ports can be used without superuser privileges.\n\nThe range 49152–65535 (215 + 214 to 216 − 1), 16 384 ports, contains dynamic or private ports that cannot be registered with IANA.[484] This range is used for private or customized services, for temporary purposes, and for automatic allocation of ephemeral ports."
    },
    {
        "link": "https://datatracker.ietf.org/doc/html/rfc793",
        "document": ""
    },
    {
        "link": "https://en.wikipedia.org/wiki/Transmission_Control_Protocol",
        "document": "Principal protocol used to stream data across an IP network\n\nThe Transmission Control Protocol (TCP) is one of the main protocols of the Internet protocol suite. It originated in the initial network implementation in which it complemented the Internet Protocol (IP). Therefore, the entire suite is commonly referred to as TCP/IP. TCP provides reliable, ordered, and error-checked delivery of a stream of octets (bytes) between applications running on hosts communicating via an IP network. Major internet applications such as the World Wide Web, email, remote administration, and file transfer rely on TCP, which is part of the transport layer of the TCP/IP suite. SSL/TLS often runs on top of TCP.\n\nTCP is connection-oriented, meaning that sender and receiver firstly need to establish a connection based on agreed parameters; they do this through three-way handshake procedure.[1] The server must be listening (passive open) for connection requests from clients before a connection is established. Three-way handshake (active open), retransmission, and error detection adds to reliability but lengthens latency. Applications that do not require reliable data stream service may use the User Datagram Protocol (UDP) instead, which provides a connectionless datagram service that prioritizes time over reliability. TCP employs network congestion avoidance. However, there are vulnerabilities in TCP, including denial of service, connection hijacking, TCP veto, and reset attack.\n\nIn May 1974, Vint Cerf and Bob Kahn described an internetworking protocol for sharing resources using packet switching among network nodes.[2] The authors had been working with Gérard Le Lann to incorporate concepts from the French CYCLADES project into the new network.[3] The specification of the resulting protocol, RFC 675 (Specification of Internet Transmission Control Program), was written by Vint Cerf, Yogen Dalal, and Carl Sunshine, and published in December 1974. It contains the first attested use of the term internet, as a shorthand for internetwork.[citation needed]\n\nThe Transmission Control Program incorporated both connection-oriented links and datagram services between hosts. In version 4, the monolithic Transmission Control Program was divided into a modular architecture consisting of the Transmission Control Protocol and the Internet Protocol.[5][6] This resulted in a networking model that became known informally as TCP/IP, although formally it was variously referred to as the DoD internet architecture model (DoD model for short) or DARPA model.[7][8][9] Later, it became the part of, and synonymous with, the Internet Protocol Suite.\n\nThe following Internet Experiment Note (IEN) documents describe the evolution of TCP into the modern version:[10]\n\nTCP was standardized in January 1980 as RFC 761.\n\nIn 2004, Vint Cerf and Bob Kahn received the Turing Award for their foundational work on TCP/IP.[11][12]\n\nThe Transmission Control Protocol provides a communication service at an intermediate level between an application program and the Internet Protocol. It provides host-to-host connectivity at the transport layer of the Internet model. An application does not need to know the particular mechanisms for sending data via a link to another host, such as the required IP fragmentation to accommodate the maximum transmission unit of the transmission medium. At the transport layer, TCP handles all handshaking and transmission details and presents an abstraction of the network connection to the application typically through a network socket interface.\n\nAt the lower levels of the protocol stack, due to network congestion, traffic load balancing, or unpredictable network behavior, IP packets may be lost, duplicated, or delivered out of order. TCP detects these problems, requests re-transmission of lost data, rearranges out-of-order data and even helps minimize network congestion to reduce the occurrence of the other problems. If the data still remains undelivered, the source is notified of this failure. Once the TCP receiver has reassembled the sequence of octets originally transmitted, it passes them to the receiving application. Thus, TCP abstracts the application's communication from the underlying networking details.\n\nTCP is used extensively by many internet applications, including the World Wide Web (WWW), email, File Transfer Protocol, Secure Shell, peer-to-peer file sharing, and streaming media.\n\nTCP is optimized for accurate delivery rather than timely delivery and can incur relatively long delays (on the order of seconds) while waiting for out-of-order messages or re-transmissions of lost messages. Therefore, it is not particularly suitable for real-time applications such as voice over IP. For such applications, protocols like the Real-time Transport Protocol (RTP) operating over the User Datagram Protocol (UDP) are usually recommended instead.[13]\n\nTCP is a reliable byte stream delivery service that guarantees that all bytes received will be identical and in the same order as those sent. Since packet transfer by many networks is not reliable, TCP achieves this using a technique known as positive acknowledgment with re-transmission. This requires the receiver to respond with an acknowledgment message as it receives the data. The sender keeps a record of each packet it sends and maintains a timer from when the packet was sent. The sender re-transmits a packet if the timer expires before receiving the acknowledgment. The timer is needed in case a packet gets lost or corrupted.[13]\n\nWhile IP handles actual delivery of the data, TCP keeps track of segments – the individual units of data transmission that a message is divided into for efficient routing through the network. For example, when an HTML file is sent from a web server, the TCP software layer of that server divides the file into segments and forwards them individually to the internet layer in the network stack. The internet layer software encapsulates each TCP segment into an IP packet by adding a header that includes (among other data) the destination IP address. When the client program on the destination computer receives them, the TCP software in the transport layer re-assembles the segments and ensures they are correctly ordered and error-free as it streams the file contents to the receiving application.\n\nTransmission Control Protocol accepts data from a data stream, divides it into chunks, and adds a TCP header creating a TCP segment. The TCP segment is then encapsulated into an Internet Protocol (IP) datagram, and exchanged with peers.\n\nThe term TCP packet appears in both informal and formal usage, whereas in more precise terminology segment refers to the TCP protocol data unit (PDU), datagram to the IP PDU, and frame to the data link layer PDU:\n\nA TCP segment consists of a segment header and a data section. The segment header contains 10 mandatory fields, and an optional extension field (Options, pink background in table). The data section follows the header and is the payload data carried for the application. The length of the data section is not specified in the segment header; it can be calculated by subtracting the combined length of the segment header and IP header from the total IP datagram length specified in the IP header.[citation needed]\n\nTCP protocol operations may be divided into three phases. Connection establishment is a multi-step handshake process that establishes a connection before entering the data transfer phase. After data transfer is completed, the connection termination closes the connection and releases all allocated resources.\n\nA TCP connection is managed by an operating system through a resource that represents the local end-point for communications, the Internet socket. During the lifetime of a TCP connection, the local end-point undergoes a series of state changes:\n\nBefore a client attempts to connect with a server, the server must first bind to and listen at a port to open it up for connections: this is called a passive open. Once the passive open is established, a client may establish a connection by initiating an active open using the three-way (or 3-step) handshake:\n• SYN: The active open is performed by the client sending a SYN to the server. The client sets the segment's sequence number to a random value A.\n• SYN-ACK: In response, the server replies with a SYN-ACK. The acknowledgment number is set to one more than the received sequence number i.e. A+1, and the sequence number that the server chooses for the packet is another random number, B.\n• ACK: Finally, the client sends an ACK back to the server. The sequence number is set to the received acknowledgment value i.e. A+1, and the acknowledgment number is set to one more than the received sequence number i.e. B+1.\n\nSteps 1 and 2 establish and acknowledge the sequence number for one direction (client to server). Steps 2 and 3 establish and acknowledge the sequence number for the other direction (server to client). Following the completion of these steps, both the client and server have received acknowledgments and a full-duplex communication is established.\n\nThe connection termination phase uses a four-way handshake, with each side of the connection terminating independently. When an endpoint wishes to stop its half of the connection, it transmits a FIN packet, which the other end acknowledges with an ACK. Therefore, a typical tear-down requires a pair of FIN and ACK segments from each TCP endpoint. After the side that sent the first FIN has responded with the final ACK, it waits for a timeout before finally closing the connection, during which time the local port is unavailable for new connections; this state lets the TCP client resend the final acknowledgment to the server in case the ACK is lost in transit. The time duration is implementation-dependent, but some common values are 30 seconds, 1 minute, and 2 minutes. After the timeout, the client enters the CLOSED state and the local port becomes available for new connections.[32]\n\nIt is also possible to terminate the connection by a 3-way handshake, when host A sends a FIN and host B replies with a FIN & ACK (combining two steps into one) and host A replies with an ACK.[33]\n\nSome operating systems, such as Linux and HP-UX,[citation needed] implement a half-duplex close sequence. If the host actively closes a connection, while still having unread incoming data available, the host sends the signal RST (losing any received data) instead of FIN. This assures that a TCP application is aware there was a data loss.\n\nA connection can be in a half-open state, in which case one side has terminated the connection, but the other has not. The side that has terminated can no longer send any data into the connection, but the other side can. The terminating side should continue reading the data until the other side terminates as well.[citation needed]\n\nMost implementations allocate an entry in a table that maps a session to a running operating system process. Because TCP packets do not include a session identifier, both endpoints identify the session using the client's address and port. Whenever a packet is received, the TCP implementation must perform a lookup on this table to find the destination process. Each entry in the table is known as a Transmission Control Block or TCB. It contains information about the endpoints (IP and port), status of the connection, running data about the packets that are being exchanged and buffers for sending and receiving data.\n\nThe number of sessions in the server side is limited only by memory and can grow as new connections arrive, but the client must allocate an ephemeral port before sending the first SYN to the server. This port remains allocated during the whole conversation and effectively limits the number of outgoing connections from each of the client's IP addresses. If an application fails to properly close unrequired connections, a client can run out of resources and become unable to establish new TCP connections, even from other applications.\n\nBoth endpoints must also allocate space for unacknowledged packets and received (but unread) data.\n\nThe Transmission Control Protocol differs in several key features compared to the User Datagram Protocol:\n• Ordered data transfer: the destination host rearranges segments according to a sequence number 13\n• Retransmission of lost packets: any cumulative stream not acknowledged is retransmitted 13\n• Error-free data transfer: corrupted packets are treated as lost and are retransmitted\n• Flow control: limits the rate a sender transfers data to guarantee reliable delivery. The receiver continually hints the sender on how much data can be received. When the receiving host's buffer fills, the next acknowledgment suspends the transfer and allows the data in the buffer to be processed. 13\n\nTCP uses a sequence number to identify each byte of data. The sequence number identifies the order of the bytes sent from each computer so that the data can be reconstructed in order, regardless of any out-of-order delivery that may occur. The sequence number of the first byte is chosen by the transmitter for the first packet, which is flagged SYN. This number can be arbitrary, and should, in fact, be unpredictable to defend against TCP sequence prediction attacks.\n\nAcknowledgments (ACKs) are sent with a sequence number by the receiver of data to tell the sender that data has been received to the specified byte. ACKs do not imply that the data has been delivered to the application, they merely signify that it is now the receiver's responsibility to deliver the data.\n\nReliability is achieved by the sender detecting lost data and retransmitting it. TCP uses two primary techniques to identify loss. Retransmission timeout (RTO) and duplicate cumulative acknowledgments (DupAcks).\n\nWhen a TCP segment is retransmitted, it retains the same sequence number as the original delivery attempt. This conflation of delivery and logical data ordering means that, when acknowledgment is received after a retransmission, the sender cannot tell whether the original transmission or the retransmission is being acknowledged, the so-called retransmission ambiguity. TCP incurs complexity due to retransmission ambiguity.\n\nIf a single segment (say segment number 100) in a stream is lost, then the receiver cannot acknowledge packets above that segment number (100) because it uses cumulative ACKs. Hence the receiver acknowledges packet 99 again on the receipt of another data packet. This duplicate acknowledgement is used as a signal for packet loss. That is, if the sender receives three duplicate acknowledgments, it retransmits the last unacknowledged packet. A threshold of three is used because the network may reorder segments causing duplicate acknowledgements. This threshold has been demonstrated to avoid spurious retransmissions due to reordering.[37] Some TCP implementations use selective acknowledgements (SACKs) to provide explicit feedback about the segments that have been received. This greatly improves TCP's ability to retransmit the right segments.\n\nRetransmission ambiguity can cause spurious fast retransmissions and congestion avoidance if there is reordering beyond the duplicate acknowledgment threshold. In the last two decades more packet reordering has been observed over the Internet[39] which led TCP implementations, such as the one in the Linux Kernel to adopt heuristic methods to scale the duplicate acknowledgment threshold.[40] Recently, there have been efforts to completely phase out duplicate-ACK-based fast-retransmissions and replace them with timer based ones.[41] (Not to be confused with the classic RTO discussed below). The time based loss detection algorithm called Recent Acknowledgment (RACK) has been adopted as the default algorithm in Linux and Windows.[43]\n\nWhen a sender transmits a segment, it initializes a timer with a conservative estimate of the arrival time of the acknowledgment. The segment is retransmitted if the timer expires, with a new timeout threshold of twice the previous value, resulting in exponential backoff behavior. Typically, the initial timer value is smoothed RTT + max(G, 4 × RTT variation), where G is the clock granularity. This guards against excessive transmission traffic due to faulty or malicious actors, such as man-in-the-middle denial of service attackers.\n\nAccurate RTT estimates are important for loss recovery, as it allows a sender to assume an unacknowledged packet to be lost after sufficient time elapses (i.e., determining the RTO time). Retransmission ambiguity can lead a sender's estimate of RTT to be imprecise. In an environment with variable RTTs, spurious timeouts can occur: if the RTT is under-estimated, then the RTO fires and triggers a needless retransmit and slow-start. After a spurious retransmission, when the acknowledgments for the original transmissions arrive, the sender may believe them to be acknowledging the retransmission and conclude, incorrectly, that segments sent between the original transmission and retransmission have been lost, causing further needless retransmissions to the extent that the link truly becomes congested; selective acknowledgement can reduce this effect. RFC 6298 specifies that implementations must not use retransmitted segments when estimating RTT. Karn's algorithm ensures that a good RTT estimate will be produced—eventually—by waiting until there is an unambiguous acknowledgment before adjusting the RTO. After spurious retransmissions, however, it may take significant time before such an unambiguous acknowledgment arrives, degrading performance in the interim. TCP timestamps also resolve the retransmission ambiguity problem in setting the RTO, though they do not necessarily improve the RTT estimate.\n\nSequence numbers allow receivers to discard duplicate packets and properly sequence out-of-order packets. Acknowledgments allow senders to determine when to retransmit lost packets.\n\nTo assure correctness a checksum field is included; see § Checksum computation for details. The TCP checksum is a weak check by modern standards and is normally paired with a CRC integrity check at layer 2, below both TCP and IP, such as is used in PPP or the Ethernet frame. However, introduction of errors in packets between CRC-protected hops is common and the 16-bit TCP checksum catches most of these.[54]\n\nTCP uses an end-to-end flow control protocol to avoid having the sender send data too fast for the TCP receiver to receive and process it reliably. Having a mechanism for flow control is essential in an environment where machines of diverse network speeds communicate. For example, if a PC sends data to a smartphone that is slowly processing received data, the smartphone must be able to regulate the data flow so as not to be overwhelmed.[13]\n\nTCP uses a sliding window flow control protocol. In each TCP segment, the receiver specifies in the receive window field the amount of additionally received data (in bytes) that it is willing to buffer for the connection. The sending host can send only up to that amount of data before it must wait for an acknowledgment and receive window update from the receiving host.\n\nWhen a receiver advertises a window size of 0, the sender stops sending data and starts its persist timer. The persist timer is used to protect TCP from a deadlock situation that could arise if a subsequent window size update from the receiver is lost, and the sender cannot send more data until receiving a new window size update from the receiver. When the persist timer expires, the TCP sender attempts recovery by sending a small packet so that the receiver responds by sending another acknowledgment containing the new window size.\n\nIf a receiver is processing incoming data in small increments, it may repeatedly advertise a small receive window. This is referred to as the silly window syndrome, since it is inefficient to send only a few bytes of data in a TCP segment, given the relatively large overhead of the TCP header.\n\nThe final main aspect of TCP is congestion control. TCP uses a number of mechanisms to achieve high performance and avoid congestive collapse, a gridlock situation where network performance is severely degraded. These mechanisms control the rate of data entering the network, keeping the data flow below a rate that would trigger collapse. They also yield an approximately max-min fair allocation between flows.\n\nAcknowledgments for data sent, or the lack of acknowledgments, are used by senders to infer network conditions between the TCP sender and receiver. Coupled with timers, TCP senders and receivers can alter the behavior of the flow of data. This is more generally referred to as congestion control or congestion avoidance.\n\nModern implementations of TCP contain four intertwined algorithms: slow start, congestion avoidance, fast retransmit, and fast recovery.\n\nIn addition, senders employ a retransmission timeout (RTO) that is based on the estimated round-trip time (RTT) between the sender and receiver, as well as the variance in this round-trip time. There are subtleties in the estimation of RTT. For example, senders must be careful when calculating RTT samples for retransmitted packets; typically they use Karn's Algorithm or TCP timestamps. These individual RTT samples are then averaged over time to create a smoothed round trip time (SRTT) using Jacobson's algorithm. This SRTT value is what is used as the round-trip time estimate.\n\nEnhancing TCP to reliably handle loss, minimize errors, manage congestion and go fast in very high-speed environments are ongoing areas of research and standards development. As a result, there are a number of TCP congestion avoidance algorithm variations.\n\nThe maximum segment size (MSS) is the largest amount of data, specified in bytes, that TCP is willing to receive in a single segment. For best performance, the MSS should be set small enough to avoid IP fragmentation, which can lead to packet loss and excessive retransmissions. To accomplish this, typically the MSS is announced by each side using the MSS option when the TCP connection is established. The option value is derived from the maximum transmission unit (MTU) size of the data link layer of the networks to which the sender and receiver are directly attached. TCP senders can use path MTU discovery to infer the minimum MTU along the network path between the sender and receiver, and use this to dynamically adjust the MSS to avoid IP fragmentation within the network.\n\nMSS announcement may also be called MSS negotiation but, strictly speaking, the MSS is not negotiated. Two completely independent values of MSS are permitted for the two directions of data flow in a TCP connection, so there is no need to agree on a common MSS configuration for a bidirectional connection.\n\nRelying purely on the cumulative acknowledgment scheme employed by the original TCP can lead to inefficiencies when packets are lost. For example, suppose bytes with sequence number 1,000 to 10,999 are sent in 10 different TCP segments of equal size, and the second segment (sequence numbers 2,000 to 2,999) is lost during transmission. In a pure cumulative acknowledgment protocol, the receiver can only send a cumulative ACK value of 2,000 (the sequence number immediately following the last sequence number of the received data) and cannot say that it received bytes 3,000 to 10,999 successfully. Thus the sender may then have to resend all data starting with sequence number 2,000.\n\nTo alleviate this issue TCP employs the selective acknowledgment (SACK) option, defined in 1996 in RFC 2018, which allows the receiver to acknowledge discontinuous blocks of packets that were received correctly, in addition to the sequence number immediately following the last sequence number of the last contiguous byte received successively, as in the basic TCP acknowledgment. The acknowledgment can include a number of SACK blocks, where each SACK block is conveyed by the Left Edge of Block (the first sequence number of the block) and the Right Edge of Block (the sequence number immediately following the last sequence number of the block), with a Block being a contiguous range that the receiver correctly received. In the example above, the receiver would send an ACK segment with a cumulative ACK value of 2,000 and a SACK option header with sequence numbers 3,000 and 11,000. The sender would accordingly retransmit only the second segment with sequence numbers 2,000 to 2,999.\n\nA TCP sender may interpret an out-of-order segment delivery as a lost segment. If it does so, the TCP sender will retransmit the segment previous to the out-of-order packet and slow its data delivery rate for that connection. The duplicate-SACK option, an extension to the SACK option that was defined in May 2000 in RFC 2883, solves this problem. Once the TCP receiver detects a second duplicate packet, it sends a D-ACK to indicate that no segments were lost, allowing the TCP sender to reinstate the higher transmission rate.\n\nThe SACK option is not mandatory and comes into operation only if both parties support it. This is negotiated when a connection is established. SACK uses a TCP header option (see § TCP segment structure for details). The use of SACK has become widespread—all popular TCP stacks support it. Selective acknowledgment is also used in Stream Control Transmission Protocol (SCTP).\n\nSelective acknowledgements can be 'reneged', where the receiver unilaterally discards the selectively acknowledged data. RFC 2018 discouraged such behavior, but did not prohibit it to allow receivers the option of reneging if they, for example, ran out of buffer space. The possibility of reneging leads to implementation complexity for both senders and receivers, and also imposes memory costs on the sender.\n\nFor more efficient use of high-bandwidth networks, a larger TCP window size may be used. A 16-bit TCP window size field controls the flow of data and its value is limited to 65,535 bytes. Since the size field cannot be expanded beyond this limit, a scaling factor is used. The TCP window scale option, as defined in RFC 1323, is an option used to increase the maximum window size to 1 gigabyte. Scaling up to these larger window sizes is necessary for TCP tuning.\n\nThe window scale option is used only during the TCP 3-way handshake. The window scale value represents the number of bits to left-shift the 16-bit window size field when interpreting it. The window scale value can be set from 0 (no shift) to 14 for each direction independently. Both sides must send the option in their SYN segments to enable window scaling in either direction.\n\nSome routers and packet firewalls rewrite the window scaling factor during a transmission. This causes sending and receiving sides to assume different TCP window sizes. The result is non-stable traffic that may be very slow. The problem is visible on some sites behind a defective router.[60]\n\nTCP timestamps, defined in RFC 1323 in 1992, can help TCP determine in which order packets were sent. TCP timestamps are not normally aligned to the system clock and start at some random value. Many operating systems will increment the timestamp for every elapsed millisecond; however, the RFC only states that the ticks should be proportional.\n\nThere are two timestamp fields:\n• a 4-byte echo reply timestamp value (the most recent timestamp received from you).\n\nTCP timestamps are used in an algorithm known as Protection Against Wrapped Sequence numbers, or PAWS. PAWS is used when the receive window crosses the sequence number wraparound boundary. In the case where a packet was potentially retransmitted, it answers the question: \"Is this sequence number in the first 4 GB or the second?\" And the timestamp is used to break the tie.\n\nAlso, the Eifel detection algorithm uses TCP timestamps to determine if retransmissions are occurring because packets are lost or simply out of order.\n\nTCP timestamps are enabled by default in Linux,[62] and disabled by default in Windows Server 2008, 2012 and 2016.[63]\n\nRecent Statistics show that the level of TCP timestamp adoption has stagnated, at ~40%, owing to Windows Server dropping support since Windows Server 2008.[64]\n\nIt is possible to interrupt or abort the queued stream instead of waiting for the stream to finish. This is done by specifying the data as urgent. This marks the transmission as out-of-band data (OOB) and tells the receiving program to process it immediately. When finished, TCP informs the application and resumes the stream queue. An example is when TCP is used for a remote login session where the user can send a keyboard sequence that interrupts or aborts the remotely running program without waiting for the program to finish its current transfer.[13]\n\nThe urgent pointer only alters the processing on the remote host and doesn't expedite any processing on the network itself. The capability is implemented differently or poorly on different systems or may not be supported. Where it is available, it is prudent to assume only single bytes of OOB data will be reliably handled.[65][66] Since the feature is not frequently used, it is not well tested on some platforms and has been associated with vulnerabilities, WinNuke for instance.\n\nNormally, TCP waits for 200 ms for a full packet of data to send (Nagle's Algorithm tries to group small messages into a single packet). This wait creates small, but potentially serious delays if repeated constantly during a file transfer. For example, a typical send block would be 4 KB, a typical MSS is 1460, so 2 packets go out on a 10 Mbit/s Ethernet taking ~1.2 ms each followed by a third carrying the remaining 1176 after a 197 ms pause because TCP is waiting for a full buffer. In the case of telnet, each user keystroke is echoed back by the server before the user can see it on the screen. This delay would become very annoying.\n\nSetting the socket option overrides the default 200 ms send delay. Application programs use this socket option to force output to be sent after writing a character or line of characters.\n\nThe RFC 793 defines the push bit as \"a message to the receiving TCP stack to send this data immediately up to the receiving application\".[13] There is no way to indicate or control it in user space using Berkeley sockets; it is controlled by the protocol stack only.[67]\n\nTCP may be attacked in a variety of ways. The results of a thorough security assessment of TCP, along with possible mitigations for the identified issues, were published in 2009,[68] and was pursued within the IETF through 2012.[69] Notable vulnerabilities include denial of service, connection hijacking, TCP veto and TCP reset attack.\n\nBy using a spoofed IP address and repeatedly sending purposely assembled SYN packets, followed by many ACK packets, attackers can cause the server to consume large amounts of resources keeping track of the bogus connections. This is known as a SYN flood attack. Proposed solutions to this problem include SYN cookies and cryptographic puzzles, though SYN cookies come with their own set of vulnerabilities.[70] Sockstress is a similar attack, that might be mitigated with system resource management.[71] An advanced DoS attack involving the exploitation of the TCP persist timer was analyzed in Phrack No. 66.[72] PUSH and ACK floods are other variants.[73]\n\nAn attacker who is able to eavesdrop on a TCP session and redirect packets can hijack a TCP connection. To do so, the attacker learns the sequence number from the ongoing communication and forges a false segment that looks like the next segment in the stream. A simple hijack can result in one packet being erroneously accepted at one end. When the receiving host acknowledges the false segment, synchronization is lost.[74] Hijacking may be combined with ARP spoofing or other routing attacks that allow an attacker to take permanent control of the TCP connection.\n\nImpersonating a different IP address was not difficult prior to RFC 1948 when the initial sequence number was easily guessable. The earlier implementations allowed an attacker to blindly send a sequence of packets that the receiver would believe came from a different IP address, without the need to intercept communication through ARP or routing attacks: it is enough to ensure that the legitimate host of the impersonated IP address is down, or bring it to that condition using denial-of-service attacks. This is why the initial sequence number is now chosen at random.\n\nAn attacker who can eavesdrop and predict the size of the next packet to be sent can cause the receiver to accept a malicious payload without disrupting the existing connection. The attacker injects a malicious packet with the sequence number and a payload size of the next expected packet. When the legitimate packet is ultimately received, it is found to have the same sequence number and length as a packet already received and is silently dropped as a normal duplicate packet—the legitimate packet is vetoed by the malicious packet. Unlike in connection hijacking, the connection is never desynchronized and communication continues as normal after the malicious payload is accepted. TCP veto gives the attacker less control over the communication but makes the attack particularly resistant to detection. The only evidence to the receiver that something is amiss is a single duplicate packet, a normal occurrence in an IP network. The sender of the vetoed packet never sees any evidence of an attack.[75]\n\nA TCP connection is identified by a four-tuple of the source address, source port, destination address, and destination port.[d] Port numbers are used to identify different services, and to allow multiple connections between hosts. TCP uses 16-bit port numbers, providing 65,536 possible values for each of the source and destination ports. The dependency of connection identity on addresses means that TCP connections are bound to a single network path; TCP cannot use other routes that multihomed hosts have available, and connections break if an endpoint's address changes.\n\nPort numbers are categorized into three basic categories: well-known, registered, and dynamic or private. The well-known ports are assigned by the Internet Assigned Numbers Authority (IANA) and are typically used by system-level processes. Well-known applications running as servers and passively listening for connections typically use these ports. Some examples include: FTP (20 and 21), SSH (22), TELNET (23), SMTP (25), HTTP over SSL/TLS (443), and HTTP (80).[e] Registered ports are typically used by end-user applications as ephemeral source ports when contacting servers, but they can also identify named services that have been registered by a third party. Dynamic or private ports can also be used by end-user applications, however, these ports typically do not contain any meaning outside a particular TCP connection.\n\nNetwork Address Translation (NAT), typically uses dynamic port numbers, on the public-facing side, to disambiguate the flow of traffic that is passing between a public network and a private subnetwork, thereby allowing many IP addresses (and their ports) on the subnet to be serviced by a single public-facing address.\n\nTCP is a complex protocol. However, while significant enhancements have been made and proposed over the years, its most basic operation has not changed significantly since its first specification RFC 675 in 1974, and the v4 specification RFC 793, published in September 1981. RFC 1122, published in October 1989, clarified a number of TCP protocol implementation requirements. A list of the 8 required specifications and over 20 strongly encouraged enhancements is available in RFC 7414. Among this list is RFC 2581, TCP Congestion Control, one of the most important TCP-related RFCs in recent years, describes updated algorithms that avoid undue congestion. In 2001, RFC 3168 was written to describe Explicit Congestion Notification (ECN), a congestion avoidance signaling mechanism.\n\nThe original TCP congestion avoidance algorithm was known as TCP Tahoe, but many alternative algorithms have since been proposed (including TCP Reno, TCP Vegas, FAST TCP, TCP New Reno, and TCP Hybla).\n\nMultipath TCP (MPTCP) is an ongoing effort within the IETF that aims at allowing a TCP connection to use multiple paths to maximize resource usage and increase redundancy. The redundancy offered by Multipath TCP in the context of wireless networks enables the simultaneous use of different networks, which brings higher throughput and better handover capabilities. Multipath TCP also brings performance benefits in datacenter environments.[81] The reference implementation[82] of Multipath TCP was developed in the Linux kernel.[83] Multipath TCP is used to support the Siri voice recognition application on iPhones, iPads and Macs.[84]\n\ntcpcrypt is an extension proposed in July 2010 to provide transport-level encryption directly in TCP itself. It is designed to work transparently and not require any configuration. Unlike TLS (SSL), tcpcrypt itself does not provide authentication, but provides simple primitives down to the application to do that. The tcpcrypt RFC was published by the IETF in May 2019.[85]\n\nTCP Fast Open is an extension to speed up the opening of successive TCP connections between two endpoints. It works by skipping the three-way handshake using a cryptographic cookie. It is similar to an earlier proposal called T/TCP, which was not widely adopted due to security issues.[86] TCP Fast Open was published as RFC 7413 in 2014.\n\nProposed in May 2013, Proportional Rate Reduction (PRR) is a TCP extension developed by Google engineers. PRR ensures that the TCP window size after recovery is as close to the slow start threshold as possible. The algorithm is designed to improve the speed of recovery and is the default congestion control algorithm in Linux 3.2+ kernels.[89]\n\nTCP Cookie Transactions (TCPCT) is an extension proposed in December 2009 to secure servers against denial-of-service attacks. Unlike SYN cookies, TCPCT does not conflict with other TCP extensions such as window scaling. TCPCT was designed due to necessities of DNSSEC, where servers have to handle large numbers of short-lived TCP connections. In 2016, TCPCT was deprecated in favor of TCP Fast Open. The status of the original RFC was changed to historic.\n\nOne way to overcome the processing power requirements of TCP is to build hardware implementations of it, widely known as TCP offload engines (TOE). The main problem of TOEs is that they are hard to integrate into computing systems, requiring extensive changes in the operating system of the computer or device.\n\nThe wire data of TCP provides significant information-gathering and modification opportunities to on-path observers, as the protocol metadata is transmitted in cleartext. While this transparency is useful to network operators and researchers, information gathered from protocol metadata may reduce the end-user's privacy. This visibility and malleability of metadata has led to TCP being difficult to extend—a case of protocol ossification—as any intermediate node (a 'middlebox') can make decisions based on that metadata or even modify it, breaking the end-to-end principle. One measurement found that a third of paths across the Internet encounter at least one intermediary that modifies TCP metadata, and 6.5% of paths encounter harmful ossifying effects from intermediaries. Avoiding extensibility hazards from intermediaries placed significant constraints on the design of MPTCP, and difficulties caused by intermediaries have hindered the deployment of TCP Fast Open in web browsers. Another source of ossification is the difficulty of modification of TCP functions at the endpoints, typically in the operating system kernel or in hardware with a TCP offload engine.\n\nAs TCP provides applications with the abstraction of a reliable byte stream, it can suffer from head-of-line blocking: if packets are reordered or lost and need to be retransmitted (and thus are reordered), data from sequentially later parts of the stream may be received before sequentially earlier parts of the stream; however, the later data cannot typically be used until the earlier data has been received, incurring network latency. If multiple independent higher-level messages are encapsulated and multiplexed onto a single TCP connection, then head-of-line blocking can cause processing of a fully-received message that was sent later to wait for delivery of a message that was sent earlier. Web browsers attempt to mitigate head-of-line blocking by opening multiple parallel connections. This incurs the cost of connection establishment repeatedly, as well as multiplying the resources needed to track those connections at the endpoints. Parallel connections also have congestion control operating independently of each other, rather than being able to pool information together and respond more promptly to observed network conditions; TCP's aggressive initial sending patterns can cause congestion if multiple parallel connections are opened; and the per-connection fairness model leads to a monopolization of resources by applications that take this approach.\n\nConnection establishment is a major contributor to latency as experienced by web users. TCP's three-way handshake introduces one RTT of latency during connection establishment before data can be sent. For short flows, these delays are very significant. Transport Layer Security (TLS) requires a handshake of its own for key exchange at connection establishment. Because of the layered design, the TCP handshake and the TLS handshake proceed serially; the TLS handshake cannot begin until the TCP handshake has concluded. Two RTTs are required for connection establishment with TLS 1.2 over TCP. TLS 1.3 allows for zero RTT connection resumption in some circumstances, but, when layered over TCP, one RTT is still required for the TCP handshake, and this cannot assist the initial connection; zero RTT handshakes also present cryptographic challenges, as efficient, replay-safe and forward secure non-interactive key exchange is an open research topic. TCP Fast Open allows the transmission of data in the initial (i.e., SYN and SYN-ACK) packets, removing one RTT of latency during connection establishment. However, TCP Fast Open has been difficult to deploy due to protocol ossification; as of 2020 , no Web browsers used it by default.\n\nTCP throughput is affected by packet reordering. Reordered packets can cause duplicate acknowledgments to be sent, which, if they cross a threshold, will then trigger a spurious retransmission and congestion control. Transmission behavior can also become bursty, as large ranges are acknowledged all at once when a reordered packet at the range's start is received (in a manner similar to how head-of-line blocking affects applications). Blanton & Allman (2002) found that throughput was inversely related to the amount of reordering, up to a threshold where all reordering triggers spurious retransmission. Mitigating reordering depends on a sender's ability to determine that it has sent a spurious retransmission, and hence on resolving retransmission ambiguity. Reducing reordering-induced spurious retransmissions may slow recovery from genuine loss.\n\nSelective acknowledgment can provide a significant benefit to throughput; Bruyeron, Hemon & Zhang (1998) measured gains of up to 45%. An important factor in the improvement is that selective acknowledgment can more often avoid going into slow start after a loss and can hence better use available bandwidth. However, TCP can only selectively acknowledge a maximum of three blocks of sequence numbers. This can limit the retransmission rate and hence loss recovery or cause needless retransmissions, especially in high-loss environments.\n\nTCP was originally designed for wired networks where packet loss is considered to be the result of network congestion and the congestion window size is reduced dramatically as a precaution. However, wireless links are known to experience sporadic and usually temporary losses due to fading, shadowing, hand off, interference, and other radio effects, that are not strictly congestion. After the (erroneous) back-off of the congestion window size, due to wireless packet loss, there may be a congestion avoidance phase with a conservative decrease in window size. This causes the radio link to be underused. Extensive research on combating these harmful effects has been conducted. Suggested solutions can be categorized as end-to-end solutions, which require modifications at the client or server,[125] link layer solutions, such as Radio Link Protocol in cellular networks, or proxy-based solutions which require some changes in the network without modifying end nodes.[125][126] A number of alternative congestion control algorithms, such as Vegas, Westwood, Veno, and Santa Cruz, have been proposed to help solve the wireless problem.[citation needed]\n\nThe idea of a TCP accelerator is to terminate TCP connections inside the network processor and then relay the data to a second connection toward the end system. The data packets that originate from the sender are buffered at the accelerator node, which is responsible for performing local retransmissions in the event of packet loss. Thus, in case of losses, the feedback loop between the sender and the receiver is shortened to the one between the acceleration node and the receiver which guarantees a faster delivery of data to the receiver.[127]\n\nSince TCP is a rate-adaptive protocol, the rate at which the TCP sender injects packets into the network is directly proportional to the prevailing load condition within the network as well as the processing capacity of the receiver. The prevalent conditions within the network are judged by the sender on the basis of the acknowledgments received by it. The acceleration node splits the feedback loop between the sender and the receiver and thus guarantees a shorter round trip time (RTT) per packet. A shorter RTT is beneficial as it ensures a quicker response time to any changes in the network and a faster adaptation by the sender to combat these changes.\n\nDisadvantages of the method include the fact that the TCP session has to be directed through the accelerator; this means that if routing changes so that the accelerator is no longer in the path, the connection will be broken. It also destroys the end-to-end property of the TCP ACK mechanism; when the ACK is received by the sender, the packet has been stored by the accelerator, not delivered to the receiver.\n\nA packet sniffer, which taps TCP traffic on a network link, can be useful in debugging networks, network stacks, and applications that use TCP by showing an engineer what packets are passing through a link. Some networking stacks support the SO_DEBUG socket option, which can be enabled on the socket using setsockopt. That option dumps all the packets, TCP states, and events on that socket, which is helpful in debugging. Netstat is another utility that can be used for debugging.\n\nFor many applications TCP is not appropriate. The application cannot normally access the packets coming after a lost packet until the retransmitted copy of the lost packet is received. This causes problems for real-time applications such as streaming media, real-time multiplayer games and voice over IP (VoIP) where it is generally more useful to get most of the data in a timely fashion than it is to get all of the data in order.\n\nFor historical and performance reasons, most storage area networks (SANs) use Fibre Channel Protocol (FCP) over Fibre Channel connections. For embedded systems, network booting, and servers that serve simple requests from huge numbers of clients (e.g. DNS servers) the complexity of TCP can be a problem. Tricks such as transmitting data between two hosts that are both behind NAT (using STUN or similar systems) are far simpler without a relatively complex protocol like TCP in the way.\n\nGenerally, where TCP is unsuitable, the User Datagram Protocol (UDP) is used. This provides the same application multiplexing and checksums that TCP does, but does not handle streams or retransmission, giving the application developer the ability to code them in a way suitable for the situation, or to replace them with other methods such as forward error correction or error concealment.\n\nStream Control Transmission Protocol (SCTP) is another protocol that provides reliable stream-oriented services similar to TCP. It is newer and considerably more complex than TCP, and has not yet seen widespread deployment. However, it is especially designed to be used in situations where reliability and near-real-time considerations are important.\n\nVenturi Transport Protocol (VTP) is a patented proprietary protocol that is designed to replace TCP transparently to overcome perceived inefficiencies related to wireless data transport.\n\nThe TCP congestion avoidance algorithm works very well for ad-hoc environments where the data sender is not known in advance. If the environment is predictable, a timing-based protocol such as Asynchronous Transfer Mode (ATM) can avoid TCP's retransmission overhead.\n\nUDP-based Data Transfer Protocol (UDT) has better efficiency and fairness than TCP in networks that have high bandwidth-delay product.[128]\n\nMultipurpose Transaction Protocol (MTP/IP) is patented proprietary software that is designed to adaptively achieve high throughput and transaction performance in a wide variety of network conditions, particularly those where TCP is perceived to be inefficient.\n\nWhen TCP runs over IPv4, the method used to compute the checksum is defined as follows:\n\nIn other words, after appropriate padding, all 16-bit words are added using ones' complement arithmetic. The sum is then bitwise complemented and inserted as the checksum field. A pseudo-header that mimics the IPv4 packet header used in the checksum computation is shown in the table below.\n\nThe checksum is computed over the following fields:\n\nWhen TCP runs over IPv6, the method used to compute the checksum is changed:\n\nA pseudo-header that mimics the IPv6 header for computation of the checksum is shown below.\n\nThe checksum is computed over the following fields:\n\nMany TCP/IP software stack implementations provide options to use hardware assistance to automatically compute the checksum in the network adapter prior to transmission onto the network or upon reception from the network for validation. This may relieve the OS from using precious CPU cycles calculating the checksum. Hence, overall network performance is increased.\n\nThis feature may cause packet analyzers that are unaware or uncertain about the use of checksum offload to report invalid checksums in outbound packets that have not yet reached the network adapter.[130] This will only occur for packets that are intercepted before being transmitted by the network adapter; all packets transmitted by the network adaptor on the wire will have valid checksums.[131] This issue can also occur when monitoring packets being transmitted between virtual machines on the same host, where a virtual device driver may omit the checksum calculation (as an optimization), knowing that the checksum will be calculated later by the VM host kernel or its physical hardware.\n• None Floyd, Sally; Mahdavi, Jamshid; Mathis, Matt; Podolsky, Matthew (July 2000). An Extension to the Selective Acknowledgement (SACK) Option for TCP. doi: . RFC 2883.\n• None Ramakrishnan, K. K.; Floyd, Sally; Black, David (September 2001). The Addition of Explicit Congestion Notification (ECN) to IP. doi: . RFC 3168.\n• None Zimmermann, Alexander; Eddy, Wesley M.; Eggert, Lars (April 2016). Moving Outdated TCP Extensions and TCP-Related Documents to Historic or Informational Status. doi: . RFC 7805.\n• None Fairhurst, Gorry; Perkins, Colin (July 2021). Considerations around Transport Header Confidentiality, Network Operations, and the Evolution of Internet Transport Protocols. doi: . RFC 9065.\n• None Bhat, Divyashri; Rizk, Amr; Zink, Michael (June 2017). \"Not so QUIC: A Performance Study of DASH over QUIC\". NOSSDAV'17: Proceedings of the 27th Workshop on Network and Operating Systems Support for Digital Audio and Video. pp. 18. doi:10.1145/3083165.3083175. S2CID 32671949.\n• None Blanton, Ethan; Allman, Mark (January 2002). \"On making TCP more robust to packet reordering\" . ACM SIGCOMM Computer Communication Review. 32: 30. doi:10.1145/510726.510728. S2CID 15305731.\n• None Briscoe, Bob; Brunstrom, Anna; Petlund, Andreas; Hayes, David; Ros, David; Tsang, Ing-Jyh; Gjessing, Stein; Fairhurst, Gorry; Griwodz, Carsten; Welzl, Michael (2016). \"Reducing Internet Latency: A Survey of Techniques and Their Merits\". IEEE Communications Surveys & Tutorials. 18 (3): 2196. doi:10.1109/COMST.2014.2375213. hdl: . S2CID 206576469.\n• None Edeline, Korian; Donnet, Benoit (2019). A Bottom-Up Investigation of the Transport-Layer Ossification. 2019 Network Traffic Measurement and Analysis Conference (TMA). doi:10.23919/TMA.2019.8784690.\n• None Ghedini, Alessandro (26 July 2018). \"The Road to QUIC\". The Cloudflare Blog. Cloudflare.\n• None Gurtov, Andrei; Floyd, Sally (February 2004). Resolving Acknowledgment Ambiguity in non-SACK TCP . Next Generation Teletraffic and Wired/Wireless Advanced Networking (NEW2AN'04).\n• None Gurtov, Andrei; Ludwig, Reiner (2003). Responding to Spurious Timeouts in TCP . IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies. doi:10.1109/INFCOM.2003.1209251.\n• None Marx, Robin (3 December 2020). \"Head-of-Line Blocking in QUIC and HTTP/3: The Details\".\n• None Papastergiou, Giorgos; Fairhurst, Gorry; Ros, David; Brunstrom, Anna; Grinnemo, Karl-Johan; Hurtig, Per; Khademi, Naeem; Tüxen, Michael; Welzl, Michael; Damjanovic, Dragana; Mangiante, Simone (2017). \"De-Ossifying the Internet Transport Layer: A Survey and Future Perspectives\". IEEE Communications Surveys & Tutorials. 19: 639. doi:10.1109/COMST.2016.2626780. hdl: . S2CID 1846371.\n• None Sy, Erik; Mueller, Tobias; Burkert, Christian; Federrath, Hannes; Fischer, Mathias (2020). \"Enhanced Performance and Privacy for TLS over TCP Fast Open\". Proceedings on Privacy Enhancing Technologies. 2020 (2): 287. arXiv: . doi: .\n• None Stevens, W. Richard (1996). TCP/IP Illustrated, Volume 3: TCP for Transactions, HTTP, NNTP, and the UNIX Domain Protocols. Addison-Wesley. ISBN . **\n• John Kristoff's Overview of TCP (Fundamental concepts behind TCP and how it is used to transport data between two endpoints)"
    },
    {
        "link": "https://iana.org/assignments/service-names-port-numbers",
        "document": ""
    }
]