[
    {
        "link": "https://dagster.io/blog/python-project-best-practices",
        "document": "We cover 9 best practices and examples on structuring your Python projects for collaboration and productivity.\n\nPython is a versatile and widely-adopted programming language used for everything from data analysis to web development. However, as Python projects grow in complexity, it can become challenging to keep track of all the moving parts and ensure that everything stays organized.\n\nThat's where having an understanding of Python file and project directory structures comes in. In this article, we'll review some key concepts in structuring Python projects and how to best apply them.\n\nIf you're just starting out, these best practices will not only help you write better code, but they can also help you better maintain and scale your Python codebases or data pipelines.\n• Why break up your projects?\n\nWhy break up your projects?\n\nAs Python programs become larger, they become harder to manage. This is especially true if a team is collaborating on the project and making changes to multiple aspects of the project at once.\n\nIn order to make the Python project more manageable and maintainable, we break large, unwieldy programming tasks into more manageable subtasks or modules. Modules, as their name suggests, can then be reused in multiple places.\n\nBreaking the project down into modules is called “Modular programming.\" As discussed in previous articles, functions, modules, and packages are all mechanisms used in Modular Programming. Modular programming provides many advantages.\n• It simplifies your work by allowing you to focus on one module at a time.\n• It makes your project more maintainable. If a team is working together on a project, adopting a modular approach reduces the likelihood your work will end up in version conflicts.\n• It makes your code more reusable. If your project is one large monolith, anybody looking to reuse it has to parse through a lot of code. If your code is organized in modules, importing just the parts that are needed becomes easier.\n• It reduces duplication. As per the point above, modular code is more reusable, meaning it is less likely you will end up duplicating functions.\n• It helps avoid namespace conflicts as each module can define a separate namespace.\n\nWhen you look for advice online about how to organize and write your Python code, you will find a lot of different ideas. But really, it comes down to a few basic things.\n\nProperly organizing your code is crucial when working on a Python project. You can start by creating separate folders for different parts of the project, such as one for the code itself, one for data, one for testing, and one for project documentation. This way to structure will help you find what you need more quickly and make it easier for others to navigate your code.\n\nIt's important to use consistent names for files and folders throughout your project. Try to follow conventions like using underscores for variables and functions and capital letters for classes. This will make it easier to read and understand your code.\n\nEven when working alone, using a tool like Git to keep track of changes to your code is a recommended best practice. It allows you to keep a record of your changes and easily back up your work to a cloud-based repository. Most cloud-based Git solutions offer a free tier for solo practitioners.\n\nUsing a package manager like pip to manage dependencies will help you install and keep track of all the different pieces of software your project needs to run. This is especially important when working with large projects with many dependencies.\n\nTo keep your Python project isolated from other projects on your computer, you can use a virtual environment. A virtual environment will prevent conflicts between packages used in different projects.\n\nAdding comments to explain what your code is doing and how to use it is important for making your code more accessible to others. It also helps you remember what you were thinking when you wrote the code.\n\nUsing automated tests to check that your code works as expected is essential for catching bugs early on. This will save you time and prevent issues down the line.\n\nUsing a tool like Ruff or Flake8 to make sure your code looks consistent and catch common mistakes will help you write better code. These tools check your code for consistency with PEP 8, the official Python style guide. You can also use a tool like Black to ensure that your code looks the same across your project. This will help you maintain consistency and make it easier to read and understand your code.\n\nUsing a tool like setuptools to package and distribute your Python code will make it easier to share your work with others. This will also help ensure that others can use your code without encountering any issues.\n\nLet’s apply these tips to a hands-on example. We’ll use several best practices, including organized code, consistent naming, helpful comments, and tests.\n\nWe’ll write a script to extract data from a database, transform it, and load it into another database. Let’s first define variables and functions in a module named my_module.py:\n\nIn this example, we use consistent names for the variables and functions. Constants like , , , , and are all capitalized and separated by underscores. Functions like , , and are all lowercase and separated by underscores.\n\nNext, let’s write a simple unit test in a file to make sure our code works the way we want it to:\n\nHere, we imported the and module, as well as the function from\n\nThen, we defined a test class called that inherits from . In this class, we define a single test function called . This function creates a sample input DataFrame with three rows of data, calls the function with this input data, and then checks the output DataFrame to make sure it has the expected values.\n\nWe define the expected output DataFrame with the same three rows of data and use the function to check that the output DataFrame matches the expected DataFrame. If the output DataFrame matches the expected DataFrame, the test will pass. If not, the test will fail and provide information on where the mismatch occurred.\n\nWhen you code with other developers, the most important things to consider are:\n• making sure you have the correct version of the code and\n\nThis is where version control comes in handy. Suppose a team of developers is working on a Python project that involves developing a web application. Each developer is working on a specific feature or module of the project. Without version control, the team would have to coordinate their work manually, which can be daunting and error-prone. One developer may accidentally overwrite another's work, leading to lost progress or conflicts.\n\nHowever, by using a version control system like Git, the team can easily track changes, collaborate on code, and ensure that everyone is working with the same version of the codebase. With Git, each developer can work on their own branch, which allows them to make changes independently without affecting the main codebase.\n\nWhen it's time to integrate everyone's changes, Git provides tools for merging code and resolving conflicts, making it much easier for the team to work together. Git also provides a complete history of the codebase, including all changes made by each developer, which can be useful for debugging and understanding how the code has evolved over time.\n\nTo ensure that changes to shared code don't break other projects, it's a good idea to use automated testing tools like pytest. It's also a good practice to review code changes before merging them into the main code base.\n\nFinally, when it comes to ‘easy collaboration’ and as mentioned in our list of best practices, it's important to document your code as you write it. This makes it easier for new team members to understand the code and get up to speed.\n\nYou might have wondered why Python projects have the structure . This way of organizing a project is popular in Python because it helps keep everything neat and tidy. The top folder, called \"my-project,\" is like the main folder for the entire project. The use of the dash and the underscore help differentiate between the two levels of the project. The underscore, in particular, helps distinguish the project reference from a variable or function name that might use the dash symbol. Because a dash is also a minus sign, the \"inner level\", which defines a python package, must use the underscore.\n\nThere are loose norms for how to organize files inside \"my-project\". The top level typically contains a file and various configuration files. The most important part of your project is the one or more python packages it contains. A python package is a directory constituting a valid target for Python's import system, typically containing an file. In this example, there is one Python package named \"my_project\", which is placed in the top level.\n\nFrom here, the key files and subfolders found in most projects are:\n• A dependency management file (typically or ) This file is used to configure your project and its dependencies. We explored dependecy management in part two of this blog series.\n• : This file, written as markdown, provides a brief introduction to your project, its purpose, and any installation or usage instructions.\n• : This plain text file specifies the license under which your code is released. There are many open-source licenses to choose from, so be sure to select one that fits your needs.\n\nIn addition, many projects will have the following two folders:\n• : This directory is an alternative location for python packages if you don't want to place them directly in the project root.\n• : This directory contains test code that verifies the functionality of your project. You can use a testing framework like pytest or unittest to write and run tests.\n\nWe’ve shared how organizing Python projects in a structured manner is crucial as the project's complexity grows, especially if you are part of a team or plan on sharing your work with other developers. By following the recommended python project structure outlined in this article, you can maintain and scale your codebases or data pipelines more easily.\n\nIn part 4 of our guide, From Python Projects to Dagster Pipelines, we explore setting up a Dagster project, and the key concept of Data Assets.\n\nWe're always happy to hear your feedback, so please reach out to us! If you have any questions, ask them in the Dagster community Slack (join here!) or start a Github discussion. If you run into any bugs, let us know with a Github issue. And if you're interested in working with us, check out our open roles!"
    },
    {
        "link": "https://reddit.com/r/learnpython/comments/f3vwzx/best_practices_in_python_scripts",
        "document": "I am learning and writing py scripts for some time now and was wondering what are the best practices that the beginner should follow to make professional looking scripts. This request is not about PeP convention rather I want to know the things which makes script professional. Can someone enumerate things like\n• try except block And other practices which beginner overlooks but should be on his/her list to learn and then start implementing in their scripts, asap."
    },
    {
        "link": "https://blog.inedo.com/python/8-ways-improve-python-scripts",
        "document": "For more information on using Python, check out Effective Package Management in Python, our free, downloadable eBook\n\nBe honest. Have you ever opened a script, spent 30 seconds trying to understand it, then walked away because you couldn’t figure out what was going on?\n\nNow be brutally honest, were you the original creator of that script?\n\nEvery day on teams around the world, team members are re-creating code that already exists.\n\nThere are TONS of articles outlining “Python Programming Best Practices” targeted towards Python projects/applications practices. But these typically require you to spend time investing in skills that take years to master.\n\nThis article will outline the 8 simple things non-developers can do to immediately improve Python scripts.\n• Differentiate Your Scripts from Your Applications\n\n1. Differentiate Your Scripts from Your Applications\n\nWith Python programming, there’s no clear line between Scripts and Applications, but identifying those differences internally is important. Scripts are much easier, simpler, and cheaper to create and maintain compared to applications. Without defining the difference internally, you run the risk of spending an application’s amount of effort on a simple script.\n\nAs a general rule, scripts are created by coders for coders. Scripts are often technically difficult and require training to understand. However, that doesn’t mean that scripts complete technically difficult executions. Scripts can do something as simple as opening a port or putting a computer to sleep.\n\nApplications are created by developers for end-users and typically come with some sort of graphic interface. Applications often must follow business and technical processes and often go through much more rigorous and regimented testing, QA, review, etc. before they’re ever available for use.\n\nThe biggest difference is who uses them and the mentality behind their creation.\n\nThe first way to improve your coding practices immediately is to stop overengineering your scripts. If there’s ever a point where you think “Oh this could be two separate scripts” then it probably should be two separate scripts. The more “features” you add to a script, the riskier it is to change – and the closer it becomes to an application.\n\nImproving your Python code isn’t about creating a piece of code that’s bug-free or optimizing something to its limits. It’s about writing a script that all members of your team can understand, run, and modify. Adopting this mentality allows team members (today and tomorrow) to easily change and evolve alongside your team and organizational needs.\n\nYou may have been the original creator of a script, but you do not own it. Your company owns your scripts, and your company needs to be the keeper of them. I’ll say it once again for the folks in the back, you cannot be the sole person responsible for understanding how/why you made your scripts and how/when to use them!\n\nEspecially for your junior team members, scripts need to help get them up to your speed, not stall their progress. Less time spent trying to understand a script means more time spent on constructive learning and growth.\n\nThere are a ton of great PyPI packages available, but the more you use, the longer it’ll take someone else to learn and understand your script.\n\nHow do you keep things simple? Well on top of splitting scripts up, scripts should mostly be able to use the standard library and not require too many (if any) third-party packages. Packages like Colorama and JMESPath are convenient and add functionality to Python, but it’s less and less likely that junior engineers will know how they work.\n\nOur advice? Stick with packages that are stable and that everyone on the team will be familiar with. Keep in mind, the better the package documentation, the easier it’ll be to train on.\n\nWhen using third-party libraries, environment management (i.e. which packages and versions are installed) becomes important. Lots of packages mean lots of environment management. While it’s possible to package all scripts and dependencies and deploy that, that’s coming really close to an application and is in danger of getting complicated quickly.\n\nIf you’re not already following it, your team needs to adopt version control for your scripts.\n\nThis doesn’t mean you need to jump into Git-based source control. There are much simpler tools available, and you’re probably already using them: SharePoint, OneDrive, and Dropbox are all fine options to get started. They’re much better than a network drive that’s backed up from time to time.\n\nVersion control can be used to roll back changes if things go wrong, and someone makes a bad edit. It also stores an audit of who made changes and when, and if you use these basic tools, it happens every time the file is saved.\n\nScripts are company assets, so they should be maintained as long as possible. If you are constantly spending time writing new scripts, you may as well not be using automation and still be doing everything by hand.\n\nWriting great comments definitely helps with script maintainability, but like writing great code, it can take a lifetime to master. There’s a much faster, simpler way to make a better script: comment headers. Here’s a quick example of the contents of a comment header:\n\nWhile there’s no real standard for what these look like, at an ABSOLUTE MINIMUM, you need to include a description and arguments to run the script. Examples are really helpful, too.\n\nYou don’t need to go overboard: just start by writing a sentence or two that describes the purpose of your script. Then add this as a comment to the comment header. Just try to keep in mind your audience and what they would want and need to properly understand and use your script:\n• Runners: people who read the script before they run it\n• Editors: people who are responsible for adapting and maintaining your script\n\nMost scripts outlive their creators in an organization, and a great script is one that can change and it’s clear how to change it.\n\nInstead of using “#” for all of your comments, you should switch to docstrings (i.e. “””) for comment headers, functions, and definitions. It’s a small change, but one that you and your future team members will appreciate later.\n\nThe most obvious immediate benefit is that you get multiline comments, and don’t need to start every line with a “#” symbol. But more importantly, docstrings provide a very easy and convenient way of associating documentation with Python modules, functions, classes, and methods. And best of all, when properly formatted, users can easily access internal help by calling the `help` function.\n\nFor example, here’s what “standard” comments look like:\n\nAs an added bonus, if you format your docstring comments following popular conventions like Google’s Style Guide for Docstring Headers, other tools like Otter can then read your script and display a UI to help run it. This means you could use those comments to create an auto-generated, personalized GUI.\n\nWhile you may find some arguments online, it’s our firmly held belief that teams should be choosing logging over print.\n\nLogging allows users to easily see where and when a logging call is being made and you can categorize your logging based on four levels of severity. Print doesn’t offer any extra functionality or usability past putting words onto the screen. It’s a small change to how you write your code, but it is a game-changer for your Python codebase.\n\nLike using print(), logging() will help you troubleshoot scripts. But unlike print(), logging will show you where and when a logging call is being made from. Logging lets you control which severity level to display on the console, which severity level to save in a text file, or do both!\n\nOther Python modules use logging as well, and you can categorize based on whether the messages are from your modules, your scripts, or third-party modules.\n\nNot that you’ll start doing any of those things right away, but as you get more experienced and advanced in your scripting practices, you’ll come to appreciate that your old scripts used logging over print.\n\nAn added bonus of logging is external Infrastructure management tools, like Otter, can read and collect the various output streams from Python to create permanent records that can be used to analyze scripts more efficiently than simply scrolling through hundreds of lines of output.\n\nCode your scripts with this mantra in mind: “Everything I write will fail.” Failures could be something as simple as not being able to find “cute-otters.jpg” or something a bit more serious, such as a setting not applying correctly, leading to a bunch of misconfigured servers.\n\nPython supports a simple but powerful Try/Except statement that will try to execute a command and catch any errors that occur. For example:\n\nThe biggest benefit you’ll get from using this today is the ability to log additional information about the error, or even continue if the problem is recoverable.\n\nAnother improvement you can start today is the raise statement. It works almost the same as printing some messages and then using sys.exit() when things go wrong.\n\nprint (\"Error: The .BAML file had an unexpected format.\")\n\nsys.exit(-1)\n\n\n\n-- vs --\n\n\n\nraise Exception(\"The .BAML file had an unexpected format.\")\n\nHowever, the raise statement will make it easier to handle the error with try/except – particularly if you’re having one script call another script. It also makes the script much more readable by clearly defining what will happen in specified scenarios.\n\nSimple code is better code. Start simplifying your code by splitting up your current scripts and practicing your commenting. Truly improving and overhauling your Python codebase will take years to get right, but using these 8 easy tricks, you can immediately improve your Python scripts.\n\nThese tricks are just the beginning of what it takes to become a Python master. To learn more, sign up for our Effective Package Management in Python guide."
    },
    {
        "link": "https://blog.inedo.com/python/modularization-and-packages",
        "document": "This article is part of a series on Effective Package Management in Python, also available as a chapter in our free, downloadable eBook\n\nRepeatedly writing the same Python scripts is tedious, and eventually, bad scripting practices can take over. Personal scripts quickly become team scripts, changes are not documented, information silos form, and the list goes on. Over time these bad practices can slowly take over until you suddenly find yourself in a dark and confusing place. Welcome to .\n\nUsing modularization and packaging can break down large scripts into smaller manageable files. Python Modularization is effective, but it needs to be done the right way or you could go from to .\n\nIn this article I’ll teach you how to make Python packages that keep you out of script hell and on your merry way to Python mastery.\n\n🔥 Every change made to the code breaks two or three other parts.\n\n🔥 Every addition or modification to the system requires that the tangles, twists, and knots be “understood” so that more tangles, twists, and knots can be added.\n\nOver time the code becomes a labyrinth that is impossible to organize or manage effectively. Once in script hell teams that were moving very fast at the beginning of a project can find themselves moving at a snail’s pace.\n\nWhat is Modularization and How Does it Help With Script Hell?\n\nModularization is the technique of splitting a large programming task into smaller, separate, and manageable subtasks. Like most modern programming languages, Python is a modular programming language. Python scripts are modularized through functions, modules, and packages.\n\nFunctions allow developers to reduce repetition in their code by executing the same block of code multiple times in one program. By giving the function a name, it can be reused by referencing it’s name instead of rewriting the code. For example, consider a simple function that greets a user after entering their name.\n\nWhen we run the code, nothing happens but if we reference the function name like so:\n\nPython Modules are “. py” files containing Python definitions and statements. You’re certainly already using modules without even realizing it!\n\nA package is a set of modules (i.e. .py files) organized in folders and subfolders. Python accesses the modules in a package by referencing the package name.\n\nIn the above example, the various Python modules are organized in relevant folders like templates and website. By referencing the package name “templates”, Python can access the modules inside the package.\n\nPackages are at the heart of code reuse, and are likely something you’re already using with PyPI (free and open-source Python packages) and “pip install”.\n\nPython packages can either act as “import” packages or “distribution” packages. Both package types are important to escaping Python script hell. Import packages allow Python code modularization while distribution packages allow you to distribute the code you’ve modularized.\n• Import packages ( files) contain reusable Python modules that can be loaded into a Python interpreter to execute various commands.\n• Distribution packages (zip files) have an archive that contains a library of reusable Python modules and metadata about the library.\n\nCreating a Python package is simple enough that anyone with Python or coding experience can create one, but make sure to follow best practices when doing so. There are many ways to make Python packages, the most common being setuptools and then uploading it via twine, but ultimately it depends on the developer’s preferences.\n\nHow to Make Better Packages and avoid Package Hell\n\nLearning how to create a Python Package can be done in a single sitting, but if you’re not confident in your ability to create high-quality packages you’re better off using scripts.\n\nWhile packages are extremely useful, a bad package can do much more damage than a bad script. One or two mediocre packages are negligible, but when you start including dozens of low-quality packages you can quickly end up in a place worse than script hell: package hell. Scripts are more likely to be higher quality due to them being reviewed before running. Users expect packages to “just work” and often will not bother doing quality checks.\n\nCreating good packages takes years of practice and experience. Packages can be difficult to manage efficiently thanks to versioning and package dependencies. Investing the time to learn how to create good packages will keep you out of both scripts and package hell. A bad package may “work” in the beginning, but it will make life difficult for whoever needs to maintain the package in the future.\n\nBetter Packages through Better Coding\n\nLearning how to create good Python packages and implementing Python modularization will take time, especially if your team was near or in script hell beforehand.\n\nA good thing to internalize early on is the fact that not everything needs to be modularized. Creating packages and modularizing everything is understandably very tempting. However, having endless unorganized packages is guaranteed to earn you a ticket straight to package hell. Knowing what to package is difficult and takes years of experience to do correctly, thus the person deciding what to modularize should have strong institutional knowledge.\n\nTo avoid future headaches, it’s a good idea to identify which copy/paste functions you will be using and double-check their quality. Remember a good quality script function is infinitely better than a mediocre package. There’s no magic formula to determine the right number of packages to use, but be aware that too few and too many packages are both forms of package hell.\n\nBetter Packages Through Better Packaging\n\nThe first step to making better packages is to accept that no matter your skill level you will make mistakes and improve in the process. The following skills are not easy, but they are worth learning if you want to avoid slipping into script hell.\n\nWhen you make changes to a file create a new version with an updated version number. Versioning needs to be organized, have meaning, and be strictly followed. Python doesn’t fully support Semantic Versioning, but we recommend using three-part versioning in the same manner. Versioning is so important that we wrote an entire article on how to version Python packages.\n\nOnce you publish a package you should always know exactly where the original code (.py file) is. Use source control to manage your packages rather than downloading, editing, changing their version, and republishing. ProGet can help with this by “repackaging” packages and maintaining an audit trail within the package.\n\nRemember that script hell is utter chaos. What’s the opposite of chaos? Order. It’s important to have a clear outline of who is responsible for changes and how they will be updating packages. This will take an upfront resource investment, but it’s well worth the number of headaches it will avoid.\n\nThe key to maintaining long-term good packaging practices is keeping accurate and up-to-date documentation. It’s really easy to get carried away and make too many packages. If this happens AND you weren’t keeping good documentation on the packages, you will certainly have a long and confusing journey out of package hell. It’s also imperative to document changes made to packages because you may not be the only one maintaining them.\n\nOnce you have implemented these better packaging practices it’s time to think like a developer and automate! Establishing a Software Development Lifecycle (SDLC) that incorporates versioning, source control, change control, and documentation will have your team modulating like a well-oiled machine.\n\nBe Wise When You Modularize\n\nPython modularization can keep you out of script hell as long as you plan ahead and follow clear practices for maintaining and creating high-quality Python packages.\n\nPhew, that was a lot to get through, and you’ll definitely want to keep this around for reference. It’s actually one of the chapters in our Effective Package Management in Python guide. Creating high-quality Python packages is an important skill. However, there are many other Python skills, like versioning and package approval workflows, that are necessary too. Here you’ll learn all the skills necessary to turn your team into Python experts.\n\nPhew, that was a lot to get through, and you’ll definitely want to keep this around for reference. This topic is covered in detail in our “Effective Package Management in Python” guide, which dives deep into creating high-quality Python packages—a crucial skill. Beyond package creation, mastering versioning and package approval workflows are also essential Python skills. Sign up and download your free copy today!"
    },
    {
        "link": "https://stackoverflow.com/questions/45129728/what-is-the-best-practice-for-running-a-python-script",
        "document": "I am developing some scripts that I am planning to use in my LAB. Currently I installed Python and all the required modules only locally on the station that I am working with (the development station).\n\nI would like to be able to run the scripts that i develop through each of my LAB stations.\n\nWhat is the best practice to do that ?\n\nWill I need to Install the same environment, except for the IDE of course, in all my stations ? If yes, then what is the recommended way to do that ?\n\nBy the way, is it mostly recommended to run those scripts from the command line screen (Windows) or is there any other elegant way to do that ?"
    },
    {
        "link": "https://docs.python.org",
        "document": "What's new in Python 3.13?\n\n Or all \"What's new\" documents since Python 2.0\n\nTutorial\n\n Start here: a tour of Python's syntax and features\n\nPython setup and usage\n\n How to install, configure, and use Python"
    },
    {
        "link": "https://docs.python.org/3/tutorial/index.html",
        "document": "Python is an easy to learn, powerful programming language. It has efficient high-level data structures and a simple but effective approach to object-oriented programming. Python’s elegant syntax and dynamic typing, together with its interpreted nature, make it an ideal language for scripting and rapid application development in many areas on most platforms.\n\nThe Python interpreter and the extensive standard library are freely available in source or binary form for all major platforms from the Python web site, https://www.python.org/, and may be freely distributed. The same site also contains distributions of and pointers to many free third party Python modules, programs and tools, and additional documentation.\n\nThe Python interpreter is easily extended with new functions and data types implemented in C or C++ (or other languages callable from C). Python is also suitable as an extension language for customizable applications.\n\nThis tutorial introduces the reader informally to the basic concepts and features of the Python language and system. It helps to have a Python interpreter handy for hands-on experience, but all examples are self-contained, so the tutorial can be read off-line as well.\n\nFor a description of standard objects and modules, see The Python Standard Library. The Python Language Reference gives a more formal definition of the language. To write extensions in C or C++, read Extending and Embedding the Python Interpreter and Python/C API Reference Manual. There are also several books covering Python in depth.\n\nThis tutorial does not attempt to be comprehensive and cover every single feature, or even every commonly used feature. Instead, it introduces many of Python’s most noteworthy features, and will give you a good idea of the language’s flavor and style. After reading it, you will be able to read and write Python modules and programs, and you will be ready to learn more about the various Python library modules described in The Python Standard Library.\n\nThe Glossary is also worth going through."
    },
    {
        "link": "https://linode.com/docs/guides/how-to-write-and-run-python-script",
        "document": "This credit will be applied to any valid services used during your first days.\n\nPython is one of the most popular programming languages due to its ease of use and a large selection of built-in features. This guide describes the basic concepts behind Python, including how to install and use Python modules. It also explains how to write and run a Python script.\n\nPython is a good example of a modern high-level programming language. It is open source and is designed for general use, capable of working in many domains. Python is simple and easy to use and is highly readable, so it is considered a good language for beginners. Python is packed with useful built-in features, but it can also be extended through the use of modules. Python is dynamically-typed, platform-independent, and supports Object-Oriented Programming (OOP) techniques. Check the More Information section of this guide for some of the Python tutorials and reference materials.\n\nPython is an interpreted language that allows users to write and run scripts interactively. Interpreted languages are processed by an interpreter, not compiled. Users can run a program as soon as they write it, with no intermediate steps. Python interpreters evaluate Python scripts. Scripts are plain text files that are written in a text editor or an interactive development environment. Every script contains a sequence of commands written in the Python programming language. Due to Python’s interpreted nature, Python scripts are completely portable from one system to another. Only the source code and a Python interpreter are required to run a Python script.\n\nThe current iteration of the Python interpreter is Python 3, which was introduced in 2008. This is the version installed on most Linux distributions. Python 3 is not compatible with earlier releases and some older scripts require Python release 2. The specific release of the Python interpreter to use can be specified from the command line using either or . A Shebang on the first line of a Python script can also identify which interpreter to use.\n\nThe Python interpreter follows the Python Execution Model. It deciphers each line at runtime and executes the command. This differs from compiled languages like C/C++. The Python compilation stage happens at runtime and is hidden from the user. Python initially compiles a program to low-level bytecode. The Python Virtual Machine (PVM) then interprets and executes the bytecode. The PVM is platform-specific. Each platform must use its own version of the PVM. A Linux system must use the Linux variant of the interpreter to run Python scripts.\n\nPython makes heavy use of external modules. Unlike a script, a module is not a stand-alone program. It contains functions and variables that are designed to be used in other programs.\n• None If you have not already done so, create a Linode account and Compute Instance. See our Getting Started with Linode and Creating a Compute Instance guides.\n• None Follow our Setting Up and Securing a Compute Instance guide to update your system. You may also wish to set the timezone, configure your hostname, create a limited user account, and harden SSH access.\n\nBefore running any Python programs, Python must be installed on the system. On most modern Linux distributions, Python is already pre-installed. To determine whether the interpreter is installed and up-to-date, use the option to verify the release number.\n\nIf the command is not recognized, Python is not installed. This might be the case if the system has not been upgraded recently or if Python has been uninstalled at some point. To install Python release 3, run the following commands:\n\nHow to Install and Use Python Modules\n\nAfter Python is installed, it is possible to use the Python package manager to download and install new modules and packages. is not installed by default and must be downloaded first. To download , use the command below:\n\nThe command downloads and installs new modules. The following command installs the Python-Markdown library. This module converts Markdown code to HTML. After it completes the installation process, provides a confirmation message.\n\nTo access the parameters, classes, and methods from a module, use the command. This command takes the form . Both third-party and built-in Python modules can be imported. directives are traditionally near the top of a Python script. The example below demonstrates how to source and use the module.\n\nFor more detailed information on modules, see our How to Install and Import Python Modules guide.\n\nDevelopment environments with many Python projects, packages and modules are often complicated to manage. Package conflicts can occur when new releases of existing packages overwrite older releases. Python virtual environments help manage these dependencies and avoid conflicts. For more information, review the Linode guide on Managing Python Packages and Versions on Linux.\n\nPython scripts are plain text files ending with the extension . You can use any text editor or IDE to write a Python script. Python does not require any type of specialized or proprietary development environment.\n\nSome Python programs include a Shebang as the first line. A Shebang begins with the characters . In a Python file, a Shebang tells the system which version of the interpreter to use. The Shebang indicates the interpreter should run the program. This ensures the correct Python interpreter is always used and avoids running a script with an incompatible interpreter. If a script does not contain a Shebang, the default interpreter is used.\n\nIn most cases, a simple Python script consists of the following elements:\n• An optional Shebang, if used, must be the first line of the file.\n• An optional list of constants. Python does not require programmers to declare variables before use. However, global variables are typically initialized here.\n• The main body of the script. This section of code calls any supporting functions or class methods it requires.\n\nThe following is an example of a short demo program demonstrating some of the key components of a Python script. It accepts an input value from the user, takes the square root of the number, and multiplies it with a constant. It begins with a Shebang that guarantees the program uses the Python 3 compiler, and imports the and modules. It declares the function, accepts a value from the user, validates the value, and calls the function with the input value. It then prints the result to standard output.\n\nIn most large programs, the main code block in the file consists solely of the conditional expression . This expression only evaluates to in the top-level environment of the program. A top-level environment occurs inside the interactive Python prompt, or inside a script that is passed as a file argument to the command. For the command , the top-level environment includes the code space inside the file.\n\nIf this conditional evaluates to , the script calls the “real” function. The function is only ever called in this situation. This technique prevents the program code from running when the script is sourced by the command. contains the main block of program code. In a well-structured application primarily consists of calls to more specialized and modular functions. The supporting functions or classes contain most of the actual functionality.\n\nFollowing is an example demonstrating how to implement this technique.\n\nHow to Use Common Python Control and Data Structures\n\nPython programs are built out of fundamental control and data structures. Without these features, Python programs would be static and relatively trivial.\n\nA control structure controls the execution flow of a program. Operators are used to making logical decisions. Data structures store and organize data, and often provide mechanisms to retrieve and manipulate the data.\n• Comparison Operations: These operators are used to compare two variables or a variable and a constant. The operator tests for equality, while tests for inequality. The (“less than”) and (“greater than”) symbols are relational comparators. For convenience, Python also provides the (“less than or equal”) and (“greater than or equal”) operators. Python allows programs to use comparison operators on strings, characters, and other objects. However, not all operations are valid on all objects. The Linode guide to Boolean Variables, Operators, and Conditional Statements in Python provides more options.\n• Conditional Statements: Conditional statements use Boolean expressions to make decisions. These decisions determine the control flow of the program. If the result of the Boolean expression is True, the program runs a sequence of commands. If the result is False, it might run other lines of code, or it might do nothing at all. In Python, the most important conditional statement is the statement, along with the and variants. For more information, see the Linode guide to If Statements and Chained Conditionals.\n• Logical Operators: Logical operators combine several comparison operations into larger compound statements. The main logical operators are , , and . The expression means must be and must also be . The expression is if either or is , or if both are . is only when evaluates to . The Linode guide to Boolean Variables, Operators, and Conditional Statements in Python introduces the logical operators.\n• Loop Statements: Python loop statements execute a block of code zero or more times. A loop is used when the number of repetitions is known before entering the loop. The statement is better for situations where a loop keeps running until some condition is met. Loops can also iterate across a sequential data type such as a list or dictionary. The Linode guide to For and While Loops provides more information.\n\nMany programs use data structures to contain and organize a series of values. Simple data structures like strings and arrays are extremely commonplace. More complex data structures including stacks, queues, graphs, trees, and hash tables are used in specialized situations. The Linode guide to Data Structures in Computer Programming explains data structures in more depth.\n\nPython also features a large number of built-in data structures, including a list, set, and dictionary. Each data structure has its own built-in methods to implement core operations for the structure. Python modules provide access to more specialized data structures. Pre-existing data structures are ready-to-use. They help programmers save development and test time and avoid errors. See the Python data structure documentation for additional information about the built-in types.\n\nHow to Use Python Functions and Methods\n\nPython programs can be as simple as a single block of code within a single text file. However, when programs grow more complex, a more modular design is encouraged. Modular programs prevent code duplication and are easier to write, test, debug, maintain, and enhance.\n\nIn Python, functions and methods are used to enhance modularity. A function is a stand-alone block of code that is not part of the main program. The code inside a function only runs when it is called. Functions accept arguments from the calling code and often return a value. The same function can be called from many different places in the code.\n\nA Python function begins with the keyword. Each line of the function body must be indented. The return value is preceded by the keyword . A Python function looks like the following:\n\nThe calling code invokes a function by specifying the name of the function and passing the arguments in parentheses. A comma separates each argument. If there are no arguments to pass, the parentheses are left empty. To invoke and assign the result to , use the following command:\n\nA method is very similar to a function, but it is bound to a class definition. A regular function is not associated with a class. Class methods are usually invoked differently. The name of the class must be explicitly stated along with the name of the method, using the format . Functions that are imported as part of a module are invoked in the same way. The name of the module or package precedes the function name. Following is an example demonstrating how to import the module and use the module function .\n\nThere are several ways to execute a Python script. One approach is to use the Python interactive shell. This is useful for developing scripts or for debugging problems. The interactive shell makes it possible to enter commands one at a time and review the results. The contents of an interactive session are only temporary. The session results and history are lost at the end of the session. However, the output from the session is often still visible in the terminal window.\n\nUsers can also launch Python scripts from the command line interface. For this method, use the command to run the script from the terminal. This launches the Python interpreter, which then executes the script. The script potentially prompts the user for information and displays the results to standard output.\n\nHow to Use the Python Interactive Shell\n\nTo enter the Python interactive shell, use the command . The Python interactive prompt should appear.\n\nAt this point, enter the Python commands one at a time. For example, the following command prints .\n\nThe interactive shell does not limit developers to simple print statements. It allows users to define and manipulate variables, run loops and conditional statements, and call functions. The following sequence defines variable and sets it to . It then sets to and prints the resulting value. To display a value in the interactive print, enter the name of the variable. The value of could also be printed using the command .\n\nThe interactive shell allows users to enter multiline statements like conditionals and loops. First, enter the conditional or iterative statement, then add all the commands within the associated code block, which is also known as a suite. All lines in the suite must be indented. The indented lines within a suite are known as continuation lines. Python changes the interactive prompt to three dots to indicate the current command is a continuation line. After reaching the end of the block, use a backspace to terminate the block.\n\nFollowing is an example of how to use a loop in the Python interactive shell. The value of increments by ten times and increases from to .\n\nTo exit an interactive session, enter the command or . On most systems, the command also terminates the session.\n\nWhen using the Python interactive shell, users often enter lines one at a time. However, the interactive shell also allows the interactive execution of modules, functions, and methods using the and libraries.\n\nThe command loads the specified module, but it also runs the module after loading it. Most built-in and third-party modules only consist of variables and methods/functions and do not display any output. However, when a script is imported, the Python interpreter processes it like it normally would. This means it requests user input and displays and outputs the same way it does when the script runs from the command line.\n\nPython only runs the script the first time it is imported. For this technique to work, the script must be found either in the current working directory or somewhere within the Python Module Search Path (PMSP). The PMSP comprehensively lists all of the locations where Python scripts and modules might be found.\n\nThe example below imports the from the script that was used earlier in the guide. It immediately runs and prompts the user for a number.\n\nThe module provides a way to run a script multiple times. To use the module inside the interactive shell, follow the steps below:\n• None Use the method to import and run a script. The example below uses to import .\n• None To reload and run the script again, import the module and then use the method. Do not enclose the name of the script or module in quotes. This is because accepts the name of an object, not a string. The module object is created when the module is imported.\n\nHow to Run a Python Program from the Command Line\n\nUsers can run any Python program non-interactively using the Python interpreter. To run a Python script from the terminal, use the command and the filename of a Python script. The interpreter processes the file contents and executes the instructions. The basic format of this command is .\n\nFor instance, the following program runs the program . The program below displays the current release of the Python interpreter.\n\nIf a Python script includes a Shebang on the first line, it is not necessary to include the or keyword. The Shebang indicates the interpreter. Specify the full path of the file containing the Shebang to run the script. To use this method, the file must be executable. Use the command to make the file executable.\n\nWhen running a Python script using the command line interface, statements are redirected to the terminal window. However, sometimes users might want to save the output to a file. To redirect the standard output to a file, use the symbol. The following command redirects the output from to . To append the output to an existing file, use the symbol instead.\n\nMost modules are designed as libraries, not self-standing programs. However, it is possible to use the Python interpreter to run certain modules. To run a Python module like a program, use the option. However, this technique does not work on all modules.\n\nThe previous examples demonstrate how to run Python scripts from the command line. But there are some other ways to launch a Python program. Many of these methods require the Python file to use a Shebang and have the execute permission set.\n• Scripts can be launched from an integrated development environment (IDE). These environments are common in professional software development. They make it easier to track, develop, and maintain larger applications. An IDE can launch a Python script using a button, icon, or link.\n• Some text editors can run a script from inside the text editor window.\n• File managers allow users to run Python scripts like any other application. Double-click on the filename of the script to run it. The script must be executable.\n• A Python script can be executed as a cron job or invoked from a shell script or another application.\n\nPython is a powerful and flexible language that is easy to write and use. Python is an interpreted language, so Python scripts do not have to be compiled. Instead, a Python interpreter reads the script and translates it into bytecode at runtime. A Python interpreter must be installed on the system to run Python scripts.\n\nTo write a Python script, use an ordinary plain text file and add Python instructions. Scripts often make use of Python modules, which contain external functions, classes, and variables. The Python package manager can download and install modules, while the command is used to access the contents of a module.\n\nThere are several ways to run a Python script. The Python interactive shell can execute individual commands or run entire scripts. This is a good method for development and testing, but all contents are lost when the shell is closed. The command is used to run Python scripts from the command line. For more information about writing and running Python scripts, see the Official Python documentation.\n\nYou may wish to consult the following resources for additional information on this topic. While these are provided in the hope that they will be useful, please note that we cannot vouch for the accuracy or timeliness of externally hosted materials."
    },
    {
        "link": "https://docs.python.org/3/using/cmdline.html",
        "document": "The CPython interpreter scans the command line and the environment for various settings."
    },
    {
        "link": "https://docs.python.org/3.10/distutils/setupscript.html",
        "document": "The setup script is the centre of all activity in building, distributing, and installing modules using the Distutils. The main purpose of the setup script is to describe your module distribution to the Distutils, so that the various commands that operate on your modules do the right thing. As we saw in section A Simple Example above, the setup script consists mainly of a call to , and most information supplied to the Distutils by the module developer is supplied as keyword arguments to .\n\nHere’s a slightly more involved example, which we’ll follow for the next couple of sections: the Distutils’ own setup script. (Keep in mind that although the Distutils are included with Python 1.6 and later, they also have an independent existence so that Python 1.5.2 users can use them to install other module distributions. The Distutils’ own setup script, shown here, is used to install the package into Python 1.5.2.)\n\nThere are only two differences between this and the trivial one-file distribution presented in section A Simple Example: more metadata, and the specification of pure Python modules by package, rather than by module. This is important since the Distutils consist of a couple of dozen modules split into (so far) two packages; an explicit list of every module would be tedious to generate and difficult to maintain. For more information on the additional meta-data, see section Additional meta-data.\n\nNote that any pathnames (files or directories) supplied in the setup script should be written using the Unix convention, i.e. slash-separated. The Distutils will take care of converting this platform-neutral representation into whatever is appropriate on your current platform before actually using the pathname. This makes your setup script portable across operating systems, which of course is one of the major goals of the Distutils. In this spirit, all pathnames in this document are slash-separated.\n\nThis, of course, only applies to pathnames given to Distutils functions. If you, for example, use standard Python functions such as or to specify files, you should be careful to write portable code instead of hardcoding path separators:\n\nThe option tells the Distutils to process (build, distribute, install, etc.) all pure Python modules found in each package mentioned in the list. In order to do this, of course, there has to be a correspondence between package names and directories in the filesystem. The default correspondence is the most obvious one, i.e. package is found in the directory relative to the distribution root. Thus, when you say in your setup script, you are promising that the Distutils will find a file (which might be spelled differently on your system, but you get the idea) relative to the directory where your setup script lives. If you break this promise, the Distutils will issue a warning but still process the broken package anyway. If you use a different convention to lay out your source directory, that’s no problem: you just have to supply the option to tell the Distutils about your convention. For example, say you keep all Python source under , so that modules in the “root package” (i.e., not in any package at all) are in , modules in the package are in , and so forth. Then you would put in your setup script. The keys to this dictionary are package names, and an empty package name stands for the root package. The values are directory names relative to your distribution root. In this case, when you say , you are promising that the file exists. Another possible convention is to put the package right in , the package in , etc. This would be written in the setup script as A entry in the dictionary implicitly applies to all packages below package, so the case is automatically handled here. In this example, having tells the Distutils to look for and . (Keep in mind that although applies recursively, you must explicitly list all packages in : the Distutils will not recursively scan your source tree looking for any directory with an file.)\n\nJust as writing Python extension modules is a bit more complicated than writing pure Python modules, describing them to the Distutils is a bit more complicated. Unlike pure modules, it’s not enough just to list modules or packages and expect the Distutils to go out and find the right files; you have to specify the extension name, source file(s), and any compile/link requirements (include directories, libraries to link with, etc.). All of this is done through another keyword argument to , the option. is just a list of instances, each of which describes a single extension module. Suppose your distribution includes a single extension, called and implemented by . If no additional instructions to the compiler/linker are needed, describing this extension is quite simple: The class can be imported from along with . Thus, the setup script for a module distribution that contains only this one extension and nothing else might be: The class (actually, the underlying extension-building machinery implemented by the build_ext command) supports a great deal of flexibility in describing Python extensions, which is explained in the following sections. The first argument to the constructor is always the name of the extension, including any package names. For example, describes an extension that lives in the root package, while describes the same extension in the package. The source files and resulting object code are identical in both cases; the only difference is where in the filesystem (and therefore where in Python’s namespace hierarchy) the resulting extension lives. If you have a number of extensions all in the same package (or all under the same base package), use the keyword argument to . For example, will compile to the extension , and to . The second argument to the constructor is a list of source files. Since the Distutils currently only support C, C++, and Objective-C extensions, these are normally C/C++/Objective-C source files. (Be sure to use appropriate extensions to distinguish C++ source files: and seem to be recognized by both Unix and Windows compilers.) However, you can also include SWIG interface ( ) files in the list; the build_ext command knows how to deal with SWIG extensions: it will run SWIG on the interface file and compile the resulting C/C++ file into your extension. This warning notwithstanding, options to SWIG can be currently passed like this: Or on the commandline like this: On some platforms, you can include non-source files that are processed by the compiler and included in your extension. Currently, this just means Windows message text ( ) files and resource definition ( ) files for Visual C++. These will be compiled to binary resource ( ) files and linked into the executable. Three optional arguments to will help if you need to specify include directories to search or preprocessor macros to define/undefine: , , and . For example, if your extension requires header files in the directory under your distribution root, use the option: You can specify absolute directories there; if you know that your extension will only be built on Unix systems with X11R6 installed to , you can get away with You should avoid this sort of non-portable usage if you plan to distribute your code: it’s probably better to write C code like If you need to include header files from some other Python extension, you can take advantage of the fact that header files are installed in a consistent way by the Distutils install_headers command. For example, the Numerical Python header files are installed (on a standard Unix installation) to . (The exact location will differ according to your platform and Python installation.) Since the Python include directory— in this case—is always included in the search path when building Python extensions, the best approach is to write C code like If you must put the include directory right into your header search path, though, you can find that directory using the Distutils module: Even though this is quite portable—it will work on any Python installation, regardless of platform—it’s probably easier to just write your C code in the sensible way. You can define and undefine pre-processor macros with the and options. takes a list of tuples, where is the name of the macro to define (a string) and is its value: either a string or . (Defining a macro to is the equivalent of a bare in your C source: with most compilers, this sets to the string .) is just a list of macros to undefine. is the equivalent of having this at the top of every C source file: You can also specify the libraries to link against when building your extension, and the directories to search for those libraries. The option is a list of libraries to link against, is a list of directories to search for libraries at link-time, and is a list of directories to search for shared (dynamically loaded) libraries at run-time. For example, if you need to link against libraries known to be in the standard library search path on target systems If you need to link with libraries in a non-standard location, you’ll have to include the location in : There are still some other options which can be used to handle special cases. The option is a boolean; if it is true, a build failure in the extension will not abort the build process, but instead simply not install the failing extension. The option is a list of object files to be passed to the linker. These files must not have extensions, as the default extension for the compiler is used. and can be used to specify additional command line options for the respective compiler and linker command lines. is only useful on Windows. It can contain a list of symbols (functions or variables) to be exported. This option is not needed when building compiled extensions: Distutils will automatically add to the list of exported symbols. The option is a list of files that the extension depends on (for example header files). The build command will call the compiler on the sources to rebuild extension if any on this files has been modified since the previous build.\n\nA distribution may relate to packages in three specific ways:\n• None It can require packages or modules.\n• None It can provide packages or modules.\n• None It can obsolete packages or modules. These relationships can be specified using keyword arguments to the function. Dependencies on other Python modules and packages can be specified by supplying the requires keyword argument to . The value must be a list of strings. Each string specifies a package that is required, and optionally what versions are sufficient. To specify that any version of a module or package is required, the string should consist entirely of the module or package name. Examples include and . If specific versions are required, a sequence of qualifiers can be supplied in parentheses. Each qualifier may consist of a comparison operator and a version number. The accepted comparison operators are: These can be combined by using multiple qualifiers separated by commas (and optional whitespace). In this case, all of the qualifiers must be matched; a logical AND is used to combine the evaluations. Let’s look at a bunch of examples: Any version after and before is compatible, except Now that we can specify dependencies, we also need to be able to specify what we provide that other distributions can require. This is done using the provides keyword argument to . The value for this keyword is a list of strings, each of which names a Python module or package, and optionally identifies the version. If the version is not specified, it is assumed to match that of the distribution. Provide version 1.1, regardless of the distribution version A package can declare that it obsoletes other packages using the obsoletes keyword argument. The value for this is similar to that of the requires keyword: a list of strings giving module or package specifiers. Each specifier consists of a module or package name optionally followed by one or more version qualifiers. Version qualifiers are given in parentheses after the module or package name. The versions identified by the qualifiers are those that are obsoleted by the distribution being described. If no qualifiers are given, all versions of the named module or package are understood to be obsoleted.\n\nOften, additional files need to be installed into a package. These files are often data that’s closely related to the package’s implementation, or text files containing documentation that might be of interest to programmers using the package. These files are called package data. Package data can be added to packages using the keyword argument to the function. The value must be a mapping from package name to a list of relative path names that should be copied into the package. The paths are interpreted as relative to the directory containing the package (information from the mapping is used if appropriate); that is, the files are expected to be part of the package in the source directories. They may contain glob patterns as well. The path names may contain directory portions; any necessary directories will be created in the installation. For example, if a package should contain a subdirectory with several data files, the files can be arranged like this in the source tree: The corresponding call to might be: Changed in version 3.1: All the files that match will be added to the file if no template is provided. See Specifying the files to distribute.\n\nThe option can be used to specify additional files needed by the module distribution: configuration files, message catalogs, data files, anything which doesn’t fit in the previous categories. specifies a sequence of (directory, files) pairs in the following way: Each (directory, files) pair in the sequence specifies the installation directory and the files to install there. Each file name in files is interpreted relative to the script at the top of the package source distribution. Note that you can specify the directory where the data files will be installed, but you cannot rename the data files themselves. The directory should be a relative path. It is interpreted relative to the installation prefix (Python’s for system installations; for user installations). Distutils allows directory to be an absolute installation path, but this is discouraged since it is incompatible with the wheel packaging format. No directory information from files is used to determine the final location of the installed file; only the name of the file is used. You can specify the options as a simple sequence of files without specifying a target directory, but this is not recommended, and the install command will print a warning in this case. To install data files directly in the target directory, an empty string should be given as the directory. Changed in version 3.1: All the files that match will be added to the file if no template is provided. See Specifying the files to distribute.\n\nThe setup script may include additional meta-data beyond the name and version. This information includes: location where the package may be downloaded\n• None It is recommended that versions take the form major.minor[.patch[.sub]].\n• None Either the author or the maintainer must be identified. If maintainer is provided, distutils lists it as the author in .\n• None The field is used by PyPI when you publish a package, to build its project page.\n• None The field is a text indicating the license covering the package where the license is not a selection from the “License” Trove classifiers. See the field. Notice that there’s a distribution option which is deprecated but still acts as an alias for .\n• None This field must be a list.\n• None The valid classifiers are listed on PyPI.\n• None To preserve backward compatibility, this field also accepts a string. If you pass a comma-separated string , it will be converted to , Otherwise, it will be converted to a list of one string. A single line of text, not more than 200 characters. Multiple lines of plain text in reStructuredText format (see http://docutils.sourceforge.net/). Encoding the version information is an art in itself. Python packages generally adhere to the version format major.minor[.patch][sub]. The major number is 0 for initial, experimental releases of software. It is incremented for releases that represent major milestones in a package. The minor number is incremented when important new features are added to the package. The patch number increments when bug-fix releases are made. Additional trailing version information is sometimes used to indicate sub-releases. These are “a1,a2,…,aN” (for alpha releases, where functionality and API may change), “b1,b2,…,bN” (for beta releases, which only fix bugs) and “pr1,pr2,…,prN” (for final pre-release release testing). Some examples: the first, experimental release of a package the second alpha release of the first patch version of 1.0 must be specified in a list: Changed in version 3.7: now warns when , or fields are not specified as a list or a string.\n\nSometimes things go wrong, and the setup script doesn’t do what the developer wants. Distutils catches any exceptions when running the setup script, and print a simple error message before the script is terminated. The motivation for this behaviour is to not confuse administrators who don’t know much about Python and are trying to install a package. If they get a big long traceback from deep inside the guts of Distutils, they may think the package or the Python installation is broken because they don’t read all the way down to the bottom and see that it’s a permission problem. On the other hand, this doesn’t help the developer to find the cause of the failure. For this purpose, the environment variable can be set to anything except an empty string, and distutils will now print detailed information about what it is doing, dump the full traceback when an exception occurs, and print the whole command line when an external program (like a C compiler) fails."
    }
]