[
    {
        "link": "https://tesseract-ocr.github.io/tessdoc/Examples_C++.html",
        "document": ""
    },
    {
        "link": "https://github.com/tesseract-ocr/tesseract",
        "document": "This package contains an OCR engine - and a command line program - .\n\nTesseract 4 adds a new neural net (LSTM) based OCR engine which is focused on line recognition, but also still supports the legacy Tesseract OCR engine of Tesseract 3 which works by recognizing character patterns. Compatibility with Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0). It also needs traineddata files which support the legacy engine, for example those from the tessdata repository.\n\nStefan Weil is the current lead developer. Ray Smith was the lead developer until 2018. The maintainer is Zdenko Podobny. For a list of contributors see AUTHORS and GitHub's log of contributors.\n\nTesseract has unicode (UTF-8) support, and can recognize more than 100 languages \"out of the box\".\n\nYou should note that in many cases, in order to get better OCR results, you'll need to improve the quality of the image you are giving Tesseract.\n\nThis project does not include a GUI application. If you need one, please see the 3rdParty documentation.\n\nTesseract can be trained to recognize other languages. See Tesseract Training for more information.\n\nTesseract was originally developed at Hewlett-Packard Laboratories Bristol UK and at Hewlett-Packard Co, Greeley Colorado USA between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some C++izing in 1998. In 2005 Tesseract was open sourced by HP. From 2006 until November 2018 it was developed by Google.\n\nMajor version 5 is the current stable version and started with release 5.0.0 on November 30, 2021. Newer minor versions and bugfix versions are available from GitHub.\n\nLatest source code is available from main branch on GitHub. Open issues can be found in issue tracker, and planning documentation.\n\nSee Release Notes and Change Log for more details of the releases.\n\nYou can either Install Tesseract via pre-built binary package or build it from source.\n\nBefore building Tesseract from source, please check that your system has a compiler which is one of the supported compilers.\n\nFor more information about the various command line options use or .\n\nExamples can be found in the documentation.\n\nDevelopers can use C or C++ API to build their own application. If you need bindings to for other programming languages, please see the wrapper section in the AddOns documentation.\n\nDocumentation of Tesseract generated from source code by doxygen can be found on tesseract-ocr.github.io.\n\nBefore you submit an issue, please review the guidelines for this repository.\n\nFor support, first read the documentation, particularly the FAQ to see if your problem is addressed there. If not, search the Tesseract user forum, the Tesseract developer forum and past issues, and if you still can't find what you need, ask for support in the mailing-lists.\n\nPlease report an issue only for a bug, not for asking questions.\n\nNOTE: This software depends on other packages that may be licensed under different open source licenses.\n\nTesseract uses Leptonica library which essentially uses a BSD 2-clause license.\n\nTesseract uses Leptonica library for opening input images (e.g. not documents like pdf). It is suggested to use leptonica with built-in support for zlib, png and tiff (for multipage tiff).\n\nFor the latest online version of the README.md see:"
    },
    {
        "link": "https://tesseract-ocr.github.io/tessdoc",
        "document": "This user manual is for Tesseract versions . For versions , and older, see the documentation for old versions.\n\nTesseract is an open source text recognition (OCR) Engine, available under the Apache 2.0 license.\n• Major version 5 is the current stable version and started with release 5.0.0 on November 30, 2021.\n• Newer minor versions and bugfix versions are available from GitHub.\n• Latest source code is available from main branch on GitHub. Open issues can be found in issue tracker, and planning documentation.\n\nTesseract can be used directly via command line, or (for programmers) by using an API to extract printed text from images. It supports a wide variety of languages. Tesseract doesn’t have a built-in GUI, but there are several available from the 3rdParty page. External tools, wrappers and training projects for Tesseract are listed under AddOns.\n\nTesseract can be used in your own project, under the terms of the Apache License 2.0. It has a fully featured API, and can be compiled for a variety of targets including Android and the iPhone. See the 3rdParty and AddOns pages for samples of what has been done with it.\n\nIf you have a question, first read the documentation, particularly the FAQ to see if your problem is addressed there. If not, search the Issues List, Tesseract user forum, and if you still can’t find what you need, please ask your question in Tesseract user forum Google group.\n\nTesseract is free software, so if you want to pitch in and help, please do! If you find a bug and fix it yourself, the best thing to do is to attach the patch to your bug report in the Issues List.\n\nTesseract 4.0 added a new OCR engine based on LSTM neural networks. It works well on x86/Linux with official Language Model data available for 100+ languages and 35+ scripts. See 4.0x-Changelog for more details.\n\nTesseract 5.x.x source code is available in the branch of the repository. The branch is using semver versioning because C++ code modernization caused API incompatibility with 4.x release.\n\nBinaries are available from:\n\nFor detailed information about the different types of models, see Data Files.\n\nModel files for version are available from tessdata tagged 4.00. It has models from November 2016. The individual language file links are available from the following link.\n\nModel files for version and later are available from tessdata tagged 4.0.0. It has legacy models from September 2017 that have been updated with Integer versions of LSTM models. This set of traineddata files has support for both the legacy recognizer with and for LSTM models with . These models are available from the following Github repo.\n\nTwo more sets of traineddata, trained at Google, are made available in the following Github repos. These do not have the legacy models and only have LSTM models usable with .\n\nLanguage model traineddata files same as listed above for version can be used with Tesseract . These are available from:\n• DAS 2016 tutorial slides Slides #2, #6, #7 have information about LSTM integration in Tesseract 4.0x.\n\nTraining with (a.k.a Tesseract 4 training) is unsupported/abandoned. Please use scripts from tesseract-ocr/tesstrain for training.\n• Train Tesseract LSTM with make from Single Line Images and Groundtruth Transcription\n• Training LSTM Tesseract 5 - based on detailed Tesseract 4 tutorial and guide by Ray Smith"
    },
    {
        "link": "https://stackoverflow.com/questions/20703570/character-recognition-using-tesseract",
        "document": "I am trying to interact with API also I am new to image processing and I am just struggling with it for last few days. I have tried simple algorithms and I have achieved around 70% accuracy.\n\nI want its accuracy to be 90+%. The problem with the images is that they are in 72dpi. I also tried to increase the resolution but did not get good results the images which I am trying to be recognized are attached.\n\nAny help would be appreciated and I am sorry if I asked something very basic.\n\nI forgot to mention that I am trying to do all the processing and recognition within 2-2.5 secs on platform and method to detect the text mentioned in this answer is taking a lot of time. Also I prefer not to use command line solution but I would prefer or .\n\nMost of the images are uploaded here\n\nI have tried following things to binarize the tickets but no luck\n\nI tried to feed the image direct to tesseract API and it is giving me 70% good results in 1 sec average. But I want to increase the accuracy in noticing the time factor So far I have tried\n\nThen I tried to feed those binarized images to tesseract, the accuracy reduced to less than 50-60%, though binarized image look perfect."
    },
    {
        "link": "https://github.com/tesseract-ocr/tessdoc/blob/main/APIExample.md",
        "document": "This documentation provides simple examples on how to use the tesseract-ocr API (v3.02.02-4.0.0) in C++. It is expected that tesseract-ocr is correctly installed including all dependencies. It is expected the user is familiar with C++, compiling and linking program on their platform, though basic compilation examples are included for beginners with Linux.\n\nMore details about tesseract-ocr API can be found at baseapi.h.\n\nThe program must be linked to the tesseract-ocr and leptonica libraries.\n\nIf you want to restrict recognition to a sub-rectangle of the image - call SetRectangle(left, top, width, height) after SetImage. Each SetRectangle clears the recognition results so multiple rectangles can be recognized with the same image. E.g.\n\nIt is possible to get confidence value and BoundingBox per word from a ResultIterator:\n\nIt is also possible to use other iterator levels (block, line, word, etc.), see PageiteratorLevel.\n\nExplanation for result codes are in publictypes.h\n\n# # () { tesseract::TessBaseAPI *api = (); Initialize tesseract-ocr with English, without specifying tessdata path (api-> ( , )) { (stderr, ); ( ); } Pix *image = ( ); api-> (image); Set lstm_choice_mode to alternative symbol choices per character, bbox is at word level. api-> ( , ); api-> ( ); tesseract::PageIteratorLevel level = tesseract::RIL_WORD; tesseract::ResultIterator* res_it = api-> (); Get confidence level for alternative symbol choices. Code is based on std::vector<std::vector<std::pair< *, >>>* choiceMap = ; (res_it != ) { { * word; conf; x1, , x2, y2, tcnt = , gcnt = , wcnt = ; res_it-> (level, &x1, & , &x2, &y2); choiceMap = res_it-> (); ( timestep : *choiceMap) { (timestep. () > ) { ( & j : timestep) { conf = (j. * ); word = j. ; ( , wcnt, word, conf, x1, , x2, y2); gcnt++; } tcnt++; } wcnt++; ( ); } } (res_it-> (level)); } api-> (); api; (&image); ; }\n\nThis is similar to running tesseract from commandline with .\n\nNotice the different confidence values for:\n\nIncluding and linking to Tesseract's API is done in a standard Linux way. To compile a basic program against the API, you can use a command like this:\n\nIf Tesseract is installed in an unusual place, you can specify the include and lib directories explicitly with g++'s -I and -L flags, like this:\n\nTesseract-ocr from version 3.02.02 provide C-API. This enable to use tesseract-ocr shared library in python (and other languages that can use C libraries):\n\nExample of passing python file object to C-API can be found at pastebin.\n\nExample of extracting orientation from Tesseract 4.0:\n\nThe C-API can of course also be used by regular C programs, as in this very basic example.\n\nOn Linux you can compile it as you would build a program using the C++ API.\n\nMore complex examples (e.g. cancelling OCR process) can be found in source code of TesseractGui, gimagereader or android textfairy app."
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/standard/native-interop/best-practices",
        "document": ".NET gives you various ways to customize your native interoperability code. This article includes the guidance that Microsoft's .NET teams follow for native interoperability.\n\nThe guidance in this section applies to all interop scenarios.\n• ✔️ DO use , if possible, when targeting .NET 7+.\n• There are cases when using is appropriate. A code analyzer with ID SYSLIB1054 tells you when that's the case.\n• ✔️ DO use the same naming and capitalization for your methods and parameters as the native method you want to call.\n• ✔️ CONSIDER using the same naming and capitalization for constant values.\n• ✔️ DO use .NET types that map closest to the native type. For example, in C#, use when the native type is .\n• ✔️ DO prefer expressing higher level native types using .NET structs rather than classes.\n• ✔️ DO prefer using function pointers, as opposed to types, when passing callbacks to unmanaged functions in C#.\n• ✔️ DO use and attributes on array parameters.\n• ✔️ DO only use and attributes on other types when the behavior you want differs from the default behavior.\n• ✔️ CONSIDER using System.Buffers.ArrayPool<T> to pool your native array buffers.\n• ✔️ CONSIDER wrapping your P/Invoke declarations in a class with the same name and capitalization as your native library.\n• This allows your or attributes to use the C# language feature to pass in the name of the native library and ensure that you didn't misspell the name of the native library.\n• ✔️ DO use handles to manage lifetime of objects that encapsulate unmanaged resources. For more information, see Cleaning up unmanaged resources.\n• ❌ AVOID finalizers to manage lifetime of objects that encapsulate unmanaged resources. For more information, see Implement a Dispose method.\n\nA code analyzer, with ID SYSLIB1054, helps guide you with . In most cases, the use of requires an explicit declaration rather than relying on default settings. This design is intentional and helps avoid unintended behavior in interop scenarios.\n\nA is pinned and used directly by native code (rather than copied) when passed by value (not or ) and any one of the following:\n• The argument is explicitly marked as .\n\n❌ DON'T use parameters. String parameters passed by value with the attribute can destabilize the runtime if the string is an interned string. See more information about string interning in the documentation for String.Intern.\n\n✔️ CONSIDER or arrays from an when native code is expected to fill a character buffer. This requires passing the argument as .\n\n✔️ CONSIDER setting the property in so the runtime knows the expected string encoding.\n\n✔️ CONSIDER avoiding parameters. marshalling always creates a native buffer copy. As such, it can be extremely inefficient. Take the typical scenario of calling a Windows API that takes a string:\n• Invoke:\n• Copies the contents if (the default for a parameter).\n• Copies the native buffer into a newly allocated managed array if {3} (also the default for ).\n\nThat's {4} allocations to get a string out of native code. The best you can do to limit this is to reuse the in another call, but this still only saves one allocation. It's much better to use and cache a character buffer from . You can then get down to just the allocation for the on subsequent calls.\n\nThe other issue with is that it always copies the return buffer back up to the first null. If the passed back string isn't terminated or is a double-null-terminated string, your P/Invoke is incorrect at best.\n\nIf you do use , one last gotcha is that the capacity does not include a hidden null, which is always accounted for in interop. It's common for people to get this wrong as most APIs want the size of the buffer including the null. This can result in wasted/unnecessary allocations. Additionally, this gotcha prevents the runtime from optimizing marshalling to minimize copies.\n\nFor more information on string marshalling, see Default Marshalling for Strings and Customizing string marshalling.\n\nBooleans are easy to mess up. By default, a .NET is marshalled to a Windows , where it's a 4-byte value. However, the , and types in C and C++ are a single byte. This can lead to hard to track down bugs as half the return value will be discarded, which will only potentially change the result. For more for information on marshalling .NET values to C or C++ types, see the documentation on customizing boolean field marshalling.\n\nGUIDs are usable directly in signatures. Many Windows APIs take type aliases like . When the method signature contains a reference parameter, place either a keyword or a attribute on the GUID parameter declaration.\n\n❌ DON'T Use for anything other than GUID parameters.\n\nBlittable types are types that have the same bit-level representation in managed and native code. As such they do not need to be converted to another format to be marshalled to and from native code, and as this improves performance they should be preferred. Some types are not blittable but are known to contain blittable contents. These types have similar optimizations as blittable types when they are not contained in another type, but are not considered blittable when in fields of structs or for the purposes of .\n• structs with fixed layout that only have blittable value types for instance fields\n• non-nested, one-dimensional arrays of blittable primitive types (for example, )\n• classes with fixed layout that only have blittable value types for instance fields\n\nWhen blittable types are passed by reference with , , or , or when types with blittable contents are passed by value, they're simply pinned by the marshaller instead of being copied to an intermediate buffer.\n\nis blittable in a one-dimensional array or if it's part of a type that contains it's explicitly marked with with .\n\ncontains blittable contents if it isn't contained in another type and is being passed by value (not or ) as an argument and any one of the following:\n• The argument is explicitly marked as .\n\nYou can see if a type is blittable or contains blittable contents by attempting to create a pinned . If the type isn't a string or considered blittable, will throw an .\n\nWhen runtime marshalling is disabled, the rules for which types are blittable are significantly simpler. All types that are C# types and don't have any fields that are marked with are blittable. All types that are not C# types are not blittable. The concept of types with blittable contents, such as arrays or strings, does not apply when runtime marshalling is disabled. Any type that is not considered blittable by the aforementioned rule is unsupported when runtime marshalling is disabled.\n\nThese rules differ from the built-in system primarily in situations where and are used. When marshalling is disabled, is passed as a 1-byte value and not normalized and is always passed as a 2-byte value. When runtime marshalling is enabled, can map to a 1, 2, or 4-byte value and is always normalized, and maps to either a 1 or 2-byte value depending on the .\n\n✔️ DO make your structures blittable when possible.\n\nFor more information, see:\n\nwill ensure an object stays in scope until the KeepAlive method is hit.\n\nallows the marshaller to keep an object alive for the duration of a P/Invoke. It can be used instead of in method signatures. effectively replaces this class and should be used instead.\n\nallows pinning a managed object and getting the native pointer to it. The basic pattern is:\n\nPinning isn't the default for . The other major pattern is for passing a reference to a managed object through native code and back to managed code, usually with a callback. Here is the pattern:\n\nDon't forget that needs to be explicitly freed to avoid memory leaks.\n\nHere is a list of data types commonly used in Windows APIs and which C# types to use when calling into the Windows code.\n\nThe following types are the same size on 32-bit and 64-bit Windows, despite their names.\n\nThe following types, being pointers, do follow the width of the platform. Use / for these.\n\nA Windows , which is a C , can be marshalled as either or , but prefer when possible.\n\nThere are rare instances when built-in support for a type is removed.\n\nThe and built-in marshal support was removed in the .NET 5 release. You must recompile binaries that use this marshalling type and that target a previous framework. It's still possible to marshal this type, but you must marshal it manually, as the following code example shows. This code will work moving forward and is also compatible with previous frameworks.\n\nThere are types in the C/C++ language that have latitude in how they are defined. When writing cross-platform interop, cases can arise where platforms differ and can cause issues if not considered.\n\nC/C++ and C# are not necessarily the same size.\n\nThe type in C/C++ is defined to have \"at least 32\" bits. This means there is a minimum number of required bits, but platforms can choose to use more bits if desired. The following table illustrates the differences in provided bits for the C/C++ data type between platforms.\n\nIn contrast, C# is always 64 bit. For this reason, it's best to avoid using C# to interop with C/C++ .\n\nIn .NET 6 and later versions, use the and types for interop with C/C++ and data types. The following example is for , but you can use to abstract in a similar way.\n\nWhen targeting .NET 5 and earlier versions, you should declare separate Windows and non-Windows signatures to handle the problem.\n\nManaged structs are created on the stack and aren't removed until the method returns. By definition then, they are \"pinned\" (it won't get moved by the GC). You can also simply take the address in unsafe code blocks if native code won't use the pointer past the end of the current method.\n\nBlittable structs are much more performant as they can simply be used directly by the marshalling layer. Try to make structs blittable (for example, avoid ). For more information, see the Blittable Types section.\n\nIf the struct is blittable, use instead of for better performance. As mentioned above, you can validate that the type is blittable by attempting to create a pinned . If the type is not a string or considered blittable, will throw an .\n\nPointers to structs in definitions must either be passed by or use and .\n\n✔️ DO match the managed struct as closely as possible to the shape and names that are used in the official platform documentation or header.\n\n✔️ DO use the C# instead of for blittable structures to improve performance.\n\n❌ DON'T depend on internal representation of struct types exposed by .NET runtime libraries unless it is explicitly documented.\n\n❌ AVOID using classes to express complex native types through inheritance.\n\n❌ AVOID using or fields to represent function pointer fields in structures.\n\nSince System.Delegate and System.MulticastDelegate don't have a required signature, they don't guarantee that the delegate passed in will match the signature the native code expects. Additionally, in .NET Framework and .NET Core, marshalling a struct containing a or from its native representation to a managed object can destabilize the runtime if the value of the field in the native representation isn't a function pointer that wraps a managed delegate. In .NET 5 and later versions, marshalling a or field from a native representation to a managed object is not supported. Use a specific delegate type instead of or .\n\nAn array like has to be marshalled to two fields, and . When the native array is a primitive type, we can use the keyword to write it a little more cleanly. For example, looks like this in the native header:\n\nIn C#, we can write it like this:\n\nHowever, there are some gotchas with fixed buffers. Fixed buffers of non-blittable types won't be correctly marshalled, so the in-place array needs to be expanded out to multiple individual fields. Additionally, in .NET Framework and .NET Core before 3.0, if a struct containing a fixed buffer field is nested within a non-blittable struct, the fixed buffer field won't be correctly marshalled to native code."
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/standard/native-interop/pinvoke",
        "document": "P/Invoke is a technology that allows you to access structs, callbacks, and functions in unmanaged libraries from your managed code. Most of the P/Invoke API is contained in two namespaces: and . Using these two namespaces give you the tools to describe how you want to communicate with the native component.\n\nLet's start from the most common example, and that is calling unmanaged functions in your managed code. Let's show a message box from a command-line application:\n\nThe previous example is simple, but it does show off what's needed to invoke unmanaged functions from managed code. Let's step through the example:\n• Line #2 shows the directive for the namespace that holds all the items needed.\n• Line #8 introduces the LibraryImportAttribute attribute. This attribute tells the runtime that it should load the unmanaged binary. The string passed in is the unmanaged binary that contains the target function. Additionally, it specifies the encoding to use for marshalling the strings. Finally, it specifies that this function calls SetLastError and that the runtime should capture that error code so the user can retrieve it via Marshal.GetLastPInvokeError().\n• Line #9 is the crux of the P/Invoke work. It defines a managed method that has the exact same signature as the unmanaged one. The declaration uses the attribute and the keyword to tell a compiler extension to generate code to call into the unmanaged library.\n• Within the generated code and prior to .NET 7, the is used. This declaration uses the keyword to indicate to the runtime this is an external method, and that when you invoke it, the runtime should find it in the unmanaged binary specified in the attribute.\n\nThe rest of the example is invoking the method as you would any other managed method.\n\nThe sample is similar for macOS. The name of the library in the attribute needs to change since macOS has a different scheme of naming dynamic libraries. The following sample uses the function to get the process ID of the application and print it out to the console:\n\nIt is also similar on Linux. The function name is the same, since is a standard POSIX system call.\n\nThe runtime allows communication to flow in both directions, enabling you to call back into managed code from native functions by using function pointers. The closest thing to a function pointer in managed code is a delegate, so this is what is used to allow callbacks from native code into managed code.\n\nThe way to use this feature is similar to the managed to native process previously described. For a given callback, you define a delegate that matches the signature and pass that into the external method. The runtime will take care of everything else.\n\nBefore walking through the example, it's good to review the signatures of the unmanaged functions you need to work with. The function to be called to enumerate all of the windows has the following signature:\n\nThe first parameter is a callback. The said callback has the following signature:\n\nNow, let's walk through the example:\n• Line #9 in the example defines a delegate that matches the signature of the callback from unmanaged code. Notice how the LPARAM and HWND types are represented using in the managed code.\n• Lines #13 and #14 introduce the function from the user32.dll library.\n• Lines #17 - 20 implement the delegate. For this simple example, we just want to output the handle to the console.\n• Finally, in line #24, the external method is called and passed in the delegate.\n\nThe Linux and macOS examples are shown below. For them, we use the function that can be found in , the C library. This function is used to traverse directory hierarchies and it takes a pointer to a function as one of its parameters. The said function has the following signature: .\n\nmacOS example uses the same function, and the only difference is the argument to the attribute, as macOS keeps in a different place.\n\nBoth of the previous examples depend on parameters, and in both cases, the parameters are given as managed types. Runtime does the \"right thing\" and processes these into its equivalents on the other side. Learn about how types are marshalled to native code in our page on Type marshalling."
    },
    {
        "link": "https://stackoverflow.com/questions/671837/is-there-a-best-practice-for-accessing-c-native-com-functions-to-interop-from",
        "document": "Is there a best practice for accessing C++ native COM functions to interop from C#?\n\nFor example, if I have 100 C++ methods (basically a native library) that interacts with a core window component.\n\nI want to basically make a wrapper for these C++ methods in C#, so all my newly hired employees can use that instead of C++, etc. The C++ code is legacy and scares me, so I want to deal with it just once. Is the approach here for each method to have a corresponding C# method? In fact, is there another way of doing this?\n\nCan I have some sort of wrapper subsystem. How do you people generally do this?\n\nAlso, are there any performance considerations, etc.?"
    },
    {
        "link": "https://mono-project.com/docs/advanced/pinvoke",
        "document": "The Common Language Infrastructure (CLI) is designed to make it “easy” to interoperate with existing code. In principle, all you need to do is create a DllImport function declaration for the existing code to invoke, and the runtime will handle the rest. For example:\n\nPlease note that most of the classes and enumerations mentioned in this document reside in the System.Runtime.InteropServices namespace.\n\nThe above C# function declaration would invoke the POSIX getpid(2) system call on platforms that have the library. If exists but doesn’t have the getpid export, an EntryPointNotFoundException exception is thrown. If can’t be loaded, a DllNotFoundException exception is thrown. Simple. Straightforward. What could be easier?\n\nThere are three problems with this:\n• Specifying the library in the DllImport statement.\n• Determining what function to actually invoke.\n• Passing parameters; most existing code is far more complex. Strings will need to be passed, structures may need to be passed, memory management practices will become involved…\n\nExisting code is a complex beast, and the interop layer needs to support this complexity.\n\nHow does the runtime find the library specified in the DllImport attribute? This question is inherently platform specific.\n\nFrom the MSDN LoadLibrary documentation, the DLLs needed by the program are searched for in the following order:\n• The directory from which the application loaded.\n• The system directory. Use the GetSystemDirectory() function to get the path of this directory.\n• The Windows directory. Use the GetWindowsDirectory() function to get the path of this directory.\n• The directories that are listed in the environment variable.\n\nOf course, reality isn’t quite that simple. In practice, the “system” directory is actually , except on Windows 9x platforms where it’s . The 16-bit system directory is typically , but isn’t recognized as a separate search directory on Windows 9x platforms.\n\nFurthermore, on Windows Server 2003 and Windows XP SP1, the registry entry alters the above ordering. If this is (the default), then the current directory is searched after the system and Windows directories. This is a security feature (it prevents a trojan library from being loaded instead of, for example, ), but it turns the above list into: 1, 3, 4, 5, 2, 6.\n\nSee also: LoadLibrary() Documentation at MSDN\n\nFrom the dlopen(3) man page, the necessary shared libraries needed by the program are searched for in the following order:\n• A colon-separated list of directories in the user’s environment variable. This is a frequently-used way to allow native shared libraries to be found by a CLI program.\n• The list of libraries cached in . is created by editing and running ldconfig(8). Editing is the preferred way to search additional directories, as opposed to using , as this is more secure (it’s more difficult to get a trojan library into than it is to insert it into ).\n\nAs a Mono extension, if the library being loaded is , then the main program is searched for method symbols. This is equivalent to calling dlopen(3) with a filename of . This allows you to P/Invoke methods that are within an application that is embedding Mono.\n\nSee also: the dlopen(3) man page, the ld.so(8) man page, Dissecting shared libraries.\n\nThe Framework and library search path is:\n• A colon-separated list of directories in the user’s environment variable.\n• A colon-separated list of directories in the user’s environment variable.\n• A colon-separated list of directories in the user’s environment variable, which defaults to the directories:\n• A colon-separated list of directories in the user’s environment variable, which defaults to the directories:\n\nNote: Mono uses GLib to load libraries, and GLib has a bug on macOS where it doesn’t use a extension, but instead uses the Unix extension. While this should eventually be fixed, the current workaround is to write a file which maps to the file, e.g.\n\nTODO: Will mono support both frameworks and dylibs?\n\nSee also: The Framework as a Library Package at Apple, the dyld(1) man page\n\nKnowing where to look for the library is only half of the problem. Knowing what library to load is the other half.\n\nDifferent platforms have different naming conventions. Windows platforms append to the library name, such as . Linux platforms use a prefix and a suffix(see Note 1). macOS platforms have a prefix and a suffix, unless they’re a Framework, in which case they’re a directory and things get more complicated.\n\nNote 1: Strictly speaking, Unix shared libraries are typically versioned, and the version number follows the suffix. For example, is a fully versioned library. Versioning throws a “wrench” into the works, and is best dealt with through Mono’s <dllmap/> mechanism; see below for details.\n\nIf you have control over the library name, keep the above naming conventions in mind and don’t use a platform-specific library name in the DllImport statement. Instead, just use the library name itself, without any prefixes or suffixes, and rely on the runtime to find the appropriate library at runtime. For example:\n\nThen, you just need to provide for Windows platforms, for Unix platforms, and for macOS platforms.\n\nNote: Windows will not automatically append a extension to library names that already have a period (.) in their name, such as . If you try to use as the library name, Windows won’t automatically append , resulting in a DllNotFoundException. Consequently you should either avoid periods in library names or always use the full filename (including the extension) and rely on Mono’s <dllmap/> mechanism.\n\nWhat if you don’t have the same name across all platforms? For example, the GTK+ library name on Windows is , while the Unix equivalent library is . How do you write portable Platform Invoke (P/Invoke) code that will work cross-platform?\n\nThe short answer is that you don’t. There is no standard way of specifying platform-specific library names.\n\nHowever, as an extension, Mono provides a library mapping mechanism. Two places are searched for library mappings: in the XML file, and in a per-assembly file, located in the same directory as the assembly. The .config file must be named like the assembly with “.config” as extension, e.g. or . These files contains elements, which map an input library (the library specified in the DllImport statement) to the actual platform-specific library to load. For example:\n\nUnlike .NET, Mono permits assemblies to have files, which are only used for this library mapping mechanism.\n\nUsing this mechanism, the Mono-endorsed way of specifying DllImport library names is to always use the Windows library name (as Microsoft .NET has no library mapping mechanism), and then provide a mapping in the per-assembly file. This is what the Gtk# library does.\n\nThis mechanism can also be used to load strongly-versioned libraries on Unix platforms. For example:\n\nAs far as managed code is concerned, unmanaged code is invoked merely by invoking a method with an associated DllImport attribute. The CLI runtime must do more work to actually invoke the unmanaged code.\n\nIn principle, this is a straightforward process. The library specified in the DllImport attribute is loaded, as described above. Then, the specified function is looked up (via GetProcAddress() or dlsym(3)). Finally, the function is invoked.\n\nBut what string is used for the function lookup (in or dlopen(3))? By default, the name of the managed code method is used, which is why getpid() in the above example invokes getpid(2) from the C library.\n\nAlternatively, the DllImport attribute’s EntryPoint field can be set, and that string will be used instead.\n\nEither way, the string used is assumed to refer to a C ABI-compatible function exported by the specified library. On some platforms, this may cause a leading underscore to be prefixed to the symbol name. Other platforms generate no mangling.\n\nNote that a C ABI is assumed. This makes it nearly impossible to directly invoke functions that are not C ABI compatible, such as C++ library functions that are not . Some variation on the C ABI is permitted, such as variation in the function’s CallingConvention. The default CallingConvention is platform-specific. Under Windows, Winapi is the default, as this is used for most Win32 API functions. (Winapi is equivalent to Stdcall for Windows 9x and Windows NT.) Under Unix platforms, Cdecl is the default.\n\nCalling convention can be specified in C code by using the and compiler intrinsics under Microsoft Visual C++, and by using the and compiler intrinsics under GCC.\n\nDoes having the default CallingConvention vary between platforms cause portability problems? Yes. All the more reason to write as much code as possible as managed code, avoiding the whole P/Invoke/marshaling conundrum in the first place.\n\nIf you need to invoke C++ code, you have two choices:\n• make the C++ function , treat it as a C function, and make sure that it uses a known calling convention\n• don’t make the function , but make sure it uses a known calling convention\n\nIf you use option (2), you’ll need to set the DllImport.EntryPoint field to the C++ mangled function name, such as .\n\nYou can retrieve the mangled name through your compiler’s binary tools, such as or nm(1). Note that C++ mangled names are highly compiler specific, and will:\n• make your .NET assembly platform specific (you’ll need a different assembly for each different platform);\n• require updating the .NET assembly every time you change C++ compilers (as the C++ name mangling scheme varies by compiler and can – and frequently will – change); and\n• be really ugly to maintain because of the above. This option is not recommended.\n\nIf you have lots of C++ code that needs to be wrapped, you might want to look into SWIG, a code generation program that easily wraps existing C and C++ code for use by a multitude of languages, including CLI languages. This makes it easier to invoke C++ code from a CLI application.\n\nIn case you call a function that is not present in the native library (or that is not public) you will get an EntryNotFoundException. In order to find out which symbols are available for a library, it’s interesting to use the following command (the example used is a shared library from Subversion):\n\nThe above section mentioned a key point: P/Invoke assumes that the unmanaged code conforms to the C ABI. C doesn’t support exceptions. As such, it is assumed that runtime exceptions will not propagate through unmanaged code.\n\nFurthermore, it’s fairly simple for an exception to propagate through unmanaged code whenever unmanaged code invokes managed code. This typically occurs through the use of callbacks – using a function pointer on the unmanaged side which can invoke a delegate on the managed side. It is very important that the managed code not propagate any exceptions – it must catch all exceptions, or else the unmanaged code calling the delegate will break.\n\nThe problem is, again, C doesn’t support exceptions. C++ supports exceptions, BUT, and this is crucial, the C++ exception mechanism will be different from the managed code exception mechanism (with one exception to this rule). Since managed code doesn’t know about unmanaged code’s exception handling support (C is assumed, and C doesn’t support exceptions), unmanaged exception handling support might as well not exist, because it won’t be used.\n\nThe one exception to this is when you use both Microsoft .NET and Microsoft Visual C++ to compile the unmanaged code. .NET uses Windows Structured Exception Handling (SEH) at the P/Invoke layer for its exception handling mechanism, and Microsoft Visual C++ uses SEH to implement C++ exception handling and supports the use of SEH in C as a language extension through the , , and keywords. SEH is a Microsoft extension; it does not exist outside of Microsoft and .NET, and as such is not portable.\n\nGiven the above scenario – unmanaged code invokes function pointer which generates a managed exception – what would happen? The managed exception handling mechanism is executed: the stack is searched for an appropriate exception handler, then the stack is unwound, with any blocks executed during the stack unwind process.\n\nNote two things: Managed code will be walking the stack, requiring that the CPU Stack Pointer and Instruction Pointers be set. Consequently, unmanaged code cannot participate in stack unwinding, as it will never be notified that a stack unwind is occurring.\n\nThink about that for a minute. If alarms are not sounding in your head, you’re in deep, deep trouble. Consider this unmanaged C code:\n\nIf handler is a pointer to a managed delegate which may throw an exception, then free(3) will not be executed, resulting in a memory leak. C++ destructors won’t help you either, as destructors still require the execution of some code, and that code will never be invoked, as it’s not C++ which is unwinding the stack, but managed code, which doesn’t know about C++ exception handling.\n\nObviously, the flip-side of this scenario – a C++ exception being propagated into managed code – is equally bad. As long as managed and unmanaged code use different exception handling mechanisms, exceptions must not be mixed between them.\n\nThe moral of this story: don’t let exceptions propagate between managed and unmanaged code. The results won’t be pretty.\n\nThis is particularly pertinent when wrapping C++ methods. C++ exceptions will need to be mapped into an “out” parameter or a return value, so that managed code can know what error occurred, and (optionally) throw a managed exception to “propagate” the original C++ exception.\n• SWIG, a code generation program that easily wraps existing C and C++ code for use by a multitude of languages, including CLI languages. This makes it easier to invoke C++ code from a CLI application.\n• The .NET Exception Model: Another one of Chris Brumme’s excellent blog entries. More information than you ever wanted to know about .NET exception handling.\n\nHow does Platform Invoke work? Given a managed call site (the function call), and an unmanaged callee site (the function that’s being called), each parameter in the call site is “marshaled” (converted) into an unmanaged equivalent. The marshaled data is in turn placed on the runtime stack (along with other data), and the unmanaged function is invoked.\n\nThe complexity is due to the marshaling. For simple types, such as integers and floating-point numbers, marshaling is a bitwise-copy (“blitting”), just as would be the case for unmanaged code. In some cases, marshaling can be avoided, such as when passing structures by reference to unmanaged code (a pointer to the structure is copied instead). It’s also possible to obtain more control over marshaling, through custom marshaling and manual marshaling.\n\nString types introduce additional complexity, as you need to specify the form of string conversion. The runtime stores strings as UTF-16-encoded strings, and these will likely need to be marshaled to a more appropriate form (ANSI strings, UTF-8 encoded strings, etc.). Strings get some special support.\n\nDefault marshaling behavior is controlled through the DllImport and MarshalAs attributes.\n\nManaged and unmanaged memory should be considered to be completely separate. Managed memory is typically memory allocated on a garbage-collected heap, while unmanaged memory is anything else: the ANSI C memory pool allocated through malloc(3), custom memory pools, and garbage-allocated heaps outside the control of the CLI implementation (such as a LISP or Scheme memory heap).\n\nIt is possible to lock a section of the managed heap by using the C# statement. This is used so that a section of the managed heap can be passed to unmanaged code without worrying that a future GC will move the memory that the unmanaged code is operating on. However, this is completely under the control of the programmer, and is not how Platform Invoke works.\n\nDuring a P/Invoke call the runtime doesn’t mimic the C# statement. Instead, classes and structures (everything of consequence) are marshaled to native code through the following pseudo-process:\n• The managed class data is copied into the unmanaged memory.\n• The unmanaged function is invoked, passing it the unmanaged memory information instead of the managed memory information. This must be done so that if a GC occurs, the unmanaged function doesn’t need to worry about it. (And yes, you need to worry about GCs, as the unmanaged function could call back into the runtime, ultimately leading to a GC. Multi-threaded code can also cause a GC while unmanaged code is executing.)\n• The unmanaged memory is copied back into managed memory.\n\nSee Class and Structure Marshaling for more detailed information about marshaling classes and structures.\n\nThere is one key point to keep in mind: the memory management specified in the above process is implicit, and there is no way to control how the runtime allocates the marshaled memory, or how long it lasts. This is crucial. If the runtime marshals a string (e.g. UTF-16 to Ansi conversion), the marshaled string will only last as long as the call. The unmanaged code CANNOT keep a reference to this memory, as it WILL be freed after the call ends. Failure to heed this restriction can result in “strange behavior”, including memory access violations and process death. This is true for any marshaling process where the runtime allocates memory for the marshal process.\n\nThe one pseudo-exception to this point is with delegates. The unmanaged function pointer that represents the managed delegate lasts as long as the managed delegate does. When the delegate is collected by the GC, the unmanaged function pointer will also be collected. This is also important: if the delegate is collected and unmanaged memory invokes the function pointer, you’re treading on thin ground. Anything could happen, including a process seg-fault. Consequently, you MUST ensure that the lifetime of the unmanaged function pointer is a proper subset of the lifetime of the managed delegate instance.\n\nMany types require minimal copying into native memory. Blittable types are types that conceptually only require a memcpy(3) or can be passed on the run-time stack without translation. These types include:\n\nStrings are special. String marshaling behavior is also highly platform dependent.\n\nString marshaling for a function call can be specified in the function declaration with the DllImport attribute, by setting the CharSet field. The default value for this field is CharSet.Ansi. The CharSet.Auto value implies “magic.”\n\nSome background. The Microsoft Win32 API supports two forms of strings: “ANSI” strings, the native character set, such as ASCII, ISO-8859-1, or a Double Byte Character Set such as Shift-JIS; and Unicode strings, originally UCS-2, and now UTF-16. Windows supports these string formats by appending an “A” for Ansi string APIs and a “W” (“wide”) for Unicode string APIs.\n\nWhen TextOut is called, the “magic” properties of String marshaling become apparent. Due to string marshaling, the runtime doesn’t just look for an unmanaged function with the same name as the specified method, as specified in Invoking Unmanaged Code. Other permutations of the function may be searched for, depending on the CLI runtime and the host platform.\n\nThere are three functions that may be searched for:\n\nFor platforms whose default character set is UCS2 or UTF-16 Unicode (all flavors of Windows NT, and Windows XP), the default search path is TextOutW, TextOutA, and TextOut. Unicode marshaling is preferred, as (ideally) the System.String can be passed as-is to the function, as long as the function doesn’t modify the string parameter. Windows CE does not look for TextOutA, as it has no Ansi APIs.\n\nFor platforms whose default character set is Ansi (Windows 9x, Windows ME), the default search path is TextOutA and TextOut (TextOutW is not looked for). Ansi marshaling will require translating the Unicode string into an 8-bit or DBCS string in the user’s locale. Most (all?) of the time, this WILL NOT be UTF-8, so you CAN NOT assume that CharSet.Ansi will generate UTF-8-encoded strings.\n\nMono on all platforms currently uses UTF-8 encoding for all string marshaling operations.\n\nIf you don’t want the runtime to search for the alternate unmanaged functions, specify a CharSet value other than CharSet.Auto. This will cause the runtime to look only for the specified function. Note that if you pass a wrongly encoded string (e.g. calling MessageBoxW when the CharSet is CharSet.Ansi, the default), you are crossing into “undefined” territory. The unmanaged function will receive data encoded in ways it wasn’t expecting, so you may get such bizarre things as Asian text when displaying “Hello, World”.\n\nPerhaps in the future the CharSet enumeration will contain more choices, such as UnicodeLE (little-endian), UnicodeBE (big-endian), Utf7, Utf8, and other common choices. Additionally, making such a change would also likely require changing the UnmanagedType enumeration. However, these would need to go through ECMA, so it won’t happen next week. (Unless some time has passed since this was originally written, in which case it may very well be next week. But don’t count on it.)\n\nUsing the DllImport attribute works if you want to control all the strings in a function, but what if you need more control? You would need more control if a string is a member of a structure, or if the function uses multiple different types of strings as parameters.\n\nIn these circumstances, the MarshalAs attribute can be used, setting the Value property (which is set in the constructor) to a value from the UnmanagedType enumeration. For example:\n\nAs you can guess by reading the example, UnmanagedType.LPStr will marshal the input string into an Ansi string, UnmanagedType.LPWStr will marshal the input string into a Unicode string (effectively doing nothing), and UnmanagedType.LPTStr will convert the string to the platform’s default string encoding.\n\nThe default platform encoding for all flavors of Windows NT (including Windows NT 3.51 and 4.0, Windows 2000, Windows XP, Windows Server 2003) is Unicode, while for all Windows 9x flavors (Windows 95, 98, ME) the platform default encoding is Ansi.\n\nMono uses UTF-8 encoding as the default encoding on all platforms.\n\nThere are other UnmangedType string marshaling options, but they’re primarily of interest in COM Interop (BStr, AnsiBStr, TBStr).\n\nIf UnmanagedType doesn’t provide enough flexibility for your string marshaling needs (for example, you’re wrapping GTK+ and you need to marshal strings in UTF-8 format), look at the Custom Marshaling or Manual Marshaling sections.\n\nA common C language idiom is for the caller to provide the callee a buffer to fill. For example, consider strncpy(3):\n\nWe can’t use System.String for both parameters, as strings are immutable. This is OK for src, but dest will be modified, and the caller should be able to see the modification.\n\nThe solution is to use a System.Text.StringBuilder , which gets special marshaling support from the runtime. This would allow strncpy(3) to be wrapped and used as:\n\nSome things to note is that the return value of strncpy(3) was changed to void, as there is no way to specify that the return value will be the same pointer address as the input dest string buffer, and thus it doesn’t need to be marshaled. If string were used instead, Bad Things could happen (the returned string would be freed; see Strings as Return Values ). The StringBuilder is allocated with the correct amount of storage as a constructor parameter, and this amount of storage is passed to strncpy(3) to prevent buffer overflow. If you use a StringBuilder instance multiple times, always call EnsureCapacity() before passing it into the native method, as the capacity may shrink as a memory optimization over time, leading to unexpectedly truncated results.\n\nTODO: How does StringBuilder interact with the specified CharSet?\n\nThe String type is a class, so see the section on returning classes from functions. Summary: the runtime will attempt to free the returned pointer. The usual symptom is a runtime crash like this:\n\nIf you don’t want the runtime to free the returned string, either (a) don’t specify the return value (as was done for the strncpy(3) function above), or (b) return an IntPtr and use one of the Marshal.PtrToString* functions, depending on the type of string returned. For example, use Marshal.PtrToStringAnsi to marshal from a Ansi string, and use Marshal.PtrToStringUni to marshal from a Unicode string.\n\nThe conceptual steps that occur to marshal classes and structures is detailed above, in the Memory Boundaries section.\n\nThe main difference between class and structure marshaling is which ones, if any, of the conceptual steps actually occur.\n\nRemember that classes are heap-allocated and garbage-collected in the CLI. As such, you cannot pass classes by value to unmanaged functions, only by reference:\n\nThis means that you cannot use classes to invoke unmanaged functions that expect pass-by-value variables (such as the WRONG function, above).\n\nThere are two other issues with classes. First of all, classes by default use LayoutKind.Auto layout. This means that the ordering of class data members is unknown, and won’t be determined until runtime. The runtime can rearrange the order of members in any way it chooses, to optimize for access time or data layout space. As such, you MUST use the StructLayout attribute and specify a LayoutKind value of LayoutKind.Sequential or LayoutKind.Explicit.\n\nSecondly, classes (again, by default) only have in-bound marshaling. That is, Step 4 (copying the unmanaged memory representation back into managed memory) is ommitted. If you need the unmanaged memory to be copied back into managed memory, you must addorn the DllImport function declaration argument with an Out attribute. You will also need to use the In attribute if you want copy-in and copy-out behavior. To summarize:\n• Using is equivalent to not specifying any parameter attributes, and will skip Step 4 (copying unmanaged memory into managed memory).\n• Using will skip Step 2 (copying managed memory into unmanaged memory).\n• Use to both copy managed memory to unmanaged memory before the unmanaged function call, and then copy unmanaged memory back to managed memory after the function call.\n\nIn some circumstances, the marshaled copy can be omitted. The object will simply be pinned in memory and a pointer to the start of the data passed to the unmanaged function.\n\nTODO: When can this actually occur? If this happened for any class with Sequential layout, you wouldn’t need to specify the Out attribute, as the unmanaged code would see the actual object. Is there a specific set of circumstances for when this can occur? This appears to happen with StringBuilder (my tests don’t require an to see changes made to the StringBuilder by unmanaged code), but this is the only example I can think of.\n\nThere are two primary differences between classes and structures. First, structures do not need to be allocated on the heap; they can be allocated on the runtime stack. Secondly, they are LayoutKind.Sequential by default, so structure declarations do not need any additional attributes to use them with unmanaged code (assuming that the default sequential layout rules are correct for the unmanaged structure).\n\nThese differences permit structures to be passed by-value to unmanaged functions, unlike classes. Additionally, if (a) the structure is located on the stack, and (b) the structure contains only blittable types, then if you pass a structure to an unmanaged function by-reference, the structure will be passed directly to the unmanaged function, without an intermediate unmanaged memory copy. This means that you may not need to specify the Out attribute to see changes made by unmanaged code.\n\nNote that as soon as the structure contains a non-blittable type (such as System.Boolean, System.String, or an array), this optimization is no longer possible and a copy of the structure must be made as part of the marshaling process.\n\nThe differences in allocation behavior between classes and structures also affect how they’re handled as return values from functions.\n\nClasses can be used as the return value of a function when the unmanaged function returns a pointer to an unmanaged structure. Classes cannot be used for by-value return types.\n\nStructures can be used when the unmanaged function returns the structure by-value. It is not possible to return structures with “ref” or “out”, so if an unmanaged function returns a pointer to a structure, IntPtr must be used for “safe” code, or a pointer to the structure can be used for “unsafe” code. If IntPtr is used as the return type, Marshal.PtrToStructure can be used to convert the unmanaged pointer into a managed structure.\n\nIt’s easy to skim over memory management for most of Platform Invoke and marshaling, but for return values the CLI implements some default handling which must be considered.\n\nThe CLI runtime assumes that, under certain circumstances, the CLI runtime is responsible for freeing memory allocated by unmanaged code. Return values are one of those circumstances, causing the return value to be a memory boundary for control of memory (de)allocation.\n\nThe CLI assumes that all memory that is passed between the CLI/unmanaged code boundary is allocated via a common memory allocator. The developer does not get a choice in which memory allocator is used. For managed code, the Marshal.AllocCoTaskMem method can be used to allocate memory, Marshal.FreeCoTaskMem is used to free the memory allocated by Marshal.AllocCoTaskMem, and Marshal.ReAllocCoTaskMem is used to resize a memory region originally allocated by Marshal.AllocCoTaskMem.\n\nSince classes are passed by reference, a pointer is returned, and the runtime assumes that it must free this memory to avoid a memory leak. The chain of events is thus:\n• Managed code invokes unmanaged function that returns a pointer to an unmanaged structure in unmanaged memory.\n• An instance of the appropriate managed class is instantiated, and the contents of the unmanaged memory is marshaled into the managed class.\n• The unmanaged memory is freed by the runtime “as if” by invoking Marshal.FreeCoTaskMem().\n\nHow is Marshal.AllocCoTaskMem, Marshal.ReAllocCoTaskMem, and Marshal.FreeCoTaskMem implemented? That’s platform-dependent. (So much for portable platform-dependent code.) Under Windows, the COM Task Memory allocator is used (via CoTaskMemAlloc(), CoTaskMemReAlloc(), and CoTaskMemFree()). Under Unix, the GLib memory functions g_malloc(), g_realloc(), and g_free() functions are used. Typically, these correspond to the ANSI C functions malloc(3), realloc(3), and free(3), but this is not necessarily the case as GLib can use different memory allocators; see g_mem_set_vtable() and g_mem_is_system_malloc() .\n\nWhat do you do if you don’t want the runtime to free the memory? Don’t return a class. Instead, return an IntPtr (the moral equivalent of a C pointer), and then use the Marshal class methods to manipulate that pointer, such as Marshal.PtrToStructure, which works for both C# struct types and class types marked .\n\nSo which should be used when wrapping unmanaged code, classes or structures?\n\nGenerally, the answer to this question depends upon what the unmanaged code requires. If you require pass-by-value semantics, you must use structures. If you want to return a pointer to an unmanaged type without resorting to “unsafe” or manual code, you must use classes (assuming that the default memory allocation rules are appropriate).\n\nFor the large intersection of unmanaged code that doesn’t have pass-by-value structures or return pointers to structures from functions? Use whichever is more convenient for the end user. Not all languages support passing types by reference (Java, for example), so using classes will permit a larger body of languages to use the wrapper library. Furthermore, Microsoft suggests that structure sizes not exceed 16 bytes.\n\nIt’s always easier to show the code, so… Given the following unmanaged code declarations:\n\nThe class wrapper could be:\n\nWhile the structure wrapper could be:\n\nAside from the major differences between classes and structures outlined above, the members of classes and structures are marshaled identically.\n\nThe general rule of advice is this: never pass classes or structures containing members of reference type (classes) to unmanaged code. This is because unmanaged code can’t do anything safely with the unmanaged reference (pointer), and the CLI runtime doesn’t do a “deep marshal” (marshal members of marshaled classes, and their members, ad infinitum).\n\nThe immediate net effect of this is that you can’t have array members in marshaled classes, and (as we’ve seen before) handling strings can be “wonky” (as strings are also a reference type).\n\nFurthermore, the default string marshaling is the platform default, though this can be changed by setting the StructLayoutAttribute.CharSet field, which defaults to CharSet.Auto. Alternatively, you can adorn string members with the MarshalAs attribute to specify what kind of string they are.\n\nThe System.Boolean (bool in C#) type is special. A within a structure is marshaled as an (a 4-byte integer), with 0 being and non-zero being ; see UnmanagedType.Bool. A passed as an argument to a function is marshaled as a (a 2-byte integer), with 0 being and -1 being (as all bits are set); see UnmanagedType.VariantBool.\n\nYou can always explicitly specify the marshaling to use by using the MarshalAsAttribute on the boolean member, but there are only three legal UnmanagedType values: UnmanagedType.Bool, UnmanagedType.VariantBool and UnmanagedType.U1. UnmanagedType.U1, the only un-discussed type, is a 1-byte integer where 1 represents and 0 represents .\n\nIf you need to marshal as another data type, you should overload the method accepting the boolean parameter, and manually convert the boolean to your desired type:\n\nSee also: Default Marshaling for Boolean Types\n\nA C union (in which multiple members share the same offset into a structure) can be simulated by using the FieldOffset attribute and specifying the same offset for the union members.\n\nThe C ‘long’ type is difficult to marshal as a struct member, since there is no CLR type which matches it, i.e. ‘int’ is 32 bit, ‘long’ is 64 bit, while C’s ‘long’ can be 32 bit or 64 bit, dependending on the platform. There are two possible solutions:\n• Using two sets of structures, one for 32 bit and one for 64 bit platforms.\n• Mapping C ‘long’ to ‘IntPtr’. This will work on all 32 bit and 64 bit platforms, _except_ 64 bit windows, where sizeof(long)==4 and sizeof(void*)==8. See This.\n\nInline arrays can be marshaled by using a MarshalAs attribute with UnmanagedType.ByValArray and specifying the MarshalAsAttribute.SizeConst field to the size of the array to marshal. Inline arrays which contain strings can use UnmanagedType.ByValTStr for a string.\n\nHowever, the runtime doesn’t automatically allocate arrays specified as UnmanagedType.ByValArray. The programmer is still responsible for allocating the managed array. See the summary for more information.\n\nTODO: Bernie Solomon says that for parameters, the runtime will allocate the inline array memory. Check this out.\n\nFor example, the unmanaged structure:\n\nCan be represented in C# as:\n\nOf course, the managed structure can be declared in other ways, with varying performance and usage tradeoffs. The previous declaration is the most straightforward to use, but has the worst performance characteristics. The following structure will marshal faster, but will be more difficult to work with:\n\nYet another alternative is to directly specify the size of the structure, instead of letting the structure contents dictate the structure size. This is done via the StructLayout.Size field. This makes the structure terribly annoying to deal with, as pointer arithmetic must be used to deal with the member:\n\nC# 2.0 adds language features to deal with inline arrays, using a fixed array syntax. This allows the previous structure to be declard as:\n\nFixed array syntax is still “unsafe”, and requires elevated privilege to execute.\n\nThis might be of use. From David Jesk:\n\nAnd the possible corresponding managed code:\n\nNote that this isn’t an exact match to the unmanaged code. This structure must be built in two phases to match the unmanaged representation: (1) create the structure, and (2) allocate memory for ManagedInformation.array. For example:\n\nThe FieldOffset attribute has one major pitfall: it makes offsets of types explicit. This is liable to break if (when) (1) the class/structure contains a pointer, reference, or array, and (2) you change the bitsize of your processor (move from a 32-bit processor to a 64-bit processor). It is preferable to use LayoutKind.Sequential if at all possible, as the runtime will take care of updating the structural offsets when the size of pointers changes.\n\nTODO: include MSDN examples using the more esotoric MarshalAs fields, such as SizeParamIndex, ArraySubType, etc.\n\nSee also: *Marshaling Data with Platform Invoke at MSDN, *Arrays Sample at MSDN\n\nDidn’t we start using a managed execution environment to avoid pointers? But I digress…\n\nAlas, pointers are a fact of life in unmanaged code. As the Avoiding Marshaling section points out, there are two ways to represent pointers: the “safe” way, using System.IntPtr or System.UIntPtr , and the “unsafe” way, by using code and pointers.\n\nBehold the topic that just won’t die! “Inline” strings – in which the storage for the string is part of the structure itself – were covered previously. Obviously, and likely more commonly, strings are not always allocated within the structure; typically a pointer to a null-terminated string is stored.\n\nThe typical approach is to map the string as an IntPtr, and use Marshal.PtrToStringAnsi and similar functions to manually marshal the string.\n\nWhy manually marshal? Because you typically use a custom memory allocator (such as malloc(3)), and don’t want the runtime incorrectly freeing the memory that the string references. In this case, it’s essential that you manually marshal the string to avoid memory corruption.\n\nThe ICustomMarshaler interface allows the CLI to invoke custom code as part of the P/Invoke call. Normal P/Invoke calls follow the structure:\n\nCustom marshaling allows this to become\n\nIn order for the custom marshaler to be invoked,\n• the custom marshaler must implement the ICustomMarshaler interface, and\n• the custom marshaler must provide a static GetInstance method which takes a string and returns a ICustomMarshaler instance:\n• The DllImport declaration must have a parameter with a MarshalAs attribute specifying UnmanagedType.CustomMarshaler and:\n• (Optionally) The MarshalCookie field. This string is passed to GetInstance.\n\nAn example custom marshaler can be found in the Mono.Unix.Native.FileNameMarshaler (FileNameMarshaler.cs) and in the Mono unit tests (marshal9.cs).\n\nGiven all the work involved with custom marshaling, such as the required ICustomMarshaler class implementation and MarshalAs attributes, what is the advantage of custom marshaling over manual marshaling? Maintenance. For only one method, manual marshaling is simpler:\n\nHowever, as the number of methods that require essentially identical marshaling increases, it becomes easier to maintain the custom marshaler than to maintain the N separate manual marshal copies that would otherwise be necessary.\n\nSee also: *ICustomMarshaler Interface at MSDN\n\nWhat do you do when the default marshaling rules (amid all the variations that the DllImport and MarshalAs attributes permit) don’t allow you to invoke a given function? You do it manually by making extensive use of the Marshal class methods.\n\nThe key in the following tutorial is System.Runtime.InteropServices, where we can find the Marshal class. That class is very useful because it bridges created managed objects and unmanaged ones. Its functionalities are very similar to blocks, unsafe, and more. For example, let’s say that all pointer types in .NET are saved in an instance of the type IntPtr. With the Marshal class, we can perform any operation like adding a determined number of bytes in order to point to other objects, and converting things that are there in a structure or a chain (other thing is if in that memory direction is something with sense or not).\n\nUsing this piece of code, we can see how to put data into an unmanaged structure through a pointer obtained from a function or an external public structure of a native library.\n\nBy default C#, establishes the order that is most optimized for the structure fields in memory. Nevertheless, if we want to dump the contents of the unmanaged pointer in our structure correctly, all the fields must maintain their order and size (in bytes). To solve this problem, we apply the attribute StructLayout(LayoutKind.Sequential) on the structure.\n\nThe structure has two pointers to X windows, a pointer to a character matrix (a string table), and an integer that defines the number of present chains. It seems to be a complex structure, but it isn’t.\n\nWe want to create a class from that structure. So, we have a constructor with a parameter that points to the unmarshalled structure. Afterwards, we use the Marshal class in order to utilize its basic types. Everything is straight forward except for the matrix that couldn’t be converted without producing an error. The Mono.UnixMarshal class solves that problem, which was basically a portability issue:\n\nThe fact that Mono is open-source helped understand that MonoUnix is merely an extension of System.Runtime.InteropServices.Marshal, using the same methods of the Marshal class. This means that we can put the necessary code of UnixMarshal in the project in order to guarantee its portability from Windows Mono or even .NET. Here’s the piece of code:\n\nAfter the following step, the final class is completely portable:\n\nMarshaling is no panacea, as marshaling implies copying data. Marshaling may be problematic because the data translation is a complex, time-consuming process. Alternatively, it may be problematic because it isn’t possible to copy the data, as the data isn’t known or is likely to change.\n\nAn example of the latter would be the GTK+ libraries. GTK+ is an object-oriented toolkit written in C. As with all object-oriented libraries, there can be an unknown number of derived classes, each of which having a different class size. Furthermore, class instances are typically accessed through pointers. As such, marshaling the entire class between managed and unmanaged memory is not an option, as a copy isn’t desired, access to the same instance is.\n\nAnother example is when using “opaque” data types; that is, types through which interaction is solely through pointers, and nothing about the internals of the type is public. This describes a large portion of the Win32 API, where HANDLE is used to represent most objects.\n\nThere are two ways to handle this in C#: the “type-safe” way, which involves using pointers and the “unsafe” C# language features, and the CLS-compliant way, which uses System.IntPtr to stand in for a void pointer.\n\nIn both cases, the separation between managed and unmanaged memory is made explicit. Managed memory remains type-safe, while unmanaged memory is not (since System.IntPtr is used to point into unmanaged memory, and there is no way to ensure the actual type of what the System.IntPtr refers to).\n\nBe warned that this may not be safe, if the “unmanaged” memory is itself garbage collected. This may be the case if the unmanaged memory is handled by a different runtime system (Python, Ruby, Lisp, etc.) or a garbage collector is being used (Boehm). If the unmanaged memory is garbage collected, then the System.IntPtr won’t be updated when unmanaged memory undergoes a garbage collection, resulting in memory corruption.\n\nFor example, given the unmanaged API:\n\nThe “type-safe” C# wrapper (using “unsafe” code) is:\n\nThis is “type-safe” in that you can’t pass arbitrary memory locations to the static Item functions, you must pass a pointer to an Item structure. This isn’t a strict amount of type safety, but it is likely to minimize accidental memory corruption. It’s biggest problem is that it uses “unsafe” code, and thus may not be usable from other .NET languages, such as Visual Basic .NET and JavaScript.\n\nThe CLS compliant version uses System.IntPtr to refer to unmanaged memory. This is similar to what the Marshal class does to interoperate with unmanaged memory.\n\nThis is “unsafe” in that it is easier to accidentally mis-use pointers. For example, if you’re using two different libraries and wrapping them using System.IntPtr, it is possible to pass an object allocated from one library to a function exported by the other library, and the CLI Runtime will not catch this error, while the “unsafe” C# code would catch this error.\n\nHowever, this isn’t normally considered a problem, as most managed code shouldn’t interact with P/Invoke code, but should instead interact with managed wrappers for the unmanaged code, which can provide a more natural interface to managed clients.\n\nThere’s one problem with the wrapper code described above: a race-condition between user code and the runtime Garbage Collector (GC).\n\nThe GC that .NET uses is not conservative. It knows all types involved, and can distinguish between an integer that looks like a pointer and an actual pointer value. It knows all stack-allocated variables, and what the scope of those variables is. Finally, the GC does not see into unmanaged code.\n\nThe result of this is that it’s possible the the GC to collect a class instance while a method of the instance is still executing.\n\nHow is this possible? If the method no longer references class data (instance members), and no other code refers to it, the GC may collect the class. After all, if no instance members are used and no one is using the instance, what’s it matter if the instance is collected?\n\nIt matters a lot if unmanaged code thinks that the instance is still alive. Or, if the class has a finalizer, which could be executed while native code is executing from within the native method.\n\nHere is an example adapted from Chris Brumme’s blog:\n\nConsider this: invokes , which invokes the unmanaged code . Note that doesn’t use anymore, so is eligible to be collected, and is placed on the GC finalization queue.\n\nThis would normally be reasonable, except for the interplay with unmanaged code. The unmanaged code is still using a member held by the instance , but the GC doesn’t – and can’t – know this.\n\nThis introduces the possibility that, although unlikely, will be invoked (from the GC finalization thread) while is still operating.\n\nIt’s fair to assume that the unmanaged code won’t appreciate this. It’s fair to assume that this could cause major problems for the process, including a segmentation fault.\n\nIn fact, a bug very similar to this exists in .NET v1.0, in one of the Registry wrapper classes.\n\nHow do you avoid this problem? Don’t use raw IntPtrs. With the IntPtr being used, the GC has no way of knowing that the class still needs to hang around. To avoid the bug, we avoid IntPtrs.\n\nInstead of using IntPtr, we use HandleRef. This is a structure which holds both a reference to the containing class, as well as the pointer value.\n\nNext, instead of having the P/Invoke code accept IntPtr parameters, the P/Invoke code accepts HandleRefs. HandleRefs are special to the runtime and GC system, and during a marshal operation they “collapse” into an IntPtr.\n\nThis allows us to write the safe code:\n\nIn .NET 2.0, a new mechanism for wrapping unmanaged handles was introduced. This new mechanism is exposed by the SafeHandle class. SafeHandles encapsulate a handle in the form of an IntPtr, but by exposing it as a subclass of the SafeHandle class (for example SafeFileHandle or SafeWaitHandle) developers gain type safety.\n\nSafeHandles in addition provide a mechanism to avoid inadvertent handle recycling (for references [1] [2]).\n\nThe runtime treats SafeHandles specially and will automatically provide marshalling of these when used in P/Invoke calls. The behavior depends on its use:\n• On outgoing parameters, the SafeHandle’s handle is passed.\n• On return values, a new instance of the concrete SafeHandle class is created, and the handle value is set to the returned IntPtr value.\n• On ref SafeHandles, the outgoing value is ignored (must be zero) and the returned value is turned into a proper SafeHandle.\n• On structure fields, the SafeHandle’s handle is passed.\n\nFor the actual implementation details in Mono, see the SafeHandles document.\n\nWhen avoiding marshaling, you’re referencing unmanaged memory and other resources from managed code. This confers a great deal of responsibility. It also creates a great deal of concern, as more things can “go wrong” in managed code, particularly because of exceptions and related complexity. When any function can throw an exception, ensuring that resources are properly disposed of can be a tricky matter.\n\nAs suggested in the previous section, a simple way to ensure that resources are eventually disposed is to wrap the resource within a class containing a finalizer. The finalizer can then free the resource.\n\nThere are two problems with that approach, both of which have to do with the garbage collector:\n• The garbage collector cannot see into unmanaged memory, it only deals with managed memory. Thus, if you have a large amount of memory in unmanaged memory (such as images or video data), all the GC will see is the IntPtr(s) that refer to this data, and not the size of the unmanaged memory “held” by the managed code. Consequently, the GC won’t know that a collection should be executed (there won’t be any “memory pressure” to cause a collection). This is partially fixed in Microsoft’s implementation of .NET 2.0 by using the System.GC.AddMemoryPressure(long) method, which can be used to tell the GC how much unmanaged memory a managed object is referencing, which can improve the GC heuristics. However, code needs to be modified to support this approach and does not work with .NET 1.1 code. At the the time of this writing (January 2015), this approach will not work on Mono, as System.GC.AddMemoryPressure(long) and System.GC.RemoveMemoryPressure(long) are implemented as no-ops. This means that some existing code that performs normally under Microsoft’s CLR will quickly exhaust the unmanaged heap and cause both unmanaged and managed memory allocations to fail.\n• The .NET garbage collector does not execute an object’s finalizer when the object is collected. Instead, the object is promoted a generation, and the object’s finalizer is executed the next time that generation is collected. For example, if a Generation 0 object with a finalizer is eligible for collection (i.e. no objects reference it), the object is promoted a generation, and placed on the Generation 1 finalization queue. The next time Generation 1 is collected, the object’s finalizer will be executed.\n\nProblem 2 is a real killer, as collection frequency is inversely proportional to the generation number. Generation 0 is (typically) collected 10 times as frequently as Generation 1, which in turn is collected 10 times as frequently as Generation 2. Generation 2 is intended to be rarelycollected, as these should be long-term objects that persist through the life of the application.\n\nGiven that the soonest a finalizer is collected is after two collections, one for Generation 0 and one for Generation 1 (which occurs after ~10 Generation 0 collections), it can be a long time before a finalizer is executed. Relying on finalizers for resource disposal and collection is a BAD IDEA, even before considering that finalizers are not guaranteed to be executed, especially at program shutdown.\n\nFortunately, there is a simple pattern used throughout the .NET Class Libraries to help ensure that resources are disposed of quickly:\n• Call Dispose when finished with the resource. The implementation for Dispose does two things:\n• dispose of the resource, and\n\nSuppressFinalize informs the GC that the object’s finalizer doesn’t need to be invoked, allowing the object to be freed during the first collection, and not after a considerable delay. A sample implementation is:\n\nFrequently IDisposable examples will provide a virtual method, which both Dispose and the finalizer delegate to, as opposed to the method used above. However, providing both a a virtual function and a non- class is advertising the ability/desire to subclass, which is a potentially bad idea.\n\nIt’s a potentially bad idea, again, because of the garbage collector. When an object is promoted a GC generation, all objects it refers to are also promoted a generation, recursively. So if your finalizable object contains an ArrayList of other objects, both the ArrayList, all objects it contains, and all objects those objects reference (recursively) will be promoted. This can be a potentially large amount of managed memory which is promoted a generation.\n\nGiven the GC promotion rules, it is highly recommended that finalizable classes be “leaf” nodes; that is, objects that don’t refer to other objects within the managed memory “tree”. For this reason, it is highly suggested that finalizable objects be sealed to prevent subclassing, to minimize the number of managed objects that the finalizable object refers to. Rico Mariani discusses this in “Almost-rule #2: Never have finalizers”.\n\nImplementing the IDisposable interface isn’t a complete solution, as it requires that users remember to invoke the Dispose method. The C# using block can be used to ensure that Dispose is invoked at the end of the block:\n• Rico Mariani’s Blog: Two things to avoid for better memory usage.\n\nTopics that didn’t seem to fit in anywhere else, but might be useful.\n\nA “problem” is that “unsafe” is an overloaded term. It can refer to the use of the “unsafe” C# keyword, and it can be used as “anything that isn’t safe”, which may not require the “unsafe” keyword.\n\nSo, “unsafe” can mean (a) C# keyword; (b) violates .NET type system (similar to (a)); (c) may be insecure (reading files from a web client); (d) capable of causing a segfault. There are likely other meanings people can dream up as well. Note that (d) doesn’t imply (b), as far as .NET is concerned. The runtime could itself have a bug that generates a segfault, but this doesn’t violate the type system.\n\nIntPtr doesn’t require a violation of the type system, as you can’t get the address of a .NET object (unless you “pin” it, which would require the appropriate Security rights), and is thus principally useful for interacting with unmanaged code, which exists outside of the .NET type system.\n\nSurely, this is pure semantics, but I can see the designers perspective.\n\n.NET has a highly flexible security system. You can’t invoke DllImported functions unless your app has the appropriate security rights – generally, that the app is running on the local machine. If you’re running it from a network share, or from a web site (similar to Java Applets), then your app will get a SecurityException.\n\nYou can get lots of security exceptions for various things, actually. Opening files can generate a security exception, for example.\n\nSystem.Security.Permissions.SecurityPermission is needed with SecurityPermissionFlag.UnmanagedCode specified in order to perform a P/Invoke.\n\nPrograms can’t specify this permission; they can only request it (or demand it, and if they can’t get it, a SecurityException is thrown).\n\nAdministrators are the people who specify what permissions an application actually receives.\n\nThat’s about the limits of my knowledge – Security isn’t my forte. You might find the following topics interesting.\n\nSee also: Unsafe Code at MSDN\n\nIn Unix, sometimes P/Invoking a library can fail due to a number of reasons:\n• The Library being P/Invoked not being in the LD_LIBRARY_PATH\n• The Library being P/Invoked has a different name\n• The library being P/Invoked has different casing (MONO_IOMAP does not apply here)\n• The library could depend on symbols from another library that has not been loaded.\n\nTo identify the source of the problem if you get an error in your P/Invoke run Mono like this:\n\nInteresting commentary that doesn’t really belong elsewhere, but is still good to know.\n\nYes, the P/Invoke specification (or lack thereof) is a mess. It was done by people that didn’t [think] through the portability issues and this is probably one of the reasons the MS CLR is not really supported on 9x-based platforms. Note: P/Invoke is intrinsically non-portable, the main issue is that P/Invoke is poorly defined in a non-win32 system. Think of Charset: they allow Ansi and Unicode (with Auto meaning one or the other according to the platform), but the world uses also other encodings. At the very least they should have added a Charset.Encoding or something, with the actual encoding specified separately as a string, for example (good luck, though, finding a UCS4 encoding implementation in the base assemblies…).\n\nPortions of this document were generated as a result of a mono-list discussion between Jonathan Pryor and David Jeske.\n\nThanks also to Paolo Molaro, Bernie Solomon, and Marcus for reviews and comments.\n\nTo the greatest extent possible, this document is dedicated to the Public Domain. Please properly document Jonathan Pryor as the original author (you don’t go quoting Mark Twain without mentioning him even though his works are all Public Domain), but I fully expect that this document can (and will) be massaged for other mediums.\n\nNote that some portions of this document are quotations from others; the original author is mentioned when quotations are made.\n\nRevised navigation menu to show 1st and 2nd level links. Documented Mono’s __Internal library name extension for importing symbols from within the loading program. Added Marshaling Arrays section, which clarifies array marshaling issues and includes the David Jesk commentary (which shouldn’t have been in the “Avoiding Marshaling” section anyway). Added boolean marshaling information. Added Marshaling Embedded Strings information. Minor corrections, additional links to blogs and articles.\n\nMono properly frees the memory of class-typed return values now. Remove comment stating otherwise. (miguel)\n\nAdded Memory Boundaries section based on suggestions from Marcus; formatting changes."
    },
    {
        "link": "https://benbowen.blog/post/pinvoke_tips",
        "document": "Not very many C# programmers will ever need to do much with P/Invoke (Microsoft's technology for interoperation with legacy or native codebases), but for those of us who do, I've amassed a few little tips that aren't always included in the various tutorials found on the 'net.If you're looking for a tutorial on using P/Invoke, this isn't the place to find it- there are already plenty of decent, in-depth discussions and examples on the internet just a Google search away; and they've already done a better job than I ever could. Instead, I'm hoping to make a quick cheat-sheet of some random parts of P/Invoke that I've used in making a game engine, and that might be useful to future programmers! So, without further introduction, here we go (in no particular order):The first tip I'm going to give is something that I actually found surprisingly difficult (but not impossible) to get information about on the internet. There's a wealth of information about how to call pre-existing native methods from C# (e.g. anything in the C runtime libs or WINAPI)- in fact, there's even a whole website dedicated to it. But what if you're writing the native side too (e.g. a C++ or C library that exposes certain functions to be called from your managed code)? Here's the best way I found to expose an interface to be used from C# in your C++ code:First, define a macro like this:Now, you can use this macro to 'export' a method from C++ to be used through P/Invoke. For example, here's an example from the game engine (slightly modified to keep things concise):That is a function namedthat returns an(more on that in a second), and takes two DirectX-related pointers as parameters. You can export as many methods like this as you want. This code for this particular method can then be called from managed C# through a P/Invoke signature that looks like this:Notice how the CallingConvention is set to. That corresponds to the function calling convention we specified in themacro with. The calling convention basically specifies where and in which order the function parameters, return value, stack values and CPU registers are when calling a function, and we must match them up on both 'sides' of the code. Thedeclaration is actually specifying the calling convention as cdecl , and thereforeis set to. Furthermore, it should be noted that when you want to export a method with the cdecl convention, you could also declare the method with theattribute instead of- but this will not prohibit the C++ compiler from name mangling your exported methods- which is not something you want most likely.Additionally, all this calling convention malarkey is purely for the benefit of 32-bit code. For 64-bit platforms, all options you try to set for the CallingConvention property are ignored and the x64 ABI is used which only has one usable calling convention (from the CLR's perspective, anyway).Concerning the rest of that method, the two parameters to the call from the C# side are basically just two pointers that will point to the relevant DirectX objects.This is certainly the easiest way to export methods from C++/native code to C#/managed via P/Invoke that I found. Of course, there are other ways, and if you have any suggestions or improvements, please do leave a comment!So in the previous section you may have noticed my use of a return type named. This is because I like to return a true/false value to indicate whether or not an interop call failed. However, what is? Well, it's a macro (and probably ought to be a typedef, but ignore my egregious crimes for now ;)), and it looks like this:So what gives? Why not just useWell, the answer is that in C++, the size of the bool type is implementation-defined, whereas the CLR mandates that thestruct is exactly 1 byte. If you don't specify any particular marshalling, the C# bool will be marshalled to a WINAPItype, which is just a 4-byte integer.All this marshalling on both sides presents a potential pitfall, espcially one where your code may work on one machine, but then not on another. Ultimately, I found it easier to just avoid the issue altogether and simply pass a single-byte in, doing the conversion from Byte -> Boolean myself. Thusly, on the C# side, I have the following struct defined:This, together with the correspondingmacros defined on the C++ side, allow me to sidestep any issues involving the marshalling of bools. It's worth noting that it is semi-possible to correctly and safely marshal bools from .NET to C++ and back ; but this approach relies on the c-bool \"\" being 1 byte, which is highly likely but is an implementation detail And finally, you might (reasonably) decide that all this extra work is unnecessary, and that the default marshalling to WinAPI'stype is fine. This will of course require you to use the windows-specific headers in your code or perhaps use a type like- though this doesn't feel particularly neat to me, considering the type is meant to represent a boolean value.When it comes to marshalling numeric types to and from p/invoke, it may again surprise you to learn that thetype is not guaranteed to be 32 bits in C++; that is only the minimum size. The same \"minimum rule\" applies to most of the inbuilt numeric types. You may think this a pedantic quibble about theoreticals, but for example, the size of thetype varies between different OSs and architectures . Furthermore, I find it's just asking for trouble when you have to remember thatalways means 'a 64-bit integer' in C#, but often just means 'a 32-bit integer' in C++. Other differences (e.g.) also exist.Therefore, at least for P/Invoke (if not everywhere in your C++ applications!), I recommend using the explicit-width types in theheader; such asand(32-bit int and unsigned 64 bit int respectively). These types correspond much better to the CLR numeric types and you are less likely to create faults in your P/Invoke operations by inadvertently marshalling between mismatched numeric types.Strings in C++ are kind of messy to use compared to .NET and other more modern languages: Whereas in .NET you have only one string type, in C++ there is simultaneous support for different char types/encodings, as well as different ways of accessing and managing the memory allocated for strings, especially if you're working with WINAPI, which makes heavy use of C-style char-pointer string types with typedefs such as, etc. etc.Although UTF-16 is the worst of both worlds , that is what the CLR's System.String class uses internally (as well as a lot of other languages/runtimes; and most of Windows' modern API). Therefore, if we want the quickest possible marshalling of strings, we need to also use UTF-16 from the native side where possible.First of all, when sharing any reference type from managed to native, you need to start thinking very carefully about how memory is shared or created, who owns it, and where it will be freed.Through (informal) testing, I found that the most performant way to marshal strings is as follows:This is a function to set the title of a window in our engine.is. On the C++ side, the corresponding exported function prototype looks like this:Andis a macro (again, a typedef would be better in retrospect), defined as:These options allow the .NET marshalling runtime to simply 'blit' the internal string pointer used by the CLR string to be used directly by the C++ code. You'll notice that mymacro defines a pointer to a constarray. This is because the pointer provided through the P/Invoke mechanism is literally the address of the internal CLR unicode string, pinned on the managed heap for the duration of the unmanaged call. That means that if you modify the data, you will modify the string from the point of view of your managed program too, something that is usually impossible in .NET without unsafe code. Here's an example of the danger:This could potentially present a particularly nasty bug in your program if the given string is interned or shared at all (i.e. any non-local string, such as const or even just a public field). Furthermore, if the native code tries to modify the string by changing its length in any way, you will at best suffer a memory access violation, and at worst corrupt the state of your program in any number of ways.At least by making the C++ type, an explicitis required, which usually implies that the programmer writing the mutation is aware that they're doing something potentially unsafe (rather than it being an accident).When marshalling string back from native to managed code, the concept of memory ownership becomes even more tricky, in my opinion- especially if your application is driven from managed code. If the string is created on the C++ side, you must somehow ensure the freeing of the unmanaged memory that the string occupies, but not before it is no longer in use on the C# side. This is not always simple, so the better option is to get the P/Invoke marshaller to copy the string from the C++ allocated memory in to the managed heap, and let RAII and smart pointers on the C++ side delete the string once the native method is complete.By default, most P/Invoke marshalling operations will exhibit this behaviour and copy strings in toobjects. You can also do this manually using, for example, Marshal.PtrToStringUni() and other associated methods; supplying the function with a pointer to the start of the unmanaged string. The function will create a new managed string object and copy the unmanaged string to it; meaning that as soon as the function returns the unmanaged memory can safely be deleted or moved.However, another, third approach is to allocate the memory completely on the C# side first (by asking the C++ side how much memory it needs) with something like stackalloc and then using methods such as the staticto convert the data in to a managed CLR string before the stack memory goes out-of-scope. This is the general approach I used for marshalling strings out of native memory in the end, because sometimes you can't be sure that the native string is not going to be moved or reclaimed in the time between getting a pointer to it and thefunction completing its copy.If you're wondering whether this is overkill, it's actually quite an easy mistake to make- returning a pointer to a local/stack copy of a string in C++ means that you're already sitting on a time-bomb by the time you return to 'managed land'. What's worse is that this mistake tends to go unpunished 99% of the time (accessing deleted memory is undefined behaviour, after all), so your application will only suddenly stop working sometimes. And that's not even considering multi-threaded scenarios! And finally, I just like the idea of the calling side (i.e. the managed side) being completely responsible for memory ownership. It's ultra-explicit, and when it comes to handling memory in this sort of code, I think it pays to be 110% sure of what you're doing. Anyway, here is an example:The other nice thing about this approach is that because we used stackalloc we don't have to remember to clean up any memory - the only allocated memory will be cleaned up when the function exits (not including theobject we also new'd up, but that will be garbage collected as usual).However, a final note of warning- this method is still not an atomic operation. Although we don't have to worry about RAII'd smart pointers removing our memory out from under us anymore, it's still possible that another thread causes the value we're trying to copy to change between our calls toand. It will be up to you to make sure that if you're using multiple threads, this code remains an atomic operation.Whichever way you choose, make sure you think very carefully about where and how memory is handled from start to finish! Although the techniques I described above have worked well enough for my entire string marshalling needs, they are not at all exhaustive. If you feel like you need more advanced string marshalling options available to you, I would totally recommend the following CodeProject article: Advanced Topics in PInvoke String Marshaling . Even if you decide not to use the techniques described in that article, just understanding the concepts behind them can help you ensure you are not making mistakes with shared or invalid memory usage in your own interop code.As you may or may not know, C# applications can be run in a secured 'sandbox', meaning that the CLR runtime will ensure an application (or AppDomain) can only execute certain functions. For a game engine, I don't find it particularly useful.However, all P/Invoke calls must still request native code execution permissions. Normally, this is done on every call. However, the check takes a not-inconsiderable amount of time. If you're not interested in sandbox security, I would highly recommend that you apply the SuppressUnmanagedCodeSecurity attribute to all of your P/Invoke functions. You can also simply apply it to the class that contains your P/Invoke functions and it will be applied to all external methods contained within.To see how much of a difference it really makes, I wrote a test framework that calls msvcrt's memcpy a whole bunch of times via P/Invoke. It runs once (A) with the security turned on by default, and once (B) with it suppressed. Both functions copied 1 kilobyte using memcpy 10000 times; and the whole test was run 60 times, with an extra 5 times at the start not counted to allow the JIT compiler (and initial security check) to do its thing.The results are as follows:Put simply, with the default security options left enabled, it took 22.536ms on my machine to copy 1000 bytes 60000 times, and with unmanaged code security suppressed, it took 16.510ms. That means that with code security enabled, there's an overheard of roughly 1ms per 10000 P/Invoke calls (on my mid-high range machine). Although you may not eventually see the benefit of this micro-optimization, the way I see it it's a free win- you only have to add the attribute once and you get some free frame time in a game engine, for example. And we don't get many free wins in our industry. ;)Unfortunately, even with unmanged code security suppressed, making thousands of P/Invoke'd calls every frame can still be too slow for your needs. One approach to solving this that we baked in to our engine is instead to make use of lots of shared memory. Having a command-buffer like structure in unmanaged memory space can allow you to fill memory with draw instructions and parameters and then pass control over to C++; where you can than simply and rapidly iterate through the buffer, dispatching DirectX draw calls.Even if you don't need this, at some point you might want to send a custom struct through a P/Invoke call. It can be tempting to keep things simple and use only primitive types like numbers and strings, but at some point you might find yourself in need of something more... Well, structured.So how exactly do we share structured data between managed and unmanaged code? Let's imagine we want to share astruct that describes the layout and meta-options for creating a new Win32 window. Let's define the exported method and P/Invoke pair as follows:So, for the first attempt, you might be content just to write the struct in C# and C++ and pass it as you would any other parameter:...But you'd be wrong. This might happen to work on your machine if you're lucky (or is that unlucky?). But C# is allowed to perform various optimisations that include the reordering of struct fields. In essence, that means that actually, thefield might start in memory after theandfields on the C# side, but be in the definition-order on the C++ size (C++ is not allowed to perform this optimization).But as well as this, both compilers/languages are allowed to add extra bytes on to the end of a struct (called 'padding') for performance reasons or alignment requirements. And finally, both compilers/languages are also allowed to add padding between the different variables of the struct in order to make them line up neatly on cache lines and so on.Now, all of these (except for alignment requirements) are simply performance tricks on most processors (some processors don't like reading words across cache lines, but x86 et al are fine). You should know these performance implications if you're writing something like a game engine, but for most cases (like when creating a window) we don't really need it. So, we kind of need to side-step these compiler optimisations somehow.When it comes to doing this, there are two options. You can use the various constructs given to you in C# and C++ to build your structs safely, or you can do everything manually with blobs of bytes. Technically, the only safe way to share data like this between two compilers, languages, computers, or architectures is the latter. In essence, you should define your structure in pure memory terms (e.g. \"8 bytes for string pointer followed by 4 bytes for window width followed by...\" etc), and then simply copy the raw binary data from source to destination (or a pointer to it); taking the fields out at the right place, manually.That being said... ;) I find that all a bit tedious. For network programming it's simply a must, but you can get C# and C++ to play nice together with a bit of hand-holding on the same machine. So, here's how:Firstly, we need to force the compiler not to add extra packing bytes. And then, we have to tell C# not to reorder our fields. Here's an updated version of the struct on both sides (in MSVC++, consult your compiler's documentation for other compilers; but the principle is usually the same):On the C++ side, we are using thedirective to force the compiler to minimize packing in our struct (the 1 value specifies a minimum distance between consecutive fields of 1 byte- i.e. no padding). On the C# side we've added a newattribute that does two things. Theproperty does the same as thestatement on the C++ side. And theselection prevents the C# compiler from re-ordering our fields.With these things in place, we can be fairly sure that passing our struct around (either as a parameter or in shared memory) is going to be safe... But not 100% sure. For example, if any of your fields on the C++ side have special alignment requirements (e.g. an SSE-enabled vector), those requirements will always take precedence over anything you write around the struct. Plus, well, it's just hard to juggle all the different compiler + language rules on both sides of the equation sometimes. So, for that reason, I recommend to anyone that they either use the manual-byte-arrays method I mentioned above, or that they include a ton of asserts in the program code near initialization to ensure that everything is the size expected (basically, checkingeverywhere), which is what I do. In C++ you can even go for. For my next project in C# I'm also going to experiment with something like Fody or another compile-time IL rewriter to embed the assertions with a custom attribute next to the struct.Finally, it is worth noting that according to the MSDN page for StructLayout , thespecifier has no effect on non-blittable types when not going through the marshaller. In essence, this means that sharing memory with non-blittable types is still not safe... But non-blittable usually means \"includes a GC-reference type\", and sharing memory with structs that include GC'd members is usually a dumb idea anyway. In a pinch, it does mention that you can use thespecification instead, marking the exact byte offset of each field with FieldOffset , if you need this.And finally, to end with, just a short and simple tip. :) If you turn on Managed Code Analysis for your projects, make sure you enable rule CA1400 : This rule will inspect the entry points in native code according to all of yourattributes, and check that they exist! Great for catching nasty typos early. :)Well, that's it for this post folks. It's been a long and technically dense one; and I'm sure there's at least one error in there (despite my proof-reading), so if you spot any corrections or just have any criticisms or improvements, do leave a comment! You can also find me using the social media links in the sidebar. Good luck!"
    }
]