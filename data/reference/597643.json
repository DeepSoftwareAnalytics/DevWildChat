[
    {
        "link": "https://learn.microsoft.com/en-us/sql/t-sql/statements/create-table-transact-sql?view=sql-server-ver16",
        "document": "Creates a new table in the database.\n\nSimple CREATE TABLE syntax (common if not using options):\n\nThe name of the database in which the table is created. database_name must specify the name of an existing database. If not specified, database_name defaults to the current database. The login for the current connection must be associated with an existing user ID in the database specified by database_name, and that user ID must have CREATE TABLE permissions.\n\nThe name of the schema to which the new table belongs.\n\nThe name of the new table. Table names must follow the rules for identifiers. table_name can be a maximum of 128 characters, except for local temporary table names (names prefixed with a single number sign ( )) that can't exceed 116 characters.\n\nApplies to: SQL Server 2012 (11.x) and later.\n\nCreates the new table as a FileTable. You don't specify columns because a FileTable has a fixed schema. For more information, see FileTables.\n\nAn expression that defines the value of a computed column. A computed column is a virtual column that isn't physically stored in the table, unless the column is marked PERSISTED. The column is computed from an expression that uses other columns in the same table. For example, a computed column can have the definition: . The expression can be a noncomputed column name, constant, function, variable, and any combination of these connected by one or more operators. The expression can't be a subquery or contain alias data types.\n\nComputed columns can be used in select lists, WHERE clauses, ORDER BY clauses, or any other locations in which regular expressions can be used, with the following exceptions:\n• None Computed columns must be marked PERSISTED to participate in a FOREIGN KEY or CHECK constraint.\n• None A computed column can be used as a key column in an index or as part of any PRIMARY KEY or UNIQUE constraint, if the computed column value is defined by a deterministic expression and the data type of the result is allowed in index columns. For example, if the table has integer columns and , the computed column might be indexed, but computed column can't be indexed because the value might change in subsequent invocations.\n• None A computed column can't be the target of an INSERT or UPDATE statement.\n\nBased on the expressions that are used, the nullability of computed columns is determined automatically by the Database Engine. The result of most expressions is considered nullable even if only nonnullable columns are present, because possible underflows or overflows also produce NULL results. Use the function with the AllowsNull property to investigate the nullability of any computed column in a table. An expression that is nullable can be turned into a nonnullable one by specifying with the check_expression constant, where the constant is a nonnull value substituted for any NULL result. REFERENCES permission on the type is required for computed columns based on common language runtime (CLR) user-defined type expressions.\n\nSpecifies that the SQL Server Database Engine will physically store the computed values in the table, and update the values when any other columns on which the computed column depends are updated. Marking a computed column as lets you create an index on a computed column that is deterministic, but not precise. For more information, see Indexes on Computed Columns. Any computed columns that are used as partitioning columns of a partitioned table must be explicitly marked . computed_column_expression must be deterministic when is specified.\n\nSpecifies the partition scheme or filegroup on which the table is stored. If partition_scheme is specified, the table is to be a partitioned table whose partitions are stored on a set of one or more filegroups specified in partition_scheme. If filegroup is specified, the table is stored in the named filegroup. The filegroup must exist within the database. If is specified, or if ON isn't specified at all, the table is stored on the default filegroup. The storage mechanism of a table as specified in CREATE TABLE can't be subsequently altered.\n\nON { partition_scheme | filegroup | \"default\" } can also be specified in a PRIMARY KEY or UNIQUE constraint. These constraints create indexes. If filegroup is specified, the index is stored in the named filegroup. If is specified, or if ON isn't specified at all, the index is stored in the same filegroup as the table. If the PRIMARY KEY or UNIQUE constraint creates a clustered index, the data pages for the table are stored in the same filegroup as the index. If is specified or the constraint otherwise creates a clustered index, and a partition_scheme is specified that differs from the partition_scheme or filegroup of the table definition, or vice-versa, only the constraint definition will be honored, and the other will be ignored.\n\nIndicates that the text, ntext, image, xml, varchar(max), nvarchar(max), varbinary(max), and CLR user-defined type columns (including geometry and geography) are stored on the specified filegroup.\n\nisn't allowed if there are no large value columns in the table. can't be specified if partition_scheme is specified. If is specified, or if isn't specified at all, the large value columns are stored in the default filegroup. The storage of any large value column data specified in can't be subsequently altered.\n\nApplies to: SQL Server 2008 R2 (10.50.x) and later. Azure SQL Database and Azure SQL Managed Instance do not support .\n\nIf the table contains FILESTREAM data and the table is partitioned, the FILESTREAM_ON clause must be included, and must specify a partition scheme of FILESTREAM filegroups. This partition scheme must use the same partition function and partition columns as the partition scheme for the table; otherwise, an error is raised.\n\nIf the table isn't partitioned, the FILESTREAM column can't be partitioned. FILESTREAM data for the table must be stored in a single filegroup. This filegroup is specified in the FILESTREAM_ON clause.\n\nIf the table isn't partitioned and the clause isn't specified, the FILESTREAM filegroup that has the property set is used. If there is no FILESTREAM filegroup, an error is raised.\n\nAs with ON and , the value set by using for can't be changed, except in the following cases:\n• A CREATE INDEX statement converts a heap into a clustered index. In this case, a different FILESTREAM filegroup, partition scheme, or NULL can be specified.\n• A DROP INDEX statement converts a clustered index into a heap. In this case, a different FILESTREAM filegroup, partition scheme, or can be specified.\n\nThe filegroup in the clause, or each FILESTREAM filegroup that is named in the partition scheme, must have one file defined for the filegroup. This file must be defined by using a CREATE DATABASE or ALTER DATABASE statement; otherwise, an error is raised.\n\nSpecifies the data type of the column, and the schema to which it belongs. For disk-based tables, use one of the following data types:\n• An alias type based on a SQL Server system data type. Alias data types are created with the statement before they can be used in a table definition. The NULL or NOT NULL assignment for an alias data type can be overridden during the statement. However, the length specification can't be changed; the length for an alias data type can't be specified in a statement.\n• A CLR user-defined type. CLR user-defined types are created with the statement before they can be used in a table definition. To create a column on CLR user-defined type, REFERENCES permission is required on the type.\n\nIf type_schema_name isn't specified, the SQL Server Database Engine references type_name in the following order:\n• The default schema of the current user in the current database.\n• The schema in the current database.\n\nFor memory-optimized tables, see Supported Data Types for In-Memory OLTP for a list of supported system types.\n• The precision for the specified data type. For more information about valid precision values, see Precision, Scale, and Length.\n• The scale for the specified data type. For more information about valid scale values, see Precision, Scale, and Length.\n• Applies only to the varchar, nvarchar, and varbinary data types for storing 2^31 bytes of character and binary data, and 2^30 bytes of Unicode data.\n\nSpecifies that each instance of the xml data type in column_name can contain multiple top-level elements. CONTENT applies only to the xml data type and can be specified only if xml_schema_collection is also specified. If not specified, CONTENT is the default behavior.\n\nSpecifies that each instance of the xml data type in column_name can contain only one top-level element. DOCUMENT applies only to the xml data type and can be specified only if xml_schema_collection is also specified.\n\nApplies only to the xml data type for associating an XML schema collection with the type. Before typing an xml column to a schema, the schema must first be created in the database by using CREATE XML SCHEMA COLLECTION.\n\nSpecifies the value provided for the column when a value isn't explicitly supplied during an insert. DEFAULT definitions can be applied to any columns except those defined as timestamp, or those with the property. If a default value is specified for a user-defined type column, the type should support an implicit conversion from constant_expression to the user-defined type. DEFAULT definitions are removed when the table is dropped. Only a constant value, such as a character string; a scalar function (either a system, user-defined, or CLR function); or NULL can be used as a default. To maintain compatibility with earlier versions of SQL Server, a constraint name can be assigned to a DEFAULT.\n• A constant, NULL, or a system function that is used as the default value for the column.\n• A constant, NULL, or a system function that is supported in used as the default value for the column. Must be supported in natively compiled stored procedures. For more information about built-in functions in natively compiled stored procedures, see Supported Features for Natively Compiled T-SQL Modules.\n\nIndicates that the new column is an identity column. When a new row is added to the table, the Database Engine provides a unique, incremental value for the column. Identity columns are typically used with PRIMARY KEY constraints to serve as the unique row identifier for the table. The property can be assigned to tinyint, smallint, int, bigint, decimal(p, 0), or numeric(p, 0) columns. Only one identity column can be created per table. Bound defaults and DEFAULT constraints can't be used with an identity column. Both the seed and increment or neither must be specified. If neither is specified, the default is (1,1).\n• The value used for the first row loaded into the table.\n• The incremental value added to the identity value of the previous row loaded.\n\nIn the statement, the clause can be specified for the IDENTITY property, FOREIGN KEY constraints, and CHECK constraints. If this clause is specified for the property, values aren't incremented in identity columns when replication agents perform inserts. If this clause is specified for a constraint, the constraint isn't enforced when replication agents perform insert, update, or delete operations.\n\nGENERATED ALWAYS AS { ROW | TRANSACTION_ID | SEQUENCE_NUMBER } { START | END } [ HIDDEN ] [ NOT NULL ]\n\nApplies to: SQL Server 2016 (13.x) and later, Azure SQL Database, and Azure SQL Managed Instance.\n\nSpecifies a column used by the system to automatically record information about row versions in the table and its history table (if the table is system versioned and has a history table). Use this argument with the parameter to create system-versioned tables: temporal or ledger tables. For more information, see updateable ledger tables and temporal tables.\n\nIf you attempt to specify a column that doesn't meet the above data type or nullability requirements, the system will throw an error. If you don't explicitly specify nullability, the system will define the column as or per the above requirements.\n\nYou can mark one or both period columns with flag to implicitly hide these columns such that doesn't return a value for those columns. By default, period columns aren't hidden. In order to be used, hidden columns must be explicitly included in all queries that directly reference the temporal table. To change the attribute for an existing period column, must be dropped and recreated with a different hidden flag.\n\nApplies to: SQL Server 2014 (12.x) and later, and Azure SQL Database.\n\nSpecifies to create an index on the table. This can be a clustered index, or a nonclustered index. The index will contain the columns listed, and will sort the data in either ascending or descending order.\n\nApplies to: SQL Server 2014 (12.x) and later, and Azure SQL Database.\n\nSpecifies to store the entire table in columnar format with a clustered columnstore index. This always includes all columns in the table. The data isn't sorted in alphabetical or numeric order since the rows are organized to gain columnstore compression benefits.\n\nYou can specify an order for the data in a clustered columnstore index starting with SQL Server 2022 (16.x), in Azure SQL Database, in Azure SQL Managed Instance with the Always-up-to-date update policy, and in Azure Synapse Analytics. For more information, see Performance tuning with ordered columnstore indexes.\n\nApplies to: SQL Server 2014 (12.x) and later versions, Azure SQL Database, and Azure SQL Managed Instance.\n\nSpecifies to create a nonclustered columnstore index on the table. The underlying table can be a rowstore heap or clustered index, or it can be a clustered columnstore index. In all cases, creating a nonclustered columnstore index on a table stores a second copy of the data for the columns in the index.\n\nThe nonclustered columnstore index is stored and managed as a clustered columnstore index. It is called a nonclustered columnstore index to because the columns can be limited and it exists as a secondary index on a table.\n\nYou can specify an order for the data in a nonclustered columnstore index in Azure SQL Database and in Azure SQL Managed Instance with the Always-up-to-date update policy. For more information, see Performance tuning with ordered columnstore indexes.\n\nSpecifies the partition scheme that defines the filegroups onto which the partitions of a partitioned index will be mapped. The partition scheme must exist within the database by executing either CREATE PARTITION SCHEME or ALTER PARTITION SCHEME. column_name specifies the column against which a partitioned index will be partitioned. This column must match the data type, length, and precision of the argument of the partition function that partition_scheme_name is using. column_name isn't restricted to the columns in the index definition. Any column in the base table can be specified, except when partitioning a UNIQUE index, column_name must be chosen from among those used as the unique key. This restriction allows the Database Engine to verify uniqueness of key values within a single partition only.\n\nIf partition_scheme_name or filegroup isn't specified and the table is partitioned, the index is placed in the same partition scheme, using the same partitioning column, as the underlying table.\n\nFor more information about partitioning indexes, Partitioned Tables and Indexes.\n\nCreates the specified index on the specified filegroup. If no location is specified and the table or view isn't partitioned, the index uses the same filegroup as the underlying table or view. The filegroup must already exist.\n\nCreates the specified index on the default filegroup.\n\nApplies to: SQL Server 2008 R2 (10.50.x) and later.\n\nSpecifies the placement of FILESTREAM data for the table when a clustered index is created. The FILESTREAM_ON clause allows FILESTREAM data to be moved to a different FILESTREAM filegroup or partition scheme.\n\nfilestream_filegroup_name is the name of a FILESTREAM filegroup. The filegroup must have one file defined for the filegroup by using a CREATE DATABASE or ALTER DATABASE statement; otherwise, an error is raised.\n\nIf the table is partitioned, the clause must be included, and must specify a partition scheme of FILESTREAM filegroups that uses the same partition function and partition columns as the partition scheme for the table. Otherwise, an error is raised.\n\nIf the table isn't partitioned, the FILESTREAM column can't be partitioned. FILESTREAM data for the table must be stored in a single filegroup that is specified in the clause.\n\ncan be specified in a statement if a clustered index is being created and the table doesn't contain a FILESTREAM column.\n\nFor more information, see FILESTREAM.\n\nIndicates that the new column is a row GUID column. Only one uniqueidentifier column per table can be designated as the ROWGUIDCOL column. Applying the ROWGUIDCOL property enables the column to be referenced using . The ROWGUIDCOL property can be assigned only to a uniqueidentifier column. User-defined data type columns can't be designated with ROWGUIDCOL.\n\nThe ROWGUIDCOL property doesn't enforce uniqueness of the values stored in the column. ROWGUIDCOL also doesn't automatically generate values for new rows inserted into the table. To generate unique values for each column, either use the NEWID or NEWSEQUENTIALID function on INSERT statements or use these functions as the default for the column.\n\nSpecifies encrypting columns by using the Always Encrypted feature.\n• Specifies the column encryption key. For more information, see CREATE COLUMN ENCRYPTION KEY.\n• Deterministic encryption uses a method that always generates the same encrypted value for any given plain text value. Using deterministic encryption allows searching using equality comparison, grouping, and joining tables using equality joins based on encrypted values, but can also allow unauthorized users to guess information about encrypted values by examining patterns in the encrypted column. Joining two tables on columns encrypted deterministically is only possible if both columns are encrypted using the same column encryption key. Deterministic encryption must use a column collation with a binary2 sort order for character columns. Randomized encryption uses a method that encrypts data in a less predictable manner. Randomized encryption is more secure, but it prevents any computations and indexing on encrypted columns, unless your SQL Server instance supports Always Encrypted with secure enclaves. See Always Encrypted with secure enclaves for details. If you are using Always Encrypted (without secure enclaves), use deterministic encryption for columns that will be searched with parameters or grouping parameters, for example a government ID number. Use randomized encryption, for data such as a credit card number, which isn't grouped with other records or used to join tables, and which isn't searched for because you use other columns (such as a transaction number) to find the row that contains the encrypted column of interest. If you are using Always Encrypted with secure enclaves, randomized encryption is a recommended encryption type. Columns must be of a qualifying data type.\n• Applies to: SQL Server 2016 (13.x) and later. For more information including feature constraints, see Always Encrypted.\n\nIndicates that the column is a sparse column. The storage of sparse columns is optimized for null values. Sparse columns can't be designated as NOT NULL. For additional restrictions and more information about sparse columns, see Use Sparse Columns.\n\nApplies to: SQL Server 2016 (13.x) and later.\n\nSpecifies a dynamic data mask. mask_function is the name of the masking function with the appropriate parameters. Four functions are available:\n\nApplies to: SQL Server 2008 R2 (10.50.x) and later.\n\nValid only for varbinary(max) columns. Specifies FILESTREAM storage for the varbinary(max) BLOB data.\n\nThe table must also have a column of the uniqueidentifier data type that has the ROWGUIDCOL attribute. This column must not allow null values and must have either a UNIQUE or PRIMARY KEY single-column constraint. The GUID value for the column must be supplied either by an application when inserting data, or by a DEFAULT constraint that uses the NEWID () function.\n\nThe ROWGUIDCOL column can't be dropped and the related constraints can't be changed while there is a FILESTREAM column defined for the table. The ROWGUIDCOL column can be dropped only after the last FILESTREAM column is dropped.\n\nWhen the FILESTREAM storage attribute is specified for a column, all values for that column are stored in a FILESTREAM data container on the file system.\n\nSpecifies the collation for the column. Collation name can be either a Windows collation name or a SQL collation name. collation_name is applicable only for columns of the char, varchar, text, nchar, nvarchar, and ntext data types. If not specified, the column is assigned either the collation of the user-defined data type, if the column is of a user-defined data type, or the default collation of the database.\n\nFor more information about the Windows and SQL collation names, see Windows Collation Name and SQL Collation Name.\n\nFor more information, see COLLATE.\n\nAn optional keyword that indicates the start of the definition of a PRIMARY KEY, NOT NULL, UNIQUE, FOREIGN KEY, or CHECK constraint.\n• The name of a constraint. Constraint names must be unique within the schema to which the table belongs.\n• Determine whether null values are allowed in the column. NULL isn't strictly a constraint but can be specified just like NOT NULL. NOT NULL can be specified for computed columns only if PERSISTED is also specified.\n• A constraint that enforces entity integrity for a specified column or columns through a unique index. Only one PRIMARY KEY constraint can be created per table.\n• A constraint that provides entity integrity for a specified column or columns through a unique index. A table can have multiple UNIQUE constraints.\n• Indicates that a clustered or a nonclustered index is created for the PRIMARY KEY or UNIQUE constraint. PRIMARY KEY constraints default to CLUSTERED, and UNIQUE constraints default to NONCLUSTERED. In a statement, CLUSTERED can be specified for only one constraint. If CLUSTERED is specified for a UNIQUE constraint and a PRIMARY KEY constraint is also specified, the PRIMARY KEY defaults to NONCLUSTERED.\n• A constraint that provides referential integrity for the data in the column or columns. FOREIGN KEY constraints require that each value in the column exists in the corresponding referenced column or columns in the referenced table. FOREIGN KEY constraints can reference only columns that are PRIMARY KEY or UNIQUE constraints in the referenced table or columns referenced in a UNIQUE INDEX on the referenced table. Foreign keys on computed columns must also be marked PERSISTED.\n• The name of the table referenced by the FOREIGN KEY constraint, and the schema to which it belongs.\n• A column, or list of columns, from the table referenced by the FOREIGN KEY constraint.\n• Specifies what action happens to rows in the table created, if those rows have a referential relationship and the referenced row is deleted from the parent table. The default is NO ACTION.\n• The Database Engine raises an error and the delete action on the row in the parent table is rolled back.\n• Corresponding rows are deleted from the referencing table if that row is deleted from the parent table.\n• All the values that make up the foreign key are set to NULL if the corresponding row in the parent table is deleted. For this constraint to execute, the foreign key columns must be nullable.\n• All the values that make up the foreign key are set to their default values when the corresponding row in the parent table is deleted. For this constraint to execute, all foreign key columns must have default definitions. If a column is nullable, and there is no explicit default value set, NULL becomes the implicit default value of the column. Don't specify if the table will be included in a merge publication that uses logical records. For more information about logical records, see Group Changes to Related Rows with Logical Records. can't be defined if an trigger already exists on the table. For example, in the database, the table has a referential relationship with the table. The foreign key references the primary key. If a statement is executed on a row in the table, and an action is specified for , the Database Engine checks for one or more dependent rows in the table. If any exist, the dependent rows in the table are deleted, and also the row referenced in the table. Conversely, if is specified, the Database Engine raises an error and rolls back the delete action on the row if there is at least one row in the table that references it.\n• Specifies what action happens to rows in the table altered when those rows have a referential relationship and the referenced row is updated in the parent table. The default is NO ACTION.\n• The Database Engine raises an error, and the update action on the row in the parent table is rolled back.\n• Corresponding rows are updated in the referencing table when that row is updated in the parent table.\n• All the values that make up the foreign key are set to NULL when the corresponding row in the parent table is updated. For this constraint to execute, the foreign key columns must be nullable.\n• All the values that make up the foreign key are set to their default values when the corresponding row in the parent table is updated. For this constraint to execute, all foreign key columns must have default definitions. If a column is nullable, and there is no explicit default value set, NULL becomes the implicit default value of the column. Don't specify if the table will be included in a merge publication that uses logical records. For more information about logical records, see Group Changes to Related Rows with Logical Records. , , or can't be defined if an trigger already exists on the table that is being altered. For example, in the database, the table has a referential relationship with the table: foreign key references the primary key. If an UPDATE statement is executed on a row in the table, and an ON UPDATE CASCADE action is specified for , the Database Engine checks for one or more dependent rows in the table. If any exist, the dependent rows in the table are updated, and also the row referenced in the table. Conversely, if NO ACTION is specified, the Database Engine raises an error and rolls back the update action on the row if there is at least one row in the table that references it.\n• A constraint that enforces domain integrity by limiting the possible values that can be entered into a column or columns. CHECK constraints on computed columns must also be marked PERSISTED.\n• A logical expression that returns TRUE or FALSE. Alias data types can't be part of the expression.\n• A column or list of columns, in parentheses, used in table constraints to indicate the columns used in the constraint definition.\n• Specifies the order in which the column or columns participating in table constraints are sorted. The default is ASC.\n• The name of the partition scheme that defines the filegroups onto which the partitions of a partitioned table will be mapped. The partition scheme must exist within the database.\n• Specifies the column against which a partitioned table will be partitioned. The column must match that specified in the partition function that partition_scheme_name is using in terms of data type, length, and precision. A computed column that participates in a partition function must be explicitly marked PERSISTED. We recommend that you specify NOT NULL on the partitioning column of partitioned tables, and also nonpartitioned tables that are sources or targets of ALTER TABLE...SWITCH operations. Doing this makes sure that any CHECK constraints on partitioning columns do not have to check for null values.\n• Specifies how full the Database Engine should make each index page that is used to store the index data. User-specified fillfactor values can be from 1 through 100. If a value isn't specified, the default is 0. Fill factor values 0 and 100 are the same in all respects. Documenting WITH FILLFACTOR = fillfactor as the only index option that applies to PRIMARY KEY or UNIQUE constraints is maintained for backward compatibility, but will not be documented in this manner in future releases.\n\nThe name of the column set. A column set is an untyped XML representation that combines all of the sparse columns of a table into a structured output. For more information about column sets, see Use Column Sets.\n\nApplies to: SQL Server 2016 (13.x) and later, and Azure SQL Database.\n\nSpecifies the names of the columns that the system will use to record the period for which a record is valid. Use this argument with the and arguments to create a temporal table. For more information, see Temporal Tables.\n\nApplies to: SQL Server 2016 (13.x) and later, and Azure SQL Database.\n\nFor a memory-optimized, delay specifies the minimum number of minutes a row must remain in the table, unchanged, before it is eligible for compression into the columnstore index. SQL Server selects specific rows to compress according to their last update time. For example, if rows are changing frequently during a two-hour period of time, you could set to ensure updates are completed before SQL Server compresses the row.\n\nFor a disk-based table, delay specifies the minimum number of minutes a delta rowgroup in the CLOSED state must remain in the delta rowgroup before SQL Server can compress it into the compressed rowgroup. Since disk-based tables don't track insert and update times on individual rows, SQL Server applies the delay to delta rowgroups in the CLOSED state.\n\nFor recommendations on when to use , see Get started with Columnstore for real time operational analytics\n\nSpecifies one or more table options.\n\nSpecifies the data compression option for the specified table, partition number, or range of partitions. The options are as follows:\n• Table or specified partitions are compressed by using row compression.\n• Table or specified partitions are compressed by using page compression.\n• Applies to: SQL Server 2016 (13.x) and later, and Azure SQL Database. Applies only to columnstore indexes, including both nonclustered columnstore and clustered columnstore indexes. COLUMNSTORE specifies to compress with the most performant columnstore compression. This is the typical choice.\n• Applies to: SQL Server 2016 (13.x) and later, and Azure SQL Database. Applies only to columnstore indexes, including both nonclustered columnstore and clustered columnstore indexes. COLUMNSTORE_ARCHIVE will further compress the table or partition to a smaller size. This can be used for archival, or for other situations that require a smaller storage size and can afford more time for storage and retrieval.\n\nFor more information, see Data Compression.\n\nApplies to: SQL Server 2022 (16.x) and later versions, Azure SQL Database, and Azure SQL Managed Instance.\n\nSpecifies the XML compression option for any xml data type columns in the table. The options are as follows:\n• Columns using the xml data type are compressed.\n\nSpecifies the partitions to which the or settings apply. If the table isn't partitioned, the argument will generate an error. If the clause isn't provided, the option will apply to all partitions of a partitioned table.\n\npartition_number_expression can be specified in the following ways:\n• Provide the partition number of a partition, for example:\n• Provide the partition numbers for several individual partitions separated by commas, for example:\n• Provide both ranges and individual partitions, for example:\n\ncan be specified as partition numbers separated by the word TO, for example: .\n\nTo set different types of data compression for different partitions, specify the option more than once, for example:\n\nYou can also specify the option more than once, for example:\n\nSpecifies one or more index options. For a complete description of these options, see CREATE INDEX.\n\nWhen ON, the percentage of free space specified by FILLFACTOR is applied to the intermediate level pages of the index. When OFF or a FILLFACTOR value it not specified, the intermediate level pages are filled to near capacity leaving enough space for at least one row of the maximum size the index can have, considering the set of keys on the intermediate pages. The default is OFF.\n\nSpecifies a percentage that indicates how full the Database Engine should make the leaf level of each index page during index creation or alteration. fillfactor must be an integer value from 1 to 100. The default is 0. Fill factor values 0 and 100 are the same in all respects.\n\nSpecifies the error response when an insert operation attempts to insert duplicate key values into a unique index. The IGNORE_DUP_KEY option applies only to insert operations after the index is created or rebuilt. The option has no effect when executing CREATE INDEX, ALTER INDEX, or UPDATE. The default is OFF.\n• A warning message will occur when duplicate key values are inserted into a unique index. Only the rows violating the uniqueness constraint will fail.\n• An error message will occur when duplicate key values are inserted into a unique index. The entire INSERT operation will be rolled back.\n\ncan't be set to ON for indexes created on a view, non-unique indexes, XML indexes, spatial indexes, and filtered indexes.\n\nIn backward compatible syntax, is equivalent to .\n\nWhen ON, out-of-date index statistics aren't automatically recomputed. When OFF, automatic statistics updating are enabled. The default is OFF.\n\nWhen ON, row locks are allowed when you access the index. The Database Engine determines when row locks are used. When OFF, row locks aren't used. The default is ON.\n\nWhen ON, page locks are allowed when you access the index. The Database Engine determines when page locks are used. When OFF, page locks aren't used. The default is ON.\n\nApplies to: SQL Server 2019 (15.x) and later, Azure SQL Database, and Azure SQL Managed Instance.\n\nSpecifies whether or not to optimize for last-page insert contention. The default is OFF. See the Sequential Keys section of the CREATE INDEX page for more information.\n\nApplies to: SQL Server 2012 (11.x) and later.\n\nSpecifies the windows-compatible FileTable directory name. This name should be unique among all the FileTable directory names in the database. Uniqueness comparison is case-insensitive, regardless of collation settings. If this value isn't specified, the name of the FileTable is used.\n\nApplies to: SQL Server 2012 (11.x) and later. Azure SQL Database and Azure SQL Managed Instance do not support .\n\nSpecifies the name of the collation to be applied to the column in the FileTable. The collation must be case-insensitive to comply with Windows operating system file naming semantics. If this value isn't specified, the database default collation is used. If the database default collation is case-sensitive, an error is raised, and the CREATE TABLE operation fails.\n• The name of a case-insensitive collation.\n• Specifies that the default collation for the database should be used. This collation must be case-insensitive.\n\nApplies to: SQL Server 2012 (11.x) and later. Azure SQL Database and Azure SQL Managed Instance do not support .\n\nSpecifies the name to be used for the primary key constraint that is automatically created on the FileTable. If this value isn't specified, the system generates a name for the constraint.\n\nApplies to: SQL Server 2012 (11.x) and later. Azure SQL Database and Azure SQL Managed Instance do not support .\n\nSpecifies the name to be used for the unique constraint that is automatically created on the stream_id column in the FileTable. If this value isn't specified, the system generates a name for the constraint.\n\nApplies to: SQL Server 2012 (11.x) and later. Azure SQL Database and Azure SQL Managed Instance do not support .\n\nSpecifies the name to be used for the unique constraint that is automatically created on the parent_path_locator and name columns in the FileTable. If this value isn't specified, the system generates a name for the constraint.\n\nSYSTEM_VERSIONING = ON [ ( HISTORY_TABLE = schema_name.history_table_name [ , DATA_CONSISTENCY_CHECK = { ON | OFF } ] ) ]\n\nApplies to: SQL Server 2016 (13.x) and later, Azure SQL Database, and Azure SQL Managed Instance.\n\nEnables system versioning of the table if the data type, nullability constraint, and primary key constraint requirements are met. The system will record the history of each record in the system-versioned table in a separate history table. If the argument isn't used, the name of this history table will be . If the name of a history table is specified during history table creation, you must specify the schema and table name.\n\nIf the history table doesn't exist, the system generates a new history table matching the schema of the current table in the same filegroup as the current table, creating a link between the two tables and enables the system to record the history of each record in the current table in the history table. By default, the history table is compressed.\n\nIf the argument is used to create a link to and use an existing history table, the link is created between the current table and the specified table. If current table is partitioned, the history table is created on default file group because partitioning configuration isn't replicated automatically from the current table to the history table. When creating a link to an existing history table, you can choose to perform a data consistency check. This data consistency check ensures that existing records don't overlap. Performing the data consistency check is the default.\n\nUse this argument with the and arguments to enable system versioning on a table. For more information, see Temporal Tables. Use this argument with the argument to create an updatable ledger table. Using existing history tables with ledger tables isn't allowed.\n\nApplies to: SQL Server 2016 (13.x) and later.\n\nCreates the new table with Stretch Database enabled or disabled. For more info, see Stretch Database.\n\nWhen you enable Stretch for a table by specifying , you can optionally specify to begin migrating data immediately, or to postpone data migration. The default value is . For more info about enabling Stretch for a table, see Enable Stretch Database for a table.\n\nPrerequisites. Before you enable Stretch for a table, you have to enable Stretch on the server and on the database. For more info, see Enable Stretch Database for a database.\n\nPermissions. Enabling Stretch for a database or a table requires db_owner permissions. Enabling Stretch for a table also requires ALTER permissions on the table.\n\nApplies to: SQL Server 2016 (13.x) and later.\n\nOptionally specifies a filter predicate to select rows to migrate from a table that contains both historical and current data. The predicate must call a deterministic inline table-valued function. For more info, see Enable Stretch Database for a table and Select rows to migrate by using a filter function.\n\nIf you don't specify a filter predicate, the entire table is migrated.\n\nWhen you specify a filter predicate, you also have to specify MIGRATION_STATE.\n\nApplies to: SQL Server 2016 (13.x) and later, Azure SQL Database, and Azure SQL Managed Instance.\n• None Specify to migrate data from SQL Server to Azure SQL Database.\n• None Specify to copy the remote data for the table from Azure SQL Database back to SQL Server and to disable Stretch for the table. For more info, see Disable Stretch Database and bring back remote data. This operation incurs data transfer costs, and it can't be canceled.\n• None Specify to pause or postpone data migration. For more info, see Pause and resume data migration -Stretch Database.\n\nEnables retention policy based cleanup of old or aged data from tables within a database. For more information, see Enable and Disable Data Retention. The following parameters must be specified for data retention to be enabled.\n• Specifies the column that should be used to determine if the rows in the table are obsolete or not. The following data types are allowed for the filter column.\n• Specifies the retention period policy for the table. The retention period is specified as a combination of a positive integer value and the date part unit.\n\nApplies to: SQL Server 2014 (12.x) and later, Azure SQL Database, and Azure SQL Managed Instance. Azure SQL Managed Instance does not support memory optimized tables in General Purpose tier.\n\nThe value ON indicates that the table is memory optimized. Memory-optimized tables are part of the In-Memory OLTP feature, which is used to optimize the performance of transaction processing. To get started with In-Memory OLTP see Quickstart 1: In-Memory OLTP Technologies for Faster Transact-SQL Performance. For more in-depth information about memory-optimized tables, see Memory-Optimized Tables.\n\nThe default value OFF indicates that the table is disk-based.\n\nApplies to: SQL Server 2014 (12.x) and later, Azure SQL Database, and Azure SQL Managed Instance.\n\nThe value of indicates that the table is durable, meaning that changes are persisted on disk and survive restart or failover. SCHEMA_AND_DATA is the default value.\n\nThe value of indicates that the table is non-durable. The table schema is persisted but any data updates aren't persisted upon a restart or failover of the database. is only allowed with .\n\nApplies to: SQL Server 2014 (12.x) and later, Azure SQL Database, and Azure SQL Managed Instance.\n\nIndicates the number of buckets that should be created in the hash index. The maximum value for BUCKET_COUNT in hash indexes is 1,073,741,824. For more information about bucket counts, see Indexes for Memory-Optimized Tables.\n\nApplies to: SQL Server 2014 (12.x) and later, Azure SQL Database, and Azure SQL Managed Instance.\n\nColumn and table indexes can be specified as part of the CREATE TABLE statement. For details about adding and removing indexes on memory-optimized tables, see Altering Memory-Optimized Tables\n• Applies to: SQL Server 2014 (12.x) and later, Azure SQL Database, and Azure SQL Managed Instance. Indicates that a HASH index is created. Hash indexes are supported only on memory-optimized tables.\n\nIndicates whether the table being created is a ledger table (ON) or not (OFF). The default is OFF. If the option is specified, the system creates an append-only ledger table allowing only inserting new rows. Otherwise, the system creates an updatable ledger table. An updatable ledger table also requires the argument. An updatable ledger table must also be a system-versioned table. However, an updatable ledger table doesn't have to be a temporal table (it doesn't require the parameter). If the history table is specified with and , it must not reference an existing table.\n\nA ledger database (a database created with the option) only allows the creation of ledger tables. Attempts to create a table with will raise an error. Each new table by default is created as an updatable ledger table, even if you don't specify , and will be created with default values for all other parameters.\n\nAn updatable ledger table must contain four columns, exactly one column defined with each of the following arguments:\n\nAn append-only ledger table must contain exactly one column defined with each of the following arguments:\n\nIf any of the required generated always columns isn't defined in the statement and the statement includes , the system will automatically attempt to add the column using an applicable column definition from the below list. If there is a name conflict with an already defined column, the system will raise an error.\n\nThe <ledger_view_option> specifies the schema and the name of the ledger view the system automatically creates and links to the table. If the option isn't specified, the system generates the ledger view name by appending to the name of the table being created ( ). If a view with the specified or generated name exists, the system will raise an error. If the table is an updatable ledger table, the ledger view is created as a union on the table and its history table.\n\nEach row in the ledger view represents either the creation or deletion of a row version in the ledger table. The ledger view contains all columns of the ledger table, except the generated always columns listed above. The ledger view also contains the following additional columns:\n\nTransactions that include creating ledger table are captured in sys.database_ledger_transactions.\n\nSpecifies the name of the ledger view and the names of additional columns the system adds to the ledger view.\n\nSpecifies whether the ledger table being created is append-only or updatable. The default is .\n\nSpecifies one or more ledger view options. Each of the ledger view option specifies a name of a column, the system will add to the view, in addition to the columns defined in the ledger table.\n\nSpecifies the name of the column storing the ID of the transaction that created or deleted a row version. The default column name is .\n\nSpecifies the name of the columns storing the sequence number of a row-level operation within the transaction on the table. The default column name is .\n\nSpecifies the name of the columns storing the operation type ID. The default column name is ledger_operation_type.\n\nSpecifies the name of the columns storing the operation type description. The default column name is .\n\nFor information about the number of allowed tables, columns, constraints and indexes, see Maximum Capacity Specifications for SQL Server.\n\nSpace is generally allocated to tables and indexes in increments of one extent at a time. When the option of is set to TRUE, or always prior to SQL Server 2016 (13.x), when a table or index is created, it is allocated pages from mixed extents until it has enough pages to fill a uniform extent. After it has enough pages to fill a uniform extent, another extent is allocated every time the currently allocated extents become full. For a report about the amount of space allocated and used by a table, execute .\n\nThe Database Engine doesn't enforce an order in which DEFAULT, IDENTITY, ROWGUIDCOL, or column constraints are specified in a column definition.\n\nWhen a table is created, the QUOTED IDENTIFIER option is always stored as ON in the metadata for the table, even if the option is set to OFF when the table is created.\n\nIn SQL database in Microsoft Fabric, some table features can be created but will not be mirrored into the Fabric OneLake. For more information, see Limitations of Fabric SQL database mirroring.\n\nYou can create local and global temporary tables. Local temporary tables are visible only in the current session, and global temporary tables are visible to all sessions. Temporary tables can't be partitioned.\n\nPrefix local temporary table names with single number sign ( ), and prefix global temporary table names with a double number sign ( ).\n\nTransact-SQL statements reference the temporary table by using the value specified for table_name in the statement, for example:\n\nIf more than one temporary table is created inside a single stored procedure or batch, they must have different names.\n\nIf you include a schema_name when you create or access a temporary table, it is ignored. All temporary tables are created in the schema.\n\nIf a local temporary table is created in a stored procedure or a SQL module that can be executed at the same time by several sessions, the Database Engine must be able to distinguish the tables created by the different sessions. The Database Engine does this by internally appending a unique suffix to each local temporary table name. The full name of a temporary table as stored in the table in is made up of the table name specified in the statement and the system-generated unique suffix. To allow for the suffix, table_name specified for a local temporary name can't exceed 116 characters.\n\nTemporary tables are automatically dropped when they go out of scope, unless explicitly dropped earlier by using :\n• A local temporary table created in a stored procedure is dropped automatically when the stored procedure is finished. The table can be referenced by any nested stored procedures executed by the stored procedure that created the table. The table can't be referenced by the process that called the stored procedure that created the table.\n• All other local temporary tables are dropped automatically at the end of the current session.\n• If the database-scoped configuration is set to ON (default), then global temporary tables are automatically dropped when the session that created the table ends and all other tasks have stopped referencing them. The association between a task and a table is maintained only for the life of a single Transact-SQL statement. This means that a global temporary table is dropped at the completion of the last Transact-SQL statement that was actively referencing the table when the creating session ended.\n• If the database-scoped configuration is set to OFF, then global temporary tables are only dropped using , or when the Database Engine instance restarts. For more information, see GLOBAL_TEMPORARY_TABLE_AUTO_DROP.\n\nA local temporary table created within a stored procedure or trigger can have the same name as a temporary table that was created before the stored procedure or trigger is called. However, if a query references a temporary table and two temporary tables with the same name exist at that time, it isn't defined which table the query is resolved against. Nested stored procedures can also create temporary tables with the same name as a temporary table that was created by the calling stored procedure. However, for modifications to resolve to the table that was created in the nested procedure, the table must have the same structure, with the same column names, as the table created in the calling procedure. This is shown in the following example.\n\nWhen you create local or global temporary tables, the syntax supports constraint definitions except for constraints. If a constraint is specified in a temporary table, the statement returns a warning message that states the constraint was skipped. The table is still created without the constraint. Temporary tables can't be referenced in constraints.\n\nIf a temporary table is created with a named constraint and the temporary table is created within the scope of a user-defined transaction, only one user at a time can execute the statement that creates the temp table. For example, if a stored procedure creates a temporary table with a named primary key constraint, the stored procedure can't be executed simultaneously by multiple users.\n\nGlobal temporary tables in SQL Server (table names prefixed with ) are stored in and shared among all user sessions across the entire SQL Server instance.\n\nAzure SQL Database supports global temporary tables that are also stored in but are scoped to the database level. This means that global temporary tables are shared among all user sessions within the same database. User sessions from other databases can't access global temporary tables. Otherwise, global temporary tables for Azure SQL Database follow the same syntax and semantics that SQL Server uses.\n\nSimilarly, global temporary stored procedures are also scoped to the database level in Azure SQL Database.\n\nLocal temporary tables (table names prefixed with ) are also supported for Azure SQL Database and follow the same syntax and semantics that SQL Server uses. For more information, see Temporary tables.\n\nAny user can create and access temporary objects.\n\nBefore creating a partitioned table by using CREATE TABLE, you must first create a partition function to specify how the table becomes partitioned. A partition function is created by using CREATE PARTITION FUNCTION. Second, you must create a partition scheme to specify the filegroups that will hold the partitions indicated by the partition function. A partition scheme is created by using CREATE PARTITION SCHEME. Placement of PRIMARY KEY or UNIQUE constraints to separate filegroups can't be specified for partitioned tables. For more information, see Partitioned Tables and Indexes.\n• None A table can contain only one PRIMARY KEY constraint.\n• None The index generated by a PRIMARY KEY constraint can't cause the number of indexes on the table to exceed 999 nonclustered indexes and 1 clustered index.\n• None If CLUSTERED or NONCLUSTERED isn't specified for a PRIMARY KEY constraint, CLUSTERED is used if there are no clustered indexes specified for UNIQUE constraints.\n• None All columns defined within a PRIMARY KEY constraint must be defined as NOT NULL. If nullability isn't specified, all columns participating in a PRIMARY KEY constraint have their nullability set to NOT NULL. For memory-optimized tables, the nullable key column is allowed.\n• None If a primary key is defined on a CLR user-defined type column, the implementation of the type must support binary ordering. For more information, see CLR User-Defined Types.\n• If CLUSTERED or NONCLUSTERED isn't specified for a UNIQUE constraint, NONCLUSTERED is used by default.\n• Each UNIQUE constraint generates an index. The number of UNIQUE constraints can't cause the number of indexes on the table to exceed 999 nonclustered indexes and 1 clustered index.\n• If a unique constraint is defined on a CLR user-defined type column, the implementation of the type must support binary or operator-based ordering. For more information, see CLR User-Defined Types.\n• None When a value other than NULL is entered into the column of a FOREIGN KEY constraint, the value must exist in the referenced column; otherwise, a foreign key violation error message is returned.\n• None FOREIGN KEY constraints are applied to the preceding column, unless source columns are specified.\n• None FOREIGN KEY constraints can reference only tables within the same database on the same server. Cross-database referential integrity must be implemented through triggers. For more information, see CREATE TRIGGER.\n• None FOREIGN KEY constraints can reference another column in the same table. This is referred to as a self-reference.\n• None The REFERENCES clause of a column-level FOREIGN KEY constraint can list only one reference column. This column must have the same data type as the column on which the constraint is defined.\n• None The REFERENCES clause of a table-level FOREIGN KEY constraint must have the same number of reference columns as the number of columns in the constraint column list. The data type of each reference column must also be the same as the corresponding column in the column list. The reference columns must be specified in the same order that was used when specifying the columns of the primary key or unique constraint on the referenced table.\n• None CASCADE, SET NULL or SET DEFAULT can't be specified if a column of type timestamp is part of either the foreign key or the referenced key.\n• None CASCADE, SET NULL, SET DEFAULT and NO ACTION can be combined on tables that have referential relationships with each other. If the Database Engine encounters NO ACTION, it stops and rolls back related CASCADE, SET NULL and SET DEFAULT actions. When a DELETE statement causes a combination of CASCADE, SET NULL, SET DEFAULT and NO ACTION actions, all the CASCADE, SET NULL and SET DEFAULT actions are applied before the Database Engine checks for any NO ACTION.\n• None The Database Engine doesn't have a predefined limit on either the number of FOREIGN KEY constraints a table can contain that reference other tables, or the number of FOREIGN KEY constraints that are owned by other tables that reference a specific table. Nevertheless, the actual number of FOREIGN KEY constraints that can be used is limited by the hardware configuration and by the design of the database and application. We recommend that a table contain no more than 253 FOREIGN KEY constraints, and that it be referenced by no more than 253 FOREIGN KEY constraints. The effective limit for you might be more or less depending on the application and hardware. Consider the cost of enforcing FOREIGN KEY constraints when you design your database and applications.\n• None FOREIGN KEY constraints can reference only columns in PRIMARY KEY or UNIQUE constraints in the referenced table or in a UNIQUE INDEX on the referenced table.\n• None If a foreign key is defined on a CLR user-defined type column, the implementation of the type must support binary ordering. For more information, see CLR User-Defined Types.\n• None Columns participating in a foreign key relationship must be defined with the same length and scale.\n• None A column can have only one DEFAULT definition.\n• None A DEFAULT definition can contain constant values, functions, SQL standard niladic functions, or . The following table shows the niladic functions and the values they return for the default during an INSERT statement. Name of user performing an insert. Name of user performing an insert. Name of user performing an insert. Name of user performing an insert.\n• None constant_expression in a DEFAULT definition can't refer to another column in the table, or to other tables, views, or stored procedures.\n• None DEFAULT definitions can't be created on columns with a timestamp data type or columns with an IDENTITY property.\n• None DEFAULT definitions can't be created for columns with alias data types if the alias data type is bound to a default object.\n• None A column can have any number of CHECK constraints, and the condition can include multiple logical expressions combined with AND and OR. Multiple CHECK constraints for a column are validated in the order they are created.\n• None The search condition must evaluate to a Boolean expression and can't reference another table.\n• None A column-level CHECK constraint can reference only the constrained column, and a table-level CHECK constraint can reference only columns in the same table. CHECK CONSTRAINTS and rules serve the same function of validating the data during INSERT and UPDATE statements.\n• None When a rule and one or more CHECK constraints exist for a column or columns, all restrictions are evaluated.\n• None CHECK constraints can't be defined on text, ntext, or image columns.\n• An index created for a constraint can't be dropped by using ; the constraint must be dropped by using . An index created for and used by a constraint can be rebuilt by using . For more information, see Reorganize and Rebuild Indexes.\n• Constraint names must follow the rules for identifiers, except that the name can't start with a number sign (#). If constraint_name isn't supplied, a system-generated name is assigned to the constraint. The constraint name appears in any error message about constraint violations.\n• When a constraint is violated in an , , or statement, the statement is ended. However, when is set to OFF, the transaction, if the statement is part of an explicit transaction, continues to be processed. When is set to ON, the whole transaction is rolled back. You can also use the statement with the transaction definition by checking the system function.\n• When and , row-, page-, and table-level locks are allowed when you access the index. The Database Engine chooses the appropriate lock and can escalate the lock from a row or page lock to a table lock. When and , only a table-level lock is allowed when you access the index.\n• If a table has FOREIGN KEY or CHECK CONSTRAINTS and triggers, the constraint conditions are evaluated before the trigger is executed.\n\nFor a report on a table and its columns, use or . To rename a table, use . For a report on the views and stored procedures that depend on a table, use sys.dm_sql_referenced_entities and sys.dm_sql_referencing_entities.\n\nThe nullability of a column determines whether that column can allow a null value ( ) as the data in that column. isn't zero or blank: means no entry was made or an explicit was supplied, and it typically implies that the value is either unknown or not applicable.\n\nWhen you use or to create or alter a table, database and session settings influence and possibly override the nullability of the data type that is used in a column definition. We recommend that you always explicitly define a column as NULL or NOT NULL for noncomputed columns or, if you use a user-defined data type, that you allow the column to use the default nullability of the data type. Sparse columns must always allow NULL.\n\nWhen column nullability isn't explicitly specified, column nullability follows the rules shown in the following table.\n\nWhen neither of the ANSI_NULL_DFLT options is set for the session and the database is set to the default (ANSI_NULL_DEFAULT is OFF), the default of NOT NULL is assigned.\n\nIf the column is a computed column, its nullability is always automatically determined by the Database Engine. To find out the nullability of this type of column, use the function with the AllowsNull property.\n\nSystem tables can't be enabled for compression. When you are creating a table, data compression is set to NONE, unless specified otherwise. If you specify a list of partitions or a partition that is out of range, an error will be generated. For a more information about data compression, see Data Compression.\n\nTo evaluate how changing the compression state will affect a table, an index, or a partition, use the sp_estimate_data_compression_savings stored procedure.\n\nRequires permission in the database and permission on the schema in which the table is being created.\n\nIf any columns in the statement are defined to be of a user-defined type, permission on the user-defined type is required.\n\nIf any columns in the statement are defined to be of a CLR user-defined type, either ownership of the type or permission on it is required.\n\nIf any columns in the statement have an XML schema collection associated with them, either ownership of the XML schema collection or permission on it is required.\n\nAny user can create temporary tables in .\n\nIf the statement creates a ledger table, permission is required.\n\nThe following example shows the column definition for a PRIMARY KEY constraint with a clustered index on the column of the table. Because a constraint name isn't specified, the system supplies the constraint name.\n\nA FOREIGN KEY constraint is used to reference another table. Foreign keys can be single-column keys or multicolumn keys. This following example shows a single-column FOREIGN KEY constraint on the table that references the table. Only the REFERENCES clause is required for a single-column FOREIGN KEY constraint.\n\nYou can also explicitly use the FOREIGN KEY clause and restate the column attribute. The column name doesn't have to be the same in both tables.\n\nMulticolumn key constraints are created as table constraints. In the database, the table includes a multicolumn PRIMARY KEY. The following example shows how to reference this key from another table; an explicit constraint name is optional.\n\nUNIQUE constraints are used to enforce uniqueness on nonprimary key columns. The following example enforces a restriction that the column of the table must be unique.\n\nDefaults supply a value (with the INSERT and UPDATE statements) when no value is supplied. For example, the database could include a lookup table listing the different jobs employees can fill in the company. Under a column that describes each job, a character string default could supply a description when an actual description isn't entered explicitly.\n\nIn addition to constants, DEFAULT definitions can include functions. Use the following example to get the current date for an entry.\n\nA niladic-function scan can also improve data integrity. To keep track of the user that inserted a row, use the niladic-function for USER. Don't enclose the niladic-functions with parentheses.\n\nThe following example shows a restriction made to values that are entered into the column of the table. The constraint is unnamed.\n\nThis example shows a named constraint with a pattern restriction on the character data entered into a column of a table.\n\nThis example specifies that the values must be within a specific list or follow a specified pattern.\n\nThe following example shows the complete table definitions with all constraint definitions for table created in the database. To run the sample, the table schema is changed to .\n\nG. Create a table with an xml column typed to an XML schema collection\n\nThe following example creates a table with an column that is typed to XML schema collection . The keyword specifies that each instance of the data type in column_name can contain only one top-level element.\n\nThe following example creates a partition function to partition a table or index into four partitions. Then, the example creates a partition scheme that specifies the filegroups in which to hold each of the four partitions. Finally, the example creates a table that uses the partition scheme. This example assumes the filegroups already exist in the database.\n\nBased on the values of column of , the partitions are assigned in the following ways.\n\nI. Use the UNIQUEIDENTIFIER data type in a column\n\nThe following example creates a table with a column. The example uses a PRIMARY KEY constraint to protect the table against users inserting duplicated values, and it uses the function in the constraint to provide values for new rows. The ROWGUIDCOL property is applied to the column so that it can be referenced using the $ROWGUID keyword.\n\nJ. Use an expression for a computed column\n\nThe following example shows the use of an expression ( ) for calculating the computed column.\n\nThe following example creates a table with one column defined as user-defined type , assuming that the type's assembly, and the type itself, have already been created in the current database. A second column is defined based on , and uses method of type(class) to compute a value for the column.\n\nL. Use the USER_NAME function for a computed column\n\nThe following example uses the function in the column.\n\nThe following example creates a table that has a column . If a table has one or more columns, the table must have one column.\n\nThe following example creates a table that uses row compression.\n\nApplies to: SQL Server 2022 (16.x) and later versions, Azure SQL Database, and Azure SQL Managed Instance.\n\nThe following example creates a table that uses XML compression.\n\nP. Create a table that has sparse columns and a column set\n\nThe following examples show to how to create a table that has a sparse column, and a table that has two sparse columns and a column set. The examples use the basic syntax. For more complex examples, see Use Sparse Columns and Use Column Sets.\n\nThis example creates a table that has a sparse column.\n\nThis example creates a table that has two sparse columns and a column set named .\n\nApplies to: SQL Server 2016 (13.x) and later, and Azure SQL Database.\n\nThe following examples show how to create a temporal table linked to a new history table, and how to create a temporal table linked to an existing history table. The temporal table must have a primary key defined to be enabled for the table to be enabled for system versioning. For examples showing how to add or remove system versioning on an existing table, see System Versioning in Examples. For use cases, see Temporal Tables.\n\nThis example creates a new temporal table linked to a new history table.\n\nThis example creates a new temporal table linked to an existing history table.\n\nApplies to: SQL Server 2016 (13.x) and later, and Azure SQL Database.\n\nThe following example shows how to create a system-versioned memory-optimized temporal table linked to a new disk-based history table.\n\nThis example creates a new temporal table linked to a new history table.\n\nThis example creates a new temporal table linked to an existing history table.\n\nThe following example creates a table with two encrypted columns. For more information, see Always Encrypted.\n\nThe following shows how to use NONCLUSTERED inline for disk-based tables:\n\nCreates a table with an anonymously named compound primary key. This is useful to avoid run-time conflicts where two session-scoped temp tables, each in a separate session, use the same name for a constraint.\n\nIf you explicitly name the constraint, the second session will generate an error such as:\n\nThe problem arises from the fact that while the temp table name is unique, the constraint names aren't.\n\nSession A creates a global temp table ##test in Azure SQL Database testdb1 and adds one row\n\nObtain global temp table name for a given object ID 1253579504 in (2)\n\nSession B connects to Azure SQL Database testdb1 and can access table ##test created by session A\n\nSession C connects to another database in Azure SQL Database testdb2 and wants to access ##test created in testdb1. This select fails due to the database scope for the global temp tables\n\nWhich generates the following error:\n\nThe following example creates a table with data retention enabled and a retention period of one week. This example applies to Azure SQL Edge only.\n\nThe following example creates an updatable ledger table that isn't a temporal table with an anonymous history table (the system will generate the name of the history table) and the generated ledger view name. As the names of the required generated always columns and the additional columns in the ledger view aren't specified, the columns will have the default names.\n\nThe following example creates a table that is both a temporal table and an updatable ledger table, with an anonymous history table (with a name generated by the system), the generated ledger view name and the default names of the generated always columns and the additional ledger view columns.\n\nThe following example creates a table that is both a temporal table and an updatable ledger table with the explicitly named history table, the user-specified name of the ledger view, and the user-specified names of generated always columns and additional columns in the ledger view.\n\nThe following example creates an append-only ledger table with the generated names of the ledger view and the columns in the ledger view.\n\nThe following example creates a ledger database in Azure SQL Database and an updatable ledger table using the default settings. Creating an updatable ledger table in a ledger database doesn't require using WITH (SYSTEM_VERSIONING = ON, LEDGER = ON); ."
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/tables/create-tables-database-engine?view=sql-server-ver16",
        "document": "Applies to: SQL Server 2016 (13.x) and later Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics Analytics Platform System (PDW) SQL database in Microsoft Fabric\n\nYou can create a new table, name it, and add it to an existing database, by using the table designer in SQL Server Management Studio (SSMS), or Transact-SQL.\n\nThis task requires permission in the database, and ALTER permission on the schema in which the table is being created.\n\nIf any columns in the statement are defined as a CLR user-defined type, either ownership of the type, or REFERENCES permission on it is required.\n\nIf any columns in the statement have an XML schema collection associated with them, either ownership of the XML schema collection or REFERENCES permission on it is required.\n• None In SSMS, in Object Explorer, connect to the instance of Database Engine that contains the database to be modified.\n• None In Object Explorer, expand the Databases node and then expand the database that will contain the new table.\n• None In Object Explorer, right-click the Tables node of your database and then select New Table.\n• None Type column names, choose data types, and choose whether to allow nulls for each column as shown in the following illustration:\n• None To specify more properties for a column, such as identity or computed column values, select the column and in the column properties tab, choose the appropriate properties. For more information about column properties, see Table Column Properties (SQL Server Management Studio).\n• None To specify a column as a primary key, right-click the column and select Set Primary Key. For more information, see Create Primary Keys.\n• None To create foreign key relationships, check constraints, or indexes, right-click in the Table Designer pane and select an object from the list as shown in the following illustration: For more information about these objects, see Create Foreign Key Relationships, Create Check Constraints and Indexes.\n• None By default, the table is contained in the schema. To specify a different schema for the table, right-click in the Table Designer pane and select Properties as shown in the following illustration. From the Schema dropdown list, select the appropriate schema. For more information about schemas, see Create a Database Schema.\n• None From the File menu, choose Save table name.\n• None In the Choose Name dialog box, type a name for the table and select OK.\n• None To view the new table, in Object Explorer, expand the Tables node and press F5 to refresh the list of objects. The new table is displayed in the list of tables.\n• None In Object Explorer, connect to an instance of Database Engine.\n• None On the Standard bar, select New Query.\n• None Copy and paste the following example into the query window and select Execute."
    },
    {
        "link": "https://w3schools.com/sql/sql_create_table.asp",
        "document": "The statement is used to create a new table in a database.\n\nThe column parameters specify the names of the columns of the table.\n\nThe datatype parameter specifies the type of data the column can hold (e.g. varchar, integer, date, etc.).\n\nTip: For an overview of the available data types, go to our complete Data Types Reference.\n\nThe following example creates a table called \"Persons\" that contains five columns: PersonID, LastName, FirstName, Address, and City:\n\nThe PersonID column is of type int and will hold an integer.\n\nThe LastName, FirstName, Address, and City columns are of type varchar and will hold characters, and the maximum length for these fields is 255 characters.\n\nThe empty \"Persons\" table will now look like this:\n\nTip: The empty \"Persons\" table can now be filled with data with the SQL INSERT INTO statement.\n\nA copy of an existing table can also be created using .\n\nThe new table gets the same column definitions. All columns or specific columns can be selected.\n\nIf you create a new table using an existing table, the new table will be filled with the existing values from the old table.\n\nThe following SQL creates a new table called \"TestTable\" (which is a copy of the \"Customers\" table):"
    },
    {
        "link": "https://learn.microsoft.com/en-us/azure/azure-sql/database/design-first-database-tutorial?view=azuresql",
        "document": "Azure SQL Database is a relational database-as-a-service (DBaaS) in the Microsoft Azure. In this tutorial, you learn how to:\n• Use SQL Server Management Studio (latest version) or the Azure portal Query Editor for Azure SQL Database.\n• You can also follow this same tutorial using Azure Data Studio (ADS).\n• If you don't have an Azure subscription, create a free account before you begin.\n• If you don't already have an Azure SQL Database created, visit Quickstart: Create a single database. Look for the option to use your offer to Deploy Azure SQL Database for free.\n\nSign in to the Azure portal\n\nSign in to the Azure portal.\n\nAzure SQL Database creates an IP firewall at the server-level. This firewall prevents external applications and tools from connecting to the server and any databases on the server unless a firewall rule allows their IP through the firewall. To enable external connectivity to your database, you must first add an IP firewall rule for your IP address (or IP address range). Follow these steps to create a server-level IP firewall rule.\n• None After the deployment completes, select SQL databases from the Azure portal menu or search for and select SQL databases from any page.\n• None Select yourDatabase on the SQL databases page. The overview page for your database opens, showing you the fully qualified Server name (such as ) and provides options for further configuration.\n• None Copy this fully qualified server name for use to connect to your server and databases from SQL Server Management Studio.\n• None Select Networking under Settings. Choose the Public Access tab, and then select Selected networks under Public network access to display the Firewall rules section.\n• None Select Add your client IPv4 on the toolbar to add your current IP address to a new IP firewall rule. An IP firewall rule can open port 1433 for a single IP address or a range of IP addresses.\n• None Select Save. A server-level IP firewall rule is created for your current IP address opening port 1433 on the server.\n• None Select OK and then close the Firewall settings page.\n\nYour IP address can now pass through the IP firewall. You can now connect to your database using SQL Server Management Studio or another tool of your choice. Be sure to use the server admin account you created previously.\n\nAzure SQL databases exist inside logical SQL servers. Can connect to the logical SQL server's using a login, then connect to your database. Or, using a contained user, you can connect directly to your Azure SQL database.\n\nUse SQL Server Management Studio to connect to your Azure SQL database.\n• None In the Connect to Server dialog box, enter the following information. Leave other options as default. This value is required. Use SQL Server Authentication to enter a user name and password. To connect using Microsoft Entra ID, if you're the Microsoft Entra server admin, choose Microsoft Entra MFA. For more information, see Configure and manage Microsoft Entra authentication with Azure SQL. If using SQL Server Authentication, the account that you specified when you created the server. The password for your server admin account If using SQL Server Authentication, the password that you specified when you created the server.\n• None Select Options in the Connect to server dialog box. In the Connect to database section, enter yourDatabase to connect to this database.\n• None In Object Explorer, expand Databases and then expand yourDatabase to view the objects in the sample database.\n• None In Object Explorer, right-click yourDatabase and select New Query. A blank query window opens that is connected to your database. Use the Azure portal Query editor for Azure SQL Database to connect to your Azure SQL database.\n• None Navigate to your SQL database in the Azure portal. For example, visit your Azure SQL dashboard.\n• None On your SQL database Overview page in the Azure portal, select Query editor (preview) from the left menu.\n• None On the sign-in screen under Welcome to SQL Database Query Editor, provide credentials to connect to the database. You can connect using SQL or Microsoft Entra authentication.\n• None To connect with SQL authentication, under SQL server authentication, enter a Login and Password for a user that has access to the database, and then select OK. You can always use the login and password for the server admin.\n• None To connect using Microsoft Entra ID, if you're the Microsoft Entra server admin, select Continue as <your user or group ID>. If sign-in is unsuccessful, try refreshing the page.\n• None A new query window opens, ready to accept T-SQL commands. In the object explorer, you can expand folders for Tables, Views, and Stored procedures.\n\nCreate four tables that model a student management system for universities using Transact-SQL:\n\nThe following diagram shows how these tables are related to each other. Some of these tables reference columns in other tables. For example, the table references the column of the table. Study the diagram to understand how the tables in this tutorial are related to one another. For an in-depth look at how to create effective normalized database tables, see Designing a Normalized Database. For information about choosing data types, see Data types. By default, tables are created in the default schema, meaning the two-part name of a table will be , for example.\n• None In the query window, execute the following T-SQL query to create four tables in your database: -- Create Person table CREATE TABLE Person ( PersonId INT IDENTITY PRIMARY KEY, FirstName NVARCHAR(128) NOT NULL, MiddelInitial NVARCHAR(10), LastName NVARCHAR(128) NOT NULL, DateOfBirth DATE NOT NULL ) -- Create Student table CREATE TABLE Student ( StudentId INT IDENTITY PRIMARY KEY, PersonId INT REFERENCES Person (PersonId), Email NVARCHAR(256) ) -- Create Course table CREATE TABLE Course ( CourseId INT IDENTITY PRIMARY KEY, Name NVARCHAR(50) NOT NULL, Teacher NVARCHAR(256) NOT NULL ) -- Create Credit table CREATE TABLE Credit ( StudentId INT REFERENCES Student (StudentId), CourseId INT REFERENCES Course (CourseId), Grade DECIMAL(5,2) CHECK (Grade <= 100.00), Attempt TINYINT, CONSTRAINT [UQ_studentgrades] UNIQUE CLUSTERED ( StudentId, CourseId, Grade, Attempt ) )\n• None Expand the Tables node under yourDatabase in the Object Explorer to see the four new tables you created.\n• None Create a folder called sampleData in your local workstation Downloads folder to store sample data for your database. For example, .\n• None Right-click the following links and save them into the sampleData folder.\n• None Open a new Windows command prompt window and navigate to the sampleData folder. For example, .\n• None Execute the following commands to insert sample data into the tables replacing the values for server, database, user, and password with the values for your environment. bcp Course in SampleCourseData -S <server>.database.windows.net -d <database> -U <user> -P <password> -q -c -t \",\" bcp Person in SamplePersonData -S <server>.database.windows.net -d <database> -U <user> -P <password> -q -c -t \",\" bcp Student in SampleStudentData -S <server>.database.windows.net -d <database> -U <user> -P <password> -q -c -t \",\" bcp Credit in SampleCreditData -S <server>.database.windows.net -d <database> -U <user> -P <password> -q -c -t \",\"\n\nYou have now loaded sample data into the tables you created earlier.\n\nExecute the following T-SQL queries to retrieve information from the database tables.\n\nThis first query joins all four tables to find the students taught by 'Dominick Pope' who have a grade higher than 75%. In a query window, execute the following T-SQL query:\n\nThis query joins all four tables and finds the courses in which 'Noe Coleman' has ever enrolled. In a query window, execute the following T-SQL query:\n\nAdvance to the next tutorial to learn about designing a database using Visual Studio and C#."
    },
    {
        "link": "https://stackoverflow.com/questions/78367297/create-new-tables-from-existing-tables-to-normalize-database",
        "document": "I am trying to figure out the best way to create new tables with additional columns to normalize my database. I have to add a column for the primary key made from data within the original table example: (key + year: 1-24, 2-24...).\n\nHow could I make the new table also update data automatically when the original table is updated.\n\nI'm not sure if I am going about this the right way?"
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/tables/create-foreign-key-relationships?view=sql-server-ver16",
        "document": "Applies to: SQL Server 2016 (13.x) and later versions Azure SQL Database Azure SQL Managed Instance SQL database in Microsoft Fabric\n\nThis article describes how to create foreign key relationships in SQL Server by using SQL Server Management Studio or Transact-SQL. You create a relationship between two tables when you want to associate rows of one table with rows of another.\n\nCreating a new table with a foreign key requires CREATE TABLE permission in the database, and ALTER SCHEMA permission on the schema in which the table is being created.\n\nCreating a foreign key in an existing table requires ALTER TABLE permission on the table.\n• None A foreign key constraint doesn't have to be linked only to a primary key constraint in another table. Foreign keys can also be defined to reference the columns of a constraint in another table.\n• None When a value other than is entered into the column of a constraint, the value must exist in the referenced column. Otherwise, a foreign key violation error message is returned. To make sure that all values of a composite foreign key constraint are verified, specify on all the participating columns.\n• None constraints can reference only tables within the same database on the same server. Cross-database referential integrity must be implemented through triggers. For more information, see CREATE TRIGGER (Transact-SQL).\n• None constraints can reference another column in the same table, and is referred to as a self-reference.\n• None A constraint specified at the column level can list only one reference column. This column must have the same data type as the column on which the constraint is defined.\n• None A constraint specified at the table level must have the same number of reference columns as the number of columns in the constraint column list. The data type of each reference column must also be the same as the corresponding column in the column list.\n• None The Database Engine doesn't have a predefined limit on the number of constraints a table can contain that reference other tables. The Database Engine also doesn't limit the number of constraints owned by other tables that reference a specific table. However, the actual number of constraints used is limited by the hardware configuration, and by the design of the database and application. A table can reference a maximum of 253 other tables and columns as foreign keys (outgoing references). SQL Server 2016 (13.x) and later versions increase the limit for the number of other tables and columns that can reference columns in a single table (incoming references), from 253 to 10,000. (Requires at least 130 compatibility level.) The increase has the following restrictions:\n• None Greater than 253 foreign key references are supported for and DML operations. operations aren't supported.\n• None A table with a foreign key reference to itself is still limited to 253 foreign key references.\n• None Greater than 253 foreign key references aren't currently available for columnstore indexes, or memory-optimized tables.\n• None If a foreign key is defined on a CLR user-defined type column, the implementation of the type must support binary ordering. For more information, see CLR User-Defined Types.\n• None A column of type varchar(max) can participate in a constraint only if the primary key it references is also defined as type varchar(max).\n• None In Object Explorer, right-click the table that will be on the foreign-key side of the relationship and select Design. The table opens in Create and update database tables.\n• None From the Table Designer menu, select Relationships. (See the Table Designer menu in the header, or, right-click in the empty space of the table definition, then select Relationships....)\n• The relationship appears in the Selected Relationship list with a system-provided name in the format , where the first tablename is the name of the foreign key table, and the second tablename is the name of the primary key table. This is just a default and common naming convention for the (Name) field of the foreign key object.\n• None Select the relationship in the Selected Relationship list.\n• None Select Tables and Columns Specification in the grid to the right and select the ellipses (...) to the right of the property.\n• None In the Tables and Columns dialog box, in the Primary Key dropdown list, choose the table that will be on the primary-key side of the relationship.\n• None In the grid beneath the dialog box, choose the columns contributing to the table's primary key. In the adjacent grid cell to the right of each column, choose the corresponding foreign-key column of the foreign-key table. Table Designer suggests a name for the relationship. To change this name, edit the contents of the Relationship Name text box.\n• None Choose OK to create the relationship.\n• None Close the table designer window and Save your changes for the foreign key relationship change to take effect.\n\nThe following example creates a table and defines a foreign key constraint on the column that references the column in the table in the database. The and clauses are used to ensure that changes made to table are automatically propagated to the table.\n\nThe following example creates a foreign key on the column and references the column in the table in the database."
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/tables/primary-and-foreign-key-constraints?view=sql-server-ver16",
        "document": "Applies to: SQL Server 2016 (13.x) and later versions Azure SQL Database Azure SQL Managed Instance SQL database in Microsoft Fabric\n\nPrimary keys and foreign keys are two types of constraints that can be used to enforce data integrity in SQL Server tables. These are important database objects.\n\nA table typically has a column or combination of columns that contain values that uniquely identify each row in the table. This column, or columns, is called the primary key (PK) of the table and enforces the entity integrity of the table. Because primary key constraints guarantee unique data, they're frequently defined on an identity column.\n\nWhen you specify a primary key constraint for a table, the Database Engine enforces data uniqueness by automatically creating a unique index for the primary key columns. This index also permits fast access to data when the primary key is used in queries. If a primary key constraint is defined on more than one column, values can be duplicated within one column, but each combination of values from all the columns in the primary key constraint definition must be unique.\n\nAs shown in the following illustration, the and columns in the table form a composite primary key constraint for this table. This makes sure that every row in the table has a unique combination of and . This prevents the insertion of duplicate rows.\n• A table can contain only one primary key constraint.\n• A primary key can't exceed 16 columns and a total key length of 900 bytes.\n• The index generated by a primary key constraint can't cause the number of indexes on the table to exceed 999 nonclustered indexes and 1 clustered index.\n• If clustered or nonclustered isn't specified for a primary key constraint, clustered is used if there's no clustered index on the table.\n• All columns defined within a primary key constraint must be defined as not null. If nullability isn't specified, all columns participating in a primary key constraint have their nullability set to not null.\n• If a primary key is defined on a CLR user-defined type column, the implementation of the type must support binary ordering.\n\nA foreign key (FK) is a column or combination of columns that is used to establish and enforce a link between the data in two tables to control the data that can be stored in the foreign key table. In a foreign key reference, a link is created between two tables when the column or columns that hold the primary key value for one table are referenced by the column or columns in another table. This column becomes a foreign key in the second table.\n\nFor example, the table has a foreign key link to the table because there's a logical relationship between sales orders and salespeople. The column in the table matches the primary key column of the table. The column in the table is the foreign key to the table. By creating this foreign key relationship, a value for can't be inserted into the table if it doesn't already exist in the table.\n\nA table can reference a maximum of 253 other tables and columns as foreign keys (outgoing references). SQL Server 2016 (13.x) increases the limit for the number of other tables and columns that can reference columns in a single table (incoming references), from 253 to 10,000. (Requires at least 130 compatibility level.) The increase has the following restrictions:\n• None Greater than 253 foreign key references are only supported for DML operations. and operations aren't supported.\n• None A table with a foreign key reference to itself is still limited to 253 foreign key references.\n• None Greater than 253 foreign key references aren't currently available for columnstore indexes, memory-optimized tables, Stretch Database, or partitioned foreign key tables. Stretch Database is deprecated in SQL Server 2022 (16.x) and Azure SQL Database. This feature will be removed in a future version of the Database Engine. Avoid using this feature in new development work, and plan to modify applications that currently use this feature.\n\nUnlike primary key constraints, creating a foreign key constraint doesn't automatically create a corresponding index. However, manually creating an index on a foreign key is often useful for the following reasons:\n• None Foreign key columns are frequently used in join criteria when the data from related tables is combined in queries by matching the column or columns in the foreign key constraint of one table with the primary or unique key column or columns in the other table. An index enables the Database Engine to quickly find related data in the foreign key table. However, creating this index isn't required. Data from two related tables can be combined even if no primary key or foreign key constraints are defined between the tables, but a foreign key relationship between two tables indicates that the two tables have been optimized to be combined in a query that uses the keys as its criteria.\n• None Changes to primary key constraints are checked with foreign key constraints in related tables.\n\nAlthough the main purpose of a foreign key constraint is to control the data that can be stored in the foreign key table, it also controls changes to data in the primary key table. For example, if the row for a salesperson is deleted from the table, and the salesperson's ID is used for sales orders in the table, the relational integrity between the two tables is broken; the deleted salesperson's sales orders are orphaned in the table without a link to the data in the table.\n\nA foreign key constraint prevents this situation. The constraint enforces referential integrity by guaranteeing that changes can't be made to data in the primary key table if those changes invalidate the link to data in the foreign key table. If an attempt is made to delete the row in a primary key table or to change a primary key value, the action fails when the deleted or changed primary key value corresponds to a value in the foreign key constraint of another table. To successfully change or delete a row in a foreign key constraint, you must first either delete the foreign key data in the foreign key table or change the foreign key data in the foreign key table, which links the foreign key to different primary key data.\n\nBy using cascading referential integrity constraints, you can define the actions that the Database Engine takes when a user tries to delete or update a key to which existing foreign keys point. The following cascading actions can be defined.\n• The Database Engine raises an error and the delete or update action on the row in the parent table is rolled back.\n• Corresponding rows are updated or deleted in the referencing table when that row is updated or deleted in the parent table. can't be specified if a timestamp column is part of either the foreign key or the referenced key. can't be specified for a table that has an trigger. can't be specified for tables that have triggers.\n• All the values that make up the foreign key are set to when the corresponding row in the parent table is updated or deleted. For this constraint to execute, the foreign key columns must be nullable. Can't be specified for tables that have triggers.\n• All the values that make up the foreign key are set to their default values if the corresponding row in the parent table is updated or deleted. For this constraint to execute, all foreign key columns must have default definitions. If a column is nullable, and there's no explicit default value set, becomes the implicit default value of the column. Can't be specified for tables that have triggers.\n\n, , , and can be combined on tables that have referential relationships with each other. If the Database Engine encounters , it stops and rolls back related , , and actions. When a statement causes a combination of , , , or actions, all the , , and actions are applied before the Database Engine checks for any .\n\nCascading referential actions fire the or triggers in the following manner:\n• None All the cascading referential actions directly caused by the original or are performed first.\n• None If there are any triggers defined on the affected tables, these triggers fire after all cascading actions are performed. These triggers fire in opposite order of the cascading action. If there are multiple triggers on a single table, they fire in random order, unless there's a dedicated first or last trigger for the table. This order is as specified by using sp_settriggerorder.\n• None If multiple cascading chains originate from the table that was the direct target of an or action, the order in which these chains fire their respective triggers is unspecified. However, one chain always fires all its triggers before another chain starts firing.\n• None An trigger on the table that is the direct target of an or action fires regardless of whether any rows are affected. There are no other tables affected by cascading in this case.\n• None If any one of the previous triggers performs or operations on other tables, these actions can start secondary cascading chains. These secondary chains are processed for each or operation at a time after all triggers on all primary chains fire. This process can be recursively repeated for subsequent or operations.\n• None Performing , , , or other data definition language (DDL) operations inside the triggers can cause DDL triggers to fire. This might subsequently perform DELETE or UPDATE operations that start additional cascading chains and triggers.\n• None If an error is generated inside any particular cascading referential action chain, an error is raised, no triggers are fired in that chain, and the DELETE or UPDATE operation that created the chain is rolled back.\n• None A table that has an trigger can't also have a clause that specifies a cascading action. However, an trigger on a table targeted by a cascading action can execute an , , or statement on another table or view that fires an trigger defined on that object."
    },
    {
        "link": "https://brentozar.com/archive/2017/09/enforce-foreign-key-relationships-database",
        "document": "It’s one of those fierce religious wars that divides families and tears loved ones apart.\n\nFirst, if two tables are related, should we tell SQL Server about it? If SQL Server knows that there’s a relationship, then it can make better decisions when building execution plans. The problem is that SQL Server has to be able to actually trust that relationship. Often, folks will disable keys and constraints temporarily in order to make a big operation go faster, like a bulk load, and then enable them again afterwards. However, if you don’t tell SQL Server to check the data afterwards, it simply doesn’t trust the constraints. I see it all the time in sp_Blitz warnings of “Foreign Keys or Check Constraints Not Trusted.” In those cases, the keys & constraints aren’t really helping your query plans.\n\nNext, should we have SQL Server re-check our data? Once we’ve realized that our keys & constraints aren’t trusted, what do we do about it? We’ll go re-check the keys & constraints, which is an intensive operation that other users on the box will notice. Try it on a restored copy of production first, like in your development environment, because you’re likely going to discover that some of your data doesn’t match your defined relationships. We’ve got orphans, and they’re not as adorable as Annie.\n\nThen what do we do about the bad data? You’ll need to clean that up, and it’s likely going to involve business discussions about data validity. How’d the junk get in there in the first place? How do we make sure it doesn’t happen again?\n\nFinally, do your fixes in production. Script out the changes first in dev to delete the bad data and re-check the existing keys & constraints, then do it live. The changes are going to be logged operations, so the bigger they are, the more you have to look out for log shipping subscribers, replication subscribers, database mirrors, AG replicas, etc.\n\nIs it all worth it? I’ve never seen a performance tuning case where I’ve said, “The one thing that will take you across the finish line is to have trusted foreign keys and constraints.” Usually, the simpler/easier/faster fix is to tune the queries and/or indexes. Plus, it’s an easier battle to fight with developers – who often don’t want to have any perceived overhead of enforcing foreign key relationships inside the database.\n\nEven worse, sometimes the keys are the problem. If sp_Blitz reports serializable locking, your application may be doing updates and deletes, and relying on cascading updates & deletes to clean up child records. (You can learn more about this in Klaus Aschenbrenner’s key range locks demo.)\n\nThis is why I don’t pick a side on this particular religious war – neither side is right all the time, hahaha.\n\nTo learn more about the gotchas, read Erik’s 5-part adventure in setting up foreign keys in the Stack Overflow database, and why they didn’t really pay off:"
    },
    {
        "link": "https://geeksforgeeks.org/foreign-key-in-ms-sql-server",
        "document": "A foreign key in SQL Server plays a crucial role in establishing and enforcing relationships between tables. It is a column or a set of columns in a table that references the primary key or a unique key in another table.\n\nBy using foreign key constraints the SQL Server keeps data consistent between related tables. In this article, We will learn about Foreign keys in MS SQL Server in detail by understanding various examples and so on.\n\nWhat is a Foreign key in SQL Server?\n• foreign key SQL Server is a column or a set of columns in one table that creates a relationship with the data in another table.\n• None It refers to the primary key or a unique key of another table, enforcing referential integrity between the two tables.\n• None It ensures that the value in the foreign key column corresponds to an existing value in the primary key\n• None It prevents actions that would destroy the links between tables, such as deleting a referenced row in the parent table.\n• None We can define foreign keys to enforce cascading updates or deletes to maintain data consistency.\n• None is used to define a name ( ) for the foreign key constraint. Giving the foreign key a meaningful name is good practice for easy identification.\n• None : It Specifies the column (or columns) in the child table ( ) that will store the foreign key. This column contains values that correspond to the primary or unique key in the referenced (parent) table.\n• None : It Indicates the table ( ) in the parent table that the foreign key refers to. The values in the foreign key column must match values in this referenced column, which is typically a primary or unique key.\n• None In the given tables, column in both tables can be used to establish a relationship because it is common to both.\n• None We can create a foreign key in the\n• None This ensures that every\n• None : We are modifying the\n• None : The foreign key is on the\n\nThis ensures that the values in the table must match the values in the table, maintaining referential integrity between the two tables.\n\nWhen defining a foreign key, we can also specify update and delete rules to control what happens when a referenced row in the parent table ( ) is updated or deleted.\n• None If we set this rule, any update to the ) will be automatically reflected in the child table (\n• None This ensures that if the table is modified, it gets updated in\n\nThis query modifies the `Marks` table by adding a foreign key constraint on the `Rollno` column, linking it to the `Rollno` column in the `Student` table. The `ON UPDATE CASCADE` ensures that if the `Rollno` in the `Student` table is updated, the corresponding `Rollno` in the `Marks` table is automatically updated, maintaining data consistency between the two tables.\n• None With this rule, if a row in the table is deleted, any corresponding rows in the table will also be deleted.\n• None This ensures that if a student is removed from the table, their associated marks will also be removed from the\n\nExplanation: This query modifies the `Marks` table by adding a foreign key constraint on the `Rollno` column, linking it to the `Rollno` column in the `Student` table. The `ON DELETE CASCADE` rule ensures that if a record in the `Student` table is deleted, all corresponding records in the `Marks` table (based on `Rollno`) will be automatically deleted, preserving referential integrity.\n• ON UPDATE SET NULL / ON DELETE SET NULL : When this rule is applied, if the parent record is updated or deleted, the corresponding foreign key value in the child table will be set to rather than being updated or deleted. This helps preserve the child record, but it removes the link between the child and parent by setting the foreign key to\n• ON UPDATE NO ACTION / ON DELETE NO ACTION : This is the default behavior. It prevents changes to the parent record (either update or delete) if it would violate the foreign key constraint.\n\nForeign keys are essential for maintaining referential integrity and consistency in SQL Server databases. By defining foreign key relationships and specifying update and delete rules, database administrators can ensure that changes in parent tables are appropriately reflected in child tables. These constraints help avoid orphaned records, ensure data integrity, and support efficient database design.\n\nWhat is the role of a foreign key in SQL Server?\n\nWhat happens if I delete a record from a parent table with a foreign key relationship?\n\nCan a foreign key reference a unique key other than the primary key?"
    },
    {
        "link": "https://gethynellis.com/2024/06/understanding-foreign-keys-in-sql-server.html",
        "document": "Foreign keys are a fundamental concept in relational databases, including SQL Server. They are crucial in maintaining data integrity and establishing relationships between tables. This blog post will explain the purpose and importance of foreign keys, how they relate to primary keys, the update and delete rules, and provide examples of creating foreign keys. We’ll also discuss different types of relationship cardinality.\n\nA foreign key is a column or a set of columns in one table that references the column value in rows in another table. The table containing the foreign key is called the child table, and the table with the primary key being referenced is called the parent table. The foreign key column(s) in the child table correspond to the primary key column(s) in the parent table.\n\nForeign keys enforce referential integrity between tables. This means that the foreign key values in the child table must match primary key values in the parent table, or be NULL (if allowed). This prevents orphaned records and maintains consistent and accurate data across the database.\n\nForeign keys define the relationships between tables, enabling structured and meaningful data modelling. They help you understand how data in one table relates to data in another, which is essential for complex queries and reports especially if those queries mean you need to write joins – more on that later.\n\nA foreign key constraint is a rule that maintains referential integrity between tables. When you define a foreign key constraint, SQL Server ensures that you cannot insert a value in the child table that does not exist in the parent table. It also controls what happens when you update or delete data in the parent table.\n\nWhen defining a foreign key, you can specify how updates and deletions in the parent table affect the child table:\n• NO ACTION: Prevents the update or delete operation on the parent table if there is a corresponding record in the child table.\n• CASCADE: Automatically updates or deletes the corresponding records in the child table when the parent record is updated or deleted.\n• SET NULL: Sets the foreign key column in the child table to NULL if the corresponding record in the parent table is deleted.\n• SET DEFAULT: Sets the foreign key column in the child table to its default value if the corresponding record in the parent table is deleted.\n\nLet’s look at an example to illustrate how to create a foreign key in SQL Server.\n\nSuppose we have two tables: and . Each order is placed by a customer, Therefore, the customer must exist before an order is placed. so we need to establish a relationship between these tables. Let’s use the customer table we created in yesterday’s post. And then create and an orders table\n\nIn this example:\n• is the primary key in the table.\n• in the table is a foreign key that references in the table.\n• The and options ensure that deleting or updating a customer will automatically delete or update the corresponding orders. Be very careful if you use the cascade option. Do you really want to delete all your customer orders if you delete a customer from the database\n\nEach row in the parent table relates to one and only one row in the child table. This type of relationship is rare and is typically used to split data into separate tables for organizational or security reasons.\n\nEach row in the parent table can relate to multiple rows in the child table. This is the most common type of relationship. For example, a single customer can have multiple orders.\n\nMultiple rows in the child table relate to a single row in the parent table. This is essentially the reverse of the one-to-many relationship. For instance, many orders can belong to one customer.\n\nRows in one table can relate to multiple rows in another table and vice versa. This type of relationship in a relational database requires a junction table to break down the many-to-many relationship into two one-to-many relationships. For example, a Product can be in multiple orders, and each order can have multiple products. In this case the OrderDetails table here is the junction table\n\nForeign keys are essential for maintaining referential integrity and defining relationships between tables in SQL Server. They ensure that data remains consistent and accurate, supporting complex data queries and reports. Understanding how to create and manage foreign keys, as well as the impact of update and delete rules, is crucial for effective database design and management. By leveraging foreign keys, you can build robust and reliable database systems that accurately represent the real-world relationships between different data entities.\n\nSubscribe now and take your SQL Server skills to the next level!"
    }
]