[
    {
        "link": "https://stackoverflow.com/questions/75392582/is-it-safe-to-reuse-textencoder-over-and-over-again-to-measure-string-size",
        "document": "So, a little bit of context : I have a huge CSV file (tens of millions of lines, ~17GB) that I'd like to send bit by bit. CSV file will contain non english alphabet like cyrillic and maybe some japanese characters (encoding UTF-8). lets say the chunk size is 10MB, then I want to parse row by row (not byte by byte), keep appending every parsed row to string, and once the string's byte size is at least 10MB, send the rows as chunk out to server, and then onto the next rows until all is sent. normally, you'd slice by byte, meaning, you may slice in the middle of the row. I need to keep the rows intact because server will immediately process sent rows.\n\nI know we can use\n\nHere is a pseudocode (since I'm still browsing what csv parser I want to use):\n\nI tested which is faster than , but for , since it's immutable, I need to keep spamming . So, my question is, do I also need to spam or can it be reused? Or is there a better way to achieve this in 2023? If possible, I want vanilla javascript without extra libraries."
    },
    {
        "link": "https://stackoverflow.com/questions/5515869/string-length-in-bytes-in-javascript",
        "document": "In my JavaScript code I need to compose a message to server in this format:\n\nThe data may contain unicode characters. I need to send them as UTF-8.\n\nI'm looking for the most cross-browser way to calculate the length of the string in bytes in JavaScript.\n\nI've tried this to compose my payload:\n\nBut it does not give me accurate results for the older browsers (or, maybe the strings in those browsers in UTF-16?).\n\nExample: length in bytes of the string in UTF-8 is 15 bytes, but some browsers report 23 bytes instead."
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/encodeInto",
        "document": "To convert a JavaScript string , the output space needed for full conversion is never less than bytes and never greater than bytes. The exact UTF-8-to-UTF-16 length ratio for your string depends on the language you are working with:\n• For basic English text that uses mostly ASCII characters, the ratio is close to 1.\n• For text in scripts using characters U+0080 to U+07FF, which includes Greek, Cyrillic, Hebrew, Arabic, etc., the ratio is about 2.\n• For text in scripts using characters U+0800 to U+FFFF, which includes Chinese, Japanese, Korean, etc., the ratio is about 3.\n• It's not common for entire scripts to be written in non-BMP characters (although they do exist). These characters are usually math symbols, emojis, historical scripts, etc. The ratio for these characters is 2, because they take 4 bytes in UTF-8 and 2 in UTF-16.\n\nIf the output allocation (typically within Wasm heap) is expected to be short-lived, it makes sense to allocate bytes for the output, in which case the first conversion attempt is guaranteed to convert the whole string.\n\nFor example, if your text is primarily English, it is unlikely that long text will exceed bytes in length. Thus, a more optimistic approach might be to allocate bytes, and perform reallocation in the rare circumstance that the optimistic prediction was wrong.\n\nIf the output is expected to be long-lived, it makes sense to compute minimum allocation , the maximum allocation size , and to have a chosen (as a tradeoff between memory usage and speed) threshold such that if , you allocate for . Otherwise, first allocate for and convert. If the item it the return dictionary is , the conversion is done. If not, reallocate the target buffer to and then convert the rest by taking a substring of starting from index and a subbuffer of the target buffer starting from index .\n\nAbove is a function that rounds up to the allocator bucket size. For example, if your Wasm allocator is known to use power-of-two buckets, should return the argument if it is a power-of-two or the next power-of-two otherwise. If the behavior of the Wasm allocator is unknown, should be an identity function.\n\nIf the behavior of your allocator is unknown, you might want to have up to two reallocation steps and make the first reallocation step multiply the remaining unconverted length by two instead of three. However, in that case, it makes sense not to implement the usual multiplying by two of the already written buffer length, because in such a case if a second reallocation happened, it would always over-allocate compared to the original length times three. The above advice assumes that you don't need to allocate space for a zero terminator. That is, on the Wasm side you are working with Rust strings or a non-zero-terminating C++ class. If you are working with C++ , even though the logical length is shown to you, you need to take the extra terminator byte into account when computing rounding up to allocator bucket size. See the next section about C strings."
    },
    {
        "link": "https://geeksforgeeks.org/how-to-get-the-length-of-a-string-in-bytes-in-javascript",
        "document": "How to Get the Length of a String in Bytes in JavaScript ?\n\nIn JavaScript, determining the length of a string in characters is straightforward using the property. However, in many cases, particularly when dealing with file sizes, network protocols, or database storage, you might need to know the length of a string in bytes. This is because characters can be represented using different numbers of bytes, depending on the encoding. This article explores various methods to calculate the byte length of a string in JavaScript.\n\nThe byte length of a string is important in scenarios where storage, transmission, and encoding constraints are critical, such as:\n• Database Storage : Managing data that may be stored in binary formats or with specific encoding requirements.\n\nBefore diving into the methods for calculating byte length, it’s essential to understand how text is encoded. The most common encodings are:\n• UTF-8 : Variable-length encoding that uses 1 to 4 bytes per character.\n• UTF-16 : Uses 2 or 4 bytes per character.\n• ASCII : Uses 1 byte per character (limited to 128 characters).\n\nTo achieve this we have two ways the first one is using the Blob API and the second is Buffer API, the first one works with the browser, and the second works with the Node.js environment. blob object is simply a group of bytes that holds the data stored in a file. To read the bytes of a string using blog we create a new instance of Blob object then we pass the string inside it and by using the size property we can get the bytes of a string.\n\nThe interface creates a binary large object from the string and returns its byte size. It’s useful for handling file-like data in web browsers. This approach is straightforward and works well with browser-based JavaScript.\n\nThe class in Node.js calculates the byte length of a string based on the specified encoding. It’s highly suitable for server-side applications, offering flexibility for various encodings. This method is accurate and efficient for Node.js environments.\n\nThe API provides an efficient way to encode a string into a specific format (e.g., UTF-8) and retrieve its byte length."
    },
    {
        "link": "https://labex.io/tutorials/javascript-calculating-string-byte-size-28182",
        "document": "Before we calculate the byte size of strings, it is important to understand how strings are represented in JavaScript.\n\nIn JavaScript, strings are sequences of UTF-16 code units. This means that characters like emojis or certain symbols may take more than one byte to represent. For example, a simple English letter takes 1 byte, but an emoji might take 4 bytes.\n\nLet's start by launching Node.js in the terminal:\n• Open the Terminal by clicking on the terminal icon in the WebIDE interface\n• Type the following command and press Enter:\n\nYou should now be in the Node.js interactive console, which looks something like this:\n\nIn this console, we can experiment with JavaScript code directly. Try typing the following command to see the length of a string:\n\nYou should see the output:\n\nThis gives us the character count, but not the actual byte size. The character count and byte size can be different, especially with special characters. Let's explore this further in the next step."
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder",
        "document": "Takes a string to encode and a destination to put resulting UTF-8 encoded text into, and returns an object indicating the progress of the encoding. This is potentially more performant than the older method."
    },
    {
        "link": "https://stackoverflow.com/questions/65976415/which-one-is-preferable-buffer-from-or-textencoder-encode",
        "document": "From my understanding, is Node’s original implementation of binary blobs before equivalent feature has made its way into browser JS runtime.\n\nAfter browsers went with a different API, Node runtime incorporated that as well (which makes sense from code portability standpoint), and preserved the original buffer support.\n\nAs a result, in Node there are multiple ways of achieving roughly similar results when it comes to binary blobs, where some ways will also work in browser while others won’t. / might be one of them.\n\nI’m not sure if there’s any performance gain to be had by choosing “Node classic” API over browser-compatible ."
    },
    {
        "link": "https://stackoverflow.com/questions/69684422/should-i-call-new-textencoder-for-the-each-encode-operation",
        "document": "The doesn't contain anything that would make it costly to create, so the benefit of reusing an instance would be very small. The call to the method is doing the heavy lifting, so creating the each time would normally not be a concern.\n\nYou are right that there would be no race conditions if you were to preallocate the instance.\n\nIf you really need to trim the performance of the code, you should look into the method, that places the result in an array that you provide. Reusing that array could do more for performance than reusing the instance.\n\nThe method is currently not supported in Opera, so you would likely need the polyfill that is provided on the page that I linked to."
    },
    {
        "link": "https://medium.com/@rashmipatil24/optimizing-javascript-performance-ba0d37b86e02",
        "document": "JavaScript is a powerful language that can sometimes lead to performance issues if not used optimally. In this blog, we’ll explore some best practices and tools to improve JavaScript performance. We’ll cover techniques such as minimizing reflows, using web workers, and leveraging modern APIs.\n\nReflows (or re-layouts) occur when the browser must recalculate the positions and sizes of elements in the document. They can be costly in terms of performance, especially if triggered frequently.\n\nMake multiple DOM changes in a single operation to avoid multiple reflows.\n\n2. Use for Multiple Class Changes:\n\nAvoid changing classes individually; use to add or remove multiple classes at once.\n\nMinimize reads from the DOM followed by writes. This causes multiple reflows.\n\nWeb Workers allow you to run JavaScript code in the background, without affecting the performance of the main thread. This is useful for heavy computations or tasks that otherwise block the UI.\n\nModern JavaScript APIs can significantly improve performance and enhance user experience. Some of the most useful APIs include , , and .\n\nUse this API to perform animations and visual updates. It syncs with the browser’s refresh rate, resulting in smoother animations.\n\nEfficiently observe changes in the visibility of elements, useful for lazy loading images or infinite scrolling.\n\nUse for network requests instead of the older . It’s more powerful and easier to use.\n\nUse debouncing and throttling techniques to limit the rate at which functions are executed.\n\nLoad resources only when they are needed to reduce initial load time and improve performance.\n\nSplit your code into smaller chunks that can be loaded on demand. Tools like Webpack can help with this.\n\nA tool by Google for auditing the performance, accessibility, and SEO of your web applications.\n\nA powerful module bundler that helps with code splitting and optimizing your JavaScript.\n\nOptimizing JavaScript performance is crucial for delivering fast and responsive web applications. By minimizing reflows, using web workers, leveraging modern APIs, and following best practices, you can significantly improve your application’s performance. Additionally, using tools like Lighthouse, Webpack, and Chrome DevTools can help you identify and fix performance bottlenecks. Implement these techniques and tools to ensure your JavaScript applications run smoothly and efficiently.\n\nStay tuned for more insights into the wonderful world of web development. Happy coding!"
    },
    {
        "link": "https://github.com/denoland/deno/issues/10978",
        "document": "After switching the implementation of the text encoding APIs to use , there was a user report at #10844 (comment) that the new implementation was significantly slower than the old Javascript-based one. Although the difference was to some extent reduced with #10865, the gap with the previous implementation is still large.\n\nI looked deep into it, and saw that in all cases there were conversions happening that weren't strictly needed. I'm splitting this into three changes so the effect of each individual change can be seen in the benchmarks:\n• The implementations of and call with the string input, which converts it into a scalar value string. Then they call either or , both of which convert the Javascript string into a Rust through (in the case of , through the bindings), which itself first converts the string into a scalar value string and then UTF-8 encodes it. Therefore, the WebIDL-level conversion to a scalar value string is unnecessary and can be removed.\n• After the first change, is still lagging behind. This seems to be because the operation has to run through each of the code points of the input string and UTF-8 encode them, writing the result into the output buffer. However, the input string is a Rust , meaning it is UTF-8 already, and it would be enough to simply find the last UTF-8 code point boundary that fits in the output buffer, and then copy the bytes. The number of UTF-16 code units that were read must be computed, but it seems like encoding the substring as UTF-16 to calculate the length does the trick without sacrificing much performance.\n• is an interesting case, since the only thing that could be slowing it down (other than V8 deopts or other factors that aren't related to text encoding) was the fact that returns a Rust , which is UTF-8. The bindings convert s with , which presumably has store the string as UTF-8 and only convert it to UTF-16 lazily – and since the test does nothing with the result of the decoding, there should be nothing that can be done to improve that benchmark. But in hopes of improving other cases, I patched to implement the missing two-byte string methods, added a new magic type to to make it possible to work with UTF-16 strings directly from ops, and then changed to use to decode to UTF-16 and then return that as a . And that apparently improved the benchmarks to some extent, suggesting that 's string conversion is not always lazy.\n\nAfter these changes, the three text encoding benchmarks seem to be roughly on the same level as their pure-Javascript counterparts, and the implementation in particular is slightly faster than it used to be.\n\nMy changes are in https://github.com/andreubotella/deno/tree/encoding-optimizations. Note that this is a proof of concept, and that I'm no expert on performance, so there may be places where I failed to apply some micro-optimization. But I think the benchmark results speak for themselves."
    }
]