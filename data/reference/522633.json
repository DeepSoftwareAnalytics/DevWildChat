[
    {
        "link": "https://docs.python.org/3/tutorial/errors.html",
        "document": "Until now error messages haven’t been more than mentioned, but if you have tried out the examples you have probably seen some. There are (at least) two distinguishable kinds of errors: syntax errors and exceptions.\n\nSyntax errors, also known as parsing errors, are perhaps the most common kind of complaint you get while you are still learning Python: The parser repeats the offending line and displays little arrows pointing at the place where the error was detected. Note that this is not always the place that needs to be fixed. In the example, the error is detected at the function , since a colon ( ) is missing just before it. The file name ( in our example) and line number are printed so you know where to look in case the input came from a file.\n\nEven if a statement or expression is syntactically correct, it may cause an error when an attempt is made to execute it. Errors detected during execution are called exceptions and are not unconditionally fatal: you will soon learn how to handle them in Python programs. Most exceptions are not handled by programs, however, and result in error messages as shown here: File , line , in : File , line , in : name 'spam' is not defined File , line , in : can only concatenate str (not \"int\") to str The last line of the error message indicates what happened. Exceptions come in different types, and the type is printed as part of the message: the types in the example are , and . The string printed as the exception type is the name of the built-in exception that occurred. This is true for all built-in exceptions, but need not be true for user-defined exceptions (although it is a useful convention). Standard exception names are built-in identifiers (not reserved keywords). The rest of the line provides detail based on the type of exception and what caused it. The preceding part of the error message shows the context where the exception occurred, in the form of a stack traceback. In general it contains a stack traceback listing source lines; however, it will not display lines read from standard input. Built-in Exceptions lists the built-in exceptions and their meanings.\n\nIt is possible to write programs that handle selected exceptions. Look at the following example, which asks the user for input until a valid integer has been entered, but allows the user to interrupt the program (using - or whatever the operating system supports); note that a user-generated interruption is signalled by raising the exception. \"Oops! That was no valid number. Try again...\" The statement works as follows.\n• None First, the try clause (the statement(s) between the and keywords) is executed.\n• None If no exception occurs, the except clause is skipped and execution of the statement is finished.\n• None If an exception occurs during execution of the clause, the rest of the clause is skipped. Then, if its type matches the exception named after the keyword, the except clause is executed, and then execution continues after the try/except block.\n• None If an exception occurs which does not match the exception named in the except clause, it is passed on to outer statements; if no handler is found, it is an unhandled exception and execution stops with an error message. A statement may have more than one except clause, to specify handlers for different exceptions. At most one handler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other handlers of the same statement. An except clause may name multiple exceptions as a parenthesized tuple, for example: A class in an clause matches exceptions which are instances of the class itself or one of its derived classes (but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order: Note that if the except clauses were reversed (with first), it would have printed B, B, B — the first matching except clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence and types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance which typically has an attribute that stores the arguments. For convenience, builtin exception types define to print all the arguments without explicitly accessing . # __str__ allows args to be printed directly, # but may be overridden in exception subclasses The exception’s output is printed as the last part (‘detail’) of the message for unhandled exceptions. is the common base class of all exceptions. One of its subclasses, , is the base class of all the non-fatal exceptions. Exceptions which are not subclasses of are not typically handled, because they are used to indicate that the program should terminate. They include which is raised by and which is raised when a user wishes to interrupt the program. can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific as possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate on. The most common pattern for handling is to print or log the exception and then re-raise it (allowing a caller to handle the exception as well): \"Could not convert data to an integer.\" The … statement has an optional else clause, which, when present, must follow all except clauses. It is useful for code that must be executed if the try clause does not raise an exception. For example: The use of the clause is better than adding additional code to the clause because it avoids accidentally catching an exception that wasn’t raised by the code being protected by the … statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur inside functions that are called (even indirectly) in the try clause. For example:\n\nThe statement allows the programmer to force a specified exception to occur. For example: The sole argument to indicates the exception to be raised. This must be either an exception instance or an exception class (a class that derives from , such as or one of its subclasses). If an exception class is passed, it will be implicitly instantiated by calling its constructor with no arguments: If you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the statement allows you to re-raise the exception:\n\nIf an unhandled exception occurs inside an section, it will have the exception being handled attached to it and included in the error message: File , line , in : [Errno 2] No such file or directory: 'database.sqlite' During handling of the above exception, another exception occurred: File , line , in : To indicate that an exception is a direct consequence of another, the statement allows an optional clause: # exc must be exception instance or None. This can be useful when you are transforming exceptions. For example: File , line , in File , line , in The above exception was the direct cause of the following exception: File , line , in : It also allows disabling automatic exception chaining using the idiom: For more information about chaining mechanics, see Built-in Exceptions.\n\nThe statement has another optional clause which is intended to define clean-up actions that must be executed under all circumstances. For example: If a clause is present, the clause will execute as the last task before the statement completes. The clause runs whether or not the statement produces an exception. The following points discuss more complex cases when an exception occurs:\n• None If an exception occurs during execution of the clause, the exception may be handled by an clause. If the exception is not handled by an clause, the exception is re-raised after the clause has been executed.\n• None An exception could occur during execution of an or clause. Again, the exception is re-raised after the clause has been executed.\n• None If the clause executes a , or statement, exceptions are not re-raised.\n• None If the statement reaches a , or statement, the clause will execute just prior to the , or statement’s execution.\n• None If a clause includes a statement, the returned value will be the one from the clause’s statement, not the value from the clause’s statement. As you can see, the clause is executed in any event. The raised by dividing two strings is not handled by the clause and therefore re-raised after the clause has been executed. In real world applications, the clause is useful for releasing external resources (such as files or network connections), regardless of whether the use of the resource was successful.\n\nSome objects define standard clean-up actions to be undertaken when the object is no longer needed, regardless of whether or not the operation using the object succeeded or failed. Look at the following example, which tries to open a file and print its contents to the screen. The problem with this code is that it leaves the file open for an indeterminate amount of time after this part of the code has finished executing. This is not an issue in simple scripts, but can be a problem for larger applications. The statement allows objects like files to be used in a way that ensures they are always cleaned up promptly and correctly. After the statement is executed, the file f is always closed, even if a problem was encountered while processing the lines. Objects which, like files, provide predefined clean-up actions will indicate this in their documentation.\n\nThere are situations where it is necessary to report several exceptions that have occurred. This is often the case in concurrency frameworks, when several tasks may have failed in parallel, but there are also other use cases where it is desirable to continue execution and collect multiple errors rather than raise the first exception. The builtin wraps a list of exception instances so that they can be raised together. It is an exception itself, so it can be caught like any other exception. By using instead of , we can selectively handle only the exceptions in the group that match a certain type. In the following example, which shows a nested exception group, each clause extracts from the group exceptions of a certain type while letting all other exceptions propagate to other clauses and eventually to be reraised. Note that the exceptions nested in an exception group must be instances, not types. This is because in practice the exceptions would typically be ones that have already been raised and caught by the program, along the following pattern:\n\nWhen an exception is created in order to be raised, it is usually initialized with information that describes the error that has occurred. There are cases where it is useful to add information after the exception was caught. For this purpose, exceptions have a method that accepts a string and adds it to the exception’s notes list. The standard traceback rendering includes all notes, in the order they were added, after the exception. For example, when collecting exceptions into an exception group, we may want to add context information for the individual errors. In the following each exception in the group has a note indicating when this error has occurred. | ExceptionGroup: We have some problems (3 sub-exceptions)"
    },
    {
        "link": "https://docs.python.org/3/library/exceptions.html",
        "document": "In Python, all exceptions must be instances of a class that derives from . In a statement with an clause that mentions a particular class, that clause also handles any exception classes derived from that class (but not exception classes from which it is derived). Two exception classes that are not related via subclassing are never equivalent, even if they have the same name.\n\nThe built-in exceptions listed in this chapter can be generated by the interpreter or built-in functions. Except where mentioned, they have an “associated value” indicating the detailed cause of the error. This may be a string or a tuple of several items of information (e.g., an error code and a string explaining the code). The associated value is usually passed as arguments to the exception class’s constructor.\n\nUser code can raise built-in exceptions. This can be used to test an exception handler or to report an error condition “just like” the situation in which the interpreter raises the same exception; but beware that there is nothing to prevent user code from raising an inappropriate error.\n\nThe built-in exception classes can be subclassed to define new exceptions; programmers are encouraged to derive new exceptions from the class or one of its subclasses, and not from . More information on defining exceptions is available in the Python Tutorial under User-defined Exceptions.\n\nThree attributes on exception objects provide information about the context in which the exception was raised: When raising a new exception while another exception is already being handled, the new exception’s attribute is automatically set to the handled exception. An exception may be handled when an or clause, or a statement, is used. This implicit exception context can be supplemented with an explicit cause by using with : The expression following must be an exception or . It will be set as on the raised exception. Setting also implicitly sets the attribute to , so that using effectively replaces the old exception with the new one for display purposes (e.g. converting to ), while leaving the old exception available in for introspection when debugging. The default traceback display code shows these chained exceptions in addition to the traceback for the exception itself. An explicitly chained exception in is always shown when present. An implicitly chained exception in is shown only if is and is false. In either case, the exception itself is always shown after any chained exceptions so that the final line of the traceback always shows the last exception that was raised.\n\nThe following are used when it is necessary to raise multiple unrelated exceptions. They are part of the exception hierarchy so they can be handled with like all other exceptions. In addition, they are recognised by , which matches their subgroups based on the types of the contained exceptions. Both of these exception types wrap the exceptions in the sequence . The parameter must be a string. The difference between the two classes is that extends and it can wrap any exception, while extends and it can only wrap subclasses of . This design is so that catches an but not . The constructor returns an rather than a if all contained exceptions are instances, so it can be used to make the selection automatic. The constructor, on the other hand, raises a if any contained exception is not an subclass. The argument to the constructor. This is a read-only attribute. A tuple of the exceptions in the sequence given to the constructor. This is a read-only attribute. Returns an exception group that contains only the exceptions from the current group that match condition, or if the result is empty. The condition can be an exception type or tuple of exception types, in which case each exception is checked for a match using the same check that is used in an clause. The condition can also be a callable (other than a type object) that accepts an exception as its single argument and returns true for the exceptions that should be in the subgroup. The nesting structure of the current exception is preserved in the result, as are the values of its , , , and fields. Empty nested groups are omitted from the result. The condition is checked for all exceptions in the nested exception group, including the top-level and any nested exception groups. If the condition is true for such an exception group, it is included in the result in full. Added in version 3.13: can be any callable which is not a type object. Like , but returns the pair where is and is the remaining non-matching part. Returns an exception group with the same , but which wraps the exceptions in . This method is used by and , which are used in various contexts to break up an exception group. A subclass needs to override it in order to make and return instances of the subclass rather than . and copy the , , and fields from the original exception group to the one returned by , so these fields do not need to be updated by . Note that defines , so subclasses that need a different constructor signature need to override that rather than . For example, the following defines an exception group subclass which accepts an exit_code and and constructs the group’s message from it. Like , any subclass of which is also a subclass of can only wrap instances of ."
    },
    {
        "link": "https://realpython.com/python311-exception-groups",
        "document": "Python 3.11 will be released in October 2022. Even though October is still months away, you can already preview some of the upcoming features, including the new task and exception groups that Python 3.11 has to offer. Task groups let you organize your asynchronous code better, while exception groups can collect several errors happening at the same time and let you handle them in a straightforward manner.\n• Install Python 3.11 alpha on your computer, next to your current Python installations\n• Explore how exception groups can organize several unrelated errors\n• Filter exception groups with and handle different types of errors\n• Use task groups to set up your asynchronous code\n• Test smaller improvements in Python 3.11, including exception notes and a new internal representation of exceptions\n\nThere are many other improvements and features coming in Python 3.11. Check out what’s new in the changelog for an up-to-date list.\n\nDealing with exceptions is an important part of programming. Sometimes errors happen because of bugs in your code. In those cases, good error messages will help you debug your code efficiently. Other times, errors happen through no fault of your code. Maybe the user tries to open a corrupt file, maybe the network is down, or maybe authentication to a database is missing. Usually, only one error happens at a time. It’s possible that another error would’ve happened if your code had continued to run. But Python will typically only report the first error it encounters. There are situations where it makes sense to report several bugs at once though:\n• Several concurrent tasks can fail at the same time.\n• Cleanup code can cause its own errors.\n• Code can try several different alternatives that all raise exceptions. In Python 3.11, a new feature called exception groups is available. It provides a way to group unrelated exceptions together, and it comes with a new syntax for handling them. A detailed description is available in PEP 654: Exception Groups and . PEP 654 has been written and implemented by Irit Katriel, one of CPython’s core developers, with support from maintainer Yury Selivanov and former BDFL Guido van Rossum. It was presented and discussed at the Python Language Summit in May 2021. This section will teach you how to work with exception groups. In the next section, you’ll see a practical example of concurrent code that uses exception groups to raise and handle errors from several tasks simultaneously. Before you explore exception groups, you’ll review how regular exception handling works in Python. If you’re already comfortable handling errors in Python, you won’t learn anything new in this subsection. However, this review will serve as a contrast to what you’ll learn about exception groups later. Everything you’ll see in this subsection of the tutorial works in all versions of Python 3, including Python 3.10. Exceptions break the normal flow of a program. If an exception is raised, then Python drops everything else and looks for code that handles the error. If there are no such handlers, then the program stops, regardless of what the program was doing. You can raise an error yourself using the keyword: Here, you explicitly raise a with the description . You can see that Python provides a traceback, which tells you that there’s an unhandled error. Sometimes, you raise errors like this in your code to signal that something has gone wrong. However, it’s more common to encounter errors raised by Python itself or some library that you’re using. For example, Python doesn’t let you add a string and an integer, and raises a if you attempt this: : can only concatenate str (not \"int\") to str Most exceptions come with a description that can help you figure out what went wrong. In this case, it tells you that your second term should also be a string. You use … blocks to handle errors. Sometimes, you use these to just log the error and continue running. Other times, you manage to recover from the error or calculate some alternative value instead. A short … block may look as follows: You handle exceptions by printing a message to your console. Note that because you handled the error, there’s no traceback in this example. However, other types of errors aren’t handled: : can only concatenate str (not \"int\") to str Even though the error happens within a … block, it’s not handled because there’s no clause that matches a . You can handle several kinds of errors in one block: Got bad types: can only concatenate str (not \"int\") to str This example will handle both and exceptions. Exceptions are defined in a hierarchy. For example, a is a kind of , which is a kind of . Note: Because most exceptions inherit from , you could try to simplify your error handling by using only blocks. This is usually a bad idea. You want your exception blocks to be as specific as possible, to avoid unexpected errors occurring and messing up your error handling. The first clause that matches the error will trigger the exception handling: When you try to import a module that doesn’t exist, Python raises a . However, since is a kind of , your error handling triggers the clause. Note that:\n• At most one clause will trigger\n• The first clause that matches will trigger If you’ve worked with exceptions before, this may seem intuitive. However, you’ll see later that exception groups behave differently. While at most one exception is active at a time, it’s possible to chain related exceptions. This chaining was introduced by PEP 3134 for Python 3.0. As an example, observe what happens if you raise a new exception while handling an error: : can only concatenate str (not \"int\") to str During handling of the above exception, another exception occurred: : Note the line During handling of the above exception, another exception occurred . There’s one traceback before this line, representing the original caused by your code. Then, there’s another traceback below the line, representing the new that you raised while handling the . This behavior is particularly useful if you happen to have an issue in your error handling code, because you then get information about both your original error and the bug in your error handler. You can also explicitly chain exceptions together yourself using a … statement. While you can use chained exceptions to raise several exceptions at once, note that the mechanism is meant for exceptions that are related, specificially where one exception happens during the handling of another. This is different from the use case that exception groups are designed to handle. Exception groups will group together exceptions that are unrelated, in the sense that they happen independently of each other. When handling chained exceptions, you’re only able to catch and handle the last error in the chain. As you’ll learn soon, you can catch all the exceptions in an exception group. In this subsection, you’ll explore the new class that’s available in Python 3.11. First, note that an is also a kind of : As is a subclass of , you can use Python’s regular exception handling to work with it. You can raise an with , although you probably won’t do that very often unless you’re implementing some low-level library. It’s also possible to catch an with . However, as you’ll learn in the next subsection, you’re usually better off using the new syntax. In contrast to most other exceptions, exception groups take two arguments when they’re initialized: The sequence of sub-exceptions can include other exception groups, but it can’t be empty: : second argument (exceptions) must be a non-empty sequence In this example, you’re instantiating a few different exception groups that show that exception groups can contain one exception, several exceptions, and even other exception groups. Exception groups aren’t allowed to be empty, though. Your first encounter with an exception group is likely to be its traceback. Exception group tracebacks are formatted to clearly show you the structure within the group. You’ll see a traceback when you raise an exception group: The traceback lists all exception that are part of an exception group. Additionally, the nested tree structure of exceptions within the group is indicated, both graphically and by listing how many sub-exceptions there are in each group. You learned earlier that doubles as a regular Python exception. This means that you can catch exception groups with regular blocks: This usually isn’t very helpful, because you’re more interested in the errors that are nested inside the exception group. Note that you’re not able to directly handle those: Even though the exception group contains a , you’re not able to handle it with . Instead, you should use a new syntax to handle exception groups. You’ll learn how that works in the next section. There have been attempts at handling multiple errors in earlier versions of Python. For example, the popular Trio library includes a exception that can wrap other exceptions. However, because Python is primed toward handling one error at a time, dealing with exceptions is less than ideal. The new syntax in Python 3.11 makes it more convenient to gracefully deal with several errors at the same time. Exception groups have a few attributes and methods that regular exceptions don’t have. In particular, you can access to obtain a tuple of all sub-exceptions in the group. You could, for example, rewrite the last example in the previous subsection as follows: Once you catch an , you loop over all the sub-exceptions and handle them based on their type. While this is possible, it quickly gets cumbersome. Also note that the code above doesn’t handle nested exception groups. Instead, you should use to handle exception groups. You can rewrite the example once more: Each clause handles an exception group that’s a subgroup of the original exception group, containing all exceptions matching the given type of error. Consider the slightly more involved example: Note that in this example, both clauses trigger. This is different from regular clauses, where at most one clause triggers at a time. First the is filtered from the original exception group and handled. The exceptions remain unhandled until they’re caught by . Each clause is only triggered once, even if there are more exceptions of that type. Your handling code must therefore deal with exception groups. You may end up only partially handling an exception group. For example, you could handle only from the previous example: In this case, the is handled. But that leaves two unhandled errors in the exception group. Those errors then bubble out and create a traceback. Note that the is not part of the traceback because it’s already been handled. You can see that behaves differently from :\n• clauses that match an error remove that error from the exception group. This is a clear change from how plain works, and may feel a bit unintuitive at first. However, the changes make it more convenient to deal with multiple concurrent errors. You can—although you probably don’t need to—split exception groups manually: You can use on exception groups to split them into two new exception groups. The first group consists of errors that match a given error, while the second group consists of those errors that are left over. If any of the groups end up empty, then they’re replaced by . See PEP 654 and the documentation for more information if you want to manually manipulate exception groups. Exception groups won’t replace regular exceptions! Instead, they’re designed to handle the specific use case where it’s useful to deal with several exceptions at the same time. Libraries should clearly differentiate between functions that can raise regular exceptions and functions that can raise exception groups. The authors of PEP 654 recommend that changing a function from raising an exception to raising an exception group should be considered a breaking change because anyone using that library needs to update how they handle errors. In the next section, you’ll learn about task groups. They’re new in Python 3.11 and are the first part of the standard library to raise exception groups. You’ve seen that it’s possible, but cumbersome, to deal with exception groups within regular blocks. It’s also possible to do the opposite. can handle regular exceptions: Even though you raise a single exception, the mechanism wraps the exception in an exception group before handling it. In theory, this means that you can replace all your blocks with . In practice, that would be a bad idea. Exception groups are designed to handle multiple exceptions. Don’t use them unless you need to! Exception groups are new in Python 3.11. However, if you’re using an older version of Python, then you can use the backport to access the same functionality. Instead of , the backport uses an context manager to handle multiple errors. You can learn more about catching multiple exceptions in How to Catch Multiple Exceptions in Python.\n\nYou learned about exception groups in the previous section. When would you use them? As noted, exception groups and aren’t meant to replace regular exceptions and . In fact, chances are that you don’t have a good use case for raising exception groups in your own code. They’ll likely be used mostly in low-level libraries. As Python 3.11 gets more widespread, packages that you rely on may start raising exception groups, so you may need to handle them in your applications. One of the motivating use cases for introducing exception groups is dealing with errors in concurrent code. If you have several tasks running at the same time, several of them may run into issues. Until now, Python hasn’t had a good way of dealing with that. Several asynchronous libraries, like Trio, AnyIO and Curio, have added a kind of multi-error container. But without language support, it’s still complicated to handle concurrent errors. If you’d like to see a video presentation of exception groups and their use in concurrent programming, have a look at Łukasz Langa’s presentation How Exception Groups Will Improve Error Handling in AsyncIO. In this section, you’ll explore a toy example that simulates analyzing several files concurrently. You’ll build the example from a basic synchronous application where the files are analyzed in sequence up to a full asynchronous tool that uses the new Python 3.11 task groups. Similar task groups exist in other asynchronous libraries, but the new implementation is the first to use exception groups in order to smooth out error handling. Your first versions of the analysis tool will work with older versions of Python, but you’ll need Python 3.11 to take advantage of task and exception groups in the final examples. In this subsection, you’ll implement a tool that can count the number of lines in several files. The output will be animated so that you get a nice visual representation of the distribution of file sizes. The final result will look something like this: You’ll expand this program to explore some features of asynchronous programming. While this tool isn’t necessarily useful on its own, it’s explicit so that you can clearly see what’s happening, and it’s flexible so that you can introduce several exceptions and work toward handling them with exception groups. Colorama is a library that gives you more control of output in your terminal. You’ll use it to create an animation as your program counts the number of lines in the different files. First, install it with : As the name suggests, Colorama’s primary use case is adding color to your terminal. However, you can also use it to print text at specific locations. Write the following code into a file named : The function is at the heart of the animation. It uses Colorama’s to print some text at a particular row or line in your terminal. Next, it sleeps for a short while to create the animation effect. You use to analyze and animate one file. The function opens a file and iterates through it, one line at a time. For each line, it adds a box ( ) to a string and uses to continually print the string on the same row. This creates the animation. At the end, the total number of lines is printed. Note: Positioning your terminal cursor with Colorama is a quick way to create a simple animation. However, it does mess with the regular flow of your terminal, and you may experience some issues with text being overwritten. You’ll have a smoother experience by clearing the screen before analyzing the files and by setting the cursor below your animation at the end. You can do this by adding something like the following to your main block: You can also change the number that’s added to the second argument of here and in to get a behavior that plays nicely with your terminal setup. When you find a number that works, you should do similar customizations in later examples as well. Your program’s entry point is . This loops over all filenames that you provide as command-line arguments and calls on them. Try out your line counter! You run the program by providing files that should be analyzed on the command line. For example, you can count the number of lines in your source code as follows: This counts the number of lines in . You should create a few other files that you’ll use to explore your line counter. Some of these files will expose that you’re not doing any exception handling at the moment. You can create a few new files with the following code: You’ve created three files: , , and . The first file contains the letters that map to each other in the ROT13 cipher. The second file is a completely empty file, while the third file contains some data that’s not UTF-8 encoded. As you’ll see soon, the last two files will create problems for your program. To count the number of lines in two files, you provide both their names on the command line: You call with all the arguments provided at the command line. The function then loops over each file name. If you provide the name of a file that doesn’t exist, then your program will raise an exception that tells you so: python count.py wrong_name.txt FileNotFoundError: [Errno 2] No such file or directory: 'wrong_name.txt' Something similar will happen if you try to analyze or : python count.py empty_file.txt UnboundLocalError: cannot access local variable 'line_num' where it is not associated with a value python count.py not_utf8.txt Both cases raise errors. For , the issue is that gets defined by iterating over the lines of the file. If there are no lines in the file, then isn’t defined, and you get an error when you try to access it. The problem with is that you try to UTF-8-decode something that isn’t UTF-8 encoded. In the next subsections, you’ll use these errors to explore how exception groups can help you improve your error handling. For now, observe what happens if you try to analyze two files that both raise an error: Note that only the first error, corresponding to , is raised. This is natural, because the files are analyzed sequentially. That error happens long before is opened. In this subsection, you’ll rewrite your program to run asynchronously. This means that the analysis of all the files happens concurrently instead of sequentially. It’s instructive to see your updated program run: The animation shows that lines are counted in all files at the same time, instead of in one file at the time like before. You achieve this concurrency by rewriting your functions into asynchronous coroutines using the and keywords. Note that this new version still uses old async practices, and this code is runnable in Python 3.7 and later. In the next subsection, you’ll take the final step and use the new task groups. Create a new file named with the following code: If you compare this code to from the previous subsection, then you’ll note that most changes only add to function definitions or to function calls. The and keywords constitute Python’s API for doing asynchronous programming. Note: is the library for doing asynchronous programming that’s included in Python’s standard library. However, Python’s asynchronous computing model is quite general, and you can use other third-party libraries like Trio and Curio instead of . Alternatively, you can use third-party libraries like uvloop and Quattro. These aren’t replacements for . Instead, they add performance or extra features on top of it. Next, note that has changed significantly. Instead of sequentially calling , you create one task for each file name. Each task prepares with the relevant arguments. All tasks are collected in a list and passed to . Finally, is initiated by calling . What happens here is that creates an event loop. The tasks are executed by the event loop. In the animation, it looks like all the files are analyzed at the same time. However, while the lines are counted concurrently, they’re not counted in parallel. There’s only one thread in your program, but the thread continously switches which task it’s working on. Asynchronous programming is sometimes called cooperative multitasking because each task voluntarily gives up control to let other tasks run. Think of as a marker in your code where you decide that it’s okay to switch tasks. In the example, that’s mainly when the code sleeps before the next animation step. Note: Threading achieves similar results but uses preemptive multitasking, where the operating system decides when to switch tasks. Asynchronous programming is typically easier to reason about than threading, because you know when tasks may take a break. See Speed Up Your Python Program With Concurrency for a comparison of threading, asynchronous programming, and other kinds of concurrency. Run your new code on a few different files and observe how they’re all analyzed in parallel: As your files animate in your console, you’ll see that finishes before the other tasks. Next, try to analyze a few of the troublesome files that you created earlier: Even though and are now analyzed concurrently, you only see the error raised for one of them. As you learned earlier, regular Python exceptions are handled one by one, and is limited by this. Note: You can use as an argument when awaiting . This will collect exceptions from all your tasks and return them in a list when all tasks are finished. However, it’s complicated to then handle these exceptions properly, because they’re not using Python’s normal error handling. Third-party libraries like Trio and Curio do some special error handling that’s able to deal with multiple exceptions. For example, Trio’s wraps two or more exceptions and provides a context manager that handles them. More convenient handling of multiple errors is exactly one of the use cases that exception groups were designed to handle. In your counter application, you’d want to see a group containing one exception per file that fails to be analyzed, and have a simple way of handling them. It’s time to give the new Python 3.11 a spin! Task groups have been a planned feature for for a long time. Yuri Selivanov mentions them as a possible enhancement for Python 3.8 in : What’s Next, a presentation he gave at PyBay 2018. Similar features have been available in other libraries, including Trio’s nurseries, Curio’s task groups, and Quattro’s task groups. The main reason the implementation has taken so much time is that task groups require properly dealing with several exceptions at once. The new exception group feature in Python 3.11 has paved the way for including asynchronous task groups as well. They were finally implemented by Yury Selivanov and Guido van Rossum and made available in Python 3.11.0a6. In this subsection, you’ll reimplement your counter application to use instead of . In the next subsection, you’ll use to conveniently handle the different exceptions that your application can raise. Put the following code in a file named : Compare this to . You’ll note that the only change is how tasks are created in . Here, you create the task group with a context manager. After that, your code is remarkably similar to the original synchronous implementation in : Tasks that are created inside a are run concurrently, similar to tasks run by . Counting files should work identically to before, as long as you’re using Python 3.11: One great improvement, though, is how errors are handled. Provoke your new code by analyzing some of your troublesome files: python count_taskgroup.py not_utf8.txt empty_file.txt | UnboundLocalError: cannot access local variable 'line_num' where it is | not associated with a value Note that you get an with two sub-exceptions, one for each file that fails to be analyzed. This is already an improvement over . In the next subsection, you’ll learn how you can handle these kinds of errors in your code. Yuri Selivanov points out that the new task groups offer a better API than the old , as task groups are “composable, predictable, and safe.” Additionally, he notes that task groups:\n• Run a set of nested tasks. If one fails, all other tasks that are still running would be canceled.\n• Allow to execute code (incl. awaits) between scheduling nested tasks.\n• Thanks to ExceptionGroups, all errors are propagated and can be handled/reported. In the next subsection, you’ll experiment with handling and reporting errors in your concurrent code. You’ve written some concurrent code that sometimes raises errors. How can you handle those exceptions properly? You’ll see examples of error handling soon. First, though, you’ll add one more way that your code can fail. The problems in your code that you’ve seen so far all raise before the analysis of the file begins. To simulate an error that may happen during the analysis, say that your tool suffers from triskaidekaphobia, meaning that it’s irrationally afraid of the number thirteen. Add two lines to : \"Files with thirteen lines are too scary!\" If a file has exactly thirteen lines, then a is raised at the end of the analysis. You can see the effect of this by analyzing : python count_taskgroup.py rot13.txt | raise RuntimeError(\"Files with thirteen lines are too scary!\") | RuntimeError: Files with thirteen lines are too scary! As expected, your new triskaidekaphobic code balks at the thirteen lines in . Next combine this with one of the errors you saw earlier: This time around, only one error is reported even though you know both files should raise an exception. The reason you get only one error is that the two issues would be raised at different times. One feature of task groups is that they implement a cancel scope. Once some tasks fail, other tasks in the same task group are canceled by the event loop. Note: Cancel scopes were pioneered by Trio. The final implementation of cancel scopes and which features they’ll support in is still being discussed. The following examples work in Python 3.11.0a7, but things may still change before Python 3.11 is finalized. In general, there are two approaches that you can take to handle errors inside your asynchronous tasks:\n• Use regular … blocks inside your coroutines to handle issues.\n• Use the new … blocks outside your task groups to handle issues. In the first case, errors in one task will typically not affect other running tasks. In the second case, however, an error in one task will cancel all other running tasks. Try this out for yourself! First, add which uses regular exception handling inside your coroutines: You also change to call the new instead of . In this implementation, you only deal with the raised whenever a file has thirteen lines. Note: doesn’t use any specific features of task groups. You could use a similar function to make and more robust as well. Analyze and some other files to confirm that the error no longer cancels the other tasks: python count_taskgroup.py count.py rot13.txt count_taskgroup.py Files with thirteen lines are too scary! Errors that are handled don’t bubble up and affect other tasks. In this example, and were properly analyzed even though the analysis of failed. Next, try to use to handle errors after the fact. You can, for example, wrap your event loop in a … block: Recall that works with exception groups. In this case, you loop through the exceptions in the group and print their first fifty characters to the console to log them. Analyze together with some other files to see the effect: In contrast to the previous example, the other tasks are canceled even though you handle the . Note that only one line is counted in both and . Note: You can wrap the call to inside a regular … block in the and examples. However, this will only allow you to deal with at most one error. In contrast, task groups can report all errors: python count_taskgroup.py not_utf8.txt count_taskgroup.py empty.txt Empty file: [\"cannot access local variable 'line_num' where it i\"] This example shows the result of having several concurrent errors after you expand the code in the previous example to deal with both and . If you don’t handle all exceptions that are raised, then the unhandled exceptions will still cause your program to crash with a traceback. To see this, switch to in your analysis: python count_taskgroup.py rot13.txt not_utf8.txt empty_file.txt | UnboundLocalError: cannot access local variable 'line_num' where it is | not associated with a value You get the familiar . Note that part of the error message points out that there’s one unhandled sub-exception. There’s no record in the traceback of the sub-exception that you did handle. You’ve now seen an example of using task groups in order to improve the error handling of your asynchronous application, and in particular being able to comfortably handle several errors happening at the same time. The combination of exception groups and task groups makes Python a very capable language for doing asynchronous programming.\n\nIn every new version of Python, a handful of features get most of the buzz. However, most of the evolution of Python has happened in small steps, by adding a function here or there, improving some existing functionality, or fixing a long-standing bug. Python 3.11 is no different. This section shows a few of the smaller improvements waiting for you in Python 3.11. You can now add custom notes to an exception. This is yet another improvement to how exceptions are handled in Python. Exception notes were suggested by Zac Hatfield-Dodds in PEP 678: Enriching Exceptions with Notes. The PEP has been accepted, and an early version of the proposal was implemented for Python 3.11.0a3 to Python 3.11.0a7. In those alpha versions, you can assign strings to a attribute on an exception, and that information will be made available if the error isn’t handled. Here’s a basic example: You’re adding a note to the before reraising it. Your note is then displayed together with the regular error message at the end of your traceback. Note: The rest of this section was updated on May 9, 2022 to reflect changes to the exception notes feature that was made available with the release of Python 3.11.0b1. During discussions of the PEP was changed to which can contain several notes. A list of notes can be useful in certain use cases where keeping track of individual notes is important. One example of this is internationalization and translation of notes. There is a also new dedicated method, , that can be used to add these notes. The full implementation of PEP 678 is available in the first beta version of Python 3.11 and later. Going forward, you should write the previous example as follows: You can add several notes with repeated calls to and recover them by looping over . All notes will be printed below the traceback when the exception is raised: The new exception notes are also compatible with the exception groups. Internally, Python has represented an exception as a tuple with information about the type of the exception, the exception itself, and the traceback of the exception. This changes in Python 3.11. Now, Python will internally store only the exception itself. Both the type and the traceback can be derived from the exception object. In general, you won’t need to think about this change, as it’s all under the hood. However, if you need to access an active exception, you can now use the new function in the module: Note that you usually won’t use in normal error handling like above. Instead, it’s sometimes handy to use in wrapper libraries that are used in error handling but don’t have direct access to active exceptions. In normal error handling, you should name your errors in the clause: In versions prior to Python 3.11, you can get the same information from : Indeed, is identical to . The new function was added in bpo-46328 by Irit Katriel, although the idea was originally floated in PEP 3134, all the way back in 2005. As noted in the previous subsection, older versions of Python represent exceptions as tuples. You can access traceback information in two different ways: Note that accessing the traceback through and returns the exact same object. In general, this is what you want. However, it turns out that there has been a subtle bug hiding around for some time. You can update the traceback on without updating . To demonstrate this, code up the following program, which changes the traceback during handling of an exception: You change the traceback of the active exception on line 18. As you’ll soon see, this wouldn’t update the traceback part of the exception tuple in Python 3.10 and earlier. To show this, lines 20 to 22 compare the last frame of the tracebacks referenced by the active exception and the traceback object. Run this with Python 3.10 or an earlier version: The important thing to note here is that the two line references are different. The active exception points to the updated location, line 11 inside , while the traceback points to the old location inside . In Python 3.11, the traceback part of the exception tuple is always read from the exception itself. Therefore, the inconsistency is gone: Now, both ways of accessing the traceback give the same result. This fixes a bug that has been present in Python for some time. Still, it’s important to note that the inconsistency was mostly academic. Yes, the old way was wrong, but it’s unlikely that it caused issues in actual code. This bug fix is interesting because it lifts the curtain on something bigger. As you learned in the previous subsection, Python’s internal representation of exceptions changes in version 3.11. This bug fix is an immediate consequence of that change. Restructuring Python’s exceptions is part of an even bigger effort to optimize many different parts of Python. Mark Shannon has initiated the faster-cpython project. Streamlining exceptions is only one of the ideas coming out of that initiative. The smaller improvements that you’ve learned about in this section examplify all the work that goes into maintaining and developing a programming language, beyond the few items stealing most of the headlines. The features that you’ve learned about here are all related to Python’s exception handling. However, there are many other small changes happening as well. What’s New In Python 3.11 keeps track of all of them."
    },
    {
        "link": "https://datacamp.com/tutorial/exception-handling-python",
        "document": "Master the basics of data analysis with Python in just four hours. This online course will introduce the Python interface and explore popular packages."
    },
    {
        "link": "https://blog.derlin.ch/diving-deeper-into-python-exceptions",
        "document": "I have been coding in Python for a long time, yet I am puzzled by how little I knew about s. This post is about some of my recent findings on this topic.\n• None Exception chaining (and the magic of )\n• None Bare except vs except Exception\n\nI had an interesting use case at work lately: some external library code was \"swallowing\" another exception, and I needed to get back the message of the initial one somehow, without touching the library itself.\n\nThe library code looked something like this:\n\nI had no clue how to do this except to override the class in my codebase. When I asked my boss about this, he looked at me and said: \"just use \". Huh? Never heard of it. I started digging, and long story short: he was right. This was the perfect solution.\n\nThose small discoveries happened a lot lately, and I wanted to share them. If this intrigues you, keep reading!\n\nException chaining (and the magic of )\n\nSo, what is this ??\n\nFormalised in PEP 3134 (I love PEPs), exceptions in Python 3 have three dunder attributes that provide information about the context in which they were raised: , and . To understand, let's first make sense of implicit and explicit exception chaining.\n\nAn exception chain starts when a new exception is raised during the handling of another, for example from an clause:\n\nThis is called an implicit chain (hence the \"During handling ...\"). To make it explicit and clearly state an exception is the cause of another, one can use the special :\n\nAs you can see, we now have another log message: \"was the direct cause of\". Of course, chains can be longer than two.\n\nTo go back to the context attributes of an exception:\n• None When raising a new exception while another exception is already being handled (in , or ), the new exception’s attribute is automatically set to the handled exception.\n• None When using , the supplied exception will additionally be saved in the attribute of the raised exception, and will be set to true.\n\nThe default traceback uses those attributes to display stacktraces in the following way:\n• None if is present, always show it\n• None if is , show the only if is false.\n\nTo ensure you followed, what does this valid Python code prints?\n\nIt only shows the , because the will set the (to ) and the (to true).\n\nNow, this doesn't completely swallow the original exception. Even when using a , the initial is still in the , just ignored when printing the stacktrace.\n\nBack to the problem in the introduction, I simply catch the exception raised by the library (in ), and then use to get the initial exception message.\n\nBare except vs except Exception\n\nI learned this one from the ruff rule bare-except (E722). When you don't care about which exception is raised, you may be tempted to use a bare except (but should NOT):\n\nThis thus catches , but also , , and other fatal errors, making it hard to interrupt the program (e.g., with Ctrl-C) and potentially disguising other problems or leaving the program in an unexpected state.\n\nSo instead, always specify an exception type, or simply if you are in doubt:\n\nWhen re-raising inside an clause, you don't need to pass an argument to , as it re-raises the caught exception by default.\n\nSimilarly, when raising an exception with no argument, no need for parentheses. If an exception class is passed to , it will be implicitly instantiated by calling its constructor with no arguments.\n\nHence the following is perfectly valid and more concise (see ruff rule unnecessary-paren-on-raise-exception (RSE102)):\n\nSince Python 3.11, it is possible to attach notes to exceptions, effectively enriching their context. This is a very interesting feature, that could replace re-raising an exception with a different message.\n\nThose notes are saved in the attribute (list of strings).\n\nIf you look at the Python documentation, you will see some strange built-in exceptions such as , , etc. They all inherit from (which itself inherits from ) but they are NOT meant to be raised. Instead, they are used as warning categories.\n\nIn short, exceptions are to be used with the module. There is much more to it, but let's look at a simple example:\n\nWhat is nice about is that users have complete control over what is reported, thanks to the warning filter:\n\nFor all available filters, see The Warnings Filter.\n\nSo, why use exceptions for that? You guessed it, it simplifies turning warnings into exceptions ( filter): one just has to raise it.\n\nThis article is already way too long, so here is a bullet list of other interesting subjects and picks:\n• None Python 3.11 introduced , a nice way to pack multiple exceptions into one. The new syntax allows filtering groups efficiently. Find out more in the documentation.\n• None Python supports try-except-else-finally, although I never found a good use case for the (also supported in loops). The block is executed after the block, but before the block (if the block doesn't run). Exceptions raised inside the block are not caught by the . See Handling exceptions for more info.\n• None The (not to confuse with the constant ) signals a missing implementation that should come one day. If the feature will never be implemented, raise a instead.\n• None Exceptions store their arguments in the attribute.\n• None I am always tempted to name my custom exception classes with the suffix (a remnant of Java perhaps?). However, PEP 8 clearly states we should use the suffix for exception class names.\n• None It is possible to catch multiple exceptions using parentheses:\n• None Never in a : this will override whatever you may have inside the or the .\n\nI haven't written in a while, so I hope you enjoyed this article."
    },
    {
        "link": "https://docs.python.org/3/library/logging.html",
        "document": "This module defines functions and classes which implement a flexible event logging system for applications and libraries.\n\nThe key benefit of having the logging API provided by a standard library module is that all Python modules can participate in logging, so your application log can include your own messages integrated with messages from third-party modules.\n\nIf you run myapp.py, you should see this in myapp.log:\n\nThe key feature of this idiomatic usage is that the majority of code is simply creating a module level logger with , and using that logger to do any needed logging. This is concise, while allowing downstream code fine-grained control if needed. Logged messages to the module-level logger get forwarded to handlers of loggers in higher-level modules, all the way up to the highest-level logger known as the root logger; this approach is known as hierarchical logging.\n\nFor logging to be useful, it needs to be configured: setting the levels and destinations for each logger, potentially changing how specific modules log, often based on command-line arguments or application configuration. In most cases, like the one above, only the root logger needs to be so configured, since all the lower level loggers at module level eventually forward their messages to its handlers. provides a quick way to configure the root logger that handles many use cases.\n\nThe module provides a lot of functionality and flexibility. If you are unfamiliar with logging, the best way to get to grips with it is to view the tutorials (see the links above and on the right).\n\nThe basic classes defined by the module, together with their attributes and methods, are listed in the sections below.\n• None Loggers expose the interface that application code directly uses.\n• None Handlers send the log records (created by loggers) to the appropriate destination.\n• None Filters provide a finer grained facility for determining which log records to output.\n• None Formatters specify the layout of log records in the final output.\n\nLoggers have the following attributes and methods. Note that Loggers should NEVER be instantiated directly, but always through the module-level function . Multiple calls to with the same name will always return a reference to the same Logger object. The is potentially a period-separated hierarchical value, like (though it could also be just plain , for example). Loggers that are further down in the hierarchical list are children of loggers higher up in the list. For example, given a logger with a name of , loggers with names of , , and are all descendants of . In addition, all loggers are descendants of the root logger. The logger name hierarchy is analogous to the Python package hierarchy, and identical to it if you organise your loggers on a per-module basis using the recommended construction . That’s because in a module, is the module’s name in the Python package namespace. This is the logger’s name, and is the value that was passed to to obtain the logger. This attribute should be treated as read-only. The threshold of this logger, as set by the method. Do not set this attribute directly - always use , which has checks for the level passed to it. The parent logger of this logger. It may change based on later instantiation of loggers which are higher up in the namespace hierarchy. This value should be treated as read-only. If this attribute evaluates to true, events logged to this logger will be passed to the handlers of higher level (ancestor) loggers, in addition to any handlers attached to this logger. Messages are passed directly to the ancestor loggers’ handlers - neither the level nor filters of the ancestor loggers in question are considered. If this evaluates to false, logging messages are not passed to the handlers of ancestor loggers. Spelling it out with an example: If the propagate attribute of the logger named evaluates to true, any event logged to via a method call such as will [subject to passing that logger’s level and filter settings] be passed in turn to any handlers attached to loggers named , and the root logger, after first being passed to any handlers attached to . If any logger in the chain , , has its attribute set to false, then that is the last logger whose handlers are offered the event to handle, and propagation stops at that point. The constructor sets this attribute to . If you attach a handler to a logger and one or more of its ancestors, it may emit the same record multiple times. In general, you should not need to attach a handler to more than one logger - if you just attach it to the appropriate logger which is highest in the logger hierarchy, then it will see all events logged by all descendant loggers, provided that their propagate setting is left set to . A common scenario is to attach handlers only to the root logger, and to let propagation take care of the rest. The list of handlers directly attached to this logger instance. This attribute should be treated as read-only; it is normally changed via the and methods, which use locks to ensure thread-safe operation. This attribute disables handling of any events. It is set to in the initializer, and only changed by logging configuration code. This attribute should be treated as read-only. Sets the threshold for this logger to level. Logging messages which are less severe than level will be ignored; logging messages which have severity level or higher will be emitted by whichever handler or handlers service this logger, unless a handler’s level has been set to a higher severity level than level. When a logger is created, the level is set to (which causes all messages to be processed when the logger is the root logger, or delegation to the parent when the logger is a non-root logger). Note that the root logger is created with level . The term ‘delegation to the parent’ means that if a logger has a level of NOTSET, its chain of ancestor loggers is traversed until either an ancestor with a level other than NOTSET is found, or the root is reached. If an ancestor is found with a level other than NOTSET, then that ancestor’s level is treated as the effective level of the logger where the ancestor search began, and is used to determine how a logging event is handled. If the root is reached, and it has a level of NOTSET, then all messages will be processed. Otherwise, the root’s level will be used as the effective level. See Logging Levels for a list of levels. Changed in version 3.2: The level parameter now accepts a string representation of the level such as ‘INFO’ as an alternative to the integer constants such as . Note, however, that levels are internally stored as integers, and methods such as e.g. and will return/expect to be passed integers. Indicates if a message of severity level would be processed by this logger. This method checks first the module-level level set by and then the logger’s effective level as determined by . Indicates the effective level for this logger. If a value other than has been set using , it is returned. Otherwise, the hierarchy is traversed towards the root until a value other than is found, and that value is returned. The value returned is an integer, typically one of , etc. Returns a logger which is a descendant to this logger, as determined by the suffix. Thus, would return the same logger as would be returned by . This is a convenience method, useful when the parent logger is named using e.g. rather than a literal string. Returns a set of loggers which are immediate children of this logger. So for example might return a set containing loggers named and , but a logger named wouldn’t be included in the set. Likewise, might return a set including a logger named , but it wouldn’t include one named . Logs a message with level on this logger. The msg is the message format string, and the args are the arguments which are merged into msg using the string formatting operator. (Note that this means that you can use keywords in the format string, together with a single dictionary argument.) No % formatting operation is performed on msg when no args are supplied. There are four keyword arguments in kwargs which are inspected: exc_info, stack_info, stacklevel and extra. If exc_info does not evaluate as false, it causes exception information to be added to the logging message. If an exception tuple (in the format returned by ) or an exception instance is provided, it is used; otherwise, is called to get the exception information. The second optional keyword argument is stack_info, which defaults to . If true, stack information is added to the logging message, including the actual logging call. Note that this is not the same stack information as that displayed through specifying exc_info: The former is stack frames from the bottom of the stack up to the logging call in the current thread, whereas the latter is information about stack frames which have been unwound, following an exception, while searching for exception handlers. You can specify stack_info independently of exc_info, e.g. to just show how you got to a certain point in your code, even when no exceptions were raised. The stack frames are printed following a header line which says: This mimics the which is used when displaying exception frames. The third optional keyword argument is stacklevel, which defaults to . If greater than 1, the corresponding number of stack frames are skipped when computing the line number and function name set in the created for the logging event. This can be used in logging helpers so that the function name, filename and line number recorded are not the information for the helper function/method, but rather its caller. The name of this parameter mirrors the equivalent one in the module. The fourth keyword argument is extra which can be used to pass a dictionary which is used to populate the of the created for the logging event with user-defined attributes. These custom attributes can then be used as you like. For example, they could be incorporated into logged messages. For example: would print something like The keys in the dictionary passed in extra should not clash with the keys used by the logging system. (See the section on LogRecord attributes for more information on which keys are used by the logging system.) If you choose to use these attributes in logged messages, you need to exercise some care. In the above example, for instance, the has been set up with a format string which expects ‘clientip’ and ‘user’ in the attribute dictionary of the . If these are missing, the message will not be logged because a string formatting exception will occur. So in this case, you always need to pass the extra dictionary with these keys. While this might be annoying, this feature is intended for use in specialized circumstances, such as multi-threaded servers where the same code executes in many contexts, and interesting conditions which arise are dependent on this context (such as remote client IP address and authenticated user name, in the above example). In such circumstances, it is likely that specialized s would be used with particular s. If no handler is attached to this logger (or any of its ancestors, taking into account the relevant attributes), the message will be sent to the handler set on . Changed in version 3.2: The stack_info parameter was added. Changed in version 3.5: The exc_info parameter can now accept exception instances. Changed in version 3.8: The stacklevel parameter was added. Logs a message with level on this logger. The arguments are interpreted as for . Logs a message with level on this logger. The arguments are interpreted as for . There is an obsolete method which is functionally identical to . As is deprecated, please do not use it - use instead. Logs a message with level on this logger. The arguments are interpreted as for . Logs a message with level on this logger. The arguments are interpreted as for . Logs a message with integer level level on this logger. The other arguments are interpreted as for . Logs a message with level on this logger. The arguments are interpreted as for . Exception info is added to the logging message. This method should only be called from an exception handler. Adds the specified filter filter to this logger. Removes the specified filter filter from this logger. Apply this logger’s filters to the record and return if the record is to be processed. The filters are consulted in turn, until one of them returns a false value. If none of them return a false value, the record will be processed (passed to handlers). If one returns a false value, no further processing of the record occurs. Adds the specified handler hdlr to this logger. Removes the specified handler hdlr from this logger. Finds the caller’s source filename and line number. Returns the filename, line number, function name and stack information as a 4-element tuple. The stack information is returned as unless stack_info is . The stacklevel parameter is passed from code calling the and other APIs. If greater than 1, the excess is used to skip stack frames before determining the values to be returned. This will generally be useful when calling logging APIs from helper/wrapper code, so that the information in the event log refers not to the helper/wrapper code, but to the code that calls it. Handles a record by passing it to all handlers associated with this logger and its ancestors (until a false value of propagate is found). This method is used for unpickled records received from a socket, as well as those created locally. Logger-level filtering is applied using . This is a factory method which can be overridden in subclasses to create specialized instances. Checks to see if this logger has any handlers configured. This is done by looking for handlers in this logger and its parents in the logger hierarchy. Returns if a handler was found, else . The method stops searching up the hierarchy whenever a logger with the ‘propagate’ attribute set to false is found - that will be the last logger which is checked for the existence of handlers. Changed in version 3.7: Loggers can now be pickled and unpickled.\n\ncan be used by and for more sophisticated filtering than is provided by levels. The base filter class only allows events which are below a certain point in the logger hierarchy. For example, a filter initialized with ‘A.B’ will allow events logged by loggers ‘A.B’, ‘A.B.C’, ‘A.B.C.D’, ‘A.B.D’ etc. but not ‘A.BB’, ‘B.A.B’ etc. If initialized with the empty string, all events are passed. Returns an instance of the class. If name is specified, it names a logger which, together with its children, will have its events allowed through the filter. If name is the empty string, allows every event. Is the specified record to be logged? Returns false for no, true for yes. Filters can either modify log records in-place or return a completely different record instance which will replace the original log record in any future processing of the event. Note that filters attached to handlers are consulted before an event is emitted by the handler, whereas filters attached to loggers are consulted whenever an event is logged (using , , etc.), before sending an event to handlers. This means that events which have been generated by descendant loggers will not be filtered by a logger’s filter setting, unless the filter has also been applied to those descendant loggers. You don’t actually need to subclass : you can pass any instance which has a method with the same semantics. Changed in version 3.2: You don’t need to create specialized classes, or use other classes with a method: you can use a function (or other callable) as a filter. The filtering logic will check to see if the filter object has a attribute: if it does, it’s assumed to be a and its method is called. Otherwise, it’s assumed to be a callable and called with the record as the single parameter. The returned value should conform to that returned by . Changed in version 3.12: You can now return a instance from filters to replace the log record rather than modifying it in place. This allows filters attached to a to modify the log record before it is emitted, without having side effects on other handlers. Although filters are used primarily to filter records based on more sophisticated criteria than levels, they get to see every record which is processed by the handler or logger they’re attached to: this can be useful if you want to do things like counting how many records were processed by a particular logger or handler, or adding, changing or removing attributes in the being processed. Obviously changing the LogRecord needs to be done with some care, but it does allow the injection of contextual information into logs (see Using Filters to impart contextual information).\n\nThe LogRecord has a number of attributes, most of which are derived from the parameters to the constructor. (Note that the names do not always correspond exactly between the LogRecord constructor parameters and the LogRecord attributes.) These attributes can be used to merge data from the record into the format string. The following table lists (in alphabetical order) the attribute names, their meanings and the corresponding placeholder in a %-style format string. If you are using {}-formatting ( ), you can use as the placeholder in the format string. If you are using $-formatting ( ), use the form . In both cases, of course, replace with the actual attribute name you want to use. In the case of {}-formatting, you can specify formatting flags by placing them after the attribute name, separated from it with a colon. For example: a placeholder of would format a millisecond value of as . Refer to the documentation for full details on the options available to you. You shouldn’t need to format this yourself. The tuple of arguments merged into to produce , or a dict whose values are used for the merge (when there is only one argument, and it is a dictionary). Human-readable time when the was created. By default this is of the form ‘2003-07-08 16:49:45,896’ (the numbers after the comma are millisecond portion of the time). Time when the was created (as returned by / 1e9). You shouldn’t need to format this yourself. Exception tuple (à la ) or, if no exception has occurred, . Name of function containing the logging call. Source line number where the logging call was issued (if available). The logged message, computed as . This is set when is invoked. Millisecond portion of the time when the was created. You shouldn’t need to format this yourself. The format string passed in the original logging call. Merged with to produce , or an arbitrary object (see Using arbitrary objects as messages). Name of the logger used to log the call. Full pathname of the source file where the logging call was issued (if available). Process name (if available). Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded. You shouldn’t need to format this yourself. Stack frame information (where available) from the bottom of the stack in the current thread, up to and including the stack frame of the logging call which resulted in the creation of this record. Thread name (if available). name (if available).\n\nIn addition to the classes described above, there are a number of module-level functions. Return a logger with the specified name or, if name is , return the root logger of the hierarchy. If specified, the name is typically a dot-separated hierarchical name like ‘a’, ‘a.b’ or ‘a.b.c.d’. Choice of these names is entirely up to the developer who is using logging, though it is recommended that be used unless you have a specific reason for not doing that, as mentioned in Logger Objects. All calls to this function with a given name return the same logger instance. This means that logger instances never need to be passed between different parts of an application. Return either the standard class, or the last class passed to . This function may be called from within a new class definition, to ensure that installing a customized class will not undo customizations already applied by other code. For example: Return a callable which is used to create a . Added in version 3.2: This function has been provided, along with , to allow developers more control over how the representing a logging event is constructed. See for more information about the how the factory is called. This is a convenience function that calls , on the root logger. The handling of the arguments is in every way identical to what is described in that method. The only difference is that if the root logger has no handlers, then is called, prior to calling on the root logger. For very short scripts or quick demonstrations of facilities, and the other module-level functions may be convenient. However, most programs will want to carefully and explicitly control the logging configuration, and should therefore prefer creating a module-level logger and calling (or other level-specific methods) on it, as described at the beginnning of this documentation. Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . There is an obsolete function which is functionally identical to . As is deprecated, please do not use it - use instead. Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Exception info is added to the logging message. This function should only be called from an exception handler. Logs a message with level level on the root logger. The arguments and behavior are otherwise the same as for . Provides an overriding level level for all loggers which takes precedence over the logger’s own level. When the need arises to temporarily throttle logging output down across the whole application, this function can be useful. Its effect is to disable all logging calls of severity level and below, so that if you call it with a value of INFO, then all INFO and DEBUG events would be discarded, whereas those of severity WARNING and above would be processed according to the logger’s effective level. If is called, it effectively removes this overriding level, so that logging output again depends on the effective levels of individual loggers. Note that if you have defined any custom logging level higher than (this is not recommended), you won’t be able to rely on the default value for the level parameter, but will have to explicitly supply a suitable value. Changed in version 3.7: The level parameter was defaulted to level . See bpo-28524 for more information about this change. Associates level level with text levelName in an internal dictionary, which is used to map numeric levels to a textual representation, for example when a formats a message. This function can also be used to define your own levels. The only constraints are that all levels used must be registered using this function, levels should be positive integers and they should increase in increasing order of severity. If you are thinking of defining your own levels, please see the section on Custom Levels. Returns a mapping from level names to their corresponding logging levels. For example, the string “CRITICAL” maps to . The returned mapping is copied from an internal mapping on each call to this function. Returns the textual or numeric representation of logging level level. If level is one of the predefined levels , , , or then you get the corresponding string. If you have associated levels with names using then the name you have associated with level is returned. If a numeric value corresponding to one of the defined levels is passed in, the corresponding string representation is returned. The level parameter also accepts a string representation of the level such as ‘INFO’. In such cases, this functions returns the corresponding numeric value of the level. If no matching numeric or string value is passed in, the string ‘Level %s’ % level is returned. Levels are internally integers (as they need to be compared in the logging logic). This function is used to convert between an integer level and the level name displayed in the formatted log output by means of the format specifier (see LogRecord attributes), and vice versa. Changed in version 3.4: In Python versions earlier than 3.4, this function could also be passed a text level, and would return the corresponding numeric value of the level. This undocumented behaviour was considered a mistake, and was removed in Python 3.4, but reinstated in 3.4.2 due to retain backward compatibility. Returns a handler with the specified name, or if there is no handler with that name. Returns an immutable set of all known handler names. Creates and returns a new instance whose attributes are defined by attrdict. This function is useful for taking a pickled attribute dictionary, sent over a socket, and reconstituting it as a instance at the receiving end. Does basic configuration for the logging system by creating a with a default and adding it to the root logger. The functions , , , and will call automatically if no handlers are defined for the root logger. This function does nothing if the root logger already has handlers configured, unless the keyword argument force is set to . This function should be called from the main thread before other threads are started. In versions of Python prior to 2.7.1 and 3.2, if this function is called from multiple threads, it is possible (in rare circumstances) that a handler will be added to the root logger more than once, leading to unexpected results such as messages being duplicated in the log. The following keyword arguments are supported. Specifies that a be created, using the specified filename, rather than a . If filename is specified, open the file in this mode. Defaults to . Use the specified format string for the handler. Defaults to attributes , and separated by colons. Use the specified date/time format, as accepted by . If format is specified, use this style for the format string. One of , or for printf-style, or respectively. Defaults to . Set the root logger level to the specified level. Use the specified stream to initialize the . Note that this argument is incompatible with filename - if both are present, a is raised. If specified, this should be an iterable of already created handlers to add to the root logger. Any handlers which don’t already have a formatter set will be assigned the default formatter created in this function. Note that this argument is incompatible with filename or stream - if both are present, a is raised. If this keyword argument is specified as true, any existing handlers attached to the root logger are removed and closed, before carrying out the configuration as specified by the other arguments. If this keyword argument is specified along with filename, its value is used when the is created, and thus used when opening the output file. If this keyword argument is specified along with filename, its value is used when the is created, and thus used when opening the output file. If not specified, the value ‘backslashreplace’ is used. Note that if is specified, it will be passed as such to , which means that it will be treated the same as passing ‘errors’. Changed in version 3.2: The style argument was added. Changed in version 3.3: The handlers argument was added. Additional checks were added to catch situations where incompatible arguments are specified (e.g. handlers together with stream or filename, or stream together with filename). Changed in version 3.8: The force argument was added. Changed in version 3.9: The encoding and errors arguments were added. Informs the logging system to perform an orderly shutdown by flushing and closing all handlers. This should be called at application exit and no further use of the logging system should be made after this call. When the logging module is imported, it registers this function as an exit handler (see ), so normally there’s no need to do that manually. Tells the logging system to use the class klass when instantiating a logger. The class should define such that only a name argument is required, and the should call . This function is typically called before any loggers are instantiated by applications which need to use custom logger behavior. After this call, as at any other time, do not instantiate loggers directly using the subclass: continue to use the API to get your loggers. Set a callable which is used to create a . factory – The factory callable to be used to instantiate a log record. Added in version 3.2: This function has been provided, along with , to allow developers more control over how the representing a logging event is constructed. The factory has the following signature: The full pathname of the file where the logging call was made. The line number in the file where the logging call was made. The arguments for the logging message. The name of the function or method which invoked the logging call. A stack traceback such as is provided by , showing the call hierarchy."
    },
    {
        "link": "https://docs.python.org/3/howto/logging.html",
        "document": "This page contains tutorial information. For links to reference information and a logging cookbook, please see Other resources.\n\nLogging is a means of tracking events that happen when some software runs. The software’s developer adds logging calls to their code to indicate that certain events have occurred. An event is described by a descriptive message which can optionally contain variable data (i.e. data that is potentially different for each occurrence of the event). Events also have an importance which the developer ascribes to the event; the importance can also be called the level or severity. When to use logging¶ You can access logging functionality by creating a logger via , and then calling the logger’s , , , and methods. To determine when to use logging, and to see which logger methods to use when, see the table below. It states, for each of a set of common tasks, the best tool to use for that task. The best tool for the task Display console output for ordinary usage of a command line script or program Report events that occur during normal operation of a program (e.g. for status monitoring or fault investigation) A logger’s (or method for very detailed output for diagnostic purposes) in library code if the issue is avoidable and the client application should be modified to eliminate the warning A logger’s method if there is nothing the client application can do about the situation, but the event should still be noted Report an error regarding a particular runtime event Report suppression of an error without raising an exception (e.g. error handler in a long-running server process) A logger’s , or method as appropriate for the specific error and application domain The logger methods are named after the level or severity of the events they are used to track. The standard levels and their applicability are described below (in increasing order of severity): Detailed information, typically of interest only when diagnosing problems. Confirmation that things are working as expected. An indication that something unexpected happened, or indicative of some problem in the near future (e.g. ‘disk space low’). The software is still working as expected. Due to a more serious problem, the software has not been able to perform some function. A serious error, indicating that the program itself may be unable to continue running. The default level is , which means that only events of this severity and higher will be tracked, unless the logging package is configured to do otherwise. Events that are tracked can be handled in different ways. The simplest way of handling tracked events is to print them to the console. Another common way is to write them to a disk file. A very simple example is: # will print a message to the console # will not print anything If you type these lines into a script and run it, you’ll see: printed out on the console. The message doesn’t appear because the default level is . The printed message includes the indication of the level and the description of the event provided in the logging call, i.e. ‘Watch out!’. The actual output can be formatted quite flexibly if you need that; formatting options will also be explained later. Notice that in this example, we use functions directly on the module, like , rather than creating a logger and calling functions on it. These functions operation on the root logger, but can be useful as they will call for you if it has not been called yet, like in this example. In larger programs you’ll usually want to control the logging configuration explicitly however - so for that reason as well as others, it’s better to create loggers and call their methods. A very common situation is that of recording logging events in a file, so let’s look at that next. Be sure to try the following in a newly started Python interpreter, and don’t just continue from the session described above: 'This message should go to the log file' 'And non-ASCII stuff, too, like Øresund and Malmö' Changed in version 3.9: The encoding argument was added. In earlier Python versions, or if not specified, the encoding used is the default value used by . While not shown in the above example, an errors argument can also now be passed, which determines how encoding errors are handled. For available values and the default, see the documentation for . And now if we open the file and look at what we have, we should find the log messages: DEBUG:__main__:This message should go to the log file INFO:__main__:So should this WARNING:__main__:And this, too ERROR:__main__:And non-ASCII stuff, too, like Øresund and Malmö This example also shows how you can set the logging level which acts as the threshold for tracking. In this case, because we set the threshold to , all of the messages were printed. If you want to set the logging level from a command-line option such as: and you have the value of the parameter passed for in some variable loglevel, you can use: to get the value which you’ll pass to via the level argument. You may want to error check any user input value, perhaps as in the following example: # assuming loglevel is bound to the string value obtained from the # command line argument. Convert to upper case to allow the user to The call to should come before any calls to a logger’s methods such as , , etc. Otherwise, that logging event may not be handled in the desired manner. If you run the above script several times, the messages from successive runs are appended to the file example.log. If you want each run to start afresh, not remembering the messages from earlier runs, you can specify the filemode argument, by changing the call in the above example to: The output will be the same as before, but the log file is no longer appended to, so the messages from earlier runs are lost. To log variable data, use a format string for the event description message and append the variable data as arguments. For example: As you can see, merging of variable data into the event description message uses the old, %-style of string formatting. This is for backwards compatibility: the logging package pre-dates newer formatting options such as and . These newer formatting options are supported, but exploring them is outside the scope of this tutorial: see Using particular formatting styles throughout your application for more information. To change the format which is used to display messages, you need to specify the format you want to use: 'This message should appear on the console' DEBUG:This message should appear on the console INFO:So should this WARNING:And this, too Notice that the ‘root’ which appeared in earlier examples has disappeared. For a full set of things that can appear in format strings, you can refer to the documentation for LogRecord attributes, but for simple usage, you just need the levelname (severity), message (event description, including variable data) and perhaps to display when the event occurred. This is described in the next section. That concludes the basic tutorial. It should be enough to get you up and running with logging. There’s a lot more that the logging package offers, but to get the best out of it, you’ll need to invest a little more of your time in reading the following sections. If you’re ready for that, grab some of your favourite beverage and carry on. If your logging needs are simple, then use the above examples to incorporate logging into your own scripts, and if you run into problems or don’t understand something, please post a question on the comp.lang.python Usenet group (available at https://groups.google.com/g/comp.lang.python) and you should receive help before too long. Still here? You can carry on reading the next few sections, which provide a slightly more advanced/in-depth tutorial than the basic one above. After that, you can take a look at the Logging Cookbook.\n\nThe logging library takes a modular approach and offers several categories of components: loggers, handlers, filters, and formatters.\n• None Loggers expose the interface that application code directly uses.\n• None Handlers send the log records (created by loggers) to the appropriate destination.\n• None Filters provide a finer grained facility for determining which log records to output.\n• None Formatters specify the layout of log records in the final output. Log event information is passed between loggers, handlers, filters and formatters in a instance. Logging is performed by calling methods on instances of the class (hereafter called loggers). Each instance has a name, and they are conceptually arranged in a namespace hierarchy using dots (periods) as separators. For example, a logger named ‘scan’ is the parent of loggers ‘scan.text’, ‘scan.html’ and ‘scan.pdf’. Logger names can be anything you want, and indicate the area of an application in which a logged message originates. A good convention to use when naming loggers is to use a module-level logger, in each module which uses logging, named as follows: This means that logger names track the package/module hierarchy, and it’s intuitively obvious where events are logged just from the logger name. The root of the hierarchy of loggers is called the root logger. That’s the logger used by the functions , , , and , which just call the same-named method of the root logger. The functions and the methods have the same signatures. The root logger’s name is printed as ‘root’ in the logged output. It is, of course, possible to log messages to different destinations. Support is included in the package for writing log messages to files, HTTP GET/POST locations, email via SMTP, generic sockets, queues, or OS-specific logging mechanisms such as syslog or the Windows NT event log. Destinations are served by handler classes. You can create your own log destination class if you have special requirements not met by any of the built-in handler classes. By default, no destination is set for any logging messages. You can specify a destination (such as console or file) by using as in the tutorial examples. If you call the functions , , , and , they will check to see if no destination is set; and if one is not set, they will set a destination of the console ( ) and a default format for the displayed message before delegating to the root logger to do the actual message output. The default format set by for messages is: You can change this by passing a format string to with the format keyword argument. For all options regarding how a format string is constructed, see Formatter Objects. The flow of log event information in loggers and handlers is illustrated in the following diagram. At least one handler objects have a threefold job. First, they expose several methods to application code so that applications can log messages at runtime. Second, logger objects determine which log messages to act upon based upon severity (the default filtering facility) or filter objects. Third, logger objects pass along relevant log messages to all interested log handlers. The most widely used methods on logger objects fall into two categories: configuration and message sending. These are the most common configuration methods:\n• None specifies the lowest-severity log message a logger will handle, where debug is the lowest built-in severity level and critical is the highest built-in severity. For example, if the severity level is INFO, the logger will handle only INFO, WARNING, ERROR, and CRITICAL messages and will ignore DEBUG messages.\n• None and add and remove handler objects from the logger object. Handlers are covered in more detail in Handlers.\n• None and add and remove filter objects from the logger object. Filters are covered in more detail in Filter Objects. You don’t need to always call these methods on every logger you create. See the last two paragraphs in this section. With the logger object configured, the following methods create log messages:\n• None , , , , and all create log records with a message and a level that corresponds to their respective method names. The message is actually a format string, which may contain the standard string substitution syntax of , , , and so on. The rest of their arguments is a list of objects that correspond with the substitution fields in the message. With regard to , the logging methods care only about a keyword of and use it to determine whether to log exception information.\n• None creates a log message similar to . The difference is that dumps a stack trace along with it. Call this method only from an exception handler.\n• None takes a log level as an explicit argument. This is a little more verbose for logging messages than using the log level convenience methods listed above, but this is how to log at custom log levels. returns a reference to a logger instance with the specified name if it is provided, or if not. The names are period-separated hierarchical structures. Multiple calls to with the same name will return a reference to the same logger object. Loggers that are further down in the hierarchical list are children of loggers higher up in the list. For example, given a logger with a name of , loggers with names of , , and are all descendants of . Loggers have a concept of effective level. If a level is not explicitly set on a logger, the level of its parent is used instead as its effective level. If the parent has no explicit level set, its parent is examined, and so on - all ancestors are searched until an explicitly set level is found. The root logger always has an explicit level set ( by default). When deciding whether to process an event, the effective level of the logger is used to determine whether the event is passed to the logger’s handlers. Child loggers propagate messages up to the handlers associated with their ancestor loggers. Because of this, it is unnecessary to define and configure handlers for all the loggers an application uses. It is sufficient to configure handlers for a top-level logger and create child loggers as needed. (You can, however, turn off propagation by setting the propagate attribute of a logger to .) objects are responsible for dispatching the appropriate log messages (based on the log messages’ severity) to the handler’s specified destination. objects can add zero or more handler objects to themselves with an method. As an example scenario, an application may want to send all log messages to a log file, all log messages of error or higher to stdout, and all messages of critical to an email address. This scenario requires three individual handlers where each handler is responsible for sending messages of a specific severity to a specific location. The standard library includes quite a few handler types (see Useful Handlers); the tutorials use mainly and in its examples. There are very few methods in a handler for application developers to concern themselves with. The only handler methods that seem relevant for application developers who are using the built-in handler objects (that is, not creating custom handlers) are the following configuration methods:\n• None The method, just as in logger objects, specifies the lowest severity that will be dispatched to the appropriate destination. Why are there two methods? The level set in the logger determines which severity of messages it will pass to its handlers. The level set in each handler determines which messages that handler will send on.\n• None selects a Formatter object for this handler to use.\n• None and respectively configure and deconfigure filter objects on handlers. Application code should not directly instantiate and use instances of . Instead, the class is a base class that defines the interface that all handlers should have and establishes some default behavior that child classes can use (or override). Formatter objects configure the final order, structure, and contents of the log message. Unlike the base class, application code may instantiate formatter classes, although you could likely subclass the formatter if your application needs special behavior. The constructor takes three optional arguments – a message format string, a date format string and a style indicator. If there is no message format string, the default is to use the raw message. If there is no date format string, the default date format is: with the milliseconds tacked on at the end. The is one of , , or . If one of these is not specified, then will be used. If the is , the message format string uses styled string substitution; the possible keys are documented in LogRecord attributes. If the style is , the message format string is assumed to be compatible with (using keyword arguments), while if the style is then the message format string should conform to what is expected by . The following message format string will log the time in a human-readable format, the severity of the message, and the contents of the message, in that order: Formatters use a user-configurable function to convert the creation time of a record to a tuple. By default, is used; to change this for a particular formatter instance, set the attribute of the instance to a function with the same signature as or . To change it for all formatters, for example if you want all logging times to be shown in GMT, set the attribute in the Formatter class (to for GMT display). Programmers can configure logging in three ways:\n• None Creating loggers, handlers, and formatters explicitly using Python code that calls the configuration methods listed above.\n• None Creating a logging config file and reading it using the function.\n• None Creating a dictionary of configuration information and passing it to the function. For the reference documentation on the last two options, see Configuration functions. The following example configures a very simple logger, a console handler, and a simple formatter using Python code: Running this module from the command line produces the following output: The following Python module creates a logger, handler, and formatter nearly identical to those in the example listed above, with the only difference being the names of the objects: Here is the logging.conf file: The output is nearly identical to that of the non-config-file-based example: You can see that the config file approach has a few advantages over the Python code approach, mainly separation of configuration and code and the ability of noncoders to easily modify the logging properties. The function takes a default parameter, , which defaults to for reasons of backward compatibility. This may or may not be what you want, since it will cause any non-root loggers existing before the call to be disabled unless they (or an ancestor) are explicitly named in the configuration. Please refer to the reference documentation for more information, and specify for this parameter if you wish. The dictionary passed to can also specify a Boolean value with key , which if not specified explicitly in the dictionary also defaults to being interpreted as . This leads to the logger-disabling behaviour described above, which may not be what you want - in which case, provide the key explicitly with a value of . Note that the class names referenced in config files need to be either relative to the logging module, or absolute values which can be resolved using normal import mechanisms. Thus, you could use either (relative to the logging module) or (for a class defined in package and module , where is available on the Python import path). In Python 3.2, a new means of configuring logging has been introduced, using dictionaries to hold configuration information. This provides a superset of the functionality of the config-file-based approach outlined above, and is the recommended configuration method for new applications and deployments. Because a Python dictionary is used to hold configuration information, and since you can populate that dictionary using different means, you have more options for configuration. For example, you can use a configuration file in JSON format, or, if you have access to YAML processing functionality, a file in YAML format, to populate the configuration dictionary. Or, of course, you can construct the dictionary in Python code, receive it in pickled form over a socket, or use whatever approach makes sense for your application. Here’s an example of the same configuration as above, in YAML format for the new dictionary-based approach: For more information about logging using a dictionary, see Configuration functions. What happens if no configuration is provided¶ If no logging configuration is provided, it is possible to have a situation where a logging event needs to be output, but no handlers can be found to output the event. The event is output using a ‘handler of last resort’, stored in . This internal handler is not associated with any logger, and acts like a which writes the event description message to the current value of (therefore respecting any redirections which may be in effect). No formatting is done on the message - just the bare event description message is printed. The handler’s level is set to , so all events at this and greater severities will be output. Changed in version 3.2: For versions of Python prior to 3.2, the behaviour is as follows:\n• None If is (production mode), the event is silently dropped.\n• None If is (development mode), a message ‘No handlers could be found for logger X.Y.Z’ is printed once. To obtain the pre-3.2 behaviour, can be set to . When developing a library which uses logging, you should take care to document how the library uses logging - for example, the names of loggers used. Some consideration also needs to be given to its logging configuration. If the using application does not use logging, and library code makes logging calls, then (as described in the previous section) events of severity and greater will be printed to . This is regarded as the best default behaviour. If for some reason you don’t want these messages printed in the absence of any logging configuration, you can attach a do-nothing handler to the top-level logger for your library. This avoids the message being printed, since a handler will always be found for the library’s events: it just doesn’t produce any output. If the library user configures logging for application use, presumably that configuration will add some handlers, and if levels are suitably configured then logging calls made in library code will send output to those handlers, as normal. A do-nothing handler is included in the logging package: (since Python 3.1). An instance of this handler could be added to the top-level logger of the logging namespace used by the library (if you want to prevent your library’s logged events being output to in the absence of logging configuration). If all logging by a library foo is done using loggers with names matching ‘foo.x’, ‘foo.x.y’, etc. then the code: should have the desired effect. If an organisation produces a number of libraries, then the logger name specified can be ‘orgname.foo’ rather than just ‘foo’. It is strongly advised that you do not log to the root logger in your library. Instead, use a logger with a unique and easily identifiable name, such as the for your library’s top-level package or module. Logging to the root logger will make it difficult or impossible for the application developer to configure the logging verbosity or handlers of your library as they wish. It is strongly advised that you do not add any handlers other than to your library’s loggers. This is because the configuration of handlers is the prerogative of the application developer who uses your library. The application developer knows their target audience and what handlers are most appropriate for their application: if you add handlers ‘under the hood’, you might well interfere with their ability to carry out unit tests and deliver logs which suit their requirements.\n\nThe numeric values of logging levels are given in the following table. These are primarily of interest if you want to define your own levels, and need them to have specific values relative to the predefined levels. If you define a level with the same numeric value, it overwrites the predefined value; the predefined name is lost. Levels can also be associated with loggers, being set either by the developer or through loading a saved logging configuration. When a logging method is called on a logger, the logger compares its own level with the level associated with the method call. If the logger’s level is higher than the method call’s, no logging message is actually generated. This is the basic mechanism controlling the verbosity of logging output. Logging messages are encoded as instances of the class. When a logger decides to actually log an event, a instance is created from the logging message. Logging messages are subjected to a dispatch mechanism through the use of handlers, which are instances of subclasses of the class. Handlers are responsible for ensuring that a logged message (in the form of a ) ends up in a particular location (or set of locations) which is useful for the target audience for that message (such as end users, support desk staff, system administrators, developers). Handlers are passed instances intended for particular destinations. Each logger can have zero, one or more handlers associated with it (via the method of ). In addition to any handlers directly associated with a logger, all handlers associated with all ancestors of the logger are called to dispatch the message (unless the propagate flag for a logger is set to a false value, at which point the passing to ancestor handlers stops). Just as for loggers, handlers can have levels associated with them. A handler’s level acts as a filter in the same way as a logger’s level does. If a handler decides to actually dispatch an event, the method is used to send the message to its destination. Most user-defined subclasses of will need to override this . Defining your own levels is possible, but should not be necessary, as the existing levels have been chosen on the basis of practical experience. However, if you are convinced that you need custom levels, great care should be exercised when doing this, and it is possibly a very bad idea to define custom levels if you are developing a library. That’s because if multiple library authors all define their own custom levels, there is a chance that the logging output from such multiple libraries used together will be difficult for the using developer to control and/or interpret, because a given numeric value might mean different things for different libraries.\n\nFormatting of message arguments is deferred until it cannot be avoided. However, computing the arguments passed to the logging method can also be expensive, and you may want to avoid doing it if the logger will just throw away your event. To decide what to do, you can call the method which takes a level argument and returns true if the event would be created by the Logger for that level of call. You can write code like this: so that if the logger’s threshold is set above , the calls to and are never made. In some cases, can itself be more expensive than you’d like (e.g. for deeply nested loggers where an explicit level is only set high up in the logger hierarchy). In such cases (or if you want to avoid calling a method in tight loops), you can cache the result of a call to in a local or instance variable, and use that instead of calling the method each time. Such a cached value would only need to be recomputed when the logging configuration changes dynamically while the application is running (which is not all that common). There are other optimizations which can be made for specific applications which need more precise control over what logging information is collected. Here’s a list of things you can do to avoid processing during logging which you don’t need: What you don’t want to collect How to avoid collecting it Information about where calls were made from. Set to . This avoids calling , which may help to speed up your code in environments like PyPy (which can’t speed up code that uses ). Current process name when using to manage multiple processes. Current name when using . Also note that the core logging module only includes the basic handlers. If you don’t import and , they won’t take up any memory."
    },
    {
        "link": "https://stackoverflow.com/questions/78826049/why-is-this-example-code-for-logging-from-python-docs-page-not-writing-to-the-fi",
        "document": "This is a very basic question on logging, straight from the documentation.\n\nI am running the following example code from the documentation on logging. The behavior is not what I would expect:\n• None There is no output to the file. I created the respective file before running the code. Why is this?\n• None The list of handlers is empty. Adding after setting the config adds a handler to the list with the path to the correct file, but still there is no output to the file. Its level is 'NOTSET'. Adding seems to have no effect on this.\n• None When removing the filename attribute from the config,the messages are printed to the console, as expected. However, when removing the config line completely, I would expect the warning and and error to be printed, but they are not.\n\nI am running the code from the terminal in an environment with Python 3.11.0.\n\nThere are a lot of related questions (see list below), but none of them seems to answer my question:\n• Problem here and here was to use instead of as object\n• Here there were additional parts of code, where the config was called multiple times. For me, there is just the code displayed above in the script.\n• The common mistake mentioned here of calling the config only after a printing statement is not the case for me.\n\nUpdate: When running the same code in an interactive session via all messages are written. Can this be a problem with the environment? In both cases I use the same python version."
    },
    {
        "link": "https://stackoverflow.com/questions/69661922/formatting-the-message-in-python-logging",
        "document": "I would like to understand if it's possible and how is it possible, to modify the message part of a log message, using the Python logging module.\n\nSo basically, you can format a complete log as:\n\nHowever, I would like to make sure the message part is always in json format. Is there any way I can modify the format of only the message part, maybe with a custom ?"
    },
    {
        "link": "https://docs.python-guide.org/writing/logging",
        "document": "The module has been a part of Python’s Standard Library since version 2.3. It is succinctly described in PEP 282. The documentation is notoriously hard to read, except for the basic logging tutorial.\n\nAs an alternative, loguru provides an approach for logging, nearly as simple as using a simple statement.\n• Diagnostic logging records events related to the application’s operation. If a user calls in to report an error, for example, the logs can be searched for context.\n• Audit logging records events for business analysis. A user’s transactions can be extracted and combined with other user details for reports or to optimize a business goal.\n\nThe only time that is a better option than logging is when the goal is to display a help statement for a command line application. Other reasons why logging is better than :\n• The log record, which is created with every logging event, contains readily available diagnostic information such as the file name, full path, function, and line number of the logging event.\n• Events logged in included modules are automatically accessible via the root logger to your application’s logging stream, unless you filter them out.\n• Logging can be selectively silenced by using the method or disabled by setting the attribute to .\n\nNotes for configuring logging for a library are in the logging tutorial. Because the user, not the library, should dictate what happens when a logging event occurs, one admonition bears repeating: It is strongly advised that you do not add any handlers other than NullHandler to your library’s loggers. Best practice when instantiating loggers in a library is to only create them using the global variable: the module creates a hierarchy of loggers using dot notation, so using ensures no name collisions. Here is an example of the best practice from the requests source – place this in your :\n\nThe twelve factor app, an authoritative reference for good practice in application development, contains a section on logging best practice. It emphatically advocates for treating log events as an event stream, and for sending that event stream to standard output to be handled by the application environment. There are at least three ways to configure a logger:\n• None\n• Pro: possible to update configuration while running, using the function to listen on a socket.\n• Con: less control (e.g. custom subclassed filters or loggers) than possible when configuring a logger in code.\n• None\n• Pro: in addition to updating while running, it is possible to load from a file using the module, in the standard library since Python 2.6.\n• Con: less control than when configuring a logger in code. Example Configuration via an INI File¶ Let us say that the file is named . More details for the file format are in the logging configuration section of the logging tutorial. Then use in the code: 'often makes a very good meal of As of Python 2.7, you can use a dictionary with configuration details. PEP 391 contains a list of the mandatory and optional elements in the configuration dictionary. 'often makes a very good meal of 'often makes a very good meal of"
    },
    {
        "link": "https://python-httpx.org/async",
        "document": ""
    },
    {
        "link": "https://python-httpx.org",
        "document": ""
    },
    {
        "link": "https://python-httpx.org/exceptions",
        "document": ""
    },
    {
        "link": "https://python-httpx.org/quickstart",
        "document": ""
    },
    {
        "link": "https://betterstack.com/community/guides/scaling-python/httpx-explained",
        "document": "If you’ve worked with APIs in Python, you’re likely familiar with the library. But what if you could get the same ease of use, asynchronous support, HTTP/2 performance gains, and advanced configuration options? That’s HTTPX exactly what offers.\n\nHTTPX is a powerful HTTP client that supports synchronous and asynchronous requests, making it an excellent choice for handling API interactions at any scale.\n\nIt provides built-in authentication, connection pooling, and streaming responses, making working with modern web services easier.\n\nThis guide will walk you through integrating HTTPX into your Python projects and maximizing its features to handle HTTP requests efficiently.\n\nBefore diving in, install Python 3.13 or higher . While this guide assumes some familiarity with making HTTP requests in Python—especially with the requests library —you can still follow along even if you're new to it.\n\nFor the best learning experience, create a new Python project to experiment with the concepts covered in this tutorial.\n\nStart by setting up a new directory and initializing a virtual environment:\n\nFollowing that, install the latest version of with the command below:\n\nCreate a new file in the root of your project directory and add the following code:\n\nThis snippet imports the package and defines a simple function that makes a GET request to a test endpoint.\n\nLet's go ahead and run this script:\n\nYou should observe output similar to the following:\n\nThe response from contains information about our request, including the sent headers. This simple example demonstrates the ease of making HTTP requests with HTTPX.\n\nWhen you make an HTTP request using , the response object contains important information about the server’s reply. This includes the status code, headers, and response body, which help determine whether the request was successful and how to process the returned data.\n\nModify your file to inspect different parts of the response:\n\nThis script retrieves data from and displays important response details. Here’s what each part of the response object represents:\n• – Indicates the HTTP status of the request (e.g., for success, for not found).\n• – A dictionary containing metadata about the response, such as content type, server information, and caching policies.\n• – Parses the response body as JSON, converting it into a Python dictionary for easy data manipulation.\n\n\n\nAfter running the script, you should see something like:\n\nThe response output consists of three key parts:\n• Status Code – Indicates whether the request was successful. A status means success, while a suggests that the requested resource was not found, and a points to a server error.\n• Headers – Provide metadata about the response, including details like , which specifies the format of the response, and , which identifies the web server handling the request.\n• Content – Contains the actual response body, typically a JSON object that includes valuable details about the request, such as the headers sent and the request's origin.\n\nNow that you understand response objects, let's explore how to make different types of HTTP requests using HTTPX.\n\nNow that you understand how HTTPX handles responses, let's explore different types of HTTP requests beyond .\n\nHTTPX supports a variety of methods, including , , , and query parameters with , allowing you to interact with APIs that require data submission or modifications.\n\nA request is typically used to send data to a server, such as creating a new resource or submitting a form.\n\nRemove all contents from and replace it with the following code to send a request with JSON data:\n\nYou should see output similar to this:\n\nThe response confirms that your request was processed successfully. The field in the response body contains the data you sent, proving that the server received it correctly.\n\nThe headers also indicate that the request was sent as , thanks to HTTPX automatically setting the correct content type.\n\nWhile is used to create new resources, a request is used to update existing ones. When you need to modify an entry rather than add a new one, ensures that the existing data is replaced with the updated values.\n\nHere’s an example of making a request with HTTPX:\n\nThis request updates an existing resource with new data, ensuring changes are correctly reflected on the server.\n\nIf you need to remove a resource instead, a request is used. This is particularly useful for deleting records from a database or removing items from an API:\n\nSometimes, API requests need additional information in the URL, such as filtering or searching for specific data. This is done using query parameters.\n\nYou should see output like:\n\nThe field in the response confirms that the query parameter was sent successfully. This is useful when filtering or searching through API results.\n\nNow that you've learned how to send different HTTP requests, the next step is to ensure your requests are resilient.\n\nNetwork issues, slow server responses, or connection failures can impact your application's performance. HTTPX provides built-in support for timeouts, retries, and error handling, which helps ensure your requests remain stable and reliable.\n\nBy default, HTTPX waits indefinitely for a response, which can cause your program to hang if the server is slow or unresponsive.\n\nYou can prevent this by setting a timeout, which defines how long HTTPX should wait before giving up on a request.\n\nReplace all the contents in the file with the following to implement a timeout:\n\nIf the server responds within 3 seconds, the request succeeds, and the response is printed. If the server takes longer than 3 seconds, HTTPX raises a , and the program prints .\n\nIf the request exceeds the timeout, you'll see:\n\nThis is useful for preventing unresponsive requests from blocking your application.\n\nSometimes, network failures or temporary server issues cause requests to fail. HTTPX allows you to retry failed requests automatically using an with a custom retry strategy.\n\nRemove all existing code in the file and update it with the following to include retries:\n\nThe script attempts to send a request to an endpoint that returns a error. If an error occurs, it retries up to 3 times before giving up.\n\nThe method ensures we only process successful responses.\n\nIf all retry attempts fail, it prints\n\nNow that you have learned how to handle timeouts and retries in HTTPX, the next step is securing API requests. Many APIs require authentication before allowing access to protected resources. HTTPX supports various authentication methods, such as Basic Auth, Token-based authentication, and OAuth.\n\nBasic Authentication ( ) is one of the simplest forms of authentication, where the client sends a username and password encoded in the request headers.\n\nReplace the contents of with the following code to use Basic Authentication:\n\nThe argument accepts a tuple containing the username and password. HTTPX automatically encodes the credentials into the header as .\n\nThen the server verifies the credentials and responds accordingly.\n\nRun the script with the following:\n\nThis confirms that the authentication was successful. If the credentials are incorrect, the server will return a response.\n\nMany APIs use token-based authentication (e.g., API keys, JWT tokens) instead of Basic Auth. Tokens are typically passed in the header.\n\nModify to send an API request with a Bearer Token:\n\nThe Authorization header is manually set to . The server verifies the token and responds accordingly.\n\nRun the script like you have been doing:\n\nIf the token is missing or invalid, you'll receive a or response.\n\nSo far, you've been making synchronous HTTP requests, meaning each request blocks the program until it responds. This is fine for small-scale applications, but asynchronous programming can significantly improve performance when dealing with multiple API calls or high-latency networks.\n\nHTTPX provides native async support using Python’s and syntax, allowing requests to be made concurrently instead of sequentially.\n• You need to make multiple API calls concurrently (e.g., fetching data from multiple endpoints).\n• You want to improve efficiency without blocking execution.\n\n\n\nInstead of waiting for each request to finish before making the next one, async HTTPX allows multiple requests to be sent simultaneously, significantly reducing wait times.\n\nReplace the contents of with the following to send an asynchronous GET request:\n\nThe function is an asynchronous coroutine that makes a non-blocking GET request.\n\nThe statement ensures proper session management, while sends the request without pausing execution.\n\nFinally, starts the event loop, allowing multiple API calls to run concurrently for improved performance.\n\nThe output confirms a successful async request with , displaying request metadata, source IP, and the requested URL—showcasing non-blocking execution.\n\nOne of the most significant advantages of async requests is that they allow multiple API calls to be made concurrently. Instead of sending them individually, all requests are sent simultaneously, reducing total execution time.\n\nThis program defines , an asynchronous function that requests a GET to a given URL and returns its response status. The function builds a list of URLs and sends all requests concurrently using , ensuring they run in parallel.\n\nAn is used within a context manager to manage connections efficiently. By executing all requests simultaneously, the program avoids delays in sequential execution.\n\nRerun the program and you will see output like this:\n\nIn a synchronous approach, each request would complete before the next one starts, leading to a total execution time roughly equal to the sum of all delays.\n\nHowever, with async execution, all requests run simultaneously, drastically reducing the overall wait time.\n\nThis method is handy when working with APIs involving network latency or when handling high requests efficiently.\n\nHTTP/2 is a major iteration of the HTTP protocol that provides a far more efficient transport layer with significant performance benefits. Unlike HTTP/1.1's text-based format, HTTP/2 uses a binary format that enables:\n• Stream prioritization: Allows clients to indicate which resources are more important\n• Server push: Enables servers to proactively send resources to clients before they're explicitly requested\n\nThese improvements can dramatically enhance performance, especially for applications making multiple concurrent requests.\n\nHTTPX doesn't enable HTTP/2 by default, as HTTP/1.1 is considered the more mature and battle-tested option. To use HTTP/2, you first need to install the required dependencies:\n\nOnce installed, you can enable HTTP/2 by setting the parameter to when creating a client:\n\nWhen you run this script, you should see output like this:\n\nIt's important to note that enabling HTTP/2 in your HTTPX client does not guarantee that your requests will use HTTP/2. Both the client and server must support HTTP/2 for it to be used.\n\nIf you connect to a server that only supports HTTP/1.1, the client will automatically fall back to using HTTP/1.1.\n\nYou can always check which version of the HTTP protocol was actually used by examining the property on the response:\n\nRunning this script will show which HTTP version was used for each request:\n\nThis demonstrates how HTTPX automatically selects the appropriate protocol based on server support.\n\nThis guide covered HTTPX's key features, from basic requests to advanced capabilities like authentication, async operations, and HTTP/2 support. HTTPX bridges the gap between the familiar requests library API and modern Python development needs.\n\nIts intuitive interface and powerful features make HTTPX suitable for everything from simple scripts to complex service architectures.\n\nFor more details, refer to the official HTTPX documentation . Happy coding!"
    }
]