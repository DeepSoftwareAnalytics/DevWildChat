[
    {
        "link": "https://docs.python.org/3/library/logging.html",
        "document": "This module defines functions and classes which implement a flexible event logging system for applications and libraries.\n\nThe key benefit of having the logging API provided by a standard library module is that all Python modules can participate in logging, so your application log can include your own messages integrated with messages from third-party modules.\n\nIf you run myapp.py, you should see this in myapp.log:\n\nThe key feature of this idiomatic usage is that the majority of code is simply creating a module level logger with , and using that logger to do any needed logging. This is concise, while allowing downstream code fine-grained control if needed. Logged messages to the module-level logger get forwarded to handlers of loggers in higher-level modules, all the way up to the highest-level logger known as the root logger; this approach is known as hierarchical logging.\n\nFor logging to be useful, it needs to be configured: setting the levels and destinations for each logger, potentially changing how specific modules log, often based on command-line arguments or application configuration. In most cases, like the one above, only the root logger needs to be so configured, since all the lower level loggers at module level eventually forward their messages to its handlers. provides a quick way to configure the root logger that handles many use cases.\n\nThe module provides a lot of functionality and flexibility. If you are unfamiliar with logging, the best way to get to grips with it is to view the tutorials (see the links above and on the right).\n\nThe basic classes defined by the module, together with their attributes and methods, are listed in the sections below.\n• None Loggers expose the interface that application code directly uses.\n• None Handlers send the log records (created by loggers) to the appropriate destination.\n• None Filters provide a finer grained facility for determining which log records to output.\n• None Formatters specify the layout of log records in the final output.\n\nLoggers have the following attributes and methods. Note that Loggers should NEVER be instantiated directly, but always through the module-level function . Multiple calls to with the same name will always return a reference to the same Logger object. The is potentially a period-separated hierarchical value, like (though it could also be just plain , for example). Loggers that are further down in the hierarchical list are children of loggers higher up in the list. For example, given a logger with a name of , loggers with names of , , and are all descendants of . In addition, all loggers are descendants of the root logger. The logger name hierarchy is analogous to the Python package hierarchy, and identical to it if you organise your loggers on a per-module basis using the recommended construction . That’s because in a module, is the module’s name in the Python package namespace. This is the logger’s name, and is the value that was passed to to obtain the logger. This attribute should be treated as read-only. The threshold of this logger, as set by the method. Do not set this attribute directly - always use , which has checks for the level passed to it. The parent logger of this logger. It may change based on later instantiation of loggers which are higher up in the namespace hierarchy. This value should be treated as read-only. If this attribute evaluates to true, events logged to this logger will be passed to the handlers of higher level (ancestor) loggers, in addition to any handlers attached to this logger. Messages are passed directly to the ancestor loggers’ handlers - neither the level nor filters of the ancestor loggers in question are considered. If this evaluates to false, logging messages are not passed to the handlers of ancestor loggers. Spelling it out with an example: If the propagate attribute of the logger named evaluates to true, any event logged to via a method call such as will [subject to passing that logger’s level and filter settings] be passed in turn to any handlers attached to loggers named , and the root logger, after first being passed to any handlers attached to . If any logger in the chain , , has its attribute set to false, then that is the last logger whose handlers are offered the event to handle, and propagation stops at that point. The constructor sets this attribute to . If you attach a handler to a logger and one or more of its ancestors, it may emit the same record multiple times. In general, you should not need to attach a handler to more than one logger - if you just attach it to the appropriate logger which is highest in the logger hierarchy, then it will see all events logged by all descendant loggers, provided that their propagate setting is left set to . A common scenario is to attach handlers only to the root logger, and to let propagation take care of the rest. The list of handlers directly attached to this logger instance. This attribute should be treated as read-only; it is normally changed via the and methods, which use locks to ensure thread-safe operation. This attribute disables handling of any events. It is set to in the initializer, and only changed by logging configuration code. This attribute should be treated as read-only. Sets the threshold for this logger to level. Logging messages which are less severe than level will be ignored; logging messages which have severity level or higher will be emitted by whichever handler or handlers service this logger, unless a handler’s level has been set to a higher severity level than level. When a logger is created, the level is set to (which causes all messages to be processed when the logger is the root logger, or delegation to the parent when the logger is a non-root logger). Note that the root logger is created with level . The term ‘delegation to the parent’ means that if a logger has a level of NOTSET, its chain of ancestor loggers is traversed until either an ancestor with a level other than NOTSET is found, or the root is reached. If an ancestor is found with a level other than NOTSET, then that ancestor’s level is treated as the effective level of the logger where the ancestor search began, and is used to determine how a logging event is handled. If the root is reached, and it has a level of NOTSET, then all messages will be processed. Otherwise, the root’s level will be used as the effective level. See Logging Levels for a list of levels. Changed in version 3.2: The level parameter now accepts a string representation of the level such as ‘INFO’ as an alternative to the integer constants such as . Note, however, that levels are internally stored as integers, and methods such as e.g. and will return/expect to be passed integers. Indicates if a message of severity level would be processed by this logger. This method checks first the module-level level set by and then the logger’s effective level as determined by . Indicates the effective level for this logger. If a value other than has been set using , it is returned. Otherwise, the hierarchy is traversed towards the root until a value other than is found, and that value is returned. The value returned is an integer, typically one of , etc. Returns a logger which is a descendant to this logger, as determined by the suffix. Thus, would return the same logger as would be returned by . This is a convenience method, useful when the parent logger is named using e.g. rather than a literal string. Returns a set of loggers which are immediate children of this logger. So for example might return a set containing loggers named and , but a logger named wouldn’t be included in the set. Likewise, might return a set including a logger named , but it wouldn’t include one named . Logs a message with level on this logger. The msg is the message format string, and the args are the arguments which are merged into msg using the string formatting operator. (Note that this means that you can use keywords in the format string, together with a single dictionary argument.) No % formatting operation is performed on msg when no args are supplied. There are four keyword arguments in kwargs which are inspected: exc_info, stack_info, stacklevel and extra. If exc_info does not evaluate as false, it causes exception information to be added to the logging message. If an exception tuple (in the format returned by ) or an exception instance is provided, it is used; otherwise, is called to get the exception information. The second optional keyword argument is stack_info, which defaults to . If true, stack information is added to the logging message, including the actual logging call. Note that this is not the same stack information as that displayed through specifying exc_info: The former is stack frames from the bottom of the stack up to the logging call in the current thread, whereas the latter is information about stack frames which have been unwound, following an exception, while searching for exception handlers. You can specify stack_info independently of exc_info, e.g. to just show how you got to a certain point in your code, even when no exceptions were raised. The stack frames are printed following a header line which says: This mimics the which is used when displaying exception frames. The third optional keyword argument is stacklevel, which defaults to . If greater than 1, the corresponding number of stack frames are skipped when computing the line number and function name set in the created for the logging event. This can be used in logging helpers so that the function name, filename and line number recorded are not the information for the helper function/method, but rather its caller. The name of this parameter mirrors the equivalent one in the module. The fourth keyword argument is extra which can be used to pass a dictionary which is used to populate the of the created for the logging event with user-defined attributes. These custom attributes can then be used as you like. For example, they could be incorporated into logged messages. For example: would print something like The keys in the dictionary passed in extra should not clash with the keys used by the logging system. (See the section on LogRecord attributes for more information on which keys are used by the logging system.) If you choose to use these attributes in logged messages, you need to exercise some care. In the above example, for instance, the has been set up with a format string which expects ‘clientip’ and ‘user’ in the attribute dictionary of the . If these are missing, the message will not be logged because a string formatting exception will occur. So in this case, you always need to pass the extra dictionary with these keys. While this might be annoying, this feature is intended for use in specialized circumstances, such as multi-threaded servers where the same code executes in many contexts, and interesting conditions which arise are dependent on this context (such as remote client IP address and authenticated user name, in the above example). In such circumstances, it is likely that specialized s would be used with particular s. If no handler is attached to this logger (or any of its ancestors, taking into account the relevant attributes), the message will be sent to the handler set on . Changed in version 3.2: The stack_info parameter was added. Changed in version 3.5: The exc_info parameter can now accept exception instances. Changed in version 3.8: The stacklevel parameter was added. Logs a message with level on this logger. The arguments are interpreted as for . Logs a message with level on this logger. The arguments are interpreted as for . There is an obsolete method which is functionally identical to . As is deprecated, please do not use it - use instead. Logs a message with level on this logger. The arguments are interpreted as for . Logs a message with level on this logger. The arguments are interpreted as for . Logs a message with integer level level on this logger. The other arguments are interpreted as for . Logs a message with level on this logger. The arguments are interpreted as for . Exception info is added to the logging message. This method should only be called from an exception handler. Adds the specified filter filter to this logger. Removes the specified filter filter from this logger. Apply this logger’s filters to the record and return if the record is to be processed. The filters are consulted in turn, until one of them returns a false value. If none of them return a false value, the record will be processed (passed to handlers). If one returns a false value, no further processing of the record occurs. Adds the specified handler hdlr to this logger. Removes the specified handler hdlr from this logger. Finds the caller’s source filename and line number. Returns the filename, line number, function name and stack information as a 4-element tuple. The stack information is returned as unless stack_info is . The stacklevel parameter is passed from code calling the and other APIs. If greater than 1, the excess is used to skip stack frames before determining the values to be returned. This will generally be useful when calling logging APIs from helper/wrapper code, so that the information in the event log refers not to the helper/wrapper code, but to the code that calls it. Handles a record by passing it to all handlers associated with this logger and its ancestors (until a false value of propagate is found). This method is used for unpickled records received from a socket, as well as those created locally. Logger-level filtering is applied using . This is a factory method which can be overridden in subclasses to create specialized instances. Checks to see if this logger has any handlers configured. This is done by looking for handlers in this logger and its parents in the logger hierarchy. Returns if a handler was found, else . The method stops searching up the hierarchy whenever a logger with the ‘propagate’ attribute set to false is found - that will be the last logger which is checked for the existence of handlers. Changed in version 3.7: Loggers can now be pickled and unpickled.\n\ncan be used by and for more sophisticated filtering than is provided by levels. The base filter class only allows events which are below a certain point in the logger hierarchy. For example, a filter initialized with ‘A.B’ will allow events logged by loggers ‘A.B’, ‘A.B.C’, ‘A.B.C.D’, ‘A.B.D’ etc. but not ‘A.BB’, ‘B.A.B’ etc. If initialized with the empty string, all events are passed. Returns an instance of the class. If name is specified, it names a logger which, together with its children, will have its events allowed through the filter. If name is the empty string, allows every event. Is the specified record to be logged? Returns false for no, true for yes. Filters can either modify log records in-place or return a completely different record instance which will replace the original log record in any future processing of the event. Note that filters attached to handlers are consulted before an event is emitted by the handler, whereas filters attached to loggers are consulted whenever an event is logged (using , , etc.), before sending an event to handlers. This means that events which have been generated by descendant loggers will not be filtered by a logger’s filter setting, unless the filter has also been applied to those descendant loggers. You don’t actually need to subclass : you can pass any instance which has a method with the same semantics. Changed in version 3.2: You don’t need to create specialized classes, or use other classes with a method: you can use a function (or other callable) as a filter. The filtering logic will check to see if the filter object has a attribute: if it does, it’s assumed to be a and its method is called. Otherwise, it’s assumed to be a callable and called with the record as the single parameter. The returned value should conform to that returned by . Changed in version 3.12: You can now return a instance from filters to replace the log record rather than modifying it in place. This allows filters attached to a to modify the log record before it is emitted, without having side effects on other handlers. Although filters are used primarily to filter records based on more sophisticated criteria than levels, they get to see every record which is processed by the handler or logger they’re attached to: this can be useful if you want to do things like counting how many records were processed by a particular logger or handler, or adding, changing or removing attributes in the being processed. Obviously changing the LogRecord needs to be done with some care, but it does allow the injection of contextual information into logs (see Using Filters to impart contextual information).\n\nThe LogRecord has a number of attributes, most of which are derived from the parameters to the constructor. (Note that the names do not always correspond exactly between the LogRecord constructor parameters and the LogRecord attributes.) These attributes can be used to merge data from the record into the format string. The following table lists (in alphabetical order) the attribute names, their meanings and the corresponding placeholder in a %-style format string. If you are using {}-formatting ( ), you can use as the placeholder in the format string. If you are using $-formatting ( ), use the form . In both cases, of course, replace with the actual attribute name you want to use. In the case of {}-formatting, you can specify formatting flags by placing them after the attribute name, separated from it with a colon. For example: a placeholder of would format a millisecond value of as . Refer to the documentation for full details on the options available to you. You shouldn’t need to format this yourself. The tuple of arguments merged into to produce , or a dict whose values are used for the merge (when there is only one argument, and it is a dictionary). Human-readable time when the was created. By default this is of the form ‘2003-07-08 16:49:45,896’ (the numbers after the comma are millisecond portion of the time). Time when the was created (as returned by / 1e9). You shouldn’t need to format this yourself. Exception tuple (à la ) or, if no exception has occurred, . Name of function containing the logging call. Source line number where the logging call was issued (if available). The logged message, computed as . This is set when is invoked. Millisecond portion of the time when the was created. You shouldn’t need to format this yourself. The format string passed in the original logging call. Merged with to produce , or an arbitrary object (see Using arbitrary objects as messages). Name of the logger used to log the call. Full pathname of the source file where the logging call was issued (if available). Process name (if available). Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded. You shouldn’t need to format this yourself. Stack frame information (where available) from the bottom of the stack in the current thread, up to and including the stack frame of the logging call which resulted in the creation of this record. Thread name (if available). name (if available).\n\nIn addition to the classes described above, there are a number of module-level functions. Return a logger with the specified name or, if name is , return the root logger of the hierarchy. If specified, the name is typically a dot-separated hierarchical name like ‘a’, ‘a.b’ or ‘a.b.c.d’. Choice of these names is entirely up to the developer who is using logging, though it is recommended that be used unless you have a specific reason for not doing that, as mentioned in Logger Objects. All calls to this function with a given name return the same logger instance. This means that logger instances never need to be passed between different parts of an application. Return either the standard class, or the last class passed to . This function may be called from within a new class definition, to ensure that installing a customized class will not undo customizations already applied by other code. For example: Return a callable which is used to create a . Added in version 3.2: This function has been provided, along with , to allow developers more control over how the representing a logging event is constructed. See for more information about the how the factory is called. This is a convenience function that calls , on the root logger. The handling of the arguments is in every way identical to what is described in that method. The only difference is that if the root logger has no handlers, then is called, prior to calling on the root logger. For very short scripts or quick demonstrations of facilities, and the other module-level functions may be convenient. However, most programs will want to carefully and explicitly control the logging configuration, and should therefore prefer creating a module-level logger and calling (or other level-specific methods) on it, as described at the beginnning of this documentation. Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . There is an obsolete function which is functionally identical to . As is deprecated, please do not use it - use instead. Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Exception info is added to the logging message. This function should only be called from an exception handler. Logs a message with level level on the root logger. The arguments and behavior are otherwise the same as for . Provides an overriding level level for all loggers which takes precedence over the logger’s own level. When the need arises to temporarily throttle logging output down across the whole application, this function can be useful. Its effect is to disable all logging calls of severity level and below, so that if you call it with a value of INFO, then all INFO and DEBUG events would be discarded, whereas those of severity WARNING and above would be processed according to the logger’s effective level. If is called, it effectively removes this overriding level, so that logging output again depends on the effective levels of individual loggers. Note that if you have defined any custom logging level higher than (this is not recommended), you won’t be able to rely on the default value for the level parameter, but will have to explicitly supply a suitable value. Changed in version 3.7: The level parameter was defaulted to level . See bpo-28524 for more information about this change. Associates level level with text levelName in an internal dictionary, which is used to map numeric levels to a textual representation, for example when a formats a message. This function can also be used to define your own levels. The only constraints are that all levels used must be registered using this function, levels should be positive integers and they should increase in increasing order of severity. If you are thinking of defining your own levels, please see the section on Custom Levels. Returns a mapping from level names to their corresponding logging levels. For example, the string “CRITICAL” maps to . The returned mapping is copied from an internal mapping on each call to this function. Returns the textual or numeric representation of logging level level. If level is one of the predefined levels , , , or then you get the corresponding string. If you have associated levels with names using then the name you have associated with level is returned. If a numeric value corresponding to one of the defined levels is passed in, the corresponding string representation is returned. The level parameter also accepts a string representation of the level such as ‘INFO’. In such cases, this functions returns the corresponding numeric value of the level. If no matching numeric or string value is passed in, the string ‘Level %s’ % level is returned. Levels are internally integers (as they need to be compared in the logging logic). This function is used to convert between an integer level and the level name displayed in the formatted log output by means of the format specifier (see LogRecord attributes), and vice versa. Changed in version 3.4: In Python versions earlier than 3.4, this function could also be passed a text level, and would return the corresponding numeric value of the level. This undocumented behaviour was considered a mistake, and was removed in Python 3.4, but reinstated in 3.4.2 due to retain backward compatibility. Returns a handler with the specified name, or if there is no handler with that name. Returns an immutable set of all known handler names. Creates and returns a new instance whose attributes are defined by attrdict. This function is useful for taking a pickled attribute dictionary, sent over a socket, and reconstituting it as a instance at the receiving end. Does basic configuration for the logging system by creating a with a default and adding it to the root logger. The functions , , , and will call automatically if no handlers are defined for the root logger. This function does nothing if the root logger already has handlers configured, unless the keyword argument force is set to . This function should be called from the main thread before other threads are started. In versions of Python prior to 2.7.1 and 3.2, if this function is called from multiple threads, it is possible (in rare circumstances) that a handler will be added to the root logger more than once, leading to unexpected results such as messages being duplicated in the log. The following keyword arguments are supported. Specifies that a be created, using the specified filename, rather than a . If filename is specified, open the file in this mode. Defaults to . Use the specified format string for the handler. Defaults to attributes , and separated by colons. Use the specified date/time format, as accepted by . If format is specified, use this style for the format string. One of , or for printf-style, or respectively. Defaults to . Set the root logger level to the specified level. Use the specified stream to initialize the . Note that this argument is incompatible with filename - if both are present, a is raised. If specified, this should be an iterable of already created handlers to add to the root logger. Any handlers which don’t already have a formatter set will be assigned the default formatter created in this function. Note that this argument is incompatible with filename or stream - if both are present, a is raised. If this keyword argument is specified as true, any existing handlers attached to the root logger are removed and closed, before carrying out the configuration as specified by the other arguments. If this keyword argument is specified along with filename, its value is used when the is created, and thus used when opening the output file. If this keyword argument is specified along with filename, its value is used when the is created, and thus used when opening the output file. If not specified, the value ‘backslashreplace’ is used. Note that if is specified, it will be passed as such to , which means that it will be treated the same as passing ‘errors’. Changed in version 3.2: The style argument was added. Changed in version 3.3: The handlers argument was added. Additional checks were added to catch situations where incompatible arguments are specified (e.g. handlers together with stream or filename, or stream together with filename). Changed in version 3.8: The force argument was added. Changed in version 3.9: The encoding and errors arguments were added. Informs the logging system to perform an orderly shutdown by flushing and closing all handlers. This should be called at application exit and no further use of the logging system should be made after this call. When the logging module is imported, it registers this function as an exit handler (see ), so normally there’s no need to do that manually. Tells the logging system to use the class klass when instantiating a logger. The class should define such that only a name argument is required, and the should call . This function is typically called before any loggers are instantiated by applications which need to use custom logger behavior. After this call, as at any other time, do not instantiate loggers directly using the subclass: continue to use the API to get your loggers. Set a callable which is used to create a . factory – The factory callable to be used to instantiate a log record. Added in version 3.2: This function has been provided, along with , to allow developers more control over how the representing a logging event is constructed. The factory has the following signature: The full pathname of the file where the logging call was made. The line number in the file where the logging call was made. The arguments for the logging message. The name of the function or method which invoked the logging call. A stack traceback such as is provided by , showing the call hierarchy."
    },
    {
        "link": "https://docs.python.org/3/howto/logging.html",
        "document": "This page contains tutorial information. For links to reference information and a logging cookbook, please see Other resources.\n\nLogging is a means of tracking events that happen when some software runs. The software’s developer adds logging calls to their code to indicate that certain events have occurred. An event is described by a descriptive message which can optionally contain variable data (i.e. data that is potentially different for each occurrence of the event). Events also have an importance which the developer ascribes to the event; the importance can also be called the level or severity. When to use logging¶ You can access logging functionality by creating a logger via , and then calling the logger’s , , , and methods. To determine when to use logging, and to see which logger methods to use when, see the table below. It states, for each of a set of common tasks, the best tool to use for that task. The best tool for the task Display console output for ordinary usage of a command line script or program Report events that occur during normal operation of a program (e.g. for status monitoring or fault investigation) A logger’s (or method for very detailed output for diagnostic purposes) in library code if the issue is avoidable and the client application should be modified to eliminate the warning A logger’s method if there is nothing the client application can do about the situation, but the event should still be noted Report an error regarding a particular runtime event Report suppression of an error without raising an exception (e.g. error handler in a long-running server process) A logger’s , or method as appropriate for the specific error and application domain The logger methods are named after the level or severity of the events they are used to track. The standard levels and their applicability are described below (in increasing order of severity): Detailed information, typically of interest only when diagnosing problems. Confirmation that things are working as expected. An indication that something unexpected happened, or indicative of some problem in the near future (e.g. ‘disk space low’). The software is still working as expected. Due to a more serious problem, the software has not been able to perform some function. A serious error, indicating that the program itself may be unable to continue running. The default level is , which means that only events of this severity and higher will be tracked, unless the logging package is configured to do otherwise. Events that are tracked can be handled in different ways. The simplest way of handling tracked events is to print them to the console. Another common way is to write them to a disk file. A very simple example is: # will print a message to the console # will not print anything If you type these lines into a script and run it, you’ll see: printed out on the console. The message doesn’t appear because the default level is . The printed message includes the indication of the level and the description of the event provided in the logging call, i.e. ‘Watch out!’. The actual output can be formatted quite flexibly if you need that; formatting options will also be explained later. Notice that in this example, we use functions directly on the module, like , rather than creating a logger and calling functions on it. These functions operation on the root logger, but can be useful as they will call for you if it has not been called yet, like in this example. In larger programs you’ll usually want to control the logging configuration explicitly however - so for that reason as well as others, it’s better to create loggers and call their methods. A very common situation is that of recording logging events in a file, so let’s look at that next. Be sure to try the following in a newly started Python interpreter, and don’t just continue from the session described above: 'This message should go to the log file' 'And non-ASCII stuff, too, like Øresund and Malmö' Changed in version 3.9: The encoding argument was added. In earlier Python versions, or if not specified, the encoding used is the default value used by . While not shown in the above example, an errors argument can also now be passed, which determines how encoding errors are handled. For available values and the default, see the documentation for . And now if we open the file and look at what we have, we should find the log messages: DEBUG:__main__:This message should go to the log file INFO:__main__:So should this WARNING:__main__:And this, too ERROR:__main__:And non-ASCII stuff, too, like Øresund and Malmö This example also shows how you can set the logging level which acts as the threshold for tracking. In this case, because we set the threshold to , all of the messages were printed. If you want to set the logging level from a command-line option such as: and you have the value of the parameter passed for in some variable loglevel, you can use: to get the value which you’ll pass to via the level argument. You may want to error check any user input value, perhaps as in the following example: # assuming loglevel is bound to the string value obtained from the # command line argument. Convert to upper case to allow the user to The call to should come before any calls to a logger’s methods such as , , etc. Otherwise, that logging event may not be handled in the desired manner. If you run the above script several times, the messages from successive runs are appended to the file example.log. If you want each run to start afresh, not remembering the messages from earlier runs, you can specify the filemode argument, by changing the call in the above example to: The output will be the same as before, but the log file is no longer appended to, so the messages from earlier runs are lost. To log variable data, use a format string for the event description message and append the variable data as arguments. For example: As you can see, merging of variable data into the event description message uses the old, %-style of string formatting. This is for backwards compatibility: the logging package pre-dates newer formatting options such as and . These newer formatting options are supported, but exploring them is outside the scope of this tutorial: see Using particular formatting styles throughout your application for more information. To change the format which is used to display messages, you need to specify the format you want to use: 'This message should appear on the console' DEBUG:This message should appear on the console INFO:So should this WARNING:And this, too Notice that the ‘root’ which appeared in earlier examples has disappeared. For a full set of things that can appear in format strings, you can refer to the documentation for LogRecord attributes, but for simple usage, you just need the levelname (severity), message (event description, including variable data) and perhaps to display when the event occurred. This is described in the next section. That concludes the basic tutorial. It should be enough to get you up and running with logging. There’s a lot more that the logging package offers, but to get the best out of it, you’ll need to invest a little more of your time in reading the following sections. If you’re ready for that, grab some of your favourite beverage and carry on. If your logging needs are simple, then use the above examples to incorporate logging into your own scripts, and if you run into problems or don’t understand something, please post a question on the comp.lang.python Usenet group (available at https://groups.google.com/g/comp.lang.python) and you should receive help before too long. Still here? You can carry on reading the next few sections, which provide a slightly more advanced/in-depth tutorial than the basic one above. After that, you can take a look at the Logging Cookbook.\n\nThe logging library takes a modular approach and offers several categories of components: loggers, handlers, filters, and formatters.\n• None Loggers expose the interface that application code directly uses.\n• None Handlers send the log records (created by loggers) to the appropriate destination.\n• None Filters provide a finer grained facility for determining which log records to output.\n• None Formatters specify the layout of log records in the final output. Log event information is passed between loggers, handlers, filters and formatters in a instance. Logging is performed by calling methods on instances of the class (hereafter called loggers). Each instance has a name, and they are conceptually arranged in a namespace hierarchy using dots (periods) as separators. For example, a logger named ‘scan’ is the parent of loggers ‘scan.text’, ‘scan.html’ and ‘scan.pdf’. Logger names can be anything you want, and indicate the area of an application in which a logged message originates. A good convention to use when naming loggers is to use a module-level logger, in each module which uses logging, named as follows: This means that logger names track the package/module hierarchy, and it’s intuitively obvious where events are logged just from the logger name. The root of the hierarchy of loggers is called the root logger. That’s the logger used by the functions , , , and , which just call the same-named method of the root logger. The functions and the methods have the same signatures. The root logger’s name is printed as ‘root’ in the logged output. It is, of course, possible to log messages to different destinations. Support is included in the package for writing log messages to files, HTTP GET/POST locations, email via SMTP, generic sockets, queues, or OS-specific logging mechanisms such as syslog or the Windows NT event log. Destinations are served by handler classes. You can create your own log destination class if you have special requirements not met by any of the built-in handler classes. By default, no destination is set for any logging messages. You can specify a destination (such as console or file) by using as in the tutorial examples. If you call the functions , , , and , they will check to see if no destination is set; and if one is not set, they will set a destination of the console ( ) and a default format for the displayed message before delegating to the root logger to do the actual message output. The default format set by for messages is: You can change this by passing a format string to with the format keyword argument. For all options regarding how a format string is constructed, see Formatter Objects. The flow of log event information in loggers and handlers is illustrated in the following diagram. At least one handler objects have a threefold job. First, they expose several methods to application code so that applications can log messages at runtime. Second, logger objects determine which log messages to act upon based upon severity (the default filtering facility) or filter objects. Third, logger objects pass along relevant log messages to all interested log handlers. The most widely used methods on logger objects fall into two categories: configuration and message sending. These are the most common configuration methods:\n• None specifies the lowest-severity log message a logger will handle, where debug is the lowest built-in severity level and critical is the highest built-in severity. For example, if the severity level is INFO, the logger will handle only INFO, WARNING, ERROR, and CRITICAL messages and will ignore DEBUG messages.\n• None and add and remove handler objects from the logger object. Handlers are covered in more detail in Handlers.\n• None and add and remove filter objects from the logger object. Filters are covered in more detail in Filter Objects. You don’t need to always call these methods on every logger you create. See the last two paragraphs in this section. With the logger object configured, the following methods create log messages:\n• None , , , , and all create log records with a message and a level that corresponds to their respective method names. The message is actually a format string, which may contain the standard string substitution syntax of , , , and so on. The rest of their arguments is a list of objects that correspond with the substitution fields in the message. With regard to , the logging methods care only about a keyword of and use it to determine whether to log exception information.\n• None creates a log message similar to . The difference is that dumps a stack trace along with it. Call this method only from an exception handler.\n• None takes a log level as an explicit argument. This is a little more verbose for logging messages than using the log level convenience methods listed above, but this is how to log at custom log levels. returns a reference to a logger instance with the specified name if it is provided, or if not. The names are period-separated hierarchical structures. Multiple calls to with the same name will return a reference to the same logger object. Loggers that are further down in the hierarchical list are children of loggers higher up in the list. For example, given a logger with a name of , loggers with names of , , and are all descendants of . Loggers have a concept of effective level. If a level is not explicitly set on a logger, the level of its parent is used instead as its effective level. If the parent has no explicit level set, its parent is examined, and so on - all ancestors are searched until an explicitly set level is found. The root logger always has an explicit level set ( by default). When deciding whether to process an event, the effective level of the logger is used to determine whether the event is passed to the logger’s handlers. Child loggers propagate messages up to the handlers associated with their ancestor loggers. Because of this, it is unnecessary to define and configure handlers for all the loggers an application uses. It is sufficient to configure handlers for a top-level logger and create child loggers as needed. (You can, however, turn off propagation by setting the propagate attribute of a logger to .) objects are responsible for dispatching the appropriate log messages (based on the log messages’ severity) to the handler’s specified destination. objects can add zero or more handler objects to themselves with an method. As an example scenario, an application may want to send all log messages to a log file, all log messages of error or higher to stdout, and all messages of critical to an email address. This scenario requires three individual handlers where each handler is responsible for sending messages of a specific severity to a specific location. The standard library includes quite a few handler types (see Useful Handlers); the tutorials use mainly and in its examples. There are very few methods in a handler for application developers to concern themselves with. The only handler methods that seem relevant for application developers who are using the built-in handler objects (that is, not creating custom handlers) are the following configuration methods:\n• None The method, just as in logger objects, specifies the lowest severity that will be dispatched to the appropriate destination. Why are there two methods? The level set in the logger determines which severity of messages it will pass to its handlers. The level set in each handler determines which messages that handler will send on.\n• None selects a Formatter object for this handler to use.\n• None and respectively configure and deconfigure filter objects on handlers. Application code should not directly instantiate and use instances of . Instead, the class is a base class that defines the interface that all handlers should have and establishes some default behavior that child classes can use (or override). Formatter objects configure the final order, structure, and contents of the log message. Unlike the base class, application code may instantiate formatter classes, although you could likely subclass the formatter if your application needs special behavior. The constructor takes three optional arguments – a message format string, a date format string and a style indicator. If there is no message format string, the default is to use the raw message. If there is no date format string, the default date format is: with the milliseconds tacked on at the end. The is one of , , or . If one of these is not specified, then will be used. If the is , the message format string uses styled string substitution; the possible keys are documented in LogRecord attributes. If the style is , the message format string is assumed to be compatible with (using keyword arguments), while if the style is then the message format string should conform to what is expected by . The following message format string will log the time in a human-readable format, the severity of the message, and the contents of the message, in that order: Formatters use a user-configurable function to convert the creation time of a record to a tuple. By default, is used; to change this for a particular formatter instance, set the attribute of the instance to a function with the same signature as or . To change it for all formatters, for example if you want all logging times to be shown in GMT, set the attribute in the Formatter class (to for GMT display). Programmers can configure logging in three ways:\n• None Creating loggers, handlers, and formatters explicitly using Python code that calls the configuration methods listed above.\n• None Creating a logging config file and reading it using the function.\n• None Creating a dictionary of configuration information and passing it to the function. For the reference documentation on the last two options, see Configuration functions. The following example configures a very simple logger, a console handler, and a simple formatter using Python code: Running this module from the command line produces the following output: The following Python module creates a logger, handler, and formatter nearly identical to those in the example listed above, with the only difference being the names of the objects: Here is the logging.conf file: The output is nearly identical to that of the non-config-file-based example: You can see that the config file approach has a few advantages over the Python code approach, mainly separation of configuration and code and the ability of noncoders to easily modify the logging properties. The function takes a default parameter, , which defaults to for reasons of backward compatibility. This may or may not be what you want, since it will cause any non-root loggers existing before the call to be disabled unless they (or an ancestor) are explicitly named in the configuration. Please refer to the reference documentation for more information, and specify for this parameter if you wish. The dictionary passed to can also specify a Boolean value with key , which if not specified explicitly in the dictionary also defaults to being interpreted as . This leads to the logger-disabling behaviour described above, which may not be what you want - in which case, provide the key explicitly with a value of . Note that the class names referenced in config files need to be either relative to the logging module, or absolute values which can be resolved using normal import mechanisms. Thus, you could use either (relative to the logging module) or (for a class defined in package and module , where is available on the Python import path). In Python 3.2, a new means of configuring logging has been introduced, using dictionaries to hold configuration information. This provides a superset of the functionality of the config-file-based approach outlined above, and is the recommended configuration method for new applications and deployments. Because a Python dictionary is used to hold configuration information, and since you can populate that dictionary using different means, you have more options for configuration. For example, you can use a configuration file in JSON format, or, if you have access to YAML processing functionality, a file in YAML format, to populate the configuration dictionary. Or, of course, you can construct the dictionary in Python code, receive it in pickled form over a socket, or use whatever approach makes sense for your application. Here’s an example of the same configuration as above, in YAML format for the new dictionary-based approach: For more information about logging using a dictionary, see Configuration functions. What happens if no configuration is provided¶ If no logging configuration is provided, it is possible to have a situation where a logging event needs to be output, but no handlers can be found to output the event. The event is output using a ‘handler of last resort’, stored in . This internal handler is not associated with any logger, and acts like a which writes the event description message to the current value of (therefore respecting any redirections which may be in effect). No formatting is done on the message - just the bare event description message is printed. The handler’s level is set to , so all events at this and greater severities will be output. Changed in version 3.2: For versions of Python prior to 3.2, the behaviour is as follows:\n• None If is (production mode), the event is silently dropped.\n• None If is (development mode), a message ‘No handlers could be found for logger X.Y.Z’ is printed once. To obtain the pre-3.2 behaviour, can be set to . When developing a library which uses logging, you should take care to document how the library uses logging - for example, the names of loggers used. Some consideration also needs to be given to its logging configuration. If the using application does not use logging, and library code makes logging calls, then (as described in the previous section) events of severity and greater will be printed to . This is regarded as the best default behaviour. If for some reason you don’t want these messages printed in the absence of any logging configuration, you can attach a do-nothing handler to the top-level logger for your library. This avoids the message being printed, since a handler will always be found for the library’s events: it just doesn’t produce any output. If the library user configures logging for application use, presumably that configuration will add some handlers, and if levels are suitably configured then logging calls made in library code will send output to those handlers, as normal. A do-nothing handler is included in the logging package: (since Python 3.1). An instance of this handler could be added to the top-level logger of the logging namespace used by the library (if you want to prevent your library’s logged events being output to in the absence of logging configuration). If all logging by a library foo is done using loggers with names matching ‘foo.x’, ‘foo.x.y’, etc. then the code: should have the desired effect. If an organisation produces a number of libraries, then the logger name specified can be ‘orgname.foo’ rather than just ‘foo’. It is strongly advised that you do not log to the root logger in your library. Instead, use a logger with a unique and easily identifiable name, such as the for your library’s top-level package or module. Logging to the root logger will make it difficult or impossible for the application developer to configure the logging verbosity or handlers of your library as they wish. It is strongly advised that you do not add any handlers other than to your library’s loggers. This is because the configuration of handlers is the prerogative of the application developer who uses your library. The application developer knows their target audience and what handlers are most appropriate for their application: if you add handlers ‘under the hood’, you might well interfere with their ability to carry out unit tests and deliver logs which suit their requirements.\n\nThe numeric values of logging levels are given in the following table. These are primarily of interest if you want to define your own levels, and need them to have specific values relative to the predefined levels. If you define a level with the same numeric value, it overwrites the predefined value; the predefined name is lost. Levels can also be associated with loggers, being set either by the developer or through loading a saved logging configuration. When a logging method is called on a logger, the logger compares its own level with the level associated with the method call. If the logger’s level is higher than the method call’s, no logging message is actually generated. This is the basic mechanism controlling the verbosity of logging output. Logging messages are encoded as instances of the class. When a logger decides to actually log an event, a instance is created from the logging message. Logging messages are subjected to a dispatch mechanism through the use of handlers, which are instances of subclasses of the class. Handlers are responsible for ensuring that a logged message (in the form of a ) ends up in a particular location (or set of locations) which is useful for the target audience for that message (such as end users, support desk staff, system administrators, developers). Handlers are passed instances intended for particular destinations. Each logger can have zero, one or more handlers associated with it (via the method of ). In addition to any handlers directly associated with a logger, all handlers associated with all ancestors of the logger are called to dispatch the message (unless the propagate flag for a logger is set to a false value, at which point the passing to ancestor handlers stops). Just as for loggers, handlers can have levels associated with them. A handler’s level acts as a filter in the same way as a logger’s level does. If a handler decides to actually dispatch an event, the method is used to send the message to its destination. Most user-defined subclasses of will need to override this . Defining your own levels is possible, but should not be necessary, as the existing levels have been chosen on the basis of practical experience. However, if you are convinced that you need custom levels, great care should be exercised when doing this, and it is possibly a very bad idea to define custom levels if you are developing a library. That’s because if multiple library authors all define their own custom levels, there is a chance that the logging output from such multiple libraries used together will be difficult for the using developer to control and/or interpret, because a given numeric value might mean different things for different libraries.\n\nFormatting of message arguments is deferred until it cannot be avoided. However, computing the arguments passed to the logging method can also be expensive, and you may want to avoid doing it if the logger will just throw away your event. To decide what to do, you can call the method which takes a level argument and returns true if the event would be created by the Logger for that level of call. You can write code like this: so that if the logger’s threshold is set above , the calls to and are never made. In some cases, can itself be more expensive than you’d like (e.g. for deeply nested loggers where an explicit level is only set high up in the logger hierarchy). In such cases (or if you want to avoid calling a method in tight loops), you can cache the result of a call to in a local or instance variable, and use that instead of calling the method each time. Such a cached value would only need to be recomputed when the logging configuration changes dynamically while the application is running (which is not all that common). There are other optimizations which can be made for specific applications which need more precise control over what logging information is collected. Here’s a list of things you can do to avoid processing during logging which you don’t need: What you don’t want to collect How to avoid collecting it Information about where calls were made from. Set to . This avoids calling , which may help to speed up your code in environments like PyPy (which can’t speed up code that uses ). Current process name when using to manage multiple processes. Current name when using . Also note that the core logging module only includes the basic handlers. If you don’t import and , they won’t take up any memory."
    },
    {
        "link": "https://coralogix.com/blog/python-logging-best-practices-tips",
        "document": "Python is a highly skilled language with a large developer community, which is essential in data science, machine learning, embedded applications, and back-end web and cloud applications.\n\nAnd logging is critical to understanding software behavior in Python. Once logs are in place, log monitoring can be utilized to make sense of what is happening in the software. Python includes several logging libraries that create and direct logs to their assigned targets.\n\n\n\nThis article will go over Python logging best practices to help you get the best log monitoring setup for your organization.\n\nLogging in Python, like other programming languages, is implemented to indicate events that have occurred in software. Logs should include descriptive messages and variable data to communicate the state of the software at the time of logging.\n\nThey also communicate the severity of the event using unique log levels. Logs can be generated using the Python standard library.\n\nThe Python standard library provides a logging module to log events from applications and libraries. Once the Python JSON logger is configured, it becomes part of the Python interpreter process that is running the code.\n\nIn other words, Python logging is global. You can also configure the Python logging subsystem using an external configuration file. The specifications for the logging configuration format are found in the Python standard library documentation.\n\nThe logging library is modular and offers four categories of components:\n• Loggers expose the interface used by the application code.\n• Handlers are created by loggers and send log records to the appropriate destination.\n• Filters can determine which log records are output.\n• Formatters specify the layout of the final log record output.\n\nMultiple logger objects are organized into a tree representing various parts of your system and the different third-party libraries you have installed. When you send a message to one of the loggers, the message gets output on that logger’s handlers using a formatter attached to each handler.\n\n\n\nThe message then propagates the logger tree until it hits the root logger or a logger in the tree configured with .propagate=False. This hierarchy allows logs to be captured up the subtree of loggers, and a single handler could catch all logging messages.\n\nThe logging.Logger objects offer the primary interface to the logging library. These objects provide the logging methods to issue log requests along with the methods to query and modify their state. From here on out, we will refer to Logger objects as loggers.\n\nThe factory function logging.getLogger(name) is typically used to create loggers. By using the factory function, clients can rely on the library to manage loggers and access loggers via their names instead of storing and passing references to loggers.\n\nThe name argument in the factory function is typically a dot-separated hierarchical name, i.e. a.b.c. This naming convention enables the library to maintain a hierarchy of loggers. Specifically, when the factory function creates a logger, the library ensures a logger exists for each level of the hierarchy specified by the name, and every logger in the hierarchy is linked to its parent and child loggers.\n\nEach logger has a threshold logging level to determine whether a log request should be processed. A logger processes a log request if the numeric value of the requested logging level is greater than or equal to the severity of the logger’s threshold logging level.\n\n\n\nClients can retrieve and change the threshold logging level of a logger via Logger.getEffectiveLevel() and Logger.setLevel(level) methods, respectively. When the factory function is used to create a logger, the function sets a logger’s threshold logging level to the threshold logging level of its parent logger as determined by its name.\n\nLog levels allow you to define event severity for each log so they are easily analyzed. Python supports predefined values, which can be found by calling logging.getLevelName(). Predefined log levels include CRITICAL, ERROR, WARNING, INFO, and DEBUG from highest to lowest severity. Developers can also maintain a dictionary of log levels by defining custom levels using logging.getLogger().\n\nPython comes with different methods to read events from the software: print() and logging. Both will communicate event data but pass this information to different storage locations using different methods.\n\nThe print function sends data exclusively to the console. This can be convenient for fast testing as a function is developed, but it is not practical for use in functional software. There are two critical reasons to not use print() in software:\n• If your code is used by other tools or scripts, the user will not know the context of the print messages.\n• When running Python software in containers like Docker, the print messages will not be seen since containers cannot access the console.\n\nThe logging library also provides many features contributing to Python logging best practices. These include identifying the line of the file, function, and time of log events, distinguishing log events by their importance, and providing formatting to keep log messages consistent.\n\nHere are a few code snippets to illustrate how to use the Python logging library.\n\nIn snippet 1, a logger is created with a log level of INFO. Any logs that have a severity less than INFO will not print (i.e. DEBUG logs). A new handler is created and assigned to the logger. New handlers can be added to send logging outputs to streams like sys.stdout or any file-like object.\n\n\n\nA formatter is created and added to the handler to transform log messages into placeholder data. In this formatter, the time of the log request (as an epoch timestamp), the logging level, the logger’s name, the module name, and the log message will all print.\n\nIn snippet 2, an info log states the app has started. When the app is started in the folder /home/kali with the logger created in snippet 1, the following log entry will be generated in the std.out stream:\n\nThis snippet logs an informational message every time data is written successfully via write_data. If a write fails, the snippet logs an error message that includes the stack trace in which the exception occurred. The logs here use positional arguments to enhance the value of the logs and provide more contextual information.\n\nWith the logger created using snippet 1, successful execution of write_data would create a log similar to:\n\nIf the execution fails, then the created log will appear like:\n\nFileNotFoundError: [Errno 2] No such file or directory: ‘/tmp1/tmp_data.txt’\n\nAlternatively to positional arguments, the same outputs could be achieved using complete names as in:\n\nEvery logger offers a shorthand method to log requests by level. Each pre-defined log level is available in shorthand; for example, Logger.error(msg, *args, **kwargs).\n\nIn addition to these shorthand methods, loggers also offer a general method to specify the log level in the arguments. This method is useful when using custom logging levels.\n\nAnother useful method is used for logs inside exception handlers. It issues log requests with the logging level ERROR and captures the current exception as part of the log entry.\n\nIn each of the methods above, the msg and args arguments are combined to create log messages captured by log entries. They each support the keyword argument exc_info to add exception information to log entries and stack_info and stacklevel to add call stack information to log entries. Also, they support the keyword argument extra, which is a dictionary, to pass values relevant to filters, handlers, and formatters.\n\nHow to get started with Python logging\n\nTo get the most out of your Python logging, they need to be set up consistently and ready to analyze. When setting up your Python logging, use these best practices below.\n\nThe logging.getLogger() factory function helps the library manage the mapping from logger names to logger instances and maintain a hierarchy of loggers. In turn, this mapping and hierarchy offer the following benefits:\n• Clients can use the factory function to access the same logger in different application parts by merely retrieving the logger by its name.\n• Only a finite number of loggers are created at runtime (under normal circumstances).\n• Log requests can be propagated up the logger hierarchy.\n• When unspecified, the threshold logging level of a logger can be inferred from its ascendants.\n• The configuration of the logging library can be updated at runtime by merely relying on the logger names.\n\n\n\nUse the shorthand logging.<logging level>() method to log at pre-defined logging levels. Besides making the code a bit shorter, the use of these functions helps partition the logging statements into two sets:\n• Those that issue log requests with pre-defined logging levels.\n• Those that issue log requests with custom logging levels.\n\nThe pre-defined logging levels capture almost all logging scenarios that occur. Most developers are universally familiar with these logging levels across different programming languages, making them easy to understand. The use of these values reduces deployment, configuration, and maintenance burdens.\n\nWhile creating loggers, we can create a logger for each class or create a logger for each module. While the first option enables fine-grained configuration, it leads to more loggers in a program, i.e., one per class. In contrast, the second option can help reduce the number of loggers in a program. So, unless such fine-grained configuration is necessary, create module-level loggers.\n\nUse logging.LoggerAdapter() to inject contextual information into log records. The class can also modify the log message and data provided as part of the request. Since the logging library does not manage these adapters, they cannot be accessed with common names. Use them to inject contextual information local to a module or class.\n• Use filters or .setLogRecordFactor() to inject global contextual information\n\nTwo options exist to seamlessly inject global contextual information (common across an app) into log records. The first option is to use the filter support to modify the log record arguments provided to filters. For example, the following filter injects version information into incoming log records.\n\nThere are two downsides to this option. First, if filters depend on the data in log records, then filters that inject data into log records should be executed before filters that use the injected data. Thus, the order of filters added to loggers and handlers becomes crucial. Second, the option “abuses” the support to filter log records to extend log records.\n\nThe second option is to initialize the logging library with a log record creating a factory function via logging.setLogRecordFactory(). Since the injected contextual information is global, it can be injected into log records when created in the factory function. This ensures the data will be available to every filter, formatter, logger, and handler in the program.\n\nThe downside of this option is that we have to ensure factory functions contributed by different components in a program play nicely with each other. While log record factory functions could be chained, such chaining increases the complexity of programs.\n• Use .disable() to inhibit processing of low-level requests\n\nA logger will process a log request based on the effective logging level. The effective logging level is the higher of two logging levels: the logger’s threshold level and the library-wide level. Set the library-wide logging level using the logging.disable(level) function. This is set to 0 by default so that every log request will be processed.\n\nUsing this function, the software will throttle the logging output of an app by increasing the logging level across the whole app. This can be important to keep log volumes in check in production software.\n\nPython’s logging library is more complicated than simple print() statements. The library has many great features that provide a complete solution for obtaining log data needed to achieve full-stack observability in your software.\n\nHere we show the high-level advantages and disadvantages of the library.\n\nThe Python logging library is highly configurable. Logs can be formatted before printing, can have placeholder data filled in automatically, and can be turned on and off as needed. Logs can also be sent to a number of different locations for easier reading and debugging. All of these settings are codified, so are well-defined for each logger.\n\nIn failures, it is useful to log debugging information showing where and when a failure occurred. These tracebacks can be generated automatically in the Python logging library to help speed up troubleshooting and fixes.\n\nLog levels used in different scenarios can be subjective across a development team. For proper analysis, it is important to keep log levels consistent. Create a well-defined strategy for your team about when to use each logging level available and when a custom level is appropriate.\n\nSince the logging module is so flexible, logging configurations can quickly get complicated. Create a strategy for your team for how each logging module will be defined to keep logs consistent across developers.\n\nLet’s look at an example of a basic logger in Python:\n\nLine 2: create a basicConf function and pass some arguments to create the log file. In this case, we indicate the severity level, date format, filename and file mode to have the function overwrite the log file.\n\nLine 3 to 5: messages for each logging level.\n\nThe default format for log records is SEVERITY: LOGGER: MESSAGE. Hence, if you run the code above as is, you’ll get this output:\n\nRegarding the output, you can set the destination of the log messages. As a first step, you can print messages to the screen using this sample code:\n\nIf your goals are aimed at the Cloud, you can take advantage of Python’s set of logging handlers to redirect content. Currently in beta release, you can write logs to Stackdriver Logging from Python applications by using Google’s Python logging handler included with the Stackdriver Logging client library, or by using the client library to access the API directly. When developing your logger, take into account that the root logger doesn’t use your log handler. Since the Python Client for Stackdriver Logging library also does logging, you may get a recursive loop if the root logger uses your Python log handler.\n\nWhen we use a logging library, we perform/trigger the following common tasks while using the associated concepts (highlighted in bold).\n• A client issues a log request by executing a logging statement. Often, such logging statements invoke a function/method in the logging (library) API by providing the log data and the logging level as arguments. The logging level specifies the importance of the log request. Log data is often a log message, which is a string, along with some extra data to be logged. Often, the logging API is exposed via logger objects.\n• To enable the processing of a request as it threads through the logging library, the logging library creates a log record that represents the log request and captures the corresponding log data.\n• Based on how the logging library is configured (via a logging configuration), the logging library filters the log requests/records. This filtering involves comparing the requested logging level to the threshold logging level and passing the log records through user-provided filters.\n• Handlers process the filtered log records to either store the log data (e.g., write the log data into a file) or perform other actions involving the log data (e.g., send an email with the log data). In some logging libraries, before processing log records, a handler may again filter the log records based on the handler’s logging level and user-provided handler-specific filters. Also, when needed, handlers often rely on user-provided formatters to format log records into strings, i.e., log entries.\n\nIndependent of the logging library, the above tasks are performed in an order similar to that shown in Figure 1.\n\nFigure 1: The flow of tasks when logging via a logging library\n\nEvery logger offers the following logging methods to issue log requests.\n\nEach of these methods is a shorthand to issue log requests with corresponding pre-defined logging levels as the requested logging level.\n\nIn addition to the above methods, loggers also offer the following two methods:\n• issues log requests with explicitly specified logging levels. This method is useful when using custom logging levels.\n• issues log requests with the logging level and that capture the current exception as part of the log entries. Consequently, clients should invoke this method only from an exception handler.\n\nand arguments in the above methods are combined to create log messages captured by log entries. All of the above methods support the keyword argument to add exception information to log entries and and to add call stack information to log entries. Also, they support the keyword argument , which is a dictionary, to pass values relevant to filters, handlers, and formatters.\n\nWhen executed, the above methods perform/trigger all of the tasks shown in Figure 1 and the following two tasks:\n• After deciding to process a log request based on its logging level and the threshold logging level, the logger creates a object to represent the log request in the downstream processing of the request. objects capture the and arguments of logging methods and the exception and call stack information along with source code information. They also capture the keys and values in the extra argument of the logging method as fields.\n• After every handler of a logger has processed a log request, the handlers of its ancestor loggers process the request (in the order they are encountered walking up the logger hierarchy). The field controls this aspect, which is by default.\n\nBeyond logging levels, filters provide a finer means to filter log requests based on the information in a log record, e.g., ignore log requests issued in a specific class. Clients can add and remove filters to/from loggers using and methods, respectively.\n\nThe logging classes introduced in the previous section provide methods to configure their instances and, consequently, customize the use of the logging library. Snippet 1 demonstrates how to use configuration methods. These methods are best used in simple single-file programs.\n\nWhen involved programs (e.g., apps, libraries) use the logging library, a better option is to externalize the configuration of the logging library. Such externalization allows users to customize certain facets of logging in a program (e.g., specify the location of log files, use custom loggers/handlers/formatters/filters) and, hence, ease the deployment and use of the program. We refer to this approach to configuration as data-based approach.\n\nClients can configure the logging library by invoking function. The argument is a dictionary and the following optional keys can be used to specify a configuration.\n\nfilters key maps to a dictionary of strings and dictionaries. The strings serve as filter ids used to refer to filters in the configuration (e.g., adding a filter to a logger) while the mapped dictionaries serve as filter configurations. The string value of the name key in filter configurations is used to construct .\n\nThis configuration snippet results in the creation of a filter that admits all records created by the logger named ‘app.io’ or its descendants.\n\nformatters key maps to a dictionary of strings and dictionaries. The strings serve as formatter ids used to refer to formatters in the configuration (e.g., adding a formatter to a handler) while the mapped dictionaries serve as formatter configurations. The string values of the datefmt and format keys in formatter configurations are used as the date and log entry formatting strings, respectively, to construct instances. The boolean value of the (optional) validate key controls the validation of the format strings during the construction of a formatter.\n\nThis configuration snippet results in the creation of two formatters. A simple formatter with the specified log entry and date formatting strings and detailed formatter with specified log entry formatting string and default date formatting string.\n\nhandlers key maps to a dictionary of strings and dictionaries. The strings serve as handler ids used to refer to handlers in the configuration (e.g., adding a handler to a logger) while the mapped dictionaries serve as handler configurations. The string value of the class key in a handler configuration names the class to instantiate to construct a handler. The string value of the (optional) level key specifies the logging level of the instantiated handler. The string value of the (optional) formatter key specifies the id of the formatter of the handler. Likewise, the list of values of the (optional) filters key specifies the ids of the filters of the handler. The remaining keys are passed as keyword arguments to the handler’s constructor.\n\nThis configuration snippet results in the creation of two handlers:\n• A handler that formats log requests with INFO and higher logging level log via the formatter and emits the resulting log entry into the standard error stream. The key is passed as keyword arguments to constructor.\n\nThe value of the key illustrates how to access objects external to the configuration. The prefixed string refers to the object that is accessible when the string without the ext:// prefix (i.e., sys.stderr) is processed via the normal importing mechanism. Refer to Access to external objects for more details. Refer to Access to internal objects for details about a similar mechanism based on prefix to refer to objects internal to a configuration.\n• An alert handler that formats ERROR and CRITICAL log requests via the formatter and emails the resulting log entry to the given email addresses. The keys , , , and subject are passed as keyword arguments to ’s constructor.\n\nloggers key maps to a dictionary of strings that serve as logger names and dictionaries that serve as logger configurations. The string value of the (optional) key specifies the logging level of the logger. The boolean value of the (optional) key specifies the propagation setting of the logger. The list of values of the (optional) key specifies the ids of the filters of the logger. Likewise, the list of values of the (optional) key specifies the ids of the handlers of the logger.\n\nThis configuration snippet results in the creation of two loggers. The first logger is named app, its threshold logging level is set to WARNING, and it is configured to forward log requests to and handlers. The second logger is named app.io, and its threshold logging level is set to INFO. Since a log request is propagated to the handlers associated with every ascendant logger, every log request with INFO or a higher logging level made via the app.io logger will be propagated to and handled by both and handlers.\n\nroot key maps to a dictionary of configuration for the root logger. The format of the mapped dictionary is the same as the mapped dictionary for a logger.\n\nincremental key maps to either True or False (default). If True, then only logging levels and propagate options of loggers, handlers, and root loggers are processed, and all other bits of the configuration is ignored. This key is useful to alter existing logging configuration. Refer to Incremental Configuration for more details.\n\ndisable_existing_loggers key maps to either (default) or . If , then all existing non-root loggers are disabled as a result of processing this configuration.\n\nAlso, the argument should map the key to 1.\n\nHere’s the complete configuration composed of the above snippets.\n\nThe configuration schema for filters supports a pattern to specify a function to create a filter. In this pattern, a filter configuration maps the () key to the fully qualified name of a filter creating factory function along with a set of keys and values to be passed as keyword arguments to the factory function. In addition, attributes and values can be added to custom filters by mapping the key to a dictionary of attribute names and values.\n\nFor example, the below configuration will cause the invocation of to create a custom filter and the addition of local attribute with the value to this filter.\n\nConfiguration schemas for formatters, handlers, and loggers also support the above pattern. In the case of handlers/loggers, if this pattern and the key occur in the configuration dictionary, then this pattern is used to create handlers/loggers. Refer to User-defined Objects for more details.\n\nThe logging library also supports loading configuration from a -format file via the < function. Since this is an older API that does not provide all of the functionalities offered by the dictionary-based configuration scheme, the use of the function is recommended; hence, we’re not discussing the function and the file format in this tutorial.\n\nWhile the above APIs can be used to update the logging configuration when the client is running (e.g., web services), programming such update mechanisms from scratch can be cumbersome. The function alleviates this issue. This function starts a socket server that accepts new configurations over the wire and loads them via or functions. Refer to for more details.\n\nSince the configuration provided to is nothing but a collection of nested dictionaries, a logging configuration can be easily represented in JSON and YAML format. Consequently, programs can use the module in Python’s standard library or external YAML processing libraries to read and write logging configurations from files.\n\nFor example, the following snippet suffices to load the logging configuration stored in JSON format.\n\nIn the supported configuration scheme, we cannot configure filters to filter beyond simple name-based filtering. For example, we cannot create a filter that admits only log requests created between 6 PM and 6 AM. We need to program such filters in Python and add them to loggers and handlers via factory functions or the method.\n\nWhile logging statements help capture information at locations in a program, they contribute to the cost of the program in terms of execution time (logging statements in loops) and storage (logging lots of data). Although cost-free yet useful logging is impossible, we can reduce the cost of logging by making choices that are informed by performance considerations.\n\nAfter adding logging statements to a program, we can use the support to configure logging (described earlier) to control the execution of logging statements and the associated execution time. In particular, consider the following configuration capabilities when making decisions about logging-related performance.\n• Change logging levels of loggers: This change helps suppress log messages below a certain log level. This helps reduce the execution cost associated with unnecessary creation of log records.\n• Change handlers: This change helps replace slower handlers with faster handlers (e.g., during testing, use a transient handler instead of a persistent handler) and even remove context-irrelevant handlers. This reduces the execution cost associated with unnecessary handling of log records.\n• Change format: This change helps exclude unnecessary parts of a log record from the log (e.g., exclude IP addresses when executing in a single node setting). This reduces the execution cost associated with unnecessary handling of parts of log records.\n\nThe above changes the range over coarser to finer aspects of logging support in Python.\n\nWhile the support to configure logging is powerful, it cannot help control the performance impact of implementation choices baked into the source code. Here are a few such logging-related implementation choices and the reasons why you should consider them when making decisions about logging-related performance.\n\nUpon adding the logging module to Python’s standard library, there were concerns about the execution cost associated with inactive logging statements — logging statements that issue log requests with logging level lower than the threshold logging level of the target logger. For example, how much extra time will a logging statement that invokes add to a program’s execution time when the threshold logging level of logger is ? This concern led to client-side coding patterns (as shown below) that used the threshold logging level of the target logger to control the execution of the logging statement.\n\nToday, this concern is not valid because the logging methods in the class perform similar checks and process the log requests only if the checks pass. For example, as shown below, the above check is performed in the method.\n\nConsequently, inactive logging statements effectively turn into no-op statements and do not contribute to the execution cost of the program.\n\nEven so, one should consider the following two aspects when adding logging statements.\n• Each invocation of a logging method incurs a small overhead associated with the invocation of the logging method and the check to determine if the logging request should proceed, e.g., a million invocations of when threshold logging level of logger was took half a second on a typical laptop. So, while the cost of an inactive logging statement is trivial, the total execution cost of numerous inactive logging statements can quickly add up to be non-trivial.\n• While disabling a logging statement inhibits the processing of log requests, it does not inhibit the calculation/creation of arguments to the logging statement. So, if such calculations/creations are expensive, then they can contribute non-trivially to the execution cost of the program even when the corresponding logging statement is inactive.\n\nClients can construct log messages in two ways: eagerly and lazily.\n• The client constructs the log message and passes it on to the method, e.g., .\n\nThis approach offers formatting flexibility via and the method, but it involves the eager construction of log messages, i.e., before the logging statements are deemed as active.\n• The client provides a -style message format string (as a argument) and the values (as a argument) to construct the log message to the logging method, e.g., . After the logging statement is deemed as active, the logger constructs the log message using the string formatting operator .\n\nThis approach relies on an older and quirky string formatting feature of Python but it involves the lazy construction of log messages.\n\nWhile both approaches result in the same outcome, they exhibit different performance characteristics due to the eagerness and laziness of message construction.\n\nFor example, on a typical laptop, a million inactive invocations of takes 2197ms while a million inactive invocations of takes 1111ms when is a list of four integers. In the case of a million active invocations, the first approach takes 11061ms and the second approach took 10149ms. A savings of 9–50% of the time taken for logging!\n\nSo, the second (lazy) approach is more performant than the first (eager) approach in cases of both inactive and active logging statements. Further, the gains would be larger when the message construction is non-trivial, e.g., use of many arguments, conversion of complex arguments to strings.\n\nBy default, when a log record is created, the following data is captured in the log record:\n• Identifier and name of the current thread.\n• Name of the current process in the multiprocessing framework.\n• Filename, line number, function name, and call stack info of the logging statement.\n\nUnless these bits of data are logged, gathering them unnecessarily increases the execution cost. So, if these bits of data will not be logged, then configure the logging framework to not gather them by setting the following flags.\n\nDo not block the main thread of execution\n\nThere are situations where we may want to log data in the main thread of execution without spending almost any time logging the data. Such situations are common in web services, e.g., a request processing thread needs to log incoming web requests without significantly increasing its response time. We can tackle these situations by separating concerns across threads: a client/main thread creates a log record while a logging thread logs the record. Since the task of logging is often slower as it involves slower resources (e.g., secondary storage) or other services (e.g., logging services such as Coralogix, pub-sub systems such as Kafka), this separation of concerns helps minimize the effort of logging on the execution time of the main/client thread.\n\nThe Python logging library helps handle such situations via the and classes as follows.\n• A pair of and instances are initialized with a queue.\n• When the instance receives a log record from the client, it merely places the log request in its queue while executing in the client’s thread. Given the simplicity of the task performed by the , the client thread hardly pauses.\n• When a log record is available in the queue, the listener retrieves the log record and executes the handlers registered with the listener to handle the log record. In terms of execution, the listener and the registered handlers execute in a dedicated thread that is different from the client thread.\n\nNote: While comes with a default threading strategy, developers are not required to use this strategy to use . Instead, developers can use alternative threading strategies that meet their needs.\n\nThat about wraps it up for this Python logging guide. If you’re looking for a log management solution to centralize your Python logs, check out our easy-to-configure Python integration."
    },
    {
        "link": "https://docs.python.org/3/library/logging.handlers.html",
        "document": "The following useful handlers are provided in the package. Note that three of the handlers ( , and ) are actually defined in the module itself, but have been documented here along with the other handlers.\n\nThe class, located in the module, is a which watches the file it is logging to. If the file changes, it is closed and reopened using the file name. A file change can happen because of usage of programs such as newsyslog and logrotate which perform log file rotation. This handler, intended for use under Unix/Linux, watches the file to see if it has changed since the last emit. (A file is deemed to have changed if its device or inode have changed.) If the file has changed, the old file stream is closed, and the file opened to get a new stream. This handler is not appropriate for use under Windows, because under Windows open log files cannot be moved or renamed - logging opens the files with exclusive locks - and so there is no need for such a handler. Furthermore, ST_INO is not supported under Windows; always returns zero for this value. Returns a new instance of the class. The specified file is opened and used as the stream for logging. If mode is not specified, is used. If encoding is not , it is used to open the file with that encoding. If delay is true, then file opening is deferred until the first call to . By default, the file grows indefinitely. If errors is provided, it determines how encoding errors are handled. Changed in version 3.6: As well as string values, objects are also accepted for the filename argument. Changed in version 3.9: The errors parameter was added. Checks to see if the file has changed. If it has, the existing stream is flushed and closed and the file opened again, typically as a precursor to outputting the record to the file. Outputs the record to the file, but first calls to reopen the file if it has changed.\n\nThe class, located in the module, is the base class for the rotating file handlers, and . You should not need to instantiate this class, but it has attributes and methods you may need to override. The parameters are as for . The attributes are: If this attribute is set to a callable, the method delegates to this callable. The parameters passed to the callable are those passed to . The namer function is called quite a few times during rollover, so it should be as simple and as fast as possible. It should also return the same output every time for a given input, otherwise the rollover behaviour may not work as expected. It’s also worth noting that care should be taken when using a namer to preserve certain attributes in the filename which are used during rotation. For example, expects to have a set of log files whose names contain successive integers, so that rotation works as expected, and deletes old log files (based on the parameter passed to the handler’s initializer) by determining the oldest files to delete. For this to happen, the filenames should be sortable using the date/time portion of the filename, and a namer needs to respect this. (If a namer is wanted that doesn’t respect this scheme, it will need to be used in a subclass of which overrides the method to fit in with the custom naming scheme.) If this attribute is set to a callable, the method delegates to this callable. The parameters passed to the callable are those passed to . Modify the filename of a log file when rotating. This is provided so that a custom filename can be provided. The default implementation calls the ‘namer’ attribute of the handler, if it’s callable, passing the default name to it. If the attribute isn’t callable (the default is ), the name is returned unchanged. default_name – The default name for the log file. The default implementation calls the ‘rotator’ attribute of the handler, if it’s callable, passing the source and dest arguments to it. If the attribute isn’t callable (the default is ), the source is simply renamed to the destination.\n• None source – The source filename. This is normally the base filename, e.g. ‘test.log’.\n• None dest – The destination filename. This is normally what the source is rotated to, e.g. ‘test.log.1’. The reason the attributes exist is to save you having to subclass - you can use the same callables for instances of and . If either the namer or rotator callable raises an exception, this will be handled in the same way as any other exception during an call, i.e. via the method of the handler. If you need to make more significant changes to rotation processing, you can override the methods. For an example, see Using a rotator and namer to customize log rotation processing.\n\nThe class, located in the module, supports rotation of disk log files at certain timed intervals. Returns a new instance of the class. The specified file is opened and used as the stream for logging. On rotating it also sets the filename suffix. Rotating happens based on the product of when and interval. You can use the when to specify the type of interval. The list of possible values is below. Note that they are not case sensitive. Roll over at midnight, if atTime not specified, else at time atTime When using weekday-based rotation, specify ‘W0’ for Monday, ‘W1’ for Tuesday, and so on up to ‘W6’ for Sunday. In this case, the value passed for interval isn’t used. The system will save old log files by appending extensions to the filename. The extensions are date-and-time based, using the strftime format or a leading portion thereof, depending on the rollover interval. When computing the next rollover time for the first time (when the handler is created), the last modification time of an existing log file, or else the current time, is used to compute when the next rotation will occur. If the utc argument is true, times in UTC will be used; otherwise local time is used. If backupCount is nonzero, at most backupCount files will be kept, and if more would be created when rollover occurs, the oldest one is deleted. The deletion logic uses the interval to determine which files to delete, so changing the interval may leave old files lying around. If delay is true, then file opening is deferred until the first call to . If atTime is not , it must be a instance which specifies the time of day when rollover occurs, for the cases where rollover is set to happen “at midnight” or “on a particular weekday”. Note that in these cases, the atTime value is effectively used to compute the initial rollover, and subsequent rollovers would be calculated via the normal interval calculation. If errors is specified, it’s used to determine how encoding errors are handled. Calculation of the initial rollover time is done when the handler is initialised. Calculation of subsequent rollover times is done only when rollover occurs, and rollover occurs only when emitting output. If this is not kept in mind, it might lead to some confusion. For example, if an interval of “every minute” is set, that does not mean you will always see log files with times (in the filename) separated by a minute; if, during application execution, logging output is generated more frequently than once a minute, then you can expect to see log files with times separated by a minute. If, on the other hand, logging messages are only output once every five minutes (say), then there will be gaps in the file times corresponding to the minutes where no output (and hence no rollover) occurred. Changed in version 3.6: As well as string values, objects are also accepted for the filename argument. Changed in version 3.9: The errors parameter was added. Does a rollover, as described above. Outputs the record to the file, catering for rollover as described above. Returns a list of filenames which should be deleted as part of rollover. These are the absolute paths of the oldest backup log files written by the handler.\n\nThe class, located in the module, supports sending logging messages to a remote or local Unix syslog. Returns a new instance of the class intended to communicate with a remote Unix machine whose address is given by address in the form of a tuple. If address is not specified, is used. The address is used to open a socket. An alternative to providing a tuple is providing an address as a string, for example ‘/dev/log’. In this case, a Unix domain socket is used to send the message to the syslog. If facility is not specified, is used. The type of socket opened depends on the socktype argument, which defaults to and thus opens a UDP socket. To open a TCP socket (for use with the newer syslog daemons such as rsyslog), specify a value of . Note that if your server is not listening on UDP port 514, may appear not to work. In that case, check what address you should be using for a domain socket - it’s system dependent. For example, on Linux it’s usually ‘/dev/log’ but on OS/X it’s ‘/var/run/syslog’. You’ll need to check your platform and use the appropriate address (you may need to do this check at runtime if your application needs to run on several platforms). On Windows, you pretty much have to use the UDP option. On macOS 12.x (Monterey), Apple has changed the behaviour of their syslog daemon - it no longer listens on a domain socket. Therefore, you cannot expect to work on this system. See gh-91070 for more information. Closes the socket to the remote host. Tries to create a socket and, if it’s not a datagram socket, connect it to the other end. This method is called during handler initialization, but it’s not regarded as an error if the other end isn’t listening at this point - the method will be called again when emitting an event, if there is no socket at that point. The record is formatted, and then sent to the syslog server. If exception information is present, it is not sent to the server. Changed in version 3.2.1: (See: bpo-12168.) In earlier versions, the message sent to the syslog daemons was always terminated with a NUL byte, because early versions of these daemons expected a NUL terminated message - even though it’s not in the relevant specification (RFC 5424). More recent versions of these daemons don’t expect the NUL byte but strip it off if it’s there, and even more recent daemons (which adhere more closely to RFC 5424) pass the NUL byte on as part of the message. To enable easier handling of syslog messages in the face of all these differing daemon behaviours, the appending of the NUL byte has been made configurable, through the use of a class-level attribute, . This defaults to (preserving the existing behaviour) but can be set to on a instance in order for that instance to not append the NUL terminator. Changed in version 3.3: (See: bpo-12419.) In earlier versions, there was no facility for an “ident” or “tag” prefix to identify the source of the message. This can now be specified using a class-level attribute, defaulting to to preserve existing behaviour, but which can be overridden on a instance in order for that instance to prepend the ident to every message handled. Note that the provided ident must be text, not bytes, and is prepended to the message exactly as is. Encodes the facility and priority into an integer. You can pass in strings or integers - if strings are passed, internal mapping dictionaries are used to convert them to integers. The symbolic values are defined in and mirror the values defined in the header file. Maps a logging level name to a syslog priority name. You may need to override this if you are using custom levels, or if the default algorithm is not suitable for your needs. The default algorithm maps , , , and to the equivalent syslog names, and all other level names to ‘warning’.\n\nThe class, located in the module, supports sending logging messages to a local Windows NT, Windows 2000 or Windows XP event log. Before you can use it, you need Mark Hammond’s Win32 extensions for Python installed. Returns a new instance of the class. The appname is used to define the application name as it appears in the event log. An appropriate registry entry is created using this name. The dllname should give the fully qualified pathname of a .dll or .exe which contains message definitions to hold in the log (if not specified, is used - this is installed with the Win32 extensions and contains some basic placeholder message definitions. Note that use of these placeholders will make your event logs big, as the entire message source is held in the log. If you want slimmer logs, you have to pass in the name of your own .dll or .exe which contains the message definitions you want to use in the event log). The logtype is one of , or , and defaults to . At this point, you can remove the application name from the registry as a source of event log entries. However, if you do this, you will not be able to see the events as you intended in the Event Log Viewer - it needs to be able to access the registry to get the .dll name. The current version does not do this. Determines the message ID, event category and event type, and then logs the message in the NT event log. Returns the event category for the record. Override this if you want to specify your own categories. This version returns 0. Returns the event type for the record. Override this if you want to specify your own types. This version does a mapping using the handler’s typemap attribute, which is set up in to a dictionary which contains mappings for , , , and . If you are using your own levels, you will either need to override this method or place a suitable dictionary in the handler’s typemap attribute. Returns the message ID for the record. If you are using your own messages, you could do this by having the msg passed to the logger being an ID rather than a format string. Then, in here, you could use a dictionary lookup to get the message ID. This version returns 1, which is the base message ID in .\n\nThe class, located in the module, supports sending logging messages to a queue, such as those implemented in the or modules. Along with the class, can be used to let handlers do their work on a separate thread from the one which does the logging. This is important in web applications and also other service applications where threads servicing clients need to respond as quickly as possible, while any potentially slow operations (such as sending an email via ) are done on a separate thread. Returns a new instance of the class. The instance is initialized with the queue to send messages to. The queue can be any queue-like object; it’s used as-is by the method, which needs to know how to send messages to it. The queue is not required to have the task tracking API, which means that you can use instances for queue. If you are using , you should avoid using and instead use . Enqueues the result of preparing the LogRecord. Should an exception occur (e.g. because a bounded queue has filled up), the method is called to handle the error. This can result in the record silently being dropped (if is ) or a message printed to (if is ). Prepares a record for queuing. The object returned by this method is enqueued. The base implementation formats the record to merge the message, arguments, exception and stack information, if present. It also removes unpickleable items from the record in-place. Specifically, it overwrites the record’s and attributes with the merged message (obtained by calling the handler’s method), and sets the , and attributes to . You might want to override this method if you want to convert the record to a dict or JSON string, or send a modified copy of the record while leaving the original intact. The base implementation formats the message with arguments, sets the and attributes to the formatted message and sets the and attributes to to allow pickling and to prevent further attempts at formatting. This means that a handler on the side won’t have the information to do custom formatting, e.g. of exceptions. You may wish to subclass and override this method to e.g. avoid setting to . Note that the / / changes are related to ensuring the record is pickleable, and you might or might not be able to avoid doing that depending on whether your are pickleable. (Note that you may have to consider not only your own code but also code in any libraries that you use.) Enqueues the record on the queue using ; you may want to override this if you want to use blocking behaviour, or a timeout, or a customized queue implementation. When created via configuration using , this attribute will contain a instance for use with this handler. Otherwise, it will be .\n\nThe class, located in the module, supports receiving logging messages from a queue, such as those implemented in the or modules. The messages are received from a queue in an internal thread and passed, on the same thread, to one or more handlers for processing. While is not itself a handler, it is documented here because it works hand-in-hand with . Along with the class, can be used to let handlers do their work on a separate thread from the one which does the logging. This is important in web applications and also other service applications where threads servicing clients need to respond as quickly as possible, while any potentially slow operations (such as sending an email via ) are done on a separate thread. Returns a new instance of the class. The instance is initialized with the queue to send messages to and a list of handlers which will handle entries placed on the queue. The queue can be any queue-like object; it’s passed as-is to the method, which needs to know how to get messages from it. The queue is not required to have the task tracking API (though it’s used if available), which means that you can use instances for queue. If you are using , you should avoid using and instead use . If is , a handler’s level is respected (compared with the level for the message) when deciding whether to pass messages to that handler; otherwise, the behaviour is as in previous Python versions - to always pass each message to each handler. Changed in version 3.5: The argument was added. The base implementation uses . You may want to override this method if you want to use timeouts or work with custom queue implementations. This implementation just returns the passed-in record. You may want to override this method if you need to do any custom marshalling or manipulation of the record before passing it to the handlers. This just loops through the handlers offering them the record to handle. The actual object passed to the handlers is that which is returned from . This starts up a background thread to monitor the queue for LogRecords to process. This asks the thread to terminate, and then waits for it to do so. Note that if you don’t call this before your application exits, there may be some records still left on the queue, which won’t be processed. Writes a sentinel to the queue to tell the listener to quit. This implementation uses . You may want to override this method if you want to use timeouts or work with custom queue implementations."
    },
    {
        "link": "https://climada-python.readthedocs.io/en/stable/guide/Guide_Exception_Logging.html",
        "document": "\n• None In CLIMADA, you cannot use printing. Any output must go into the LOGGER.\n• None For any logging messages, always think about the audience. What would a user or developer need for information? This also implies to carefully think about the correct LOGGER level. For instance, some information is for debugging, then use the debug level. In this case, make sure that the message actually helps the debugging process! Some message might just inform the user about certain default parameters, then use the inform level. See below for more details about logger levels.\n• None Do not overuse the LOGGER. Think about which level of logging. Logging errors must be useful for debugging.\n\nYou can set the level of the LOGGER using . This way you can for instance ‘turn-off’ info messages when you are making an application. For example, setting the logger to the “ERROR” level, use:\n\nWhat levels to use in CLIMADA?\n• None Debug: what you would print while developing/debugging\n• None Info: information for example in the check instance\n• None Warning: whenever CLIMADA fills in values, makes an extrapolation, computes something that might potentially lead to unwanted results (e.g., the 250year damages extrapolated from data over 20 years)\n\nNo known use case:\n• None Error: instead, raise an Error and add the message (raise ValueError(“Error message”))"
    },
    {
        "link": "https://python.land/deep-dives/python-try-except",
        "document": "Python exception handling is the process of identifying and responding to errors in a program. In other words, it is a way to deal with errors that might occur in your program. In this article, you will learn how to handle errors in Python by using the Python and keywords. It will also teach you how to create custom exceptions, which can be used to define your own specific error messages.\n\nWhat is an exception?\n\nAn exception is a condition that arises during a program’s execution. It is a signal that something unexpected happened. Python represents exceptions by an object of a specific type.\n\nIn Python, all built-in, non-system-exiting exceptions are derived from the class. Exceptions have their own descriptive names. For example, if you try to divide a number by zero, you will get a exception, which is also a subclass of the class.\n\nFor a complete hierarchy of all exceptions, you can view the Python manual if you’re interested. Here’s a small excerpt from this hierarchy to illustrate:\n\nIf your knowledge about objects, classes, and inheritance is a bit rusty, you may want to read my article on objects and classes and my article on inheritance first.\n\nWhen something unexpected occurs, we can raise an exception at the point of the error. When an exception is raised, Python stops the current flow of execution and starts looking for an exception handler that can handle it. So what is an exception handler? Here’s where the try and except statements come into play.\n\nAs the illustration demonstrates, we can create a code block by starting with a try statement. This means: try to run this code, but an exception might occur.\n\nAfter our try block, one or more except blocks must follow. This is where the magic happens. These except blocks can catch an exception, as we usually call this. In fact, many other programming languages use a statement called instead of . Each block can handle a specific type of exception.\n\nRemember: classes are hierarchical. For that reason, exceptions are hierarchical as well. Hence, except blocks must go from the most specific, like a , to less specific, like an .\n\nTo demonstrate this, imagine what happens when we start with an except block that catches Exception. This first block would catch everything because most exceptions inherit from this one, rendering the other except blocks useless.\n\nNow let’s first go back to raising an exception. When an exception is raised, the exception handler that’s able to handle the exception can be nearby, but it can also be in a different module. What’s important to realize is that Python won’t just scan your code randomly for an exception handler. Instead, the handler should be somewhere in the call stack.\n\nPlease forget about and for now. I’ll explain them in detail further down in this article. We first need to discuss call stacks to understand how an exception finds its way to an exception handler.\n\nA call stack is an ordered list of functions that are currently being executed. For example, you might call function A, which calls function B, which calls function C. We now have a call stack consisting of A, B, and C. When C raises an exception, Python will look for an exception handler in this call stack, going backward from end to start. It can be in function C (closest to the exception), in function B (somewhat farther), in function A, or even at the top level of the program where we called function A.\n\nIf Python finds a suitable except block, it executes the code in that block. If it doesn’t find one, Python handles the exception by itself. This means it will print the exception and exit the program since it has no clue what to do with it.\n\nI hope you’re still with me! If not, no worries. The examples on this page will hopefully clarify everything. You might want to revisit this section after finishing the entire article.\n\nCatching exceptions with try except\n\nLet’s finally write some actual code! To handle an exception, we need to catch it. As we just learned, we can catch an exception by using the and keywords. When an exception occurs while we are inside the block, the code in the block is executed.\n\nLet’s try a simple example first. As you hopefully know, we can’t divide by the number zero. If we do so anyway, Python will throw and exception called , which is a subclass of :\n\n\n\nIf you call a Python function inside the try block, and an exception occurs in that function, the flow of code execution stops at the point of the exception and the code in the except block is executed. Try doing this again without try and except. You’ll see that Python prints the exception for us. You can do so in the following code crumb:\n\nAlso, note that Python prints the error to stderr if you don’t handle the exception yourself. In the crumb above, this is visible because the output appears in an ‘Error’ tab instead of an ‘Output’ tab.\n\nLet’s try another, more common example. After all, who divides a number by zero, right?\n\nExceptions are likely to occur when interacting with the outside world, e.g., when working with files or networks. For example, if you try to open a file with Python, but that file doesn’t exist, you will get an exception. If you don’t have access to a file due to permissions, you will again get an exception. Let’s see how to handle these exceptions.\n\nPlease do the following:\n• Run the code below, and notice the file name (it doesn’t exist). See what happens.\n• Alter the file name to myfile.txt file and rerun the code. What happens now?\n\nThe file is not found in the first case. You should get this output:\n\nYou’ll still get an error after creating the file in the second case. This time, we’re trying to write to a file that is opened in read-only mode. For more information on these modes, read the article on opening, reading, and writing files with Python. The error should look like this:\n\nAlthough this is an error, it’s not written to the stderr output of the operating system. That’s because we handled the exception ourselves. If you removed the try.. except from the code completely and then try to write to the file in read-only mode, Python will catch the error, force the program to terminate, and show this message:\n\nThe finally and else blocks\n\nRemember the other two blocks that I asked you to forget for a while? Let’s look at those now, starting with the block.\n\nThe block is executed regardless of whether an exception occurs or not. blocks are useful, for example, when you want to close a file or a network connection regardless of what happens. After all, you want to clean up resources to prevent memory leaks.\n\nHere’s an example of this at work, in which we open a file without using the with , forcing us to close it ourselves:\n\nYou can also try this interactive example:\n\nYou should see the ‘Closing the file now’ message printed on your screen. Now change the writing mode to ‘r’ instead of ‘w’. You’ll get an error since the file does not exist. Despite this exception, we try to close the file anyway thanks to the finally block. This in turn goes wrong too: a exception is thrown because the file was never opened, and hence does not exist. You can fix this with a nested . Try it for yourself.\n\nThe else block in try-except\n\nIn addition to the and blocks, you can add an else block. The else block executes only when no exception occurs. So it differs from the finally block, since finally executes even if an exception occurs.\n\nWhen should you use the block? And why shouldn’t you just add extra code to the block? Good questions!\n\nAccording to the Python manual, using the else clause is better than adding additional code to the try clause. But why? The reasoning is that it avoids accidentally catching an exception that wasn’t raised by the code being protected by the try and except statements in the first place. I admit I don’t use else blocks very often myself. Also, I find them somewhat confusing, especially for people coming from other languages.\n\nSome exceptions are so common that you’ll inevitably encounter them. Here are a few of the most common ones:\n\nIf you like, you can try to evoke these exceptions intentionally. I promise you that you will encounter these countless times in your Python programming career. Understanding what they mean and when they occur will greatly help you debug your code.\n\nNow that we know the mechanics of handling exceptions, I’d like to share a couple of best practices with you.\n\nI’ve written about this in the blog post ‘How not to handle exceptions in Python‘. Don’t use a blank block when you want to catch a broad range of exceptions. By this, I mean something like:\n\nYou might encounter this in code samples on the web. If you do, make a habit of improving the exception handling. Why should you, and how can you improve code like the example above?\n\nAll exceptions, including system exceptions, inherit from a class called . If an clause mentions a particular class, that clause also handles any exception classes derived from that class. An empty is equivalent to , hence it will catch all possible exceptions.\n\nSo, although the syntax is allowed, I don’t recommend it. E.g., you’ll also catch KeyboardInterrupt and SystemExit exceptions, which prevent your program from exiting. Instead, use a try block with a list of explicit exceptions you can handle. Or, if you really need to, catch the base class to handle almost all the regular exceptions, but not the system ones.\n\nIf you’re feeling adventurous, you can try to catch all exceptions and see what happens:\n\nYou’ll probably need to close your terminal to stop this program. Now change the except block to catch . You will still catch almost all exceptions, but the program will exit on system exceptions like and :\n\nIt’s better to ask for forgiveness\n\nIn Python, you’ll often see a pattern where people simply try if something works, and if it doesn’t, catch the exception. In other words, it’s better to ask for forgiveness than permission. This is in contrast to other languages, where you preferably ask for permission. For example, in Java, exceptions can slow down your program, and you “ask for permission” by doing checks on an object instead of simply trying.\n\nTo make this more concrete: in Python, we often just try to access the key in a dictionary. If the key doesn’t exist, we’ll get an exception and handle it. Suppose we just converted some externally provided JSON to a dictionary and now start to use it:\n\nThis will print the error:\n\nWe could have added three checks ( if 'name' in user , , etc.) to make sure that all the fields are there. But this is not a good practice. It potentially introduces a lot of code just to check if keys exist. Instead, we ask for forgiveness in our except block once, which is much cleaner and more readable. And if you worry about performance: exceptions don’t take up that many CPU cycles in Python. Lots of comparisons are in fact slower than catching a single exception (if it occurs at all!).\n\nAll built-in, non-system-exiting exceptions are derived from the class as we learned before. All user-defined exceptions should also be derived from this class. So if we want to create our own exceptions, we need to create a subclass of the class.\n\nFor example, if you want to create an exception that indicates that a user was not found, you can create a exception. This would, in its most basic form, look like this:\n\nThis inherits all the properties and methods of , but we give it a new name to distinguish it from the class. This way, we’ll be able to specifically catch it with an except block.\n\nThe name of this exception clearly tells us the type of problem that was encountered, so as an added bonus, it functions as a form of code documentation as well. Just like well-named variables and functions, a well-named exception can be a big difference when reading back your code.\n\nWe’ll use this class in the example that follows.\n\nWe know some built-in exceptions and how to create custom exceptions. We also know how to catch exceptions with try and except. What’s left, is what’s called raising or throwing an exception. You can raise an exception yourself with the raise keyword.\n\nIn the example below, we use your previously defined . We call a function, , that fetches some user data from an imaginary database. If the user is not found, this database returns None. We decided that we don’t want to return None, which would force the caller to check for None every time. Instead, we use our custom .\n\nHere’s a little assignment. We could have used a regular Exception object instead. That way, we don’t need to define a custom one. Why is this a bad idea?\n\nYou can in fact raise a regular exception, e.g. with . But if you do, you need to catch all exceptions of type Exception. And as we know, there are a lot of those. Chances are you inadvertently catch some other exception that you’re not able to handle. For example, the database client might throw a which is also a subclass of .\n\nYou can print exceptions directly as long as you catch them properly. You may have seen examples of this above already. To be clear, here’s an example of how to catch and print an exception:\n\nIf you’d like to print the call stack, just like Python does when you don’t catch the exception yourself, you can import the traceback module:\n\nHere are some more resources to deepen your knowledge:\n• My blog article ‘How not to handle exceptions in Python‘\n• The official documentation on exceptions.\n• The official documentation on errors."
    },
    {
        "link": "https://stackoverflow.com/questions/16138232/is-it-a-good-practice-to-use-try-except-else-in-python",
        "document": "Or if I really do not want to return anything if an exception happens, then:\n\nIt is my understanding that exceptions are not errors , and that they should only be used for exceptional conditions (e.g. I try to write a file into disk and there is no more space, or maybe I do not have permission), and not for flow control.\n\nI do not like that kind of programming, as it is using exceptions to perform flow control. However, if it is included in the language, there must be a good reason for it, isn't it?\n\nWhat is the reason for the try-except-else to exist?\n\nFrom time to time in Python, I see the block:\n\n\"I do not know if it is out of ignorance, but I do not like that kind of programming, as it is using exceptions to perform flow control.\" In the Python world, using exceptions for flow control is common and normal. Even the Python core developers use exceptions for flow-control and that style is heavily baked into the language (i.e. the iterator protocol uses StopIteration to signal loop termination). In addition, the try-except-style is used to prevent the race-conditions inherent in some of the \"look-before-you-leap\" constructs. For example, testing os.path.exists results in information that may be out-of-date by the time you use it. Likewise, Queue.full returns information that may be stale. The try-except-else style will produce more reliable code in these cases. \"It my understanding that exceptions are not errors, they should only be used for exceptional conditions\" In some other languages, that rule reflects their cultural norms as reflected in their libraries. The \"rule\" is also based in-part on performance considerations for those languages. The Python cultural norm is somewhat different. In many cases, you must use exceptions for control-flow. Also, the use of exceptions in Python does not slow the surrounding code and calling code as it does in some compiled languages (i.e. CPython already implements code for exception checking at every step, regardless of whether you actually use exceptions or not). In other words, your understanding that \"exceptions are for the exceptional\" is a rule that makes sense in some other languages, but not for Python. \"However, if it is included in the language itself, there must be a good reason for it, isn't it?\" Besides helping to avoid race-conditions, exceptions are also very useful for pulling error-handling outside loops. This is a necessary optimization in interpreted languages which do not tend to have automatic loop invariant code motion. Also, exceptions can simplify code quite a bit in common situations where the ability to handle an issue is far removed from where the issue arose. For example, it is common to have top level user-interface code calling code for business logic which in turn calls low-level routines. Situations arising in the low-level routines (such as duplicate records for unique keys in database accesses) can only be handled in top-level code (such as asking the user for a new key that doesn't conflict with existing keys). The use of exceptions for this kind of control-flow allows the mid-level routines to completely ignore the issue and be nicely decoupled from that aspect of flow-control. There is a nice blog post on the indispensibility of exceptions here. Also, see this Stack Overflow answer: Are exceptions really for exceptional errors? \"What is the reason for the try-except-else to exist?\" The else-clause itself is interesting. It runs when there is no exception but before the finally-clause. That is its primary purpose. Without the else-clause, the only option to run additional code before finalization would be the clumsy practice of adding the code to the try-clause. That is clumsy because it risks raising exceptions in code that wasn't intended to be protected by the try-block. The use-case of running additional unprotected code prior to finalization doesn't arise very often. So, don't expect to see many examples in published code. It is somewhat rare. Another use-case for the else-clause is to perform actions that must occur when no exception occurs and that do not occur when exceptions are handled. For example: recip = float('Inf') try: recip = 1 / f(x) except ZeroDivisionError: logging.info('Infinite result') else: logging.info('Finite result') Another example occurs in unittest runners: try: tests_run += 1 run_testcase(case) except Exception: tests_failed += 1 logging.exception('Failing test case: %r', case) print('F', end='') else: logging.info('Successful test case: %r', case) print('.', end='') Lastly, the most common use of an else-clause in a try-block is for a bit of beautification (aligning the exceptional outcomes and non-exceptional outcomes at the same level of indentation). This use is always optional and isn't strictly necessary.\n\nWhat is the reason for the try-except-else to exist? A block allows you to handle an expected error. The block should only catch exceptions you are prepared to handle. If you handle an unexpected error, your code may do the wrong thing and hide bugs. An clause will execute if there were no errors, and by not executing that code in the block, you avoid catching an unexpected error. Again, catching an unexpected error can hide bugs. try: try_this(whatever) except SomeException as the_exception: handle(the_exception) else: return something The \"try, except\" suite has two optional clauses, and . So it's actually . will evaluate only if there is no exception from the block. It allows us to simplify the more complicated code below: no_error = None try: try_this(whatever) no_error = True except SomeException as the_exception: handle(the_exception) if no_error: return something so if we compare an to the alternative (which might create bugs) we see that it reduces the lines of code and we can have a more readable, maintainable, and less buggy code-base. will execute no matter what, even if another line is being evaluated with a return statement. It might help to break this down, in the smallest possible form that demonstrates all features, with comments. Assume this syntactically correct (but not runnable unless the names are defined) pseudo-code is in a function. try: try_this(whatever) except SomeException as the_exception: handle_SomeException(the_exception) # Handle a instance of SomeException or a subclass of it. except Exception as the_exception: generic_handle(the_exception) # Handle any other exception that inherits from Exception # - doesn't include GeneratorExit, KeyboardInterrupt, SystemExit # Avoid bare `except:` else: # there was no exception whatsoever return something() # if no exception, the \"something()\" gets evaluated, # but the return will not be executed due to the return in the # finally block below. finally: # this block will execute no matter what, even if no exception, # after \"something\" is eval'd but before that value is returned # but even if there is an exception. # a return here will hijack the return functionality. e.g.: return True # hijacks the return in the else clause above It is true that we could include the code in the block in the block instead, where it would run if there were no exceptions, but what if that code itself raises an exception of the kind we're catching? Leaving it in the block would hide that bug. We want to minimize lines of code in the block to avoid catching exceptions we did not expect, under the principle that if our code fails, we want it to fail loudly. This is a best practice. It is my understanding that exceptions are not errors In Python, most exceptions are errors. We can view the exception hierarchy by using pydoc. For example, in Python 2: Will give us the hierarchy. We can see that most kinds of are errors, although Python uses some of them for things like ending loops ( ). This is Python 3's hierarchy: Say you have a method which pings an external API and you want to handle the exception at a class outside the API wrapper, do you simply return e from the method under the except clause where e is the exception object? No, you don't return the exception, just reraise it with a bare to preserve the stacktrace. try: try_this(whatever) except SomeException as the_exception: handle(the_exception) raise Or, in Python 3, you can raise a new exception and preserve the backtrace with exception chaining: try: try_this(whatever) except SomeException as the_exception: handle(the_exception) raise DifferentException from the_exception I elaborate in my answer here.\n\nPython doesn't subscribe to the idea that exceptions should only be used for exceptional cases, in fact the idiom is 'ask for forgiveness, not permission'. This means that using exceptions as a routine part of your flow control is perfectly acceptable, and in fact, encouraged. This is generally a good thing, as working this way helps avoid some issues (as an obvious example, race conditions are often avoided), and it tends to make code a little more readable. Imagine you have a situation where you take some user input which needs to be processed, but have a default which is already processed. The try: ... except: ... else: ... structure makes for very readable code: try: raw_value = int(input()) except ValueError: value = some_processed_value else: # no error occured value = process_value(raw_value) Compare to how it might work in other languages: raw_value = input() if valid_number(raw_value): value = process_value(int(raw_value)) else: value = some_processed_value Note the advantages. There is no need to check the value is valid and parse it separately, they are done once. The code also follows a more logical progression, the main code path is first, followed by 'if it doesn't work, do this'. The example is naturally a little contrived, but it shows there are cases for this structure.\n\nI'm attempting to answer this question in a slightly different angle. There were 2 parts of the OP's question, and I add the 3rd one, too.\n• What is the reason for the try-except-else to exist?\n• Does the try-except-else pattern, or the Python in general, encourage using exceptions for flow control?\n• When to use exceptions, anyway? Question 1: What is the reason for the try-except-else to exist? It can be answered from a tactical standpoint. There is of course reason for to exist. The only new addition here is the clause, whose usefulness boils down to its uniqueness:\n• None It runs an extra code block ONLY WHEN there was no exception happened in the block.\n• None It runs that extra code block, OUTSIDE of the block (meaning any potential exceptions happen inside the block would NOT be caught).\n• None It runs that extra code block BEFORE the finalization. db = open(...) try: db.insert(something) except Exception: db.rollback() logging.exception('Failing: %s, db is ROLLED BACK', something) else: db.commit() logging.info( 'Successful: %d', # <-- For the sake of demonstration, # there is a typo %d here to trigger an exception. # If you move this section into the try... block, # the flow would unnecessarily go to the rollback path. something) finally: db.close() In the example above, you can't move that successful log line into behind the block. You can't quite move it into inside the block, either, due to the potential exception inside the block. Question 2: does Python encourage using exceptions for flow control? I found no official written documentation to support that claim. (To readers who would disagree: please leave comments with links to evidences you found.) The only vaguely-relevant paragraph that I found, is this EAFP term: Easier to ask for forgiveness than permission. This common Python coding style assumes the existence of valid keys or attributes and catches exceptions if the assumption proves false. This clean and fast style is characterized by the presence of many try and except statements. The technique contrasts with the LBYL style common to many other languages such as C. Such paragraph merely described that, rather than doing this: def make_some_noise(speaker): try: speaker.quack() except AttributeError: logger.warning(\"This speaker is not a duck\") make_some_noise(DonaldDuck()) # This would work make_some_noise(DonaldTrump()) # This would trigger exception or potentially even omitting the try...except: So, the EAFP encourages duck-typing. But it does not encourage using exceptions for flow control. Question 3: In what situation you should design your program to emit exceptions? It is a moot conversation on whether it is anti-pattern to use exception as control flow. Because, once a design decision is made for a given function, its usage pattern would also be determined, and then the caller would have no choice but to use it that way. So, let's go back to the fundamentals to see when a function would better produce its outcome via returning a value or via emitting exception(s). What is the difference between the return value and the exception?\n• None Their \"blast radius\" are different. Return value is only available to the immediate caller; exception can be automatically relayed for unlimited distance until it is caught.\n• None Their distribution patterns are different. Return value is by definition one piece of data (even though you could return a compound data type such as a dictionary or a container object, it is still technically one value). The exception mechanism, on the contrary, allows multiple values (one at a time) to be returned via their respective dedicate channel. Here, each and block is considered as its own dedicate channel. Therefore, it is up to each different scenario to use one mechanism that fits well.\n• None All normal cases should better be returned via return value, because the callers would most likely need to use that return value immediately. The return-value approach also allows nesting layers of callers in a functional programming style. The exception mechanism's long blast radius and multiple channels do not help here. For example, it would be unintuitive if any function named produces its happy path result as an exception. (This is not really a contrived example. There is one practice to implement to use exception to ship the value back in the middle of a deep recursion.)\n• None If the caller would likely forget to handle the error sentinel from the return value, it is probably a good idea to use exception's characterist #2 to save caller from its hidden bug. A typical non-example would be the , unfortunately its return value of or would tend to cause a bug in the caller.\n• None If the error sentinel would collide with a normal value in the result namespace, it is almost certain to use an exception, because you'd have to use a different channel to convey that error.\n• None If the normal channel i.e. the return value is already used in the happy-path, AND the happy-path does NOT have sophisicated flow control, you have no choice but to use exception for flow control. People keep talking about how Python uses exception for iteration termination, and use it to kind of justify \"using exception for flow control\". But IMHO this is only a practical choice in a particular situation, it does not generalize and glorify \"using exception for flow control\". At this point, if you already make a sound decision on whether your function would produce only return-value or also raise exceptions, or if that function is provided by an existing library so that its behavior has long be decided, you do not have much choice in writing its caller . Whether to use 's exception to control the flow in your is merely a matter of whether your business logic requires you to do so. If yes, do it; otherwise, let the exception bubble up to a higher level (this utilizes the characteristic #1 \"long blast radius\" of exception). In particular, if you are implementing a middle-layer library and you happen to be making a dependency on lower-level library , you would probably want to hide your implementation detail, by catching all , , ..., and map them into . In this case, the long blast radius is actually working against us, so you might hope \"only if library Bar were returning its errors via return values\". But then again, that decision has long been made in , so you can just live with it. All in all, I think whether to use exception as control flow is a moot point."
    },
    {
        "link": "https://reddit.com/r/learnpython/comments/1flof8q/best_practices_for_tryexcept_blocks_in_python",
        "document": "I am writing a python script to interact with an instrument. The instrument comes with a python library that I am using in my script.\n\nI am not sure what might be the best practice for using try/except blocks in Python.\n\nWhen there is an error that raises to a level of an exception, I don't want my script to just catch the exception and move on to the next step.\n\nThe step where this error could have occurred might be critical that it is not necessary to proceed with the execution of the remainder of the script.\n\nI am thinking that Approach 2 might be the best approach for my problem. But is it a good practice to do it this way?\n\nThe type of error that raises to the level of exception include: Instrument has a problem that it doesn't want to execute the command, lost communications etc."
    },
    {
        "link": "https://reviewnprep.com/blog/mastering-exception-handling-in-python-real-life-examples-and-best-practices",
        "document": "Welcome to the beginner’s guide to exception handling in Python! As Python continues to dominate the programming world, it’s essential for developers of all levels to master the art of handling exceptions effectively. Whether you’re just starting out or looking to refresh your skills, this comprehensive guide will take you through the ins and outs of exception handling in Python, using practical examples to bring the concepts to life.\n\nException handling plays a crucial role in writing reliable and robust code, ensuring that your programs gracefully handle unexpected errors and prevent crashes. In this guide, we’ll dive deep into the world of exceptions, exploring the different types of exceptions, how to raise and handle them, and the best practices for error handling in Python.\n\nThrough a series of practical examples, you’ll gain hands-on experience in dealing with common exceptions, such as ValueError, FileNotFoundError, and IndexError. By the end of this guide, you’ll have the confidence and skills to tackle any unforeseen errors that come your way, making your Python programs more resilient and user-friendly.\n\nSo let’s get started on this exception handling journey and level up your Python coding skills!\n\nExceptions are error conditions that disrupt the normal flow of a program. They can occur due to a wide range of reasons, such as invalid input, file operations, or unexpected issues during execution.\n\nThese exceptions halt the normal flow of the program. Without exception handling, our Python scripts would crash whenever they encounter an error condition. By leveraging built-in exception handling tools like the try-except block, we can account for potential exceptions and take appropriate actions.\n\nPython has a wide range of built-in exception classes for different types of errors:\n• – Raised when a module/library cannot be imported\n• – Occurs when trying to access an invalid index in a list, tuple, etc\n• – Happens when using an undeclared variable\n• – Indicates two incompatible types are mixed in an operation\n• – Thrown when dividing by zero\n• – Raised when a file cannot be found at a specified path\n\nAnd many more specialized exceptions…\n\nBeing aware of common error types helps write code that catches the exceptions specific to our program logic and use case.\n\nThe basic structure for handling exceptions in Python is the block. It allows you to catch and handle exceptions gracefully:\n\nThe code inside the try clause is executed. If that code raises no exceptions, then no output from except clause is generated. But if an exception occurs, it is caught and the except block with the matching exception type is executed.\n\nWe can thus anticipate errors and ensure the program doesn’t crash if things go wrong.\n\nUsing Multiple Except Blocks for Different Types of Exceptions\n\nYou can use multiple blocks to handle different types of exceptions:\n\nHaving specific except blocks allow handling exceptions differently instead of generic handling.\n\nThe Else Clause and Finally Clause in Exception Handling\n\nThe clause is executed if the code in the block doesn’t raise any exceptions. The clause is always executed, regardless of whether an exception occurred or not:\n\nThe finally clause helps execute cleanup code like closing files, connections etc irrespective of exceptions.\n\nAlong with built-in exceptions, we can define custom exception classes by subclassing Exception:\n\nWe can raise exceptions manually with raise and catch them later:\n\nThis makes code more readable by separating custom error scenarios.\n\nBest Practices for Exception Handling in Python\n\nHere are some best practices to write clean, robust exception handling:\n• Keep try blocks small and focused to properly handle exceptions\n• Catch specific exceptions instead of generic Exception class to differentiate errors\n• Print custom error messages from except blocks upon failures\n• Use finally clause to execute sections of cleanup code reliably\n• Use blocks only where needed.\n• Don’t wrap your entire code in a massive block; limit it to potential error-prone sections.\n• Avoid using without specifying the exception type, as it can catch unintended errors.\n• Use logging to record exceptions for later analysis.\n\nMastering the basics of exception handling in Python is crucial for writing robust and error-resistant code. By understanding common types of exceptions, using try-except blocks effectively, and following best practices, you can create code that gracefully handles unexpected issues, making your applications more reliable and user-friendly.\n\nWhether you’re working on file operations, game development, or any other project, effective exception handling is a skill that will serve you well in your programming journey.\n\nI hope this guide gave you a solid understanding of key exception handling principles along with actionable coding examples. These learnings will help you eliminate crashes in your Python codebase and handle failures gracefully!"
    },
    {
        "link": "https://docs.python.org/3/tutorial/errors.html",
        "document": "Until now error messages haven’t been more than mentioned, but if you have tried out the examples you have probably seen some. There are (at least) two distinguishable kinds of errors: syntax errors and exceptions.\n\nSyntax errors, also known as parsing errors, are perhaps the most common kind of complaint you get while you are still learning Python: The parser repeats the offending line and displays little arrows pointing at the place where the error was detected. Note that this is not always the place that needs to be fixed. In the example, the error is detected at the function , since a colon ( ) is missing just before it. The file name ( in our example) and line number are printed so you know where to look in case the input came from a file.\n\nEven if a statement or expression is syntactically correct, it may cause an error when an attempt is made to execute it. Errors detected during execution are called exceptions and are not unconditionally fatal: you will soon learn how to handle them in Python programs. Most exceptions are not handled by programs, however, and result in error messages as shown here: File , line , in : File , line , in : name 'spam' is not defined File , line , in : can only concatenate str (not \"int\") to str The last line of the error message indicates what happened. Exceptions come in different types, and the type is printed as part of the message: the types in the example are , and . The string printed as the exception type is the name of the built-in exception that occurred. This is true for all built-in exceptions, but need not be true for user-defined exceptions (although it is a useful convention). Standard exception names are built-in identifiers (not reserved keywords). The rest of the line provides detail based on the type of exception and what caused it. The preceding part of the error message shows the context where the exception occurred, in the form of a stack traceback. In general it contains a stack traceback listing source lines; however, it will not display lines read from standard input. Built-in Exceptions lists the built-in exceptions and their meanings.\n\nIt is possible to write programs that handle selected exceptions. Look at the following example, which asks the user for input until a valid integer has been entered, but allows the user to interrupt the program (using - or whatever the operating system supports); note that a user-generated interruption is signalled by raising the exception. \"Oops! That was no valid number. Try again...\" The statement works as follows.\n• None First, the try clause (the statement(s) between the and keywords) is executed.\n• None If no exception occurs, the except clause is skipped and execution of the statement is finished.\n• None If an exception occurs during execution of the clause, the rest of the clause is skipped. Then, if its type matches the exception named after the keyword, the except clause is executed, and then execution continues after the try/except block.\n• None If an exception occurs which does not match the exception named in the except clause, it is passed on to outer statements; if no handler is found, it is an unhandled exception and execution stops with an error message. A statement may have more than one except clause, to specify handlers for different exceptions. At most one handler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other handlers of the same statement. An except clause may name multiple exceptions as a parenthesized tuple, for example: A class in an clause matches exceptions which are instances of the class itself or one of its derived classes (but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order: Note that if the except clauses were reversed (with first), it would have printed B, B, B — the first matching except clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence and types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance which typically has an attribute that stores the arguments. For convenience, builtin exception types define to print all the arguments without explicitly accessing . # __str__ allows args to be printed directly, # but may be overridden in exception subclasses The exception’s output is printed as the last part (‘detail’) of the message for unhandled exceptions. is the common base class of all exceptions. One of its subclasses, , is the base class of all the non-fatal exceptions. Exceptions which are not subclasses of are not typically handled, because they are used to indicate that the program should terminate. They include which is raised by and which is raised when a user wishes to interrupt the program. can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific as possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate on. The most common pattern for handling is to print or log the exception and then re-raise it (allowing a caller to handle the exception as well): \"Could not convert data to an integer.\" The … statement has an optional else clause, which, when present, must follow all except clauses. It is useful for code that must be executed if the try clause does not raise an exception. For example: The use of the clause is better than adding additional code to the clause because it avoids accidentally catching an exception that wasn’t raised by the code being protected by the … statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur inside functions that are called (even indirectly) in the try clause. For example:\n\nThe statement allows the programmer to force a specified exception to occur. For example: The sole argument to indicates the exception to be raised. This must be either an exception instance or an exception class (a class that derives from , such as or one of its subclasses). If an exception class is passed, it will be implicitly instantiated by calling its constructor with no arguments: If you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the statement allows you to re-raise the exception:\n\nIf an unhandled exception occurs inside an section, it will have the exception being handled attached to it and included in the error message: File , line , in : [Errno 2] No such file or directory: 'database.sqlite' During handling of the above exception, another exception occurred: File , line , in : To indicate that an exception is a direct consequence of another, the statement allows an optional clause: # exc must be exception instance or None. This can be useful when you are transforming exceptions. For example: File , line , in File , line , in The above exception was the direct cause of the following exception: File , line , in : It also allows disabling automatic exception chaining using the idiom: For more information about chaining mechanics, see Built-in Exceptions.\n\nThe statement has another optional clause which is intended to define clean-up actions that must be executed under all circumstances. For example: If a clause is present, the clause will execute as the last task before the statement completes. The clause runs whether or not the statement produces an exception. The following points discuss more complex cases when an exception occurs:\n• None If an exception occurs during execution of the clause, the exception may be handled by an clause. If the exception is not handled by an clause, the exception is re-raised after the clause has been executed.\n• None An exception could occur during execution of an or clause. Again, the exception is re-raised after the clause has been executed.\n• None If the clause executes a , or statement, exceptions are not re-raised.\n• None If the statement reaches a , or statement, the clause will execute just prior to the , or statement’s execution.\n• None If a clause includes a statement, the returned value will be the one from the clause’s statement, not the value from the clause’s statement. As you can see, the clause is executed in any event. The raised by dividing two strings is not handled by the clause and therefore re-raised after the clause has been executed. In real world applications, the clause is useful for releasing external resources (such as files or network connections), regardless of whether the use of the resource was successful.\n\nSome objects define standard clean-up actions to be undertaken when the object is no longer needed, regardless of whether or not the operation using the object succeeded or failed. Look at the following example, which tries to open a file and print its contents to the screen. The problem with this code is that it leaves the file open for an indeterminate amount of time after this part of the code has finished executing. This is not an issue in simple scripts, but can be a problem for larger applications. The statement allows objects like files to be used in a way that ensures they are always cleaned up promptly and correctly. After the statement is executed, the file f is always closed, even if a problem was encountered while processing the lines. Objects which, like files, provide predefined clean-up actions will indicate this in their documentation.\n\nThere are situations where it is necessary to report several exceptions that have occurred. This is often the case in concurrency frameworks, when several tasks may have failed in parallel, but there are also other use cases where it is desirable to continue execution and collect multiple errors rather than raise the first exception. The builtin wraps a list of exception instances so that they can be raised together. It is an exception itself, so it can be caught like any other exception. By using instead of , we can selectively handle only the exceptions in the group that match a certain type. In the following example, which shows a nested exception group, each clause extracts from the group exceptions of a certain type while letting all other exceptions propagate to other clauses and eventually to be reraised. Note that the exceptions nested in an exception group must be instances, not types. This is because in practice the exceptions would typically be ones that have already been raised and caught by the program, along the following pattern:\n\nWhen an exception is created in order to be raised, it is usually initialized with information that describes the error that has occurred. There are cases where it is useful to add information after the exception was caught. For this purpose, exceptions have a method that accepts a string and adds it to the exception’s notes list. The standard traceback rendering includes all notes, in the order they were added, after the exception. For example, when collecting exceptions into an exception group, we may want to add context information for the individual errors. In the following each exception in the group has a note indicating when this error has occurred. | ExceptionGroup: We have some problems (3 sub-exceptions)"
    }
]