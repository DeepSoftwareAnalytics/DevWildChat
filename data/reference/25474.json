[
    {
        "link": "https://stackoverflow.com/questions/12102110/nginx-to-reverse-proxy-websockets-and-enable-ssl-wss",
        "document": "I'm so lost and new to building NGINX on my own but I want to be able to enable secure websockets without having an additional layer.\n\nI don't want to enable SSL on the websocket server itself but instead I want to use NGINX to add an SSL layer to the whole thing.\n\nEvery web page out there says I can't do it, but I know I can! Thanks to whoever (myself) can show me how!"
    },
    {
        "link": "https://betterstack.com/community/questions/nginx-to-reverse-proxy-websockets-and-enable-ssl",
        "document": "To configure Nginx as a reverse proxy for WebSocket connections and enable SSL/TLS (for ), you'll need to set up both WebSocket-specific configuration and SSL/TLS settings. Here's a step-by-step guide to achieve this:\n\nEnsure that Nginx is installed with SSL/TLS support. You can verify this by checking if the module is available:\n\nIf it is not installed, you may need to install Nginx from a package that includes SSL support or compile it with the option.\n\nYou need SSL/TLS certificates for your domain to enable . You can obtain certificates from a Certificate Authority (CA) or use a tool like Let's Encrypt to get a free SSL certificate.\n• None Let's Encrypt: You can use tools like to obtain and automatically renew certificates.\n• None Manually: If you have your own certificates, ensure you have the certificate file ( ) and the private key file ( ).\n\nHere’s a sample Nginx configuration to set up SSL and reverse proxy WebSocket connections:\n• SSL/TLS Setup:\n• : Configures Nginx to listen on port 443 with SSL enabled.\n• and : Specify the paths to your SSL certificate and private key.\n• WebSocket Configuration:\n• : Ensures the header is passed through, which is necessary for WebSocket connections.\n• : Sets the header to for WebSocket connections.\n• HTTP to HTTPS Redirection:\n• The second server block listens on port 80 and redirects all HTTP traffic to HTTPS.\n\nAfter configuring Nginx, it’s crucial to test your configuration for syntax errors and then reload or restart Nginx to apply the changes.\n\nEnsure that your WebSocket connections are working over by using a WebSocket client or testing tool. For example, you can use the browser’s developer tools to monitor WebSocket traffic and verify that it is being upgraded and proxied correctly.\n• None Check Nginx Logs: If there are issues, check the Nginx error and access logs for troubleshooting.\n• None Firewall and Network: Ensure that ports 80 and 443 are open and accessible through your firewall and network configuration.\n\nBy following these steps, you can successfully configure Nginx to reverse proxy WebSocket connections over SSL ( ), ensuring secure and efficient communication between clients and your WebSocket server."
    },
    {
        "link": "https://piehost.com/websocket/setup-secure-websocket-with-nginx",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/77373927/nginx-reverse-proxy-wss-spring-boot",
        "document": "Trying to setup reverse proxy with WS support, but I'm getting 403 (forbidden). I'm confused why it happen, because everything works as expected without proxy. My config is here:\n\nIf I'm trying to reach it with https: https://game.memoux.com/ websocket not work. But if I'm trying to reach it with http://game.memoux.com:8080 everything works propoerly. It means, something wrong with my config, and not with application behind the proxy."
    },
    {
        "link": "https://f5.com/company/blog/nginx/websocket-nginx",
        "document": ""
    },
    {
        "link": "http://nginx.org/en/docs/http/websocket.html",
        "document": "To turn a connection between a client and server from HTTP/1.1 into WebSocket, the protocol switch mechanism available in HTTP/1.1 is used.\n\nThere is one subtlety however: since the “Upgrade” is a hop-by-hop header, it is not passed from a client to proxied server. With forward proxying, clients may use the method to circumvent this issue. This does not work with reverse proxying however, since clients are not aware of any proxy servers, and special processing on a proxy server is required.\n\nSince version 1.3.13, nginx implements special mode of operation that allows setting up a tunnel between a client and proxied server if the proxied server returned a response with the code 101 (Switching Protocols), and the client asked for a protocol switch via the “Upgrade” header in a request.\n\nAs noted above, hop-by-hop headers including “Upgrade” and “Connection” are not passed from a client to proxied server, therefore in order for the proxied server to know about the client’s intention to switch a protocol to WebSocket, these headers have to be passed explicitly:\n\nA more sophisticated example in which a value of the “Connection” header field in a request to the proxied server depends on the presence of the “Upgrade” field in the client request header:\n\nBy default, the connection will be closed if the proxied server does not transmit any data within 60 seconds. This timeout can be increased with the proxy_read_timeout directive. Alternatively, the proxied server can be configured to periodically send WebSocket ping frames to reset the timeout and check if the connection is still alive."
    },
    {
        "link": "https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy",
        "document": "This article describes the basic configuration of a proxy server. You will learn how to pass a request from NGINX to proxied servers over different protocols, modify client request headers that are sent to the proxied server, and configure buffering of responses coming from the proxied servers.\n\nProxying is typically used to distribute the load among several servers, seamlessly show content from different websites, or pass requests for processing to application servers over protocols other than HTTP.\n\nWhen NGINX proxies a request, it sends the request to a specified proxied server, fetches the response, and sends it back to the client. It is possible to proxy requests to an HTTP server (another NGINX server or any other server) or a non-HTTP server (which can run an application developed with a specific framework, such as PHP or Python) using a specified protocol. Supported protocols include FastCGI, uwsgi, SCGI, and memcached.\n\nTo pass a request to an HTTP proxied server, the proxy_pass directive is specified inside a location. For example:\n\nThis example configuration results in passing all requests processed in this location to the proxied server at the specified address. This address can be specified as a domain name or an IP address. The address may also include a port:\n\nNote that in the first example above, the address of the proxied server is followed by a URI, . If the URI is specified along with the address, it replaces the part of the request URI that matches the location parameter. For example, here the request with the URI will be proxied to . If the address is specified without a URI, or it is not possible to determine the part of URI to be replaced, the full request URI is passed (possibly, modified).\n\nTo pass a request to a non-HTTP proxied server, the appropriate directive should be used:\n\nNote that in these cases, the rules for specifying addresses may be different. You may also need to pass additional parameters to the server (see the reference documentation for more detail).\n\nThe proxy_pass directive can also point to a named group of servers. In this case, requests are distributed among the servers in the group according to the specified method.\n\nBy default, NGINX redefines two header fields in proxied requests, “Host” and “Connection”, and eliminates the header fields whose values are empty strings. “Host” is set to the variable, and “Connection” is set to .\n\nTo change these setting, as well as modify other header fields, use the proxy_set_header directive. This directive can be specified in a location or higher. It can also be specified in a particular server context or in the http block. For example:\n\nIn this configuration the “Host” field is set to the $host variable.\n\nTo prevent a header field from being passed to the proxied server, set it to an empty string as follows:\n\nBy default NGINX buffers responses from proxied servers. A response is stored in the internal buffers and is not sent to the client until the whole response is received. Buffering helps to optimize performance with slow clients, which can waste proxied server time if the response is passed from NGINX to the client synchronously. However, when buffering is enabled NGINX allows the proxied server to process responses quickly, while NGINX stores the responses for as much time as the clients need to download them.\n\nThe directive that is responsible for enabling and disabling buffering is proxy_buffering. By default it is set to and buffering is enabled.\n\nThe proxy_buffers directive controls the size and the number of buffers allocated for a request. The first part of the response from a proxied server is stored in a separate buffer, the size of which is set with the proxy_buffer_size directive. This part usually contains a comparatively small response header and can be made smaller than the buffers for the rest of the response.\n\nIn the following example, the default number of buffers is increased and the size of the buffer for the first portion of the response is made smaller than the default.\n\nIf buffering is disabled, the response is sent to the client synchronously while it is receiving it from the proxied server. This behavior may be desirable for fast interactive clients that need to start receiving the response as soon as possible.\n\nTo disable buffering in a specific location, place the proxy_buffering directive in the location with the parameter, as follows:\n\nIn this case NGINX uses only the buffer configured by proxy_buffer_size to store the current part of a response.\n\nA common use of a reverse proxy is to provide load balancing. Learn how to improve power, performance, and focus on your apps with rapid deployment in the free Five Reasons to Choose a Software Load Balancer ebook.\n\nIf your proxy server has several network interfaces, sometimes you might need to choose a particular source IP address for connecting to a proxied server or an upstream. This may be useful if a proxied server behind NGINX is configured to accept connections from particular IP networks or IP address ranges.\n\nSpecify the proxy_bind directive and the IP address of the necessary network interface:\n\nThe IP address can be also specified with a variable. For example, the variable passes the IP address of the network interface that accepted the request:"
    },
    {
        "link": "https://docs.nginx.com/nginx/admin-guide/load-balancer/using-proxy-protocol",
        "document": "This article explains how to configure NGINX and F5 NGINX Plus to accept the PROXY protocol, rewrite the IP address of a load balancer or proxy to the one received in the PROXY protocol header, configure simple logging of a client’s IP address, and enable the PROXY protocol between NGINX and a TCP upstream server.\n\nThe PROXY protocol enables NGINX and NGINX Plus to receive client connection information passed through proxy servers and load balancers such as HAproxy and Amazon Elastic Load Balancer (ELB).\n\nWith the PROXY protocol, NGINX can learn the originating IP address from HTTP, SSL, HTTP/2, SPDY, WebSocket, and TCP. Knowing the originating IP address of a client may be useful for setting a particular language for a website, keeping a denylist of IP addresses, or simply for logging and statistics purposes.\n\nThe information passed via the PROXY protocol is the client IP address, the proxy server IP address, and both port numbers.\n\nUsing this data, NGINX can get the originating IP address of the client in several ways:\n• With the and variables which capture the original client IP address and port. The and variables capture the IP address and port of the load balancer.\n• With the RealIP module which rewrites the values in the and variables, replacing the IP address and port of the load balancer with the original client IP address and port. The and variables retain the address and port of the load balancer, and the and variables retain the original client IP address and port anyway.\n• To accept the PROXY protocol v2, NGINX Plus R16 and later or NGINX Open Source 1.13.11 and later\n• To accept the PROXY protocol for HTTP, NGINX Plus R3 and later or NGINX Open Source 1.5.12 and later\n• For TCP client‑side PROXY protocol support, NGINX Plus R7 and later or NGINX Open Source 1.9.3 and later\n• To accept the PROXY protocol for TCP, NGINX Plus R11 and later or NGINX Open Source 1.11.4 and later\n• The Real‑IP modules for HTTP and Stream TCP are not included in NGINX Open Source by default; see Installing NGINX Open Source for details. No extra steps are required for NGINX Plus.\n\nTo configure NGINX to accept PROXY protocol headers, add the parameter to the directive in a block in the or block.\n\nNow you can use the and variables for the client IP address and port and additionally configure the HTTP and RealIP modules to replace the IP address of the load balancer in the and variables with the IP address and port of the client.\n\nChanging the Load Balancer’s IP Address To the Client IP Address\n\nYou can replace the address of the load balancer or TCP proxy with the client IP address received from the PROXY protocol. This can be done with the HTTP and RealIP modules. With these modules, the and variables retain the real IP address and port of the client, while the and variables retain the IP address and port of the load balancer.\n\nTo change the IP address from the load balancer’s IP address to the client’s IP address:\n• Make sure you’ve configured NGINX to accept the PROXY protocol headers. See Configuring NGINX to Accept the PROXY Protocol.\n• Make sure that your NGINX installation includes the HTTP and Stream Real‑IP modules: If not, recompile NGINX with these modules. See Installing NGINX Open Source for details. No extra steps are required for NGINX Plus.\n• In the directive for HTTP, Stream, or both, specify the IP address or the CIDR range of addresses of the TCP proxy or load balancer:\n• In the context, change the IP address of the load balancer to the IP address of the client received from the PROXY protocol header, by specifying the parameter to the directive:\n\nWhen you know the original IP address of the client, you can configure the correct logging:\n• For HTTP, configure NGINX to pass the client IP address to upstream servers using the variable with the directive:\n• Add the variable to the directive (HTTP or Stream):\n\nPROXY Protocol for a TCP Connection to an Upstream\n\nFor a TCP stream, the PROXY protocol can be enabled for connections between NGINX and an upstream server. To enable the PROXY protocol, include the directive in a block at the level:\n\nThe example assumes that there is a load balancer in front of NGINX to handle all incoming HTTPS traffic, for example Amazon ELB. NGINX accepts HTTPS traffic on port 443 ( ), TCP traffic on port 12345, and accepts the client’s IP address passed from the load balancer via the PROXY protocol as well (the parameter to the directive in both the and blocks.\n\nNGINX terminates HTTPS traffic (the and directives) and proxies the decrypted data to a backend server:\n\nIt includes the client IP address and port with the directives.\n\nThe variable specified in the directive also passes the client’s IP address to the log for both HTTP and TCP.\n\nAdditionally, a TCP server (the block) sends its own PROXY protocol data to its backend servers (the directive)."
    },
    {
        "link": "http://nginx.org/en/docs/http/ngx_http_upstream_module.html",
        "document": "Highest-priority SRV records (records with the same lowest-number priority value) are resolved as primary servers, the rest of SRV records are resolved as backup servers. If the backup parameter is specified for the server, high-priority SRV records are resolved as backup servers, the rest of SRV records are ignored."
    },
    {
        "link": "https://stackoverflow.com/questions/12102110/nginx-to-reverse-proxy-websockets-and-enable-ssl-wss",
        "document": "I'm so lost and new to building NGINX on my own but I want to be able to enable secure websockets without having an additional layer.\n\nI don't want to enable SSL on the websocket server itself but instead I want to use NGINX to add an SSL layer to the whole thing.\n\nEvery web page out there says I can't do it, but I know I can! Thanks to whoever (myself) can show me how!"
    }
]