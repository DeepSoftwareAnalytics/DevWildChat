[
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/standard/garbage-collection/implementing-dispose",
        "document": "The Dispose method is primarily implemented to release unmanaged resources. When working with instance members that are IDisposable implementations, it's common to cascade Dispose calls. There are other reasons for implementing Dispose, for example, to free memory that was allocated, remove an item that was added to a collection, or signal the release of a lock that was acquired.\n\nThe .NET garbage collector doesn't allocate or release unmanaged memory. The pattern for disposing an object, referred to as the dispose pattern, imposes order on the lifetime of an object. The dispose pattern is used for objects that implement the IDisposable interface. This pattern is common when interacting with file and pipe handles, registry handles, wait handles, or pointers to blocks of unmanaged memory, because the garbage collector is unable to reclaim unmanaged objects.\n\nTo help ensure that resources are always cleaned up appropriately, a Dispose method should be idempotent, such that it's callable multiple times without throwing an exception. Furthermore, subsequent invocations of Dispose should do nothing.\n\nThe code example provided for the GC.KeepAlive method shows how garbage collection can cause a finalizer to run while an unmanaged reference to the object or its members is still in use. It may make sense to utilize GC.KeepAlive to make the object ineligible for garbage collection from the start of the current routine to the point where this method is called.\n\nIf your class owns an instance of another type that implements IDisposable, the containing class itself should also implement IDisposable. Typically a class that instantiates an IDisposable implementation and stores it as an instance member (or property) is also responsible for its cleanup. This helps ensure that the referenced disposable types are given the opportunity to deterministically perform cleanup through the Dispose method. In the following example, the class is (or in Visual Basic).\n\nThe IDisposable interface requires the implementation of a single parameterless method, Dispose. Also, any non-sealed class should have an overload method.\n\nBecause the , non-virtual ( in Visual Basic), parameterless method is called when it's no longer needed (by a consumer of the type), its purpose is to free unmanaged resources, perform general cleanup, and to indicate that the finalizer, if one is present, doesn't have to run. Freeing the actual memory associated with a managed object is always the domain of the garbage collector. Because of this, it has a standard implementation:\n\nThe method performs all object cleanup, so the garbage collector no longer needs to call the objects' Object.Finalize override. Therefore, the call to the SuppressFinalize method prevents the garbage collector from running the finalizer. If the type has no finalizer, the call to GC.SuppressFinalize has no effect. The actual cleanup is performed by the method overload.\n\nIn the overload, the parameter is a Boolean that indicates whether the method call comes from a Dispose method (its value is ) or from a finalizer (its value is ).\n\nThe body of the method consists of three blocks of code:\n• None A block for conditional return if object is already disposed.\n• None A conditional block that frees managed resources. This block executes if the value of is . The managed resources that it frees can include:\n• Managed objects that implement IDisposable. The conditional block can be used to call their Dispose implementation (cascade dispose). If you have used a derived class of System.Runtime.InteropServices.SafeHandle to wrap your unmanaged resource, you should call the SafeHandle.Dispose() implementation here.\n• Managed objects that consume large amounts of memory or consume scarce resources. Assign large managed object references to to make them more likely to be unreachable. This releases them faster than if they were reclaimed nondeterministically.\n• None A block that frees unmanaged resources. This block executes regardless of the value of the parameter.\n\nIf the method call comes from a finalizer, only the code that frees unmanaged resources should execute. The implementer is responsible for ensuring that the false path doesn't interact with managed objects that may have been disposed. This is important because the order in which the garbage collector disposes managed objects during finalization is nondeterministic.\n\nAll non-sealed classes (or Visual Basic classes not modified as ) should be considered a potential base class, because they could be inherited. If you implement the dispose pattern for any potential base class, you must add the following methods to your class:\n• If your class deals with unmanaged resources, either provide an override to the Object.Finalize method or wrap the unmanaged resource in a SafeHandle.\n\nHere's a general example of implementing the dispose pattern for a base class that only owns managed resources.\n\nHere's an example for implementing the dispose pattern for a base class that overrides Object.Finalize in order to clean up unmanaged resources it owns. The example also demonstrates a way to implement in a thread-safe manner. Synchronization might be critical when dealing with unmanaged resources in a multi-threaded application. As mentioned earlier, this is an advanced scenario.\n\nA class derived from a class that implements the IDisposable interface shouldn't implement IDisposable, because the base class implementation of IDisposable.Dispose is inherited by its derived classes. Instead, to clean up a derived class, you provide the following:\n• A method that overrides the base class method and performs the actual cleanup of the derived class. This method must also call the ( in Visual Basic) method passing it the disposing status ( parameter) as an argument.\n• Either a class derived from SafeHandle that wraps your unmanaged resource (recommended), or an override to the Object.Finalize method. The SafeHandle class provides a finalizer that frees you from having to code one. If you do provide a finalizer, it must call the overload with argument.\n\nHere's an example of the general pattern for implementing the dispose pattern for a derived class that uses a safe handle:\n\nHere's the general pattern for implementing the dispose pattern for a derived class that overrides Object.Finalize:\n\nWriting code for an object's finalizer is a complex task that can cause problems if not done correctly. Therefore, we recommend that you construct System.Runtime.InteropServices.SafeHandle objects instead of implementing a finalizer.\n\nA System.Runtime.InteropServices.SafeHandle is an abstract managed type that wraps an System.IntPtr that identifies an unmanaged resource. On Windows it might identify a handle, and on Unix, a file descriptor. The provides all of the logic necessary to ensure that this resource is released once and only once, either when the is disposed of or when all references to the have been dropped and the instance is finalized.\n\nThe System.Runtime.InteropServices.SafeHandle is an abstract base class. Derived classes provide specific instances for different kinds of handle. These derived classes validate what values for the System.IntPtr are considered invalid and how to actually free the handle. For example, SafeFileHandle derives from to wrap that identify open file handles and descriptors, and overrides its SafeHandle.ReleaseHandle() method to close it (via the function on Unix or function on Windows). Most APIs in .NET libraries that create an unmanaged resource wrap it in a and return that to you as needed, rather than handing back the raw pointer. In situations where you interact with an unmanaged component and get an for an unmanaged resource, you can create your own type to wrap it. As a result, few non- types need to implement finalizers. Most disposable pattern implementations only end up wrapping other managed resources, some of which might be objects.\n\nThe following code demonstrates how to handle unmanaged resources by implementing a SafeHandle.\n\nThe following derived classes in the Microsoft.Win32.SafeHandles namespace provide safe handles."
    },
    {
        "link": "https://stackoverflow.com/questions/18336856/implementing-idisposable-correctly",
        "document": "The following example shows the general best practice to implement interface. Reference\n\nKeep in mind that you need a destructor(finalizer) only if you have unmanaged resources in your class. And if you add a destructor you should suppress Finalization in the Dispose, otherwise it will cause your objects resides in memory longer that it should (Note: Read how Finalization works). Below example elaborate all above."
    },
    {
        "link": "https://stackoverflow.com/questions/7300522/best-practices-for-handling-idisposable",
        "document": "I have a class hierarchy, each member of which may create objects.\n\nI added a property to the base class in this hierarchy, to which I add any disposable objects on creation. The root method iterates through this list and calls for each item in its list and clears the list. In the application, I explicitly call the top object's method, causing disposal to cascade through the hierarchy.\n\nThis works, but is there a better way? Am I unwittingly duplicating some functionality already present in the framework?\n\nJust for clarification - I'm only keeping those objects around that need to be kept. Some are disposed of in the same method where they are created, but many are used in such a way that this isn't possible."
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/standard/garbage-collection/using-objects",
        "document": "The common language runtime's garbage collector (GC) reclaims the memory used by managed objects. Typically, types that use unmanaged resources implement the IDisposable or IAsyncDisposable interface to allow the unmanaged resources to be reclaimed. When you finish using an object that implements IDisposable, you call the object's Dispose or DisposeAsync implementation to explicitly perform cleanup. You can do this in one of two ways:\n• With the C# statement or declaration ( in Visual Basic).\n• By implementing a block, and calling the Dispose or DisposeAsync method in the .\n\nObjects that implement System.IDisposable or System.IAsyncDisposable should always be properly disposed of, regardless of variable scoping, unless otherwise explicitly stated. Types that define a finalizer to release unmanaged resources usually call GC.SuppressFinalize from either their or implementation. Calling SuppressFinalize indicates to the GC that the finalizer has already been run and the object shouldn't be promoted for finalization.\n\nThe statement in C# and the statement in Visual Basic simplify the code that you must write to cleanup an object. The statement obtains one or more resources, executes the statements that you specify, and automatically disposes of the object. However, the statement is useful only for objects that are used within the scope of the method in which they are constructed.\n\nThe following example uses the statement to create and release a System.IO.StreamReader object.\n\nA declaration is an alternative syntax available where the braces are removed, and scoping is implicit.\n\nAlthough the StreamReader class implements the IDisposable interface, which indicates that it uses an unmanaged resource, the example doesn't explicitly call the StreamReader.Dispose method. When the C# or Visual Basic compiler encounters the statement, it emits intermediate language (IL) that is equivalent to the following code that explicitly contains a block.\n\nThe C# statement also allows you to acquire multiple resources in a single statement, which is internally equivalent to nested statements. The following example instantiates two StreamReader objects to read the contents of two different files.\n\nInstead of wrapping a block in a statement, you may choose to implement the block directly. It may be your personal coding style, or you might want to do this for one of the following reasons:\n• To include a block to handle exceptions thrown in the block. Otherwise, any exceptions thrown within the statement are unhandled.\n• To instantiate an object that implements IDisposable whose scope is not local to the block within which it is declared.\n\nThe following example is similar to the previous example, except that it uses a block to instantiate, use, and dispose of a StreamReader object, and to handle any exceptions thrown by the StreamReader constructor and its ReadToEnd method. The code in the block checks that the object that implements IDisposable isn't before it calls the Dispose method. Failure to do this can result in a NullReferenceException exception at run time.\n\nYou can follow this basic pattern if you choose to implement or must implement a block, because your programming language doesn't support a statement but does allow direct calls to the Dispose method.\n\nIf a class owns an instance field or property and its type implements IDisposable, the class should also implement IDisposable. For more information, see Implement a cascade dispose."
    },
    {
        "link": "https://medium.com/ingeniouslysimple/managing-unmanaged-objects-in-c-6c69968c60eb",
        "document": "So how do we fix the problem in this code? I think there are a few options, depending on what your requirements are:\n\nCreate the in the outer scope and pass it into .\n\nIn this case, wouldn’t be responsible for creating its own temporary folder; instead it would be passed a workspace to create a folder in.\n\nThis option requires a bit more code: we need an extra parameter on , and we’d need to add a line to the bottom of the test. This ensures that the variable is marked as being used for the full length of the test method. Alternatively, we could put into a statement to ensure that it is cleaned up exactly at the end of the test.\n\nThe advantage of this option is that we’re being much more explicit about the temporary folder’s lifetime — the code makes it clear that the folder needs to exist for the full duration of the test.\n\nWrap the in another object, so that it doesn’t go out of scope when returns.\n\nInstead of considering the problem in terms of object lifetime, we could instead think about object ownership. Thinking this way, the problem with is that it returns a representing the project file, but the project file depends on a temporary folder which isn’t returned. If consuming code is responsible for owning a project file, then it also needs to own the associated folder.\n\nThe fix here is to create a new class to return from . This class would contain references to both the project file and temporary folder. Since this class owns the temporary folder — a managed resource implementing —then it should also implement and pass the call through to the folder. This class wouldn’t own any unmanaged resources, so it doesn’t need its own finalizer.\n\nThe big advantage here is that so long as we pass this new class everywhere that we want to interact with the test project, the consuming code will keep the alive, which in turn keeps the alive. Once the is no longer referenced, it should make the eligible for garbage collection. Implementing like this should also mean that statements work as expected.\n\nThinking about object ownership like this makes this the most object-oriented solution.\n\nRemove the finalizer from .\n\nThis is the easiest option, but the least ‘correct’ from a lifetime or ownership perspective. The upshot is that the GC is no longer involved in cleaning up the temporary folder: the only way is through the method (either by calling it explicitly or through a statement).\n\nWhile this isn’t an ideal solution, it’s the one we eventually chose. Our reasoning was that the test failure wasn’t an isolated incident. In our production code we’d also seen similar issues with temporary folders being prematurely deleted, and we weren’t sure that we had applied complete fixes in those situations. With this solution we’re trading risks: removing the finalizer means that temporary folders might be left lying around, but that’s a safer failure state than having them deleted in unexpected places.\n\nThis is a highly contextual decision. With other types of unmanaged objects this might be a really bad idea. For example, if you’re handling a database transaction that needs to be committed, then you’re more likely to prioritise getting the transaction committed in a finalizer. The temporary folders we’re talking about in this case are pretty small: if we were thinking about larger folders that could significantly impact the user’s disk space, then we’d have different priorities as well."
    },
    {
        "link": "https://pollydocs.org",
        "document": "Polly is a powerful library for .NET that helps you handle transient faults and improve the resilience of your applications. With Polly, you can easily define and apply strategies such as Retry, Circuit Breaker, Hedging, Timeout, Rate Limiter and Fallback to handle failures and slowdowns in a fluent and thread-safe way.\n\nPolly is part of the .NET Foundation!\n\nWhat can Polly do for you?\n\nPolly lets you use and combine different resilience strategies to cope with various scenarios, such as:\n• Retry: Try again if something fails. This can be useful when the problem is temporary and might go away.\n• Circuit Breaker: Stop trying if something is broken or busy. This can benefit you by avoiding wasting time and making things worse. It can also support the system to recover.\n• Timeout: Give up if something takes too long. This can improve your performance by freeing up space and resources.\n• Rate Limiter: Limit how many requests you make or accept. This can enable you to control the load and prevent problems or penalties.\n• Fallback: Do something else if something fails. This can improve your user experience and keep the program working.\n• Hedging: Do more than one thing at the same time and take the fastest one. This can make your program faster and more responsive.\n\nYou can learn more about each strategy and how to use them resilience strategies section.\n\nHow to get started with Polly?\n\nPolly is easy to install and use. You can follow the getting started guide to add and start using Polly in your projects.\n\nWhere to find more information?\n\nPolly has a rich documentation that covers various topics, such as:\n• Resilience strategies: A collection of strategies for improving the resilience of your system.\n• Resilience pipelines: How to combine and reuse strategies in a flexible and modular way.\n• Telemetry and monitoring: How to access and analyze the data generated by Polly strategies and pipelines.\n• Dependency injection: How to integrate Polly with dependency injection frameworks and containers.\n• Performance: Tips on optimizing and getting the best performance from Polly.\n• Testing: How to test the composition and configuration of resilience pipelines.\n• Chaos engineering: How to use Polly to inject faults and test the resilience of your system.\n• Extensibility: How to create and use custom strategies and extensions for Polly.\n\nYou can also find many resources and community contributions, such as:\n• Samples: Samples in this repository that serve as an introduction to Polly.\n• Practical Samples: Practical examples for using various implementations of Polly. Please feel free to contribute to the Polly-Samples repository in order to assist others who are either learning Polly for the first time, or are seeking advanced examples and novel approaches provided by our generous community.\n• Polly-Contrib: Community projects and libraries that extend and enhance Polly's functionality and ecosystem.\n• Libraries and contributions: Dependencies and contributors that make Polly possible and awesome.\n• Microsoft's eShopOnContainers project: Sample project demonstrating a .NET Micro-services architecture and using Polly for resilience.\n• Git Workflow: Our suggested Git workflow for contributing to Polly.\n\nYou can browse the documentation using the sidebar or visit the API section for the reference documentation."
    },
    {
        "link": "https://github.com/App-vNext/Polly",
        "document": "Polly is a .NET resilience and transient-fault-handling library that allows developers to express resilience strategies such as Retry, Circuit Breaker, Hedging, Timeout, Rate Limiter and Fallback in a fluent and thread-safe manner.\n\nWe are a member of the .NET Foundation!\n\nKeep up to date with new feature announcements, tips & tricks, and other news through www.thepollyproject.org\n\nThis README aims to give a quick overview of some Polly features - including enough to get you started with any resilience strategy. For deeper detail on any resilience strategy, and many other aspects of Polly, be sure also to check out pollydocs.org.\n\nTo use Polly, you must provide a callback and execute it using resilience pipeline. A resilience pipeline is a combination of one or more resilience strategies such as retry, timeout, and rate limiter. Polly uses builders to integrate these strategies into a pipeline.\n\nTo get started, first add the Polly.Core package to your project by running the following command:\n\nYou can create a using the class as shown below:\n\nIf you prefer to define resilience pipelines using , you'll need to install the Polly.Extensions package:\n\nYou can then define your resilience pipeline using the extension method as shown:\n\nPolly provides a variety of resilience strategies. Alongside the comprehensive guides for each strategy, the wiki also includes an overview of the role each strategy plays in resilience engineering.\n\nThese strategies handle specific exceptions that are thrown, or results that are returned, by the callbacks executed through the strategy.\n\nUnlike reactive strategies, proactive strategies do not focus on handling errors, but the callbacks might throw or return. They can make proactive decisions to cancel or reject the execution of callbacks.\n\nVisit resilience strategies docs to explore how to configure individual resilience strategies in more detail.\n\n// For instant retries with no delay // For advanced control over the retry behavior, including the number of attempts, // delay between retries, and the types of exceptions to handle. // To use a custom function to generate the delay for retries args _ // This example uses a synchronous delay generator, // but the API also supports asynchronous implementations. // To extract the delay from the result object args // Returning null means the retry strategy will use its internal delay for this attempt. // To get notifications when a retry is performed args // Event handlers can be asynchronous; here, we return an empty ValueTask. // To keep retrying indefinitely or until success use int.MaxValue. // Add a retry strategy with a RetryStrategyOptions{<TResult>} instance to the pipeline\n\nIf all retries fail, a retry strategy rethrows the final exception back to the calling code.\n\nFor more details, visit the retry strategy documentation.\n\n// The circuit will break if more than 50% of actions result in handled exceptions, // within any 10-second sampling duration, and at least 8 actions are processed. // The break duration is dynamically determined based on the properties of BreakDurationGeneratorArguments. args response // Monitor the circuit state, useful for health reporting: // Manually close the circuit to allow actions to be executed again. // Add a circuit breaker strategy with a CircuitBreakerStrategyOptions{<TResult>} instance to the pipeline\n\nFor more details, visit the circuit breaker strategy documentation.\n\nFor more details, visit the fallback strategy documentation.\n\nIf all hedged attempts fail, the hedging strategy will either re-throw the original exception or return the original failed result to the caller.\n\nFor more details, visit the hedging strategy documentation.\n\nThe timeout resilience strategy assumes delegates you execute support co-operative cancellation. You must use overloads taking a , and the executed delegate must honor that .\n\nFor more details, visit the timeout strategy documentation.\n\nFor more details, visit the rate limiter strategy documentation.\n\nStarting with version , Polly has integrated Simmy, a chaos engineering library, directly into its core. For more information, please refer to the dedicated chaos engineering documentation.\n\nTo learn more about Polly, visit pollydocs.org.\n• Samples: Samples in this repository that serve as an introduction to Polly.\n• Polly-Samples: Contains practical examples for using various implementations of Polly. Please feel free to contribute to the Polly-Samples repository in order to assist others who are either learning Polly for the first time, or are seeking advanced examples and novel approaches provided by our generous community.\n• Microsoft's eShopOnContainers project: Sample project demonstrating a .NET Micro-services architecture and using Polly for resilience.\n\nThanks to the following companies for sponsoring the ongoing development of Polly.\n\nHelp support this project by becoming a sponsor through GitHub Sponsors.\n\nLicensed under the terms of the New BSD License"
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/architecture/microservices/implement-resilient-applications/implement-http-call-retries-exponential-backoff-polly",
        "document": "Implement HTTP call retries with exponential backoff with IHttpClientFactory and Polly policies\n\nThe recommended approach for retries with exponential backoff is to take advantage of more advanced .NET libraries like the open-source Polly library.\n\nPolly is a .NET library that provides resilience and transient-fault handling capabilities. You can implement those capabilities by applying Polly policies such as Retry, Circuit Breaker, Bulkhead Isolation, Timeout, and Fallback. Polly targets .NET Framework 4.x and .NET Standard 1.0, 1.1, and 2.0 (which supports .NET Core and later).\n\nThe following steps show how you can use Http retries with Polly integrated into , which is explained in the previous section.\n\nFirst, you will need to install the package.\n\nis available since .NET Core 2.1, however, we recommend you use the latest .NET 8 packages from NuGet in your project. You typically also need to reference the extension package .\n\nThe AddPolicyHandler() method is what adds policies to the objects you'll use. In this case, it's adding a Polly's policy for Http Retries with exponential backoff.\n\nTo have a more modular approach, the Http Retry Policy can be defined in a separate method within the Program.cs file, as shown in the following code:\n\nAs shown in previous sections, you need to define a named or typed client HttpClient configuration in your standard Program.cs app configuration. Now you add incremental code specifying the policy for the Http retries with exponential backoff, as follows:\n\nWith Polly, you can define a Retry policy with the number of retries, the exponential backoff configuration, and the actions to take when there's an HTTP exception, such as logging the error. In this case, the policy is configured to try six times with an exponential retry, starting at two seconds.\n\nA regular Retry policy can affect your system in cases of high concurrency and scalability and under high contention. To overcome peaks of similar retries coming from many clients in partial outages, a good workaround is to add a jitter strategy to the retry algorithm/policy. This strategy can improve the overall performance of the end-to-end system. As recommended in Polly: Retry with Jitter, a good jitter strategy can be implemented by smooth and evenly distributed retry intervals applied with a well-controlled median initial retry delay on an exponential backoff. This approach helps to spread out the spikes when the issue arises. The principle is illustrated by the following example:"
    },
    {
        "link": "https://cosmin-vladutu.medium.com/everything-you-need-to-know-about-polly-e44b3235df7f",
        "document": "I heard the first time about Polly somewhere around 2016–2017, and I think it had only a preview version at that time. I really liked it, since I was searching for the equivalent of Hystrix from Java into .NET, and at that time at least, there wasn’t anything like that.\n\nWhat is this parrot?\n\nTheir definition says it all: “Polly is a .NET resilience and transient-fault-handling library that allows developers to express policies such as Retry, Circuit Breaker, Timeout, Bulkhead Isolation, Rate-limiting and Fallback in a fluent and thread-safe manner.”, and can be found here with its NuGet package. There you can also find a lot of examples of how you can write your policies. If you are using older .NET versions, and you don’t work in .NET Core, you can also, have the benefit of using Polly, since it supports most of the older versions also; you can check the supported targets here.\n\nTo be honest, I’ve used Polly only with retry and circuit breaker policies in production, and made some pet projects with the cache and fallback policies, but never got the chance or the need to add them in a production code. Don’t get me wrong, they are working fine, and easy to do, but I am not a fan of adding stuff in a production code, just because they are fancy. \n\nWhat I can say is that for the retry policy, I didn’t have, ever, a business scenario in which I couldn’t use Polly. You can retry a number of times, you can wait and retry a fixed number of seconds, or an exponential time, you can retry forever; for the circuit breaker, you can a failure threshold, you have the duration of the break, the min throughput, you basically have anything you want, so really, both are highly configurable; and if you read my articles, I almost never say such big words, about packages.\n\nLet’s say you have a method that you want to retry 5 times (if it throws an exception) and you want to log its result and the exception message for each exception that may be thrown.\n\nWith Polly, the code would look more “elegant”, but to be honest, I wouldn’t add another NuGet package, if I need only a retry in one single place.\n\nFor example, if you have multiple instances of an API or you get the feeling that you might get concurrency expectations, you might want to retry your logic, without sending back an error to the client. As a real-life example, this might look like this:\n\nAnother good example may be the one with wait and retry. Do you remember all those times when a 3rd party system went down for 3–5 min, and after that everything was fine? Do you remember how much time you lost debugging the problem and after some time you realised it was just a transient problem? If you just retried, and the 3rd party system was down, due to the high CPU, memory, DB issues or even network traffic, to burst that service with retries and add to it more load won’t help it at all. This is why this “wait and retry” appeared, to give the 3rd party system time to recover.\n\nRegarding caching, I won’t show you any code since there are a lot of examples, but those I liked most can be found on the “no dogma blog” (the blog written by Bryan Hogan), and the articles can be found here and here (on his posts you can find the code sources as well). What is worth mentioning is that you can easily add some configuration on the app's startup, and all the requests (responses for the requests) will be cached, or you can configure policies on the request level, and you may have a policy for each request. In my mind, this is a pretty cool thing.\n\nYou can have policies to do even different things based on response codes for example, or re-authorization if needed! You just need to create a delegate and that’s all!\n\nIf you want more policies nested, you can do that, but if you want to reuse them in multiple places my recommendation would be to use “IPolicyWrap”. It will make your code reusable and you’ll have less code in front of your eyes and let you focus on your business logic, not on the policies.\n\nIf you’re thinking that is pretty hard to test this, well, you’re wrong.\n\nOption one (the ugly one) would be to mock the policy and do your unit tests. This option will make Sonar, or whatever you have over there (for checking the code coverage), happy. This will give you “the ability” to test your “business logic”, aka the logic that should be retried, easier. \n\nFor this you most likely need the next packages:\n\nIf you don’t want to have anything to do with Polly you have the option to use Policy.NoOpAsync and your policy won’t do a thing.\n\nOption two would be to use Simmy, which is a tool for chaos engineering. With this tool, you’ll be able to inject “problems”, and you’ll be able to test not only the logic but also the policies. I highly recommend doing this also.\n\nPolly is a nice open-source project that I really recommend. It can be used with any type of request (GET, PUT, etc), but it’s your job to take care they are idempotent; also, it is thread save, but as you can imagine, it’s not a silver bullet. It shouldn’t be used everywhere, and you shouldn’t add it only for only one small thing, but you should always consider it when you build something."
    },
    {
        "link": "https://ironpdf.com/blog/net-help/polly-retry",
        "document": "Test in production without watermarks.\n\nWorks wherever you need it to."
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/http/httpclient-guidelines",
        "document": "The System.Net.Http.HttpClient class sends HTTP requests and receives HTTP responses from a resource identified by a URI. An HttpClient instance is a collection of settings that's applied to all requests executed by that instance, and each instance uses its own connection pool, which isolates its requests from others. Starting in .NET Core 2.1, the SocketsHttpHandler class provides the implementation, making behavior consistent across all platforms.\n\nHttpClient only resolves DNS entries when a connection is created. It does not track any time to live (TTL) durations specified by the DNS server. If DNS entries change regularly, which can happen in some scenarios, the client won't respect those updates. To solve this issue, you can limit the lifetime of the connection by setting the PooledConnectionLifetime property, so that DNS lookup is repeated when the connection is replaced. Consider the following example:\n\nThe preceding is configured to reuse connections for 15 minutes. After the timespan specified by PooledConnectionLifetime has elapsed and the connection has completed its last associated request (if any), this connection is closed. If there are any requests waiting in the queue, a new connection is created as needed.\n\nThe 15-minute interval was chosen arbitrarily for illustration purposes. You should choose the value based on the expected frequency of DNS or other network changes.\n\nThe connection pool for an HttpClient is linked to the underlying SocketsHttpHandler. When the HttpClient instance is disposed, it disposes all existing connections inside the pool. If you later send a request to the same server, a new connection must be recreated. As a result, there's a performance penalty for unnecessary connection creation. Moreover, TCP ports are not released immediately after connection closure. (For more information on that, see TCP in RFC 9293.) If the rate of requests is high, the operating system limit of available ports might be exhausted. To avoid port exhaustion problems, we recommend reusing HttpClient instances for as many HTTP requests as possible.\n\nTo summarize recommended use in terms of lifetime management, you should use either long-lived clients and set (.NET Core and .NET 5+) or short-lived clients created by .\n• \n• Use a or singleton HttpClient instance with PooledConnectionLifetime set to the desired interval, such as 2 minutes, depending on expected DNS changes. This solves both the port exhaustion and DNS changes problems without adding the overhead of IHttpClientFactory. If you need to be able to mock your handler, you can register it separately. If you only use a limited number of HttpClient instances, that's also an acceptable strategy. What matters is that they're not created and disposed with each request, as they each contain a connection pool. Using more than one instance is necessary for scenarios with multiple proxies or to separate cookie containers without completely disabling cookie handling.\n• None Using IHttpClientFactory, you can have multiple, differently configured clients for different use cases. However, be aware that the factory-created clients are intended to be short-lived, and once the client is created, the factory no longer has control over it. The factory pools HttpMessageHandler instances, and, if its lifetime hasn't expired, a handler can be reused from the pool when the factory creates a new HttpClient instance. This reuse avoids any socket exhaustion issues. If you desire the configurability that IHttpClientFactory provides, we recommend using the typed-client approach.\n• None In .NET Framework, use IHttpClientFactory to manage your instances. If you don't use the factory and instead create a new client instance for each request yourself, you can exhaust available ports. If your app requires cookies, consider disabling automatic cookie handling or avoiding IHttpClientFactory. Pooling the HttpMessageHandler instances results in sharing of CookieContainer objects. Unanticipated CookieContainer object sharing often results in incorrect code.\n\nFor more information about managing lifetime with , see guidelines.\n\nIt's possible to configure a or singleton client to use any number of resilience pipelines using the following pattern:\n• Specifies a transient HTTP error handler, configured with retry pipeline that with each attempt will exponentially backoff delay intervals.\n• Defines a pooled connection lifetime of fifteen minutes for the .\n• Passes the to the with the retry logic."
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/api/system.net.http.httpclient?view=net-9.0",
        "document": ""
    },
    {
        "link": "https://medium.com/@iamprovidence/http-client-in-c-best-practices-for-experts-840b36d8f8c4",
        "document": "Did you think that learning how to create an is all you need to start using it? Oh silly you are 😌. Network communication is unreliable, therefore you need to make your resilient.\n\nWhen you have one service calling another, there are multiple issues you can encounter:\n• the request may take too long\n• the server may be slow or not available at all\n\nTherefore, you should learn about:\n\nThere is another popular NuGet, called , which allows you to write resilient code in a fluent manner:\n\nMicrosoft saw how good it is, and decided to use in their own NuGet ( that adds resiliency to .\n\nLet’s see it in practice.\n\nWhen a user clicks a button, he does not care whether you are performing complex computations or calling an external service. The user just expects to see a response right away.\n\nHowever, when an external service is overloaded and the request takes too long, it will cause slowness in your application.\n\nTherefore you should set a timeout of how long you can wait for the response:\n\nIf the request takes longer, it will be aborted and considered as a failed one.\n\nWe can face another issue. The response is returned in an acceptable interval, however, it failed with an error.\n\nIn that case, it is worth try sending the same request again.\n\nWith retries you need to consider the following factors:\n• which status codes should be retried\n\nHTTP’s status code indicates the result of the request, whether it was successful or encountered an error. The codes are grouped into five categories based on their first digit:\n\nAnd only and groups indicate an error.\n\nIt is important to understand which codes should be retried.\n\nIf the request is returned with client error ( ), it means that it was poorly formed. Parameters are invalid, the authorization token is missing, the validation failed, and so on. Retrying such a request will likely result in the same error.\n\nTherefore you should not retry the group. But there are exceptions:\n• . This status code indicates that the server did not complete the request within the expected time. Retrying after a reasonable delay might help\n• . If you encounter this status code, it means you’re making too many requests in a given time frame. Retrying after some period can help avoid hitting rate limits\n\nOn the other hand, server errors ( ), typically means temporary issues that will be resolved on a retry (except 😅).\n\nIn practice, you don’t have to think about which status codes to retry, because Microsoft already implemented that 🙏:\n\nIt’s often a good practice to set a limit on the number of retry attempts to prevent infinite retry loops in case of persistent failures.\n\nOf course, in case you are integrating with a third party, you should take into account the number of requests you send, the rate limits it imposes, and the potential impact on performance and costs.\n\nWe agreed on a number of retry attempts. It is also important to choose a delay between retries.\n\nEach retry can happen after a constant timeout, let’s say .\n\nThis can be easily set in our retry policy:\n\nIt is simple, but not very effective.\n\nIf the server returns an error, retrying after a short delay can help quickly obtain a response from the server.\n\nHowever, if you fail on a second attempt, on the third one, it usually means the server is overloaded, and spamming it with more requests just worsens the situation.\n\nSo, if the client “sees” that the server is unavailable, but it desperately needs a response, it is better to wait for a longer period.\n\nIt is recommended to increase the delay between each retry linearly or exponentially. This way you wait , then , then , and so on.\n\nEven though this strategy is a bit better, it still has some drawbacks.\n\nPicture this: your server goes down entirely. Multiple begin retrying their requests, and these retries align in time, generating peak load moments on the already overwhelmed server. This can potentially lead to a self-DDoS attack.\n\nYou need to add a random delay to each retry, also known as jitter.\n\nWhen implementing retries you should remember that some HTTP methods may have side effects.\n\nAccording to REST, you can classify any operation as Create, Read, Update, or Delete (CRUD).\n\nLet’s say we receive from a server. This does not mean that the request was not handled. It just indicates that we no longer wait for a response.\n\nAs expected our client will do the retry. The behavior will be different depending on the operation:\n• — on the first attempt, the server will delete the resource, and on the second retry, there will be nothing to delete, so the retry should not harm our server\n• — generally, the update operation is not harmful. For example, if you send the same data multiple times, the server should overwrite the resource with identical values\n• — it does not matter, how many times you retrieve the data as fetch is a read-only, side-effect-free operation\n• — retrying the request responsible for creation could result in duplicate entries 😖\n\nTherefore, the server should ensure idempotency.\n\nOr in plain English, if you have an API endpoint to pay for an order and unpetient users click 10 times, only 1 payment will be charged.\n\nTypically, clients should include a with each request, enabling the server to maintain a record of processed requests:\n\nWe won’t discuss idempotency in detail here. It is another big topic that deserves its own article 🙃. Just remember, that if your server does not implement idempotency (which is often the case with third-party apps), retries can cause more issues than solve.\n\nSo, we have timeout and retries. Still, there is another known problem.\n\nLet’s say our server is overwhelmed with requests and it takes time to respond.\n\nSure we have a timeout, however, during the waiting period, the client continues sending requeues and also runs out of resources, such as memory, TCP connections, available threads, and so on.\n\nOver time the client will deplete its resources and also fail.\n\nSometimes it is better to fail fast instead of trying to send requests that will allocate the client’s resources and fail anyway.\n\nIt is solved with the Circuit-Breaker pattern. The idea is as follows:\n• we add a proxy that will gather the statistics about the number of failed requests\n• if at some point we realize that the server has stopped responding, we should stop all requests for a while. This is known as open-state\n• from time to time, our proxy goes to a half-open state. It allows some requests through just to verify whether the server has recovered or not\n• in case, the server starts responding at a reasonable rate, we can get back to the close state when there is no gap in the connection line\n\nThe good news here is that we don’t need to implement Circuit-Breaker from scratch or add any proxy service here. As before, everything can be done with one configuration line 😁:\n\nYou can tune parameters more granularly, depending on your needs, but I will leave it as is because I am lazy 🙃.\n\nAs you can see, configuring the resiliency pipeline is complex. Microsoft also knows that it is quite easy to f#ck it up 😅. You can set policies in the wrong order, set invalid parameters, and so on. Therefore, they give us an extension method, that will register standard policies:\n\nThey look like this:\n\nStill, it is possible to tune some settings, if needed:"
    },
    {
        "link": "https://stackoverflow.com/questions/58493140/what-are-the-best-practices-with-using-httpclient-httpclienthandler-for-multip",
        "document": "Using is not as straight forward as I would've hoped. Despite it being an type it is not best practice to wrap it in a statement and it's even ideal to make it a singleton. However, what about when you pass in a to the constructor of the like:\n\nI've seen code like above where the is deliberately wrapped in a statement but the is a singleton. The docs indicate the client handler is disposed of unless the second param indicates as is done above:\n\nPart of the problem with using HttpClient is several things like a timeout must be shared with all instances of that HttpClient, so for this reason it would be nice to create separate instances of HttpClient that use the same connection pool presumably provided by the HttpClientHandler (assuming that is how this works). My concern is that I don't want HttpClient to create a connection pool that will then be disposed of each time. There's multiple posts on how this is really bad for performance. I can't seem to find any good documentation on effectively using HttpClient together with HttpClientHandlers.\n\nSo... My question is basically:\n\nWhen using an HttpClient & HttpClientHandler together, is it best to make the HttpClientHandler a singleton and then instantiate as many new HttpClients in blocks each time? -- This again only makes sense if the connection pool is managed by the HttpClientHandler, which I think is the case."
    },
    {
        "link": "https://stackoverflow.com/questions/37157164/best-practice-for-use-httpclient",
        "document": "The challenge in using just one HttpClient across your application is when you want to use different credentials or you try to vary the default headers for your requests (or anything in the HttpClientHandler passed in). In this case you will need a set of purpose specific HttpClients to re-use since using just one will be problematic.\n\nI suggest creating a HttpClient per the \"type\" of request you wish to make and re-use those. E.g. one for each credential you need - and maybe if you have a few sets of default headers, one per each of those.\n\nIt can be a bit of a juggling act between the HttpClient properties (which are not thread safe) and need their own instance if being varied:\n\nAnd what you can pass in to the \"VERB\" methods (get, put, post etc). For example, using you can specify your headers for the (and not have to put them in the HttpClient DefaultHeaders).\n\nAll of the Async methods off the HttpClient are thread safe (PostAsync) etc."
    }
]