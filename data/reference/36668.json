[
    {
        "link": "https://w3schools.com/sql/sql_Groupby.asp",
        "document": "The statement groups rows that have the same values into summary rows, like \"find the number of customers in each country\".\n\nThe statement is often used with aggregate functions ( , , , , ) to group the result-set by one or more columns.\n\nBelow is a selection from the \"Customers\" table in the Northwind sample database:\n\nThe following SQL statement lists the number of customers in each country:\n\nThe following SQL statement lists the number of customers in each country, sorted high to low:\n\nBelow is a selection from the \"Orders\" table in the Northwind sample database:\n\nAnd a selection from the \"Shippers\" table:\n\nGROUP BY With JOIN Example\n\nThe following SQL statement lists the number of orders sent by each shipper:\n\nSELECT Shippers.ShipperName, COUNT(Orders.OrderID) AS NumberOfOrders FROM Orders\n\nLEFT JOIN Shippers ON Orders.ShipperID = Shippers.ShipperID\n\n GROUP BY ShipperName; Try it Yourself »"
    },
    {
        "link": "https://w3schools.com/sql/sql_groupby.asp",
        "document": "The statement groups rows that have the same values into summary rows, like \"find the number of customers in each country\".\n\nThe statement is often used with aggregate functions ( , , , , ) to group the result-set by one or more columns.\n\nBelow is a selection from the \"Customers\" table in the Northwind sample database:\n\nThe following SQL statement lists the number of customers in each country:\n\nThe following SQL statement lists the number of customers in each country, sorted high to low:\n\nBelow is a selection from the \"Orders\" table in the Northwind sample database:\n\nAnd a selection from the \"Shippers\" table:\n\nGROUP BY With JOIN Example\n\nThe following SQL statement lists the number of orders sent by each shipper:\n\nSELECT Shippers.ShipperName, COUNT(Orders.OrderID) AS NumberOfOrders FROM Orders\n\nLEFT JOIN Shippers ON Orders.ShipperID = Shippers.ShipperID\n\n GROUP BY ShipperName; Try it Yourself »"
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/t-sql/queries/select-group-by-transact-sql?view=sql-server-ver16",
        "document": "Applies to: SQL Server Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics Analytics Platform System (PDW) SQL analytics endpoint in Microsoft Fabric Warehouse in Microsoft Fabric SQL database in Microsoft Fabric\n\nA SELECT statement clause that divides the query result into groups of rows, usually by performing one or more aggregations on each group. The SELECT statement returns one row per group.\n\nSpecifies a column or a non-aggregate calculation on a column. This column can belong to a table, derived table, or view. The column must appear in the FROM clause of the SELECT statement, but is not required to appear in the SELECT list.\n\nThe column must appear in the FROM clause of the SELECT statement, but is not required to appear in the SELECT list. However, each table or view column in any nonaggregate expression in the <select> list must be included in the GROUP BY list:\n\nThe following statements are allowed:\n\nThe following statements are not allowed:\n\nThe column expression cannot contain:\n• A column alias that is defined in the SELECT list. It can use a column alias for a derived table that is defined in the FROM clause.\n• A column of type text, ntext, or image. However, you can use a column of text, ntext, or image as an argument to a function that returns a value of a valid data type. For example, the expression can use SUBSTRING() and CAST(). This also applies to expressions in the HAVING clause.\n• xml data type methods. It can include a user-defined function that uses xml data type methods. It can include a computed column that uses xml data type methods.\n\nGroups the SELECT statement results according to the values in a list of one or more column expressions.\n\nFor example, this query creates a Sales table with columns for Country, Region, and Sales. It inserts four rows and two of the rows have matching values for Country and Region.\n\nThe Sales table contains these rows:\n\nThis next query groups Country and Region and returns the aggregate sum for each combination of values.\n\nThe query result has 3 rows since there are 3 combinations of values for Country and Region. The TotalSales for Canada and British Columbia is the sum of two rows.\n\nCreates a group for each combination of column expressions. In addition, it \"rolls up\" the results into subtotals and grand totals. To do this, it moves from right to left decreasing the number of column expressions over which it creates groups and the aggregation(s).\n\nThe column order affects the ROLLUP output and can affect the number of rows in the result set.\n\nFor example, creates groups for each combination of column expressions in the following lists.\n• NULL, NULL, NULL, NULL --This is the grand total\n\nUsing the table from the previous example, this code runs a GROUP BY ROLLUP operation instead of a simple GROUP BY.\n\nThe query result has the same aggregations as the simple GROUP BY without the ROLLUP. In addition, it creates subtotals for each value of Country. Finally, it gives a grand total for all rows. The result looks like this:\n\nGROUP BY CUBE creates groups for all possible combinations of columns. For GROUP BY CUBE (a, b) the results has groups for unique values of (a, b), (NULL, b), (a, NULL), and (NULL, NULL).\n\nUsing the table from the previous examples, this code runs a GROUP BY CUBE operation on Country and Region.\n\nThe query result has groups for unique values of (Country, Region), (NULL, Region), (Country, NULL), and (NULL, NULL). The results look like this:\n\nThe GROUPING SETS option gives you the ability to combine multiple GROUP BY clauses into one GROUP BY clause. The results are the equivalent of UNION ALL of the specified groups.\n\nFor example, and return the same results.\n\nWhen GROUPING SETS has two or more elements, the results are a union of the elements. This example returns the union of the ROLLUP and CUBE results for Country and Region.\n\nThe results are the same as this query that returns a union of the two GROUP BY statements.\n\nSQL does not consolidate duplicate groups generated for a GROUPING SETS list. For example, in , both elements return a row for the grand total and both rows will be listed in the results.\n\nSpecifies the empty group, which generates the grand total. This is useful as one of the elements of a GROUPING SET. For example, this statement gives the total sales for each country/region and then gives the grand-total for all countries/regions.\n\nSpecifies to include all groups in the results regardless of whether they meet the search criteria in the WHERE clause. Groups that don't meet the search criteria have NULL for the aggregation.\n• Is not supported in queries that access remote tables if there is also a WHERE clause in the query.\n• Will fail on columns that have the FILESTREAM attribute.\n\nThe DISTRIBUTED_AGG query hint forces the massively parallel processing (MPP) system to redistribute a table on a specific column before performing an aggregation. Only one column in the GROUP BY clause can have a DISTRIBUTED_AGG query hint. After the query finishes, the redistributed table is dropped. The original table is not changed.\n\nNOTE: The DISTRIBUTED_AGG query hint is provided for backwards compatibility with earlier Analytics Platform System (PDW) versions and will not improve performance for most queries. By default, MPP already redistributes data as necessary to improve performance for aggregations.\n\nHow GROUP BY interacts with the SELECT statement\n• Vector aggregates. If aggregate functions are included in the SELECT list, GROUP BY calculates a summary value for each group. These are known as vector aggregates.\n• Distinct aggregates. The aggregates AVG (DISTINCT column_name), COUNT (DISTINCT column_name), and SUM (DISTINCT column_name) are supported with ROLLUP, CUBE, and GROUPING SETS.\n• SQL removes Rows that do not meet the conditions in the WHERE clause before any grouping operation is performed.\n• SQL uses the having clause to filter groups in the result set.\n• Use the ORDER BY clause to order the result set. The GROUP BY clause does not order the result set.\n• If a grouping column contains NULL values, all NULL values are considered equal, and they are collected into a single group.\n\nApplies to: SQL Server (starting with 2008) and Azure Synapse Analytics\n\nFor a GROUP BY clause that uses ROLLUP, CUBE, or GROUPING SETS, the maximum number of expressions is 32. The maximum number of groups is 4096 (212). The following examples fail because the GROUP BY clause has more than 4096 groups.\n• None The following example generates 4097 (212 + 1) grouping sets and will fail.\n• None The following example generates 4097 (212 + 1) groups and will fail. Both and the grouping set produce a grand total row and duplicate grouping sets aren't eliminated.\n• None This example uses the backwards compatible syntax. It generates 8192 (213) grouping sets and will fail. GROUP BY CUBE (a1, ..., a13) GROUP BY a1, ..., a13 WITH CUBE For backwards compatible GROUP BY clauses that don't contain CUBE or ROLLUP, the number of group by items is limited by the GROUP BY column sizes, the aggregated columns, and the aggregate values involved in the query. This limit originates from the limit of 8,060 bytes on the intermediate worktable that is needed to hold intermediate query results. A maximum of 12 grouping expressions is permitted when CUBE or ROLLUP is specified.\n\nSupport for ISO and ANSI SQL-2006 GROUP BY Features\n\nThe GROUP BY clause supports all GROUP BY features that are included in the SQL-2006 standard with the following syntax exceptions:\n• None Grouping sets aren't allowed in the GROUP BY clause unless they are part of an explicit GROUPING SETS list. For example, ) is allowed in the standard but not in Transact-SQL. Transact-SQL supports and , which are semantically equivalent. These are semantically equivalent to the previous example. This is to avoid the possibility that ) might be misinterpreted as , which aren't semantically equivalent.\n• None Grouping sets aren't allowed inside grouping sets. For example, is allowed in the SQL-2006 standard but not in Transact-SQL. Transact-SQL allows or , which are semantically equivalent to the first GROUP BY example and have a more clear syntax.\n• None GROUP BY [ALL/DISTINCT] is only allowed in a simple GROUP BY clause that contains column expressions. It isn't allowed with the GROUPING SETS, ROLLUP, CUBE, WITH CUBE or WITH ROLLUP constructs. ALL is the default and is implicit. It is also only allowed in the backwards compatible syntax.\n\nThe following table describes the GROUP BY features that are supported based upon SQL versions and database compatibility level.\n\nThe following example retrieves the total for each from the table. This example uses AdventureWorks.\n\nB. Use a GROUP BY clause with multiple tables\n\nThe following example retrieves the number of employees for each from the table joined to the table. This example uses AdventureWorks.\n\nC. Use a GROUP BY clause with an expression\n\nThe following example retrieves the total sales for each year by using the function. The same expression must be present in both the list and clause.\n\nD. Use a GROUP BY clause with a HAVING clause\n\nThe following example uses the clause to specify which of the groups generated in the clause should be included in the result set.\n\nE. Basic use of the GROUP BY clause\n\nThe following example finds the total amount for all sales on each day. One row containing the sum of all sales is returned for each day.\n\nF. Basic use of the DISTRIBUTED_AGG hint\n\nThis example uses the DISTRIBUTED_AGG query hint to force the appliance to shuffle the table on the column before performing the aggregation.\n\nWhen the select list has no aggregations, each column in the select list must be included in the GROUP BY list. Computed columns in the select list can be listed, but are not required, in the GROUP BY list. These are examples of syntactically valid SELECT statements:\n\nH. Using a GROUP BY with multiple GROUP BY expressions\n\nThe following example groups results using multiple criteria. If, within each group, there are subgroups that can be differentiated by , a new grouping will be defined for the result set.\n\nI. Using a GROUP BY clause with a HAVING clause\n\nThe following example uses the clause to specify the groups generated in the clause that should be included in the result set. Only those groups with order dates in 2004 or later will be included in the results."
    },
    {
        "link": "https://sqlshack.com/an-overview-of-the-sql-group-by-clause",
        "document": "This article briefly explains the SQL group by clause, when it should be used, and what we should consider when using it.\n\nSide Note: All code examples in this article are made using SQL Server 2019 and Stack Overflow 2010 database.\n\nWhat is “Grouping” in SQL, and why is it needed?\n\nConsider that we are analyzing the Stack overflow QA website database. This database contains several tables that store information about the website users, posted questions, answers, comments, and awarded badges.\n\nFor example, let’s take the “Posts” table. This table contains all information about different types of posts on the QA website; questions, answers, wiki, moderators’ nominations… If we are looking to count the number of each type of post, using a simple SELECT statement can return the number of rows of a single type by using the COUNT() function besides filtering the result using the WHERE clause:\n\nFigure 1 – Calculating the number of rows for one post’s type\n\nIf we try to add the PostTypeId column before the COUNT(*), the SQL command will not be executed and will throw the following exception to notify the user that aggregation is required to perform this operation:\n\nColumn ‘StackOverflow2010.dbo.Posts.PostTypeId’ is invalid in the select list because it is not contained in either an aggregate function or the GROUP BY clause.\n\nThe SQL GROUP BY clause arranges similar data stored within one or several columns into groups, where an aggregate function is applied to produce summaries. For example, calculating the number of posts for each user.\n\nFigure 2 – Calculating the number of each type of post\n\nBefore explaining the SQL GROUP BY clause and when we should use it, we need to know how is the SQL query executed by the database engine. Once asking to execute a SQL command, the database engine parses the different parts of it in the following order:\n\nAs defined in the Microsoft official documentation, a SELECT – GROUP BY command is a SELECT statement clause that divides the query result into groups of rows, usually to perform one or more aggregations on each group. The SELECT statement returns one row per group”.\n\nThe syntax of the GROUP BY clause is as follows:\n\nA SQL GROUP BY clause can be used to perform aggregations over each group or even to remove duplicated rows based on the grouping expression. For example, assume that we need to extract all the distinct locations of the Stack Overflow users. We can simply add the DISTINCT keyword after the SELECT term.\n\nOr, we can use a SELECT – GROUP BY command to achieve the same thing:\n\nIt is worth mentioning that both queries have the same execution plan.\n\nNow, we can add an aggregation function in the SELECT clause to perform it per each group.\n\nAs shown in the image below, all NULL values are considered equal and collected into a single group.\n\nFigure 4 – Adding an aggregate function to the SELECT – GROUP BY command\n\nChecking the command execution plan, we can see that after aggregating the data within groups, a scalar function is applied per each group.\n\nThe simplest way to use the SQL GROUP BY clause is to select the columns needed for the grouping operation. All columns specified in the SELECT clause – except the aggregation functions – should be specified in the GROUP BY clause. For example, if we execute the following query:\n\nThe following exception is thrown:\n\nColumn ‘StackOverflow2010.dbo.Users.Id’ is invalid in the select list because it is not contained in either an aggregate function or the GROUP BY clause.\n\nAnother thing worth mentioning is that column aliases cannot be used in the SQL GROUP BY clause since it is computed before the SELECT clause by the SQL engine.\n\nWe can also use user-defined scalar functions alongside the columns specified in the SELECT and GROUP BY clauses. For example, we created the following function to get whether a question has an answer or not:\n\nThe following query can be executed successfully.\n\nAnother way to group the result is by using column expressions. For example, if we are looking to group the columns based on a specific computation such as a mathematical expression or a CASE WHEN expression, we can simply use it similar to a single column. For example, assume that we want to count the number of questions being solved and the number of open issues on the Stack Overflow website. Noting that the Posts table only contains a column named AccetpedAnswerId that contains the identifier of the answer.\n\nWe cannot use the WHERE clause in this operation to filter the query result based on the group aggregated function result since the database engine executes the WHERE clause before applying the aggregate function. This is why the HAVING clause was found.\n\nThe HAVING clause can only be used with a SQL GROUP BY clause. For example, we need to get the locations mentioned in more than 1000 and less than 10000 user profiles.\n\nFigure 8 – Using the HAVING keyword to filter the result of a grouping operation\n\nTo explain the ROLLUP, CUBE, and GROUPING SETS options, we create a view from the Posts and Users tables with the following structure:\n\nLet’s assume that we want to generate a report showing the number of posts in each year, quarter, and month, for each post’s type. The result should be as the following:\n\nThe SQL GROUP BY ROLLUP lets us create the combinations that exist in the data in addition to rolling up within the hierarchical order we define in the ROLLUP statement. For example, let us try the following query:\n\nAs shown in the image below, the result includes three levels of aggregations:\n• The number of posts per month\n• The number of posts per quarter\n• The number of posts per year\n\nFigure 9 – Using the ROLLUP statement to apply aggregation on different hierarchical levels\n\nNow, let’s assume that we are asked to generate a report that shows the number of posts per user location, the post type, or both.\n\nTHE SQL GROUP BY CUBE statement produces every possible combination between the columns mentioned in the CUBE statement. For example, let’s try the following command:\n\nAs shown in the image below, the results contain three groups:\n• The number of posts per location\n• The number of posts per type\n• The number of posts per location and type\n\nFigure 10 – Using the GROUP BY CUBE statement\n\nSometimes we will be asked to only generate a report for only some specific combination of columns and expressions. In this case, using the CUBE or ROLLUP may be inefficient and time-consuming.\n\nFor this reason, we can use the GROUPING SETS statement, where we should define each combination explicitly. For example, we only want to generate a report showing the number of posts per location, per type, and the total number of posts.\n\nAs shown in the image below, the first five rows show the number of posts for each type, the 6th row shows the total number of posts, and the rest shows the number of posts per location.\n\nThis article briefly explained the SQL GROUP BY clause and how to use it to perform aggregate functions on the data. We also demonstrated the options available, such as grouping over a set of columns, expressions, and user-defined functions. In addition, we explained how to use the HAVING keyword for filtering and the ROLLUP, CUBE, and GROUPING SETS options for reporting purposes.\n\nTo learn more about the SQL GROUP BY function, you can refer to the following articles previously published on SQL Shack:"
    },
    {
        "link": "https://docs.data.world/documentation/sql/concepts/intermediate/GROUP_BY.html",
        "document": "enables you to use aggregate functions on groups of data returned from a query.\n\nis a modifier used on an aggregate function to limit the values used in an aggregation. All the columns in the select statement that aren’t aggregated should be specified in a clause in the query.\n\nReturning to a previous section, when we were working with aggregations, we used the aggregate function to find out the average deal size. If we wanted to know the average value of the deals won by each sales person from highest average to lowest, the query would look like:\n\nWe could even ascertain the average value of deals aggregated by manager by running a query with a join like this:\n\nThough it’s not required by SQL, it is advisable to include all non-aggregated columns from your clause in your clause. If you don’t, there are cases where the query will return the desired results, there are also instances where a random value from the non-aggregated row will be used as the representative for all the values returned by the query.\n\nFor example, let’s say you wanted to know the average deal by sales agent for each of their customers. If you used the query:\n\nyou would get back the following table which shows each sales agent one time and chooses a value at random from the accounts won by that sales person:\n\nTo get the average deal by sales agent for each account the query would look like this:\n\nThe first several rows of the table returned would look like this:\n\nIf you wanted to refine your query even more by running your aggregations against a limited set of the values in a column you could use the keyword. For example, if you wanted to know both the number of deals won by a sales agent and the number of those deals that had a value greater than 1000, you could use the query:\n\nThe first several rows of the resulting table would look like this:\n\nThe first several rows returned by the above query would look like:\n\nThere are two ways to do these exercises. The first is to use the “Try query” links to test your queries without saving them. The second is to create a data.world project and save your queries to it. If you are reading this documentation and completing the exercises as a tutorial, you will need to create your own project to save your work. Details and instructions are in the SQL tutorial which has instructions for setting up your project and links to all the current exercises.\n\nWrite a query that returns the patient column and a count of all the allergies the patient has from allergies table. Group your results by patient, and order them by the number of allergies from greatest to least.\n\nWrite a query that returns the patient column, the average of the value column relabeled as , the count of the value column relabeled as and the maximum value of the value column filtered for values over 30 and label it as . The query should be written against the observations_cleaned table and the results should all be for records where the description is “Body Mass Index”. Group your results by the patient column."
    },
    {
        "link": "https://simplilearn.com/tutorials/sql-tutorial/sql-aggregate-functions",
        "document": ""
    },
    {
        "link": "https://w3schools.com/sql/sql_aggregate_functions.asp",
        "document": "W3Schools offers a wide range of services and products for beginners and professionals, helping millions of people everyday to learn and master new skills."
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/t-sql/functions/aggregate-functions-transact-sql?view=sql-server-ver16",
        "document": "Applies to: SQL Server Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics Analytics Platform System (PDW) SQL analytics endpoint in Microsoft Fabric Warehouse in Microsoft Fabric\n\nAn aggregate function performs a calculation on a set of values, and returns a single value. Except for , aggregate functions ignore null values. Aggregate functions are often used with the GROUP BY clause of the SELECT statement.\n\nAll aggregate functions are deterministic. In other words, aggregate functions return the same value each time that they are called, when called with a specific set of input values. See Deterministic and Nondeterministic Functions for more information about function determinism. The OVER clause may follow all aggregate functions, except the STRING_AGG, GROUPING or GROUPING_ID functions.\n\nUse aggregate functions as expressions only in the following situations:\n• The select list of a SELECT statement (either a subquery or an outer query).\n\nTransact-SQL provides the following aggregate functions:"
    },
    {
        "link": "https://satnamsingh99.medium.com/aggregate-functions-and-grouping-data-in-sql-unleashing-the-power-of-sum-count-avg-group-by-59d8e7a85ef9",
        "document": "In the realm of relational databases, performing calculations on data is a common requirement. SQL (Structured Query Language) provides powerful aggregate functions that enable us to summarize and analyze data efficiently. In this comprehensive blog, we will explore essential aggregate functions, including SUM, COUNT, AVG, as well as the GROUP BY and HAVING clauses. With practical SQL examples, we will unlock the potential of these functions, empowering you to extract valuable insights from your data. Let’s dive into the world of aggregate functions and data grouping in SQL!\n\nAggregate functions in SQL allow us to perform calculations on groups of rows and return a single result. These functions are used in combination with the SELECT statement to compute meaningful summaries from data. The most commonly used aggregate functions include:\n• COUNT: Counts the number of rows in a result set or the number of non-null values in a column.\n• AVG: Computes the average value of a numeric column.\n• MIN: Retrieves the minimum value from a column.\n• MAX: Retrieves the maximum value from a column.\n\nWe will focus on SUM, COUNT, and AVG for this blog. Let’s delve into each of these functions with practical SQL examples.\n\nThe SUM function calculates the total sum of a numeric column in a table. It is often used to determine the sum of quantities, sales amounts, or any other numerical values. The basic syntax for the SUM function is as follows:\n\nHere’s a brief explanation of each part of the SUM function:\n• : This clause indicates that we want to retrieve data from the table.\n• : This is the aggregate function itself. Replace with the name of the column you want to sum.\n• : This optional part renames the result column to for better readability.\n\nLet’s illustrate the SUM function with an example:\n\nSuppose we have a table called that stores information about sales transactions, including the of each sale. To calculate the total sales amount, we can use the SUM function as follows:\n\nThe COUNT function is used to count the number of rows in a result set or the number of non-null values in a column. It is valuable for understanding the size of datasets or the frequency of specific values. The basic syntax for the COUNT function is as follows:\n\nHere’s a brief explanation of each part of the COUNT function:\n• : This clause indicates that we want to retrieve data from the table.\n• : This is the aggregate function itself. Replace with the name of the column you want to count. If you use , it will count all rows in the table.\n• : This optional part renames the result column to for better readability.\n\nLet’s demonstrate the COUNT function with some examples:\n\nExample 2: Counting the Number of Sales\n\nContinuing from the previous example, let’s count the number of sales transactions in the table:\n\nExample 3: Counting the Number of Customers\n\nSuppose we have a table called that contains information about individual customers. To count the number of unique customers in the table, we can use the COUNT function as follows:\n\nThe AVG function calculates the average value of a numeric column in a table. It provides valuable insights into the central tendency of the data. The basic syntax for the AVG function is as follows:\n\nHere’s a brief explanation of each part of the AVG function:\n• : This clause indicates that we want to retrieve data from the table.\n• : This is the aggregate function itself. Replace with the name of the column for which you want to calculate the average.\n• : This optional part renames the result column to for better readability.\n\nLet’s explore the AVG function with an example:\n\nSuppose we have a table called that contains information about employees, including their . To calculate the average salary of all employees, we can use the AVG function as follows:\n\nThe GROUP BY clause is used in combination with aggregate functions to group rows based on one or more columns. It allows us to apply aggregate functions to specific subsets of data within a table. The basic syntax for the GROUP BY clause is as follows:\n\nHere’s a brief explanation of each part of the GROUP BY clause:\n• : This clause indicates that we want to retrieve data from the table.\n• : These are the columns based on which we want to group the data.\n• : This is the aggregate function you want to apply to a specific column.\n• : This optional part assigns a name to the result of the aggregate function.\n\nLet’s illustrate the GROUP BY clause with an example:\n\nSuppose we have a table called that contains information about sales transactions, including the of each sale and the . To group the sales by month and calculate the total sales amount for each month, we can use the GROUP BY clause along with the SUM function as follows:\n\nThe HAVING clause is used to filter the results of a GROUP BY query based on specified conditions. It allows us to apply filtering to the results of aggregate functions. The basic syntax for the HAVING clause is as follows:\n\nHere’s a brief explanation of each part of the HAVING clause:\n• : This clause indicates that we want to retrieve data from the table.\n• : These are the columns based on which we grouped the data using the GROUP BY clause.\n• : This is the aggregate function applied to a specific column.\n• : This optional part assigns a name to the result of the aggregate function.\n• : This keyword indicates that we want to filter the results based on a condition.\n• : This is the filtering condition based on which the results will be filtered.\n\nLet’s demonstrate the HAVING clause with an example:\n\nContinuing from Example 4, suppose we want to filter the average salary results and only display the departments with an average salary greater than $50000. We can use the HAVING clause as follows:\n\nIn this blog, we explored the power of aggregate functions and data grouping in SQL. We learned about essential aggregate functions such as SUM, COUNT, and AVG, enabling us to perform calculations on data efficiently. The GROUP BY clause allowed us to group data based on specific columns and apply aggregate functions to subsets of data. The HAVING clause enabled us to filter the results of GROUP BY queries based on specified conditions.\n\nBy mastering these aggregate functions and data grouping techniques, you gain valuable tools to summarize and analyze data in your relational databases effectively. As you continue to work with SQL, experiment with various aggregate functions and explore different ways to group and analyze data. Happy querying!"
    },
    {
        "link": "https://datacarpentry.github.io/sql-ecology-lesson/02-sql-aggregation.html",
        "document": "Last updated on 2023-04-21 | Edit this page\n\nAggregation allows us to combine results by grouping records based on value. It is also useful for calculating combined values in groups. Let’s go to the surveys table and find out how many individuals there are. Using the wildcard * counts the number of records (rows): We can also find out how much all of those individuals weigh: We can output this value in kilograms (dividing the value by 1000.00), then rounding to 3 decimal places: (Notice the divisor has numbers after the decimal point, which forces the answer to have a decimal fraction) There are many other aggregate functions included in SQL, for example: , , and . Write a query that returns: the total weight, average weight, minimum and maximum weights for all animals caught over the duration of the survey. Can you modify it so that it outputs these values only for weights between 5 and 10? -- Only weights between 5 and 10 Now, let’s see how many individuals were counted in each species. We do this using a clause tells SQL what field or fields we want to use to aggregate the data. If we want to group by multiple fields, we give a comma separated list.\n• How many individuals were counted in each year in total\n• How many were counted each year, for each different species\n• The average weights of each species in each year Can you get the answer to both 2 and 3 in a single query?\n\nAs queries get more complex, the expressions we use can get long and unwieldy. To help make things clearer in the query and in its output, we can use aliases to assign new names to things in the query. We can use aliases in column names using : The isn’t technically required, so you could do but using is much clearer so it is good style to include it. We can not only alias column names, but also table names in the same way: And again, the keyword is not required, so this works, too: Aliasing table names can be helpful when working with queries that involve multiple tables; you will learn more about this later.\n\nIn the previous episode, we have seen the keyword , allowing to filter the results according to some criteria. SQL offers a mechanism to filter the results based on aggregate functions, through the keyword. For example, we can request to only return information about species with a count higher than 10: The keyword works exactly like the keyword, but uses aggregate functions instead of database fields to filter. You can use the keyword to assign an alias to a column or table, and refer to that alias in the clause. For example, in the above query, we can call the by another name, like . This can be written this way: Note that in both queries, comes after . One way to think about this is: the data are retrieved ( ), which can be filtered ( ), then joined in groups ( ); finally, we can filter again based on some of these groups ( ). Write a query that returns, from the table, the number of in each , only for the with more than 10 .\n\nIt is not uncommon to repeat the same operation more than once, for example for monitoring or reporting purposes. SQL comes with a very powerful mechanism to do this by creating views. Views are a form of query that is saved in the database, and can be used to look at, filter, and even update information. One way to think of views is as a table, that can read, aggregate, and filter information from several places before showing it to you. Creating a view from a query requires us to add before the query itself. For example, imagine that our project only covers the data gathered during the summer (May - September) of 2000. That query would look like: But we don’t want to have to type that every time we want to ask a question about that particular subset of data. Hence, we can benefit from a view: Using a view we will be able to access these results with a much shorter notation:\n\nFrom the last example, there should only be five records. If you look at the column, it’s easy to see what the average weight would be. If we use SQL to find the average weight, SQL behaves like we would hope, ignoring the NULL values: But if we try to be extra clever, and find the average ourselves, we might get tripped up: Here the function includes all five records (even those with NULL values), but the only includes the three records with data in the field, giving us an incorrect average. However, our strategy will work if we modify the function slightly: When we count the weight field specifically, SQL ignores the records with data missing in that field. So here is one example where NULLs can be tricky: and can return different values. Another case is when we use a “negative” query. Let’s count all the non-female animals: Now let’s count all the non-male animals: But if we compare those two numbers with the total: We’ll see that they don’t add up to the total! That’s because SQL doesn’t automatically include NULL values in a negative conditional statement. So if we are querying “not x”, then SQL divides our data into three categories: ‘x’, ‘not NULL, not x’ and NULL; then, returns the ‘not NULL, not x’ group. Sometimes this may be what we want - but sometimes we may want the missing values included as well! In that case, we’d need to change our query to:\n• Use the keyword to aggregate data.\n• Functions like , , , , , etc. operate on aggregated data.\n• Aliases can help shorten long queries. To write clear and readable queries, use the keyword when creating aliases.\n• Use the keyword to filter on aggregate properties.\n• Use a to access the result of a query as though it was a new table."
    },
    {
        "link": "https://dataforgelabs.com/advanced-sql-concepts/complex-sql-queries",
        "document": "Structured Query Language (SQL) is a standard language for defining, modifying, and controlling data within relational databases. A basic SQL query typically involves selecting data from tables, applying filters, and sorting the results. However, advanced SQL queries become necessary when data structure and business logic complexity increase. They enable intricate data transformations at scale in areas like ETL (Extract, Transform, Load), data warehousing, data analysis, and reporting. Key techniques in complex SQL queries include subqueries, joins, unions, intersections, aggregate functions, window functions, common table expressions (CTEs), pivoting, recursive queries, string manipulation, date and time functions, and case statements. This article provides an overview of each technique, along with best practices to achieve precise and efficient data processing.\n\nRecursive queries allow you to link one record with others in the same table, making them suitable for handling hierarchical data structures such as organizational charts or product dependencies. They are typically built using Common Table Expressions (CTEs). CTEs simplify complex queries by breaking them into smaller, reusable subparts. It involves defining the subquery with a meaningful name so that it can be referenced multiple times within the main query. CTEs improve readability and allow you to build queries modularly, making debugging and testing more efficient.\n\nUse a declarative approach to build reusable code blocks and make your SQL logic more modular and understandable. Declarative configurations emphasize specifying what to do rather than how to do it. They tend to be easier to debug, reuse, and optimize. Unfortunately, SQL statements are only declarative in isolation. Multi-statement SQL scripts dictate the exact order of persistence (e.g., using INSERT and UPDATE in a specific order) and tend to become rigid and monolithic. DataForge is an open-source, next-generation data transformation tool that improves SQL’s declarative approach. It provides more flexibility and declarative power, especially for complex data transformations and processing tasks. For example, we could define a “products” source using the below code with Dataforge :"
    },
    {
        "link": "https://mode.com/sql-tutorial/sql-sub-queries",
        "document": "Starting here? This lesson is part of a full-length tutorial in using SQL for Data Analysis. Check out the beginning.\n\nIn this lesson we'll cover:\n• Using subqueries to aggregate in multiple stages\n\nIn this lesson, you will continue to work with the same San Francisco Crime data used in a previous lesson.\n\nSubqueries (also known as inner queries or nested queries) are a tool for performing operations in multiple steps. For example, if you wanted to take the sums of several columns, then average all of those values, you'd need to do each aggregation in a distinct step.\n\nSubqueries can be used in several places within a query, but it's easiest to start with the statement. Here's an example of a basic subquery:\n\nLet's break down what happens when you run the above query:\n\nFirst, the database runs the \"inner query\"—the part between the parentheses:\n\nIf you were to run this on its own, it would produce a result set like any other query. It might sound like a no-brainer, but it's important: your inner query must actually run on its own, as the database will treat it as an independent query. Once the inner query runs, the outer query will run using the results from the inner query as its underlying table:\n\nSubqueries are required to have names, which are added after parentheses the same way you would add an alias to a normal table. In this case, we've used the name \"sub.\"\n\nA quick note on formatting: The important thing to remember when using subqueries is to provide some way to for the reader to easily determine which parts of the query will be executed together. Most people do this by indenting the subquery in some way. The examples in this tutorial are indented quite far—all the way to the parentheses. This isn't practical if you nest many subqueries, so it's fairly common to only indent two spaces or so.\n\nThe above examples, as well as the practice problem don't really require subqueries—they solve problems that could also be solved by adding multiple conditions to the clause. These next sections provide examples for which subqueries are the best or only way to solve their respective problems.\n\nUsing subqueries to aggregate in multiple stages\n\nWhat if you wanted to figure out how many incidents get reported on each day of the week? Better yet, what if you wanted to know how many incidents happen, on average, on a Friday in December? In January? There are two steps to this process: counting the number of incidents each day (inner query), then determining the monthly average (outer query):\n\nIf you're having trouble figuring out what's happening, try running the inner query individually to get a sense of what its results look like. In general, it's easiest to write inner queries first and revise them until the results make sense to you, then to move on to the outer query.\n\nYou can use subqueries in conditional logic (in conjunction with , / , or ). The following query returns all of the entries from the earliest date in the dataset (theoretically—the poor formatting of the date column actually makes it return the value that sorts first alphabetically):\n\nThe above query works because the result of the subquery is only one cell. Most conditional logic will work with subqueries containing one-cell results. However, is the only type of conditional logic that will work when the inner query contains multiple results:\n\nNote that you should not include an alias when you write a subquery in a conditional statement. This is because the subquery is treated as an individual value (or set of values in the case) rather than as a table.\n\nYou may remember that you can filter queries in joins. It's fairly common to join a subquery that hits the same table as the outer query rather than filtering in the clause. The following query produces the same results as the previous example:\n\nThis can be particularly useful when combined with aggregations. When you join, the requirements for your subquery output aren't as stringent as when you use the clause. For example, your inner query can output multiple results. The following query ranks all of the results according to how many incidents were reported in a given day. It does this by aggregating the total number of incidents each day in the inner query, then using those values to sort the outer query:\n\nSubqueries can be very helpful in improving the performance of your queries. Let's revisit the Crunchbase Data briefly. Imagine you'd like to aggregate all of the companies receiving investment and companies acquired each month. You could do that without subqueries if you wanted to, but don't actually run this as it will take minutes to return:\n\nNote that in order to do this properly, you must join on date fields, which causes a massive \"data explosion.\" Basically, what happens is that you're joining every row in a given month from one table onto every month in a given row on the other table, so the number of rows returned is incredibly great. Because of this multiplicative effect, you must use instead of to get accurate counts. You can see this below:\n\nIf you'd like to understand this a little better, you can do some extra research on cartesian products. It's also worth noting that the and above actually runs pretty fast—it's the that takes forever. More on that in the lesson on optimizing queries.\n\nOf course, you could solve this much more efficiently by aggregating the two tables separately, then joining them together so that the counts are performed across far smaller datasets:\n\nNote: We used a above just in case one table had observations in a month that the other table didn't. We also used to display months when the subquery didn't have month entries (presumably no acquisitions occurred in those months). We strongly encourage you to re-run the query without some of these elements to better understand how they work. You can also run each of the subqueries independently to get a better understanding of them as well.\n\nFor this next section, we will borrow directly from the lesson on UNIONs—again using the Crunchbase data:\n\nIt's certainly not uncommon for a dataset to come split into several parts, especially if the data passed through Excel at any point (Excel can only handle ~1M rows per spreadsheet). The two tables used above can be thought of as different parts of the same dataset—what you'd almost certainly like to do is perform operations on the entire combined dataset rather than on the individual parts. You can do this by using a subquery:\n\nThis is pretty straightforward. Try it for yourself:"
    },
    {
        "link": "https://popsql.com/blog/complex-sql-queries",
        "document": "Complex queries in SQL don't need to be hard to write. Learn what they are, how to create them, and some examples in this article.\n\nWhen you start working with SQL, you'll learn about the query to get data from tables. You'll then learn a range of techniques such as using the keyword, joining to tables, and ordering your results.\n\nOnce you've got the basics, you'll start moving into more advanced queries.\n\nA complex query in SQL is one that has more complexity and that you need to give some more thought to when you design and write it.\n\nA complex query could include features such as:\n• joining to many tables, and using different join types\n• group by and having\n\nThese kinds of queries take a bit more thought to understand how to design them and write them so they show the results you need, perform well, and are easy to understand.\n\nThe main piece of advice I can offer for writing a complex query is that it's like writing many small queries put together.\n\nYou might be confused or overwhelmed by the need to write something pretty complex.\n\nHowever, I suggest writing a small query first, and then adding to it piece-by-piece, until you get the final result you need.\n\nSo, start small. Write a simple query that just selects one or two columns from a table.\n\nRun the query and see the result. Is it what you are expecting?\n\nIf so, update the query to add a little more to it. Perhaps add some more columns, or a clause to filter data.\n\nRun the query again and check the results. If they look good, keep going. If they don't, then review your query and see what may be causing the issue.\n\nWhen you start to join to tables in your query, you may want to run a Select query on those tables first. This is so you can see the data in the table and to help you understand what your results might look like.\n\nOnce you can see the results from a simple Select in another table, then you may want to join it to your main query. Run the query, then check the results.\n\nKeep going until you have the query and results that you need.\n\nSo, to write a complex query in SQL, it's easier to write it in smaller pieces and test it as you go by running the query and checking the results.\n\nIn the previous section, we mentioned that a complex SQL query may include features such as joining multiple tables and subqueries.\n\nThere are a range of other features in SQL to make it easier to write SQL complex queries.\n\nLet's look at a few of them now.\n\nA Common Table Expression (CTE) is a name you can give to a subquery within your main query.\n\nThe main reason you would do this is to simplify your query, making it easier to read and debug. It can sometimes improve performance, which is another benefit, but it's mostly about readability and simplification.\n\nHere's a query with a subquery that does not have a Common Table Expression:\n\nThis same query could be updated to use a Common Table Expression. This would involve giving a name to the subquery. This named subquery could then be used as though it was a table in the main query:\n\nThis might not seem like much of an improvement.\n\nHowever, there are a few ways it can help.\n\nMoving the subquery to the top of the query and giving it a name will mean it's easier to understand what the query does. If your subquery selects all employees that have a higher-than-average salary, you could name your subquery something like . When you refer to this in the main query, you'll see this name and will know what it refers to.\n\nYou can also read and update the logic in one place. The logic to calculate the results for this subquery is at the top of the query. You can often copy and paste this query to another tab and run it separately, making it easier to understand and even debug the query.\n\nIt's also helpful if you have a long query and need this logic in several places. You can define it once, at the top of the query, and refer to it many times throughout your main query.\n\nSo, consider using Common Table Expressions whenever you have a subquery as a way to improve the readability of your query.\n\nIn SQL, you have functions that calculate a value based on many other records, such as and , and return a single row. These are called aggregate functions.\n\nYou can use the clause with these functions to calculate numbers for each group that is shown.\n\nLet's say you had a table of orders that looked like this:\n\nLet's say you wanted to see the total amount of orders per day. You can use a and a for this:\n\nYour results would be:\n\nThis works, but using the and in this way means that the records you display must match the way that the data is calculated.\n\nYou show one row for each date, and you calculate the sum for that date.\n\nWhat if you wanted to see all orders and the sum for each date? Or, you wanted to see a running total: the sum of orders so far for that date?\n\nYou can do this with window functions.\n\nA window function is a way to write an SQL function that lets you perform a calculation on a range of rows that's different to how you display the rows.\n\nSo, you might want a running total like this:\n\nYour query could look like this:\n\nThe clause means that the function is calculated over a range of rows, and not the entire set of results.\n\nThe clause refers to the column that's used to define the range of rows. In this example, all records with the same order_date are used for calculating the sum.\n\nThe determines which records come first in the running total calculation. In this example, it's by .\n\nThis query will give you the results including the running total.\n\nSo, if you need to calculate data using a different range to what is being displayed, you can use a window function. If it's something you were going to do in application code, consider using a window function to take advantage of the database.\n\nThe final technique that's common with complex SQL queries is a hierarchical query.\n\nA hierarchical query, or recursive query, is where you write a query that links one record with other records in the same table.\n\nThis allows you to work with a table that stores different records where a record is a parent of another record.\n• employees and managers, where the manager is an employee\n• product categories and subcategories, which can have many levels\n\nRather than having many tables for each level, you can store all of your data in a single table and have a column that refers to the primary key of another record in the same table.\n\nYou can then write a query to show the data you need.\n\nFor example, you may have an employee table that has a column called that refers to that employee's manager:\n\nThis allows many levels of employees and managers. Sarah has a of indicating she is at the head of the organization.\n\nYou can use SQL to write a recursive query or hierarchical query to show the entire organization chart.\n\nHere's a query to do that:\n\nThis query uses a Common Table Expression to get a list of employees and their managers.\n\nWithin the CTE, called , we select the employee with an id of 1, which is the top of the organization.\n\nWe then combine this with all of the other employees, by selecting from the same query defined in the clause, joining on the manager id and employee id.\n\nThis ability to refer to a CTE from within the same CTE is what makes the query a recursive query.\n\nIf you're using Oracle or SQL Server, this will work. If you're using MySQL or Postgres, you'll need to add the word after the keyword to get it to work:\n\nYou will then display a list of employees and their level in the organization.\n\nYou can also do some interesting things with this query, such as:\n• adding the name of a person's manager\n• indenting their name a number of spaces depending on a person's level, to make it look like a tree\n\nSo, a recursive or hierarchical query uses a range of advanced techniques such as Common Table Expressions, Unions, and self-joins to get the result you want in a specific type of database design.\n\nLet's take a look at some more examples of complex queries in SQL, using some of the techniques above, as well as other techniques.\n\nYou can calculate the rank of a record based on one of its values by using the RANK function as a window function.\n\nFor example, this query calculates the rank of an order based on its order amount.\n\nThis will show all orders, and the column will show 1 for the highest order amount, 2 for the second highest, and so on. It shows the same values regardless of how you want to order the overall result.\n\nAnother example is using a window function called to find the difference of a value between two rows.\n\nWithout window functions, this would be difficult, but fortunately, we can use as a window function to find this out.\n\nLet's say we want to display the total of orders for each month, and then show the difference of this total compared to the previous month.\n\nOur query may look like this:\n\nUsing the function lets you refer to the previous row, which is done using the clause within the clause.\n\nYou can use the function to add up number values. It's often used to add everything in a column.\n\nHowever, it can also be used to add numbers based on certain criteria.\n\nLet's say we wanted to show the total amount of orders in a month but separated based on paid status.\n\nHere's a query that could be used:\n\nThe result could be something like this:\n\nYou can use along with to create this kind of result where you only values that meet certain criteria.\n\nThere are several features within PopSQL that help you work with complex SQL queries.\n\nA complex query in SQL can often include specifying parameter values, such as a value to check in the clause or conditions for a statement.\n\nIf you have this written in an SQL script file, and need to change the values, you'll need to update the query manually for all occurrences of this value, then run the query - and hopefully you don't break it along the way.\n\nIn PopSQL, there's a handy feature called SQL Variables. You can add a placeholder for a variable within your query and specify a value. If you need to change the value to be used in the query, you can simply change the value of the variable and run the query.\n\nHere's an example of a query with a variable.\n\nWe can see the query has the variable within the SQL (called ) and the variable at the top of the query outside the query itself. It has a value of \"USA\" but it can be changed.\n\nYou can change that value, and run the query again. This is much easier than manually editing the SQL script.\n\nThese variables can also be set to use a dropdown of specific values, so you can choose one from the list, reducing the chance of errors.\n\nSometimes when you're working on a complex query, you'll need to involve another person. This could be a person within your team to get a second opinion, or a person in another team who's an expert in a certain area of the business, for example.\n\nIn PopSQL, you can easily share your query with other people. You don't need to email them a link or a link to a GitHub file.\n\nWhen you have a query opened, you can click on the “Share” button to specify how you want to share the query.\n\nYou can select “Can View” if you want the other person to only be able to view the query. This can be helpful if you're presenting the query but don't need it to be edited, or if you only want someone to be able to run the query and see the results. If your query includes variables, the viewer can change those too.\n\nYou can select “Can Edit” if you want the other person to be able to view and edit the query. The other person can edit the query, run it, and essentially work on it with you to complete the query.\n\nThe SQL Editor within PopSQL has some handy features for working with complex queries.\n\nRun Multiple Statements: You can write multiple statements in one query. This is common when working with complex queries, as you may be writing smaller queries as you build up to the final query, or take parts of a large query and run them independently.\n\nIf you have multiple statements, you can run them independently. You could also run them all at once by clicking the arrow next to the “Run” button and selecting “Run all statements”.\n\nNow, whenever you click “Run”, all of the statements will be executed. If this is something you do often, this can save you time.\n\nQuery Descriptions: You can add descriptions to your queries to make it easier to identify them in your editor. This is helpful whether you only have a few queries or a lot of queries. I think this is better than adding an SQL comment to the start of the query because you can see the description as you scroll down the query.\n\nVersion History: PopSQL includes a version history of your queries. This is helpful as you write complex SQL queries and if you ever need to go back in time to a previous version.\n\nPopSQL's editor includes many features you'll find in other SQL editors such as tabbed windows and syntax highlighting, but these features mentioned above are additional features that are helpful for working with complex queries.\n\nOnce you get comfortable with the basics of SQL, you'll start working with more complex queries that are longer and include more features such as subqueries and grouping. Getting better at writing and reading these queries comes with practice and understanding how they work. PopSQL can make it easier for you, whether you're writing them by yourself or working with a team of people."
    },
    {
        "link": "https://medium.com/learning-sql/mastering-subqueries-in-sql-a-comprehensive-guide-cc584de5128a",
        "document": "Structured Query Language (SQL) is a powerful tool for managing and manipulating relational databases. One of the most advanced and versatile features of SQL is the subquery. Subqueries, also known as nested queries or inner queries, allow you to use the result of one query as the input for another query. Mastering subqueries can significantly enhance your ability to write complex and efficient SQL queries. In this guide, we’ll explore what subqueries are, how they work, and how you can master them to become a proficient SQL developer.\n\nA subquery is a query nested within another SQL statement, such as SELECT, INSERT, UPDATE, or DELETE. Subqueries can be used in various parts of a SQL statement, including the SELECT clause, WHERE clause, FROM clause, and HAVING clause. The result of a subquery is treated as a temporary table or dataset that can be used by the outer query.\n\nThere are several types of subqueries, each serving different purposes:\n\n1. Single-Row Subqueries: These subqueries return only one row of data and are typically used with comparison operators like =, <, >, etc.\n\nExample: Suppose we have a database with a table of employees and another table of departments. We want to find the department name of the employee with the highest salary.\n\n2. Multiple-Row Subqueries: These subqueries return multiple rows of data and are often used with set operators like IN, ANY, ALL, EXISTS, etc.\n\nExample: Suppose we want to find all employees who work in departments located in specific cities.\n\n3. Correlated Subqueries: In correlated subqueries, the inner query depends on the outer query, and the inner query is executed for each row processed by the outer query.\n\nExample: Suppose we want to find all employees who earn a salary greater than the average salary in their department.\n\n4. Nested Subqueries: Nested subqueries contain multiple levels of nesting, where one subquery is nested within another subquery.\n\nExample: Suppose we want to find all employees who work in departments with the highest average salary among all departments.\n\nBest Practices for Mastering Subqueries in SQL: Explained and Illustrated\n\nSubqueries in SQL are a powerful tool for extracting, manipulating, and analyzing data from relational databases. Mastering subqueries requires not only understanding their syntax but also applying best practices to ensure efficient and effective query writing. Let’s delve deeper into each of the best practices outlined:\n\n1. Understand the Logic: Before diving into writing subqueries, it’s crucial to have a clear understanding of the logic and purpose of the query. Break down the problem into smaller steps and identify where subqueries can be useful.\n\nExample: Suppose we have a database containing tables for employees and departments. We want to find the names of employees who work in the same department as employee “John Smith.”\n\nThis subquery identifies the department ID of “John Smith” based on his name.\n\n2. Start Simple: Begin with simple subqueries and gradually increase complexity as you become more comfortable. Practice writing basic single-row and multiple-row subqueries to understand their syntax and behavior.\n\nExample: Let’s say we want to find all employees who have a salary greater than the average salary.\n\nThis single-row subquery calculates the average salary and compares it with each employee’s salary.\n\n3. Optimize Performance: Subqueries can impact query performance, especially if they are nested or correlated. Optimize performance by ensuring that subqueries are well-written, properly indexed, and avoid unnecessary repetition of calculations.\n\nExample: Consider a scenario where we want to find all employees who have a salary greater than the average salary in their department.\n\nBy correlating the subquery with the outer query on the department ID, we ensure that the subquery is optimized for the specific department.\n\n4. Use Correlated Subqueries Wisely: While correlated subqueries can be powerful, they can also lead to performance issues if not used judiciously. Limit their use and consider alternative approaches such as JOINs or window functions where applicable.\n\nExample: Let’s rewrite the previous example using a JOIN instead of a correlated subquery.\n\nThis query achieves the same result as the correlated subquery but may be more efficient in certain scenarios.\n\n5. Test and Debug: Test your subqueries thoroughly to ensure they return the expected results. Use sample data and test cases to validate the accuracy and efficiency of your queries. Debug any errors or unexpected outcomes by analyzing the logic of your subqueries.\n\nExample: Create a set of test data and run your subqueries against it to verify their correctness. If discrepancies arise, carefully examine the logic of your subqueries and identify any potential issues.\n\n6. Leverage Documentation and Resources: Take advantage of SQL documentation, tutorials, and online resources to deepen your understanding of subqueries. Learn from examples and practice implementing different types of subqueries in various scenarios.\n\nExample: Explore SQL tutorials, forums, and documentation to learn about advanced subquery techniques, optimization strategies, and real-world use cases. Experiment with different types of subqueries and analyze their performance and effectiveness.\n\nMastering subqueries in SQL is essential for writing efficient, scalable, and powerful database queries. By understanding the types of subqueries, following best practices, and gaining practical experience, you can become proficient in leveraging subqueries to extract, manipulate, and analyze data from relational databases. With practice and perseverance, you can elevate your SQL skills and become a more effective SQL developer or data analyst."
    },
    {
        "link": "https://metabase.com/learn/grow-your-data-skills/learn-sql/working-with-sql/sql-best-practices",
        "document": "This article covers some best practices for writing SQL queries for data analysts and data scientists. Most of our discussion will concern SQL in general, but we’ll include some notes on features specific to Metabase that make writing SQL a breeze.\n\nCorrectness, readability, then optimization: in that order\n\nThe standard warning against premature optimization applies here. Avoid tuning your SQL query until you know your query returns the data you’re looking for. And even then, only prioritize optimizing your query if it’s run frequently (like powering a popular dashboard), or if the query traverses a large number of rows. In general, prioritize accuracy (does the query produce the intended results), and readability (can others easily understand and modify the code) before worrying about performance.\n\nMake your haystacks as small as possible before searching for your needles\n\nArguably, we’re already getting into optimization here, but the goal should be to tell the database to scan the minimum number of values necessary to retrieve your results.\n\nPart of SQL’s beauty is its declarative nature. Instead of telling the database how to retrieve records, you need only tell the database which records you need, and the database should figure out the most efficient way to get that information. Consequently, much of the advice about improving the efficiency of queries is simply about showing people how to use the tools in SQL to articulate their needs with more precision.\n\nWe’ll review the general order of query execution, and include tips along the way to reduce your search space. Then we’ll talk about three essential tools to add to your utility belt: INDEX, EXPLAIN, and WITH.\n\nFirst, get to know your data\n\nFamiliarize yourself with your data before your write a single line of code by studying the metadata to make sure that a column really does contain the data you expect. The SQL editor in Metabase features a handy data reference tab (accessible via the book icon), where you can browse through the tables in your database, and view their columns and connections:\n\nYou can also view sample values for specific columns:\n\nMetabase gives you many different ways to explore your data: you can X-ray tables, compose questions using the query builder, convert a saved question to SQL code, or build from an existing SQL query. We cover this in other articles; for now, let’s go through the general workflow of a query.\n\nEveryone’s method will differ, but here’s an example workflow to follow when developing a query.\n• As above, study the column and table metadata. If you’re using Metabase’s native (SQL) editor, you can also search for Snippets that contain SQL code for the table and columns you’re working with. Snippets allow you to see how other analysts have been querying the data. Or you can start a query from an existing SQL question.\n• To get a feel for a table’s values, SELECT * from the tables you’re working with and LIMIT your results. Keep the LIMIT applied as you refine your columns (or add more columns via joins).\n• Narrow down the columns to the minimal set required to answer your question.\n• Apply any filters to those columns.\n• If you need to aggregate data, aggregate a small number of rows and confirm that the aggregations are as you expect.\n• Once you have a query returning the results you need, look for sections of the query to save as a Common Table Expression (CTE) to encapsulate that logic.\n• With Metabase, you can also save code as a Snippet to share and reuse in other queries.\n\nBefore we get into individual tips on writing SQL code, it’s important to have a sense of how databases will carry out your query. This differs from the reading order (left to right, top to bottom) you use to compose your query. Query optimizers can change the order of the following list, but this general lifecycle of a SQL query is good to keep in mind when writing SQL. We’ll use the execution order to group the tips on writing good SQL that follow.\n\nThe rule of thumb here is this: the earlier in this list you can eliminate data, the better.\n• FROM (and JOIN) get(s) the tables referenced in the query. These tables represent the maximum search space specified by your query. Where possible, restrict this search space before moving forward.\n• HAVING filters out aggregated data that doesn’t meet the criteria.\n• SELECT grabs the columns (then deduplicates rows if DISTINCT is invoked).\n\nAnd, of course, there will always be occasions where the query optimizer for your particular database will devise a different query plan, so don’t get hung up on this order.\n\nThe following tips are guidelines, not rules, intended to keep you out of trouble. Each database handles SQL differently, has a slightly different set of functions, and takes different approaches to optimizing queries. And that’s before we even get into comparing traditional transactional databases with analytics databases that use columnar storage formats, which have vastly different performance characteristics.\n\nHelp people out (including yourself three months from now) by adding comments that explain different parts of the code. The most important thing to capture here is the “why.” For example, it’s obvious that the code below filters out orders with greater than 10, but the reason it’s doing that is because the first 10 orders are used for testing.\n\nThe catch here is that you introduce a little maintenance overhead: if you change the code, you need to make sure that the comment is still relevant and up to date. But that’s a small price to pay for readable code.\n\nSQL best practices for FROM\n\nJoin tables using the ON keyword\n\nAlthough it’s possible to “join” two tables using a clause (that is, to perform an implicit join, like ), you should instead prefer an explicit JOIN:\n\nMostly for readability, as the + syntax distinguishes joins from clauses intended to filter the results.\n\nWhen querying multiple tables, use aliases, and employ those aliases in your select statement, so the database (and your reader) doesn’t need to parse which column belongs to which table. Note that if you have columns with the same name across multiple tables, you will need to explicitly reference them with either the table name or alias.\n\nThis is a trivial example, but when the number of tables and columns in your query increases, your readers won’t have to track down which column is in which table. That and your queries might break if you join a table with an ambiguous column name (e.g., both tables include a field called .\n\nNote that field filters are incompatible with table aliases, so you’ll need to remove aliases when connecting filter widgets to your Field Filters.\n\nSQL best practices for WHERE\n\nFilter with WHERE before HAVING\n\nUse a clause to filter superfluous rows, so you don’t have to compute those values in the first place. Only after removing irrelevant rows, and after aggregating those rows and grouping them, should you include a clause to filter out aggregates.\n\nAvoid functions on columns in WHERE clauses\n\nUsing a function on a column in a clause can really slow down your query, as the function makes the query non-sargable (i.e., it prevents the database from using an index to speed up the query). Instead of using the index to skip to the relevant rows, the function on the column forces the database to run the function on each row of the table.\n\nAnd remember, the concatenation operator is also a function, so don’t get fancy trying to concat strings to filter multiple columns. Prefer multiple conditions instead:\n\nThis is not always the case. It’s good to know that compares characters, and can be paired with wildcard operators like , whereas the operator compares strings and numbers for exact matches. The can take advantage of indexed columns. This isn’t the case with all databases, as can use indexes (if they exist for the field) as long as you avoid prefixing the search term with the wildcard operator, . Which brings us to our next point:\n\nUsing wildcards for searching can be expensive. Prefer adding wildcards to the end of strings. Prefixing a string with a wildcard can lead to a full table scan.\n\nIf you just need to verify the existence of a value in a table, prefer to , as the process exits as soon as it finds the search value, whereas will scan the entire table. should be used for finding values in lists.\n\nSQL best practices for GROUP BY\n\nWhere possible, columns in order of descending cardinality. That is, group by columns with more unique values first (like IDs or phone numbers) before grouping by columns with fewer distinct values (like state or gender).\n\nSQL best practices for HAVING\n\nOnly use HAVING for filtering aggregates\n\nAnd before , filter out values using a clause before aggregating and grouping those values.\n\nSpecify the columns you’d like to include in the results (though it’s fine to use when first exploring tables — just remember to your results).\n\nIf duplicates are not an issue, won’t discard them, and since isn’t tasked with removing duplicates, the query will be more efficient.\n\nSQL best practices for ORDER BY\n\nAvoid sorting where possible, especially in subqueries\n\nSorting is expensive. If you must sort, make sure your subqueries are not needlessly sorting data.\n\nThis section is for the database admins in the crowd (and a topic too large to fit in this article). One of the most common things folks run into when experiencing performance issues in database queries is a lack of adequate indexing.\n\nWhich columns you should index usually depends on the columns you’re filtering by (i.e., which columns typically end up in your clauses). If you find that you’re always filtering by a common set of columns, you should consider indexing those columns.\n\nIndexing foreign key columns and frequently queried columns can significantly decrease query times. Here’s an example statement to create an index:\n\nThere are different types of indexes available, the most common index type uses a B-tree to speed up retrieval. Check out our article on making dashboards faster, and consult your database’s documentation on how to create an index.\n\nFor particularly large datasets, or lopsided datasets, where certain value ranges appear more frequently, consider creating an index with a clause to limit the number of rows indexed. Partial indexes can also be useful for date ranges as well, for example if you want to index the past week of data only.\n\nFor columns that typically go together in queries (such as last_name, first_name), consider creating a composite index. The syntax is similar to creating a single index. For example:\n\nSome databases, like PostgreSQL, offer insight into the query plan based on your SQL code. Simply prefix your code with the keywords . You can use these commands to check your query plans and look for bottlenecks, or to compare plans from one version of your query to another to see which version is more efficient.\n\nHere’s an example query using the sample database available for PostgreSQL.\n\nYou’ll see milliseconds required for planning time, execution time, as well as the cost, rows, width, times, loops, memory usage, and more. Reading these analyses is somewhat of an art, but you can use them to identify problem areas in your queries (such as nested loops, or columns that could benefit from indexing), as you refine them.\n\nUse the clause to encapsulate logic in a common table expression (CTE). Here’s an example of a query that looks for the products with the highest average revenue per unit sold in 2019, as well as max and min values.\n\nThe clause makes the code readable, as the main query (what you’re actually looking for) isn’t interrupted by a long sub query.\n\nYou can also use CTEs to make your SQL more readable if, for example, your database has fields that are awkwardly named, or that require a little bit of data munging to get the useful data. For example, CTEs can be useful when working with JSON fields. Here’s an example of extracting and converting fields from a JSON blob of user events.\n\nAlternatively, you could save a subquery as a Snippet:\n\nAnd yes, as you might expect, the Aerodynamic Leather Toucan fetches the highest average revenue per unit sold.\n\nWith Metabase, you don’t even have to use SQL\n\nSQL is amazing. But so is Metabase’s Query Builder. You can compose queries using Metabase’s graphical interface to join tables, filter and summarize data, create custom columns, and more. And with custom expressions, you can handle the vast majority of analytical use cases, without ever needing to reach for SQL. Questions composed using the Query Builderr also benefit from automatic drill-through, which allows viewers of your charts to click through and explore the data, a feature not available to questions written in SQL.\n\nThere are libraries of books on SQL, so we’re only scratching the surface here. You can share the secrets of your SQL sorcery with other Metabase users on our forum."
    }
]