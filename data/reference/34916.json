[
    {
        "link": "https://scapy.readthedocs.io/en/latest/usage.html",
        "document": "Scapy’s interactive shell is run in a terminal session. Root privileges are needed to send the packets, so we’re using here: On Windows, please open a command prompt ( ) and make sure that you have administrator privileges: If you do not have all optional packages installed, Scapy will inform you that some features will not be available: The basic features of sending and receiving packets should still work, though.\n\nThis section will show you several of Scapy’s features with Python 2. Just open a Scapy session as shown above and try the examples yourself. You can configure the Scapy terminal by modifying the file. Let’s build a packet and play with it: The operator has been used as a composition operator between two layers. When doing so, the lower layer can have one or more of its defaults fields overloaded according to the upper layer. (You still can give the value you want). A string can be used as a raw layer. Each packet can be built or dissected (note: in Python (underscore) is the latest result): We see that a dissected packet has all its fields filled. That’s because I consider that each field has its value imposed by the original string. If this is too verbose, the method hide_defaults() will delete every field that has the same value as the default: You can read packets from a pcap file and write them to a pcap file. If you have PyX installed, you can make a graphical PostScript/PDF dump of a packet or a list of packets (see the ugly PNG image below. PostScript/PDF are far better quality…): have the list of fields values for a developed view of the packet same as show but on the assembled packet (checksum is calculated, for instance) fills a format string with fields values of the packet changes the way the payload is decoded return a Scapy command that can generate the packet For the moment, we have only generated one packet. Let see how to specify sets of packets as easily. Each field of the whole packet (ever layers) can be a set. This implicitly defines a set of packets, generated using a kind of cartesian product between all the fields. Some operations (like building the string from a packet) can’t work on a set of packets. In these cases, if you forgot to unroll your set of packets, only the first element of the list you forgot to generate will be used to assemble the packet. On the other hand, it is possible to move sets of packets into a object, which provides some operations on lists of packets. displays a list of summaries of each packet same as previous, with the packet number returns a hexdump of the Raw layer of all packets Now that we know how to manipulate packets. Let’s see how to send them. The send() function will send packets at layer 3. That is to say, it will handle routing and layer 2 for you. The sendp() function will work at layer 2. It’s up to you to choose the right interface and the right link layer protocol. send() and sendp() will also return sent packet list if return_packets=True is passed as parameter. This feature is only available since Scapy 2.6.0. If you try to use multicast addresses (IPv4) or link-local addresses (IPv6), you’ll notice that Scapy follows the routing table and takes the first entry. In order to specify which interface to use when looking through the routing table, Scapy supports scope identifiers (similar to RFC6874 but for both IPv6 and IPv4). # answer IP will be != from the one we requested You can use both format or (the interface id) format. You can query those using . Behind the scene, calling creates a object that contains on the scope of the interface . If you are using an interface object (for instance ), you can also craft that object. For instance:: The function fuzz() is able to change any default value that is not to be calculated (like checksums) by an object whose value is random and whose type is adapted to the field. This enables quickly building fuzzing templates and sending them in a loop. In the following example, the IP layer is normal, and the UDP and NTP layers are fuzzed. The UDP checksum will be correct, the UDP destination port will be overloaded by NTP to be 123 and the NTP version will be forced to be 4. All the other ports will be randomized. Note: If you use fuzz() in IP layer, src and dst parameter won’t be random so in order to do that use RandIP().: In a packet, each field has a specific type. For instance, the length field of the IP packet expects an integer. More on that later. If you’re developing a PoC, there are times where you’ll want to inject some value that doesn’t fit that type. This is possible using Now, let’s try to do some fun things. The sr() function is for sending packets and receiving answers. The function returns a couple of packet and answers, and the unanswered packets. The function sr1() is a variant that only returns one packet that answered the packet (or the packet set) sent. The packets must be layer 3 packets (IP, ARP, etc.). The function srp() do the same for layer 2 packets (Ethernet, 802.3, etc.). If there is no response, a None value will be assigned instead when the timeout is reached. A DNS query ( = recursion desired). The host 192.168.5.1 is my DNS server. Note the non-null padding coming from my Linksys having the Etherleak flaw: The “send’n’receive” functions family is the heart of Scapy. They return a couple of two lists. The first element is a list of couples (packet sent, answer), and the second element is the list of unanswered packets. These two elements are lists, but they are wrapped by an object to present them better, and to provide them with some methods that do most frequently needed actions: If there is a limited rate of answers, you can specify a time interval (in seconds) to wait between two packets with the inter parameter. If some packets are lost or if specifying an interval is not enough, you can resend all the unanswered packets, either by calling the function again, directly with the unanswered list, or by specifying a retry parameter. If retry is 3, Scapy will try to resend unanswered packets 3 times. If retry is -3, Scapy will resend unanswered packets until no more answer is given for the same set of unanswered packets 3 times in a row. The timeout parameter specify the time to wait after the last packet has been sent: Classic SYN Scan can be initialized by executing the following command from Scapy’s prompt: The above will send a single SYN packet to Google’s port 80 and will quit after receiving a single response: From the above output, we can see Google returned “SA” or SYN-ACK flags indicating an open port. Use either notations to scan ports 440 through 443 on the system: In order to quickly review responses simply request a summary of collected packets: The above will display stimulus/response pairs for answered probes. We can display only the information we are interested in by using a simple loop: Even better, a table can be built using the function to display information about multiple targets: The above example will even print the ICMP error type if the ICMP packet was received as a response instead of expected TCP. For larger scans, we could be interested in displaying only certain responses. The example below will only display packets with the “SA” flag set: In case we want to do some expert analysis of responses, we can use the following command to indicate which ports are open: Again, for larger scans we can build a table of open ports: If all of the above methods were not enough, Scapy includes a report_ports() function which not only automates the SYN scan, but also produces a LaTeX output with collected results: Note that the TCP traceroute and some other high-level functions are already coded: sr1 : Send packets at layer 3 and return only the first answer srp1 : Send and receive packets at layer 2 and return only the first answer srloop : Send a packet at layer 3 in loop and print the answer each time srploop : Send a packet at layer 2 in loop and print the answer each time arping : Send ARP who-has requests to determine which hosts are up ls : List available layers, or infos on a given layer dyndns_add : Send a DNS add message to a nameserver for \"name\" to have a new \"rdata\" dyndns_del : Send a DNS delete message to a nameserver for \"name\" Scapy may also use the GeoIP2 module, in combination with matplotlib and cartopy to generate fancy graphics such as below: In this example, we used the function to print the graphic. This method is a shortcut which uses the of the objects. It could have been done differently: To use those functions, it is required to have installed the geoip2 module, its database (direct download) but also the cartopy module. Different super sockets are available in Scapy: the native ones, and the ones that use libpcap (to send/receive packets). By default, Scapy will try to use the native ones (except on Windows, where the winpcap/npcap ones are preferred). To manually use the libpcap ones, you must:\n• None On Unix/OSX: be sure to have libpcap installed. This will automatically update the sockets pointing to and . If you want to manually set them, you have a bunch of sockets available, depending on your platform. For instance, you might want to use: We can easily capture some packets or even clone tcpdump or tshark. Either one interface or a list of interfaces to sniff on can be provided. If no interface is given, sniffing will happen on : 802.11 / LLC / SNAP / ARP who has 172.20.70.172 says 172.20.70.171 / Padding 802.11 / LLC / SNAP / ARP is at 00:0a:b7:4b:9c:dd says 172.20.70.172 / Padding For even more control over displayed information we can use the function: We can sniff and do passive OS fingerprinting: The number before the OS guess is the accuracy of the guess. When sniffing on several interfaces (e.g. ), you can check what interface a packet was sniffed on by using the attribute, as shown in one of the examples above. Asynchronous sniffing is only available since Scapy 2.4.3 Asynchronous sniffing does not necessarily improves performance (it’s rather the opposite). If you want to sniff on multiple interfaces / socket, remember you can pass them all to a single call It is possible to sniff asynchronously. This allows to stop the sniffer programmatically, rather than with ctrl^C. It provides , and utils. The basic usage would be: The class has a few useful keys, such as (the packets collected) or , that can be used. It accepts the same arguments than (in fact, their implementations are merged). For instance: # this will hold until 200 packets are collected Another example: using and Sessions are only available since Scapy 2.4.3 also provides Sessions, that allows to dissect a flow of packets seamlessly. For instance, you may want your function to automatically defragment IP packets, before executing the . Scapy includes some basic Sessions, but it is possible to implement your own. Available by default:\n• None\n• None and maybe other protocols if this page isn’t up to date. Those sessions can be used using the parameter of . Examples: To implement your own Session class, in order to support another flow-based protocol, start by copying a sample from scapy/sessions.py Your custom class only needs to extend the class, and implement a or a function, such as in the examples. The inner workings of is currently UNSTABLE: custom Sessions may break in the future. How to use TCPSession to defragment TCP packets The layer on which the decompression is applied must be immediately following the TCP layer. You need to implement a class function called that accepts the binary data, a metadata dictionary as argument and returns, when full, a packet. Let’s study the (pseudo) example of TLS: In this example, we first get the total length of the TLS payload announced by the TLS header, and we compare it to the length of the data. When the data reaches this length, the packet is complete and can be returned. When implementing , it’s usually a matter of detecting when a packet isn’t missing anything else. The argument is bytes and the argument is a dictionary which keys are as follow:\n• None : will be present if the PUSH flag is set\n• None : will be present if the END or RESET flag is set Demo of both bpf filter and sprintf() method: Here is an example of a (h)ping-like functionality : you always send the same set of packets to see if something change: It is often useful to save capture packets to pcap file for use at later time or with different applications: Scapy allows you to export recorded packets in various hex formats. Use to display one or more packets using classic hexdump format: Hexdump above can be reimported back into Scapy using : You can also convert entire packet into a binary string using the function: We can reimport the produced binary string by selecting the appropriate first layer (e.g. ). Using the function, Scapy can export a base64 encoded Python data structure representing a packet: The output above can be reimported back into Scapy using : At last Scapy is capable of saving all session variables using the function: Next time you start Scapy you can load the previous saved session using the command: Now we have a demonstration of the presentation function. It takes a list as parameter, and a function who returns a 3-uple. The first element is the value on the x axis from an element of the list, the second is about the y value and the third is the value that we want to see at coordinates (x,y). The result is a table. This function has 2 variants, and to copy/paste into your LaTeX pentest report. Those functions are available as methods of a result object : Here we can see a multi-parallel traceroute (Scapy already has a multi TCP traceroute function. See later): Here is a more complex example to distinguish machines or their IP stacks from their IPID field. We can see that 172.20.80.200:22 is answered by the same IP stack as 172.20.80.201 and that 172.20.80.197:25 is not answered by the same IP stack as other ports on the same IP. It can help identify network topologies very easily when playing with TTL, displaying received TTL, etc. Now Scapy has its own routing table, so that you can have your packets routed differently than the system: We can easily plot some harvested values using Matplotlib. (Make sure that you have matplotlib installed.) For example, we can observe the IP ID patterns to know how many distinct IP stacks are used behind a load balancer: Scapy also has a powerful TCP traceroute function. Unlike other traceroute programs that wait for each node to reply before going to the next, Scapy sends all the packets at the same time. This has the disadvantage that it can’t know when to stop (thus the maxttl parameter) but the great advantage that it took less than 3 seconds to get this multi-target traceroute result: The last line is in fact the result of the function : a traceroute result object and a packet list of unanswered packets. The traceroute result is a more specialised version (a subclass, in fact) of a classic result object. We can save it to consult the traceroute result again a bit later, or to deeply inspect one of the answers, for example to check padding. Like any result object, traceroute objects can be added : Traceroute result object also have a very neat feature: they can make a directed graph from all the routes they got, and cluster them by AS (Autonomous System). You will need graphviz. By default, ImageMagick is used to display the graph. If you have VPython installed, you also can have a 3D representation of the traceroute. With the right button, you can rotate the scene, with the middle button, you can zoom, with the left button, you can move the scene. If you click on a ball, it’s IP will appear/disappear. If you Ctrl-click on a ball, ports 21, 22, 23, 25, 80 and 443 will be scanned and the result displayed: See the TroubleShooting section for more information on the usage of Monitor mode among Scapy. Provided that your wireless card and driver are correctly configured for frame injection, you can have a kind of FakeAP: Depending on the driver, the commands needed to get a working frame injection interface may vary. You may also have to replace the first pseudo-layer (in the example ) by , or by a proprietary pseudo-layer, or even to remove it.\n\nUsing Scapy’s powerful packet crafting facilities we can quick replicate classic TCP Scans. For example, the following string will be sent to simulate an ACK Scan: We can find unfiltered ports in answered packets: Similarly, filtered ports can be found with unanswered packets: Xmas Scan can be launched using the following command: Checking RST responses will reveal closed ports on the target. A lower level IP Scan can be used to enumerate supported protocols: The fastest way to discover hosts on a local ethernet network is to use the ARP Ping method: Answers can be reviewed with the following command: Scapy also includes a built-in arping() function which performs similar to the above two commands: Classical ICMP Ping can be emulated using the following command: Information on live hosts can be collected with the following request: In cases where ICMP echo requests are blocked, we can still use various TCP Pings such as TCP SYN Ping below: Any response to our probes will indicate a live host. We can collect results with the following command: If all else fails there is always UDP Ping which will produce ICMP Port unreachable errors from live hosts. Here you can pick any port which is most likely to be closed, such as port 0: Once again, results can be collected with this command: This will perform a DNS request looking for IPv4 addresses This attack prevents a client from joining the gateway by poisoning its ARP cache through a VLAN hopping attack. This poisons the cache of 2 machines, then answers all following ARP requests to put the host between. Calling ctrl^C will restore the connection. Send a TCP SYN on each port. Wait for a SYN-ACK or a RST or an ICMP error: We try to identify VPN concentrators by sending ISAKMP Security Association proposals and receiving the answers: By default, uses a joker (IPv4 only): it answers to all unknown servers with the joker. See : You can also use to replace the joker behavior with a forward to a server included in . # Mandatory because we are using a broadcast destination and receiving unicast As you can see, we used a scope identifier ( ) to specify on which interface we want to use the above multicast IP. Tracerouting an UDP application like we do with TCP is not reliable, because there’s no handshake. We need to give an applicative payload (DNS, ISAKMP, NTP, etc.) to deserve an answer: We can visualize the results as a list of routers: We can perform a DNS traceroute by specifying a complete packet in parameter of function: In very specific conditions, a double 802.1q encapsulation will make a packet jump to another VLAN: The following command will display information similar to most wireless sniffers: On Windows and OSX, you will need to also use , which only works on scapy>2.4.0 (2.4.0dev+). This might require you to manually toggle monitor mode. The above command will produce output similar to the one below:\n\nThis program uses the callback (parameter prn). The store parameter is set to 0 so that the function will not store anything (as it would do otherwise) and thus can run forever. The filter parameter is used for better performances on high load : the filter is applied inside the kernel and Scapy will only see ARP traffic. You suspect that someone has installed an additional, unauthorized DHCP server on your LAN – either unintentionally or maliciously. Thus you want to check for any active DHCP servers and identify their IP and MAC addresses. Use Scapy to send a DHCP discover request and analyze the replies: In this case we got 2 replies, so there were two active DHCP servers on the test network: We are only interested in the MAC and IP addresses of the replies: We specify to make Scapy wait for more answer packets after the first response is received. This is also the reason why we can’t use the more convenient function and have to construct the DHCP packet manually: uses for sending and receiving and thus would immediately return after the first answer packet. Moreover, Scapy normally makes sure that replies come from the same IP address the stimulus was sent to. But our DHCP packet is sent to the IP broadcast address (255.255.255.255) and any answer packet will have the IP address of the replying DHCP server as its source IP address (e.g. 192.168.1.1). Because these IP addresses don’t match, we have to disable Scapy’s check with before sending the stimulus. TTL decrementation after a filtering operation only not filtered packets generate an ICMP TTL exceeded Find subnets on a multi-NIC firewall only his own NIC’s IP are reachable with this TTL: You have generated or sniffed some packets with Scapy. Now you want to view them with Wireshark, because of its advanced packet dissection capabilities. That’s what is for! Wireshark will start in the background, and show your packets. With a or , serialises your packets, and streams this into Wireshark via as if it were a capture device. Because this uses format to serialise the packets, there are some limitations:\n• None Packets must be all of the same . For example, you can’t mix and at the top layer.\n• None Packets must have an assigned (and supported) constant for the . An unsupported is replaced with (Ethernet), and will display incorrectly in Wireshark. For example, can’t pass a bare packet, but you can send it as a payload of an or packet. With a filename (passed as a string), this loads the given file in Wireshark. This needs to be in a format that Wireshark supports. You can tell Scapy where to find the Wireshark executable by changing the configuration setting. This accepts the same extra parameters as . Additional description of Wireshark’s functionality, and its command-line arguments. Contains detailed information about Wireshark’s protocol dissectors, and reference documentation for various network protocols. Please bear in mind that Scapy is not designed to be blazing fast, but rather easily hackable & extensible. The packet model makes it VERY easy to create new layers, compared to pretty much all other alternatives, but comes with a performance cost. Of course, we still do our best to make Scapy as fast as possible, but it’s not the absolute main goal. There are quite a few ways of speeding up scapy’s dissection. You can use all of them\n• None Using a BPF filter: The OS is faster than Scapy. If you make the OS filter the packets instead of Scapy, it will only handle a fraction of the load. Use the argument of the function.\n• None By disabling layers you don’t use: If you are not using some layers, why dissect them? You can let Scapy know which layers to dissect and all the others will simply be parsed as . This comes with a great performance boost but requires you to know what you’re doing. # Enable filtering: only Ether, IP and ICMP will be dissected Very slow start because of big routes Scapy takes ages to start because you have very big routing tables. Disable the auto-loading of the routing tables: # Before any other Scapy import At anytime, you can trigger the routes loading using or , or add the routes yourself as shown here. Scapy can be used to analyze ISN (Initial Sequence Number) increments to possibly discover vulnerable systems. First we will collect target responses by sending a number of SYN probes in a loop: Once we obtain a reasonable number of responses we can start analyzing collected data with something like this: Nmap fingerprinting (the old “1st generation” one that was done by Nmap up to v4.20) is supported in Scapy. In Scapy v2 you have to load an extension module first: If you have Nmap installed you can use it’s active os fingerprinting database with Scapy. Make sure that version 1 of signature database is located in the path specified by: Then you can use the function which implements same probes as in Nmap’s OS Detection engine: If you have p0f installed on your system, you can use it to guess OS name and version right from Scapy (only SYN database is used). First make sure that p0f database exists in the path specified by: For example to guess OS from a single captured packet:"
    },
    {
        "link": "https://scapy.readthedocs.io/en/latest/introduction.html",
        "document": "On top of this can be built more high level functions. For example, one that does traceroutes and give as a result only the start TTL of the request and the source IP of the answer. One that pings a whole network and gives the list of machines answering. One that does a portscan and returns a LaTeX report.\n\nThe idea is simple. Scapy mainly does two things: sending packets and receiving answers. You define a set of packets, it sends them, receives answers, matches requests with answers and returns a list of packet couples (request, answer) and a list of unmatched packets. This has the big advantage over tools like Nmap or hping that an answer is not reduced to open, closed, or filtered, but is the whole packet.\n\nScapy also performs very well on a lot of other specific tasks that most other tools can’t handle, like sending invalid frames, injecting your own 802.11 frames, combining techniques (VLAN hopping+ARP cache poisoning, VOIP decoding on WEP encrypted channel, …), etc.\n\nIn other words, Scapy is a powerful interactive packet manipulation program. It is able to forge or decode packets of a wide number of protocols, send them on the wire, capture them, match requests and replies, and much more. Scapy can easily handle most classical tasks like scanning, tracerouting, probing, unit tests, attacks or network discovery. It can replace hping, arpspoof, arp-sk, arping, p0f and even some parts of Nmap, tcpdump, and tshark.\n\nFirst, with most other networking tools, you won’t build something the author didn’t imagine. These tools have been built for a specific goal and can’t deviate much from it. For example, an ARP cache poisoning program won’t let you use double 802.1q encapsulation. Or try to find a program that can send, say, an ICMP packet with padding (I said padding, not payload, see?). In fact, each time you have a new need, you have to build a new tool.\n\nSecond, they usually confuse decoding and interpreting. Machines are good at decoding and can help human beings with that. Interpretation is reserved for human beings. Some programs try to mimic this behavior. For instance they say “this port is open” instead of “I received a SYN-ACK”. Sometimes they are right. Sometimes not. It’s easier for beginners, but when you know what you’re doing, you keep on trying to deduce what really happened from the program’s interpretation to make your own, which is hard because you lost a big amount of information. And you often end up using to decode and interpret what the tool missed.\n\nThird, even programs which only decode do not give you all the information they received. The vision of the network they give you is the one their author thought was sufficient. But it is not complete, and you have a bias. For instance, do you know a tool that reports the Ethernet padding?\n\nScapy tries to overcome those problems. It enables you to build exactly the packets you want. Even if I think stacking an 802.1q layer on top of TCP has no sense, it may have some for somebody else working on some product I don’t know. Scapy has a flexible model that tries to avoid such arbitrary limits. You’re free to put any value you want in any field you want and stack them like you want. You’re an adult after all.\n\nIn fact, it’s like building a new tool each time, but instead of dealing with a hundred line C program, you only write 2 lines of Scapy.\n\nAfter a probe (scan, traceroute, etc.) Scapy always gives you the full decoded packets from the probe, before any interpretation. That means that you can probe once and interpret many times. Ask for a traceroute and look at the padding, for instance.\n\nOther tools stick to the program-that-you-run-from-a-shell paradigm. The result is an awful syntax to describe a packet. For these tools, the solution adopted uses a higher but less powerful description, in the form of scenarios imagined by the tool’s author. As an example, only the IP address must be given to a port scanner to trigger the port scanning scenario. Even if the scenario is tweaked a bit, you still are stuck to a port scan. Scapy’s paradigm is to propose a Domain Specific Language (DSL) that enables a powerful and fast description of any kind of packet. Using the Python syntax and a Python interpreter as the DSL syntax and interpreter has many advantages: there is no need to write a separate interpreter, users don’t need to learn yet another language, and they benefit from a complete, concise, and very powerful language. Scapy enables the user to describe a packet or set of packets as layers that are stacked one upon another. Fields of each layer have useful default values that can be overloaded. Scapy does not oblige the user to use predetermined methods or templates. This alleviates the requirement of writing a new tool each time a different scenario is required. In C, it may take an average of 60 lines to describe a packet. With Scapy, the packets to be sent may be described in only a single line, with another line to print the result. 90% of network probing tools can be rewritten in 2 lines of Scapy.\n\nNetwork discovery is blackbox testing. When probing a network, many stimuli are sent, while only a few of them are answered. If the right stimuli are chosen, the desired information may be obtained by the responses or the lack of responses. Unlike many tools, Scapy gives all the information, i.e. all the stimuli sent and all the responses received. Examination of this data will give the user the desired information. When the dataset is small, the user can just dig for it. In other cases, the interpretation of the data will depend on the point of view taken. Most tools choose the viewpoint and discard all the data not related to that point of view. Because Scapy gives the complete raw data, that data may be used many times allowing the viewpoint to evolve during analysis. For example, a TCP port scan may be probed and the data visualized as the result of the port scan. The data could then also be visualized with respect to the TTL of the response packet. A new probe need not be initiated to adjust the viewpoint of the data.\n\nScapy decodes, it does not interpret A common problem with network probing tools is they try to interpret the answers received instead of only decoding and giving facts. Reporting something like Received a TCP Reset on port 80 is not subject to interpretation errors. Reporting Port 80 is closed is an interpretation that may be right most of the time but wrong in some specific contexts the tool’s author did not imagine. For instance, some scanners tend to report a filtered TCP port when they receive an ICMP destination unreachable packet. This may be right, but in some cases, it means the packet was not filtered by the firewall, but rather there was no host to forward the packet to. Interpreting results can help users that don’t know what a port scan is, but it can also make more harm than good, as it injects bias into the results. What can tend to happen is that knowledgeable users will try to reverse engineer the tool’s interpretation to derive the facts that triggered that interpretation, so that they can do the interpretation themselves. Unfortunately, much information is lost in this operation."
    },
    {
        "link": "https://media.readthedocs.org/pdf/scapy/latest/scapy.pdf",
        "document": ""
    },
    {
        "link": "https://scapy.net",
        "document": ""
    },
    {
        "link": "https://media.readthedocs.org/pdf/scapy/stable/scapy.pdf",
        "document": ""
    },
    {
        "link": "https://networkx.org/documentation/stable/tutorial.html",
        "document": "This guide can help you start working with NetworkX.\n\nThe graph can be grown in several ways. NetworkX includes many graph generator functions and facilities to read and write graphs in many formats. To get started though we’ll look at simple manipulations. You can add one node at a time, or add nodes from any iterable container, such as a list You can also add nodes along with node attributes if your container yields 2-tuples of the form : Node attributes are discussed further below. Nodes from one graph can be incorporated into another: now contains the nodes of as nodes of . In contrast, you could use the graph as a node in . The graph now contains as a node. This flexibility is very powerful as it allows graphs of graphs, graphs of files, graphs of functions and much more. It is worth thinking about how to structure your application so that the nodes are useful entities. Of course you can always use a unique identifier in and have a separate dictionary keyed by identifier to the node information if you prefer. You should not change the node object if the hash depends on its contents.\n\ncan also be grown by adding one edge at a time, or by adding any ebunch of edges. An ebunch is any iterable container of edge-tuples. An edge-tuple can be a 2-tuple of nodes or a 3-tuple with 2 nodes followed by an edge attribute dictionary, e.g., . Edge attributes are discussed further below. There are no complaints when adding existing nodes or edges. For example, after removing all nodes and edges, we add new nodes/edges and NetworkX quietly ignores any that are already present. At this stage the graph consists of 8 nodes and 3 edges, as can be seen by: The order of adjacency reporting (e.g., , , ) is the order of edge addition. However, the order of G.edges is the order of the adjacencies which includes both the order of the nodes and each node’s adjacencies. See example below:\n\nWe can examine the nodes and edges. Four basic graph properties facilitate reporting: , , and . These are set-like views of the nodes, edges, neighbors (adjacencies), and degrees of nodes in a graph. They offer a continually updated read-only view into the graph structure. They are also dict-like in that you can look up node and edge data attributes via the views and iterate with data attributes using methods , . If you want a specific container type instead of a view, you can specify one. Here we use lists, though sets, dicts, tuples and other containers may be better in other contexts. # the number of edges incident to 1 One can specify to report the edges and degree from a subset of all nodes using an nbunch. An nbunch is any of: (meaning all nodes), a node, or an iterable container of nodes that is not itself a node in the graph.\n\nWhat to use as nodes and edges# You might notice that nodes and edges are not specified as NetworkX objects. This leaves you free to use meaningful items as nodes and edges. The most common choices are numbers or strings, but a node can be any hashable object (except ), and an edge can be associated with any object using . As an example, and could be protein objects from the RCSB Protein Data Bank, and could refer to an XML record of publications detailing experimental observations of their interaction. We have found this power quite useful, but its abuse can lead to surprising behavior unless one is familiar with Python. If in doubt, consider using to obtain a more traditional graph with integer labels.\n\nThe class provides additional methods and properties specific to directed edges, e.g., , , , etc. To allow algorithms to work with both classes easily, the directed versions of is equivalent to while reports the sum of and even though that may feel inconsistent at times. Some algorithms work only for directed graphs and others are not well defined for directed graphs. Indeed the tendency to lump directed and undirected graphs together is dangerous. If you want to treat a directed graph as undirected for some measurement you should probably convert it using or with\n\nNetworkX can be configured to use separate thrid-party backends to improve performance and add functionality. Backends are optional, installed separately, and can be enabled either directly in the user’s code or through environment variables. Several backends are available to accelerate NetworkX–often significantly–using GPUs, parallel processing, and other optimizations, while other backends add additional features such as graph database integration. Multiple backends can be used together to compose a NetworkX runtime environment optimized for a particular system or use case. Refer to the Backends section to see a list of available backends known to work with the current stable release of NetworkX. NetworkX uses backends by dispatching function calls at runtime to corresponding functions provided by backends, either automatically via configuration variables, or explicitly by hard-coded arguments to functions. Automatic dispatch is possibly the easiest and least intrusive means by which a user can use backends with NetworkX code. This technique is useful for users that want to write portable code that runs on systems without specific backends, or simply want to use backends for existing code without modifications. The example below configures NetworkX to automatically dispatch to a backend named for all NetworkX functions that supports.\n• None If does not support a NetworkX function used by the application, the default NetworkX implementation for that function will be used.\n• None If is not installed on the system running this code, an exception will be raised. # runs using backend from NETWORKX_BACKEND_PRIORITY, if set The equivalent configuration can be applied to NetworkX directly to the code through the NetworkX global parameters, which may be useful if environment variables are not suitable. This will override the corresponding environment variable allowing backends to be enabled programatically in Python code. However, the tradeoff is slightly less portability as updating the backend specification may require a small code change instead of simply updating an environment variable. Automatic dispatch using the environment variable or the global config also allows for the specification of multiple backends, ordered based on the priority which NetworkX should attempt to dispatch to. The following examples both configure NetworkX to dispatch functions first to if it supports the function, then if does not, then finally the default NetworkX implementation if no backend specified can handle the call. NetworkX includes debug logging calls using Python’s standard logging mechanism. These can be enabled to help users understand when and how backends are being used. To enable debug logging only in NetworkX modules: or to enable it globally: Backends can also be used explicitly on a per-function call basis by specifying a backend using the keyword argument. This technique not only requires that the backend is installed, but also requires that the backend implement the function, since NetworkX will not fall back to the default NetworkX implementation if a backend is specified with . This is possibly the least portable option, but has the advantage that NetworkX will raise an exception if cannot be used, which is useful for users that require a specific implementation. Explicit dispatch can also provide a more interactive experience and is especially useful for demonstrations, experimentation, and debugging. The NetworkX dispatcher allows users to use backends for NetworkX code in very specific ways not covered in this tutorial. Refer to the Backends reference section for details on topics such as:\n• None Control of how specific function types (algorithms vs. generators) are dispatched to specific backends\n• None Details on automatic conversions to/from backend and NetworkX graphs for dispatch and fallback"
    },
    {
        "link": "https://networkx.org/documentation/stable/reference/drawing.html",
        "document": "NetworkX provides basic functionality for visualizing graphs, but its main goal is to enable graph analysis rather than perform graph visualization. In the future, graph visualization functionality may be removed from NetworkX or only available as an add-on package.\n\nProper graph visualization is hard, and we highly recommend that people visualize their graphs with tools dedicated to that task. Notable examples of dedicated and fully-featured graph visualization tools are Cytoscape, Gephi, Graphviz and, for LaTeX typesetting, PGF/TikZ. To use these and other such tools, you should export your NetworkX graph into a format that can be read by those tools. For example, Cytoscape can read the GraphML format, and so, might be an appropriate choice.\n\nFor the possible resulting shape is a square of side [0, scale] (default: [0, 1]) Changing shifts the layout by that amount. For the other layout routines, the extent is [center - scale, center + scale] (default: [-1, 1]). Warning: Most layout routines have only been tested in 2-dimensions. Position nodes uniformly at random in the unit square. Returns scaled position array to (-scale, scale) in all axes. Position nodes using the eigenvectors of the graph Laplacian.\n\nExport NetworkX graphs in LaTeX format using the TikZ library within TeX/LaTeX. Usually, you will want the drawing to appear in a figure environment so you use . If you want the raw drawing commands without a figure environment use . And if you want to write to a file instead of just returning the latex code as a string, use . To construct a figure with subfigures for each graph to be shown, provide or a list of graphs, a list of subcaptions, and a number of rows of subfigures inside the figure. To be able to refer to the figures or subfigures in latex using , the keyword is available for figures and for a list of labels, one for each subfigure. We intend to eventually provide an interface to the TikZ Graph features which include e.g. layout algorithms. Let us know via github what you’d like to see available, or better yet give us some code to do it, or even better make a github pull request to add the feature. Drawing options can be stored on the graph as node/edge attributes, or can be provided as dicts keyed by node/edge to a string of the options for that node/edge. Similarly a label can be shown for each node/edge by specifying the labels as graph node/edge attributes or by providing a dict keyed by node/edge to the text to be written for that node/edge. Options for the tikzpicture environment (e.g. “[scale=2]”) can be provided via a keyword argument. Similarly default node and edge options can be provided through keywords arguments. The default node options are applied to the single TikZ “path” that draws all nodes (and no edges). The default edge options are applied to a TikZ “scope” which contains a path for each edge. You can change many features of the nodes and edges. Then compile the LaTeX using something like and view the pdf file created: . If you want subfigures each containing one graph, you can input a list of graphs. If you want to change the preamble/postamble of the figure/document/subfigure environment, use the keyword arguments: , , . The default values are stored in private variables e.g. Return a string of the LaTeX/TikZ code to draw Return latex code to draw the graph(s) in Write the latex code to draw the graph(s) onto ."
    },
    {
        "link": "https://medium.com/towards-data-science/navigating-networks-with-networkx-a-short-guide-to-graphs-in-python-c16cbafe8063",
        "document": "Navigating Networks with NetworkX: A Short Guide to Graphs in Python\n\nIn a world brimming with connections — from social media friendships to complex transportation networks — understanding relationships and patterns is key to making sense of the systems around us. Imagine visualizing a social network where each person is a dot (a “node”) connected to friends by lines (or “edges”). Or picture mapping a city’s metro system where each station is a node and each route is an edge connecting them.\n\nThis is where NetworkX shines, offering a powerful way to build, analyze, and visualize these intricate webs of relationships.\n\nNetworkX allows us to represent data in ways that would be cumbersome or even impractical with traditional tables but become easy and natural in a graph format. Relationships that would take many rows and columns to define in a spreadsheet can be captured in an intuitive, visual way, helping us to understand and interpret complex data.\n\nThe library lets us apply a wide range of methods and algorithms to these graphs, providing fresh insights each time as we reframe our data with a new approach.\n\nLet’s start out by breaking down what a graph is. In network analysis, a graph is made up of nodes (or vertices) and edges (or links).\n• Think of nodes as the main entities, like people or web pages, and edges as the connections between them — like friendships in a social network or hyperlinks between websites.\n• Some edges even carry weights, representing the strength, distance, or cost of the connection between two nodes. This added layer of information helps us analyze not just if two nodes are connected, but how strongly or closely.\n\nThese graphs can be used to model a wide variety of systems, from social networks, to molecules and transportation grids.\n\nLet’s start by seeing how to create a graph using . If you don’t have it installed first run:\n\nTo make a network we will:\n• Initialize the network: by creating a graph with\n• Add Nodes with Attributes: Use G.add_node() to add nodes, each of which can store custom attributes like labels or ages.\n• Add Edges: Connect nodes with G , where each edge can include a weight attribute to represent the strength or cost of the connection.\n• Visualize the Graph: Use Matplotlib functions like and to display the graph, showing node labels and edge weights for easy interpretation.\n\nThis is the code to achieve this:\n\nIn this example we initialise the graph and then create:\n• 3 weighted edges that connect these nodes: (1, 2), (1, 3), and (2, 4) by calling\n\nBoth nodes and edges in NetworkX can hold additional attributes, making the graph richer with information.\n• Node attributes (accessed via allow each node to store data, like a person’s occupation in a social network.\n• Edge attributes (accessed via store information for each connection, such as the distance or travel time in a transportation network. These attributes add context and depth, enabling more detailed analysis of the network.\n\nWe then use NetworkX’s spring layout to position the nodes for visualization, ensuring they’re spaced naturally within the plot. Finally, and display the graph with node labels and edge weights, creating a clear view of the network’s structure and connections.\n\nWhile this was a rather simple network, it illustrates the basics of working with networks: to manipulate graphs we need to handle the nodes and their connections along any attributes they might have.\n\nOne of the most well-known examples in network science is the Zachary’s Karate Club, often used to illustrate social network analysis and community detection. The dataset is public domain and is included in networkx by default. You can access as shown below:\n\nThis network represents the friendships among 34 members of a karate club, and it is famous for the split that occurred between two factions, each centered around a central figure — Mr. Hi and Officer.\n\nLet’s take a look at the attributes contained within the node data:\n\nThe node attribute refers to the community or that each node belongs to. Let’s use them to create color the nodes in the graph.\n\nTo do this we assign the blue color to the nodes with label and red those with label in a list , which we can use to visualize the network using .\n\nThe legend tells that a conflict arose between the club’s instructor, “Mr. Hi,” and the club’s administrator, “Officer.” This division eventually caused the club to split into two distinct groups, each centered around one of these leaders.\n\nBy representing these relationships as a network, we can visually capture this split and reveal patterns and clusters within the data — insights that may be hard to see having the data in traditional table formats.\n\nTo understand the structure and dynamics of a network, it’s essential to identify the most influential or strategically positioned nodes. This is where centrality measures come in, a key concept in network science.\n\nIt measures the position of nodes based on their types connections, identifying key nodes based on certain criteria. Common measures include:\n• degree centrality (merely the number of connections each node possess)\n• closeness centrality (how quickly a node can access all other nodes in the network).\n• and betweenness centrality (how often a node appears on the shortest paths between other nodes)\n\nThese measures help reveal key players or bottlenecks in the network, giving insight into its structure/dynamic.\n\nFor nodes and we see, that these nodes are the most central in the network, with high degree, betweenness, and closeness centralities.\n\nTheir central roles suggest they are well-connected hubs, frequently acting as bridges between other members and able to quickly reach others in the network. This positioning highlights them as key players, holding significance in the network’s flow and structure.\n\nA community C is a set of nodes (e.g., individuals in a social network, web pages connected by hyperlinks etc.) that exhibit stronger connections among themselves than with the rest of the network.\n\nWith a visual representation of centrality in mind, let’s apply the Girvan-Newman Algorithm to this graph.\n• The algorithm generates a series of community splits as it progressively removes edges with the highest betweenness centrality.\n• The first time the algorithm is run, it identifies the most significant community division.\n• Since returns an iterator as , calling allows you to retrieve the first split, i.e., the first division of the network into two communities.\n\nLet’s compare the detected communities with the actual node label\n\nThe communities detected by the Girvan-Newman algorithm are similar to the actual Mr. Hi and Officer communities but not an exact match. This is because the Girvan-Newman algorithm divides the network based solely on edge betweenness centrality, without relying on any predefined community labels.\n\nThis approach is especially useful in unstructured datasets where labels are absent, as it reveals meaningful groupings based on the network’s structural properties. This highlights a key consideration in community detection: there is no strict definition of what constitutes a community.\n\nAs a result, there is no single “correct” way to partition a network. Different methods, driven by varying metrics, can yield diverse results, each providing valuable insights depending on the context.\n\nA useful concept in networks is the clique. In network science, a clique refers to a subset of nodes in a graph where every node is connected to every other node in that subset. This means that all members of a clique have direct relationships with each other, forming a tightly-knit group. Cliques can be particularly useful when studying the structure of complex networks because they often represent highly connected or cohesive groups within a larger system.\n\nFor example in:\n• In social Networks: cliques can represent groups of people who know each other, such as close-knit circles of friends or professional colleagues.\n• In collaborative Networks: In a collaborative network (e.g., research collaborations), cliques can reveal teams of researchers who work together on the same topics or projects.\n• In biological Networks: In biological networks, cliques can indicate functional groups of proteins or genes that interact closely within a biological process.\n\nLet’s find the biggest clique in the karate network. We will find the largest group of people that have all links with each other.\n\nDespite the challenges in defining “community” in network science, cliques offer a concrete and well-defined concept for identifying groups that are fully interconnected, offering meaningful insights into both structured and unstructured networks.\n\nAnother interesting concept in network science is Shortest Path. The shortest path between two nodes in a graph refers to the sequence of edges that connects the nodes while minimizing the total distance or cost, which can be interpreted in various ways depending on the application. This concept plays a crucial role in fields like routing algorithms, network design, transportation planning, and even social network analysis.\n\nNetworkX provides several algorithms to compute shortest paths, such as Dijkstra’s Algorithm for weighted graphs and Breadth-First Search (BFS) for unweighted graphs.\n\nLet’s take a look at an example, we will create a synthetic dataset where nodes represent stations and the edges connections between the stations.\n• We will also add weighted edge time, representing the time it takes to reach from one station to the next.\n\nIn this example we use Dijkstra’s algorithm to compute the shortest path from station A to station H, where the edge weights represent travel times. The shortest path and its total travel time are printed, and the path is highlighted in red on the graph for visualization, with edge weights shown to indicate travel times between stations.\n\nThe algorithm calculates both the shortest route and its total travel time, which are then displayed. The shortest path between A and H is highlighted in red on the graph , with edge weights showing the time between each connected station, adding to a total of 45.\n\nWhile this was a simple computation, shortest path algorithms have broad applications. In transportation, they optimize routes and reduce travel time; in digital communication, they route data efficiently. They’re essential in logistics to minimize costs, in supply chains for timely deliveries, and in social networks to gauge closeness between individuals. Understanding shortest paths enables data-driven decisions across fields — from urban planning to network infrastructure — making it a vital tool for navigating complex systems efficiently.\n\nWe’ve explored several fundamental concepts in Network Science using NetworkX, such as shortest path algorithms, community detection, and the power of graph theory to model and analyze complex systems.\n\nIf you want to continue learning, I’ve placed a couple of links below :). In case you want to go deeper on community detection algorithms take a look to the CDLib library.\n\nNOTE: Computing advanced metrics and measures on graphs can often be ambiguous or even misleading. With so many potential metrics available, it’s easy to generate numbers that may not hold meaningful value or may misrepresent the network’s true structure. Choosing the right metrics requires careful consideration, as not all measures will provide relevant insights for every type of network analysis. If this resonates, have a look here for more information: statistical inference links data and theory in network science\n• Karate Club Network: Zachary, Wayne W. “An information flow model for conflict and fission in small groups.” Journal of Anthropological Research, 33(4), 452–473, 1977."
    },
    {
        "link": "https://toptal.com/data-science/graph-data-science-python-networkx",
        "document": "We’re inundated with data. Ever-expanding databases and spreadsheets are rife with hidden business insights. How can we analyze data and extract conclusions when there’s so much of it? Graphs (networks, not bar graphs) provide an elegant approach.\n\nWe often use tables to represent information generically. But graphs use a specialized data structure: Instead of a table row, a node represents an element. An edge connects two nodes to indicate their relationship.\n\nThis graph data structure enables us to observe data from unique angles, which is why graph data science is used in every field from molecular biology to the social sciences:\n\nSo how can developers leverage graph data science? Let’s turn to the most-used data science programming language: Python.\n\nGetting Started With “Graph Theory” Graphs in Python\n\nPython developers have several graph data libraries available to them, such as NetworkX, igraph, SNAP, and graph-tool. Pros and cons aside, they have very similar interfaces for Python graph visualization and structure manipulation.\n\nWe’ll use the popular NetworkX library. It’s simple to install and use, and supports the community detection algorithm we’ll be using.\n\nBut isn’t much of a graph yet, being devoid of nodes and edges.\n\nHow to Add Nodes to a Graph\n\nWe can add a node to the network by chaining on the return value of with (or for multiple nodes in a list). We can also add arbitrary characteristics or attributes to the nodes by passing a dictionary as a parameter, as we show with and :\n\nBut without edges between nodes, they’re isolated, and the dataset is no better than a simple table.\n\nHow to Add Edges to a Graph\n\nSimilar to the technique for nodes, we can use with the names of two nodes as parameters (or for multiple edges in a list), and optionally include a dictionary of attributes:\n\nThe NetworkX library supports graphs like these, where each edge can have a weight. For example, in a social network graph where nodes are users and edges are interactions, weight could signify how many interactions happen between a given pair of users—a highly relevant metric.\n\nNetworkX lists all edges when using , but it does not include their attributes. If we want edge attributes, we can use to get everything that’s connected to a node or to get the attributes of a particular edge:\n\nBut reading our first graph this way is impractical. Thankfully, there’s a much better representation.\n\nHow to Generate Images From Graphs (and Weighted Graphs)\n\nVisualizing a graph is essential: It lets us see the relationships between the nodes and the structure of the network quickly and clearly.\n\nA quick call to is all it takes:\n\nWe provided a default thickness for weightless edges, as seen in the result:\n\nOur methods and graph algorithms are about to get more complex, so for our next NetworkX/Python example, we’ll use a better-known dataset.\n\nGraph Data Science Using Data From the Movie Star Wars: Episode IV\n\nTo make it easier to interpret and understand our results, we’ll use this dataset. Nodes represent important characters, and edges (which aren’t weighted here) signify co-appearance in a scene.\n\nNote: The dataset is from Gabasova, E. (2016). Star Wars social network. DOI: https://doi.org/10.5281/zenodo.1411479.\n\nFirst, we’ll visualize the data with :\n\nCharacters that usually appear together, like R2-D2 and C-3PO, appear closely connected. In contrast, we can see that Darth Vader does not share scenes with Owen.\n\nWhy is each node located where it is in the previous graph?\n\nIt’s the result of the default algorithm. It simulates the force of a spring, attracting connected nodes and repelling disconnected ones. This helps highlight well-connected nodes, which end up in the center.\n\nNetworkX has other layouts that use different criteria to position nodes, like :\n\nThis layout is neutral in the sense that the location of a node does not depend on its importance—all nodes are represented equally. (The circular layout could also help visualize separate connected components—subgraphs having a path between any two nodes—but here, the whole graph is one big connected component.)\n\nBoth of the layouts we’ve seen have a degree of visual clutter because edges are free to cross other edges. But Kamada-Kawai, another force-directed algorithm like , positions the nodes so as to minimize the energy of the system.\n\nThis reduces edge-crossing but at a price: It’s slower than other layouts and therefore not highly recommended for graphs with many nodes.\n\nThis one has a specialized draw function:\n\nThat yields this shape instead:\n\nWithout any special intervention, the algorithm put main characters (like Luke, Leia, and C-3PO) in the center, and less prominent ones (like Camie and General Dodonna) by the border.\n\nVisualizing the graph with a specific layout can give us some interesting qualitative results. Still, quantitative results are a vital part of any data science analysis, so we’ll need to define some metrics.\n\nNow that we can visualize our network clearly, it may be of interest to us to characterize the nodes. There are multiple metrics that describe the characteristics of the nodes and, in our example, of the characters.\n\nOne basic metric for a node is its degree: how many edges it has. The degree of a Star Wars character’s node measures how many other characters they shared a scene with.\n\nThe function can calculate the degree of a character or of the entire network:\n\nThe output of both commands:\n\nSorting nodes from highest to lowest according to degree can be done with a single line of code:\n\nBeing just a total, the degree doesn’t take into account details of individual edges. Does a given edge connect to an otherwise isolated node or to a node that is connected with the entire network? Google’s PageRank algorithm aggregates this information to gauge how “important” a node is in a network.\n\nThe PageRank metric can be interpreted as an agent moving randomly from one node to another. Better-connected nodes have more paths leading through them, so the agent will tend to visit them more often.\n\nSuch nodes will have a higher PageRank, which we can calculate with the NetworkX library:\n\nThis prints Luke’s rank and our characters sorted by rank:\n\nOwen is the character with the highest PageRank, surpassing Luke, who had the highest degree. The analysis: Although Owen is not the character who shares the most scenes with other characters, he is a character who shares scenes with many important characters such as Luke himself, R2-D2, and C-3PO.\n\nIn greater contrast, C-3PO, the character with the third-highest degree, is the one with the lowest PageRank. Despite C-3PO having many connections, a lot of them are with unimportant characters.\n\nThe takeaway: Using multiple metrics can give deeper insight into different characteristics of a graph’s nodes.\n\nWhen performing Python graph analysis on a network it may be important to separate communities: groups of nodes that are highly connected to each other but minimally connected with nodes outside their community.\n\nThere are multiple algorithms for this. Most of them are found within unsupervised machine learning algorithms because they assign a label to the nodes without the need for them to have been labeled previously.\n\nOne of the most famous is label propagation. In it, each node starts with a unique label, in a community of one. The labels of the nodes are iteratively updated according to the majority of the labels of the neighboring nodes.\n\nThe labels diffuse through the network until all nodes share a label with most of their neighbors. Groups of nodes closely connected to each other end up having the same label.\n\nWith the NetworkX library, running this algorithm takes a mere three lines of Python:\n\nIn this list of sets, each set represents a community. Readers familiar with the movie will notice the algorithm managed to perfectly separate the “good guys” from the “bad guys,” differentiating the characters meaningfully without using any true (community) label or metadata.\n\nWe’ve seen that getting started with graph data science tools is more straightforward than it might sound. Once we represent data as a graph using the NetworkX library in Python, a few short lines of code can be illuminating. We can visualize our dataset, measure and compare node characteristics, and cluster nodes sensibly via community detection algorithms.\n\nHaving the skill to extract conclusions and insights from a network using Python enables developers to integrate with tools and methodology commonly found in data science services pipelines. From search engines to flight scheduling to electrical engineering, these methods apply easily to a wide range of contexts.\n\nCommunity Detection Algorithms\n\nZhao Yang, René Algesheimer, and Claudio Tessone. “A Comparative Analysis of Community Detection Algorithms on Artificial Networks.” Scientific Reports, 6, no. 30750 (2016).\n\n\n\n Graph Deep Learning\n\nThomas Kipf. “Graph Convolutional Networks.” September 30, 2016.\n\n\n\n Applications of Graph Data Science\n\nAlbanese, Federico, Leandro Lombardi, Esteban Feuerstein, and Pablo Balenzuela. “Predicting Shifting Individuals Using Text Mining and Graph Machine Learning on Twitter.” (August 24, 2020): arXiv:2008.10749 [cs.SI].\n\n\n\nCohen, Elior. “PyData Tel Aviv Meetup: Node2vec.” YouTube. November 22, 2018. Video, 21:09. https://www.youtube.com/watch?v=828rZgV9t1g."
    },
    {
        "link": "https://geeksforgeeks.org/python-visualize-graphs-generated-in-networkx-using-matplotlib",
        "document": "Prerequisites: Generating Graph using Network X, Matplotlib Intro\n\nIn this article, we will be discussing how to plot a graph generated by NetworkX in Python using Matplotlib. NetworkX is not a graph visualizing package but basic drawing with Matplotlib is included in the software package.\n\nStep 1 : Import networkx and matplotlib.pyplot in the project file.\n\nStep 2 : Generate a graph using networkx. \n\nStep 3 : Now use draw() function of networkx.drawing to draw the graph. \n\nStep 4 : Use savefig(“filename.png”) function of matplotlib.pyplot to save the drawing of graph in filename.png file.\n\nBelow is the Python code:\n\nTo add numbering in the node add one argument with_labels=True in draw() function.\n\nDifferent graph types and plotting can be done using networkx drawing and matplotlib.\n\nNote** : Here keywords is referred to optional keywords that we can mention use to format the graph plotting. Some of the general graph layouts are :"
    }
]