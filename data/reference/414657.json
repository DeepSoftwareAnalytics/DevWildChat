[
    {
        "link": "https://techcommunity.microsoft.com/blog/modernworkappconsult/use-the-uwp-inking-platform-as-input-for-advanced-scenarios/1352471",
        "document": "Since almost 5 years, Windows 10 is bringing innovations and powerful usages of devices' capabilities; The Windows Inking platform ‚úè is a one great example of natural user interface: With the use of the pen, your computer or tablet becomes a intelligent digital paper! You can free your imagination and draw/paint thanks to apps like Fresh Paint. Also with AI services your written words are understood and the corresponding text is produced; your drawings are recognized and converted into geometric shapes!\n\nIn the Enterprise space, writing and drawing can be a vector for innovation and productivity for users. Let's first go deeper in some usages of the Windows Inking capabilities. We will then explore how Azure AI Services can unlock impressive scenarios.\n\nThe Microsoft docs website gives you all the APIs and controls details to bring you into the Digital Inking journey. Let me give you some pieces of advise for starting:\n‚Ä¢ Just open/compile/look at the source code of the SimpleInk Sample which is part of the Universal Windows official samples. The XAML is straightforward. The C# code is light and easily understandable. It will give you the ability to give a try to inking code in your project with only some copy/paste. The initial controls to use are\n‚Ä¢ Keep an eye on the Windows Ink UX guidelines - https://docs.microsoft.com/en-us/windows/uwp/design/controls-and-patterns/inking-controls\n‚Ä¢ Refer to the following 2 namespaces\n\nWith all the documentation mentioned before, you would be easily able to\n‚Ä¢ Use the InkCanvas for allowing pen/mouse/touch drawing\n‚Ä¢ Use the ruler to draw perfect lines\n\nThe idea: Go further of the InkStrokes\n\nThe purpose of this blog post is to go deeper on one scenario: Accept Inkstrokes and convert them to shapes! What? Inkstrokes are not good? Do not misunderstand: Strokes are perfect. They are the digital objects representing the strokes that the user created by using the pen/mouse/touch. The idea is to leverage on the drawings to create digital formalized shapes. This way we can produce high fidelity floor plan, measure lengths, areas; we can create vectorial shapes and figures for printing, creating user interfaces, etc.\n\nThe simplest way to be able to accept inking is to use the InkCanvas control. Create a new empty UWP blank projet and just add the following XAML:\n\nIn the C# code, we just say what type of input we accept for this InkCanvas. Make your choice depending of the requirements of your app (You can change it at anytime by code):\n\nWe are done, you can draw on the whole surface of the app with pen/touch/mouse.\n\nThe source code is available on GitHub - https://github.com/sbovo/UWP-Advanced-Inking/tree/master/StrokesToShapes\n\nGetting the last InkStroke drawn ‚úè\n\nIn order to be able to do some actions after each draw, the Ink platform gives us the StrokesCollected event on the InkPresenter object associated with the InkCanvas.\n\nThen, in this event handler, we just get the latest stroke from the InkPresenter:\n\nXAML Shapes were first introduced in WPF. If you discover XAML Shapes, the following page gives you a perfect startup: Draw shapes - https://docs.microsoft.com/en-us/windows/uwp/design/controls-and-patterns/shapes.\n\nXAML Shapes are basically vector-based regions in the XAML UI. They provide you the ability to draw not only simple forms like rectangles, circles, ellipses but also any path, Bezier curves or geometric shapes. All are vector's shapes displayed on a XAML Canvas.\n\nLet's go back to our goal: We have the last InkStroke and we would like to \"replace\" it by a nice and friendly XAML Shapes that we could manipulate/move/modify easily by APIs.\n\nFirst, we modify the XAML page in order to add a new Canvas. The one that will contains all XAML Shapes:\n\nThe entire XAML page is like:\n\nIt now like we have two layers, on for drawing on the surface and the other one for displaying/manipulating all the final XAML shapes.\n\nWe can now do two actions:\n‚Ä¢ Create the new XAML Line based on the properties of the last InkStroke and add this line to the ShapesCanvas\n‚Ä¢ Remove the last InkStroke from the inkCanvas in order to have a clean display made only by XAML Shapes\n\nIt is just about creating a Line (Windows.UI.Xaml.Shapes.Line) object with the initial and final positions of the InkStroke üòíüòÄ:\n\nHere we go. We did it. We can draw on the surface and the final line will only be the XAML Line we added to the second Canvas.\n\nThis scenario \"converting an Ink stroke to a XAML shape\" is the basis for being able to achieve great and complex manipulations. Stay tuned for upcoming blog posts about XAML Shapes manipulations and modifications.\n\nAs usual, all the source code is available on GitHub - https://github.com/microsoft/Windows-AppConsult-Samples-UWP/\n\nThis article is part of a series exploring concepts about inking and XAML Shapes. Here are all links:\n‚Ä¢ Use the UWP Inking platform as input for advanced scenarios ‚áê You are here\n‚Ä¢ Turning to the dark side of inking = UnprocessedInput\n‚Ä¢ SimpleInk sample: Find examples of customization and extensibility possibilities provided by the Ink controls and APIs - https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/SimpleInk"
    },
    {
        "link": "https://stackoverflow.com/questions/47469759/how-can-i-draw-a-circle-with-inkstroke",
        "document": "If I understood your question correctly, you just want to use InkStroke to draw a ellipse and add these strokes of ellipse into InkCanvas. Then, you could get use these strokes for other purposes (e.g, save these strokes and use it for the next usage). If so, I could only tell you it's impossible. Because when you draw a similar ellipse on InkCanvas, you could use InkAnalyzer to convert it to ellipse, but it actually only returns four points to you. Jayden also has mentioned it on this thread: Add polygon/ellipse to inkcanvas in uwp\n\nBut as I said, if the reason of using inkstroke to draw ellipse is to save strokes for other purposes, I can give you another way. You could use win2D-UWP relevant APIs to draw ellipse on CanvasControl and save it as CanvasSvgDocument. Then, you could save it as a svg xml file. For the net usage, you could load this svg xml file by into CanvasControl.\n\nIf you're interested in CanvasSvgDocument, you could refer to SvgExample for more details."
    },
    {
        "link": "https://github.com/MicrosoftDocs/windows-uwp/blob/docs/hub/apps/design/controls/inking-controls.md",
        "document": "There are two different controls that facilitate inking in Windows apps: InkCanvas and InkToolbar.\n\nThe InkCanvas control renders pen input as either an ink stroke (using default settings for color and thickness) or an erase stroke. This control is a transparent overlay that doesn't include any built-in UI for changing the default ink stroke properties.\n\nAs the InkCanvas control does not include support for changing the default ink stroke settings, it can be paired with an InkToolbar control. The InkToolbar contains a customizable and extensible collection of buttons that activate ink-related features in an associated InkCanvas.\n\nBy default, the InkToolbar includes buttons for drawing, erasing, highlighting, and displaying a ruler. Depending on the feature, other settings and commands, such as ink color, stroke thickness, erase all ink, are provided in a flyout.\n\nUse the InkCanvas when you need to enable basic inking features in your app without providing any ink settings to the user.\n\nBy default, strokes are rendered as ink when using the pen tip (a black ballpoint pen with a thickness of 2 pixels) and as an eraser when using the eraser tip. If an eraser tip is not present, the InkCanvas can be configured to process input from the pen tip as an erase stroke.\n\nPair the InkCanvas with an InkToolbar to provide a UI for activating ink features and setting basic ink properties such as stroke size, color, and shape of the pen tip.\n\nThe InkToolbar includes the following built-in buttons:\n‚Ä¢ Ballpoint pen - draws a solid, opaque stroke with a circle pen tip. The stroke size is dependent on the pen pressure detected.\n‚Ä¢ Pencil - draws a soft-edged, textured, and semi-transparent stroke (useful for layered shading effects) with a circle pen tip. The stroke color (darkness) is dependent on the pen pressure detected.\n\nYou can customize both the color palette and size attributes (min, max, default) in the flyout for each pen.\n‚Ä¢ Eraser ‚Äì deletes any ink stroke touched. Note that the entire ink stroke is deleted, not just the portion under the eraser stroke.\n‚Ä¢ Ruler ‚Äì shows or hides the ruler. Drawing near the ruler edge causes the ink stroke to snap to the ruler.\n\n\n\nAlthough this is the default configuration, you have complete control over which built-in buttons are included in the InkToolbar for your app.\n\nThe InkToolbar consists of two distinct groups of button types:\n‚Ä¢ A group of \"tool\" buttons containing the built-in drawing, erasing, and highlighting buttons. Custom pens and tools are added here.\n‚Ä¢ A group of \"toggle\" buttons containing the built-in ruler button. Custom toggles are added here.\n\nDepending on your application and the inking functionality required, you can add any of the following buttons (bound to your custom ink features) to the InkToolbar:\n‚Ä¢ Custom pen ‚Äì a pen for which the ink color palette and pen tip properties, such as shape, rotation, and size, are defined by the host app.\n‚Ä¢ Custom toggle ‚Äì Sets the state of an app-defined feature to on or off. When turned on, the feature works in conjunction with the active tool.\n\nAlthough the InkToolbar can be a top level item, it is typically exposed through an \"Inking\" button or command. We recommend using EE56 glyph from the Segoe MLD2 Assets font as a top level icon.\n\nAll built-in pen and tool buttons include a flyout menu where ink properties and pen tip shape and size can be set. An \"extension glyph\" is displayed on the button to indicate the existence of the flyout.\n\nThe flyout is shown when the button of an active tool is selected again. When the color or size is changed, the flyout is automatically dismissed and inking can be resumed. Custom pens and tools can use the default flyout or specify a custom flyout.\n\nThe eraser also has a flyout that provides the Erase All Ink command.\n\nFor information on customization and extensibility, check out SimpleInk sample.\n‚Ä¢ The InkCanvas, and inking in general, is best experienced through an active pen. However, we recommend supporting inking with mouse and touch (including passive pen) input if required by your app.\n‚Ä¢ Use an InkToolbar control with the InkCanvas to provide basic inking features and settings. Both the InkCanvas and InkToolbar can be programmatically customized.\n‚Ä¢ The InkToolbar, and inking in general, is best experienced through an active pen. However, inking with mouse and touch can be supported if required by your app.\n‚Ä¢ If supporting inking with touch input, we recommend using the ED5F icon from the Segoe MLD2 Assets font for the toggle button, with a \"Touch writing\" tooltip.\n‚Ä¢ If providing stroke selection, we recommend using the EF20 icon from the Segoe MLD2 Assets font for the tool button, with a \"Selection tool\" tooltip.\n‚Ä¢ If using more than one InkCanvas, we recommend using a single InkToolbar to control inking across canvases.\n‚Ä¢ For best performance, we recommend altering the default flyout rather than creating a custom one for both default and custom tools.\n\nMicrosoft Edge uses the InkCanvas and InkToolbar for Web Notes.\n\n\n\nThe InkCanvas and InkToolbar are also used for Snip & Sketch in the Windows Ink Workspace.\n\n\n\nAdding an InkCanvas to your app requires just one line of markup:\n\nThe InkToolbar control must be used in conjunction with an InkCanvas. Incorporating an InkToolbar (with all built-in tools) into your app requires one additional line of markup:\n\nThis displays the following InkToolbar:\n‚Ä¢ SimpleInk sample - Demonstrates 8 scenarios around the customization and extensibility capabilities of the InkCanvas and InkToolbar controls. Each scenario provides basic guidance on common inking situations and control implementations.\n‚Ä¢ WinUI 2 Gallery sample - See all the XAML controls in an interactive format."
    },
    {
        "link": "https://learn.microsoft.com/en-us/uwp/api/windows.ui.xaml.controls.inkcanvas?view=winrt-26100",
        "document": "An InkCanvas has default Height and Width properties of zero, unless it is the child of an element that automatically sizes its child elements, such as StackPanel or Grid controls.\n\nInkCanvas has maximum height and width dimensions of 2^21 physical pixels.\n\nBy default, the InkCanvas does not support ink input from devices other than pen. You must specify support for other devices through the InputDeviceTypes of an InkPresenter object.\n\nAssociate an InkToolbar with an InkCanvas to provide a customizable and extensible collection of buttons that activate ink-related features in the InkCanvas. By default, the toolbar includes buttons for drawing, erasing, highlighting, and displaying a ruler.\n\nAn InkCanvas control is bound to a single instance of an InkPresenter object (exposed through the InkPresenter property). This object provides all default inking functionality exposed by the InkCanvas, along with a comprehensive set of APIs for additional customization.\n\nThe configuration of the InkPresenter determines the pointer event handling behavior of the InkCanvas. You must set InkPresenter.InputDeviceTypes to CoreInputDeviceTypes.None for the InkCanvas to process pointer events, otherwise they are passed to the InkPresenter object.\n\nTo handle pointer events with the InkPresenter object, you must set RightDragAction to LeaveUnprocessed to pass the input through as UnprocessedInput for custom processing by your app.\n\nThe InkCanvas control doesn't work if a Transform3D is set on the control or on any element in the XAML tree above the control.\n\nGets or sets the access key (mnemonic) for this element. (Inherited from UIElement) Gets or sets a source element that provides the access key scope for this element, even if it's not in the visual tree of the source element. (Inherited from UIElement) Gets the rendered height of a FrameworkElement. See Remarks. (Inherited from FrameworkElement) Gets the position of this UIElement, relative to its parent, computed during the arrange pass of the layout process. (Inherited from UIElement) Gets the size that this UIElement computed during the arrange pass of the layout process. (Inherited from UIElement) Gets the UI theme that is currently used by the element, which might be different than the RequestedTheme. (Inherited from FrameworkElement) Gets the rendered width of a FrameworkElement. See Remarks. (Inherited from FrameworkElement) Gets or sets a value that determines whether this UIElement can be a drop target for purposes of drag-and-drop operations. (Inherited from UIElement) Gets or sets a value that indicates whether the element automatically gets focus when the user interacts with it. (Inherited from FrameworkElement) Gets or sets whether a disabled control can receive focus. (Inherited from FrameworkElement) Gets a Uniform Resource Identifier (URI) that represents the base Uniform Resource Identifier (URI) for an XAML-constructed object at XAML load time. This property is useful for Uniform Resource Identifier (URI) resolution at run time. (Inherited from FrameworkElement) Gets or sets a value that indicates that rendered content should be cached as a composited bitmap when possible. (Inherited from UIElement) Gets or sets a value that indicates whether the UIElement can be a candidate for scroll anchoring. (Inherited from UIElement) Gets or sets a value that indicates whether the element can be dragged as data in a drag-and-drop operation. (Inherited from UIElement) Gets or sets the center point of the element, which is the point about which rotation or scaling occurs. Affects the rendering position of the element. (Inherited from UIElement) Gets or sets the RectangleGeometry used to define the outline of the contents of a UIElement. (Inherited from UIElement) Gets or sets a property that declares alternate composition and blending modes for the element in its parent layout and window. This is relevant for elements that are involved in a mixed XAML / Microsoft DirectX UI. (Inherited from UIElement) Gets or sets the flyout associated with this element. (Inherited from UIElement) Gets or sets the data context for a FrameworkElement. A common use of a data context is when a FrameworkElement uses the {Binding} markup extension and participates in data binding. (Inherited from FrameworkElement) Gets the size that this UIElement computed during the measure pass of the layout process. (Inherited from UIElement) Gets the CoreDispatcher that this object is associated with. The CoreDispatcher represents a facility that can access the DependencyObject on the UI thread even if the code is initiated by a non-UI thread. (Inherited from DependencyObject) Gets or sets a value that specifies whether the access key display is dismissed when an access key is invoked. (Inherited from UIElement) Gets or sets the direction in which text and other UI elements flow within any parent element that controls their layout. This property can be set to either LeftToRight or RightToLeft. Setting FlowDirection to RightToLeft on any element sets the alignment to the right, the reading order to right-to-left and the layout of the control to flow from right to left. (Inherited from FrameworkElement) Gets or sets the outer margin of the focus visual for a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the brush used to draw the outer border of a or focus visual for a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the thickness of the outer border of a or focus visual for a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the brush used to draw the inner border of a or focus visual for a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the thickness of the inner border of a or focus visual for a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the suggested height of a FrameworkElement. (Inherited from FrameworkElement) Gets or sets a value that indicates whether the framework automatically adjusts the element's visual properties when high contrast themes are enabled. (Inherited from UIElement) Gets or sets the horizontal alignment characteristics that are applied to a FrameworkElement when it is composed in a layout parent, such as a panel or items control. (Inherited from FrameworkElement) Gets the underlying InkPresenter object associated with the InkCanvas. Each InkCanvas control is associated with an instance of an InkPresenter object (exposed through the InkPresenter property). The InkPresenter provides properties, methods, and events for managing the input, processing, and rendering of ink data for an InkCanvas control. The InkPresenter cannot be instantiated directly. Gets or sets a value that indicates whether an element defines its own access key scope. (Inherited from UIElement) Gets or sets a value that determines whether the DoubleTapped event can originate from that element. (Inherited from UIElement) Gets or sets whether the contained area of this UIElement can return true values for hit testing. (Inherited from UIElement) Gets or sets a value that determines whether the Holding event can originate from that element. (Inherited from UIElement) Gets a value that indicates whether the element has been added to the element tree and is ready for interaction. (Inherited from FrameworkElement) Gets or sets a value that determines whether the RightTapped event can originate from that element. (Inherited from UIElement) Gets or sets a value that determines whether the Tapped event can originate from that element. (Inherited from UIElement) Gets or sets a value that indicates whether the control tooltip displays the key combination for its associated keyboard accelerator. (Inherited from UIElement) Gets or sets a value that indicates the control tooltip that displays the accelerator key combination. (Inherited from UIElement) Gets the collection of key combinations that invoke an action using the keyboard. Accelerators are typically assigned to buttons or menu items. \n\n Example of a menu showing keyboard accelerators for various menu items (Inherited from UIElement) Gets or sets a value that indicates how far left or right the Key Tip is placed in relation to the UIElement. (Inherited from UIElement) Gets or sets a value that indicates where the access key Key Tip is placed in relation to the boundary of the UIElement. (Inherited from UIElement) Gets or sets a value that indicates the element targeted by the access key Key Tip. (Inherited from UIElement) Gets or sets a value that indicates how far up or down the Key Tip is placed in relation to the UI element. (Inherited from UIElement) Gets or sets localization/globalization language information that applies to a FrameworkElement, and also to all child elements of the current FrameworkElement in the object representation and in UI. (Inherited from FrameworkElement) Gets the collection of XamlLight objects attached to this element. (Inherited from UIElement) Gets or sets the ManipulationModes value used for UIElement behavior and interaction with gestures. Setting this value enables handling the manipulation events from this element in app code. (Inherited from UIElement) Gets or sets the outer margin of a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the maximum height constraint of a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the maximum width constraint of a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the minimum height constraint of a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the minimum width constraint of a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the identifying name of the object. When a XAML processor creates the object tree from XAML markup, run-time code can refer to the XAML-declared object by this name. (Inherited from FrameworkElement) Gets or sets the degree of the object's opacity. (Inherited from UIElement) Gets or sets the ScalarTransition that animates changes to the Opacity property. (Inherited from UIElement) Gets the parent object of this FrameworkElement in the object tree. (Inherited from FrameworkElement) Gets the set of all captured pointers, represented as Pointer values. (Inherited from UIElement) Gets or sets the perspective projection (3-D effect) to apply when rendering this element. (Inherited from UIElement) Gets the final render size of a UIElement. Use is not recommended, see Remarks. (Inherited from UIElement) Gets or sets transform information that affects the rendering position of a UIElement. (Inherited from UIElement) Gets or sets the origin point of any possible render transform declared by RenderTransform, relative to the bounds of the UIElement. (Inherited from UIElement) Gets or sets the UI theme that is used by the UIElement (and its child elements) for resource determination. The UI theme you specify with RequestedTheme can override the app-level RequestedTheme. (Inherited from FrameworkElement) Gets the locally defined resource dictionary. In XAML, you can establish resource items as child object elements of a property element, through XAML implicit collection syntax. (Inherited from FrameworkElement) Gets or sets the angle of clockwise rotation, in degrees. Rotates relative to the RotationAxis and the CenterPoint. Affects the rendering position of the element. (Inherited from UIElement) Gets or sets the axis to rotate the element around. (Inherited from UIElement) Gets or sets the ScalarTransition that animates changes to the Rotation property. (Inherited from UIElement) Gets or sets the scale of the element. Scales relative to the element's CenterPoint. Affects the rendering position of the element. (Inherited from UIElement) Gets or sets the Vector3Transition that animates changes to the Scale property. (Inherited from UIElement) Gets or sets the shadow effect cast by the element. (Inherited from UIElement) Gets or sets an instance Style that is applied for this object during layout and rendering. (Inherited from FrameworkElement) Gets or sets a value that modifies how tabbing and TabIndex work for this control. (Inherited from UIElement) Gets or sets an arbitrary object value that can be used to store custom information about this object. (Inherited from FrameworkElement) Gets or sets the 3-D transform effect to apply when rendering this element. (Inherited from UIElement) Gets or sets the transformation matrix to apply to the element. (Inherited from UIElement) Gets or sets the collection of Transition style elements that apply to a UIElement. (Inherited from UIElement) Gets or sets the x, y, and z rendering position of the element. (Inherited from UIElement) Gets or sets the Vector3Transition that animates changes to the Translation property. (Inherited from UIElement) Gets the collection of triggers for animations that are defined for a FrameworkElement. Not commonly used. See Remarks. (Inherited from FrameworkElement) Gets the context identifier for the element. (Inherited from UIElement) Gets or sets a value that determines whether rendering for the object and its visual subtree should use rounding behavior that aligns rendering to whole pixels. (Inherited from UIElement) Gets or sets the vertical alignment characteristics that are applied to a FrameworkElement when it is composed in a parent object such as a panel or items control. (Inherited from FrameworkElement) Gets or sets the visibility of a UIElement. A UIElement that is not visible is not rendered and does not communicate its desired size to layout. (Inherited from UIElement) Gets or sets the width of a FrameworkElement. (Inherited from FrameworkElement) Gets or sets the in which this element is being viewed. (Inherited from UIElement) Gets or sets a value that specifies the strategy used to determine the target element of a down navigation. (Inherited from UIElement) Gets or sets a value that enables or disables navigation using the keyboard directional arrows. (Inherited from UIElement) Gets or sets a value that specifies the strategy used to determine the target element of a left navigation. (Inherited from UIElement) Gets or sets a value that specifies the strategy used to determine the target element of a right navigation. (Inherited from UIElement) Gets or sets a value that specifies the strategy used to determine the target element of an up navigation. (Inherited from UIElement)\n\nOccurs when access keys should no longer be displayed. (Inherited from UIElement) Occurs when the user requests that access keys be displayed. (Inherited from UIElement) Occurs when the ActualTheme property value has changed. (Inherited from FrameworkElement) Occurs when StartBringIntoView is called on this element or one of its descendants. (Inherited from UIElement) Occurs when a single, composed character is received by the input queue. (Inherited from UIElement) Occurs when a context input gesture continues into a manipulation gesture, to notify the element that the context flyout should not be opened. (Inherited from UIElement) Occurs when the user has completed a context input gesture, such as a right-click. (Inherited from UIElement) Occurs when the value of the FrameworkElement.DataContext property changes. (Inherited from FrameworkElement) Occurs when an otherwise unhandled DoubleTap interaction occurs over the hit test area of this element. (Inherited from UIElement) Occurs when the input system reports an underlying drag event with this element as the target. (Inherited from UIElement) Occurs when the input system reports an underlying drag event with this element as the origin. (Inherited from UIElement) Occurs when the input system reports an underlying drag event with this element as the potential drop target. (Inherited from UIElement) Occurs when the input system reports an underlying drop event with this element as the drop target. (Inherited from UIElement) Occurs when a drag-and-drop operation with this element as the source is ended. (Inherited from UIElement) Occurs when the FrameworkElement's effective viewport changes. (Inherited from FrameworkElement) Occurs before a UIElement receives focus. This event is raised synchronously to ensure focus isn't moved while the event is bubbling. (Inherited from UIElement) Occurs when a UIElement receives focus. This event is raised asynchronously, so focus can move again before bubbling is complete. (Inherited from UIElement) Occurs when an otherwise unhandled Hold interaction occurs over the hit test area of this element. (Inherited from UIElement) Occurs when a keyboard key is pressed while the UIElement has focus. (Inherited from UIElement) Occurs when a keyboard key is released while the UIElement has focus. (Inherited from UIElement) Occurs when the layout of the visual tree changes, due to layout-relevant properties changing value or some other action that refreshes the layout. (Inherited from FrameworkElement) Occurs when a FrameworkElement has been constructed and added to the object tree, and is ready for interaction. (Inherited from FrameworkElement) Occurs before a UIElement loses focus. This event is raised synchronously to ensure focus isn't moved while the event is bubbling. (Inherited from UIElement) Occurs when a UIElement loses focus. This event is raised asynchronously, so focus can move again before bubbling is complete. (Inherited from UIElement) Occurs when a manipulation on the UIElement is complete. (Inherited from UIElement) Occurs when the input device changes position during a manipulation. (Inherited from UIElement) Occurs when the input device loses contact with the UIElement object during a manipulation and inertia begins. (Inherited from UIElement) Occurs when an input device begins a manipulation on the UIElement. (Inherited from UIElement) Occurs when the manipulation processor is first created. (Inherited from UIElement) Occurs when a user attempts to move focus (via tab or directional arrows), but focus doesn't move because no focus candidate is found in the direction of movement. (Inherited from UIElement) Occurs when pointer capture previously held by this element moves to another element or elsewhere. (Inherited from UIElement) Occurs when a pointer enters the hit test area of this element. (Inherited from UIElement) Occurs when a pointer leaves the hit test area of this element. (Inherited from UIElement) Occurs when a pointer moves while the pointer remains within the hit test area of this element. (Inherited from UIElement) Occurs when the pointer device initiates a Press action within this element. (Inherited from UIElement) Occurs when the pointer device that previously initiated a Press action is released, while within this element. Note that the end of a Press action is not guaranteed to fire a PointerReleased event; other events may fire instead. For more info, see Remarks. (Inherited from UIElement) Occurs when the delta value of a pointer wheel changes. (Inherited from UIElement) Occurs when a keyboard key is pressed while the UIElement has focus. (Inherited from UIElement) Occurs when a keyboard key is released while the UIElement has focus. (Inherited from UIElement) Occurs when a keyboard shortcut (or accelerator) is pressed. (Inherited from UIElement) Occurs when a right-tap input stimulus happens while the pointer is over the element. (Inherited from UIElement) Occurs when either the ActualHeight or the ActualWidth property changes value on a FrameworkElement. (Inherited from FrameworkElement) Occurs when an otherwise unhandled Tap interaction occurs over the hit test area of this element. (Inherited from UIElement) Occurs when this object is no longer connected to the main object tree. (Inherited from FrameworkElement)\n‚Ä¢ Get Started Tutorial: Support ink in your UWP app\n‚Ä¢ Get Started Tutorial: Support ink in your UWP app"
    },
    {
        "link": "https://github.com/MicrosoftDocs/windows-uwp/blob/docs/hub/apps/design/input/convert-ink-to-text.md",
        "document": "Convert ink strokes to text and shapes using the recognition capabilities built into Windows Ink.\n\nHere, we demonstrate how to use the Windows Ink analysis engine (Windows.UI.Input.Inking.Analysis) to classify, analyze, and recognize a set of free-form strokes on an InkCanvas as either text or shapes. (In addition to text and shape recognition, ink analysis can also be used to recognize document structure, bullet lists, and generic drawings.)\n\nIn this example, recognition is initiated when the user clicks a button to indicate they are finished drawing.\n‚Ä¢ First, we set up the UI (MainPage.xaml). The UI includes a \"Recognize\" button, an InkCanvas, and a standard Canvas. When the \"Recognize\" button is pressed, all ink strokes on the ink canvas are analyzed and (if recognized) corresponding shapes and text are drawn on the standard canvas. The original ink strokes are then deleted from the ink canvas. < = > < .RowDefinitions> < = /> < = /> </ .RowDefinitions> < = = Grid.Row= > < = = = = /> < = = = /> </ > < = Grid.Row= > The canvas where we render the replacement text and shapes. < = /> < = /> </ > </ >\n‚Ä¢ In the UI code-behind file (MainPage.xaml.cs), add the namespace type references required for our ink and ink analysis functionality:\n‚Ä¢ We then specify our global variables:\n‚Ä¢ Next, we set some basic ink input behaviors:\n‚Ä¢ The InkPresenter is configured to interpret input data from pen, mouse, and touch as ink strokes (InputDeviceTypes).\n‚Ä¢ Ink strokes are rendered on the InkCanvas using the specified InkDrawingAttributes.\n‚Ä¢ A listener for the click event on the \"Recognize\" button is also declared.\n‚Ä¢ For this example, we perform the ink analysis in the click event handler of the \"Recognize\" button.\n‚Ä¢ First, call GetStrokes on the StrokeContainer of the InkCanvas.InkPresenter to get the collection of all current ink strokes.\n‚Ä¢ If ink strokes are present, pass them in a call to AddDataForStrokes of the InkAnalyzer.\n‚Ä¢ We're trying to recognize both drawings and text, but you can use the SetStrokeDataKind method to specify whether you're interested only in text (including document structure and bullet lists) or only in drawings (including shape recognition).\n‚Ä¢ Call AnalyzeAsync to initiate ink analysis and get the InkAnalysisResult.\n‚Ä¢ If Status returns a state of Updated, call FindNodes for both InkAnalysisNodeKind.InkWord and InkAnalysisNodeKind.InkDrawing.\n‚Ä¢ Iterate through both sets of node types and draw the respective text or shape on the recognition canvas (below the ink canvas).\n‚Ä¢ Finally, delete the recognized nodes from the InkAnalyzer and the corresponding ink strokes from the ink canvas. // In this example, we try to recognizing both // writing and drawing, so the platform default // of \"InkAnalysisStrokeKind.Auto\" is used. // If you're only interested in a specific type of recognition, // such as writing or drawing, you can constrain recognition // using the SetStrokDataKind method as follows: // This can improve both efficiency and recognition results. // Have ink strokes on the canvas changed? // Find all strokes that are recognized as handwriting and // (for this example, we ignore alternatives), and delete // Find all strokes that are recognized as a drawing and // Catch and process unsupported shapes (lines and so on) here. // Draw an Ellipse object on the recognitionCanvas (circle is a specialized ellipse).\n‚Ä¢ Here's the function for drawing a TextBlock on our recognition canvas. We use the bounding rectangle of the associated ink stroke on the ink canvas to set the position and font size of the TextBlock.\n‚Ä¢ Here are the functions for drawing ellipses and polygons on our recognition canvas. We use the bounding rectangle of the associated ink stroke on the ink canvas to set the position and font size of the shapes. // Draw an ellipse on the recognitionCanvas.\n\nIn the preceding section (Free-form recognition with ink analysis), we demonstrated how to use the ink analysis APIs to analyze and recognize arbitrary ink strokes within an InkCanvas area.\n\nIn this section, we demonstrate how to use the Windows Ink handwriting recognition engine (not ink analysis) to convert a set of strokes on an InkCanvas to text (based on the installed default language pack).\n\nIn this example, recognition is initiated when the user clicks a button to indicate they are finished writing.\n‚Ä¢ First, we set up the UI. The UI includes a \"Recognize\" button, the InkCanvas, and an area to display recognition results.\n‚Ä¢ For this example, you need to first add the namespace type references required for our ink functionality:\n‚Ä¢ We then set some basic ink input behaviors. The InkPresenter is configured to interpret input data from both pen and mouse as ink strokes (InputDeviceTypes). Ink strokes are rendered on the InkCanvas using the specified InkDrawingAttributes. A listener for the click event on the \"Recognize\" button is also declared.\n‚Ä¢ Finally, we perform the basic handwriting recognition. For this example, we use the click event handler of the \"Recognize\" button to perform the handwriting recognition.\n‚Ä¢ An InkPresenter stores all ink strokes in an InkStrokeContainer object. The strokes are exposed through the StrokeContainer property of the InkPresenter and retrieved using the GetStrokes method. // Get all strokes on the InkCanvas.\n‚Ä¢ An InkRecognizerContainer is created to manage the handwriting recognition process.\n‚Ä¢ RecognizeAsync is called to retrieve a set of InkRecognitionResult objects. Recognition results are produced for each word that is detected by an InkRecognizer. // Recognize all ink strokes on the ink canvas.\n‚Ä¢ Each InkRecognitionResult object contains a set of text candidates. The topmost item in this list is considered by the recognition engine to be the best match, followed by the remaining candidates in order of decreasing confidence. We iterate through each InkRecognitionResult and compile the list of candidates. The candidates are then displayed and the InkStrokeContainer is cleared (which also clears the InkCanvas). // Get all recognition candidates from each recognition result. // Clear the ink canvas once recognition is complete.\n‚Ä¢ Here's the click handler example, in full. // Get all strokes on the InkCanvas. // inkRecognizerContainer is null if a recognition engine is not available. // Recognize all ink strokes on the ink canvas. // Get all recognition candidates from each recognition result. // Clear the ink canvas once recognition is complete.\n\nThe handwriting recognition built into the Windows ink platform includes an extensive subset of locales and languages supported by Windows.\n\nSee the InkRecognizer.Name property topic for a list of languages supported by the InkRecognizer .\n\nYour app can query the set of installed handwriting recognition engines and use one of those, or let a user select their preferred language.\n\nNote Users can see a list of installed languages by going to Settings -> Time & Language. Installed languages are listed under Languages.\n\nTo install new language packs and enable handwriting recognition for that language:\n‚Ä¢ Select a language from the list, then choose the region version. The language is now listed on the Region & language page.\n‚Ä¢ On the Language options page, download the Handwriting recognition engine (they can also download the full language pack, speech recognition engine, and keyboard layout here).\n\nHere, we demonstrate how to use the handwriting recognition engine to interpret a set of strokes on an InkCanvas based on the selected recognizer.\n\nThe recognition is initiated by the user clicking a button when they are finished writing.\n‚Ä¢ First, we set up the UI. The UI includes a \"Recognize\" button, a combo box that lists all installed handwriting recognizers, the InkCanvas, and an area to display recognition results.\n‚Ä¢ We then set some basic ink input behaviors. The InkPresenter is configured to interpret input data from both pen and mouse as ink strokes (InputDeviceTypes). Ink strokes are rendered on the InkCanvas using the specified InkDrawingAttributes. We call an function to populate the recognizer combo box with a list of installed handwriting recognizers. We also declare listeners for the click event on the \"Recognize\" button and the selection changed event on the recognizer combo box.\n‚Ä¢ We populate the recognizer combo box with a list of installed handwriting recognizers. An InkRecognizerContainer is created to manage the handwriting recognition process. Use this object to call GetRecognizers and retrieve the list of installed recognizers to populate the recognizer combo box. // inkRecognizerContainer is null if a recognition engine is not available.\n‚Ä¢ Update the handwriting recognizer if the recognizer combo box selection changes. Use the InkRecognizerContainer to call SetDefaultRecognizer based on the selected recognizer from the recognizer combo box.\n‚Ä¢ Finally, we perform the handwriting recognition based on the selected handwriting recognizer. For this example, we use the click event handler of the \"Recognize\" button to perform the handwriting recognition.\n‚Ä¢ An InkPresenter stores all ink strokes in an InkStrokeContainer object. The strokes are exposed through the StrokeContainer property of the InkPresenter and retrieved using the GetStrokes method. // Get all strokes on the InkCanvas.\n‚Ä¢ RecognizeAsync is called to retrieve a set of InkRecognitionResult objects. Recognition results are produced for each word that is detected by an InkRecognizer. // Recognize all ink strokes on the ink canvas.\n‚Ä¢ Each InkRecognitionResult object contains a set of text candidates. The topmost item in this list is considered by the recognition engine to be the best match, followed by the remaining candidates in order of decreasing confidence. We iterate through each InkRecognitionResult and compile the list of candidates. The candidates are then displayed and the InkStrokeContainer is cleared (which also clears the InkCanvas). // Get all recognition candidates from each recognition result. // Clear the ink canvas once recognition is complete.\n‚Ä¢ Here's the click handler example, in full. // Get all strokes on the InkCanvas. // inkRecognizerContainer is null if a recognition engine is not available. // Recognize all ink strokes on the ink canvas. // Get all recognition candidates from each recognition result. // Clear the ink canvas once recognition is complete.\n\nWhile, the previous two examples require the user to press a button to start recognition, you can also perform dynamic recognition using stroke input paired with a basic timing function.\n\nFor this example, we'll use the same UI and stroke settings as the previous international recognition example.\n‚Ä¢ These global objects (InkAnalyzer, InkStroke, InkAnalysisResult, DispatcherTimer) are used throughout our app.\n‚Ä¢ Instead of a button to initiate recognition, we add listeners for two InkPresenter stroke events (StrokesCollected and StrokeStarted), and set up a basic timer (DispatcherTimer) with a one second Tick interval. // Listen for stroke events on the InkPresenter to // StrokesCollected is fired when the user stops inking by // lifting their pen or finger, or releasing the mouse button. // StrokeStarted is fired when ink input is first detected.\n‚Ä¢ We then define the handlers for the InkPresenter events we declared in the first step (we also override the OnNavigatingFrom page event to manage our timer).\n‚Ä¢ StrokesCollected\n\n Add ink strokes (AddDataForStrokes) to the InkAnalyzer and start the recognition timer when the user stops inking (by lifting their pen or finger, or releasing the mouse button). After one second of no ink input, recognition is initiated. Use the SetStrokeDataKind method to specify whether you're interested only in text (including document structure amd bullet lists) or only in drawings (including shape recognition).\n‚Ä¢ StrokeStarted\n\n If a new stroke starts before the next timer tick event, stop the timer as the new stroke is likely the continuation of a single handwriting entry. // Don't perform analysis while a stroke is in progress. // If a new stroke starts before the next timer tick event, // stop the timer as the new stroke is likely the continuation // Stop the timer and add the collected strokes to the InkAnalyzer. // Start the recognition timer when the user stops inking (by // lifting their pen or finger, or releasing the mouse button). // If ink input is not detected after one second, initiate recognition. // If you're only interested in a specific type of recognition, // such as writing or drawing, you can constrain recognition // using the SetStrokDataKind method, which can improve both // In this example, \"InkAnalysisStrokeKind.Writing\" is used.\n‚Ä¢ Finally, we perform the handwriting recognition. For this example, we use the Tick event handler of a DispatcherTimer to initiate the handwriting recognition.\n‚Ä¢ Call AnalyzeAsync to initiate ink analysis and get the InkAnalysisResult.\n‚Ä¢ If Status returns a state of Updated, call FindNodes for node types of InkAnalysisNodeKind.InkWord.\n‚Ä¢ Iterate through the nodes and display the recognized text.\n‚Ä¢ Finally, delete the recognized nodes from the InkAnalyzer and the corresponding ink strokes from the ink canvas. // Have ink strokes on the canvas changed? // Find all strokes that are recognized as handwriting and // Display the primary recognized text (for this example, // we ignore alternatives), and then delete the // Ink analyzer is busy. Wait a while and try again.\n‚Ä¢ Get Started Tutorial: Support ink in your Windows app"
    },
    {
        "link": "https://learn.microsoft.com/en-us/uwp/api/windows.ui.xaml.media.ellipsegeometry?view=winrt-26100",
        "document": "Gets a Rect that specifies the axis-aligned bounding box of the Geometry. (Inherited from Geometry)\n\nGets or sets the center point of the EllipseGeometry.\n\nGets the CoreDispatcher that this object is associated with. The CoreDispatcher represents a facility that can access the DependencyObject on the UI thread even if the code is initiated by a non-UI thread. (Inherited from DependencyObject)\n\nGets or sets the x-radius value of the EllipseGeometry.\n\nGets or sets the y-radius value of the EllipseGeometry.\n\nGets or sets the Transform object applied to a Geometry. (Inherited from Geometry)"
    },
    {
        "link": "https://learn.microsoft.com/mt-mt/uwp/api/windows.ui.xaml.media.ellipsegeometry?view=winrt-10586",
        "document": "Gets a Rect that specifies the axis-aligned bounding box of the Geometry. (Inherited from Geometry)\n\nGets or sets the center point of the EllipseGeometry.\n\nGets the CoreDispatcher that this object is associated with. The CoreDispatcher represents a facility that can access the DependencyObject on the UI thread even if the code is initiated by a non-UI thread. (Inherited from DependencyObject)\n\nGets or sets the x-radius value of the EllipseGeometry.\n\nGets or sets the y-radius value of the EllipseGeometry.\n\nGets or sets the Transform object applied to a Geometry. (Inherited from Geometry)"
    },
    {
        "link": "https://stackoverflow.com/questions/59909032/load-geometry-from-resources-in-uwp",
        "document": "I'm having a similar issue to the one discussed here - Using Geometry resources in XAML - but I did not find answer there. I have a page in UWP, which looks like this:\n\nThe sample code is taken from a WPF book, where it's supposed to work. On UWP the app throws a run-time exception (meaning the app builds fine) of type Windows.UI.Xaml.Markup.XamlParseException with a message: \"Failed to assign to property 'Windows.UI.Xaml.Shapes.Path.Data\" The error points to this line:\n\nIn particular this piece Data=\"{StaticResource Geometry}\" - do you have any ideas please? Thank you!\n\nIf I try this example, then it works. If I rewrite the example like this:\n\nI get the same exception."
    },
    {
        "link": "https://stackoverflow.com/questions/24534148/how-can-i-bind-to-the-center-property-of-an-ellipsegeometry",
        "document": "I am trying to move an Ellipse around inside of a custom control, and I care about it's center point so I am using inside of a instead of using on its own.\n\nSo I created this custom control (CenterPoint is harded coded to 100,100):\n\nThe default style for this class (EllipseGeometry's Center is bound to CenterPoint in the control):\n\nWhen put my RippleButton on a WPF window, the red ellipse is always in the top left corner instead of 100,100. What is going on here and how do I get it to move to the CenterPoint that is defined in the class?"
    },
    {
        "link": "https://github.com/HillHouse/MilSym/blob/master/README.md",
        "document": "This is a re-hosting of the MilSym Codeplex project. Although the project is no longer under active development, there are some additions and updates:\n‚Ä¢ A new WPF map example was added, based on the Fischer XAML-Map-Control.\n‚Ä¢ A new UWP map example was added, based on the Fischer XAML-Map-Control.\n‚Ä¢ A new UWP map example was added, based on Windows.UI.Xaml.Controls.Maps.MapControl.\n‚Ä¢ The Esri ArcGIS Client WPF map control was updated to version 10.2.5.\n‚Ä¢ The Bing WPF map control was updated to version 1.0.1.\n\nFor those seeking to utilize open source military symbology projects supported by the US military, the projects at Mission Command are active and recommended.\n\nOnly the WPF and UWP portions of this project are relevant as Microsoft no longer supports Silveright in recent Visual Studio versions. The entire project (except Silverlight) can be built under Windows using the\n\nFor those interested in symbology in general, the NATO Symbology Wikipedia article is a good introduction to the military symbology defined by MIL-STD 2525C.\n\nMilSym provides XAML-based, Bing-, Fischer- and Esri-compatible map symbology for units, equipment, installations, tactical graphics, weather, oceanography, signals intelligence, stability ops and emergency management.\n\nUWP vs WPF vs Silverlight dependencies have been isolated to specific XAML files and C# statements. The GraphicsTest and its associated Resource Dictionaries (that exercise all single point symbology) works for both WPF and UWP. The WPF and UWP example map programs display sample single- and multi-point symbols.\n\nThe code was written in C# for WPF .NET 4.x, Silverlight 4.x and Windows 10 Fall Creator's Edition UWP.\n\nThe symbology code consists primarily of XAML files with some support code. The workhorse for point symbology is a Resource Dictionary of Control Templates representing base symbols. A symbol code specifies a control template that is then rendered using either default or user-specified brushes for fills and outlines. The resulting symbol is then overlaid with label, echelon, mobility and other symbol decoration. The result is returned as a MilSymbol object whose base class is Canvas. The interesting symbology parameters are exposed as dependency properties.\n\nThe official 2525C symbology appendices and their status in this project are:\n\nAppendices A, B, and D cover symbology that has primary applicability to military operations. The symbols in appendices C, E, and G have broader applicability.\n\nAppendix F simply describes different ways to use or display symbols in a 2.5D or 3D display. In the case of Silverlight, adding a skew transformation to a symbol for a 2.5D display is straightforward. Only the scale and rotate transforms are exposed in the MilSymbol interface for this release. The various MapTest applications, as shown in Figure 5, demonstrate the use of a translate transform.\n‚Ä¢ UWP blows up when using a really small font size to the point where it can crash Windows when debugging in Visual Studio. The MilSymbol and MilGraphic symbology classes protect against this situation by binding to each TextBlock‚Äôs Visibility using a TextVisibility property. Visibility is then set to Collapsed when a map draws a symbol using a really small font size.\n‚Ä¢ Almost all UWP classes are in different DLLs compared to their WPF and Silverlight counterparts. The most common change was replacing classes with classes.\n‚Ä¢ UWP does not support the use of in the following syntax (throws a runtime error): Maybe the word is now reserved? Changing the bound property name to fixed this problem. Other bound terms such as and did not have this problem.\n‚Ä¢ UWP resources are addressed differently, requiring an absolute Uri. For example,\n‚Ä¢ A Canvas can no longer be clipped to an ellipse geometry - the lone instance was replaced with properly computed clipped points.\n‚Ä¢ UWP cannot \"get\" a non-existent ControlTemplate (throws an exception) so requested templates are now checked for existence.\n‚Ä¢ Minor changes were required in property values such as:\n‚Ä¢ The UWP Bing map does not scale map tiles according to a web Mercator projection. Therefore, MilGraphic objects are no longer properly scaled. This might be fixable but the high refresh latency makes the usefulness questionable.\n‚Ä¢ Location‚Äôs Latitude and Longitude are now readonly.\n‚Ä¢ XAML symbology objects were enclosed in Borders to render them properly. A MapParent property was added to the MilGraphic and MapMilSymbol objects to maintain a reference to the Border object.\n\nIn Figure 1, the base of each bounding box remains located at the user-specified point as the map zooms and the symbol resizes. The example includes commented out code to add labels. The bounding box automatically exapnds to encompass the labels. All test map programs use the same C# rendering codebase, the TestMapDrawing class. Most of the common symbology code is located in the Silverlight directory and linked to the various projects.\n\n \n\n \n\n Figure 2a: Zoomed map output showing two- and three-point symbololgy.\n\nIn Figure 2a, the map shows a subset of the supported symbols that require a fixed number of anchor points. Sometimes these values represent points and sometimes they represent points and measures such as radii or lengths. The PlotSymbol method in the TestMapDrawing class has code commented out code that draws the base vectors that define these symbols. This is useful to verify that the symbols are being drawn correctly relative to their defining points.\n\nIn Figure 2b, the map shows a subset of the supported symbols that use multiple points to define polylines or polygons. The PlotSymbol method in the TestMapDrawing class has code commented out code that draws the base vectors that define these symbols.\n\n\n\n Figure 2c: Zoomed in tactical graphics showing the presence of text elements when zoomed in past a certain point with OpenStreetMap background. The spline flag is set on one graphic.\n\nIn Figure 2c, the map shows a zoomed section of the available multi-point symbology. One graphic illustrates using the isSpline property in the MilGraphic class.\n\nMiSym includes a third-party contribution for a PNG-based military symbology generator. The project is called MilSymService and is part of the MilSym solution. After building the project, there will be both an install.cmd and a uninstall.cmd file in the same directory as the MilSymService.exe file. To start the service running, run as administrator and execute the install.cmd file. By default the project will install using port number 8765 and will be called ‚Äúmilsym.‚Äù\n\nThere is no unit test for this service. To test the service, start it and enter a URL in your browser such as http://localhost:8765/milsym/SJAPMFRZ--MS***?scale=0.20.\n‚Ä¢ fillColor: can set symbol fill color as an HTML5 color name or as a hex string - e.g., Orange or 0xff00ff.\n‚Ä¢ lineColor: can set symbol outline color as an HTML5 color name or as a hex string.\n‚Ä¢ labeString: list of label names and values. Use commas to separate label/value pairs and colons to separate labels from values but other separators are acceptable as long as they are consistent within the string.\n\nTo debug the service, set a breakpoint in the HandleRequests method in Services.cs and attach the debugger to the Military Symbol Service. The core code (in MilSymBitmap.cs) can also be used to support IIS.\n\nThe Fischer and UWP Bing map work were the last to be completed. Initial ports to Silverlight, WPF and UWP are complete. There are some abstractions to preserve a common code base. For example, ILocation, ILocationCollection, ILocationRect, and IMilSymLayer. A single factory with support for these types is injected.\n\nThe original ESRI map work was limited to WKIDs 102113 and 102100. Otherwise the generated tactical graphics didn't register properly witth their underlying vector definitions. For example, WKID 4326 compresses the latitude coordinate differently than WKID 102113. Support for other coordinate systems would require some abstraction of the coordinate mapping. The current technique of using ScaleTransform to properly size the results also limits potential coordinate mappings.\n\nThe Fischer map work is complete for both WPF and UWP.\n\nThe Bing UWP map work is incomplete as that map uses a different (unexposed) definition for the actual zoom factor. It should be possible to dynamically compute the actual zoom factor for each latitude and each claimed zoom factor and apply that factor in MilGraphic's CanvasLayoutUpdated method.\n\nMulti-point symbology work is incomplete. The latest drop includes some work on two-, three- and multi-point symbols (arrows, zones, lines) from Appendix B. The original plan was to finish Appendix B's multi-point items, then Appendix C's multi-point items, then interactivity. Other possible improvements would have included dynamic loading of resources to reduce memory footprint.\n\nMiscellaneous MilSym computes content bounds for many single-point symbols to support their precise placement on the map.\n\n \n\n \n\n Figure 3: Sample output from Appendix G as displayed by the GraphicsTest project\\\n\nAlthough less, relevant, this project also supports the generation of the files necessary to support Microsoft's Silverlight Pivot Viewer. A JavaScript version of this program is now available at https://seajax.github.io.\n\n\n\n Figure 4: Sample output from PivotTest after PAuthor is used on generated CXML file\n\nResummarizing, this is the last of several plannned military symbology code drops corresponding to the various appendices in the MIL-STD 2525C standard. For those interested in symbology in general, the APP-6A Wikipedia article is a good introduction to military symbology.\n\n \n\n The original Silverlight code in this C# project now works in WPF and UWP. Most C# differences are managed through #if's. XAML dependencies have been isolated to specific files.\n\n \n\n This code drop covers Appendices A, B, C, D, E and G.\n‚Ä¢ The error handling in this version is incomplete. Most error handling is silent (or not present).\n\nHow Does It Work?\n\nThe workhorse of this application is a ResourceDictionary of ControlTemplates representing base symbols. A symbol code specifies a control template that is then rendered using either default or user-specified brushes for fills and outlines. The resulting symbol is then overlaid with label, echelon, mobility and other symbol decoration. The result is returned as a MilSymbol object whose base class is Canvas. The interesting symbology parameters are exposed as dependency properties.\n\nThe main class, MilSymbol, is in MilSymbol.cs. The sample test programs illustrate three different ways to create a military symbol:\n‚Ä¢ Calling a constructor with arguments ‚Äî as in GraphicsTest. All arguments, except for symbolCode, are optional\n\n2. Setting properties individually ‚Äî also in GraphicsTest, for example\n\n3. Binding through XAML ‚Äî as shown in BindingTest, for example\n‚Ä¢ SymbolCode ‚Äî the 15 character symbol code defined by MIL-STD 2525C. The symbol code is very complex and should be developed in accordance with the standards document. If the symbol code is not recognized, the MilSymbol will return an empty canvas. The Boolean property, Empty, denotes this state.\n‚Ä¢ LabelString ‚Äî a string representing the concatenated labels for the military symbol. For example, \"C=23;T=Some Comment;M=Hello World;Q=34;V=\". Any non-alphanumeric character can be used for the separators '=' and ';' including the same character for each. The example above includes five fields, C, T, M, Q and V. Add new labels or change old label values by setting LabelString to a new value. In the example, label V is cleared. By default there are no labels for a symbol.\n‚Ä¢ FillBrush ‚Äî the brush to be used to fill the background of the symbol. In the event that this value is null or not set, the default brush for the current color scheme for that symbol code will be used.\n‚Ä¢ LineBrush ‚Äî the brush to be used to outline the symbol. In the event that this value is null or not set, the default brush for the current color scheme for that symbol code will be used.\n‚Ä¢ Scale ‚Äî the size of the symbol relative to its default size of roughly 300√ó300 pixels. Good map values are typically in the range from 0.1 to 0.2. The default scale of 1.0 is quite large.\n‚Ä¢ Angle ‚Äî the angle at which the symbol is to be rendered, measured in degrees clockwise from map north. The standard requires that symbols be displayed upright except in certain cases but this is NOT enforced in the code.\n‚Ä¢ Bounds ‚Äî a readonly Rect that bounds the symbol and all of its decorations (including labels). The class MapMilSymbol in the MapTest sample application shows how to take this information and enclose a symbol in a polygon that points to that symbol's map location. As the map is resized the symbol and its containing polygon are also resized even as the polygon continues to point to the symbol's location. This example illustrates: adding another child (the enclosing polygon) element to the returned MilSymbol's children collection, setting a translate transform to move the symbol to the correct location within the polygon, and responding to the LayoutUpdated event to ensure that the symbol gets smaller as the user zooms out (using an arbitrary power law). Support for Bounds is incomplete as not all symbols (mostly those in Appendices B and C) compute the correct bounds.\n‚Ä¢ LabelStyle ‚Äî the Style to be used for external labels. Only the Foreground, FontFamily, FontSize, and FontWeight properties are relevant. Setting this value to null restores the default styles as listed in the LabelResources.xaml file. The default font is Arial which is a proportional font. Font sizes up to about 96px will yield reasonable results. These styles are cached so it is a good idea to reuse styles where possible.\n‚Ä¢ Label{[A-Z,AA-AZ]} ‚Äî the individual labels for a military symbol. In the following table the unsupported labels are in italics. Some values also support Appendix B's multi-point symbols. Some labels have mutliple values such as W and W1, used to denote a date range. This is most common in Appendix B.\n\nMilGraphic is based on Canvas and places multi-point tactical graphics on a map.\n\n \n\n An alternative, hybrid MilGraphic class of text and \"map polylines\" was also successfully implemented but its drawbacks outweighed its features. For example, multiple map objects (lines and text) must then be generated to support a single symbol code. and the MilGraphic class must then support a method to add these objects to the map on behalf of the user - a variance from the preferred interface contract.\n\n \n\n Currently, adding a MilGraphic to a BingMap object might look like this:\n\nwould have been required if a hybrid class had been adopted.\n\nThe Anchors establish the position for the graphic. Placing the graphic someplace else by calling the AddChild method of a MapLayer (with a position) will result in an incorrectly behaving graphic. The UpdateLayout event is processed whenever the map is zoomed to ensure that the correct scale factor is applied to the graphic. This approach depends on the fact that updating a simple scale transform is sufficient to maintain the correct appearance (location) of the graphic at varying zoom levels.\n\n \n\n A different mapping system might require a more complex transformation as will moving the graphic across the landscape (which will be supported through binding the Anchor collection).\n\n \n\n In the current MilGraphic class, a ControlTemplate is transformed according to the user-supplied Anchor points. An artifact of the original approach to the transform was that line widths did not scale evenly in all directions. So all geometries were converted to PathGeometries to eliminate the line width scaling issue. However future changes may be required to reduce rendering artifacts on text or other graphics primitives. The proper scaling of line widths remains under investigation.\n\n \n\n As previously mentioned, the MilGraphic class scales properly, and smoothly, when zooming. The setup matrix and map transformation computations to get to this point remain messy.\n\n \n\n The standard often uses the third specified point in a tactical graphic to set a length rather than to set an exact point. The code has been modified to use projected lengths in many places.\n\n \n\n As described above, the MilGraphic user interface is quite simple (also uses optional arguments):\\\n‚Ä¢ SymbolCode ‚Äî the 15 character symbol code defined by MIL-STD 2525C. The symbol code is very complex and should be developed in accordance with the standards document. If the symbol code is not recognized, the MilGraphic will return an empty canvas. The Boolean property, Empty, denotes this state.\n‚Ä¢ Anchors ‚Äî an array of Locations representing the points specified by MIL-STD 2525C to anchor the given graphic. Currently only some two and three point graphics are supported. Currently there is no support for MGRS or DMS coordinate input - only abstracted collections of WGS-84 decimal latitudes and longitudes.\n\nTwo point objects (there are many in Appendix B) are generally simpler than these three point objects. Deciding on proportionality remains an issue. For example, should a long arrow have a bigger head than a short arrow drawn at the same zoom level? The current approach is to scale the entire two point object proportionally.\n\n \n\n Many multi-point objects (e.g., weather fronts) are really just complex line styles. The rendering approach includes a hybrid of templates and code. Axis of advance is a good example.\n\nThe MilBrush class provides access to pre-defined static solid color Brushes as specified by MIL-STD 2525C. These are useful for filling symbol backgrounds.\n\n \n\n MilBrush supports the ColorScheme property. ColorSchemeProperty supports an enumerated set of color schemes ‚Äî Dark, Medium and Light. Once set, new symbols are drawn using that color scheme. The default color scheme is Light.\n\n \n\n Table 2 ColorSchemes with matching brush names\n\nThe symbol code descriptions are static methods that return user-friendly descriptions based on the symbol code.\n\n \n\n Table 3 Methods that support user-friendly descriptions of military symbol codes\n\nThis is the most comprehensive visual test. It runs through many of the code paths and generates four basic charts. Some versions of the program can compute a chart image checksum and compare it against future chart image checksums, but currently there is no initial checksum. The Check button computes the checksum and does the comparison. This and the maps are currently the only tests that run in UWP, WPF and Silverlight.\n‚Ä¢ GraphicsTest opens with a simple example of a single rotating military symbol that changes its symbol code periodically. It also displays its current angle. Click on any of the chart buttons to terminate this test.\n‚Ä¢ The Labels button exercises all of the currently supported labels. The test uses the Arial and Times New Roman fonts. The symbol arrows correspond to a Q field numeric value. Because Silverlight supports very feature rich tooltips, the need for a symbol to display more than a cursory amount of data is diminished.\n‚Ä¢ The Miscellaneous button draws a variety of symbols including various brushes for the interiors and edges of the symbols. Various echelon markings are also displayed.\n‚Ä¢ The Appendices combo box supports rendering all of the base symbols in the available appendix resource dictionaries. There are gaps because the standard has some symbol codes that lack any representation. The symbols are arranged in a hierarchy and the parent nodes of some hierarchies lack any generic symbol. The black band across the top of some symbols indicates that the symbol is for Space. The same symbol without the black band is for Air. These symbols are drawn in the same order as they are in their respective MIL-STD 2525C appendices.\n\n\n\n Figure 8: Some symbols in Appendix D\n\n \n\n \n\n Figure 9: Some symbols in Appendix C\n\n \n\n \n\n Figure 10: Some symbols in Appendix B\n‚Ä¢ The Mobility button illustrates the use of Modifier codes\n\nSome symbols in Appendix C require either an altitude or a depth value. The label field X (Altitude/Depth) was chosen to hold this value as a string representing meters. The following symbols use this value when plotting:\n‚Ä¢ The tropopause low symbol WAS-PLT---P---- (parsed as a double rounded to the nearest integer for display purposes)\n‚Ä¢ The tropopause high symbol WAS-PHT---P---- (parsed as a double rounded to the nearest integer for display purposes\n‚Ä¢ The tropopause level symbol WAS-WST-LVP---- (parsed as a double rounded to the nearest integer for display purposes\n‚Ä¢ The freezing level symbol WAS-WSF-LVP---- (parsed as a double rounded to the nearest integer for display purposes\n‚Ä¢ The soundings symbol WOS-HDS---P---- (parsed as the double meters.decimeters ‚Äî only the first digit after the decimal point is displayed)\n\nSee the Appendix C frame in GraphicsTest for examples.\n\nThe Miscellany frame in GraphicsTest includes examples of the tropical storm system symbols WAS-WSTSD-P----, WAS-WSTSS-P---- and WAS-WSTSH-P----.\n\n \n\n These symbols must be render-able in red (current), purple (future), or black (past) ‚Äî this is accomplished by using the fill and line brushes that are available as optional arguments to MilSymbol (if the brushes are null then the default value red is used).\n\n \n\n Additionally, the storm fins for these symbols must reverse direction when in the southern hemisphere ‚Äî this is accomplished by placing a negative sign on the MilSymbol scale parameter (this will left-to-right reverse any symbol).\n\nThe package uses the label field AA to support cloud cover for the wind symbols WAS-WC----P---- and WAS-WP----P----. Field AA was chosen because it represents content for the symbol's interior. Using the integer values (0-8) in this field represents cloud obscuration in 1/8's with| 0 |representing a clear sky and 8 representing an overcast sky. An additional value of 9 represents an obscured sky.\n\n \n\n The wind plot symbol WAS-WP----P---- requires additional fields to support wind speed, wind direction, and hemisphere.\n‚Ä¢ The label field Z (Speed) is used to represent a double value as the wind speed in knots. This is a null-able value so its absence is detected as \"no report\" and a barb is displayed with no wind speed.\n‚Ä¢ The label field Q (Direction of Movement Indicator) is used to represent a double value as the wind direction, measured clockwise in degrees from true north. If this value is not present or is invalid, no wind barb will be plotted.\n‚Ä¢ The label field Y (Location) is used to represent the southern or northern hemisphere via the values N (northern hemisphere) and S (southern hemisphere). The northern hemisphere is the default if this field is not present.\n\nSee the Miscellany frame in GraphicsTest for examples.\n\nThe binding test illustrates how one can use the dependency properties of the MilSymbol class to bind an ObservableCollection of business objects to a Panel (a Canvas in this case) as MilSymbols. Through the use of this binding, the plot is manipulated simply by changing the business data that is bound to the display. A feature of this approach is that simply adding or removing entities from the ObservableCollection will result in those entities being added or removed from the canvas.\n\n The example binding is defined in the MainPage.xaml for this sample and looks something like this:\n\nLabelH is generated by converting the double angle value into a string, including a degree mark.\n\n The example uses a Canvas as the Panel. A Bing map layer also derives from Panel. The only thing that would change for the Bing map would be that the Canvas.Top and Canvas.Left values would be replaced by something like the following where m: is the map reference and Position is a Location (or use a value converter to generate a Location object).\n\nThe actual collection of business objects is attached inside the XAML for the Canvas as follows:\n\nBasically what this says is that we have a business object referred to by the key SymbolItemsSource, which in this case is the class Symbols, and that Symbols has a collection called Items that is to be bound to the Canvas using the DataTemplate known by the key SymbolItemTemplate.\n\n MilSymbol's SymbolCode is especially nice for bindings because it is shorthand for a significant number of properties. Combining that with MilSymbol's LabelString for creating or modifying multiple labels simultaneously helps provide an efficient update mechanism.\n\n \n\n The boilerplate binding code for this example (BindStuff.cs) is due to Michael S. Scherotter at Microsoft. The transition of the Bing map from CTP to release may obviate the need for this particular approach.\\\n\nMapTest (Figure 2) illustrates some initial two- and three-point tactical graphics symbology as well as bounding boxes for single point symbology.\n\nThe tactical graphics can also be drawn with their backing vector(s). The red (or purple) vectors represent the original anchor points while the blue (or orange) vectors represent the transformed vectors supporting that particular tactical graphic based on an interpretation of the standard.\n\n \n\n \n\n Figure 13: Sample three point tactical graphic (G*TPWP----****X) using the MilGraphic interface, showing anchor point vectors\n\nThe MilSymUnitTest does not illustrate any particular features of the project. It exercises a number of class methods using the Silverlight unit test framework.\n\nThis first table is a list of the symbol codes from Appendix B that don't need to be implemented because there is no symbol associated with them.\n\nThis second table is a list of the symbol codes from Appendix B that haven't been implemented yet or that are not fully implemented. These symbols are not being worked.\n\nThis third table is a list of the symbol codes from Appendix B that have been fully implemented."
    },
    {
        "link": "https://learn.microsoft.com/en-us/uwp/api/windows.ui.input.inking.inkstrokebuilder?view=winrt-26100",
        "document": "Sets the default InkDrawingAttributes for all new ink strokes created after the current stroke.\n\nSetDefaultDrawingAttributes does not affect the current stroke, or any existing strokes."
    },
    {
        "link": "https://learn.microsoft.com/en-us/uwp/api/windows.ui.input.inking.inkstrokebuilder.-ctor?view=winrt-26100",
        "document": "Creates a new InkStrokeBuilder object that is used to construct InkStroke objects.\n\nFor Universal Windows app using Extensible Application Markup Language (XAML), we recommend using InkPresenter and the InkCanvas control instead of InkManager.\n\nUse CreateStrokeFromInkPoints and SetDefaultDrawingAttributes to programmatically build strokes for an InkPresenter."
    },
    {
        "link": "https://stackoverflow.com/questions/66949977/c-sharp-uwp-render-inkstrokes-in-inkcanvas-seperately",
        "document": "To learn more, see our tips on writing great answers .\n\nThanks for contributing an answer to Stack Overflow!\n\nBy clicking ‚ÄúPost Your Answer‚Äù, you agree to our terms of service and acknowledge you have read our privacy policy."
    },
    {
        "link": "https://github.com/MicrosoftDocs/winrt-api/blob/docs/windows.ui.input.inking/inkstrokebuilder.md",
        "document": "For Universal Windows app using Extensible Application Markup Language (XAML), we recommend using InkPresenter and the InkCanvas control instead of InkManager.\n\nUse CreateStrokeFromInkPoints and SetDefaultDrawingAttributes to programmatically build strokes for an InkPresenter.\n\nThis class is not agile, which means that you need to consider its threading model and marshaling behavior. For more info, see Threading and Marshaling (C++/CX) and Using Windows Runtime objects in a multithreaded environment (.NET).\n\nPen and stylus interactions, Get started: Support ink in your UWP app, Ink analysis sample (basic) (C#), Ink handwriting recognition sample (C#), Save and load ink strokes from an Ink Serialized Format (ISF) file, Save and load ink strokes from the clipboard, Ink toolbar location and orientation sample (basic), Ink toolbar location and orientation sample (dynamic), Coloring book sample, Family notes sample, Inking sample (JavaScript), Simple inking sample (C#/C++), Complex inking sample (C++), Ink analysis sample"
    },
    {
        "link": "https://stackoverflow.com/questions/47469759/how-can-i-draw-a-circle-with-inkstroke",
        "document": "If I understood your question correctly, you just want to use InkStroke to draw a ellipse and add these strokes of ellipse into InkCanvas. Then, you could get use these strokes for other purposes (e.g, save these strokes and use it for the next usage). If so, I could only tell you it's impossible. Because when you draw a similar ellipse on InkCanvas, you could use InkAnalyzer to convert it to ellipse, but it actually only returns four points to you. Jayden also has mentioned it on this thread: Add polygon/ellipse to inkcanvas in uwp\n\nBut as I said, if the reason of using inkstroke to draw ellipse is to save strokes for other purposes, I can give you another way. You could use win2D-UWP relevant APIs to draw ellipse on CanvasControl and save it as CanvasSvgDocument. Then, you could save it as a svg xml file. For the net usage, you could load this svg xml file by into CanvasControl.\n\nIf you're interested in CanvasSvgDocument, you could refer to SvgExample for more details."
    }
]