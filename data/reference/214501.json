[
    {
        "link": "https://tvm.apache.org/docs/reference/api/python/relax/relax.html",
        "document": "The Relax IR namespace containing the IR, type, operator, builder, vm, etc.\n• None args (list[tvm.runtime.NDArray] or list[np.ndarray]) – The arguments to the closure. Convenience function. Takes a function from the module and saves a that, when called, will invoke the function with the given arguments. The can be accessed from the module using . This is included to facilitate timing trials: Invoking the returned will have less overhead from dictionary lookups than normally running through the VM. If the saved name is taken, it can be overridden, though it cannot override the name of a function defined in the Relax source. This is really creating a closure, but the function has a different name to avoid confusion with (they are not meant to be used together).\n• None func_name (str) – The function that should be packaged up.\n• None saved_name (str) – The name that the resulting closure should be saved under.\n• None include_return (bool) – Whether the saved PackedFunc should return its output. If timing over RPC, it may not be desirable to send output between machines.\n• None args (List[Any]) – The arguments to package up with the function.\n• None kwargs (Dict[str, Any]) – Any named arguments to package up with the function Set the inputs to a function. This interface works when using VM over RPC by internally converting NDArray in the arguments to DLTensor, which is supported in RPC where remote could only have a minimal C runtime. Note: If is used, the function must be called using and the results must be obtained using .\n• None func_name (str) – The name of the function.\n• None args (List[tvm.runtime.NDArray] or List[np.ndarray]) – The arguments to the function.\n• None kwargs (dict of str to tvm.runtime.NDArray or np.ndarray) – Named arguments to the function. relax.Call the named function from the VM module using the arguments set using . It is an error to call without using first (even if it’s to set 0 inputs); conversely, if has been called, it is an error to call the function without using . The results of the call can be obtained by calling . func_name (str) – The name of the function to call. Get the value output by the function by the given name after a call of . It is an error to call this function without first calling . func_name (str) – The name of the function whose output should be fetched. ret – The result of the earlier call to the function via . If the result is a tuple, it returns a list of the fields. The fields are potentially also tuples, so these can be arbitrily nested. If instrument is present, the function will be called before/after each relax.Call instruction. The function have the following signature: The instrument takes the following parameters: - func: function object to be called. - func_symbol: the symbol name of the function. - before_run: whether it is before or after call. - ret_value: the return value of the call, only valid after run. - args: the arguments being passed to call. The instrument function can choose an integer, which corresponds to action direction for the following run. See VMInstrumentReturnKind for more details. instrument (tvm.runtime.PackedFunc) – A instrumentation function that get invoked every VM call instr. the possible return values in VM. Returns an evaluator that times a function in the module. This follows the same convention as time_evaluator in tvm.runtime.module. This can be used in combination with save_function() so that the timings avoid extra dictionary lookups.\n• None func_name (str) – The name of the function in the module.\n• None dev (Device) – The device we should run this function on.\n• None number (int) – The number of times to run this function for taking average. We call these runs as one of measurement.\n• None repeat (int, optional) – The number of times to repeat the measurement. In total, the function will be invoked (1 + number x repeat) times, where the first one is warm up and will be discarded. The returned result contains costs, each of which is an average of costs.\n• None min_repeat_ms (int, optional) – The minimum duration of one in milliseconds. By default, one contains runs. If this parameter is set, the parameters will be dynamically adjusted to meet the minimum duration requirement of one . i.e., When the run time of one falls below this time, the parameter will be automatically increased.\n• None cooldown_interval_ms (int, optional) – The cooldown interval in milliseconds between the number of repeats defined by .\n• None repeats_to_cooldown (int, optional) – The number of repeats before the cooldown is activated.\n• None f_preproc (str, optional) – The preprocess function name we want to execute before executing the time evaluator. The function will be invoked (1 + number x repeat) times, with the first call discarded in case there is lazy initialization. Normal use with a VM function (may not work over RPC if the function returns a tuple): Use with the stateful API: With saved closures via (this results in fewer dictionary lookups in the timed portion): ftimer – The function that takes same argument as func and returns a BenchmarkResult. The ProfileResult reports time costs in seconds.\n• None func_name (str) – The name of the function.\n• None args (List of NDArray or other objects supported by PackedFunc.) – The arguments to the function.\n\nrelax.Call a TIR PrimFunc and return the result, doing the specified computations in-place (based on the argument; outputs will alias the inputs selected by in-place indices). Warning: This operator is considered pure by the type system but actually mutates the arguments specified by . This operator should not be used directly, but rather should be inserted by passes that have checked whether it is safe to perform operations in-place (i.e., none of the arguments specified as an output is aliased or is live after calling call_tir_inplace). Direct calls to this operator should be done for testing purposes only.\n• None inplace_indices (Union[int, List[int]]) – Specify which arguments should be used for in-place computations. If is a single integer, it will be made into a singleton list. Suppose , where . Then the i`th output will be an alias of `args[j] . If , then the i`th output will be a freshly allocated tensor. At least one member of `inplace_indices must not be -1.\n• None out_sinfo (Union[TensorStructInfo, List[TensorStructInfo]]) – The structure info of the call_tir_inplace output. It should be a single or a list of . Each one denotes the structure info of a returned tensor. If a list of is given, the result will be a tuple of .\n• None tir_vars (Optional[Union[ShapeExpr, Tuple[PrimExpr], List[PrimExpr]]]) – ShapeExpr representing a tuple of integers to unpack when calling func. Is null if not used\n\nAn abstract ExprVisitor with customized methods on the python-side. This is the user facing class for method overwriting inheritance. _tvm_metadata discribes the class to inherit(“cls”), the methods that users can overwrite(“methods”). Note: @relax.expr_functor.visitor is required for proper usage of any inherited class. Generic dispatcher for Expr. Users can customized this function to overwrite VisitExpr(const Expr& expr) on the C++ side. expr (Expr) – The expr to be visited. Generic dispatcher for Binding. Users can customized this function to overwrite VisitBinding(const Binding& binding) on the C++ side. binding (Binding) – The binding to be visited. Generic dispatcher for BindingBlock. Users can customized this function to overwrite VisitBindingBlock(const BindingBlock& block) on the C++ side. block (BindingBlock) – The block to be visited. Generic dispatcher for visiting the var definition site. Users can customized this function to overwrite VisitVarDef(const relax.Var& var) on the C++ side. Note that visit_var_() will only visit the usage site of an Var. var (relax.Var) – The var to be visited. Visit Constant. Users can customized this function to overwrite VisitExpr_(const ConstantNode* op) on the C++ side. op (Constant) – The Constant to be visited. Visit Tuple. Users can customized this function to overwrite VisitExpr_(const TupleNode* op) on the C++ side. op (Tuple) – The Tuple to be visited. Visit Var. Users can customized this function to overwrite VisitExpr_(const VarNode* op) on the C++ side. op (relax.Var) – The relax.Var to be visited. Visit DataflowVar. Users can customized this function to overwrite VisitExpr_(const DataflowVarNode* op) on the C++ side. op (DataflowVar) – The DataflowVar to be visited. Visit ShapeExpr. Users can customized this function to overwrite VisitExpr_(const ShapeExprNode* op) on the C++ side. op (ShapeExpr) – The ShapeExpr to be visited. Visit ExternFunc. Users can customized this function to overwrite VisitExpr_(const ExternFuncNode* op) on the C++ side. op (ExternFunc) – The ExternFunc to be visited. Visit GlobalVar. Users can customized this function to overwrite VisitExpr_(const GlobalVarNode* op) on the C++ side. op (GlobalVar) – The GlobalVar to be visited. Visit Function. Users can customized this function to overwrite VisitExpr_(const FunctionNode* op) on the C++ side. op (Function) – The Function to be visited. Visit Call. Users can customized this function to overwrite VisitExpr_(const CallNode* op) on the C++ side. op (relax.Call) – The relax.Call to be visited. Visit SeqExpr. Users can customized this function to overwrite VisitExpr_(const SeqExprNode* op) on the C++ side. op (SeqExpr) – The SeqExpr to be visited. Visit If. Users can customized this function to overwrite VisitExpr_(const IfNode* op) on the C++ side. op (If) – The If to be visited. Visit Op. Users can customized this function to overwrite VisitExpr_(const OpNode* op) on the C++ side. op (Op) – The Op to be visited. Visit TupleGetItem. Users can customized this function to overwrite VisitExpr_(const TupleGetItemNode* op) on the C++ side. op (TupleGetItem) – The TupleGetItem to be visited. Visit PrimValue. Users can customized this function to overwrite VisitExpr_(const PrimValueNode* op) on the C++ side. op (PrimValue) – The PrimValue to be visited. Visit StringImm. Users can customized this function to overwrite VisitExpr_(const StringImmNode* op) on the C++ side. op (StringImm) – The StringImm to be visited. Visit DataTypeImm. Users can customized this function to overwrite VisitExpr_(const DataTypeImmNode* op) on the C++ side. op (DataTypeImm) – The DataTypeImm to be visited. Visit VarBinding. Users can customized this function to overwrite VisitBinding_(const VarBindingNode* binding) on the C++ side. binding (VarBinding) – The VarBinding to be visited. Visit MatchCast. Users can customized this function to overwrite VisitBinding_(const MatchCastNode* binding) on the C++ side. binding (MatchCast) – The MatchCast to be visited. Visit BindingBlock. Users can customized this function to overwrite VisitBindingBlock_(const BindingBlockNode* block) on the C++ side. block (BindingBlock) – The BindingBlock to be visited. Visit DataflowBlock. Users can customized this function to overwrite VisitBindingBlock_(const DataflowBlockNode* block) on the C++ side. block (DataflowBlock) – The DataflowBlock to be visited. Visit the relax.Var definition site. Users can customized this function to overwrite VisitVarDef_(const VarNode* var) on the C++ side. var (relax.Var) – The relax.Var to be visited. Visit the DataflowVar definition site. Users can customized this function to overwrite VisitVarDef_(const DataflowVarNode* var) on the C++ side. var (DataflowVar) – The DataflowVar to be visited. Visit Span. Users can customized this function to overwrite VisitSpan(const Span& span) on the C++ side. span (Span) – The Span to be visited.\n\nAn abstract ExprMutator with customized methods on the python-side. This is the user facing class for method overwriting inheritance. _tvm_metadata discribes the class to inherit(“cls”), the methods that users can overwrite(“methods”), the constructor’s parameters(“fields”) Note: @relax.expr_functor.mutator is required for proper usage of any inherited class. Generic dispatcher for Expr. Users can customized this function to overwrite VisitExpr(const Expr& expr) on the C++ side. expr (Expr) – The expr to be visited. Generic dispatcher for Binding. Users can customized this function to overwrite VisitBinding(const Binding& binding) on the C++ side. binding (Binding) – The binding to be visited. Generic dispatcher for BindingBlock. Users can customized this function to overwrite VisitBindingBlock(const BindingBlock& block) on the C++ side. block (BindingBlock) – The block to be visited. Generic dispatcher for visiting the var definition site. Users can customized this function to overwrite VisitVarDef(const relax.Var& var) on the C++ side. Note that visit_var_() will only visit the usage site of an Var. var (relax.Var) – The var to be visited. Visit Constant. Users can customized this function to overwrite VisitExpr_(const ConstantNode* op) on the C++ side. op (Constant) – The Constant to be visited. Visit Tuple. Users can customized this function to overwrite VisitExpr_(const TupleNode* op) on the C++ side. op (Tuple) – The Tuple to be visited. Visit Var. Users can customized this function to overwrite VisitExpr_(const VarNode* op) on the C++ side. op (relax.Var) – The relax.Var to be visited. Visit DataflowVar. Users can customized this function to overwrite VisitExpr_(const DataflowVarNode* op) on the C++ side. op (DataflowVar) – The DataflowVar to be visited. Visit ShapeExpr. Users can customized this function to overwrite VisitExpr_(const ShapeExprNode* op) on the C++ side. op (ShapeExpr) – The ShapeExpr to be visited. Visit ExternFunc. Users can customized this function to overwrite VisitExpr_(const ExternFuncNode* op) on the C++ side. op (ExternFunc) – The ExternFunc to be visited. Visit GlobalVar. Users can customized this function to overwrite VisitExpr_(const GlobalVarNode* op) on the C++ side. op (GlobalVar) – The GlobalVar to be visited. Visit Function. Users can customized this function to overwrite VisitExpr_(const FunctionNode* op) on the C++ side. op (Function) – The Function to be visited. Visit Call. Users can customized this function to overwrite VisitExpr_(const CallNode* op) on the C++ side. op (relax.Call) – The relax.Call to be visited. Visit SeqExpr. Users can customized this function to overwrite VisitExpr_(const SeqExprNode* op) on the C++ side. op (SeqExpr) – The SeqExpr to be visited. Visit If. Users can customized this function to overwrite VisitExpr_(const IfNode* op) on the C++ side. op (If) – The If to be visited. Visit Op. Users can customized this function to overwrite VisitExpr_(const OpNode* op) on the C++ side. op (Op) – The Op to be visited. Visit TupleGetItem. Users can customized this function to overwrite VisitExpr_(const TupleGetItemNode* op) on the C++ side. op (TupleGetItem) – The TupleGetItem to be visited. Visit PrimValue. Users can customized this function to overwrite VisitExpr_(const PrimValueNode* op) on the C++ side. op (PrimValue) – The PrimValue to be visited. Visit StringImm. Users can customized this function to overwrite VisitExpr_(const StringImmNode* op) on the C++ side. op (StringImm) – The StringImm to be visited. Visit DataTypeImm. Users can customized this function to overwrite VisitExpr_(const DataTypeImmNode* op) on the C++ side. op (DataTypeImm) – The DataTypeImm to be visited. Visit VarBinding. Users can customized this function to overwrite VisitBinding_(const VarBindingNode* binding) on the C++ side. binding (VarBinding) – The VarBinding to be visited. Visit MatchCast. Users can customized this function to overwrite VisitBinding_(const MatchCastNode* binding) on the C++ side. binding (MatchCast) – The MatchCast to be visited. Visit BindingBlock. Users can customized this function to overwrite VisitBindingBlock_(const BindingBlockNode* block) on the C++ side. block (BindingBlock) – The BindingBlock to be visited. Visit DataflowBlock. Users can customized this function to overwrite VisitBindingBlock_(const DataflowBlockNode* block) on the C++ side. block (DataflowBlock) – The DataflowBlock to be visited. Visit the relax.Var definition site. Users can customized this function to overwrite VisitVarDef_(const VarNode* var) on the C++ side. var (relax.Var) – The relax.Var to be visited. Visit the DataflowVar definition site. Users can customized this function to overwrite VisitVarDef_(const DataflowVarNode* var) on the C++ side. var (DataflowVar) – The DataflowVar to be visited. Visit Span. Users can customized this function to overwrite VisitSpan(const Span& span) on the C++ side. span (Span) – The Span to be visited. expr (Expr) – The Expr to be rewritten. Remap a var to a new var in use-site.\n• None vid (Id) – The vid of the old var. Remap a var to a new var in use-site. vid (Id) – The vid of the old var Rewrite the expr with a new scope, used in a Function’s body and the branches of If. expr (Expr) – The expr to be visited. Look up the value bound to a variable. Note: For function parameters, this function returns NullOpt. var (relax.Var) – The var to be looked up. var – The value bound to the input var. Create a new var with specified shape and type if the original var’s shape or type does not match with the specified ones.\n• None var (relax.Var) – The var to be updated. var – The var filled with shape and type.\n\nDue to the immutable and copy-on-write nature of TVM AST nodes, the rewriting is not done in place. Instead, a new DataflowBlock is created and returned with mutated_dfb. Similarly, its new root Function is created and returned by mutated_root_fn. To apply this change for an IRModule, use mutate_irmodule which rewrites the old function that registered in the constructor. Replace all uses of old_var with new_var.\n• None old_var (relax.Var) – The old variable to replace.\n• None new_var (relax.Var) – The new variable to replace with. Add a new statement to the DataflowBlock with an automatically generated variable name.\n• None name (Optional[str], optional) – Variable name, by default None If the variable name is not given, it will be automatically generated in a form of “tmp${COUNTER}”. The variable type will be DataflowVar if is_dfvar is True, otherwise it will be Var. Being relax.Var means the variables are output variables of the DataflowBlock. While being DataflowVar means the variables are internal variables of the DataflowBlock. Remove a statement by its variable definition if and only if it is unused.\n• None allow_undef (bool, optional) – Whether to allow var being undefined variable, by default False TVMError if the variable is used or undefined (allow_undef=False). – This could remove unused variables in other DataflowBlocks as well. Return an updated IRModule by replacing the old function with the mutated root function."
    },
    {
        "link": "https://docs.python.org/3.11",
        "document": "What's new in Python 3.11?\n\n Or all \"What's new\" documents since Python 2.0\n\nTutorial\n\n Start here: a tour of Python's syntax and features\n\nPython setup and usage\n\n How to install, configure, and use Python"
    },
    {
        "link": "https://tvm.apache.org/docs//reference/api/python/relax/relax.html",
        "document": "The Relax IR namespace containing the IR, type, operator, builder, vm, etc.\n• None args (list[tvm.runtime.NDArray] or list[np.ndarray]) – The arguments to the closure. Convenience function. Takes a function from the module and saves a that, when called, will invoke the function with the given arguments. The can be accessed from the module using . This is included to facilitate timing trials: Invoking the returned will have less overhead from dictionary lookups than normally running through the VM. If the saved name is taken, it can be overridden, though it cannot override the name of a function defined in the Relax source. This is really creating a closure, but the function has a different name to avoid confusion with (they are not meant to be used together).\n• None func_name (str) – The function that should be packaged up.\n• None saved_name (str) – The name that the resulting closure should be saved under.\n• None include_return (bool) – Whether the saved PackedFunc should return its output. If timing over RPC, it may not be desirable to send output between machines.\n• None args (List[Any]) – The arguments to package up with the function.\n• None kwargs (Dict[str, Any]) – Any named arguments to package up with the function Set the inputs to a function. This interface works when using VM over RPC by internally converting NDArray in the arguments to DLTensor, which is supported in RPC where remote could only have a minimal C runtime. Note: If is used, the function must be called using and the results must be obtained using .\n• None func_name (str) – The name of the function.\n• None args (List[tvm.runtime.NDArray] or List[np.ndarray]) – The arguments to the function.\n• None kwargs (dict of str to tvm.runtime.NDArray or np.ndarray) – Named arguments to the function. relax.Call the named function from the VM module using the arguments set using . It is an error to call without using first (even if it’s to set 0 inputs); conversely, if has been called, it is an error to call the function without using . The results of the call can be obtained by calling . func_name (str) – The name of the function to call. Get the value output by the function by the given name after a call of . It is an error to call this function without first calling . func_name (str) – The name of the function whose output should be fetched. ret – The result of the earlier call to the function via . If the result is a tuple, it returns a list of the fields. The fields are potentially also tuples, so these can be arbitrily nested. If instrument is present, the function will be called before/after each relax.Call instruction. The function have the following signature: The instrument takes the following parameters: - func: function object to be called. - func_symbol: the symbol name of the function. - before_run: whether it is before or after call. - ret_value: the return value of the call, only valid after run. - args: the arguments being passed to call. The instrument function can choose an integer, which corresponds to action direction for the following run. See VMInstrumentReturnKind for more details. instrument (tvm.runtime.PackedFunc) – A instrumentation function that get invoked every VM call instr. the possible return values in VM. Returns an evaluator that times a function in the module. This follows the same convention as time_evaluator in tvm.runtime.module. This can be used in combination with save_function() so that the timings avoid extra dictionary lookups.\n• None func_name (str) – The name of the function in the module.\n• None dev (Device) – The device we should run this function on.\n• None number (int) – The number of times to run this function for taking average. We call these runs as one of measurement.\n• None repeat (int, optional) – The number of times to repeat the measurement. In total, the function will be invoked (1 + number x repeat) times, where the first one is warm up and will be discarded. The returned result contains costs, each of which is an average of costs.\n• None min_repeat_ms (int, optional) – The minimum duration of one in milliseconds. By default, one contains runs. If this parameter is set, the parameters will be dynamically adjusted to meet the minimum duration requirement of one . i.e., When the run time of one falls below this time, the parameter will be automatically increased.\n• None cooldown_interval_ms (int, optional) – The cooldown interval in milliseconds between the number of repeats defined by .\n• None repeats_to_cooldown (int, optional) – The number of repeats before the cooldown is activated.\n• None f_preproc (str, optional) – The preprocess function name we want to execute before executing the time evaluator. The function will be invoked (1 + number x repeat) times, with the first call discarded in case there is lazy initialization. Normal use with a VM function (may not work over RPC if the function returns a tuple): Use with the stateful API: With saved closures via (this results in fewer dictionary lookups in the timed portion): ftimer – The function that takes same argument as func and returns a BenchmarkResult. The ProfileResult reports time costs in seconds.\n• None func_name (str) – The name of the function.\n• None args (List of NDArray or other objects supported by PackedFunc.) – The arguments to the function.\n\nrelax.Call a TIR PrimFunc and return the result, doing the specified computations in-place (based on the argument; outputs will alias the inputs selected by in-place indices). Warning: This operator is considered pure by the type system but actually mutates the arguments specified by . This operator should not be used directly, but rather should be inserted by passes that have checked whether it is safe to perform operations in-place (i.e., none of the arguments specified as an output is aliased or is live after calling call_tir_inplace). Direct calls to this operator should be done for testing purposes only.\n• None inplace_indices (Union[int, List[int]]) – Specify which arguments should be used for in-place computations. If is a single integer, it will be made into a singleton list. Suppose , where . Then the i`th output will be an alias of `args[j] . If , then the i`th output will be a freshly allocated tensor. At least one member of `inplace_indices must not be -1.\n• None out_sinfo (Union[TensorStructInfo, List[TensorStructInfo]]) – The structure info of the call_tir_inplace output. It should be a single or a list of . Each one denotes the structure info of a returned tensor. If a list of is given, the result will be a tuple of .\n• None tir_vars (Optional[Union[ShapeExpr, Tuple[PrimExpr], List[PrimExpr]]]) – ShapeExpr representing a tuple of integers to unpack when calling func. Is null if not used\n\nAn abstract ExprVisitor with customized methods on the python-side. This is the user facing class for method overwriting inheritance. _tvm_metadata discribes the class to inherit(“cls”), the methods that users can overwrite(“methods”). Note: @relax.expr_functor.visitor is required for proper usage of any inherited class. Generic dispatcher for Expr. Users can customized this function to overwrite VisitExpr(const Expr& expr) on the C++ side. expr (Expr) – The expr to be visited. Generic dispatcher for Binding. Users can customized this function to overwrite VisitBinding(const Binding& binding) on the C++ side. binding (Binding) – The binding to be visited. Generic dispatcher for BindingBlock. Users can customized this function to overwrite VisitBindingBlock(const BindingBlock& block) on the C++ side. block (BindingBlock) – The block to be visited. Generic dispatcher for visiting the var definition site. Users can customized this function to overwrite VisitVarDef(const relax.Var& var) on the C++ side. Note that visit_var_() will only visit the usage site of an Var. var (relax.Var) – The var to be visited. Visit Constant. Users can customized this function to overwrite VisitExpr_(const ConstantNode* op) on the C++ side. op (Constant) – The Constant to be visited. Visit Tuple. Users can customized this function to overwrite VisitExpr_(const TupleNode* op) on the C++ side. op (Tuple) – The Tuple to be visited. Visit Var. Users can customized this function to overwrite VisitExpr_(const VarNode* op) on the C++ side. op (relax.Var) – The relax.Var to be visited. Visit DataflowVar. Users can customized this function to overwrite VisitExpr_(const DataflowVarNode* op) on the C++ side. op (DataflowVar) – The DataflowVar to be visited. Visit ShapeExpr. Users can customized this function to overwrite VisitExpr_(const ShapeExprNode* op) on the C++ side. op (ShapeExpr) – The ShapeExpr to be visited. Visit ExternFunc. Users can customized this function to overwrite VisitExpr_(const ExternFuncNode* op) on the C++ side. op (ExternFunc) – The ExternFunc to be visited. Visit GlobalVar. Users can customized this function to overwrite VisitExpr_(const GlobalVarNode* op) on the C++ side. op (GlobalVar) – The GlobalVar to be visited. Visit Function. Users can customized this function to overwrite VisitExpr_(const FunctionNode* op) on the C++ side. op (Function) – The Function to be visited. Visit Call. Users can customized this function to overwrite VisitExpr_(const CallNode* op) on the C++ side. op (relax.Call) – The relax.Call to be visited. Visit SeqExpr. Users can customized this function to overwrite VisitExpr_(const SeqExprNode* op) on the C++ side. op (SeqExpr) – The SeqExpr to be visited. Visit If. Users can customized this function to overwrite VisitExpr_(const IfNode* op) on the C++ side. op (If) – The If to be visited. Visit Op. Users can customized this function to overwrite VisitExpr_(const OpNode* op) on the C++ side. op (Op) – The Op to be visited. Visit TupleGetItem. Users can customized this function to overwrite VisitExpr_(const TupleGetItemNode* op) on the C++ side. op (TupleGetItem) – The TupleGetItem to be visited. Visit PrimValue. Users can customized this function to overwrite VisitExpr_(const PrimValueNode* op) on the C++ side. op (PrimValue) – The PrimValue to be visited. Visit StringImm. Users can customized this function to overwrite VisitExpr_(const StringImmNode* op) on the C++ side. op (StringImm) – The StringImm to be visited. Visit DataTypeImm. Users can customized this function to overwrite VisitExpr_(const DataTypeImmNode* op) on the C++ side. op (DataTypeImm) – The DataTypeImm to be visited. Visit VarBinding. Users can customized this function to overwrite VisitBinding_(const VarBindingNode* binding) on the C++ side. binding (VarBinding) – The VarBinding to be visited. Visit MatchCast. Users can customized this function to overwrite VisitBinding_(const MatchCastNode* binding) on the C++ side. binding (MatchCast) – The MatchCast to be visited. Visit BindingBlock. Users can customized this function to overwrite VisitBindingBlock_(const BindingBlockNode* block) on the C++ side. block (BindingBlock) – The BindingBlock to be visited. Visit DataflowBlock. Users can customized this function to overwrite VisitBindingBlock_(const DataflowBlockNode* block) on the C++ side. block (DataflowBlock) – The DataflowBlock to be visited. Visit the relax.Var definition site. Users can customized this function to overwrite VisitVarDef_(const VarNode* var) on the C++ side. var (relax.Var) – The relax.Var to be visited. Visit the DataflowVar definition site. Users can customized this function to overwrite VisitVarDef_(const DataflowVarNode* var) on the C++ side. var (DataflowVar) – The DataflowVar to be visited. Visit Span. Users can customized this function to overwrite VisitSpan(const Span& span) on the C++ side. span (Span) – The Span to be visited.\n\nAn abstract ExprMutator with customized methods on the python-side. This is the user facing class for method overwriting inheritance. _tvm_metadata discribes the class to inherit(“cls”), the methods that users can overwrite(“methods”), the constructor’s parameters(“fields”) Note: @relax.expr_functor.mutator is required for proper usage of any inherited class. Generic dispatcher for Expr. Users can customized this function to overwrite VisitExpr(const Expr& expr) on the C++ side. expr (Expr) – The expr to be visited. Generic dispatcher for Binding. Users can customized this function to overwrite VisitBinding(const Binding& binding) on the C++ side. binding (Binding) – The binding to be visited. Generic dispatcher for BindingBlock. Users can customized this function to overwrite VisitBindingBlock(const BindingBlock& block) on the C++ side. block (BindingBlock) – The block to be visited. Generic dispatcher for visiting the var definition site. Users can customized this function to overwrite VisitVarDef(const relax.Var& var) on the C++ side. Note that visit_var_() will only visit the usage site of an Var. var (relax.Var) – The var to be visited. Visit Constant. Users can customized this function to overwrite VisitExpr_(const ConstantNode* op) on the C++ side. op (Constant) – The Constant to be visited. Visit Tuple. Users can customized this function to overwrite VisitExpr_(const TupleNode* op) on the C++ side. op (Tuple) – The Tuple to be visited. Visit Var. Users can customized this function to overwrite VisitExpr_(const VarNode* op) on the C++ side. op (relax.Var) – The relax.Var to be visited. Visit DataflowVar. Users can customized this function to overwrite VisitExpr_(const DataflowVarNode* op) on the C++ side. op (DataflowVar) – The DataflowVar to be visited. Visit ShapeExpr. Users can customized this function to overwrite VisitExpr_(const ShapeExprNode* op) on the C++ side. op (ShapeExpr) – The ShapeExpr to be visited. Visit ExternFunc. Users can customized this function to overwrite VisitExpr_(const ExternFuncNode* op) on the C++ side. op (ExternFunc) – The ExternFunc to be visited. Visit GlobalVar. Users can customized this function to overwrite VisitExpr_(const GlobalVarNode* op) on the C++ side. op (GlobalVar) – The GlobalVar to be visited. Visit Function. Users can customized this function to overwrite VisitExpr_(const FunctionNode* op) on the C++ side. op (Function) – The Function to be visited. Visit Call. Users can customized this function to overwrite VisitExpr_(const CallNode* op) on the C++ side. op (relax.Call) – The relax.Call to be visited. Visit SeqExpr. Users can customized this function to overwrite VisitExpr_(const SeqExprNode* op) on the C++ side. op (SeqExpr) – The SeqExpr to be visited. Visit If. Users can customized this function to overwrite VisitExpr_(const IfNode* op) on the C++ side. op (If) – The If to be visited. Visit Op. Users can customized this function to overwrite VisitExpr_(const OpNode* op) on the C++ side. op (Op) – The Op to be visited. Visit TupleGetItem. Users can customized this function to overwrite VisitExpr_(const TupleGetItemNode* op) on the C++ side. op (TupleGetItem) – The TupleGetItem to be visited. Visit PrimValue. Users can customized this function to overwrite VisitExpr_(const PrimValueNode* op) on the C++ side. op (PrimValue) – The PrimValue to be visited. Visit StringImm. Users can customized this function to overwrite VisitExpr_(const StringImmNode* op) on the C++ side. op (StringImm) – The StringImm to be visited. Visit DataTypeImm. Users can customized this function to overwrite VisitExpr_(const DataTypeImmNode* op) on the C++ side. op (DataTypeImm) – The DataTypeImm to be visited. Visit VarBinding. Users can customized this function to overwrite VisitBinding_(const VarBindingNode* binding) on the C++ side. binding (VarBinding) – The VarBinding to be visited. Visit MatchCast. Users can customized this function to overwrite VisitBinding_(const MatchCastNode* binding) on the C++ side. binding (MatchCast) – The MatchCast to be visited. Visit BindingBlock. Users can customized this function to overwrite VisitBindingBlock_(const BindingBlockNode* block) on the C++ side. block (BindingBlock) – The BindingBlock to be visited. Visit DataflowBlock. Users can customized this function to overwrite VisitBindingBlock_(const DataflowBlockNode* block) on the C++ side. block (DataflowBlock) – The DataflowBlock to be visited. Visit the relax.Var definition site. Users can customized this function to overwrite VisitVarDef_(const VarNode* var) on the C++ side. var (relax.Var) – The relax.Var to be visited. Visit the DataflowVar definition site. Users can customized this function to overwrite VisitVarDef_(const DataflowVarNode* var) on the C++ side. var (DataflowVar) – The DataflowVar to be visited. Visit Span. Users can customized this function to overwrite VisitSpan(const Span& span) on the C++ side. span (Span) – The Span to be visited. expr (Expr) – The Expr to be rewritten. Remap a var to a new var in use-site.\n• None vid (Id) – The vid of the old var. Remap a var to a new var in use-site. vid (Id) – The vid of the old var Rewrite the expr with a new scope, used in a Function’s body and the branches of If. expr (Expr) – The expr to be visited. Look up the value bound to a variable. Note: For function parameters, this function returns NullOpt. var (relax.Var) – The var to be looked up. var – The value bound to the input var. Create a new var with specified shape and type if the original var’s shape or type does not match with the specified ones.\n• None var (relax.Var) – The var to be updated. var – The var filled with shape and type.\n\nDue to the immutable and copy-on-write nature of TVM AST nodes, the rewriting is not done in place. Instead, a new DataflowBlock is created and returned with mutated_dfb. Similarly, its new root Function is created and returned by mutated_root_fn. To apply this change for an IRModule, use mutate_irmodule which rewrites the old function that registered in the constructor. Replace all uses of old_var with new_var.\n• None old_var (relax.Var) – The old variable to replace.\n• None new_var (relax.Var) – The new variable to replace with. Add a new statement to the DataflowBlock with an automatically generated variable name.\n• None name (Optional[str], optional) – Variable name, by default None If the variable name is not given, it will be automatically generated in a form of “tmp${COUNTER}”. The variable type will be DataflowVar if is_dfvar is True, otherwise it will be Var. Being relax.Var means the variables are output variables of the DataflowBlock. While being DataflowVar means the variables are internal variables of the DataflowBlock. Remove a statement by its variable definition if and only if it is unused.\n• None allow_undef (bool, optional) – Whether to allow var being undefined variable, by default False TVMError if the variable is used or undefined (allow_undef=False). – This could remove unused variables in other DataflowBlocks as well. Return an updated IRModule by replacing the old function with the mutated root function."
    },
    {
        "link": "https://docs.python.org/release/3.11.1",
        "document": ""
    },
    {
        "link": "https://docs.python.org/3/whatsnew/3.11.html",
        "document": "This article explains the new features in Python 3.11, compared to 3.10. Python 3.11 was released on October 24, 2022. For full details, see the changelog.\n\nWhen printing tracebacks, the interpreter will now point to the exact expression that caused the error, instead of just the line. For example: Previous versions of the interpreter would point to just the line, making it ambiguous which object was . These enhanced errors can also be helpful when dealing with deeply nested objects and multiple function calls: As well as complex arithmetic expressions: Additionally, the information used by the enhanced traceback feature is made available via a general API, that can be used to correlate bytecode instructions with source code location. This information can be retrieved using:\n• None The function in the C API. See PEP 657 for more details. (Contributed by Pablo Galindo, Batuhan Taskaya and Ammar Askar in bpo-43950.) This feature requires storing column positions in Code Objects, which may result in a small increase in interpreter memory usage and disk usage for compiled Python files. To avoid storing the extra information and deactivate printing the extra traceback information, use the command line option or the environment variable. PEP 654 introduces language features that enable a program to raise and handle multiple unrelated exceptions simultaneously. The builtin types and make it possible to group exceptions and raise them together, and the new syntax generalizes to match subgroups of exception groups. See PEP 654 for more details. PEP 678: Exceptions can be enriched with notes¶ The method is added to . It can be used to enrich exceptions with context information that is not available at the time when the exception is raised. The added notes appear in the default traceback. See PEP 678 for more details. The copy of the Python Launcher for Windows included with Python 3.11 has been significantly updated. It now supports company/tag syntax as defined in PEP 514 using the argument instead of the limited . This allows launching distributions other than , the one hosted on python.org. When using selectors, either company or tag can be omitted, but all installs will be searched. For example, will select the “best” tag registered for , while or will select the “best” distribution with tag . When using the legacy , , or arguments, all existing behaviour should be preserved from past versions, and only releases from will be selected. However, the suffix now implies “not 32-bit” (not necessarily x86-64), as there are multiple supported 64-bit platforms. 32-bit runtimes are detected by checking the runtime’s tag for a suffix. All releases of Python since 3.5 have included this in their 32-bit builds.\n\nThis section covers major changes affecting PEP 484 type hints and the module. PEP 484 previously introduced , enabling creation of generics parameterised with a single type. PEP 646 adds , enabling parameterisation with an arbitrary number of types. In other words, a is a variadic type variable, enabling variadic generics. This enables a wide variety of use cases. In particular, it allows the type of array-like structures in numerical computing libraries such as NumPy and TensorFlow to be parameterised with the array shape. Static type checkers will now be able to catch shape-related bugs in code that uses these libraries. See PEP 646 for more details. and provide a straightforward way to mark whether individual items in a must be present. Previously, this was only possible using inheritance. All fields are still required by default, unless the total parameter is set to , in which case all fields are still not-required by default. For example, the following specifies a with one required and one not-required key: # OK (year is not required) The following definition is equivalent: See PEP 655 for more details. The new annotation provides a simple and intuitive way to annotate methods that return an instance of their class. This behaves the same as the -based approach specified in PEP 484, but is more concise and easier to follow. Common use cases include alternative constructors provided as s, and methods that return : can also be used to annotate method parameters or attributes of the same type as their enclosing class. See PEP 673 for more details. The new annotation may be used to indicate that a function parameter can be of any literal string type. This allows a function to accept arbitrary literal string types, as well as strings created from other literal strings. Type checkers can then enforce that sensitive functions, such as those that execute SQL statements or shell commands, are called only with static arguments, providing protection against injection attacks. For example, a SQL query function could be annotated as follows: \"SELECT * FROM students WHERE name = See PEP 675 for more details. may be used to decorate a class, metaclass, or a function that is itself a decorator. The presence of tells a static type checker that the decorated object performs runtime “magic” that transforms a class, giving it -like behaviors. # The create_model decorator is defined by a library. # The create_model decorator can now be used to create new model classes: See PEP 681 for more details. PEP 563 may not be the future¶ PEP 563 Postponed Evaluation of Annotations (the future statement) that was originally planned for release in Python 3.10 has been put on hold indefinitely. See this message from the Steering Council for more information.\n\nCPython 3.11 is an average of 25% faster than CPython 3.10 as measured with the pyperformance benchmark suite, when compiled with GCC on Ubuntu Linux. Depending on your workload, the overall speedup could be 10-60%. This project focuses on two major areas in Python: Faster Startup and Faster Runtime. Optimizations not covered by this project are listed separately under Optimizations. Python caches bytecode in the __pycache__ directory to speed up module loading. Previously in 3.10, Python module execution looked like this: In Python 3.11, the core modules essential for Python startup are “frozen”. This means that their Code Objects (and bytecode) are statically allocated by the interpreter. This reduces the steps in module execution process to: Interpreter startup is now 10-15% faster in Python 3.11. This has a big impact for short-running programs using Python. Python frames, holding execution information, are created whenever Python calls a Python function. The following are new frame optimizations:\n• None Avoided memory allocation by generously re-using frame space on the C stack.\n• None Streamlined the internal frame struct to contain only essential information. Frames previously held extra debugging and memory management information. Old-style frame objects are now created only when requested by debuggers or by Python introspection functions such as and . For most user code, no frame objects are created at all. As a result, nearly all Python functions calls have sped up significantly. We measured a 3-7% speedup in pyperformance. During a Python function call, Python will call an evaluating C function to interpret that function’s code. This effectively limits pure Python recursion to what’s safe for the C stack. In 3.11, when CPython detects Python code calling another Python function, it sets up a new frame, and “jumps” to the new code inside the new frame. This avoids calling the C interpreting function altogether. Most Python function calls now consume no C stack space, speeding them up. In simple recursive functions like fibonacci or factorial, we observed a 1.7x speedup. This also means recursive functions can recurse significantly deeper (if the user increases the recursion limit with ). We measured a 1-3% improvement in pyperformance. PEP 659 is one of the key parts of the Faster CPython project. The general idea is that while Python is a dynamic language, most code has regions where objects and types rarely change. This concept is known as type stability. At runtime, Python will try to look for common patterns and type stability in the executing code. Python will then replace the current operation with a more specialized one. This specialized operation uses fast paths available only to those use cases/types, which generally outperform their generic counterparts. This also brings in another concept called inline caching, where Python caches the results of expensive operations directly in the bytecode. The specializer will also combine certain common instruction pairs into one superinstruction, reducing the overhead during execution. Python will only specialize when it sees code that is “hot” (executed multiple times). This prevents Python from wasting time on run-once code. Python can also de-specialize when code is too dynamic or when the use changes. Specialization is attempted periodically, and specialization attempts are not too expensive, allowing specialization to adapt to new circumstances. Binary add, multiply and subtract for common types such as , and take custom fast paths for their underlying types. Subscripting container types such as , and directly index the underlying data structures. Subscripting custom is also inlined similar to Inlined Python function calls. Calls to common builtin (C) functions and types such as and directly call their underlying C version. This avoids going through the internal calling convention. The object’s index in the globals/builtins namespace is cached. Loading globals and builtins require zero namespace lookups. Similar to loading global variables. The attribute’s index inside the class/object’s namespace is cached. In most cases, attribute loading will require zero namespace lookups. The actual address of the method is cached. Method loading now has no namespace lookups – even for classes with long inheritance chains. Specialized for common containers such as and . Avoids internal calling convention.\n• None Objects now require less memory due to lazily created object namespaces. Their namespace dictionaries now also share keys more freely. (Contributed Mark Shannon in bpo-45340 and bpo-40116.)\n• None “Zero-cost” exceptions are implemented, eliminating the cost of statements when no exception is raised. (Contributed by Mark Shannon in bpo-40222.)\n• None A more concise representation of exceptions in the interpreter reduced the time required for catching an exception by about 10%. (Contributed by Irit Katriel in bpo-45711.)\n• None ’s regular expression matching engine has been partially refactored, and now uses computed gotos (or “threaded code”) on supported platforms. As a result, Python 3.11 executes the pyperformance regular expression benchmarks up to 10% faster than Python 3.10. (Contributed by Brandt Bucher in gh-91404.) How should I write my code to utilize these speedups?¶ Write Pythonic code that follows common best practices; you don’t have to change your code. The Faster CPython project optimizes for common code patterns we observe. Will CPython 3.11 use more memory?¶ Maybe not; we don’t expect memory use to exceed 20% higher than 3.10. This is offset by memory optimizations for frame objects and object dictionaries as mentioned above. I don’t see any speedups in my workload. Why?¶ Certain code won’t have noticeable benefits. If your code spends most of its time on I/O operations, or already does most of its computation in a C extension library like NumPy, there won’t be significant speedups. This project currently benefits pure-Python workloads the most. Furthermore, the pyperformance figures are a geometric mean. Even within the pyperformance benchmarks, certain benchmarks have slowed down slightly, while others have sped up by nearly 2x! No. We’re still exploring other optimizations. Faster CPython explores optimizations for CPython. The main team is funded by Microsoft to work on this full-time. Pablo Galindo Salgado is also funded by Bloomberg LP to work on the project part-time. Finally, many contributors are volunteers from the community."
    },
    {
        "link": "https://stackoverflow.com/questions/7336802/how-to-avoid-circular-imports-in-python",
        "document": "Consider the following example python package where and depend on each other:\n\nCircular import dependencies typically fall into two categories depending on what you're trying to import and where you're using it inside each module. (And whether you're using python 2 or 3).\n\nIn some cases, just importing a module with a circular import dependency can result in errors even if you're not referencing anything from the imported module.\n\nThere are several standard ways to import a module in python\n\nUnfortunately, only the 1st and 4th options actually work when you have circular dependencies (the rest all raise or ). In general, you shouldn't be using the 4th syntax, since it only works in python2 and runs the risk of clashing with other 3rd party modules. So really, only the first syntax is guaranteed to work.\n\nEDIT: The and issues only occur in python 2. In python 3 the import machinery has been rewritten and all of these import statements (with the exception of 4) will work, even with circular dependencies. While the solutions in this section may help refactoring python 3 code, they are mainly intended for people using python 2.\n\nJust use the first import syntax above. The downside to this method is that the import names can get super long for large packages.\n\nI've seen this method used in lots of packages, but it still feels hacky to me, and I dislike that I can't look at the top of a module and see all its dependencies, I have to go searching through all the functions as well.\n\nThis also works, but has the same problem as the first method, where all the package and submodule calls get super long. It also has two major flaws -- it forces all the submodules to be imported, even if you're only using one or two, and you still can't look at any of the submodules and quickly see their dependencies at the top, you have to go sifting through functions.\n\nNow, while you may be able to import a module with a circular import dependency, you won't be able to import any objects defined in the module or actually be able to reference that imported module anywhere in the top level of the module where you're importing it. You can, however, use the imported module inside functions and code blocks that don't get run on import.\n\nFor example, this will work:\n\nGenerally, in most valid cases of circular dependencies, it's possible to refactor or reorganize the code to prevent these errors and move module references inside a code block."
    },
    {
        "link": "https://builtin.com/articles/python-circular-import",
        "document": "A Python circular import can occur when two or more modules mutually depend on each other. This can happen if each module tries to import the other before fully loading, leading to unpredictable behavior and runtime errors.\n\nTo avoid these issues, it’s essential to carefully consider the import statements in your code and use one of the methods described in the next section to break the cycle of imports. Below is an example of a Python circular import error statement.\n\nIf you encounter a Python circular import error in your code, there are a few methods you can try to eliminate it. Let’s take a look at each one below:\n\nOne way to avoid circular imports is to import the module inside a function, rather than at the top level of the module. This allows the module to be imported only when it’s needed, rather than when the module is first imported. For example:\n\nMore on PythonFix ModuleNotFoundError: No Module Named ‘Sklearn‘\n\nAnother way to avoid circular imports is to use the import as syntax. This allows you to import the module using a different name, which can then be used to reference the module within your code. For example:\n\n3. Move the Import to the End of the Module\n\nA third option is to move the import statement to the end of the module after all the other code has been defined. This ensures that the module has been fully defined before another module imports it. For example:\n\nAnother option for escaping circular imports is to use the library, which allows you to import a module dynamically at runtime. This can be useful if you are not sure which module needs to be imported until runtime. For example:\n\nMore on PythonGarbage Collection and Memory Management in Python\n\nAnother option is to create a common file that both modules can import from. This can help to break the cycle of imports and avoid circular imports. For example:\n\nNow instead of wasting hours trying to figure out what circular imports mean, you can try using any of these methods and you’ll be done in a jiffy. I recommend the fifth method. It works like a charm."
    },
    {
        "link": "https://medium.com/@hamana.hadrien/so-you-got-a-circular-import-in-python-e9142fe10591",
        "document": "Now that’s we’re done with the pointless gatekeeping and shaming, we still have that import issue to deal with. Here are some ideas to work around, and don’t feel guilty, really Python was not designed for large complex applications with many types and modules in the first place.\n\nCounter-intuitive solution: more modules to import from\n\nPython’s import system is still trying its best to mitigate the issue. You have to know that once fully imported, the module is cached, so any other import statements referencing to the same module will not need to go through the whole importing process again. That’s why you don’t run into those errors all the time, at least.\n\nThis can be used to our advantage. Notice the emphasis on *fully*: if the module can be imported to the last line fully once, it won’t be an issue anymore. It may be possible to move the class that is imported from 2 different places referencing each-other, to a new, 3rd one. Create a new file, put that class there, modify/create the import in the 2 original files to that new location. That new file would contain only that class (and unfortunately, the necessary imports for that one class to work), and as long as the class can be defined without also referencing from the original modules, it can be imported fully on its own. It doesn’t matter which one of the 2 importer loads it first anymore, you got your problem fixed in the most elegant way possible.\n\nThe trick does rely on the offending class to be self-contained enough to be relied on from many places, but not itself rely on others. Basically, try to convert it to a leaf in your import tree structure. Admittedly, that’s not always possible.\n\nReally, it would be nice if I could only define the logic to my import myself, I know better than the interpreter. Well you can, actually. Python is just that hacky.\n\nThe import cache can be accessed like a , and is found in . Here you have it. Go wild with your import logic.\n\nThere, it will only be available it if it’s cached already, avoiding any circular dependency. Particularly useful for re-exports that you don’t really need in the module, but feel much nicer to import from there instead of having to dig seven levels deeper into the module and updating every time that structure changes, with all the issues that may come with it (hello, you’re here).\n\nDo note, such module-level code is only executed once when the module itself is imported, so there may be limitations in how far that can actually take you.\n\ns are code, and Python doesn’t actually care if you wrote that code in the first lines of your module or inside the function that needs it. Functions are not executed at import time, only parsed, so imports inside functions are not resolved yet.They’ll only be imported when executed, which will likely after all modules have been imported and the cache is filled.\n\nThose kind of imports are called deferred imports. This solves many issues.\n\nJust like when importing a module, when the function is called, the import will check the cache, and if still not cached by that point, will try to fill it, like in did in the surrounding module. First time may be a full import and it’ll be cached, and further calls are then only cache hits.\n\nIf you’re at that point, it’s likely other parts of your code in the same module also need it, so that import line might be soon found repeated. Just take a deep breath, you’ll be fine. If there’s no other way around (or you don’t have 6 months of free time to refactor the whole system to just load a class), just do it. There may just not be a better way.\n\nDo note however that a function call at module level will be executed at that time. Trying to hide imports into such functions will still break, they’re just not deferred.\n\nThere is no god: import last\n\nReally, there is nothing that forces you to import at the top of the file. Conventions are just other other peoples’ opinions, man. Remember when I said “once a module has been fully loaded”? I lied. Once a class has been defined (indentation returned to module level), it can be used. Even if the whole module is not actually 100% defined. You can put the import for something that will reference back to the class right after that class is defined.\n\nBut if you know that you have to define this class first before importing another module, probably top-level imports can be altered to achieve the same thing in a way that feels much less hacky.\n\nAnd in case you need something from module 1 and module 2 to define type/function 3, instead of defining more in module 1 or 2, do consider a third file from which 1 and 2 can be imported independently.\n\nPeople claim that the problem is aggravated by using instead of only and then using . That’s not quite True. When it comes to the importing logic, both syntax will import the module, parse it, and if that module or one of its own dependencies refers back to where it was trying to import it before it is done with it, it will raise that same circular import error.\n\nNevertheless, people surely have tried to change their imports to the only version, and some saw that fixed their problem. What the hell am I on about? was bad, end of story, right?\n\nWell, think again and consider the following:\n\nYou get a on line 1. Hah, see, is bad!\n\nYou get an on line 2. Interesting.\n\nThe first line will only check that the module exists at all, putting its name in the cache, without checking what it’s in it yet. Then this:\n\nThis works. Hah, I knew was good! Wait, but how come wrapping it in function does it? That’s almost like…\n\nGuess what, this works too. Because it’s actually doing the same thing. Both are actually deferred imports.\n\nThe attribute lookup for a module will look into the cache, just like when executed. And it has to import it if it’s not there yet, and error if it refers back. I told you.\n\nOf course, the complex systems that get circular imports in the first place are more likely to only use those imported types inside functions than at module level like a plain script. This naturally contributes to the belief that was to blame when the syntax change fixes it. In truth, what solved it was to defer the import. The syntax used to do so matters little.\n\nFor the same reason, the method will not save you if you’re trying to use them for type hinting, as the types must be available at module level.\n\nUsing type hints with python 3.5+ can easily increase how many imports you do within your own modules to define those hints. Which multiplies the opportunities to run into circular import conflicts.\n\nIt’s even more painful that they need to be available when *defining* the function, so the deferred import trick can’t be used, they really have to be at module level.\n\nThankfully, the module has thought of a genius solution to that problem, and offered us: , a simple bool, defined at runtime, and that tools like mypy should consider as True. You can use it to define a conditional import. Python will still error at runtime with a if you have a hint with an unknown type, even if it’s actually in that conditional import block, so that’s not all.\n\nType hints can also be forward-looking, i.e, defined as plain strings, telling to linters to figure out later if there’s a type that matches that name. With that, the Python interpreter won’t complain at runtime. It’s useful if the other type it’s referring to is defined later in the module, or is the type itself, which would be still considered undefined. And it’s also useful if the type is only imported when is True, as that’s all the type checkers should see. Those tools are not bothered by circular dependencies because they just do not import things as code execution.\n\nYou can use it like this:\n\nThis can at least limit the impact of the increased import issues, as they are just… not loaded at runtime. It IS a conditional import, but that doesn’t need to go through the extremes of checking the cache or such. And you still get the full benefits of type checking tools.\n\nStaring at the beast: change the import order\n\nThe hard mode you want to avoid: having a deep look into the order in which each module is imported.\n\nIt is fairly hard to get a real idea of the order in which modules are actually resolved in the first place, but this is obviously key to solving the issue.\n\nTooling is pretty lacking for this, but some attempts were made, such as pycycle. It might be good for you, but unfortunately did not work on my project. Feel free to recommend other existing tools in the comments, or give this project some love.\n\nFor lack of better, I tend to put a at the top of all files, and that’ll print the name of the modules as they’re imported, so you can see the actual order. Enough to see wonders when launching your system.\n\nDebugging is also possible with breakpoints on the first line (or the specific import line). You might want to explicitly and watch for or , to check for presence in the cache. Partially initialized modules do show up, with the special variable as (which is how python knows it’s probably a circular import) and showing the classes and modules they have imported and/or defined so far as class variables.\n\nOnce you got a clearer idea of what you have at what point in time during the importing, it’s up to you to fix that order so needed modules are imported first before loading the one that will cycle back.\n\nTools like love to order imports from the standard library first, dependency second, and your own in a last group. And each group in alphabetical order. That’s neat and all, but sometimes that neat-looking order may not make sense to the actual module needs (ways to disable isort here). If something needs to be loaded first, put it first, regardless of the alphabetical order.\n\nYou can also enforce the order you need by defining them line by line in your , which will be looked at before going any deeper. Putting an import here will make sure that module is loaded first.\n\nThis is really a last resort however, that can more often than not create even more issues, as it forces imports, while you want to be as lazy as possible to have modules imported fully and maximize the cache usage.\n\nThat’s it. Those are all your tools. Use them wisely.\n\nThis example taken from StackOverflow:\n\nHere is how this one goes, starting from main: main imports foo. first line foo imports bar, (foo not fully loaded). first line bar imports foo, crash as it’s not fully loaded.\n\nFix 1: main imports bar first. main imports bar, first line bar imports foo (bar not fully loaded), foo imports bar, but does not resolve anything in it yet (it’s just an ). foo keeps going, fully loads, and returns to bar. bar keeps loading, fully loads, and returns to main. main line 2 imports foo, it’s already loaded, takes from cache. print. Solved.\n\nWhere the first fix may break: if foo tries to actually use bar’s . Or really anything from at module level. Both syntax and a later break at the circular import if not wrapped in a function.\n\nFix 2.1: define that inside foo, and import it in bar with a . This makes the module self-contained again. Problem fixed.\n\nFix 2.2, where you can’t define in foo somehow: deferred import. Our foo.py can look like this:\n\nor, same thing, different syntax, for those who prefer to see dots:\n\nIf it’s not at module level, it can be deferred.\n\nDo note however that a function call at module level will be executed at that time, so even trying to use a deferred import at that time will break. Maybe try moving that function call to the other module.\n\nPython’s import system is confusing, and solutions can honestly feel quite hacky. Python was designed as a scripting language, and has been taken far beyond that role. There are ways to work it, but for that, you need to understand how to make the best out of the cache in Python.\n\nTherefore, in Python, it is important to keep your modules as self-contained as possible, so that they can be imported fully and not be a problem anymore. This consideration should guide you towards many smaller modules. Some fundamental relationship may require deferring the import, moving code, or ultimately enforce a convenient order.\n\nAnd there’s nothing wrong with that. Of course classes interact with each-other. That’s all good. I can only wish you best of luck to import them safely."
    },
    {
        "link": "https://mend.io/blog/closing-the-loop-on-python-circular-import-issue",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/1556387/circular-import-dependency-in-python",
        "document": "The problem is that when running from a directory, by default only the packages that are sub directories are visible as candidate imports, so you cannot import a.b.d. You can however import b.d. since b is a sub package of a.\n\nIf you really want to import a.b.d in you can accomplish this by changing the system path to be one directory above a and change the import in to be import a.b.c.\n\nYour should look like this:\n\nAn additional difficulty arises when you want to run modules in c as scripts. Here the packages a and b do not exist. You can hack the in the c directory to point the sys.path to the top-level directory and then import in any modules inside c to be able to use the full path to import a.b.d. I doubt that it is good practice to import but it has worked for my use cases."
    }
]