[
    {
        "link": "https://tutorial.math.lamar.edu/classes/calciii/lagrangemultipliers.aspx",
        "document": "In the previous section we optimized (i.e. found the absolute extrema) a function on a region that contained its boundary. Finding potential optimal points in the interior of the region isn’t too bad in general, all that we needed to do was find the critical points and plug them into the function. However, as we saw in the examples finding potential optimal points on the boundary was often a fairly long and messy process.\n\nIn this section we are going to take a look at another way of optimizing a function subject to given constraint(s). The constraint(s) may be the equation(s) that describe the boundary of a region although in this section we won’t concentrate on those types of problems since this method just requires a general constraint and doesn’t really care where the constraint came from.\n\nSo, let’s get things set up. We want to optimize (i.e. find the minimum and maximum value of) a function, \\(f\\left( {x,y,z} \\right)\\), subject to the constraint \\(g\\left( {x,y,z} \\right) = k\\). Again, the constraint may be the equation that describes the boundary of a region or it may not be. The process is actually fairly simple, although the work can still be a little overwhelming at times.\n\nNotice that the system of equations from the method actually has four equations, we just wrote the system in a simpler form. To see this let’s take the first equation and put in the definition of the gradient vector to see what we get.\n\nIn order for these two vectors to be equal the individual components must also be equal. So, we actually have three equations here.\n\nThese three equations along with the constraint, \\(g\\left( {x,y,z} \\right) = c\\), give four equations with four unknowns \\(x\\), \\(y\\), \\(z\\), and \\(\\lambda \\).\n\nNote as well that if we only have functions of two variables then we won’t have the third component of the gradient and so will only have three equations in three unknowns \\(x\\), \\(y\\), and \\(\\lambda \\).\n\nAs a final note we also need to be careful with the fact that in some cases minimums and maximums won’t exist even though the method will seem to imply that they do. In every problem we’ll need to make sure that minimums and maximums will exist before we start the problem.\n\nTo see a physical justification for the formulas above let’s consider the minimum and maximum value of \\(f\\left( {x,y} \\right) = 8{x^2} - 2y\\) subject to the constraint \\({x^2} + {y^2} = 1\\). In the practice problems for this section (problem #2 to be exact) we will show that minimum value of \\(f\\left( {x,y} \\right)\\) is -2 which occurs at \\(\\left( {0,1} \\right)\\) and the maximum value of \\(f\\left( {x,y} \\right)\\) is 8.125 which occurs at \\(\\left( { - \\frac{{3\\sqrt 7 }}{8}, - \\frac{1}{8}} \\right)\\) and \\(\\left( {\\frac{{3\\sqrt 7 }}{8}, - \\frac{1}{8}} \\right)\\).\n\nHere is a sketch of the constraint as well as \\(f\\left( {x.y} \\right) = k\\) for various values of \\(k\\).\n\nFirst remember that solutions to the system must be somewhere on the graph of the constraint, \\({x^2} + {y^2} = 1\\) in this case. Because we are looking for the minimum/maximum value of \\(f\\left( {x,y} \\right)\\) this, in turn, means that the location of the minimum/maximum value of \\(f\\left( {x,y} \\right)\\), i.e. the point \\(\\left( {x,y} \\right)\\), must occur where the graph of \\(f\\left( {x,y} \\right) = k\\) intersects the graph of the constraint when \\(k\\) is either the minimum or maximum value of \\(f\\left( {x,y} \\right)\\).\n\nNow, we can see that the graph of \\(f\\left( {x,y} \\right) = - 2\\), i.e. the graph of the minimum value of \\(f\\left( {x,y} \\right)\\), just touches the graph of the constraint at \\(\\left( {0,1} \\right)\\). In fact, the two graphs at that point are tangent.\n\nIf the two graphs are tangent at that point then their normal vectors must be parallel, i.e. the two normal vectors must be scalar multiples of each other. Mathematically, this means,\n\nfor some scalar \\(\\lambda \\) and this is exactly the first equation in the system we need to solve in the method.\n\nNote as well that if \\(k\\) is smaller than the minimum value of \\(f\\left( {x,y} \\right)\\) the graph of \\(f\\left( {x,y} \\right) = k\\) doesn’t intersect the graph of the constraint and so it is not possible for the function to take that value of \\(k\\) at a point that will satisfy the constraint.\n\nLikewise, if \\(k\\) is larger than the minimum value of \\(f\\left( {x,y} \\right)\\) the graph of \\(f\\left( {x,y} \\right) = k\\) will intersect the graph of the constraint but the two graphs are not tangent at the intersection point(s). This means that the method will not find those intersection points as we solve the system of equations.\n\nNext, the graph below shows a different set of values of \\(k\\). In this case, the values of \\(k\\) include the maximum value of \\(f\\left( {x,y} \\right)\\) as well as a few values on either side of the maximum value.\n\nAgain, we can see that the graph of \\(f\\left( {x,y} \\right) = 8.125\\) will just touch the graph of the constraint at two points. This is a good thing as we know the solution does say that it should occur at two points. Also note that at those points again the graph of \\(f\\left( {x,y} \\right) = 8.125\\)and the constraint are tangent and so, just as with the minimum values, the normal vectors must be parallel at these points.\n\nLikewise, for value of \\(k\\) greater than 8.125 the graph of \\(f\\left( {x,y} \\right) = k\\) does not intersect the graph of the constraint and so it will not be possible for \\(f\\left( {x,y} \\right)\\) to take on those larger values at points that are on the constraint.\n\nAlso, for values of \\(k\\) less than 8.125 the graph of \\(f\\left( {x,y} \\right) = k\\) does intersect the graph of the constraint but will not be tangent at the intersection points and so again the method will not produce these intersection points as we solve the system of equations.\n\nSo, with these graphs we’ve seen that the minimum/maximum values of \\(f\\left( {x,y} \\right)\\) will come where the graph of \\(f\\left( {x,y} \\right) = k\\) and the graph of the constraint are tangent and so their normal vectors are parallel. Also, because the point must occur on the constraint itself. In other words, the system of equations we need to solve to determine the minimum/maximum value of \\(f\\left( {x,y} \\right)\\) are exactly those given in the above when we introduced the method.\n\nNote that the physical justification above was done for a two dimensional system but the same justification can be done in higher dimensions. The difference is that in higher dimensions we won’t be working with curves. For example, in three dimensions we would be working with surfaces. However, the same ideas will still hold. At the points that give minimum and maximum value(s) of the surfaces would be parallel and so the normal vectors would also be parallel.\n\nFind the dimensions of the box with largest volume if the total surface area is 64 cm2. Before we start the process here note that we also saw a way to solve this kind of problem in Calculus I, except in those problems we required a condition that related one of the sides of the box to the other sides so that we could get down to a volume and surface area function that only involved two variables. We no longer need this condition for these problems. Now, let’s get on to solving the problem. We first need to identify the function that we’re going to optimize as well as the constraint. Let’s set the length of the box to be \\(x\\), the width of the box to be \\(y\\) and the height of the box to be \\(z\\). Let’s also note that because we’re dealing with the dimensions of a box it is safe to assume that \\(x\\), \\(y\\), and \\(z\\) are all positive quantities. We want to find the largest volume and so the function that we want to optimize is given by, \\[f\\left( {x,y,z} \\right) = xyz\\] Next, we know that the surface area of the box must be a constant 64. So this is the constraint. The surface area of a box is simply the sum of the areas of each of the sides so the constraint is given by, \\[2xy + 2xz + 2yz = 64\\hspace{0.5in} \\Rightarrow \\hspace{0.5in}xy + xz + yz = 32\\] Note that we divided the constraint by 2 to simplify the equation a little. Also, we get the function \\(g\\left( {x,y,z} \\right)\\) from this. \\[g\\left( {x,y,z} \\right) = xy + xz + yz\\] The function itself, \\(f\\left( {x,y,z} \\right) = xyz\\) will clearly have neither minimums or maximums unless we put some restrictions on the variables. The only real restriction that we’ve got is that all the variables must be positive. This, of course, instantly means that the function does have a minimum, zero, even though this is a silly value as it also means we pretty much don’t have a box. It does however mean that we know the minimum of \\(f\\left( {x,y,z} \\right)\\) does exist. So, let’s now see if \\(f\\left( {x,y,z} \\right)\\) will have a maximum. Clearly, hopefully, \\(f\\left( {x,y,z} \\right)\\) will not have a maximum if all the variables are allowed to increase without bound. That however, can’t happen because of the constraint, \\[xy + xz + yz = 32\\] Here we’ve got the sum of three positive numbers (remember that we \\(x\\), \\(y\\), and \\(z\\) are positive because we are working with a box) and the sum must equal 32. So, if one of the variables gets very large, say \\(x\\), then because each of the products must be less than 32 both \\(y\\) and \\(z\\) must be very small to make sure the first two terms are less than 32. So, there is no way for all the variables to increase without bound and so it should make some sense that the function, \\(f\\left( {x,y,z} \\right) = xyz\\), will have a maximum. This is not an exact proof that \\(f\\left( {x,y,z} \\right)\\) will have a maximum but it should help to visualize that \\(f\\left( {x,y,z} \\right)\\) should have a maximum value as long as it is subject to the constraint. Here are the four equations that we need to solve. \\[\\begin{equation}yz = \\lambda \\left( {y + z} \\right)\\hspace{0.75in}\\left( {{f_x} = \\lambda {g_x}} \\right) \\label{eq:eq1}\\end{equation}\\] \\[\\begin{equation}xz = \\lambda \\left( {x + z} \\right)\\hspace{0.75in}\\left( {{f_y} = \\lambda {g_y}} \\right)\\label{eq:eq2}\\end{equation}\\] \\[\\begin{equation}xy = \\lambda \\left( {x + y} \\right)\\hspace{0.75in}\\left( {{f_z} = \\lambda {g_z}} \\right)\\label{eq:eq3}\\end{equation}\\] \\[\\begin{equation}xy + xz + yz = 32\\hspace{0.75in}\\left( {g\\left( {x,y,z} \\right) = 32} \\right) \\label{eq:eq4} \\end{equation}\\] \\[\\begin{equation}yz = \\lambda \\left( {y + z} \\right)\\hspace{0.75in}\\left( {{f_x} = \\lambda {g_x}} \\right) \\label{eq:eq1}\\end{equation}\\] \\[\\begin{equation}xz = \\lambda \\left( {x + z} \\right)\\hspace{0.75in}\\left( {{f_y} = \\lambda {g_y}} \\right)\\label{eq:eq2}\\end{equation}\\] \\[\\begin{equation}xy = \\lambda \\left( {x + y} \\right)\\hspace{0.75in}\\left( {{f_z} = \\lambda {g_z}} \\right)\\label{eq:eq3}\\end{equation}\\] \\[\\begin{equation}xy + xz + yz = 32\\hspace{0.75in}\\left( {g\\left( {x,y,z} \\right) = 32} \\right) \\label{eq:eq4} \\end{equation}\\] There are many ways to solve this system. We’ll solve it in the following way. Let’s multiply equation \\(\\eqref{eq:eq1}\\) by \\(x\\), equation \\(\\eqref{eq:eq2}\\) by \\(y\\) and equation \\(\\eqref{eq:eq3}\\) by \\(z\\). This gives, \\[\\begin{equation}xyz = \\lambda x\\left( {y + z} \\right)\\label{eq:eq5}\\end{equation}\\] \\[\\begin{equation}xyz = \\lambda y\\left( {x + z} \\right)\\label{eq:eq6}\\end{equation}\\] \\[\\begin{equation}xyz = \\lambda z\\left( {x + y} \\right)\\label{eq:eq7}\\end{equation}\\] Now notice that we can set equations \\(\\eqref{eq:eq5}\\) and \\(\\eqref{eq:eq6}\\) equal. Doing this gives, \\[\\begin{align*}\\lambda x\\left( {y + z} \\right) & = \\lambda y\\left( {x + z} \\right)\\\\ \\lambda \\left( {xy + xz} \\right) - \\lambda \\left( {yx + yz} \\right) &= 0\\\\ \\lambda \\left( {xz - yz} \\right) & = 0\\hspace{0.5in} \\Rightarrow \\hspace{0.5in}\\lambda = 0\\,\\,\\,\\,\\,\\,{\\mbox{or}}\\,\\,\\,\\,\\,xz = yz\\end{align*}\\] \\[\\begin{align*}\\lambda x\\left( {y + z} \\right) & = \\lambda y\\left( {x + z} \\right)\\\\ \\lambda \\left( {xy + xz} \\right) - \\lambda \\left( {yx + yz} \\right) &= 0\\\\ \\lambda \\left( {xz - yz} \\right) & = 0\\hspace{0.5in} \\Rightarrow \\hspace{0.5in}\\lambda = 0\\,\\,\\,\\,\\,\\,{\\mbox{or}}\\,\\,\\,\\,\\,xz = yz\\end{align*}\\] This gave two possibilities. The first, \\(\\lambda = 0\\) is not possible since if this was the case equation \\(\\eqref{eq:eq1}\\) would reduce to \\[yz = 0\\hspace{0.5in} \\Rightarrow \\hspace{0.25in}y = 0\\,\\,\\,{\\mbox{or}}\\,\\,\\,z = 0\\] Since we are talking about the dimensions of a box neither of these are possible so we can discount \\(\\lambda = 0\\). This leaves the second possibility. \\[xz = yz\\] Since we know that \\(z \n\ne 0\\) (again since we are talking about the dimensions of a box) we can cancel the \\(z\\) from both sides. This gives, \\[\\begin{equation}x = y\\label{eq:eq8}\\end{equation}\\] Next, let’s set equations \\(\\eqref{eq:eq6}\\) and \\(\\eqref{eq:eq7}\\) equal. Doing this gives, \\[\\begin{align*}\\lambda y\\left( {x + z} \\right) & = \\lambda z\\left( {x + y} \\right)\\\\ \\lambda \\left( {yx + yz - zx - zy} \\right) & = 0\\\\ \\lambda \\left( {yx - zx} \\right) & = 0\\hspace{0.5in} \\Rightarrow \\hspace{0.5in}\\lambda = 0\\,\\,\\,{\\mbox{or}}\\,\\,\\,\\,yx = zx\\end{align*}\\] \\[\\begin{align*}\\lambda y\\left( {x + z} \\right) & = \\lambda z\\left( {x + y} \\right)\\\\ \\lambda \\left( {yx + yz - zx - zy} \\right) & = 0\\\\ \\lambda \\left( {yx - zx} \\right) & = 0\\hspace{0.5in} \\Rightarrow \\hspace{0.5in}\\lambda = 0\\,\\,\\,{\\mbox{or}}\\,\\,\\,\\,yx = zx\\end{align*}\\] As already discussed we know that \\(\\lambda = 0\\) won’t work and so this leaves, \\[yx = zx\\] We can also say that \\(x \n\ne 0\\)since we are dealing with the dimensions of a box so we must have, \\[\\begin{equation}z = y\\label{eq:eq9}\\end{equation}\\] Plugging equations \\(\\eqref{eq:eq8}\\) and \\(\\eqref{eq:eq9}\\) into equation \\(\\eqref{eq:eq4}\\) we get, \\[{y^2} + {y^2} + {y^2} = 3{y^2} = 32\\hspace{0.5in}y = \\pm \\sqrt {\\frac{{32}}{3}} = \\pm \\,3.266\\] However, we know that \\(y\\) must be positive since we are talking about the dimensions of a box. Therefore, the only solution that makes physical sense here is \\[x = y = z = \\,3.266\\] So, it looks like we’ve got a cube. We should be a little careful here. Since we’ve only got one solution we might be tempted to assume that these are the dimensions that will give the largest volume. Anytime we get a single solution we really need to verify that it is a maximum (or minimum if that is what we are looking for). This is actually pretty simple to do. First, let’s note that the volume at our solution above is, Now, we know that a maximum of \\(f\\left( {x,y,z} \\right)\\) will exist (“proved” that earlier in the solution) and so to verify that that this really is a maximum all we need to do if find another set of dimensions that satisfy our constraint and check the volume. If the volume of this new set of dimensions is smaller that the volume above then we know that our solution does give a maximum. If, on the other hand, the new set of dimensions give a larger volume we have a problem. We only have a single solution and we know that a maximum exists and the method should generate that maximum. So, in this case, the likely issue is that we will have made a mistake somewhere and we’ll need to go back and find it. So, let’s find a new set of dimensions for the box. The only thing we need to worry about is that they will satisfy the constraint. Outside of that there aren’t other constraints on the size of the dimensions. So, we can freely pick two values and then use the constraint to determine the third value. Let’s choose \\(x = y = 1\\). No reason for these values other than they are “easy” to work with. Plugging these into the constraint gives, So, this is a set of dimensions that satisfy the constraint and the volume for this set of dimensions is, So, the new dimensions give a smaller volume and so our solution above is, in fact, the dimensions that will give a maximum volume of the box are \\(x = y = z = \\,3.266\\) Find the dimensions of the box with largest volume if the total surface area is 64 cm\n\nNotice that we never actually found values for \\(\\lambda \\) in the above example. This is fairly standard for these kinds of problems. The value of \\(\\lambda \\) isn’t really important to determining if the point is a maximum or a minimum so often we will not bother with finding a value for it. On occasion we will need its value to help solve the system, but even in those cases we won’t use it past finding the point.\n\nIn the first two examples we’ve excluded \\(\\lambda = 0\\) either for physical reasons or because it wouldn’t solve one or more of the equations. Do not always expect this to happen. Sometimes we will be able to automatically exclude a value of \\(\\lambda \\) and sometimes we won’t.\n\nLet’s take a look at another example.\n\nBefore we proceed we need to address a quick issue that the last example illustrates about the method of Lagrange Multipliers. We found the absolute minimum and maximum to the function. However, what we did not find is all the locations for the absolute minimum. For example, assuming \\(x,y,z\\ge 0\\), consider the following sets of points.\n\n\\[\\begin{array}{ll} \\left( 0,y,z \\right) & \\text{where}\\,\\,\\,\\,y+z=1 \\\\ \\left( x,0,z \\right) & \\text{where}\\,\\,\\,\\,x+z=1 \\\\ \\left( x,y,0 \\right) & \\text{where}\\,\\,\\,\\,x+y=1 \\\\ \\end{array}\\]\n\nEvery point in this set of points will satisfy the constraint from the problem and in every case the function will evaluate to zero and so also give the absolute minimum.\n\nSo, what is going on? Recall from the previous section that we had to check both the critical points and the boundaries to make sure we had the absolute extrema. The same was true in Calculus I. We had to check both critical points and end points of the interval to make sure we had the absolute extrema.\n\nIt turns out that we really need to do the same thing here if we want to know that we’ve found all the locations of the absolute extrema. The method of Lagrange multipliers will find the absolute extrema, it just might not find all the locations of them as the method does not take the end points of variables ranges into account (note that we might luck into some of these points but we can’t guarantee that).\n\nSo, after going through the Lagrange Multiplier method we should then ask what happens at the end points of our variable ranges. For the example that means looking at what happens if \\(x=0\\), \\(y=0\\), \\(z=0\\), \\(x=1\\), \\(y=1\\), and \\(z=1\\). In the first three cases we get the points listed above that do happen to also give the absolute minimum. For the later three cases we can see that if one of the variables are 1 the other two must be zero (to meet the constraint) and those were actually found in the example. Sometimes that will happen and sometimes it won’t.\n\nIn the case of this example the end points of each of the variable ranges gave absolute extrema but there is no reason to expect that to happen every time. In Example 2 above, for example, the end points of the ranges for the variables do not give absolute extrema (we’ll let you verify this).\n\nThe moral of this is that if we want to know that we have every location of the absolute extrema for a particular problem we should also check the end points of any variable ranges that we might have. If all we are interested in is the value of the absolute extrema then there is no reason to do this.\n\nOkay, it’s time to move on to a slightly different topic. To this point we’ve only looked at constraints that were equations. We can also have constraints that are inequalities. The process for these types of problems is nearly identical to what we’ve been doing in this section to this point. The main difference between the two types of problems is that we will also need to find all the critical points that satisfy the inequality in the constraint and check these in the function when we check the values we found using Lagrange Multipliers.\n\nLet’s work an example to see how these kinds of problems work.\n\nThe final topic that we need to discuss in this section is what to do if we have more than one constraint. We will look only at two constraints, but we can naturally extend the work here to more than two constraints.\n\nWe want to optimize \\(f\\left( {x,y,z} \\right)\\) subject to the constraints \\(g\\left( {x,y,z} \\right) = c\\) and \\(h\\left( {x,y,z} \\right) = k\\). The system that we need to solve in this case is,\n\n\\[\\begin{align*}\n\nabla f\\left( {x,y,z} \\right) & = \\lambda \n\nabla g\\left( {x,y,z} \\right) + \\mu \n\nabla h\\left( {x,y,z} \\right)\\\\ g\\left( {x,y,z} \\right) & = c\\\\ h\\left( {x,y,z} \\right) & = k\\end{align*}\\]\n\nSo, in this case we get two Lagrange Multipliers. Also, note that the first equation really is three equations as we saw in the previous examples. Let’s see an example of this kind of optimization problem."
    },
    {
        "link": "https://math.libretexts.org/Bookshelves/Calculus/Vector_Calculus_(Corral)/02%3A_Functions_of_Several_Variables/2.07%3A_Constrained_Optimization_-_Lagrange_Multipliers",
        "document": "In Sections 2.5 and 2.6 we were concerned with finding maxima and minima of functions without any constraints on the variables (other than being in the domain of the function). What would we do if there were constraints on the variables? The following example illustrates a simple case of this type of problem.\n\nFor a rectangle whose perimeter is 20 m, find the dimensions that will maximize the area. The area \\(A\\) of a rectangle with width \\(x\\) and height \\(y\\) is \\(A = x y\\). The perimeter \\(P\\) of the rectangle is then given by the formula \\(P = 2x+2y\\). Since we are given that the perimeter \\(P = 20\\), this problem can be stated as: The reader is probably familiar with a simple method, using single-variable calculus, for solving this problem. Since we must have \\(2x + 2y = 20\\), then we can solve for, say, \\(y\\) in terms of \\(x\\) using that equation. This gives \\(y = 10− x\\), which we then substitute into \\(f\\) to get \\(f (x, y) = x y = x(10 − x) = 10x − x^2\\). This is now a function of \\(x\\) alone, so we now just have to maximize the function \\(f (x) = 10x− x^2\\) on the interval [0,10]. Since \\(f ′ (x) = 10−2x = 0 \\Rightarrow x = 5 \\text{ and }f ′′(5) = −2 < 0\\), then the Second Derivative Test tells us that \\(x = 5\\) is a local maximum for \\(f\\), and hence \\(x = 5\\) must be the global maximum on the interval [0,10] (since \\(f = 0\\) at the endpoints of the interval). So since \\(y = 10 − x = 5\\), then the maximum area occurs for a rectangle whose width and height both are 5 m.\n\nNotice in the above example that the ease of the solution depended on being able to solve for one variable in terms of the other in the equation \\(2x+2y = 20\\). But what if that were not possible (which is often the case)? In this section we will use a general method, called the Lagrange multiplier method, for solving constrained optimization problems:\n\n\\[\n\nonumber \\begin{align} \\text{Maximize (or minimize) : }&f (x, y)\\quad (\\text{or }f (x, y, z)) \\\\[4pt] \n\nonumber \\text{given : }&g(x, y) = c \\quad (\\text{or }g(x, y, z) = c) \\text{ for some constant } c \\end{align}\\]\n\nThe equation \\(g(x, y) = c\\) is called the constraint equation, and we say that \\(x\\) and \\(y\\) are constrained by \\(g(x, y) = c\\). Points \\((x, y)\\) which are maxima or minima of \\(f (x, y)\\) with the condition that they satisfy the constraint equation \\(g(x, y) = c\\) are called constrained maximum or constrained minimum points, respectively. Similar definitions hold for functions of three variables.\n\nThe Lagrange multiplier method for solving such problems can now be stated:\n\nA rigorous proof of the above theorem requires use of the Implicit Function Theorem, which is beyond the scope of this text. Note that the theorem only gives a necessary condition for a point to be a constrained maximum or minimum. Whether a point \\((x, y)\\) that satisfies \\(\n\nabla f (x, y) = \\lambda \n\nabla g(x, y)\\) for some \\(\\lambda\\) actually is a constrained maximum or minimum can sometimes be determined by the nature of the problem itself. For instance, in Example 2.24 it was clear that there had to be a global maximum.\n\nSo how can you tell when a point that satisfies the condition in Theorem 2.7 really is a constrained maximum or minimum? The answer is that it depends on the constraint function \\(g(x, y)\\), together with any implicit constraints. It can be shown that if the constraint equation \\(g(x, y) = c\\) (plus any hidden constraints) describes a bounded set \\(B\\) in \\(\\mathbb{R}^2\\), then the constrained maximum or minimum of \\(f (x, y)\\) will occur either at a point \\((x, y)\\) satisfying \\(\n\nabla f (x, y) = \\lambda \n\nabla g(x, y)\\) or at a “boundary” point of the set \\(B\\).\n\nIn Example 2.24 the constraint equation \\(2x+2y = 20\\) describes a line in \\(\\mathbb{R}^2\\), which by itself is not bounded. However, there are “hidden” constraints, due to the nature of the problem, namely \\(0 ≤ x, y ≤ 10\\), which cause that line to be restricted to a line segment in \\(\\mathbb{R}^2\\) (including the endpoints of that line segment), which is bounded.\n\nFor a rectangle whose perimeter is 20 m, use the Lagrange multiplier method to find the dimensions that will maximize the area. As we saw in Example 2.24, with \\(x\\) and \\(y\\) representing the width and height, respectively, of the rectangle, this problem can be stated as: Then solving the equation \\(\n\nabla f (x, y) = \\lambda \n\nabla g(x, y)\\) for some \\(\\lambda\\) means solving the equations \\(\\dfrac{∂f}{∂x} = \\lambda \\dfrac{∂g}{∂x}\\text{ and }\\dfrac{∂f}{∂y} = \\lambda \\dfrac{∂g}{∂y}\\), namely: The general idea is to solve for \\(\\lambda\\) in both equations, then set those expressions equal (since they both equal \\(\\lambda\\)) to solve for \\(x \\text{ and }y\\). Doing this we get so now substitute either of the expressions for \\(x \\text{ or }y\\) into the constraint equation to solve for \\(x \\text{ and }y\\): There must be a maximum area, since the minimum area is 0 and \\(f (5,5) = 25 > 0\\), so the point \\((5,5)\\) that we found (called a constrained critical point) must be the constrained maximum. \\(\\therefore\\) The maximum area occurs for a rectangle whose width and height both are 5 m.\n\nFind the points on the circle \\(x^2 + y^2 = 80\\) which are closest to and farthest from the point \\((1,2)\\). The distance \\(d\\) from any point \\((x, y)\\) to the point \\((1,2)\\) is and minimizing the distance is equivalent to minimizing the square of the distance. Thus the problem can be stated as: Note that \\(x \n\neq 0\\) since otherwise we would get −2 = 0 in the first equation. Similarly, \\(y \n\neq 0\\). So we can solve both equations for \\(\\lambda\\) as follows: Substituting this into \\(g(x, y) = x^2 + y^2 = 80\\) yields \\(5x^2 = 80\\), so \\(x = \\pm 4\\). So the two constrained critical points are \\((4,8)\\text{ and }(−4,−8)\\). Since \\(f (4,8) = 45 \\text{ and }f (−4,−8) = 125\\), and since there must be points on the circle closest to and farthest from \\((1,2)\\), then it must be the case that \\((4,8)\\) is the point on the circle closest to \\((1,2)\\text{ and }(−4,−8)\\) is the farthest from \\((1,2)\\) (see Figure 2.7.1). Notice that since the constraint equation \\(x^2+y^2 = 80\\) describes a circle, which is a bounded set in \\(\\mathbb{R}^2\\), then we were guaranteed that the constrained critical points we found were indeed the constrained maximum and minimum.\n\nThe Lagrange multiplier method can be extended to functions of three variables.\n\nSo far we have not attached any significance to the value of the Lagrange multiplier \\(\\lambda\\). We needed \\(\\lambda\\) only to find the constrained critical points, but made no use of its value. It turns out that \\(\\lambda\\) gives an approximation of the change in the value of the function \\(f (x, y)\\) that we wish to maximize or minimize, when the constant c in the constraint equation \\(g(x, y) = c\\) is changed by 1.\n\nFor example, in Example 2.25 we showed that the constrained optimization problem\n\nhad the solution \\((x, y) = (5,5)\\), and that \\(\\lambda = \\dfrac{x}{2} = \\dfrac{y}{2}\\). Thus, \\(\\lambda = 2.5\\). In a similar fashion we could show that the constrained optimization problem\n\nhas the solution \\((x, y) = (5.25,5.25)\\). So we see that the value of \\(f (x, y)\\) at the constrained maximum increased from \\(f (5,5) = 25 \\text{ to }f (5.25,5.25) = 27.5625\\), i.e. it increased by 2.5625 when we increased the value of \\(c\\) in the constraint equation \\(g(x, y) = c \\text{ from }c = 20 \\text{ to }c = 21\\). Notice that \\(\\lambda = 2.5\\) is close to 2.5625, that is,\n\nFinally, note that solving the equation \\(\n\nabla f (x, y) = \\lambda \n\nabla g(x, y)\\) means having to solve a system of two (possibly nonlinear) equations in three unknowns, which as we have seen before, may not be possible to do. And the 3-variable case can get even more complicated. All of this somewhat restricts the usefulness of Lagrange’s method to relatively simple functions. Luckily there are many numerical methods for solving constrained optimization problems, though we will not discuss them here."
    },
    {
        "link": "https://iist.ac.in/sites/default/files/people/Lagrange-Multiplier.pdf",
        "document": ""
    },
    {
        "link": "https://khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint",
        "document": ""
    },
    {
        "link": "https://calcworkshop.com/partial-derivatives/lagrange-multiplier",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/56709473/allocate-resources-in-the-fairest-way-possible",
        "document": "Working on a personal project, I have encountered a problem that I'll try to generalize here.\n\nGiven a list of resources of different value (e.g. ), I want to share them among a group of N people in a way that is as fair as possible (i.e. no one ends up hoarding too much value while others have too little).\n\nI assume a good way of tackling this issue is to minimize the function:\n\nWhere and is the resources assigned to person .\n\nI have stumbled upon , and I think it might be helpful, but I can't figure out how to describe the constrain that the values of cannot be arbitrary but instead need to be taken from (and in a way that the same resource is not given to more than one person in a solution), since I don't have any experience with this module nor a strong mathematical background applicable to this type of problem.\n\nIs there an easy way of solving this problem with ?"
    },
    {
        "link": "https://apmonitor.com/me575/index.php/Main/PythonOptimization",
        "document": "Optimization Introduction in the Engineering Optimization online course.\n\nEngineering optimization platforms in Python are an important tool for engineers in the modern world. They allow engineers to quickly and easily optimize complex engineering problems and tasks, such as design optimization, resource allocation, and route planning. This notebook has examples for solving LP, QP, NLP, MILP, and MINLP problems in Python.\n\nFirst, install the necessary gekko library for this notebook. The solutions to the examples are with scipy and gekko. Installing packages only needs to occur once and then it is always available in that Python distribution. Jupyter notebook may require a restart of the kernel to make the library accessible for import.\n\nA company manufactures two products (G and H) and has two resources (X and Y) available.\n• Each unit of product G requires 3 units of resource X and 8 units of resource Y\n• Each unit of product H requires 6 units of resource X and 4 units of resource Y\n• The company has a maximum of 30 units of resource X and 44 units of resource Y available.\n• The company wants to maximize profits:\n\nLinear programming is an optimization method for solving systems of linear constraints and objectives. This problem is mathematically expressed as:\n\nwhere G and H are the number of units of products to be produced, respectively.\n\nThe following code shows how to use linear programming to solve this problem in scipy.optimize with the linprog function. The linear programming problem is placed into the following matrix form:\n\nThe following code shows how to use linear programming to solve this problem in gekko. There is additional information on solving linear programming problems with sparse or dense matrices in gekko.\n\nUse either gekko or scipy to solve the LP and report the results for x, y, and the objective function value. Find the solution on the contour plot to graphically verify the results.\n\nA car manufacturer wants to minimize the weight of a car while maintaining a minimum strength requirement. The weight of the car is modeled as a quadratic function of the thickness of the car frame components. The strength of the car is modeled as a linear function of the thickness of the car frame components. The manufacturer wants to minimize the weight of the car while maintaining a minimum strength requirement. This problem is formulated as:\n\nwhere x is the thickness of the car frame components, Q is the quadratic weight coefficient matrix, p is the linear weight coefficient vector, G is the strength coefficient matrix, and h is the strength constraint vector.\n\nThe minimize function in the scipy.optimize module is a general-purpose nonlinear optimization routine that can be used to find the minimum of a scalar function of one or more variables. To use it, you need to provide the following inputs:\n• Objective function: This should be a Python function that has decision variables as inputs and returns a scalar value to be minimized.\n• The initial guess for the variables: This should be an array of initial guesses for the variables.\n• Constraints with any inequality and equality bounds in residual format.\n• Bounds: upper and lower bounds on the decision variables.\n• Method: This is an optional parameter that specifies the optimization algorithm.\n\nThe following code shows how to use quadratic programming in gekko. Change to remote=False to solve locally instead of using the public compute server. The public server has additional solver options.\n\nUse either gekko or scipy to solve the QP and report the results for x, y, and the objective function value.\n\nThis problem has a nonlinear objective that must be minimized. The variable values at the optimal solution are subject to (s.t.) both equality (=40) and inequality (>=25) constraints. The product of the four variables must be greater than 25 while the sum of squares of the variables must also equal 40. In addition, all variables are constrained between 1 and 5 and the initial guess is x=[1,5,5,1].\n\nThe following code shows how to solve nonlinear programming problems in gekko. All solvers in gekko can solve LP, QP, and NLP problems.\n\nUse either gekko or scipy to solve the NLP and report the results for x, y, and the objective function value.\n\nMixed integer linear programming (MILP) is a type of optimization problem that involves both continuous and discrete (integer) variables. In contrast, regular linear programming (LP) only involves continuous variables. The presence of integer variables in MIP makes the problem more difficult to solve, as the solution space is now discrete rather than continuous. This means that many of the techniques used for solving LP problems are not applicable to MIP. Specialized algorithms and solvers, such as branch-and-bound and branch-and-cut, are typically used to solve MIP problems.\n\nUse the integrality option in the linprog function to specify:\n\nThe following code shows how to solve mixed integer linear programming problems. Use integer=True to specify an integer variable. The solver APOPT is a mixed integer solver in gekko that is selected with m.options.SOLVER=1.\n\nwhere x and y are integer values. Use either gekko or scipy to solve the MILP and report the results for x, y, and the objective function value. There are 3 potential solutions. Find the integer solutions on the contour plot to graphically verify the results.\n\nMixed integer nonlinear programming (MINLP) is like MILP but may have a nonlinear objective and constraints. It also requires specialized solvers such as the APOPT solver in gekko. There is no current MINLP solver for scipy, but that is likely changing in a future release.\n\nIn addition to binary (0,1) and integer variables, Special Ordered Sets are also possible to define from a selection of discrete options such as [0.5, 1.15, 2.6, 5.2].\n\nA piece of letter paper 8.5x11 inches is made into an open-top box by first removing the corners and then by folding the sides up to the adjacent side. The starting sheet has height and width. The objective is to maximize the volume of the box (no lid) by choosing an appropriate value of x (the height of the box).\n• Additional information on paper box folding with solution help.\n\nStarting with the continuous solution, restrict the height to inch values in integer increments. Below is the continuous solution:\n\nCalculate how much the integer solution requirement decreases the volume.\n\nThese tutorial are examples of using Python Gekko to solve an optimization problem."
    },
    {
        "link": "https://medium.com/@jeffmarvel/constrained-resource-allocation-using-scipy-minimize-1b6cd0f973bf",
        "document": "Optimization algorithms were my first significant exposure to the field of Data Science and planted the seed that would eventually lead to me pursuing this field full time. Optimization in this context involves solving a set of equations for a value x (or a series of x values) that minimizes (or maximizes) the objective function. These equations can be inequalities (less than or greater than) or equalities (must equal some value). They can be linear or non-linear in nature. Many optimization algorithms also allow you to specify bounds on the x values. I.e., the solution must exist within a defined range.\n\nThe beauty of these models is they have countless applications in business and research. Any problem that can be defined by a series of equations is a candidate for optimization. This approach allows teams to find the mathematically correct answer to a problem that can then be one piece of the puzzle in a broader decision-making process. In my case, I was on a team in that was solving a constrained resource allocation problem using optimization. The basic premise was to find the optimal way to distribute a scarce resource (the bank’s capital) across the bank’s products in a way that maximized profitability subject to our regulatory constraints.\n\nI’ve recreated this problem by constructing a sample bank balance sheet with a simplified version of the constraints (link to the project GitHub). I use Scipy’s Optimize library to find the composition of the balance sheet (the size of each of the products) that maximizes profitability while adhering to these constraints.\n\nA bank’s B/S is comprised of assets and liabilities. The rule of any balance sheet is that assets must equal liabilities (this forms the basis of the equality constraint in our optimization problem). Assets could include mortgages, auto loans, business loans, and markets products while liabilities include various deposit products, debt, and equity. Each of these items generates profit in an easily measurable way. For example, the mortgage will have a coupon (or spread) that the bank earns.\n\nAmong the banks liabilities is the bank’s capital (also called its resource stack). This is comprised of equity, preferred equity, and debt. The bank regulations (and the source of the inequality constraints in our optimization) pertain to how much of each of these resources the bank needs based on the riskiness of its B/S. Generally, a bank would want to minimize these balances relative to its contraints. Capital is expensive! Shareholders of common equity demand a certain return, and banks pay a coupon on their debt.\n\nThe aforementioned regulations convert each of the balances on the B/S to a risk-weighted equivalent. I.e., a mortgage loan might have a risk weight of 50%, meaning that a $100 mortgage loan will generate $50 of risk-weighted assets. The regulations then state that the bank must have sufficient capital to cover a certain percentage of its total risk weighted assets.\n\nThere are various regulatory frameworks that calculate risk weights differently. And products on the bank’s B/S may contribute to these risk weights in different ways. Also, not all bank resources contribute to solving every constraints. For example, only Common Equity counts towards solving the the Standardized RWA CET1 constraint while Common Equity plus Preferred Equity contribute to the T1 constraint. For my final problem setup, I had the following:\n• 10 inequality constraints (pertaining to the regulations just described)\n• Upper and lower bounds for each product (how much I allow them to grow / shrink)\n\nA sample of in the inputs looks as follows:\n\nEach line item on the balance sheet has:\n• Asset / Liability flags (A_L) to be used in the equality constraint\n• Risk weights (“b1_leverage” through “s_rwa”), which is that product’s contribution to one of the inequality constraints\n• Resource contribution (CET1_resource through TLAC_resource) flags a product’s ability to contribute towards “solving” one of the constraints\n\nI chose scipy.optimize.minize as my tool of choice as some of my inequality constraints are non-linear. For purely linear programming, something like scipy.optimize.linprog would be a better choice. From the documentation on minimize:\n\nfun refers to the objective function. In my case, it’s the profitability of the balance sheet. If we want to maximize something in an optimization algorithm that finds the “minimum” solution, it’s as easy as flipping the sign. In other words, I want to minimize “negative profitability”. Profitability is simply the spread times the balance. Therefore, I want the sum of the following formula:\n\nIn Python, this formula can be written as follows:\n\nx0 is the starting guess of the balances. In my case, this is just an array of all the starting balances on the B/S.\n\nargs is an optional parameter where you can pass additional data needed to calculate your objective function. In my case, the objective function needs the spread of each line item, so an array of these values is passed to args.\n\nbounds are the upper and lower limits of my balances. I.e., the balances of each line item cannot exceed the bounds in either direction in the solution. The minimize function requires this to be a “tuple of tuples” when dealing with multiple x values.\n\nconstraints is a list of dictionaries for all the inequality and equality constraints in the optimization. I have 11 total constraints in my model, but I will just describe the set up for one of the inequality and the equality constraint. The full math notation for the inequality constraint is show below. The standard setup for minimize is that the inequality is greater than or equal to some value. If that’s not exactly how your problem is set up, you can flip the signs until the equation is in that format. Note that this is not consistent across all optimization libraries. Be sure to check the documentation for how they want you to structure the inequality constraints.\n\nIf that looks complicated, the plain English description is “do I have enough equity on the B/S to cover a given percentage of my risk-weighted assets”. That “given percentage” is in turn partly dependent on the balances. This is where my problem becomes non-linear. For purposes of Scipy Minimize, this can be implemented as follows:\n\nThe equality constraint is that assets must equal liabilities. Among the inputs, I have an Asset (+1) and Liability (-1) weight for each line item. The sumproduct of these weights and the balances should always equal 0.\n\nScipy Minimize requires a dictionary, which contains certain information about the constraints. For this problem, I need to specify the type of constraint (inequality vs. equality) along with its format, in this case I’m passing a function. This can all be collected in a list to be passed to the final optimization formula.\n\nFinally, I’m ready to optimize! By gathering up all my inputs, I can run Scipy Minimize as follows, storing the result in a “sol” or “solution” object. (note that I’m using the ‘trust-constr’ solver for this problem. Certain solvers are better suited for different problems and should be a consideration in any optimization implementation).\n\nThe first thing to determine is whether our optimization actually found a solution. This is easily check using the “success” attribute of our solution object.\n\nLooks like it worked! To sense check the results, there are a few principles of optimization we can use to see if it’s working as expected.\n• The solution has improved the objective function in the expected direction\n• All constraints are binding (and if they aren’t, they overlap with a more binding constraint)\n• All products have been shrunk (or grown) to what’s allowable based on their bounds. There are two exceptions to this:\n\n- There should be one product that is the “marginal product” and hasn’t completely grown (or shrunk) to its allowable limits\n\n- The resources used to satisfy the constraints won’t be maxed out\n\nChecking the profitability improvement is easy. The solution object has a “fun” attribute that returns the objective function result using the optimal balances. This can be compared with the the objective function using the starting balances.\n\nThe optimal balance sheet as a 38% higher profit than our starting balances!\n\nTo check, which constraints are binding, we need to extract the ending balances using the “x” attribute of our solution.\n\nBy plugging those balances into our inequality constraints, we’re able to see which constraints are binding, and which have excess capacity.\n\nI haven’t gotten into the weeds of bank capital constraints in this post. Based on the above table however, I know that SRWA is binding for CET1, TC, and TLAC while Leverage is binding for T1. The different frameworks overlap for a given row, meaning that I wouldn’t necessarily expect SRWA, ARWA, and Leverage to all be binding in a single row. The excess vs. the constraints should be minimized overall. This becomes a lot more obvious when I compare to where the B/S started (you can even see that I’m in breach of one of the constraints to start):\n\nThe final sense check is that the optimization should be maxing out or minimizing balances up to their bounds. In this sample below, you can see that the optimal balance is perfectly aligned with the bounds except for row 10. This is our “marginal product”. It’s the very last item that the optimization chose to grow, and any further growth than what’s shown below would’ve started to decrease the objective function. Identifying this “marginal product” can be very useful from a business perspective. On the other hand, several products not meeting their upper and lower bounds could be a sign that something is off with the setup of your optimization problem.\n\nRecreating this analysis I first so saw many years ago has been a really interesting experience. What was originally a black box gradually unraveled as I’ve expanded my linear algebra and Python knowledge. And while I definitely made this more complicated than it had to be for a practice optimization problem, I wanted to capture the spirit of the original analysis.\n\nThe work doesn’t stop with the optimization running successfully, however. As any good Data Scientist knows, the math is just one input into a broader decision-making process. Maybe there are qualitative considerations for why we wouldn’t pursue strictly the optimal solution.\n\nOne natural follow-up to this optimization is to perform a prioritization analysis. Rather than determine the optimal balance sheet, you allow it to grow by a certain amount, and have the optimization tell you which products you should invest in. This can be useful in valuing new business or other growth opportunities.\n\nThanks for reading! Please feel free to drop a comment or reach out with questions."
    },
    {
        "link": "https://towardsdatascience.com/quadratic-optimization-with-constraints-in-python-using-cvxopt-fc924054a9fc",
        "document": "Quadratic optimization is a problem encountered in many fields, from least squares regression [1] to portfolio optimization [2] and passing by model predictive control [3]. In all of these problems, one must optimize the allocation of resources to different assets or agents (which usually corresponds to the linear term) knowing that there can be helpful or unhelpful interactions between these assets or agents (this corresponds to the quadratic term), all the while satisfying some particular Constraints (not allocating all the resources to the same agent or asset, making sure the sum of all allocated resources does not surpass the total available resources, etc.). Difficulties may arise when the constraints cannot be formulated linearly. In this article, we will see how to tackle these optimization problems using a very powerful python library called CVXOPT [4, 5], which relies on LAPACK and BLAS routines (these are highly efficient linear algebra libraries written in Fortran 90) [6].\n\nFormulated mathematically, the goal is to find the arguments that minimize a multivariate quadratic function while fulfilling some equality and inequality constraints. The function to be optimized has the following general form:\n\nwhere x is the unknown vector of size n, r is a vector of the same size as x, and Q is a square symmetric matrix of dimension n by n. The constraints can be formulated as a set of equalities and inequalities, such that:\n\nwhere A is an n by m matrix (with m the number of equality constraints), b is a vector of size m, G is an n by m’ matrix (with m’ the number of inequality constraints), and h is a vector of size m’. The curly inequality symbol means that the inequality holds for every element of the vector.\n\nHow do we write this in the CVXOPT formalism? Consider the code below:\n\nThe solution ‘sol’ is a dictionary containing, among other things, the vector that minimizes the loss function under the key ‘x’, as well as the information whether an optimal solution was found under the key ‘status’.\n\nHow does one implement constraints in this formalism? All that needs to be done is supply the matrices A and G as well as the vectors b and h defined earlier. Let’s say we want the sum of the elements of x to be equal to one, as well as all elements of x to be positive. Mathematically, these conditions are:\n\nand can be written in matrix format as:\n\nWe can thus define the matrices A, G, b, and h as:\n\nIn the CVXOPT formalism, these become:\n\nThe solution now found follows the imposed constraints.\n\nNow let us add a different type of constraint that is not linear. Suppose an optimal solution has been found at a certain time. At a later time, the matrix Q and the vector r have been updated with new values. However, changing the allocation of resources or assets has a cost. Changing a value in the old vector x must therefore be worth it in order to justify this cost. The problem can now be formulated as:\n\nwith c a vector representing the friction effects from going to one solution to another, or the cost of allocating and unallocating resources. This new loss is no longer quadratic, as there is a term containing an absolute value, which is problematic as it is not differentiable. How does one go around this problem? The solution is to add extra variables that will correspond to the change from one state to the next, and then linearizing the loss function. The linear part of the preceding equation becomes:\n\nIn the above equation we have considered that the friction effects or costs may be different for allocating and unallocating resources to the different agents/assets. We must then add extra constraints to ensure these extra variables correspond well to the change from one solution to the next:\n\nWe obtain the new unknown vector X by concatenating x with the variations of x. We do the same for the new Q and r matrix and vector:\n\nand we implement the constraints:\n\nThe code is then modified in the following way:\n\nWe have therefore seen how to take into account the friction effects for transitioning from one solution to another.\n\nLet us consider a practical example to fully understand the use of this technique: portfolio Optimization. In Markowitz’s portfolio optimization theory [2], the r vector corresponds to a prediction of the returns of different assets. This prediction is given by any predictive model which we will not consider here. The Q matrix corresponds to the covariance matrix of the returns of these same assets. One may take the historical covariance matrix in this case. We will change the notation here a bit and use ω as the unknown vector. The values of ω correspond to the weights of the different assets in the portfolio. The loss function can now be written as:\n\nwhere we have also introduced λ which represents the user’s risk aversion. The first term of the equation represents the expected returns of this portfolio. The second term represents the risk of the portfolio. Low values of λ mean that more risk is tolerated. The last term represents the transaction costs to go from one portfolio to another.\n\nWe would like to add a few more constraints which are common in portfolio optimization. We would like our portfolio to be somewhat diversified, which we can ensure by adding an upper bound to the weights. We might also want to reduce even more the movement from one portfolio to another, which is translated by a turnover constraint. Mathematically, these can be written as:\n\nwhere T corresponds to the maximum turnover allowed, and can take on values between 0 (no modifications allowed) and 2 (no turnover constraint). The last term in the constraints listed below is a modification of the previous constraint where the sum of weights should be equal to one. This modification reflects the fact that when assets are sold and bought, transaction fees are paid and therefore the capital of the portfolio decreases [6]. In matrix form, these constraints become:\n\nand the code is modified in the following way:\n\nWe then compute the efficient frontier, which is the collection of the best portfolios for a given risk aversion\n\nIn this figure, we have plotted the risks and returns of a collection of random portfolios to have a baseline. We see that the best computed portfolios always have far greater returns than any random portfolio for a given risk. The risk and return of the initial portfolio is also portrayed.\n\nIn order to visualize the importance of the maximum turnover, we can repeat the calculations of the efficient frontier varying its value (25%, 50%, 100%, and 200%). Completely changing the portfolio implies selling all the assets (turning over 100% of assets) and then buying a completely new set of assets (turning over 100% again) which amounts to 200% turnover. The maximum amount of turnover of a portfolio is therefore 200%. We expect the efficient frontier to contract with smaller maximum turnovers, as the algorithm has less options to change the weights of the initial portfolio.\n\nThis assumption is verified to a certain extent: it would seem that increasing the maximum turnover from 100% to 200% with this particular initial portfolio does not hinder the optimization process too much. This is likely due to the nature of the predictions, which in our case do not change much from one time step to another. Therefore, a somewhat optimized portfolio does not require too many changes in order to be fully optimized.\n\nIn this article we have seen how to use CVXOPT which is a powerful and fast solver in order to solve quadratic optimization problems with constraints. We have seen how to adapt some types of constraints and losses which are neither linear nor quadratic (such as the transaction cost loss and the turnover constraint) so that the solver can handle them. However, while the solver is very efficient and quite flexible, it cannot handle all types of constraints. Indeed, if we wish to add a sparsity constraint (we want to have at most N non-zero weights), this cannot be reformulated in a linear or quadratic way. In this case, it may be worthwhile to investigate other methods that are more flexible and that can handle any type of loss function, such as simulated annealing for example.\n\nAdvestis is a European Contract Research Organization (CRO) with a deep understanding and practice of statistics and interpretable machine learning techniques. The expertise of Advestis covers the modeling of complex systems and predictive analysis for temporal phenomena. LinkedIn: https://www.linkedin.com/company/advestis/"
    },
    {
        "link": "https://datacamp.com/tutorial/optimization-in-python",
        "document": "Level up your data science skills by creating visualizations using Matplotlib and manipulating DataFrames with pandas."
    }
]