[
    {
        "link": "https://docs.python.org/3/library/json.html",
        "document": "JSON (JavaScript Object Notation), specified by RFC 7159 (which obsoletes RFC 4627) and by ECMA-404, is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript ).\n\nexposes an API familiar to users of the standard library and modules.\n\nUsing from the shell to validate and pretty-print:\n\nSerialize obj as a JSON formatted stream to fp (a -supporting file-like object) using this Python-to-JSON conversion table. Unlike and , JSON is not a framed protocol, so trying to serialize multiple objects with repeated calls to using the same fp will result in an invalid JSON file.\n• None obj (object) – The Python object to be serialized.\n• None fp (file-like object) – The file-like object obj will be serialized to. The module always produces objects, not objects, therefore must support input.\n• None skipkeys (bool) – If , keys that are not of a basic type ( , , , , ) will be skipped instead of raising a . Default .\n• None ensure_ascii (bool) – If (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If , these characters will be outputted as-is.\n• None check_circular (bool) – If , the circular reference check for container types is skipped and a circular reference will result in a (or worse). Default .\n• None allow_nan (bool) – If , serialization of out-of-range values ( , , ) will result in a , in strict compliance with the JSON specification. If (the default), their JavaScript equivalents ( , , ) are used.\n• None cls (a subclass) – If set, a custom JSON encoder with the method overridden, for serializing into custom datatypes. If (the default), is used.\n• None indent (int | str | None) – If a positive integer or string, JSON array elements and object members will be pretty-printed with that indent level. A positive integer indents that many spaces per level; a string (such as ) is used to indent each level. If zero, negative, or (the empty string), only newlines are inserted. If (the default), the most compact representation is used.\n• None separators (tuple | None) – A two-tuple: . If (the default), separators defaults to if indent is , and otherwise. For the most compact JSON, specify to eliminate whitespace.\n• None default (callable | None) – A function that is called for objects that can’t otherwise be serialized. It should return a JSON encodable version of the object or raise a . If (the default), is raised.\n• None sort_keys (bool) – If , dictionaries will be outputted sorted by key. Default . Changed in version 3.2: Allow strings for indent in addition to integers. Changed in version 3.4: Use as default if indent is not . Changed in version 3.6: All optional parameters are now keyword-only. Serialize obj to a JSON formatted using this conversion table. The arguments have the same meaning as in . Keys in key/value pairs of JSON are always of the type . When a dictionary is converted into JSON, all the keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON and then back into a dictionary, the dictionary may not equal the original one. That is, if x has non-string keys. Deserialize fp to a Python object using the JSON-to-Python conversion table.\n• None fp (file-like object) – A -supporting text file or binary file containing the JSON document to be deserialized.\n• None cls (a subclass) – If set, a custom JSON decoder. Additional keyword arguments to will be passed to the constructor of cls. If (the default), is used.\n• None object_hook (callable | None) – If set, a function that is called with the result of any object literal decoded (a ). The return value of this function will be used instead of the . This feature can be used to implement custom decoders, for example JSON-RPC class hinting. Default .\n• None object_pairs_hook (callable | None) – If set, a function that is called with the result of any object literal decoded with an ordered list of pairs. The return value of this function will be used instead of the . This feature can be used to implement custom decoders. If object_hook is also set, object_pairs_hook takes priority. Default .\n• None parse_float (callable | None) – If set, a function that is called with the string of every JSON float to be decoded. If (the default), it is equivalent to . This can be used to parse JSON floats into custom datatypes, for example .\n• None parse_int (callable | None) – If set, a function that is called with the string of every JSON int to be decoded. If (the default), it is equivalent to . This can be used to parse JSON integers into custom datatypes, for example .\n• None parse_constant (callable | None) – If set, a function that is called with one of the following strings: , , or . This can be used to raise an exception if invalid JSON numbers are encountered. Default .\n• None JSONDecodeError – When the data being deserialized is not a valid JSON document.\n• None UnicodeDecodeError – When the data being deserialized does not contain UTF-8, UTF-16 or UTF-32 encoded data.\n• None All optional parameters are now keyword-only.\n• None fp can now be a binary file. The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.11: The default parse_int of now limits the maximum length of the integer string via the interpreter’s integer string conversion length limitation to help avoid denial of service attacks. Identical to , but instead of a file-like object, deserialize s (a , or instance containing a JSON document) to a Python object using this conversion table. Changed in version 3.6: s can now be of type or . The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.9: The keyword argument encoding has been removed.\n\nPerforms the following translations in decoding by default: It also understands , , and as their corresponding values, which is outside the JSON spec. object_hook is an optional function that will be called with the result of every JSON object decoded and its return value will be used in place of the given . This can be used to provide custom deserializations (e.g. to support JSON-RPC class hinting). object_pairs_hook is an optional function that will be called with the result of every JSON object decoded with an ordered list of pairs. The return value of object_pairs_hook will be used instead of the . This feature can be used to implement custom decoders. If object_hook is also defined, the object_pairs_hook takes priority. parse_float is an optional function that will be called with the string of every JSON float to be decoded. By default, this is equivalent to . This can be used to use another datatype or parser for JSON floats (e.g. ). parse_int is an optional function that will be called with the string of every JSON int to be decoded. By default, this is equivalent to . This can be used to use another datatype or parser for JSON integers (e.g. ). parse_constant is an optional function that will be called with one of the following strings: , , . This can be used to raise an exception if invalid JSON numbers are encountered. If strict is false ( is the default), then control characters will be allowed inside strings. Control characters in this context are those with character codes in the 0–31 range, including (tab), , and . If the data being deserialized is not a valid JSON document, a will be raised. Changed in version 3.6: All parameters are now keyword-only. Return the Python representation of s (a instance containing a JSON document). will be raised if the given JSON document is not valid. Decode a JSON document from s (a beginning with a JSON document) and return a 2-tuple of the Python representation and the index in s where the document ended. This can be used to decode a JSON document from a string that may have extraneous data at the end. Supports the following objects and types by default: Changed in version 3.4: Added support for int- and float-derived Enum classes. To extend this to recognize other objects, subclass and implement a method with another method that returns a serializable object for if possible, otherwise it should call the superclass implementation (to raise ). If skipkeys is false (the default), a will be raised when trying to encode keys that are not , , or . If skipkeys is true, such items are simply skipped. If ensure_ascii is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is. If check_circular is true (the default), then lists, dicts, and custom encoded objects will be checked for circular references during encoding to prevent an infinite recursion (which would cause a ). Otherwise, no such check takes place. If allow_nan is true (the default), then , , and will be encoded as such. This behavior is not JSON specification compliant, but is consistent with most JavaScript based encoders and decoders. Otherwise, it will be a to encode such floats. If sort_keys is true (default: ), then the output of dictionaries will be sorted by key; this is useful for regression tests to ensure that JSON serializations can be compared on a day-to-day basis. If indent is a non-negative integer or string, then JSON array elements and object members will be pretty-printed with that indent level. An indent level of 0, negative, or will only insert newlines. (the default) selects the most compact representation. Using a positive integer indent indents that many spaces per level. If indent is a string (such as ), that string is used to indent each level. Changed in version 3.2: Allow strings for indent in addition to integers. If specified, separators should be an tuple. The default is if indent is and otherwise. To get the most compact JSON representation, you should specify to eliminate whitespace. Changed in version 3.4: Use as default if indent is not . If specified, default should be a function that gets called for objects that can’t otherwise be serialized. It should return a JSON encodable version of the object or raise a . If not specified, is raised. Changed in version 3.6: All parameters are now keyword-only. Implement this method in a subclass such that it returns a serializable object for o, or calls the base implementation (to raise a ). For example, to support arbitrary iterators, you could implement like this: # Let the base class default method raise the TypeError Return a JSON string representation of a Python data structure, o. For example: Encode the given object, o, and yield each string representation as available. For example:\n\nThe JSON format is specified by RFC 7159 and by ECMA-404. This section details this module’s level of compliance with the RFC. For simplicity, and subclasses, and parameters other than those explicitly mentioned, are not considered. This module does not comply with the RFC in a strict fashion, implementing some extensions that are valid JavaScript but not valid JSON. In particular:\n• None Infinite and NaN number values are accepted and output;\n• None Repeated names within an object are accepted, and only the value of the last name-value pair is used. Since the RFC permits RFC-compliant parsers to accept input texts that are not RFC-compliant, this module’s deserializer is technically RFC-compliant under default settings. The RFC requires that JSON be represented using either UTF-8, UTF-16, or UTF-32, with UTF-8 being the recommended default for maximum interoperability. As permitted, though not required, by the RFC, this module’s serializer sets ensure_ascii=True by default, thus escaping the output so that the resulting strings only contain ASCII characters. Other than the ensure_ascii parameter, this module is defined strictly in terms of conversion between Python objects and , and thus does not otherwise directly address the issue of character encodings. The RFC prohibits adding a byte order mark (BOM) to the start of a JSON text, and this module’s serializer does not add a BOM to its output. The RFC permits, but does not require, JSON deserializers to ignore an initial BOM in their input. This module’s deserializer raises a when an initial BOM is present. The RFC does not explicitly forbid JSON strings which contain byte sequences that don’t correspond to valid Unicode characters (e.g. unpaired UTF-16 surrogates), but it does note that they may cause interoperability problems. By default, this module accepts and outputs (when present in the original ) code points for such sequences. The RFC does not permit the representation of infinite or NaN number values. Despite that, by default, this module accepts and outputs , , and as if they were valid JSON number literal values: # Neither of these calls raises an exception, but the results are not valid JSON In the serializer, the allow_nan parameter can be used to alter this behavior. In the deserializer, the parse_constant parameter can be used to alter this behavior. The RFC specifies that the names within a JSON object should be unique, but does not mandate how repeated names in JSON objects should be handled. By default, this module does not raise an exception; instead, it ignores all but the last name-value pair for a given name: The object_pairs_hook parameter can be used to alter this behavior. The old version of JSON specified by the obsolete RFC 4627 required that the top-level value of a JSON text must be either a JSON object or array (Python or ), and could not be a JSON null, boolean, number, or string value. RFC 7159 removed that restriction, and this module does not and has never implemented that restriction in either its serializer or its deserializer. Regardless, for maximum interoperability, you may wish to voluntarily adhere to the restriction yourself. Some JSON deserializer implementations may set limits on:\n• None the maximum level of nesting of JSON objects and arrays\n• None the range and precision of JSON numbers\n• None the content and maximum length of JSON strings This module does not impose any such limits beyond those of the relevant Python datatypes themselves or the Python interpreter itself. When serializing to JSON, beware any such limitations in applications that may consume your JSON. In particular, it is common for JSON numbers to be deserialized into IEEE 754 double precision numbers and thus subject to that representation’s range and precision limitations. This is especially relevant when serializing Python values of extremely large magnitude, or when serializing instances of “exotic” numerical types such as .\n\nThe module provides a simple command line interface to validate and pretty-print JSON objects. If the optional and arguments are not specified, and will be used respectively: Changed in version 3.5: The output is now in the same order as the input. Use the option to sort the output of dictionaries alphabetically by key. The JSON file to be validated or pretty-printed: python -m json.tool mp_films.json \"title\": \"And Now for Something Completely Different\", If infile is not specified, read from . Write the output of the infile to the given outfile. Otherwise, write it to . Sort the output of dictionaries alphabetically by key. Disable escaping of non-ascii characters, see for more information."
    },
    {
        "link": "https://realpython.com/python-json",
        "document": "Python’s module provides you with the tools you need to effectively handle JSON data. You can convert Python data types to a JSON-formatted string with or write them to files using . Similarly, you can read JSON data from files with and parse JSON strings with .\n\nJSON, or JavaScript Object Notation, is a widely-used text-based format for data interchange. Its syntax resembles Python dictionaries but with some differences, such as using only double quotes for strings and lowercase for Boolean values. With built-in tools for validating syntax and manipulating JSON files, Python makes it straightforward to work with JSON data.\n\nBy the end of this tutorial, you’ll understand that:\n• JSON in Python is handled using the standard-library module, which allows for data interchange between JSON and Python data types.\n• JSON is a good data format to use with Python as it’s human-readable and straightforward to serialize and deserialize, which makes it ideal for use in APIs and data storage.\n• You write JSON with Python using to serialize data to a file.\n• You can minify and prettify JSON using Python’s module.\n\nSince its introduction, JSON has rapidly emerged as the predominant standard for the exchange of information. Whether you want to transfer data with an API or store information in a document database, it’s likely you’ll encounter JSON. Fortunately, Python provides robust tools to facilitate this process and help you manage JSON data efficiently.\n\nWhile JSON is the most common format for data distribution, it’s not the only option for such tasks. Both XML and YAML serve similar purposes. If you’re interested in how the formats differ, then you can check out the tutorial on how to serialize your data with Python.\n\nThe acronym JSON stands for JavaScript Object Notation. As the name suggests, JSON originated from JavaScript. However, JSON has transcended its origins to become language-agnostic and is now recognized as the standard for data interchange. The popularity of JSON can be attributed to native support by the JavaScript language, resulting in excellent parsing performance in web browsers. On top of that, JSON’s straightforward syntax allows both humans and computers to read and write JSON data effortlessly. To get a first impression of JSON, have a look at this example code: You’ll learn more about the JSON syntax later in this tutorial. For now, recognize that the JSON format is text-based. In other words, you can create JSON files using the code editor of your choice. Once you set the file extension to , most code editors display your JSON data with syntax highlighting out of the box: The screenshot above shows how VS Code displays JSON data using the Bearded color theme. You’ll have a closer look at the syntax of the JSON format next! In the previous section, you got a first impression of how JSON data looks. And as a Python developer, the JSON structure probably reminds you of common Python data structures, like a dictionary that contains a string as a key and a value. If you understand the syntax of a dictionary in Python, you already know the general syntax of a JSON object. Note: Later in this tutorial, you’ll learn that you’re free to use lists and other data types at the top level of a JSON document. The similarity between Python dictionaries and JSON objects is no surprise. One idea behind establishing JSON as the go-to data interchange format was to make working with JSON as convenient as possible, independently of which programming language you use: [A collection of key-value pairs and arrays] are universal data structures. Virtually all modern programming languages support them in one form or another. It makes sense that a data format that is interchangeable with programming languages is also based on these structures. (Source) To explore the JSON syntax further, create a new file named and add a more complex JSON structure as the content of the file: In the code above, you see data about a dog named Frieda, which is formatted as JSON. The top-level value is a JSON object. Just like Python dictionaries, you wrap JSON objects inside curly braces ( ). In line 1, you start the JSON object with an opening curly brace ( ), and then you close the object at the end of line 20 with a closing curly brace ( ). Note: Although whitespace doesn’t matter in JSON, it’s customary for JSON documents to be formatted with two or four spaces to indicate indentation. If the file size of the JSON document is important, then you may consider minifying the JSON file by removing the whitespace. You’ll learn more about minifying JSON data later in the tutorial. Inside the JSON object, you can define zero, one, or more key-value pairs. If you add multiple key-value pairs, then you must separate them with a comma ( ). A key-value pair in a JSON object is separated by a colon ( ). On the left side of the colon, you define a key. A key is a string you must wrap in double quotes ( ). Unlike Python, JSON strings don’t support single quotes ( ). The values in a JSON document are limited to the following data types: Either or without quotes Just like in dictionaries and lists, you’re able to nest data in JSON objects and arrays. For example, you can include an object as the value of an object. Also, you’re free to use any other allowed value as an item in a JSON array. As a Python developer, you may need to pay extra attention to the Boolean values. Instead of using or in title case, you must use the lowercase JavaScript-style Booleans or . Unfortunately, there are some other details in the JSON syntax that you may stumble over as a developer. You’ll have a look at them next. The JSON standard doesn’t allow any comments, trailing commas, or single quotes for strings. This can be confusing to developers who are used to Python dictionaries or JavaScript objects. Here’s a smaller version of the JSON file from before with invalid syntax:\n• Line 5 has a trailing comma after the final key-value pair.\n• Line 10 contains a trailing comma in the array. Using double quotes is something you can get used to as a Python developer. Comments can be helpful in explaining your code, and trailing commas can make moving lines around in your code less fragile. This is why some developers like to use Human JSON (Hjson) or JSON with comments (JSONC). Hjson gives you the freedom to use comments, ditch commas between properties, or create quoteless strings. Apart from the curly braces ( ), the Hjson syntax look like a mix of YAML and JSON. JSONC is a bit stricter than Hjson. Compared to regular JSON, JSONC allows you to use comments and trailing commas. You may have encountered JSONC when editing the file of VS Code. Inside its configuration files, VS Code works in a JSONC mode. For common JSON files, VS Code is more strict and points out JSON syntax errors. If you want to make sure you write valid JSON, then your coding editor can be of great help. The invalid JSON document above contains marks for each occurrence of incorrect JSON syntax: When you don’t want to rely on your code editor, you can also use online tools to verify that the JSON syntax you write is correct. Popular online tools for validating JSON are JSON Lint and JSON Formatter. Later in the tutorial, you’ll learn how to validate JSON documents from the comfort of your terminal. But before that, it’s time to find out how you can work with JSON data in Python.\n\nPython supports the JSON format through the built-in module named . The module is specifically designed for reading and writing strings formatted as JSON. That means you can conveniently convert Python data types into JSON data and the other way around. The act of converting data into the JSON format is referred to as serialization. This process involves transforming data into a series of bytes for storage or transmission over a network. The opposite process, deserialization, involves decoding data from the JSON format back into a usable form within Python. You’ll start with the serialization of Python code into JSON data with the help of the module. One of the most common actions when working with JSON in Python is to convert a Python dictionary into a JSON object. To get an impression of how this works, hop over to your Python REPL and follow along with the code below: After importing the module, you can use to convert a Python dictionary to a JSON-formatted string, which represents a JSON object. It’s important to understand that when you use , you get a Python string in return. In other words, you don’t create any kind of JSON data type. The result is similar to what you’d get if you used Python’s built-in function: Using gets more interesting when your Python dictionary doesn’t contain strings as keys or when values don’t directly translate to a JSON format: In the dictionary, the keys , , and are numbers. Once you use , the dictionary keys become strings in the JSON-formatted string. Note: When you convert a dictionary to JSON, the dictionary keys will always be strings in JSON. The Boolean Python values of your dictionary become JSON Booleans. As mentioned before, the tiny but significant difference between JSON Booleans and Python Booleans is that JSON Booleans are lowercase. The cool thing about Python’s module is that it takes care of the conversion for you. This can come in handy when you’re using variables as dictionary keys: When converting Python data types into JSON, the module receives the evaluated values. While doing so, sticks tightly to the JSON standard. For example, when converting integer keys like to the string . The module allows you to convert common Python data types to JSON. Here’s an overview of all Python data types and values that you can convert to JSON values: Note that different Python data types like lists and tuples serialize to the same JSON data type. This can cause problems when you convert JSON data back to Python, as the data type may not be the same as before. You’ll explore this pitfall later in this tutorial when you learn how to read JSON. Dictionaries are probably the most common Python data type that you’ll use as a top-level value in JSON. But you can convert the data types listed above just as smoothly as dictionaries using . Take a Boolean or a list, for example: A JSON document may contain a single scalar value, like a number, at the top level. That’s still valid JSON. But more often than not, you want to work with a collection of key-value pairs. Similar to how not every data type can be used as a dictionary key in Python, not all keys can be converted into JSON key strings: You can’t use dictionaries, lists, or tuples as JSON keys. For dictionaries and lists, this rule makes sense as they’re not hashable. But even when a tuple is hashable and allowed as a key in a dictionary, you’ll get a when you try to use a tuple as a JSON key: : keys must be str, int, float, bool or None, not tuple By providing the argument, you can prevent getting a when creating JSON data with unsupported Python keys: When you set in to , then Python skips the keys that are not supported and would otherwise raise a . The result is a JSON-formatted string that only contains a subset of the input dictionary. In practice, you usually want your JSON data to resemble the input object as close as possible. So, you must use with caution to not lose information when calling . Note: If you’re ever in a situation where you need to convert an unsupported object into JSON, then you can consider creating a subclass of the and implementing a method. When you use , you can use additional arguments to control the look of the resulting JSON-formatted string. For example, you can sort the dictionary keys by setting the parameter to : When you set to , then Python sorts the keys alphabetically for you when serializing a dictionary. Sorting the keys of a JSON object can come in handy when your dictionary keys formerly represented the column names of a database, and you want to display them in an organized fashion to the user. Another notable parameter of is , which you’ll probably use the most when serializing JSON data. You’ll explore later in this tutorial in the prettify JSON section. When you convert Python data types into the JSON format, you usually have a goal in mind. Most commonly, you’ll use JSON to persist and exchange data. To do so, you need to save your JSON data outside of your running Python program. Conveniently, you’ll explore saving JSON data to a file next. The JSON format can come in handy when you want to save data outside of your Python program. Instead of spinning up a database, you may decide to use a JSON file to store data for your workflows. Again, Python has got you covered. To write Python data into an external JSON file, you use . This is a similar function to the one you saw earlier, but without the s at the end of its name: In lines 3 to 22, you define a dictionary that you write to a JSON file in line 25 using a context manager. To properly indicate that the file contains JSON data, you set the file extension to . When you use , then it’s good practice to define the encoding. For JSON, you commonly want to use as the encoding when reading and writing files: The RFC requires that JSON be represented using either UTF-8, UTF-16, or UTF-32, with UTF-8 being the recommended default for maximum interoperability. (Source) The function has two required arguments:\n• The object you want to write\n• The file you want to write into Other than that, there are a bunch of optional parameters for . The optional parameters of are the same as for . You’ll investigate some of them later in this tutorial when you prettify and minify JSON files.\n\nIn the former sections, you learned how to serialize Python data into JSON-formatted strings and JSON files. Now, you’ll see what happens when you load JSON data back into your Python program. In parallel to and , the library provides two functions to deserialize JSON data into a Python object: As a rule of thumb, you work with when your data is already present in your Python program. You use with external files that are saved on your disk. The conversion from JSON data types and values to Python follows a similar mapping as before when you converted Python objects into the JSON format: When you compare this table to the one in the previous section, you may recognize that Python offers a matching data type for all JSON types. That’s very convenient because this way, you can be sure you won’t lose any information when deserializing JSON data to Python. Note: Deserialization is not the exact reverse of the serialization process. The reason for this is that JSON keys are always strings, and not all Python data types can be converted to JSON data types. This discrepancy means that certain Python objects may not retain their original type when serialized and then deserialized. To get a better feeling for the conversion of data types, you’ll start with serializing a Python object to JSON and then convert the JSON data back to Python. That way, you can spot differences between the Python object you serialize and the Python object you end up with after deserializing the JSON data. To investigate how to load a Python dictionary from a JSON object, revisit the example from before. Start by creating a dictionary and then serialize the Python dictionary to a JSON string using : By passing into , you’re creating a string with a JSON object that you save in . If you want to convert back to a Python dictionary, then you can use : By using , you can convert JSON data back into Python objects. With the knowledge about JSON that you’ve gained so far, you may already suspect that the content of the dictionary is not identical to the content of : The difference between and is subtle but can be impactful in your Python programs. In JSON, the keys must always be strings. When you converted to using , the integer key became the string . When you used , there was no way for Python to know that the string key should be an integer again. That’s why your dictionary key remained a string after deserialization. You’ll investigate a similar behavior by doing another conversion roundtrip with other Python data types! To explore how different data types behave in a roundtrip from Python to JSON and back, take a portion of the dictionary from a former section. Note how the dictionary contains different data types as values: The dictionary contains a bunch of common Python data types as values. For example, a string in line 2, a Boolean in line 3, a in line 7, and a tuple in line 8, just to name a few. Next, convert to a JSON-formatted string and back to Python again. Afterward, have a look at the newly created dictionary: You can convert every JSON data type perfectly into a matching Python data type. The JSON Boolean deserializes into , converts back into , and objects and arrays become dictionaries and lists. Still, there’s one exception that you may encounter in roundtrips: When you serialize a Python tuple, it becomes a JSON array. When you load JSON, a JSON array correctly deserializes into a list because Python has no way of knowing that you want the array to be a tuple. Problems like the one described above can always be an issue when you’re doing data roundtrips. When the roundtrip happens in the same program, you may be more aware of the expected data types. Data type conversions may be even more obfuscated when you’re dealing with external JSON files that originated in another program. You’ll investigate a situation like this next! In a previous section, you created a file that saved a file. If you need to refresh your memory, you can expand the collapsible section below that shows the code again: Take a look at the data types of the dictionary. Is there a data type in a value that the JSON format doesn’t support? When you want to write content to a JSON file, you use . The counterpart to is . As the name suggests, you can use to load a JSON file into your Python program. Jump back into the Python REPL and load the JSON file from before: Just like when writing files, it’s a good idea to use a context manager when reading a file in Python. That way, you don’t need to bother with closing the file again. When you want to read a JSON file, then you use inside the statement’s block. The argument for the function must be either a text file or a binary file. The Python object that you get from depends on the top-level data type of your JSON file. In this case, the JSON file contains an object at the top level, which deserializes into a dictionary. When you deserialize a JSON file as a Python object, then you can interact with it natively—for example, by accessing the value of the key with square bracket notation ( ). Still, there’s a word of caution here. Import the original dictionary from before and compare it to : When you load a JSON file as a Python object, then any JSON data type happily deserializes into Python. That’s because Python knows about all data types that the JSON format supports. Unfortunately, it’s not the same the other way around. As you learned before, there are Python data types like that you can convert into JSON, but you’ll end up with an data type in the JSON file. Once you convert the JSON data back to Python, then an array deserializes into the Python data type. Generally, being cautious about data type conversions should be the concern of the Python program that writes the JSON. With the knowledge you have about JSON files, you can always anticipate which Python data types you’ll end up with as long as the JSON file is valid. If you use , then the content of the file you load must contain valid JSON syntax. Otherwise, you’ll receive a . Luckily, Python caters to you with more tools you can use to interact with JSON. For example, it allows you to check a JSON file’s validity from the convenience of the terminal.\n\nSo far, you’ve explored the JSON syntax and have already spotted some common JSON pitfalls like trailing commas and single quotes for strings. When writing JSON, you may have also spotted some annoying details. For example, neatly indented Python dictionaries end up being a blob of JSON data. In the last section of this tutorial, you’ll try out some techniques to make your life easier as you work with JSON data in Python. To start, you’ll give your JSON object a well-deserved glow-up. One huge advantage of the JSON format is that JSON data is human-readable. Even more so, JSON data is human-writable. This means you can open a JSON file in your favorite text editor and change the content to your liking. Well, that’s the idea, at least! Editing JSON data by hand is not particularly easy when your JSON data looks like this in the text editor: Even with word wrapping and syntax highlighting turned on, JSON data is hard to read when it’s a single line of code. And as a Python developer, you probably miss some whitespace. But worry not, Python has got you covered! When you call or to serialize a Python object, then you can provide the argument. Start by trying out with different indentation levels: The default value for is . When you call without or with as a value, you’ll end up with one line of a compact JSON-formatted string. If you want linebreaks in your JSON string, then you can set to or provide an empty string. Although probably less useful, you can even provide a negative number as the indentation or any other string. More commonly, you’ll provide values like or for : When you use positive integers as the value for when calling , then you’ll indent every level of the JSON object with the given count as spaces. Also, you’ll have newlines for each key-value pair. Note: To actually see the whitespace in the REPL, you can wrap the calls in function calls. The parameter works exactly the same for as it does for . Go ahead and write the dictionary into a JSON file with an indentation of spaces: When you set the indentation level when serializing JSON data, then you end up with prettified JSON data. Have a look at how the file looks in your editor: Python can work with JSON files no matter how they’re indented. As a human, you probably prefer a JSON file that contains newlines and is neatly indented. A JSON file that looks like this is way more convenient to edit. The convenience of being able to edit JSON data in the editor comes with a risk. When you move key-value pairs around or add strings with one quote instead of two, you end up with an invalid JSON. To swiftly check if a JSON file is valid, you can leverage Python’s . You can run the module as an executable in the terminal using the switch. To see in action, also provide as the positional argument: When you run only with an option, then Python validates the JSON file and outputs the JSON file’s content in the terminal if the JSON is valid. Running in the example above means that contains valid JSON syntax. Note: The prints the JSON data with an indentation of 4 by default. You’ll explore this behavior in the next section. To make complain, you need to invalidate your JSON document. You can make the JSON data of invalid by removing the comma ( ) between the key-value pairs: After saving , run again to validate the file: The module successfully stumbles over the missing comma in . Python notices that there’s a delimiter missing once the property name enclosed in double quotes starts in line 3 at position 5. Go ahead and try fixing the JSON file again. You can also be creative with invalidating and check how reports your error. But keep in mind that only reports the first error. So you may need to go back and forth between fixing a JSON file and running . Once is valid, you may notice that the output always looks the same. Of course, like any well-made command-line interface, offers you some options to control the program. In the previous section, you used to validate a JSON file. When the JSON syntax was valid, showed the content with newlines and an indentation of four spaces. To control how prints the JSON, you can set the option. If you followed along with the tutorial, then you’ve got a file that doesn’t contain newlines or indentation. Alternatively, you can download in the materials by clicking the link below: Free Bonus: Click here to download the free sample code that shows you how to work with JSON data in Python. When you pass in to , then you can pretty print the content of the JSON file in your terminal. When you set , then you can control which indentation level uses to display the code: Seeing the prettified JSON data in the terminal is nifty. But you can step up your game even more by providing another option to the run! By default, writes the output to , just like you commonly do when calling the function. But you can also redirect the output of into a file by providing a positional argument: With as the value of the option, you write the output into the JSON file instead of showing the content in the terminal. If the file doesn’t exist yet, then Python creates the file on the way. If the target file already exists, then you overwrite the file with the new content. Note: You can prettify a JSON file in place by using the same file as and arguments. You can verify that the file exists by running the terminal command: The whitespace you added to comes with a price. Compared to the original, unindented file, the file size of is now around double that. Here, the 308-byte increase may not be significant. But when you’re dealing with big JSON data, then a good-looking JSON file will take up quite a bit of space. Having a small data footprint is especially useful when serving data over the web. Since the JSON format is the de facto standard for exchanging data over the web, it’s worth keeping the file size as small as possible. And again, Python’s has got your back! As you know by now, Python is a great helper when working with JSON. You can minify JSON data with Python in two ways:\n• Use the module in your Python code Before, you used with the option to add whitespace. Instead of using here, you can use provide to do the opposite and remove any whitespace between the key-value pairs of your JSON: After calling the module, you provide a JSON file as the and another JSON file as the . If the target JSON file exists, then you overwrite its contents. Otherwise, you create a new file with the filename you provide. Just like with , you provide the same file as a source and target file to minify the file in-place. In the example above, you minify into . Run the command to see how many bytes you squeezed out of the original JSON file: Compared to , the file size of is 337 bytes smaller. That’s even 29 bytes less than the original file that didn’t contain any indentation. To investigate where Python managed to remove even more whitespace from the original JSON, open the Python REPL again and minify the content of the original file with Python’s module: In the code above, you use Python’s to get the content of as text. Then, you use to deserialize to , which is a Python dictionary. You could use to get a Python dictionary right away, but you need the JSON data as a string first to compare it properly. That’s also why you use to create and then use instead of leveraging directly to save the minified JSON data in . As you learned before, needs JSON data as the first argument and then accepts a value for the indentation. The default value for is , so you could skip setting the argument explicitly like you do above. But with , you’re making your intention clear that you don’t want any indentation, which will be a good thing for others who read your code later. The parameter for allows you to define a tuple with two values:\n• The separator between the key-value pairs or list items. By default, this separator is a comma followed by a space ( ).\n• The separator between the key and the value. By default, this separator is a colon followed by a space ( ). By setting to , you continue to use valid JSON separators. But you tell Python not to add any spaces after the comma ( ) and the colon ( ). That means that the only whitespace left in your JSON data can be whitespace appearing in key names and values. That’s pretty tight! With both and containing your JSON strings, it’s time to compare them: You can already spot the difference between and when you look at the output. You then use the function to verify that the size of is indeed smaller. If you’re curious about why the length of the JSON strings almost exactly matches the file size of the written files, then looking into Unicode & character encodings in Python is a great idea. Both and are excellent helpers when you want to make JSON data look prettier, or if you want to minify JSON data to save some bytes. With the module, you can conveniently interact with JSON data in your Python programs. That’s great when you need to have more control over the way you interact with JSON. The module comes in handy when you want to work with JSON data directly in your terminal."
    },
    {
        "link": "https://docs.python.org/3/tutorial/inputoutput.html",
        "document": "There are several ways to present the output of a program; data can be printed in a human-readable form, or written to a file for future use. This chapter will discuss some of the possibilities.\n\nSo far we’ve encountered two ways of writing values: expression statements and the function. (A third way is using the method of file objects; the standard output file can be referenced as . See the Library Reference for more information on this.) Often you’ll want more control over the formatting of your output than simply printing space-separated values. There are several ways to format output.\n• None To use formatted string literals, begin a string with or before the opening quotation mark or triple quotation mark. Inside this string, you can write a Python expression between and characters that can refer to variables or literal values.\n• None The method of strings requires more manual effort. You’ll still use and to mark where a variable will be substituted and can provide detailed formatting directives, but you’ll also need to provide the information to be formatted. In the following code block there are two examples of how to format variables: Notice how the are padded with spaces and a negative sign only for negative numbers. The example also prints multiplied by 100, with 2 decimal places and followed by a percent sign (see Format Specification Mini-Language for details).\n• None Finally, you can do all the string handling yourself by using string slicing and concatenation operations to create any layout you can imagine. The string type has some methods that perform useful operations for padding strings to a given column width. When you don’t need fancy output but just want a quick display of some variables for debugging purposes, you can convert any value to a string with the or functions. The function is meant to return representations of values which are fairly human-readable, while is meant to generate representations which can be read by the interpreter (or will force a if there is no equivalent syntax). For objects which don’t have a particular representation for human consumption, will return the same value as . Many values, such as numbers or structures like lists and dictionaries, have the same representation using either function. Strings, in particular, have two distinct representations. The value of x is 32.5, and y is 40000... # The repr() of a string adds string quotes and backslashes: # The argument to repr() may be any Python object: The module contains a class that offers yet another way to substitute values into strings, using placeholders like and replacing them with values from a dictionary, but offers much less control of the formatting. Formatted string literals (also called f-strings for short) let you include the value of Python expressions inside a string by prefixing the string with or and writing expressions as . An optional format specifier can follow the expression. This allows greater control over how the value is formatted. The following example rounds pi to three places after the decimal: 'The value of pi is approximately The value of pi is approximately 3.142. Passing an integer after the will cause that field to be a minimum number of characters wide. This is useful for making columns line up. Other modifiers can be used to convert the value before it is formatted. applies , applies , and applies : 'My hovercraft is full of My hovercraft is full of eels. 'My hovercraft is full of My hovercraft is full of 'eels'. The specifier can be used to expand an expression to the text of the expression, an equal sign, then the representation of the evaluated expression: See self-documenting expressions for more information on the specifier. For a reference on these format specifications, see the reference guide for the Format Specification Mini-Language. Basic usage of the method looks like this: We are the knights who say \"Ni!\" The brackets and characters within them (called format fields) are replaced with the objects passed into the method. A number in the brackets can be used to refer to the position of the object passed into the method. If keyword arguments are used in the method, their values are referred to by using the name of the argument. Positional and keyword arguments can be arbitrarily combined: The story of Bill, Manfred, and Georg. If you have a really long format string that you don’t want to split up, it would be nice if you could reference the variables to be formatted by name instead of by position. This can be done by simply passing the dict and using square brackets to access the keys. This could also be done by passing the dictionary as keyword arguments with the notation. This is particularly useful in combination with the built-in function , which returns a dictionary containing all local variables: __name__: __main__; __doc__: None; __package__: None; __loader__: ... As an example, the following lines produce a tidily aligned set of columns giving integers and their squares and cubes: For a complete overview of string formatting with , see Format String Syntax. Here’s the same table of squares and cubes, formatted manually: # Note use of 'end' on previous line The method of string objects right-justifies a string in a field of a given width by padding it with spaces on the left. There are similar methods and . These methods do not write anything, they just return a new string. If the input string is too long, they don’t truncate it, but return it unchanged; this will mess up your column lay-out but that’s usually better than the alternative, which would be lying about a value. (If you really want truncation you can always add a slice operation, as in .) There is another method, , which pads a numeric string on the left with zeros. It understands about plus and minus signs: The % operator (modulo) can also be used for string formatting. Given (where format is a string), conversion specifications in format are replaced with zero or more elements of values. This operation is commonly known as string interpolation. For example: 'The value of pi is approximately The value of pi is approximately 3.142. More information can be found in the printf-style String Formatting section.\n\nreturns a file object, and is most commonly used with two positional arguments and one keyword argument: The first argument is a string containing the filename. The second argument is another string containing a few characters describing the way in which the file will be used. mode can be when the file will only be read, for only writing (an existing file with the same name will be erased), and opens the file for appending; any data written to the file is automatically added to the end. opens the file for both reading and writing. The mode argument is optional; will be assumed if it’s omitted. Normally, files are opened in text mode, that means, you read and write strings from and to the file, which are encoded in a specific encoding. If encoding is not specified, the default is platform dependent (see ). Because UTF-8 is the modern de-facto standard, is recommended unless you know that you need to use a different encoding. Appending a to the mode opens the file in binary mode. Binary mode data is read and written as objects. You can not specify encoding when opening file in binary mode. In text mode, the default when reading is to convert platform-specific line endings ( on Unix, on Windows) to just . When writing in text mode, the default is to convert occurrences of back to platform-specific line endings. This behind-the-scenes modification to file data is fine for text files, but will corrupt binary data like that in or files. Be very careful to use binary mode when reading and writing such files. It is good practice to use the keyword when dealing with file objects. The advantage is that the file is properly closed after its suite finishes, even if an exception is raised at some point. Using is also much shorter than writing equivalent - blocks: # We can check that the file has been automatically closed. If you’re not using the keyword, then you should call to close the file and immediately free up any system resources used by it. Calling without using the keyword or calling might result in the arguments of not being completely written to the disk, even if the program exits successfully. After a file object is closed, either by a statement or by calling , attempts to use the file object will automatically fail. The rest of the examples in this section will assume that a file object called has already been created. To read a file’s contents, call , which reads some quantity of data and returns it as a string (in text mode) or bytes object (in binary mode). size is an optional numeric argument. When size is omitted or negative, the entire contents of the file will be read and returned; it’s your problem if the file is twice as large as your machine’s memory. Otherwise, at most size characters (in text mode) or size bytes (in binary mode) are read and returned. If the end of the file has been reached, will return an empty string ( ). 'This is the entire file.\n\n' reads a single line from the file; a newline character ( ) is left at the end of the string, and is only omitted on the last line of the file if the file doesn’t end in a newline. This makes the return value unambiguous; if returns an empty string, the end of the file has been reached, while a blank line is represented by , a string containing only a single newline. 'This is the first line of the file.\n\n' 'Second line of the file\n\n' For reading lines from a file, you can loop over the file object. This is memory efficient, fast, and leads to simple code: This is the first line of the file. If you want to read all the lines of a file in a list you can also use or . writes the contents of string to the file, returning the number of characters written. Other types of objects need to be converted – either to a string (in text mode) or a bytes object (in binary mode) – before writing them: returns an integer giving the file object’s current position in the file represented as number of bytes from the beginning of the file when in binary mode and an opaque number when in text mode. To change the file object’s position, use . The position is computed from adding offset to a reference point; the reference point is selected by the whence argument. A whence value of 0 measures from the beginning of the file, 1 uses the current file position, and 2 uses the end of the file as the reference point. whence can be omitted and defaults to 0, using the beginning of the file as the reference point. # Go to the 6th byte in the file # Go to the 3rd byte before the end In text files (those opened without a in the mode string), only seeks relative to the beginning of the file are allowed (the exception being seeking to the very file end with ) and the only valid offset values are those returned from the , or zero. Any other offset value produces undefined behaviour. File objects have some additional methods, such as and which are less frequently used; consult the Library Reference for a complete guide to file objects. Strings can easily be written to and read from a file. Numbers take a bit more effort, since the method only returns strings, which will have to be passed to a function like , which takes a string like and returns its numeric value 123. When you want to save more complex data types like nested lists and dictionaries, parsing and serializing by hand becomes complicated. Rather than having users constantly writing and debugging code to save complicated data types to files, Python allows you to use the popular data interchange format called JSON (JavaScript Object Notation). The standard module called can take Python data hierarchies, and convert them to string representations; this process is called serializing. Reconstructing the data from the string representation is called deserializing. Between serializing and deserializing, the string representing the object may have been stored in a file or data, or sent over a network connection to some distant machine. The JSON format is commonly used by modern applications to allow for data exchange. Many programmers are already familiar with it, which makes it a good choice for interoperability. If you have an object , you can view its JSON string representation with a simple line of code: Another variant of the function, called , simply serializes the object to a text file. So if is a text file object opened for writing, we can do this: To decode the object again, if is a binary file or text file object which has been opened for reading: JSON files must be encoded in UTF-8. Use when opening JSON file as a text file for both of reading and writing. This simple serialization technique can handle lists and dictionaries, but serializing arbitrary class instances in JSON requires a bit of extra effort. The reference for the module contains an explanation of this. Contrary to JSON, pickle is a protocol which allows the serialization of arbitrarily complex Python objects. As such, it is specific to Python and cannot be used to communicate with applications written in other languages. It is also insecure by default: deserializing pickle data coming from an untrusted source can execute arbitrary code, if the data was crafted by a skilled attacker."
    },
    {
        "link": "https://zyte.com/blog/json-parsing-with-python",
        "document": "JSON (JavaScript Object Notation) is a text-based data format used for exchanging and storing data between web applications. It simplifies the data transmission process between different programming languages and platforms.\n\nThe has become increasingly popular in recent years. It’s a simple and flexible way of representing data that can be easily understood and parsed by both humans and machines. JSON consists of key-value pairs enclosed in curly braces, separated by a colon.\n\nPython provides various and manipulating JSON data, making it a popular choice for data analysts, web developers, and data scientists.\n\nIn this guide, we’ll explore the syntax and data types of JSON, as well as the Python libraries and methods used for parsing JSON data, including more advanced options like JMESPath and ChompJS, which are very useful for web scraping data."
    },
    {
        "link": "https://geeksforgeeks.org/json-formatting-python",
        "document": "JSON (JavaScript Object Notation) is a popular data format that is used for exchanging data between applications. It is a lightweight format that is easy for humans to read and write, and easy for machines to parse and generate.\n\nJavascript Object Notation abbreviated as JSON is a lightweight data interchange format. It encodes Python objects as JSON strings and decodes JSON strings into Python objects.\n• Many of the APIs like Github, send their results in this format. JSON is probably most widely used for communicating between the web server and client in an AJAX application but is not limited to that problem domain.\n• For example, if you are trying to build an exciting project like this, you need to format the JSON output to render the necessary results. So let’s dive into the JSON module which Python offers for formatting JSON output.\n• JSONEncoder: An encoder class to convert Python objects to JSON format.\n\nThe conversions are based on this conversion table.\n\nThe JSON module provides the following two methods to encode Python objects into JSON format. We will be using dump(), dumps(), and JSON.Encoder class. The json.dump() method is used to write Python serialized objects as JSON formatted data into a file. The JSON. dumps() method encodes any Python object into JSON formatted String.\n\nJSON string decoding is done with the help of the inbuilt method json.loads() & json.load() of JSON library in Python. The json.loads() is used to convert the JSON String document into the Python dictionary, and The json.load() is used to read the JSON document from the file."
    },
    {
        "link": "https://stackoverflow.com/questions/17688349/sql-like-operator-to-find-words-in-stored-json",
        "document": "I have this JSON stored in a MySQL DB, column name:\n\nI want to make a search using operator to find all categories with \"Category\" word:\n\nAt the moment I'm doing it this way, but it only return a complete phrase:\n\nHow can I build a query that returns all categories containing the word \"Category\"?"
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/json/format-query-results-as-json-with-for-json-sql-server?view=sql-server-ver16",
        "document": "Format query results as JSON with FOR JSON\n\nApplies to: SQL Server Azure SQL Managed Instance Azure Synapse Analytics (serverless SQL pool only) SQL analytics endpoint in Microsoft Fabric Warehouse in Microsoft Fabric\n\nFormat query results as JSON, or export data from SQL Server as JSON, by adding the clause to a statement. Use the clause to simplify client applications by delegating the formatting of JSON output from the app to SQL Server.\n\nIn Fabric Data Warehouse, must be the last operator in the query, and so is not allowed inside subqueries.\n\nWhen you use the clause, you can specify the structure of the JSON output explicitly, or let the structure of the statement determine the output.\n• None To maintain full control over the format of the JSON output, use . You can create wrapper objects and nest complex properties.\n• None To format the JSON output automatically based on the structure of the statement, use .\n\nHere's an example of a statement with the clause and its output.\n\nIn mode, you can use the dot syntax - for example, - to format nested output. Here's a sample query that uses mode with the clause. The following example also uses the option to specify a named root element. More info about FOR JSON PATH For more detailed info and examples, see Format Nested JSON Output with PATH Mode. For syntax and usage, see SELECT - FOR Clause (Transact-SQL). In mode, the structure of the statement determines the format of the JSON output. By default, values aren't included in the output. You can use to change this behavior. Here's a sample query that uses mode with the clause. SELECT name, surname FROM emp FOR JSON AUTO; Example with JOIN and The following example of includes a display of what the JSON results look like when there's a 1:many relationship between data from joined tables. The absence of the null value from the returned JSON is also illustrated. However, you can override this default behavior by use of the keyword on the clause. DROP TABLE IF EXISTS #tabStudent; DROP TABLE IF EXISTS #tabClass; GO CREATE TABLE #tabClass ( ClassGuid UNIQUEIDENTIFIER NOT NULL DEFAULT newid(), ClassName NVARCHAR(32) NOT NULL ); CREATE TABLE #tabStudent ( StudentGuid UNIQUEIDENTIFIER NOT NULL DEFAULT newid(), StudentName NVARCHAR(32) NOT NULL, ClassGuid UNIQUEIDENTIFIER NULL -- Foreign key. ); GO INSERT INTO #tabClass (ClassGuid, ClassName) VALUES ('DE807673-ECFC-4850-930D-A86F921DE438', 'Algebra Math'), ('C55C6819-E744-4797-AC56-FF8A729A7F5C', 'Calculus Math'), ('98509D36-A2C8-4A65-A310-E744F5621C83', 'Art Painting'); INSERT INTO #tabStudent (StudentName, ClassGuid) VALUES ('Alice Apple', 'DE807673-ECFC-4850-930D-A86F921DE438'), ('Alice Apple', 'C55C6819-E744-4797-AC56-FF8A729A7F5C'), ('Betty Boot', 'C55C6819-E744-4797-AC56-FF8A729A7F5C'), ('Betty Boot', '98509D36-A2C8-4A65-A310-E744F5621C83'), ('Carla Cap', null); GO SELECT c.ClassName, s.StudentName FROM #tabClass AS c RIGHT JOIN #tabStudent AS s ON s.ClassGuid = c.ClassGuid ORDER BY c.ClassName, s.StudentName FOR JSON AUTO -- To include NULL values in the output, uncomment the following line: --, INCLUDE_NULL_VALUES ; GO DROP TABLE IF EXISTS #tabStudent; DROP TABLE IF EXISTS #tabClass; GO And next is the JSON that is output by the preceding SELECT. More info about FOR JSON AUTO For more detailed info and examples, see Format JSON Output Automatically with AUTO Mode (SQL Server). For syntax and usage, see SELECT - FOR Clause (Transact-SQL).\n\nControl the output of the clause, using the following extra options.\n• To add a single, top-level element to the JSON output, specify the option. If you don't specify this option, the JSON output doesn't have a root element. For more info, see Add a Root Node to JSON Output with the ROOT Option (SQL Server).\n• To include null values in the JSON output, specify the option. If you don't specify this option, the output doesn't include JSON properties for values in the query results. For more info, see Include Null Values in JSON - INCLUDE_NULL_VALUES Option.\n• To remove the square brackets that surround the JSON output of the clause by default, specify the option. Use this option to generate a single JSON object as output from a single-row result. If you don't specify this option, the JSON output is formatted as an array - that is, the output is enclosed within square brackets. For more info, see Remove Square Brackets from JSON - WITHOUT_ARRAY_WRAPPER Option.\n\nOutput of the FOR JSON clause\n\nThe output of the clause has the following characteristics:\n• \n• A large result set splits the long JSON string across multiple rows.\n• None By default, SQL Server Management Studio (SSMS) concatenates the results into a single row when the output setting is Results to Grid. The SSMS status bar displays the actual row count.\n• None Other client applications might require code to recombine lengthy results into a single, valid JSON string by concatenating the contents of multiple rows. For an example of this code in a C# application, see Use FOR JSON output in a C# client app.\n• None The results are formatted as an array of JSON objects.\n• None The number of elements in the JSON array is equal to the number of rows in the results of the SELECT statement (before the FOR JSON clause is applied).\n• None Each row in the results of the SELECT statement (before the FOR JSON clause is applied) becomes a separate JSON object in the array.\n• None Each column in the results of the SELECT statement (before the FOR JSON clause is applied) becomes a property of the JSON object.\n• None Both the names of columns and their values are escaped according to JSON syntax. For more info, see How FOR JSON escapes special characters and control characters (SQL Server).\n\nHere's an example that demonstrates how the clause formats the JSON output.\n• How FOR JSON converts SQL Server data types to JSON data types (SQL Server)\n• How FOR JSON escapes special characters and control characters (SQL Server)\n• Video: JSON as a bridge between NoSQL and relational worlds\n• Use FOR JSON output in SQL Server and in client apps (SQL Server)"
    },
    {
        "link": "https://stackoverflow.com/questions/64541493/how-to-create-json-from-variables-in-sql-server-using-for-json-auto",
        "document": "I'm trying to write a query in SQL Server 2016 where I:\n• create JSON objects from those variables to store in my database\n\nThis is a basic example of the code I have so far\n\nFrom this, I am hoping to get a Json object that looks something like this:\n\nWhen I try to run this, I am getting the error: \"FOR JSON AUTO requires at least one table for generating JSON objects. Use FOR JSON PATH or add a FROM clause with a table name.\"\n\nWhat is the best way to implement this workflow?"
    },
    {
        "link": "https://reddit.com/r/roguelikedev/comments/j5ljzd/game_data_storage_json_sql",
        "document": "How do you store your game data, such as character class properties, weapon types or monster stats? I'm currently developing a solution that uses a SQLite database for this purpose; however, this format is certainly harder to human-read and fiddle with than a series of JSON files. Besides, relational DBs might prove trickier when the data I want to store is more complex in its structure. There may be other solutions, of course. How do you do this?\n\nThe idea to use a SQLite database came naturally when I started using databases as savefiles. It makes sense for me, since the savefile in my game includes world data (worlds are generated for each game), items, monsters, etc. I'm not so sure about static game data, however."
    },
    {
        "link": "https://docs.oracle.com/database/122/ADJSN/generation.htm",
        "document": "You can use SQL/JSON functions , , , and to construct JSON data from non-JSON data in the database. The JSON data is returned as a SQL value. These generation functions make it easy to construct JSON data directly from a SQL query. They allow non-JSON data to be represented as JSON objects and JSON arrays. You can generate complex, hierarchical JSON documents by nesting calls to these functions. Nested subqueries can generate JSON collections that represent one-to-many relationships.Foot 1 The Best Way to Construct JSON Data from Non-JSON Data Alternatives to using the SQL/JSON generation functions are generally error prone or inefficient.\n• Using string concatenation to generate JSON documents is error prone. In particular, there are a number of complex rules that must be respected concerning when and how to escape special characters, such as double quotation marks ( ). It is easy to overlook or misunderstand these rules, which can result in generating incorrect JSON data.\n• Reading non-JSON result sets from the database and using client-side application code to generate JSON data is typically quite inefficient, particularly due to network overhead. When representing one-to-many relationships as JSON data, multiple operations are often required, to collect all of the non-JSON data needed. If the documents to be generated represent multiple levels of one-to-many relationships then this technique can be quite costly. The SQL/JSON generation functions do not suffer from such problems; they are designed for the job of constructing JSON data from non-JSON database data.\n• By using SQL subqueries with these functions, you can generate an entire set of JSON documents using a single SQL statement, which allows the generation operation to be optimized.\n• Because only the generated documents are returned to a client, network overhead is minimized: there is at most one round trip per document generated.\n• Functions and construct a JSON object or array, respectively, given as arguments SQL name–value pairs and values, respectively. The number of arguments corresponds to the number of object members and array elements, respectively (except when an argument expression evaluates to SQL and the clause applies). Each name must have the syntax of a SQL identifier. Each value can be any SQL value, including a value computed using a scalar SQL (sub)query that returns at most one item (a single row with a single column — an error is raised if such a query argument returns more than one row.)\n• Functions , and are aggregate SQL functions. They transform information that is contained in the rows of a grouped SQL query into JSON objects and arrays, respectively. Evaluation of the arguments determines the number of object members and array elements, respectively; that is, the size of the result reflects the current queried data. For , the order of object members is unspecified. For , the order of array elements reflects the query result order. You can use SQL in the query to control the array element order. Formats of Input Values for JSON_OBJECT and JSON_ARRAY For function you can use any SQL value of the supported data types as arguments. Similarly for the value arguments of name–value pairs that you pass to function . In some cases you know or expect that such a value is in fact JSON data (represented as a SQL string or number). You can add keywords after any input value expression to declare this expectation for the value that results from that expression. If Oracle can determine that the value is in fact JSON data then it is treated as if it were followed by an explicit declaration. This is the case, for instance, if the value expression is an invocation of a SQL/JSON generation function. specify , and if Oracle determine that the value is JSON data, then it is assumed to be ordinary (non-JSON) SQL data. In that case it is serialized as follows (any other SQL value raises an error):\n• A or value is wrapped in double quotation marks ( ).\n• A numeric value is converted to a JSON number. (It is not quoted.)\n• A or value is converted to ISO 8601 format, and the result is enclosed in double quotation marks ( ).\n• A PL/SQL value is converted to JSON or . (It is not quoted.)\n• A value is converted to JSON , regardless of the data type. If you dospecify, and if Oracledetermine that the value is JSON data, then it is assumed to be ordinary (non-JSON) SQL data. In that case it is serialized as follows (any other SQL value raises an error): Because Oracle SQL treats an empty string as there is no way to construct an empty JSON string ( ). The format of an input argument can affect the format of the data that is returned by the function. In particular, if an input is determined to be of format JSON then it is treated as JSON data when computing the return value. Example 19-1 illustrates this — it explicitly uses to interpret the SQL string as JSON Boolean value . You can optionally specify a SQL -handling clause, a clause, and keyword .\n• -handling clause — Determines how a SQL value resulting from input evaluation is handled.\n• — An input SQL value is converted to JSON for output. This is the default behavior for and .\n• — An input SQL value results in no corresponding output. This is the default behavior for and .\n• clause — The SQL data type used for the function return value. The default is .\n• keyword — If present, the returned JSON data is checked, to be sure it is well-formed. If is present and the returned data is not well-formed then an error is raised. The generated JSON data is returned from the function as a SQL value, whose size can be controlled by the optional clause. For the aggregate SQL functions ( and ), you can also specify as the SQL data type in the clause. JSON values within the returned data are derived from SQL values in the input as follows:\n• A non- and non-number SQL value is converted to a JSON string.\n• A SQL value is handled by the optional -handling clause. Example 19-1 Declaring an Input Value To Be JSON This example specifies for SQL string values and , in order that the JSON Boolean values and are used. SELECT json_object('name' VALUE first_name || ' ' || last_name, 'hasCommission' VALUE CASE WHEN commission_pct IS NULL THEN 'false' ELSE 'true' END ) FROM employees WHERE first_name LIKE 'W%'; JSON_OBJECT('NAME'ISFIRST_NAME||''||LAST_NAME,' ----------------------------------------------- {\"name\":\"William Gietz\",\"hasCommission\": } {\"name\":\"William Smith\",\"hasCommission\": } {\"name\":\"Winston Taylor\",\"hasCommission\": }\n\nSQL/JSON function constructs JSON objects from name–value pairs. Each pair is provided as an explicit argument. Each name of a pair must evaluate to a SQL identifier. Each value of a pair can be any SQL expression. The name and value are separated by keyword . The evaluated arguments you provide to are explicit object field names and field values. The resulting object has an member for each pair of name–value arguments you provide (except when an value expression evaluates to SQL and the clause applies). Example 19-2 Using JSON_OBJECT to Construct JSON Objects This example constructs a JSON object for each employee of table (from standard database schema ) whose salary is less than 15000. The object includes, as the value of its field , an object with fields and . Because the return value of is JSON data, is deduced for the input format of field — the explicit here is not needed. SELECT ('id' VALUE employee_id, 'name' VALUE first_name || ' ' || last_name, 'hireDate' VALUE hire_date, 'pay' VALUE salary, 'contactInfo' VALUE ('mail' VALUE email, 'phone' VALUE phone_number) FORMAT JSON) FROM employees WHERE salary > 15000; -- The query returns rows such as this (pretty-printed here for clarity): {\"id\":101, \"name\":\"Neena Kochhar\", \"hireDate\":\"21-SEP-05\", \"pay\":17000, \"contactInfo\":{\"mail\":\"NKOCHHAR\", \"phone\":\"515.123.4568\"}} Example 19-3 Using JSON_OBJECT With ABSENT ON NULL This example queries table from standard database schema to create JSON objects with fields and . The default -handling behavior for json_object is . In order to prevent the creation of a field with a JSON value, the example uses . The SQL value for column when column has value means that no field is created for that location. SELECT JSON_OBJECT('city' VALUE city, 'province' VALUE state_province ) FROM locations WHERE city LIKE 'S%'; JSON_OBJECT('CITY'ISCITY,'PROVINCE'ISSTATE_PROVINCEABSENTONNULL) ---------------------------------------------------------------- {\"city\":\"Southlake\", :\"Texas\"} {\"city\":\"South San Francisco\", :\"California\"} {\"city\":\"South Brunswick\", :\"New Jersey\"} {\"city\":\"Seattle\", :\"Washington\"} {\"city\":\"Sydney\", :\"New South Wales\"} {\"city\":\"Stretford\", :\"Manchester\"} {\"city\":\"Sao Paulo\", :\"Sao Paulo\"}\n\nSQL/JSON function constructs a JSON array from the results of evaluating its argument SQL expressions. Each argument can be any SQL expression. Array element order is the same as the argument order. The evaluated arguments you provide to are explicit array element values. The resulting array has an element for each argument you provide (except when an argument expression evaluates to SQL and the clause applies). An argument expression that evaluates to a SQL number is converted to a JSON number. A non- and non-number argument value is converted to a JSON string. Example 19-4 Using JSON_ARRAY to Construct a JSON Array This example constructs a JSON object for each job in database table (from standard database schema ). The fields of the objects are the job title and salary range. The salary range (field ) is an array of two numeric values, the minimum and maximum salaries for the job. These values are taken from SQL columns and . SELECT json_object('title' VALUE job_title, 'salaryRange' VALUE (min_salary, max_salary)) FROM jobs; JSON_OBJECT('TITLE'ISJOB_TITLE,'SALARYRANGE'ISJSON_ARRAY(MIN_SALARY,MAX_SALARY)) -------------------------------------------------------------------------------- {\"title\":\"President\",\"salaryRange\":[20080,40000]} {\"title\":\"Administration Vice President\",\"salaryRange\":[15000,30000]} {\"title\":\"Administration Assistant\",\"salaryRange\":[3000,6000]} {\"title\":\"Finance Manager\",\"salaryRange\":[8200,16000]} {\"title\":\"Accountant\",\"salaryRange\":[4200,9000]} {\"title\":\"Accounting Manager\",\"salaryRange\":[8200,16000]} {\"title\":\"Public Accountant\",\"salaryRange\":[4200,9000]} {\"title\":\"Sales Manager\",\"salaryRange\":[10000,20080]} {\"title\":\"Sales Representative\",\"salaryRange\":[6000,12008]} {\"title\":\"Purchasing Manager\",\"salaryRange\":[8000,15000]} {\"title\":\"Purchasing Clerk\",\"salaryRange\":[2500,5500]} {\"title\":\"Stock Manager\",\"salaryRange\":[5500,8500]} {\"title\":\"Stock Clerk\",\"salaryRange\":[2008,5000]} {\"title\":\"Shipping Clerk\",\"salaryRange\":[2500,5500]} {\"title\":\"Programmer\",\"salaryRange\":[4000,10000]} {\"title\":\"Marketing Manager\",\"salaryRange\":[9000,15000]} {\"title\":\"Marketing Representative\",\"salaryRange\":[4000,9000]} {\"title\":\"Human Resources Representative\",\"salaryRange\":[4000,9000]} {\"title\":\"Public Relations Representative\",\"salaryRange\":[4500,10500]}\n\nFootnote 1: The behavior of the SQL/JSON generation functions for JSON data is similar to that of the SQL/XML generation functions for XML data."
    }
]