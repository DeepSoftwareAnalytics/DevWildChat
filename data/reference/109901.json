[
    {
        "link": "https://nodejs.org/api/child_process.html",
        "document": "The module provides the ability to spawn subprocesses in a manner that is similar, but not identical, to . This capability is primarily provided by the function:\n\nBy default, pipes for , , and are established between the parent Node.js process and the spawned subprocess. These pipes have limited (and platform-specific) capacity. If the subprocess writes to stdout in excess of that limit without the output being captured, the subprocess blocks waiting for the pipe buffer to accept more data. This is identical to the behavior of pipes in the shell. Use the option if the output will not be consumed.\n\nThe command lookup is performed using the environment variable if is in the object. Otherwise, is used. If is set without , lookup on Unix is performed on a default search path search of (see your operating system's manual for execvpe/execvp), on Windows the current processes environment variable is used.\n\nOn Windows, environment variables are case-insensitive. Node.js lexicographically sorts the keys and uses the first one that case-insensitively matches. Only first (in lexicographic order) entry will be passed to the subprocess. This might lead to issues on Windows when passing objects to the option that have multiple variants of the same key, such as and .\n\nThe method spawns the child process asynchronously, without blocking the Node.js event loop. The function provides equivalent functionality in a synchronous manner that blocks the event loop until the spawned process either exits or is terminated.\n\nFor convenience, the module provides a handful of synchronous and asynchronous alternatives to and . Each of these alternatives are implemented on top of or .\n• : spawns a shell and runs a command within that shell, passing the and to a callback function when complete.\n• : similar to except that it spawns the command directly without first spawning a shell by default.\n• : spawns a new Node.js process and invokes a specified module with an IPC communication channel established that allows sending messages between parent and child.\n• : a synchronous version of that will block the Node.js event loop.\n• : a synchronous version of that will block the Node.js event loop.\n\nFor certain use cases, such as automating shell scripts, the synchronous counterparts may be more convenient. In many cases, however, the synchronous methods can have significant impact on performance due to stalling the event loop while spawned processes complete.\n\nThe , , , and methods all follow the idiomatic asynchronous programming pattern typical of other Node.js APIs. Each of the methods returns a instance. These objects implement the Node.js API, allowing the parent process to register listener functions that are called when certain events occur during the life cycle of the child process. The and methods additionally allow for an optional function to be specified that is invoked when the child process terminates. The importance of the distinction between and can vary based on platform. On Unix-type operating systems (Unix, Linux, macOS) can be more efficient because it does not spawn a shell by default. On Windows, however, and files are not executable on their own without a terminal, and therefore cannot be launched using . When running on Windows, and files can be invoked using with the option set, with , or by spawning and passing the or file as an argument (which is what the option and do). In any case, if the script filename contains spaces it needs to be quoted. The option can be a WHATWG object using protocol. The option is supported now.\n• <string> The command to run, with space-separated arguments.\n• <Object>\n• <string> Shell to execute the command with. See Shell requirements and Default Windows shell. Default: on Unix, on Windows.\n• <AbortSignal> allows aborting the child process using an AbortSignal.\n• <number> Largest amount of data in bytes allowed on stdout or stderr. If exceeded, the child process is terminated and any output is truncated. See caveat at and Unicode. Default: .\n• <number> Sets the user identity of the process (see ).\n• <number> Sets the group identity of the process (see ).\n• <boolean> Hide the subprocess console window that would normally be created on Windows systems. Default: .\n• <Function> called with the output when process terminates. Spawns a shell then executes the within that shell, buffering any generated output. The string passed to the exec function is processed directly by the shell and special characters (vary based on shell) need to be dealt with accordingly: Never pass unsanitized user input to this function. Any input containing shell metacharacters may be used to trigger arbitrary command execution. If a function is provided, it is called with the arguments . On success, will be . On error, will be an instance of . The property will be the exit code of the process. By convention, any exit code other than indicates an error. will be the signal that terminated the process. The and arguments passed to the callback will contain the stdout and stderr output of the child process. By default, Node.js will decode the output as UTF-8 and pass strings to the callback. The option can be used to specify the character encoding used to decode the stdout and stderr output. If is , or an unrecognized character encoding, objects will be passed to the callback instead. If is greater than , the parent process will send the signal identified by the property (the default is ) if the child process runs longer than milliseconds. Unlike the POSIX system call, does not replace the existing process and uses a shell to execute the command. If this method is invoked as its ed version, it returns a for an with and properties. The returned instance is attached to the as a property. In case of an error (including any error resulting in an exit code other than 0), a rejected promise is returned, with the same object given in the callback, but with two additional properties and . If the option is enabled, calling on the corresponding is similar to calling on the child process except the error passed to the callback will be an : The option can be a WHATWG object using protocol. The option is supported now.\n• <string> The name or path of the executable file to run.\n• <Object>\n• <number> Largest amount of data in bytes allowed on stdout or stderr. If exceeded, the child process is terminated and any output is truncated. See caveat at and Unicode. Default: .\n• <number> Sets the user identity of the process (see ).\n• <number> Sets the group identity of the process (see ).\n• <boolean> Hide the subprocess console window that would normally be created on Windows systems. Default: .\n• <boolean> No quoting or escaping of arguments is done on Windows. Ignored on Unix. Default: .\n• <boolean> | <string> If , runs inside of a shell. Uses on Unix, and on Windows. A different shell can be specified as a string. See Shell requirements and Default Windows shell. Default: (no shell).\n• <AbortSignal> allows aborting the child process using an AbortSignal.\n• <Function> Called with the output when process terminates. The function is similar to except that it does not spawn a shell by default. Rather, the specified executable is spawned directly as a new process making it slightly more efficient than . The same options as are supported. Since a shell is not spawned, behaviors such as I/O redirection and file globbing are not supported. The and arguments passed to the callback will contain the stdout and stderr output of the child process. By default, Node.js will decode the output as UTF-8 and pass strings to the callback. The option can be used to specify the character encoding used to decode the stdout and stderr output. If is , or an unrecognized character encoding, objects will be passed to the callback instead. If this method is invoked as its ed version, it returns a for an with and properties. The returned instance is attached to the as a property. In case of an error (including any error resulting in an exit code other than 0), a rejected promise is returned, with the same object given in the callback, but with two additional properties and . If the option is enabled, do not pass unsanitized user input to this function. Any input containing shell metacharacters may be used to trigger arbitrary command execution. If the option is enabled, calling on the corresponding is similar to calling on the child process except the error passed to the callback will be an : The parameter can be a WHATWG object using protocol. The option can be a WHATWG object using protocol. The option is supported now. The option can now be a string. The option is supported now.\n• <string> | <URL> The module to run in the child.\n• <Object>\n• <boolean> Prepare child process to run independently of its parent process. Specific behavior depends on the platform (see ).\n• <string> Executable used to create the child process.\n• <string[]> List of string arguments passed to the executable. Default: .\n• <number> Sets the group identity of the process (see ).\n• <string> Specify the kind of serialization used for sending messages between processes. Possible values are and . See Advanced serialization for more details. Default: .\n• <AbortSignal> Allows closing the child process using an AbortSignal.\n• <string> | <integer> The signal value to be used when the spawned process will be killed by timeout or abort signal. Default: .\n• <boolean> If , stdin, stdout, and stderr of the child process will be piped to the parent process, otherwise they will be inherited from the parent process, see the and options for 's for more details. Default: .\n• <Array> | <string> See 's . When this option is provided, it overrides . If the array variant is used, it must contain exactly one item with value or an error will be thrown. For instance .\n• <number> Sets the user identity of the process (see ).\n• <boolean> No quoting or escaping of arguments is done on Windows. Ignored on Unix. Default: .\n• <number> In milliseconds the maximum amount of time the process is allowed to run. Default: . The method is a special case of used specifically to spawn new Node.js processes. Like , a object is returned. The returned will have an additional communication channel built-in that allows messages to be passed back and forth between the parent and child. See for details. Keep in mind that spawned Node.js child processes are independent of the parent with exception of the IPC communication channel that is established between the two. Each process has its own memory, with their own V8 instances. Because of the additional resource allocations required, spawning a large number of child Node.js processes is not recommended. By default, will spawn new Node.js instances using the of the parent process. The property in the object allows for an alternative execution path to be used. Node.js processes launched with a custom will communicate with the parent process using the file descriptor (fd) identified using the environment variable on the child process. Unlike the POSIX system call, does not clone the current process. The option available in is not supported by and will be ignored if set. If the option is enabled, calling on the corresponding is similar to calling on the child process except the error passed to the callback will be an : The option can be a WHATWG object using protocol. The option is supported now. The option is supported now. The option is supported now. The option is supported now.\n• <Object>\n• <string> Explicitly set the value of sent to the child process. This will be set to if not specified.\n• <boolean> Prepare child process to run independently of its parent process. Specific behavior depends on the platform (see ).\n• <number> Sets the user identity of the process (see ).\n• <number> Sets the group identity of the process (see ).\n• <string> Specify the kind of serialization used for sending messages between processes. Possible values are and . See Advanced serialization for more details. Default: .\n• <boolean> | <string> If , runs inside of a shell. Uses on Unix, and on Windows. A different shell can be specified as a string. See Shell requirements and Default Windows shell. Default: (no shell).\n• <boolean> No quoting or escaping of arguments is done on Windows. Ignored on Unix. This is set to automatically when is specified and is CMD. Default: .\n• <boolean> Hide the subprocess console window that would normally be created on Windows systems. Default: .\n• <AbortSignal> allows aborting the child process using an AbortSignal.\n• <number> In milliseconds the maximum amount of time the process is allowed to run. Default: .\n• <string> | <integer> The signal value to be used when the spawned process will be killed by timeout or abort signal. Default: . The method spawns a new process using the given , with command-line arguments in . If omitted, defaults to an empty array. If the option is enabled, do not pass unsanitized user input to this function. Any input containing shell metacharacters may be used to trigger arbitrary command execution. A third argument may be used to specify additional options, with these defaults: Use to specify the working directory from which the process is spawned. If not given, the default is to inherit the current working directory. If given, but the path does not exist, the child process emits an error and exits immediately. is also emitted when the command does not exist. Use to specify environment variables that will be visible to the new process, the default is . values in will be ignored. Example of running , capturing , , and the exit code: Example: A very elaborate way to run Example of checking for failed : Certain platforms (macOS, Linux) will use the value of for the process title while others (Windows, SunOS) will use . Node.js overwrites with on startup, so in a Node.js child process will not match the parameter passed to from the parent. Retrieve it with the property instead. If the option is enabled, calling on the corresponding is similar to calling on the child process except the error passed to the callback will be an : On Windows, setting to makes it possible for the child process to continue running after the parent exits. The child process will have its own console window. Once enabled for a child process, it cannot be disabled. On non-Windows platforms, if is set to , the child process will be made the leader of a new process group and session. Child processes may continue running after the parent exits regardless of whether they are detached or not. See for more information. By default, the parent will wait for the detached child process to exit. To prevent the parent process from waiting for a given to exit, use the method. Doing so will cause the parent process' event loop to not include the child process in its reference count, allowing the parent process to exit independently of the child process, unless there is an established IPC channel between the child and the parent processes. When using the option to start a long-running process, the process will not stay running in the background after the parent exits unless it is provided with a configuration that is not connected to the parent. If the parent process' is inherited, the child process will remain attached to the controlling terminal. Example of a long-running process, by detaching and also ignoring its parent file descriptors, in order to ignore the parent's termination: Alternatively one can redirect the child process' output into files: The value is now accepted as a file descriptor. The option is used to configure the pipes that are established between the parent and child process. By default, the child's stdin, stdout, and stderr are redirected to corresponding , , and streams on the object. This is equivalent to setting the equal to . For convenience, may be one of the following strings: Otherwise, the value of is an array where each index corresponds to an fd in the child. The fds 0, 1, and 2 correspond to stdin, stdout, and stderr, respectively. Additional fds can be specified to create additional pipes between the parent and child. The value is one of the following:\n• : Create a pipe between the child process and the parent process. The parent end of the pipe is exposed to the parent as a property on the object as . Pipes created for fds 0, 1, and 2 are also available as , and , respectively. These are not actual Unix pipes and therefore the child process can not use them by their descriptor files, e.g. or .\n• : Same as except that the flag is set on the handle. This is necessary for overlapped I/O on the child process's stdio handles. See the docs for more details. This is exactly the same as on non-Windows systems.\n• : Create an IPC channel for passing messages/file descriptors between parent and child. A may have at most one IPC stdio file descriptor. Setting this option enables the method. If the child process is a Node.js instance, the presence of an IPC channel will enable and methods, as well as and events within the child process. Accessing the IPC channel fd in any way other than or using the IPC channel with a child process that is not a Node.js instance is not supported.\n• : Instructs Node.js to ignore the fd in the child. While Node.js will always open fds 0, 1, and 2 for the processes it spawns, setting the fd to will cause Node.js to open and attach it to the child's fd.\n• : Pass through the corresponding stdio stream to/from the parent process. In the first three positions, this is equivalent to , , and , respectively. In any other position, equivalent to .\n• <Stream> object: Share a readable or writable stream that refers to a tty, file, socket, or a pipe with the child process. The stream's underlying file descriptor is duplicated in the child process to the fd that corresponds to the index in the array. The stream must have an underlying descriptor (file streams do not start until the event has occurred). NOTE: While it is technically possible to pass as a writable or / as readable, it is not recommended. Readable and writable streams are designed with distinct behaviors, and using them incorrectly (e.g., passing a readable stream where a writable stream is expected) can lead to unexpected results or errors. This practice is discouraged as it may result in undefined behavior or dropped callbacks if the stream encounters errors. Always ensure that is used as writable and / as readable to maintain the intended flow of data between the parent and child processes.\n• Positive integer: The integer value is interpreted as a file descriptor that is open in the parent process. It is shared with the child process, similar to how <Stream> objects can be shared. Passing sockets is not supported on Windows.\n• , : Use default value. For stdio fds 0, 1, and 2 (in other words, stdin, stdout, and stderr) a pipe is created. For fd 3 and up, the default is . It is worth noting that when an IPC channel is established between the parent and child processes, and the child process is a Node.js instance, the child process is launched with the IPC channel unreferenced (using ) until the child process registers an event handler for the event or the event. This allows the child process to exit normally without the process being held open by the open IPC channel. See also: and .\n\nInstances of are not intended to be created directly. Rather, use the , , , or methods to create instances of .\n• <number> The exit code if the child process exited on its own.\n• <string> The signal by which the child process was terminated. The event is emitted after a process has ended and the stdio streams of a child process have been closed. This is distinct from the event, since multiple processes might share the same stdio streams. The event will always emit after was already emitted, or if the child process failed to spawn. The event is emitted after calling the method in parent process or in child process. After disconnecting it is no longer possible to send or receive messages, and the property is . The event is emitted whenever:\n• The process could not be spawned.\n• The process could not be killed.\n• The child process was aborted via the option. The event may or may not fire after an error has occurred. When listening to both the and events, guard against accidentally invoking handler functions multiple times. See also and .\n• <number> The exit code if the child process exited on its own.\n• <string> The signal by which the child process was terminated. The event is emitted after the child process ends. If the process exited, is the final exit code of the process, otherwise . If the process terminated due to receipt of a signal, is the string name of the signal, otherwise . One of the two will always be non- . When the event is triggered, child process stdio streams might still be open. Node.js establishes signal handlers for and and Node.js processes will not terminate immediately due to receipt of those signals. Rather, Node.js will perform a sequence of cleanup actions and then will re-raise the handled signal. The event is triggered when a child process uses to send messages. The message goes through serialization and parsing. The resulting message might not be the same as what is originally sent. If the option was set to used when spawning the child process, the argument can contain data that JSON is not able to represent. See Advanced serialization for more details. The event is emitted once the child process has spawned successfully. If the child process does not spawn successfully, the event is not emitted and the event is emitted instead. If emitted, the event comes before all other events and before any data is received via or . The event will fire regardless of whether an error occurs within the spawned process. For example, if spawns successfully, the event will fire, though may fail to spawn . This caveat also applies when using . The object no longer accidentally exposes native C++ bindings.\n• <Object> A pipe representing the IPC channel to the child process. The property is a reference to the child's IPC channel. If no IPC channel exists, this property is . This method makes the IPC channel keep the event loop of the parent process running if has been called before. This method makes the IPC channel not keep the event loop of the parent process running, and lets it finish even while the channel is open.\n• <boolean> Set to after is called. The property indicates whether it is still possible to send and receive messages from a child process. When is , it is no longer possible to send or receive messages. Closes the IPC channel between parent and child processes, allowing the child process to exit gracefully once there are no other connections keeping it alive. After calling this method the and properties in both the parent and child processes (respectively) will be set to , and it will be no longer possible to pass messages between the processes. The event will be emitted when there are no messages in the process of being received. This will most often be triggered immediately after calling . When the child process is a Node.js instance (e.g. spawned using ), the method can be invoked within the child process to close the IPC channel as well. The property indicates the exit code of the child process. If the child process is still running, the field will be . The method sends a signal to the child process. If no argument is given, the process will be sent the signal. See for a list of available signals. This function returns if succeeds, and otherwise. The object may emit an event if the signal cannot be delivered. Sending a signal to a child process that has already exited is not an error but may have unforeseen consequences. Specifically, if the process identifier (PID) has been reassigned to another process, the signal will be delivered to that process instead which can have unexpected results. While the function is called , the signal delivered to the child process may not actually terminate the process. On Windows, where POSIX signals do not exist, the argument will be ignored except for , , and , and the process will always be killed forcefully and abruptly (similar to ). See Signal Events for more details. On Linux, child processes of child processes will not be terminated when attempting to kill their parent. This is likely to happen when running a new process in a shell or with the use of the option of :\n• <boolean> Set to after is used to successfully send a signal to the child process. The property indicates whether the child process successfully received a signal from . The property does not indicate that the child process has been terminated. Returns the process identifier (PID) of the child process. If the child process fails to spawn due to errors, then the value is and is emitted. Calling after making a call to will restore the removed reference count for the child process, forcing the parent process to wait for the child process to exit before exiting itself. The parameter, and the option in particular, is supported now. This method returns a boolean for flow control now. The parameter is supported now.\n• <Object> The argument, if present, is an object used to parameterize the sending of certain types of handles. supports the following properties:\n• <boolean> A value that can be used when passing instances of . When , the socket is kept open in the sending process. Default: . When an IPC channel has been established between the parent and child processes ( i.e. when using ), the method can be used to send messages to the child process. When the child process is a Node.js instance, these messages can be received via the event. The message goes through serialization and parsing. The resulting message might not be the same as what is originally sent. For example, in the parent script: And then the child script, might look like this: Child Node.js processes will have a method of their own that allows the child process to send messages back to the parent process. There is a special case when sending a message. Messages containing a prefix in the property are reserved for use within Node.js core and will not be emitted in the child's event. Rather, such messages are emitted using the event and are consumed internally by Node.js. Applications should avoid using such messages or listening for events as it is subject to change without notice. The optional argument that may be passed to is for passing a TCP server or socket object to the child process. The child process will receive the object as the second argument passed to the callback function registered on the event. Any data that is received and buffered in the socket will not be sent to the child. Sending IPC sockets is not supported on Windows. The optional is a function that is invoked after the message is sent but before the child process may have received it. The function is called with a single argument: on success, or an object on failure. If no function is provided and the message cannot be sent, an event will be emitted by the object. This can happen, for instance, when the child process has already exited. will return if the channel has closed or when the backlog of unsent messages exceeds a threshold that makes it unwise to send more. Otherwise, the method returns . The function can be used to implement flow control. The argument can be used, for instance, to pass the handle of a TCP server object to the child process as illustrated in the example below: The child process would then receive the server object as: Once the server is now shared between the parent and child, some connections can be handled by the parent and some by the child. While the example above uses a server created using the module, module servers use exactly the same workflow with the exceptions of listening on a event instead of and using instead of . This is, however, only supported on Unix platforms. Similarly, the argument can be used to pass the handle of a socket to the child process. The example below spawns two children that each handle connections with \"normal\" or \"special\" priority: The would receive the socket handle as the second argument passed to the event callback function: Do not use on a socket that has been passed to a subprocess. The parent cannot track when the socket is destroyed. Any handlers in the subprocess should verify that exists, as the connection may have been closed during the time it takes to send the connection to the child. The property indicates the signal received by the child process if any, else . The property represents the full list of command-line arguments the child process was launched with. The property indicates the executable file name of the child process that is launched. For , its value will be equal to . For , its value will be the name of the executable file. For , its value will be the name of the shell in which the child process is launched. If the child process was spawned with set to anything other than , then this will be . is an alias for . Both properties will refer to the same value. The property can be or if the child process could not be successfully spawned. If a child process waits to read all of its input, the child process will not continue until this stream has been closed via . If the child process was spawned with set to anything other than , then this will be . is an alias for . Both properties will refer to the same value. The property can be or if the child process could not be successfully spawned. A sparse array of pipes to the child process, corresponding with positions in the option passed to that have been set to the value . , , and are also available as , , and , respectively. In the following example, only the child's fd (stdout) is configured as a pipe, so only the parent's is a stream, all other values in the array are . The property can be if the child process could not be successfully spawned. If the child process was spawned with set to anything other than , then this will be . is an alias for . Both properties will refer to the same value. The property can be or if the child process could not be successfully spawned. By default, the parent process will wait for the detached child process to exit. To prevent the parent process from waiting for a given to exit, use the method. Doing so will cause the parent's event loop to not include the child process in its reference count, allowing the parent to exit independently of the child, unless there is an established IPC channel between the child and the parent processes."
    },
    {
        "link": "https://stackoverflow.com/questions/68009544/how-to-make-child-process-exec-run-bat-file",
        "document": "I am asking a strange question, but I hope this helps other people if they encounter a similar problem.\n\nI've got regular commands.bat file and I want node to run (execute) this file. So, I've done something like that:\n\nBut it doesn't seem to work at all.\n\nNode.js docs says that expects command or executable as first parameter.\n\nProbably, there is better way to run .bat file and I will appreciate it if you share this knowledge with me. Thanks in advance!"
    },
    {
        "link": "https://stackoverflow.com/questions/37292103/spawn-new-child-process-with-own-console-window",
        "document": "I've got a parent application in node.js which needs to spawn multiple worker applications (also in node.js) applications according to need.\n\nI've already got communication working between them - don't need to use any of the built-in node stuff.\n\nNow the problem is that I'd like each worker process to have it's own console window - since I do a lot of writing to the console and I want to keep an eye on it.\n\nI've looked through the Node child_process documentation, and it says that by setting options to detached:\n\nHowever when I use my own code\n\nIt doesn't work. The child application does spawn, but no console window turns up."
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-launch-child-processes-in-node-js",
        "document": "The author selected the COVID-19 Relief Fund to receive a donation as part of the Write for DOnations program.\n\nWhen a user executes a single Node.js program, it runs as a single operating system (OS) process that represents the instance of the program running. Within that process, Node.js executes programs on a single thread. As mentioned earlier in this series with the How To Write Asynchronous Code in Node.js tutorial, because only one thread can run on one process, operations that take a long time to execute in JavaScript can block the Node.js thread and delay the execution of other code. A key strategy to work around this problem is to launch a child process, or a process created by another process, when faced with long-running tasks. When a new process is launched, the operating system can employ multiprocessing techniques to ensure that the main Node.js process and the additional child process run concurrently, or at the same time.\n\nNode.js includes the module, which has functions to create new processes. Aside from dealing with long-running tasks, this module can also interface with the OS and run shell commands. System administrators can use Node.js to run shell commands to structure and maintain their operations as a Node.js module instead of shell scripts.\n\nIn this tutorial, you will create child processes while executing a series of sample Node.js applications. You’ll create processes with the module by retrieving the results of a child process via a buffer or string with the function, and then from a data stream with the function. You’ll finish by using to create a child process of another Node.js program that you can communicate with as it’s running. To illustrate these concepts, you will write a program to list the contents of a directory, a program to find files, and a web server with multiple endpoints.\n• You must have Node.js installed to run through these examples. This tutorial uses version 10.22.0. To install this on macOS or Ubuntu 18.04, follow the steps in How To Install Node.js and Create a Local Development Environment on macOS or the Installing Using a PPA section of How To Install Node.js on Ubuntu 18.04.\n• This article uses an example that creates a web server to explain how the function works. To get familiar with creating web servers, you can read our guide on How To Create a Web Server in Node.js with the HTTP Module.\n\nDevelopers commonly create child processes to execute commands on their operating system when they need to manipulate the output of their Node.js programs with a shell, such as using shell piping or redirection. The function in Node.js creates a new shell process and executes a command in that shell. The output of the command is kept in a buffer in memory, which you can accept via a callback function passed into .\n\nLet’s begin creating our first child processes in Node.js. First, we need to set up our coding environment to store the scripts we’ll create throughout this tutorial. In the terminal, create a folder called :\n\nEnter that folder in the terminal with the command:\n\nCreate a new file called and open the file in a text editor. In this tutorial we will use nano, a terminal text editor:\n\nWe’ll be writing a Node.js module that uses the function to run the command. The command list the files and folders in a directory. This program takes the output from the command and displays it to the user.\n\nIn the text editor, add the following code:\n\nWe first import the command from the module using JavaScript destructuring. Once imported, we use the function. The first argument is the command we would like to run. In this case, it’s , which lists all the files and folders in the current directory in long format, with a total file size in human-readable units at the top of the output.\n\nThe second argument is a callback function with three parameters: , , and . If the command failed to run, will capture the reason why it failed. This can happen if the shell cannot find the command you’re trying to execute. If the command is executed successfully, any data it writes to the standard output stream is captured in , and any data it writes to the standard error stream is captured in .\n\nIn our callback function, we first check if we received an error. If we did, we display the error’s (a property of the object) with and end the function with . We then check if the command printed an error message and if so. If the command successfully executes, we log its output to the console with .\n\nLet’s run this file to see it in action. First, save and exit by pressing .\n\nBack in your terminal, run your application with the command:\n\nYour terminal will display the following output:\n\nThis lists the contents of the directory in long format, along with the size of the contents at the top. Your results will have your own user and group in place of . This shows that the program successfully ran the shell command .\n\nNow let’s look at another way to execute concurrent processes. Node.js’s module can also run executable files with the function. The key difference between the and functions is that the first argument of is now a path to an executable file instead of a command. The output of the executable file is stored in a buffer like , which we access via a callback function with , , and parameters.\n\nLet’s begin by adding an executable script for to run. We’ll write a bash script that downloads the Node.js logo from the Node.js website and Base64 encodes it to convert its data to a string of ASCII characters.\n\nNow write a script to download the image and base64 convert it:\n\nThe first statement is a shebang statement. It’s used in Unix, Linux, and macOS when we want to specify a shell to execute our script. The second statement is a command. The cURL utility, whose command is , is a command-line tool that can transfer data to and from a server. We use cURL to download the Node.js logo from the website, and then we use redirection to save the downloaded data to a new file . The last statement uses the utility to encode the file we downloaded with cURL. The script then outputs the encoded string to the console.\n\nIn order for our Node program to run the bash script, we have to make it executable. To do this, run the following:\n\nThis will give your current user the permission to execute the file.\n\nWith our script in place, we can write a new Node.js module to execute it. This script will use to run the script in a child process, catching any errors and displaying all output to console.\n\nIn your terminal, make a new JavaScript file called :\n\nType the following code in the text editor:\n\nWe use JavaScript destructuring to import the function from the module. We then use that function, passing the file path as the first name. contains the directory path of the module in which it is written. Node.js provides the variable to a module when the module runs. By using , our script will always find the file across different operating systems, no matter where we run . Note that for our current project setup, and must be in the same folder.\n\nThe second argument is a callback with the , , and parameters. Like with our previous example that used , we check for each possible output of the script file and log them to the console.\n\nIn your text editor, save this file and exit from the editor.\n\nIn your terminal, use to execute the module:\n\nRunning this script will produce output like this:\n\nNote that we truncated the output in this article because of its large size.\n\nBefore base64 encoding the image, first downloads it. You can also verify that you downloaded the image by inspecting the current directory.\n\nExecute to find the updated list of files in our directory:\n\nThe script will display content similar to the following on the terminal:\n\nWe’ve now successfully executed as a child process in Node.js using the function.\n\nThe and functions can run commands on the operating system’s shell in a Node.js child process. Node.js also provides another method with similar functionality, . The difference is that instead of getting the output of the shell commands all at once, we get them in chunks via a stream. In the next section we’ll use the command to create a child process.\n\nThe function runs a command in a process. This function returns data via the stream API. Therefore, to get the output of the child process, we need to listen for stream events.\n\nStreams in Node.js are instances of event emitters. If you would like to learn more about listening for events and the foundations of interacting with streams, you can read our guide on Using Event Emitters in Node.js.\n\nIt’s often a good idea to choose over or when the command you want to run can output a large amount of data. With a buffer, as used by and , all the processed data is stored in the computer’s memory. For large amounts of data, this can degrade system performance. With a stream, the data is processed and transferred in small chunks. Therefore, you can process a large amount of data without using too much memory at any one time.\n\nLet’s see how we can use to make a child process. We will write a new Node.js module that creates a child process to run the command. We will use the command to list all the files in the current directory.\n\nIn your text editor, begin by calling the command:\n\nWe first imported the function from the module. We then called the function to create a child process that executes the command. We hold the reference to the process in the variable, which we will use to listen to its streamed events.\n\nThe first argument in is the command to run, in this case . The second argument is an array that contains the arguments for the executed command. In this case, we are telling Node.js to execute the command with the argument , thereby making the command find all the files in the current directory. The equivalent command in the terminal is .\n\nWith the and functions, we wrote the arguments along with the command in one string. However, with , all arguments to commands must be entered in the array. That’s because , unlike and , does not create a new shell before running a process. To have commands with their arguments in one string, you need Node.js to create a new shell as well.\n\nLet’s continue our module by adding listeners for the command’s output. Add the following highlighted lines:\n\nCommands can return data in either the stream or the stream, so you added listeners for both. You can add listeners by calling the method of each streams’ objects. The event from the streams gives us the command’s output to that stream. Whenever we get data on either stream, we log it to the console.\n\nWe then listen to two other events: the event if the command fails to execute or is interrupted, and the event for when the command has finished execution, thus closing the stream.\n\nIn the text editor, complete the Node.js module by writing the following highlighted lines:\n\nFor the and events, you set up a listener directly on the variable. When listening for events, if one occurs Node.js provides an object. In this case, you log the error’s property.\n\nWhen listening to the event, Node.js provides the exit code of the command. An exit code denotes if the command ran successfully or not. When a command runs without errors, it returns the lowest possible value for an exit code: . When executed with an error, it returns a non-zero code.\n\nThe module is complete. Save and exit with .\n\nNow, run the code with the command:\n\nOnce complete, you will find the following output:\n\nWe find a list of all files in our current directory and the exit code of the command, which is as it ran successfully. While our current directory has a small number of files, if we ran this code in our home directory, our program would list every single file in every accessible folder for our user. Because it has such a potentially large output, using the function is most ideal as its streams do not require as much memory as a large buffer.\n\nSo far we’ve used functions to create child processes to execute external commands in our operating system. Node.js also provides a way to create a child process that executes other Node.js programs. Let’s use the function to create a child process for a Node.js module in the next section.\n\nNode.js provides the function, a variation of , to create a child process that’s also a Node.js process. The main benefit of using to create a Node.js process over or is that enables communication between the parent and the child process.\n\nWith , in addition to retrieving data from the child process, a parent process can send messages to the running child process. Likewise, the child process can send messages to the parent process.\n\nLet’s see an example where using to create a new Node.js child process can improve the performance of our application. Node.js programs run on a single process. Therefore, CPU intensive tasks like iterating over large loops or parsing large JSON files stop other JavaScript code from running. For certain applications, this is not a viable option. If a web server is blocked, then it cannot process any new incoming requests until the blocking code has completed its execution.\n\nLet’s see this in practice by creating a web server with two endpoints. One endpoint will do a slow computation that blocks the Node.js process. The other endpoint will return a JSON object saying .\n\nFirst, create a new file called , which will have the code for our HTTP server:\n\nWe’ll begin by setting up the HTTP server. This involves importing the module, creating a request listener function, creating a server object, and listening for requests on the server object. If you would like to dive deeper into creating HTTP servers in Node.js or would like a refresher, you can read our guide on How To Create a Web Server in Node.js with the HTTP Module.\n\nEnter the following code in your text editor to set up an HTTP server:\n\nThis code sets up an HTTP server that will run at . It uses template literals to dynamically generate that URL.\n\nNext, we will write an intentionally slow function that counts in a loop 5 billion times. Before the function, add the following code:\n\nThis uses the arrow function syntax to create a loop that counts to .\n\nTo complete this module, we need to add code to the function. Our function will call the on subpath, and return a small JSON message for the other. Add the following code to the module:\n\nIf the user reaches the server at the subpath, then we run . If we are hit at the subpath, we return this JSON message: .\n\nSave and exit the file by pressing .\n\nTo test, run this server module with :\n\nWhen our server starts, the console will display the following:\n\nNow, to test the performance of our module, open two additional terminals. In the first terminal, use the command to make a request to the endpoint, which we expect to be slow:\n\nIn the other terminal, use to make a request to the endpoint like this:\n\nThe first request will return the following JSON:\n\nWhereas the second request will return this JSON:\n\nThe request to completed only after the request to . The blocked all other code from executing while it was still in its loop. You can verify this by looking at the Node.js server output that was logged in your original terminal:\n\nTo process the blocking code while still accepting incoming requests, we can move the blocking code to a child process with . We will move the blocking code into its own module. The Node.js server will then create a child process when someone accesses the endpoint and listen for results from this child process.\n\nRefactor the server by first creating a new module called that will contain :\n\nNow enter the code for once again:\n\nSince this module will be a child process created with , we can also add code to communicate with the parent process when has completed processing. Add the following block of code that sends a message to the parent process with the JSON to return to the user:\n\nLet’s break down this block of code. The messages between a parent and child process created by are accessible via the Node.js global object. We add a listener to the variable to look for events. Once we receive a event, we check if it’s the event. Our server code will send the event when someone accesses the endpoint. Upon receiving that event, we run and create a JSON string with the result of the function. We use to send a message to the parent process.\n\nSave and exit by entering in nano.\n\nNow, let’s modify the file so that instead of calling , it creates a child process that executes .\n\nFirst, import the function from the module:\n\nNext, we are going to remove the from this module and modify the function to create a child process. Change the code in your file so it looks like this:\n\nWhen someone goes to the endpoint, we now create a new child process with . The argument of is the path to the Node.js module. In this case, it is the file in our current directory, which we receive from . The reference to this child process is stored in a variable .\n\nWe then add a listener to the object. This listener captures any messages that the child process gives us. In this case, will return a JSON string with the total number counted by the loop. When we receive that message, we send the JSON to the user.\n\nWe use the function of the variable to give it a message. This program sends the message , which begins the execution of in the child process.\n\nTo test the improvement using made on HTTP server, begin by executing the file with :\n\nLike before, it will output the following message when it launches:\n\nTo test the server, we will need an additional two terminals as we did the first time. You can re-use them if they are still open.\n\nIn the first terminal, use the command to make a request to the endpoint, which takes a while to compute:\n\nIn the other terminal, use to make a request to the endpoint, which responds in a short time:\n\nThe first request will return the following JSON:\n\nWhereas the second request will return this JSON:\n\nUnlike the first time we tried this, the second request to runs immediately. You can confirm by reviewing the logs, which will look like this:\n\nThese logs show that the request for the endpoint ran after the child process was created but before the child process had finished its task.\n\nSince we moved the blocking code in a child process using , the server was still able to respond to other requests and execute other JavaScript code. Because of the function’s message passing ability, we can control when a child process begins an activity and we can return data from a child process to a parent process.\n\nIn this article, you used various functions to create a child process in Node.js. You first created child processes with to run shell commands from Node.js code. You then ran an executable file with the function. You looked at the function, which can also run commands but returns data via a stream and does not start a shell like and . Finally, you used the function to allow for two-way communication between the parent and child process.\n\nTo learn more about the module, you can read the Node.js documentation. If you’d like to continue learning Node.js, you can return to the How To Code in Node.js series, or browse programming projects and setups on our Node topic page."
    },
    {
        "link": "https://github.com/nodejs/node/issues/15217",
        "document": "This ticket is specifically in reference to this: https://nodejs.org/api/child_process.html#child_process_spawning_bat_and_cmd_files_on_windows\n\nI've put together a comparison as an example, basically it uses edgejs to spawn a command that's based off of a file (electron): https://gist.github.com/atrauzzi/bbcc171b57a7ea276a2e6bf6419c7e51\n\nThe point of the comparison is to show that it is possible to run and files without requiring a console window open the whole time. It would just be a matter of figuring out how .net is doing it and plugging into that same mechanism when running on Windows vs however nodejs is currently doing things.\n\nBut I really think this issue is long overdue to be addressed."
    },
    {
        "link": "https://stackoverflow.com/questions/14332721/node-js-spawn-child-process-and-get-terminal-output-live",
        "document": "It's much easier now (6 years later)!\n\nSpawn returns a childObject, which you can then listen for events with. The events are:\n\nThere are also a bunch of objects from childObject, they are:\n\nSee more information here about childObject: https://nodejs.org/api/child_process.html\n\nIf you want to run your process in the background while node is still able to continue to execute, use the asynchronous method. You can still choose to perform actions after your process completes, and when the process has any output (for example if you want to send a script's output to the client).\n\nHere's how you would use a callback + asynchronous method:\n\nUsing the method above, you can send every line of output from the script to the client (for example using Socket.io to send each line when you receive events on or ).\n\nIf you want node to stop what it's doing and wait until the script completes, you can use the synchronous version:\n• If the script takes a while to complete, your server will hang for that amount of time!\n• The stdout will only be returned once the script has finished running. Because it's synchronous, it cannot continue until the current line has finished. Therefore it's unable to capture the 'stdout' event until the spawn line has finished.\n\nHow to use it:"
    },
    {
        "link": "https://nodejs.org/api/child_process.html",
        "document": "The module provides the ability to spawn subprocesses in a manner that is similar, but not identical, to . This capability is primarily provided by the function:\n\nBy default, pipes for , , and are established between the parent Node.js process and the spawned subprocess. These pipes have limited (and platform-specific) capacity. If the subprocess writes to stdout in excess of that limit without the output being captured, the subprocess blocks waiting for the pipe buffer to accept more data. This is identical to the behavior of pipes in the shell. Use the option if the output will not be consumed.\n\nThe command lookup is performed using the environment variable if is in the object. Otherwise, is used. If is set without , lookup on Unix is performed on a default search path search of (see your operating system's manual for execvpe/execvp), on Windows the current processes environment variable is used.\n\nOn Windows, environment variables are case-insensitive. Node.js lexicographically sorts the keys and uses the first one that case-insensitively matches. Only first (in lexicographic order) entry will be passed to the subprocess. This might lead to issues on Windows when passing objects to the option that have multiple variants of the same key, such as and .\n\nThe method spawns the child process asynchronously, without blocking the Node.js event loop. The function provides equivalent functionality in a synchronous manner that blocks the event loop until the spawned process either exits or is terminated.\n\nFor convenience, the module provides a handful of synchronous and asynchronous alternatives to and . Each of these alternatives are implemented on top of or .\n• : spawns a shell and runs a command within that shell, passing the and to a callback function when complete.\n• : similar to except that it spawns the command directly without first spawning a shell by default.\n• : spawns a new Node.js process and invokes a specified module with an IPC communication channel established that allows sending messages between parent and child.\n• : a synchronous version of that will block the Node.js event loop.\n• : a synchronous version of that will block the Node.js event loop.\n\nFor certain use cases, such as automating shell scripts, the synchronous counterparts may be more convenient. In many cases, however, the synchronous methods can have significant impact on performance due to stalling the event loop while spawned processes complete.\n\nThe , , , and methods all follow the idiomatic asynchronous programming pattern typical of other Node.js APIs. Each of the methods returns a instance. These objects implement the Node.js API, allowing the parent process to register listener functions that are called when certain events occur during the life cycle of the child process. The and methods additionally allow for an optional function to be specified that is invoked when the child process terminates. The importance of the distinction between and can vary based on platform. On Unix-type operating systems (Unix, Linux, macOS) can be more efficient because it does not spawn a shell by default. On Windows, however, and files are not executable on their own without a terminal, and therefore cannot be launched using . When running on Windows, and files can be invoked using with the option set, with , or by spawning and passing the or file as an argument (which is what the option and do). In any case, if the script filename contains spaces it needs to be quoted. The option can be a WHATWG object using protocol. The option is supported now.\n• <string> The command to run, with space-separated arguments.\n• <Object>\n• <string> Shell to execute the command with. See Shell requirements and Default Windows shell. Default: on Unix, on Windows.\n• <AbortSignal> allows aborting the child process using an AbortSignal.\n• <number> Largest amount of data in bytes allowed on stdout or stderr. If exceeded, the child process is terminated and any output is truncated. See caveat at and Unicode. Default: .\n• <number> Sets the user identity of the process (see ).\n• <number> Sets the group identity of the process (see ).\n• <boolean> Hide the subprocess console window that would normally be created on Windows systems. Default: .\n• <Function> called with the output when process terminates. Spawns a shell then executes the within that shell, buffering any generated output. The string passed to the exec function is processed directly by the shell and special characters (vary based on shell) need to be dealt with accordingly: Never pass unsanitized user input to this function. Any input containing shell metacharacters may be used to trigger arbitrary command execution. If a function is provided, it is called with the arguments . On success, will be . On error, will be an instance of . The property will be the exit code of the process. By convention, any exit code other than indicates an error. will be the signal that terminated the process. The and arguments passed to the callback will contain the stdout and stderr output of the child process. By default, Node.js will decode the output as UTF-8 and pass strings to the callback. The option can be used to specify the character encoding used to decode the stdout and stderr output. If is , or an unrecognized character encoding, objects will be passed to the callback instead. If is greater than , the parent process will send the signal identified by the property (the default is ) if the child process runs longer than milliseconds. Unlike the POSIX system call, does not replace the existing process and uses a shell to execute the command. If this method is invoked as its ed version, it returns a for an with and properties. The returned instance is attached to the as a property. In case of an error (including any error resulting in an exit code other than 0), a rejected promise is returned, with the same object given in the callback, but with two additional properties and . If the option is enabled, calling on the corresponding is similar to calling on the child process except the error passed to the callback will be an : The option can be a WHATWG object using protocol. The option is supported now.\n• <string> The name or path of the executable file to run.\n• <Object>\n• <number> Largest amount of data in bytes allowed on stdout or stderr. If exceeded, the child process is terminated and any output is truncated. See caveat at and Unicode. Default: .\n• <number> Sets the user identity of the process (see ).\n• <number> Sets the group identity of the process (see ).\n• <boolean> Hide the subprocess console window that would normally be created on Windows systems. Default: .\n• <boolean> No quoting or escaping of arguments is done on Windows. Ignored on Unix. Default: .\n• <boolean> | <string> If , runs inside of a shell. Uses on Unix, and on Windows. A different shell can be specified as a string. See Shell requirements and Default Windows shell. Default: (no shell).\n• <AbortSignal> allows aborting the child process using an AbortSignal.\n• <Function> Called with the output when process terminates. The function is similar to except that it does not spawn a shell by default. Rather, the specified executable is spawned directly as a new process making it slightly more efficient than . The same options as are supported. Since a shell is not spawned, behaviors such as I/O redirection and file globbing are not supported. The and arguments passed to the callback will contain the stdout and stderr output of the child process. By default, Node.js will decode the output as UTF-8 and pass strings to the callback. The option can be used to specify the character encoding used to decode the stdout and stderr output. If is , or an unrecognized character encoding, objects will be passed to the callback instead. If this method is invoked as its ed version, it returns a for an with and properties. The returned instance is attached to the as a property. In case of an error (including any error resulting in an exit code other than 0), a rejected promise is returned, with the same object given in the callback, but with two additional properties and . If the option is enabled, do not pass unsanitized user input to this function. Any input containing shell metacharacters may be used to trigger arbitrary command execution. If the option is enabled, calling on the corresponding is similar to calling on the child process except the error passed to the callback will be an : The parameter can be a WHATWG object using protocol. The option can be a WHATWG object using protocol. The option is supported now. The option can now be a string. The option is supported now.\n• <string> | <URL> The module to run in the child.\n• <Object>\n• <boolean> Prepare child process to run independently of its parent process. Specific behavior depends on the platform (see ).\n• <string> Executable used to create the child process.\n• <string[]> List of string arguments passed to the executable. Default: .\n• <number> Sets the group identity of the process (see ).\n• <string> Specify the kind of serialization used for sending messages between processes. Possible values are and . See Advanced serialization for more details. Default: .\n• <AbortSignal> Allows closing the child process using an AbortSignal.\n• <string> | <integer> The signal value to be used when the spawned process will be killed by timeout or abort signal. Default: .\n• <boolean> If , stdin, stdout, and stderr of the child process will be piped to the parent process, otherwise they will be inherited from the parent process, see the and options for 's for more details. Default: .\n• <Array> | <string> See 's . When this option is provided, it overrides . If the array variant is used, it must contain exactly one item with value or an error will be thrown. For instance .\n• <number> Sets the user identity of the process (see ).\n• <boolean> No quoting or escaping of arguments is done on Windows. Ignored on Unix. Default: .\n• <number> In milliseconds the maximum amount of time the process is allowed to run. Default: . The method is a special case of used specifically to spawn new Node.js processes. Like , a object is returned. The returned will have an additional communication channel built-in that allows messages to be passed back and forth between the parent and child. See for details. Keep in mind that spawned Node.js child processes are independent of the parent with exception of the IPC communication channel that is established between the two. Each process has its own memory, with their own V8 instances. Because of the additional resource allocations required, spawning a large number of child Node.js processes is not recommended. By default, will spawn new Node.js instances using the of the parent process. The property in the object allows for an alternative execution path to be used. Node.js processes launched with a custom will communicate with the parent process using the file descriptor (fd) identified using the environment variable on the child process. Unlike the POSIX system call, does not clone the current process. The option available in is not supported by and will be ignored if set. If the option is enabled, calling on the corresponding is similar to calling on the child process except the error passed to the callback will be an : The option can be a WHATWG object using protocol. The option is supported now. The option is supported now. The option is supported now. The option is supported now.\n• <Object>\n• <string> Explicitly set the value of sent to the child process. This will be set to if not specified.\n• <boolean> Prepare child process to run independently of its parent process. Specific behavior depends on the platform (see ).\n• <number> Sets the user identity of the process (see ).\n• <number> Sets the group identity of the process (see ).\n• <string> Specify the kind of serialization used for sending messages between processes. Possible values are and . See Advanced serialization for more details. Default: .\n• <boolean> | <string> If , runs inside of a shell. Uses on Unix, and on Windows. A different shell can be specified as a string. See Shell requirements and Default Windows shell. Default: (no shell).\n• <boolean> No quoting or escaping of arguments is done on Windows. Ignored on Unix. This is set to automatically when is specified and is CMD. Default: .\n• <boolean> Hide the subprocess console window that would normally be created on Windows systems. Default: .\n• <AbortSignal> allows aborting the child process using an AbortSignal.\n• <number> In milliseconds the maximum amount of time the process is allowed to run. Default: .\n• <string> | <integer> The signal value to be used when the spawned process will be killed by timeout or abort signal. Default: . The method spawns a new process using the given , with command-line arguments in . If omitted, defaults to an empty array. If the option is enabled, do not pass unsanitized user input to this function. Any input containing shell metacharacters may be used to trigger arbitrary command execution. A third argument may be used to specify additional options, with these defaults: Use to specify the working directory from which the process is spawned. If not given, the default is to inherit the current working directory. If given, but the path does not exist, the child process emits an error and exits immediately. is also emitted when the command does not exist. Use to specify environment variables that will be visible to the new process, the default is . values in will be ignored. Example of running , capturing , , and the exit code: Example: A very elaborate way to run Example of checking for failed : Certain platforms (macOS, Linux) will use the value of for the process title while others (Windows, SunOS) will use . Node.js overwrites with on startup, so in a Node.js child process will not match the parameter passed to from the parent. Retrieve it with the property instead. If the option is enabled, calling on the corresponding is similar to calling on the child process except the error passed to the callback will be an : On Windows, setting to makes it possible for the child process to continue running after the parent exits. The child process will have its own console window. Once enabled for a child process, it cannot be disabled. On non-Windows platforms, if is set to , the child process will be made the leader of a new process group and session. Child processes may continue running after the parent exits regardless of whether they are detached or not. See for more information. By default, the parent will wait for the detached child process to exit. To prevent the parent process from waiting for a given to exit, use the method. Doing so will cause the parent process' event loop to not include the child process in its reference count, allowing the parent process to exit independently of the child process, unless there is an established IPC channel between the child and the parent processes. When using the option to start a long-running process, the process will not stay running in the background after the parent exits unless it is provided with a configuration that is not connected to the parent. If the parent process' is inherited, the child process will remain attached to the controlling terminal. Example of a long-running process, by detaching and also ignoring its parent file descriptors, in order to ignore the parent's termination: Alternatively one can redirect the child process' output into files: The value is now accepted as a file descriptor. The option is used to configure the pipes that are established between the parent and child process. By default, the child's stdin, stdout, and stderr are redirected to corresponding , , and streams on the object. This is equivalent to setting the equal to . For convenience, may be one of the following strings: Otherwise, the value of is an array where each index corresponds to an fd in the child. The fds 0, 1, and 2 correspond to stdin, stdout, and stderr, respectively. Additional fds can be specified to create additional pipes between the parent and child. The value is one of the following:\n• : Create a pipe between the child process and the parent process. The parent end of the pipe is exposed to the parent as a property on the object as . Pipes created for fds 0, 1, and 2 are also available as , and , respectively. These are not actual Unix pipes and therefore the child process can not use them by their descriptor files, e.g. or .\n• : Same as except that the flag is set on the handle. This is necessary for overlapped I/O on the child process's stdio handles. See the docs for more details. This is exactly the same as on non-Windows systems.\n• : Create an IPC channel for passing messages/file descriptors between parent and child. A may have at most one IPC stdio file descriptor. Setting this option enables the method. If the child process is a Node.js instance, the presence of an IPC channel will enable and methods, as well as and events within the child process. Accessing the IPC channel fd in any way other than or using the IPC channel with a child process that is not a Node.js instance is not supported.\n• : Instructs Node.js to ignore the fd in the child. While Node.js will always open fds 0, 1, and 2 for the processes it spawns, setting the fd to will cause Node.js to open and attach it to the child's fd.\n• : Pass through the corresponding stdio stream to/from the parent process. In the first three positions, this is equivalent to , , and , respectively. In any other position, equivalent to .\n• <Stream> object: Share a readable or writable stream that refers to a tty, file, socket, or a pipe with the child process. The stream's underlying file descriptor is duplicated in the child process to the fd that corresponds to the index in the array. The stream must have an underlying descriptor (file streams do not start until the event has occurred). NOTE: While it is technically possible to pass as a writable or / as readable, it is not recommended. Readable and writable streams are designed with distinct behaviors, and using them incorrectly (e.g., passing a readable stream where a writable stream is expected) can lead to unexpected results or errors. This practice is discouraged as it may result in undefined behavior or dropped callbacks if the stream encounters errors. Always ensure that is used as writable and / as readable to maintain the intended flow of data between the parent and child processes.\n• Positive integer: The integer value is interpreted as a file descriptor that is open in the parent process. It is shared with the child process, similar to how <Stream> objects can be shared. Passing sockets is not supported on Windows.\n• , : Use default value. For stdio fds 0, 1, and 2 (in other words, stdin, stdout, and stderr) a pipe is created. For fd 3 and up, the default is . It is worth noting that when an IPC channel is established between the parent and child processes, and the child process is a Node.js instance, the child process is launched with the IPC channel unreferenced (using ) until the child process registers an event handler for the event or the event. This allows the child process to exit normally without the process being held open by the open IPC channel. See also: and .\n\nInstances of are not intended to be created directly. Rather, use the , , , or methods to create instances of .\n• <number> The exit code if the child process exited on its own.\n• <string> The signal by which the child process was terminated. The event is emitted after a process has ended and the stdio streams of a child process have been closed. This is distinct from the event, since multiple processes might share the same stdio streams. The event will always emit after was already emitted, or if the child process failed to spawn. The event is emitted after calling the method in parent process or in child process. After disconnecting it is no longer possible to send or receive messages, and the property is . The event is emitted whenever:\n• The process could not be spawned.\n• The process could not be killed.\n• The child process was aborted via the option. The event may or may not fire after an error has occurred. When listening to both the and events, guard against accidentally invoking handler functions multiple times. See also and .\n• <number> The exit code if the child process exited on its own.\n• <string> The signal by which the child process was terminated. The event is emitted after the child process ends. If the process exited, is the final exit code of the process, otherwise . If the process terminated due to receipt of a signal, is the string name of the signal, otherwise . One of the two will always be non- . When the event is triggered, child process stdio streams might still be open. Node.js establishes signal handlers for and and Node.js processes will not terminate immediately due to receipt of those signals. Rather, Node.js will perform a sequence of cleanup actions and then will re-raise the handled signal. The event is triggered when a child process uses to send messages. The message goes through serialization and parsing. The resulting message might not be the same as what is originally sent. If the option was set to used when spawning the child process, the argument can contain data that JSON is not able to represent. See Advanced serialization for more details. The event is emitted once the child process has spawned successfully. If the child process does not spawn successfully, the event is not emitted and the event is emitted instead. If emitted, the event comes before all other events and before any data is received via or . The event will fire regardless of whether an error occurs within the spawned process. For example, if spawns successfully, the event will fire, though may fail to spawn . This caveat also applies when using . The object no longer accidentally exposes native C++ bindings.\n• <Object> A pipe representing the IPC channel to the child process. The property is a reference to the child's IPC channel. If no IPC channel exists, this property is . This method makes the IPC channel keep the event loop of the parent process running if has been called before. This method makes the IPC channel not keep the event loop of the parent process running, and lets it finish even while the channel is open.\n• <boolean> Set to after is called. The property indicates whether it is still possible to send and receive messages from a child process. When is , it is no longer possible to send or receive messages. Closes the IPC channel between parent and child processes, allowing the child process to exit gracefully once there are no other connections keeping it alive. After calling this method the and properties in both the parent and child processes (respectively) will be set to , and it will be no longer possible to pass messages between the processes. The event will be emitted when there are no messages in the process of being received. This will most often be triggered immediately after calling . When the child process is a Node.js instance (e.g. spawned using ), the method can be invoked within the child process to close the IPC channel as well. The property indicates the exit code of the child process. If the child process is still running, the field will be . The method sends a signal to the child process. If no argument is given, the process will be sent the signal. See for a list of available signals. This function returns if succeeds, and otherwise. The object may emit an event if the signal cannot be delivered. Sending a signal to a child process that has already exited is not an error but may have unforeseen consequences. Specifically, if the process identifier (PID) has been reassigned to another process, the signal will be delivered to that process instead which can have unexpected results. While the function is called , the signal delivered to the child process may not actually terminate the process. On Windows, where POSIX signals do not exist, the argument will be ignored except for , , and , and the process will always be killed forcefully and abruptly (similar to ). See Signal Events for more details. On Linux, child processes of child processes will not be terminated when attempting to kill their parent. This is likely to happen when running a new process in a shell or with the use of the option of :\n• <boolean> Set to after is used to successfully send a signal to the child process. The property indicates whether the child process successfully received a signal from . The property does not indicate that the child process has been terminated. Returns the process identifier (PID) of the child process. If the child process fails to spawn due to errors, then the value is and is emitted. Calling after making a call to will restore the removed reference count for the child process, forcing the parent process to wait for the child process to exit before exiting itself. The parameter, and the option in particular, is supported now. This method returns a boolean for flow control now. The parameter is supported now.\n• <Object> The argument, if present, is an object used to parameterize the sending of certain types of handles. supports the following properties:\n• <boolean> A value that can be used when passing instances of . When , the socket is kept open in the sending process. Default: . When an IPC channel has been established between the parent and child processes ( i.e. when using ), the method can be used to send messages to the child process. When the child process is a Node.js instance, these messages can be received via the event. The message goes through serialization and parsing. The resulting message might not be the same as what is originally sent. For example, in the parent script: And then the child script, might look like this: Child Node.js processes will have a method of their own that allows the child process to send messages back to the parent process. There is a special case when sending a message. Messages containing a prefix in the property are reserved for use within Node.js core and will not be emitted in the child's event. Rather, such messages are emitted using the event and are consumed internally by Node.js. Applications should avoid using such messages or listening for events as it is subject to change without notice. The optional argument that may be passed to is for passing a TCP server or socket object to the child process. The child process will receive the object as the second argument passed to the callback function registered on the event. Any data that is received and buffered in the socket will not be sent to the child. Sending IPC sockets is not supported on Windows. The optional is a function that is invoked after the message is sent but before the child process may have received it. The function is called with a single argument: on success, or an object on failure. If no function is provided and the message cannot be sent, an event will be emitted by the object. This can happen, for instance, when the child process has already exited. will return if the channel has closed or when the backlog of unsent messages exceeds a threshold that makes it unwise to send more. Otherwise, the method returns . The function can be used to implement flow control. The argument can be used, for instance, to pass the handle of a TCP server object to the child process as illustrated in the example below: The child process would then receive the server object as: Once the server is now shared between the parent and child, some connections can be handled by the parent and some by the child. While the example above uses a server created using the module, module servers use exactly the same workflow with the exceptions of listening on a event instead of and using instead of . This is, however, only supported on Unix platforms. Similarly, the argument can be used to pass the handle of a socket to the child process. The example below spawns two children that each handle connections with \"normal\" or \"special\" priority: The would receive the socket handle as the second argument passed to the event callback function: Do not use on a socket that has been passed to a subprocess. The parent cannot track when the socket is destroyed. Any handlers in the subprocess should verify that exists, as the connection may have been closed during the time it takes to send the connection to the child. The property indicates the signal received by the child process if any, else . The property represents the full list of command-line arguments the child process was launched with. The property indicates the executable file name of the child process that is launched. For , its value will be equal to . For , its value will be the name of the executable file. For , its value will be the name of the shell in which the child process is launched. If the child process was spawned with set to anything other than , then this will be . is an alias for . Both properties will refer to the same value. The property can be or if the child process could not be successfully spawned. If a child process waits to read all of its input, the child process will not continue until this stream has been closed via . If the child process was spawned with set to anything other than , then this will be . is an alias for . Both properties will refer to the same value. The property can be or if the child process could not be successfully spawned. A sparse array of pipes to the child process, corresponding with positions in the option passed to that have been set to the value . , , and are also available as , , and , respectively. In the following example, only the child's fd (stdout) is configured as a pipe, so only the parent's is a stream, all other values in the array are . The property can be if the child process could not be successfully spawned. If the child process was spawned with set to anything other than , then this will be . is an alias for . Both properties will refer to the same value. The property can be or if the child process could not be successfully spawned. By default, the parent process will wait for the detached child process to exit. To prevent the parent process from waiting for a given to exit, use the method. Doing so will cause the parent's event loop to not include the child process in its reference count, allowing the parent to exit independently of the child, unless there is an established IPC channel between the child and the parent processes."
    },
    {
        "link": "https://stackoverflow.com/questions/5775088/how-to-execute-an-external-program-from-within-node-js",
        "document": "The simplest way is:\n\nunref is necessary to end your process without waiting for \"yourApp\"\n\nHere are the exec docs"
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-launch-child-processes-in-node-js",
        "document": "The author selected the COVID-19 Relief Fund to receive a donation as part of the Write for DOnations program.\n\nWhen a user executes a single Node.js program, it runs as a single operating system (OS) process that represents the instance of the program running. Within that process, Node.js executes programs on a single thread. As mentioned earlier in this series with the How To Write Asynchronous Code in Node.js tutorial, because only one thread can run on one process, operations that take a long time to execute in JavaScript can block the Node.js thread and delay the execution of other code. A key strategy to work around this problem is to launch a child process, or a process created by another process, when faced with long-running tasks. When a new process is launched, the operating system can employ multiprocessing techniques to ensure that the main Node.js process and the additional child process run concurrently, or at the same time.\n\nNode.js includes the module, which has functions to create new processes. Aside from dealing with long-running tasks, this module can also interface with the OS and run shell commands. System administrators can use Node.js to run shell commands to structure and maintain their operations as a Node.js module instead of shell scripts.\n\nIn this tutorial, you will create child processes while executing a series of sample Node.js applications. You’ll create processes with the module by retrieving the results of a child process via a buffer or string with the function, and then from a data stream with the function. You’ll finish by using to create a child process of another Node.js program that you can communicate with as it’s running. To illustrate these concepts, you will write a program to list the contents of a directory, a program to find files, and a web server with multiple endpoints.\n• You must have Node.js installed to run through these examples. This tutorial uses version 10.22.0. To install this on macOS or Ubuntu 18.04, follow the steps in How To Install Node.js and Create a Local Development Environment on macOS or the Installing Using a PPA section of How To Install Node.js on Ubuntu 18.04.\n• This article uses an example that creates a web server to explain how the function works. To get familiar with creating web servers, you can read our guide on How To Create a Web Server in Node.js with the HTTP Module.\n\nDevelopers commonly create child processes to execute commands on their operating system when they need to manipulate the output of their Node.js programs with a shell, such as using shell piping or redirection. The function in Node.js creates a new shell process and executes a command in that shell. The output of the command is kept in a buffer in memory, which you can accept via a callback function passed into .\n\nLet’s begin creating our first child processes in Node.js. First, we need to set up our coding environment to store the scripts we’ll create throughout this tutorial. In the terminal, create a folder called :\n\nEnter that folder in the terminal with the command:\n\nCreate a new file called and open the file in a text editor. In this tutorial we will use nano, a terminal text editor:\n\nWe’ll be writing a Node.js module that uses the function to run the command. The command list the files and folders in a directory. This program takes the output from the command and displays it to the user.\n\nIn the text editor, add the following code:\n\nWe first import the command from the module using JavaScript destructuring. Once imported, we use the function. The first argument is the command we would like to run. In this case, it’s , which lists all the files and folders in the current directory in long format, with a total file size in human-readable units at the top of the output.\n\nThe second argument is a callback function with three parameters: , , and . If the command failed to run, will capture the reason why it failed. This can happen if the shell cannot find the command you’re trying to execute. If the command is executed successfully, any data it writes to the standard output stream is captured in , and any data it writes to the standard error stream is captured in .\n\nIn our callback function, we first check if we received an error. If we did, we display the error’s (a property of the object) with and end the function with . We then check if the command printed an error message and if so. If the command successfully executes, we log its output to the console with .\n\nLet’s run this file to see it in action. First, save and exit by pressing .\n\nBack in your terminal, run your application with the command:\n\nYour terminal will display the following output:\n\nThis lists the contents of the directory in long format, along with the size of the contents at the top. Your results will have your own user and group in place of . This shows that the program successfully ran the shell command .\n\nNow let’s look at another way to execute concurrent processes. Node.js’s module can also run executable files with the function. The key difference between the and functions is that the first argument of is now a path to an executable file instead of a command. The output of the executable file is stored in a buffer like , which we access via a callback function with , , and parameters.\n\nLet’s begin by adding an executable script for to run. We’ll write a bash script that downloads the Node.js logo from the Node.js website and Base64 encodes it to convert its data to a string of ASCII characters.\n\nNow write a script to download the image and base64 convert it:\n\nThe first statement is a shebang statement. It’s used in Unix, Linux, and macOS when we want to specify a shell to execute our script. The second statement is a command. The cURL utility, whose command is , is a command-line tool that can transfer data to and from a server. We use cURL to download the Node.js logo from the website, and then we use redirection to save the downloaded data to a new file . The last statement uses the utility to encode the file we downloaded with cURL. The script then outputs the encoded string to the console.\n\nIn order for our Node program to run the bash script, we have to make it executable. To do this, run the following:\n\nThis will give your current user the permission to execute the file.\n\nWith our script in place, we can write a new Node.js module to execute it. This script will use to run the script in a child process, catching any errors and displaying all output to console.\n\nIn your terminal, make a new JavaScript file called :\n\nType the following code in the text editor:\n\nWe use JavaScript destructuring to import the function from the module. We then use that function, passing the file path as the first name. contains the directory path of the module in which it is written. Node.js provides the variable to a module when the module runs. By using , our script will always find the file across different operating systems, no matter where we run . Note that for our current project setup, and must be in the same folder.\n\nThe second argument is a callback with the , , and parameters. Like with our previous example that used , we check for each possible output of the script file and log them to the console.\n\nIn your text editor, save this file and exit from the editor.\n\nIn your terminal, use to execute the module:\n\nRunning this script will produce output like this:\n\nNote that we truncated the output in this article because of its large size.\n\nBefore base64 encoding the image, first downloads it. You can also verify that you downloaded the image by inspecting the current directory.\n\nExecute to find the updated list of files in our directory:\n\nThe script will display content similar to the following on the terminal:\n\nWe’ve now successfully executed as a child process in Node.js using the function.\n\nThe and functions can run commands on the operating system’s shell in a Node.js child process. Node.js also provides another method with similar functionality, . The difference is that instead of getting the output of the shell commands all at once, we get them in chunks via a stream. In the next section we’ll use the command to create a child process.\n\nThe function runs a command in a process. This function returns data via the stream API. Therefore, to get the output of the child process, we need to listen for stream events.\n\nStreams in Node.js are instances of event emitters. If you would like to learn more about listening for events and the foundations of interacting with streams, you can read our guide on Using Event Emitters in Node.js.\n\nIt’s often a good idea to choose over or when the command you want to run can output a large amount of data. With a buffer, as used by and , all the processed data is stored in the computer’s memory. For large amounts of data, this can degrade system performance. With a stream, the data is processed and transferred in small chunks. Therefore, you can process a large amount of data without using too much memory at any one time.\n\nLet’s see how we can use to make a child process. We will write a new Node.js module that creates a child process to run the command. We will use the command to list all the files in the current directory.\n\nIn your text editor, begin by calling the command:\n\nWe first imported the function from the module. We then called the function to create a child process that executes the command. We hold the reference to the process in the variable, which we will use to listen to its streamed events.\n\nThe first argument in is the command to run, in this case . The second argument is an array that contains the arguments for the executed command. In this case, we are telling Node.js to execute the command with the argument , thereby making the command find all the files in the current directory. The equivalent command in the terminal is .\n\nWith the and functions, we wrote the arguments along with the command in one string. However, with , all arguments to commands must be entered in the array. That’s because , unlike and , does not create a new shell before running a process. To have commands with their arguments in one string, you need Node.js to create a new shell as well.\n\nLet’s continue our module by adding listeners for the command’s output. Add the following highlighted lines:\n\nCommands can return data in either the stream or the stream, so you added listeners for both. You can add listeners by calling the method of each streams’ objects. The event from the streams gives us the command’s output to that stream. Whenever we get data on either stream, we log it to the console.\n\nWe then listen to two other events: the event if the command fails to execute or is interrupted, and the event for when the command has finished execution, thus closing the stream.\n\nIn the text editor, complete the Node.js module by writing the following highlighted lines:\n\nFor the and events, you set up a listener directly on the variable. When listening for events, if one occurs Node.js provides an object. In this case, you log the error’s property.\n\nWhen listening to the event, Node.js provides the exit code of the command. An exit code denotes if the command ran successfully or not. When a command runs without errors, it returns the lowest possible value for an exit code: . When executed with an error, it returns a non-zero code.\n\nThe module is complete. Save and exit with .\n\nNow, run the code with the command:\n\nOnce complete, you will find the following output:\n\nWe find a list of all files in our current directory and the exit code of the command, which is as it ran successfully. While our current directory has a small number of files, if we ran this code in our home directory, our program would list every single file in every accessible folder for our user. Because it has such a potentially large output, using the function is most ideal as its streams do not require as much memory as a large buffer.\n\nSo far we’ve used functions to create child processes to execute external commands in our operating system. Node.js also provides a way to create a child process that executes other Node.js programs. Let’s use the function to create a child process for a Node.js module in the next section.\n\nNode.js provides the function, a variation of , to create a child process that’s also a Node.js process. The main benefit of using to create a Node.js process over or is that enables communication between the parent and the child process.\n\nWith , in addition to retrieving data from the child process, a parent process can send messages to the running child process. Likewise, the child process can send messages to the parent process.\n\nLet’s see an example where using to create a new Node.js child process can improve the performance of our application. Node.js programs run on a single process. Therefore, CPU intensive tasks like iterating over large loops or parsing large JSON files stop other JavaScript code from running. For certain applications, this is not a viable option. If a web server is blocked, then it cannot process any new incoming requests until the blocking code has completed its execution.\n\nLet’s see this in practice by creating a web server with two endpoints. One endpoint will do a slow computation that blocks the Node.js process. The other endpoint will return a JSON object saying .\n\nFirst, create a new file called , which will have the code for our HTTP server:\n\nWe’ll begin by setting up the HTTP server. This involves importing the module, creating a request listener function, creating a server object, and listening for requests on the server object. If you would like to dive deeper into creating HTTP servers in Node.js or would like a refresher, you can read our guide on How To Create a Web Server in Node.js with the HTTP Module.\n\nEnter the following code in your text editor to set up an HTTP server:\n\nThis code sets up an HTTP server that will run at . It uses template literals to dynamically generate that URL.\n\nNext, we will write an intentionally slow function that counts in a loop 5 billion times. Before the function, add the following code:\n\nThis uses the arrow function syntax to create a loop that counts to .\n\nTo complete this module, we need to add code to the function. Our function will call the on subpath, and return a small JSON message for the other. Add the following code to the module:\n\nIf the user reaches the server at the subpath, then we run . If we are hit at the subpath, we return this JSON message: .\n\nSave and exit the file by pressing .\n\nTo test, run this server module with :\n\nWhen our server starts, the console will display the following:\n\nNow, to test the performance of our module, open two additional terminals. In the first terminal, use the command to make a request to the endpoint, which we expect to be slow:\n\nIn the other terminal, use to make a request to the endpoint like this:\n\nThe first request will return the following JSON:\n\nWhereas the second request will return this JSON:\n\nThe request to completed only after the request to . The blocked all other code from executing while it was still in its loop. You can verify this by looking at the Node.js server output that was logged in your original terminal:\n\nTo process the blocking code while still accepting incoming requests, we can move the blocking code to a child process with . We will move the blocking code into its own module. The Node.js server will then create a child process when someone accesses the endpoint and listen for results from this child process.\n\nRefactor the server by first creating a new module called that will contain :\n\nNow enter the code for once again:\n\nSince this module will be a child process created with , we can also add code to communicate with the parent process when has completed processing. Add the following block of code that sends a message to the parent process with the JSON to return to the user:\n\nLet’s break down this block of code. The messages between a parent and child process created by are accessible via the Node.js global object. We add a listener to the variable to look for events. Once we receive a event, we check if it’s the event. Our server code will send the event when someone accesses the endpoint. Upon receiving that event, we run and create a JSON string with the result of the function. We use to send a message to the parent process.\n\nSave and exit by entering in nano.\n\nNow, let’s modify the file so that instead of calling , it creates a child process that executes .\n\nFirst, import the function from the module:\n\nNext, we are going to remove the from this module and modify the function to create a child process. Change the code in your file so it looks like this:\n\nWhen someone goes to the endpoint, we now create a new child process with . The argument of is the path to the Node.js module. In this case, it is the file in our current directory, which we receive from . The reference to this child process is stored in a variable .\n\nWe then add a listener to the object. This listener captures any messages that the child process gives us. In this case, will return a JSON string with the total number counted by the loop. When we receive that message, we send the JSON to the user.\n\nWe use the function of the variable to give it a message. This program sends the message , which begins the execution of in the child process.\n\nTo test the improvement using made on HTTP server, begin by executing the file with :\n\nLike before, it will output the following message when it launches:\n\nTo test the server, we will need an additional two terminals as we did the first time. You can re-use them if they are still open.\n\nIn the first terminal, use the command to make a request to the endpoint, which takes a while to compute:\n\nIn the other terminal, use to make a request to the endpoint, which responds in a short time:\n\nThe first request will return the following JSON:\n\nWhereas the second request will return this JSON:\n\nUnlike the first time we tried this, the second request to runs immediately. You can confirm by reviewing the logs, which will look like this:\n\nThese logs show that the request for the endpoint ran after the child process was created but before the child process had finished its task.\n\nSince we moved the blocking code in a child process using , the server was still able to respond to other requests and execute other JavaScript code. Because of the function’s message passing ability, we can control when a child process begins an activity and we can return data from a child process to a parent process.\n\nIn this article, you used various functions to create a child process in Node.js. You first created child processes with to run shell commands from Node.js code. You then ran an executable file with the function. You looked at the function, which can also run commands but returns data via a stream and does not start a shell like and . Finally, you used the function to allow for two-way communication between the parent and child process.\n\nTo learn more about the module, you can read the Node.js documentation. If you’d like to continue learning Node.js, you can return to the How To Code in Node.js series, or browse programming projects and setups on our Node topic page."
    },
    {
        "link": "https://freecodecamp.org/news/node-js-child-processes-everything-you-need-to-know-e69498fe970a",
        "document": "How to use spawn(), exec(), execFile(), and fork()\n\nSingle-threaded, non-blocking performance in Node.js works great for a single process. But eventually, one process in one CPU is not going to be enough to handle the increasing workload of your application.\n\nNo matter how powerful your server may be, a single thread can only support a limited load.\n\nThe fact that Node.js runs in a single thread does not mean that we can’t take advantage of multiple processes and, of course, multiple machines as well.\n\nUsing multiple processes is the best way to scale a Node application. Node.js is designed for building distributed applications with many nodes. This is why it’s named Node. Scalability is baked into the platform and it’s not something you start thinking about later in the lifetime of an application.\n\nPlease note that you’ll need a good understanding of Node.js events and streams before you read this article. If you haven’t already, I recommend that you read these two other articles before you read this one:\n\nUnderstanding Node.js Event-Driven Architecture\n\nMost of Node’s objects — like HTTP requests, responses, and streams — implement the EventEmitter module so they can…\n\nStreams: Everything you need to know\n\nNode.js streams have a reputation for being hard to work with, and even harder to understand. Well I’ve got good news…\n\nWe can easily spin a child process using Node’s module and those child processes can easily communicate with each other with a messaging system.\n\nThe module enables us to access Operating System functionalities by running any system command inside a, well, child process.\n\nWe can control that child process input stream, and listen to its output stream. We can also control the arguments to be passed to the underlying OS command, and we can do whatever we want with that command’s output. We can, for example, pipe the output of one command as the input to another (just like we do in Linux) as all inputs and outputs of these commands can be presented to us using Node.js streams.\n\nNote that examples I’ll be using in this article are all Linux-based. On Windows, you need to switch the commands I use with their Windows alternatives.\n\nThere are four different ways to create a child process in Node: , , , and .\n\nWe’re going to see the differences between these four functions and when to use each.\n\nThe function launches a command in a new process and we can use it to pass that command any arguments. For example, here’s code to spawn a new process that will execute the command.\n\nWe simply destructure the function out of the module and execute it with the OS command as the first argument.\n\nThe result of executing the function (the object above) is a instance, which implements the EventEmitter API. This means we can register handlers for events on this child object directly. For example, we can do something when the child process exits by registering a handler for the event:\n\nThe handler above gives us the exit for the child process and the , if any, that was used to terminate the child process. This variable is null when the child process exits normally.\n\nThe other events that we can register handlers for with the instances are , , , and .\n• The event is emitted when the parent process manually calls the function.\n• The event is emitted if the process could not be spawned or killed.\n• The event is emitted when the streams of a child process get closed.\n• The event is the most important one. It’s emitted when the child process uses the function to send messages. This is how parent/child processes can communicate with each other. We’ll see an example of this below.\n\nEvery child process also gets the three standard streams, which we can access using , , and .\n\nWhen those streams get closed, the child process that was using them will emit the event. This event is different than the event because multiple child processes might share the same streams and so one child process exiting does not mean that the streams got closed.\n\nSince all streams are event emitters, we can listen to different events on those streams that are attached to every child process. Unlike in a normal process though, in a child process, the / streams are readable streams while the stream is a writable one. This is basically the inverse of those types as found in a main process. The events we can use for those streams are the standard ones. Most importantly, on the readable streams, we can listen to the event, which will have the output of the command or any error encountered while executing the command:\n\nThe two handlers above will log both cases to the main process and . When we execute the function above, the output of the command gets printed and the child process exits with code , which means no error occurred.\n\nWe can pass arguments to the command that’s executed by the function using the second argument of the function, which is an array of all the arguments to be passed to the command. For example, to execute the command on the current directory with a argument (to list files only), we can do:\n\nIf an error occurs during the execution of the command, for example, if we give find an invalid destination above, the event handler will be triggered and the event handler will report an exit code of , which signifies that an error has occurred. The error values actually depend on the host OS and the type of error.\n\nA child process is a writable stream. We can use it to send a command some input. Just like any writable stream, the easiest way to consume it is using the function. We simply pipe a readable stream into a writable stream. Since the main process is a readable stream, we can pipe that into a child process stream. For example:\n\nIn the example above, the child process invokes the command, which counts lines, words, and characters in Linux. We then pipe the main process (which is a readable stream) into the child process (which is a writable stream). The result of this combination is that we get a standard input mode where we can type something and when we hit , what we typed will be used as the input of the command.\n\nGif captured from my Pluralsight course — Advanced Node.js\n\nWe can also pipe the standard input/output of multiple processes on each other, just like we can do with Linux commands. For example, we can pipe the of the command to the stdin of the command to count all the files in the current directory:\n\nI added the argument to the command to make it count only the lines. When executed, the code above will output a count of all files in all directories under the current one.\n\nBy default, the function does not create a shell to execute the command we pass into it. This makes it slightly more efficient than the function, which does create a shell. The function has one other major difference. It buffers the command’s generated output and passes the whole output value to a callback function (instead of using streams, which is what does).\n\nHere’s the previous example implemented with an function.\n\nSince the function uses a shell to execute the command, we can use the shell syntax directly here making use of the shell pipe feature.\n\nNote that using the shell syntax comes at a security risk if you’re executing any kind of dynamic input provided externally. A user can simply do a command injection attack using shell syntax characters like ; and $ (for example, )\n\nThe function buffers the output and passes it to the callback function (the second argument to ) as the argument there. This argument is the command’s output that we want to print out.\n\nThe function is a good choice if you need to use the shell syntax and if the size of the data expected from the command is small. (Remember, will buffer the whole data in memory before returning it.)\n\nThe function is a much better choice when the size of the data expected from the command is large, because that data will be streamed with the standard IO objects.\n\nWe can make the spawned child process inherit the standard IO objects of its parents if we want to, but also, more importantly, we can make the function use the shell syntax as well. Here’s the same command implemented with the function:\n\nBecause of the option above, when we execute the code, the child process inherits the main process , , and . This causes the child process data events handlers to be triggered on the main stream, making the script output the result right away.\n\nBecause of the option above, we were able to use the shell syntax in the passed command, just like we did with . But with this code, we still get the advantage of the streaming of data that the function gives us. This is really the best of both worlds.\n\nThere are a few other good options we can use in the last argument to the functions besides and . We can, for example, use the option to change the working directory of the script. For example, here’s the same count-all-files example done with a function using a shell and with a working directory set to my Downloads folder. The option here will make the script count all files I have in :\n\nAnother option we can use is the option to specify the environment variables that will be visible to the new child process. The default for this option is which gives any command access to the current process environment. If we want to override that behavior, we can simply pass an empty object as the option or new values there to be considered as the only environment variables:\n\nThe echo command above does not have access to the parent process’s environment variables. It can’t, for example, access , but it can access because it was passed as a custom environment variable through the option.\n\nOne last important child process option to explain here is the option, which makes the child process run independently of its parent process.\n\nAssuming we have a file that keeps the event loop busy:\n\nWe can execute it in the background using the option:\n\nThe exact behavior of detached child processes depends on the OS. On Windows, the detached child process will have its own console window while on Linux the detached child process will be made the leader of a new process group and session.\n\nIf the function is called on the detached process, the parent process can exit independently of the child. This can be useful if the child is executing a long-running process, but to keep it running in the background the child’s configurations also have to be independent of the parent.\n\nThe example above will run a node script ( ) in the background by detaching and also ignoring its parent file descriptors so that the parent can terminate while the child keeps running in the background.\n\nGif captured from my Pluralsight course — Advanced Node.js\n\nIf you need to execute a file without using a shell, the function is what you need. It behaves exactly like the function, but does not use a shell, which makes it a bit more efficient. On Windows, some files cannot be executed on their own, like or files. Those files cannot be executed with and either or with shell set to true is required to execute them.\n\nThe functions , , and from the module also have synchronous blocking versions that will wait until the child process exits.\n\nThose synchronous versions are potentially useful when trying to simplify scripting tasks or any startup processing tasks, but they should be avoided otherwise.\n\nThe function is a variation of the function for spawning node processes. The biggest difference between and is that a communication channel is established to the child process when using , so we can use the function on the forked process along with the global object itself to exchange messages between the parent and forked processes. We do this through the module interface. Here’s an example:\n\nIn the parent file above, we fork (which will execute the file with the command) and then we listen for the event. The event will be emitted whenever the child uses , which we’re doing every second.\n\nTo pass down messages from the parent to the child, we can execute the function on the forked object itself, and then, in the child script, we can listen to the event on the global object.\n\nWhen executing the file above, it’ll first send down the object to be printed by the forked child process and then the forked child process will send an incremented counter value every second to be printed by the parent process.\n\nScreenshot captured from my Pluralsight course — Advanced Node.js\n\nLet’s do a more practical example about the function.\n\nLet’s say we have an http server that handles two endpoints. One of these endpoints ( below) is computationally expensive and will take a few seconds to complete. We can use a long for loop to simulate that:\n\nThis program has a big problem; when the the endpoint is requested, the server will not be able to handle any other requests because the event loop is busy with the long for loop operation.\n\nThere are a few ways with which we can solve this problem depending on the nature of the long operation but one solution that works for all operations is to just move the computational operation into another process using .\n\nWe first move the whole function into its own file and make it invoke that function when instructed via a message from the main process:\n\nNow, instead of doing the long operation in the main process event loop, we can the file and use the messages interface to communicate messages between the server and the forked process.\n\nWhen a request to happens now with the above code, we simply send a message to the forked process to start executing the long operation. The main process’s event loop will not be blocked.\n\nOnce the forked process is done with that long operation, it can send its result back to the parent process using .\n\nIn the parent process, we listen to the event on the forked child process itself. When we get that event, we’ll have a value ready for us to send to the requesting user over http.\n\nThe code above is, of course, limited by the number of processes we can fork, but when we execute it and request the long computation endpoint over http, the main server is not blocked at all and can take further requests.\n\nNode’s module, which is the topic of my next article, is based on this idea of child process forking and load balancing the requests among the many forks that we can create on any system.\n\nThat’s all I have for this topic. Thanks for reading! Until next time!"
    }
]