[
    {
        "link": "https://seaborn.pydata.org/archive/0.11/generated/seaborn.lineplot.html",
        "document": "Draw a line plot with possibility of several semantic groupings.\n\nThe relationship between and can be shown for different subsets of the data using the , , and parameters. These parameters control what visual semantics are used to identify the different subsets. It is possible to show up to three dimensions independently by using all three semantic types, but this style of plot can be hard to interpret and is often ineffective. Using redundant semantics (i.e. both and for the same variable) can be helpful for making graphics more accessible.\n\nSee the tutorial for more information.\n\nThe default treatment of the (and to a lesser extent, ) semantic, if present, depends on whether the variable is inferred to represent “numeric” or “categorical” data. In particular, numeric variables are represented with a sequential colormap by default, and the legend entries show regular “ticks” with values that may or may not exist in the data. This behavior can be controlled through various parameters, as described and illustrated below.\n\nBy default, the plot aggregates over multiple values at each value of and shows an estimate of the central tendency and a confidence interval for that estimate.\n\nVariables that specify positions on the x and y axes. Grouping variable that will produce lines with different colors. Can be either categorical or numeric, although color mapping will behave differently in latter case. Grouping variable that will produce lines with different widths. Can be either categorical or numeric, although size mapping will behave differently in latter case. Grouping variable that will produce lines with different dashes and/or markers. Can have a numeric dtype but will always be treated as categorical. Input data structure. Either a long-form collection of vectors that can be assigned to named variables or a wide-form dataset that will be internally reshaped. Method for choosing the colors to use when mapping the semantic. String values are passed to . List or dict values imply categorical mapping, while a colormap object implies numeric mapping. Specify the order of processing and plotting for categorical levels of the semantic. Either a pair of values that set the normalization range in data units or an object that will map from data units into a [0, 1] interval. Usage implies numeric mapping. An object that determines how sizes are chosen when is used. It can always be a list of size values or a dict mapping levels of the variable to sizes. When is numeric, it can also be a tuple specifying the minimum and maximum size to use such that other values are normalized within this range. Specified order for appearance of the variable levels, otherwise they are determined from the data. Not relevant when the variable is numeric. Normalization in data units for scaling plot objects when the variable is numeric. Object determining how to draw the lines for different levels of the variable. Setting to will use default dash codes, or you can pass a list of dash codes or a dictionary mapping levels of the variable to dash codes. Setting to will use solid lines for all subsets. Dashes are specified as in matplotlib: a tuple of lengths, or an empty string to draw a solid line. Object determining how to draw the markers for different levels of the variable. Setting to will use default markers, or you can pass a list of markers or a dictionary mapping levels of the variable to markers. Setting to will draw marker-less lines. Markers are specified as in matplotlib. Specified order for appearance of the variable levels otherwise they are determined from the data. Not relevant when the variable is numeric. Grouping variable identifying sampling units. When used, a separate line will be drawn for each unit with appropriate semantics, but no legend entry will be added. Useful for showing distribution of experimental replicates when exact identities are not needed. estimator name of pandas method or callable or None Method for aggregating across multiple observations of the variable at the same level. If , all observations will be drawn. Size of the confidence interval to draw when aggregating with an estimator. “sd” means to draw the standard deviation of the data. Setting to will skip bootstrapping. Number of bootstraps to use for computing the confidence interval. If True, the data will be sorted by the x and y variables, otherwise lines will connect points in the order they appear in the dataset. Whether to draw the confidence intervals with translucent error bands or discrete error bars. Additional paramters to control the aesthetics of the error bars. The kwargs are passed either to or , depending on . How to draw the legend. If “brief”, numeric and variables will be represented with a sample of evenly spaced values. If “full”, every group will get an entry in the legend. If “auto”, choose between brief or full representation based on number of levels. If , no legend data is added and no legend is drawn. Pre-existing axes for the plot. Otherwise, call internally. Other keyword arguments are passed down to . The matplotlib axes containing the plot.\n\nThe dataset has 10 years of monthly airline passenger data:\n\nTo draw a line plot using long-form data, assign the and variables:\n\nTo plot a single vector, pass it to . If the vector is a , it will be plotted against its index:\n\nPassing the entire wide-form dataset to plots a separate line for each column:\n\nPassing the entire dataset in long-form mode will aggregate over repeated values (each year) to show the mean and 95% confidence interval:\n\nThe same column can be assigned to multiple semantic variables, which can increase the accessibility of the plot:\n\nEach semantic variable can also represent a different column. For that, we’ll need a more complex dataset:\n\nRepeated observations are aggregated even when semantic grouping is used:\n\nAssign both and to represent two different grouping variables:\n\nWhen assigning a variable, markers can be used instead of (or along with) dashes to distinguish the groups:\n\nShow error bars instead of error bands and plot the 68% confidence interval (standard error):\n\nAssigning the variable will plot multiple lines without applying a semantic mapping:\n\nAssigning a numeric variable to maps it differently, using a different default palette and a quantitative color mapping:\n\nControl the color mapping by setting the and passing a object:\n\nOr pass specific colors, either as a Python list or dictionary:\n\nAssign the semantic to map the width of the lines with a numeric variable:\n\nPass a a tuple, , to control the range of linewidths used to map the semantic:\n\nBy default, the observations are sorted by . Disable this to plot a line with the order that observations appear in the dataset:\n\nUse to combine and . This allows grouping within additional categorical variables. Using is safer than using directly, as it ensures synchronization of the semantic mappings across facets:"
    },
    {
        "link": "https://seaborn.pydata.org/archive/0.11/whatsnew.html",
        "document": "This page contains information about what has changed in each new version of .\n\nThis is a major release with several important new features, enhancements to existing functions, and changes to the library. Highlights include an overhaul and modernization of the distributions plotting functions, more flexible data specification, new colormaps, and better narrative documentation. For an overview of the new features and a guide to updating, see this Medium post. Most plotting functions now require all of their parameters to be specified using keyword arguments. To ease adaptation, code without keyword arguments will trigger a in v0.11. In a future release (v0.12 or v0.13, depending on release cadence), this will become an error. Once keyword arguments are fully enforced, the signature of the plotting functions will be reorganized to accept as the first and only positional argument (#2052, #2081). The distribution module has been completely overhauled, modernizing the API and introducing several new functions and features within existing functions. Some new features are explained here; the tutorial documentation has also been rewritten and serves as a good introduction to the functions. First, three new functions, , and have been added (#2157, #2125, #2141). The figure-level function is an interface to the various distribution plots (analogous to or ). It can draw univariate or bivariate histograms, density curves, ECDFs, and rug plots on a . The axes-level function draws univariate or bivariate histograms with a number of features, including:\n• None adding a KDE fit to show a smoothed distribution over all bin statistics\n• None experimental support for histograms over categorical and datetime variables. Second, the existing functions and have been completely overhauled (#2060, #2104). The overhauled functions now share a common API with the rest of seaborn, they can show conditional distributions by mapping a third variable with a semantic, and they have been improved in numerous other ways. The github pull request (#2104) has a longer explanation of the changes and the motivation behind them. This is a necessarily API-breaking change. The parameter names for the positional variables are now and , and the old names have been deprecated. Efforts were made to handle and warn when using the deprecated API, but it is strongly suggested to check your plots carefully. Additionally, the statsmodels-based computation of the KDE has been removed. Because there were some inconsistencies between the way different parameters (specifically, , , and ) were implemented by each backend, this may cause plots to look different with non-default parameters. Support for using non-Gaussian kernels, which was available only in the statsmodels backend, has been removed.\n• None several options for representing multiple densities (using the and parameters)\n• None weighted density estimation (using the new parameter)\n• None better control over the smoothing bandwidth (using the new parameter)\n• None more meaningful parameterization of the contours that represent a bivariate density (using the and parameters)\n• None log-space density estimation (using the new parameter, or by scaling the data axis before plotting)\n• None “bivariate” rug plots with a single function call (by assigning both and ) Finally, the function is now formally deprecated. Its features have been subsumed by and . Some effort was made to gradually transition by adding the features in and handling backwards compatibility, but this proved to be too difficult. The similarity in the names will likely cause some confusion during the transition, which is regrettable. These additions facilitated new features (and forced changes) in and (#2210) and in and (#2234).\n• None Added support for the semantic in / . This support is lightweight and simply delegates the mapping to the underlying axes-level functions.\n• None Delegated the handling of in / to the plotting function when it understands , meaning that (1) the zorder of scatterplot points will be determined by row in dataframe, (2) additional options for resolving hue (e.g. the parameter) can be used, and (3) numeric hue variables can be naturally mapped when using .\n• None Added to , which draws a bivariate histogram on the joint axes and univariate histograms on the marginal axes, as well as both and to , which behaves likewise.\n• None The various modes of that plot marginal histograms now use rather than . This slightly changes the default appearance and affects the valid keyword arguments that can be passed to customize the plot. Likewise, the marginal histogram plots in now use . The code that processes input data has been refactored and enhanced. In v0.11, this new code takes effect for the relational and distribution modules; other modules will be refactored to use it in future releases (#2071). These changes should be transparent for most use-cases, although they allow a few new features:\n• None Named variables for long-form data can refer to the named index of a or to levels in the case of a multi-index. Previously, it was necessary to call before using index variables (e.g., after a groupby operation).\n• None now has the same flexibility as the axes-level functions to accept data in long- or wide-format and to accept data vectors (rather than named variables) in long-form mode.\n• None The data parameter can now be a Python or an object that implements that interface. This is a new feature for wide-form data. For long-form data, it was previously supported but not documented.\n• None A wide-form data object can have a mixture of types; the non-numeric types will be removed before plotting. Previously, this caused an error.\n• None There are better error messages for other instances of data mis-specification. See the new user guide chapter on data formats for more information about what is supported.\n• None Docs Added two new chapters to the user guide, one giving an overview of the types of functions in seaborn, and one discussing the different data formats that seaborn understands.\n• None Docs Expanded the color palette tutorial to give more background on color theory and better motivate the use of color in statistical graphics.\n• None Docs Added more information to the installation guidelines and streamlined the introduction page.\n• None Docs Improved cross-linking within the seaborn docs and between the seaborn and matplotlib docs.\n• None API The function has been renamed to for more clarity about what it does. For the foreseeable future, will remain as an alias, but it is recommended to update your code.\n• None Enhancement Defaults Reduced some of the surprising behavior of relational plot legends when using a numeric hue or size mapping (#2229):\n• None Added an “auto” mode (the new default) that chooses between “brief” and “full” legends based on the number of unique levels of each variable.\n• None Modified the ticking algorithm for a “brief” legend to show up to 6 values and not to show values outside the limits of the data.\n• None Changed the approach to the legend title: the normal matplotlib legend title is used when only one variable is assigned a semantic mapping, whereas the old approach of adding an invisible legend artist with a subtitle label is used only when multiple semantic variables are defined.\n• None Modified legend subtitles to be left-aligned and to be drawn in the default legend title font size.\n• None Enhancement Defaults Changed how functions that use different representations for numeric and categorical data handle vectors with an data type. Previously, data was considered numeric if it could be coerced to a float representation without error. Now, object-typed vectors are considered numeric only when their contents are themselves numeric. As a consequence, numbers that are encoded as strings will now be treated as categorical data (#2084).\n• None Enhancement Defaults Plots with a semantic can now generate an infinite number of unique dashes and/or markers by default. Previously, an error would be raised if the variable had more levels than could be mapped using the default lists. The existing defaults were slightly modified as part of this change; if you need to exactly reproduce plots from earlier versions, refer to the old defaults (#2075).\n• None Defaults Changed how sets the default linewidth for the edges of the scatter points. New behavior is to scale with the point sizes themselves (on a plot-wise, not point-wise basis). This change also slightly reduces the default width when point sizes are not varied. Set to reproduce the previous behavior. (#2708).\n• None Enhancement Improved support for datetime variables in and (#2138).\n• None Fix Fixed a bug where did not pass the parameter down to matplotlib (#2095).\n• None Fix Adapted to a change in matplotlib that prevented passing vectors of literal values to and in (#2079).\n• None Enhancement Defaults Fix Fixed a few computational issues in and improved its visual appearance (#2086):\n• None Changed the default method for computing the number of boxes to``k_depth=”tukey” ) is based on a heuristic that produces too many boxes for small datasets.\n• None Added the option to specify the specific number of boxes (e.g. ) or to plot boxes that will cover most of the data points ( ).\n• None Added a new parameter, , to control the number of boxes when .\n• None Changed the visual appearance of to more closely resemble . Notably, thin boxes will remain visible when the edges are white.\n• None Enhancement Allowed to use different values on the categorical axis of each facet when axis sharing is turned off (e.g. by specifying ) (#2196).\n• None Enhancement Improved the error messages produced when categorical plots process the orientation parameter.\n• None Enhancement Added an explicit warning in when more than 5% of the points overlap in the “gutters” of the swarm (#2045).\n• None Feature Enhancement Defaults A few small changes to make life easier when using (#2234):\n• None Added public access to the legend object through the attribute (also affects ).\n• None The and parameters are no longer passed to the plotting functions when is not used.\n• None The data is no longer converted to a numpy object before plotting on the marginal axes.\n• None It is possible to specify only one of or , using all variables for the unspecified dimension.\n• None The parameter is stored and used every time you call the method.\n• None Feature Added a method to and , which runs the algorithm without interference from the external legend (#2073).\n• None Feature Added the attribute to for named access to the component axes (#2046).\n• None Feature Added the parameter to which, if set to , will show ticks on the count/density axis of the marginal plots (#2210).\n• None Enhancement Improved with , such that texts representing the original row titles are removed before adding new ones (#2083).\n• None Defaults Changed the default value for to in , , , and corresponding functions. As all or nearly all seaborn and matplotlib plotting functions handle missing data well, this option is no longer useful, but it causes problems in some edge cases. It may be deprecated in the future. (#2204).\n• None Fix Fixed a bug in that appeared when setting and (#2203).\n• None Docs Improved and modernized the color palettes chapter of the seaborn tutorial.\n• None Feature Added two new perceptually-uniform colormaps: “flare” and “crest”. The new colormaps are similar to “rocket” and “mako”, but their luminance range is reduced. This makes them well suited to numeric mappings of line or scatter plots, which need contrast with the axes background at the extremes (#2237).\n• \n• None Added string-based access within the interface to , , and . This means that anywhere you specify a palette in seaborn, a name like will use with the input .\n• None Added the parameter to and changed internal code that uses a continuous colormap to take this route.\n• None Tweaked the and functions to use an endpoint that is a very desaturated version of the input color, rather than a pure gray. This produces smoother ramps. To exactly reproduce previous plots, use with for dark or for light.\n• None Changed to have a default value of , which gives better results.\n• None Enhancement Added a rich HTML representation to the object returned by (#2225).\n• None Fix Fixed the logic to modify reversed colormaps and to use the correct direction of the luminance ramp in both cases.\n• None Enhancement Removed an optional (and undocumented) dependency on BeautifulSoup (#2190) in .\n• None API Deprecated the function; use instead.\n• None API Deprecated the function; use instead.\n• None API Final removal of the previously-deprecated method on , along with related parameters.\n• None API Final removal of the function (the previously-deprecated name for ).\n\nThis is a major update that is being released simultaneously with version 0.9.1. It has all of the same features (and bugs!) as 0.9.1, but there are important changes to the dependencies. Most notably, all support for Python 2 has now been dropped. Support for Python 3.5 has also been dropped. Seaborn is now strictly compatible with Python 3.6+. Minimally supported versions of the dependent PyData libraries have also been increased, in some cases substantially. While seaborn has tended to be very conservative about maintaining compatibility with older dependencies, this was causing increasing pain during development. At the same time, these libraries are now much easier to install. Going forward, seaborn will likely stay close to the Numpy community guidelines for version support. This release also removes a few previously-deprecated features:\n• None The function and module have been removed. Recall that was replaced with .\n• None The entry-point has been removed.\n• None The module (previously renamed to ) has been removed. Now that seaborn is a Python 3 library, it can take advantage of keyword-only arguments. It is likely that future versions will introduce this syntax, potentially in a breaking way. For guidance, most seaborn functions have a signature that looks like where the are specified in the function. Going forward it will likely be necessary to specify and all subsequent arguments with an explicit mapping. This style has long been used throughout the documentation, and the formal requirement will not be introduced until at least the next major release. Adding this feature will make it possible to enhance some older functions with more modern capabilities (e.g., adding a native semantic within functions like and ) and will allow parameters that control new features to be situated nearby related, making them more discoverable.\n\nThis is a major release with several substantial and long-desired new features. There are also updates/modifications to the themes and color palettes that give better consistency with matplotlib 2.0 and some notable API changes. Three completely new plotting functions have been added: , , and . The first is a figure-level interface to the latter two that combines them with a . The functions bring the high-level, dataset-oriented API of the seaborn categorical plotting functions to more general plots (scatter plots and line plots). These functions can visualize a relationship between two numeric variables while mapping up to three additional variables by modifying , , and/or semantics. The common high-level API is implemented differently in the two functions. For example, the size semantic in scales the area of scatter plot points, but in it scales width of the line plot lines. The API is dataset-oriented, meaning that in both cases you pass the variable in your dataset rather than directly specifying the matplotlib parameters to use for point area or line width. Another way the relational functions differ from existing seaborn functionality is that they have better support for using numeric variables for and semantics. This functionality may be propagated to other functions that can add a semantic in future versions; it has not been in this release. The function also has support for statistical estimation and is replacing the older function, which still exists but is marked for removal in a future release. is better aligned with the API of the rest of the library and more flexible in showing relationships across additional variables by modifying the size and style semantics independently. It also has substantially improved support for date and time data, a major pain factor in . The cost is that some of the more esoteric options in for representing uncertainty (e.g. a colormapped KDE of the bootstrap distribution) have not been implemented in the new function. There is quite a bit of new documentation that explains these new functions in more detail, including detailed examples of the various options in the API reference and a more verbose tutorial. These functions should be considered in a “stable beta” state. They have been thoroughly tested, but some unknown corner cases may remain to be found. The main features are in place, but not all planned functionality has been implemented. There are planned improvements to some elements, particularly the default legend, that are a little rough around the edges in this release. Finally, some of the default behavior (e.g. the default range of point/line sizes) may change somewhat in future releases. A few functions have been renamed or have had changes to their default parameters.\n• None The function has been renamed to . The new name ditches the original R-inflected terminology to use a name that is more consistent with terminology in pandas and in seaborn itself. This change should hopefully make easier to discover, and it should make more clear what its role is. still exists and will pass its arguments through to with a warning. It may be removed eventually, but the transition will be as gradual as possible.\n• None The other reason that the name was changed was to ease another alteration which is that the default in is now (corresponding to ). This plots a categorical scatter plot which is usually a much better place to start and is more consistent with the default in . The old default style in ( , corresponding to ) remains available if you want to show a statistical estimation.\n• None The function has been renamed to . The “letter-value” terminology that was used to name the original kind of plot is obscure, and the abbreviation to did not help anything. The new name should make the plot more discoverable by describing its format (it plots multiple boxes, also known as “boxen”). As with , the function still exists to provide a relatively smooth transition.\n• None Renamed the parameter to in multi-plot grid objects ( , , and ) along with functions that use them ( , , , and ) to avoid conflicts with the parameter that is used in and (necessary to make work) and also makes the meaning of the parameter a bit more clear.\n• None Changed the default diagonal plots in to use func: when a dimension is used.\n• None Deprecated the statistical annotation component of . The method is still available but will be removed in a future version.\n• None Two older functions that were deprecated in earlier versions, and , have undergone final removal from the code base. There has been some effort put into improving the documentation. The biggest change is that the introduction to the library has been completely rewritten to provide much more information and, critically, examples. In addition to the high-level motivation, the introduction also covers some important topics that are often sources of confusion, like the distinction between figure-level and axes-level functions, how datasets should be formatted for use in seaborn, and how to customize the appearance of the plots. Other improvements have been made throughout, most notably a thorough re-write of the categorical tutorial.\n• None Changed to plot a matplotlib instead of many objects, providing a big speedup for large arrays.\n• None Changed the default off-diagonal plots to use . (Note that the currently draws three separate scatterplots instead of using the hue semantic of the scatterplot function).\n• None Changed color handling when using with two variables. The default colormap for the 2D density now follows the color cycle, and the function can use and kwargs, adding more flexibility and avoiding a warning when using with multi-plot grids.\n• None Added the parameter to for more flexibility.\n• None Removed a special case in that defaulted to drawing stacked histograms on the diagonal axes.\n• None Fixed / and so that they now accept list inputs.\n• None Fixed a bug in when using a single row/column level or using .\n• None Fixed functions that set axis limits so that they preserve auto-scaling state on matplotlib 2.0.\n• None Avoided an error when using matplotlib backends that cannot render a canvas (e.g. PDF).\n• None Changed the install infrastructure to explicitly declare dependencies in a way that is aware of. This means that will now work in an empty environment. Additionally, the dependencies are specified with strict minimal versions.\n• None Updated the testing infrastructure to execute tests with pytest (although many individual tests still use nose assertion).\n\nThis is a major release from 0.5. The main objective of this release was to unify the API for categorical plots, which means that there are some relatively large API changes in some of the older functions. See below for details of those changes, which may break code written for older versions of seaborn. There are also some new functions ( , and ), numerous enhancements to existing functions, and bug fixes. Additionally, the documentation has been completely revamped and expanded for the 0.6 release. Now, the API docs page for each function has multiple examples with embedded plots showing how to use the various options. These pages should be considered the most comprehensive resource for examples, and the tutorial pages are now streamlined and oriented towards a higher-level overview of the various features.\n• None Added the function, which draws a scatterplot where one of the variables is categorical. This plot has the same API as and . It is useful both on its own and when composed with one of these other plot kinds to show both the observations and underlying distribution.\n• None Added the function, which uses a bar plot representation to show counts of variables in one or more categorical bins. This replaces the old approach of calling without a numeric variable.\n• None The and underlying functions have been deprecated in favor of , which is much more flexible and robust. These two functions are still available in version 0.6, but they will be removed in a future version.\n• None Added the function and the argument to and . This changes the interpretation of shorthand color codes (i.e. “b”, “g”, k”, etc.) within matplotlib to use the values from one of the named seaborn palettes (i.e. “deep”, “muted”, etc.). That makes it easier to have a more uniform look when using matplotlib functions directly with seaborn imported. This could be disruptive to existing plots, so it does not happen by default. It is possible this could change in the future.\n• None The function no longer trims palettes that are longer than 6 colors when passed into it.\n• None Added the method to color palette objects, to return a list of hex codes rather than rgb tuples.\n• None now passes additional keyword arguments to the function used to draw the plot on the joint axes.\n• None Changed the default in and to 0 so that larger matrices plot correctly. This parameter still exists and can be used to get the old effect of lines demarcating each cell in the heatmap (the old default was 0.5).\n• None and now automatically use a mask for missing values, which previously were shown with the “under” value of the colormap per default behavior.\n• None Added the dictionary and the function to define colors from the 120 box (!) of Crayola crayons.\n• None Added the parameter to to change the style of the lowess line, when used.\n• None Added open-ended to the method on and , which will pass additional keyword arguments through when calling the legend function on the or .\n• None Added the parameter to , which allows for control over the size of individual facets in the grid to emphasize certain plots or account for differences in variable ranges.\n• None The interactive palette widgets now show a continuous colorbar, rather than a discrete palette, when is True.\n• None The default Axes size for and is now slightly smaller.\n• None Added the parameter to which will set the alpha for the lowest contour level to 0, making it easier to plot multiple bivariate distributions on the same axes.\n• None The parameter of is now interpreted as a function of the axis size and is invariant to changes in the data scale on that axis. The rug lines are also slightly narrower by default.\n• None Added a catch in when calculating a default number of bins. For highly skewed data it will now use sqrt(n) bins, where previously the reference rule would return “infinite” bins and cause an exception in matplotlib.\n• None Added a ceiling (50) to the default number of bins used for histograms. This will help avoid confusing errors with certain kinds of datasets that heavily violate the assumptions of the reference rule used to get a default number of bins. The ceiling is not applied when passing a specific number of bins.\n• None The various property dictionaries that can be passed to are now applied after the seaborn restyling to allow for full customizability.\n• None Added a method to that defaults to a tight bounding box to make it easier to save figures using this class, and set a tight bbox as the default for the method on other Grid objects.\n• None You can now pass an integer to the and parameter of (and, by extension, ). This will make the plot use the ticklabels inferred from the data, but only plot every label, where is the number you pass. This can help when visualizing larger matrices with some sensible ordering to the rows or columns of the dataframe.\n• None Added to the style parameters and set the default to white.\n• None The function now caches datasets locally after downloading them, and uses the local copy on subsequent calls.\n• None Fixed bugs in where the mask and specified ticklabels were not being reorganized using the dendrograms.\n• None Fixed a bug in and that lead to incorrect legend labels when levels of the variable appeared in but not in the data.\n• None Fixed a bug in or when is being used.\n• None Fixed a bug in where the parameter was ignored.\n• None Fixed two bugs in that caused errors when trying to trim the spines on plots that had inverted axes or no ticks.\n• None Improved support for the option in , which can now be used with a legend.\n\nThis is a major release from 0.3. Highlights include new approaches for quick, high-level dataset exploration (along with a more flexible interface) and easy creation of perceptually-appropriate color palettes using the cubehelix system. Along with these additions, there are a number of smaller changes that make visualizing data with seaborn easier and more powerful.\n• None A new object, , and a corresponding function , for drawing grids of pairwise relationships in a dataset. This style of plot is sometimes called a “scatterplot matrix”, but the representation of the data in is flexible and many styles other than scatterplots can be used. See the docs for more information. Note: due to a bug in older versions of matplotlib, you will have best results if you use these functions with matplotlib 1.4 or later.\n• None The rules for choosing default color palettes when variables are mapped to different colors have been unified (and thus changed in some cases). Now when no specific palette is requested, the current global color palette will be used, unless the number of variables to be mapped exceeds the number of unique colors in the palette, in which case the palette will be used to avoid cycling.\n• None Added a keyword argument to . When a is now drawn without a KDE or parametric density, the histogram is drawn as counts instead of a density. This can be overridden by by setting to .\n• None When using with a variable, the legend is no longer drawn by default when you call . Instead, you have to call manually. This should make it easier to layer multiple plots onto the grid without having duplicated legends.\n• None Made some changes to so that it behaves better when not all levels of the variable are represented in each facet.\n• None Added the option to for fitting the regression in log space.\n• None When encounters a bin with only a single observation, it will now plot a horizontal line at that value instead of erroring out.\n• None Added the function for generating sequential palettes from the cubehelix system. See the palette docs for more information on how these palettes can be used. There is also the which will launch an interactive app to select cubehelix parameters in the notebook.\n• None Added the and the dictionary so that colors can be specified with names from the xkcd color survey.\n• None Added the option to , , and . can independently increase or decrease the size of the font elements in the plot.\n• None Font-handling should work better on systems without Arial installed. This is accomplished by adding the field to the definition with Arial and Liberation Sans prepended to matplotlib defaults. The font family can also be set through the keyword argument in . Due to matplotlib bugs, this might not work as expected on matplotlib 1.3.\n• None The function gets a new keyword argument , which replaces the deprecated function. You no longer need to offset the spines before plotting data.\n• None Added a default value for so that text in PDFs is editable in Adobe Illustrator.\n• None Removed the deprecated and functions. These were replaced in version 0.3 by the function and ability to use directly in a statement.\n• None Removed the ability to specify a style, which was renamed to in 0.3.\n\nThis is a major release from 0.2 with a number of enhancements to the plotting capabilities and styles. Highlights include , , , and an overhaul to style management. There is also lots of new documentation, including an example gallery and reorganized tutorial.\n• None The class adds a new form of functionality to seaborn, providing a way to abstractly structure a grid of plots corresponding to subsets of a dataset. It can be used with a wide variety of plotting functions (including most of the matplotlib and seaborn APIs. See the tutorial for more information.\n• None Version 0.3 introduces the function, which is similar in spirit to but intended for use when the main independent variable is categorical instead of quantitative. can draw a plot in either a point or bar representation using the corresponding Axes-level functions and (which are also new). Additionally, the function can be used to draw box plots on a faceted grid. For examples of how to use these functions, you can refer to the tutorial.\n• None Another new function is , which is built using the new object. generalizes the behavior of in previous versions of seaborn ( has changed somewhat in 0.3; see below for details) by drawing a bivariate plot of the relationship between two variables with their marginal distributions drawn on the side of the plot. With , you can draw a scatterplot or regression plot as before, but you can now also draw bivariate kernel densities or hexbin plots with appropriate univariate graphs for the marginal distributions. Additionally, it’s easy to use directly to build up more complex plots when the default methods offered by are not suitable for your visualization problem. The tutorial for has more examples of how this object can be useful.\n• None The function complements and can be quickly used to diagnose problems with a linear model by calculating and plotting the residuals of a simple regression. There is also a kind for .\n• None The most noticeable change will be that no longer produces a multi-component plot with distributions in marginal axes. Instead. is now an “Axes-level” function that can be plotted into any existing figure on a specific set of axes. and have also been unified (the latter uses the former behind the scenes), so all options for how to fit and represent the regression model can be used for both functions. To get the old behavior of , use with .\n• None As noted above, has been rewritten to exploit the machinery. This involves a few changes. The keyword argument has been replaced with , for better consistency across the package. The parameter will always take a variable name, while will take a color name or (in some cases) a palette. The function now returns the used to draw the plot instance.\n• None The functions that interact with matplotlib rc parameters have been updated and standardized. There are now three pairs of functions, and , and , and and . In each case, the pairs take the exact same arguments. The first function defines and returns the parameters, and the second sets the matplotlib defaults. Additionally, the first function in each pair can be used in a statement to temporarily change the defaults. Both the style and context functions also now accept a dictionary of matplotlib rc parameters to override the seaborn defaults, and now also takes a dictionary to update any of the matplotlib defaults. See the tutorial for more information.\n• None The style has been deprecated and changed to for more uniformity (i.e. there are now , , , and styles).\n• None If you want to use plotting functions provided by the package without setting the matplotlib style to a seaborn theme, you can now do or , etc. This is using the (also new) function, which returns the rc parameters to what they are at matplotlib import time — i.e. they will respect any custom settings on top of the matplotlib defaults.\n• None The dependency load of the package has been reduced. It can now be installed and used with only , , , and . Although is still recommended for full functionality, it is not required.\n• None (and ) have two new options for fitting regression models: and . The former fits a nonparametric smoother, while the latter fits a regression using methods that are less sensitive to outliers.\n• None The regression uncertainty in and is now estimated with fewer bootstrap iterations, so plotting should be faster.\n• None The univariate can now be drawn as a cumulative density plot.\n• None Changed to use a robust calculation of the data range when finding default limits for the contour colormap to work better when there are outliers in the data.\n• None There is a new style, , which shares most features with but does not draw a grid by default.\n• None There is a new function, , and a corresponding option in called . Together, these can be used to make plots where the axis spines are offset from the main part of the figure and limited within the range of the ticks. This is recommended for use with the style.\n• None Other aspects of the seaborn styles have been tweaked for more attractive plots.\n\nThis is a major release from 0.1 with a number of API changes, enhancements, and bug fixes. Highlights include an overhaul of timeseries plotting to work intelligently with dataframes, the new function for visualizing continuous interactions, bivariate kernel density estimates in , and significant improvements to color palette handling. In addition to the library enhancements, the documentation has been substantially rewritten to reflect the new features and improve the presentation of the ideas behind the package.\n• None The function was rewritten to accept data in a long-form and to plot different traces by condition. This introduced a relatively minor but unavoidable API change, where instead of doing , you now must do (the parameter is now optional, for quicker specification of simple plots). Additionally, the and error styles in have been renamed to and , respectively.\n• None Functions that fit kernel density estimates ( and ) now use instead of , and the parameters that influence the density estimate have changed accordingly. This allows for increased flexibility in specifying the bandwidth and kernel, and smarter choices for defining the range of the support. Default options should produce plots that are very close to the old defaults.\n• None The function now takes a second positional argument of data for drawing bivariate densities.\n• None The function has been changed to , for consistency. In 0.2, will still work, but it will fire a .\n• None The function draws a contour plot for an interactive linear model (i.e., the contour shows from the model ) over a scatterplot between the two predictor variables. This plot should aid the understanding of an interaction between two continuous variables.\n• None The function can now draw a bivariate density estimate as a contour plot if provided with two-dimensional input data.\n• None The function provides a simple grid-based visualization of a color palette.\n• None The function can be drawn without the correlation coefficient annotation and with variable names on the side of the plot to work with large datasets.\n• None Additionally, sets the color palette intelligently based on the direction of the specified test.\n• None The histogram uses a reference rule to choose the bin size if it is not provided.\n• None Added the option in for binning a continuous predictor variable, allowing for clearer trends with many datapoints.\n• None Enhanced support for labeling plot elements and axes based on attributes in several distribution plot functions and for smarter Pandas integration.\n• None Scatter points in are slightly transparent so it is easy to see where observations overlap.\n• None Added the parameter to and to control the order of the bins when using a Pandas object.\n• None When an argument is not provided to a plotting function, it grabs the currently active axis instead of drawing a new one.\n• None Added the and for on-the-fly creation of blended color palettes.\n• None The color palette machinery is now intelligent about qualitative ColorBrewer palettes ( , , etc.), which are properly treated as discrete.\n• None Seaborn color palettes ( , , etc.) have been standardized in terms of basic hue sequence, and all palettes now have 6 colors.\n• None Introduced palettes, which make a palette with the basic color scheme of the source palette, but with a sequential blend from dark instead of light colors for use with line/scatter/contour plots.\n• None Added the function for blockwise color palettes controlled by a statement.\n• None A new plot style, has been added.\n• None Tick labels are padded a bit farther from the axis in all styles, avoiding collisions at (0, 0).\n• None Reorganized the package by breaking up the monolithic module into smaller modules grouped by general objective of the constituent plots.\n• None Installing with should automatically install most missing dependencies.\n• None The example notebooks are now used as an automated test suite.\n• None Fixed a bug where labels did not match data for and when using a groupby.\n• None Specifying bins for the histogram now works.\n• None Fixed a bug where would reset the axis height and cut off existing data.\n• None All axis styling has been moved out of the top-level function, so context or color palette can be cleanly changed."
    },
    {
        "link": "https://seaborn.pydata.org/generated/seaborn.lineplot.html",
        "document": "Draw a line plot with possibility of several semantic groupings.\n\nThe relationship between and can be shown for different subsets of the data using the , , and parameters. These parameters control what visual semantics are used to identify the different subsets. It is possible to show up to three dimensions independently by using all three semantic types, but this style of plot can be hard to interpret and is often ineffective. Using redundant semantics (i.e. both and for the same variable) can be helpful for making graphics more accessible.\n\nSee the tutorial for more information.\n\nThe default treatment of the (and to a lesser extent, ) semantic, if present, depends on whether the variable is inferred to represent “numeric” or “categorical” data. In particular, numeric variables are represented with a sequential colormap by default, and the legend entries show regular “ticks” with values that may or may not exist in the data. This behavior can be controlled through various parameters, as described and illustrated below.\n\nBy default, the plot aggregates over multiple values at each value of and shows an estimate of the central tendency and a confidence interval for that estimate.\n\nInput data structure. Either a long-form collection of vectors that can be assigned to named variables or a wide-form dataset that will be internally reshaped. Variables that specify positions on the x and y axes. Grouping variable that will produce lines with different colors. Can be either categorical or numeric, although color mapping will behave differently in latter case. Grouping variable that will produce lines with different widths. Can be either categorical or numeric, although size mapping will behave differently in latter case. Grouping variable that will produce lines with different dashes and/or markers. Can have a numeric dtype but will always be treated as categorical. Grouping variable identifying sampling units. When used, a separate line will be drawn for each unit with appropriate semantics, but no legend entry will be added. Useful for showing distribution of experimental replicates when exact identities are not needed. Data values or column used to compute weighted estimation. Note that use of weights currently limits the choice of statistics to a ‘mean’ estimator and ‘ci’ errorbar. Method for choosing the colors to use when mapping the semantic. String values are passed to . List or dict values imply categorical mapping, while a colormap object implies numeric mapping. Specify the order of processing and plotting for categorical levels of the semantic. Either a pair of values that set the normalization range in data units or an object that will map from data units into a [0, 1] interval. Usage implies numeric mapping. An object that determines how sizes are chosen when is used. List or dict arguments should provide a size for each unique data value, which forces a categorical interpretation. The argument may also be a min, max tuple. Specified order for appearance of the variable levels, otherwise they are determined from the data. Not relevant when the variable is numeric. Normalization in data units for scaling plot objects when the variable is numeric. Object determining how to draw the lines for different levels of the variable. Setting to will use default dash codes, or you can pass a list of dash codes or a dictionary mapping levels of the variable to dash codes. Setting to will use solid lines for all subsets. Dashes are specified as in matplotlib: a tuple of lengths, or an empty string to draw a solid line. Object determining how to draw the markers for different levels of the variable. Setting to will use default markers, or you can pass a list of markers or a dictionary mapping levels of the variable to markers. Setting to will draw marker-less lines. Markers are specified as in matplotlib. Specified order for appearance of the variable levels otherwise they are determined from the data. Not relevant when the variable is numeric. estimator name of pandas method or callable or None Method for aggregating across multiple observations of the variable at the same level. If , all observations will be drawn. Name of errorbar method (either “ci”, “pi”, “se”, or “sd”), or a tuple with a method name and a level parameter, or a function that maps from a vector to a (min, max) interval, or None to hide errorbar. See the errorbar tutorial for more information. Number of bootstraps to use for computing the confidence interval. Dimension along which the data are sorted / aggregated. Equivalently, the “independent variable” of the resulting function. If True, the data will be sorted by the x and y variables, otherwise lines will connect points in the order they appear in the dataset. Whether to draw the confidence intervals with translucent error bands or discrete error bars. Additional parameters to control the aesthetics of the error bars. The kwargs are passed either to or , depending on . How to draw the legend. If “brief”, numeric and variables will be represented with a sample of evenly spaced values. If “full”, every group will get an entry in the legend. If “auto”, choose between brief or full representation based on number of levels. If , no legend data is added and no legend is drawn. Size of the confidence interval to draw when aggregating. Deprecated since version 0.12.0: Use the new parameter for more flexibility. Pre-existing axes for the plot. Otherwise, call internally. Other keyword arguments are passed down to . The matplotlib axes containing the plot.\n\nThe dataset has 10 years of monthly airline passenger data:\n\nTo draw a line plot using long-form data, assign the and variables:\n\nTo plot a single vector, pass it to . If the vector is a , it will be plotted against its index:\n\nPassing the entire wide-form dataset to plots a separate line for each column:\n\nPassing the entire dataset in long-form mode will aggregate over repeated values (each year) to show the mean and 95% confidence interval:\n\nThe same column can be assigned to multiple semantic variables, which can increase the accessibility of the plot:\n\nUse the parameter to aggregate and sort along the vertical dimension of the plot:\n\nEach semantic variable can also represent a different column. For that, we’ll need a more complex dataset:\n\nRepeated observations are aggregated even when semantic grouping is used:\n\nAssign both and to represent two different grouping variables:\n\nWhen assigning a variable, markers can be used instead of (or along with) dashes to distinguish the groups:\n\nShow error bars instead of error bands and extend them to two standard error widths:\n\nAssigning the variable will plot multiple lines without applying a semantic mapping:\n\nAssigning a numeric variable to maps it differently, using a different default palette and a quantitative color mapping:\n\nControl the color mapping by setting the and passing a object:\n\nOr pass specific colors, either as a Python list or dictionary:\n\nAssign the semantic to map the width of the lines with a numeric variable:\n\nPass a a tuple, , to control the range of linewidths used to map the semantic:\n\nBy default, the observations are sorted by . Disable this to plot a line with the order that observations appear in the dataset:\n\nUse to combine and . This allows grouping within additional categorical variables. Using is safer than using directly, as it ensures synchronization of the semantic mappings across facets:"
    },
    {
        "link": "https://seaborn.pydata.org/archive/0.11/introduction.html",
        "document": "Seaborn is a library for making statistical graphics in Python. It builds on top of matplotlib and integrates closely with pandas data structures.\n\nSeaborn helps you explore and understand your data. Its plotting functions operate on dataframes and arrays containing whole datasets and internally perform the necessary semantic mapping and statistical aggregation to produce informative plots. Its dataset-oriented, declarative API lets you focus on what the different elements of your plots mean, rather than on the details of how to draw them.\n\nHere’s an example of what seaborn can do: A few things have happened here. Let’s go through them one by one: Seaborn is the only library we need to import for this simple example. By convention, it is imported with the shorthand . Behind the scenes, seaborn uses matplotlib to draw its plots. For interactive work, it’s recommended to use a Jupyter/IPython interface in matplotlib mode, or else you’ll have to call when you want to see the plot. This uses the matplotlib rcParam system and will affect how all matplotlib plots look, even if you don’t make them with seaborn. Beyond the default theme, there are several other options, and you can independently control the style and scaling of the plot to quickly translate your work between presentation contexts (e.g., making a version of your figure that will have readable fonts when projected during a talk). If you like the matplotlib defaults or prefer a different theme, you can skip this step and still use the seaborn plotting functions. Most code in the docs will use the function to get quick access to an example dataset. There’s nothing special about these datasets: they are just pandas dataframes, and we could have loaded them with or built them by hand. Most of the examples in the documentation will specify data using pandas dataframes, but seaborn is very flexible about the data structures that it accepts. This plot shows the relationship between five variables in the tips dataset using a single call to the seaborn function . Notice how we provided only the names of the variables and their roles in the plot. Unlike when using matplotlib directly, it wasn’t necessary to specify attributes of the plot elements in terms of the color values or marker codes. Behind the scenes, seaborn handled the translation from values in the dataframe to arguments that matplotlib understands. This declarative approach lets you stay focused on the questions that you want to answer, rather than on the details of how to control matplotlib.\n\nThere is no universally best way to visualize data. Different questions are best answered by different plots. Seaborn makes it easy to switch between different visual representations by using a consistent dataset-oriented API. The function is named that way because it is designed to visualize many different statistical relationships. While scatter plots are often effective, relationships where one variable represents a measure of time are better represented by a line. The function has a convenient parameter that lets you easily switch to this alternate representation: Notice how the and parameters are used in both the scatter and line plots, but they affect the two visualizations differently: changing the marker area and symbol in the scatter plot vs the line width and dashing in the line plot. We did not need to keep those details in mind, letting us focus on the overall structure of the plot and the information we want it to convey.\n\nOften, we are interested in the average value of one variable as a function of other variables. Many seaborn functions will automatically perform the statistical estimation that is necessary to answer these questions: When statistical values are estimated, seaborn will use bootstrapping to compute confidence intervals and draw error bars representing the uncertainty of the estimate. Statistical estimation in seaborn goes beyond descriptive statistics. For example, it is possible to enhance a scatterplot by including a linear regression model (and its uncertainty) using :\n\nSeveral specialized plot types in seaborn are oriented towards visualizing categorical data. They can be accessed through . These plots offer different levels of granularity. At the finest level, you may wish to see every observation by drawing a “swarm” plot: a scatter plot that adjusts the positions of the points along the categorical axis so that they don’t overlap: Alternately, you could use kernel density estimation to represent the underlying distribution that the points are sampled from: Or you could show only the mean value and its confidence interval within each nested category:\n\nSeaborn creates complete graphics with a single function call: when possible, its functions will automatically add informative axis labels and legends that explain the semantic mappings in the plot. In many cases, seaborn will also choose default values for its parameters based on characteristics of the data. For example, the color mappings that we have seen so far used distinct hues (blue, orange, and sometimes green) to represent different levels of the categorical variables assigned to . When mapping a numeric variable, some functions will switch to a continuous gradient: When you’re ready to share or publish your work, you’ll probably want to polish the figure beyond what the defaults achieve. Seaborn allows for several levels of customization. It defines multiple built-in themes that apply to all figures, its functions have standardized parameters that can modify the semantic mappings for each plot, and additional keyword arguments are passed down to the underlying matplotlib artsts, allowing even more control. Once you’ve created a plot, its properties can be modified through both the seaborn API and by dropping down to the matplotlib layer for fine-grained tweaking:"
    },
    {
        "link": "https://kaggle.com/code/vijayjoshi17/seaborn-guide-all-important-plots",
        "document": ""
    },
    {
        "link": "https://numpy.org/doc/2.1/reference/generated/numpy.linspace.html",
        "document": "The end value of the sequence, unless endpoint is set to False. In that case, the sequence consists of all but the last of evenly spaced samples, so that stop is excluded. Note that the step size changes when endpoint is False.\n\nNumber of samples to generate. Default is 50. Must be non-negative.\n\nIf True, stop is the last sample. Otherwise, it is not included. Default is True.\n\nIf True, return (samples, step), where step is the spacing between samples.\n\nThe type of the output array. If is not given, the data type is inferred from start and stop. The inferred dtype will never be an integer; float is chosen even if the arguments would produce an array of integers.\n\nThe axis in the result to store the samples. Relevant only if start or stop are array-like. By default (0), the samples will be along a new axis inserted at the beginning. Use -1 to get an axis at the end.\n\nThe device on which to place the created array. Default: None. For Array-API interoperability only, so must be if passed."
    },
    {
        "link": "https://numpy.org/devdocs/reference/generated/numpy.linspace.html",
        "document": "The end value of the sequence, unless endpoint is set to False. In that case, the sequence consists of all but the last of evenly spaced samples, so that stop is excluded. Note that the step size changes when endpoint is False.\n\nNumber of samples to generate. Default is 50. Must be non-negative.\n\nIf True, stop is the last sample. Otherwise, it is not included. Default is True.\n\nIf True, return (samples, step), where step is the spacing between samples.\n\nThe type of the output array. If is not given, the data type is inferred from start and stop. The inferred dtype will never be an integer; float is chosen even if the arguments would produce an array of integers.\n\nThe axis in the result to store the samples. Relevant only if start or stop are array-like. By default (0), the samples will be along a new axis inserted at the beginning. Use -1 to get an axis at the end.\n\nThe device on which to place the created array. Default: None. For Array-API interoperability only, so must be if passed."
    },
    {
        "link": "https://datacamp.com/tutorial/how-to-use-the-numpy-linspace-function",
        "document": "Master your skills in NumPy by learning how to create, sort, filter, and update arrays using NYC’s tree census."
    },
    {
        "link": "https://realpython.com/np-linspace-numpy",
        "document": "When you’re working with numerical applications using NumPy, you often need to create an array of numbers. In many cases you want the numbers to be evenly spaced, but there are also times when you may need non-evenly spaced numbers. One of the key tools you can use in both situations is .\n\nIn its basic form, can seem relatively straightforward to use. However, it’s an essential part of the numerical programming toolkit. It’s both very versatile and powerful. In this tutorial, you’ll find out how to use this function effectively.\n\nIn this tutorial, you’ll learn how to:\n• Create an evenly or non-evenly spaced range of numbers\n• Decide when to use instead of alternative tools\n• Use the required and optional input parameters\n• Create arrays with two or more dimensions\n\nThis tutorial assumes you’re already familiar with the basics of NumPy and the data type. You’ll start by learning about various ways of creating a range of numbers in Python. Then you’ll take a closer look at all the ways of using and how you can use it effectively in your programs.\n\nCreating Ranges of Numbers With Even Spacing There are several ways in which you can create a range of evenly spaced numbers in Python. allows you to do this and to customize the range to fit your specific needs, but it’s not the only way to create a range of numbers. In the next section, you’ll learn how to use before comparing it with other ways of creating ranges of evenly spaced numbers. has two required parameters, and , which you can use to set the beginning and end of the range: This code returns an with equally spaced intervals between the and values. This is a vector space, also called a linear space, which is where the name comes from. Note that the value is included in the output array. The function returns a closed range, one that includes the endpoint, by default. This is contrary to what you might expect from Python, in which the end of a range usually isn’t included. This break with convention isn’t an oversight. You’ll see later on that this is usually what you want when using this function. The array in the example above is of length , which is the default number. In most cases, you’ll want to set your own number of values in the array. You can do so with the optional parameter : The output array in this instance contains equally spaced values between and , which is just the numbers from to . Here’s another example: In the example above, you create a linear space with values between and . You use the parameter as a positional argument, without explicitly mentioning its name in the function call. This is the form you’re likely to use most often. Let’s take a step back and look at what other tools you could use to create an evenly spaced range of numbers. The most straightforward option that Python offers is the built-in . The function call returns an object that produces the sequence from to , which is an evenly spaced range of numbers. For many numerical applications, the fact that is limited to integers is too restrictive. Of the examples shown above, only can be accomplished with : The values returned by , when converted explicitly into a list, are the same as those returned by the NumPy version, except that they’re integers instead of floats. You can still use with list comprehensions to create non-integer ranges: The values in the list are the same as the values in the array outputted by . However, even using a list comprehension is rather clumsy and inelegant compared to using . You first need to work out the interval required and then use that interval within a loop. In most applications, you’ll still need to convert the list into a NumPy array since element-wise computations are less complicated to perform using NumPy arrays. Another point you may need to take into account when deciding whether to use NumPy tools or core Python is execution speed. You can expand the section below to see how using a list performs in comparison to using a NumPy array. You can compare the method using NumPy with the one using list comprehensions by creating functions that perform the same arithmetic operation on all elements in both sequences. In the example below, you divide the range from to into samples, which is the same as intervals: The functions and perform the same operations on the sequences. You can confirm this by checking that the outputs from both functions are the same, as shown on line 12 in the code snippet above. Using the module to time the execution of both versions shows that using lists can be significantly slower than using NumPy arrays. Using NumPy tools rather than core Python can yield efficiency gains in some instances. In applications that require many computations on large amounts of data, this increase in efficiency can be significant. NumPy has its own version of the built-in . It’s called , and unlike , it’s not restricted to just integers. You can use in a similar way to , using , , and as the input parameters: The output values are the same, although returns a range object, which can be converted to a list to display all the values, while returns an array. The array returned by uses a half-open interval, which excludes the endpoint of the range. This behavior is similar to but different from . These differences can be a bit confusing initially, but you’ll get used to them as you start using these functions more often. You can even use non-integer numbers with : The output is an array starting from the value, with the gap between each number being exactly equal to the size used in the input arguments. The last number is the largest number in this series that is smaller than the number used for the of the range. The argument can also be a floating-point number, although you’ll need to use caution in this case as the output may not always be quite what you intend: In the first example, everything seems fine. However, you may have noticed that in the second example, when the is 0.345, the last value in the output is equal to the value even though uses a half-open interval. The documentation for has a warning about this: When using a non-integer step, such as 0.1, the results will often not be consistent. It is better to use for these cases. (Source) Here’s a good rule of thumb for deciding which of the two functions to use:\n• Use when the exact values for the and points of your range are the important attributes in your application.\n• Use when the size between values is more important. You’ll use again in this tutorial. To learn more about it, check out NumPy arange(): How to Use np.arange().\n\nUsing with the , , and parameters is the most common way of using the function, and for many applications you won’t need to look beyond this approach. However, you can customize your output further. In this section, you’ll learn how to customize the range that’s created, determine the data types of the items in the array, and control the behavior of the endpoint. Although and are the only required parameters, you’ll usually also want to use a third parameter, . The parameters and are the beginning and end of the range you wish to create, and is an integer that determines how many elements the output array will have. Depending on the application you’re developing, you may think of as the sampling, or resolution, of the array you’re creating. Have a look at a few more examples: Both arrays represent the range between -5 and 5 but with different sampling, or resolution. If you prefer, you can use named parameters: The use of named parameters makes the code more readable. In many applications that use extensively, however, you’ll most often see it used without the first three parameters being named. You can use non-integer numbers to define the range: The array now consists of equally spaced numbers starting and stopping at the exact values used as arguments for the and parameters. You now know how to use the three main input parameters: Often, you’ll use this function with only these three input parameters. However, as you’ll see in the next sections, you can modify the output further. The elements of a NumPy array all belong to the same data type. typically returns arrays of floats. You can see this both by inspecting the output or, better still, by looking at the attribute for the array: The numbers in the array are floats. This is true even in cases such as the following: Even though all elements are whole numbers, they’re still displayed with a trailing period to show that they’re floats. You confirm that by looking at the value of . You can use the optional input parameter to change the data type of the elements in the output array: Although the argument states , NumPy interprets this as an , which is a data type within NumPy. You can confirm this by checking the type of one of the elements of : This shows that NumPy uses its own version of the basic data types. You can use the NumPy data types directly as an argument for the parameter: This produces the same output result but avoids ambiguity by explicitly stating the NumPy data type. When choosing a specific data type, you need to use caution to make sure that your linear space is still valid: NumPy forces the values to be of type by rounding in the usual manner, but the result is no longer a linear space. It’s unlikely that this is the outcome you want. You can read more on data types in NumPy in the official documentation. By default, uses a closed interval, , in which the endpoint is included. This will often be your desired way of using this function. However, if you need to create a linear space with a half-open interval, , then you can set the optional Boolean parameter to : This option allows you to use the function with the Python convention of not including the endpoint with a range. The function can also output the size of the interval between samples that it calculates. If you need the value of the step size between elements, then you can set the Boolean parameter to : The return value in this case is a tuple with the array as the first element and a float with the size as the second. You can also use nonscalar values for and . This returns a higher-dimensional array: Both and are lists of the same length. The first items from each list, and , are the and points for the first vector, which has samples as determined by the parameter. The same applies for the second elements from each list and the third ones. The output is a two-dimensional NumPy array with ten rows and three columns. You can explore this array further by inspecting a row and an element from the two-dimensional array: The first result represents the first row of the array. The second result shows the element in the third column of the first row. You can return the transposed version of this array by setting the optional parameter to : The output array now has the number of rows and columns swapped relative to the earlier example, in which the parameter was not explicitly set and the default value of was used. The function declaration serves as a good summary of the options at your disposal: You can find the full details in the documentation. The key points to remember about the input parameters are listed below: These required parameters define the beginning and end of the range. Often these will be scalar values, either or , but can be any array-like object. This parameter defines the number of points in the array, often referred to as sampling or resolution. If this parameter is set to , then the function treats the interval as a half-open interval and excludes the endpoint from the output array. If this parameter is set to , then the function returns the array and a with the step size between each element of the linear space. Otherwise, only the array is returned. This parameter can be used to set the data type of the elements in the output array. This parameter is used only with nonscalar and values. It determines the axis along which the results are stored. The outputs returned from calling the function are listed below:\n• An array of type containing the vector space\n• The step size as a , if is set to You can use this section as a reference when you start experimenting with and the different ways you can customize its output. Imagine that a company that produces packaged food items has a conveyor belt system in its food production factory. The position along the conveyor belt is referenced by a number that represents the length of the conveyor path from the starting point. There are 27 temperature sensors that have been installed at equal intervals along a critical stretch of the belt. The first sensor is located at position 17.5 along the belt, and the last one at 46.2. The temperature sensor array outputs data that can be read as a list in Python. Here’s an example of a readout of temperatures in degrees Celsius: The factory manager needs to see these temperatures plotted against their position on the conveyor belt to ensure temperatures remain within tolerance at each point on this critical stretch of the belt. You’ll need to import to plot the temperatures: You plot the values in the list and set the title and axis labels. This gives the following plot: This plot shows the temperatures plotted against the list index of the sensors. This isn’t useful for the factory manager, who wants to know the temperatures with respect to the standard reference positions of the belt. To create an index for the temperatures that matches the known reference positions, you’ll use three bits of information:\n• The first one is at position 17.5.\n• The last one is at position 46.2. This is an ideal scenario for using : The linear space shows the exact locations of all the temperature sensors along the conveyor belt. You can now plot the temperatures against the array: The difference from the previous example in the code above is that you use the array as the first argument in . This gives the following plot: The graph now shows the correct x-axis, which represents the positions at which each temperature was measured. This example shows a typical case for which is the ideal solution.\n\nMany areas of science, engineering, finance, and other fields rely on mathematical functions. These are often functions of continuous variables. If you want to study these processes computationally, then you’ll need to approximate these mathematical functions with a discrete representation. One of the key tools you’ll need in this process is the ability to create a linear space. In this section, you’ll learn how to represent a mathematical function in Python and plot it. Consider the following function: This mathematical function is a mapping from the continuous real number line. Even if limits are set, say for -5 ≤ x ≤ 5, there is still an infinite number of values of x. To represent the function above, you’ll first need to create a discrete version of the real number line: In this tutorial, the symbol x is used to represent the continuous mathematical variable defined over the real number line, and is used to represent the computational, discrete approximation of it. The version with an underscore is also used for the Python variable representing the array. Since is a NumPy array, you can compute algebraic manipulations similarly to how you would mathematically, and no loops are required: The new array, , is a discrete version of the continuous variable . The final step is to visualize it: This creates a plot of against , which is shown below: Note that this plot doesn’t seem very smooth. The linear space created has only points. That’s not enough to represent the mathematical function properly. The function is undersampled. Doubling the resolution may work better: This gives the following plot: That’s better, and you can be more confident that it’s a fair representation of the function. However, the plot still isn’t as smooth as you might expect to see in a math textbook. With an even higher sampling, the plot becomes smoother: This gives the following plot: You can choose an even higher sampling, but that will come at a cost. Larger arrays require more memory, and computations will require more time. In this section, you’ll create two different waves with distinct properties, then you’ll superimpose them and create an animation to show how they travel. A wave can be represented mathematically by the following function: This tutorial isn’t about the physics of waves, so I’ll keep the physics very brief! A wave follows a sinusoidal function that is defined by the following five terms:\n• The amplitude of the wave (A)\n• The velocity of the wave (v) You’ll learn how to deal with two-dimensional functions in the next section, but for this example you’ll take a different approach. You can start by creating a linear space to represent x: Once the constants are defined, you can create the wave. You can start by defining the constants: # You can set time to 0 for now The function includes time (t), but initially you’ll focus on the variable x. Setting for now means that you can still write the full equations in your code even though you’re not using time yet. You can now create the array to represent the wave: The array created is the discrete version of the equation that describes the wave. Now you can plot the : The plot of the is shown below: That doesn’t look like a sine wave, but you saw this issue earlier. The resolution of the linear space used for isn’t sufficient. You can fix this by increasing the sampling: This plot of the now shows a smooth wave: Now you’re ready to superimpose two waves. All you need to do is create two different waves and add them up. This is also a good time to refactor the code to tidy it up a bit: # Parameters are tuples with a value for each wave (2 in this case) # You can set time to 0 for now # Create 2 (or more) waves using a list comprehension and superimpose # Plot both waves separately to see what they look like This code creates two different waves and adds them together, showing the superimposition of waves: You can see both waves plotted separately in the top figure. The bottom figure shows the superimposition of the waves, when they’re added together. Your final task now is to set these waves in motion by plotting the superimposed waves for different values of time t: # Create 2 (or more) waves using a list comprehension and superimpose # Fix the limits on the y-axis This gives the following output: You can try out the code above with waves of different parameters, and you can even add a third or fourth wave. You can now pick your own favorite functions to experiment with and try to represent them in Python. In the previous example, you resolved the problem of having a function with two variables by representing one as a spatial coordinate and one as a time coordinate. This made sense as the two coordinates were indeed one spatial and one temporal. This method won’t always work, though. Here’s a function with two variables: This is the simplified Gaussian function in two dimensions, with all parameters having unit value. To represent this, you’ll need to create two linear spaces, one for x and one for y. In this case, they can be identical, but that doesn’t always need to be the case: These vectors are each one-dimensional, but the required array must be two-dimensional since it needs to represent a function of two variables. NumPy has a useful function called that you can use in conjunction with to transform one-dimensional vectors into two-dimensional matrices. These matrices represent the coordinates in two dimensions: You’ve transformed the vectors into two-dimensional arrays. You can now use these arrays to create the two-dimensional function: You can show this matrix in two or three dimensions using : The two-dimensional and three-dimensional representations are shown below: You can use this method for any function of two variables. If you wanted to create a binary disk-shaped mask, then you could represent this function using comparison operators: On line 10, you generate the array using element-wise comparison. This gives the following plot: The array has the value (or ) for all values of and that fall within the equation of the circle. Otherwise, it has the value (or ). You’re now equipped with the tools to represent mathematical functions in one dimension and two dimensions computationally, using to create the linear spaces required to represent the function variables. You can extend the same concept to higher dimensions as well.\n\nYou’ve seen how to create and use an evenly spaced range of numbers. However, there are times when you may need an array that isn’t spaced linearly. The steps between each value may need to be logarithmic or follow some other pattern. In this final section, you’ll find out what your options are for creating this type of array. The function creates a logarithmic space in which the numbers created are evenly spaced on a log scale. Once you’ve mastered , you’ll be well equipped to use since the input parameters and returned output of the two functions are very similar. One parameter that’s missing from is since there isn’t a single value to represent the step change between successive numbers. has an additional input parameter, , with a default value of . Another key difference is that and represent the logarithmic start and end points. The first value in the array is , and the final value is : This creates a logarithmic space with elements ranging from to , or from to . The output array shows the numbers , , , , and in scientific notation. Although base 10 is the default value, you can create logarithmic spaces with any base: This example shows a logarithmic space in base e. In the next section, you’ll see how to create other nonlinear ranges that aren’t logarithmic. You can now create linear and logarithmic spaces. You may also need a range of numbers that follow other nonlinear intervals. You can achieve this by transforming a linear space. You can now transform this to be a range of numbers that are linear over x2: This may seem familiar. It’s the same method you used to represent mathematical functions earlier in this tutorial. Indeed, it’s exactly the same. The reason you may sometimes want to think of this as creating a non-evenly spaced array will become clearer in the next section, when you look at a concrete example. Example: Simulation of an Orbiting Planet In this section, you’ll create a simulation of a planet orbiting around its sun. To simplify the simulation slightly, you can assume the planet’s orbit is circular rather than elliptical. The equation that describes a circle is a function of x and y and depends on the radius R: So if the x-positions of the planet are set, the corresponding y-positions will be given by rearranging the equation above: The planet can therefore be placed at a set of coordinates (x, y), and as long as y is given by the equation above, the planet will remain in orbit. Its location will be on the circumference of a circle. You’re now well versed with , so the first attempt can use the methods you already know: The variable x spans the diameter of the circle along the horizontal, from left to right, which means from -R to +R. Now you can work out y: The array is the discrete version of the continuous variable y, which describes a circle. You can plot these points using a scatter plot: To make sure the two-dimensional plot shows the correct pattern, you set the axes to , which ensures that each pixel has a square aspect ratio: All points fit nicely on the circumference of a circle, which should be the case for a planet in a circular orbit. But planets don’t only go around a semicircular orbit. The problem is that the values of x for the other half of the circle are the same. The top semicircle and the bottom one share the same x values but not the same y values. You can resolve this issue by looking back at the above equation that gives y in terms of x. This equation has both a positive solution and a negative one. As x swings back from +R on the right to -R on the left, you can take the negative solution for y: # x_return and y_return are the x_ and y_ values as the # planet moves from right to left The array is the reverse of but without the endpoints. Otherwise, the endpoints will be repeated when you concatenate and . The array is the negative solution for . Therefore, you can overwrite to become the concatenation of and : The values within go from through to and then back through to . You can also print to confirm that it corresponds to the positive values of y for the first half and the negative values of y for the second half. A scatter plot of and will confirm that the planet is now in an orbit that’s a full circle: This gives the following plot: You may already be able to spot the problem in this scatter plot, but you’ll come back to it a bit later. For now, you can use the and vectors above to create a simulation of the moving planet. You’ll need to import for this: # an equal aspect (square), and turn the axes off # Images are generated and stored in a list to animate later # Scatter plot each point using a dot of size 250 and color red # Let's also put a large yellow sun in the middle # The animation can now be created using ArtistAnimation This gives the following output: Unfortunately, planets don’t orbit in this manner. You can see how the planet speeds up as it crosses the x-axis at the left and right of the orbit and slows down as it crosses the y-axis at the top and bottom. Take another look at the scatter plots showing all the planet positions around the orbit to see why this happens. The points are closer together at the top and bottom of the orbit but spaced out on the left and right. You need points that are evenly spaced over the circumference of the orbit, but what you have are points based on an evenly spaced vector. To fix this, you need to create an array of values that isn’t linear but that produces points that are linear along the circumference of the orbit. As a point moves smoothly around a circular orbit, its projection on the x-axis moves (co-)sinusoidally, so you can fix this by changing so that it’s linear over : The first line transforms a linear space into a nonlinear one. The intervals between each value of aren’t equal but vary according to the cosine function. This gives the following plot: The points are now evenly spaced across the circumference of the circular orbit. Your final step is to re-create the animation using the same code as earlier. This is also a good time to increase the resolution by increasing the value of the variable you defined at the start: This gives the following output: To see the full version of the code that generates this animation, you can expand the section below. The full, final version of the simulation, including saving the simulation to a , is available here: # Create vector x_ that is linear on cos(x_) # First create x_ from left to right (-R to +R) # And then x_ returns from right to left (+R to R) # Calculate y_ using the positive solution when x_ is increasing # And the negative solution when x_ is decreasing You’ve just created an animation of a planet orbiting a star. You had to make the movement of the planet linear over the circumference of a circle by making the positions of the planet evenly spaced over the circumference of the circle. You can now create any non-evenly spaced range of numbers as long as you can express it mathematically."
    },
    {
        "link": "https://geeksforgeeks.org/numpy-linspace",
        "document": "linspace() function in NumPy returns an array of evenly spaced numbers over a specified range. Unlike the range() function in Python that generates numbers with a specific step size. linspace() allows you to specify the total number of points you want in the array, and NumPy will calculate the spacing between the numbers automatically.\n\nLet’s understand with the help of an example:\n• None In this example, np.linspace(0, 1, num=10) generates an array of 10 numbers between 0 and 1, including both endpoints.\n• num : [int, optional] No. of samples to generate\n• retstep : If True, Stop is the last sample By default restep = False\n• endpoint : If True, stop is included as the last value. If False, stop is excluded. By default endpoint=True.\n• axis : If start and stop are arrays, axis specifies on what axis will the values be added. If axis = 0, value is added to front, if axis = -1 value is added at the end.\n\nIncluding or Excluding the Stop Value\n\nBy default, includes the value. However, you can exclude it by setting the parameter to .\n\nparameter allows you to return the step size between each number along with the array.\n\nWe can also generate multi-dimensional arrays using linspace(). We can create a 2D array of numbers between 0 and 1:"
    }
]