[
    {
        "link": "https://docs.oracle.com/javase/8/docs/api/java/awt/image/BufferedImage.html",
        "document": ". Returns a of objects that are the immediate sources, not the sources of these immediate sources, of image data for this\n\nSets a rectangular region of the image to the contents of the specified , which is assumed to be in the same coordinate space as the ."
    },
    {
        "link": "https://docs.oracle.com/javase/7/docs/api/java/awt/image/BufferedImage.html",
        "document": ". Returns a of objects that are the immediate sources, not the sources of these immediate sources, of image data for this\n\nSets a rectangular region of the image to the contents of the specified , which is assumed to be in the same coordinate space as the ."
    },
    {
        "link": "https://gihansblog.wordpress.com/2011/07/11/contrast-control-with-java-buffered-image-class",
        "document": "Hi, in this post I’m going to tell you how to change the contrast of an buffered image. And it will be very easy to you if you read my previous post on Brightness control with java Buffered image class... Here I’m going to explain only the key methods and others will be same as Brightness control.\n\nIn this program also here are two methods I’ve written.\n\nLet’s consider them, one by one\n\n}//end rescale\n\n In here, I’ve created RescaleOp object, and should pass parameters as in order sacleFactors, offsets, hints .\n\nBy changing offsets value we can adjust the brightness of an image, and by changing sacleFactors value we can adjust contrast of an image and hints for the specified RenderingHints or can be kept as null. In my program scaleFactor is set to 1.0 in float for default image and for enhanced image it is set to 3.6 in float.\n\nIn the filter method filter(sourse_bufferedImage, destination_bufferedImage); should be given as like this, and it returns filtered buffered image. Then in the contrastChange() the rescale() method is called and as I mentioned in my previous post, the buffered image is printed on a JLabel.\n\nHere is the source code of it and if you want you can DOWNLOAD my Netbeans project. And it has two classes Contrast.java and Main.java which is included the main method.\n\n/**\n\n *\n\n * @author gihan\n\n */\n\n public class Contrast extends JFrame{\n\n //globel variables\n\n BufferedImage bufferedImage;\n\n String path=”/home/gihan/Pictures/nfs_bmw.jpg”;// image file path \n\n float scaleFactor=3.6f;//change scaleFactor to change contrast \n\n /*keep the value scaleFactor = 1.0f; as for a normal image*/\n\n RescaleOp rescale;\n\n ImageIcon icon;\n\n JLabel picLabel=new JLabel();\n\nIf you have any doubt, feel free to ask. \n\n Thank you"
    },
    {
        "link": "https://geeksforgeeks.org/image-processing-in-java-read-and-write",
        "document": "Java implements a particular type of object called a BufferedImage for images in Java. A BufferedImage can be read from several distinct image types (i.e., BMP, HEIC, etc.). Not all of these are backed by ImageIO itself, but there are plugins to extend ImageIO and other libraries such as Apache Imaging and JDeli.\n\nIn Java itself, all the complexity of various image types is hidden, and we only work on BufferedImage. Java provides immediate access to the image pixels and color information and allows conversions and image processing.\n\nClasses Required to Perform the Read and Write Operations:\n\n1. java.io.File: To read and write an image file, we must import the File class. This class represents file and directory path names in general.\n\n2. java.io.IOException: To handle errors, we use the IOException class.\n\n3. java.awt.image.BufferedImage: To hold the image, we create the BufferedImage object; we use BufferedImage class. This object is used to store an image in RAM.\n\n4. javax.imageio.ImageIO: To perform the image read-write operation, we will import the ImageIO class. This class has static methods to read and write an image."
    },
    {
        "link": "https://stackoverflow.com/questions/3433275/adjust-brightness-and-contrast-of-bufferedimage-in-java",
        "document": "That was easy, actually.\n\nA of 1.2 and of 15 seems to make the image about a stop brighter.\n\nRead more in the docs for ."
    },
    {
        "link": "https://geeksforgeeks.org/java-awt-color-class",
        "document": "The Color class is a part of Java Abstract Window Toolkit(AWT) package. The Color class creates color by using the given RGBA values where RGBA stands for RED, GREEN, BLUE, ALPHA or using HSB value where HSB stands for HUE, SATURATION, BRIcomponents. The value for individual components RGBA ranges from 0 to 255 or 0.0 to 0.1. The value of alpha determines the opacity of the color, where 0 or 0.0 stands fully transparent and 255 or 1.0 stands opaque.\n• Color(ColorSpace c, float[] co, float a) : Creates a color in the specified ColorSpace with the color components specified in the float array and the specified alpha.\n• Color(float r, float g, float b) : creates a opaque color with specified RGB components(values are in range 0.0 – 0.1)\n• Color(float r, float g, float b, float a) : creates a color with specified RGBA components(values are in range 0.0 – 0.1)\n• Color(int rgb): Creates an opaque RGB color with the specified combined RGB value consisting of the red component in bits 16-23, the green component in bits 8 – 15, and the blue component in bits 0-7.\n• Color(int rgba, boolean b): Creates an sRGB color with the specified combined RGBA value consisting of the alpha component in bits 24-31, the red component in bits 16 – 23, the green component in bits 8 \n\n– 15, and the blue component in bits 0 – 7.\n• Color(int r, int g, int b) : Creates a opaque color with specified RGB components(values are in range 0 – 255)\n• Color(int r, int g, int b, int a) : Creates a color with specified RGBA components(values are in range 0 – 255)\n\nBelow programs illustrate the Color class in Java AWT :\n• Program to set the background color of panel using the color specified in the constants of the class\n• Program to create a new Color by stating the RGB value and set it as background of panel\n• Program to create a new Color by stating the RGB value and alpha value, set it as background of panel\n• Program to create a new Color by using Color(int rgb) method, set it as background of panel\n• Program to take RGBA value from user and set it as background of panel\n• Program to take HSB value from user and set it as background of panel"
    },
    {
        "link": "https://docs.oracle.com/javase/6/docs/api/java/awt/Color.html",
        "document": "The class is used to encapsulate colors in the default sRGB color space or colors in arbitrary color spaces identified by a . Every color has an implicit alpha value of 1.0 or an explicit one provided in the constructor. The alpha value defines the transparency of a color and can be represented by a float value in the range 0.0 - 1.0 or 0 - 255. An alpha value of 1.0 or 255 means that the color is completely opaque and an alpha value of 0 or 0.0 means that the color is completely transparent. When constructing a with an explicit alpha or getting the color/alpha components of a , the color components are never premultiplied by the alpha component.\n\nThe default color space for the Java 2D(tm) API is sRGB, a proposed standard RGB color space. For further information on sRGB, see http://www.w3.org/pub/WWW/Graphics/Color/sRGB.html .\n\nFinds a color in the system properties. The argument is treated as the name of a system property to be obtained. The string value of this property is then interpreted as an integer which is then converted to a object. If the specified property is not found or could not be parsed as an integer then is returned. - the name of the color property the converted from the system property.\n\nFinds a color in the system properties. The first argument is treated as the name of a system property to be obtained. The string value of this property is then interpreted as an integer which is then converted to a object. If the specified property is not found or cannot be parsed as an integer then the specified by the second argument is returned instead. - the name of the color property the converted from the system property, or the specified .\n\nFinds a color in the system properties. The first argument is treated as the name of a system property to be obtained. The string value of this property is then interpreted as an integer which is then converted to a object. If the specified property is not found or could not be parsed as an integer then the integer value is used instead, and is converted to a object. - the name of the color property - the default color value, as an integer the converted from the system property or the converted from the specified integer.\n\nConverts the components of a color, as specified by the HSB model, to an equivalent set of values for the default RGB model. The and components should be floating-point values between zero and one (numbers in the range 0.0-1.0). The component can be any floating-point number. The floor of this number is subtracted from it to create a fraction between 0 and 1. This fractional number is then multiplied by 360 to produce the hue angle in the HSB color model. The integer that is returned by encodes the value of a color in bits 0-23 of an integer value that is the same format used by the method . This integer can be supplied as an argument to the constructor that takes a single integer argument. - the hue component of the color - the saturation of the color - the brightness of the color the RGB value of the color with the indicated hue, saturation, and brightness."
    },
    {
        "link": "https://reintech.io/blog/java-image-processing-manipulating-analyzing-images",
        "document": "Java, being a robust and versatile language, offers extensive libraries and methodologies for image processing. This tutorial aims to guide software developers through the process of manipulating and analyzing images using Java. Even if you are a novice, this tutorial will equip you with the necessary knowledge to handle image processing in Java.\n\nBefore we delve into the image processing techniques, let's understand the basic concept of an image in Java. An image is basically an instance of the BufferedImage class in Java. It contains pixels, which are the smallest units of an image. Each pixel contains information about the color in RGBA format (Red, Green, Blue, and Alpha for transparency).\n\nFirst, let's see how to load an image in Java. We can use the ImageIO.read() method to read an image from a file, URL or InputStream. Here's how you can do this:\n\nOnce we have loaded the image, we can begin manipulating it. Let's see how we can perform various operations like resizing, rotating and changing the color of an image.\n\nWe can use the getScaledInstance() method of the Image class to resize an image. Below is a code snippet that demonstrates how to resize an image:\n\nTo rotate an image, we can use the AffineTransform class and the Graphics2D class. Here's an example:\n\nJava allows us to perform image analysis by extracting the pixel data. We can read and manipulate pixel data using the getRGB() and setRGB() methods.\n\nIn this tutorial, we have learned how to load, manipulate, and analyze images using Java. This knowledge will be very useful for any Java developer, especially if you are working in projects that require intensive image processing. If you're looking to hire remote Java developers or if you need a remote Java development team, you can consider Reintech."
    },
    {
        "link": "https://stackoverflow.com/questions/4281932/how-should-i-do-image-processing-in-java",
        "document": "I'm making an applet that lets users crop out a piece of an image and save it. For cropping, I'm going to implement a \"magic wand\"-esque tool. I can do all this in Matlab but i'm having some trouble figuring out the Java libraries. Here are a few tasks I need to perform:\n• Randomly access pixels in an image by (x,y) and return a single object (java.awt.Color, ARGB int, short[], whatever -- as long as I'm not dealing with channels individually)\n• Create a N by M image that's initialized to green\n\nAny pros out there who can help me? Just some code snippets off the top of your head would be fine."
    },
    {
        "link": "https://docs.oracle.com/javase/7/docs/technotes/guides/2d/spec/j2d-image.html",
        "document": "The following table contrasts the features of each of these imaging models.\n\nThis chapter focuses on the objects and techniques of the immediate mode imaging model. The immediate mode imaging classes and interfaces of the Java 2D API provide techniques for dealing with pixel mapped images whose data is stored in memory. This API supports accessing image data in a variety of storage formats and manipulating image data through several types of filtering operations.\n\nThe immediate mode imaging APIs in the Java 2D™ API can be grouped into six categories: interfaces, image data classes, image operation classes, sample model classes, color model classes, and exceptions.\n\nThe immediate mode imaging model supports fixed-resolution images stored in memory. The model also supports filtering operations on image data. A number of classes and interfaces are used in this model.\n\nAs shown in Figure 5-1, provides general image management. A can be created directly in memory and used to hold and manipulate image data retrieved from a file or URL. A can be displayed using any object for a screen device, or rendered to any other destination using appropriate context. A object contains two other objects: a and a .\n\nThe class provides image data management. It represents the rectangular coordinates of the image, maintains image data in memory, and provides a mechanism for creating multiple subimages from a single image data buffer. It also provides methods for accessing specific pixels within an image. A Raster object contains two other objects, a and a .\n\nThe class interprets data in the buffer and provides it as individual pixels or rectangular ranges of pixels.\n\nThe class provides a color interpretation of pixel data provided by the image’s sample model.\n\nThe image package provides additional classes that define filtering operations on and objects. Each image processing operation is embodied in a class that implements the interface, the interface, or both interfaces. The operation class defines methods that performs the actual image manipulation.\n\nNote that if you’re interested just in displaying and manipulating images, you only need to understand the class and the filtering operation classes. On the other hand, if you’re planning to write filters or otherwise directly access image data, you’ll need to understand the classes associated with .\n\nHere are some terms used throughout the following discussions:\n\nData Elements: primitive types used as units of storage of image data. Data elements are individual members of a array. The layout of elements in the data buffer is independent of the interpretation of the data as pixels by an image’s .\n\nSamples: distinct members of the pixels of an image. A provides a mechanism for converting elements in the to pixels and their samples. The samples of a pixel may represent primary values in a particular color model. For example, a pixel in an RGB color model consists of three samples: red, green, and blue.\n\nComponents: values of pixels independent of color interpretation. The distinction between component and sample is useful with , where pixel components are indexes into the .\n\nBand: the set of all samples of one type in an image, such as all red samples or all green samples. Pixel data can be stored in a number of ways, the two supported in the Java 2D API being banded and pixel interleaved. Banded storage organizes image data by bands, and a pixel is made up of sample data from the same position in each band. Pixel interleaved storage organizes image data by pixels, with a single array containing all pixels, and bands consisting of the set of samples at the same index position in each pixel.\n\nPrimaries: distinct members of a color value in a specific color model; for example the RGB model forms color values from the primaries red, green, and blue.\n\nThe class is the main class supporting the immediate imaging mode. It manages an image in memory, providing ways to store pixel data, interpret pixel data, and to render the pixel data to a or context.\n\nTo create a , call the method; this returns a whose drawing characteristics match those of the component used to create it—the created image is opaque, has the foreground and background colors of the , and you can’t adjust the transparency of the image. You could use this technique when you want to do double buffered drawing for animation in a component; the discussion “Drawing in an Offscreen Buffer” on page 79 gives more details.\n\nYou can also create a blank in memory using one of several constructor methods provided.\n\nThe class can be used to prepare graphic elements offscreen then copy them to the screen. This technique is especially useful when a graphic is complex or used repeatedly. For example, if you want to display a complicated shape several times, you could draw it once into an offscreen buffer and then copy it to different locations in the window. By drawing the shape once and copying it, you can display the graphics more quickly.\n\nThe package facilitates the use of offscreen buffers by letting you draw to an object the same way that you draw to a window. All of the Java 2D™ API rendering features can be used when drawing to offscreen images.\n\nOffscreen buffers are often used for animation. For example, you could use an offscreen buffer to draw an object once and then move it around in a window. Similarly, you could use an offscreen buffer to provide feedback as a user moves a graphic using the mouse. Instead of redrawing the graphic at every mouse location, you could draw the graphic once to an offscreen buffer, and then copy it to the mouse location as the user drags the mouse.\n\nFigure 5-3 demonstrates how a program can draw to an offscreen image and then copy that image into a window multiple times. The last time the image is copied, it is transformed. Note that transforming the image instead of redrawing it with the transformation might produce unsatisfactory results.\n\nThe simplest way to create an image that you can use as an offscreen buffer is to use the . method.\n\nBy creating an image whose color space, depth, and pixel layout exactly match the window into which you are drawing, the image can be efficiently blitted to a graphics device. This allows to do its job quickly.\n\nYou can also construct a object directly to use as an offscreen buffer. This is useful when you need control over the offscreen image’s type or transparency.\n\nA object can contain an alpha channel. In Figure 5-3, an alpha channel is used to distinguish painted and unpainted areas, allowing an irregular shape to appear over graphics that have already been painted (in this case, a shaded rectangle). In other cases, you might use alpha channel to blend the colors of the new image into those in the existing image.\n\nNote: unless you need alpha image data for transparency, as with the irregularly shaped images shown in Figure 5-2, you should avoid creating an off-screen buffer with alpha. Using alpha where it’s unnecessary slows rendering performance.\n\nprovides convenience methods that automatically create buffered images in a format compatible with your configuration. You can also query the graphics configuration associated with the graphics device on which the window resides to get the information you need to construct a compatible object.\n\nTo draw in a buffered image, you call its method, which returns a object. With this object, you can call all of the methods to draw graphics primitives, place text, and render other images in the image. This drawing technique supports dithering and other enhancements provided by the 2D imaging package. The following code illustrates the use of offscreen buffering:\n\nIn addition to drawing directly in a , you can directly access and manipulate the image’s pixel data in a couple of ways. These are useful if you’re implementing the filtering interface, as described in “Image Processing and Enhancement” on page 84.\n\nYou can use the . methods to directly set the value of a pixel or a pixel array to a specific RGB value. Note that no dithering is performed when you modify pixels directly. You can also manipulate pixel data by manipulating a object associated with a (see“Managing and Manipulating Rasters” on page 80).\n\nYou can apply a filtering operation to a using an object that implements interface. Filtering and the classes that provide this filtering interface are discussed in “Image Processing and Enhancement” on page 84.\n\nTo render a buffered image into a specific context, call one of the method of the context’s object. For example, when rendering within a . method, you call on the graphics object passed to the method.\n\nA object uses a to manage its rectangular array of pixel data. The class defines fields for the image’s coordinate system—width, height, and origin. A object itself uses two objects to manage the pixel data, a and a . The is the object that stores pixel data for the raster (as described on page 82), and the provides the interpretation of pixel data from the (as described on page 82).\n\nIn most cases, you don’t need to create a directly, since one is supplied with any that you create in memory. However, one of the constructor methods allows you to create a by passing in a .\n\nThe class provides a number of static factory methods for creating with the and you specify. You can use these factories when implementing filtering classes.\n\nThe class incorporates the concept of parent and child rasters. This can improve storage efficiency by allowing you to construct any number of buffered images from the same parent. The parent and its children all refer to the same data buffer, and each child has a specific offset and bounds to identify its image location in the buffer. A child identifies its ownership through its method.\n\nTo create a subraster, you use the . method.When you create a subraster, you identify the area of its parent that it covers and its offset from the parent’s origin.\n\nThe class defines a number of ways to access pixels and pixel data. These are useful when you’re implementing the interface, which provides raster-level filtering and manipulation of image data, or when implementing any method that needs to perform low-level pixel manipulation.\n\nThe methods let you get an individual pixel, which is returned as individual samples in an array. The . methods return a specified run of uninterpreted image data from the . The . method returns samples of an individual pixel. The method returns a band for a particular region of an image.\n\nIn addition to these methods, you can also access the data buffer and the sample model through instance variables of the class. These objects provide additional ways to access and interpret the ’s pixel data.\n\nThe subclass provides methods for setting pixel data and samples. The associated with a is actually a , thus providing full access to manipulate its pixel data.\n\nThe belonging to a represents an array of image data. When you create a directly or through the constructors, you specify a width and height in pixels, along with a for the image data. This information is used to create a of the appropriate data type and size.\n\nThere are three subclasses of , each representing a different type of data element:\n\nAs defined earlier, elements are the discrete members of the array of the data buffer, and components or samples are the discrete values that together make up a pixel. There can be various mappings between a particular type of element in a and a particular type of pixel represented by a . It is the responsibility of the various subclasses to implement that mapping and provide a way to get specific pixels from a specific .\n\nconstructors provide ways to create buffers of a specific size and a specific number of banks.\n\nWhile you can access image data in a directly, it’s generally easier and more convenient to do so through the methods of the and classes.\n\nThe abstract class defines methods for extracting samples of an image without knowing how the underlying data is stored. The class provides fields for tracking the height and width of the image data in the associated , and for describing the number of bands and the data type of that buffer. methods provide image data as a collection of pixels, with each pixel consisting of a number of samples or components.\n\nThe package provides five types of sample models:\n\nPixel data presented by the may or may not correlate directly to a color data representation of a particular color model, depending on the data source. For example, in photographic image data, the samples may represent RGB data. In image data from a medical imaging device, samples can represent different types of data such as temperature or bone density.\n\nThere are three categories of methods for accessing image data. The methods return a whole pixel as an array, with one entry for each sample. The methods provide access to the raw, uninterpreted data stored in the . The methods provide access to pixel components for a specific band.\n\nIn addition to the object for managing image data, the class includes a for interpreting that data as color pixel values. The abstract class defines methods for turning an image’s pixel data into a color value in its associated .\n\nThe package provides four types of color models:\n\nand are new in the Java™ 2 SDK software release.\n\nBased on data in the , the provides the with a pixel, which the then interprets as a color.\n\nA lookup table contains data for one or more channels or image components; for example, separate arrays for R, G, and B. The package defines two types of lookup tables that extend the abstract class, one that contains byte data and one that contains short data ( and ).\n\nThe image package provides a pair of interfaces that define operations on and objects: and .\n\nThe classes that implement these interfaces include , , . These classes can be used to geometrically transform, blur, sharpen, enhance contrast, threshold, and color correct images.\n\nFigure 5-4 illustrates edge detection and enhancement, an operation that emphasizes sharp changes in intensity within an image. Edge detection is commonly used in medical imaging and mapping applications. Edge detection is used to increase the contrast between adjacent structures in an image, allowing the viewer to discriminate greater detail.\n\nFigure 5-5 demonstrates lookup table manipulation. A lookup operation can be used to alter individual components of a pixel.\n\nFigure 5-6 illustrates rescaling. Rescaling can increase or decrease the intensity of all points. Rescaling can be used to increase the dynamic range of an otherwise neutral image, bringing out detail in a region that appears neutral or flat.\n\nConvolution is the process that underlies most spatial filtering algorithms. Convolution is the process of weighting or averaging the value of each pixel in an image with the values of neighboring pixels.This allows each output pixel to be affected by the immediate neighborhood in a way that can be mathematically specified with a kernel. Figure 5-7 illustrates Convolution.\n\nThe following code fragment illustrates how to use one of the image processing classes, . In this example, each pixel in the source image is averaged equally with the eight pixels that surround it.\n\nThe variable simpleBlur contains a new instance of that implements a blur operation on a or a . Suppose that sourceImage and destImage are two instances of . When you call , the core method of the class, it sets the value of each pixel in the destination image by averaging the corresponding pixel in the source image with the eight pixels that surround it.\n\nThe convolution kernel in this example could be represented by the following matrix, with elements specified to four significant figures:\n\nWhen an image is convolved, the value of each pixel in the destination image is calculated by using the kernel as a set of weights to average the pixel’s value with the values of surrounding pixels. This operation is performed on each channel of the image.\n\nThe following formula shows how the weights in the kernel are associated with the pixels in the source image when the convolution is performed. Each value in the kernel is tied to a spatial position in the image.\n\nThe value of a destination pixel is the sum of the products of the weights in the kernel multiplied by the value of the corresponding source pixel. For many simple operations, the kernel is a matrix that is square and symmetric, and the sum of its weights adds up to one.\n\nThe convolution kernel in this example is relatively simple. It weights each pixel from the source image equally. By choosing a kernel that weights the source image at a higher or lower level, a program can increase or decrease the intensity of the destination image. The object, which is set in the constructor, determines the type of filtering that is performed. By setting other values, you can perform other types of convolutions, including blurring (such as Gaussian blur, radial blur, and motion blur), sharpening, and smoothing operations. Figure 5-8 illustrates sharpening using Convolution.\n\nThe following code snippet illustrates sharpening with Convolution:"
    }
]