[
    {
        "link": "https://pytorch-geometric.readthedocs.io/en/2.5.1/modules/nn.html",
        "document": "An extension of the container in order to define a sequential GNN model. Since GNN operators take in multiple input arguments, additionally expects both global input arguments, and function header definitions of individual operators. If omitted, an intermediate module will operate on the output of its preceding module: Here, defines the input arguments of , and defines the function header, i.e. input arguments and return types of . In particular, this also allows to create more sophisticated models, such as utilizing :\n• None input_args (str) – The input arguments of the model.\n• None modules ([(str, Callable) or Callable]) – A list of modules (with optional function header definitions). Alternatively, an of modules (and function header definitions) can be passed."
    },
    {
        "link": "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GCN.html",
        "document": "\n• None in_channels (int) – Size of each input sample, or to derive the size from the first input(s) to the forward method.\n• None out_channels (int, optional) – If not set to , will apply a final linear transformation to convert hidden node embeddings to output size . (default: )\n• None act (str or Callable, optional) – The non-linear activation function to use. (default: )\n• None act_first (bool, optional) – If set to , activation is applied before normalization. (default: )\n• None act_kwargs (Dict[str, Any], optional) – Arguments passed to the respective activation function defined by . (default: )\n• None norm (str or Callable, optional) – The normalization function to use. (default: )\n• None norm_kwargs (Dict[str, Any], optional) – Arguments passed to the respective normalization function defined by . (default: )\n• None jk (str, optional) – The Jumping Knowledge mode. If specified, the model will additionally apply a final linear transformation to transform node embeddings to the expected output feature dimensionality. ( , , , , ). (default: )"
    },
    {
        "link": "https://pytorch-geometric.readthedocs.io",
        "document": "PyG (PyTorch Geometric) is a library built upon PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data.\n\nIt consists of various methods for deep learning on graphs and other irregular structures, also known as geometric deep learning, from a variety of published papers. In addition, it consists of easy-to-use mini-batch loaders for operating on many small and single giant graphs, multi GPU-support, torch.compile support, DataPipe support, a large number of common benchmark datasets (based on simple interfaces to create your own), and helpful transforms, both for learning on arbitrary graphs as well as on 3D meshes or point clouds."
    },
    {
        "link": "https://github.com/pyg-team/pytorch_geometric",
        "document": "PyG (PyTorch Geometric) is a library built upon PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data.\n\nIt consists of various methods for deep learning on graphs and other irregular structures, also known as geometric deep learning, from a variety of published papers. In addition, it consists of easy-to-use mini-batch loaders for operating on many small and single giant graphs, multi GPU-support, support, support, a large number of common benchmark datasets (based on simple interfaces to create your own), and helpful transforms, both for learning on arbitrary graphs as well as on 3D meshes or point clouds.\n\nClick here to join our Slack community!\n\nWhether you are a machine learning researcher or first-time user of machine learning toolkits, here are some reasons to try out PyG for machine learning on graph-structured data.\n• Easy-to-use and unified API: All it takes is 10-20 lines of code to get started with training a GNN model (see the next section for a quick tour). PyG is PyTorch-on-the-rocks: It utilizes a tensor-centric API and keeps design principles close to vanilla PyTorch. If you are already familiar with PyTorch, utilizing PyG is straightforward.\n• Comprehensive and well-maintained GNN models: Most of the state-of-the-art Graph Neural Network architectures have been implemented by library developers or authors of research papers and are ready to be applied.\n• Great flexibility: Existing PyG models can easily be extended for conducting your own research with GNNs. Making modifications to existing models or creating new architectures is simple, thanks to its easy-to-use message passing API, and a variety of operators and utility functions.\n• Large-scale real-world GNN models: We focus on the need of GNN applications in challenging real-world scenarios, and support learning on diverse types of graphs, including but not limited to: scalable GNNs for graphs with millions of nodes; dynamic GNNs for node predictions over time; heterogeneous GNNs with multiple node types and edge types.\n\nIn this quick tour, we highlight the ease of creating and training a GNN model with only a few lines of code.\n\nIn the first glimpse of PyG, we implement the training of a GNN for classifying papers in a citation graph. For this, we load the Cora dataset, and create a simple 2-layer GCN model using the pre-defined :\n\nMore information about evaluating final model performance can be found in the corresponding example.\n\nIn addition to the easy application of existing GNNs, PyG makes it simple to implement custom Graph Neural Networks (see here for the accompanying tutorial). For example, this is all it takes to implement the edge convolutional layer from Wang et al.:\n\nPyG provides a multi-layer framework that enables users to build Graph Neural Network solutions on both low and high levels. It comprises of the following components:\n• The PyG engine utilizes the powerful PyTorch deep learning framework with full and TorchScript support, as well as additions of efficient CPU/CUDA libraries for operating on sparse data, e.g., .\n• The PyG storage handles data processing, transformation and loading pipelines. It is capable of handling and processing large-scale graph datasets, and provides effective solutions for heterogeneous graphs. It further provides a variety of sampling solutions, which enable training of GNNs on large-scale graphs.\n• The PyG operators bundle essential functionalities for implementing Graph Neural Networks. PyG supports important GNN building blocks that can be combined and applied to various parts of a GNN model, ensuring rich flexibility of GNN design.\n• Finally, PyG provides an abundant set of GNN models, and examples that showcase GNN models on standard graph benchmarks. Thanks to its flexibility, users can easily build and modify custom GNN models to fit their specific needs.\n\nWe list currently supported PyG models, layers and operators according to category:\n\nGNN layers: All Graph Neural Network layers are implemented via the interface. A GNN layer specifies how to perform message passing, i.e. by designing different message, aggregation and update functions as defined here. These GNN layers can be stacked together to create Graph Neural Network models.\n• GCNConv from Kipf and Welling: Semi-Supervised Classification with Graph Convolutional Networks (ICLR 2017) [Example]\n• ChebConv from Defferrard et al.: Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering (NIPS 2016) [Example]\n• GATConv from Veličković et al.: Graph Attention Networks (ICLR 2018) [Example]\n\nPooling layers: Graph pooling layers combine the vectorial representations of a set of nodes in a graph (or a subgraph) into a single vector representation that summarizes its properties of nodes. It is commonly applied to graph-level tasks, which require combining node features into a single graph representation.\n• Top-K Pooling from Gao and Ji: Graph U-Nets (ICML 2019), Cangea et al.: Towards Sparse Hierarchical Graph Classifiers (NeurIPS-W 2018) and Knyazev et al.: Understanding Attention and Generalization in Graph Neural Networks (ICLR-W 2019) [Example]\n• DiffPool from Ying et al.: Hierarchical Graph Representation Learning with Differentiable Pooling (NeurIPS 2018) [Example]\n\nGNN models: Our supported GNN models incorporate multiple message passing layers, and users can directly use these pre-defined models to make predictions on graphs. Unlike simple stacking of GNN layers, these models could involve pre-processing, additional learnable parameters, skip connections, graph coarsening, etc.\n• SchNet from Schütt et al.: SchNet: A Continuous-filter Convolutional Neural Network for Modeling Quantum Interactions (NIPS 2017) [Example]\n• DimeNet and DimeNetPlusPlus from Klicpera et al.: Directional Message Passing for Molecular Graphs (ICLR 2020) and Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules (NeurIPS-W 2020) [Example]\n• Node2Vec from Grover and Leskovec: node2vec: Scalable Feature Learning for Networks (KDD 2016) [Example]\n• Deep Multiplex Graph Infomax from Park et al.: Unsupervised Attributed Multiplex Network Embedding (AAAI 2020) [Example]\n• Masked Label Prediction from Shi et al.: Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification (CoRR 2020) [Example]\n• PMLP from Yang et al.: Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs (ICLR 2023)\n\nGNN operators and utilities: PyG comes with a rich set of neural network operators that are commonly used in many GNN models. They follow an extensible design: It is easy to apply these operators and graph utilities to existing GNN layers and models to further enhance model performance.\n• DropEdge from Rong et al.: DropEdge: Towards Deep Graph Convolutional Networks on Node Classification (ICLR 2020)\n• DropNode, MaskFeature and AddRandomEdge from You et al.: Graph Contrastive Learning with Augmentations (NeurIPS 2020)\n• GraphNorm from Cai et al.: GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training (ICML 2021)\n• GDC from Klicpera et al.: Diffusion Improves Graph Learning (NeurIPS 2019) [Example]\n\nScalable GNNs: PyG supports the implementation of Graph Neural Networks that can scale to large-scale graphs. Such application is challenging since the entire graph, its associated features and the GNN parameters cannot fit into GPU memory. Many state-of-the-art scalability approaches tackle this challenge by sampling neighborhoods for mini-batch training, graph clustering and partitioning, or by using simplified GNN models. These approaches have been implemented in PyG, and can benefit from the above GNN layers, operators and models.\n• NeighborLoader from Hamilton et al.: Inductive Representation Learning on Large Graphs (NIPS 2017) [Example1, Example2, Example3]\n• ClusterGCN from Chiang et al.: Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks (KDD 2019) [Example1, Example2]\n• GraphSAINT from Zeng et al.: GraphSAINT: Graph Sampling Based Inductive Learning Method (ICLR 2020) [Example]\n\nPyG is available for Python 3.9 to Python 3.12.\n\nYou can now install PyG via Anaconda for all major OS/PyTorch/CUDA combinations 🤗 If you have not yet installed PyTorch, install it via as described in the official PyTorch documentation. Given that you have PyTorch installed ( ), simply run\n\nFrom PyG 2.3 onwards, you can install and use PyG without any external library required except for PyTorch. For this, simply run\n\nIf you want to utilize the full set of features from PyG, there exists several additional libraries you may want to install:\n\nThese packages come with their own CPU and GPU kernel implementations based on the PyTorch C++/CUDA/hip(ROCm) extension interface. For a basic usage of PyG, these dependencies are fully optional. We recommend to start with a minimal installation, and install additional dependencies once you start to actually need them.\n\nFor ease of installation of these extensions, we provide wheels for all major OS/PyTorch/CUDA combinations, see here.\n\nTo install the binaries for PyTorch 2.5.0, simply run\n\nwhere should be replaced by either , , , or depending on your PyTorch installation.\n\nTo install the binaries for PyTorch 2.4.0, simply run\n\nwhere should be replaced by either , , , or depending on your PyTorch installation.\n\nNote: Binaries of older versions are also provided for PyTorch 1.4.0, PyTorch 1.5.0, PyTorch 1.6.0, PyTorch 1.7.0/1.7.1, PyTorch 1.8.0/1.8.1, PyTorch 1.9.0, PyTorch 1.10.0/1.10.1/1.10.2, PyTorch 1.11.0, PyTorch 1.12.0/1.12.1, PyTorch 1.13.0/1.13.1, PyTorch 2.0.0/2.0.1, PyTorch 2.1.0/2.1.1/2.1.2, PyTorch 2.2.0/2.2.1/2.2.2, and PyTorch 2.3.0/2.3.1 (following the same procedure). For older versions, you might need to explicitly specify the latest supported version number or install via in order to prevent a manual installation from source. You can look up the latest supported version number here.\n\nNVIDIA provides a PyG docker container for effortlessly training and deploying GPU accelerated GNNs with PyG, see here.\n\nIn case you want to experiment with the latest PyG features which are not fully released yet, either install the nightly version of PyG via\n\nor install PyG from master via\n\nThe external repository provides wheels and detailed instructions on how to install PyG for ROCm. If you have any questions about it, please open an issue here.\n\nPlease cite our paper (and the respective papers of the methods used) if you use this code in your own work:\n\nFeel free to email us if you wish your work to be listed in the external resources. If you notice anything unexpected, please open an issue and let us know. If you have any questions or are missing a specific feature, feel free to discuss them with us. We are motivated to constantly make PyG even better."
    },
    {
        "link": "https://pytorch-geometric.readthedocs.io/en/2.5.0/generated/torch_geometric.nn.models.GCN.html",
        "document": "\n• None in_channels (int) – Size of each input sample, or to derive the size from the first input(s) to the forward method.\n• None out_channels (int, optional) – If not set to , will apply a final linear transformation to convert hidden node embeddings to output size . (default: )\n• None act (str or Callable, optional) – The non-linear activation function to use. (default: )\n• None act_first (bool, optional) – If set to , activation is applied before normalization. (default: )\n• None act_kwargs (Dict[str, Any], optional) – Arguments passed to the respective activation function defined by . (default: )\n• None norm (str or Callable, optional) – The normalization function to use. (default: )\n• None norm_kwargs (Dict[str, Any], optional) – Arguments passed to the respective normalization function defined by . (default: )\n• None jk (str, optional) – The Jumping Knowledge mode. If specified, the model will additionally apply a final linear transformation to transform node embeddings to the expected output feature dimensionality. ( , , , , ). (default: )"
    },
    {
        "link": "https://projects.volkamerlab.org/teachopencadd/talktorials/T035_graph_neural_networks.html",
        "document": "Note: This talktorial is a part of TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects.\n\nThere are several ways to represent molecules which are explained and discussed in Talktorial T033. If we work with molecules, one intuitive approach to apply deep learning to certain tasks is to make use of the graph structure of molecules. Graph neural networks can directly work on given graphs. Molecules can easily be represented as a graph, as seen in Figure 1. Given a graph \\(G=(V, E)\\), \\(V\\) describes the vertices or nodes. In molecular graphs, a node \\(v_i \\in \\mathbb{R}^{d_v}\\) represents an atom. Nodes can have \\(d_v\\) different features, such as atomic number and chirality. Edges usually correspond to covalent bonds between the atoms. Each edge \\(e_{ij} \\in \\mathbb{R}^{d_e}\\) is described by \\(d_e\\) number of features, which usually represent the bond type. A graph neural network is a network consisting of learnable and differentiable functions that are invariant for graph permutations. Graph neural networks consist of so-called message-passing layers which will be explained in more detail below, followed by more specific explanations of two different GNN architectures. We can perform different tasks with a GNN:\n• None Graph-level tasks: one application would be to predict a specific property of the entire graph. This can be a classification task such as toxicity prediction or a regression task. In this tutorial, we will implement a regression task to predict molecular properties. Another graph-level task would be to predict entirely new graphs/molecules. This is especially relevant in the area of drug discovery, where new drug candidates are of interest.\n• None Node-level tasks: we can predict a property of a specific node in the graph, e.g. the atomic charges of each atom. We could also predict a new node to be added to the graph. This is often done for molecule generation, where we want to add multiple atoms to form new molecules one after the other.\n• None Edge-level tasks: we can predict edge properties, e.g. intramolecular forces between atoms, or a new edge in the graph. In the molecule generation context, we want to predict potential bonds between the atoms. Edge prediction can also be used to infer connections/interactions e.g. in a gene regulatory network. Instead of MLP layers in standard neural networks, GNNs have message-passing layers, where we collect information about the neighboring nodes. For each node \\(v\\), we look at the direct neighbors \\(N(v)\\) and gather information. Then all the information is aggregated, for example with summation. Then we update the node \\(v\\) with the aggregated messages. If we perform this aggregation and combining, each node contains the information about the direct neighbors (1-hop). If we repeat this \\(n\\) times, we aggregate information about the \\(n_{th}\\) closest neighbors (\\(n\\) -hop). where \\(h_v^{(k)}\\) is the embedding of node \\(v\\) at layer \\(k\\), \\(N(v)\\) are the neighbors of node \\(v\\). One important property of a GNN is permutation invariance. This means that changing the order of nodes in the graph should not affect the outcome. For example, when working with adjacency matrices, changing the order of nodes would mean swapping rows and/or columns. However, this does not change any properties of a graph, but the input would differ. In GNNs, we want to overcome this. We, therefore need an aggregation function and a combining function that are permutation invariant, such as using the mean, the maximum or a sum. Using a permutation invariant aggregation function ensures that the graph-level outputs are also invariant to permutations. In this tutorial, we will explain graph-level regression tasks and in the following, we will present two different GNN architectures. One of the simplest GNNs is a Graph Convolutional Network (GCN). For GCNs, we sum over all neighbors of node \\(v\\), including the node \\(v\\) itself and aggregate all information. We divide it by the degree to keep the range of different nodes comparable. The node-wise aggregation function for layer \\(k\\) is where \\(d_j\\) and \\(d_i\\) denote the degree of node \\(j\\) and \\(i\\), respectively, and \\(\\Theta\\) represent trainable weights. One disadvantage of GCNs is, that they use a mean-based aggregation and this function is not injective. This means that different graphs can lead to the same graph embedding and the network cannot distinguish between the two graphs anymore. One example is visualized in Figure 3 below. Assuming the node and edge properties are identical, GCNs could create the same hidden embedding for these two graphs. Another type of GNN is the Graph Isomorphism Network (GIN), which has been proposed to overcome the disadvantages of GCNs explained above. The aggregation function is defined as follows The aggregation function here is a sum. The parameter \\(\\epsilon\\) decides on the importance of the node \\(v\\) compared to its neighbors. \\(h_\\Theta\\) represents a neural network for all nodes \\(v\\), for example an MLP. The sum aggregation function is more powerful compared to a mean aggregation (used in the GCN above) since we can distinguish between more similar graphs, for example, the two graphs in Figure 3. GINs are a good example of a simple network, which still is quite powerful, as they are quite good at distinguishing between non-isomorphic graphs. Two graphs are isomorphic if the graphs are identical except for node permutations. While this might be easily visible for smaller graphs, it is a complex problem for larger graphs. When working with GNNs, we would like the model to give us the same output if the input graphs are isomorphic. On the other hand, we also want the model to be able to differentiate between non-isomorphic graphs and output (possibly) different results. GINs can differentiate between non-isomorphic graphs a lot better than other simple GNNs such as GCN and GraphSage. For example, the two graphs in the figure above have different embeddings using GINs, since we are using a sum-based aggregation without any scaling or averaging. It is proven that GINs are as powerful as the Weisfeiler-Lehman test, a common (but not perfect) isomorphism test for graphs. If you are interested in the WL test or more details on GINs, have a look at the original publication about GINs or this blog post about the WL test. GINs cannot distinguish between all non-isomorphic graphs, one example is in Figure 4. Each node in both graphs has the same number of neighbors, therefore \\(h_v\\) is the same for all nodes \\(v\\) in both graphs. Similar to training a standard neural network, different design choices and hyperparameters need to be decided on. We will shortly present some concepts commonly used in neural networks, which can also be used for GNNs. Loss functions and activation functions are already discussed in Talktorial T022. We also used the mean squared error loss as well as the ReLU activation function. It is common to do batching when training a GNN to improve performance. The batch size indicates how many samples from the training data are fed to the neural network before updating model parameters. Choosing the right batch size is a trade-off between computational cost and generalization. For larger batches, the model is updated fewer times and the training is a lot faster. Models using smaller batches can generalize better, meaning that the test error can be lowered. Since this is not the only hyperparameter, choosing the batch size is also linked to the learning rate, the number of training epochs etc. One way to implement batching in GNNs is to stack the adjacency matrices of all graphs in the batch diagonally and to concatenate the node feature matrices. However, graphs (especially molecular graphs) can have rather sparse adjacency matrices. In this case, it is more efficient to use a sparse representation for the edges. PyTorch Geometric for example uses edge lists, where only the indexes of present edges are saved. These lists are concatenated during batching. Figure 4: Batching in GNNs, image taken from [3] Pooling layers help a neural network to reduce dimensionality. This makes the model more robust to variations. In graphs, global pooling layers can produce a graph embedding from the different node embeddings. There are different ways for pooling, the most common ones are: mean, max and sum, which are permutation invariant. Hence, pooling layers are also permutation invariant. For our GCN, we use a global mean pooling layer and for our GIN we use a global sum pooling layer, as it was proposed in the original publications listed in the references above. Pooling layers are also very useful to reduce the size of the layer to a fixed size for graph representation, therefore global pooling layers are also referred to as readout layers. One common problem in deep learning tasks is overfitting. This usually means that the dataset used to train the neural network is too small. Applying an overfitted network to a different dataset then leads to a high error in prediction, since the model is fit too closely to the training data and does not generalize well enough. To reduce overfitting, one approach is to use dropout layers, which can lead to a better generalization of the model. During training, nodes are randomly dropped. The probability of dropping nodes is another hyperparameter to be fixed. In each iteration, the nodes in a neural network (and the number of nodes) can therefore differ. This means we incorporate more noise and therefore force the neural network to generalize better. GNNs can be applied to a wide variety of tasks involving graphs, these could be based on small molecules (like in this tutorial), but also proteins (see Talktorial T038), gene regulatory networks and many more. Some applications are:\n• None Property prediction of molecules, such as toxicity and solubility (see: Wieder, Oliver, et al. A compact review of molecular property prediction with graph neural networks Drug Discovery Today: Technologies 37 (2020): 1-12. and MoleculeNet: a benchmark for molecular machine learning by Zhenqin Wu et al., Chemical science 9.2 (2018): 513-530.)\n• None Generating new molecules, which is especially relevant in the field of drug discovery (for more details, read this review by Tong, Xiaochu, et al. Generative models for De Novo drug design Journal of Medicinal Chemistry 64.19 (2021): 14011-14027)\n• None Inferring new interactions/associations in biological networks, such as gene regulatory networks or protein-protein interaction networks For a more detailed overview of GNNs and their applications, you can read the article by Zhang, Xiao-Meng, et al. Graph Neural Networks and Their Current Applications in Bioinformatics Frontiers in Genetics 12 (2021).\n\nFor the practical section, we have used PyTorch and PyTorch-Geometric, which helps us to handle graph data efficiently. PyTorch Geometric for example uses sparse matrix representations and implemented efficient graph batching. However, there are also different graph libraries for Python, such as the Deep Graph Library which is not covered in this tutorial. For this tutorial, we use the QM9 dataset, which can be imported with . The dataset is part of a benchmarking collection called MoleculeNet. It contains around \\(130,000\\) small molecules with at most 9 heavy atoms as well as various molecular properties. We will choose one property which we will then try to predict. If you are running this tutorial for the first time, the dataset will be downloaded here. As an example, the first molecule from the dataset is shown below. The dataset contains the following information: - : contains the different node features, such as atomic number, chirality, hybridization, is aromatic, is ring, - : adjacency matrix, representing the covalent bonds between the atoms, - : contains the edge features (bond type, is conjugated, stereo configuration), - : 3D atom coordinates, we will not use them in this tutorial, - : atomic numbers, - : target values, this dataset contains 19 different properties describing each molecule, such as dipole moment, different molecular energies, enthalpy and rotational constants. In this tutorial, we only use , and to keep it simple. While the dataset has many regression targets, we will only focus on one of the tasks, which is the prediction of the dipole moment \\(\\mu\\). For this tutorial, we only sample a subset of QM9. This keeps the runtime low and this is still enough to show some first results. The dataset is split into training, validation and test sets with a \\(80:10:10\\) split ratio. In addition, we normalize the training data (\\(\\mu=0, \\sigma=1\\)) and apply the same mean and standard deviation to the test and validation set. ~/.miniconda3/envs/teachopencadd/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`. warnings.warn(msg) ~/.miniconda3/envs/teachopencadd/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`. warnings.warn(msg) ~/.miniconda3/envs/teachopencadd/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`. warnings.warn(msg) The following two Python classes are the two GNNs we will consider in this tutorial. Both have 3 convolutional layers, one global pooling layer, linear layers, ReLU activation functions between the layers and a dropout layer. When training a GNN (or any neural network), we have a training set, a validation set and a test set. The training set is used for training, the validation set is used to test the loss in each epoch not only on the training set but also on another dataset (monitor generalization performance). The test set is used to calculate the error of the fully trained model using a dataset, which has not been used during the whole training process. loss (nn.functional): loss function to use during training epochs (int): number of epochs to train for path (string): path to save the best model array: returning train and validation losses over all epochs, prediction and ground truth values for training data in the last epoch # record truly vs predicted values for training data from last epoch We have trained both models with 100 epochs and saved the best models under and . Since this takes some time, we reduced the number of epochs to 10 for this tutorial for demonstration purposes. The results and the plots below are based on the models trained for 100 epochs. If you want to train your own model using our tutorial, you can change the number of epochs and any other parameters in our models (such as learning rate, batch size, etc.). # Remember to change the path if you want to keep the previously trained model # Remember to change the path if you want to keep the previously trained model For evaluation, we use a validation dataset to find the best model and a test set, to test our model on unseen data. First, we plotted the losses of our training and validation sets. As expected, the GIN model has a lower training and validation loss. \"\"\"Plot the loss for each epoch \"\"\"Plot true vs predicted value in a scatter plot When looking at the losses for each epoch, we can see that the GIN model performs better overall. We can also see that the training loss is often lower compared to the validation loss. This is normal since the training loss describes the error of the model using the training set, which is the dataset used for improving the model. The validation loss is calculated on a separate dataset, which is not used for updating the model weights. Therefore, the error is often higher. This is also the reason, the validation loss sometimes fluctuates more. As long as both losses show a decreasing tendency, this is not problematic. It is important to have a low training loss and a low validation loss. # Plot overall losses of GIN and GCN Then, we also plotted the actual predictions of our target value compared to the ground truth for the GIN model, since this model performs better. Below, we have calculated the test loss for both the GCN and the GIN. We also plot the predicted dipole moment compared to the ground truth for both models. If we are interested in the actual numeric range of the predicted dipole moment, the normalization applied during the preprocessing should be subtracted again. Since we only visualize the data in our evaluation, this does not make a difference. In the figures below, we can see that the GIN model performs a lot better compared to the GCN since the test error is lower. # Calculate test loss from the best GCN model (according to validation loss) # Calculate test loss from the best GIN model (according to validation loss)\n\nIn this talktorial we have first presented two different graph neural networks. We applied these two GNNs to a molecular dataset to predict molecular properties. We showed how to train and evaluate a simple GNN using pytorch and pytorch_geometric. This model can be used for any type of graph-level regression and, with small changes (such as the loss function), graph-level classification is also easy. One disadvantage of GNNs is that the quality of the model is extremely data-dependent, the more of the chemical space is covered in the training set, the better the performance would be on new, unseen data. In addition, training a model can be rather complex, since there are many parameters influencing the model. Model parameters, such as learning rate, batch size and number of hidden dimensions could be more thoroughly evaluated to improve the model. To apply this to real tasks, first, a bigger dataset is needed. When using the whole QM9 dataset and not only a small subset, the performance will increase. In addition, the model parameters can also still be optimized. The model architecture can also still be adapted. These changes could lead to longer runtimes, which is why we have chosen this simplified version for demonstration purposes."
    },
    {
        "link": "https://medium.com/we-talk-data/pytorch-geometric-tutorial-94af3ae2b8cb",
        "document": "I understand that learning data science can be really challenging… …especially when you are just starting out. But it doesn’t have to be this way. That’s why I spent weeks creating a 46-week Data Science Roadmap with projects and study resources for getting your first data science job. If that’s not enough, I’ve also added: 4. A Discord community to help our data scientist buddies get access to study resources, projects, and job referrals. Click here to access everything! Now, let’s get back to the blog:\n\n“Data is the new oil,” they say — but if that’s true, graphs are the pipelines carrying insights from data. As a data scientist, you’ve probably encountered situations where relationships between data points were as important as the data points themselves. Think about social networks, molecular structures, or even recommendation systems. Traditional deep learning struggles to capture these intricate relationships. This is where PyTorch Geometric (PyG) comes into play — a library designed specifically for graph-based deep learning. PyG isn’t just another library. It’s modular, lightning-fast, and integrates seamlessly with PyTorch. Whether you’re tackling a problem involving node classification, link prediction, or graph-level tasks, PyG provides tools that make handling graph data not only possible but intuitive. You might be wondering: Why should I pick PyG over other frameworks like DGL? Here’s the deal:\n• Performance: PyG is built with sparse operations optimized for GPUs, making it ideal for handling large graphs efficiently.\n• Modularity: The library is highly customizable, offering a range of pre-built layers like GCNConv, GATConv, and SAGEConv. Plus, it allows you to easily create your own.\n• Real-World Use Cases: PyG has been used to solve problems in diverse fields — analyzing molecular structures for drug discovery, modeling fraud detection in financial systems, and even building recommendation engines for streaming platforms. If you’ve ever felt the limitations of traditional deep learning when applied to interconnected data, PyG is the answer you’ve been looking for. Before we dive into the hands-on part, let’s make sure you’re ready to hit the ground running. This guide assumes that:\n• You have a solid grasp of PyTorch — autograd, tensor manipulations, and the basics of building and training neural networks.\n• You understand graph theory basics, like nodes, edges, adjacency matrices, and edge lists.\n• You’re comfortable with deep learning concepts such as forward passes, backpropagation, and optimization. If all that checks out, you’re in the perfect place to get started. Let’s roll up our sleeves and get your environment ready.\n\nWhen it comes to PyTorch Geometric, setting up your environment can sometimes feel like walking through a minefield, especially if you’re dealing with CUDA dependencies. But don’t worry — I’ve been there, and I’m here to guide you through it. First, you’ll need to install PyTorch. If you haven’t already, use the command below to ensure your PyTorch installation matches your hardware (CPU or GPU). Next, install PyTorch Geometric and its dependencies. PyG uses separate packages for scatter and sparse operations: I can’t stress this enough: always verify the compatibility of your PyTorch version with PyG. If something doesn’t work, check the official installation instructions here. Let’s make sure everything is working before moving forward. Run this quick script to verify: If you see a version number without errors, you’re good to go. If not, double-check your CUDA setup or consult the documentation for troubleshooting.\n\nHere’s where the fun begins. PyTorch Geometric introduces several concepts that are different from traditional deep learning. Don’t worry — once you understand how the library structures data, everything else falls into place. At the heart of PyG lies the Data object, which is how graphs are represented. It’s flexible enough to handle both simple and complex graphs. Here’s a practical example to get your hands dirty: from torch_geometric.data import Data\n\nimport torch\n\n\n\n# Define an edge list\n\nedge_index = torch.tensor([[0, 1, 1, 2], # Source nodes\n\n [1, 0, 2, 1]], # Target nodes\n\n dtype=torch.long)\n\n\n\n# Define node features (e.g., node labels or embeddings)\n\nx = torch.tensor([[1], [2], [3]], dtype=torch.float)\n\n\n\n# Create a Data object\n\ndata = Data(x=x, edge_index=edge_index)\n\nprint(data)\n• x: This tensor contains node features. In this case, we have three nodes, each with a single feature.\n• edge_index: This is the connectivity of the graph, represented as an adjacency list.\n• The Data object acts like a container, holding additional attributes like edge_attr (edge features) and y (node or graph labels). Most real-world problems don’t involve manually constructing graphs. PyG provides several built-in datasets for benchmarking, such as Cora, CiteSeer, and TUDataset. Let’s load the Cora dataset, a citation network used for node classification: from torch_geometric.datasets import Planetoid\n\n\n\n# Load the Cora dataset\n\ndataset = Planetoid(root='/tmp/Cora', name='Cora')\n\n\n\n# Inspect the dataset\n\nprint(f\"Dataset: {dataset}\")\n\nprint(f\"Number of graphs: {len(dataset)}\")\n\nprint(f\"Number of nodes: {dataset[0].num_nodes}\")\n\nprint(f\"Number of edges: {dataset[0].num_edges}\")\n\nprint(f\"Node features: {dataset[0].num_node_features}\")\n\nprint(f\"Classes: {dataset.num_classes}\") This might surprise you: despite being a “graph dataset,” Planetoid treats the entire dataset as one large graph. It’s common in tasks like node classification, where the goal is to label each node. Quick Tip: If you’re working with large datasets or custom graphs, consider using PyG’s InMemoryDataset or Dataset classes to streamline data handling. With these foundations in place, you’re ready to dive deeper into building and training graph neural networks. In the next section, we’ll craft a GNN from scratch and explore how PyG simplifies the entire process. Stay tuned!\n\nGraph Neural Networks (GNNs) are the heart of PyTorch Geometric, and building them is where things get exciting. Imagine you’re sculpting a statue. The dataset is your raw marble, and the GNN layers are your chisels, each designed to carve out intricate patterns from the graph data. With PyG, creating a custom GNN is like having precision tools at your disposal — powerful, flexible, and optimized for performance. Let’s start with something simple yet effective: a Graph Convolutional Network (GCN). Here’s the code to define a GCN model: import torch\n\nfrom torch.nn import Linear\n\nfrom torch_geometric.nn import GCNConv\n\n\n\n# Define a simple two-layer GCN\n\nclass GCN(torch.nn.Module):\n\n def __init__(self):\n\n super().__init__()\n\n self.conv1 = GCNConv(16, 32) # Input: 16 features, Output: 32 features\n\n self.conv2 = GCNConv(32, 2) # Output: 2 classes for classification\n\n\n\n def forward(self, x, edge_index):\n\n # Apply the first convolution and activation\n\n x = self.conv1(x, edge_index).relu()\n\n # Apply the second convolution\n\n x = self.conv2(x, edge_index)\n\n return x\n• GCNConv(16, 32): This layer takes node features with 16 dimensions and produces a 32-dimensional representation for each node.\n• edge_index: This parameter defines the graph structure, representing connections between nodes. Why GCN?\n\nThe beauty of a GCN lies in its ability to aggregate information from neighboring nodes. Think of it as asking your neighbors for advice before making a decision — your prediction becomes a blend of your features and your neighbors’ insights. You might be wondering: What actually happens during the forward pass? Here’s a simple breakdown:\n• Graph Convolution (Layer 1): Nodes share information with their immediate neighbors, creating new feature representations. Now that we’ve built our model, it’s time to train it. For this example, let’s use the Cora dataset, a classic benchmark for node classification. # Initialize the model\n\nmodel = GCN()\n\n\n\n# Define optimizer and loss function\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\ncriterion = torch.nn.CrossEntropyLoss()\n\n\n\n# Training loop\n\nfor epoch in range(200):\n\n model.train() # Set model to training mode\n\n optimizer.zero_grad() # Clear gradients from the previous step\n\n \n\n # Forward pass\n\n out = model(dataset[0].x, dataset[0].edge_index)\n\n \n\n # Compute loss only for training nodes\n\n loss = criterion(out[dataset[0].train_mask], dataset[0].y[dataset[0].train_mask])\n\n \n\n # Backpropagation\n\n loss.backward()\n\n optimizer.step()\n\n \n\n # Print progress\n\n print(f'Epoch {epoch}, Loss: {loss.item()}') Pro Tip: Use the train_mask provided by the dataset to ensure only the designated training nodes influence the model updates. Why This Matters:\n\nIn graph-based tasks, you’re often working with semi-supervised learning. You don’t need labels for every node — just a fraction is enough for the GNN to generalize across the graph.\n\nGNNs go beyond simple node classification. Let’s explore two other tasks: link prediction and graph-level classification. This task is all about predicting the label of individual nodes. The GCN example above is a classic implementation. For more complex relationships, you can replace GCNConv with GATConv (Graph Attention Networks), which weigh edges based on importance. Here’s the deal: predicting whether an edge exists between two nodes is crucial for tasks like recommendation systems or fraud detection. PyG simplifies this with utilities like negative_sampling: Pair this with a decoder (e.g., a simple dot product between node embeddings) to predict the likelihood of an edge. Sometimes, the goal isn’t about individual nodes or edges but the entire graph. For example, predicting molecular properties in drug discovery involves graph-level classification. from torch_geometric.data import DataLoader\n\n\n\n# Load your dataset\n\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n\n\nfor batch in loader:\n\n # Each batch contains multiple graphs\n\n print(batch.x.shape, batch.edge_index.shape, batch.y.shape)\n\nBuilding a graph neural network is just the first step. The real challenge begins when you’re dealing with large-scale data. Without careful optimization, even the most elegant models can grind to a halt. So, how do we ensure our PyTorch Geometric models perform efficiently? Let’s dive into some essential strategies. One of the first lessons I learned while working with GNNs is that handling multiple graphs at once is critical for scalability. Unlike traditional deep learning, where batching is straightforward, batching graphs can feel a bit tricky due to varying sizes and structures. PyG simplifies this with its DataLoader, which handles the complexities of batching graphs behind the scenes. Here’s how you can batch graphs for training: from torch_geometric.loader import DataLoader\n\n\n\n# Assuming 'dataset' contains multiple graphs\n\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n\n\nfor batch in loader:\n\n print(batch)\n\n print(f\"Batch node features shape: {batch.x.shape}\")\n\n print(f\"Batch edge index shape: {batch.edge_index.shape}\")\n• The DataLoader combines multiple graphs into a single batch, represented as a large graph with disconnected subgraphs.\n• batch.x: Node features for all graphs in the batch.\n• Why it matters: This batching strategy allows you to leverage GPU parallelism, significantly speeding up training on large datasets. Pro Tip: If you’re working with very large graphs that can’t fit into memory, consider subgraph sampling methods like NeighborSampler. Here’s the deal: Graphs are inherently sparse, and treating them as dense structures wastes memory and computation. PyG leverages sparse matrix representations, which can lead to massive performance gains when handling large graphs. For example, PyG uses sparse tensors for edge indexing in operations like GCNConv. You might be wondering how to take advantage of this directly. Here’s a quick snippet:\n• They enable faster computations for large graphs where most connections are absent. Practical Tip: Always use PyG’s built-in layers (e.g., GCNConv, SAGEConv) as they’re optimized to handle sparse adjacency matrices natively. Optimization isn’t just about writing efficient code — it’s also about identifying bottlenecks. PyTorch Profiler is a game-changer when it comes to debugging performance issues in your PyG models. Here’s a quick guide to using the profiler: import torch\n\nfrom torch.profiler import profile, record_function, ProfilerActivity\n\n\n\nmodel = GCN()\n\n\n\n# Sample input data\n\nx = dataset[0].x\n\nedge_index = dataset[0].edge_index\n\n\n\nwith profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n\n with record_function(\"model_inference\"):\n\n out = model(x, edge_index)\n\n\n\nprint(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n• A breakdown of which operations consume the most time. This might surprise you: Sometimes, the bottleneck isn’t in the model itself but in data loading or preprocessing. Profiling helps pinpoint the exact source of inefficiency."
    },
    {
        "link": "https://github.com/chaitjo/geometric-gnn-dojo/blob/main/geometric_gnn_101.ipynb",
        "document": "To see all available qualifiers, see our documentation .\n\nSaved searches Use saved searches to filter your results more quickly\n\nWe read every piece of feedback, and take your input very seriously.\n\nYou signed in with another tab or window. Reload to refresh your session.\n\nYou signed out in another tab or window. Reload to refresh your session.\n\nYou switched accounts on another tab or window. Reload to refresh your session."
    },
    {
        "link": "https://colab.research.google.com/github/chaitjo/geometric-gnn-dojo/blob/main/geometric_gnn_101.ipynb",
        "document": ""
    },
    {
        "link": "https://github.com/pyg-team/pytorch_geometric",
        "document": "PyG (PyTorch Geometric) is a library built upon PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data.\n\nIt consists of various methods for deep learning on graphs and other irregular structures, also known as geometric deep learning, from a variety of published papers. In addition, it consists of easy-to-use mini-batch loaders for operating on many small and single giant graphs, multi GPU-support, support, support, a large number of common benchmark datasets (based on simple interfaces to create your own), and helpful transforms, both for learning on arbitrary graphs as well as on 3D meshes or point clouds.\n\nClick here to join our Slack community!\n\nWhether you are a machine learning researcher or first-time user of machine learning toolkits, here are some reasons to try out PyG for machine learning on graph-structured data.\n• Easy-to-use and unified API: All it takes is 10-20 lines of code to get started with training a GNN model (see the next section for a quick tour). PyG is PyTorch-on-the-rocks: It utilizes a tensor-centric API and keeps design principles close to vanilla PyTorch. If you are already familiar with PyTorch, utilizing PyG is straightforward.\n• Comprehensive and well-maintained GNN models: Most of the state-of-the-art Graph Neural Network architectures have been implemented by library developers or authors of research papers and are ready to be applied.\n• Great flexibility: Existing PyG models can easily be extended for conducting your own research with GNNs. Making modifications to existing models or creating new architectures is simple, thanks to its easy-to-use message passing API, and a variety of operators and utility functions.\n• Large-scale real-world GNN models: We focus on the need of GNN applications in challenging real-world scenarios, and support learning on diverse types of graphs, including but not limited to: scalable GNNs for graphs with millions of nodes; dynamic GNNs for node predictions over time; heterogeneous GNNs with multiple node types and edge types.\n\nIn this quick tour, we highlight the ease of creating and training a GNN model with only a few lines of code.\n\nIn the first glimpse of PyG, we implement the training of a GNN for classifying papers in a citation graph. For this, we load the Cora dataset, and create a simple 2-layer GCN model using the pre-defined :\n\nMore information about evaluating final model performance can be found in the corresponding example.\n\nIn addition to the easy application of existing GNNs, PyG makes it simple to implement custom Graph Neural Networks (see here for the accompanying tutorial). For example, this is all it takes to implement the edge convolutional layer from Wang et al.:\n\nPyG provides a multi-layer framework that enables users to build Graph Neural Network solutions on both low and high levels. It comprises of the following components:\n• The PyG engine utilizes the powerful PyTorch deep learning framework with full and TorchScript support, as well as additions of efficient CPU/CUDA libraries for operating on sparse data, e.g., .\n• The PyG storage handles data processing, transformation and loading pipelines. It is capable of handling and processing large-scale graph datasets, and provides effective solutions for heterogeneous graphs. It further provides a variety of sampling solutions, which enable training of GNNs on large-scale graphs.\n• The PyG operators bundle essential functionalities for implementing Graph Neural Networks. PyG supports important GNN building blocks that can be combined and applied to various parts of a GNN model, ensuring rich flexibility of GNN design.\n• Finally, PyG provides an abundant set of GNN models, and examples that showcase GNN models on standard graph benchmarks. Thanks to its flexibility, users can easily build and modify custom GNN models to fit their specific needs.\n\nWe list currently supported PyG models, layers and operators according to category:\n\nGNN layers: All Graph Neural Network layers are implemented via the interface. A GNN layer specifies how to perform message passing, i.e. by designing different message, aggregation and update functions as defined here. These GNN layers can be stacked together to create Graph Neural Network models.\n• GCNConv from Kipf and Welling: Semi-Supervised Classification with Graph Convolutional Networks (ICLR 2017) [Example]\n• ChebConv from Defferrard et al.: Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering (NIPS 2016) [Example]\n• GATConv from Veličković et al.: Graph Attention Networks (ICLR 2018) [Example]\n\nPooling layers: Graph pooling layers combine the vectorial representations of a set of nodes in a graph (or a subgraph) into a single vector representation that summarizes its properties of nodes. It is commonly applied to graph-level tasks, which require combining node features into a single graph representation.\n• Top-K Pooling from Gao and Ji: Graph U-Nets (ICML 2019), Cangea et al.: Towards Sparse Hierarchical Graph Classifiers (NeurIPS-W 2018) and Knyazev et al.: Understanding Attention and Generalization in Graph Neural Networks (ICLR-W 2019) [Example]\n• DiffPool from Ying et al.: Hierarchical Graph Representation Learning with Differentiable Pooling (NeurIPS 2018) [Example]\n\nGNN models: Our supported GNN models incorporate multiple message passing layers, and users can directly use these pre-defined models to make predictions on graphs. Unlike simple stacking of GNN layers, these models could involve pre-processing, additional learnable parameters, skip connections, graph coarsening, etc.\n• SchNet from Schütt et al.: SchNet: A Continuous-filter Convolutional Neural Network for Modeling Quantum Interactions (NIPS 2017) [Example]\n• DimeNet and DimeNetPlusPlus from Klicpera et al.: Directional Message Passing for Molecular Graphs (ICLR 2020) and Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules (NeurIPS-W 2020) [Example]\n• Node2Vec from Grover and Leskovec: node2vec: Scalable Feature Learning for Networks (KDD 2016) [Example]\n• Deep Multiplex Graph Infomax from Park et al.: Unsupervised Attributed Multiplex Network Embedding (AAAI 2020) [Example]\n• Masked Label Prediction from Shi et al.: Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification (CoRR 2020) [Example]\n• PMLP from Yang et al.: Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs (ICLR 2023)\n\nGNN operators and utilities: PyG comes with a rich set of neural network operators that are commonly used in many GNN models. They follow an extensible design: It is easy to apply these operators and graph utilities to existing GNN layers and models to further enhance model performance.\n• DropEdge from Rong et al.: DropEdge: Towards Deep Graph Convolutional Networks on Node Classification (ICLR 2020)\n• DropNode, MaskFeature and AddRandomEdge from You et al.: Graph Contrastive Learning with Augmentations (NeurIPS 2020)\n• GraphNorm from Cai et al.: GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training (ICML 2021)\n• GDC from Klicpera et al.: Diffusion Improves Graph Learning (NeurIPS 2019) [Example]\n\nScalable GNNs: PyG supports the implementation of Graph Neural Networks that can scale to large-scale graphs. Such application is challenging since the entire graph, its associated features and the GNN parameters cannot fit into GPU memory. Many state-of-the-art scalability approaches tackle this challenge by sampling neighborhoods for mini-batch training, graph clustering and partitioning, or by using simplified GNN models. These approaches have been implemented in PyG, and can benefit from the above GNN layers, operators and models.\n• NeighborLoader from Hamilton et al.: Inductive Representation Learning on Large Graphs (NIPS 2017) [Example1, Example2, Example3]\n• ClusterGCN from Chiang et al.: Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks (KDD 2019) [Example1, Example2]\n• GraphSAINT from Zeng et al.: GraphSAINT: Graph Sampling Based Inductive Learning Method (ICLR 2020) [Example]\n\nPyG is available for Python 3.9 to Python 3.12.\n\nYou can now install PyG via Anaconda for all major OS/PyTorch/CUDA combinations 🤗 If you have not yet installed PyTorch, install it via as described in the official PyTorch documentation. Given that you have PyTorch installed ( ), simply run\n\nFrom PyG 2.3 onwards, you can install and use PyG without any external library required except for PyTorch. For this, simply run\n\nIf you want to utilize the full set of features from PyG, there exists several additional libraries you may want to install:\n\nThese packages come with their own CPU and GPU kernel implementations based on the PyTorch C++/CUDA/hip(ROCm) extension interface. For a basic usage of PyG, these dependencies are fully optional. We recommend to start with a minimal installation, and install additional dependencies once you start to actually need them.\n\nFor ease of installation of these extensions, we provide wheels for all major OS/PyTorch/CUDA combinations, see here.\n\nTo install the binaries for PyTorch 2.5.0, simply run\n\nwhere should be replaced by either , , , or depending on your PyTorch installation.\n\nTo install the binaries for PyTorch 2.4.0, simply run\n\nwhere should be replaced by either , , , or depending on your PyTorch installation.\n\nNote: Binaries of older versions are also provided for PyTorch 1.4.0, PyTorch 1.5.0, PyTorch 1.6.0, PyTorch 1.7.0/1.7.1, PyTorch 1.8.0/1.8.1, PyTorch 1.9.0, PyTorch 1.10.0/1.10.1/1.10.2, PyTorch 1.11.0, PyTorch 1.12.0/1.12.1, PyTorch 1.13.0/1.13.1, PyTorch 2.0.0/2.0.1, PyTorch 2.1.0/2.1.1/2.1.2, PyTorch 2.2.0/2.2.1/2.2.2, and PyTorch 2.3.0/2.3.1 (following the same procedure). For older versions, you might need to explicitly specify the latest supported version number or install via in order to prevent a manual installation from source. You can look up the latest supported version number here.\n\nNVIDIA provides a PyG docker container for effortlessly training and deploying GPU accelerated GNNs with PyG, see here.\n\nIn case you want to experiment with the latest PyG features which are not fully released yet, either install the nightly version of PyG via\n\nor install PyG from master via\n\nThe external repository provides wheels and detailed instructions on how to install PyG for ROCm. If you have any questions about it, please open an issue here.\n\nPlease cite our paper (and the respective papers of the methods used) if you use this code in your own work:\n\nFeel free to email us if you wish your work to be listed in the external resources. If you notice anything unexpected, please open an issue and let us know. If you have any questions or are missing a specific feature, feel free to discuss them with us. We are motivated to constantly make PyG even better."
    }
]