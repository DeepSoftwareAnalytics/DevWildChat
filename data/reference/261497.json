[
    {
        "link": "https://matplotlib.org",
        "document": "You can help by answering questions on discourse , reporting a bug or requesting a feature on GitHub , or improving the documentation and code !\n\nMatplotlib is a community project maintained for and by its users\n\nMatplotlib is the result of development efforts by John Hunter (1968–2012) and the project's many contributors.\n\nIf Matplotlib contributes to a project that leads to a scientific publication, please acknowledge this work by citing the project!"
    },
    {
        "link": "https://matplotlib.org/3.4.0",
        "document": "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n\nTrying to learn how to do a particular kind of plot? Check out the examples gallery or the list of plotting commands .\n\nMatplotlib is a welcoming, inclusive project, and everyone within the community is expected to abide by our code of conduct.\n\nJoin our community at discourse.matplotlib.org to get help, discuss contributing & development, and share your work. If you have questions, be sure to check the FAQ, the API docs. The full text search is a good way to discover the docs including the many examples. Check out the Matplotlib tag on stackoverflow. Short questions may be posted on the gitter channel.\n\nTo keep up to date with what's going on in Matplotlib, see the what's new page or browse the source code. Anything that could require changes to your existing code is logged in the API changes file.\n\nMatplotlib is the brainchild of John Hunter (1968-2012), who, along with its many contributors, have put an immeasurable amount of time and effort into producing a piece of software utilized by thousands of scientists worldwide. If Matplotlib contributes to a project that leads to a scientific publication, please acknowledge this work by citing the project. A ready-made citation entry is available.\n\nMatplotlib is a Sponsored Project of NumFOCUS, a 501(c)(3) nonprofit charity in the United States. NumFOCUS provides Matplotlib with fiscal, legal, and administrative support to help ensure the health and sustainability of the project. Visit numfocus.org for more information. Donations to Matplotlib are managed by NumFOCUS. For donors in the United States, your gift is tax-deductible to the extent provided by law. As with any donation, you should consult with your tax adviser about your particular tax situation. Please consider donating to the Matplotlib project through the NumFOCUS organization or to the John Hunter Technology Fellowship. The Matplotlib license is based on the Python Software Foundation (PSF) license. There is an active developer community and a long list of people who have made significant contributions."
    },
    {
        "link": "https://devdocs.io/matplotlib~3.4",
        "document": ""
    },
    {
        "link": "https://oreilly.com/library/view/python-data-science/9781491912126/ch04.html",
        "document": "We’ll now take an in-depth look at the Matplotlib tool for visualization in Python. Matplotlib is a multiplatform data visualization library built on NumPy arrays, and designed to work with the broader SciPy stack. It was conceived by John Hunter in 2002, originally as a patch to IPython for enabling interactive MATLAB-style plotting via gnuplot from the IPython command line. IPython’s creator, Fernando Perez, was at the time scrambling to finish his PhD, and let John know he wouldn’t have time to review the patch for several months. John took this as a cue to set out on his own, and the Matplotlib package was born, with version 0.1 released in 2003. It received an early boost when it was adopted as the plotting package of choice of the Space Telescope Science Institute (the folks behind the Hubble Telescope), which financially supported Matplotlib’s development and greatly expanded its capabilities.\n\nOne of Matplotlib’s most important features is its ability to play well with many operating systems and graphics backends. Matplotlib supports dozens of backends and output types, which means you can count on it to work regardless of which operating system you are using or which output format you wish. This cross-platform, everything-to-everyone approach has been one of the great strengths of Matplotlib. It has led to a large userbase, which in turn has led to an active developer base and Matplotlib’s powerful tools and ubiquity within the scientific Python world.\n\nIn recent years, however, the interface and style of Matplotlib have begun to show their age. Newer tools like ggplot and ggvis in the R language, along with web visualization toolkits based on D3js and HTML5 canvas, often make Matplotlib feel clunky and old-fashioned. Still, I’m of the opinion that we cannot ignore Matplotlib’s strength as a well-tested, cross-platform graphics engine. Recent Matplotlib versions make it relatively easy to set new global plotting styles (see “Customizing Matplotlib: Configurations and Stylesheets”), and people have been developing new packages that build on its powerful internals to drive Matplotlib via cleaner, more modern APIs—for example, Seaborn (discussed in “Visualization with Seaborn”), ggplot, HoloViews, Altair, and even Pandas itself can be used as wrappers around Matplotlib’s API. Even with wrappers like these, it is still often useful to dive into Matplotlib’s syntax to adjust the final plot output. For this reason, I believe that Matplotlib itself will remain a vital piece of the data visualization stack, even if new tools mean the community gradually moves away from using the Matplotlib API directly.\n\nPerhaps the simplest of all plots is the visualization of a single function . Here we will take a first look at creating a simple plot of this type. As with all the following sections, we’ll start by setting up the notebook for plotting and importing the functions we will use: For all Matplotlib plots, we start by creating a figure and an axes. In their simplest form, a figure and axes can be created as follows (Figure 4-5): In Matplotlib, the figure (an instance of the class ) can be thought of as a single container that contains all the objects representing axes, graphics, text, and labels. The axes (an instance of the class ) is what we see above: a bounding box with ticks and labels, which will eventually contain the plot elements that make up our visualization. Throughout this book, we’ll commonly use the variable name to refer to a figure instance, and to refer to an axes instance or group of axes instances. Once we have created an axes, we can use the function to plot some data. Let’s start with a simple sinusoid (Figure 4-6): Alternatively, we can use the pylab interface and let the figure and axes be created for us in the background (Figure 4-7; see “Two Interfaces for the Price of One” for a discussion of these two interfaces): If we want to create a single figure with multiple lines, we can simply call the function multiple times (Figure 4-8): That’s all there is to plotting simple functions in Matplotlib! We’ll now dive into some more details about how to control the appearance of the axes and lines. The first adjustment you might wish to make to a plot is to control the line colors and styles. The function takes additional arguments that can be used to specify these. To adjust the color, you can use the keyword, which accepts a string argument representing virtually any imaginable color. The color can be specified in a variety of ways (Figure 4-9): # specify color by name If no color is specified, Matplotlib will automatically cycle through a set of default colors for multiple lines. Similarly, you can adjust the line style using the keyword (Figure 4-10): # For short, you can use the following codes: Example of various line styles If you would like to be extremely terse, these and codes can be combined into a single nonkeyword argument to the function (Figure 4-11): Controlling colors and styles with the shorthand syntax These single-character color codes reflect the standard abbreviations in the RGB (Red/Green/Blue) and CMYK (Cyan/Magenta/Yellow/blacK) color systems, commonly used for digital color graphics. There are many other keyword arguments that can be used to fine-tune the appearance of the plot; for more details, I’d suggest viewing the docstring of the function using IPython’s help tools (see “Help and Documentation in IPython”). Matplotlib does a decent job of choosing default axes limits for your plot, but sometimes it’s nice to have finer control. The most basic way to adjust axis limits is to use the and methods (Figure 4-12): If for some reason you’d like either axis to be displayed in reverse, you can simply reverse the order of the arguments (Figure 4-13): Example of reversing the y-axis A useful related method is (note here the potential confusion between axes with an e, and axis with an i). The method allows you to set the and limits with a single call, by passing a list that specifies (Figure 4-14): The method goes even beyond this, allowing you to do things like automatically tighten the bounds around the current plot (Figure 4-15): It allows even higher-level specifications, such as ensuring an equal aspect ratio so that on your screen, one unit in is equal to one unit in (Figure 4-16): Example of an “equal” layout, with units matched to the output resolution For more information on axis limits and the other capabilities of the method, refer to the docstring. As the last piece of this section, we’ll briefly look at the labeling of plots: titles, axis labels, and simple legends. Titles and axis labels are the simplest such labels—there are methods that can be used to quickly set them (Figure 4-17): You can adjust the position, size, and style of these labels using optional arguments to the function. For more information, see the Matplotlib documentation and the docstrings of each of these functions. When multiple lines are being shown within a single axes, it can be useful to create a plot legend that labels each line type. Again, Matplotlib has a built-in way of quickly creating such a legend. It is done via the (you guessed it) method. Though there are several valid ways of using this, I find it easiest to specify the label of each line using the keyword of the plot function (Figure 4-18): As you can see, the function keeps track of the line style and color, and matches these with the correct label. More information on specifying and formatting plot legends can be found in the docstring; additionally, we will cover some more advanced legend options in “Customizing Plot Legends”. While most functions translate directly to methods (such as → , → , etc.), this is not the case for all commands. In particular, functions to set limits, labels, and titles are slightly modified. For transitioning between MATLAB-style functions and object-oriented methods, make the following changes: In the object-oriented interface to plotting, rather than calling these functions individually, it is often more convenient to use the method to set all these properties at once (Figure 4-19): Example of using ax.set to set multiple properties at once\n\nMatplotlib’s default tick locators and formatters are designed to be generally sufficient in many common situations, but are in no way optimal for every plot. This section will give several examples of adjusting the tick locations and formatting for the particular plot type you’re interested in. Before we go into examples, it will be best for us to understand further the object hierarchy of Matplotlib plots. Matplotlib aims to have a Python object representing everything that appears on the plot: for example, recall that the is the bounding box within which plot elements appear. Each Matplotlib object can also act as a container of sub-objects; for example, each can contain one or more objects, each of which in turn contain other objects representing plot contents. The tick marks are no exception. Each has attributes and , which in turn have attributes that contain all the properties of the lines, ticks, and labels that make up the axes. Within each axis, there is the concept of a major tick mark and a minor tick mark. As the names would imply, major ticks are usually bigger or more pronounced, while minor ticks are usually smaller. By default, Matplotlib rarely makes use of minor ticks, but one place you can see them is within logarithmic plots (Figure 4-73): Example of logarithmic scales and labels We see here that each major tick shows a large tick mark and a label, while each minor tick shows a smaller tick mark with no label. We can customize these tick properties—that is, locations and labels—by setting the and objects of each axis. Let’s examine these for the x axis of the plot just shown: We see that both major and minor tick labels have their locations specified by a (which makes sense for a logarithmic plot). Minor ticks, though, have their labels formatted by a ; this says that no labels will be shown. We’ll now show a few examples of setting these locators and formatters for various plots. Perhaps the most common tick/label formatting operation is the act of hiding ticks or labels. We can do this using and , as shown here (Figure 4-74): Notice that we’ve removed the labels (but kept the ticks/gridlines) from the x axis, and removed the ticks (and thus the labels as well) from the y axis. Having no ticks at all can be useful in many situations—for example, when you want to show a grid of images. For instance, consider Figure 4-75, which includes images of different faces, an example often used in supervised machine learning problems (for more information, see “In-Depth: Support Vector Machines”): # Get some face data from scikit-learn Notice that each image has its own axes, and we’ve set the locators to null because the tick values (pixel number in this case) do not convey relevant information for this particular visualization. Reducing or Increasing the Number of Ticks One common problem with the default settings is that smaller subplots can end up with crowded labels. We can see this in the plot grid shown in Figure 4-76: Particularly for the x ticks, the numbers nearly overlap, making them quite difficult to decipher. We can fix this with the , which allows us to specify the maximum number of ticks that will be displayed. Given this maximum number, Matplotlib will use internal logic to choose the particular tick locations (Figure 4-77): # For every axis, set the x and y major locator This makes things much cleaner. If you want even more control over the locations of regularly spaced ticks, you might also use , which we’ll discuss in the following section. Matplotlib’s default tick formatting can leave a lot to be desired; it works well as a broad default, but sometimes you’d like to do something more. Consider the plot shown in Figure 4-78, a sine and a cosine: There are a couple changes we might like to make. First, it’s more natural for this data to space the ticks and grid lines in multiples of . We can do this by setting a , which locates ticks at a multiple of the number you provide. For good measure, we’ll add both major and minor ticks in multiples of (Figure 4-79): But now these tick labels look a little bit silly: we can see that they are multiples of , but the decimal representation does not immediately convey this. To fix this, we can change the tick formatter. There’s no built-in formatter for what we want to do, so we’ll instead use , which accepts a user-defined function giving fine-grained control over the tick outputs (Figure 4-80): This is much better! Notice that we’ve made use of Matplotlib’s LaTeX support, specified by enclosing the string within dollar signs. This is very convenient for display of mathematical symbols and formulae; in this case, is rendered as the Greek character . The offers extremely fine-grained control over the appearance of your plot ticks, and comes in very handy when you’re preparing plots for presentation or publication. We’ve mentioned a couple of the available formatters and locators. We’ll conclude this section by briefly listing all the built-in locator and formatter options. For more information on any of these, refer to the docstrings or to the Matplotlib online documentation. Each of the following is available in the namespace: Ticks and range are a multiple of base Finds up to a max number of ticks at nice locations Set the strings from a list of labels Set the strings manually for the labels Use a format string for each value We’ll see additional examples of these throughout the remainder of the book.\n\nOne common type of visualization in data science is that of geographic data. Matplotlib’s main tool for this type of visualization is the Basemap toolkit, which is one of several Matplotlib toolkits that live under the namespace. Admittedly, Basemap feels a bit clunky to use, and often even simple visualizations take much longer to render than you might hope. More modern solutions, such as leaflet or the Google Maps API, may be a better choice for more intensive map visualizations. Still, Basemap is a useful tool for Python users to have in their virtual toolbelts. In this section, we’ll show several examples of the type of map visualization that is possible with this toolkit. Installation of Basemap is straightforward; if you’re using conda you can type this and the package will be downloaded: We add just a single new import to our standard boilerplate: Once you have the Basemap toolkit installed and imported, geographic plots are just a few lines away (the graphics in Figure 4-102 also require the package in Python 2, or the package in Python 3): The meaning of the arguments to Basemap will be discussed momentarily. The useful thing is that the globe shown here is not a mere image; it is a fully functioning Matplotlib axes that understands spherical coordinates and allows us to easily over-plot data on the map! For example, we can use a different map projection, zoom in to North America, and plot the location of Seattle. We’ll use an etopo image (which shows topographical features both on land and under the ocean) as the map background (Figure 4-103): Plotting data and labels on the map This gives you a brief glimpse into the sort of geographic visualizations that are possible with just a few lines of Python. We’ll now discuss the features of Basemap in more depth, and provide several examples of visualizing map data. Using these brief examples as building blocks, you should be able to create nearly any map visualization that you desire. The first thing to decide when you are using maps is which projection to use. You’re probably familiar with the fact that it is impossible to project a spherical map, such as that of the Earth, onto a flat surface without somehow distorting it or breaking its continuity. These projections have been developed over the course of human history, and there are a lot of choices! Depending on the intended use of the map projection, there are certain map features (e.g., direction, area, distance, shape, or other considerations) that are useful to maintain. The Basemap package implements several dozen such projections, all referenced by a short format code. Here we’ll briefly demonstrate some of the more common ones. We’ll start by defining a convenience routine to draw our world map along with the longitude and latitude lines: # lats and longs are returned as a dictionary # cycle through these lines and set the desired style The simplest of map projections are cylindrical projections, in which lines of constant latitude and longitude are mapped to horizontal and vertical lines, respectively. This type of mapping represents equatorial regions quite well, but results in extreme distortions near the poles. The spacing of latitude lines varies between different cylindrical projections, leading to different conservation properties, and different distortion near the poles. In Figure 4-104, we show an example of the equidistant cylindrical projection, which chooses a latitude scaling that preserves distances along meridians. Other cylindrical projections are the Mercator ( ) and the cylindrical equal-area ( ) projections. The additional arguments to Basemap for this view specify the latitude ( ) and longitude ( ) of the lower-left corner ( ) and upper-right corner ( ) for the desired map, in units of degrees. Pseudo-cylindrical projections relax the requirement that meridians (lines of constant longitude) remain vertical; this can give better properties near the poles of the projection. The Mollweide projection ( ) is one common example of this, in which all meridians are elliptical arcs (Figure 4-105). It is constructed so as to preserve area across the map: though there are distortions near the poles, the area of small patches reflects the true area. Other pseudo-cylindrical projections are the sinusoidal ( ) and Robinson ( ) projections. The extra arguments to here refer to the central latitude ( ) and longitude ( ) for the desired map. Perspective projections are constructed using a particular choice of perspective point, similar to if you photographed the Earth from a particular point in space (a point which, for some projections, technically lies within the Earth!). One common example is the orthographic projection ( ), which shows one side of the globe as seen from a viewer at a very long distance. Thus, it can show only half the globe at a time. Other perspective-based projections include the gnomonic projection ( ) and stereographic projection ( ). These are often the most useful for showing small portions of the map. Here is an example of the orthographic projection (Figure 4-106): A conic projection projects the map onto a single cone, which is then unrolled. This can lead to very good local properties, but regions far from the focus point of the cone may become very distorted. One example of this is the Lambert conformal conic projection ( ), which we saw earlier in the map of North America. It projects the map onto a cone arranged in such a way that two standard parallels (specified in by and ) have well-represented distances, with scale decreasing between them and increasing outside of them. Other useful conic projections are the equidistant conic ( ) and the Albers equal-area ( ) projection (Figure 4-107). Conic projections, like perspective projections, tend to be good choices for representing small to medium patches of the globe. If you’re going to do much with map-based visualizations, I encourage you to read up on other available projections, along with their properties, advantages, and disadvantages. Most likely, they are available in the Basemap package. If you dig deep enough into this topic, you’ll find an incredible subculture of geo-viz geeks who will be ready to argue fervently in support of their favorite projection for any given application! Earlier we saw the and methods for projecting global images on the map, as well as the and methods for drawing lines of constant latitude and longitude. The Basemap package contains a range of useful functions for drawing borders of physical features like continents, oceans, lakes, and rivers, as well as political boundaries such as countries and US states and counties. The following are some of the available drawing functions that you may wish to explore using IPython’s help features:\n• Draw a mask between the land and sea, for use with projecting images on one or the other Draw the map boundary, including the fill color for oceans Fill the continents with a given color; optionally fill lakes with another color\n• Draw an etopo relief image onto the map For the boundary-based features, you must set the desired resolution when creating a Basemap image. The argument of the class sets the level of detail in boundaries, either (crude), (low), (intermediate), (high), (full), or if no boundaries will be used. This choice is important: setting high-resolution boundaries on a global map, for example, can be very slow. Here’s an example of drawing land/sea boundaries, and the effect of the resolution parameter. We’ll create both a low- and high-resolution map of Scotland’s beautiful Isle of Skye. It’s located at 57.3°N, 6.2°W, and a map of 90,000×120,000 kilometers shows it well (Figure 4-108): Notice that the low-resolution coastlines are not suitable for this level of zoom, while high-resolution works just fine. The low level would work just fine for a global view, however, and would be much faster than loading the high-resolution border data for the entire globe! It might require some experimentation to find the correct resolution parameter for a given view; the best route is to start with a fast, low-resolution plot and increase the resolution as needed. Perhaps the most useful piece of the Basemap toolkit is the ability to over-plot a variety of data onto a map background. For simple plotting and text, any function works on the map; you can use the instance to project latitude and longitude coordinates to coordinates for plotting with , as we saw earlier in the Seattle example. In addition to this, there are many map-specific functions available as methods of the instance. These work very similarly to their standard Matplotlib counterparts, but have an additional Boolean argument , which if set to allows you to pass raw latitudes and longitudes to the method, rather than projected coordinates. Some of these map-specific methods are: We’ll see examples of a few of these as we continue. For more information on these functions, including several example plots, see the online Basemap documentation. Recall that in “Customizing Plot Legends”, we demonstrated the use of size and color in a scatter plot to convey information about the location, size, and population of California cities. Here, we’ll create this plot again, but using Basemap to put the data in context. We start with loading the data, as we did before: # Extract the data we're interested in Next, we set up the map projection, scatter the data, and then create a colorbar and legend (Figure 4-109): This shows us roughly where larger populations of people have settled in California: they are clustered near the coast in the Los Angeles and San Francisco areas, stretched along the highways in the flat central valley, and avoiding almost completely the mountainous regions along the borders of the state. As an example of visualizing some more continuous geographic data, let’s consider the “polar vortex” that hit the eastern half of the United States in January 2014. A great source for any sort of climatic data is NASA’s Goddard Institute for Space Studies. Here we’ll use the GIS 250 temperature data, which we can download using shell commands (these commands may have to be modified on Windows machines). The data used here was downloaded on 6/12/2016, and the file size is approximately 9 MB: The data comes in NetCDF format, which can be read in Python by the library. You can install this library as shown here: We read the data as follows: The file contains many global temperature readings on a variety of dates; we need to select the index of the date we’re interested in—in this case, January 15, 2014: Now we can load the latitude and longitude data, as well as the temperature anomaly for this index: Finally, we’ll use the method to draw a color mesh of the data. We’ll look at North America, and use a shaded relief map in the background. Note that for this data we specifically chose a divergent colormap, which has a neutral color at zero and two contrasting colors at negative and positive values (Figure 4-110). We’ll also lightly draw the coastlines over the colors for reference: The data paints a picture of the localized, extreme temperature anomalies that happened during that month. The eastern half of the United States was much colder than normal, while the western half and Alaska were much warmer. Regions with no recorded temperature show the map background.\n\nMatplotlib has proven to be an incredibly useful and popular visualization tool, but even avid users will admit it often leaves much to be desired. There are several valid complaints about Matplotlib that often come up:\n• Prior to version 2.0, Matplotlib’s defaults are not exactly the best choices. It was based off of MATLAB circa 1999, and this often shows.\n• Matplotlib’s API is relatively low level. Doing sophisticated statistical visualization is possible, but often requires a lot of boilerplate code.\n• Matplotlib predated Pandas by more than a decade, and thus is not designed for use with Pandas s. In order to visualize data from a Pandas , you must extract each and often concatenate them together into the right format. It would be nicer to have a plotting library that can intelligently use the labels in a plot. An answer to these problems is Seaborn. Seaborn provides an API on top of Matplotlib that offers sane choices for plot style and color defaults, defines simple high-level functions for common statistical plot types, and integrates with the functionality provided by Pandas s. To be fair, the Matplotlib team is addressing this: it has recently added the tools (discussed in “Customizing Matplotlib: Configurations and Stylesheets”), and is starting to handle Pandas data more seamlessly. The 2.0 release of the library will include a new default stylesheet that will improve on the current status quo. But for all the reasons just discussed, Seaborn remains an extremely useful add-on. Here is an example of a simple random-walk plot in Matplotlib, using its classic plot formatting and colors. We start with the typical imports: Now we create some random walk data: Although the result contains all the information we’d like it to convey, it does so in a way that is not all that aesthetically pleasing, and even looks a bit old-fashioned in the context of 21st-century data visualization. Now let’s take a look at how it works with Seaborn. As we will see, Seaborn has many of its own high-level plotting routines, but it can also overwrite Matplotlib’s default parameters and in turn get even simple Matplotlib scripts to produce vastly superior output. We can set the style by calling Seaborn’s method. By convention, Seaborn is imported as : Now let’s rerun the same two lines as before (Figure 4-112): # same plotting code as above! The main idea of Seaborn is that it provides high-level commands to create a variety of plot types useful for statistical data exploration, and even some statistical model fitting. Let’s take a look at a few of the datasets and plot types available in Seaborn. Note that all of the following could be done using raw Matplotlib commands (this is, in fact, what Seaborn does under the hood), but the Seaborn API is much more convenient. Often in statistical data visualization, all you want is to plot histograms and joint distributions of variables. We have seen that this is relatively straightforward in Matplotlib (Figure 4-113): Rather than a histogram, we can get a smooth estimate of the distribution using a kernel density estimation, which Seaborn does with (Figure 4-114): Histograms and KDE can be combined using (Figure 4-115): If we pass the full two-dimensional dataset to , we will get a two-dimensional visualization of the data (Figure 4-116): We can see the joint distribution and the marginal distributions together using . For this plot, we’ll set the style to a white background (Figure 4-117): There are other parameters that can be passed to —for example, we can use a hexagonally based histogram instead (Figure 4-118): When you generalize joint plots to datasets of larger dimensions, you end up with pair plots. This is very useful for exploring correlations between multidimensional data, when you’d like to plot all pairs of values against each other. We’ll demo this with the well-known Iris dataset, which lists measurements of petals and sepals of three iris species: Visualizing the multidimensional relationships among the samples is as easy as calling (Figure 4-119): A pair plot showing the relationships between four variables Sometimes the best way to view data is via histograms of subsets. Seaborn’s makes this extremely simple. We’ll take a look at some data that shows the amount that restaurant staff receive in tips based on various indicator data (Figure 4-120): Out[14]: total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 An example of a faceted histogram Factor plots can be useful for this kind of visualization as well. This allows you to view the distribution of a parameter within bins defined by any other parameter (Figure 4-121): An example of a factor plot, comparing distributions given various discrete factors Similar to the pair plot we saw earlier, we can use to show the joint distribution between different datasets, along with the associated marginal distributions (Figure 4-122): The joint plot can even do some automatic kernel density estimation and regression (Figure 4-123): Time series can be plotted with . In the following example (visualized in Figure 4-124), we’ll use the Planets data that we first saw in “Aggregation and Grouping”: We can learn more by looking at the method of discovery of each of these planets, as illustrated in Figure 4-125: Number of planets discovered by year and type (see the online appendix for a full-scale figure) For more information on plotting with Seaborn, see the Seaborn documentation, a tutorial, and the Seaborn gallery. Here we’ll look at using Seaborn to help visualize and understand finishing results from a marathon. I’ve scraped the data from sources on the Web, aggregated it and removed any identifying information, and put it on GitHub where it can be downloaded (if you are interested in using Python for web scraping, I would recommend Web Scraping with Python by Ryan Mitchell). We will start by downloading the data from the Web, and loading it into Pandas: By default, Pandas loaded the time columns as Python strings (type ); we can see this by looking at the attribute of the : Let’s fix this by providing a converter for the times: That looks much better. For the purpose of our Seaborn plotting utilities, let’s next add columns that give the times in seconds: To get an idea of what the data looks like, we can plot a over the data (Figure 4-126): The relationship between the split for the first half-marathon and the finishing time for the full marathon The dotted line shows where someone’s time would lie if they ran the marathon at a perfectly steady pace. The fact that the distribution lies above this indicates (as you might expect) that most people slow down over the course of the marathon. If you have run competitively, you’ll know that those who do the opposite—run faster during the second half of the race—are said to have “negative-split” the race. Let’s create another column in the data, the split fraction, which measures the degree to which each runner negative-splits or positive-splits the race: Where this split difference is less than zero, the person negative-split the race by that fraction. Let’s do a distribution plot of this split fraction (Figure 4-127): The distribution of split fractions; 0.0 indicates a runner who completed the first and second halves in identical times Out of nearly 40,000 participants, there were only 250 people who negative-split their marathon. Let’s see whether there is any correlation between this split fraction and other variables. We’ll do this using a , which draws plots of all these correlations (Figure 4-128): The relationship between quantities within the marathon dataset It looks like the split fraction does not correlate particularly with age, but does correlate with the final time: faster runners tend to have closer to even splits on their marathon time. (We see here that Seaborn is no panacea for Matplotlib’s ills when it comes to plot styles: in particular, the x-axis labels overlap. Because the output is a simple Matplotlib plot, however, the methods in “Customizing Ticks” can be used to adjust such things if desired.) The difference between men and women here is interesting. Let’s look at the histogram of split fractions for these two groups (Figure 4-129): The distribution of split fractions by gender The interesting thing here is that there are many more men than women who are running close to an even split! This almost looks like some kind of bimodal distribution among the men and women. Let’s see if we can suss out what’s going on by looking at the distributions as a function of age. A nice way to compare distributions is to use a violin plot (Figure 4-130): This is yet another way to compare the distributions between men and women. Let’s look a little deeper, and compare these violin plots as a function of age. We’ll start by creating a new column in the array that specifies the decade of age that each person is in (Figure 4-131): A violin plot showing the split fraction by gender and age Looking at this, we can see where the distributions of men and women differ: the split distributions of men in their 20s to 50s show a pronounced over-density toward lower splits when compared to women of the same age (or of any age, for that matter). Also surprisingly, the 80-year-old women seem to outperform everyone in terms of their split time. This is probably due to the fact that we’re estimating the distribution from small numbers, as there are only a handful of runners in that range: Back to the men with negative splits: who are these runners? Does this split fraction correlate with finishing quickly? We can plot this very easily. We’ll use , which will automatically fit a linear regression to the data (Figure 4-132): Apparently the people with fast splits are the elite runners who are finishing within ~15,000 seconds, or about 4 hours. People slower than that are much less likely to have a fast second split."
    },
    {
        "link": "https://geeksforgeeks.org/matplotlib-tutorial",
        "document": "Matplotlib is an open-source visualization library for the Python programming language, widely used for creating static, animated and interactive plots. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, Qt, GTK and wxPython. It offers a variety of plotting functionalities, including line plots, bar charts, histograms, scatter plots and 3D visualizations. Created by John D. Hunter in 2003, Matplotlib has become a fundamental tool for data visualization in Python, extensively used by data scientists, researchers and engineers worldwide.\n\nWhat is Matplotlib in Python used for?\n\nWith Matplotlib, we can perform a wide range of visualization tasks, including:\n• None Creating basic plots such as line, bar and scatter plots.\n• None Saving plots in various formats like PNG, PDF and SVG.\n• None Combining multiple plots into subplots for better data representation.\n\nNow that we know what Matplotlib is and its uses, let’s move towards the tutorial part. Below, you will find sections ranging from basic to advanced topics that will help you master Matplotlib.\n\nIn this section, we will explore the fundamentals of Matplotlib. We will start with an introduction, learn how to install it and understand its core functionalities. Additionally, we will cover how to use Jupyter Notebook for interactive visualizations.\n\nThis section focuses on different types of plots and their implementations using Matplotlib.\n\nMatplotlib provides extensive customization options for better visualization and aesthetics.\n\nSave your visualizations in various formats for reports and presentations.\n\nSeveral toolkits extend Matplotlib’s functionality, some of which are external downloads, while others are included with Matplotlib but have external dependencies. Here are some of the most notable toolkits:\n• Seaborn : A high-level statistical data visualization library built on top of Matplotlib, extremely popular for creating attractive and informative statistical graphics with minimal code.\n• Mplot3d : Integrated into Matplotlib itself, this toolkit is the go‑to choice for creating 3‑D plots with ease and flexibility.\n• GeoPandas : A library that leverages Matplotlib for geospatial plotting, simplifying the handling of geospatial data without needing a spatial database.\n• Cartopy : A modern mapping library offering an object‑oriented approach to map projections and geospatial data, largely replacing Basemap in new projects.\n• Tikzplotlib : A niche toolkit that converts Matplotlib figures into LaTeX-friendly TikZ/PGFPlots code, ideal for producing high-quality, publication-ready plots.\n\nIntegrate Matplotlib with Pandas and Seaborn for enhanced data visualization.\n\nTest your knowledge of Matplotlib with this quiz. It covers essential topics such as plotting techniques, customization and integration with other libraries.\n• None Plot Different Sounds Using Python and Matplotlib\n\n1. What are the key functions of Matplotlib?\n\n2. What is the difference between Matplotlib and Seaborn?\n\n3. How many types of graphs are there in matplotlib?\n\n4. Can I use seaborn without matplotlib?\n\n5. What are the different line types in matplotlib?\n\n6. What are the different types of fonts in matplotlib?\n\n7. What is the full form of Matplotlib?\n\n8. What is the size of plot in Matplotlib?"
    },
    {
        "link": "https://medium.com/@jsteinb/python-build-a-program-to-retrieve-and-graph-live-stock-market-data-311d9ca1b7d3",
        "document": "The first step is to import the aforementioned packages.\n\nYou can import these packages using the following lines of code:\n\nOnce the required packages are imported, we can begin utilizing them to retrieve market data.\n\nII. Specify Which Stock We Wish To Graph (Ticker)\n\nWith the yahoo finance API and pandas data reader we can write code that will allow us to import data from any publicly traded stock symbol.\n• Next, we will need to create an input field for us to input our desired stock symbol. By setting variable ‘stock’ equal to the input, we can utilize the stock variable to be the specified symbol. This will allow us to query yahoo finance api for our desired data.\n• Running the above lines of code will ensure that python recognizes the stock variable and the output should be whatever ticker symbol you put in.\n\nIn order to retrieve data from the Yahoo Finance API we will need to make several arguments to specify what data we are trying to receive.\n\nYahoo Finance API requires the following 3 mandatory arguments in this order:\n• To call your data you will need to use the following syntax\n\nSince we have created a variable ‘stock’ to hold our stock name, we can utilize the above function to gather data from a certain stock according to the specified period and interval amounts requested:\n\nTo summarize, the above command is calling Yahoo Finance API for the specified stock for a period of 1 day and at an interval of 1 minute.\n• The output is as follows with the NVDA example:\n\nNow that we know the commands work, let’s try to test our program by re-running it and entering a new stock symbol. For an easier way to compile and run your code, I highly recommend Visual Studio Code which is an IDE for many different languages, and can help run your program continuously.\n• If you are saving your file, you can run it in a command window using the following:\n• When running our program and entering symbol ‘AMZN’ the following returns:\n\nNow that we have access to our data, let’s graph it\n\nIn order to visualize our data we will need to declare and set up our graph. This can be done using Plotly with the following code:\n• There are numerous ways to visualize this data and I highly suggest you play around with what’s available to get your optimal result."
    },
    {
        "link": "https://interactivebrokers.com/campus/trading-lessons/python-receiving-market-data",
        "document": "Welcome to this lesson on requesting market data in the Trader Workstation API. In this video, we will be highlighting the requirements for requesting market data, how to request delayed data, how to request live market data, and how to request historical bars. Please note that these are the most popular methods of requesting market data; however, Interactive Brokers also offers tick data, histogram data, and market depth.\n\nLet’s begin by discussing market data subscriptions. In order for clients to subscribe to market data, users must have a funded IBKR account for at least $500 USD in most instances. There are some instances where this is not the case; however, for the average individual at Interactive Brokers, $500 is the minimum. This threshold must be maintained in addition to the cost of any subscriptions held by the account.\n\nFor those with a long-time IBKR PRO account, you may have observed that some instruments return market data to your Trader Workstation for free by default. That is because some market data can be provided to users for free while “on-platform”. On-platform simply means that users are observing data directly display through one of Interactive Brokers platforms. Exchanges consider API functionality to be considered off-platform, and as a result, typically have a cost affiliated with them. Some of the most popular market data subscriptions for API use are listed in the API Documentation for Market Data on IBKR Campus. Users can subscribe to market data through the Client Portal.\n\nIt is also worth clarifying that Market Data is affiliated on a per-user basis. Many clients will run a single Trader Workstation instance for monitoring trades; however, it is common to have a separate machine running your trading algorithm on IB Gateway hosted on a virtual machine elsewhere. In order for both of these platforms to retrieve market data, each user consuming market data would need to subscribe to data separately.\n\nWith the subscription discussion out of the way, we can start to dive into the actual API requests. Please note that we will be using the same framework from our Essential Components video, so if there are any questions on the initial structure in this video, please be sure to review that lesson first.\n\nThe most popular way of requesting and viewing data in the API would be with EClient.reqMktData method, which requests the same data available in the TWS Watchlists.\n\nClients that do not have a market data subscription for instruments can often request 15 minute delayed data. This is only a single extra step compared to standard market data subscriptions, so I will include it before moving forward.\n\nTo clarify if your requests will be Live or delayed, users simply need to call the app.reqMarketDataType function. The only argument this takes is the type of data to retrieve, which can be 1,2,3,4 or Live, Frozen, Delayed, or Delayed Frozen respectively. Frozen data will refer to market data from the most recent close, while delayed frozen data will return yesterday’s closing values. And then as we’ve mentioned, standard delayed data will return 15-minute delayed data.\n\nIf I am subscribed to market data on a given instrument, but request delayed market data, live data will still be returned. Interactive Brokers will always try to provide the most up-to-date market data where possible.\n\nNow, let’s start building out our request for streaming data. We will be focused on requesting price and size data; however, the reqMktData request can also return string, news, generic and even Greek values depending on the tick types provided.\n\nFrom within our TestApp class, let’s start defining one of our tick functions, tickPrice. This will handle all returning values related to price values. tickPrice takes self, reqId, tickType, price, and attrib as arguments. While we’re already familiar with the first two, and the last two are rather self-explanatory, the tickType argument is used to indicate what kind of data is coming in.\n\nEach tickType is an integer value that correlates to a specific value, be it bid price, last size, closing price, or otherwise. For a full list of all of these tick values, we can look at ticktype.py inside the ibapi source files and see exactly what everything is relating to. Users are welcome to reference the returned integer values directly; however, the enumerator contains a toStr method that converts our tick type integers into the values we see before us. In our file, we can add an import for . This will allow us to reference the TicKTypeEnum.toStr() method and print out our value directly in a moment.\n\nI will print out all of these values in an ­ , including our reference of TickTypeEnum.toStr(). As we discussed before, this would be perfectly fine to print out our price values; however, I also want to see the quantities of our trades effected by this. To do this, we will also add the EWrapper.tickSize function to our TestApp class as well. This function only takes the arguments: self, reqId, tickType, and size. The sizes returned here will relate to the prices returned in our tickPrice function and allow us to create a clearer picture of the trades taking place.\n\nNow that we have everything in place to receive the data, let’s build out a contract object and a request for market data. Leaping off of our prior video, I’ll make a request for AAPL market data using the symbol, security type, currency, and exchange values.\n\nWith a contract now set, I can call app.reqMktData to start requesting my streaming data. For arguments, we’ll need to pass the reqId, which we’ll use our app.nextId() function for. I can pass mycontract for the contract object. For our next argument, the generic tick list, I will pass “232” as a string so I can retrieve the mark price from my request. For users looking to request multiple generic ticks, you would simply comma-separate the values within the string. So maybe you would pass “232, 233, 234” as an example.\n\nThe next argument defines if we are requesting a Snapshot value.\n\nThis is a single return instance aggregating the last 11 seconds of trading. If no trading has taken place, this will not return any values. And if we do see trades in the last 11 seconds, we will see those values returned in aggregate. Similarly, the next argument determines if we are requesting a regulatory snapshot. This is a snapshot used to determine the price of an instrument before executing a trade.\n\nRegulatory snapshots will cost approximately $0.01 per request, until we reach the cost of the affiliated subscription. If I request market data for AAPL repeatedly, Interactive Brokers will eventually add the subscription to your account, as the cost of the regulatory snapshots equate to the value of the subscription anyway. The final argument takes market data options, which is an argument used only for internal purposes.\n\nIf we run this script, we’ll find an initial flood of data depicting the most recent values for several tick types, then over time we will receive all the live data prices and sizes as they come through.\n\nRequesting Historical Data follows a similar pattern to the live market data requests. The one caveat to this is that market data cannot be retrieved if you do not have a valid market data subscription. Before we begin to dig into historical data, I’d like to first find how far back we can request market data. I’ll start finding this value using a new python file.\n\nIn our new file, I will create a new function in the TestApp class to define the headTimeStamp function. This takes three arguments, self, a request ID, and the headTimeStamp string. Within my new function, I will print out my headTimeStamp value. I will also make a request for self.cancelHeadTimeStamp to terminate the request now that I’m done with it, and we can just pass the requestId we received as an argument. With the EWrapper piece out of the way, I will move out of the TestApp class to create my headTimeStamp request. I will copy over my same AAPL contract I used from the Live Data script, because I want to validate how far back I can find AAPL market data.\n\nNext, I will make a call to the app.reqHeadTimeStamp function. This takes an argument for a request ID, which can use our nextId function; and a contract reference, which will take my object. After these two, I’m now encountering something known as the “whatToShow” value. This same value is used to denote what data is displayed in your TWS bar charts. In my case, I will use the value for Trades, though the full list of whatToShow values are available in our documentation.\n\nThe next argument relates to using regular trading hours. A 1 will indicate that we want the earliest date within trading hours, while a 0 will request the earliest date outside of trading hours. Finally, we have the formatDate parameter. This will indicate whether we want 1, a UTC timestamp in a string format, or 2, an Epoch timestamp. The latter is an integer representation of the same timestamp. You can consider the former better for human consumption, while the latter is best utilized in a programmatic request structure. I will show these off in just a moment by making two requests.\n\nIf we run this script using ‘1’ as the date format, we’ll see 19801212-14:30:00. Meaning AAPL’s “Trades” market data can go as far back as December 12, 1980 at 9:30 AM Eastern. Before we move on, I’ll quickly add another print statement to my headTimeStamp method for the datetime.datetime.fromtimestamp function, taking in the integer version of our headTimeStamp. If I change my original request to use 2 as my date format, I’ll print out the original epoch value as well as the python translated datetime, which is automatically converted to my pc’s local time in US/Central time.\n\nNow that we know our historical data range, we can start making a request for historical data. You are welcome to use the same file, but for my demonstration, I’ll be starting from a fresh example of our standard layout but add in our AAPL contract again. As always, we’ll define the EWrapper function inside TestApp using def historicalData. This function takes an argument for self, reqId, and bar. We will finish the function by printing the reqId and bar values.\n\nI will note that we are printing out the full bar object; however, the bar object can be split out, so you may print bar.open for the opening price, bar.close for the closing price, and so on. But just for our presentation here, I’ll print the whole thing.\n\nEach bar size is returned separately, so for us to know we’re done we should reference the EWrapper function for historicalDataEnd. This function takes an argument for self and reqID and is just meant to indicate that all available data has been returned to the user.\n\nWith the wrapper functions set, we’ll start our EClient request. To make the request, we’ll call the app.reqHistoricalData function. This takes 10 total arguments, starting with reqid, contract.\n\nThe next argument is endDateTime, which takes the value we’d like to end our historical data at. If we leave this as an empty string, the system will assume the current time. Otherwise, we would make a format for year, month, day followed by the 24 hour timestamp, and a timezone. You must pass the timezone for the exchange, available through a Contract Details request, the exact timezone used for your TWS, which is set prior to the homescreen, or using UTC. I will send my request for “20240523 16:00:00 US/Eastern”.\n\nThen, we’ll pass in a duration value, which corresponds to the full interval over which data will be returned. So, if I specify “1 D”, I will receive however many bars in a single day. On the topic of bars, the next argument will take the bar size. In my case, I can pass “1 hour” to receive an hour.\n\nThis means I will receive 7 bars for my day, a bit more on that later.\n\nMoving forward in our arguments, we’ll find more familiar values, like the whatToShow value we used before, which I’ll use “TRADES” for once again, then useRth and formatDate, again using 1 in both cases. Now we have the option for “keepUpToDate”, which allows us to build bars as data is available and return these new bars to the historicalDataUpdate function. I’m not interested in this data at the moment, so I’ll go ahead and leave this as False for now. Finally, we end with market data options, which I’ll again leave as an empty list.\n\nNow if we run this script, I will see my request ID, and all of my bar’s values. While most of this is self-explanatory, there are a few points I’d like to mention from the programmatic standpoint. You might notice that we sent the request using US/Eastern, but my data shows America/Chicago. That’s because I’m choosing to print out my “Operator Timezone” even though I made the request with the “Instrument Timezone”. You can modify the time zone returned in TWS by opening the Global Configuration page and opening the API Settings. You’ll notice a section for “Send instrument-specific attributes for dual-mode API Client in”. Specifying Operator Timezone returns your TWS time zone, Instrument time zone returns the time zone for the contract, and UTC is obviously the UTC time zone.\n\nThe other piece I’d like to mention is the 7 bars I had referenced earlier. The Date value in the bar references the starting time for the bar. In my case, we can see my bar started at 08:30:00 America/Chicago, which is when NASDAQ opens for trading AAPL. But then we’ll see 09:00 as our next bar, meaning our first bar is only 30 minutes long, before turning into a series of 1-hour bars. This is the same behavior as Trader Workstation, though it may not be as commonly understood when pulling data programmatically. Therefore, it’s best practice to use the next bar as an indicator of approximate bar size.\n\nThis concludes our lesson on market data in the TWS API. Thank you for watching. If you have any questions, please be sure to review our documentation or leave a comment below this video. We look forward to having you in the next lesson of our TWS API series."
    },
    {
        "link": "https://geeksforgeeks.org/python-api-tutorial-getting-started-with-apis",
        "document": "In this article, we will learn about how Python API is used to retrieve data from various sources. Also, we will cover all concepts related to Python API from basic to advanced. Various websites provide weather data, Twitter provides data for research purposes, and stock market websites provide data for share prices.\n\nWhat is an API?\n\nAPI stands for \"Application Programming Interface.\" In simple terms, it's a set of rules and protocols that allow how different software applications can communicate and interact with each other. APIs define the methods and data formats that applications can use to request and exchange information. To retrieve data from a web server, a client application initiates a request, and the server responds with the requested data. APIs facilitate this communication by serving as intermediaries, allowing seamless integration between diverse software systems. In essence, APIs act as bridges that enable the smooth exchange of data and functionality, enhancing interoperability across various applications.\n\nIn order to work with API some tools are required such as requests so we need to first install them in our system.\n\nOnce we have installed it, we need to import it in our code to use it.\n\nLet us understand the working of API with examples. First let us take a simple example.\n\nExtracting stock price by the help of API\n\nIn this Python program fetches the live stock data for \"IBM\" from the Alpha Vantage API using the 5-minute interval and prints the opening price.Here we make use of 'requests' to make a call and it is checked with the help of that whether our request was successful or not.Then the response is converted to python and the respected data is stored .\n\nAs we know Status code tells us about what happened with our request, whether it was successfully executed or other was some error while processing it. They are returned with every request we place.\n• 200 OK : The server successfully processed the request, and the requested data is returned.\n• 201 Created : A new resource is created on the server as a result of the request.\n• 204 No Content : The request is successful, but there is no additional data to return.\n• 300 Multiple Choices : The requested resource has multiple representations, each with its own URL.\n• 302 Found (Temporary Redirect) : The requested resource is temporarily located at a different URL.\n• 304 Not Modified : The client's cached copy of the resource is still valid, and no re-download is necessary.\n• 400 Bad Request : The request has malformed syntax or contains invalid data, making it incomprehensible to the server.\n• 401 Unauthorized : Authentication is required, and the client's credentials (e.g., API key) are missing or invalid.\n• 502 Bad Gateway : Acting as a gateway or proxy, the server received an invalid response from an upstream server.\n\nThese status codes help communicate the outcome of API requests and guide developers and clients in understanding the results, errors, or necessary actions.\n\nAPI Documentation is very essential and it helps in effective interaction. Here, we are using NewsAPI that provides us the information regarding various news of various countries and celebrities. To get news updates from NewsAPI, we need a special key called an API key. Think of it as a digital passcode that lets us access their news database. We've stored this key in a place called .\n\nNext, we've built a specific web address (or URL) that tells NewsAPI exactly what kind of news we want – in this case, top business headlines from the United States. It's like telling a librarian you're interested in the business section of a newspaper from a particular city.\n\nAfter setting up this request, our code then sends a message to NewsAPI using this URL. It's similar to clicking on a link to see a webpage. Once we send this message, NewsAPI replies with a status update. This status tells us if our request was successful or if there was any problem. We then simply print out this status to see if everything worked as expected.\n\nA successful request yields a '200' status code, signifying success. The documentation also mentions that the API response comes in JSON format. Now, we will use response.json() method to get complete output in next section (Using API with Query).\n\nWhile working with APIs, it is very essential to know how to work with JSON data. Json universally works as the language of APIs that helps in providing a way to encode the data structures in a format that is easily interpreted by machines. Imagine browsing a news website. The data we see there—headlines, descriptions, images—is often structured in a format called JSON. It's like the universal language that APIs speak.\n\nNow, to make sense of this digital jigsaw puzzle, we've written a Python script. This script acts like a digital news curator: it reaches out to NewsAPI using a library called requests and fetches the latest business headlines from the US. Once it has this data, Python steps in, sorting and presenting it in a neat list. Think of it as a friendly librarian picking out the top three articles for us from a vast collection. This whole process not only gives us a glimpse into how APIs and JSON work hand in hand but also underscores the magic Python brings to the table in managing such tasks effortlessly.\n\nWhen interacting with an API, especially one as popular as NewsAPI, it's essential to know how to specify and tailor the data you want to retrieve. In this code snippet, we're making use of the NewsAPI to fetch top headlines specifically for the United States. To communicate with the NewsAPI, we have the endpoint URL defined as . Additionally, each developer or user is provided with an API key for authentication purposes. Here, the API key is stored in the variable.\n\nHowever, simply knowing the endpoint and having an API key isn't enough. Often, APIs allow for a level of customization, letting users specify certain parameters to refine their request. This is where the dictionary comes into play. In this case, we're interested in fetching news from the U.S., so we set the parameter to \"us\". Additionally, to ensure our request is authenticated and linked to our account, we include the API key in the parameters.\n\nExample 2: How To Track ISS (International Space Station) Using Python?\n\nIn this example we will discuss how to track the current location of ISS(International Space Station) and then maps the location.\n• geocoder : Retrieving the latitude and longitude of locations.\n\nSo now there is a problem with tracking ISS because it travels at a speed of almost 28000km/h. Thus, it takes only 90 minutes to complete 1 rotation around the earth. At such a speed, it becomes quite difficult to lock the exact coordinates. So here comes the API to solve this issue. API acts as an intermediate between the website and the program, thus providing the current time data for the program.\n\nIn our case, API will provide us with the current location of ISS in earth’s orbit, so visit the link below as an API link for astronaut info.\n\nUse inorder to open the API url and to read the data from the URL.\n\nCreate iss.text file using an in write mode and write the result(names & numbers of astronauts) as data inside the file.\n\nUse geocoder.ip(‘me’) to know your current location in terms of latitude and longitude and after that using write the data in the file and then close the file using the function.\n\nUse turtle.screen() function to get access to the screen, then use screen.setup() to set the size and position of the output window. Use screen.setworldcoordinates() function to set the coordinates of all 4 corners on x, y-axis so that when iss reach out from reaches they appear again from another edge.\n\nSet map as background pic using screen.bgpic() function and set iss image as turtle shape using screen.register_shape() function. Use it as an object and assign it as a shape using iss.shape() function, then set the angle of shape using iss.setheading() function. iss.penup() function indicates that their drawings. Thus, the turtle stops. The file can be downloaded:\n\nAccess the current status of ISS using the API below:\n\nExtract the current location of ISS in terms of latitude and longitude from the above API. This script below runs inside the while loop so you can see the updated position and movement of the ISS until you stop the program.\n\nUpdate the position of ISS every 5 seconds by refreshing the latitude and longitude value from API.\n\nBelow is the full implementation.\n\nCrew Information: Here is info on the onboarded crew members along with their names.\n\nISS Location: Here is a screenshot of the moving ISS i.e orbiting around the earth. You can see it by zooming in on the screenshot.\n\nISS Moving look: Here you can see the ISS moving every 5 seconds.\n\nHere the question arises why use API? if we can get data in the a form of CSV file from the resource. To understand this let us look at the examples below:\n• Change in Data : Suppose we are using API to collect data about the temperature of all the cities in India. As the temperature changes with time, a new is to be downloaded every time we want the information and it will require a lot of bandwidth and a lot of time to process the same. The same data can be collected with the API very easily and in less time.\n• None Size of data: At certain times we require only a small part of the large data. For example, if we want to get the comments on a tweet then we don't need to download the whole dataset of Twitter. The required task can be done very easily with the help of Twitter API. APIs enable the extraction of specific, targeted data, minimizing unnecessary data transfer and optimizing the process for tasks that require only a fraction of the available information.\n\nIn conclusion , an API (Application Programming Inferface) serves a protocol and tools that enables different software applications to communicate and protocols interact with each other. APIs are instrumental in enabling the interoperability of applications, fostering innovation, and streamlining the development process by providing standardized interfaces for communication and data exchange.\n\nHow Do I Start an API in Python?\n\nWhat is API and How It Works in Python?\n\nHow to Connect API in Python?\n\nHow to Get API Data in Python?\n\nHow to Create a FastAPI in Python?"
    },
    {
        "link": "https://interactivebrokers.com/campus/ibkr-quant-news/how-to-request-market-data-via-the-python-api",
        "document": "When you visit any website it may use cookies and web beacons to store or retrieve information on your browser. This information might be about you, your preferences or your device and is typically used to make the website work as expected. The information does not usually directly identify you, but can provide a personalized browsing experience. Because we respect your right to privacy, you can choose not to allow some types of cookies and web beacons. Please click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience on our website and limit the services we can offer.\n\nStrictly necessary cookies are necessary for the website to function and cannot be switched off in our systems. They are typically set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. While you can set your browser to block or alert you about these cookies, some parts of the website will not work. These cookies do not store any personally identifiable information.\n\nPerformance cookies and web beacons allow us to count visits and traffic sources so we can measure and improve website performance. They help us to know which pages are the most and least popular and see how visitors navigate around our website. All information these cookies and web beacons collect is aggregated and anonymous. If you do not allow these cookies and web beacons we will not know when you have visited our website and will not be able to monitor its performance.\n\nFunctional cookies enable our website to provide enhanced functionality and personalization. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.\n\nMarketing Cookies and web beacons may be set through our website by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other websites. They do not directly store personal information, but uniquely identify your browser and internet device. If you do not allow these cookies and web beacons, you will experience less targeted advertising. Our website does not track users when they cross to third party websites, does not provide targeted advertising to them and therefore does not respond to \"Do Not Track\" signals.\n\nWhat are Cookies and Web Beacons? Cookies are pieces of data that a website transfers to a user's hard drive for record-keeping purposes. Web beacons are transparent pixel images that are used in collecting information about website usage, e-mail response and tracking. Generally, cookies may contain information about your Internet Protocol (\"IP\") addresses, the region or general location where your computer or device is accessing the internet, browser type, operating system and other usage information about the website or your usage of our services, including a history of the pages you view. How We Use Cookies and Web Beacons Interactive Brokers Group collects information from cookies and web beacons and stores it in an internal database. This information is retained in accordance with our Privacy Policy. This website uses the following cookies and web beacons: These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can configure your browser to block or alert you about these cookies, but certain areas of the site will not function properly. These cookies do not store any personal data. These cookies and web beacons allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information that these cookies and web beacons collect is aggregated and, therefore, anonymous. If you do not allow these cookies and web beacons our aggregated statistics will not have a record of your visit. The website uses Google Analytics, a web analytics service provided by Google, Inc. (\"Google\"). Google Analytics uses cookies to help analyse how you use this website. The information generated by the cookie about your use of this website (including your IP address) will be transmitted to and stored by Google on servers in the United States. Google will use this information for the purposes of evaluating your use of the website, compiling reports on website activity for website operators and providing other services relating to website activity and internet usage. Google may also transfer this information to third parties where required to do so by law, or where such third parties process the information on Google's behalf. Google will not associate your IP address with any other data held by Google. These cookies enable the website to provide enhanced functionality and personalization. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies, some or all of these services may not function properly. These cookies and web beacons may be set throughout our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant advertisements on other sites. They do not store personal information that could identify you directly, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies and web beacons, you will experience less targeted advertising. The website does not track users when they cross to third party websites, does not provide targeted advertising to them and therefore does not respond to Do Not Track (\"DNT\") signals. You have many choices with regards to the management of cookies on your computer. All major browsers allow you to block or delete cookies from your system. However, if you do decide to disable cookies you may not be able to access some areas of our website or the website may function incorrectly. To learn more about your ability to manage cookies and web beacons and how to disable them, please consult the privacy features in your browser or visit www.allaboutcookies.org. This website may link through to third party websites which may also use cookies and web beacons over which we have no control. We recommend that you check the relevant third parties privacy policy for information about any cookies and web beacons that may be used."
    },
    {
        "link": "https://medium.com/@noorfatimaafzalbutt/fetching-data-through-apis-with-python-a-comprehensive-guide-e3b335de0067",
        "document": "APIs (Application Programming Interfaces) are essential tools in modern software development, enabling applications to communicate and share data. Whether you are building a web application, mobile app, or backend service, understanding how to fetch data from APIs using Python is a crucial skill. This guide will take you through the basics of fetching data through APIs using Python, with practical examples and best practices to help you get started.\n\nWhat is an API?\n\nAn API is a set of rules and protocols that allow different software applications to communicate with each other. APIs define the methods and data formats that applications can use to request and exchange information, enabling developers to leverage existing services and data sources instead of building everything from scratch.\n\nThere are several types of APIs, including:\n• REST (Representational State Transfer): A popular architectural style for designing networked applications. RESTful APIs use standard HTTP methods (GET, POST, PUT, DELETE) and are typically used for web services.\n• SOAP (Simple Object Access Protocol): An older protocol for exchanging structured information in web services. SOAP uses XML for message formatting and relies on a set of rules for message structure.\n• GraphQL: A query language for APIs developed by Facebook, allowing clients to request exactly the data they need, making it more efficient than REST in some scenarios.\n\nHow to Fetch Data from an API\n\nFetching data from an API typically involves making an HTTP request to a specific endpoint and processing the response. Here’s a step-by-step guide to fetching data from a RESTful API using Python.\n\nBefore you start coding, it’s essential to understand the API you’re working with. Most APIs provide documentation that explains the available endpoints, request parameters, authentication methods, and response formats. Take the time to read through the documentation to familiarize yourself with the API.\n\nTo fetch data from an API, you’ll need a development environment with Python installed. You’ll also need a library to make HTTP requests. In this example, we’ll use the library, which is popular for its simplicity and ease of use.\n• Install Python: If you don’t have Python installed, download and install it from python.org.\n• Install the Library: You can install the library using pip.\n\nCreate a new Python file, e.g., , and add the following code:\n\nThis code snippet does the following:\n• Imports the Library: We use the library to make HTTP requests.\n• Defines the API Endpoint: We specify the URL of the API endpoint we want to fetch data from.\n• Creates Variables to Store Data: We initialize empty lists to store the data we fetch from the API response.\n• Processes the Response: We loop through the results in the API response and append the relevant data to our lists.\n• Creates a Dictionary to Organize Data: We combine our lists into a dictionary for easier access and manipulation.\n\nBest Practices for Fetching Data from APIs\n• Handle Errors Gracefully: Always include error handling to manage network issues, invalid responses, or other unexpected conditions.\n• Use Environment Variables: Store sensitive information, such as API keys and secrets, in environment variables to keep them secure.\n• Respect Rate Limits: Many APIs impose rate limits to prevent abuse. Be mindful of these limits and implement appropriate throttling in your code.\n• Cache Responses: To improve performance and reduce the number of requests, consider caching API responses when appropriate.\n• Use Pagination: When dealing with large datasets, use pagination to fetch data in smaller chunks, rather than retrieving everything in a single request.\n• Keep Your Code Modular: Organize your code into reusable modules to make it easier to maintain and extend.\n\nFetching data from APIs is a fundamental skill for modern software development. By understanding how to make HTTP requests, handle responses, and follow best practices, you can build robust applications that leverage external data and services. Whether you’re working with REST, SOAP, or GraphQL APIs, the principles and techniques outlined in this guide will help you get started and succeed in your development projects."
    }
]