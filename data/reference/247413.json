[
    {
        "link": "https://sitepoint.com/using-node-mysql-javascript-client",
        "document": "NoSQL databases are rather popular among Node developers, with MongoDB (the “M” in the MEAN stack) leading the pack. When starting a new Node project, however, you shouldn’t just accept Mongo as the default choice. Rather, the type of database you choose should depend on your project’s requirements. If, for example, you need dynamic table creation, or real-time inserts, then a NoSQL solution is the way to go. If your project deals with complex queries and transactions, on the other hand, an SQL database makes much more sense.\n\nIn this tutorial, we’ll have a look at getting started with the mysql module — a Node.js client for MySQL, written in JavaScript. I’ll explain how to use the module to connect to a MySQL database and perform the usual CRUD operations, before looking at stored procedures and escaping user input.\n\nThis popular article was updated in 2020 to reflect current practices for using MySQL with Node.js. For more on MySQL, read Jump Start MySQL.\n• Utilize the `mysql` module in Node.js to connect to a MySQL database and perform CRUD operations efficiently.\n• Ensure Node.js and npm are installed on your system before installing the `mysql` module using npm to manage project dependencies.\n• Create a connection to the MySQL database using the `mysql.createConnection` method and handle potential errors for robust database interaction.\n• Use the `con.query` method to execute SQL queries, retrieve data from the database, and handle results within Node.js applications.\n• Implement stored procedures in MySQL to manage SQL code more effectively and call these procedures within your Node.js code using the `con.query` method.\n• Protect your application from SQL injection attacks by using parameterized queries or the `mysql.escape` method to sanitize user inputs.\n\nQuick Start: How to Use MySQL in Node\n\nIf you’ve arrived here looking for a quick way to get up and running with MySQL in Node, we’ve got you covered!\n\nHere’s how to use MySQL in Node in five easy steps:\n• Create an file and copy in the snippet below (editing the placeholders as appropriate).\n\nNow let’s take a closer look at each of those steps.\n\nFirst of all we’re using the command line to create a new directory and navigate to it. Then we’re creating a file using the command . The flag means that npm will use defaults without going through an interactive process.\n\nThis step also assumes that you have Node and npm installed on your system. If this is not the case, then check out this SitePoint article to find out how to do that: Install Multiple Versions of Node.js using nvm.\n\nAfter that, we’re installing the mysql module from npm and saving it as a project dependency. Project dependencies (as opposed to devDependencies) are those packages required for the application to run. You can read more about the differences between the two here.\n\nIf you need further help using npm, then be sure to check out this guide, or ask in our forums.\n\nBefore we get on to connecting to a database, it’s important that you have MySQL installed and configured on your machine. If this is not the case, please consult the installation instructions on their home page.\n\nThe next thing we need to do is to create a database and a database table to work with. You can do this using a\n\n graphical interface, such as Adminer, or using the command line. For this article I’ll be using a database called and a table called . Here’s a dump of the database, so that you can get up and running quickly if you wish to follow along:\n\nNow, let’s create a file called in our directory and see how to connect to MySQL from Node.js.\n\nNow open up a terminal and enter . Once the connection is successfully established you should be able to see the “Connection established” message in the console. If something goes wrong (for example, you enter the wrong password), a callback is fired, which is passed an instance of the JavaScript Error object ( ). Try logging this to the console to see what additional useful information it contains.\n\nUsing nodemon to Watch the Files for Changes\n\nRunning by hand every time we make a change to our code is going to get a bit tedious, so let’s automate that. This part isn’t necessary to follow along with the rest of the tutorial, but will certainly save you some keystrokes.\n\nLet’s start off by installing a the nodemon package. This is a tool that automatically restarts a Node application when file changes in a directory are detected:\n\nNow run and make a change to . nodemon should detect the change and restart the app.\n\nNote: we’re running nodemon straight from the folder. You could also install it globally, or create an npm script to kick it off.\n\nNow that you know how to establish a connection to a MySQL database from Node.js, let’s see how to execute SQL queries. We’ll start by specifying the database name ( ) in the command:\n\nOnce the connection is established, we’ll use the variable to execute a query against the database table :\n\nWhen you run (either using nodemon or by typing into your terminal), you should be able to see the data returned from the database logged to the terminal:\n\nData returned from the MySQL database can be parsed by simply looping over the object.\n\nThis gives you the following:\n\nYou can execute an insert query against a database, like so:\n\nNote how we can get the ID of the inserted record using the callback parameter.\n\nSimilarly, when executing an update query, the number of rows affected can be retrieved using :\n\nThe same thing goes for a delete query:\n\nI’d like to finish off by looking at how the mysql module handles stored procedures and the escaping of user input.\n\nPut simply, a stored procedure is prepared SQL code that you can save to a database, so that it can easily be reused. If you’re in need of a refresher on stored procedures, then check out this tutorial.\n\nLet’s create a stored procedure for our database which fetches all the author details. We’ll call it . To do this, you’ll need some kind of interface to the database. I’m using Adminer. Run the following query against the database, ensuring that your user has admin rights on the MySQL server:\n\nThis will create and store the procedure in the database in the table.\n\nNote: if the delimiter syntax looks strange to you, it’s explained here.\n\nNext, establish a connection and use the connection object to call the stored procedure as shown:\n\nSave the changes and run the file. Once it’s executed, you should be able to view the data returned from the database:\n\nAlong with the data, it returns some additional information, such as the affected number of rows, etc. You need to iterate over the 0th index of the returned data to get employee details separated from the rest of the information:\n\nThis gives you the following:\n\nNow let’s consider a stored procedure which requires an input parameter:\n\nWe can pass the input parameter while making a call to the stored procedure:\n\nThis gives you the following:\n\nMost of the time when we try to insert a record into the database, we need the last inserted ID to be returned as an out parameter. Consider the following insert stored procedure with an out parameter:\n\nTo make a procedure call with an out parameter, we first need to enable multiple calls while creating the connection. So, modify the connection by setting the multiple statement execution to :\n\nNext, when making a call to the procedure, set an out parameter and pass it in:\n\nAs seen in the above code, we have set an out parameter and passed it while making a call to the stored procedure. Once the call has been made we need to select the out parameter to access the returned ID.\n\nRun . On successful execution you should be able to see the selected out parameter along with various other information. should give you access to the selected out parameter:\n\nNote: To delete a stored procedure you need to run the command against the database you created it for.\n\nIn order to avoid SQL Injection attacks, you should always escape any data you receive from users before using it inside an SQL query. Let’s demonstrate why:\n\nThis seems harmless enough and even returns the correct result:\n\nHowever, try changing the to this:\n\nWe suddenly have access to the entire data set. Now change it to this:\n\nThe good news is that help is at hand. You just have to use the mysql.escape method:\n\nYou can also use a question mark placeholder, as we did in the examples at the beginning of the article:\n\nWhy Not Just USE an ORM?\n\nBefore we get into the pros and cons of this approach, let’s take a second to look at what ORMs are. The following is taken from an answer on Stack Overflow:\n\nSo this means you write your database logic in the domain-specific language of the ORM, as opposed to the vanilla approach we’ve been taking so far. To give you an idea of what this might look like, here’s an example using Sequelize, which queries the database for all authors and logs them to the console:\n\nWhether or not using an ORM makes sense for you will depend very much on what you’re working on and with whom. On the one hand, ORMS tend to make developers more productive, in part by abstracting away a large part of the SQL so that not everyone on the team needs to know how to write super efficient database specific queries. It’s also easy to move to different database software, because you’re developing to an abstraction.\n\nOn the other hand however, it is possible to write some really messy and inefficient SQL as a result of not understanding how the ORM does what it does. Performance is also an issue in that it’s much easier to optimize queries that don’t have to go through the ORM.\n\nWhichever path you take is up to you, but if this is a decision you’re in the process of making, check out this Stack Overflow thread: Why should you use an ORM?. Also check out this post on SitePoint: 3 JavaScript ORMs You Might Not Know.\n\nIn this tutorial, we’ve installed the mysql client for Node.js and configured it to connect to a database. We’ve also seen how to perform CRUD operations, work with prepared statements and escape user input to mitigate SQL injection attacks. And yet, we’ve only scratched the surface of what the mysql client offers. For more detailed information, I recommend reading the official documentation.\n\nAnd please bear in mind that the mysql module is not the only show in town. There are other options too, such as the popular node-mysql2.\n\nFAQs on Using MySQL with Node.js\n\nCan I use MySQL with JavaScript? Yes, you can use MySQL with JavaScript. JavaScript is a versatile language that can be used on the server-side with technologies like Node.js to interact with MySQL databases. To work with MySQL in JavaScript, you can use the library or other MySQL-related packages like or object-relational mapping (ORM) libraries like Sequelize. These libraries provide APIs to establish database connections, execute SQL queries, and work with data in MySQL databases. You can build server-side applications, web applications, or APIs that interact with MySQL using JavaScript as the programming language. Can I use Node.js with MySQL? es, you can use Node.js with MySQL. Node.js is a popular server-side runtime environment for JavaScript, and it has robust support for working with MySQL databases. You can use various MySQL libraries and packages to interact with MySQL databases in Node.js, including the official package, , and object-relational mapping (ORM) libraries like Sequelize.\n\nThese packages allow you to establish database connections, execute SQL queries, and work with data in MySQL databases, making Node.js a versatile and powerful choice for building server-side applications, web applications, and APIs that interact with MySQL databases. This combination is widely used for developing dynamic and data-driven web applications. How to connect Node.js with MySQL Workbench? To connect Node.js with MySQL Workbench, you’ll need to ensure you have both Node.js and MySQL installed on your system. Node.js is a server-side runtime environment for JavaScript, while MySQL is a popular relational database management system. After installing these components, you can proceed to establish the connection.\n\nYou’ll need a Node.js module for connecting to the MySQL database. A commonly used choice is the module, which you can install via npm with the command . Once installed, you can create a JavaScript file to write your Node.js application.\n\nIn your Node.js application, you’ll need to configure the MySQL connection by specifying details like the host, username, password, and the name of the database you want to connect to. After the connection is established, you can perform various database operations using the module. Be sure to replace the connection details in the code with the specific information for your MySQL server and database. How to create a MySQL database in JavaScript? To create a MySQL database using JavaScript, you can utilize the package in a Node.js environment. First, ensure that you have both Node.js and MySQL installed on your system. Node.js is the server-side runtime environment for JavaScript, while MySQL is a widely-used relational database management system.\n\nYou’ll need to install the package, a popular choice for connecting to MySQL databases with Node.js. This package can be easily installed via npm with the command . After installation, you can proceed to write a JavaScript file to create your database.\n\nIn your JavaScript file, you’ll establish a connection to the MySQL server by providing the host, username, and password. Then, you can issue a SQL command to create a new database. In the example provided, a database named is created. After successfully executing the SQL command, you’ll receive feedback in the form of log messages indicating whether the operation was successful. Make sure to replace the connection details and database name with your specific MySQL server credentials and desired database name. Finally, run your Node.js application with the command to execute the database creation script.\n\nBy following these steps, you can use JavaScript with the package to create a MySQL database within your Node.js application, enabling you to work with structured data for various web and application projects. How to query in MySQL using JavaScript? \n\nTo query a MySQL database using JavaScript, you can use the package in a Node.js environment. Before proceeding, ensure that Node.js is installed on your machine. If not, you can download it from the official website. Additionally, install MySQL, including the MySQL server and MySQL Workbench, which can be obtained from the official MySQL website.\n\nAfter having Node.js and MySQL set up, you’ll need to install the package. This package is widely used for connecting to MySQL databases with Node.js and can be effortlessly installed via npm. Once installed, you can proceed to write your JavaScript code to perform MySQL queries.\n\nIn your JavaScript file, you’ll create a connection to the MySQL server by specifying the host, username, password, and the database you want to interact with. The code example provided illustrates connecting to the MySQL server and executing a sample query. Replace the connection details and SQL query with your specific MySQL server credentials and the query you wish to run. When you run your Node.js application, the code will connect to the MySQL database, execute the query, and return the results, making it suitable for retrieving, updating, or manipulating data in your database using JavaScript."
    },
    {
        "link": "https://github.com/mysqljs/mysql",
        "document": "\n• Closing all the connections in a pool\n• Getting the id of an inserted row\n• Getting the number of affected rows\n• Getting the number of changed rows\n\nThis is a Node.js module available through the npm registry.\n\nBefore installing, download and install Node.js. Node.js 0.6 or higher is required.\n\nInstallation is done using the command:\n\nFor information about the previous 0.9.x releases, visit the v0.9 branch.\n\nSometimes I may also ask you to install the latest version from Github to check if a bugfix is working. In this case, please do:\n\nThis is a node.js driver for mysql. It is written in JavaScript, does not require compiling, and is 100% MIT licensed.\n\nHere is an example on how to use it:\n\nFrom this example, you can learn the following:\n• Every method you invoke on a connection is queued and executed in sequence.\n• Closing the connection is done using which makes sure all remaining queries are executed before sending a quit packet to the mysql server.\n\nThanks goes to the people who have contributed code to this module, see the GitHub Contributors page.\n\nAdditionally I'd like to thank the following people:\n• Andrey Hristov (Oracle) - for helping me with protocol questions.\n• Ulf Wendel (Oracle) - for helping me with protocol questions.\n\nThe following companies have supported this project financially, allowing me to spend more time on it (ordered by time of contribution):\n• Transloadit (my startup, we do file uploading & video encoding as a service, check it out)\n\nIf you'd like to discuss this module, or ask questions about it, please use one of the following:\n• IRC Channel: #node.js (on freenode.net, I pay attention to any message including the term )\n\nThe recommended way to establish a connection is this:\n\nHowever, a connection can also be implicitly established by invoking a query:\n\nDepending on how you like to handle your errors, either method may be appropriate. Any type of connection error (handshake or network) is considered a fatal error, see the Error Handling section for more information.\n\nWhen establishing a connection, you can set the following options:\n• : The hostname of the database you are connecting to. (Default: )\n• : The port number to connect to. (Default: )\n• : The source IP address to use for TCP connection. (Optional)\n• : The path to a unix domain socket to connect to. When used and are ignored.\n• : The MySQL user to authenticate as.\n• : The password of that MySQL user.\n• : Name of the database to use for this connection (Optional).\n• : The charset for the connection. This is called \"collation\" in the SQL-level of MySQL (like ). If a SQL-level charset is specified (like ) then the default collation for that charset is used. (Default: )\n• : The timezone configured on the MySQL server. This is used to type cast server date/time values to JavaScript object and vice versa. This can be , , or an offset in the form or . (Default: )\n• : The milliseconds before a timeout occurs during the initial connection to the MySQL server. (Default: )\n• : Stringify objects instead of converting to values. (Default: )\n• : Allow connecting to MySQL instances that ask for the old (insecure) authentication method. (Default: )\n• : Determines if column values should be converted to native JavaScript types. (Default: )\n• : When dealing with big numbers (BIGINT and DECIMAL columns) in the database, you should enable this option (Default: ).\n• : Enabling both and forces big numbers (BIGINT and DECIMAL columns) to be always returned as JavaScript String objects (Default: ). Enabling but leaving disabled will return big numbers as String objects only when they cannot be accurately represented with [JavaScript Number objects] (https://tc39.es/ecma262/#sec-ecmascript-language-types-number-type) (which happens when they exceed the [-2^53, +2^53] range), otherwise they will be returned as Number objects. This option is ignored if is disabled.\n• : Force date types (TIMESTAMP, DATETIME, DATE) to be returned as strings rather than inflated into JavaScript Date objects. Can be / or an array of type names to keep as strings. (Default: )\n• : Prints protocol details to stdout. Can be / or an array of packet type names that should be printed. (Default: )\n• : Generates stack traces on to include call site of library entrance (\"long stack traces\"). Slight performance penalty for most calls. (Default: )\n• : Allow to use the modifier. (Default: )\n• : Allow multiple mysql statements per query. Be careful with this, it could increase the scope of SQL injection attacks. (Default: )\n• : List of connection flags to use other than the default ones. It is also possible to blacklist default ones. For more information, check Connection Flags.\n• : object with ssl parameters or a string containing name of ssl profile. See SSL options.\n\nIn addition to passing these options as an object, you can also use a url string. For example:\n\nNote: The query values are first attempted to be parsed as JSON, and if that fails assumed to be plaintext strings.\n\nThe option in the connection options takes a string or an object. When given a string, it uses one of the predefined SSL profiles included. The following profiles are included:\n• : this profile is for connecting to an Amazon RDS server and contains the certificates from https://rds.amazonaws.com/doc/rds-ssl-ca-cert.pem and https://s3.amazonaws.com/rds-downloads/rds-combined-ca-bundle.pem\n\nWhen connecting to other servers, you will need to provide an object with any of the following options:\n• : The certificate(s) to trust instead of the ones Node.js is configured to trust. This refers to the value of the certificate(s) and not a filename of the certificate(s). This is passed as the option for the underlying call (or underlying if using Node.js below 0.12).\n• : The client certificate to use in the SSL handshake. This is passed as the option for the underlying call (or underlying if using Node.js below 0.12).\n• : The ciphers to use to use in the SSL handshake instead of the default ones for Node.js. This is passed as the option for call (or underlying if using Node.js below 0.12).\n• : This is passed as the option for the underlying call.\n• : This is passed as the option for the underlying call.\n• : This is passed as the option for call (or underlying if using Node.js below 0.12).\n• : This is passed as the option for call (or underlying if using Node.js below 0.12).\n• : The server certificate is verified against the list of supplied CAs and the hostname, and if no match is found, the SSL connection will fail. (Default: )\n\nHere is a simple example:\n\nYou can also connect to a MySQL server without properly providing the appropriate CA to trust. You should not do this.\n\nIf, for any reason, you would like to change the default connection flags, you can use the connection option . Pass a string with a comma separated list of items to add to the default flags. If you don't want a default flag to be used prepend the flag with a minus sign. To add a flag that is not in the default list, just write the flag name, or prefix it with a plus (case insensitive).\n\nThe following flags are available:\n• - Enable protocol compression. This feature is not currently supported by the Node.js implementation so cannot be turned on. (Default off)\n• - Ability to specify the database on connection. (Default on)\n• - Send the found rows instead of the affected rows as . (Default on)\n• - Don't issue SIGPIPE if network failures. This flag has no effect on this Node.js implementation. (Default on)\n• - Let the parser ignore spaces before the in queries. (Default on)\n• - Indicates to the MySQL server this is an \"interactive\" client. This will use the interactive timeouts on the MySQL server and report as interactive in the process list. (Default off)\n• - Can use . This flag is controlled by the connection option . (Default on)\n• - Use the improved version of Old Password Authentication. (Default on)\n• - Can handle multiple resultsets for queries. (Default on)\n• - The client may send multiple statement per query or statement prepare (separated by ). This flag is controlled by the connection option . (Default off)\n• Special handling of ODBC behaviour. This flag has no effect on this Node.js implementation. (Default on)\n• - Uses the plugin authentication mechanism when connecting to the MySQL server. This feature is not currently supported by the Node.js implementation so cannot be turned on. (Default off)\n• - Uses the 4.1 protocol. (Default on)\n• - Can handle multiple resultsets for execute. (Default on)\n• - This is specific to the C client, and has no effect on this Node.js implementation. (Default off)\n• - Old flag for the 4.1 protocol. (Default on)\n• - Use SSL after handshake to encrypt data in transport. This feature is controlled though the connection option, so the flag has no effect. (Default off)\n• - Verify the server certificate during SSL set up. This feature is controlled though the connection option, so the flag has no effect. (Default off)\n• - Asks for the transaction status flags. (Default on)\n\nThere are two ways to end a connection. Terminating a connection gracefully is done by calling the method:\n\nThis will make sure all previously enqueued queries are still executed before sending a packet to the MySQL server. If a fatal error occurs before the packet can be sent, an argument will be provided to the callback, but the connection will be terminated regardless of that.\n\nAn alternative way to end the connection is to call the method. This will cause an immediate termination of the underlying socket. Additionally guarantees that no more events or callbacks will be triggered for the connection.\n\nUnlike the method does not take a callback argument.\n\nRather than creating and managing connections one-by-one, this module also provides built-in connection pooling using . Read more about connection pooling.\n\nCreate a pool and use it directly:\n\nThis is a shortcut for the -> -> code flow. Using is useful to share connection state for subsequent queries. This is because two calls to may use two different connections and run in parallel. This is the basic structure:\n\nIf you would like to close the connection and remove it from the pool, use instead. The pool will create a new connection the next time one is needed.\n\nConnections are lazily created by the pool. If you configure the pool to allow up to 100 connections, but only ever use 5 simultaneously, only 5 connections will be made. Connections are also cycled round-robin style, with connections being taken from the top of the pool and returning to the bottom.\n\nWhen a previous connection is retrieved from the pool, a ping packet is sent to the server to check if the connection is still good.\n\nPools accept all the same options as a connection. When creating a new connection, the options are simply passed to the connection constructor. In addition to those options pools accept a few extras:\n• : The milliseconds before a timeout occurs during the connection acquisition. This is slightly different from , because acquiring a pool connection does not always involve making a connection. If a connection request is queued, the time the request spends in the queue does not count towards this timeout. (Default: )\n• : Determines the pool's action when no connections are available and the limit has been reached. If , the pool will queue the connection request and call it when one becomes available. If , the pool will immediately call back with an error. (Default: )\n• : The maximum number of connections to create at once. (Default: )\n• : The maximum number of connection requests the pool will queue before returning an error from . If set to , there is no limit to the number of queued connection requests. (Default: )\n\nThe pool will emit an event when a connection is acquired from the pool. This is called after all acquiring activity has been performed on the connection, right before the connection is handed to the callback of the acquiring code.\n\nThe pool will emit a event when a new connection is made within the pool. If you need to set session variables on the connection before it gets used, you can listen to the event.\n\nThe pool will emit an event when a callback has been queued to wait for an available connection.\n\nThe pool will emit a event when a connection is released back to the pool. This is called after all release activity has been performed on the connection, so the connection will be listed as free at the time of the event.\n\nWhen you are done using the pool, you have to end all the connections or the Node.js event loop will stay active until the connections are closed by the MySQL server. This is typically done if the pool is used in a script or when trying to gracefully shutdown a server. To end all the connections in the pool, use the method on the pool:\n\nThe method takes an optional callback that you can use to know when all the connections are ended.\n\nOnce is called, and other operations can no longer be performed. Wait until all connections in the pool are released before calling . If you use the shortcut method , in place of → → , wait until it completes.\n\ncalls on every active connection in the pool. This queues a packet on the connection and sets a flag to prevent from creating new connections. All commands / queries already in progress will complete, but new commands won't execute.\n• : If , will attempt to reconnect when connection fails. (Default: )\n• : If connection fails, node's increases. When is greater than , remove a node in the . (Default: )\n• : If connection fails, specifies the number of milliseconds before another connection attempt will be made. If set to , then node will be removed instead and never re-used. (Default: )\n• : The default selector. (Default: )\n• : Select the first node available unconditionally.\n\nMySQL offers a changeUser command that allows you to alter the current user and other aspects of the connection without shutting down the underlying socket:\n\nThe available options for this feature are:\n• : The name of the new user (defaults to the previous one).\n• : The password of the new user (defaults to the previous one).\n• : The new charset (defaults to the previous one).\n• : The new database (defaults to the previous one).\n\nA sometimes useful side effect of this functionality is that this function also resets any connection state (variables, transactions, etc.).\n\nErrors encountered during this operation are treated as fatal connection errors by this module.\n\nYou may lose the connection to a MySQL server due to network problems, the server timing you out, the server being restarted, or crashing. All of these events are considered fatal errors, and will have the . See the Error Handling section for more information.\n\nRe-connecting a connection is done by establishing a new connection. Once terminated, an existing connection object cannot be re-connected by design.\n\nWith Pool, disconnected connections will be removed from the pool freeing up space for a new connection to be created on the next getConnection call.\n\nWith PoolCluster, disconnected connections will count as errors against the related node, incrementing the error code for that node. Once there are more than errors on a given node, it is removed from the cluster. When this occurs, the PoolCluster may emit a error if there are no longer any matching nodes for the pattern. The config can be set to restore offline nodes after a given timeout.\n\nThe most basic way to perform a query is to call the method on an object (like a , , or instance).\n\nThe simplest form of is , where a SQL string is the first argument and the second is a callback:\n\nThe second form comes when using placeholder values (see escaping query values):\n\nThe third form comes when using various advanced options on the query, like escaping query values, joins with overlapping column names, timeouts, and type casting.\n\nNote that a combination of the second and third forms can be used where the placeholder values are passed as an argument and not in the options object. The argument will override the in the option object.\n\nIf the query only has a single replacement character ( ), and the value is not , , or an array, it can be passed directly as the second argument to :\n\nCaution These methods of escaping values only works when the NO_BACKSLASH_ESCAPES SQL mode is disabled (which is the default state for MySQL servers).\n\nCaution This library performs client-side escaping, as this is a library to generate SQL strings on the client side. The syntax for functions like may look similar to a prepared statement, but it is not and the escaping rules from this module are used to generate a resulting SQL string. The purpose of escaping input is to avoid SQL Injection attacks. In order to support enhanced support like and formatting, this module will escape based on the shape of the passed in JavaScript value, and the resulting escaped string may be more than a single value. When structured user input is provided as the value to escape, care should be taken to validate the shape of the input to validate the output will be what is expected.\n\nIn order to avoid SQL Injection attacks, you should always escape any user provided data before using it inside a SQL query. You can do so using the , or methods:\n\nAlternatively, you can use characters as placeholders for values you would like to have escaped like this:\n\nMultiple placeholders are mapped to values in the same order as passed. For example, in the following query equals , equals , equals , and will be :\n\nThis looks similar to prepared statements in MySQL, however it really just uses the same method internally.\n\nCaution This also differs from prepared statements in that all are replaced, even those contained in comments and strings.\n\nDifferent value types are escaped differently, here is how:\n• Arrays are turned into list, e.g. turns into\n• Nested arrays are turned into grouped lists (for bulk inserts), e.g. turns into\n• Objects that have a method will have called and the returned value is used as the raw SQL.\n• Objects are turned into pairs for each enumerable property on the object. If the property's value is a function, it is skipped; if the property's value is an object, toString() is called on it and the returned value is used.\n• / are left as-is. MySQL does not support these, and trying to insert them as values will trigger MySQL errors until they implement support.\n\nThis escaping allows you to do neat things like this:\n\nAnd the method allows you to form complex queries with functions:\n\nTo generate objects with a method, the method can be used. This creates an object that will be left un-touched when using in a placeholder, useful for using functions as dynamic values:\n\nCaution The string provided to will skip all escaping functions when used, so be careful when passing in unvalidated input.\n\nIf you feel the need to escape queries by yourself, you can also use the escaping function directly:\n\nIf you can't trust an SQL identifier (database / table / column name) because it is provided by a user, you should escape it with , or like this:\n\nIt also supports adding qualified identifiers. It will escape both parts.\n\nIf you do not want to treat as qualified identifiers, you can set the second argument to in order to keep the string as a literal identifier:\n\nAlternatively, you can use characters as placeholders for identifiers you would like to have escaped like this:\n\nPlease note that this last character sequence is experimental and syntax might change\n\nWhen you pass an Object to or , is used to avoid SQL injection in object keys.\n\nYou can use mysql.format to prepare a query with multiple insertion points, utilizing the proper escaping for ids and values. A simple example of this follows:\n\nFollowing this you then have a valid, escaped query that you can then send to the database safely. This is useful if you are looking to prepare the query before actually sending it to the database. As mysql.format is exposed from SqlString.format you also have the option (but are not required) to pass in stringifyObject and timezone, allowing you provide a custom means of turning objects into strings, as well as a location-specific/timezone-aware Date.\n\nIf you prefer to have another type of query escape format, there's a connection configuration option you can use to define a custom format function. You can access the connection object if you want to use the built-in or any other connection function.\n\nHere's an example of how to implement another format:\n\nIf you are inserting a row into a table with an auto increment primary key, you can retrieve the insert id like this:\n\nWhen dealing with big numbers (above JavaScript Number precision limit), you should consider enabling option to be able to read the insert id as a string, otherwise it will throw an error.\n\nThis option is also required when fetching big numbers from the database, otherwise you will get values rounded to hundreds or thousands due to the precision limit.\n\nYou can get the number of affected rows from an insert, update or delete statement.\n\nYou can get the number of changed rows from an update statement.\n\n\"changedRows\" differs from \"affectedRows\" in that it does not count updated rows whose values were not changed.\n\nYou can get the MySQL connection ID (\"thread ID\") of a given connection using the property.\n\nThe MySQL protocol is sequential, this means that you need multiple connections to execute queries in parallel. You can use a Pool to manage connections, one simple approach is to create one connection per incoming http request.\n\nSometimes you may want to select large quantities of rows and process each of them as they are received. This can be done like this:\n\nPlease note a few things about the example above:\n• Usually you will want to receive a certain amount of rows before starting to throttle the connection using . This number will depend on the amount and size of your rows.\n• / operate on the underlying socket and parser. You are guaranteed that no more events will fire after calling .\n• You MUST NOT provide a callback to the method when streaming rows.\n• The event will fire for both rows as well as OK packets confirming the success of a INSERT/UPDATE query.\n• It is very important not to leave the result paused too long, or you may encounter The time limit for this is determined by the net_write_timeout setting on your MySQL server.\n\nAdditionally you may be interested to know that it is currently not possible to stream individual row columns, they will always be buffered up entirely. If you have a good use case for streaming large fields to and from MySQL, I'd love to get your thoughts and contributions on this.\n\nThe query object provides a convenience method that wraps query events into a Readable Stream object. This stream can easily be piped downstream and provides automatic pause/resume, based on downstream congestion and the optional . The parameter of the stream is set to and cannot be changed (if you need a byte stream, you will need to use a transform stream, like objstream for example).\n\nFor example, piping query results into another stream (with a max buffer of 5 objects) is simply:\n\nSupport for multiple statements is disabled for security reasons (it allows for SQL injection attacks if values are not properly escaped). To use this feature you have to enable it for your connection:\n\nOnce enabled, you can execute multiple statement queries like any other query:\n\nAdditionally you can also stream the results of multiple statement queries:\n\nIf one of the statements in your query causes an error, the resulting Error object contains a property which tells you which statement caused it. MySQL will also stop executing any remaining statements when an error occurs.\n\nPlease note that the interface for streaming multiple statement queries is experimental and I am looking forward to feedback on it.\n\nYou can call stored procedures from your queries as with any other mysql driver. If the stored procedure produces several result sets, they are exposed to you the same way as the results for multiple statement queries.\n\nWhen executing joins, you are likely to get result sets with overlapping column names.\n\nBy default, node-mysql will overwrite colliding column names in the order the columns are received from MySQL, causing some of the received values to be unavailable.\n\nHowever, you can also specify that you want your columns to be nested below the table name like this:\n\nOr use a string separator to have your results merged.\n\nSimple transaction support is available at the connection level:\n\nPlease note that beginTransaction(), commit() and rollback() are simply convenience functions that execute the START TRANSACTION, COMMIT, and ROLLBACK commands respectively. It is important to understand that many commands in MySQL can cause an implicit commit, as described in the MySQL documentation\n\nA ping packet can be sent over a connection using the method. This method will send a ping packet to the server and when the server responds, the callback will fire. If an error occurred, the callback will fire with an error argument.\n\nEvery operation takes an optional inactivity timeout option. This allows you to specify appropriate timeouts for operations. It is important to note that these timeouts are not part of the MySQL protocol, and rather timeout operations through the client. This means that when a timeout is reached, the connection it occurred on will be destroyed and no further operations can be performed.\n\nThis module comes with a consistent approach to error handling that you should review carefully in order to write solid applications.\n\nMost errors created by this module are instances of the JavaScript Error object. Additionally they typically come with two extra properties:\n• : String, contains the MySQL server error symbol if the error is a MySQL server error (e.g. ), a Node.js error code if it is a Node.js error (e.g. ), or an internal error code (e.g. ).\n• : Number, contains the MySQL server error number. Only populated from MySQL server error.\n• : Boolean, indicating if this error is terminal to the connection object. If the error is not from a MySQL protocol operation, this property will not be defined.\n• : String, contains the full SQL of the failed query. This can be useful when using a higher level interface like an ORM that is generating the queries.\n• : String, contains the five-character SQLSTATE value. Only populated from MySQL server error.\n• : String, contains the message string that provides a textual description of the error. Only populated from MySQL server error.\n\nFatal errors are propagated to all pending callbacks. In the example below, a fatal error is triggered by trying to connect to a blocked port. Therefore the error object is propagated to both pending callbacks:\n\nNormal errors however are only delegated to the callback they belong to. So in the example below, only the first callback receives an error, the second query works as expected:\n\nLast but not least: If a fatal errors occurs and there are no pending callbacks, or a normal error occurs which has no callback belonging to it, the error is emitted as an event on the connection object. This is demonstrated in the example below:\n\nNote: events are special in node. If they occur without an attached listener, a stack trace is printed and your process is killed.\n\ntl;dr: This module does not want you to deal with silent failures. You should always provide callbacks to your method calls. If you want to ignore this advice and suppress unhandled errors, you can do this:\n\nThis module is exception safe. That means you can continue to use it, even if one of your callback functions throws an error which you're catching using 'uncaughtException' or a domain.\n\nFor your convenience, this driver will cast mysql types into native JavaScript types by default. The default behavior can be changed through various Connection options. The following mappings exist:\n• BIT (last byte will be filled with 0 bits as necessary)\n\nNote text in the binary character set is returned as , rather than a string.\n• TIME (could be mapped to Date, but what date would be set?)\n• GEOMETRY (never used those, get in touch if you do)\n\nIt is not recommended (and may go away / change in the future) to disable type casting, but you can currently do so on either the connection:\n\nOr on the query level:\n\nYou can also pass a function and handle type casting yourself. You're given some column information like database, table and name and also type and length. If you just want to apply a custom type casting to a specific type you can do it and then fallback to the default.\n\nThe function is provided two arguments and and is expected to return the value for the given field by invoking the parser functions through the object.\n\nThe argument is a object and contains data about the field that need to be parsed. The following are some of the properties on a object:\n• - a string of the database the field came from.\n• - a string of the table the field came from.\n• - a string of the field name.\n• - a string of the field type in all caps.\n• - a number of the field length, as given by the database.\n\nThe argument is a that, when called, will return the default type conversion for the given field.\n\nWhen getting the field data, the following helper methods are present on the object:\n• - parse the field as a geometry value.\n\nThe MySQL protocol is a text-based protocol. This means that over the wire, all field types are represented as a string, which is why only string-like functions are available on the object. Based on the type information (like ), the type cast should convert the string field into a different JavaScript type (like a ).\n\nHere's an example of converting to boolean:\n\nWARNING: YOU MUST INVOKE the parser using one of these three field functions in your custom typeCast callback. They can only be called once.\n\nIf you are running into problems, one thing that may help is enabling the mode for the connection:\n\nThis will print all incoming and outgoing packets on stdout. You can also restrict debugging to packet types by passing an array of types to debug:\n\nto restrict debugging to the query and data packets.\n\nIf that does not help, feel free to open a GitHub issue. A good GitHub issue will have:\n• The minimal amount of code required to reproduce the problem (if possible)\n• As much debugging output and information about your environment (mysql version, node version, os, etc.) as you can gather.\n\nSecurity issues should not be first reported through GitHub or another public forum, but kept private in order for the collaborators to assess the report and either (a) devise a fix and plan a release date or (b) assert that it is not a security issue (in which case it can be posted in a public forum, like a GitHub issue).\n\nThe primary private forum is email, either by emailing the module's author or opening a GitHub issue simply asking to whom a security issues should be addressed to without disclosing the issue or type of issue.\n\nAn ideal report would include a clear indication of what the security issue is and how it would be exploited, ideally with an accompanying proof of concept (\"PoC\") for collaborators to work against and validate potentional fixes against.\n\nThis project welcomes contributions from the community. Contributions are accepted using GitHub pull requests. If you're not familiar with making GitHub pull requests, please refer to the GitHub documentation \"Creating a pull request\".\n\nFor a good pull request, we ask you provide the following:\n• Try to include a clear description of your pull request in the description. It should include the basic \"what\" and \"why\"s for the request.\n• The tests should pass as best as you can. See the Running tests section on how to run the different tests. GitHub will automatically run the tests as well, to act as a safety net.\n• The pull request should include tests for the change. A new feature should have tests for the new feature and bug fixes should include a test that fails without the corresponding code change and passes after they are applied. The command will generate a folder that contains HTML pages of the code coverage, to better understand if everything you're adding is being tested.\n• If the pull request is a new feature, please be sure to include all appropriate documentation additions in the file as well.\n• To help ensure that your code is similar in style to the existing code, run the command and fix any displayed issues.\n\nThe test suite is split into two parts: unit tests and integration tests. The unit tests run on any machine while the integration tests require a MySQL server instance to be setup.\n\nSet the environment variables , , , and . can also be used in place of and to connect over a UNIX socket. Then run .\n\nFor example, if you have an installation of mysql running on localhost:3306 and no password set for the user, run:\n• Support for encodings other than UTF-8 / ASCII"
    },
    {
        "link": "https://medium.com/@greennolgaa/building-scalable-and-efficient-database-applications-with-node-js-mysql-b82bd12f2b3e",
        "document": "Node.js and MySQL are two powerful technologies that are used together to build scalable and efficient web applications. Node.js is an open-source, cross-platform, and runtime environment that executes JavaScript code outside a web browser, while MySQL is a widely-used open-source relational database management system. When used together, Node.js and MySQL can help developers build server-side applications with ease. This article explores Node.js and MySQL, how they can be used together, and their advantages.\n\nNode.js MySQL is a combination of two powerful technologies that are used together to build scalable and efficient web applications. Node.js is an open-source, cross-platform, and runtime environment that executes JavaScript code outside a web browser. Node.js is built on top of the V8 JavaScript engine, which makes it fast and efficient. MySQL is a widely-used open-source relational database management system that is known for its scalability and high performance.\n\nNodejs MySQL provides a simple and efficient way to interact with a MySQL database from a Node.js application. Node.js uses the MySQL driver to connect to a MySQL database and execute queries. The MySQL driver is a JavaScript library that provides a simple and efficient interface to interact with a MySQL database.\n\nNode.js MySQL applications can be built using various tools and frameworks. Some of the popular tools and frameworks used to build Node.js MySQL applications are:\n• Express.js: Express.js is a popular Node.js web application framework that provides a set of features for building web applications, including routing, middleware, and templating.\n• Sequelize: Sequelize is an ORM (Object-Relational Mapping) that provides a simple and efficient way to interact with a MySQL database from a Node.js application. Sequelize supports various MySQL features, including transactions, associations, and validations.\n• Knex.js: Knex.js is a SQL query builder for Node.js that supports various SQL databases, including MySQL. Knex.js provides a simple and efficient way to build and execute SQL queries.\n• Installing Node.js and MySQL: To build Node.js MySQL applications, you need to install Node.js and MySQL on your system. Node.js can be installed from the official website, while MySQL can be installed from the official website or using a package manager.\n• Setting up the project: Once Node.js and MySQL are installed, you need to set up the project by creating a new directory and initializing a Node.js project using npm (Node Package Manager).\n• Installing dependencies: After setting up the project, you need to install the required dependencies, including the MySQL driver and any other libraries or frameworks that you want to use.\n• Creating a database connection: To interact with a MySQL database from a Node.js application, you need to establish a database connection. This can be done using the MySQL driver, which provides a simple and efficient interface to interact with a MySQL database.\n• Executing queries: Once the database connection is established, you can execute queries to retrieve data from the database or insert data into the database. This can be done using various tools and frameworks, including the MySQL driver, Sequelize, or Knex.js.\n\nNode.js MySQL is a powerful combination that brings together the best of both worlds, allowing developers to build high-performance, scalable, and efficient applications. Here are some of the advantages of using Node.js MySQL:\n• Easy Integration: Node.js MySQL offers seamless integration with Node.js, making it easy for developers to build applications with MySQL databases.\n• Speed and Performance: Node.js is known for its speed and performance, and when combined with MySQL, it can handle large amounts of data and transactions with ease.\n• Scalability: Node.js MySQL is highly scalable, allowing applications to handle increased traffic and data volume as needed. This is particularly important for applications that require real-time data processing, such as financial applications and e-commerce sites.\n• Support for Multiple Platforms: Node.js MySQL supports multiple platforms, including Windows, Linux, and Mac OS, making it a versatile choice for developers.\n• Security: Node.js MySQL provides robust security features, such as SSL encryption and password hashing, to protect data and prevent unauthorized access.\n• High Availability: With Node.js MySQL, developers can ensure high availability of their applications by implementing features such as load balancing and database replication.\n• Community Support: Both Node.js and MySQL have active and supportive communities, providing developers with access to a wealth of resources, documentation, and tutorials.\n\nOverall, Node.js MySQL provides a powerful and flexible platform for building high-performance and scalable applications that can handle large amounts of data and transactions. By leveraging the strengths of both Node.js and MySQL, developers can create applications that are fast, reliable, and secure.\n\nBest Practices for Using Node.js MySQL\n• Avoid using SELECT * When writing queries in Node.js MySQL, it is best to avoid using SELECT * as it can have a significant impact on the performance of the application. Instead, you should specify the exact columns that you need to retrieve.\n• Use connection pooling Connection pooling is a technique that allows you to reuse database connections rather than creating new ones every time you need to interact with the database. This can help improve the performance of your application by reducing the overhead associated with creating and tearing down connections.\n• Parameterize your queries Parameterizing your queries can help prevent SQL injection attacks, where an attacker inserts malicious code into a query. Parameterization involves using placeholders in your queries and then passing in the actual values as parameters.\n• Use prepared statements Prepared statements are a feature in Node.js MySQL that can help improve the performance of your application by caching query execution plans. Prepared statements involve preparing a query once and then executing it multiple times with different parameters.\n• Use transactions Transactions can help ensure data consistency by grouping a set of database operations into a single unit of work. If any of the operations in the transaction fail, all of the changes are rolled back.\n\nCommon Node.js MySQL Errors and How to Fix Them\n• Connection Errors Connection errors can occur when there is a problem connecting to the database server. This can be caused by a variety of issues, such as incorrect connection details or a firewall blocking the connection.\n\nSolution: Double-check your connection details and ensure that your database server is running and accessible. Also, make sure that any firewalls or network security settings are configured correctly.\n• Syntax Errors Syntax errors occur when there is a problem with the syntax of the SQL query. This can be caused by typos, missing or incorrect keywords, or incorrect table or column names.\n\nSolution: Double-check your SQL query for any syntax errors. You can also use a tool like MySQL Workbench to help you identify and fix syntax errors.\n• Timeout Errors Timeout errors can occur when a query takes too long to execute. This can be caused by a variety of factors, such as slow database performance or an overly complex query.\n\nSolution: Try optimizing your query or database performance to reduce the execution time. You can also try increasing the query timeout setting in your Node.js MySQL configuration.\n\nNode.js MySQL is a powerful combination that enables developers to create fast, scalable, and efficient web applications. With the ability to handle large amounts of data and process requests quickly, Node.js MySQL is an ideal choice for projects that require high performance and reliability. It allows developers to use a single language for both the frontend and backend, resulting in better collaboration and faster development times. Additionally, Node.js MySQL comes with a range of advantages, including high-speed performance, scalability, flexibility, and ease of use, making it a popular choice among developers worldwide.\n\nAt CronJ, our team of expert developers has extensive experience working with Node.js MySQL and can help you create a custom web application that meets your specific business requirements. With our in-depth knowledge of the latest web development technologies and practices, we can provide you with a scalable and robust solution that will help you achieve your business goals."
    },
    {
        "link": "https://stackoverflow.com/questions/24049239/best-practices-for-mysql-queries-in-nodejs",
        "document": "I'm pretty new to nodeJS, and what's the best way to implement SQL queries..\n\nWhen I'm doing a mysql insert in NodeJS I need to query to see if the value exists, then I need to do an additional query to grab the max value of 1 field.\n\nEverything has call-backs, and relies on one query to execute before moving on to the next. This is getting pretty messy, especially because I have to pass all the callbacks in the functions.\n\nI'm considering creating stored procedures to keep the logic cleaner.."
    },
    {
        "link": "https://w3schools.com/nodejs/nodejs_mysql.asp",
        "document": "Node.js can be used in database applications.\n\nOne of the most popular databases is MySQL.\n\nTo be able to experiment with the code examples, you should have MySQL installed on your computer.\n\nYou can download a free MySQL database at https://www.mysql.com/downloads/.\n\nOnce you have MySQL up and running on your computer, you can access it by using Node.js.\n\nTo access a MySQL database with Node.js, you need a MySQL driver. This tutorial will use the \"mysql\" module, downloaded from NPM.\n\nTo download and install the \"mysql\" module, open the Command Terminal and execute the following:\n\nNow you have downloaded and installed a mysql database driver.\n\nNode.js can use this module to manipulate the MySQL database:\n\nStart by creating a connection to the database.\n\nUse the username and password from your MySQL database.\n\nSave the code above in a file called \"demo_db_connection.js\" and run the file:\n\nWhich will give you this result:\n\nNow you can start querying the database using SQL statements.\n\nUse SQL statements to read from (or write to) a MySQL database. This is also called \"to query\" the database.\n\nThe connection object created in the example above, has a method for querying the database:\n\nThe query method takes an sql statements as a parameter and returns the result.\n\nLearn how to read, write, delete, and update a database in the next chapters.\n\nRead more about SQL statements in our SQL Tutorial."
    },
    {
        "link": "https://expressjs.com/en/resources/middleware/session.html",
        "document": "This is a Node.js module available through the npm registry. Installation is done using the command:\n\nCreate a session middleware with the given .\n\nNote Session data is not saved in the cookie itself, just the session ID. Session data is stored server-side.\n\nNote Since version 1.5.0, the middleware no longer needs to be used for this module to work. This module now directly reads and writes cookies on / . Using may result in issues if the is not the same between this module and .\n\nWarning The default server-side session storage, , is purposely not designed for a production environment. It will leak memory under most conditions, does not scale past a single process, and is meant for debugging and developing.\n\nFor a list of stores, see compatible session stores.\n\naccepts these properties in the options object.\n\nSettings object for the session ID cookie. The default value is .\n\nThe following are options that can be set in this object.\n\nSpecifies the value for the attribute. By default, no domain is set, and most clients will consider the cookie to apply to only the current domain.\n\nSpecifies the object to be the value for the attribute. By default, no expiration is set, and most clients will consider this a “non-persistent cookie” and will delete it on a condition like exiting a web browser application.\n\nNote If both and are set in the options, then the last one defined in the object is what is used.\n\nNote The option should not be set directly; instead only use the option.\n\nSpecifies the value for the attribute. When truthy, the attribute is set, otherwise it is not. By default, the attribute is set.\n\nNote be careful when setting this to , as compliant clients will not allow client-side JavaScript to see the cookie in .\n\nSpecifies the (in milliseconds) to use when calculating the attribute. This is done by taking the current server time and adding milliseconds to the value to calculate an datetime. By default, no maximum age is set.\n\nNote If both and are set in the options, then the last one defined in the object is what is used.\n\nSpecifies the value for the attribute. When truthy, the attribute is set, otherwise it is not. By default, the attribute is not set.\n\nNote This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it.\n\nMore information about can be found in the proposal.\n\nSpecifies the value for the . By default, this is set to , which is the root path of the domain.\n\nSpecifies the to be the value for the attribute.\n• will set the attribute to .\n• will set the attribute to , the default priority when not set.\n• will set the attribute to .\n\nMore information about the different priority levels can be found in the specification.\n\nNote This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it.\n\nSpecifies the or to be the value for the attribute. By default, this is .\n• will set the attribute to for strict same site enforcement.\n• will not set the attribute.\n• will set the attribute to for lax same site enforcement.\n• will set the attribute to for an explicit cross-site cookie.\n• will set the attribute to for strict same site enforcement.\n\nMore information about the different enforcement levels can be found in the specification.\n\nNote This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it.\n\nNote There is a draft spec that requires that the attribute be set to when the attribute has been set to . Some web browsers or other clients may be adopting this specification.\n\nSpecifies the value for the attribute. When truthy, the attribute is set, otherwise it is not. By default, the attribute is not set.\n\nNote be careful when setting this to , as compliant clients will not send the cookie back to the server in the future if the browser does not have an HTTPS connection.\n\nPlease note that is a recommended option. However, it requires an https-enabled website, i.e., HTTPS is necessary for secure cookies. If is set, and you access your site over HTTP, the cookie will not be set. If you have your node.js behind a proxy and are using , you need to set “trust proxy” in express:\n\nFor using secure cookies in production, but allowing for testing in development, the following is an example of enabling this setup based on in express:\n\nThe option can also be set to the special value to have this setting automatically match the determined security of the connection. Be careful when using this setting if the site is available both as HTTP and HTTPS, as once the cookie is set on HTTPS, it will no longer be visible over HTTP. This is useful when the Express setting is properly setup to simplify development vs production configuration.\n\nFunction to call to generate a new session ID. Provide a function that returns a string that will be used as a session ID. The function is given as the first argument if you want to use some value attached to when generating the ID.\n\nThe default value is a function which uses the library to generate IDs.\n\nNOTE be careful to generate unique IDs so your sessions do not conflict.\n\nThe name of the session ID cookie to set in the response (and read from in the request).\n\nThe default value is .\n\nNote if you have multiple apps running on the same hostname (this is just the name, i.e. or ; different schemes and ports do not name a different hostname), then you need to separate the session cookies from each other. The simplest method is to simply set different s per app.\n\nTrust the reverse proxy when setting secure cookies (via the “X-Forwarded-Proto” header).\n\nThe default value is .\n• The “X-Forwarded-Proto” header will be used.\n• All headers are ignored and the connection is considered secure only if there is a direct TLS/SSL connection.\n• Uses the “trust proxy” setting from express\n\nForces the session to be saved back to the session store, even if the session was never modified during the request. Depending on your store this may be necessary, but it can also create race conditions where a client makes two parallel requests to your server and changes made to the session in one request may get overwritten when the other request ends, even if it made no changes (this behavior also depends on what store you’re using).\n\nThe default value is , but using the default has been deprecated, as the default will change in the future. Please research into this setting and choose what is appropriate to your use-case. Typically, you’ll want .\n\nHow do I know if this is necessary for my store? The best way to know is to check with your store if it implements the method. If it does, then you can safely set . If it does not implement the method and your store sets an expiration date on stored sessions, then you likely need .\n\nForce the session identifier cookie to be set on every response. The expiration is reset to the original , resetting the expiration countdown.\n\nThe default value is .\n\nWith this enabled, the session identifier cookie will expire in since the last response was sent instead of in since the session was last modified by the server.\n\nThis is typically used in conjuction with short, non-session-length values to provide a quick timeout of the session data with reduced potential of it occurring during on going server interactions.\n\nNote When this option is set to but the option is set to , the cookie will not be set on a response with an uninitialized session. This option only modifies the behavior when an existing session was loaded for the request.\n\nForces a session that is “uninitialized” to be saved to the store. A session is uninitialized when it is new but not modified. Choosing is useful for implementing login sessions, reducing server storage usage, or complying with laws that require permission before setting a cookie. Choosing will also help with race conditions where a client makes multiple parallel requests without a session.\n\nThe default value is , but using the default has been deprecated, as the default will change in the future. Please research into this setting and choose what is appropriate to your use-case.\n\nNote if you are using Session in conjunction with PassportJS, Passport will add an empty Passport object to the session for use after a user is authenticated, which will be treated as a modification to the session, causing it to be saved. This has been fixed in PassportJS 0.3.0\n\nThis is the secret used to sign the session ID cookie. The secret can be any type of value that is supported by Node.js (like a string or a ). This can be either a single secret, or an array of multiple secrets. If an array of secrets is provided, only the first element will be used to sign the session ID cookie, while all the elements will be considered when verifying the signature in requests. The secret itself should be not easily parsed by a human and would best be a random set of characters. A best practice may include:\n• The use of environment variables to store the secret, ensuring the secret itself does not exist in your repository.\n• Periodic updates of the secret, while ensuring the previous secret is in the array.\n\nUsing a secret that cannot be guessed will reduce the ability to hijack a session to only guessing the session ID (as determined by the option).\n\nChanging the secret value will invalidate all existing sessions. In order to rotate the secret without invalidating sessions, provide an array of secrets, with the new secret as first element of the array, and including previous secrets as the later elements.\n\nNote HMAC-256 is used to sign the session ID. For this reason, the secret should contain at least 32 bytes of entropy.\n\nThe session store instance, defaults to a new instance.\n\nControl the result of unsetting (through , setting to , etc.).\n\nThe default value is .\n• The session will be destroyed (deleted) when the response ends.\n• The session in the store will be kept, but modifications made during the request are ignored and not saved.\n\nTo store or access session data, simply use the request property , which is (generally) serialized as JSON by the store, so nested objects are typically fine. For example below is a user-specific view counter:\n\nTo regenerate the session simply invoke the method. Once complete, a new SID and instance will be initialized at and the will be invoked.\n\nDestroys the session and will unset the property. Once complete, the will be invoked.\n\nReloads the session data from the store and re-populates the object. Once complete, the will be invoked.\n\nSave the session back to the store, replacing the contents on the store with the contents in memory (though a store may do something else–consult the store’s documentation for exact behavior).\n\nThis method is automatically called at the end of the HTTP response if the session data has been altered (though this behavior can be altered with various options in the middleware constructor). Because of this, typically this method does not need to be called.\n\nThere are some cases where it is useful to call this method, for example, redirects, long-lived requests or in WebSockets.\n\nUpdates the property. Typically this is not necessary to call, as the session middleware does this for you.\n\nEach session has a unique ID associated with it. This property is an alias of and cannot be modified. It has been added to make the session ID accessible from the object.\n\nEach session has a unique cookie object accompany it. This allows you to alter the session cookie per visitor. For example we can set to to enable the cookie to remain for only the duration of the user-agent.\n\nAlternatively will return the time remaining in milliseconds, which we may also re-assign a new value to adjust the property appropriately. The following are essentially equivalent\n\nFor example when is set to (one minute), and 30 seconds has elapsed it will return until the current request has completed, at which time is called to reset to its original value.\n\nThe property returns the original (time-to-live), in milliseconds, of the session cookie.\n\nTo get the ID of the loaded session, access the request property . This is simply a read-only value set when a session is loaded/created.\n\nEvery session store must be an and implement specific methods. The following methods are the list of required, recommended, and optional.\n• Required methods are ones that this module will always call on the store.\n• Recommended methods are ones that this module will call on the store if available.\n• Optional methods are ones this module does not call at all, but helps present uniform stores to users.\n\nFor an example implementation view the connect-redis repo.\n\nThis optional method is used to get all sessions in the store as an array. The should be called as .\n\nThis required method is used to destroy/delete a session from the store given a session ID ( ). The should be called as once the session is destroyed.\n\nThis optional method is used to delete all sessions from the store. The should be called as once the store is cleared.\n\nThis optional method is used to get the count of all sessions in the store. The should be called as .\n\nThis required method is used to get a session from the store given a session ID ( ). The should be called as .\n\nThe argument should be a session if found, otherwise or if the session was not found (and there was no error). A special case is made when to act like .\n\nThis required method is used to upsert a session into the store given a session ID ( ) and session ( ) object. The callback should be called as once the session has been set in the store.\n\nThis recommended method is used to “touch” a given session given a session ID ( ) and session ( ) object. The should be called as once the session has been touched.\n\nThis is primarily used when the store will automatically delete idle sessions and this method is used to signal to the store the given session is active, potentially resetting the idle timer.\n\nThe following modules implement a session store that is compatible with this module. Please make a PR to add additional modules :)\n\ncluster-store A wrapper for using in-process / embedded stores - such as SQLite (via knex), leveldb, files, or memory - with node cluster (desirable for Raspberry Pi 2 and other multi-core embedded devices).\n\nconnect-memjs A memcached-based session store using memjs as the memcached client.\n\nconnect-session-knex A session store using Knex.js, which is a SQL query builder for PostgreSQL, MySQL, MariaDB, SQLite3, and Oracle.\n\nconnect-session-sequelize A session store using Sequelize.js, which is a Node.js / io.js ORM for PostgreSQL, MySQL, SQLite and MSSQL.\n\ndynamodb-store-v3 Implementation of a session store using DynamoDB backed by the AWS SDK for JavaScript v3.\n\nexpress-mysql-session A session store using native MySQL via the node-mysql module.\n\nexpress-oracle-session A session store using native oracle via the node-oracledb module.\n\nexpress-session-cache-manager A store that implements cache-manager, which supports a variety of storage types.\n\nexpress-session-rsdb Session store based on Rocket-Store: A very simple, super fast and yet powerfull, flat file database.\n\nnedb-session-store An alternate NeDB-based (either in-memory or file-persisted) session store.\n\nsession-pouchdb-store Session store for PouchDB / CouchDB. Accepts embedded, custom, or remote PouchDB instance and realtime synchronization.\n\nsessionstore A session store that works with various databases.\n\nA simple example using to store page views for a user.\n\nA simple example using to keep a user log in session.\n\nThis module uses the debug module internally to log information about session operations.\n\nTo see all the internal logs, set the environment variable to when launching your app ( , in this example):\n\nOn Windows, use the corresponding command;"
    },
    {
        "link": "https://geeksforgeeks.org/how-to-handle-sessions-in-express",
        "document": "How to handle sessions in Express ?\n\n﻿ExpressJS is a small framework that works on top of Node web server functionality to simplify its APIs and add helpful new features. It makes it easier to organize your application’s functionality with middleware and routing. It adds helpful utilities to Node HTTP objects and facilitates the rendering of dynamic HTTP objects.\n• Use Session Middleware : Start by installing and configuring a session middleware for ExpressJS, such as\n• Require the Middleware : In your ExpressJS application, require the session middleware and initialize it by passing a configuration object.\n• Session Configuration : Set up the session configuration, including options like secret key, session expiration, and cookie settings.\n• Middleware Integration : Add the session middleware to your method. This ensures that session functionality is available throughout your application.\n• Session Data Access : Access session data within your routes and middleware using the object. You can store and retrieve user-specific data in the session object, such as user authentication status or preferences.\n• Session Management : Implement logic to manage session data, such as creating a session upon user login, updating session data during user interactions, and destroying the session upon user logout or inactivity.\n• Security Considerations : Ensure that session-related data, such as session IDs and sensitive user information, are handled securely to prevent and other security vulnerabilities. Use secure , HTTPS, and other best practices to protect session data.\n• Testing : Test your session handling functionality thoroughly to ensure it works as expected. Use tools like or browser testing to simulate user interactions and verify session behavior.\n• None middleware in your ExpressJS application. This middleware creates a session object on the request ) object, which you can use to store session data:\n• None Once the session middleware is set up, you can access and modify session data in your route handlers:\n• None By default, sessions are stored in memory, which is not suitable for production use. You can use session stores like\n• None uses cookies to store session IDs. Ensure that your application properly handles session cookies and sets appropriate security options, such as , to prevent common security vulnerabilities like session hijacking and\n\nBy following these steps, you can effectively handle sessions in your ExpressJS application, allowing you to maintain user state and provide personalized experiences for your users.\n\nExample: Below is the example to handle session in ExpressJS.\n\n// used to sign the session ID cookie // do not save the session if it's not modified // do not save new sessions that have not been modified"
    },
    {
        "link": "https://expressjs.com/en/api.html",
        "document": "Creates an Express application. The function is a top-level function exported by the module.\n\nThe object conventionally denotes the Express application. Create it by calling the top-level function exported by the Express module:\n\nThe object has methods for\n• Routing HTTP requests; see for example, app.METHOD and app.param.\n\nIt also has settings (properties) that affect how the application behaves; for more information, see Application settings.\n\nAdd callback triggers to route parameters, where is the name of the parameter or an array of them, and is the callback function. The parameters of the callback function are the request object, the response object, the next middleware, the value of the parameter and the name of the parameter, in that order. If is an array, the trigger is registered for each parameter declared in it, in the order in which they are declared. Furthermore, for each declared parameter except the last one, a call to inside the callback will call the callback for the next declared parameter. For the last parameter, a call to will call the next middleware in place for the route currently being processed, just like it would if were just a string. For example, when is present in a route path, you may map user loading logic to automatically provide to the route, or perform validations on the parameter input. // try to get the user details from the User model and attach it to the request object Param callback functions are local to the router on which they are defined. They are not inherited by mounted apps or routers, nor are they triggered for route parameters inherited from parent routers. Hence, param callbacks defined on will be triggered only by route parameters defined on routes. All param callbacks will be called before any handler of any route in which the param occurs, and they will each be called only once in a request-response cycle, even if the parameter is matched in multiple routes, as shown in the following examples. On , the following is printed: CALLED ONLY ONCE although this matches and this matches too On , the following is printed: CALLED ONLY ONCE with 42 CALLED ONLY ONCE with 3 although this matches and this matches too The following section describes , which is deprecated as of v4.11.0. The behavior of the method can be altered entirely by passing only a function to . This function is a custom implementation of how should behave - it accepts two parameters and must return a middleware. The first parameter of this function is the name of the URL parameter that should be captured, the second parameter can be any JavaScript object which might be used for returning the middleware implementation. The middleware returned by the function decides the behavior of what happens when a URL parameter is captured. In this example, the signature is modified to . Instead of accepting a name and a callback, will now accept a name and a number. In this example, the signature remains the same, but instead of a middleware callback, a custom data type checking function has been defined to validate the data type of the user id. The ‘ ’ character can’t be used to capture a character in your capturing regexp. For example you can’t use to capture , use or instead (as in . // captures '1-a_6' and '543-az(ser\"-sder' but not '5-a s'\n\nThe object represents the HTTP request and has properties for the request query string, parameters, body, HTTP headers, and so on. In this documentation and by convention, the object is always referred to as (and the HTTP response is ) but its actual name is determined by the parameters to the callback function in which you’re working.\n\nBut you could just as well have:\n\nThe object is an enhanced version of Node’s own request object and supports all built-in fields and methods.\n\nThe object represents the HTTP response that an Express app sends when it gets an HTTP request.\n\nIn this documentation and by convention, the object is always referred to as (and the HTTP request is ) but its actual name is determined by the parameters to the callback function in which you’re working.\n\nBut you could just as well have:\n\nThe object is an enhanced version of Node’s own response object and supports all built-in fields and methods."
    },
    {
        "link": "https://expressjs.com/en/starter/examples.html",
        "document": "This page contains list of examples using Express.\n• resource - Multiple HTTP operations on the same resource\n\nThese are some additional examples with more extensive integrations.\n\nThis information refers to third-party sites, products, or modules that are not maintained by the Expressjs team. Listing here does not constitute an endorsement or recommendation from the Expressjs project team.\n• prisma-fullstack - Fullstack app with Express and Next.js using Prisma as an ORM\n• prisma-rest-api-ts - REST API with Express in TypeScript using Prisma as an ORM"
    },
    {
        "link": "https://bump.sh/blog/express-api-openapi",
        "document": "Express is a popular backend JavaScript framework for building landing pages and integrated content management systems or integrating APIs with other tools. With over twenty million weekly downloads on npm at the time of writing, the framework's popularity comes from its ease of setup and use, extensibility with first- and third-party middleware functions, and its flexible built-in router.\n\nOpenAPI is a standard for describing HTTP APIs in a document that humans and computers alike can understand or consume. Building APIs according to the OpenAPI specification can ease friction between an API's developer and its consumers, especially in terms of how the API should operate. Some knowledge about the OpenAPI specification can definitely help you understand the examples provided.\n\nIn this article, you'll learn how to build REST APIs using Express. You'll also learn how to document your APIs according to the OpenAPI specification with . Finally, you'll learn how to effectively manage your API documentation using Bump.sh.\n\nThe Express architecture is based around middleware, which are functions that can access and modify the request and response object and either return a response or trigger subsequent middleware functions. Middleware can be registered by invoking the method on an Express application, like so:\n\nExpress has three built-in middleware functions for serving static files ( , parsing JSON ( ) and URL-encoded request payloads ( ). Together with the Express router, these provide a good starting point for most applications.\n\nThe OpenAPI specification is an opinionated, language-agnostic standard for describing HTTP APIs that allows humans and machines to understand and interact with an API without the need to access the source code. A valid OpenAPI description document is also called an API contract because, like a contract, it enforces a specific behavior that must be implemented by the developer and adhered to by the consumer.\n\nAn API contract adds value in many ways, including easing the development burden, improving ease of adoption for first-time consumers, and using automated tools to reduce the amount of work needed to generate client code and documentation or validate I/O data.\n\nIn the next few sections, we'll see API contracts in action as we build an Express application and generate documentation with Bump.sh.\n\nImplementing an API with OpenAPI and Express\n\nIn this section, using Express, you'll build an API that follows the OpenAPI specification. You will be walked through steps to set up an Express application, configure it according to the OpenAPI spec, and see how to view your API documentation.\n\nIn order to follow along with this tutorial, you'll need the following:\n• A Node.js package manager — was used in this article\n\nYou can find the source code for the project in this GitHub repo.\n\nLet's start with creating an Express application. As mentioned, one of the reasons Express is so popular is that it's quick and easy to set up.\n\nFirst, create a new folder for your project. Spin up a terminal session and run the following command to create a folder named :\n\nNext, initialize a JavaScript project by adding a package.json file. Using the same terminal session or via your computer's file manager, create a file named package.json:\n\nOpen the package.json file using a text editor, then copy and paste the following in the file:\n\nYou can also use or to automatically generate a package.json file. Both and (on Yarn Classic) run interactively, meaning that you'll need to respond to a series of prompts before the file is generated. To skip these prompts and use the defaults, you can run the command with the flag:\n\nFinally, install the package dependency from the npm or yarn registry and create your Express application.\n\nIn your terminal, run the command to install dependencies:\n\nNext, create a file named index.js in your project's root folder. You can do that via the terminal by running the following:\n\nOpen this file using your text editor, then import and initialize your Express application:\n\nThe default export from the package is a function that, when invoked, creates an application instance. This instance or object contains methods for routing HTTP requests, configuring middleware, and binding and listening for connections on a specified host and port.\n\nIn the code block above, you configured an Express application and registered the middleware, which parses incoming requests with JSON payloads and a matching header.\n\nIf you try to access the application at this stage by running and navigating to http://localhost:3000 on a web browser, you'll be greeted by an error. There's no need to worry about this, however, as it just indicates that there are no routes or logic configured in your application yet. In the next section, we'll add some logic and set up the application's documentation with , an OpenAPI framework for Express.\n\nFor developing APIs, it helps to think of the API as a collection of resources, with each resource represented by a simple object that can be—from the moment of its creation—viewed, modified, or destroyed.\n\nFor simplicity, you can use this create, read, update, and delete (CRUD) pattern to help plan or design your API quickly. You can set up an OpenAPI-compliant API in a few steps using the package. For this one we will assume that our project has only one resource, called .\n\nis an un-opinionated OpenAPI framework for Express, which supports OpenAPI versions 2.x and 3.0 at the time of writing. Configuration can be done in JavaScript or from a YAML string/file. In this project, you'll be using a JavaScript object.\n\nallows you to keep the OpenAPI definition in sync with the code. Basically, you will provide an OpenAPI definition file with empty paths and they will be populated from your code. Doing this ensures the OpenAPI file will be exactly reflecting how the code behaves, updated as the code is. It also allows you if you go play around with the tool to validate your schemas, automatically provide tailored to a particular route, helps with your API security management, and so much more I can’t list them all now. The whole purpose of this framework is to stay as close as possible to express while leveraging the power of OpenAPI.\n\nTo get started, run this command in your terminal to install the package:\n\nOpen the index.js file in your editor and add the following import near the top of the file:\n\nThe import is a function that accepts a configuration object and sets up an OpenAPI-compliant contract that can be viewed or generated for your API. The required configuration parameters are as follows:\n• an object containing exposed HTTP methods and handler functions\n• a string that points to a directory where route files can be found\n• an object describing the API's base definition, including schemas of objects used in your documentation\n\nNote that either or will be required at any time. This means that if is present, then isn't required and vice versa.\n\nNow make the following changes to the index.js file to see what this config looks like in action.\n\nAs first argument, you need to pass a reference to your Express app, then optionally specify a path to the keyword if you want the API contract file to be served by your server, in development mode this can be useful (as you will see later when using the Bump CLI), however in production mode you might want to remove this and replace it with the option. Something like:\n\nNext, configure the object by specifying the path of a file containing the base of your API definition. In this tutorial, you'll be using OpenAPI 3.1. Add the file path to the config object:\n\nAnd create the file with the following content:\n\nNote that the API definition paths property is an empty object. This is because will generate its members based on the value of the property given in the function dynamically, which you'll add next.\n\nTo do this, we will import javascript files by adding the folder path or our API endpoints logic to the function call:\n\nFinally, you'll need to add a route with some operations to complete the initialization. The package uses filesystem-based routing. Let's look at the following routes we want to define:\n\nThey would need the following files to be created (assuming is the starting directory):\n\nWhile we'll be using more routes, these two files will be enough for what our project needs, so go ahead and create them:\n\nWe'll add some logic to our API application inside these files. Each file will contain a function as its default export, and this function will act as the corresponding path handler. For example, requests sent to will be handled by the function exported in , and requests sent to will be handled by the function exported in .\n\nFirst, open the users.js file and add the following code:\n\nNext, add the following code to the users/{id}.js file:\n\nLet's quickly break down what's happening in these files:\n• You have a function as the default export, and this function returns an object representing valid operations (HTTP methods) for the route.\n• As mentioned earlier, the file names correspond to the route that will be matched when your API is queried.\n• For each operation defined in the object, you need a corresponding handler function, and the function name must match the HTTP verb (PUT, GET, etc).\n• Finally, the documentation for each handler function can be described by adding an property to the handler functions.\n\nWhat's missing now are: your API documentation and the actual API logic. We'll add those in the next few steps.\n\nFirst let's add your API endpoints documentation. We will update the property for the GET and POST handler functions in the users.js file:\n\nWe'll also add the documentation for the GET, PUT, and DELETE handler functions in the users/{id}.js file:\n\nThe property of a function handler defines the OpenAPI documentation for that endpoint while the summary and operationId fields provide a brief description and a unique identifier, respectively. Route parameters and the required format for the request body data can be configured with the and fields, respectively. Finally, the field provides information about the possible responses—and their status codes—for an endpoint.\n\nNext, update the function handlers to include CRUD logic:\n\nThe GET and POST function handlers here respond to GET and POST requests made to , respectively. The GET function retrieves all user data from a database, the —which we'll get to later—and returns it in JSON format with a status code of 200. The POST function adds a new user to the database from data provided via the request's body and returns the updated user list with a status code of 201.\n\nWe'll also need to update the function handlers in the /users/{id}.js file. Open the file and update the GET, PUT, and DELETE functions to include the following code:\n\nAs mentioned earlier, requests made to will be routed to this file and handled according to their HTTP verbs. The GET function here retrieves a single user from the database, matching the ID provided in the request's path. The PUT function updates a single user, also matching the provided ID, and returns the updated user as JSON with a status code of 200. The DELETE function removes a user from the database using the ID provided in the request. No data is returned from the DELETE function, so the status code is 204.\n\nThe object referenced in the function handlers code is a simple object with methods for updating and reading from an in-memory data store (an array of objects). We can add this to our project by creating a file named database.js in the project root:\n\nAnd adding the following code to the file:\n\nThe code above defines a function named that returns an object with multiple functions to perform CRUD operations on an in-memory data store, the array. The functions , , and respectively perform operations to add, update, or delete users from the data store. The and functions retrieve one or multiple users from the data store, while is a utility function for checking if a user with a matching ID exists in the data store.\n\nWe instantiate and store the in the variable, and we export and use this in our function handlers. Let's update the rest of our code to include the import.\n\nOpen the files in your directory, and add the following line at the top of each file:\n\nNote that for the paths/users/{id}.js file, you need to add two dots and a slash (../) as it's nested one level deep:\n\nWith that, your API and its contract have been set up. When you test your application in the next section, you'll see that errors will be thrown for invalid requests or payloads that don't conform to the documentation you've described. This is where the library shines as you didn't need to define any validation code but the provided documentation schemas and constraints will do all the job for you.\n\nWhile you've learned to create an Express application with in this section, it's been light on information about the OpenAPI specification and the package. You can start with the OpenAPI guide if you'd like to learn more about the OpenAPI specification and the express-openapi documentation for more information on how to use the package.\n\nIt's time to run and test the application. Simply run and navigate to http://localhost:3000/api-definition in a browser to see your API definition.\n\nYou can also test the API by visiting http://localhost:3000/users to list the users in your database.\n\nIn a production environment, you will probably want to deploy the updated API definition each time you make a change in your code without having to expose the API definition on your express server.\n\nTo do so, copy the following script into a new file named :\n\nThis is a simple script which uses the package to generate the API definition file without the need to run an Express server.\n\nSo if you run the following command:\n\nYou will be able to snapshot the current OpenAPI definition file inside the file.\n\nUsing Bump.sh for Documenting Your Express APIs\n\nUsing OpenAPI (and the package) enables you to use API contracts that make collaboration easy among developers when building and integrating with APIs. However, manually generating and maintaining these contracts can be tough, as you just saw. Bump.sh can improve this collaboration by helping documenting your API based on the contract.\n\nAs an API documentation management solution, Bump.sh helps publish API contracts into developer portals, track changes, and alert teams when breaking changes are introduced. It essentially eases the workload of manually updating your API's documentation, communicating changes made to your API's consumers, and keeping track of all your product documentation.\n\nBump.sh provides a command line interface (CLI) tool that lets you easily preview your API documentation while it's in development (with support for live reloading), deploy versions of your documentation automatically from your CI build step, compare changes made between versions of your API, as well as notify consumers of changes made to your APIs.\n\nTo configure Bump.sh for your Express app, you need to add the Bump.sh CLI to your existing Express project:\n\nAs mentioned, can be used to preview, compare versions, or deploy new versions of your API documentation.\n\nSign up or login in your Bump.sh account. You can begin by navigating to your dashboard and clicking Create Documentation.\n\nNext, add your documentation's name and, optionally, specify its access level (public or private).\n\nNext, you'll be asked to upload a specification file. Choose the Use Bump.sh CLI option, which will immediately take you to the newly created documentation's deployment configuration page. Here, you'll find the token that's required to deploy your documentation using the CLI. It's the string labeled Access token, as shown below.\n\nCopy this token and replace with it when running the command to deploy your project:\n\nRunning the command above will trigger a deployment that you can view by clicking View Documentation from your documentation's General Settings page.\n\nYour deployed documentation should open in a new tab, and it should look like this:\n\nIn order to automatically deploy a new version of your documentation every time you push code changes to a branch, we will add the Bump Github Action to your repository.\n\nTo deploy a new version on each push, create a file named in the folder of your project, then paste the following code into the file:\n\nThis workflow runs every time is run on the branch. It will generate the API definition thanks to the script, then deploy the API definition file to Bump.sh thanks to the Bump Github Action.\n\nJust make sure you provide your Bump documentation slug (replace the value) and an encrypted secret containing the Bump access token used earlier in a secret variable on your repository.\n\nThe resulting action should run on each push to the branch:\n\nYour API consumers can then subscribe to changes made to your API by clicking on API Changelog from your API documentation page. Either by completing the form or adding the RSS feed link to apps that can display RSS feeds.\n\nBy following this tutorial, you created an Express application and documented the API according to the OpenAPI specification with the npm package. You also learnt how to deploy a live version of your API documentation using Bump.sh.\n\nDocumenting your APIs correctly is key to your API quality, usability, maintainability and helps your API consumers quickly get up to speed with using your product, reducing the number of support tickets and issues related to consuming your API.\n\nBump.sh helps with documenting your APIs but goes one step further by giving you tools like an automatic API changelog with notifications and diffs and a hub to manage all your API documentation in one place."
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-use-ejs-to-template-your-node-application",
        "document": "When quickly creating Node applications, a fast way to template your application is sometimes necessary.\n\nJade comes as the default template engine for Express but Jade syntax can be overly complex for many use cases.\n\nEmbedded JavaScript templates (EJS) can be used as an alternative template engine.\n\nIn this article, you will learn how to apply EJS to an Express application, include repeatable parts of your site, and pass data to the views.\n\nIf you would like to follow along with this article, you will need:\n• A local development environment for Node.js. Follow How to Install Node.js and Create a Local Development Environment.\n\nThis tutorial was originally written for v4.17.1 and v3.1.5. It has been verified with Node v16.0.0, v7.11.1, v4.17.1, and v3.1.6.\n\nFirst, open your terminal window and create a new project directory:\n\nThen, navigate to the newly created directory:\n\nAt this point, you can initialize a new npm project:\n\nNext, you will need to install the package:\n\nAt this point, you have a new project ready to use Express and EJS.\n\nWith all of the dependencies installed, let’s configure the application to use EJS and set up the routes for the Index page and the About page.\n\nCreate a new file and open it with your code editor and add the following lines of code:\n\nThis code defines the application and listens on port .\n\nThis code also sets EJS as the view engine for the Express application using:\n\nNotice how the code sends a view to the user by using . It is important to note that will look in a folder for the view. So you only have to define since the full path is .\n\nNext, you will create the views using EJS.\n\nLike a lot of the applications you build, there will be a lot of code that is reused. These are considered partials. In this example, there will be three partials that will be reused on the Index page and About page: , , and . Let’s make those files now.\n\nIn this directory, create a new file and open it with your code editor. Add the following lines of code:\n\nThis code contains metadata for the for an HTML document. It also includes Bootstrap styles.\n\nNext, create a new file and open it with your code editor. Add the following lines of code:\n\nThis code contains navigation for an HTML document and uses several classes from Bootstrap for styling.\n\nNext, create a new file and open it with your code editor. Add the following lines of code:\n\nThis code contains copyright information and uses several classes from Bootstrap for styling.\n\nNext, you will use these partials in and .\n\nYou have three partials defined. Now you can them in your views.\n\nUse to embed an EJS partial in another file.\n• The hyphen instead of just to tell EJS to render raw HTML.\n• The path to the partial is relative to the current file.\n\nIn this directory, create a new file and open it with your code editor. Add the following lines of code:\n\nSave the changes to this file and then run the application:\n\nIf you visit in a web browser, you can observe the Index page:\n\nNext, create a new file and open it with your code editor. Add the following lines of code:\n\nThis code adds a Bootstrap sidebar to demonstrate how partials can be structured to reuse across different templates and pages.\n\nSave the changes to this file and then run the application:\n\nIf you visit in a web browser, you can observe the About page with a sidebar:\n\nNow you can start using EJS for passing data from the Node application to the views.\n\nLet’s define some basic variables and a list to pass to the Index page.\n\nRevisit in your code editor and add the following lines of code inside the route:\n\nThis code defines an array called and a string called . Next, let’s use them in .\n\nTo echo a single variable, you can use .\n\nRevisit in your code editor and add the following lines of code:\n\nThis code will display the value on the Index page.\n\nTo loop over data, you can use .\n\nRevisit in your code editor and add the following lines of code:\n\nSave the changes to this file and then run the application:\n\nIf you visit in a web browser, you can observe the Index page with the :\n\nThe EJS partial has access to all the same data as the parent view. But be careful. If you are referencing a variable in a partial, it needs to be defined in every view that uses the partial or it will throw an error.\n\nYou can also define and pass variables to an EJS partial in the include syntax like this:\n\nBut you need to again be careful about assuming a variable has been defined.\n\nIf you want to reference a variable in a partial that may not always be defined, and give it a default value, you can do so like this:\n\nIn the line above, the EJS code is rendering the value of if it’s defined, and if not.\n\nIn this article, you learned how to apply EJS to an Express application, include repeatable parts of your site, and pass data to the views.\n\nEJS lets you build applications when you do not require additional complexity. By using partials and having the ability to easily pass variables to your views, you can build some great applications quickly.\n\nConsult the EJS documentation for additional information on features and syntax. Consult Comparing JavaScript Templating Engines: Jade, Mustache, Dust and More for understanding the pros and cons of different view engines."
    },
    {
        "link": "https://expressjs.com/en/guide/using-template-engines.html",
        "document": "A template engine enables you to use static template files in your application. At runtime, the template engine replaces variables in a template file with actual values, and transforms the template into an HTML file sent to the client. This approach makes it easier to design an HTML page.\n\nThe Express application generator uses Pug as its default, but it also supports Handlebars, and EJS, among others.\n\nTo render template files, set the following application setting properties, in the default created by the generator:\n• , the directory where the template files are located. Eg: . This defaults to the directory in the application root directory.\n• , the template engine to use. For example, to use the Pug template engine: .\n\nThen install the corresponding template engine npm package; for example to install Pug:\n\nAfter the view engine is set, you don’t have to specify the engine or load the template engine module in your app; Express loads the module internally, for example:\n\nThen, create a Pug template file named in the directory, with the following content:\n\nCreate a route to render the file. If the property is not set, you must specify the extension of the file. Otherwise, you can omit it.\n\nWhen you make a request to the home page, the file will be rendered as HTML.\n\nThe view engine cache does not cache the contents of the template’s output, only the underlying template itself. The view is still re-rendered with every request even when the cache is on."
    },
    {
        "link": "https://geeksforgeeks.org/use-ejs-as-template-engine-in-node-js",
        "document": "EJS (Embedded JavaScript) is a popular templating engine for Node.js that allows you to generate HTML markup with plain JavaScript. It is particularly useful for creating dynamic web pages, as it enables you to embed JavaScript logic directly within your HTML.\n\nEJS or Embedded Javascript Templating is a templating engine used by Node.js. Template engine helps to create an HTML template with minimal code. Also, it can inject data into an HTML template on the client side and produce the final HTML. EJS is a simple templating language that is used to generate HTML markup with plain JavaScript. It also helps to embed JavaScript into HTML pages.\n\nSteps to Use EJS as Template Engine\n\nTo begin with, using EJS as templating engine we need to install EJS using the given command:\n\nIt will install exxpress and ejs as dependency in the node.js project.\n\nThe default behavior of EJS is that it looks into the ‘views’ folder for the templates to render. So, let’s make a ‘views’ folder in our main node project folder and make a file named “home.ejs” which is to be served on some desired requests in our node project. The content of this page is:\n\nNow, we will render this page on a certain request by the user:\n\nNow, the page home.ejs will be displayed on requesting localhost. To add dynamic content this render method takes a second parameter which is an object. This is done as:\n\nNow, We will embed the name to the HTML page as:\n\nIt is used to embed dynamic content to the page and is used to embed normal JavaScript. Now embedding normal JavaScript:\n\nSteps to run the program: After creating all the files go to the root directory of your project folder and run the below command\n\nType the node file_name.js command to run your program and see the output as displayed.\n• Embedded JavaScript: Allows you to embed JavaScript logic directly within your HTML.\n• Partial Templates: Supports partials, enabling you to reuse common template fragments (like headers and footers) across different pages.\n• Layout Support: EJS can be used with layout managers to create consistent layouts across multiple views.\n\nEJS is a powerful and flexible templating engine that enhances your Node.js applications by allowing you to generate dynamic HTML content with ease. Its simplicity and integration with Express make it an ideal choice for developers looking to build server-rendered web applications quickly. Whether you’re developing a simple site or a complex web application, EJS provides the tools you need to create dynamic and interactive user interfaces."
    },
    {
        "link": "https://topcoder.com/thrive/articles/using-ejs-template-engine-with-express-js",
        "document": "Template engine is a part of Express that enables us to use static files in our applications.Template engine converts variables to values and changes the template to HTML files to send to the client.\n\nThe default template engine of Express is Jade, but EJS is the most commonly used engine. In this article we will be discussing EJS only.\n\nIn this article we will cover\n\nIf you don’t have nodeJS installed see How to install and configure nodeJS.\n\nOpen up the terminal and create the project directory.\n\nThen, navigate to the directory.\n\nNow, initialize npm in it.\n\nLet’s install the npm modules we will need to build the application.\n\nLet’s install another module that will rerun our application automatically every time we make changes to it.\n\nWhen we have all the required modules, create a server.js file and configure it to use EJS.\n\nAlso, set routes for the index page and magic page.\n\nCreate a server.js file, open your editor, and write down the following code:\n\nLet’s understand what this code does.\n\nWe are importing the Express module and declaring its instance as an app.\n\nWe are setting up a server to listen at port 8080 by using app.listen().\n\nWe are telling our server to use EJS template engine in line,\n\napp.set(“view engine”, “ejs”).\n\nWe also set up routes / and /magic to render index and magic EJS pages respectively.\n\nYou can notice that our server shows user HTML content by using res.render(). Note that this res.render method will look for EJS files in the views directory so we only have to give the file name overall path will be interpreted as /views/index .\n\nStart the server by running the following command in the terminal.\n\nNow we will create view using EJS.\n\nBefore we start implementing partials, let’s understand what partials are. Partials are code blocks that are reused many times in an application. For example, in this tutorial we are going to create two view pages, index and magic, and in both of these files we will need to write a header and footer. We can create a separate one for each and reuse it in both view pages. Let’s create the files header.ejs and footer.ejs now.\n\nNow create header.ejs in partials directory, open that file in your editor, and write down the following code.\n\nThis EJS code is similar to HTML, there are no EJS variables. It is simple HTML containing a header component which also loads CDN to semantic UI (a CSS library). Then, in the body section we have navbar created using Simatic UI classes in HTML under tags.\n\nCreate the footer.js file inside partials and write down the given code.\n\nNow we will use these partials in our view files index and magic.\n\nWe have two partials defined. We will use them in index.ejs view page.\n\nWe can include any partial by writing the following syntax where we want to import a partial.\n\nNote: we have replaced all occurances of with due to syntax highlighter issues.\n\nNow create an index.ejs file in views directory and write down the given code.\n\nSave file, open browser, and enter url localhost:8080. You should see this web page.\n\nNow create magic.ejs and write down the code as given.\n\nAnd now visit localhost:8080/magic in the browser.\n\n\n\nNow let’s see how we can pass data to view pages.\n\nLet’s set up some variables and lists to pass to index.js.\n\nOpen server.js and modify the index route as given.\n\nLet’s use the variables we just defined in index.ejs.\n\nA single variable can be represented by using syntax <%= variable_name %>.\n\nWe can use subheading in index.ejs that we passed as given.\n\nAnd now you should see the webpage in your browser as:\n\nNow we know how to render a single variable. Let’s see how we can loop over a list to display each element of the list.\n\nWe can iterate over an array using .forEach function of Javascript.\n\nOpen index.js and modify it as:\n\nYou can notice that for each character in the characters array we passed we are displaying a list point with name and designation associated with each. If you open the browser, the webpage will now look like:\n\nIn this article you learned how to render templates using EJS and how to pass variables between files. Hence, EJS helps to develop simple applications very easily."
    },
    {
        "link": "https://stackoverflow.com/questions/48482616/how-can-i-use-the-ejs-templating-engine-in-nodejs-express-without-doing-res-ren",
        "document": "I would like to res.send a JSON object containing a HTML snippet generated from one of my EJS templates.\n\nIs that possible somehow? Thanks!"
    }
]