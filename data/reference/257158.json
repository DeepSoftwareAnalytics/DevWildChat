[
    {
        "link": "https://backtrader.com/docu/datafeed",
        "document": ""
    },
    {
        "link": "https://backtrader.com/docu/pandas-datafeed/pandas-datafeed",
        "document": ""
    },
    {
        "link": "https://backtrader.com/docu",
        "document": ""
    },
    {
        "link": "https://reddit.com/r/algotrading/comments/1he0fo1/how_to_write_custom_live_data_feeder_for",
        "document": "I'm looking to feed Backtrader with live data from custom sources, but haven't yet found any specifications as to how to implement this such a class. I'll likely need to extend a class such as and override functions such as and , but where can I find information to guide me on this?\n\nEdit: I just came across this: https://www.backtrader.com/docu/datafeed-develop-general/datafeed-develop-general/#vchartdata-full-code. Likely I can build on that. Must say I find the data feed part of the documentation somewhat confusing though."
    },
    {
        "link": "https://backtrader.com/blog/posts/2017-04-09-multi-example/multi-example",
        "document": ""
    },
    {
        "link": "https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html",
        "document": "Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected. A local file could be: . If you want to pass in a path object, pandas accepts any . By file-like object, we refer to objects with a method, such as a file handle (e.g. via builtin function) or . Deprecated since version 2.1.0: Passing byte strings is deprecated. To read from a byte string, wrap it in a object.\n\nColumn (0-indexed) to use as the row labels of the DataFrame. Pass None if there is no such column. If a list is passed, those columns will be combined into a . If a subset of data is selected with , index_col is based on the subset. Missing values will be forward filled to allow roundtripping with for . To avoid forward filling the missing values use after reading the data instead of .\n\nData type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32} Use to preserve data as stored in Excel and not interpret dtype, which will necessarily result in dtype. If converters are specified, they will be applied INSTEAD of dtype conversion. If you use , it will infer the dtype of each column based on the data.\n\nIf io is not a buffer or path, this must be set to identify io. Engine compatibility : When , the following logic will be used to determine the engine:\n• None If is an OpenDocument format (.odf, .ods, .odt), then odf will be used.\n• None Otherwise if is an xls format, will be used.\n• None Otherwise if is in xlsb format, will be used.\n• None Otherwise will be used.\n\nWhether or not to include the default NaN values when parsing the data. Depending on whether is passed in, the behavior is as follows:\n• None If is True, and are specified, is appended to the default NaN values used for parsing.\n• None If is True, and are not specified, only the default NaN values are used for parsing.\n• None If is False, and are specified, only the NaN values specified are used for parsing.\n• None If is False, and are not specified, no strings will be parsed as NaN. Note that if is passed in as False, the and parameters will be ignored.\n\nThe behavior is as follows:\n• None . If True -> try parsing the index.\n• None of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column.\n• None of lists. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column. If a column or index contains an unparsable date, the entire column or index will be returned unaltered as an object data type. If you don`t want to parse some cells as date just change their type in Excel to “Text”. For non-standard datetime parsing, use after .\n\nFunction to use for converting a sequence of string columns to an array of datetime instances. The default uses to do the conversion. Pandas will try to call in three different ways, advancing to the next if an exception occurs: 1) Pass one or more arrays (as defined by ) as arguments; 2) concatenate (row-wise) the string values from the columns defined by into a single array and pass that; and 3) call once for each row using one or more strings (corresponding to the columns defined by ) as arguments. Deprecated since version 2.0.0: Use instead, or read in as and then apply as-needed."
    },
    {
        "link": "https://geeksforgeeks.org/working-with-excel-files-using-pandas",
        "document": "Excel sheets are very instinctive and user-friendly, which makes them ideal for manipulating large datasets even for less technical folks. If you are looking for places to learn to manipulate and automate stuff in Excel files using Python, look no further. You are at the right place.\n\nIn this article, you will learn how to use Pandas to work with Excel spreadsheets. In this article we will learn about:\n\nTo install Pandas in Python, we can use the following command in the command prompt:\n\nTo install Pandas in Anaconda, we can use the following command in Anaconda Terminal:\n\nFirst of all, we need to import the Pandas module which can be done by running the command:\n\nInput File: Let’s suppose the Excel file looks like this\n\nNow we can import the Excel file using the read_excel function in Pandas to read Excel file using Pandas in Python. The second statement reads the data from Excel and stores it into a pandas Data Frame which is represented by the variable newData.\n\nIf there are multiple sheets in the Excel workbook, the command will import data from the first sheet. To make a data frame with all the sheets in the workbook, the easiest method is to create different data frames separately and then concatenate them. The read_excel method takes argument sheet_name and index_col where we can specify the sheet of which the frame should be made of and index_col specifies the title column, as is shown below:\n\nThe third statement concatenates both sheets. Now to check the whole data frame, we can simply run the following command:\n\nTo view 5 columns from the top and from the bottom of the data frame, we can run the command. This head() and tail() method also take arguments as numbers for the number of columns to show.\n\nThe shape() method can be used to view the number of rows and columns in the data frame as follows:\n\nIf any column contains numerical data, we can sort that column using the sort_values() method in pandas as follows:\n\nNow, let’s suppose we want the top 5 values of the sorted column, we can use the head() method here:\n\nWe can do that with any numerical column of the data frame as shown below:\n\nNow, suppose our data is mostly numerical. We can get the statistical information like mean, max, min, etc. about the data frame using the describe() method as shown below:\n\nThis can also be done separately for all the numerical columns using the following command:\n\nOther statistical information can also be calculated using the respective methods. Like in Excel, formulas can also be applied, and calculated columns can be created as follows:\n\nAfter operating on the data in the data frame, we can export the data back to an Excel file using the method to_excel. For this, we need to specify an output Excel file where the transformed data is to be written, as shown below:\n\nHow to Use Pandas with Excel Files?\n\nPandas provides powerful tools to read from and write to Excel files, making it easy to integrate Excel data with your Python scripts. You can read Excel files using the function. It requires the or library for files or the library for files. To write a DataFrame to an Excel file, you can use the method of the DataFrame class. It requires the library to write to files. # Write the DataFrame to an Excel file \n\n\n\nHow to Extract Data from Excel Using Pandas?\n\nCan We Read XLSX File in Pandas?\n\nIs Pandas Better Than SQL?\n\nDo I Need openpyxl for Pandas?"
    },
    {
        "link": "https://stackoverflow.com/questions/50275969/python-pandas-create-function-to-use-read-excel-for-multiple-files",
        "document": "I am trying to make a reusable functions in python that would read two Excel files and save save to another.\n\nMy function looks like this:\n\nI am calling to the functions as:\n\nIt do not have any errors but it do not create the Excel files that should be performed by function.\n\nIt reads the function parameters until parameter and returns error for the last two.\n\nI will be using quite a number of times in my code so I am trying to make it a function. I am also aware the reads the filenames as string and tried doing `somefile.xlsx' but still the same result.\n\nThe Excel files that will be read are on the same path of the python script.\n\nQuestion: Any advice on how this would work? Is it advisable to make this a function or should I just use repetitively?"
    },
    {
        "link": "https://stackoverflow.com/questions/20908018/import-multiple-excel-files-into-python-pandas-and-concatenate-them-into-one-dat",
        "document": "As mentioned in the comments, one error you are making is that you are looping over an empty list.\n\nHere is how I would do it, using an example of having 5 identical Excel files that are appended one after another.\n\n(5) Loop over list of files to append to empty dataframe:"
    },
    {
        "link": "https://digitalocean.com/community/tutorials/pandas-read_excel-reading-excel-file-in-python",
        "document": "We can use the pandas module read_excel() function to read the excel file data into a DataFrame object. If you look at an excel sheet, it’s a two-dimensional table. The DataFrame object also represents a two-dimensional tabular data structure.\n\nLet’s say we have an excel file with two sheets - Employees and Cars. The top row contains the header of the table.\n\nHere is the example to read the “Employees” sheet data and printing it.\n• The first parameter is the name of the excel file.\n• The sheet_name parameter defines the sheet to be read from the excel file.\n• When we print the DataFrame object, the output is a two-dimensional table. It looks similar to an excel sheet records.\n\n2. List of Columns Headers of the Excel Sheet\n\nWe can get the list of column headers using the property of the dataframe object.\n\nWe can get the column data and convert it into a list of values.\n\nWe can specify the column names to be read from the excel file. It’s useful when you are interested in only a few of the columns of the excel sheet.\n\nIf the excel sheet doesn’t have any header row, pass the header parameter value as None.\n\nIf you pass the header value as an integer, let’s say 3. Then the third row will be treated as the header row and the values will be read from the next row onwards. Any data before the header row will be discarded.\n\nThe DataFrame object has various utility methods to convert the tabular data into Dict, CSV, or JSON format."
    }
]