[
    {
        "link": "https://mathworks.com/matlabcentral/fileexchange/73480-jacobi-method",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/answers/157632-jacobi-iterative-method-in-matlab",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/fileexchange/63167-gauss-seidel-method-jacobi-method",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/answers/368935-matlab-code-for-solving-2d-laplace-pde",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/fileexchange/24827-hamilton-jacobi-solver-on-unstructured-triangular-grids",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/fileexchange/178854-gauss-seidel-method-vs-gauss-jacobi-method",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/answers/86085-gauss-seidel-method-in-matlab",
        "document": ""
    },
    {
        "link": "https://simulationtutor.com/gauss-seidel-method-matlab-code-solving-equations-efficiently",
        "document": "Numerical analysis stands at the heart of modern engineering, empowering us to solve complex mathematical problems that cannot be handled by traditional analytical methods. One such powerful solution technique is the Gauss Seidel method, a cornerstone in the world of iterative algorithms. The use of “Gauss Seidel Method MATLAB Code” has revolutionized the way we approach these problems, offering an efficient and convenient tool for numerous applications.\n\nIn this comprehensive guide, we will walk through the Gauss Seidel method, its implementation in MATLAB, and explore its applications within electrical engineering domains. Whether you are a MATLAB enthusiast, an ambitious engineering student, a professional in the field of electrical engineering, or someone eager to understand numerical methods better, this post is for you.\n\nWhat is the Gauss Seidel Method?\n\nFundamentally, the Gauss Seidel method consists of the splitting of a system of linear equations into multiple variables. Given an initial guess for these variables, the method updates each variable with the previous iteration to arrive at a new approximate solution set. This process proceeds until the difference in the variables from one iteration to the next is small enough, suggesting that the current approximation is close to the true solution.\n\nUsing MATLAB, the implementation is systematic, and to efficiently solve complicated equations, one should understand it. We shall look into the setting of the iteration loop come up with equations and perform the update of the variables. We will also cover techniques for convergence problems and an assessment of the accuracy of the solutions. Also, we will give you a working code example that you can adjust to resolve your engineering issues.\n\nThe initial procedures of executing the Gauss Seidel method in MATLAB start with defining the variables and their initial guesses. The number of variables is dictated by the system of equations under consideration. The values are next saved as arrays of known lengths and populated with the initial guesses of each variable.\n\nThen the convergence criteria and tolerance level should be specified. This will enable us to know when the iterations should end as earlier stated. One way is to set a maximum number of iterations as one more safety measure.\n\nAfter the variables have been defined, we have to write equations to represent their associations. This step consists of transforming the original equations into a set which permits us to write every variable in terms of the other variables.\n\nThe initial setup being done, we can now begin with the iteration process. The charm of this method consists in its simplicity as it involves only elementary algebraic operations. In each iteration, we change one variable at a time based on the new values of other variables just calculated.\n\nThe Gauss Seidel method finds extensive utilization in various electrical engineering fields, such as circuit analysis, power flow calculations, and heat transfer simulations. By using this method, we can efficiently solve complex systems of equations that arise in these domains.\n\nThe Advantages of the Gauss-Seidel Method\n\nGauss-Seidel is known for several advantages over other solution techniques. Its convergence speed and memory efficiency are particularly noteworthy.\n\nThe Gauss-Seidel method often converges faster than other iterative techniques, such as the Jacobi method, especially for systems with good properties for convergence. Its speed can significantly reduce the number of iterations required to achieve a satisfactory solution, saving valuable computational resources and time.\n\nUnlike the Gauss elimination method, which requires the storage of the entire matrix, the Gauss-Seidel method works with just one matrix. This memory efficiency is highly beneficial when dealing with large systems of equations, where memory allocations can become a limiting factor.\n\nIn the realm of electrical engineering, the Gauss-Seidel method is a workhorse in various applications, revolutionizing the way we approach and solve complex electrical problems. Here are some of its primary applications:\n\nThe method’s ability to solve systems of equations efficiently makes it an invaluable tool in analyzing complex electrical circuits. With the help of MATLAB, we can quickly obtain accurate results for circuit simulations and analyses.\n\nPower flow is a critical aspect of power system operations, and the Gauss-Seidel method plays a crucial role in its solution. With its convergence speed and memory efficiency, it is a go-to technique for analyzing large power systems.\n\nPower system studies often involve solving nonlinear and complex equations to analyze and predict the operation of electrical grids. The Gauss-Seidel method, with its iterative approach, is perfect for computing load flows and stability studies in power networks, offering accurate solutions to the most critical industry problems.\n\nFor electronic circuit aficionados, the method offers a strategic way to analyze and solve large systems of circuit equations. By directly incorporating boundary conditions and constraints into the iterative process, the Gauss-Seidel method provides circuit designers with deeper insights into their design solutions.\n\nTo harness the full potential of the Gauss-Seidel method in MATLAB, it’s crucial to optimize the code for maximum performance. We will explore various strategies, from algorithmic optimizations to leveraging MATLAB’s features for matrix operations.\n\nOptimizing MATLAB code doesn’t just involve making the syntax neat; it’s about designing the algorithm for parallel processing, inspection of floating-point behavior, and efficient data handling. These optimization strategies can lead to significant improvements in the execution time and memory footprint of your algorithm.\n\nVectorization is a vital technique in MATLAB to enhance performance by operating on arrays and matrices instead of individual elements. We will discuss how to apply this technique to the Gauss-Seidel method, transforming the iterative calculations into an array operation that can significantly boost your code’s speed. Additionally, leveraging built-in MATLAB functions for matrix operations can further optimize your code.\n\nWe’ve reached the heart of this guide, where we’ll demonstrate the Gauss-Seidel method in action with MATLAB code examples.\n\n% Initialize the solution vector 'x' with zeros and set the maximum number of iterations\n\n% Confirm convergence or take corrective action if necessary\n\nThis abbreviated example highlights the core iteration process. It involves initializing the solution vector and then updating it based on the previous iteration’s calculated values, in turn, until a convergence criterion is met.\n\nUnderstanding convergence is critical to managing the iterations effectively. We’ll explore the convergence criteria, how to set and monitor them, and what to do when the method doesn’t converge.\n\nThe convergence criterion is a predetermined tolerance level that signifies when the solution is sufficiently close to the true one. Commonly used criteria include a specified number of significant figures or a percentage change.\n\nWhen the solution doesn’t converge, it’s important to change the initial guess, employ relaxation factors, or modify the equations. We will discuss these corrective actions and their implications on the solution process.\n\nExtending the method to handle nonlinear equations requires a different approach to the update rules. Learn how to adapt the algorithm to handle nonlinear relationships and still leverage its iterative benefits.\n\nWhen we encounter nonlinear systems, we must re-evaluate the factor updating rules at each iteration. We incorporate the latest values and changes to find the best approximation.\n\nConsiderations for different forms of nonlinear equations and their applications, such as root finding and optimization, shed light on the versatility of the Gauss-Seidel method beyond its linear roots.\n\nThis example extends the previous code sample to handle nonlinear equations using a nested function approach.\n\n% Initialize the solution vector 'x' with zeros and set the maximum number of iterations\n\n% Confirm convergence or take corrective action if necessary\n\nThis example shows how the Gauss-Seidel approach can be modified for nonlinear equations with only minor adjustments to the iterative procedure. By making only a few changes this code can solve several types of nonlinear systems and provide solutions that are accurate and efficient. In general, the Gauss-Seidel method still proves to be a powerful aid for circuit designers n modeling and analyzing complex circuits with precision. When with appropriate optimization methods and knowledge of its convergence properties, this approach may provide important ideas for circuit design solutions, which in turn, may result in better performance and functionality.\n\nThus, do not fear to implement the Gauss-Seidel method in your MATLAB-based simulations, so your design process will be improved, and you will have the best results. Happy coding! Therefore, we can now stop our tutorial on the Gauss-Seidel method in MATLAB. However, this is not all that can be learned from this mighty algorithm. Do not hesitate to look deeper into the more advanced methods and ways of application of the tool to attain an even greater effectiveness of your code optimization.\n\nApplication of the Gauss-Seidel Method in Engineering\n\nThe real-world applications of the Gauss-Seidel method in various engineering disciplines are plentiful. We will discuss specific examples in areas like structural mechanics, heat transfer, fluid dynamics, and more.\n\nDifferences and Considerations in Various Fields\n\nDifferent engineering domains require different approaches and considerations when applying numerical methods. Understanding these domain-specific requirements can refine the application of the Gauss-Seidel method.\n\nDifferences between Guass Seidel Method MATLAB Code with others\n\nUnderstanding the differences between the Gauss-Seidel method and other iterative techniques is crucial to selecting the right method for a given problem. We will highlight the main distinctions and how they influence performance and applicability.\n\nComparing the iterative strategies of Jacobi and Gauss-Seidel methods illuminates the nuanced strengths and weaknesses of each approach. Understanding these differences can help in selecting the most appropriate method for a given problem.\n\nComparison of a direct approach in Gaussian elimination with the iterative Gauss-Seidel method looks at the computational demand of each method and the tasks they are appropriate for. We use the Gauss elimination method to solve systems of linear equations. We convert the matrix into an upper triangular form using a series of row operations, and then solve it through back substitution to find the solution vectors. For larger systems, this process may be more computationally demanding since the process is based on matrix factorization and may require more memory.\n\nGauss-Seidel methodology is however basically an iterative process, which does not involve matrix transformations but rather refines the solution by immediate substitution of the most recent accessible values during the iteration.\n\nThis allows it to be highly space-efficient for very large systems since it does not require holding the entire coefficient matrix in memory, but rather depends on the previous iteration value for the next step. Each iteration can be quicker than performing row operations in the case of large matrices, but the method may need more iterations to achieve the required level of accuracy, especially when the system does not converge rapidly.\n\nAn insightful look into how the Newton-Raphson method differs and why it excels in solving systems of nonlinear equations. Understanding these differences helps to identify the best method for handling nonlinear systems in different scenarios.\n\nBelow is a curated list of resources where you can find sample MATLAB code and additional references for the Gauss-Seidel method. These resources are valuable for both beginners and advanced users, providing a range of examples that demonstrate the implementation of the Gauss-Seidel algorithm in MATLAB.\n• MathWorks File Exchange: MathWorks offers a community-driven platform where users can share custom MATLAB functions and applications. You can search for Gauss-Seidel implementations by visiting MathWorks File Exchange.\n• GitHub Repositories: GitHub is a hub for developers to maintain and share their code. A quick search for “Gauss-Seidel MATLAB” on GitHub yields numerous repositories containing implementations of the method.\n• Online Academic Resources: Educational institutions often share resources online. For instance, MIT OpenCourseWare includes course materials that may cover iterative methods in numerical computation. Check out relevant courses for potential code samples and further insights.\n• Coding Forums: Platforms like Stack Overflow and Reddit have active communities of MATLAB programmers. On these forums, you can find discussions and shared code related to the Gauss-Seidel method. Explore threads on Stack Overflow or subreddits like r/matlab.\n• Tutorial Websites: Sites like GeeksforGeeks, Tutorialspoint, and others provide tutorials and code examples for various algorithms, including the Gauss-Seidel method.\n\nBy exploring these references, you can enhance your understanding of the Gauss-Seidel method and incorporate the learned techniques into your MATLAB projects.\n\nThe provided URLs are for reference purposes and may require further navigation to reach specific content related to the Gauss-Seidel method.\n\nWhat is the Gauss-Seidel method?\n\nAn iterative numerical algorithm, the Gauss-Seidel method actively solves systems of linear and nonlinear equations. It operates on the concept of continually enhancing approximate solutions until it achieves convergence.\n\nHow does the Gauss-Seidel method work?\n\nThe method works by splitting a system of equations into smaller, simpler subproblems and solving them iteratively. In each iteration, the solution is updated using new values calculated from the previous iteration until a satisfactory level of accuracy is reached.\n\nWhat are some key advantages of the Gauss-Seidel method?\n• Firstly, it has a relatively simple implementation compared to other iterative methods. Moreover, it converges faster for certain types of systems, such as diagonally dominant systems.\n• Lastly, it can be easily adapted to handle nonlinear equations without significant changes to the iterative process."
    },
    {
        "link": "https://mathworks.com/help/matlab/matlab_prog/techniques-for-improving-performance.html",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/answers/518877-gauss-seidel-method-help",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/fileexchange/28226-successive-over-relaxation",
        "document": ""
    },
    {
        "link": "https://pgclasses.wordpress.com/2017/02/12/successive-over-relaxation-sor-method-in-matlab",
        "document": "लोड हो रहा है..."
    },
    {
        "link": "https://atozmath.com/example/conm/GaussEli.aspx?q=SOR2&q1=E1",
        "document": "1. Solve Equations 3x-y+z=-1,-x+3y-z=7,x-y+3z=-7 using SOR (Successive over-relaxation) method\n\n\n\nSolution:\n\nWe know that, for symmetric positive definite matrix the SOR method converges for values of the relaxation parameter `w` from the interval `0 < w < 2`\n\n\n\nThe iterations of the SOR method\n\n1. Total Equations are `3`\n\n\n\n`3x-y+z=-1`\n\n\n\n`-x+3y-z=7`\n\n\n\n`x-y+3z=-7`\n\n\n\n\n\n2. From the above equations, First write down the equations for Gauss Seidel method\n\n`x_(k+1)=1/3(-1+y_(k)-z_(k))`\n\n\n\n`y_(k+1)=1/3(7+x_(k+1)+z_(k))`\n\n\n\n`z_(k+1)=1/3(-7-x_(k+1)+y_(k+1))`\n\n\n\n3. Now multiply the right hand side by the parameter `w` and add to it the vector `x_k` from the previous iteration multiplied by the factor of `(1-w)`\n\n\n\n`x_(k+1)=(1-w)*x_(k)+w*1/3(-1+y_(k)-z_(k))`\n\n\n\n`y_(k+1)=(1-w)*y_(k)+w*1/3(7+x_(k+1)+z_(k))`\n\n\n\n`z_(k+1)=(1-w)*z_(k)+w*1/3(-7-x_(k+1)+y_(k+1))`\n\n\n\n4. Initial gauss `(x,y,z) = (0,0,0)` and `w=1.25`\n\n\n\nSolution steps are\n\n`1^(st)` Approximation\n\n\n\n`x_1=(1-1.25)*0+1.25*1/3[-1+(0)-(0)]=(-0.25)*0+1.25*1/3[-1]=0+-0.41667=-0.41667`\n\n\n\n`y_1=(1-1.25)*0+1.25*1/3[7+(-0.41667)+(0)]=(-0.25)*0+1.25*1/3[6.58333]=0+2.74306=2.74306`\n\n\n\n`z_1=(1-1.25)*0+1.25*1/3[-7-(-0.41667)+(2.74306)]=(-0.25)*0+1.25*1/3[-3.84028]=0+-1.60012=-1.60012`\n\n\n\n`2^(nd)` Approximation\n\n\n\n`x_2=(1-1.25)*-0.41667+1.25*1/3[-1+(2.74306)-(-1.60012)]=(-0.25)*-0.41667+1.25*1/3[3.34317]=0.10417+1.39299=1.49715`\n\n\n\n`y_2=(1-1.25)*2.74306+1.25*1/3[7+(1.49715)+(-1.60012)]=(-0.25)*2.74306+1.25*1/3[6.89704]=-0.68576+2.87377=2.188`\n\n\n\n`z_2=(1-1.25)*-1.60012+1.25*1/3[-7-(1.49715)+(2.188)]=(-0.25)*-1.60012+1.25*1/3[-6.30915]=0.40003+-2.62881=-2.22878`\n\n\n\n`3^(rd)` Approximation\n\n\n\n`x_3=(1-1.25)*1.49715+1.25*1/3[-1+(2.188)-(-2.22878)]=(-0.25)*1.49715+1.25*1/3[3.41679]=-0.37429+1.42366=1.04937`\n\n\n\n`y_3=(1-1.25)*2.188+1.25*1/3[7+(1.04937)+(-2.22878)]=(-0.25)*2.188+1.25*1/3[5.82059]=-0.547+2.42524=1.87824`\n\n\n\n`z_3=(1-1.25)*-2.22878+1.25*1/3[-7-(1.04937)+(1.87824)]=(-0.25)*-2.22878+1.25*1/3[-6.17113]=0.5572+-2.5713=-2.01411`\n\n\n\n`4^(th)` Approximation\n\n\n\n`x_4=(1-1.25)*1.04937+1.25*1/3[-1+(1.87824)-(-2.01411)]=(-0.25)*1.04937+1.25*1/3[2.89235]=-0.26234+1.20515=0.9428`\n\n\n\n`y_4=(1-1.25)*1.87824+1.25*1/3[7+(0.9428)+(-2.01411)]=(-0.25)*1.87824+1.25*1/3[5.9287]=-0.46956+2.47029=2.00073`\n\n\n\n`z_4=(1-1.25)*-2.01411+1.25*1/3[-7-(0.9428)+(2.00073)]=(-0.25)*-2.01411+1.25*1/3[-5.94207]=0.50353+-2.47586=-1.97234`\n\n\n\n`5^(th)` Approximation\n\n\n\n`x_5=(1-1.25)*0.9428+1.25*1/3[-1+(2.00073)-(-1.97234)]=(-0.25)*0.9428+1.25*1/3[2.97307]=-0.2357+1.23878=1.00308`\n\n\n\n`y_5=(1-1.25)*2.00073+1.25*1/3[7+(1.00308)+(-1.97234)]=(-0.25)*2.00073+1.25*1/3[6.03074]=-0.50018+2.51281=2.01263`\n\n\n\n`z_5=(1-1.25)*-1.97234+1.25*1/3[-7-(1.00308)+(2.01263)]=(-0.25)*-1.97234+1.25*1/3[-5.99045]=0.49308+-2.49602=-2.00294`\n\n\n\n`6^(th)` Approximation\n\n\n\n`x_6=(1-1.25)*1.00308+1.25*1/3[-1+(2.01263)-(-2.00294)]=(-0.25)*1.00308+1.25*1/3[3.01556]=-0.25077+1.25648=1.00572`\n\n\n\n`y_6=(1-1.25)*2.01263+1.25*1/3[7+(1.00572)+(-2.00294)]=(-0.25)*2.01263+1.25*1/3[6.00278]=-0.50316+2.50116=1.998`\n\n\n\n`z_6=(1-1.25)*-2.00294+1.25*1/3[-7-(1.00572)+(1.998)]=(-0.25)*-2.00294+1.25*1/3[-6.00771]=0.50073+-2.50321=-2.00248`\n\n\n\n`7^(th)` Approximation\n\n\n\n`x_7=(1-1.25)*1.00572+1.25*1/3[-1+(1.998)-(-2.00248)]=(-0.25)*1.00572+1.25*1/3[3.00048]=-0.25143+1.2502=0.99877`\n\n\n\n`y_7=(1-1.25)*1.998+1.25*1/3[7+(0.99877)+(-2.00248)]=(-0.25)*1.998+1.25*1/3[5.99629]=-0.4995+2.49845=1.99895`\n\n\n\n`z_7=(1-1.25)*-2.00248+1.25*1/3[-7-(0.99877)+(1.99895)]=(-0.25)*-2.00248+1.25*1/3[-5.99982]=0.50062+-2.49992=-1.9993`\n\n\n\n`8^(th)` Approximation\n\n\n\n`x_8=(1-1.25)*0.99877+1.25*1/3[-1+(1.99895)-(-1.9993)]=(-0.25)*0.99877+1.25*1/3[2.99826]=-0.24969+1.24927=0.99958`\n\n\n\n`y_8=(1-1.25)*1.99895+1.25*1/3[7+(0.99958)+(-1.9993)]=(-0.25)*1.99895+1.25*1/3[6.00028]=-0.49974+2.50012=2.00038`\n\n\n\n`z_8=(1-1.25)*-1.9993+1.25*1/3[-7-(0.99958)+(2.00038)]=(-0.25)*-1.9993+1.25*1/3[-5.9992]=0.49983+-2.49967=-1.99984`\n\n\n\n`9^(th)` Approximation\n\n\n\n`x_9=(1-1.25)*0.99958+1.25*1/3[-1+(2.00038)-(-1.99984)]=(-0.25)*0.99958+1.25*1/3[3.00022]=-0.2499+1.25009=1.0002`\n\n\n\n`y_9=(1-1.25)*2.00038+1.25*1/3[7+(1.0002)+(-1.99984)]=(-0.25)*2.00038+1.25*1/3[6.00035]=-0.50009+2.50015=2.00005`\n\n\n\n`z_9=(1-1.25)*-1.99984+1.25*1/3[-7-(1.0002)+(2.00005)]=(-0.25)*-1.99984+1.25*1/3[-6.00014]=0.49996+-2.50006=-2.0001`\n\n\n\n\n\nSolution By SOR (successive over-relaxation) method.\n\n`x=1.0002~=1`\n\n\n\n`y=2.00005~=2`\n\n\n\n`z=-2.0001~=-2`\n\n\n\nIntertions are tabulated as below\n\n \n\n \n\n We know that, for symmetric positive definite matrix the SOR method converges for values of the relaxation parameter `w` from the interval `0 < w < 2`The iterations of the SOR method1. Total Equations are `3``3x-y+z=-1``-x+3y-z=7``x-y+3z=-7`2. From the above equations, First write down the equations for Gauss Seidel method`x_(k+1)=1/3(-1+y_(k)-z_(k))``y_(k+1)=1/3(7+x_(k+1)+z_(k))``z_(k+1)=1/3(-7-x_(k+1)+y_(k+1))`3. Now multiply the right hand side by the parameter `w` and add to it the vector `x_k` from the previous iteration multiplied by the factor of `(1-w)``x_(k+1)=(1-w)*x_(k)+w*1/3(-1+y_(k)-z_(k))``y_(k+1)=(1-w)*y_(k)+w*1/3(7+x_(k+1)+z_(k))``z_(k+1)=(1-w)*z_(k)+w*1/3(-7-x_(k+1)+y_(k+1))`4. Initial gauss `(x,y,z) = (0,0,0)` and `w=1.25`Solution steps are`1^(st)` Approximation`x_1=(1-1.25)*0+1.25*1/3[-1+(0)-(0)]=(-0.25)*0+1.25*1/3[-1]=0+-0.41667=-0.41667``y_1=(1-1.25)*0+1.25*1/3[7+(-0.41667)+(0)]=(-0.25)*0+1.25*1/3[6.58333]=0+2.74306=2.74306``z_1=(1-1.25)*0+1.25*1/3[-7-(-0.41667)+(2.74306)]=(-0.25)*0+1.25*1/3[-3.84028]=0+-1.60012=-1.60012``2^(nd)` Approximation`x_2=(1-1.25)*-0.41667+1.25*1/3[-1+(2.74306)-(-1.60012)]=(-0.25)*-0.41667+1.25*1/3[3.34317]=0.10417+1.39299=1.49715``y_2=(1-1.25)*2.74306+1.25*1/3[7+(1.49715)+(-1.60012)]=(-0.25)*2.74306+1.25*1/3[6.89704]=-0.68576+2.87377=2.188``z_2=(1-1.25)*-1.60012+1.25*1/3[-7-(1.49715)+(2.188)]=(-0.25)*-1.60012+1.25*1/3[-6.30915]=0.40003+-2.62881=-2.22878``3^(rd)` Approximation`x_3=(1-1.25)*1.49715+1.25*1/3[-1+(2.188)-(-2.22878)]=(-0.25)*1.49715+1.25*1/3[3.41679]=-0.37429+1.42366=1.04937``y_3=(1-1.25)*2.188+1.25*1/3[7+(1.04937)+(-2.22878)]=(-0.25)*2.188+1.25*1/3[5.82059]=-0.547+2.42524=1.87824``z_3=(1-1.25)*-2.22878+1.25*1/3[-7-(1.04937)+(1.87824)]=(-0.25)*-2.22878+1.25*1/3[-6.17113]=0.5572+-2.5713=-2.01411``4^(th)` Approximation`x_4=(1-1.25)*1.04937+1.25*1/3[-1+(1.87824)-(-2.01411)]=(-0.25)*1.04937+1.25*1/3[2.89235]=-0.26234+1.20515=0.9428``y_4=(1-1.25)*1.87824+1.25*1/3[7+(0.9428)+(-2.01411)]=(-0.25)*1.87824+1.25*1/3[5.9287]=-0.46956+2.47029=2.00073``z_4=(1-1.25)*-2.01411+1.25*1/3[-7-(0.9428)+(2.00073)]=(-0.25)*-2.01411+1.25*1/3[-5.94207]=0.50353+-2.47586=-1.97234``5^(th)` Approximation`x_5=(1-1.25)*0.9428+1.25*1/3[-1+(2.00073)-(-1.97234)]=(-0.25)*0.9428+1.25*1/3[2.97307]=-0.2357+1.23878=1.00308``y_5=(1-1.25)*2.00073+1.25*1/3[7+(1.00308)+(-1.97234)]=(-0.25)*2.00073+1.25*1/3[6.03074]=-0.50018+2.51281=2.01263``z_5=(1-1.25)*-1.97234+1.25*1/3[-7-(1.00308)+(2.01263)]=(-0.25)*-1.97234+1.25*1/3[-5.99045]=0.49308+-2.49602=-2.00294``6^(th)` Approximation`x_6=(1-1.25)*1.00308+1.25*1/3[-1+(2.01263)-(-2.00294)]=(-0.25)*1.00308+1.25*1/3[3.01556]=-0.25077+1.25648=1.00572``y_6=(1-1.25)*2.01263+1.25*1/3[7+(1.00572)+(-2.00294)]=(-0.25)*2.01263+1.25*1/3[6.00278]=-0.50316+2.50116=1.998``z_6=(1-1.25)*-2.00294+1.25*1/3[-7-(1.00572)+(1.998)]=(-0.25)*-2.00294+1.25*1/3[-6.00771]=0.50073+-2.50321=-2.00248``7^(th)` Approximation`x_7=(1-1.25)*1.00572+1.25*1/3[-1+(1.998)-(-2.00248)]=(-0.25)*1.00572+1.25*1/3[3.00048]=-0.25143+1.2502=0.99877``y_7=(1-1.25)*1.998+1.25*1/3[7+(0.99877)+(-2.00248)]=(-0.25)*1.998+1.25*1/3[5.99629]=-0.4995+2.49845=1.99895``z_7=(1-1.25)*-2.00248+1.25*1/3[-7-(0.99877)+(1.99895)]=(-0.25)*-2.00248+1.25*1/3[-5.99982]=0.50062+-2.49992=-1.9993``8^(th)` Approximation`x_8=(1-1.25)*0.99877+1.25*1/3[-1+(1.99895)-(-1.9993)]=(-0.25)*0.99877+1.25*1/3[2.99826]=-0.24969+1.24927=0.99958``y_8=(1-1.25)*1.99895+1.25*1/3[7+(0.99958)+(-1.9993)]=(-0.25)*1.99895+1.25*1/3[6.00028]=-0.49974+2.50012=2.00038``z_8=(1-1.25)*-1.9993+1.25*1/3[-7-(0.99958)+(2.00038)]=(-0.25)*-1.9993+1.25*1/3[-5.9992]=0.49983+-2.49967=-1.99984``9^(th)` Approximation`x_9=(1-1.25)*0.99958+1.25*1/3[-1+(2.00038)-(-1.99984)]=(-0.25)*0.99958+1.25*1/3[3.00022]=-0.2499+1.25009=1.0002``y_9=(1-1.25)*2.00038+1.25*1/3[7+(1.0002)+(-1.99984)]=(-0.25)*2.00038+1.25*1/3[6.00035]=-0.50009+2.50015=2.00005``z_9=(1-1.25)*-1.99984+1.25*1/3[-7-(1.0002)+(2.00005)]=(-0.25)*-1.99984+1.25*1/3[-6.00014]=0.49996+-2.50006=-2.0001`Solution By SOR (successive over-relaxation) method.`x=1.0002~=1``y=2.00005~=2``z=-2.0001~=-2`Intertions are tabulated as below This material is intended as a summary. Use your textbook for detail explanation. \n\nAny bug, improvement, feedback then"
    },
    {
        "link": "https://codewithc.com/successive-over-relaxation-sor-method-in-matlab?amp=1",
        "document": "Successive Over-Relaxation Method, also known as SOR method, is popular iterative method of linear algebra to solve linear system of equations. This method is the generalization of improvement on Gauss Seidel Method. Being extrapolated from Gauss Seidel Method, this method converges the solution faster than other iterative methods.\n\nIn this tutorial, we’re going to write a program for Successive Over-Relaxation – SoR method in MATLAB, and go through its mathematical derivation and theoretical background.\n\nConsider the following sets of liner equations:\n\nExpress these equations in the form: Ax = b\n\nNow, decompose matrix A into Diagonal component matrix D, Lower triangular matrix L, and upper triangular matrix U, such that:\n\nWhere, ω is the relaxation factor and ω > 1\n\nDuring the iteration process, the left hand side of the equation is solved by using the previous value for x on right hand side.\n\nThe iteration equation is expressed analytically as:\n\nWhere, x(k) is the kth approximation for x and x(k+1) is (k+1)th approximation for x.\n\nTaking the advantage of triangular matrix form of ( D + ωL), the (k+1)th can be evaluated sequentially by using forward substitution. The expression obtained for x(k+1) is:\n\nThe above code for Successive Over-Relaxation method in Matlab for solving linear system of equation is a three input program. Here, matrix A, matrix B, and relaxation parameter ω are the input to the program. The user defined function in the program proceeds with input arguments A and B and gives output X.\n\nWhen the program is executed in MATLAB workspace, it asks for the value of coefficient matrix A and checks if it is square matrix or not. After getting valid input for A, another input matrix B is required to be entered to the program which must be a column matrix. Finally, the relaxation parameter is given as input and solution of linear equation comes as output.\n\nWhile giving input to the program, the standard MATLAB syntaxes must be obeyed. Here’s a sample output of the MATLAB program for SOR method:\n\nIn this output of the Matlab program, 2x + y – z = 8, -3x – y + 2z = -11, and -2x + y +2z = -3 have been tried to be solved. But, the largest Eigen value of iterative matrix is not less than 1. As a result of which, the problem here is not suitable for SOR method."
    },
    {
        "link": "https://dspace.mit.edu/bitstream/handle/1721.1/75282/18-335j-fall-2006/contents/lecture-notes/lec18handout6pp.pdf",
        "document": ""
    }
]