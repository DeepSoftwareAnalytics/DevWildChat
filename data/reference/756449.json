[
    {
        "link": "https://demonstrations.wolfram.com/AddingPointsOnAnEllipticCurve",
        "document": ""
    },
    {
        "link": "https://library.wolfram.com/infocenter/Conferences/9260",
        "document": ""
    },
    {
        "link": "https://mathematica.stackexchange.com/questions/292964/adding-points-on-an-elliptic-curve",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    },
    {
        "link": "https://mathematica.stackexchange.com/questions/127779/plotting-the-sum-of-two-points-on-an-elliptic-curve",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    },
    {
        "link": "https://eprint.iacr.org/2015/1060.pdf",
        "document": ""
    },
    {
        "link": "https://martin.kleppmann.com/papers/curve25519.pdf",
        "document": ""
    },
    {
        "link": "https://mathematica.stackexchange.com/questions/43771/elliptic-curve-cryptography-in-mathematica",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    },
    {
        "link": "https://mdpi.com/1424-8220/24/3/1030",
        "document": "Elliptic curve cryptography (ECC) has been deployed as the main asymmetric cryptographic primitive to secure various systems. Notably, transport layer security (TLS) 1.3 [ 1 ] added elliptic curve Diffie–Hellman key exchange (ECDHE) in the base specification, and it removed RSA-based cipher suites. Secure messaging applications like Signal and WhatsApp rely on ECC for their end-to-end encryption (E2EE) protocols. Signal additionally makes heavy use of ECC in its private group system [ 2 ] and its sealed unidentified delivery system [ 3 ], which greatly improves the security for Signal users. ECC is appealing in those settings because of its unmatched performance and security properties. An -bit secure elliptic curve key can be encoded in bits, with being a small number. This means that for the typical 128-bit security level, a key can be encoded in only 32 bytes. Even considering the high potential throughput of ECC operations, a carefully optimised implementation of ECC algorithms is beneficial. In some applications—for example, zero-knowledge proofs (e.g., Bulletproofs [ 4 ])—thousands of ECC operations need to be carried out as efficiently as possible. Other applications might run on battery-powered devices and benefit from consuming as little power as possible for executing these computations. In this article, we aim to improve the performance of the extended twisted Edwards curve of Curve25519 [ 5 ]. Curve25519 is one of the fastest curves in the literature. Since it is not covered by any patent [ 5 ], it has quickly gained popularity in many different applications. This article proposes a highly efficient implementation of Curve25519 elliptic curve operations for ARM processors since they are by far the most widely used processors in smartphone and tablet devices. Our proposed improvements help compensate for the limited processing power of such handheld devices. We specifically target ARM processors that support the ARM NEON single instruction, multiple data (SIMD) instruction set. We show an improvement in performance of 20%. The main contributions in this article are the following:\n• None We present an adaption of the parallel formulae for extended twisted Edwards curves by Hisil et al. [ 6 ] for ARM processors by designing a new representation for an elliptic curve point using ARM NEON vectors.\n• None We provide an open source implementation of those formulae in the Dalek cryptography Curve25519 Rust library [ 7 8 ].\n• None We perform a performance analysis of our implementation on multiple ARM devices, demonstrating a significant speed-up.\n\nECC is a popular technique for securing digital communication [ 9 ]. It is used in a range of cryptographic primitives, such as key agreement protocols, signatures, and zero-knowledge proofs (ZKPs) [ 10 ]. One of the key challenges in implementing ECC is the implementation of fast modular arithmetic operations, which can be optimised for specific microarchitectures [ 11 ]. Several articles have investigated the optimisation of ECC for specific hardware platforms. Our work builds on the previous efforts of Bernstein [ 5 ], Bernstein and Schwabe [ 9 ], and Hisil et al. [ 6 ]. Bernstein and Schwabe [ 9 ] describe the use of NEON vector instructions on ARM processors. Our library utilises the methods for multiplication described by Bernstein and Schwabe [ 9 ] for multiplication, reduction, and squaring within Curve25519. Instead of pure assembly, it uses a mix of Rust and assembly instructions and takes into account our new representation. Hisil et al. [ 6 ] propose a new addition algorithm for extended twisted Edwards curves that can be computed using four processors for an even faster implementation. We use this algorithm with Curve25519 [ 5 ] with our new representation for elliptic curve points. Notable parallels can be drawn between our efforts and those outlined in related studies, although there are some key differences. Hamburg [ 12 ] introduced a swift and resource-efficient implementation of elliptic curve cryptography (ECC), albeit lacking ARM NEON instructions. Faz-Hernández et al. [ 13 ] harnessed AVX2 SIMD vector instructions, yielding substantial performance enhancements for ECC on contemporary Intel x86-64 architectures. In a similar vein, Cheng et al. [ 14 ] introduced a throughput-optimised AVX2 implementation of variable-base scalar multiplication. It is important to note that none of these references involve the utilisation of the parallel formulae of Hisil et al. [ 6 ]. Goetschmann et al. [ 15 ] leveraged Intel Skylake floating-point arithmetic to expedite elliptic curve algorithms, although without SIMD instructions. Our approach, in contrast, relies on integer arithmetic. Meanwhile, Dong et al. [ 16 ] achieved performance gains through an alternative avenue: harnessing embedded graphical processing units (GPUs). Another body of research has concentrated on optimising ECC specifically for ARM processor architectures. Luc et al. [ 17 ] devised a technique to enhance point arithmetic efficiency on elliptic curves using ARM processors and NEON instructions. Additionally, Longa [ 18 ] introduced FourQNEON: an accelerated ECC scalar multiplication algorithm tailored for ARM processors. Our work differs from these previous optimisations for ARM NEON in that we create a new representation specifically for the parallel formulae of Hisil et al. [ 6 ] that works for ARM NEON. An overview of these related works is presented in Table 1 We target to improve the speed of the ECC algorithms using NEON, specifically by using the parallel formula for extended twisted Edwards curves proposed by Hisil et al. [ 6 ] relying on an ARM NEON SIMD representation. We do this by implementing a Curve25519 back-end in a widely used Rust library, curve25519-dalek [ 7 ], targeting the ARM NEON SIMD architecture. We evaluate the performance on a range of ARM devices and compare our results to the state-of-the-art implementation without SIMD.\n\nIn this section, we first explain the different elliptic curve operations in the context of extended twisted Edwards curves. We then elaborate on how SIMD operations are currently implemented in the curve25519-dalek library for these operations. In Section 4 , we build on this knowledge for speeding up the ECC operations, both using SIMD in a general way and specifically for ARM NEON. The security of elliptic curve cryptography is based on the discrete logarithm assumption. This assumption states that multiplication of a point on the elliptic curve by a scalar , where , is easy, but if knowing only and , it is generally very hard to find in polynomial time. This problem is known as the (elliptic curve) discrete logarithm problem, and it allows elliptic curves to be used in cryptography as a public key cryptosystem. . For any two points, we can create their sum by drawing a line through them and mirroring along the -axis where the curve and the line intersect in a third point (by negating the coordinate). This is illustrated in Elliptic curves are a group of points that satisfy a specific equation: most commonly, the simplified Weierstrass equation. For any two points, we can create their sum by drawing a line through them and mirroring along the-axis where the curve and the line intersect in a third point (by negating thecoordinate). This is illustrated in Figure 1 . This figure also shows the addition of a point with itself, in which case the tangent along the curve is used as the line; this operation is called point doubling. Note that Figure 1 shows a continuous curve, whereas for cryptographic purposes, curves are defined over a finite field, but the properties for addition still hold. . Conforming to the geometric construction of the addition and doubling, the following are the formulae to perform these operations: From this addition, we can define multiplication of a point by a scalar as a series of additions and doublings: for example,. Conforming to the geometric construction of the addition and doubling, the following are the formulae to perform these operations: . The points on this curve consist of four coordinates, , and there is a single formula for doubling and addition: The above simplified Weierstrass equation and addition and doubling formulae have several shortcomings in the context of cryptography. First, the addition and doubling formulae are different. This leads to vulnerabilities such as side channel attacks [ 19 ], as by knowing the series of additions and doublings that was used, an attacker can uniquely restructure and derive the original scalar. The formulae given above are also lengthy, which is a disadvantage when they need to be repeated often. Researchers have looked for faster formulae that use fewer operations to achieve the same result. This has led to alternative curve representations, such as extended twisted Edwards curves [ 6 ], for which the curve equation is. The points on this curve consist of four coordinates,, and there is a single formula for doubling and addition: , where is a large prime. This cofactor can lead to vulnerabilities such as small-subgroup attacks, which should be taken into account [ With this representation, more coordinates per point need to be tracked, but operations are faster as there are fewer field operations in the formula. However, a new problem is introduced by the fact that the order of extended twisted Edwards curves is not prime. These curves generally have a cofactor of 8, which means the order of the curve is, whereis a large prime. This cofactor can lead to vulnerabilities such as small-subgroup attacks, which should be taken into account [ 20 ]. These can be mitigated by ensuring that the points used in cryptographic operations are in the correct subgroup. This can be done using a costly multiplication or by using optimised methods such as Ristretto [ 21 ], which is based on the Decaf method of Hamburg [ 20 ]. The advantages of the speed-up generally outweigh the drawbacks of cofactor elimination methods, especially since the extended twisted Edwards coordinates have additional optimisations using parallel computation. + = can be written as the parallel formula seen in is a predetermined constant) as formulated by Hisil et al. [ The extended twisted Edwards addition formula forcan be written as the parallel formula seen in Table 2 using four processors (is a predetermined constant) as formulated by Hisil et al. [ 6 ]: In the cost column, represents a multiplication in the field, and is a multiplication by a known scalar. This algorithm describes a way to add two curve points in only five steps and with a cost of . In reality, the algorithm cannot be split over four separate processing units due to the need to synchronise after every step, which introduces too large an overhead. Fortunately, SIMD instructions provide a way to execute this optimised algorithm. We are able to represent each column in the parallel formula above as a sub-vector in a larger SIMD vector. On each of these sub-vectors, the same operation can be executed simultaneously, such as addition or multiplication with another SIMD vector or multiplication with a constant. This operation happens pair-wise, i.e., the first sub-vector of the first SIMD vector will be added to the first sub-vector of the second SIMD vector. Curve25519 [ 5 ] was specifically designed to be fast by having efficient formulae. At the same time, Curve25519 avoids many implementation-related vulnerabilities. Such vulnerabilities include side-channel attacks and certain algebraic attacks. This specific design of the curve avoids some of these side-channel attacks, as described by Fan et al. [ 22 ] and Abarzúa et al. [ 23 ]. Countermeasures against other side-channel attacks still rely on the implementation. Avoiding these other side-channel attacks is out of the scope of this paper. However, the implementation described in this paper is based on an already existing popular implementation of Curve25519 that has no known vulnerabilities. It uses algorithms that are known to be safe against timing-based attacks. Our implementation, which adapts these algorithms, should, in theory, have the same safety. The speed and security of Curve25519 derive from specifically chosen properties such as the field size and the fixed-base point that allow for efficient arithmetic operations while remaining secure. Curve25519 is a curve over the finite prime field of order with the following Weierstrass equation: , which translates into the extended twisted Edwards equation of: . Operations in the field of this elliptic curve are done with 255-bit numbers. To represent them inside our algorithm, we can split these numbers into 10 numbers with radixes of . In reality, these will be alternatively 25- and 26-bit numbers and radixes. Since CPU representations that contain these numbers will be at least 32 bits, there are some unused bits after each number. These are useful to ensure that algorithms need to do fewer reductions to field size. This leads to an increase in performance compared to an implementation with a larger radix and more reductions. The polynomial representation for a field element takes the form of , where each component of is referred to as a . This representation illustrates how addition and multiplication operations should be performed when the field element is divided into limbs, as it is equivalent to performing these operations on the polynomials. to but also additional terms ranging from to . The to terms can be reduced by multiplying the resulting term with . This follows from: When two of these polynomials are multiplied together, the resulting polynomial will contain terms fromtobut also additional terms ranging fromto. Thetoterms can be reduced by multiplying the resulting term with. This follows from: This effectively reduces the -index of these terms by 10, so the term of is added to the term of , to , … This representation and these reduction techniques are exactly how we will represent and reduce field elements using SIMD. To add two polynomials together, terms of the same power are added together, whereas in a SIMD addition, sub-vectors with the same index in two SIMD vectors are added together.\n\nSIMD allows us to perform a single instruction on multiple elements in a SIMD vector at the same time. This is applied in the curve255119-dalek library with the parallel extended twisted Edwards formulae for the AVX2 architecture. We implement Hisil et al. [ 6 ] for ARM NEON, creating a new representation accounting for the 128-bit SIMD vector size. We will first discuss how elliptic curve points and field elements are represented in the library. In Section 3 , we discussed how a field element is split into ten pieces of 32 bits with some unused bits per limb. These unused bits are used to extend the bound of the field order so that after some operations, such as addition, these bits are used instead of performing a reduction step. Using these bits, we can delay the costly reduction step as long as possible. This distribution is represented in Figure 2 , we can divide each element into limbs to . This results in the structure shown in . In this representation, we call each column a . Every limb is not immediately put in the first open place in a vector. This follows from the fact that in the extended twisted Edwards representation, every point is constructed of four field elements and that we have to distribute the ten limbs of each of those four elements over the SIMD vectors. First, we will consider the already implemented case in the existing curve25519-library, for which these SIMD vectors are 256 bits long in the AVX2 architecture. These 256-bit vectors can only hold 8 limbs, so we will need 5 vectors to hold all 40 limbs of the four field elements of an elliptic curve point projective representation. If we have four field elements, we can divide each elementinto limbsto. This results in the structure shown in Figure 3 , where each row represents a SIMD vector consisting of the limbs. In this representation, we call each column a are distributed in the vectors as follows: This table of five 256-bit SIMD vectors now holds all the information about a single elliptic curve point. The limbsare distributed in the vectorsas follows: and lanes and bit-shifting by 32 to the left, as can be seen in and limbs, substitute them with 0, place them in a new vector in the same place as the and limbs would be, and fill the rest with 0 again. This representation makes multiplication between elliptic point tables easier. When we multiply two 32-bit numbers together, the result will be a 64-bit number. Because our SIMD operations happen on the whole vector at the same time, a multiplication would be impossible without losing information when using the default above representation because there is not enough space. However, this representation allows us to easily double the number of vectors by extracting theandlanes and bit-shifting by 32 to the left, as can be seen in Figure 4 . In other words, we take out all theandlimbs, substitute them with 0, place them in a new vector in the same place as theandlimbs would be, and fill the rest with 0 again. After a multiplication of two limbs, those zeroed sub-vectors will be filled with the higher 32 bits of the 64-bit result of the multiplication. This 64-bit result can then be reduced modulo the field order, which reduces each limb once again to 32 bits, and put back in the default representation by interweaving the vectors: effectively the reverse of the operations seen in Figure 4 For our representation using ARM NEON, we only have vectors of 128 bits to work with. To keep using the same techniques, we have split the representation of a point into two tables. This would theoretically double the number of operations in algorithms compared to an implementation without this split. An elliptic curve point representation previously consisting of five SIMD vectors will now use ten, and since each operation on such a representation applies over all SIMD vectors, the number of operations is doubled. There are some cases in which we can make use of the split of tables without drawbacks—or even to our advantage. For example, switching the and lanes with the and lanes is equivalent to trivially swapping the two variables holding each table in memory. This is significantly simpler and more efficient than the equivalent SIMD operation to rearrange these vectors. This swapping of lanes is necessary when an operation needs to happen between two different lanes of two elliptic curve point tables, e.g., the and lanes. When we want to add what is in the lane of one representation to what is in the lane of the other, we would have to place the lane in the lane or vice versa. Operations such as addition happen pair-wise between lanes of two representations—the lane of the first gets added to the lane of the second—so if we want to add a different lane, we need to swap it first. This swapping and other techniques we used for optimisation will be further discussed in Section 4.3 . First, we will present the functions in which our back-end is used and how it is used. to an . An is the elliptic curve point representation as discussed above. A is the same, but it has some pre-computed variables. This follows from the parallel formula seen in Our goal when speeding up ECC is to make the scalar multiplication faster. This scalar multiplication is done using an algorithm that utilises the addition algorithm between two elliptic curve points. This addition algorithm uses our back-end. The addition algorithm of the curve25519-dalek [ 7 ] library adds ato an. Anis the elliptic curve point representation as discussed above. Ais the same, but it has some pre-computed variables. This follows from the parallel formula seen in Table 2 , where the first steps only use the elements of one elliptic curve point at a time; thus, when using the same elliptic curve point multiple times for addition in a row, it is more efficient to pre-compute this step. from a point , we execute the following steps Algorithm 1. The value 121666 in this algorithm is the constant in the parallel formula. To create afrom a point, we execute the following steps Algorithm 1. The value 121666 in this algorithm is the constantin the parallel formula. Step 2 gives us a . To add two elliptic curve points, and , we first transform into a : . Then, we follow the steps in Algorithm 2 to perform the elliptic curve point addition of . . Some steps are omitted in the above algorithms that are necessary when executing them with SIMD vectors. We treat each element in a SIMD vector, such as , as a separate variable that we can move and manipulate. In reality, these are all stored in a singular SIMD vector, and moving and performing operations on them is a bit more involved. For example, on Line 3 of Algorithm 1 and Line 4 of Algorithm 2, we perform the operation . All the separate steps required for this operation with SIMD are given in Algorithm 3. This yields the same results as the parallel formula of Hisil et al. [ 6 ], with a slightly different execution order due to the. Some steps are omitted in the above algorithms that are necessary when executing them with SIMD vectors. We treat each element in a SIMD vector, such as, as a separate variable that we can move and manipulate. In reality, these are all stored in a singular SIMD vector, and moving and performing operations on them is a bit more involved. For example, on Line 3 of Algorithm 1 and Line 4 of Algorithm 2, we perform the operation. All the separate steps required for this operation with SIMD are given in Algorithm 3. Algorithm 3 SIMD instructions necessary to calculate from In Algorithm 3, we use functions in Lines 2–5 to perform operations on the SIMD vector. These are the functions in which we use ARM NEON intrinsics to optimise performance. They are further explained in Section 4.3 We have optimised functions such as “shuffle”, “negate”, “blend”, and “add” seen in Algorithm 3 for ARM NEON. These optimisations are based on the adaptation of the the back-end for the Intel AVX2 SIMD vector instructions such that it can use our ARM NEON representation and specific instructions. They all happen in the of the elliptic curve: e.g., adding two of our representations means adding the sub-vectors pair-wise and not performing an elliptic curve point addition. Below, we will discuss these field algorithms. and returns a new sequence of lanes according to a control sequence: for example, or . The problem with our representation of a two SIMD vector solution is that lanes that are stored in the first vector might need to be swapped with lanes in the second vector. To account for this, we give both SIMD vectors of our representation to the macro of the Rust crate [ once for each SIMD vector, so twice in total. We could use the ARM NEON intrinsic, which can also combine two SIMD vectors by reordering every 8 bits according to a third input vector; however, this instruction is slow according to the specification. This instruction would only be preferable if it is necessary to reorder every sub-vector of 8 bits instead of the sub-vectors of 32 bits we work with. Instead, it is better to use multiple other instructions to get the same result. The shuffle function takes an input set of field elementsand returns a new sequence of lanes according to a control sequence: for example,or. The problem with our representation of a two SIMD vector solution is that lanes that are stored in the first vector might need to be swapped with lanes in the second vector. To account for this, we give both SIMD vectors of our representation to themacro of the Rustcrate [ 24 ]. We do thisonce for each SIMD vector, so twice in total. We could use theARM NEON intrinsic, which can also combine two SIMD vectors by reordering every 8 bits according to a third input vector; however, this instruction is slow according to the specification. This instruction would only be preferable if it is necessary to reorder every sub-vector of 8 bits instead of the sub-vectors of 32 bits we work with. Instead, it is better to use multiple other instructions to get the same result. This is what the macro does. It first lowers to the LLVM instruction, which becomes a sequence of assembly instructions using ARM NEON intrinsics such as and to get the desired reordering of the vectors. The instructions and combine vectors by taking, respectively, the even- or odd-numbered sub-vectors from the first input vector and vice versa for the second input vector. This, combined with some instructions to extract and insert sub-vectors from the SIMD vector, gives us our wanted output. Blend behaves in much the same way as shuffle but merges two field elements together based on an input. For example, given two field elements and and an input lane C, returns as the C input as dictated by the C lane being taken from the second input field element. This function is performed using the macro with some optimisations. A naive implementation would use twice to combine the first SIMD vectors of the inputs and then again for the second vectors. However, this is not always necessary. When taking everything from the first SIMD vector from the first input and everything from the second SIMD vector from the second input or vice versa, we can simply take those SIMD vectors as our output without having to perform a shuffle. Similarly, when taking only one lane from the first or second input, only the SIMD vector holding that lane has to be shuffled, and we can directly take the other vector. This input that decides how to blend the lanes or how to reorder in the function is determined by the formula in which it is used. Thus, it is always known at compile time and does not raise issues of not being constant time as it does not depend on the input of which points are used with the algorithm. To negate within the finite field, we subtract the field element from a multiple of the field order. The multiple of the field order is taken to avoid an underflow as for any integer with field order . In certain algorithms when we know the bounds are low, we can perform a lazy negation with and without a reduction, ensuring that the bound stays low. Otherwise, if the bounds are high, we can perform a reduction with and perform a reduction afterwards. This still requires knowing the bounds beforehand, as we cannot exceed the field size. This implementation is equivalent to the AVX2 implementation. . This is done by splitting each vector up into two, with each vector taking every other limb, as seen in , which combines two vectors into one. In order to multiply a SIMD vector with another SIMD vector or constant, it first has to be. This is done by splitting each vector up into two, with each vector taking every other limb, as seen in Figure 5 . Then, after multiplication, the vector has to be, which combines two vectors into one. and ARM NEON instructions, which, respectively, get the lower two and the higher two limbs from a SIMD vector. There is a key difference here with the AVX2 implementation. AVX2 splits into two SIMD vectors for multiplication as described in Figure 5 . For ARM NEON however, the multiplication SIMD instructions expect two 64-bit vectors that result in a 128-bit vector. The SIMD vector is still split in two, with each result vector taking every other limb, but the result vectors are of length 64 bits. This splitting can be seen in Figure 6 , and our representation using two ARM NEON SIMD vectors results in four SIMD vectors. We create these four vectors using theandARM NEON instructions, which, respectively, get the lower two and the higher two limbs from a SIMD vector. with and then inserting with to get . The is first extracted with the , which can extract an arbitrary limb from a SIMD vector. In the same way, we obtain to combine both using and get . This process is repeated again to obtain our second vector . After multiplication, a reduction always happens. We explain reduction in more detail in Section 4.3.5 . This reduced form will consist of alternating limbs and zeroed sub-vectors, as described in Figure 5 . Repacking the vectors into the default representation involves extracting the limbs and putting them into new SIMD vectors. We do this by extractingwithand then insertingwithto get. Theis first extracted with the, which can extract an arbitrary limb from a SIMD vector. In the same way, we obtainto combine both usingand get. This process is repeated again to obtain our second vector The function is called to reduce an elliptic curve point field element in our default two SIMD vector representation. A reduction is performed by adding the extra bound bits of each limb to the next limb, and for the last limb, we add it to the first after a multiplication with 19 to conform with the modulo operations. The same is done with , except the extra bits are now 25 or 26 bits long after a multiplication. These functions are implemented similarly to the ones in the existing AVX2 implementation, except that, similar to functions described above, extraction from vectors and combination of vectors is done with , , and . The add, multiplication with scalar, and multiplication between field element operations are again a straightforward reimplementation of the AVX2 functions ported to ARM NEON intrinsics. Addition is a straightforward operation, for which we again rely on the crate to provide the optimal instructions. When adding two elliptic curve point representations together vectorwise, we simply add the corresponding vectors of the first point to the second point. For multiplication by a scalar, each SIMD vector in our representation is multiplied by a scalar using the intrinsic. As these scalars can be large, the representation is first unpacked, then the multiplication happens, and then the result is reduced with before being repacked. by Bernstein and Schwabe [ The same unpacking, multiplication, reduction, and repacking happens for the multiplication between the elliptic curve point representation. The algorithm for this is a direct reimplementation of the formula described inby Bernstein and Schwabe [ 9 ].\n\nThe results of our benchmarks are discussed in this section. For each of our evaluations, we show a table with the summarised results of the benchmark as well as a figure that depicts the results of the benchmarks with a violin plot. displays the results of the benchmarks of constant-time variable-base scalar multiplication. This shows little to no improvement from the non-SIMD version to the auto-vectorised. From non-SIMD to the NEON version, there is an improvement on Jolla, Pi, and X10 II of, respectively, , , and . displays the results of the benchmarks of constant-time variable-base scalar multiplication. This shows little to no improvement from the non-SIMD version to the auto-vectorised. From non-SIMD to the NEON version, there is an improvement on Jolla, Pi, and X10 II of, respectively,, and Table 4 displays the results of the benchmarks of constant-time variable-base scalar multiplication. This shows little to no improvement from the non-SIMD version to the auto-vectorised. From non-SIMD to the NEON version, there is an improvement on Jolla, Pi, and X10 II of, respectively,, and Figure 7 displays a violin-plot of the results. , , and faster than baseline on Jolla, Pi, and X10 II, respectively. Similar to the previous point, the results of the benchmark of the decrypt UUID function can be found in Table 5 , with a violin plot of the results in Figure 8 . This function aims to give a more practical example of the usage of the SIMD back-end in an actual library (Signal). Auto-vectorised again has little to no speed-up, while NEON SIMD performs, andfaster than baseline on Jolla, Pi, and X10 II, respectively. The results are completely in line with expectations. Since curve25519-dalek [ 7 ] reports a 40% speed-up for AVX2 and we use roughly twice the number of instructions, we get the expected speed-up of 20%. It seems that the speed-up is lower on newer devices, though more extensive testing on a variety of different cores, looking specifically at clock speeds, boost, architecture, etc. would be necessary to get a clear answer as to why. The benchmarks demonstrate the efficiency of using the four-way parallel formulae of Hisil et al. [ 6 ], even with smaller SIMD vectors. This indicates that formulae specifically designed for four-way parallelism, and thus for 256-bit SIMD architectures, can still work on 128-bit SIMD architectures. The inherent parallelism of SIMD provides a speed-up for these algorithms, even on smaller SIMD vector sizes. Small further optimisations might be possible by changing some of the SIMD instructions used in the proposed implementation. However, given the use of a state-of-the-art algorithm for extended twisted Edwards curves and the fact that our speed-up already is in line with the theoretically expected speed-up, large improvements would require more fundamental changes to the elliptic curve algorithms themselves."
    },
    {
        "link": "http://tomlr.free.fr/Math%E9matiques/Math%20Complete/Cryptography/Guide%20to%20Elliptic%20Curve%20Cryptography%20-%20D.%20Hankerson,%20A.%20Menezes,%20S.%20Vanstone.pdf",
        "document": ""
    },
    {
        "link": "https://medium.com/edge-elections/a-gentle-introduction-to-elliptic-curve-cryptography-b16ed8f4a5c5",
        "document": "If you have ever read any article about elliptic curves, you already know that an elliptic curve is defined by the equation y² = x³ + a ⋅ x + b and has a strange looking graph like this one:\n\nHowever, what is the meaning of this? How do we use this strangely shaped line for cryptography? And why would we want to deal with elliptic curves in the first place?\n\nLet’s take a step back for a second. Why do we need cryptography to begin with? In most daily cases, we need it for only three things:\n• to encrypt stuff (and then decrypt it)\n• to exchange keys (so we can communicate and exchange data securely)\n\nOf course, this doesn’t include an e-voting case, which needs cryptography for more specific operations: proving something about the secret without revealing the secret (zero-knowledge proofs), performing mathematics over encrypted data (e.g., homomorphic tally), etc.\n\nSo, how do cryptography goals relate to elliptic curves? The answer is speed. We use cryptography daily without even realizing it: connecting to websites, opening our cloud, logging into an app, etc. We don’t notice cryptography running in the background because it’s running fast. If we had to wait a few minutes every time we wanted to send a message, we would be aware and incredibly irritated at how slow everything is.\n\nTo see why elliptic curves help speed of cryptographic processes, recall that cryptography loves dealing with huge numbers, which is difficult even for modern computers. Generally, the bigger the number — the slower doing mathematics with it will be. However, if we check the guidelines, we’ll see that to achieve 128-bit level of security, we need 3072-bit numbers when working with integers but only 256-bit numbers for elliptic curve points. A 12-fold difference! That is why elliptic curves are so fast — they don’t need to deal with such enormous integers as cryptography based on discrete logarithms or module factoring.\n\nHowever, the cost to pay for using such lightweights is the complexity of the operations. With integers, the mathematics we do is modular (we divide and keep the remainder of the division), which is relatively easy to understand. On the other hand, elliptic curves require artificial formulas — specifically designed operations to obtain a cyclic group of curve points suitable for cryptography. Those formulas are not as intuitively understandable as modular math. Nevertheless, if we focus on graphical representations of those operations, we can understand the logic of elliptic curve math.\n\nThe first operation we need is negation. We all know that 2 — 2 = 0, so -2 is the inverse of 2. In modular math, it’s a bit more complex. We claim number a is an inverse of b if a ⋅ b = 1 mod p. For example, for p = 11, the inverse of 2 would be 6 because 2 ⋅ 6 mod 11 = 12 mod 11 = 1. However, what would be the inverse of a point Q = (x, y) on a curve? There is no natural definition, but since we must define it, we say it is a “mirror point” or reflection -Q = (x, -y) (see Figure 2).\n\nWhat about points addition? This is where things get crazy. To add points P and Q, we draw a line (the green line in Figure 3) between P and Q and find where it intersects with the curve (the blue line in Figure 3). Then, we need to find an inverse of the intersection point, which gives us the P + Q point. If it seems unnecessarily convoluted, remember that the formula is artificial. The mathematics were designed to ensure the sum of two points will stay on the curve and P + Q + (-Q) = P. Check, it will be true!\n\nHowever, what if we would like to add Q + Q? There is only one point, but our formula for point addition says we need two. Luckily, there is a different formula for the Q + Q operation called point doubling. To double the point, we need to draw a tangent — a straight line that “just touches” the curve at point Q. Then we find where the tangent intersects with the curve and inverse that point to get 2Q.\n\nIs that it? Not yet! There are a couple of exceptional cases (see Figure 5) when the tangent is a vertical line and when we try to add Q and -Q. Strictly speaking, there is no intersection with a curve in these cases, so our formulas do not work … unless we imagine an intersection.\n\nThis imaginary point is called a point at infinity Θ, and we must always add it to our curve, so the math works smoothly. We also say that Θ + Θ = Θ, Q + Θ = Q and Q + (-Q) = Θ.\n\nWhat about point multiplication? Well, such an operation is not defined. We are only allowed to do point addition, negation, and doubling. However, we can extend formulas to compute xP for any x (e.g., 5P = 2 ⋅ (2 ⋅ P) + P). The beauty is that, by only looking at the result, it is hard to say what x was used (if we use sufficiently large numbers and a secure curve), which is enough to build cryptography!\n\nOf course, our phones and computers do not draw graphs and find intersections — that would be too slow. Also, computers love integers, so we use elliptic curves over finite fields instead of dealing with all numbers. In other words, we always do mathematics modulo some prime p.\n\nBy definition, the elliptic curve over a finite field with a prime p > 3 is the set of all points with integer coordinates (x, y) which fulfill the equation y² ≡ x³ + a · x + b mod p together with an imaginary point of infinity Θ, where a, b are such integers that 4 · a³ + 27 · b² ≠ 0 mod p. The extra condition is needed to ensure the curve is non-singular — without self-twists or cusps (see Figure 6) because our math would not work with them.\n\nTo perform point addition and doubling, there are formulas:\n\nAs you can see, all cases involving the point at infinity must be handled with care. Moreover, this point does not always have a numerical representation, so some curves should be more careful with arithmetic than others. But we’ll talk about that in the next ECC article.\n\nIf you’ve read this far, you’re probably wondering why all our graphs were plotted for all numbers when elliptic curve cryptography always does operations modular prime p. The answer is for the simplicity of the explanation. Figure 7 shows the curve y² = x³ — 7x + 10 plotted for all numbers and curve points over a finite field with the prime p = 11. The result is quite different, right? However, as crazy as it sounds, all points still belong to the curve.\n\nRecall that in the modular mathematics x + np mod p = x for any n. So, many different numbers would become x after the mod operation.\n\nSimilar logic holds for curves: a curve y² = f(x) in finite fields would be equivalent to f(x) + p, f(x) + 2p, etc. So, if we plot y² = mod(f(x), 11) for all numbers, the elliptic curve points we use for cryptography should end up on one of the resulting lines (see Figure 8).\n\nThere are many more things to say about elliptic curves: optimizations for faster arithmetic, security, what is a safe curve to use, mapping messages to points, etc. Hopefully, we’ll touch on some of these topics next time!"
    }
]