[
    {
        "link": "https://github.com/cycfi/q",
        "document": "Q is a cross-platform C++ library for audio digital signal processing. Q is named after the \"Q factor,\" a dimensionless parameter that describes the quality of a resonant circuit. The Q DSP Library is designed to be simple and elegant, as the simplicity of its name suggests, and efficient enough to run on small microcontrollers.\n\nQ simplifies complex DSP programming tasks without sacrificing readability by leveraging the power of modern C++ and efficient use of functional programming techniques, especially function composition using fine-grained and reusable function objects (both stateless and stateful).\n\nQ is the host of some experimental Music related DSP facilities the author has accumulated over the years as part of research and development, and will continue to evolve to accommodate more facilities necessary for the fulfillment of various Music related projects.\n\nThe library is Open Source and released under the very liberal MIT license.\n\nNOTE: The library has now reached version 1.0 and has stabilized. The documentation is in sync with the code in the master branch. Any future changes will be developed in feature branches and merged incrementally to the master branch. The develop branch will cease to exist. The API is now stable, and any changes will be documented accordingly. Versions will be in separate branches. The master branch will target the latest version. Currently, it targets v1.5, which will be a significant departure from v1.0, when completed. This update includes the retirement of the BACF (bitstream autocorrelation) based pitch detector and the introduction of a new, much better pitch detection algorithm with integrated onset detection.\n\nUpdate: We're closing in towards v1.5. The Hz pitch detection system is presented in this article series: Pitch Perfect: Enhanced Pitch Detection Techniques (Part 1)\n\nThe Q library comprises of two layers:\n• q_io: Audio and MIDI I/O layer. The q_io layer provides cross-platform audio and MIDI host connectivity straight out of the box. The q_io layer is optional. The q_lib layer is usable without it.\n\nThe dependencies are determined by the arrows.\n• q_io has very minimal dependencies (portaudio and portmidi) with very loose coupling via thin wrappers that are easy to transplant and port to a host, with or without an operating system, such as an audio plugin or direct to hardware ADC and DAC.\n• q_io is used in the tests and examples, but can be easily replaced by other mechanisms in an application. DAW (digital audio workstations), for example, have their own audio and MIDI I/O mechanisms.\n• q_lib has no dependencies except the standard c++ library.\n\nThe q_io layer provides cross-platform audio and MIDI host connectivity straight out of the box. The q_io layer is optional. The q_lib layer is usable without it. q_io is used in the tests and examples, but can be easily replaced by other mechanisms in an application.\n\nJoel got into electronics and programming in the 80s because almost everything in music, his first love, is becoming electronic and digital. Since then, he builds his own guitars, effect boxes and synths. He enjoys playing distortion-laden rock guitar, composes and produces his own music in his home studio.\n\nJoel de Guzman is the principal architect and engineer at Cycfi Research. He is a software engineer specializing in advanced C++ and an advocate of Open Source. He has authored a number of highly successful Open Source projects such as Boost.Spirit, Boost.Phoenix and Boost.Fusion. These libraries are all part of the Boost Libraries, a well respected, peer-reviewed, Open Source, collaborative development effort.\n\nFeel free to join the discord channel for discussion and chat with the developer.\n\nCopyright (c) 2014-2024 Joel de Guzman. All rights reserved. Distributed under the MIT License"
    },
    {
        "link": "https://forum.juce.com/t/pitch-recognizer-c-api/6603",
        "document": "I’m looking for a straightforward pitch recognizer C++ API (like every real tuner do). Does anybody here know how to find this kind of API? What I would like to do is basically extract the fundamental frequency from a given wave sample (in real-time), then convert it to the closest pitched note, and finally into a proper NoteOn MIDI signal. I already tried to Google it, but I haven’t found anything so far. Working with AudioBuffer to do Pitch Detection on Low Frequencies\n\nI believe you could “grab” it (along with, why not, other interesting features) from Mixx: BTW, as I suggest, collaboration is better than “stealing” !\n\nAdam that YIN stuff is the best solution around I seem to remember?? PS. I don’t think FFT would be a good solution here. Presumably it’s woefully inaccurate for low pitches … (actually just found some analysis of how inaccurate: http://blog.bjornroche.com/2012/07/frequency-detection-using-fft-aka-pitch.html)\n\nYes FFT / frequency-domain based pitch detection is generally much faster than time-domain, but tends to be less accurate. Peak picking FFT is the least accurate, and can completely miss the fundamental frequency. In my tests, I found the the McLeod Pitch Method faster and more accurate than YIN.\n\nHi all,\n\n I am looking into all this stuff.\n\n A friend asked me to build a bass synth VST for him.\n\n I made a simple application using PYO that used Yin and an envelope follower.\n\n It worked pretty well. I had to mess around to get it to work.\n\n A buffersize of 1024 with a window size of 3072 at 96k seemed to work best but it didn’t work at all below 50hz ( ie the bottom 4 notes on the low E string weren’t recognized. I wonder if the MPM method would work better that low. I guess the lower down you get the bigger the errors get. A couple of HZ is almost a semitone/half-step down there … I set the minimum freq yin was looking for to 10hz and applied a hi pass filter at 1000k … I managed to build a simple sampler in JUCE totally in C++ but getting on of these complicated algorythms to work seems a bit beyond my skills … I wish JUCE would compile PYO properly which was 7 lines of code … All the books I read seem to go from a description of DSP of a sine wave to rocket science. It would be nice if someone could suggest an easy way in. I also want to try and implement a PSOLA algorithm I made easily in JUCE. … Sean"
    },
    {
        "link": "https://github.com/fftune/fftune",
        "document": "This is an audio pitch detection library written in modern C++20, providing multiple pitch detection methods and a ready to use binary to convert an input WAV file into a MIDI file.\n\nNote that Arch Linux users can simply install the native fftune-git package from the AUR.\n\nThe following libraries are required to be installed:\n\nA is provided for distributions that can not satisfy the dependency requirements. To build the container, use or :\n\nThe most basic usecase is:\n\nIt is also possible to stream data in realtime via in an OS-independent way. For example on Linux with Pulseaudio, you can process a live recording in realtime with:\n\nThere are many more options available, view them by showing the help with or by looking at the provided man-page with .\n\nThis library comes with a developer API documentation. To build it use:\n\nYou can then open in a web browser.\n\nIf you are a developer and want to use this library in your own program, you can include the header with and link against . Examples for using this library can be found in the examples directory. This library comes with support, so it is not necessary to manually link against it.\n\nships with a testing suite, for more information checkout the tests directory."
    },
    {
        "link": "https://superpowered.com/audio-library-list",
        "document": "Superpowered is the leading C++ Audio Library. Download it today.\n\nC++ audio libraries are critical for high performance audio programming since C++ is a language designed for high performance computing. While other, more modern languages like Swift or Java may be easier to learn and pick up by developers; low latency audio development must be done in C and/or C++ because they are the closest languages to Assembly. C and C++ is said to “run close to the metal”, that is C++ audio code compiles down to native machine code for the CPU it is to run on. Furthermore, C and C++ libraries often contain Assembly code for the most performance-critical parts.\n\nThis means that the code has no “layers” it has to get through to get to the CPU at run time (eg as a Virtual Machine or interpreter). Which makes for better performance by manipulating RAM and hardware registers directly. Only Assembly runs closer, on top of “bare metal”.\n\nThe downside is that in C++, programmers have to deal with stack vs heap, pointers and memory allocation, synchronization and blocking that other languages do for you automatically albeit much less efficiently. This is why real-time audio cannot be programmed in JAVA, for example. Today there are a number of options for C++ audio processing libraries available.\n\nThe best C++ audio libraries offer a wide-ranging, ready-built collection of audio classes, from decoders to players to audio filters, all of which should improve the development process and run equally well on desktop and mobile processors to make cross-platform development easy.\n\nLibraries should include efficient algorithms for digital signal processing (such as FFT, polar FFT and IIR filter) and audio analysis (eg BPM, key detection). It is critical they also offer low-level DSP functions, paramount for low-latency and jitter-free audio performance. Moreover, a good c++ dsp library or good C++ music library will provide multiple levels of audio abstraction, from low-level abstractions such as primitives like FFTs and IIR filters to mid-level abstractions like reverbs and flanger effects to high-level abstractions such as advanced audio players with built-in time-stretching. This allows developers to choose the appropriate level of abstraction needed for their project.\n\nLastly, a good C++ audio dsp library should be easy to integrate into existing code. C++ audio DSP (such as C++ audio filters, like biquads) should be as efficient and fast as possible, both for user audio experience and for longer battery life.\n\nSuperpowered is the leading real-time, cross-platform C++ Audio Library for Desktop, Mobile, IoT and Embedded Devices on Android, iOS, macOS, tvOS, Linux and Windows.\n\nAquila is an open-source software and cross-platform DSP (Digital Signal Processing) library written in C++, focusing on frequency domain analysis.\n\nAubio is a tool designed for the extraction of annotations from audio signals (mostly for audio analysis).\n\nBASS is a cross-platform audio library with players (using third-party/OS codecs) and effects.\n\nCLAM is a software framework mostly for research in the audio and music domain.\n\nFMOD is a proprietary sound effects engine and authoring tool for video games and applications.\n\nirrKlang is a high level 2D and 3D cross platform (Windows, Mac OS X, Linux) sound engine and audio library focusing on games.\n\nJUCE is a partially open-source cross-platform C++ application framework most frequently used in audio plugins (such as synthesizers).\n\nKFR is an open-source C++ DSP framework with frequency domain features and SIMD functions.\n\nMaximillian is a C++ Audio and Music DSP Library.\n\nOpenAL is a cross-platform 3D audio API appropriate for use with gaming applications and many other types of audio applications.\n\nPortAudio is an open-source cross-platform audio library for managing audio input/output.\n\nRtAudio is a set of C++ classes that provide a common API for realtime audio input/output.\n\nSoLoud is a C/C++ audio engine for games with audio players, sample playback and filters.\n\nSoundFile is an audio library for reading and writing audio files, based on libsndfile, CFFI, and NumPy.\n\nSoundTouch is an open-source audio processing library for changing the Tempo, Pitch and Audio Playback Rates of audio streams or audio files. The library additionally supports estimating stable beats-per-minute rates for audio tracks.\n\nThe Synthesis ToolKit in C++ (STK) is a set of open source audio signal processing and algorithmic synthesis classes written in the C++ programming language.\n\nGamma is a cross-platform, C++ library for doing generic synthesis and filtering of signals.\n\nA C++ library for audio input/output on Android.\n\nWhat is needed in a C++ audio library for games?\n\nA C++ audio library for games should offer cross-platform support allowing developers to target multiple tech platforms simultaneously. It should offer real-time audio latency (sub-10ms) for intuitive gameplay. App lifecycle management should be easy and the API needs to be modular, allowing developers to choose the best level of abstraction. All of this should be supported with both free and paid support options.\n\nWhere can I find a helpful C++ audio programming tutorial?\n\nBenefits of Using Superpowered Audio as a C++ Audio Library\n\nTime is a developer's most precious resource. This is why with Superpowered, source code is written once in C++ (for performance reasons) and easily portable to multiple platforms. Not only is code portability important but audio output is bit-perfect identical on any and all platforms.\n\nWith Superpowered, developers only need to write audio source code once, and can deploy with identical audio playback, sound and performance anywhere.\n\nCopy-paste C++ audio code between Android, iOS, macOS, tvOS, Linux and Windows.\n\nAudio processing is a real-time process in which developers have to perform complex DSP transformations in a few milliseconds to queue up the audio stream in the buffer.\n\nSuperpowered offers the lowest latency audio processing on mobile devices, faster than OpenSL ES, Core Audio or vDSP/Accelerate.\n\nSuperpowered operates independently of the operating system media stack (except using audio I/O), so updates to platforms such as Android, iOS, macOS, tvOS, Linux and Windows won’t break audio code. Superpowered C++ audio library works out of the box and provides standalone audio processing because it isn’t a software wrapper atop another C++ dsp library.\n\nSuperpowered offers multiple levels of abstractions. Developers can code their own audio effects and players, or use Superpowered built-in audio effects and player classes. The simple Superpowered API is consistent across Android, iOS, macOS, tvOS, Linux and Windows versions. This means no more fragmentation issues, identical audio features and quality on all devices starting from Android 4.4, iOS 8, Windows Vista and higher. Thoughtful API design removes messy connection and unnecessary audio graph abstractions, making it easier to integrate with existing and/or custom processing code.\n\nSuperpowered offers three levels of free and paid support options for developer code, programming logic, bug fixes and applications developed and deployed using Superpowered SDKs.\n\nOur support group is staffed by developers who are dedicated to providing timely, accurate and useful information. Superpowered also provides free C++ audio programming tutorials for the Superpowered example projects.\n\nSuperpowered is the leading C++ Audio Library. Download it today."
    },
    {
        "link": "https://stackoverflow.com/questions/1466968/real-time-pitch-detection-using-fft",
        "document": "Closed. This question does not meet This question does not meet Stack Overflow guidelines . It is not currently accepting answers. This question appears to be off-topic because it lacks sufficient information to diagnose the problem. Describe your problem in more detail or include a minimal example in the question itself.\n\nI'm trying to do real-time pitch detection using C++. I'm testing some code from performous (http://performous.org/), because everything else hasn't worked for me. I know for sure that this works, but i just cant get it to work. I've been trying this for a few weeks now, and I haven't been able to get any pitch detection code working."
    },
    {
        "link": "https://perso.crans.org/fpicard/rapport.pdf",
        "document": ""
    },
    {
        "link": "https://audiolabs-erlangen.de/resources/MIR/FMP/C3/C3S2_DTWbasic.html",
        "document": "Given two sequences $X:=(x_1,x_2,\\ldots,x_N)$ of length $N\\in\\mathbb{N}$ and $Y:=(y_1,y_2,\\ldots,y_M)$ of length $M\\in\\mathbb{N}$, the objective of dynamic time warping (DTW) is to temporally align these two sequences in some optimal sense under certain constraints. The sequences may be discrete signals, feature sequences, sequences of characters, or any kind of time series. Often the indices of the sequences correspond to successive points in time that are spaced at uniform time intervals. The following figure illustrates an alignment (indicated by the red bidirectional arrows) between a sequence $X$ of length $N=9$ and a sequence $Y$ of length $M=7$. Each of the red bidirectional arrows encodes a correspondence between two elements $x_n$ and $y_m$ for $n\\in[1:N]$ and $m\\in[1:M]$. Such a local correspondence can be modeled by the index pair $(n,m)$. The right side of the above figure illustrates how the alignment shown on the left is encoded by a sequence of index pairs.\n\nTo model a global alignment between the elements of the sequences $X$ and $Y$, the idea is to consider a sequence of index pairs that fulfills certain constraints. This leads to the notion of a warping path. By definition, an $(N,M)$-warping path of length $L\\in\\mathbb{N}$ is a sequence \\begin{equation} P=(p_1,\\ldots,p_L) \\end{equation} with $p_\\ell=(n_\\ell,m_\\ell)\\in[1:N]\\times [1:M]$ for $\\ell\\in[1:L]$ satisfying the following conditions: An $(N,M)$-warping path $P=(p_1,\\ldots,p_L)$ defines an alignment between two sequences $X=(x_1,x_2,\\ldots,x_N)$ and $Y=(y_1,y_2,\\ldots,y_M)$ by assigning the element $x_{n_\\ell}$ of $X$ to the element $y_{m_\\ell}$ of $Y$. The boundary condition enforces that the first elements of $X$ and $Y$ as well as the last elements of $X$ and $Y$ are aligned to each other. The monotonicity condition reflects the requirement of faithful timing: if an element in $X$ precedes a second element in $X$, then this should also hold for the corresponding elements in $Y$, and vice versa. Finally, the step size condition with respect to the set $\\Sigma$ expresses a kind of continuity condition: no element in $X$ and $Y$ can be omitted, and there are no replications in the alignment. Note that the step size condition implies the monotonicity condition, which nevertheless has been quoted explicitly for the sake of clarity. The following figure illustrates the conditions by some examples where the conditions (boundary, monotonicity, step size) are violated.\n\nNext, we introduce a notion that tells us something about the quality of a warping path. To this end, we need a way to numerically compare the elements of the feature sequences $X$ and $Y$. Let $\\mathcal{F}$ be a feature space and assume that $x_n,y_m\\in\\mathcal{F}$ for $n\\in[1:N]$ and $m\\in[1:M]$. To compare two different features $x,y\\in\\mathcal{F}$, one needs a local cost measure, which is defined to be a function \\begin{equation} c:\\mathcal{F}\\times\\mathcal{F}\\to \\mathbb{R}. \\end{equation} Typically, $c(x,y)$ is small (low cost) if $x$ and $y$ are similar to each other, and otherwise $c(x,y)$ is large (high cost). Evaluating the local cost measure for each pair of elements of the sequences $X$ and $Y$, one obtains a cost matrix $C\\in\\mathbb{R}^{N\\times M}$ defined by \\begin{equation} C(n,m):=c(x_n,y_m) \\end{equation} for $n\\in[1:N]$ and $m\\in[1:M]$. A tuple $(n,m)$ representing an entry of the matrix $C$ will be referred to as a cell of the matrix. The total cost $c_P(X,Y)$ of a warping path $P$ between two sequences $X$ and $Y$ with respect to the local cost measure $c$ is defined as \\begin{equation} c_P:=\\sum_{\\ell=1}^L c(x_{n_\\ell},y_{m_\\ell}) = \\sum_{\\ell=1}^L C(n_\\ell,m_\\ell). \\end{equation} The intuition of this definition is that the warping path accumulates the cost of all cells it runs through. A warping path is \"good\" if its total cost is low, and it is \"bad\" if its total cost is high. Now, we are interested in an optimal warping path between $X$ and $Y$, which is defined to be a warping path $P^\\ast$ that has minimal total cost among all possible warping paths. The cells of this warping path encode an overall optimal alignment between the elements of the two sequences, where the warping path conditions ensure that each element of sequence $X$ is assigned to at least one element of $Y$ and vice versa. This leads us to the definition of the DTW distance denoted as $\\mathrm{DTW}(X,Y)$ between the two sequences $X$ of length $N$ and $Y$ of length $M$, which is defined as the total cost of an optimal $(N,M)$-warping path $P^\\ast$: \\begin{eqnarray} \\mathrm{DTW}(X,Y) :=c_{P^\\ast}(X,Y) = \\min\\{c_P(X,Y)\\mid P \\mbox{ is an $(N,M)$-warping path} \\} \\end{eqnarray}\n\nTo determine an optimal warping path $P^\\ast$ for two sequences $X$ and $Y$, one could compute the total cost of all possible $(N,M)$-warping paths and then take the minimal cost. However, the number of different $(N,M)$-warping paths is exponential in $N$ and $M$. Therefore, such a naive approach is computationally infeasible for large $N$ and $M$. We now introduce an $O(NM)$ algorithm that is based on dynamic programming. The general idea behind dynamic programming is to break down a given problem into simpler subproblems and then to combine the solutions of the subproblems to reach an overall solution. In the case of DTW, the idea is to derive an optimal warping path for the original sequences from optimal warping paths for truncated subsequences. This idea can then be applied recursively. To formalize this idea, we define the prefix sequences $X(1\\!:\\!n) := (x_1,\\ldots x_n)$ for $n\\in[1:N]$ and $Y(1\\!:\\!m) := (y_1,\\ldots y_m)$ for $m\\in[1:M]$ and set \\begin{equation} D(n,m):=\\mathrm{DTW}(X(1\\!:\\!n),Y(1\\!:\\!m)). \\end{equation} The values $D$ define an $(N\\times M)$ matrix $D$, which is also referred to as the accumulated cost matrix. Each value $D(n,m)$ specifies the total (or accumulated) cost of an optimal warping path starting at cell $(1,1)$ and ending at cell $(n,m)$. Obviously, one has $D(N,M)=\\mathrm{DTW}(X,Y)$. The following table gives a description of the DTW Algorithm based on dynamic programming. In the first part, the accumulated cost matrix $D$ is computed iteratively using a nested loop. In the second part, the optimal warping path is computed using a backtracking procedure. For further details and a proof of the algorithm's correctness, we refer to Section 3.2.1 of [Müller, FMP, Springer 2015]."
    },
    {
        "link": "https://ursinus-cs371-s2021.github.io/CoursePage/Assignments/HW3_DTW_AudioAlignment",
        "document": "The purpose of this assignment is to give you practice implementing dynamic programming techniques in python in the service of a cool application: alignment/synchronization of audio.\n\nClick here to download the starter code for this assignment. You will be editing\n\nTo handle audio, you will need to setup a library called librosa. To install this, either go to your anaconda prompt and type\n\nor go into the interactive console in spyder and type\n\nIf this worked properly, when you run the following code:\n\nYou should see this image\n• Implement an exact and an approximate version of the same algorithm.\n• Implement a dynamic programming algorithm with backtracing to extract an optimal solution.\n• Use recursion to enumerate paths on a branching structure.\n• Use sparse matrices to implement memory efficient 2D arrays, leading to a linear memory algorithm\n\nPlease submit your file to canvas. Please also submit answers to the following questions on Canvas\n• The name of your buddy, if you chose to work with one.\n• Approximately how many hours it took you to finish this assignment (I will not judge you for this at all...I am simply using it to gauge if the assignments are too easy or hard)\n• Any suggestions if I run this assignment again?\n• Any other concerns that you have. For instance, if you have a bug that you were unable to solve but you made progress, write that here. The more you articulate the problem the more partial credit you will receive (fine to leave this blank)\n\nThe problem we're going to address in this assignment is one of spatial time series alignment. Let's start with an an example to motivate this. Suppose I'm running a 30 meter race against Usain Bolt. I'm definitely going to lose by a lot! But maybe later it would be interesting to line up our videos to show us side by side at different places on the track to compare our form at those locations. Which frames of the videos should we show side by side to best line us up on the track? Let's look at the frames we captured below. We'll line up the frames next to 2D coordinates for our positions over time, which we can think of as a \"2D spatial time series,\" or the positions of the frames that were captured over time. The orange path shows my trajectory, and the blue path shows Usain Bolt's trajectory. (NOTE: This is not at all realistic, but just as an example for the sake of argument. For an actual analysis of Usain Bolt's record setting 100m race, refer to a lab I made for math 111)\n\nAs you can see, it takes me three video frames frames (indices 0-2) to run nearly as far as Usain Bolt ran in the interval between his first two frames (indices 0-1), even as Usain Bolt veers slightly out of his lane and runs along a diagonal. Then, Usain Bolt looks back and realizes he can win without even trying, so he slows down and doesn't move as far between his last two frames as he runs straight to the end. Meanwhile, I also slow down after frame two from pure exhaustion and move a bit slower. Eventually, we both make it to the end.\n\nTo figure out how to line up the frames, we define something called a warping path. A warping path is a sequence of pairs of indices between the two time series, where each pair indicates two points that should be aligned between the time series. A warping path satisfies the following rules for a time series of length M aligned to a time series of length N:\n• The first frames are aligned; that is, is in the warping path. Likewise, the last frames are aligned; that is, is in the warping path. These are known as the boundary conditions.\n• We can only stay in place or move forward along each time series from one pair to the next in the warping path; we never move backwards. This is known as the monotonicity condition. Furthermore, we can move at most one step in each time series from one pair to the next, but at least one time series has to move. This is known as the continuity condition Taken together, these two conditions mean that for a pair , the next pair can be one of the three options:\n• : The first time series moves forward one step, while the second one stays still.\n• : The second time series moves forward one step, while the first one stays still.\n• : Both time series move forward by one step.\n\nTo figure out which warping path best aligns the time series, we'll define a score associated to each path, which is the sum of the lengths of straight line segments between each pair of aligned points. For example, letting Usain's time series be the first time series and mine be the second one, we could consider the following warping path\n\nWe then compute and sum up all of the distances between corresponding pairs. For instance, for , the distance between point 2 on Usain's path and point 0 on my path is 25.3. The total cost in this example is approximately 130, but we can definitely do better. For instance, consider the following warping path\n\nThis starts and ends at the same place, but it takes different steps in between that lead to fewer and shorter segments. The overall cost is around 27, which is much lower than our original try! But is this the best we can do? The animation below shows all possible warping paths and their associated costs:\n\nIn fact, we see that the following warping path is the best over all possible warping paths in this example that achieves a lower cost of 19.8\n\nThis intuitively captures the notion that Usain Bolt went the same distance as my first 3 frames over only his first 2 frames, and then we did about the same thing for the rest of it.\n\nNow that we have a way to quantify what a good correspondence is between time series via warping paths and their costs, we need to devise an algorithm to compute them efficiently. A brute force algorithm would check every single warping path and return the one with the lowest cost. To see how efficient this is, we need to know how many warping paths to check. In fact, there's a known sequence of numbers, the Delannoy numbers, that count the number of possible warping paths based on the size of two time series (this also happens to be the number of possible edit sequences in the edit distance). In particular, given a time series of length M and a time series of length N, the Delannoy number D(M, N) is defined with the following recurrence relation:\n\nThe base case is (M = 1 or N = 1) is aligning a time series with a single point to another time series, and the only way to do this is by matching that point to every point in the time series, so there is only one possible warping path. The rest of the recurrence comes from the boundary and monotonicity conditions of warping paths. To compute the number of paths, it's possible to simply translate the recurrence over to recursive calls\n\nBut we know that there's a more efficient way to evaluate recurrence relations such as these by using memoization, where we fill in an entire dynamic programming table as follows\n\nBelow is an example of some of these numbers\n\nThe bolded numbers, in which N = M, are referred to as central Delannoy numbers, and we can study them to see how the warping paths scale in one parameter. As shown in this paper, the central Delannoy numbers D(N, N) are\n\nwhich is not quite exponential due to the square root of N in the denominator, but the scaling is still terrible for all practical purposes. So checking all possible warping paths is a dead end idea for an efficient algorithm.\n\nTo solve this efficiently, we're going to follow a dynamic programming strategy extremely similar to the one we used to solve string edit distance. This means that we have to break down our problem into smaller problems and combine their solutions incrementally to build up to the full problem. Let's say we have a time series X with M that we want to align to a time series Y with N samples, and that we're able to compute the distance between a point x in X and a point y in Y as d . Furthermore, let the optimal cost to align the first i samples of X to the first j samples of Y be expressed as S[i, j]; that is S[i, j] holds the sum of the distances of all segments in an optimal warping path from to . Then, we can make the dynamic programming observation:\n\nIn other words, take the min of the upper, left, and upper left neighbhors in , then add the distance from X to Y . This happens because we know that all possible warping paths from 0 to i in X and from 0 to j in Y must end by matching to (the boundary condition), so we pay a cost of d for that pair. Furthermore, by the monotonicity and continuity conditions, we know the pair before has to have moved by either 1 or 0 along both indices, so we consider the optimal costs of all three possible sub-alignments that could have happened directly before aligning the last pair .\n\nAll that remains is the base case / stopping condition. We know by the first boundary condition that x needs to match to y , so\n\nTo fill in the rest of the table, we can simply loop along row by row and fill in each element in the row one at at time, looking back at and , just as we did for the edit distance dynamic programming solution.\n\nIn addition to filling in the dynamic programming table S, we can store another 2D array choices which stores which direction out of and led to the optimal cost at each step, and we can then backtrace from the bottom right of the table to the upper left.\n\nSo far, we've described dynamic time warping (DTW) as a procedure for aligning spatial time series in 2D. However, it was originally conceived as a means to align audio (Sakoe and Chiba, 1970, Sakoe and Chiba, 1978). Surprisingly, there is a way to think of audio as a spatial trajectory in high dimensions. The idea is to summarize little chunks of audio using different statistics, and each statistic ends up being a dimension. As a simple example in 2D, one could consider loudness as a dimension along the x-axis and pitch as another dimension along the y-axis. As the music evolves, the loudness and pitch will change, and the music will trace out a curve.\n\nFor a more involved example with other audio statistics, click here to view an interactive animation I made, which I call \"Loop Ditty.\" You won't have to worry about how this actually works in this assignment; the spatial trajectory corresponding to audio will be generated for you, and you will be able to align audio of similar things being played at different rates using general purpose dynamic time warping code you develop.\n\nEven though there is a huge number of warping paths as the size of the inputs scale, it is still interesting to examine what all possible warping paths look like for smaller enough M and N. Your task in this section will be to plot all possible warping paths for a particular M and N using recursion. For example, here's where M = 4, N = 4\n\nAnd here's an example of M = 3, N = 5\n\nFill in the method to do this. The code already has the stopping condition built in for when a path reaches , and it will save a plot to your computer as an image for every complete path it finds.\n\nAll paths start off with . You should use recursive calls to branch off and consider the possible continuous steps to the next pair in the warping path. You may want to refer to the recursive backtracing code for edit distance, which used a stack to help branch off for a bunch of paths. The code here isn't exactly the same, but using push and pop to push on the next element before a recursive call and to pop it off before the next recursive call is the way to go. Note that you can use a python list as a stack; the method is for a list, but is still .\n\nThe image below shows some pseudocode and a picture depicting how the recursion branches out and grows different paths. Here is short for . The overlapping subproblems are quite visible even after only two branches, which is part of what motivates a dynamic programming solution.\n\nNOTE: You may get the paths in a different order from the animation above, but as long as they are all unique and you have a number of paths equal to the respective Delannoy number, you're good to go. You should also check several examples beyond the ones I've shown above and verify that you get the right number of paths.\n\nNow you are ready to implement dynamic time warping. You will start by implementing the dynamic time warping algorithm described in the background to compute an optimal warping path between a sequence of points X and a sequence of points Y. Fill in the method to accomplish this. Once this is finished, you can test out the Usain Bolt example from above:\n\nIf this works, you should get the optimal solution\n\nHere are some implementation details to help you. If X has M points and Y has N points, then you should fill in an M x N dynamic programming table called , which is a 2D array that has been initialized for you in the code. As you're filling in , you can use the provided method to compute the distance between a point in X and a point in Y. In particular, the line\n\nwill compute the distance between the ith point in X and the jth point in Y. Before you go any further, you should check to make sure the lower right element of your array is 19.8 in the Usain Bolt example.\n\nOnce you feel you have the table right, you should add code to remember the optimal choices you made so you can trace back to extract the optimal warping path. For the purposes of this assignment, it's fine to break ties arbitrarily if there happen to be multiple warping paths that achieve the optimal cost. So your solution should be similar to how the iterative backtracing was done in edit distance, using a while loop. When you are finished, You should return the warping path expressed as a list. Be sure to return a path that starts at and ends at , not the other way around. As in the edit distance example, you may find that the method of python lists comes in handy.\n\nBelow is a slightly more intricate example that you can test before moving onto audio. It matches two sets of point samples on Figure 8 curves in 2D which go at different rates around the Figure 8:\n\nIf this works properly, you should get a result like the following, where you see the points are well-matched even though the two Figure 8s have been warped in time:\n\nBut we can go beyond these synthetic examples in 2D and test on some real audio, which we detail below:\n\nConsider the following two audio clips of people reading the beginning of the Gettysburg address\n\nYour browser does not support the audio element.\n\nYour browser does not support the audio element.\n\nIf we line them up, they are completely out of sync\n\nYour browser does not support the audio element.\n\nBut we can align them by using DTW. First, we turn them into a spatial trajectory using the provided method , and then we can pass them on just like any other sets of points on a path:\n\nThis takes about 8 seconds on my computer and comes up with the following output (one in each ear):\n\nYour browser does not support the audio element.\n\nIf instead we flip the two audio clips, we get the following result\n\nThis takes about 8 seconds on my computer and comes up with the following output:\n\nYour browser does not support the audio element.\n\nNOTE: Some students have reported that the .wav files the above code saves do not play under Windows. You can instead run the above code from within a Jupyter notebook and then type\n\nAnd that should pop up with an audio widget that you can play. Be sure you've opened jupyter in the directory where your code is.\n\nIf X has M points and Y has N points, the above algorithm takes \\[ O(MN) \\] space and time. As far as the time complexity goes, this is certainly much better than a brute force check through all \\[ O \\left( \\frac{ (3 + 2 \\sqrt{2})^{N}}{\\sqrt{N}} \\right) \\] paths, but this still does not scale very well. Let's say we want to align two performances of Vivaldi's Spring, each of which is about 220 seconds long. The audio below puts one of these pieces in one ear and the other piece in the other ear, and, as you can hear, they are quite out of sync:\n\nYour browser does not support the audio element.\n\nIf it took 8 seconds to align two clips which were 20 seconds long, then it will take\n\nseconds to align (~16 minutes), which is much longer than the length of each individual clip. And it only gets worse from there. If we have two audio clips which are 1000 seconds (about 17 minutes), they will take nearly 6 hours to align at this rate.\n\nAside from the time, the O(MN) memory also starts to become prohibitive as we scale up. For 17 minutes of of audio using the parameters above and 4-byte floating point numbers, the dynamic programming table alone takes up nearly 7GB.\n\nClearly, we need a better solution to be practical for longer audio clips. For this, we turn to an O(M+N) algorithm in both time and space that has been dubbed \"FastDTW.\" This algorithm is an approximation algorithm, which means it is not guaranteed to give the optimal warping path, but in practice, it still gives good results. It was first described in a 2004 paper by Stan Salvador and Philip Chan, and it was also described in the context of music in a 2006 paper by Müller, Mattes, and Kurth. This is an instance of what's known as a multiresolution algorithm. What we do is solve a coarser version of the problem and then use that solution to constrain our search for finer problems, eventually solving the one at the finest scale that we want.\n\nThe example below shows the matrix and the constrained warping paths at different levels on the Gettysburg address example. In this example, M = 863, N = 603. In FastDTW, we keep halving the number of points in X and Y 5 times until we get down to a problem of size M = 26, N = 18. At this point, we perform full on DTW on this small problem, which is very fast, to extract a coarse warping path. We then use the coarse path to help us solve the problem at a scale of M = 53, N=37, searching only through warping paths which fall within a particular radius of the coarse path. We then use the warping path we find at this scale to constrain the warping path at the next larger scale M = 107, N=75 in a similar way, and we keep doing this until we get up to the original scale. The images below depict this. As you can see, we're able to ignore tons of cells once we get to the finer scales, because the boxes we put around the constraint warping path are so small compared to the size of the dynamic programming matrix\n\nOnce you finish the method, the code to run this is as follows\n\nThis takes about 5 seconds on my computer and comes up with the following output:\n\nYour browser does not support the audio element.\n\nIn this case, the output is exactly the same as with the regular quadratic algorithm, though this is not guaranteed.\n\nBelow we describe the recursive algorithm in more detail.\n\nGiven a time series X with M points, a time series Y with N points, and a whole number radius, we refer to the time series at level L as X and Y , which have a size of\n• Downsample X and Y by a factor of 2 to create X and Y of length M and N , respectively.\n• If M or N is less than radius, this is the stopping condition; the problems are small enough to simply perform regular DTW on them. Otherwise, recursively compute a warping path P between X and Y using FastDTW, and continue to the next step.\n• Create an occupancy mask on P which constrains the warping path at level L. This is a 2D array of size M x N that has a 1 at an element if we need to fill in that element in the dynamic programming table, and a 0 otherwise (it can be assumed to be infinity). To construct this mask, for each coordinate in P, set all elements in a square of length 2*radius+1 around to be 1; that is, set all elements in the box to 1 if they aren't already. The picture below depicts the process of constructing this occupancy mask Any cell that is not touched by a box can be completely skipped, and doesn't even have to be stored in memory! This is what leads to efficiency in both time and space.\n• Compute the dynamic programming array and the array of optimal choices at all locations that are 1s in the occupancy mask, and ignore all others (they are assumed to be infinity in ).\n• Backtrace the array of choices to extract the optimal warping path , subject to the constraints in the occupancy matrix.\n\n, respectively. We can construct the warping pathat levelas follows:\n\nAs your first task, you should fill in code to compute an occupancy mask. We will be using a special data structure known as a sparse matrix to efficiently store it. A sparse matrix efficiently represents a table with many zeros, as it only stores the nonzero elements in memory. Anything that is not stored is implied to be 0.\n\nOnce a sparse matrix has been initialized, you can basically just think of it like a 2D array, but there is one important syntactic caveat. In particular, for our occupancy sparse array , we access an element with . The syntax will not work for sparse matrices.\n\nFill in the code to fill in a sparse occupancy mask for a particular path. For each in , you should set all of the elements of in a square of length 2*radius+1 around the location to be 1. As a hint, the easiest way to do this is to assign to a 2D slice for each point using numpy broadcasting. For example, if I say\n\nThat is equivalent to saying\n\nBoth of these lines of code set an 11x11 box of values to 1, but the first one is more concise and efficient in python.\n\nBelow are a couple of simple tests you can run to see if your code is working properly. Be careful not to go out of bounds!\n\nwhich should output the following image\n\nand the following code\n\nwhich should output the following image\n\nIf P is the length of your path, then your code should run in O(P) time. So do not loop through every element in the grid and check to see if it's in the array. Instead, loop through each element in the path and draw a square around it in turn, as shown in the animation below:\n\nOnce you've computed the occupancy grid, you have all of the pieces you need to implement the recursive algorithm. Here's what you need to do\n• Make a recursive call to fastdtw to get a warping path from X and Y\n• Use this path to create a mask using your method. Then, extract a list of the indices from this mask in the order they should be visited to fill in the dynamic programming table. You can use the provided to do this.\n• Loop through all of the indices in the order they are returned from , and compute the dynamic programming matrix , as well as the choices matrix, both which are sparse matrices. Be very careful that if you're looking at a neighbor of which is not actually a 1 in the occupancy matrix, it is assumed to be infinity, not 0. In other words, a neighbor should never be considered as an option if it is not a 1 in , so be sure to ignore it if it's a 0 in .\n• Backtrace through the choices to extract the optimal warping path and store this in the list\n\nSteps 3 and 4 should be very similar to regular DTW. The only difference is in that in step 3, you're being very careful to only consider neighboring elements which are a 1 in\n\nIf you believe this is working properly, you should test the Gettysburg address again using the code above. The code will output the matrices and scaled warping paths at each level as images to your hard drive to help with debugging.\n\nFor a lengthier example, you can try Vivaldi's spring with the following code:\n\nThis takes about 80 seconds on my computer, and it comes up with the following audio\n\nYour browser does not support the audio element."
    },
    {
        "link": "https://en.wikipedia.org/wiki/Dynamic_time_warping",
        "document": "An algorithm for measuring similarity between two temporal sequences, which may vary in speed\n\nIn time series analysis, dynamic time warping (DTW) is an algorithm for measuring similarity between two temporal sequences, which may vary in speed. For instance, similarities in walking could be detected using DTW, even if one person was walking faster than the other, or if there were accelerations and decelerations during the course of an observation. DTW has been applied to temporal sequences of video, audio, and graphics data — indeed, any data that can be turned into a one-dimensional sequence can be analyzed with DTW. A well-known application has been automatic speech recognition, to cope with different speaking speeds. Other applications include speaker recognition and online signature recognition. It can also be used in partial shape matching applications.\n\nIn general, DTW is a method that calculates an optimal match between two given sequences (e.g. time series) with certain restriction and rules:\n• Every index from the first sequence must be matched with one or more indices from the other sequence, and vice versa\n• The first index from the first sequence must be matched with the first index from the other sequence (but it does not have to be its only match)\n• The last index from the first sequence must be matched with the last index from the other sequence (but it does not have to be its only match)\n• The mapping of the indices from the first sequence to indices from the other sequence must be monotonically increasing, and vice versa, i.e. if are indices from the first sequence, then there must not be two indices in the other sequence, such that index is matched with index and index is matched with index , and vice versa\n\nWe can plot each match between the sequences and as a path in a matrix from to , such that each step is one of . In this formulation, we see that the number of possible matches is the Delannoy number.\n\nThe optimal match is denoted by the match that satisfies all the restrictions and the rules and that has the minimal cost, where the cost is computed as the sum of absolute differences, for each matched pair of indices, between their values.\n\nThe sequences are \"warped\" non-linearly in the time dimension to determine a measure of their similarity independent of certain non-linear variations in the time dimension. This sequence alignment method is often used in time series classification. Although DTW measures a distance-like quantity between two given sequences, it doesn't guarantee the triangle inequality to hold.\n\nIn addition to a similarity measure between the two sequences (a so called \"warping path\" is produced), by warping according to this path the two signals may be aligned in time. The signal with an original set of points X(original), Y(original) is transformed to X(warped), Y(warped). This finds applications in genetic sequence and audio synchronisation. In a related technique sequences of varying speed may be averaged using this technique see the average sequence section.\n\nThis is conceptually very similar to the Needleman–Wunsch algorithm.\n\nThis example illustrates the implementation of the dynamic time warping algorithm when the two sequences and are strings of discrete symbols. For two symbols and , is a distance between the symbols, e.g. = .\n\nwhere is the distance between and with the best alignment.\n\nWe sometimes want to add a locality constraint. That is, we require that if is matched with , then is no larger than , a window parameter.\n\nWe can easily modify the above algorithm to add a locality constraint (differences ). However, the above given modification works only if is no larger than , i.e. the end point is within the window length from diagonal. In order to make the algorithm work, the window parameter must be adapted so that (see the line marked with (*) in the code).\n\nThe DTW algorithm produces a discrete matching between existing elements of one series to another. In other words, it does not allow time-scaling of segments within the sequence. Other methods allow continuous warping. For example, Correlation Optimized Warping (COW) divides the sequence into uniform segments that are scaled in time using linear interpolation, to produce the best matching warping. The segment scaling causes potential creation of new elements, by time-scaling segments either down or up, and thus produces a more sensitive warping than DTW's discrete matching of raw elements.\n\nThe time complexity of the DTW algorithm is , where and are the lengths of the two input sequences. The 50 years old quadratic time bound was broken in 2016: an algorithm due to Gold and Sharir enables computing DTW in time and space for two input sequences of length .[2] This algorithm can also be adapted to sequences of different lengths. Despite this improvement, it was shown that a strongly subquadratic running time of the form for some cannot exist unless the Strong exponential time hypothesis fails.[3][4]\n\nWhile the dynamic programming algorithm for DTW requires space in a naive implementation, the space consumption can be reduced to using Hirschberg's algorithm.\n\nFast techniques for computing DTW include PrunedDTW,[5] SparseDTW,[6] FastDTW,[7] and the MultiscaleDTW.[8][9]\n\nA common task, retrieval of similar time series, can be accelerated by using lower bounds such as LB_Keogh,[10] LB_Improved,[11] or LB_Petitjean.[12] However, the Early Abandon and Pruned DTW algorithm reduces the degree of acceleration that lower bounding provides and sometimes renders it ineffective.\n\nIn a survey, Wang et al. reported slightly better results with the LB_Improved lower bound than the LB_Keogh bound, and found that other techniques were inefficient.[13] Subsequent to this survey, the LB_Enhanced bound was developed that is always tighter than LB_Keogh while also being more efficient to compute.[14] LB_Petitjean is the tightest known lower bound that can be computed in linear time.[12]\n\nAveraging for dynamic time warping is the problem of finding an average sequence for a set of sequences. NLAAF[15] is an exact method to average two sequences using DTW. For more than two sequences, the problem is related to the one of the multiple alignment and requires heuristics. DBA[16] is currently a reference method to average a set of sequences consistently with DTW. COMASA[17] efficiently randomizes the search for the average sequence, using DBA as a local optimization process.\n\nA nearest-neighbour classifier can achieve state-of-the-art performance when using dynamic time warping as a distance measure.[18]\n\nAmerced Dynamic Time Warping (ADTW) is a variant of DTW designed to better control DTW's permissiveness in the alignments that it allows.[19] The windows that classical DTW uses to constrain alignments introduce a step function. Any warping of the path is allowed within the window and none beyond it. In contrast, ADTW employs an additive penalty that is incurred each time that the path is warped. Any amount of warping is allowed, but each warping action incurs a direct penalty. ADTW significantly outperforms DTW with windowing when applied as a nearest neighbor classifier on a set of benchmark time series classification tasks.[19]\n\nIn functional data analysis, time series are regarded as discretizations of smooth (differentiable) functions of time. By viewing the observed samples at smooth functions, one can utilize continuous mathematics for analyzing data.[20] Smoothness and monotonicity of time warp functions may be obtained for instance by integrating a time-varying radial basis function, thus being a one-dimensional diffeomorphism.[21] Optimal nonlinear time warping functions are computed by minimizing a measure of distance of the set of functions to their warped average. Roughness penalty terms for the warping functions may be added, e.g., by constraining the size of their curvature. The resultant warping functions are smooth, which facilitates further processing. This approach has been successfully applied to analyze patterns and variability of speech movements.[22][23]\n\nAnother related approach are hidden Markov models (HMM) and it has been shown that the Viterbi algorithm used to search for the most likely path through the HMM is equivalent to stochastic DTW.[24][25][26]\n\nDTW and related warping methods are typically used as pre- or post-processing steps in data analyses. If the observed sequences contain both random variation in both their values, shape of observed sequences and random temporal misalignment, the warping may overfit to noise leading to biased results. A simultaneous model formulation with random variation in both values (vertical) and time-parametrization (horizontal) is an example of a nonlinear mixed-effects model.[27] In human movement analysis, simultaneous nonlinear mixed-effects modeling has been shown to produce superior results compared to DTW.[28]\n• The tempo C++ library with Python bindings implements Early Abandoned and Pruned DTW as well as Early Abandoned and Pruned ADTW and DTW lower bounds LB_Keogh, LB_Enhanced and LB_Webb.\n• The UltraFastMPSearch Java library implements the UltraFastWWSearch algorithm 29 for fast warping window tuning.\n• The lbimproved C++ library implements Fast Nearest-Neighbor Retrieval algorithms under the GNU General Public License (GPL). It also provides a C++ implementation of dynamic time warping, as well as various lower bounds.\n• The FastDTW library is a Java implementation of DTW and a FastDTW implementation that provides optimal or near-optimal alignments with an O(N) time and memory complexity, in contrast to the O(N2) requirement for the standard DTW algorithm. FastDTW uses a multilevel approach that recursively projects a solution from a coarser resolution and refines the projected solution.\n• time-series-classification (Java) a package for time series classification using DTW in Weka.\n• The DTW suite provides Python (dtw-python) and R packages (dtw) with a comprehensive coverage of the DTW algorithm family members, including a variety of recursion rules (also called step patterns), constraints, and substring matching.\n• The pydtw Python library implements the Manhattan and Euclidean flavoured DTW measures including the LB_Keogh lower bounds.\n• The cudadtw C++/CUDA library implements subsequence alignment of Euclidean-flavoured DTW and z-normalized Euclidean distance similar to the popular UCR-Suite on CUDA-enabled accelerators.\n• The ndtw C# library implements DTW with various options.\n• Sketch-a-Char uses Greedy DTW (implemented in JavaScript) as part of LaTeX symbol classifier program.\n• The MatchBox implements DTW to match mel-frequency cepstral coefficients of audio signals.\n• The PyHubs software package implements DTW and nearest-neighbour classifiers, as well as their extensions (hubness-aware classifiers).\n• The simpledtw Python library implements the classic O(NM) Dynamic Programming algorithm and bases on Numpy. It supports values of any dimension, as well as using custom norm functions for the distances. It is licensed under the MIT license.\n• The tslearn Python library implements DTW in the time-series context.\n• The cuTWED CUDA Python library implements a state of the art improved Time Warp Edit Distance using only linear memory with phenomenal speedups.\n• DynamicAxisWarping.jl Is a Julia implementation of DTW and related algorithms such as FastDTW, SoftDTW, GeneralDTW and DTW barycenters.\n• The Multi_DTW implements DTW to match two 1-D arrays or 2-D speech files (2-D array).\n• The dtwParallel (Python) package incorporates the main functionalities available in current DTW libraries and novel functionalities such as parallelization, computation of similarity (kernel-based) values, and consideration of data with different types of features (categorical, real-valued, etc.). 30\n\nDue to different speaking rates, a non-linear fluctuation occurs in speech pattern versus time axis, which needs to be eliminated.[31] DP matching is a pattern-matching algorithm based on dynamic programming (DP), which uses a time-normalization effect, where the fluctuations in the time axis are modeled using a non-linear time-warping function. Considering any two speech patterns, we can get rid of their timing differences by warping the time axis of one so that the maximal coincidence is attained with the other. Moreover, if the warping function is allowed to take any possible value, very less[clarify] distinction can be made between words belonging to different categories. So, to enhance the distinction between words belonging to different categories, restrictions were imposed on the warping function slope.\n\nUnstable clocks are used to defeat naive power analysis. Several techniques are used to counter this defense, one of which is dynamic time warping.\n\nDynamic time warping is used in finance and econometrics to assess the quality of the prediction versus real-world data.[32][33][34]\n• None Sakoe, H.; Chiba (1978). \"Dynamic programming algorithm optimization for spoken word recognition\". IEEE Transactions on Acoustics, Speech, and Signal Processing. 26 (1): 49. doi:10.1109/tassp.1978.1163055. S2CID 17900407.\n• None Myers, C. S.; Rabiner, L. R. (1981). \"A Comparative Study of Several Dynamic Time-Warping Algorithms for Connected-Word Recognition\". Bell System Technical Journal. 60 (7): 1409. doi:10.1002/j.1538-7305.1981.tb00272.x. ISSN 0005-8580. S2CID 12857347.\n• None Müller, Meinard (2007). Dynamic Time Warping. In Information Retrieval for Music and Motion, chapter 4, pages 69-84 . Springer. doi:10.1007/978-3-540-74048-3. ISBN .\n• None Rakthanmanon, Thanawin (September 2013). \"Addressing Big Data Time Series: Mining Trillions of Time Series Subsequences Under Dynamic Time Warping\". ACM Transactions on Knowledge Discovery from Data. 7 (3): 10:1–10:31. doi:10.1145/2513092.2500489. PMC . PMID 31607834."
    },
    {
        "link": "https://csdl.ics.hawaii.edu/techreports/2008/08-04/08-04.pdf",
        "document": ""
    }
]