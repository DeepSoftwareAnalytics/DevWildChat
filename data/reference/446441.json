[
    {
        "link": "https://learn.microsoft.com/en-us/ef",
        "document": "Entity Framework is a modern object-relation mapper that lets you build a clean, portable, and high-level data access layer with .NET (C#) across a variety of databases, including SQL Database (on-premises and Azure), SQLite, MySQL, PostgreSQL, and Azure Cosmos DB. It supports LINQ queries, change tracking, updates, and schema migrations."
    },
    {
        "link": "https://learn.microsoft.com/en-us/ef/core",
        "document": "Entity Framework (EF) Core is a lightweight, extensible, open source and cross-platform version of the popular Entity Framework data access technology.\n\nEF Core can serve as an object-relational mapper (O/RM), which:\n• Enables .NET developers to work with a database using .NET objects.\n• Eliminates the need for most of the data-access code that typically needs to be written.\n\nEF Core supports many database engines, see Database Providers for details.\n\nWith EF Core, data access is performed using a model. A model is made up of entity classes and a context object that represents a session with the database. The context object allows querying and saving data. For more information, see Creating a Model.\n• Once a model is created, use EF Migrations to create a database from the model. Migrations allow evolving the database as the model changes.\n\nInstances of your entity classes are retrieved from the database using Language Integrated Query (LINQ). For more information, see Querying Data.\n\nData is created, deleted, and modified in the database using instances of your entity classes. See Saving Data to learn more.\n\nWhile EF Core is good at abstracting many programming details, there are some best practices applicable to any O/RM that help to avoid common pitfalls in production apps:\n• Intermediate-level knowledge or higher of the underlying database server is essential to architect, debug, profile, and migrate data in high performance production apps. For example, knowledge of primary and foreign keys, constraints, indexes, normalization, DML and DDL statements, data types, profiling, etc.\n• Functional and integration testing: It's important to replicate the production environment as closely as possible to:\n• Find issues in the app that only show up when using a specific versions or edition of the database server.\n• Catch breaking changes when upgrading EF Core and other dependencies. For example, adding or upgrading frameworks like ASP.NET Core, OData, or AutoMapper. These dependencies can affect EF Core in unexpected ways.\n• Performance and stress testing with representative loads. The naïve usage of some features doesn't scale well. For example, multiple collections Includes, heavy use of lazy loading, conditional queries on non-indexed columns, massive updates and inserts with store-generated values, lack of concurrency handling, large models, inadequate cache policy.\n• Security review: For example, handling of connection strings and other secrets, database permissions for non-deployment operation, input validation for raw SQL, encryption for sensitive data. See Secure authentication flows for secure configuration and authentication flow.\n• Make sure logging and diagnostics are sufficient and usable. For example, appropriate logging configuration, query tags, and Application Insights.\n• Error recovery. Prepare contingencies for common failure scenarios such as version rollback, fallback servers, scale-out and load balancing, DoS mitigation, and data backups.\n• Application deployment and migration. Plan out how migrations are going to be applied during deployment; doing it at application start can suffer from concurrency issues and requires higher permissions than necessary for normal operation. Use staging to facilitate recovery from fatal errors during migration. For more information, see Applying Migrations.\n• Detailed examination and testing of generated migrations. Migrations should be thoroughly tested before being applied to production data. The shape of the schema and the column types cannot be easily changed once the tables contain production data. For example, on SQL Server, and are rarely the best types for columns mapped to string and decimal properties, but those are the defaults that EF uses because it doesn't have knowledge of your specific scenario.\n\nFor introductory tutorials, see Getting Started with Entity Framework Core."
    },
    {
        "link": "https://github.com/dotnet/EntityFramework.Docs/blob/main/entity-framework/core/what-is-new/ef-core-6.0/whatsnew.md",
        "document": "EF Core 6.0 has shipped to NuGet. This page contains an overview of interesting changes introduced in this release.\n\nSQL Server temporal tables automatically keep track of all data ever stored in a table, even after that data has been updated or deleted. This is achieved by creating a parallel \"history table\" into which timestamped historical data is stored whenever a change is made to the main table. This allows historical data to be queried, such as for auditing, or restored, such as for recovery after accidental mutation or deletion.\n• The creation of temporal tables using Migrations\n• Transformation of existing tables into temporal tables, again using Migrations\n• Restoring data from some point in the past\n\nThe model builder can be used to configure a table as temporal. For example:\n\nWhen using EF Core to create the database, the new table will be configured as a temporal table with the SQL Server defaults for the timestamps and history table. For example, consider an entity type:\n\nThe temporal table created will look like this:\n\nNotice that SQL Server creates two hidden columns called and . These \"period columns\" represent the time range during which the data in the row existed. These columns are mapped to shadow properties in the EF Core model, allowing them to be used in queries as shown later.\n\nNotice also that an associated history table called is created automatically. The names of the period columns and history table can be changed with additional configuration to the model builder. For example:\n\nThis is reflected in the table created by SQL Server:\n\nMost of the time, temporal tables are used just like any other table. That is, the period columns and historical data are handled transparently by SQL Server such that the application can ignore them. For example, new entities can be saved to the database in the normal way:\n\nThis data can then be queried, updated, and deleted in the normal way. For example:\n\nAlso, after a normal tracking query, the values from the period columns of the current data can be accessed from the tracked entities. For example:\n\nNotice that the column (by default called ) contains the max value. This is always the case for the current rows in the table. The columns (by default called ) contains the UTC time that the row was inserted.\n\nEF Core supports queries that include historical data through several new query operators:\n• : Returns rows that were active (current) at the given UTC time. This is a single row from the current table or history table for a given primary key.\n• : Returns all rows in the historical data. This is typically many rows from the history table and/or the current table for a given primary key.\n• : Returns all rows that were active between two given UTC times. This may be many rows from the history table and/or the current table for a given primary key.\n• : The same as , except that rows are included that became active on the upper boundary.\n• : Returns all rows that started being active and ended being active between two given UTC times. This may be many rows from the history table and/or the current table for a given primary key.\n\nFor example, after making some updates and deletes to our data, we can run a query using to see the historical data:\n\nNotice how the EF.Property method can be used to access values from the period columns. This is used in the clause to sort the data, and then in a projection to include these values in the returned data.\n\nThis query brings back the following data:\n\nNotice that the last row returned stopped being active at 8/26/2021 4:44:59 PM. This is because the row for Rainbow Dash was deleted from the main table at that time. We will see later how this data can be restored.\n\nSimilar queries can be written using , , or . For example:\n\nThis query returns the following rows:\n\nAs mentioned above, Rainbow Dash was deleted from the table. This was clearly a mistake, so let's go back to a point-in-time and restore the missing row from that time.\n\nThis query returns a single row for Rainbow Dash as it was at the given UTC time. All queries using temporal operators are no-tracking by default, so the returned entity here is not tracked. This makes sense, because it does not currently exist in the main table. To re-insert the entity into the main table, we simply mark it as and then call .\n\nAfter re-inserting the row Rainbow Dash, querying the historical data shows that the row was restored as it was at the given UTC time:\n\nEF Core migrations are used to generate database schema updates based on changes to the EF model. These schema updates should be applied at application deployment time, often as part of a continuous integration/continuous deployment (C.I./C.D.) system.\n\nEF Core now includes a new way to apply these schema updates: migration bundles. A migration bundle is a small executable containing migrations and the code needed to apply these migrations to the database.\n\nMigration bundles are created using the command-line tool. Ensure that you have installed the latest version of the tool before continuing.\n\nA bundle needs migrations to include. These are created using as described in the migrations documentation. Once you have migrations ready to deploy, create a bundle using the . For example:\n\nThe output is an executable suitable for your target operating system. In my case this is Windows x64, so I get an dropped in my local folder. Running this executable applies the migrations contained within it:\n\nMigrations are applied to the database only if they have not been already applied. For example, running the same bundle again does nothing, since there are no new migrations to apply:\n\nHowever, if changes are made to the model and more migrations are generated with , then these can be bundled into a new executable ready to apply. For example:\n\nNotice that the option can be used to overwrite the existing bundle with a new one.\n\nExecuting this new bundle applies these two new migrations to the database:\n\nBy default, the bundle uses the database connection string from your application's configuration. However, a different database can be migrated by passing the connection string on the command line. For example:\n\nNotice that this time all three migrations were applied, since none of them had yet been applied to the production database.\n\nOther options can be passed to the command line. Some common options are:\n• to specify the path of executable file to create.\n• to specify the DbContext type to use when the project contains multiple context types.\n• to specify the project to use. Defaults to the current working directory.\n• to specify the startup project to use. Defaults to the current working directory.\n• to prevent the project from being built before running the command. This should only be used if the project is known to be up-to-date.\n• to see detailed information on what the command is doing. Use this option when including information in bug reports.\n\nUse to see all available options.\n\nNote that by default each migration is applied in its own transaction. See GitHub issue #22616 for a discussion of possible future enhancements in this area.\n\nPrevious versions of EF Core require that the mapping for every property of a given type is configured explicitly when that mapping differs from the default. This includes \"facets\" like the maximum length of strings and decimal precision, as well as value conversion for the property type.\n• Explicit iteration over all properties of all entity types and use of the low-level metadata APIs when building the model.\n\nNote that explicit iteration is error-prone and hard to do robustly because the list of entity types and mapped properties may not be final at the time this iteration happens.\n\nEF Core 6.0 allows this mapping configuration to be specified once for a given type. It will then be applied to all properties of that type in the model. This is called \"pre-convention model configuration\", since it configures aspects of the model that are then used by the model building conventions. Such configuration is applied by overriding on your :\n\nFor example, consider the following entity types:\n\nAll string properties can be configured to be ANSI (instead of Unicode) and have a maximum length of 1024:\n\nAll DateTime properties can be converted to 64-bit integers in the database, using the default conversion from DateTimes to longs:\n\nAll bool properties can be converted to the integers or using one of the built-in value converters:\n\nAssuming is a transient property of the entity and should not be persisted, it can be ignored everywhere in the model:\n\nPre-convention model configuration is very useful when working with value objects. For example, the type in the model above is represented by read-only struct:\n\nThis is then serialized to and from JSON using a custom value converter:\n\nThis value converter can be configured once for all uses of Money:\n\nNotice also that additional facets can be specified for the string column into which the serialized JSON is stored. In this case, the column is limited to a maximum length of 64.\n\nThe tables created for SQL Server using migrations show how the configuration has been applied to all mapped columns:\n\nIt is also possible to specify a default type mapping for a given type. For example:\n\nThis is rarely needed, but can be useful if a type is used in query in a way that is uncorrelated with any mapped property of the model.\n\nCompiled models can improve EF Core startup time for applications with large models. A large model typically means 100s to 1000s of entity types and relationships.\n\nStartup time means the time to perform the first operation on a DbContext when that DbContext type is used for the first time in the application. Note that just creating a DbContext instance does not cause the EF model to be initialized. Instead, typical first operations that cause the model to be initialized include calling or executing the first query.\n\nCompiled models are created using the command-line tool. Ensure that you have installed the latest version of the tool before continuing.\n\nA new command is used to generate the compiled model. For example:\n\nThe and options can be used to specify the directory and namespace into which the compiled model will be generated. For example:\n\nThe output from running this command includes a piece of code to copy-and-paste into your DbContext configuration to cause EF Core to use the compiled model. For example:\n\nIt is typically not necessary to look at the generated bootstrapping code. However, sometimes it can be useful to customize the model or its loading. The bootstrapping code looks something like this:\n\nThis is a partial class with partial methods that can be implemented to customize the model as needed.\n\nIn addition, multiple compiled models can be generated for DbContext types that may use different models depending on some runtime configuration. These should be placed into different folders and namespaces, as shown above. Runtime information, such as the connection string, can then be examined and the correct model returned as needed. For example:\n• Lazy loading and change-tracking proxies are not supported.\n• Custom IModelCacheKeyFactory implementations are not supported. However, you can compile multiple models and load the appropriate one as needed.\n• The model must be manually synchronized by regenerating it any time the model definition or configuration change.\n\nBecause of these limitations, you should only use compiled models if your EF Core startup time is too slow. Compiling small models is typically not worth it.\n\nIf supporting any of these features is critical to your success, then please vote for the appropriate issues linked above.\n\nThe model in the GitHub repo referenced above contains 449 entity types, 6390 properties, and 720 relationships. This is a moderately large model. Using BenchmarkDotNet to measure, the average time to first query is 1.02 seconds on a reasonably powerful laptop. Using compiled models brings this down to 117 milliseconds on the same hardware. An 8x to 10x improvement like this stays relatively constant as the model size increases.\n\nWe made significant improvements to query performance for EF Core 6.0. Specifically:\n• EF Core 6.0 performance is now 70% faster on the industry-standard TechEmpower Fortunes benchmark, compared to 5.0.\n• This is the full-stack perf improvement, including improvements in the benchmark code, the .NET runtime, etc.\n• Heap allocations have been reduced by 43% when executing queries.\n\nAfter these improvements, the gap between the popular \"micro-ORM\" Dapper and EF Core in the TechEmpower Fortunes benchmark narrowed from 55% to around a little under 5%.\n\nEF Core 6.0 contains many improvements to the Azure Cosmos DB database provider.\n\nWhen building a model for the Azure Cosmos DB provider, EF Core 6.0 will mark child entity types as owned by their parent entity by default. This removes the need for much of the and calls in the Azure Cosmos DB model. This makes it easier to embed child types into the document for the parent type, which is usually the appropriate way to model parents and children in a document database.\n\nFor example, consider these entity types:\n\nIn EF Core 5.0, these types would have been modeled for Azure Cosmos DB with the following configuration:\n\nIn EF Core 6.0, the ownership is implicit, reducing the model configuration to:\n\nThe resulting Azure Cosmos DB documents have the family's parents, children, pets, and address embedded in the family document. For example:\n\nEF Core 6.0 natively maps collections of primitive types when using the Azure Cosmos DB database provider. For example, consider this entity type:\n\nBoth the list and the dictionary can be populated and inserted into the database in the normal way:\n\nThis results in the following JSON document:\n\nThese collections can then be updated, again in the normal way:\n• Only dictionaries with string keys are supported\n• Querying into the contents of primitive collections is not currently supported. Vote for #16926, #25700, and #25701 if these features are important to you.\n\nThe Azure Cosmos DB provider now translates more Base Class Library (BCL) methods to Azure Cosmos DB built-in-functions. The following tables show translations that are new in EF Core 6.0.\n\nTranslations for , , , , , and were contributed by @Marusyk. Many thanks!\n\nThese translations were contributed by @Marusyk. Many thanks!\n\nThese translations were contributed by @Marusyk. Many thanks!\n\nSometimes it is necessary to execute a raw SQL query instead of using LINQ. This is now supported with the Azure Cosmos DB provider through use of the method. This works the same way it always has done with relational providers. For example:\n\nWhich is executed as:\n\nSimple queries using are now translated. For example:\n\nThe Azure Cosmos DB provider now logs more diagnostic information, including events for inserting, querying, updating, and deleting data from the database. The request units (RU) are included in these events whenever appropriate.\n\nInserting an item into the Azure Cosmos DB database generates the event. For example, this code:\n\nRetrieving items from the Azure Cosmos DB database using a query generates the event, and then one or more events for the items read. For example, this code:\n\nRetrieving a single item from the Azure Cosmos DB database using with a partition key generates the and events. For example, this code:\n\nSaving an updated item to the Azure Cosmos DB database generates the event. For example, this code:\n\nDeleting an item from the Azure Cosmos DB database generates the event. For example, this code:\n\nThe Azure Cosmos DB model can now be configured with manual or auto-scale throughput. These values provision throughput on the database. For example:\n\nIn addition, individual entity types can be configured to provision throughput for the corresponding container. For example:\n\nEntity types in the Azure Cosmos DB model can now be configured with the default time-to-live and time-to-live for the analytical store. For example:\n\nGitHub Issue: #21274. This feature was contributed by @dnperfors. Many thanks!\n\nThe used by the Azure Cosmos DB provider can now be set explicitly. This can be especially useful during testing, for example to bypass certificate validation when using the Azure Cosmos DB emulator on Linux:\n\nEF Core 6.0 contains several improvements when reverse engineering an EF model from an existing database.\n\nEF Core 6.0 detects simple join tables and automatically generates a many-to-many mapping for them. For example, consider tables for and , and a join table connecting them:\n\nThese tables can be scaffolded from the command line. For example:\n\nThis results in a class for Post:\n\nBut no class for the table. Instead, configuration for a many-to-many relationship is scaffolded:\n\nEF Core 6.0 now scaffolds an EF model and entity types that use C# nullable reference types (NRTs). NRT usage is scaffolded automatically when NRT support is enabled in the C# project into which the code is being scaffolded.\n\nFor example, the following table contains both nullable non-nullable string columns:\n\nThis results in corresponding nullable and non-nullable string properties in the generated class:\n\nSimilarly, the following tables contains a required relationship to the table:\n\nThis results in the scaffolding of non-nullable (required) relationship between blogs:\n\nFinally, DbSet properties in the generated DbContext are created in a NRT-friendly way. For example:\n\nGitHub Issue: #19113. This feature was contributed by @ErikEJ. Many thanks!\n\nComments on SQL tables and columns are now scaffolded into the entity types created when reverse-engineering an EF Core model from an existing SQL Server database.\n\nEF Core 6.0 contains several improvements in the translation and execution of LINQ queries.\n\nEF Core 6.0 contains better support for queries. Specifically, EF Core now:\n• Translate GroupBy followed by (or similar) over a group\n• Expands navigations after the operator has been applied\n\nThe following are example queries from customer reports and their translation on SQL Server.\n\nThe entity types used for these examples are:\n\nGitHub Issue: #23859. This feature was contributed by @wmeints. Many thanks!\n\nStarting with EF Core 6.0, calls to xref:System.String.Concat*?displayProperty=nameWithType with multiple arguments are now translated to SQL. For example, the following query:\n\nWill be translated to the following SQL when using SQL Server:\n\nThe System.Linq.Async package adds client-side async LINQ processing. Using this package with previous versions of EF Core was cumbersome due to a namespace clash for the async LINQ methods. In EF Core 6.0 we have taken advantage of C# pattern matching for xref:System.Collections.Generic.IAsyncEnumerable`1 such that the exposed EF Core xref:Microsoft.EntityFrameworkCore.DbSet`1 does not need to implement the interface directly.\n\nNote that most applications do not need to use System.Linq.Async since EF Core queries are usually fully translated on the server.\n\nIn EF Core 6.0, we have relaxed the parameter requirements for xref:Microsoft.EntityFrameworkCore.SqlServerDbFunctionsExtensions.FreeText(Microsoft.EntityFrameworkCore.DbFunctions,System.String,System.String) and xref:Microsoft.EntityFrameworkCore.SqlServerDbFunctionsExtensions.Contains*. This allows these functions to be used with binary columns, or with columns mapped using a value converter. For example, consider an entity type with a property defined as a value object:\n\nThis is mapped to JSON in the database:\n\nA query can now be executed using or even though the type of the property is not . For example:\n\nThis generates the following SQL, when using SQL Server:\n\nGitHub Issue: #17223. This feature was contributed by @ralmsdeveloper. Many thanks!\n\nCalls to xref:System.Object.ToString are now translated to SQL when using the SQLite database provider. This can be useful for text searches involving non-string columns. For example, consider a entity type that stores phone numbers as numeric values:\n\ncan be used to convert the number to a string in the database. We can then use this string with a function such as to find numbers that match a pattern. For example, to find all numbers containing 555:\n\nThis translates to the following SQL when using a SQLite database:\n\nNote that translation of xref:System.Object.ToString for SQL Server is already supported in EF Core 5.0, and may also be supported by other database providers.\n\nGitHub Issue: #16141. This feature was contributed by @RaymondHuy. Many thanks!\n\nmaps to a database function returning a pseudo-random number between 0 and 1 exclusive. Translations have been implemented in the EF Core repo for SQL Server, SQLite, and Azure Cosmos DB. For example, consider a entity type with a property:\n\ncan have values from 1 to 5 inclusive. Using we can write a query to return all users with a randomly chosen popularity:\n\nThis translates to the following SQL when using a SQL Server database:\n\nGitHub Issue: #22916. This feature was contributed by @Marusyk. Many thanks!\n\nConsider the following query:\n\nBefore EF Core 6.0, this was translated to the following on SQL Server:\n\nThis translation has been improved for EF Core 6.0 to:\n\nA new method can be used to write a defining query against the in-memory database for a given entity type. This is most useful for creating the equivalent of views on the in-memory database, especially when those views return keyless entity types. For example, consider a customer database for customers based in the United Kingdom. Each customer has an address:\n\nNow, imagine we want a view over this data that shows how many customers their are into each postcode area. We can create a keyless entity type to represent this:\n\nAnd define a DbSet property for it on the DbContext, along with sets for other top-level entity types:\n\nThen, in , we can write a LINQ query that defines the data to be returned for :\n\nThis can then be queried just like any other DbSet property:\n\nGitHub Issue: #20173. This feature was contributed by @stevendarby. Many thanks!\n\nEF Core 6.0 now translates uses of with a single argument. For example:\n\nThis translates to the following SQL when using SQL Server:\n\nEF Core supports splitting a single LINQ query into multiple SQL queries. In EF Core 6.0, this support has been expanded to include cases where non-navigation collections are contained in the query projection.\n\nThe following are example queries showing the translation on SQL Server into either a single query or multiple queries.\n\nWhen loading related one-to-many entities, EF Core adds ORDER BY clauses to make sure all related entities for a given entity are grouped together. However, the last ORDER BY clause is not necessary for EF generate the needed groupings, and can have an impact in performance. Therefore, EF Core 6.0 this clause is removed.\n\nFor example, consider this query:\n\nWith EF Core 5.0 on SQL Server, this query is translated to:\n\nWith EF Core 6.0, it is instead translated to:\n\nGitHub Issue: #14176. This feature was contributed by @michalczerwinski. Many thanks!\n\nQuery tags allow adding a textural tag to a LINQ query such that it is then included in the generated SQL. In EF Core 6.0, this can be used to tag queries with the filename and line number of the LINQ code. For example:\n\nThis results in the following generated SQL when using SQL Server:\n\nIt becomes tricky to know whether an optional dependent entity exists or not when it shares a table with its principal entity. This is because there is a row in the table for the dependent because the principal needs it, regardless of whether or not the dependent exists. The way to handle this unambiguously is to ensure that the dependent has at least one required property. Since a required property cannot be null, it means if the value in the column for that property is null, then the dependent entity does not exist.\n\nFor example, consider a class where each customer has an owned :\n\nThe address is optional, meaning that it is valid to save a customer with no address:\n\nHowever, if a customer does have an address, then that address must have at least a non-null postcode:\n\nThis is ensured by marking the property as .\n\nNow when customers are queried, if the Postcode column is null, then this means the customer does not have an address, and the navigation property is left null. For example, iterating through the customers and checking if the Address is null:\n\nConsider instead the case where no property off the address is required:\n\nNow it is possible to save both a customer with no address, and a customer with an address where all the address properties are null:\n\nHowever, in the database, these two cases are indistinguishable, as we can see by directly querying the database columns:\n\nFor this reason, EF Core 6.0 will now warn you when saving an optional dependent where all of its properties are null. For example:\n\nThis becomes even more tricky where the optional dependent itself acts a a principal for a further optional dependent, also mapped to the same table. Rather than just warning, EF Core 6.0 disallows just cases of nested optional dependents. For example, consider the following model, where is owned by and is in turned owned by :\n\nNow if is null, then EF Core will not create an instance of if the relationship is optional, even though the address itself may have data. For this kind of model, EF Core 6.0 will throw the following exception:\n\nThe bottom line here is to avoid the case where an optional dependent can contain all nullable property values and shares a table with its principal. There are three easy ways to avoid this:\n• Make the dependent required. This means that the dependent entity will always have a value after it is queried, even if all its properties are null.\n• Make sure that the dependent contains at least one required property, as described above.\n• Save optional dependents to their own table, instead of sharing a table with the principal.\n\nA dependent can be made required by using the attribute on it's navigation:\n\nOr by specifying it is required in :\n\nDependents can be saved to a different table by specifying the tables to use in :\n\nSee the OptionalDependentsSample in GitHub for more examples of optional dependents, including cases with nested optional dependents.\n\nEF Core 6.0 contains several new attributes that can be applied to code to change the way it is mapped to the database.\n\nGitHub Issue: #19794. This feature was contributed by @RaymondHuy. Many thanks!\n\nStarting with EF Core 6.0, a string property can now be mapped to a non-Unicode column using a mapping attribute without specifying the database type directly. For example, consider a entity type with a property for the International Standard Book Number (ISBN) in the form \"ISBN 978-3-16-148410-0\":\n\nSince ISBNs cannot contain any non-unicode characters, the attribute will cause a non-Unicode string type to be used. In addition, is used to limit the size of the database column. For example, when using SQL Server, this results in a database column of :\n\nGitHub Issue: #17914. This feature was contributed by @RaymondHuy. Many thanks!\n\nThe precision and scale of a database column can now be configured using mapping attributes without specifying the database type directly. For example, consider a entity type with a decimal property:\n\nEF Core will map this property to a database column with precision 10 and scale 2. For example, on SQL Server:\n\nGitHub Issue: #23163. This feature was contributed by @KaloyanIT. Many thanks!\n\nxref:Microsoft.EntityFrameworkCore.IEntityTypeConfiguration`1 instances allow xref:Microsoft.EntityFrameworkCore.ModelBuilder configuration for each entity type to be contained in its own configuration class. For example:\n\nNormally, this configuration class must be instantiated and called into from xref:Microsoft.EntityFrameworkCore.DbContext.OnModelCreating*?displayProperty=nameWithType. For example:\n\nStarting with EF Core 6.0, an can be placed on the entity type such that EF Core can find and use appropriate configuration. For example:\n\nThis attribute means that EF Core will use the specified implementation whenever the entity type is included in a model. The entity type is included in a model using one of the normal mechanisms. For example, by creating a xref:Microsoft.EntityFrameworkCore.DbSet`1 property for the entity type:\n\nOr by registering it in xref:Microsoft.EntityFrameworkCore.DbContext.OnModelCreating*:\n\nIn addition to new mapping attributes, EF Core 6.0 contains several other improvements to the model building process.\n\nSQL Server sparse columns are ordinary columns that are optimized to store null values. This can be useful when using TPH inheritance mapping where properties of a rarely used subtype will result in null column values for most rows in the table. For example, consider a class that extends from :\n\nThere may be millions of users, with only a handful of these being moderators. This means mapping the as sparse might make sense here. This can now be configured using in xref:Microsoft.EntityFrameworkCore.DbContext.OnModelCreating*. For example:\n\nEF Core migrations will then mark the column as sparse. For example:\n\nBefore EF Core 6.0, the generic overloads of the methods used the generic parameter to specify the type to convert to. For example, consider a enum:\n\nEF Core can be configured to save values of this enum as the strings \"UsDollars\", \"PoundsStirling\", and \"Euros\" using . For example:\n\nStarting with EF Core 6.0, the generic type can instead specify a value converter type. This can be one of the built-in value converters. For example, to store the enum values as 16-bit numbers in the database:\n\nOr it can be a custom value converter type. For example, consider a converter that stores the enum values as their currency symbols:\n\nThis can now be configured using the generic method:\n\nUnambiguous many-to-many relationships between two entity types are discovered by convention. Where necessary or if desired, the navigations can be specified explicitly. For example:\n\nIn both these cases, EF Core creates a shared entity typed based on to act as the join entity between the two types. Starting with EF Core 6.0, can be added to the configuration to change only this type, without the need for additional configuration. For example:\n\nIn addition, the join entity type can be additional configured without needing to specify the left and right relationships explicitly. For example:\n\nAnd finally, the full configuration can be supplied. For example:\n\nValue converters do not generally allow the conversion of null to some other value. This is because the same value converter can be used for both nullable and non-nullable types, which is very useful for PK/FK combinations where the FK is often nullable and the PK is not.\n\nStarting with EF Core 6.0, a value converter can be created that does convert nulls. However, validation of this feature has revealed proved it to be very problematic in practice with many pitfalls. For example:\n• Value conversion to null in the store generates bad queries\n• Value conversion from null in the store generates bad queries\n• Value converters do not handle cases where the database column has multiple different values that convert to the same value\n• Allow value converters to change nullability of columns\n\nThese are not trivial issues and for the query issues they are not easy to detect. Therefore, we have marked this feature as internal for EF Core 6.0. You can still use it, but you will get a compiler warning. The warning can be disabled using .\n\nOne example of where converting nulls can be useful is when the database contains nulls, but the entity type wants to use some other default value for the property. For example, consider an enum where its default value is \"Unknown\":\n\nHowever, the database may have null values when the breed is unknown. In EF Core 6.0, a value converter can be used to account for this:\n\nCats with a breed of \"Unknown\" will have their column set to null in the database. For example:\n\nWhich generates the following insert statements on SQL Server:\n\nSometimes it is useful to have both a DbContext type and a factory for contexts of that type both registered in the applications dependency injection (D.I.) container. This allows, for example, a scoped instance of the DbContext to be resolved from the request scope, while the factory can be used to create multiple independent instances when needed.\n\nTo support this, now also registers the DbContext type as a scoped service. For example, consider this registration in the application's D.I. container:\n\nWith this registration, the factory can be resolved from the root D.I. container, just as in previous versions:\n\nNote that context instances created by the factory must be explicitly disposed.\n\nIn addition, a DbContext instance can be resolved directly from a container scope:\n\nIn this case the context instance is disposed when the container scope is disposed; the context should not be disposed explicitly.\n\nAt a higher level, this means that either the DbContext of the factory can be injected into other D.I. types. For example:\n\nEF Core 6.0 now allows both a parameterless DbContext constructor, and a constructor that takes to be used on the same context type when the factory is registered through . For example, the context used in the examples above contains both constructors:\n\nThe type has been made public so that it can be used as a stand-alone pool for DbContext instances, without the need for your application to have a dependency injection container. The pool is created with an instance of that will be used to create context instances:\n\nThe factory can then be used to create and pool instances. For example:\n\nInstances are returned to the pool when they are disposed.\n\nAnd finally, EF Core contains several improvements in areas not covered above.\n\nThe property of can now be used to order columns when creating a table with migrations. For example, consider the following model:\n\nBy default, EF Core orders primary key columns first, following by properties of the entity type and owned types, and finally properties from base types. For example, the following table is created on SQL Server:\n\nIn EF Core 6.0, can be used to specify a different column order. For example:\n\nOn SQL Server, the table generated is now:\n\nThis moves the and columns are moved to the top, even though they are defined in a base type. Notice that the column order values can have gaps, allowing ranges to be used to always place columns at the end, even when used by multiple derived types.\n\nThis example also shows how the same can be used to specify both the column name and order.\n\nColumn ordering can also be configured using the API in . For example:\n\nOrdering on the model builder with takes precedence over any order specified with . This means can be used to override ordering made with attributes, including resolving any conflicts when attributes on different properties specify the same order number.\n\n.NET Core 6.0 includes updated templates that feature simplified \"minimal APIs\" which remove a lot of the boilerplate code traditionally needed in .NET applications.\n\nEF Core 6.0 contains a new extension method that registers a DbContext type and supplies the configuration for a database provider in a single line. For example:\n\nThese are exactly equivalent to:\n\nCheck out these resources to learn more about minimal APIs:\n• The presentation Minimal APIs in .NET 6 by Maria Naggaga\n• The gist Minimal APIs at a glance by David Fowler\n\nWe changed the EF Core code in the 5.0 release to set xref:System.Threading.Tasks.Task.ConfigureAwait*?displayProperty=nameWithType to in all places where we async code. This is generally a better choice for EF Core usage. However, xref:System.Data.Entity.DbContext.SaveChangesAsync* is a special case because EF Core will set generated values into tracked entities after the async database operation is complete. These changes may then trigger notifications which, for example, may have to run on the U.I. thread. Therefore, we are reverting this change in EF Core 6.0 for the xref:System.Data.Entity.DbContext.SaveChangesAsync* method only.\n\nGitHub Issue: #10613. This feature was contributed by @fagnercarvalho. Many thanks!\n\nThe EF Core in-memory database will now throw an exception if an attempt is made to save a null value for a property marked as required. For example, consider a type with a required property:\n\nAttempting to save an entity with a null will result in the following exception:\n\nThis validation can be disabled if necessary. For example:\n\nGitHub Issue: #23719. This feature was contributed by @Giorgi. Many thanks!\n\nThe supplied to diagnostics sources and interceptors now contains an enum value indicating which part of EF was responsible for creating the command. This can be used as a filter in the diagnostics or interceptor. For example, we may want an interceptor that only applies to commands that come from :\n\nThis filters the interceptor to only events when used in an application which also generates migrations and queries. For example:\n\nEF Core does not expose temporary values on entity type instances. For example, consider a entity type with a store-generated key:\n\nThe key property will get a temporary value as soon as a is tracked by the context. For example, when calling :\n\nThe temporary value can be obtained from the context change tracker, but is not set into the entity instance. For example, this code:\n\nThis is good because it prevents the temporary value leaking into application code where it can accidentally be treated as non-temporary. However, sometimes it is useful to deal with temporary values directly. For example, an application may want to generate its own temporary values for a graph of entities before they are tracked so that they can be used to form relationships using foreign keys. This can be done by explicitly marking the values as temporary. For example:\n\nIn EF Core 6.0, the value will remain on the entity instance even though it is now marked as temporary. For example, the code above generates the following output:\n\nLikewise, temporary values generated by EF Core can be set explicitly on to entity instances and marked as temporary values. This can be used to explicitly set relationships between new entities using their temporary key values. For example:\n\nThe EF Core codebase now uses C# nullable reference types (NRTs) throughout. This means that you will get the correct compiler indications for null usage when using EF Core 6.0 from your own code.\n\nIt is common practice to keep database connections open for as little time as possible. This helps prevent contention on the connection resource. This is why libraries like EF Core open the connection immediately before performing a database operation, and close it again immediately after. For example, consider this EF Core code:\n\nThe output from this code, with logging for connections turned on, is:\n\nNotice that the connection is opened and closed rapidly for each operation.\n\nHowever, for most database systems, opening a physical connection to the database is an expensive operation. Therefore most ADO.NET providers create a pool of physical connections and rent them out to instances as needed.\n\nSQLite is a little bit different since database access is typically just accessing a file. This means opening a connection to a SQLite database is usually very fast. However, this is not always the case. For example, opening a connection to an encrypted database can be very slow. Therefore, SQLite connections are now pooled when using Microsoft.Data.Sqlite 6.0.\n\nMicrosoft.Data.Sqlite 6.0 supports the new and types from .NET 6. These can also be used in EF Core 6.0 with the SQLite provider. As always with SQLite, its native type system means that the values from these types need to be stored as one of the four supported types. Microsoft.Data.Sqlite stores them as . For example, an entity using these types:\n\nMaps to the following table in the SQLite database:\n\nValues can then be saved, queried, and updated in the normal way. For example, this EF Core LINQ query:\n\nIs translated into the following on SQLite:\n\nAnd returns only uses with birthdays before 1900 CE:\n\nWe have been standardizing on a common API for savepoints in ADO.NET providers. Microsoft.Data.Sqlite now supports this API, including:\n• xref:System.Data.Common.DbTransaction.Save(System.String) to create a savepoint in the transaction\n\nUsing a savepoint allows part of a transaction to be rolled back without rolling back the entire transaction. For example, the code below:\n• Sends an update to the database\n• Sends another update to the database\n\nThis will result in the first update being committed to the database, while the second update is not committed since the savepoint was rolled back before committing the transaction.\n\nGitHub Issue: #22505. This feature was contributed by @nmichels. Many thanks!\n• The connection timeout, which determines the maximum time to wait when making a connection to the database.\n• The command timeout, which determines the maximum time to wait for a command to complete executing.\n\nThe command timeout can be set from code using xref:System.Data.Common.DbCommand.CommandTimeout?displayProperty=nameWithType. Many providers are now also exposing this command timeout in the connection string. Microsoft.Data.Sqlite is following this trend with the connection string keyword. For example, will use 60 seconds as the default timeout for commands created by the connection."
    },
    {
        "link": "https://learnentityframeworkcore.com",
        "document": "Entity Framework Core (EF Core) is the recommended Object-Relational Mapper (ORM) for .NET, formerly known as .NET Core. As the successor to EF6, EF Core has been entirely reengineered and made open source on GitHub.\n\nWhy use an ORM?\n\nAn ORM (Object-Relational Mapper) is used to interact with a database using an object-oriented programming language. ORMs allow developers to work with databases using familiar, object-oriented concepts, rather than writing raw SQL statements.\n• This can make the development process more efficient and less error-prone, as well as allow for easier maintenance of the codebase.\n• Additionally, ORMs often provide features such as caching, lazy loading, and connection pooling, which can improve application performance.\n• They also provide an abstraction layer between the application and the database, so that the application code can be insulated from changes to the underlying database schema.\n• This can make it easier to switch to a different database in the future or to improve scalability by distributing the data across multiple servers.\n• Overall, ORMs can help improve developer productivity, code maintainability, and application performance.\n\nMost development frameworks include libraries that enable access to data from relational databases via recordset-like data structures. The following code sample illustrates a typical scenario where data is retrieved from a database and stored in an ADO.NET so that it is accessible to the program's code:\n\nThe data within the DataTable is accessible via numeric or string indexers and needs to be converted from to the correct type:\n\nThis late-bound or \"weakly-typed\" approach to data access is prone to error. Problems commonly arise from mistyping the name of a column, finding that the name of the column has been changed in the database, or from a change to the order in which fields are specified in the SQL statement without a corresponding change being made to the application code. Equally, data type conversions might fail. The code will still compile but will error at runtime. Consequently, professional developers prefer to work with data in a strongly-typed manner.\n\nEntity Framework Core (EF Core) has several features that make it a powerful and efficient tool for data access and management:\n• Cross-platform: EF Core can be used on a variety of platforms including Windows, Linux, and Mac.\n• Lightweight: EF Core has a smaller footprint and fewer dependencies than the full version of Entity Framework.\n• Code first: EF Core allows developers to create a database from code, which enables a more agile and test-driven development workflow.\n• LINQ support: EF Core supports LINQ, a powerful and expressive query language, which allows developers to write efficient and readable queries using C# or Visual Basic.\n• Support for multiple databases: EF Core supports a wide range of relational databases including SQL Server, MySQL, MariaDB, SQLite, and PostgreSQL.\n• Migrations: EF Core has built-in support for creating and managing database migrations, which allows for easy management of database changes over time.\n• Performance improvements: EF Core has been optimized for performance and can handle large datasets efficiently.\n\nEntity Framework Core (EF Core) is an ORM (Object-Relational Mapping) framework for the .NET platform. One of the key features of EF Core is its support for strong typing.\n• When working with EF Core, you define your database schema using C# classes known as entities, these classes are then mapped to the corresponding tables in the database.\n• Because the entities are strongly typed, the compiler can catch any errors related to the schema at compile-time, rather than at runtime.\n• Additionally, EF Core supports the use of LINQ (Language-Integrated Query) to query the data in the database, which provides a strongly-typed, expressive, and easy-to-use API for querying data.\n• This can make it easier for developers to write maintainable and efficient code.\n\nWhen you take a strongly-typed approach to data, you work with properties of predefined classes that form a domain model in an object-oriented way:\n\nWork still needs to be done to retrieve and map the data from the database to an instance of the domain object. One option is to write your code to manage this. However, as the domain model grows, the amount of code required can grow and will need more and more development time to maintain. This will increase the overall amount of time required to complete an application.\n\nORMs are pre-written libraries of code that do this work for you. Full-featured ORMs do a lot more too. They can\n• create databases and maintain the schema in line with changes to the model\n• generate SQL and execute it against the database\n• keep track of objects that have already been retrieved\n• How To Get Entity Framework Core"
    },
    {
        "link": "https://medium.com/@lucas.and227/step-by-step-guide-to-entity-framework-in-net-c629faf9f322",
        "document": "Entity Framework (EF) is a powerful and widely used Object-Relational Mapping (ORM) tool for .NET Core developers. It simplifies database interactions by allowing you to work with database objects as if they were regular C# objects.\n\nIn this step-by-step guide, we’ll walk you through the process of installing and implementing Entity Framework in a .NET Core application. We’ll also use SQL Server as the database and show you how to install the required NuGet package, EntityFrameworkCore.SqlServer.\n\nBefore we begin, make sure you have the following prerequisites in place:\n• .NET Core SDK: Download and install the .NET Core SDK from the official website (https://dotnet.microsoft.com/download).\n• Visual Studio or Visual Studio Code: You can use your preferred Integrated Development Environment (IDE).\n• SQL Server: Install and set up SQL Server on your machine or use an existing SQL Server instance.\n\nOpen your command-line interface or IDE, and create a new .NET Core project by running the following command:\n\nThis command will create a new console application with the name “EFCoreExample.”\n\nTo use Entity Framework in your project, you need to install the EntityFrameworkCore.SqlServer package. Navigate to your project folder and run the following command:\n\nOr use the Nuget Package manager:\n\nIn this example, we’ll create a User class to represent the data we want to store in the database. Create a new file named “User.cs” in your project and define the User class as follows:\n\nEntity Framework uses a DbContext class to represent your database and its tables. Create a new file named “AppDbContext.cs” in your project and define your DbContext class:\n\nThe DbSet<> is used to represent the tables that your entities represent.\n\nWhile the OnModelCreating() method maps the entities by the assembly, and each entity should have a map class, like:\n\nFor the DbContext function how it musts, the database must be configured, and we do that by configuring the ConnectionString. For that, on your appsettings.json you must add:\n\nThen, on the Program.cs add the following:\n\nNow that you’ve set up your User class and DbContext, it’s time to create and apply the database migration. In your project directory, run the following commands:\n\nOr use the Package Manager Console:\n\nThese commands will create the initial database migration and apply it to your SQL Server instance. At this step, your appsettings.json must have your ConnectionString already.\n\nNow, you can use Entity Framework to interact with the database in your application. Here’s an example of how to add a new user to the database:\n\nYou have successfully installed and implemented Entity Framework in a .NET Core application.\n\nEntity Framework simplifies database operations and allows you to work with your data using C# objects. You can now build upon this foundation to create more complex database-driven applications with ease."
    },
    {
        "link": "https://newtonsoft.com/json/help/html/serializingjson.htm",
        "document": "The quickest method of converting between JSON text and a .NET object is using the JsonSerializer. The JsonSerializer converts .NET objects into their JSON equivalent and back again by mapping the .NET object property names to the JSON property names and copies the values for you.\n\nFor simple scenarios where you want to convert to and from a JSON string, the SerializeObject and DeserializeObject methods on JsonConvert provide an easy-to-use wrapper over JsonSerializer. SerializeObject and DeserializeObject both have overloads that take a JsonSerializerSettings object. JsonSerializerSettings lets you use many of the JsonSerializer settings listed below while still using the simple serialization methods.\n\nFor more control over how an object is serialized, the JsonSerializer can be used directly. The JsonSerializer is able to read and write JSON text directly to a stream via JsonTextReader and JsonTextWriter. Other kinds of JsonWriters can also be used, such as JTokenReader/JTokenWriter, to convert your object to and from LINQ to JSON objects, or BsonReader/BsonWriter, to convert to and from BSON. JsonSerializer has a number of properties on it to customize how it serializes JSON. These can also be used with the methods on JsonConvert via the JsonSerializerSettings overloads. You can read more about the available JsonSerializer settings here: Serialization Settings"
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/overview",
        "document": "The System.Text.Json namespace provides functionality for serializing to and deserializing from (or marshalling and unmarshalling) JavaScript Object Notation (JSON). Serialization is the process of converting the state of an object, that is, the values of its properties, into a form that can be stored or transmitted. The serialized form doesn't include any information about an object's associated methods. Deserialization reconstructs an object from the serialized form.\n\nThe library design emphasizes high performance and low memory allocation over an extensive feature set. Built-in UTF-8 support optimizes the process of reading and writing JSON text encoded as UTF-8, which is the most prevalent encoding for data on the web and files on disk.\n\nThe library also provides classes for working with an in-memory document object model (DOM). This feature enables random access to the elements in a JSON file or string.\n\nFor Visual Basic, there are some limitations on what parts of the library you can use. For more information, see Visual Basic support.\n\nHow to get the library\n\nThe library is built-in as part of the shared framework for .NET Core 3.0 and later versions. The source generation feature is built-in as part of the shared framework for .NET 6 and later versions.\n\nFor framework versions earlier than .NET Core 3.0, install the System.Text.Json NuGet package. The package supports:\n• The System.Text.Json namespace contains all the entry points and the main types.\n• The System.Text.Json.Serialization namespace contains attributes and APIs for advanced scenarios and customization specific to serialization and deserialization.\n• The System.Net.Http.Json namespace contains extension methods for serializing and deserializing JSON payloads from the network.\n\nBy default, gathers the metadata it needs to access properties of objects for serialization and deserialization at run time using reflection. As an alternative, can use the C# source generation feature to improve performance, reduce private memory usage, and facilitate assembly trimming, which reduces app size.\n\nFor more information, see Reflection versus source generation.\n\nFor information about security threats that were considered when designing JsonSerializer, and how they can be mitigated, see Threat Model.\n\nThe serializer was designed with thread safety in mind. Practically, this means that once locked, JsonSerializerOptions instances can be safely shared across multiple threads. JsonDocument provides an immutable, and in .NET 8 and later versions, thread-safe, DOM representation for JSON values.\n• How to use the library"
    },
    {
        "link": "https://stackoverflow.com/questions/60117142/how-to-handle-object-references-in-json-document-with-newtonsoft-json-net",
        "document": "You'll need some mechanism that resolves those references.\n\nHere are two approaches:\n\nOne such mechanism is the Newtonsoft serializer's property, which does exactly what you describe, except it looks for and instead of and .\n\nTo use this, you could transform the JSON tree before it's being converted into typed objects, by first reading it into a JSON tree representation (using ), then traversing this tree, replacing and properties with and (since the intermediate JSON tree is modifiable and dynamic in nature, you can do this easily).\n\nThen you could convert this transformed tree into your typed objects using the built-in reference resolution mechanism, by using to obtain a over the transformed tree, which you can give to to instruct it to deserialize it into your desired type.\n\nA more complex approach, if you want to do it yourself: you'll need to add your own reference resolution layer, which would transform the JSON tree before it's converted into typed objects.\n\nHere again, you can start by reading the JSON stream into a JSON tree representation. Then then you'll need to traverse that tree twice:\n• None On the first traversal you'll look for objects with an property, and record them in a dictionary (from to the object containing it).\n• None On the second traversal you'll look for objects with a property, and replace those ref-objects with the appropriate value, by looking up the referenced object by its in the dictionary you created earlier, then navigating its properties according to the property chain described in the value. For example, if the ref is , you'll look up the object with ID 3, then find the value of its property, and then the value of the property of that value, and that would be the final value of the reference.\n\nOnce the JSON tree has been transformed and all reference-objects have been replaced by their corresponding referenced values, you can convert the JSON tree into a typed object.\n\nCode-wise that would be exactly the same as the previous example, except in , instead of just renaming the and properties, you'll have to implement the actual lookup and reference resolution logic.\n\nIt could look something like this:\n\nEDIT: Also take a look at which allows you to navigate a property chain from a string or , saving a lot of trouble from the above (assuming the reference syntax in your document matches the one Newtonsoft supports, e.g. with respect to array indices).\n\nIt's been years since I wrote any C# so please excuse any syntax errors or non-idiomatic usage. But that's the general idea."
    },
    {
        "link": "https://newtonsoft.com",
        "document": "Query JSON with an XPath-like syntax. Find out more about JSON Path here\n\nLINQ to JSON Create, parse, query and modify JSON using Json.NET's JObject, JArray and JValue objects.\n\nWorld-class JSON Serializer Serialize and deserialize any .NET object with Json.NET's powerful JSON serializer.\n\n50% faster than DataContractJsonSerializer, and 250% faster than JavaScriptSerializer.\n\nJson.NET makes the simple easy and the complex possible.\n\nIf you need it, Json.NET supports converting between XML and JSON."
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/migrate-from-newtonsoft",
        "document": "This article shows how to migrate from Newtonsoft.Json to System.Text.Json.\n\nThe namespace provides functionality for serializing to and deserializing from JavaScript Object Notation (JSON). The library is included in the runtime for .NET Core 3.1 and later versions. For other target frameworks, install the System.Text.Json NuGet package. The package supports:\n\nfocuses primarily on performance, security, and standards compliance. It has some key differences in default behavior and doesn't aim to have feature parity with . For some scenarios, currently has no built-in functionality, but there are recommended workarounds. For other scenarios, workarounds are impractical.\n\nThe team is investing in adding the features that are most often requested. If your application depends on a missing feature, consider filing an issue in the dotnet/runtime GitHub repository to find out if support for your scenario can be added.\n\nMost of this article is about how to use the JsonSerializer API, but it also includes guidance on how to use the JsonDocument (which represents the Document Object Model or DOM), Utf8JsonReader, and Utf8JsonWriter types.\n\nIn Visual Basic, you can't use Utf8JsonReader, which also means you can't write custom converters. Most of the workarounds presented here require that you write custom converters. You can write a custom converter in C# and register it in a Visual Basic project. For more information, see Visual Basic support.\n\nThe following table lists features and equivalents. The equivalents fall into the following categories:\n• ✔️ Supported by built-in functionality. Getting similar behavior from might require the use of an attribute or global option.\n• ⚠️ Not supported, but workaround is possible. The workarounds are custom converters, which might not provide complete parity with functionality. For some of these, sample code is provided as examples. If you rely on these features, migration will require modifications to your .NET object models or other code changes.\n• ❌ Not supported, and workaround is not practical or possible. If you rely on these features, migration will not be possible without significant changes.\n\nThis is not an exhaustive list of features. The list includes many of the scenarios that have been requested in GitHub issues or StackOverflow posts. If you implement a workaround for one of the scenarios listed here that doesn't currently have sample code, and if you want to share your solution, select This page in the Feedback section at the bottom of this page. That creates an issue in this documentation's GitHub repo and lists it in the Feedback section on this page too.\n\nSystem.Text.Json is strict by default and avoids any guessing or interpretation on the caller's behalf, emphasizing deterministic behavior. The library is intentionally designed this way for performance and security. is flexible by default. This fundamental difference in design is behind many of the following specific differences in default behavior.\n\nDuring deserialization, does case-insensitive property name matching by default. The System.Text.Json default is case-sensitive, which gives better performance since it's doing an exact match. For information about how to do case-insensitive matching, see Case-insensitive property matching.\n\nIf you're using indirectly by using ASP.NET Core, you don't need to do anything to get behavior like . ASP.NET Core specifies the settings for camel-casing property names and case-insensitive matching when it uses .\n\nDuring serialization, is relatively permissive about letting characters through without escaping them. That is, it doesn't replace them with where is the character's code point. Where it does escape them, it does so by emitting a before the character (for example, becomes ). System.Text.Json escapes more characters by default to provide defense-in-depth protections against cross-site scripting (XSS) or information-disclosure attacks and does so by using the six-character sequence. escapes all non-ASCII characters by default, so you don't need to do anything if you're using in . also escapes HTML-sensitive characters, by default. For information about how to override the default behavior, see Customize character encoding.\n\nDuring deserialization, ignores comments in the JSON by default. The System.Text.Json default is to throw exceptions for comments because the RFC 8259 specification doesn't include them. For information about how to allow comments, see Allow comments and trailing commas.\n\nDuring deserialization, ignores trailing commas by default. It also ignores multiple trailing commas (for example, ). The System.Text.Json default is to throw exceptions for trailing commas because the RFC 8259 specification doesn't allow them. For information about how to make accept them, see Allow comments and trailing commas. There's no way to allow multiple trailing commas.\n\nThe registration precedence for custom converters is as follows:\n\nThis order means that a custom converter in the collection is overridden by a converter that is registered by applying an attribute at the type level. Both of those registrations are overridden by an attribute at the property level.\n\nThe System.Text.Json registration precedence for custom converters is different:\n\nThe difference here is that a custom converter in the collection overrides an attribute at the type level. The intention behind this order of precedence is to make run-time changes override design-time choices. There's no way to change the precedence.\n\nFor more information about custom converter registration, see Register a custom converter.\n\nThe latest version of has a maximum depth limit of 64 by default. System.Text.Json also has a default limit of 64, and it's configurable by setting JsonSerializerOptions.MaxDepth.\n\nIf you're using indirectly by using ASP.NET Core, the default maximum depth limit is 32. The default value is the same as for model binding and is set in the JsonOptions class.\n\nDuring deserialization, accepts property names surrounded by double quotes, single quotes, or without quotes. It accepts string values surrounded by double quotes or single quotes. For example, accepts the following JSON:\n\nonly accepts property names and string values in double quotes because that format is required by the RFC 8259 specification and is the only format considered valid JSON.\n\nA value enclosed in single quotes results in a JsonException with the following message:\n\naccepts non-string values, such as a number or the literals and , for deserialization to properties of type string. Here's an example of JSON that successfully deserializes to the following class:\n\ndoesn't deserialize non-string values into string properties. A non-string value received for a string field results in a JsonException with the following message:\n\nSome of the following scenarios aren't supported by built-in functionality, but workarounds are possible. The workarounds are custom converters, which may not provide complete parity with functionality. For some of these, sample code is provided as examples. If you rely on these features, migration will require modifications to your .NET object models or other code changes.\n\nFor some of the following scenarios, workarounds are not practical or possible. If you rely on these features, migration will not be possible without significant changes.\n\nAllow or write numbers in quotes\n\ncan serialize or deserialize numbers represented by JSON strings (surrounded by quotes). For example, it can accept: instead of . To enable that behavior in System.Text.Json, set JsonSerializerOptions.NumberHandling to WriteAsString or AllowReadingFromString, or use the [JsonNumberHandling] attribute.\n\nIf you're using indirectly by using ASP.NET Core, you don't need to do anything to get behavior like . ASP.NET Core specifies web defaults when it uses , and web defaults allow quoted numbers.\n\nFor more information, see Allow or write numbers in quotes.\n\nSpecify constructor to use when deserializing\n\nThe attribute lets you specify which constructor to call when deserializing to a POCO.\n\nalso has a [JsonConstructor] attribute. For more information, see Immutable types and Records.\n\nhas several ways to conditionally ignore a property on serialization or deserialization:\n• lets you select properties to include or ignore, based on arbitrary criteria.\n• The and settings on let you specify that all null-value or default-value properties should be ignored.\n• The and settings on the attribute let you specify individual properties that should be ignored when set to null or the default value.\n\nSystem.Text.Json provides the following ways to ignore properties or fields while serializing:\n• The [JsonIgnore] attribute on a property causes the property to be omitted from the JSON during serialization.\n• The IgnoreReadOnlyProperties global option lets you ignore all read-only properties.\n• If you're including fields, the JsonSerializerOptions.IgnoreReadOnlyFields global option lets you ignore all read-only fields.\n• The global option lets you ignore all value type properties that have default values, or ignore all reference type properties that have null values.\n\nIn addition, in .NET 7 and later versions, you can customize the JSON contract to ignore properties based on arbitrary criteria. For more information, see Custom contracts.\n\ncan serialize and deserialize fields as well as properties.\n\nIn System.Text.Json, use the JsonSerializerOptions.IncludeFields global setting or the [JsonInclude] attribute to include public fields when serializing or deserializing. For an example, see Include fields.\n\nBy default, serializes by value. For example, if an object contains two properties that contain a reference to the same object, the values of that object's properties are duplicated in the JSON.\n\nhas a setting on that lets you serialize by reference:\n• An identifier metadata is added to the JSON created for the first object.\n• The JSON that is created for the second object contains a reference to that identifier instead of property values.\n\nalso has a setting that lets you ignore circular references rather than throw an exception.\n\nTo preserve references and handle circular references in System.Text.Json, set JsonSerializerOptions.ReferenceHandler to Preserve. The setting is equivalent to = in .\n\nThe option has behavior similar to Newtonsoft.Json . One difference is that the System.Text.Json implementation replaces reference loops with the JSON token instead of ignoring the object reference. For more information, see Ignore circular references.\n\nLike the Newtonsoft.Json ReferenceResolver, the System.Text.Json.Serialization.ReferenceResolver class defines the behavior of preserving references on serialization and deserialization. Create a derived class to specify custom behavior. For an example, see GuidReferenceResolver.\n\nFor more information, see Preserve references and handle circular references.\n\nBoth and support collections of type . For information about supported key types, see Supported key types.\n\nSystem.Text.Json doesn't provide built-in support for the following types:\n• DataTable and related types (for more information, see Supported types)\n• ValueTuple and its associated generic types\n\nCustom converters can be implemented for types that don't have built-in support.\n\nautomatically does polymorphic serialization. Starting in .NET 7, System.Text.Json supports polymorphic serialization through the JsonDerivedTypeAttribute attribute. For more information, see Serialize properties of derived classes.\n\nhas a setting that adds type-name metadata to the JSON while serializing. It uses the metadata while deserializing to do polymorphic deserialization. Starting in .NET 7, System.Text.Json relies on type discriminator information to perform polymorphic deserialization. This metadata is emitted in the JSON and then used during deserialization to determine whether to deserialize to the base type or a derived type. For more information, see Serialize properties of derived classes.\n\nTo support polymorphic deserialization in older .NET versions, create a converter like the example in How to write custom converters.\n\nBy default, System.Text.Json doesn't support deserializing string enum values, whereas does. For example, the following code throws a JsonException:\n\nHowever, you can enable deserialization of string enum values by using the JsonStringEnumConverter converter. For more information, see Enums as strings.\n\nWhen deserializes to Object, it:\n• Infers the type of primitive values in the JSON payload (other than ) and returns the stored , , , , or as a boxed object. Primitive values are single JSON values such as a JSON number, string, , , or .\n• Returns a or for complex values in the JSON payload. Complex values are collections of JSON key-value pairs within braces ( ) or lists of values within brackets ( ). The properties and values within the braces or brackets can have additional properties or values.\n• Returns a null reference when the payload has the JSON literal.\n\nSystem.Text.Json stores a boxed for both primitive and complex values whenever deserializing to Object, for example:\n\nHowever, treats the same as and returns a null reference when the payload has the JSON literal in it.\n\nTo implement type inference for properties, create a converter like the example in How to write custom converters.\n\ndoesn't throw an exception in the following scenario:\n• is set to , and\n• During deserialization, the JSON contains a null value for a non-nullable value type.\n\nIn the same scenario, System.Text.Json does throw an exception. (The corresponding null-handling setting in is JsonSerializerOptions.IgnoreNullValues = .)\n\nIf you own the target type, the best workaround is to make the property in question nullable (for example, change to ).\n\nAnother workaround is to make a converter for the type, such as the following example that handles null values for types:\n\nRegister this custom converter by using an attribute on the property or by adding the converter to the Converters collection.\n\nNote: The preceding converter handles null values differently than does for POCOs that specify default values. For example, suppose the following code represents your target object:\n\nAnd suppose the following JSON is deserialized by using the preceding converter:\n\nAfter deserialization, the property has 1/1/0001 ( ), that is, the value set in the constructor is overwritten. Given the same POCO and JSON, deserialization would leave 1/1/2001 in the property.\n\ncan deserialize to immutable classes and structs because it can use constructors that have parameters.\n\nIn System.Text.Json, use the [JsonConstructor] attribute to specify use of a parameterized constructor. Records in C# 9 are also immutable and are supported as deserialization targets. For more information, see Immutable types and Records.\n\nIn , you specify that a property is required by setting on the attribute. throws an exception if no value is received in the JSON for a property marked as required.\n\nStarting in .NET 7, you can use the C# modifier or the JsonRequiredAttribute attribute on a required property. System.Text.Json throws an exception if the JSON payload doesn't contain a value for the marked property. For more information, see Required properties.\n\nprovides several ways to control how properties of and types are serialized and deserialized:\n• The setting can be used to serialize all values as UTC dates.\n• The setting and converters can be used to customize the format of date strings.\n\nSystem.Text.Json supports ISO 8601-1:2019, including the RFC 3339 profile. This format is widely adopted, unambiguous, and makes round trips precisely. To use any other format, create a custom converter. For example, the following converters serialize and deserialize JSON that uses Unix epoch format with or without a time zone offset (values such as or ):\n\nFor more information, see DateTime and DateTimeOffset support in System.Text.Json.\n\nlets you execute custom code at several points in the serialization or deserialization process:\n• OnDeserializing (when beginning to deserialize an object)\n• OnSerializing (when beginning to serialize an object)\n\nSystem.Text.Json exposes the same notifications during serialization and deserialization. To use them, implement one or more of the following interfaces from the System.Text.Json.Serialization namespace:\n\nHere's an example that checks for a null property and writes messages at start and end of serialization and deserialization:\n\nThe code doesn't have access to the new POCO instance. To manipulate the new POCO instance at the start of deserialization, put that code in the POCO constructor.\n\ncan use private and internal property setters and getters via the attribute.\n\nSystem.Text.Json supports private and internal property setters and getters via the [JsonInclude] attribute. For sample code, see Non-public property accessors.\n\nThe method in deserializes a JSON document to an existing instance of a class, instead of creating a new instance. System.Text.Json always creates a new instance of the target type by using the default public parameterless constructor. Custom converters can deserialize to an existing instance.\n\nStarting in .NET 8, System.Text.Json supports reusing initialized properties rather than replacing them. There are some differences in behavior, which you can read about in the API proposal.\n\nFor more information, see Populate initialized properties.\n\nStarting in .NET 8, System.Text.Json supports populating properties, including those that don't have a setter. For more information, see Populate initialized properties.\n\nSystem.Text.Json includes a built-in naming policy for snake case. However, there are some behavior differences with for some inputs. The following table shows some of these differences when converting input using the JsonNamingPolicy.SnakeCaseLower policy.\n\nSystem.Runtime.Serialization attributes such as DataContractAttribute, DataMemberAttribute, and IgnoreDataMemberAttribute let you define a data contract. A data contract is a formal agreement between a service and a client that abstractly describes the data to be exchanged. The data contract precisely defines which properties are serialized for exchange.\n\nSystem.Text.Json doesn't have built-in support for these attributes. However, starting in .NET 7, you can use a custom type resolver to add support. For a sample, see ZCS.DataContractResolver.\n\ntreats numbers with a leading zero as octal numbers. System.Text.Json doesn't allow leading zeroes because the RFC 8259 specification doesn't allow them.\n\nIf the JSON that's being deserialized includes properties that are missing in the target type, can be configured to throw exceptions. By default, System.Text.Json ignores extra properties in the JSON, except when you use the [JsonExtensionData] attribute.\n\nIn .NET 8 and later versions, you can set your preference for whether to skip or disallow unmapped JSON properties using one of the following means:\n• Apply the JsonUnmappedMemberHandlingAttribute attribute to the type you're deserializing to.\n• To set your preference globally, set the JsonSerializerOptions.UnmappedMemberHandling property. Or, for source generation, set the JsonSourceGenerationOptionsAttribute.UnmappedMemberHandling property and apply the attribute to your JsonSerializerContext class.\n\nhas an attribute, , that can be applied at the type level to control which members are serialized, how values are handled, and whether all members are required. System.Text.Json has no equivalent attribute that can be applied on a type. For some behaviors, such as value handling, you can either configure the same behavior on the global JsonSerializerOptions or individually on each property.\n\nConsider the following example that uses to specify that all properties should be ignored:\n\nIn System.Text.Json, you can set the behavior for all types and properties:\n\nOr you can set the behavior on each property separately:\n\nNext, consider the following example that uses to specify that all member properties must be present in the JSON:\n\nYou can achieve the same behavior in System.Text.Json by adding the C# modifier or the JsonRequiredAttribute to each property. For more information, see Required properties.\n\nlets you debug by using a to view logs that are generated by serialization or deserialization. System.Text.Json doesn't do logging.\n\nJsonDocument and JsonElement compared to JToken (like JObject, JArray)\n\nSystem.Text.Json.JsonDocument provides the ability to parse and build a read-only Document Object Model (DOM) from existing JSON payloads. The DOM provides random access to data in a JSON payload. The JSON elements that compose the payload can be accessed via the JsonElement type. The type provides APIs to convert JSON text to common .NET types. exposes a RootElement property.\n\nStarting in .NET 6, you can parse and build a mutable DOM from existing JSON payloads by using the JsonNode type and other types in the System.Text.Json.Nodes namespace. For more information, see Use .\n\nbuilds an in-memory view of the data into a pooled buffer. Therefore, unlike or from , the type implements and needs to be used inside a using block. For more information, see JsonDocument is IDisposable.\n\nThe System.Text.Json DOM can't add, remove, or modify JSON elements. It's designed this way for performance and to reduce allocations for parsing common JSON payload sizes (that is, < 1 MB).\n\nexposes the as a property of type JsonElement, which is a union struct type that encompasses any JSON element. uses dedicated hierarchical types like , , , and so forth. is what you can search and enumerate over, and you can use to materialize JSON elements into .NET types.\n\nStarting in .NET 6, you can use JsonNode type and types in the System.Text.Json.Nodes namespace that correspond to , , and . For more information, see Use .\n\nHow to search a JsonDocument and JsonElement for sub-elements\n\nSearches for JSON tokens using or from tend to be relatively fast because they're lookups in some dictionary. By comparison, searches on require a sequential search of the properties and hence are relatively slow (for example when using ). System.Text.Json is designed to minimize initial parse time rather than lookup time. For more information, see How to search a JsonDocument and JsonElement for sub-elements.\n\nSystem.Text.Json.Utf8JsonReader is a high-performance, low allocation, forward-only reader for UTF-8 encoded JSON text, read from a ReadOnlySpan<byte> or ReadOnlySequence<byte>. The is a low-level type that can be used to build custom parsers and deserializers.\n\nThe in is a class. The type differs in that it's a ref struct. For more information, see ref struct limitations for Utf8JsonReader.\n\nprovides APIs that return Nullable<T>, such as , which handles a for you by returning a . The built-in APIs return only non-nullable value types. For more information, see Read null values into nullable value types.\n\nIf you need to continue to use for certain target frameworks, you can multi-target and have two implementations. However, this is not trivial and would require some and source duplication. One way to share as much code as possible is to create a wrapper around Utf8JsonReader and . This wrapper would unify the public surface area while isolating the behavioral differences. This lets you isolate the changes mainly to the construction of the type, along with passing the new type around by reference. This is the pattern that the Microsoft.Extensions.DependencyModel library follows:\n\nSystem.Text.Json.Utf8JsonWriter is a high-performance way to write UTF-8 encoded JSON text from common .NET types like , , and . The writer is a low-level type that can be used to build custom serializers.\n\nhas a method that writes raw JSON where a value is expected. System.Text.Json has a direct equivalent: Utf8JsonWriter.WriteRawValue. For more information, see Write raw JSON.\n\nThere are no workarounds that would let you customize the JSON produced by in these ways.\n\nprovides methods for TimeSpan, Uri, and char values. doesn't have equivalent methods. Instead, format these values as strings (by calling , for example) and call WriteStringValue.\n\nIf you need to continue to use for certain target frameworks, you can multi-target and have two implementations. However, this is not trivial and would require some and source duplication. One way to share as much code as possible is to create a wrapper around Utf8JsonWriter and . This wrapper would unify the public surface area while isolating the behavioral differences. This lets you isolate the changes mainly to the construction of the type. Microsoft.Extensions.DependencyModel library follows:\n\nThe decision to exclude -equivalent functionality from was intentional. Allowing a JSON payload to specify its own type information is a common source of vulnerabilities in web applications. In particular, configuring with allows the remote client to embed an entire executable application within the JSON payload itself, so that during deserialization the web application extracts and runs the embedded code. For more information, see Friday the 13th JSON attacks PowerPoint and Friday the 13th JSON attacks details.\n\nThe DOM doesn't support querying by using JSON Path.\n\nIn a JsonNode DOM, each instance has a method that returns a path to that node. But there is no built-in API to handle queries based on JSON Path query strings.\n\nFor more information, see the dotnet/runtime #31068 GitHub issue.\n\nSystem.Text.Json sets limits that can't be changed for some values, such as the maximum token size in characters (166 MB) and in base 64 (125 MB). For more information, see in the source code and GitHub issue dotnet/runtime #39953.\n\nNewtonsoft parses , , and JSON string tokens. With System.Text.Json, use JsonNumberHandling.AllowNamedFloatingPointLiterals. For information about how to use this setting, see Allow or write numbers in quotes.\n\nYou can get coding help from GitHub Copilot to migrate your code from to within your IDE. You can customize the prompt per your requirements.\n\nGitHub Copilot is powered by AI, so surprises and mistakes are possible. For more information, see Copilot FAQs.\n\nLearn more about GitHub Copilot in Visual Studio and GitHub Copilot in VS Code.\n• How to serialize and deserialize JSON"
    },
    {
        "link": "https://dotnet.microsoft.com/en-us/apps/aspnet/signalr",
        "document": "Bring your ASP.NET apps to life with SignalR\n\nToday's modern apps are expected to deliver up-to-date information without hitting a refresh button. Add real-time functionality to your dashboards, maps, games and more.\n\nWhat is real-time functionality? It's the ability to have your server-side code push content to connected clients as it happens, in real-time."
    },
    {
        "link": "https://medium.com/@paulotorres/building-real-time-applications-with-signalr-in-net-core-8e60f166648a",
        "document": "In the modern web development landscape, real-time functionality is increasingly in demand. Whether it’s live chat, real-time notifications, or dynamic dashboards, users expect instantaneous updates. SignalR, a library for ASP.NET, simplifies adding real-time web functionality to your applications. In this article, we will explore how to build real-time applications with SignalR in .NET Core, using practical examples to illustrate its capabilities.\n\nSignalR is a library that simplifies adding real-time web functionality to applications. It allows server-side code to push content to connected clients instantly. SignalR handles connection management automatically, and it scales out to handle large numbers of connections.\n\nKey Features of SignalR\n\n- Real-time Communication: Enables bi-directional communication between server and client.\n\n- Automatic Reconnection: Automatically reconnects if the connection is dropped.\n\n- Multiple Transport Options: Chooses the best transport method (WebSockets, Server-Sent Events, Long Polling) depending on the client’s capabilities.\n\nStep 1: Create a New .NET Core Project\n\nFirst, create a new .NET Core Web API project using the .NET CLI:\n\nStep 2: Add SignalR NuGet Package\n\nAdd the SignalR package to your project:\n\nStep 3: Create a Hub\n\nA Hub is a central point in the SignalR API that handles connections, groups, and messaging. Create a new Hub class:\n\nStep 4: Configure SignalR in Startup\n\nConfigure the SignalR services and middleware in the `Startup.cs` file:\n\nStep 5: Create a Client Application\n\nTo demonstrate real-time communication, we will create a simple chat and notification client using HTML and JavaScript.\n\nOpen the HTML file in a web browser, enter a username and message, and click send. The message will be broadcasted to all connected clients in real time, and notifications can also be sent and received instantly.\n\nImplementing real-time applications with SignalR in .NET Core enhances the interactivity and responsiveness of web applications. By following the steps outlined in this article, you can create robust real-time features such as chat applications and notifications. SignalR simplifies the complexities of real-time communication, making it an essential tool for modern web developers. Dive into SignalR and explore its potential to transform your .NET Core applications."
    },
    {
        "link": "https://learn.microsoft.com/en-us/shows/on-dotnet/real-time-web-applications-with-aspnet-core-signalr",
        "document": "Brady Gaster (@bradygaster) joins Cecil (@cecilphillip) to show how easy it is to add real-time functionality to your web applications using ASP.NET Core SignalR. They discuss topics such as targeting with clients, SignalR transports, and options for running your SignalR application in the cloud.\n\nNow, you can even leverage the Hub protocol spec is the available on GitHub if you're interested in creating your own SignalR client."
    },
    {
        "link": "https://krishan-samarawickrama.medium.com/building-a-real-time-application-with-asp-net-core-signalr-a-comprehensive-guide-874e975377c8",
        "document": "In the digital age, real-time applications have become a cornerstone of modern software development. These applications allow users to receive information as it happens, without any significant delay. From chat applications to live sports updates, real-time technology is transforming the way we interact with the digital world.\n\nOne of the key technologies enabling the development of real-time applications is SignalR, a library that simplifies the process of adding real-time web functionality to applications. This article will focus on ASP.NET Core SignalR, a powerful framework for building real-time applications.\n\nASP.NET Core SignalR is an open-source library that simplifies the process of adding real-time web functionality to your applications. Real-time web functionality is the ability to have server-side code push content to connected clients instantly as it becomes available, rather than having the server wait for a client to request new data.\n\nSignalR provides an abstraction over various techniques used for building real-time web applications, such as WebSockets, Server-Sent Events, and Long Polling. It automatically selects the best available transport based on the client and server capabilities.\n\nASP.NET Core SignalR comes with several features that make it a preferred choice for building real-time applications:\n• Automatic Transport Selection: SignalR automatically chooses the best transport mechanism (WebSockets, Server-Sent Events, or Long Polling) based on the capabilities of the client and server.\n• Connection Management: SignalR handles connection management automatically, allowing you to focus on your application logic.\n• High-Level API: SignalR provides a high-level API for server-to-client communication. You can call methods on the client from the server and vice versa.\n• Support for Binary and Text Data: SignalR supports both binary and text data, not just text.\n• Scalability: SignalR is designed to scale out to multiple servers, making it suitable for large applications.\n\nHow ASP.NET Core SignalR Differs from Other Real-Time Frameworks\n\nUnlike other real-time frameworks, ASP.NET Core SignalR is not just a wrapper around WebSocket. It provides a higher-level API for managing connections, broadcasting messages, and handling groups. It also falls back to other techniques when WebSocket is not available, ensuring your application works across different environments.\n\nNow, let’s dive into the practical part of this guide. We will build a simple chat application using ASP.NET Core SignalR.\n\nFirst, create a new ASP.NET Core Web Application project in Visual Studio. Name it “SignalRChat”.\n\nNext, install the SignalR library via NuGet. You can do this by running the following command in the Package Manager Console:\n\nA “Hub” in SignalR is a high-level pipeline that allows the client and server to call methods on each other. Create a new class named “ChatHub” in the Hubs folder and replace the existing code with the following:\n\nOn the client side, you’ll need to add a reference to the SignalR library. You can do this by adding the following script tag to your HTML file:\n\nThen, establish a connection to the hub and define a method to send messages:\n\nAnd that’s it! You’ve built a simple real-time chat application using ASP.NET Core SignalR.\n\nASP.NET Core SignalR can be used to build a variety of real-time applications. Here are a few examples:\n• Chat Applications: As demonstrated in this guide, SignalR is perfect for building real-time chat applications.\n• Live Updates: SignalR can be used to push live updates to clients. This can be useful in applications like stock trading, live sports updates, etc.\n• Collaborative Apps: Applications that require multiple users to interact in real-time, like Google Docs, can be built using SignalR.\n• Gaming: Real-time games that require high-frequency updates can benefit from SignalR.\n\nASP.NET Core SignalR is a powerful library for building real-time applications. It provides an abstraction over various real-time techniques, automatically selects the best transport based on client and server capabilities, and provides a high-level API for server-to-client communication.\n\nThis guide has provided a step-by-step process to build a simple real-time chat application using ASP.NET Core SignalR. However, the possibilities with SignalR are endless. I encourage you to experiment with this powerful library and see what amazing real-time applications you can build!\n\nRemember, the key to mastering any technology is practice. So, start building, start experimenting, and most importantly, have fun while doing it!"
    },
    {
        "link": "https://theonetechnologies.com/blog/post/real-time-communication-with-signalr-in-net-core-building-interactive-web-applications",
        "document": "SignalR is a bi-directional communication library that makes use of the .NET framework to facilitate real-time applications, where the client and server have a constant connection and can exchange information. An example where this may be beneficial is in the development of online multiplayer games, chat applications, or real-time data displays where updates need to be delivered instantaneously.\n\nStart an exhilarating journey into real-time communication with SignalR in .NET Core! As a .NET Core developer, you'll discover the power of building interactive web applications that engage users like never before.\n• Demo projects can be found at this link\n\nTo your project, add the SignalR package: SignalR by Microsoft.AspNetCore\n\nA SignalR hub is a class that manages client-server communication by acting as a high-level pipeline. For your hub, create a new class:\n\nThe hub in this example contains a SendMessage method that sends out a message to every client that is connected.\n\nThe ConfigureServices and Configure methods included in the Startup.cs file should be used to configure SignalR:\n\nThe SignalR client library is available for usage on the client side (in JavaScript within a web application). As an illustration, using JavaScript:\n\nYou may use dependency injection to inject an instance of the SignalR hub context into your controller or service so that you can call SignalR from an action in a.NET Core application.\n\nAssuming you have a SignalR hub as shown in the example above (eg, ChatHub), let's create a controller that calls SignalR from an action:\n\nThe SendMessage action in this example is designated to handle HTTP POST requests via the [HttpPost] attribute. The action calls, after your business logic (replace the remark with your actual code). it calls _hubContext.Clients.All.SendAsync(\"ReceiveMessage\", client, msg); to broadcast a message via the ChatHub to every client that is connected.\n\nVerify that the SignalR hub and MyController are being used by your Startup.cs file:\n\nYou can have a form in your client-side JavaScript code that makes a POST request to the SendMessage action:\n\nYou should be able to observe the SignalR hub in operation when you run your.NET Core application.\n\nThis is a rudimentary configuration; SignalR offers other tools to control authorization, connections, and other aspects. Check the official documentation for advanced usage and more detailed information.\n\nOne project must be set up as the hub (server), and the second project has to connect to and communicate with the hub (client) in order to use SignalR with two projects. These kinds of scenarios, in which numerous components exchange real-time information with one another, are common in distributed systems and microservices designs.\n\nUsing two projects—a server project that houses a SignalR hub and a client project that connects to the hub—this is a simple lesson on configuring SignalR.\n\nAdd the SignalR package to your server project: Microsoft.AspNetCore.SignalR\n\nMake a new.NET Core project and include the SignalR hub class (the same one as in the earlier examples).\n\nConfigure SignalR in the Startup.cs file of the server project.\n\n1. Add the SignalR client package to the client project.\n\nLink to the SignalR hub and handle events in your client code (such as a console application, Blazor app, or other web application).\n\nAdjust the WithUrl URL to correspond with the SignalR hub's URL.\n\nSelect Choose specific files you want to work with, expand the dist/browser folder and choose signalr.js and signalr.min.js.\n\nRun the project for the client.\n\nYou can try sending messages from the hub to the client and vice versa once communication has been established between the SignalR hub and the client.\n\nAlthough this is a simple example, depending on your application's requirements, you may also need to take security, error handling, and other issues into account in a real-world setting.\n\nThis blog post demonstrates how SignalR is a tool that can recognize the steps involved in developing real-time online functionality. It makes it simpler for developers to manage client-server relationships and push content updates to the client side from the SignalR Hub because it includes an ASP.NET Site server library and a Javascript client library. In order to use this service for web apps and have real-time data and functionality, developers must first install the SignalR library to an existing ASP.NET application. The SignalR service assists.NET development firms in building reliable, fast, and scalable web applications.\n\nAfter reading this post, you must want to experience the power of SignalR to propel your web applications into the realm of real-time functionality and engagement. So, what are you waiting for? Hire a trustworthy .Net development company and take your projects to the next level.\n\nDemo projects can be found at this link\n\nNutan is a seasoned Sr .NET Developer at The One Technologies having over 3 years of experience in IT industry. Since commencing her journey in 2019, she has shown remarkable career progression driven by a passion for learning and innovation. With expertise in C# programming and the .NET Framework, she excels in ASP.NET for web development, crafting dynamic and interactive applications. She aims to become a recognized expert in .NET development, contributing to impactful projects and assuming leadership roles."
    }
]