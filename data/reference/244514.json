[
    {
        "link": "https://stackoverflow.com/questions/66667550/training-loss-is-nan-in-keras-lstm",
        "document": "I have tun this code in google colab with GPU to create a multilayer LSTM. It is for time series prediction.\n\nNote that I have used used the gradient-clipping. But still, when I train this model, it return nan as the training loss:\n\nThis is the result"
    },
    {
        "link": "https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network",
        "document": "I have a data matrix in \"one-hot encoding\" (all ones and zeros) with 260,000 rows and 35 columns. I am using Keras to train a simple neural network to predict a continuous variable. The code to make the network is the following: However, during the training process, I see the loss decrease nicely, but during the middle of the second epoch, it goes to nan: I tried using instead of , I tried instead of , I tried with and without dropout, all to no avail. I tried with a smaller model, i.e. with only one hidden layer, and same issue (it becomes nan at a different point). However, it does work with less features, i.e. if there are only 5 columns, and gives quite good predictions. It seems to be there is some kind of overflow, but I can't imagine why--the loss is not unreasonably large at all. Python version 2.7.11, running on a linux machine, CPU only. I tested it with the latest version of Theano, and I also get Nans, so I tried going to Theano 0.8.2 and have the same problem. With the latest version of Keras has the same problem, and also with the 0.3.2 version."
    },
    {
        "link": "https://github.com/keras-team/keras/issues/2134",
        "document": "I'm running a regression model on patches of size 32x32 extracted from images against a real value as the target value. I have 200,000 samples for training but during the first epoch itself, I'm encountering a nan loss. Can anyone help me solve this problem please ? I've tried on both GPU and CPU but the issue still appears."
    },
    {
        "link": "https://datascience.stackexchange.com/questions/68331/keras-sequential-model-returns-loss-nan",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    },
    {
        "link": "https://omi.me/blogs/tensorflow-errors/nan-loss-values-in-tensorflow-causes-and-how-to-fix",
        "document": "TensorFlow is a robust library for numerical computation and machine learning. However, during training, you may encounter an error where the loss value becomes 'NaN' (not a number). Understanding the root causes of this error is critical for diagnosing and improving your model's performance.\n• Numerical Instability: One of the primary reasons for encountering NaN loss values is numerical instability. Operations like division by zero, logarithms of zero or negative numbers, or operations resulting in infinite values can cause NaN values. For example, if you have a log operation where the input value approaches zero (e.g., `log(x) where x ≈ 0`), this will result in negative infinity, and further operations might propagate NaN.\n• Exploding Gradients: In some cases, especially in recurrent networks, the gradients can become excessively large. This is known as the exploding gradient problem. When the gradient becomes too large to fit into the numerical precision of the floating point numbers, it can result in NaN values. For example, with a large learning rate, you might have weights updates like: \\`\\`\\`python W += large_learning_rate \\* large\\_gradient \\`\\`\\` which can go beyond the floating-point range.\n• Inappropriate Model Initialization: Poor initialization of model weights can also precipitate NaN errors. If weights are initialized in such a way that the outputs of some layers result in extremely large values, it may cause the activation functions (like sigmoid or tanh) to saturate, making backpropagation unstable.\n• Data Issues: If the input data contains extreme or incorrect values, it can cause the model to produce NaN outputs. This includes cases where input data is not normalized or contains missing values represented by NaNs or infinities, thereby influencing the computations leading to the loss.\n• Inadequate Numerical Precision: When dealing with deep networks or very sensitive problems, using 32-bit floating-point precision might not suffice causing computational errors that propagate to NaN values. This happens because the precision of floating-point numbers can only represent numbers with a certain level of accuracy. Understanding these causes can significantly aid in diagnosing and resolving NaN loss values during model training. Paying close attention to initialization, normalization, as well as ensuring stability through careful gradient control, can mitigate these issues."
    },
    {
        "link": "https://stackoverflow.com/questions/54136325/use-of-keras-sparse-categorical-crossentropy-for-pixel-wise-multi-class-classifi",
        "document": "I'll start by disclosing that I'm a machine learning and Keras novice and don't know much beyond general CNN binary classifiers. I'm trying to perform pixelwise multi-class classification using a U-Net architecture (TF backend) on many 256x256 images. In other words, I input a 256x256 image, and I want it to output a 256x256 \"mask\" (or label image) where the values are integers from 0-30 (each integer represents a unique class). I'm training on 2 1080Ti NVIDIA GPUs.\n\nWhen I attempt to perform one-hot encoding, I get an OOM error, which is why I'm using sparse categorical cross entropy as my loss function instead of regular categorical cross entropy. However, when training my U-Net, my loss value is \"nan\" from start to finish (it initializes as nan and never changes). When I normalize my \"masks\" by dividing all values by 30 (so they go from 0-1), I get ~0.97 accuracy, which I'm guessing is because most of the labels in my image are 0 (and it's just outputting a bunch of 0s).\n\nNote that I needed to flatten the output just to get sparse categorical cross entropy to function properly (it didn't like my 2D matrix for some reason).\n\nAnd here's an example of a training run (just 1 epoch because it's the same no matter how many I run)\n\nLet me know if more information is needed to diagnose the problem. Thanks in advance!"
    },
    {
        "link": "https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-sparse-categorical-crossentropy-in-keras.md",
        "document": "For multiclass classification problems, many online tutorials - and even François Chollet's book Deep Learning with Python, which I think is one of the most intuitive books on deep learning with Keras - use categorical crossentropy for computing the loss value of your neural network.\n\nHowever, traditional categorical crossentropy requires that your data is one-hot encoded and hence converted into categorical format. Often, this is not what your dataset looks like when you'll start creating your models. Rather, you likely have feature vectors with integer targets - such as 0 to 9 for the numbers 0 to 9.\n\nThis means that you'll have to convert these targets first. In Keras, this can be done with , which essentially applies one-hot encoding to your training set's targets. When applied, you can start using categorical crossentropy.\n\nBut did you know that there exists another type of loss - sparse categorical crossentropy - with which you can leave the integers as they are, yet benefit from crossentropy loss? I didn't when I just started with Keras, simply because pretty much every article I read performs one-hot encoding before applying regular categorical crossentropy loss.\n\nIn this blog, we'll figure out how to build a convolutional neural network with sparse categorical crossentropy loss.\n\nWe'll create an actual CNN with Keras. It'll be a simple one - an extension of a CNN that we created before, with the MNIST dataset. However, doing that allows us to compare the model in terms of its performance - to actually see whether sparse categorical crossentropy does as good a job as the regular one.\n\nAfter reading this tutorial, you will...\n• Understand what does when creating your TensorFlow/Keras models.\n• Why it's not necessary if you have integer labels/targets, but why you will have to change your loss function.\n• How loss can be useful in that case.\n\nNote that model code is also available on GitHub.\n\nUpdate 28/Jan/2021: Added summary and code example to get started straight away. Performed textual improvements, changed header information and slight addition to title of the tutorial.\n\nTraining a neural network involves passing data forward, through the model, and comparing predictions with ground truth labels. This comparison is done by a loss function. In multiclass classification problems, categorical crossentropy loss is the loss function of choice. However, it requires that your labels are one-hot encoded, which is not always the case.\n\nIn that case, sparse categorical crossentropy loss can be a good choice. This loss function performs the same type of loss - categorical crossentropy loss - but works on integer targets instead of one-hot encoded ones. Saves you that step which is common with TensorFlow/Keras models!\n\nHave you also seen lines of code like these in your Keras projects?\n\nMost likely, you have - because many blogs explaining how to create multiclass classifiers with Keras apply categorical crossentropy, which requires you to one-hot encode your target vectors.\n\nNow you may wonder: what is one-hot encoding?\n\nSuppose that you have a classification problem where you have four target classes: { 0, 1, 2, 3 }.\n\nYour dataset likely comes in this flavor: , where your target is an integer value from { 0, 1, 2, 3 }.\n\nHowever, as we saw in another blog on categorical crossentropy, its mathematical structure doesn't allow us to feed it integers directly.\n\nWe'll have to convert it into categorical format first - with one-hot encoding, or in Keras.\n\nYou'll effectively transform your targets into this:\n\nNote that when you have more classes, the trick goes on and on - you simply create n-dimensional vectors, where n equals the unique number of classes in your dataset.\n\nWhen converted into categorical data, you can apply categorical crossentropy:\n\nDon't worry - it's a human pitfall to always think defensively when we see maths.\n\nIt's not so difficult at all, to be frank, so make sure to read on!\n\nWhat you see is obviously the categorical crossentropy formula. What it does is actually really simple: it iterates over all the possible classes predicted by the ML during the forward pass of your machine learning training process.\n\nFor each class, it takes a look at the target observation of the class - i.e., whether the actual class matching the prediction in your training set is 0 or one. Additionally, it computes the (natural) logarithm of the prediction of the observation (the odds that it belongs to that class). From this, it follows that only one such value is relevant - the actual target. For this, it simply computes the natural log value which increases significantly when it is further away from 1:\n\nNow, it could be the case that your dataset is not categorical at first ... and possibly, that it is too large in order to use . In that case, it would be rather difficult to use categorical crossentropy, since it is dependent on categorical data.\n\nHowever, when you have integer targets instead of categorical vectors as targets, you can use sparse categorical crossentropy. It's an integer-based version of the categorical crossentropy loss function, which means that we don't have to convert the targets into categorical format anymore.\n\nLet's now create a CNN with Keras that uses sparse categorical crossentropy. In some folder, create a file called and open it in some code editor.\n\nAs usual, like in our previous blog on creating a (regular) CNN with Keras, we use the MNIST dataset. This dataset, which contains thousands of 28x28 pixel handwritten digits (individual numbers from 0-9), is one of the standard datasets in machine learning training programs because it's a very easy and normalized one. The images are also relatively small and high in quantity, which benefits the predictive and generalization power of your model when trained properly. This way, one can really focus on the machine learning aspects of an exercise, rather than the data related issues.\n\nIf we wish to run the sparse categorical crossentropy Keras CNN, it's necessary to install a few software tools:\n• Obviously, you need TensorFlow, version 2.x (i.e. some version of 2), which comes with Keras installed as .\n• By consequence, you'll need to install peer dependencies such as NumPy. You'll also need them for processing the data.\n• In order to run any of those, you need to have a working Python installation; preferably, your Python version is 3.6+.\n\nPreferably, you run your model in an Anaconda environment. This way, you will be able to install your packages in a unique environment with which other packages do not interfere. Mingling Python packages is often a tedious job, which often leads to trouble. Anaconda resolves this by allowing you to use environments or isolated sandboxes in which your code can run. Really recommended!\n\nThis will be our model for today:\n\nFirst, we add our imports - packages and functions that we'll need for our model to work as intended.\n• Import the MNIST dataset. It comes with Keras by default because it's a perfect dataset for educational purposes. When you use a model with this dataset for the first time, Keras will download the dataset automatically, after which it is stored locally - and you don't ever have to worry about downloading the dataset again. Very user friendly.\n• Import the Sequential API - which is one of the two APIs with which engineers can create Keras based models, the other being the Functional API. As Sequential is relatively easier than Functional, we'll use it for this tutorial.\n• Import the Dense layer, the Dropout function and the Flatten layer. Dense layers are used for the classification part of the CNN; Dropout adds random noise which reduces the odds of overfitting, and Flatten converts the multidimensional output of the convolutional layers (which interpret your images) into a onedimensional vector to be used by the Dense layers (for classifying the interpretations into the correct classes).\n• Additionally, we import Conv2D and MaxPooling2D, which are used for image interpretation and downscaling - i.e., the first part of your CNN.\n\nWe specify image width and image height, which are 28 for both given the images in the MNIST dataset. We specify a batch size of 250, which means that during training 250 images at once will be processed. When all images are processed, one completes an epoch, of which we will have 25 in total during the training of our model. Additionally, we specify the number of classes in advance - 10, the numbers 0 to 9. 20% of our training set will be set apart for validating the model after every batch, and for educational purposes we set model verbosity to True (1) - which means that all possible output is actually displayed on screen.\n\nNext, we load and prepare the MNIST data:\n\nWhat we do is simple - we use to load the MNIST data into four Python variables, representing inputs and targets for both the training and testing datasets.\n\nAdditionally, we reshape the data so that TensorFlow will accept it.\n\nAdditionally, we perform some other preparations which concern the data instead of how it is handled by your system:\n\nWe first parse the numbers as floats. This benefits the optimization step of the training process.\n\nAdditionally, we normalize the data, which benefits the training process as well.\n\nWe then create the architecture of our model:\n\nTo be frank: the architecture of our model doesn't really matter for showing that sparse categorical crossentropy really works. In fact, you can use the architecture you think is best for your machine learning problem. However, we put up the architecture above because it is very generic and hence works well in many simple classification scenarios:\n• We use two convolutional blocks which comprise a 2-dimensional convolutional layer, max pooling and Dropout. The convolutional layer interprets the features into feature maps, which are subsequently downsampled (made smaller / less granular) by the max pooling operation. Subsequently, random Dropout noise is introduced to reduce the odds of overfitting, which means that your model is tailored too specifically to your training data, and might not work anymore with data it has never seen.\n• We then flatten the multidimensional input into a 1-dimensional vector that can be handled by the densely-connected layers. We specify the number of output neurons to which in the case of the MNIST dataset is 10: each neuron generates the probability (summated to one considering all neurons together) that the input belongs to one of the 10 classes in the MNIST scenario.\n• We use two Dense layers which essentially give the CNN its classification power. Note that ReLU is used as an activation function throughout all layers given its simplicity and relative power in today's deep learning problems. However, the last layer uses a Softmax activation, which essentially generates a multiclass probability distribution over all the classes that are available in your targets.\n\nWe next compile the model, which involves configuring it by means of hyperparameter tuning:\n\nWe specify the loss function used - sparse categorical crossentropy! We use it together with the Adam optimizer, which is one of the standard ones used today in very generic scenarios, and use accuracy as an additional metric, since it is more intuitive to humans.\n\nNext, we fit the data following the specification created in the model configuration step and specify evaluation metrics that test the trained model with the testing data:\n\nNow, we can start the training process. Open a command prompt, possible the Anaconda one navigating to your environment by means of , and navigate to the folder storing by means of the function.\n\nNext, start the training process with Python: .\n\nYou should then see something like this:\n\n25 epochs as configured, with impressive scores in both the validation and testing phases. It pretty much works as well as the classifier created with categorical crossentropy - and I actually think the difference can be attributed to the relative randomness of the model optimization process:\n\nWell, today, we've seen how to create a Convolutional Neural Network (and by consequence, any model) with sparse categorical crossentropy in Keras. If you have integer targets in your dataset, which happens in many cases, you usually perform in order to use multiclass crossentropy loss. With sparse categorical crossentropy, this is no longer necessary. This blog demonstrated this by means of an example Keras implementation of a CNN that classifies the MNIST dataset.\n\nModel code is also available on GitHub, if it benefits you.\n\nI hope this blog helped you - if it did, or if you have any questions, let me know in the comments section! 👇 I'm happy to answer any questions you may have 😊 Thanks and enjoy coding!\n\nHow to create a CNN classifier with Keras? – MachineCurve. (2019, September 24). Retrieved from https://www.machinecurve.com/index.php/2019/09/17/how-to-create-a-cnn-classifier-with-keras\n\nAbout loss and loss functions – MachineCurve. (2019, October 4). Retrieved from https://www.machinecurve.com/index.php/2019/10/04/about-loss-and-loss-functions/"
    },
    {
        "link": "https://stackoverflow.com/questions/54043399/output-format-using-sparse-categorical-cross-entropy-in-keras-for-multi-class-cl",
        "document": "I've built a u-net architecture using Keras Functional API but I'm having trouble using the sparse categorical cross entropy loss function. My learning task is multi-class, pixel-wise classification for many 256x256 images. The intended output is a 256x256 mask images with integer values from 0-31 (not every mask will contain each class). I have 32 classes so one-hot encoding gives me an OOM error which is why I don't use categorical cross entropy. The majority of the mask pixels are 0s (which may be part of the problem).\n\nI keep getting loss = nan. I've normalized my input data to have mean = 0, std = 1. If I leave the masks as they are, I get an accuracy around 0.97 and the output masks are all 1s (which is obviously incorrect). If I add 1 to all my masks before performing training, the accuracy is 0. I'm using relu activations with a SoftMax in the last convolutional layer.\n\nIt seems the problem likely has to do with the format of my output data, so my main question is, what format should it be in for sparse categorical cross entropy? Should I normalize the mask values to be 0-1? Alternatively, are there any other loss functions or accuracy metrics I can use for training? As far as multi-class classification goes the only function I know of is categorical cross entropy. I can provide additional information about my data, network, etc. if needed."
    },
    {
        "link": "https://keras.io/api/losses",
        "document": "The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.\n\nNote that all losses are available both via a class handle and via a function handle. The class handles enable you to pass configuration arguments to the constructor (e.g. ), and they perform reduction by default when used in a standalone way (see details below).\n\nThis is the class to subclass in order to create new custom losses.\n• reduction: Type of reduction to apply to the loss. In almost all cases this should be . Supported options are , , , or . sums the loss, and sum the loss and divide by the sample size, and sums the loss and divides by the sum of the sample weights. and perform no aggregation. Defaults to .\n• name: Optional name for the loss instance.\n• dtype: The dtype of the loss's computations. Defaults to , which means using . is a unless set to different value (via ). If a is provided, then the will be utilized.\n\nTo be implemented by subclasses:\n• : Contains the logic for loss calculation using , .\n\nA loss function is one of the two arguments required for compiling a Keras model:\n\nAll built-in loss functions may also be passed via their string identifier:\n\nLoss functions are typically created by instantiating a loss class (e.g. ). All losses are also provided as function handles (e.g. ).\n\nUsing classes enables you to pass configuration arguments at instantiation time, e.g.:\n• y_true: Ground truth values, of shape . For sparse loss functions, such as sparse categorical crossentropy, the shape should be\n• sample_weight: Optional acts as reduction weighting coefficient for the per-sample losses. If a scalar is provided, then the loss is simply scaled by the given value. If is a tensor of size , then the total loss for each sample of the batch is rescaled by the corresponding element in the vector. If the shape of is (or can be broadcasted to this shape), then each loss element of is scaled by the corresponding value of . (Note on : all loss functions reduce by 1 dimension, usually .)\n\nBy default, loss functions return one scalar loss value for each input sample in the batch dimension, e.g.\n\nHowever, loss class instances feature a constructor argument, which defaults to (i.e. average). Allowable values are \"sum_over_batch_size\", \"sum\", and \"none\":\n• \"sum_over_batch_size\" means the loss instance will return the average of the per-sample losses in the batch.\n• \"sum\" means the loss instance will return the sum of the per-sample losses in the batch.\n• \"none\" means the loss instance will return the full array of per-sample losses.\n\nNote that this is an important difference between loss functions like and default loss class instances like : the function version does not perform reduction, but by default the class instance does.\n\nWhen using , this difference is irrelevant since reduction is handled by the framework.\n\nHere's how you would use a loss class instance as part of a simple training loop:\n\nAny callable with the signature that returns an array of losses (one of sample in the input batch) can be passed to as a loss. Note that sample weighting is automatically supported for any such loss.\n\nLoss functions applied to the output of a model aren't the only way to create losses.\n\nWhen writing the method of a custom layer or a subclassed model, you may want to compute scalar quantities that you want to minimize during training (e.g. regularization losses). You can use the layer method to keep track of such loss terms.\n\nHere's an example of a layer that adds a sparsity regularization loss based on the L2 norm of the inputs:\n\nLoss values added via can be retrieved in the list property of any or (they are recursively retrieved from every underlying layer):\n\nThese losses are cleared by the top-level layer at the start of each forward pass – they don't accumulate. So always contain only the losses created during the last forward pass. You would typically use these losses by summing them before computing your gradients when writing a training loop.\n\nWhen using , such loss terms are handled automatically.\n\nWhen writing a custom training loop, you should retrieve these terms by hand from , like this:\n\nSee the documentation for more details."
    },
    {
        "link": "https://medium.com/@francescofranco_39234/how-to-use-sparse-categorical-crossentropy-in-keras-8d07fbb6fa71",
        "document": "For multiclass classification problems, many online tutorials — and even François Chollet’s book Deep Learning with Python, which I think is one of the most intuitive books on deep learning with Keras — use categorical crossentropy for computing the loss value of your neural network.\n\nHowever, traditional categorical crossentropy requires your data to be one-hot encoded and hence converted into categorical format. Often, this is not what your dataset looks like when you start creating your models. Rather, you likely have feature vectors with integer targets — such as 0 to 9 for the numbers 0 to 9.\n\nThis means that you’ll have to convert these targets first. In Keras, this can be done with , which essentially applies one-hot encoding to your training set's targets. When applied, you can start using categorical crossentropy.\n\nBut did you know that there exists another type of loss — sparse categorical crossentropy — with which you can leave the integers as they are, yet benefit from crossentropy loss? I didn’t when I just started out with Keras, simply because, in pretty much every article I read, the authors applied one-hot encoding before applying regular categorical crossentropy loss.\n\nIn this blog, we’ll figure out how to build a convolutional neural network with sparse categorical crossentropy loss.\n\nWe’ll create an actual CNN with Keras. It’ll be a simple one, with the MNIST dataset. However, doing that allows us to compare the model in terms of its performance — to actually see whether sparse categorical crossentropy does as good a job as the regular one.\n\nAfter reading this tutorial, you will…\n• Understand what does when creating your TensorFlow/Keras models.\n• Why it’s not necessary if you have integer labels/targets, but why you will have to change your loss function.\n• How loss can be useful in that case.\n\nHave you ever seen lines of code like these in your Keras projects?\n\nMost likely, you have — because many blogs explaining how to create multiclass classifiers with Keras apply categorical crossentropy, which requires you to one-hot encode your target vectors.\n\nNow you may wonder: what is one-hot encoding?\n\nSuppose that you have a classification problem where you have four target classes: { 0, 1, 2, 3 }.\n\nYour dataset likely comes in this flavor: , where your target is an integer value from { 0, 1, 2, 3 }.\n\nHowever, as we saw in another blog on categorical crossentropy, its mathematical structure doesn’t allow us to feed it integers directly.\n\nWe’ll have to convert it into categorical format first — with one-hot encoding, or in Keras.\n\nYou effectively transform your targets into this:\n\nNote that when you have more classes, the trick goes on and on — you simply create n-dimensional vectors, where n equals the unique number of classes in your dataset.\n\nWhen converted into categorical data, you can apply categorical crossentropy:\n\nWhat you see above is obviously the categorical crossentropy formula. What it does is actually really simple: it iterates over all the possible classes predicted by the ML model during the forward pass of your machine learning training process.\n\nFor each class, it takes a look at the target observation of the class — i.e., whether the actual class matching the prediction in your training set is 0 or one. Additionally, it computes the (natural) logarithm of the prediction of the observation (the odds that it belongs to that class). From this, it follows that only one such value is relevant — the actual target. For this, it simply computes the natural log value which increases significantly when it is further away from 1.\n\nNow, it could be the case that your dataset is not categorical at first- and possibly, that it is too large to be able to use . In that case, it would be rather difficult to use categorical crossentropy, since it is dependent on categorical data.\n\nHowever, when you have integer targets instead of categorical vectors as targets, you can use sparse categorical crossentropy. It’s an integer-based version of the categorical crossentropy loss function, which means that we don’t have to convert the targets into categorical format anymore.\n\nLet’s now create a CNN with Keras that uses sparse categorical crossentropy. In some folder, create a file called and open it in some code editor.\n\nAs usual, we use the MNIST dataset. This dataset, which contains thousands of 28x28 pixel handwritten digits (individual numbers from 0–9), is one of the standard datasets in machine learning training programs because it’s a very easy and normalized one. The images are also relatively small and high in quantity, which benefits the predictive and generalization power of your model when trained properly. This way, one can really focus on the machine learning aspects of an exercise, rather than the data related issues.\n\nIf we wish to run the sparse categorical crossentropy Keras CNN, it’s necessary to install a few software tools:\n• Obviously, you need TensorFlow, version 2.x (i.e. some version of 2), which comes with Keras installed as .\n• As a consequence, you’ll need to install peer dependencies such as NumPy. You’ll also need them for processing the data.\n• In order to run any of those, you need to have a working Python installation; preferably, your Python version is 3.12x.\n\nPreferably, you’ll run your model in an Anaconda environment. This way, you will be able to install your packages in a unique environment with which other packages do not interfere. Mingling Python packages is often a tedious job, which often leads to trouble. Anaconda resolves this by allowing you to use environments or isolated sandboxes in which your code can run. Strongly recommended!\n\nThis will be our model for today:\n\nNow, let’s break the model into parts.\n\nFirst, we add our imports — packages and functions that we’ll need for our model to work as intended.\n• Import the MNIST dataset. It comes with Keras by default because it’s a perfect dataset for educational purposes. When you use a model with this dataset for the first time, Keras will download the dataset automatically, after which it is stored locally — and you don’t ever have to worry about downloading the dataset again. Very user friendly.\n• Import the Sequential API — which is one of the two APIs with which engineers can create Keras based models, the other being the Functional API. As Sequential is relatively easier than Functional, we’ll use it for this tutorial.\n• Import the Dense layer, the Dropout function and the Flatten layer. Dense layers are used for the classification part of the CNN; Dropout adds random noise which reduces the odds of overfitting, and Flatten converts the multidimensional output of the convolutional layers (which interpret your images) into a one dimensional vector to be used by the Dense layers (for classifying the interpretations into the correct classes).\n• Additionally, we import Conv2D and MaxPooling2D, which are used for image interpretation and downscaling — i.e., the first part of your CNN.\n\nWe specify image width and image height, which are 28 for both given the images in the MNIST dataset. We specify a batch size of 250, which means that during training 250 images at once will be processed. When all images are processed, one completes an epoch, of which we will have 25 in total during the training of our model. Additionally, we specify the number of classes in advance — 10, the numbers 0 to 9. 20% of our training set will be set apart for validating the model after every batch, and for educational purposes we set model verbosity to True (1) — which means that all possible output is actually displayed on screen.\n\nNext, we load and prepare the MNIST data:\n\nWhat we do is simple — we use to load the MNIST data into four Python variables, representing inputs and targets for both the training and testing datasets.\n\nAdditionally, we reshape the data so that TensorFlow will accept it.\n\nAdditionally, we perform some other preparations which concern the data instead of how it is handled by your system:\n\nWe first parse the numbers as floats. This benefits the optimization step of the training process. Then, we normalize the data, which benefits the training process as well.\n\nWe then create the architecture of our model:\n\nTo be frank: the architecture of our model doesn’t really matter for showing that sparse categorical crossentropy really works. In fact, you can use the architecture you think is best for your machine learning problem. However, we put up the architecture above because it is very generic and hence works well in many simple classification scenarios:\n• We use two convolutional blocks which comprise a 2-dimensional convolutional layer, max pooling and Dropout. The convolutional layer interprets the features into feature maps, which are subsequently downsampled (made smaller/less granular) by the max pooling operation. Subsequently, random Dropout noise is introduced to reduce the odds of overfitting, which means that your model is tailored too specifically to your training data, and might not work anymore with data it has never seen.\n• We then flatten the multidimensional input into a 1-dimensional vector that can be handled by the densely-connected layers. We specify the number of output neurons to which in the case of the MNIST dataset is 10: each neuron generates the probability (summed to one considering all neurons together) that the input belongs to one of the 10 classes in the MNIST scenario.\n• We use two Dense layers which essentially give the CNN its classification power. Note that ReLU is used as an activation function throughout all layers given its simplicity and relative power in today’s deep learning problems. However, the last layer uses a Softmax activation, which essentially generates a multiclass probability distribution over all the classes that are available in your targets.\n\nWe next compile the model, which involves configuring it by means of hyperparameter tuning:\n\nWe specify the loss function used — sparse categorical crossentropy! We use it together with the Adam optimizer, which is one of the standard ones used today in very generic scenarios, and use accuracy as an additional metric, since it is more intuitive to humans.\n\nNext, we fit the data following the specification created in the model configuration step and specify evaluation metrics that test the trained model with the testing data:\n\nNow, we can start the training process. Open a terminal, possibly the Anaconda, one navigating to your environment by means of , and navigate to the folder storing by means of the function.\n\nNext, start the training process with Python: .\n\nYou should then see something like this:\n\n25 epochs as configured, with impressive scores in both the validation and testing phases. It pretty much works as well as the classifier created with categorical crossentropy — and I actually think the difference can be attributed to the relative randomness of the model optimization process:\n\nWell, today, we’ve seen how to create a Convolutional Neural Network (and by consequence, any model) with sparse categorical crossentropy in Keras. If you have integer targets in your dataset, which happens in many cases, you usually perform in order to use multiclass crossentropy loss. With sparse categorical crossentropy, this is no longer necessary. This blog demonstrated this by means of an example Keras implementation of a CNN that classifies the MNIST dataset.\n\nI hope you have benefited from today’s blog post (which was more of a how to). Any questions, suggestions or comments are most welcome.Thank you for reading”!!"
    }
]