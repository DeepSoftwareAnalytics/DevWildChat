[
    {
        "link": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html",
        "document": ""
    },
    {
        "link": "https://pandas.pydata.org/docs/reference/frame.html",
        "document": "Access a single value for a row/column pair by integer position. Access a group of rows and columns by label(s) or a boolean array. Insert column into DataFrame at specified location. Get the 'info axis' (see Indexing for more). Get item from object for given key (ex: DataFrame column). Whether each element in the DataFrame is contained in values. Replace values where the condition is False. Replace values where the condition is True. Query the columns of a DataFrame with a boolean expression. For more information on , , , and , see the indexing documentation.\n\nGet Addition of DataFrame and other, column-wise. Get Addition of dataframe and other, element-wise (binary operator ). Get Subtraction of dataframe and other, element-wise (binary operator ). Get Multiplication of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Integer division of dataframe and other, element-wise (binary operator ). Get Modulo of dataframe and other, element-wise (binary operator ). Get Exponential power of dataframe and other, element-wise (binary operator ). Compute the matrix multiplication between the DataFrame and other. Get Addition of dataframe and other, element-wise (binary operator ). Get Subtraction of dataframe and other, element-wise (binary operator ). Get Multiplication of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Floating division of dataframe and other, element-wise (binary operator ). Get Integer division of dataframe and other, element-wise (binary operator ). Get Modulo of dataframe and other, element-wise (binary operator ). Get Exponential power of dataframe and other, element-wise (binary operator ). Get Less than of dataframe and other, element-wise (binary operator ). Get Greater than of dataframe and other, element-wise (binary operator ). Get Less than or equal to of dataframe and other, element-wise (binary operator ). Get Greater than or equal to of dataframe and other, element-wise (binary operator ). Get Not equal to of dataframe and other, element-wise (binary operator ). Get Equal to of dataframe and other, element-wise (binary operator ). Update null elements with value in the same location in .\n\nAlign two objects on their axes with the specified join method. Select values at particular time of day (e.g., 9:30AM). Select values between particular times of the day (e.g., 9:00-9:30 AM). Drop specified labels from rows or columns. Test whether two objects contain the same elements. Subset the dataframe rows or columns according to the specified index labels. Return index of first occurrence of maximum over requested axis. Return index of first occurrence of minimum over requested axis. Conform DataFrame to new index with optional filling logic. Return an object with matching indices as other object. Set the name of the axis for the index or columns. Reset the index, or a level of it. Return a random sample of items from an axis of object. Return the elements in the given positional indices along an axis. Truncate a Series or DataFrame before and after some index value.\n\n(DEPRECATED) Fill NA/NaN values by using the next valid observation to fill the gap. Fill NA/NaN values by using the next valid observation to fill the gap. Fill NA/NaN values by propagating the last valid observation to next valid. Fill NA/NaN values using the specified method. DataFrame.isnull is an alias for DataFrame.isna. DataFrame.notnull is an alias for DataFrame.notna. (DEPRECATED) Fill NA/NaN values by propagating the last valid observation to next valid. Replace values given in with .\n\nSort by the values along either axis. Sort object by labels (along an axis). Return the first rows ordered by in descending order. Return the first rows ordered by in ascending order. Stack the prescribed level(s) from columns to index. Transform each element of a list-like to a row, replicating index values. Return an xarray object from the pandas object. The transpose of the DataFrame.\n\nReturn the last row(s) without any NaNs before . Shift index by desired number of periods with an optional time . Return index for first non-NA value or None, if no non-NA value is found. Return index for last non-NA value or None, if no non-NA value is found. Cast to DatetimeIndex of timestamps, at beginning of period. Localize tz-naive index of a Series or DataFrame to target time zone.\n\nFlags refer to attributes of the pandas object. Properties of the dataset (like the date is was recorded, the URL it was accessed from, etc.) should be stored in ."
    },
    {
        "link": "https://pandas.pydata.org/docs/user_guide/10min.html",
        "document": "This is a short introduction to pandas, geared mainly for new users. You can see more complex recipes in the Cookbook.\n\nCustomarily, we import as follows:\n\nSee the Intro to data structures section. Creating a by passing a NumPy array with a datetime index using and labeled columns: Creating a by passing a dictionary of objects where the keys are the column labels and the values are the column values. The columns of the resulting have different dtypes: If you’re using IPython, tab completion for column names (as well as public attributes) is automatically enabled. Here’s a subset of the attributes that will be completed: As you can see, the columns , , , and are automatically tab completed. and are there as well; the rest of the attributes have been truncated for brevity.\n\nUse and to view the top and bottom rows of the frame respectively: Return a NumPy representation of the underlying data with without the index or column labels: NumPy arrays have one dtype for the entire array while pandas DataFrames have one dtype per column. When you call , pandas will find the NumPy dtype that can hold all of the dtypes in the DataFrame. If the common data type is , will require copying data.\n\nWhile standard Python / NumPy expressions for selecting and setting are intuitive and come in handy for interactive work, for production code, we recommend the optimized pandas data access methods, , , and . See the indexing documentation Indexing and Selecting Data and MultiIndex / Advanced Indexing. For a , passing a single label selects a columns and yields a equivalent to : See more in Selection by Label using or . For label slicing, both endpoints are included: For getting fast access to a scalar (equivalent to the prior method): See more in Selection by Position using or . Select via the position of the passed integers: For getting a value explicitly: For getting fast access to a scalar (equivalent to the prior method): Select rows where is greater than . Selecting values from a where a boolean condition is met: Setting a new column automatically aligns the data by the indexes: The result of the prior setting operations:\n\nFor NumPy data types, represents missing data. It is by default not included in computations. See the Missing Data section. Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data: drops any rows that have missing data: gets the boolean mask where values are :\n\nSee the Basic section on Binary Ops. Calculate the mean value for each column: Calculate the mean value for each row: Operating with another or with a different index or column will align the result with the union of the index or column labels. In addition, pandas automatically broadcasts along the specified dimension and will fill unaligned labels with . and applies a user defined function that reduces or broadcasts its result respectively. See more at Histogramming and Discretization. is equipped with a set of string processing methods in the attribute that make it easy to operate on each element of the array, as in the code snippet below. See more at Vectorized String Methods.\n\nBy “group by” we are referring to a process involving one or more of the following steps:\n• None Splitting the data into groups based on some criteria Grouping by a column label, selecting column labels, and then applying the function to the resulting groups:\n\nSee the sections on Hierarchical Indexing and Reshaping. The method “compresses” a level in the DataFrame’s columns: With a “stacked” DataFrame or Series (having a as the ), the inverse operation of is , which by default unstacks the last level: See the section on Pivot Tables. pivots a specifying the , and\n\npandas can include categorical data in a . For full docs, see the categorical introduction and the API documentation. Rename the categories to more meaningful names: Reorder the categories and simultaneously add the missing categories (methods under return a new by default): Sorting is per order in the categories, not lexical order: Grouping by a categorical column with also shows empty categories:\n\nIf you are attempting to perform a boolean operation on a or you might see an exception like: Traceback (most recent call last) in in : The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). See Comparisons and Gotchas for an explanation and what to do."
    },
    {
        "link": "https://pandas.pydata.org/docs/user_guide/index.html",
        "document": "The User Guide covers all of pandas by topic area. Each of the subsections introduces a topic (such as “working with missing data”), and discusses how pandas approaches the problem, with many examples throughout.\n\nUsers brand-new to pandas should start with 10 minutes to pandas.\n\nFor a high level summary of the pandas fundamentals, see Intro to data structures and Essential basic functionality.\n\nFurther information on any specific method can be obtained in the API reference.\n\nHow to read these guides# In these guides you will see input code inside code blocks such as: The first block is a standard python input, while in the second the indicates the input is inside a notebook. In Jupyter Notebooks the last line is printed and plots are shown inline."
    },
    {
        "link": "https://pandas.pydata.org/docs/user_guide/dsintro.html",
        "document": "We’ll start with a quick, non-comprehensive overview of the fundamental data structures in pandas to get you started. The fundamental behavior about data types, indexing, axis labeling, and alignment apply across all of the objects. To get started, import NumPy and load pandas into your namespace:\n\nFundamentally, data alignment is intrinsic. The link between labels and data will not be broken unless done so explicitly by you.\n\nWe’ll give a brief intro to the data structures, then consider all of the broad categories of functionality and methods in separate sections.\n\nis a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. The basic method to create a is to call: Here, can be many different things: The passed index is a list of axis labels. Thus, this separates into a few cases depending on what data is: If is an ndarray, index must be the same length as data. If no index is passed, one will be created having values . pandas supports non-unique index values. If an operation that does not support duplicate index values is attempted, an exception will be raised at that time. can be instantiated from dicts: If an index is passed, the values in data corresponding to the labels in the index will be pulled out. NaN (not a number) is the standard missing data marker used in pandas. If is a scalar value, an index must be provided. The value will be repeated to match the length of index. acts very similarly to a and is a valid argument to most NumPy functions. However, operations such as slicing will also slice the index. We will address array-based indexing like in section on indexing. This is often a NumPy dtype. However, pandas and 3rd-party libraries extend NumPy’s type system in a few places, in which case the dtype would be an . Some examples within pandas are Categorical data and Nullable integer data type. See dtypes for more. If you need the actual array backing a , use . Accessing the array can be useful when you need to do some operation without the index (to disable automatic alignment, for example). will always be an . Briefly, an ExtensionArray is a thin wrapper around one or more concrete arrays like a . pandas knows how to take an and store it in a or a column of a . See dtypes for more. While is ndarray-like, if you need an actual ndarray, then use . Even if the is backed by a , will return a NumPy ndarray. A is also like a fixed-size dict in that you can get and set values by index label: If a label is not contained in the index, an exception is raised: Traceback (most recent call last) in in in in in : 'f' Traceback (most recent call last) in # Convert generator to list before going through hashable part # (We will iterate through the generator there to check for slices) in # Similar to Index.get_value, but we do not fall back to positional in # If we have a listlike key, _check_indexing_error will raise # InvalidIndexError. Otherwise we fall through and re-raise : 'f' Using the method, a missing label will return None or specified default: These labels can also be accessed by attribute. When working with raw NumPy arrays, looping through value-by-value is usually not necessary. The same is true when working with in pandas. can also be passed into most NumPy methods expecting an ndarray. A key difference between and ndarray is that operations between automatically align the data based on label. Thus, you can write computations without giving consideration to whether the involved have the same labels. The result of an operation between unaligned will have the union of the indexes involved. If a label is not found in one or the other, the result will be marked as missing . Being able to write code without doing any explicit data alignment grants immense freedom and flexibility in interactive data analysis and research. The integrated data alignment features of the pandas data structures set pandas apart from the majority of related tools for working with labeled data. In general, we chose to make the default result of operations between differently indexed objects yield the union of the indexes in order to avoid loss of information. Having an index label, though the data is missing, is typically important information as part of a computation. You of course have the option of dropping labels with missing data via the dropna function. The can be assigned automatically in many cases, in particular, when selecting a single column from a , the will be assigned the column label. You can rename a with the method. Note that and refer to different objects.\n\nis a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used pandas object. Like Series, DataFrame accepts many different kinds of input: Along with the data, you can optionally pass index (row labels) and columns (column labels) arguments. If you pass an index and / or columns, you are guaranteeing the index and / or columns of the resulting DataFrame. Thus, a dict of Series plus a specific index will discard all data not matching up to the passed index. If axis labels are not passed, they will be constructed from the input data based on common sense rules. From dict of Series or dicts# The resulting index will be the union of the indexes of the various Series. If there are any nested dicts, these will first be converted to Series. If no columns are passed, the columns will be the ordered list of dict keys. The row and column labels can be accessed respectively by accessing the index and columns attributes: When a particular set of columns is passed along with a dict of data, the passed columns override the keys in the dict. All ndarrays must share the same length. If an index is passed, it must also be the same length as the arrays. If no index is passed, the result will be , where is the array length. This case is handled identically to a dict of arrays. DataFrame is not intended to work exactly like a 2-dimensional NumPy ndarray. You can automatically create a MultiIndexed frame by passing a tuples dictionary. The result will be a DataFrame with the same index as the input Series, and with one column whose name is the original name of the Series (only if no other column name provided). The field names of the first in the list determine the columns of the . The remaining namedtuples (or tuples) are simply unpacked and their values are fed into the rows of the . If any of those tuples is shorter than the first then the later columns in the corresponding row are marked as missing values. If any are longer than the first , a is raised. Data Classes as introduced in PEP557, can be passed into the DataFrame constructor. Passing a list of dataclasses is equivalent to passing a list of dictionaries. Please be aware, that all values in the list should be dataclasses, mixing types in the list would result in a . To construct a DataFrame with missing data, we use to represent missing values. Alternatively, you may pass a as the data argument to the DataFrame constructor, and its masked entries will be considered missing. See Missing data for more. takes a dict of dicts or a dict of array-like sequences and returns a DataFrame. It operates like the constructor except for the parameter which is by default, but which can be set to in order to use the dict keys as row labels. If you pass , the keys will be the row labels. In this case, you can also pass the desired column names: takes a list of tuples or an ndarray with structured dtype. It works analogously to the normal constructor, except that the resulting DataFrame index may be a specific field of the structured dtype. You can treat a semantically like a dict of like-indexed objects. Getting, setting, and deleting columns works with the same syntax as the analogous dict operations: Columns can be deleted or popped like with a dict: When inserting a scalar value, it will naturally be propagated to fill the column: When inserting a that does not have the same index as the , it will be conformed to the DataFrame’s index: You can insert raw ndarrays but their length must match the length of the DataFrame’s index. By default, columns get inserted at the end. inserts at a particular location in the columns: Inspired by dplyr’s verb, DataFrame has an method that allows you to easily create new columns that are potentially derived from existing columns. In the example above, we inserted a precomputed value. We can also pass in a function of one argument to be evaluated on the DataFrame being assigned to. always returns a copy of the data, leaving the original DataFrame untouched. Passing a callable, as opposed to an actual value to be inserted, is useful when you don’t have a reference to the DataFrame at hand. This is common when using in a chain of operations. For example, we can limit the DataFrame to just those observations with a Sepal Length greater than 5, calculate the ratio, and plot: Since a function is passed in, the function is computed on the DataFrame being assigned to. Importantly, this is the DataFrame that’s been filtered to those rows with sepal length greater than 5. The filtering happens first, and then the ratio calculations. This is an example where we didn’t have a reference to the filtered DataFrame available. The function signature for is simply . The keys are the column names for the new fields, and the values are either a value to be inserted (for example, a or NumPy array), or a function of one argument to be called on the . A copy of the original is returned, with the new values inserted. The order of is preserved. This allows for dependent assignment, where an expression later in can refer to a column created earlier in the same . In the second expression, will refer to the newly created column, that’s equal to . The basics of indexing are as follows: Row selection, for example, returns a whose index is the columns of the : For a more exhaustive treatment of sophisticated label-based indexing and slicing, see the section on indexing. We will address the fundamentals of reindexing / conforming to new sets of labels in the section on reindexing. Data alignment between objects automatically align on both the columns and the index (row labels). Again, the resulting object will have the union of the column and row labels. When doing an operation between and , the default behavior is to align the index on the columns, thus broadcasting row-wise. For example: For explicit control over the matching and broadcasting behavior, see the section on flexible binary operations. To transpose, access the attribute or , similar to an ndarray: # only show the first 5 rows Most NumPy functions can be called directly on and . is not intended to be a drop-in replacement for ndarray as its indexing semantics and data model are quite different in places from an n-dimensional array. implements , which allows it to work with NumPy’s universal functions. The ufunc is applied to the underlying array in a . When multiple are passed to a ufunc, they are aligned before performing the operation. Like other parts of the library, pandas will automatically align labeled inputs as part of a ufunc with multiple inputs. For example, using on two with differently ordered labels will align before the operation. As usual, the union of the two indices is taken, and non-overlapping values are filled with missing values. When a binary ufunc is applied to a and , the implementation takes precedence and a is returned. NumPy ufuncs are safe to apply to backed by non-ndarray arrays, for example (see Sparse calculation). If possible, the ufunc is applied without converting the underlying data to an ndarray. A very large will be truncated to display them in the console. You can also get a summary using . (The baseball dataset is from the plyr R package): However, using will return a string representation of the in tabular form, though it won’t always fit the console width: Wide DataFrames will be printed across multiple rows by default: You can change how much to print on a single row by setting the option: You can adjust the max width of the individual columns by setting You can also disable this feature via the option. This will print the table in one block. If a column label is a valid Python variable name, the column can be accessed like an attribute: The columns are also connected to the IPython completion mechanism so they can be tab-completed:"
    },
    {
        "link": "https://numpy.org/doc/2.1/reference/random/generated/numpy.random.normal.html",
        "document": "The probability density function of the normal distribution, first derived by De Moivre and 200 years later by both Gauss and Laplace independently [2], is often called the bell curve because of its characteristic shape (see the example below).\n\nThe normal distributions occurs often in nature. For example, it describes the commonly occurring distribution of samples influenced by a large number of tiny, random disturbances, each with its own unique distribution [2].\n\nThe probability density for the Gaussian distribution is\n\nwhere \\(\\mu\\) is the mean and \\(\\sigma\\) the standard deviation. The square of the standard deviation, \\(\\sigma^2\\), is called the variance.\n\nThe function has its peak at the mean, and its “spread” increases with the standard deviation (the function reaches 0.607 times its maximum at \\(x + \\sigma\\) and \\(x - \\sigma\\) [2]). This implies that normal is more likely to return samples lying close to the mean, rather than those far away.\n\nVerify the mean and the variance:\n\nDisplay the histogram of the samples, along with the probability density function:\n\nTwo-by-four array of samples from the normal distribution with mean 3 and standard deviation 2.5:"
    },
    {
        "link": "https://numpy.org/doc/2.0/reference/random/generated/numpy.random.normal.html",
        "document": "The probability density function of the normal distribution, first derived by De Moivre and 200 years later by both Gauss and Laplace independently [2], is often called the bell curve because of its characteristic shape (see the example below).\n\nThe normal distributions occurs often in nature. For example, it describes the commonly occurring distribution of samples influenced by a large number of tiny, random disturbances, each with its own unique distribution [2].\n\nThe probability density for the Gaussian distribution is\n\nwhere \\(\\mu\\) is the mean and \\(\\sigma\\) the standard deviation. The square of the standard deviation, \\(\\sigma^2\\), is called the variance.\n\nThe function has its peak at the mean, and its “spread” increases with the standard deviation (the function reaches 0.607 times its maximum at \\(x + \\sigma\\) and \\(x - \\sigma\\) [2]). This implies that normal is more likely to return samples lying close to the mean, rather than those far away.\n\nVerify the mean and the variance:\n\nDisplay the histogram of the samples, along with the probability density function:\n\nTwo-by-four array of samples from the normal distribution with mean 3 and standard deviation 2.5:"
    },
    {
        "link": "https://numpy.org/devdocs/reference/random/generated/numpy.random.normal.html",
        "document": "The probability density function of the normal distribution, first derived by De Moivre and 200 years later by both Gauss and Laplace independently [2], is often called the bell curve because of its characteristic shape (see the example below).\n\nThe normal distributions occurs often in nature. For example, it describes the commonly occurring distribution of samples influenced by a large number of tiny, random disturbances, each with its own unique distribution [2].\n\nThe probability density for the Gaussian distribution is\n\nwhere \\(\\mu\\) is the mean and \\(\\sigma\\) the standard deviation. The square of the standard deviation, \\(\\sigma^2\\), is called the variance.\n\nThe function has its peak at the mean, and its “spread” increases with the standard deviation (the function reaches 0.607 times its maximum at \\(x + \\sigma\\) and \\(x - \\sigma\\) [2]). This implies that normal is more likely to return samples lying close to the mean, rather than those far away.\n\nVerify the mean and the standard deviation: Display the histogram of the samples, along with the probability density function: Two-by-four array of samples from the normal distribution with mean 3 and standard deviation 2.5:"
    },
    {
        "link": "https://numpy.org/doc/2.1/reference/random/generator.html",
        "document": "The provides access to a wide range of distributions, and served as a replacement for . The main difference between the two is that relies on an additional BitGenerator to manage state and generate the random bits, which are then transformed into random values from useful distributions. The default BitGenerator used by is . The BitGenerator can be changed by passing an instantized BitGenerator to .\n\nConstruct a new Generator with the default BitGenerator (PCG64). A seed to initialize the . If None, then fresh, unpredictable entropy will be pulled from the OS. If an or is passed, then all values must be non-negative and will be passed to to derive the initial state. One may also pass in a instance. Additionally, when passed a , it will be wrapped by . If passed a , it will be returned unaltered. If is not a or a , a new is instantiated. This function does not manage a default global instance. See Seeding and entropy for more information about seeding. is the recommended constructor for the random number class . Here are several ways we can construct a random number generator using and the class. Here we use to generate a random float: Here we use to generate 3 random integers between 0 (inclusive) and 10 (exclusive): Here we specify a seed so that we have reproducible results: If we exit and restart our Python interpreter, we’ll see that we generate the same random numbers again:\n\nexposes a number of methods for generating random numbers drawn from a variety of probability distributions. In addition to the distribution-specific arguments, each method takes a keyword argument size that defaults to . If size is , then a single value is generated and returned. If size is an integer, then a 1-D array filled with generated values is returned. If size is a tuple, then an array with that shape is filled and returned. The function will instantiate a with numpy’s default . does not provide a version compatibility guarantee. In particular, as better algorithms evolve the bit stream may change. BitGenerator to use as the core generator. The Python stdlib module contains pseudo-random number generator with a number of methods that are similar to the ones available in . It uses Mersenne Twister, and this bit generator can be accessed using . , besides being NumPy-aware, has the advantage that it provides a much larger number of probability distributions to choose from.\n\nThe methods for randomly permuting a sequence are Modify an array or sequence in-place by shuffling its contents. The following table summarizes the behaviors of the methods. either (use ‘out’ for in-place) The following subsections provide more details about the differences. The main difference between and is that operates in-place, while returns a copy. By default, returns a copy. To operate in-place with , pass the same array as the first argument and as the value of the parameter. For example, Note that when is given, the return value is : An important distinction for these methods is how they handle the parameter. Both and treat the input as a one-dimensional sequence, and the parameter determines which dimension of the input array to use as the sequence. In the case of a two-dimensional array, will, in effect, rearrange the rows of the array, and will rearrange the columns. For example Note that the columns have been rearranged “in bulk”: the values within each column have not changed. The method treats the parameter similar to how treats it. Each slice along the given axis is shuffled independently of the others. Compare the following example of the use of to the above example of : In this example, the values within each row (i.e. the values along ) have been shuffled independently. This is not a “bulk” shuffle of the columns. works on non-NumPy sequences. That is, if it is given a sequence that is not a NumPy array, it shuffles that sequence in-place."
    },
    {
        "link": "https://w3schools.com/python/numpy/numpy_random_normal.asp",
        "document": "The Normal Distribution is one of the most important distributions.\n\nIt is also called the Gaussian Distribution after the German mathematician Carl Friedrich Gauss.\n\nIt fits the probability distribution of many events, eg. IQ Scores, Heartbeat etc.\n\nUse the method to get a Normal Data Distribution.\n\nIt has three parameters:\n\n- (Mean) where the peak of the bell exists.\n\n- (Standard Deviation) how flat the graph distribution should be.\n\n- The shape of the returned array.\n\nNote: The curve of a Normal Distribution is also known as the Bell Curve because of the bell-shaped curve."
    }
]