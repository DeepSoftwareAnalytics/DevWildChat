[
    {
        "link": "https://understanding-recursion.readthedocs.io/en/latest",
        "document": "A shamelessly verbose guide to the wonders of recursion\n\nFor a lot of people, learning recursion for the first time pretty much sucks. It doesn’t have to be that way.\n\nThis guide is intended to help beginning (and perhaps even intermediate) programmers learn to think recursively. It’s not math-heavy, so there are no proofs, and very little discussion of time/space complexity. But I do take a text-heavy approach, because I think patient explanation is a key ingredient in helping people understand this crucial technique. Although the code is presented in Python, recursion is a fairly universal concept, so the material should be accessible to non-Python developers.\n\nSometimes I’ll present the code immediately and then unpack it. Other times, we’ll work towards the final recursive solution, starting only from first principles. At the end of each section I deduce a few heuristics, and include an exercise or two that will apply the material and push comprehension a bit further.\n\nI hope the end result is a critical framework developers can use to identify, analyze and solve problems that demand (or simply favor) recursive solutions."
    },
    {
        "link": "https://docs.python.org/3/tutorial/datastructures.html",
        "document": "This chapter describes some things you’ve learned about already in more detail, and adds some new things as well.\n\nThe list data type has some more methods. Here are all of the methods of list objects: Add an item to the end of the list. Similar to . Extend the list by appending all the items from the iterable. Similar to . Insert an item at a given position. The first argument is the index of the element before which to insert, so inserts at the front of the list, and is equivalent to . Remove the first item from the list whose value is equal to x. It raises a if there is no such item. Remove the item at the given position in the list, and return it. If no index is specified, removes and returns the last item in the list. It raises an if the list is empty or the index is outside the list range. Remove all items from the list. Similar to . Return zero-based index in the list of the first item whose value is equal to x. Raises a if there is no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument. Return the number of times x appears in the list. Sort the items of the list in place (the arguments can be used for sort customization, see for their explanation). Reverse the elements of the list in place. Return a shallow copy of the list. Similar to . An example that uses most of the list methods: You might have noticed that methods like , or that only modify the list have no return value printed – they return the default . This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, doesn’t sort because integers can’t be compared to strings and can’t be compared to other types. Also, there are some types that don’t have a defined ordering relation. For example, isn’t a valid comparison. The list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved (“last-in, first-out”). To add an item to the top of the stack, use . To retrieve an item from the top of the stack, use without an explicit index. For example: It is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-out”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing inserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use which was designed to have fast appends and pops from both ends. For example: # The first to arrive now leaves # The second to arrive now leaves List comprehensions provide a concise way to create lists. Common applications are to make new lists where each element is the result of some operations applied to each member of another sequence or iterable, or to create a subsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like: Note that this creates (or overwrites) a variable named that still exists after the loop completes. We can calculate the list of squares without any side effects using: which is more concise and readable. A list comprehension consists of brackets containing an expression followed by a clause, then zero or more or clauses. The result will be a new list resulting from evaluating the expression in the context of the and clauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal: Note how the order of the and statements is the same in both these snippets. If the expression is a tuple (e.g. the in the previous example), it must be parenthesized. # create a new list with the values doubled # apply a function to all the elements # the tuple must be parenthesized, otherwise an error is raised File , line : did you forget parentheses around the comprehension target? # flatten a list using a listcomp with two 'for' List comprehensions can contain complex expressions and nested functions: The initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4: The following list comprehension will transpose rows and columns: As we saw in the previous section, the inner list comprehension is evaluated in the context of the that follows it, so this example is equivalent to: which, in turn, is the same as: # the following 3 lines implement the nested listcomp In the real world, you should prefer built-in functions to complex flow statements. The function would do a great job for this use case: See Unpacking Argument Lists for details on the asterisk in this line.\n\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two examples of sequence data types (see Sequence Types — list, tuple, range). Since Python is an evolving language, other sequence data types may be added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance: File , line , in : # but they can contain mutable objects: As you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they may be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple is part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to create tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples are immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later in this section) or indexing (or even by attribute in the case of ). Lists are mutable, and their elements are usually homogeneous and are accessed by iterating over the list. A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accommodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed by following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example: The statement is an example of tuple packing: the values , and are packed together in a tuple. The reverse operation is also possible: This is called, appropriately enough, sequence unpacking and works for any sequence on the right-hand side. Sequence unpacking requires that there are as many variables on the left side of the equals sign as there are elements in the sequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking.\n\nPython also includes a data type for sets. A set is an unordered collection with no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. Set objects also support mathematical operations like union, intersection, difference, and symmetric difference. Curly braces or the function can be used to create sets. Note: to create an empty set you have to use , not ; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration: # show that duplicates have been removed # Demonstrate set operations on unique letters from two words # letters in a but not in b # letters in a or b or both # letters in both a and b # letters in a or b but not both Similarly to list comprehensions, set comprehensions are also supported:\n\nAnother useful data type built into Python is the dictionary (see Mapping Types — dict). Dictionaries are sometimes found in other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range of numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be keys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable object either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified in place using index assignments, slice assignments, or methods like and . It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within one dictionary). A pair of braces creates an empty dictionary: . Placing a comma-separated list of key:value pairs within the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also possible to delete a key:value pair with . If you store using a key that is already in use, the old value associated with that key is forgotten. It is an error to extract a value using a non-existent key. Performing on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you want it sorted, just use instead). To check whether a single key is in the dictionary, use the keyword. Here is a small example using a dictionary: The constructor builds dictionaries directly from sequences of key-value pairs: In addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions: When the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the method. When looping through a sequence, the position index and corresponding value can be retrieved at the same time using the function. To loop over two or more sequences at the same time, the entries can be paired with the function. What is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the function. To loop over a sequence in sorted order, use the function which returns a new sorted list while leaving the source unaltered. Using on a sequence eliminates duplicate elements. The use of in combination with over a sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. It is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create a new list instead.\n\nThe conditions used in and statements can contain any operators, not just comparisons. The comparison operators and are membership tests that determine whether a value is in (or not in) a container. The operators and compare whether two objects are really the same object. All comparison operators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, tests whether is less than and moreover equals . Comparisons may be combined using the Boolean operators and , and the outcome of a comparison (or of any other Boolean expression) may be negated with . These have lower priorities than comparison operators; between them, has the highest priority and the lowest, so that A and not B or C is equivalent to (A and (not B)) or C . As always, parentheses can be used to express the desired composition. The Boolean operators and are so-called short-circuit operators: their arguments are evaluated from left to right, and evaluation stops as soon as the outcome is determined. For example, if and are true but is false, A and B and C does not evaluate the expression . When used as a general value and not as a Boolean, the return value of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example, Note that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator . This avoids a common class of problems encountered in C programs: typing in an expression when was intended.\n\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses lexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of the comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried out recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence is an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one. Lexicographical ordering for strings uses the Unicode code point number to order individual characters. Some examples of comparisons between sequences of the same type: Note that comparing objects of different types with or is legal provided that the objects have appropriate comparison methods. For example, mixed numeric types are compared according to their numeric value, so 0 equals 0.0, etc. Otherwise, rather than providing an arbitrary ordering, the interpreter will raise a exception."
    },
    {
        "link": "https://realpython.com/python-recursion",
        "document": "If you’re familiar with functions in Python, then you know that it’s quite common for one function to call another. In Python, it’s also possible for a function to call itself! A function that calls itself is said to be recursive, and the technique of employing a recursive function is called recursion.\n\nIt may seem peculiar for a function to call itself, but many types of programming problems are best expressed recursively. When you bump up against such a problem, recursion is an indispensable tool for you to have in your toolkit.\n\nBy the end of this tutorial, you’ll understand:\n• What it means for a function to call itself recursively\n• How the design of Python functions supports recursion\n• What factors to consider when choosing whether or not to solve a problem recursively\n• How to implement a recursive function in Python\n\nThen you’ll study several Python programming problems that use recursion and contrast the recursive solution with a comparable non-recursive one.\n\nThe word recursion comes from the Latin word recurrere, meaning to run or hasten back, return, revert, or recur. Here are some online definitions of recursion:\n• Dictionary.com: The act or process of returning or running back\n• Wiktionary: The act of defining an object (usually a function) in terms of that object itself\n• The Free Dictionary: A method of defining a sequence of objects, such as an expression, function, or set, where some number of initial objects are given and each successive object is defined in terms of the preceding objects A recursive definition is one in which the defined term appears in the definition itself. Self-referential situations often crop up in real life, even if they aren’t immediately recognizable as such. For example, suppose you wanted to describe the set of people that make up your ancestors. You could describe them this way: Notice how the concept that is being defined, ancestors, shows up in its own definition. This is a recursive definition. In programming, recursion has a very precise meaning. It refers to a coding technique in which a function calls itself.\n\nMost programming problems are solvable without recursion. So, strictly speaking, recursion usually isn’t necessary. However, some situations particularly lend themselves to a self-referential definition—for example, the definition of ancestors shown above. If you were devising an algorithm to handle such a case programmatically, a recursive solution would likely be cleaner and more concise. Traversal of tree-like data structures is another good example. Because these are nested structures, they readily fit a recursive definition. A non-recursive algorithm to walk through a nested structure is likely to be somewhat clunky, while a recursive solution will be relatively elegant. An example of this appears later in this tutorial. On the other hand, recursion isn’t for every situation. Here are some other factors to consider:\n• For some problems, a recursive solution, though possible, will be awkward rather than elegant.\n• Recursive implementations often consume more memory than non-recursive ones.\n• In some cases, using recursion may result in slower execution time. Typically, the readability of the code will be the biggest determining factor. But it depends on the circumstances. The examples presented below should help you get a feel for when you should choose recursion.\n\nWhen you call a function in Python, the interpreter creates a new local namespace so that names defined within that function don’t collide with identical names defined elsewhere. One function can call another, and even if they both define objects with the same name, it all works out fine because those objects exist in separate namespaces. The same holds true if multiple instances of the same function are running concurrently. For example, consider the following definition: When executes the first time, Python creates a namespace and assigns the value in that namespace. Then calls itself recursively. The second time runs, the interpreter creates a second namespace and assigns to there as well. These two instances of the name are distinct from each another and can coexist without clashing because they are in separate namespaces. Unfortunately, running as it stands produces a result that is less than inspiring, as the following traceback shows: File , line , in File , line , in File , line , in File , line , in As written, would in theory go on forever, calling itself over and over without any of the calls ever returning. In practice, of course, nothing is truly forever. Your computer only has so much memory, and it would run out eventually. Python doesn’t allow that to happen. The interpreter limits the maximum number of times a function can call itself recursively, and when it reaches that limit, it raises a exception, as you see above. Technical note: You can find out what Python’s recursion limit is with a function from the module called : You can change it, too, with : You can set it to be pretty large, but you can’t make it infinite. There isn’t much use for a function to indiscriminately call itself recursively without end. It’s reminiscent of the instructions that you sometimes find on shampoo bottles: “Lather, rinse, repeat.” If you were to follow these instructions literally, you’d shampoo your hair forever! This logical flaw has evidently occurred to some shampoo manufacturers, because some shampoo bottles instead say “Lather, rinse, repeat as necessary.” That provides a termination condition to the instructions. Presumably, you’ll eventually feel your hair is sufficiently clean to consider additional repetitions unnecessary. Shampooing can then stop. Similarly, a function that calls itself recursively must have a plan to eventually stop. Recursive functions typically follow this pattern:\n• There are one or more base cases that are directly solvable without the need for further recursion.\n• Each recursive call moves the solution progressively closer to a base case. You’re now ready to see how this works with some examples.\n\nThe next example involves the mathematical concept of factorial. The factorial of a positive integer n, denoted as n!, is defined as follows: In other words, n! is the product of all integers from 1 to n, inclusive. Factorial so lends itself to recursive definition that programming texts nearly always include it as one of the first examples. You can express the definition of n! recursively like this: As with the example shown above, there are base cases that are solvable without recursion. The more complicated cases are reductive, meaning that they reduce to one of the base cases:\n• The base cases (n = 0 or n = 1) are solvable without recursion.\n• For values of n greater than 1, n! is defined in terms of (n - 1)!, so the recursive solution progressively approaches the base case. For example, recursive computation of 4! looks like this: The calculations of 4!, 3!, and 2! suspend until the algorithm reaches the base case where n = 1. At that point, 1! is computable without further recursion, and the deferred calculations run to completion. Here’s a recursive Python function to calculate factorial. Note how concise it is and how well it mirrors the definition shown above: A little embellishment of this function with some statements gives a clearer idea of the call and return sequence: Notice how all the recursive calls stack up. The function gets called with = , , , and in succession before any of the calls return. Finally, when is , the problem can be solved without any more recursion. Then each of the stacked-up recursive calls unwinds back out, returning , , , and finally from the outermost call. Recursion isn’t necessary here. You could implement iteratively using a loop: You can also implement factorial using Python’s , which you can import from the module: Again, this shows that if a problem is solvable with recursion, there will also likely be several viable non-recursive solutions as well. You’ll typically choose based on which one results in the most readable and intuitive code. Another factor to take into consideration is execution speed. There can be significant performance differences between recursive and non-recursive solutions. In the next section, you’ll explore these differences a little further. To evaluate execution time, you can use a function called from a module that is also called . This function supports a number of different formats, but you’ll use the following format in this tutorial: first executes the commands contained in the specified . Then it executes the given number of and reports the cumulative execution time in seconds: Here, the parameter assigns the value . Then prints one hundred times. The total execution time is just over 3/100 of a second. The examples shown below use to compare the recursive, iterative, and implementations of factorial from above. In each case, contains a setup string that defines the relevant function. then executes a total of ten million times and reports the aggregate execution. Next up is the iterative implementation: Last, here’s the version that uses : In this case, the iterative implementation is the fastest, although the recursive solution isn’t far behind. The method using is the slowest. Your mileage will probably vary if you try these examples on your own machine. You certainly won’t get the same times, and you may not even get the same ranking. Does it matter? There’s a difference of almost four seconds in execution time between the iterative implementation and the one that uses , but it took ten million calls to see it. If you’ll be calling a function many times, you might need to take execution speed into account when choosing an implementation. On the other hand, if the function will run relatively infrequently, then the difference in execution times will probably be negligible. In that case, you’d be better off choosing the implementation that seems to express the solution to the problem most clearly. For factorial, the timings recorded above suggest a recursive implementation is a reasonable choice. Frankly, if you’re coding in Python, you don’t need to implement a factorial function at all. It’s already available in the standard module: Perhaps it might interest you to know how this performs in the timing test: Wow! performs better than the best of the other three implementations shown above by roughly a factor of 10. Technical note: The fact that is so much speedier probably has nothing to do with whether it’s implemented recursively. More likely it’s because the function is implemented in C rather than Python. For more reading on Python and C, see these resources:\n• Python Bindings: Calling C or C++ From Python\n• Your Guide to the CPython Source Code A function implemented in C will virtually always be faster than a corresponding function implemented in pure Python.\n\nThe next example involves visiting each item in a nested list structure. Consider the following Python list: As the following diagram shows, contains two sublists. The first of these sublists itself contains another sublist: Suppose you wanted to count the number of leaf elements in this list—the lowest-level objects—as though you’d flattened out the list. The leaf elements are , , , , , , , , , and , so the answer should be . Just calling on the list doesn’t give the correct answer: counts the objects at the top level of , which are the three leaf elements , , and and two sublists and : What you need here is a function that traverses the entire list structure, sublists included. The algorithm goes something like this:\n• Walk through the list, examining each item in turn.\n• If you find a leaf element, then add it to the accumulated count.\n• If you encounter a sublist, then do the following:\n• Drop down into that sublist and similarly walk through it.\n• Once you’ve exhausted the sublist, go back up, add the elements from the sublist to the accumulated count, and resume the walk through the parent list where you left off. Note the self-referential nature of this description: Walk through the list. If you encounter a sublist, then similarly walk through that list. This situation begs for recursion! Recursion fits this problem very nicely. To solve it, you need to be able to determine whether a given list item is leaf item or not. For that, you can use the built-in Python function . In the case of the list, if an item is an instance of type , then it’s a sublist. Otherwise, it’s a leaf item: Now you have the tools in place to implement a function that counts leaf elements in a list, accounting for sublists recursively: If you run on several lists, including the list defined above, you get this: As with the factorial example, adding some statements helps to demonstrate the sequence of recursive calls and return values: Here’s a synopsis of what’s happening in the example above:\n• Line 9: is , so has found a sublist.\n• Line 11: The function calls itself recursively to count the items in the sublist, then adds the result to the accumulating total.\n• Line 12: is , so has encountered a leaf item.\n• Line 14: The function increments the accumulating total by one to account for the leaf item. Note: To keep things simple, this implementation assumes the list passed to contains only leaf items or sublists, not any other type of composite object like a dictionary or tuple. The output from when it’s executed on the list now looks like this: Each time a call to terminates, it returns the count of leaf elements it tallied in the list passed to it. The top-level call returns , as it should. Like the other examples shown so far, this list traversal doesn’t require recursion. You can also accomplish it iteratively. Here’s one possibility: If you run this non-recursive version of on the same lists as shown previously, you get the same results: The strategy employed here uses a stack to handle the nested sublists. When this version of encounters a sublist, it pushes the list that is currently in progress and the current index in that list onto a stack. Once it has counted the sublist, the function pops the parent list and index from the stack so it can resume counting where it left off. In fact, essentially the same thing happens in the recursive implementation as well. When you call a function recursively, Python saves the state of the executing instance on a stack so the recursive call can run. When the recursive call finishes, the state is popped from the stack so that the interrupted instance can resume. It’s the same concept, but with the recursive solution, Python is doing the state-saving work for you. Notice how concise and readable the recursive code is when compared to the non-recursive version: This is a case where using recursion is definitely an advantage.\n\nThe choice of whether to use recursion to solve a problem depends in large part on the nature of the problem. Factorial, for example, naturally translates to a recursive implementation, but the iterative solution is quite straightforward as well. In that case, it’s arguably a toss-up. The list traversal problem is a different story. In that case, the recursive solution is very elegant, while the non-recursive one is cumbersome at best. For the next problem, using recursion is arguably silly. A palindrome is a word that reads the same backward as it does forward. Examples include the following words: If asked to devise an algorithm to determine whether a string is palindromic, you would probably come up with something like “Reverse the string and see if it’s the same as the original.” You can’t get much plainer than that. Even more helpfully, Python’s slicing syntax for reversing a string provides a convenient way to code it: \"\"\"Return True if word is a palindrome, False if not.\"\"\" This is clear and concise. There’s hardly any need to look for an alternative. But just for fun, consider this recursive definition of a palindrome:\n• Base cases: An empty string and a string consisting of a single character are inherently palindromic.\n• Reductive recursion: A string of length two or greater is a palindrome if it satisfies both of these criteria:\n• The first and last characters are the same.\n• The substring between the first and last characters is a palindrome. Slicing is your friend here as well. For a string , indexing and slicing give the following substrings:\n• The first character is .\n• The last character is .\n• The substring between the first and last characters is . So you can define recursively like this: \"\"\"Return True if word is a palindrome, False if not.\"\"\" It’s an interesting exercise to think recursively, even when it isn’t especially necessary.\n\nThe final example presented, like the nested list traversal, is a good example of a problem that very naturally suggests a recursive approach. The Quicksort algorithm is an efficient sorting algorithm developed by British computer scientist Tony Hoare in 1959. Quicksort is a divide-and-conquer algorithm. Suppose you have a list of objects to sort. You start by choosing an item in the list, called the pivot item. This can be any item in the list. You then partition the list into two sublists based on the pivot item and recursively sort the sublists. The steps of the algorithm are as follows:\n• Partition the list into two sublists:\n• Those items that are less than the pivot item\n• Those items that are greater than the pivot item Each partitioning produces smaller sublists, so the algorithm is reductive. The base cases occur when the sublists are either empty or have one element, as these are inherently sorted. The Quicksort algorithm will work no matter what item in the list is the pivot item. But some choices are better than others. Remember that when partitioning, two sublists that are created: one with items that are less than the pivot item and one with items that are greater than the pivot item. Ideally, the two sublists are of roughly equal length. Imagine that your initial list to sort contains eight items. If each partitioning results in sublists of roughly equal length, then you can reach the base cases in three steps: At the other end of the spectrum, if your choice of pivot item is especially unlucky, each partition results in one sublist that contains all the original items except the pivot item and another sublist that is empty. In that case, it takes seven steps to reduce the list to the base cases: The Quicksort algorithm will be more efficient in the first case. But you’d need to know something in advance about the nature of the data you’re sorting in order to systematically choose optimal pivot items. In any case, there isn’t any one choice that will be the best for all cases. So if you’re writing a Quicksort function to handle the general case, the choice of pivot item is somewhat arbitrary. The first item in the list is a common choice, as is the last item. These will work fine if the data in the list is fairly randomly distributed. However, if the data is already sorted, or even nearly so, then these will result in suboptimal partitioning like that shown above. To avoid this, some Quicksort algorithms choose the middle item in the list as the pivot item. Another option is to find the median of the first, last, and middle items in the list and use that as the pivot item. This is the strategy used in the sample code below. Once you’ve chosen the pivot item, the next step is to partition the list. Again, the goal is to create two sublists, one containing the items that are less than the pivot item and the other containing those that are greater. You could accomplish this directly in place. In other words, by swapping items, you could shuffle the items in the list around until the pivot item is in the middle, all the lesser items are to its left, and all the greater items are to its right. Then, when you Quicksort the sublists recursively, you’d pass the slices of the list to the left and right of the pivot item. Alternately, you can use Python’s list manipulation capability to create new lists instead of operating on the original list in place. This is the approach taken in the code below. The algorithm is as follows:\n• Choose the pivot item using the median-of-three method described above.\n• Using the pivot item, create three sublists:\n• The items in the original list that are less than the pivot item\n• The items in the original list that are greater than the pivot item\n• Concatenate all three lists back together. Note that this involves creating a third sublist that contains the pivot item itself. One advantage to this approach is that it smoothly handles the case where the pivot item appears in the list more than once. In that case, list 2 will have more than one element. Now that the groundwork is in place, you are ready to move on to the Quicksort algorithm. Here’s the Python code: This is what each section of is doing:\n• Line 4: The base cases where the list is either empty or has only a single element\n• Lines 7 to 13: Calculation of the pivot item by the median-of-three method\n• Lines 14 to 18: Creation of the three partition lists\n• Lines 20 to 24: Recursive sorting and reassembly of the partition lists Note: This example has the advantage of being succinct and relatively readable. However, it isn’t the most efficient implementation. In particular, the creation of the partition lists on lines 14 to 18 involves iterating through the list three separate times, which isn’t optimal from the standpoint of execution time. Here are some examples of in action: For testing purposes, you can define a short function that generates a list of random numbers between and : Now you can use to test : To further understand how works, see the diagram below. This shows the recursion sequence when sorting a twelve-element list: In the first step, the first, middle, and last list values are , , and , respectively. The median is , so that becomes the pivot item. The first partition then consists of the following sublists: The items less than the pivot item The items greater than the pivot item Each sublist is subsequently partitioned recursively in the same manner until all the sublists either contain a single element or are empty. As the recursive calls return, the lists are reassembled in sorted order. Note that in the second-to-last step on the left, the pivot item appears in the list twice, so the pivot item list has two elements."
    },
    {
        "link": "https://docs.python.org/3/tutorial/controlflow.html",
        "document": ""
    },
    {
        "link": "https://docs.python.org/3/library/functions.html",
        "document": "The Python interpreter has a number of functions and types built into it that are always available. They are listed here in alphabetical order.\n\nOpen file and return a corresponding file object. If the file cannot be opened, an is raised. See Reading and Writing Files for more examples of how to use this function. file is a path-like object giving the pathname (absolute or relative to the current working directory) of the file to be opened or an integer file descriptor of the file to be wrapped. (If a file descriptor is given, it is closed when the returned I/O object is closed unless closefd is set to .) mode is an optional string that specifies the mode in which the file is opened. It defaults to which means open for reading in text mode. Other common values are for writing (truncating the file if it already exists), for exclusive creation, and for appending (which on some Unix systems, means that all writes append to the end of the file regardless of the current seek position). In text mode, if encoding is not specified the encoding used is platform-dependent: is called to get the current locale encoding. (For reading and writing raw bytes use binary mode and leave encoding unspecified.) The available modes are: open for writing, truncating the file first open for exclusive creation, failing if the file already exists open for writing, appending to the end of file if it exists The default mode is (open for reading text, a synonym of ). Modes and open and truncate the file. Modes and open the file with no truncation. As mentioned in the Overview, Python distinguishes between binary and text I/O. Files opened in binary mode (including in the mode argument) return contents as objects without any decoding. In text mode (the default, or when is included in the mode argument), the contents of the file are returned as , the bytes having been first decoded using a platform-dependent encoding or using the specified encoding if given. Python doesn’t depend on the underlying operating system’s notion of text files; all the processing is done by Python itself, and is therefore platform-independent. buffering is an optional integer used to set the buffering policy. Pass 0 to switch buffering off (only allowed in binary mode), 1 to select line buffering (only usable when writing in text mode), and an integer > 1 to indicate the size in bytes of a fixed-size chunk buffer. Note that specifying a buffer size this way applies for binary buffered I/O, but (i.e., files opened with ) would have another buffering. To disable buffering in , consider using the flag for . When no buffering argument is given, the default buffering policy works as follows:\n• None Binary files are buffered in fixed-size chunks; the size of the buffer is chosen using a heuristic trying to determine the underlying device’s “block size” and falling back on . On many systems, the buffer will typically be 4096 or 8192 bytes long.\n• None “Interactive” text files (files for which returns ) use line buffering. Other text files use the policy described above for binary files. encoding is the name of the encoding used to decode or encode the file. This should only be used in text mode. The default encoding is platform dependent (whatever returns), but any text encoding supported by Python can be used. See the module for the list of supported encodings. errors is an optional string that specifies how encoding and decoding errors are to be handled—this cannot be used in binary mode. A variety of standard error handlers are available (listed under Error Handlers), though any error handling name that has been registered with is also valid. The standard names include:\n• None to raise a exception if there is an encoding error. The default value of has the same effect.\n• None ignores errors. Note that ignoring encoding errors can lead to data loss.\n• None causes a replacement marker (such as ) to be inserted where there is malformed data.\n• None will represent any incorrect bytes as low surrogate code units ranging from U+DC80 to U+DCFF. These surrogate code units will then be turned back into the same bytes when the error handler is used when writing data. This is useful for processing files in an unknown encoding.\n• None is only supported when writing to a file. Characters not supported by the encoding are replaced with the appropriate XML character reference .\n• None (also only supported when writing) replaces unsupported characters with escape sequences. newline determines how to parse newline characters from the stream. It can be , , , , and . It works as follows:\n• None When reading input from the stream, if newline is , universal newlines mode is enabled. Lines in the input can end in , , or , and these are translated into before being returned to the caller. If it is , universal newlines mode is enabled, but line endings are returned to the caller untranslated. If it has any of the other legal values, input lines are only terminated by the given string, and the line ending is returned to the caller untranslated.\n• None When writing output to the stream, if newline is , any characters written are translated to the system default line separator, . If newline is or , no translation takes place. If newline is any of the other legal values, any characters written are translated to the given string. If closefd is and a file descriptor rather than a filename was given, the underlying file descriptor will be kept open when the file is closed. If a filename is given closefd must be (the default); otherwise, an error will be raised. A custom opener can be used by passing a callable as opener. The underlying file descriptor for the file object is then obtained by calling opener with (file, flags). opener must return an open file descriptor (passing as opener results in functionality similar to passing ). The following example uses the dir_fd parameter of the function to open a file relative to a given directory: 'This will be written to somedir/spamspam.txt' The type of file object returned by the function depends on the mode. When is used to open a file in a text mode ( , , , , etc.), it returns a subclass of (specifically ). When used to open a file in a binary mode with buffering, the returned class is a subclass of . The exact class varies: in read binary mode, it returns an ; in write binary and append binary modes, it returns an , and in read/write mode, it returns an . When buffering is disabled, the raw stream, a subclass of , , is returned. See also the file handling modules, such as , (where is declared), , , , and . The and arguments may have been modified or inferred from the original call.\n• None used to be raised, it is now an alias of .\n• None is now raised if the file opened in exclusive creation mode ( ) already exists.\n• None The file is now non-inheritable.\n• None If the system call is interrupted and the signal handler does not raise an exception, the function now retries the system call instead of raising an exception (see PEP 475 for the rationale).\n• None On Windows, opening a console buffer may return a subclass of other than . Changed in version 3.11: The mode has been removed.\n\nReturn a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing inherited methods that have been overridden in a class. The object_or_type determines the method resolution order to be searched. The search starts from the class right after the type. For example, if of object_or_type is and the value of type is , then searches . The attribute of the class corresponding to object_or_type lists the method resolution search order used by both and . The attribute is dynamic and can change whenever the inheritance hierarchy is updated. If the second argument is omitted, the super object returned is unbound. If the second argument is an object, must be true. If the second argument is a type, must be true (this is useful for classmethods). When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument ”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately enclosing function (typically ). (This means that zero-argument will not work as expected within nested functions, including generator expressions, which implicitly create nested functions.) There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer to parent classes without naming them explicitly, thus making the code more maintainable. This use closely parallels the use of super in other programming languages. The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This use case is unique to Python and is not found in statically compiled languages or languages that only support single inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes implement the same method. Good design dictates that such implementations have the same calling signature in every case (because the order of calls is determined at runtime, because that order adapts to changes in the class hierarchy, and because that order can include sibling classes that are unknown prior to runtime). For both use cases, a typical superclass call looks like this: # This does the same thing as: In addition to method lookups, also works for attribute lookups. One possible use case for this is calling descriptors in a parent or sibling class. Note that is implemented as part of the binding process for explicit dotted attribute lookups such as . It does so by implementing its own method for searching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, is undefined for implicit lookups using statements or operators such as . Also note that, aside from the zero argument form, is not limited to use inside methods. The two argument form specifies the arguments exactly and makes the appropriate references. The zero argument form only works inside a class definition, as the compiler fills in the necessary details to correctly retrieve the class being defined, as well as accessing the current instance for ordinary methods. For practical suggestions on how to design cooperative classes using , see guide to using super()."
    },
    {
        "link": "https://geeksforgeeks.org/how-to-parse-nested-json-in-python",
        "document": "We are given a nested JSON object and our task is to parse the nested JSON in Python using different approaches. In this article, we will see how we can parse nested JSON in Python.\n\nBelow are some of the ways by which we can parse nested JSON in Python:\n\nIn this example, we use the module to parse a nested JSON string. Subsequently, we access specific values within the JSON structure using dictionary keys, demonstrating how to retrieve information such as the name, age, city, and zipcode.\n\nIn this example, the function employs recursion to traverse the nested JSON structure and create a flattened dictionary. The parsed data is then accessed using keys to retrieve specific values such as name, age, city, and zipcode from the original nested JSON data.\n\nIn this example, the function from the Pandas library is utilized to flatten the nested JSON data into a Pandas DataFrame. The resulting DataFrame, , allows easy access to specific columns such as 'name' and 'age.' Finally, the extracted values are printed as lists, showcasing a convenient way to work with nested JSON data in a tabular format using Pandas."
    },
    {
        "link": "https://zyte.com/blog/json-parsing-with-python",
        "document": "JSON (JavaScript Object Notation) is a text-based data format used for exchanging and storing data between web applications. It simplifies the data transmission process between different programming languages and platforms.\n\nThe has become increasingly popular in recent years. It’s a simple and flexible way of representing data that can be easily understood and parsed by both humans and machines. JSON consists of key-value pairs enclosed in curly braces, separated by a colon.\n\nPython provides various and manipulating JSON data, making it a popular choice for data analysts, web developers, and data scientists.\n\nIn this guide, we’ll explore the syntax and data types of JSON, as well as the Python libraries and methods used for parsing JSON data, including more advanced options like JMESPath and ChompJS, which are very useful for web scraping data."
    },
    {
        "link": "https://stackoverflow.com/questions/70782902/best-way-to-navigate-a-nested-json-in-python",
        "document": "I have tried different for loops trying to iterate through this JSON and I cant figure out how to do it. I have a list of numbers and want to compare it to the \"key\" values under each object of \"data\" (For example, Aatrox, Ahri, Akali, and so on) and if the numbers match store the \"name\" value in another list.\n\n266 and 166 would match the \"key\" in the Aatrox and Akshan objects respectively so I would want to pull that name and store it in a list.\n\nI understant this JSON is mostly accessed by key values rather than being indexed so Im not sure how I would iterate through all the \"data\" objects in a for loop(s)."
    },
    {
        "link": "https://docs.python.org/3/library/json.html",
        "document": "JSON (JavaScript Object Notation), specified by RFC 7159 (which obsoletes RFC 4627) and by ECMA-404, is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript ).\n\nexposes an API familiar to users of the standard library and modules.\n\nUsing from the shell to validate and pretty-print:\n\nSerialize obj as a JSON formatted stream to fp (a -supporting file-like object) using this Python-to-JSON conversion table. Unlike and , JSON is not a framed protocol, so trying to serialize multiple objects with repeated calls to using the same fp will result in an invalid JSON file.\n• None obj (object) – The Python object to be serialized.\n• None fp (file-like object) – The file-like object obj will be serialized to. The module always produces objects, not objects, therefore must support input.\n• None skipkeys (bool) – If , keys that are not of a basic type ( , , , , ) will be skipped instead of raising a . Default .\n• None ensure_ascii (bool) – If (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If , these characters will be outputted as-is.\n• None check_circular (bool) – If , the circular reference check for container types is skipped and a circular reference will result in a (or worse). Default .\n• None allow_nan (bool) – If , serialization of out-of-range values ( , , ) will result in a , in strict compliance with the JSON specification. If (the default), their JavaScript equivalents ( , , ) are used.\n• None cls (a subclass) – If set, a custom JSON encoder with the method overridden, for serializing into custom datatypes. If (the default), is used.\n• None indent (int | str | None) – If a positive integer or string, JSON array elements and object members will be pretty-printed with that indent level. A positive integer indents that many spaces per level; a string (such as ) is used to indent each level. If zero, negative, or (the empty string), only newlines are inserted. If (the default), the most compact representation is used.\n• None separators (tuple | None) – A two-tuple: . If (the default), separators defaults to if indent is , and otherwise. For the most compact JSON, specify to eliminate whitespace.\n• None default (callable | None) – A function that is called for objects that can’t otherwise be serialized. It should return a JSON encodable version of the object or raise a . If (the default), is raised.\n• None sort_keys (bool) – If , dictionaries will be outputted sorted by key. Default . Changed in version 3.2: Allow strings for indent in addition to integers. Changed in version 3.4: Use as default if indent is not . Changed in version 3.6: All optional parameters are now keyword-only. Serialize obj to a JSON formatted using this conversion table. The arguments have the same meaning as in . Keys in key/value pairs of JSON are always of the type . When a dictionary is converted into JSON, all the keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON and then back into a dictionary, the dictionary may not equal the original one. That is, if x has non-string keys. Deserialize fp to a Python object using the JSON-to-Python conversion table.\n• None fp (file-like object) – A -supporting text file or binary file containing the JSON document to be deserialized.\n• None cls (a subclass) – If set, a custom JSON decoder. Additional keyword arguments to will be passed to the constructor of cls. If (the default), is used.\n• None object_hook (callable | None) – If set, a function that is called with the result of any object literal decoded (a ). The return value of this function will be used instead of the . This feature can be used to implement custom decoders, for example JSON-RPC class hinting. Default .\n• None object_pairs_hook (callable | None) – If set, a function that is called with the result of any object literal decoded with an ordered list of pairs. The return value of this function will be used instead of the . This feature can be used to implement custom decoders. If object_hook is also set, object_pairs_hook takes priority. Default .\n• None parse_float (callable | None) – If set, a function that is called with the string of every JSON float to be decoded. If (the default), it is equivalent to . This can be used to parse JSON floats into custom datatypes, for example .\n• None parse_int (callable | None) – If set, a function that is called with the string of every JSON int to be decoded. If (the default), it is equivalent to . This can be used to parse JSON integers into custom datatypes, for example .\n• None parse_constant (callable | None) – If set, a function that is called with one of the following strings: , , or . This can be used to raise an exception if invalid JSON numbers are encountered. Default .\n• None JSONDecodeError – When the data being deserialized is not a valid JSON document.\n• None UnicodeDecodeError – When the data being deserialized does not contain UTF-8, UTF-16 or UTF-32 encoded data.\n• None All optional parameters are now keyword-only.\n• None fp can now be a binary file. The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.11: The default parse_int of now limits the maximum length of the integer string via the interpreter’s integer string conversion length limitation to help avoid denial of service attacks. Identical to , but instead of a file-like object, deserialize s (a , or instance containing a JSON document) to a Python object using this conversion table. Changed in version 3.6: s can now be of type or . The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.9: The keyword argument encoding has been removed.\n\nPerforms the following translations in decoding by default: It also understands , , and as their corresponding values, which is outside the JSON spec. object_hook is an optional function that will be called with the result of every JSON object decoded and its return value will be used in place of the given . This can be used to provide custom deserializations (e.g. to support JSON-RPC class hinting). object_pairs_hook is an optional function that will be called with the result of every JSON object decoded with an ordered list of pairs. The return value of object_pairs_hook will be used instead of the . This feature can be used to implement custom decoders. If object_hook is also defined, the object_pairs_hook takes priority. parse_float is an optional function that will be called with the string of every JSON float to be decoded. By default, this is equivalent to . This can be used to use another datatype or parser for JSON floats (e.g. ). parse_int is an optional function that will be called with the string of every JSON int to be decoded. By default, this is equivalent to . This can be used to use another datatype or parser for JSON integers (e.g. ). parse_constant is an optional function that will be called with one of the following strings: , , . This can be used to raise an exception if invalid JSON numbers are encountered. If strict is false ( is the default), then control characters will be allowed inside strings. Control characters in this context are those with character codes in the 0–31 range, including (tab), , and . If the data being deserialized is not a valid JSON document, a will be raised. Changed in version 3.6: All parameters are now keyword-only. Return the Python representation of s (a instance containing a JSON document). will be raised if the given JSON document is not valid. Decode a JSON document from s (a beginning with a JSON document) and return a 2-tuple of the Python representation and the index in s where the document ended. This can be used to decode a JSON document from a string that may have extraneous data at the end. Supports the following objects and types by default: Changed in version 3.4: Added support for int- and float-derived Enum classes. To extend this to recognize other objects, subclass and implement a method with another method that returns a serializable object for if possible, otherwise it should call the superclass implementation (to raise ). If skipkeys is false (the default), a will be raised when trying to encode keys that are not , , or . If skipkeys is true, such items are simply skipped. If ensure_ascii is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is. If check_circular is true (the default), then lists, dicts, and custom encoded objects will be checked for circular references during encoding to prevent an infinite recursion (which would cause a ). Otherwise, no such check takes place. If allow_nan is true (the default), then , , and will be encoded as such. This behavior is not JSON specification compliant, but is consistent with most JavaScript based encoders and decoders. Otherwise, it will be a to encode such floats. If sort_keys is true (default: ), then the output of dictionaries will be sorted by key; this is useful for regression tests to ensure that JSON serializations can be compared on a day-to-day basis. If indent is a non-negative integer or string, then JSON array elements and object members will be pretty-printed with that indent level. An indent level of 0, negative, or will only insert newlines. (the default) selects the most compact representation. Using a positive integer indent indents that many spaces per level. If indent is a string (such as ), that string is used to indent each level. Changed in version 3.2: Allow strings for indent in addition to integers. If specified, separators should be an tuple. The default is if indent is and otherwise. To get the most compact JSON representation, you should specify to eliminate whitespace. Changed in version 3.4: Use as default if indent is not . If specified, default should be a function that gets called for objects that can’t otherwise be serialized. It should return a JSON encodable version of the object or raise a . If not specified, is raised. Changed in version 3.6: All parameters are now keyword-only. Implement this method in a subclass such that it returns a serializable object for o, or calls the base implementation (to raise a ). For example, to support arbitrary iterators, you could implement like this: # Let the base class default method raise the TypeError Return a JSON string representation of a Python data structure, o. For example: Encode the given object, o, and yield each string representation as available. For example:\n\nThe JSON format is specified by RFC 7159 and by ECMA-404. This section details this module’s level of compliance with the RFC. For simplicity, and subclasses, and parameters other than those explicitly mentioned, are not considered. This module does not comply with the RFC in a strict fashion, implementing some extensions that are valid JavaScript but not valid JSON. In particular:\n• None Infinite and NaN number values are accepted and output;\n• None Repeated names within an object are accepted, and only the value of the last name-value pair is used. Since the RFC permits RFC-compliant parsers to accept input texts that are not RFC-compliant, this module’s deserializer is technically RFC-compliant under default settings. The RFC requires that JSON be represented using either UTF-8, UTF-16, or UTF-32, with UTF-8 being the recommended default for maximum interoperability. As permitted, though not required, by the RFC, this module’s serializer sets ensure_ascii=True by default, thus escaping the output so that the resulting strings only contain ASCII characters. Other than the ensure_ascii parameter, this module is defined strictly in terms of conversion between Python objects and , and thus does not otherwise directly address the issue of character encodings. The RFC prohibits adding a byte order mark (BOM) to the start of a JSON text, and this module’s serializer does not add a BOM to its output. The RFC permits, but does not require, JSON deserializers to ignore an initial BOM in their input. This module’s deserializer raises a when an initial BOM is present. The RFC does not explicitly forbid JSON strings which contain byte sequences that don’t correspond to valid Unicode characters (e.g. unpaired UTF-16 surrogates), but it does note that they may cause interoperability problems. By default, this module accepts and outputs (when present in the original ) code points for such sequences. The RFC does not permit the representation of infinite or NaN number values. Despite that, by default, this module accepts and outputs , , and as if they were valid JSON number literal values: # Neither of these calls raises an exception, but the results are not valid JSON In the serializer, the allow_nan parameter can be used to alter this behavior. In the deserializer, the parse_constant parameter can be used to alter this behavior. The RFC specifies that the names within a JSON object should be unique, but does not mandate how repeated names in JSON objects should be handled. By default, this module does not raise an exception; instead, it ignores all but the last name-value pair for a given name: The object_pairs_hook parameter can be used to alter this behavior. The old version of JSON specified by the obsolete RFC 4627 required that the top-level value of a JSON text must be either a JSON object or array (Python or ), and could not be a JSON null, boolean, number, or string value. RFC 7159 removed that restriction, and this module does not and has never implemented that restriction in either its serializer or its deserializer. Regardless, for maximum interoperability, you may wish to voluntarily adhere to the restriction yourself. Some JSON deserializer implementations may set limits on:\n• None the maximum level of nesting of JSON objects and arrays\n• None the range and precision of JSON numbers\n• None the content and maximum length of JSON strings This module does not impose any such limits beyond those of the relevant Python datatypes themselves or the Python interpreter itself. When serializing to JSON, beware any such limitations in applications that may consume your JSON. In particular, it is common for JSON numbers to be deserialized into IEEE 754 double precision numbers and thus subject to that representation’s range and precision limitations. This is especially relevant when serializing Python values of extremely large magnitude, or when serializing instances of “exotic” numerical types such as .\n\nThe module provides a simple command line interface to validate and pretty-print JSON objects. If the optional and arguments are not specified, and will be used respectively: Changed in version 3.5: The output is now in the same order as the input. Use the option to sort the output of dictionaries alphabetically by key. The JSON file to be validated or pretty-printed: python -m json.tool mp_films.json \"title\": \"And Now for Something Completely Different\", If infile is not specified, read from . Write the output of the infile to the given outfile. Otherwise, write it to . Sort the output of dictionaries alphabetically by key. Disable escaping of non-ascii characters, see for more information."
    },
    {
        "link": "https://pybit.es/articles/case-study-how-to-parse-nested-json",
        "document": "I was asked to help parse a JSON file that is delivered by the iTunes Store Customer Reviews API JSON endpoint. It is not so important how this API works or if there are better APIs for this. Instead, let’s assume that we found our favorite API to work with and that our request makes perfect sense and now we have to deal with the API’s response, JSON in this case. This article will guide you through the necessary steps to parse this JSON response into a pandas . I will focus heavily on the concepts and code development and less on explaining each line of code. Ideally, you should be already familiar with at least a little Python and its standard data types, most importantly dictionaries.\n\nFirst, I want to understand what I am dealing with and because the display of the JSON response is not so nice for the original URL, I use a JSON pretify tool like http://jsonprettify.com/.\n\nThis will give me the following reformatted JSON response\n\nI’ve only shown the first object of the list. So the JSON response is structured in the following way:\n• this root element has only two children, “author” and “entry”, from which I am only interested in “entry”\n• “entry” is a list of objects and each object has a set of properties like “author”, “link” and ,”im:rating”\n• Each property is again a JSON object\n• The most simple property is an object with just a “label” key and a value.\n• More complex properties like “author” are again nested\n\nBefore I dive deeper in how to parse this nested structure, let me try pandas method first.\n\nThe output of this is the following table:\n\nThis is clearly not what I had in mind. The first problem I should eliminate is that pandas cannot possibly know that I am only interested in the “entry” list, so I will first fetch the JSON response, parse it into a dictionary and access the “entry” value:\n\nThus, looks like this:\n\nNow, I can try pandas again. Note, that I no longer have a JSON string but a normal Python list, containing dictionaries. Therefore, I can directly use pandas class:\n\nThe first rows of this data frame looks as follows ( ):\n\nMuch better but still not there yet. We have the correct columns and each row is indeed one entry from the entries list. However, all values are strings and, worse, a string representation of the inner dictionaries (and sometimes multiple nested dictionaries). I cannot work with data like this so we have to manually parse the list of entries, which I will explain next.\n\nLooking again at the structure of the entries (see Listing “JSON response”), the strategy is simple: go through each entry, and as long as the value is a dictionary, concatenate the keys to a single column name and the final value is the value for this column and row.\n\nNow a very crude first attempt could be to hardcode all attribute names like this:\n\nThis implementation might be naive and does not generalize at all to any other use case, but it is still a highly effective method to begin with because it forces you to explicitly state the JSON structure down to the last element. That this method works can be tested again with the pandas class that can create a data frame from a dictionary that has a list of values for each column:\n\nThe output will be a data frame like this:\n\nHowever, aiming at a more general solution that can deal automatically with all attributes/properties without knowing the structure (but relying on the fact that there are only two levels of nested dictionaries, at least for now), I derived at the following solution:\n\nThe code is not the most beautiful one but I will come to this later. For now let’s focus on the intend: For each entry I look at the first key-value pair, knowing that value is always a dictionary (object in JSON). Now I have to deal with two different cases. In the first case, the value dictionary is flat and does not contain another dictionary, only key-value pairs. This is the simple case in which I combine the outer key with the inner key to a column name and take the value as column value for each pair. In the second case, the dictionary contains a key-value pair where the value is again a dictionary. I rely on the fact that there are at most two levels of nested dictionaries so I iterate over the key-value pairs of the inner dictionary and again combine the outer key and the most inner key to a column name and take the inner value as column value.\n\nThis procedure gives me a dictionary where the keys are the column names of the data frame and each key has a list as value with the row values for this column. This is the perfect format for the pandas DataFrame class to create a data frame from:\n\nAnd the first rows look like this:\n\nAnd there it is! I have a few more columns than originally expected because I decided to keep every bit of information by flattening the nested structure of dicts into a single dict where each combination of attributes is preserved by concatenating the different keys into a single column name, separated by an underscore “_”. This data frame has 50 rows and 16 columns, which is in accordance with the original JSON response. If you dislike the additional “label” part in the column names, it is easy to get rid of it:\n\nRight now, all columns have the data type , which is not ideal memory-wise, but does not have a huge impact as long as the data set is as small as this. However, I can change the dtype with a simple one-liner:\n\nTo conclude this article, I want to improve the reusability of my code. The first obvious thing to do would be to extract the parsing logic into one or several functions with proper type annotation and docstring. However, this is not the focus of this article so I will leave this part to the more practically inclined reader.\n\nInstead, I want to stress that my solution (Listing “advanced implementation”) breaks for deeper nested JSON structures. That is because I had to explicitly iterate over the inner dictionaries with a loop for each dictionary. A better solution to such a problem is a recursive approach where we apply a divide-and-conquer paradigm to handle the complexity. In other words what I really intend to do is to go into each dictionary as long as there are inner dictionaries and once I reach the end, add all values as separate columns:\n\nIsn’t that a beauty! Like often when a recursive approach is more natural to the task at hand the recursive implementation is more readable and often shorter than the iterative approach. You can verify yourself that the data frame obtained by this approach is identical to the data frame obtained from the previous iterative solution.\n\nThere are of course other approaches. A common strategy is to flatten the original JSON by doing something very similar like we did here: pull out all nested objects by concatenating all keys and keeping the final inner value. If you change the original JSON like this you obtain a JSON that can be directly fed into pandas. There is even a module you can use right out of the box: flatten_json. But where would be the fun in this…\n\nI hope you enjoyed following me on this little journey and as always I am open for your comments, discussions and questions.\n\nKeep Calm and Code in Python!"
    }
]