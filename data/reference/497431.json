[
    {
        "link": "https://redis.io/docs/latest/develop/clients/redis-py",
        "document": "redis-py is the Python client for Redis. The sections below explain how to install and connect your application to a Redis database.\n\nrequires a running Redis or Redis Stack server. See Getting started for Redis installation instructions.\n\nYou can also access Redis with an object-mapping client interface. See RedisOM for Python for more information.\n\nFor faster performance, install Redis with support. This provides a compiled response parser, and for most cases requires zero code changes. By default, if >= 1.0 is available, attempts to use it for response parsing.\n\nConnect to localhost on port 6379, set a value in Redis, and retrieve it. All responses are returned as bytes in Python. To receive decoded strings, set . For more connection options, see these examples.\n\nThe website has a command reference and some tutorials for various tasks. There are also some examples in the GitHub repository for .\n\nSee also the other pages in this section for more information and examples:"
    },
    {
        "link": "https://redis-py-doc.readthedocs.io",
        "document": "This abstract class provides a Python interface to all Redis commands and an implementation of the Redis protocol.\n\nConnection and Pipeline derive from this, implementing how the commands are sent and received to the Redis server"
    },
    {
        "link": "https://redis-py.readthedocs.io",
        "document": "redis-py can be installed using pip via pip install redis .\n\nredis-py requires a running Redis server, and Python 3.7+. See the Redis quickstart for Redis installation instructions.\n\nThere are two quick ways to connect to Redis.\n\nAssuming you run Redis on localhost:6379 (the default)\n\nAnother example with foo.bar.com, port 12345\n\nAfter that, you probably want to run redis commands."
    },
    {
        "link": "https://stackoverflow.com/questions/32276493/how-to-store-and-retrieve-a-dictionary-with-redis",
        "document": "How would I store my_dict and retrieve it with redis. For example, the following code does not work.\n\nAs the basic answer has already give by other people, I would like to add some to it. Following are the commands in to perform basic operations with type values.\n• HSET => set/updates value for the single key\n• HGETALL => Returns all the (key, value) pairs in the mapping. Following are their respective methods in library :- All of the above setter methods creates the mapping, if it doesn't exists. All of the above getter methods doesn't raise error/exceptions, if mapping/key in mapping doesn't exists. Example: ======= In [98]: import redis In [99]: conn = redis.Redis('localhost') In [100]: user = {\"Name\":\"Pradeep\", \"Company\":\"SCTL\", \"Address\":\"Mumbai\", \"Location\":\"RCP\"} In [101]: con.hmset(\"pythonDict\", {\"Location\": \"Ahmedabad\"}) Out[101]: True In [102]: con.hgetall(\"pythonDict\") Out[102]: {b'Address': b'Mumbai', b'Company': b'SCTL', b'Last Name': b'Rajpurohit', b'Location': b'Ahmedabad', b'Name': b'Mangu Singh'} In [103]: con.hmset(\"pythonDict\", {\"Location\": \"Ahmedabad\", \"Company\": [\"A/C Pri ...: sm\", \"ECW\", \"Musikaar\"]}) Out[103]: True In [104]: con.hgetall(\"pythonDict\") Out[104]: {b'Address': b'Mumbai', b'Company': b\"['A/C Prism', 'ECW', 'Musikaar']\", b'Last Name': b'Rajpurohit', b'Location': b'Ahmedabad', b'Name': b'Mangu Singh'} In [105]: con.hget(\"pythonDict\", \"Name\") Out[105]: b'Mangu Singh' In [106]: con.hmget(\"pythonDict\", \"Name\", \"Location\") Out[106]: [b'Mangu Singh', b'Ahmedabad']\n\nIf you want to store a python dict in redis, it is better to store it as json string. While retrieving de-serialize it using json.loads What about types (eg.bytes) that are not serialized by json functions ? You can write encoder/decoder functions for types that cannot be serialized by json functions. eg. writing base64/ascii encoder/decoder function for byte array.\n\nThe redis SET command stores a string, not arbitrary data. You could try using the redis HSET command to store the dict as a redis hash with something like but the redis datatypes and python datatypes don't quite line up. Python dicts can be arbitrarily nested, but a redis hash is going to require that your value is a string. Another approach you can take is to convert your python data to string and store that in redis, something like and then when you get the string out you will need to parse it to recreate the python object.\n\nIf you don't know exactly how to organize data in Redis, I did some performance tests, including the results parsing. The dictonary I used (d) had 437.084 keys (md5 format), and the values of this form: conn.hmset('my_dict', d) # 437.084 keys added in 8.98s conn.info()['used_memory_human'] # 166.94 Mb for key in d: json.loads(conn.hget('my_dict', key).decode('utf-8').replace(\"'\", '\"')) # 41.1 s import ast for key in d: ast.literal_eval(conn.hget('my_dict', key).decode('utf-8')) # 1min 3s conn.delete('my_dict') # 526 ms for key in d: conn.hmset(key, d[key]) # 437.084 keys added in 1min 20s conn.info()['used_memory_human'] # 326.22 Mb for key in d: json.loads(conn.hgetall(key)[b'info'].decode('utf-8').replace(\"'\", '\"')) # 1min 11s for key in d: conn.delete(key) # 37.3s As you can see, in the second test, only 'info' values have to be parsed, because the hgetall(key) already returns a dict, but not a nested one. And of course, the best example of using Redis as python's dicts, is the First Test\n\nTry rejson-py which is relatively new since 2017. Look at this introduction. from rejson import Client, Path rj = Client(host='localhost', port=6379) # Set the key `obj` to some object obj = { 'answer': 42, 'arr': [None, True, 3.14], 'truth': { 'coord': 'out there' } } rj.jsonset('obj', Path.rootPath(), obj) # Get something print 'Is there anybody... {}?'.format( rj.jsonget('obj', Path('.truth.coord')) ) # Delete something (or perhaps nothing), append something and pop it rj.jsondel('obj', Path('.arr[0]')) rj.jsonarrappend('obj', Path('.arr'), 'something') print '{} popped!'.format(rj.jsonarrpop('obj', Path('.arr'))) # Update something else rj.jsonset('obj', Path('.answer'), 2.17)\n\nLots of good answers but this worked for me.\n• nested hash instead of mapping the dict as key to field and value to value like other answers above. (see example 1)\n• get all field/values and go from there as normally you would in a project where you want to dump a dict to a redis hash where the dict is a nested hash. (see example 2) note: these commands were done in the python repl\n• if you want Also refer to other answers, particularly Saji Xavier's since its simple and works. If you want a nested hash like # to set import json r = redis.Redis(host=\"localhost\", port=6379, db=0, decode_responses=True) pdict = {'field1': 'Hello', 'field2': 'World'} pdict_string = json.dumps(pdict) r.hset(\"queues_data\", \"queue1\", pdict_string) # to get a single field value r.hget(\"queues_data\", \"queue1\") # '{\"field1\": \"Hello\", \"field2\": \"World\"}' # to get all fields data = r.hgetall(\"queues_data\") # {'queue1': '{\"field1\": \"Hello\", \"field2\": \"World\"}' queue1 = data['queue1'] queue1 # '{\"field1\": \"Hello\", \"field2\": \"World\"}' result = json.loads(queue1) result # {'field1': 'Hello', 'field2': 'World'} result['field1'] # 'Hello' Then if you just need the keys/values Then if you want get the dict back for all values in one line use lvalues = list(data.values()) # ['{\"field1\": \"Hello\", \"field2\": \"World\"}', '{\"field1\": \"Hello\", \"field2\": \"World\"}'] [json.loads(x) for x in lvalues] # [{'field1': 'Hello', 'field2': 'World'}, {'field1': 'Hello', 'field2': 'World'}]"
    },
    {
        "link": "https://redis.io/docs/latest/integrate/redis-py",
        "document": "Learn how to build with Redis and Python\n\nConnect your Python application to a Redis database using the redis-py client library.\n\nRefer to the complete Python guide to install, connect, and use redis-py."
    },
    {
        "link": "https://stackoverflow.com/questions/15219858/how-to-store-a-complex-object-in-redis-using-redis-py",
        "document": "The hmset function can set the value of each field, but I found that if the value itself is a complex structured object, the value return from hget is a serialized string, not the original object\n\nthe type of i is a string, not a python object, is there any way to solve this problem besides manually parse each fields?"
    },
    {
        "link": "https://stackoverflow.com/questions/32276493/how-to-store-and-retrieve-a-dictionary-with-redis",
        "document": "How would I store my_dict and retrieve it with redis. For example, the following code does not work.\n\nAs the basic answer has already give by other people, I would like to add some to it. Following are the commands in to perform basic operations with type values.\n• HSET => set/updates value for the single key\n• HGETALL => Returns all the (key, value) pairs in the mapping. Following are their respective methods in library :- All of the above setter methods creates the mapping, if it doesn't exists. All of the above getter methods doesn't raise error/exceptions, if mapping/key in mapping doesn't exists. Example: ======= In [98]: import redis In [99]: conn = redis.Redis('localhost') In [100]: user = {\"Name\":\"Pradeep\", \"Company\":\"SCTL\", \"Address\":\"Mumbai\", \"Location\":\"RCP\"} In [101]: con.hmset(\"pythonDict\", {\"Location\": \"Ahmedabad\"}) Out[101]: True In [102]: con.hgetall(\"pythonDict\") Out[102]: {b'Address': b'Mumbai', b'Company': b'SCTL', b'Last Name': b'Rajpurohit', b'Location': b'Ahmedabad', b'Name': b'Mangu Singh'} In [103]: con.hmset(\"pythonDict\", {\"Location\": \"Ahmedabad\", \"Company\": [\"A/C Pri ...: sm\", \"ECW\", \"Musikaar\"]}) Out[103]: True In [104]: con.hgetall(\"pythonDict\") Out[104]: {b'Address': b'Mumbai', b'Company': b\"['A/C Prism', 'ECW', 'Musikaar']\", b'Last Name': b'Rajpurohit', b'Location': b'Ahmedabad', b'Name': b'Mangu Singh'} In [105]: con.hget(\"pythonDict\", \"Name\") Out[105]: b'Mangu Singh' In [106]: con.hmget(\"pythonDict\", \"Name\", \"Location\") Out[106]: [b'Mangu Singh', b'Ahmedabad']\n\nIf you want to store a python dict in redis, it is better to store it as json string. While retrieving de-serialize it using json.loads What about types (eg.bytes) that are not serialized by json functions ? You can write encoder/decoder functions for types that cannot be serialized by json functions. eg. writing base64/ascii encoder/decoder function for byte array.\n\nThe redis SET command stores a string, not arbitrary data. You could try using the redis HSET command to store the dict as a redis hash with something like but the redis datatypes and python datatypes don't quite line up. Python dicts can be arbitrarily nested, but a redis hash is going to require that your value is a string. Another approach you can take is to convert your python data to string and store that in redis, something like and then when you get the string out you will need to parse it to recreate the python object.\n\nIf you don't know exactly how to organize data in Redis, I did some performance tests, including the results parsing. The dictonary I used (d) had 437.084 keys (md5 format), and the values of this form: conn.hmset('my_dict', d) # 437.084 keys added in 8.98s conn.info()['used_memory_human'] # 166.94 Mb for key in d: json.loads(conn.hget('my_dict', key).decode('utf-8').replace(\"'\", '\"')) # 41.1 s import ast for key in d: ast.literal_eval(conn.hget('my_dict', key).decode('utf-8')) # 1min 3s conn.delete('my_dict') # 526 ms for key in d: conn.hmset(key, d[key]) # 437.084 keys added in 1min 20s conn.info()['used_memory_human'] # 326.22 Mb for key in d: json.loads(conn.hgetall(key)[b'info'].decode('utf-8').replace(\"'\", '\"')) # 1min 11s for key in d: conn.delete(key) # 37.3s As you can see, in the second test, only 'info' values have to be parsed, because the hgetall(key) already returns a dict, but not a nested one. And of course, the best example of using Redis as python's dicts, is the First Test\n\nTry rejson-py which is relatively new since 2017. Look at this introduction. from rejson import Client, Path rj = Client(host='localhost', port=6379) # Set the key `obj` to some object obj = { 'answer': 42, 'arr': [None, True, 3.14], 'truth': { 'coord': 'out there' } } rj.jsonset('obj', Path.rootPath(), obj) # Get something print 'Is there anybody... {}?'.format( rj.jsonget('obj', Path('.truth.coord')) ) # Delete something (or perhaps nothing), append something and pop it rj.jsondel('obj', Path('.arr[0]')) rj.jsonarrappend('obj', Path('.arr'), 'something') print '{} popped!'.format(rj.jsonarrpop('obj', Path('.arr'))) # Update something else rj.jsonset('obj', Path('.answer'), 2.17)\n\nLots of good answers but this worked for me.\n• nested hash instead of mapping the dict as key to field and value to value like other answers above. (see example 1)\n• get all field/values and go from there as normally you would in a project where you want to dump a dict to a redis hash where the dict is a nested hash. (see example 2) note: these commands were done in the python repl\n• if you want Also refer to other answers, particularly Saji Xavier's since its simple and works. If you want a nested hash like # to set import json r = redis.Redis(host=\"localhost\", port=6379, db=0, decode_responses=True) pdict = {'field1': 'Hello', 'field2': 'World'} pdict_string = json.dumps(pdict) r.hset(\"queues_data\", \"queue1\", pdict_string) # to get a single field value r.hget(\"queues_data\", \"queue1\") # '{\"field1\": \"Hello\", \"field2\": \"World\"}' # to get all fields data = r.hgetall(\"queues_data\") # {'queue1': '{\"field1\": \"Hello\", \"field2\": \"World\"}' queue1 = data['queue1'] queue1 # '{\"field1\": \"Hello\", \"field2\": \"World\"}' result = json.loads(queue1) result # {'field1': 'Hello', 'field2': 'World'} result['field1'] # 'Hello' Then if you just need the keys/values Then if you want get the dict back for all values in one line use lvalues = list(data.values()) # ['{\"field1\": \"Hello\", \"field2\": \"World\"}', '{\"field1\": \"Hello\", \"field2\": \"World\"}'] [json.loads(x) for x in lvalues] # [{'field1': 'Hello', 'field2': 'World'}, {'field1': 'Hello', 'field2': 'World'}]"
    },
    {
        "link": "https://medium.com/@vickypalaniappan12/store-nested-data-structures-and-python-objects-in-redis-cache-814f03436d89",
        "document": "Storing nested data structures and Python objects in Redis can be a bit tricky, but it’s definitely doable with serialization. Here’s a streamlined approach to demonstrate how you can achieve this using both JSON and Pickle for serialization.\n\nHowever, we might face a scenario where we need to store nested data structures or Python objects. Let's try to store those,\n\nIf you execute the above set of code, you’ll end up with this output in your terminal.\n\nSo, how can we store these types of data in the Redis cache? We can serialize the dictionary into a string with\n\nAnd we can use to get the dictionary after fetching the value from the list through indexing.\n\nBut what about Python objects, we can do the same… But it’ll get more complex and the implementations will be hard to maintain.\n\nSo, we need something that can save the state of objects while serializing and deserializing. Luckily we can achieve the same with , Pickle is a module in Python used for serializing and deserializing objects. Serialization (or pickling) is the process of converting a Python object into a byte stream, and deserialization (or unpickling) is the process of converting the byte stream back into a Python object.\n\nLet's try to store the nested data structures and Python objects in Redis cache with the help of .\n\nIf you execute this, you’ll get the following output in the terminal.\n\nTo make the process of serializing and deserializing more scalable, you can create a class to handle these operations:\n\n\n\nclass RedisClient:\n\n \"\"\"A client for interacting with Redis cache.\"\"\"\n\n\n\n def __init__(self, host, port):\n\n \"\"\"\n\n Initialize the Redis client.\n\n\n\n Args:\n\n host (str): The hostname of the Redis server.\n\n port (int): The port number of the Redis server.\n\n \"\"\"\n\n self.host = host\n\n self.port = port\n\n self.redis = redis.Redis(host=self.host, port=self.port)\n\n\n\n async def close(self):\n\n \"\"\"Close the Redis connection.\"\"\"\n\n await self.redis.aclose()\n\n\n\n async def set(self, key, value):\n\n \"\"\"\n\n Set a key-value pair in Redis.\n\n\n\n Args:\n\n key (str): The key to set.\n\n value (Any): The value to set. If it's an integer, it's stored as-is.\n\n Otherwise, it's pickled before storage.\n\n \"\"\"\n\n if isinstance(value, int):\n\n await self.redis.set(key, value)\n\n else:\n\n await self.redis.set(key, pickle.dumps(value))\n\n\n\n async def get(self, key):\n\n \"\"\"\n\n Get a value from Redis by key.\n\n\n\n Args:\n\n key (str): The key to retrieve.\n\n\n\n Returns:\n\n Any: The unpickled value if found, None otherwise.\n\n \"\"\"\n\n value = await self.redis.get(key)\n\n if value:\n\n return pickle.loads(value)\n\n return None\n\n\n\n async def clear_all(self):\n\n \"\"\"Clear all keys and values from the Redis database.\"\"\"\n\n await self.redis.flushall()\n\nNow, let’s use the class to store and retrieve various data types:\n\nAs you can see, we are able to encapsulate Redis operations with , providing a clean and simple interface for setting, getting, and clearing values. This abstraction hides the complexity of direct Redis interactions, making the code easier to understand and maintain. Also, the client can handle different data types, such as strings, lists, dictionaries, python objects, and even complex nested structures."
    },
    {
        "link": "https://realpython.com/python-redis",
        "document": "In this tutorial, you’ll learn how to use Python with Redis (pronounced RED-iss, or maybe REE-diss or Red-DEES, depending on who you ask), which is a lightning fast in-memory key-value store that can be used for anything from A to Z. Here’s what Seven Databases in Seven Weeks, a popular book on databases, has to say about Redis:\n\nIntrigued? This tutorial is built for the Python programmer who may have zero to little Redis experience. We’ll tackle two tools at once and introduce both Redis itself as well as one of its Python client libraries, .\n\n(which you import as just ) is one of many Python clients for Redis, but it has the distinction of being billed as “currently the way to go for Python” by the Redis developers themselves. It lets you call Redis commands from Python, and get back familiar Python objects in return.\n• Installing Redis from source and understanding the purpose of the resulting binaries\n• Learning a bite-size slice of Redis itself, including its syntax, protocol, and design\n• Mastering while also seeing glimpses of how it implements Redis’ protocol\n• Setting up and communicating with an Amazon ElastiCache Redis server instance\n\nAs my great-great-grandfather said, nothing builds grit like installing from source. This section will walk you through downloading, making, and installing Redis. I promise that this won’t hurt one bit! Note: This section is oriented towards installation on Mac OS X or Linux. If you’re using Windows, there is a Microsoft fork of Redis that can be installed as a Windows Service. Suffice it to say that Redis as a program lives most comfortably on a Linux box and that setup and use on Windows may be finicky. First, download the Redis source code as a tarball: Next, switch over to and extract the archive’s source code to : Optionally, you can now remove the archive itself: This will leave you with a source code repository at . Redis is written in C, so you’ll need to compile, link, and install with the utility: Using does two actions:\n• The first command compiles and links the source code.\n• The part takes the binaries and copies them to so that you can run them from anywhere (assuming that is in ). Here are all the steps so far: At this point, take a moment to confirm that Redis is in your and check its version: If your shell can’t find , check to make sure that is on your environment variable, and add it if not. In addition to , actually leads to a handful of different executable files (and one symlink) being placed at : # A snapshot of executables that come bundled with Redis ls -hFG /usr/local/bin/redis-* sort While all of these have some intended use, the two you’ll probably care about most are and , which we’ll outline shortly. But before we get to that, setting up some baseline configuration is in order.\n\nTen or So Minutes to Redis This section will provide you with just enough knowledge of Redis to be dangerous, outlining its design and basic usage. Redis has a client-server architecture and uses a request-response model. This means that you (the client) connect to a Redis server through TCP connection, on port 6379 by default. You request some action (like some form of reading, writing, getting, setting, or updating), and the server serves you back a response. There can be many clients talking to the same server, which is really what Redis or any client-server application is all about. Each client does a (typically blocking) read on a socket waiting for the server response. The in stands for command line interface, and the in is for, well, running a server. In the same way that you would run at the command line, you can run to jump into an interactive REPL (Read Eval Print Loop) where you can run client commands directly from the shell. First, however, you’ll need to launch so that you have a running Redis server to talk to. A common way to do this in development is to start a server at localhost (IPv4 address ), which is the default unless you tell Redis otherwise. You can also pass the name of your configuration file, which is akin to specifying all of its key-value pairs as command-line arguments: We set the configuration option to , so the server runs in the background. (Otherwise, use as an option to .) Now you’re ready to launch the Redis REPL. Enter on your command line. You’ll see the server’s host:port pair followed by a prompt: Here’s one of the simplest Redis commands, , which just tests connectivity to the server and returns if things are okay: Redis commands are case-insensitive, although their Python counterparts are most definitely not. Note: As another sanity check, you can search for the process ID of the Redis server with : To kill the server, use from the command line. On Mac OS X, you can also use . Next, we’ll use some of the common Redis commands and compare them to what they would look like in pure Python. “You mean, like a Python dictionary?” you may ask. Yes. Broadly speaking, there are many parallels you can draw between a Python dictionary (or generic hash table) and what Redis is and does:\n• A Redis database holds key:value pairs and supports commands such as , , and , as well as several hundred additional commands.\n• Redis values may be a number of different data types. We’ll cover some of the more essential value data types in this tutorial: , , , and . Some advanced types include geospatial items and the new stream type.\n• Many Redis commands operate in constant O(1) time, just like retrieving a value from a Python or any hash table. Redis creator Salvatore Sanfilippo would probably not love the comparison of a Redis database to a plain-vanilla Python . He calls the project a “data structure server” (rather than a key-value store, such as memcached) because, to its credit, Redis supports storing additional types of key:value data types besides string:string. But for our purposes here, it’s a useful comparison if you’re familiar with Python’s dictionary object. Let’s jump in and learn by example. Our first toy database (with ID 0) will be a mapping of country:capital city, where we use to set key-value pairs: The corresponding sequence of statements in pure Python would look like this: We use rather than because Redis will return rather than an error when a key is not found, which is analogous to Python’s . Redis also allows you to set and get multiple key-value pairs in one command, and , respectively: The closest thing in Python is with : We use rather than to mimic Redis’ behavior of returning a null-like value when no key is found. As a third example, the command does what it sounds like, which is to check if a key exists: Python has the keyword to test the same thing, which routes to : These few examples are meant to show, using native Python, what’s happening at a high level with a few common Redis commands. There’s no client-server component here to the Python examples, and has not yet entered the picture. This is only meant to show Redis functionality by example. Here’s a summary of the few Redis commands you’ve seen and their functional Python equivalents: The Python Redis client library, , that you’ll dive into shortly in this article, does things differently. It encapsulates an actual TCP connection to a Redis server and sends raw commands, as bytes serialized using the REdis Serialization Protocol (RESP), to the server. It then takes the raw reply and parses it back into a Python object such as , , or even . Note: So far, you’ve been talking to the Redis server through the interactive REPL. You can also issue commands directly, in the same way that you would pass the name of a script to the executable, such as . So far, you’ve seen a few of Redis’ fundamental data types, which is a mapping of string:string. While this key-value pair is common in most key-value stores, Redis offers a number of other possible value types, which you’ll see next. More Data Types in Python vs Redis Before you fire up the Python client, it also helps to have a basic grasp on a few more Redis data types. To be clear, all Redis keys are strings. It’s the value that can take on data types (or structures) in addition to the string values used in the examples so far. A hash is a mapping of string:string, called field-value pairs, that sits under one top-level key: This sets three field-value pairs for one key, . If you’re used to Python’s terminology and objects, this can be confusing. A Redis hash is roughly analogous to a Python that is nested one level deep: Redis’ fields are akin to the Python keys of each nested key-value pair in the inner dictionary above. Redis reserves the term key for the top-level database key that holds the hash structure itself. Just like there’s for basic string:string key-value pairs, there is also for hashes to set multiple pairs within the hash value object: Using is probably a closer parallel for the way that we assigned to a nested dictionary above, rather than setting each nested pair as is done with . Two additional value types are lists and sets, which can take the place of a hash or string as a Redis value. They are largely what they sound like, so I won’t take up your time with additional examples. Hashes, lists, and sets each have some commands that are particular to that given data type, which are in some cases denoted by their initial letter:\n• Hashes: Commands to operate on hashes begin with an , such as , , or .\n• Sets: Commands to operate on sets begin with an , such as , which gets the number of elements at the set value corresponding to a given key.\n• Lists: Commands to operate on lists begin with an or . Examples include and . The or refers to which side of the list is operated on. A few list commands are also prefaced with a , which means blocking. A blocking operation doesn’t let other operations interrupt it while it’s executing. For instance, executes a blocking left-pop on a list structure. Note: One noteworthy feature of Redis’ list type is that it is a linked list rather than an array. This means that appending is O(1) while indexing at an arbitrary index number is O(N). Here is a quick listing of commands that are particular to the string, hash, list, and set data types in Redis: This table isn’t a complete picture of Redis commands and types. There’s a smorgasbord of more advanced data types, such as geospatial items, sorted sets, and HyperLogLog. At the Redis commands page, you can filter by data-structure group. There is also the data types summary and introduction to Redis data types. Since we’re going to be switching over to doing things in Python, you can now clear your toy database with and quit the REPL: This will bring you back to your shell prompt. You can leave running in the background, since you’ll need it for the rest of the tutorial also.\n\nNow that you’ve mastered some basics of Redis, it’s time to jump into , the Python client that lets you talk to Redis from a user-friendly Python API. is a well-established Python client library that lets you talk to a Redis server directly through Python calls: Next, make sure that your Redis server is still up and running in the background. You can check with , and if you come up empty-handed, then restart a local server with . Now, let’s get into the Python-centric part of things. Here’s the “hello world” of : , used in Line 2, is the central class of the package and the workhorse by which you execute (almost) any Redis command. The TCP socket connection and reuse is done for you behind the scenes, and you call Redis commands using methods on the class instance . Notice also that the type of the returned object, in Line 6, is Python’s type, not . It is rather than that is the most common return type across , so you may need to call depending on what you want to actually do with the returned bytestring. Does the code above look familiar? The methods in almost all cases match the name of the Redis command that does the same thing. Here, you called and , which correspond to and in the native Redis API. This also means that becomes , becomes , and so on. There are a few exceptions, but the rule holds for the large majority of commands. While the Redis command arguments usually translate into a similar-looking method signature, they take Python objects. For example, the call to in the example above uses a Python as its first argument, rather than a sequence of bytestrings. We built the instance with no arguments, but it comes bundled with a number of parameters if you need them: You can see that the default hostname:port pair is , which is exactly what we need in the case of our locally kept instance. The parameter is the database number. You can manage multiple databases in Redis at once, and each is identified by an integer. The max number of databases is 16 by default. When you run just from the command line, this starts you at database 0. Use the flag to start a new database, as in . One thing that’s worth knowing is that requires that you pass it keys that are , , , or . (It will convert the last 3 of these types to before sending them off to the server.) Consider a case where you want to use calendar dates as keys: : Convert to a byte, string or number first. You’ll need to explicitly convert the Python object to , which you can do with : To recap, Redis itself only allows strings as keys. is a bit more liberal in what Python types it will accept, although it ultimately converts everything to bytes before sending them off to a Redis server. It’s time to break out a fuller example. Let’s pretend we’ve decided to start a lucrative website, PyHats.com, that sells outrageously overpriced hats to anyone who will buy them, and hired you to build the site. You’ll use Redis to handle some of the product catalog, inventorying, and bot traffic detection for PyHats.com. It’s day one for the site, and we’re going to be selling three limited-edition hats. Each hat gets held in a Redis hash of field-value pairs, and the hash has a key that is a prefixed random integer , such as . Using the prefix is Redis convention for creating a sort of namespace within a Redis database: Let’s start with database since we used database in a previous example: To do an initial write of this data into Redis, we can use (hash multi-set), calling it for each dictionary. The “multi” is a reference to setting multiple field-value pairs, where “field” in this case corresponds to a key of any of the nested dictionaries in : The code block above also introduces the concept of Redis pipelining, which is a way to cut down the number of round-trip transactions that you need to write or read data from your Redis server. If you would have just called three times, then this would necessitate a back-and-forth round trip operation for each row written. With a pipeline, all the commands are buffered on the client side and then sent at once, in one fell swoop, using in Line 3. This is why the three responses are all returned at once, when you call in Line 4. You’ll see a more advanced use case for a pipeline shortly. Note: The Redis docs provide an example of doing this same thing with the , where you can pipe the contents of a local file to do mass insertion. Let’s do a quick check that everything is there in our Redis database: # Careful on a big DB. keys() is O(N) The first thing that we want to simulate is what happens when a user clicks Purchase. If the item is in stock, increase its by 1 and decrease its (inventory) by 1. You can use to do this: Note: still operates on a hash value that is a string, but it tries to interpret the string as a base-10 64-bit signed integer to execute the operation. This applies to other commands related to incrementing and decrementing for other data structures, namely , , , , and . You’ll get an error if the string at the value can’t be represented as an integer. It isn’t really that simple, though. Changing the and in two lines of code hides the reality that a click, purchase, and payment entails more than this. We need to do a few more checks to make sure we don’t leave someone with a lighter wallet and no hat:\n• Step 1: Check if the item is in stock, or otherwise raise an exception on the backend.\n• Step 2: If it is in stock, then execute the transaction, decrease the field, and increase the field.\n• Step 3: Be alert for any changes that alter the inventory in between the first two steps (a race condition). Step 1 is relatively straightforward: it consists of an to check the available quantity. Step 2 is a little bit more involved. The pair of increase and decrease operations need to be executed atomically: either both should be completed successfully, or neither should be (in the case that at least one fails). With client-server frameworks, it’s always crucial to pay attention to atomicity and look out for what could go wrong in instances where multiple clients are trying to talk to the server at once. The answer to this in Redis is to use a transaction block, meaning that either both or neither of the commands get through. In , is a transactional pipeline class by default. This means that, even though the class is actually named for something else (pipelining), it can be used to create a transaction block also. In Redis, a transaction starts with and ends with : (Line 1) marks the start of the transaction, and (Line 4) marks the end. Everything in between is executed as one all-or-nothing buffered sequence of commands. This means that it will be impossible to decrement (Line 2) but then have the balancing increment operation fail (Line 3). Let’s circle back to Step 3: we need to be aware of any changes that alter the inventory in between the first two steps. Step 3 is the trickiest. Let’s say that there is one lone hat remaining in our inventory. In between the time that User A checks the quantity of hats remaining and actually processes their transaction, User B also checks the inventory and finds likewise that there is one hat listed in stock. Both users will be allowed to purchase the hat, but we have 1 hat to sell, not 2, so we’re on the hook and one user is out of their money. Not good. Redis has a clever answer for the dilemma in Step 3: it’s called optimistic locking, and is different than how typical locking works in an RDBMS such as PostgreSQL. Optimistic locking, in a nutshell, means that the calling function (client) does not acquire a lock, but rather monitors for changes in the data it is writing to during the time it would have held a lock. If there’s a conflict during that time, the calling function simply tries the whole process again. You can effect optimistic locking by using the command ( in ), which provides a check-and-set behavior. Let’s introduce a big chunk of code and walk through it afterwards step by step. You can picture as being called any time a user clicks on a Buy Now or Purchase button. Its purpose is to confirm the item is in stock and take an action based on that result, all in a safe manner that looks out for race conditions and retries if one is detected: \"\"\"Raised when PyHats.com is all out of today's hottest hat\"\"\" # Get available inventory, watching for changes # related to this itemid before the transaction # Stop watching the itemid and raise to break out # Log total num. of errors by this user to buy this item, # then try the same process again of WATCH/HGET/MULTI/EXEC The critical line occurs at Line 16 with , which tells Redis to monitor the given for any changes to its value. The program checks the inventory through the call to , in Line 17: If the inventory gets touched during this short window between when the user checks the item stock and tries to purchase it, then Redis will return an error, and will raise a (Line 30). That is, if any of the hash pointed to by changes after the call but before the subsequent calls in Lines 20 and 21, then we’ll re-run the whole process in another iteration of the loop as a result. This is the “optimistic” part of the locking: rather than letting the client have a time-consuming total lock on the database through the getting and setting operations, we leave it up to Redis to notify the client and user only in the case that calls for a retry of the inventory check. One key here is in understanding the difference between client-side and server-side operations: This Python assignment brings the result of client-side. Conversely, methods that you call on effectively buffer all of the commands into one, and then send them to the server in a single request: No data comes back to the client side in the middle of the transactional pipeline. You need to call (Line 19) to get the sequence of results back all at once. Even though this block contains two commands, it consists of exactly one round-trip operation from client to server and back. This means that the client can’t immediately use the result of , from Line 20, because methods on a return just the instance itself. We haven’t asked anything from the server at this point. While normally returns the resulting value, you can’t immediately reference it on the client side until the entire transaction is completed. There’s a catch-22: this is also why you can’t put the call to into the transaction block. If you did this, then you’d be unable to know if you want to increment the field yet, since you can’t get real-time results from commands that are inserted into a transactional pipeline. Finally, if the inventory sits at zero, then we the item ID and raise an (Line 27), ultimately displaying that coveted Sold Out page that will make our hat buyers desperately want to buy even more of our hats at ever more outlandish prices: # Stop watching the itemid and raise to break out Here’s an illustration. Keep in mind that our starting quantity is for hat 56854717 since we called above. Let’s mimic 3 purchases, which should modify the and fields: Now, we can fast-forward through more purchases, mimicking a stream of purchases until the stock depletes to zero. Again, picture these coming from a whole bunch of different clients rather than just one instance: # Buy remaining 196 hats for item 56854717 and deplete stock to 0 Now, when some poor user is late to the game, they should be met with an that tells our application to render an error message page on the frontend: File , line , in File , line , in : Sorry, hat:56854717 is out of stock! Looks like it’s time to restock. Let’s introduce key expiry, which is another distinguishing feature in Redis. When you expire a key, that key and its corresponding value will be automatically deleted from the database after a certain number of seconds or at a certain timestamp. In , one way that you can accomplish this is through , which lets you set a basic string:string key-value pair with an expiration: \"now you see me, now you don't\" You can specify the second argument as a number in seconds or a object, as in Line 6 above. I like the latter because it seems less ambiguous and more deliberate. There are also methods (and corresponding Redis commands, of course) to get the remaining lifetime (time-to-live) of a key that you’ve set to expire: Below, you can accelerate the window until expiration, and then watch the key expire, after which will return and will return : b\"now you see me, now you don't\" # Key & value are both gone (expired) The table below summarizes commands related to key-value expiration, including the ones covered above. The explanations are taken directly from method docstrings: Sets the value of key to that expires in seconds, where can be represented by an or a Python object Sets the value of key to that expires in milliseconds, where can be represented by an or a Python object Sets an expire flag on key for seconds, where can be represented by an or a Python object Sets an expire flag on key , where can be represented as an indicating Unix time or a Python object Sets an expire flag on key for milliseconds, and can be represented by an or a Python object Sets an expire flag on key , where can be represented as an representing Unix time in milliseconds (Unix time * 1000) or a Python object Returns the number of milliseconds until the key will expire Returns the number of seconds until the key will expire A few days after its debut, PyHats.com has attracted so much hype that some enterprising users are creating bots to buy hundreds of items within seconds, which you’ve decided isn’t good for the long-term health of your hat business. Now that you’ve seen how to expire keys, let’s put it to use on the backend of PyHats.com. We’re going to create a new Redis client that acts as a consumer (or watcher) and processes a stream of incoming IP addresses, which in turn may come from multiple HTTPS connections to the website’s server. The watcher’s goal is to monitor a stream of IP addresses from multiple sources, keeping an eye out for a flood of requests from a single address within a suspiciously short amount of time. Some middleware on the website server pushes all incoming IP addresses into a Redis list with . Here’s a crude way of mimicking some incoming IPs, using a fresh Redis database: As you can see, returns the length of the list after the push operation succeeds. Each call of puts the IP at the beginning of the Redis list that is keyed by the string . In this simplified simulation, the requests are all technically from the same client, but you can think of them as potentially coming from many different clients and all being pushed to the same database on the same Redis server. Now, open up a new shell tab or window and launch a new Python REPL. In this shell, you’ll create a new client that serves a very different purpose than the rest, which sits in an endless loop and does a blocking left-pop call on the list, processing each address: # Where we put all the bad egg IP addresses The acts like a consumer, sitting around and waiting for new IPs to be pushed on the Redis list. It receives them as , such as b”51.218.112.236”, and makes them into a more proper address object with the module: Then you form a Redis string key using the address and minute of the hour at which the saw the address, incrementing the corresponding count by and getting the new count in the process: If the address has been seen more than , then it looks as if we have a PyHats.com web scraper on our hands trying to create the next tulip bubble. Alas, we have no choice but to give this user back something like a dreaded 403 status code. We use to expire the (address minute) combination 60 seconds from when it was last seen. This is to prevent our database from becoming clogged up with stale one-time page viewers. If you execute this code block in a new shell, you should immediately see this output: 2019-03-11 15:10:41.489214: saw 51.218.112.236 2019-03-11 15:10:41.490298: saw 115.215.230.176 2019-03-11 15:10:41.490839: saw 90.213.45.98 2019-03-11 15:10:41.491387: saw 51.218.112.236 The output appears right away because those four IPs were sitting in the queue-like list keyed by , waiting to be pulled out by our . Using (or the command) will block until an item is available in the list, then pops it off. It behaves like Python’s , which also blocks until an item is available. Besides just spitting out IP addresses, our has a second job. For a given minute of an hour (minute 1 through minute 60), will classify an IP address as a hat-bot if it sends 15 or more requests in that minute. Switch back to your first shell and mimic a page scraper that blasts the site with 20 requests in a few milliseconds: Finally, toggle back to the second shell holding , and you should see an output like this: 2019-03-11 15:15:43.041363: saw 104.174.118.18 2019-03-11 15:15:43.042027: saw 104.174.118.18 2019-03-11 15:15:43.042598: saw 104.174.118.18 2019-03-11 15:15:43.043143: saw 104.174.118.18 2019-03-11 15:15:43.043725: saw 104.174.118.18 2019-03-11 15:15:43.044244: saw 104.174.118.18 2019-03-11 15:15:43.044760: saw 104.174.118.18 2019-03-11 15:15:43.045288: saw 104.174.118.18 2019-03-11 15:15:43.045806: saw 104.174.118.18 2019-03-11 15:15:43.046318: saw 104.174.118.18 2019-03-11 15:15:43.046829: saw 104.174.118.18 2019-03-11 15:15:43.047392: saw 104.174.118.18 2019-03-11 15:15:43.047966: saw 104.174.118.18 2019-03-11 15:15:43.048479: saw 104.174.118.18 Hat bot detected!: 104.174.118.18 Hat bot detected!: 104.174.118.18 Hat bot detected!: 104.174.118.18 Hat bot detected!: 104.174.118.18 Hat bot detected!: 104.174.118.18 Hat bot detected!: 104.174.118.18 Now, + out of the loop and you’ll see that the offending IP has been added to your blacklist: Can you find the defect in this detection system? The filter checks the minute as rather than the last 60 seconds (a rolling minute). Implementing a rolling check to monitor how many times a user has been seen in the last 60 seconds would be trickier. There’s a crafty solution using using Redis’ sorted sets at ClassDojo. Josiah Carlson’s Redis in Action also presents a more elaborate and general-purpose example of this section using an IP-to-location cache table. One of the reasons that Redis is so fast in both read and write operations is that the database is held in memory (RAM) on the server. However, a Redis database can also be stored (persisted) to disk in a process called snapshotting. The point behind this is to keep a physical backup in binary format so that data can be reconstructed and put back into memory when needed, such as at server startup. You already enabled snapshotting without knowing it when you set up basic configuration at the beginning of this tutorial with the option: The format is . This tells Redis to save the database to disk if both the given number of seconds and number of write operations against the database occurred. In this case, we’re telling Redis to save the database to disk every 60 seconds if at least one modifying write operation occurred in that 60-second timespan. This is a fairly aggressive setting versus the sample Redis config file, which uses these three directives: An RDB snapshot is a full (rather than incremental) point-in-time capture of the database. (RDB refers to a Redis Database File.) We also specified the directory and file name of the resulting data file that gets written: This instructs Redis to save to a binary data file called in the current working directory of wherever was executed from: You can also manually invoke a save with the Redis command : The “BG” in indicates that the save occurs in the background. This option is available in a method as well: This example introduces another new command and method, . In Redis, it returns the Unix timestamp of the last DB save, which Python gives back to you as a object. Above, you can see that the result changes as a result of . will also change if you enable automatic snapshotting with the configuration option. To rephrase all of this, there are two ways to enable snapshotting:\n• Explicitly, through the Redis command or method\n• Implicitly, through the configuration option (which you can also set with in ) RDB snapshotting is fast because the parent process uses the system call to pass off the time-intensive write to disk to a child process, so that the parent process can continue on its way. This is what the background in refers to. There’s also ( in ), but this does a synchronous (blocking) save rather than using , so you shouldn’t use it without a specific reason. Even though occurs in the background, it’s not without its costs. The time for itself to occur can actually be substantial if the Redis database is large enough in the first place. If this is a concern, or if you can’t afford to miss even a tiny slice of data lost due to the periodic nature of RDB snapshotting, then you should look into the append-only file (AOF) strategy that is an alternative to snapshotting. AOF copies Redis commands to disk in real time, allowing you to do a literal command-based reconstruction by replaying these commands. Let’s get back to talking about Redis data structures. With its hash data structure, Redis in effect supports nesting one level deep: The Python client equivalent would look like this: Here, you can think of as being the key-value pair of a Python dict, , while is the top-level key: But what if you want the value of this dictionary (the Redis hash) to contain something other than a string, such as a or nested dictionary with strings as values? Here’s an example using some JSON-like data to make the distinction clearer: Say that we want to set a Redis hash with the key and field-value pairs corresponding to the key-value pairs from . Redis does not support this directly, because is nested: : Convert to a byte, string or number first. You can in fact make this work with Redis. There are two different ways to mimic nested data in and Redis:\n• Serialize the values into a string with something like\n• Use a delimiter in the key strings to mimic nesting in the values Let’s take a look at an example of each. You can use to serialize the into a JSON-formatted string: If you call , the value you get back will be a object, so don’t forget to deserialize it to get back the original object. and are inverses of each other, for serializing and deserializing data, respectively: This applies to any serialization protocol, with another common choice being : No matter what serialization protocol you choose to go with, the concept is the same: you’re taking an object that is unique to Python and converting it to a bytestring that is recognized and exchangeable across multiple languages. There’s a second option that involves mimicking “nestedness” by concatenating multiple levels of keys in a Python . This consists of flattening the nested dictionary through recursion, so that each key is a concatenated string of keys, and the values are the deepest-nested values from the original dictionary. Consider our dictionary object : We want to get it into this form: That’s what below does, with the added feature that it does inplace operations on the instance itself rather than returning a copy of the input dictionary: Calls `.set()` to write to Redis instance inplace and returns None. `prefix` is an optional str that prefixes all keys. `delim` is the delimiter that separates the joined, flattened keys. `_autopfix` is used in recursive calls to created de-nested keys. The deepest-nested keys must be str, bytes, float, or int. The function iterates over the key-value pairs of , first checking the type of the value (Line 25) to see if it looks like it should stop recursing further and set that key-value pair. Otherwise, if the value looks like a (Line 27), then it recurses into that mapping, adding the previously seen keys as a key prefix (Line 28). The final loop above uses , where is interpreted as a pattern and matches all keys in the database that begin with . Notice also how calls just rather than , because we’re working with plain string:string field-value pairs, and the 484272 ID key is prepended to each field string. Another trick to help you sleep well at night is to add symmetric encryption before sending anything to a Redis server. Consider this as an add-on to the security that you should make sure is in place by setting proper values in your Redis configuration. The example below uses the package: To illustrate, pretend that you have some sensitive cardholder data (CD) that you never want to have sitting around in plaintext on any server, no matter what. Before caching it in Redis, you can serialize the data and then encrypt the serialized string using Fernet: Because contains a value that is a , you’ll need to serialize this into a string that’s acceptable by Redis. (You could use , , or any other serialization for this.) Next, you encrypt and decrypt that string using the object. You need to deserialize the decrypted bytes using so that you can get the result back into the type of your initial input, a . Note: Fernet uses AES 128 encryption in CBC mode. See the docs for an example of using AES 256. Whatever you choose to do, use , not (imported as ), which is no longer actively maintained. If security is paramount, encrypting strings before they make their way across a network connection is never a bad idea. One last quick optimization is compression. If bandwidth is a concern or you’re cost-conscious, you can implement a lossless compression and decompression scheme when you send and receive data from Redis. Here’s an example using the bzip2 compression algorithm, which in this extreme case cuts down on the number of bytes sent across the connection by a factor of over 2,000: \"i have a lot to talk about\" # Set the compressed string as value # Get and decompress the value, then confirm it's equal to the original The way that serialization, encryption, and compression are related here is that they all occur client-side. You do some operation on the original object on the client-side that ends up making more efficient use of Redis once you send the string over to the server. The inverse operation then happens again on the client side when you request whatever it was that you sent to the server in the first place.\n\nWhile Redis itself is open-source and free, several managed services have sprung up that offer a data store with Redis as the core and some additional features built on top of the open-source Redis server:\n• Amazon ElastiCache for Redis: This is a web service that lets you host a Redis server in the cloud, which you can connect to from an Amazon EC2 instance. For full setup instructions, you can walk through Amazon’s ElastiCache for Redis launch page.\n• Microsoft’s Azure Cache for Redis: This is another capable enterprise-grade service that lets you set up a customizable, secure Redis instance in the cloud. The designs of the two have some commonalities. You typically specify a custom name for your cache, which is embedded as part of a DNS name, such as (AWS) or (Azure). Once you’re set up, here are a few quick tips on how to connect. From the command line, it’s largely the same as in our earlier examples, but you’ll need to specify a host with the flag rather than using the default localhost. For Amazon AWS, execute the following from your instance shell: For Microsoft Azure, you can use a similar call. Azure Cache for Redis uses SSL (port 6380) by default rather than port 6379, allowing for encrypted communication to and from Redis, which can’t be said of TCP. All that you’ll need to supply in addition is a non-default port and access key: The flag specifies a host, which as you’ve seen is (localhost) by default. When you’re using in Python, it’s always a good idea to keep sensitive variables out of Python scripts themselves, and to be careful about what read and write permissions you afford those files. The Python version would look like this: # Specify a DNS endpoint instead of the default localhost That’s all there is to it. Besides specifying a different , you can now call command-related methods such as as normal. Note: If you want to use solely the combination of and an AWS or Azure Redis instance, then you don’t really need to install and make Redis itself locally on your machine, since you don’t need either or . If you’re deploying a medium- to large-scale production application where Redis plays a key role, then going with AWS or Azure’s service solutions can be a scalable, cost-effective, and security-conscious way to operate."
    },
    {
        "link": "https://faun.pub/the-two-ways-of-storing-nested-dictionaries-in-redis-3404bedb198b",
        "document": "For working with Redis with Python you need to install redis-py, a client library that lets you talk to a Redis server directly through Python calls.\n\nLet's coding it!\n\nIn the first step, we need to import the necessary modules, define the Redis server endpoint and assign a variable which we can consider as a nested object. \n\nNote: the host, port, and db parameters are default, so you should change them with yours.\n\n1. By the first way, we’ll insert (write) the object into Redis as a string data type.\n\nFor inserting a string into Redis we need to use the method. When we call this method we should pass the key-value pairs to it. At the same time, we must convert the type of the student object from a dictionary (JSON) to a string.\n\nAs while we have successfully stored our object in Redis, let’s read it by using the method. You have to notice that the method returns an object with bytes type.\n\nFor that reason, we have to decode it and make a string. After that, we can convert that string to a dictionary object, with method."
    }
]