[
    {
        "link": "https://stackoverflow.com/questions/37072844/select-subset-of-columns-based-on-vector-r",
        "document": "I have a data frame with 300 columns of data. I created a vector with 126 elements that are the column names of 126 of the 300. I want to subset the 300 based on not being in my 126. They are NOT in order, so I can't simply remove by specifying -1:-126.\n\nI tried various things with grep and matrix operations, but they did not work. Such as the following which did not work. x has 300 columns. f contains vector of 126 column names I want to exclude from x1.\n\nIf I definitively use a variable name or several, I can get it to work, but I don't want to type out the 126 elements in f."
    },
    {
        "link": "https://stackoverflow.com/questions/12208090/selecting-columns-in-r-data-frame-based-on-those-not-in-a-vector",
        "document": "I'm familiar with being able to extract columns from an R data frame (or matrix) like so:\n\nBut can one use a or other tool to select all but those listed columns?\n\nFor background, I have a data frame with quite a few column vectors and I'd like to avoid:\n• Typing out the majority of the names when I could just remove a minority\n• Using the much shorter because when my .csv file changes, my code goes to heck since the numbering isn't the same anymore. I'm new to R and think I've learned the hard way not to use number vectors for larger df's that might change.\n\nAnd just as I was typing this, found out that this works:\n\nIs there a better way than this last one?"
    },
    {
        "link": "https://mitchcraver.com/2021/06/15/subsetting-and-filtering-a-data-frame-in-r",
        "document": "When I was first learning R in a Coursera course from Johns Hopkins University, subsetting and filtering was one of the first things I learned how to do in R. Subsetting is essentially scaling down your data frame so that you are only seeing relevant data points. Filtering a data frame is super important to know how to do, since data frames, in my opinion, are the most common data structures you’ll use in R.\n\nWhile I think it is extremely important for those learning R to have a good foundation in base R code, I know that there are several packages out there that make subsetting and filtering data frames easier and faster. We’ll get in to those later, but for now, let’s look at the base R way of doing things.\n\nWhen I say Base R, I am referring to using straight R code and not introducing any additional packages to be loaded.\n\nThe general format for subsetting a data frame looks like this:\n\nThe row and column parameters between the brackets can be a single index, a range , a character vector containing multiple indexes ), or left blank to return all rows. The column parameter can take the same options, and it will also accept column names. Subsetting allows you to scale down the dataset with which you are working.\n\nA best practice that I use is to assign the subset to a new variable so that the original information is not lost.\n\nWhen I was first learning to subset data frames in R, I preferred to use the column indexes because I didn’t need to have opening and closing quotes, saving me time. I changed my ways a long time ago when I got bit by an automated report that was modified. The column names were not in the same order anymore and tons of errors were in the console.\n\nShow the first 10 rows of the mtcars dataset and all columns:\n\nShow the first 3 rows, but only see the mpg and cyl columns:\n\nShow rows 1, 3, 5, 7 and 9, and only the values from the mpg and cyl columns:\n\nIf you want to filter a data frame, you’ll add the logic to the row parameter in the brackets. This is where it can get confusing to write R code using base R.\n\nTo filter a data frame based on a column, you’ll use the following format:\n\nThe part is where you’ll add your conditional logic for the filter. Additional logic can be used by adding the and operator ( ) or the or operator ( ). It always seemed backwards in my head to add the logic to the rows and not the columns, but eventually it clicked, and off I went.\n\nThe column parameter functions identically to how it does when subsetting a data frame. The column parameter will accept a single index, a range ( ), a character vector containing multiple indexes or column names in quotes, or left blank to return all columns.\n\nFilter the mtcars dataset to show cars that values greater than or equal to 21:\n\nFilter the mtcars dataset to show cars that mpg values greater than or equal to 21 and have horsepower (hp) of 100:\n\nShow cars that have 3 or 5 gears:\n\nShow cars that get 21 or more mpg, and only show the mpg and gear columns:\n\nSubsetting and filtering data frames in R using the base R code is super important on your coding journey. It’s best to learn the base R way of doing things so that down the road, you’ll be able to troubleshoot errors and understand why there are conflicts with packages. That said, subsetting and filtering in R can be done faster and easier (in my opinion) with the help of the dplyr package. This package is very powerful for manipulating data frames, and it is extremely well documented."
    },
    {
        "link": "https://anyamemensah.com/blog/select-col-name",
        "document": "When analyzing a data set, sometimes you only want to include columns (or variables) that meet specific criteria. In a recent post, I shared how to extract columns based on data type. This post examines several techniques for selecting columns from a data frame in the R environment by name. First, let's load the tidyverse packages and generate some fake data. We are going to create a data frame with four variables and 100 observations:\n• None ID: An identification variable (numbers range from 1 to 80).\n• None Gender: A nominal variable indicating whether a participant identifies as a Woman, Non-Binary, or Man.\n• None Low_Income: A binary variable indicating whether a participant was raised in a low-income household (1) or not (0).\n• None HS_Grad: A binary variable indicating whether a participant graduated from high school (1) or not (0).\n\nIn this first section, I will focus on how to select a single column. The second part of the post will share options for selecting multiple columns by name. In Base R, the simplest way to extract a column by name is to place the name enclosed in double quotes within square brackets. For example, you could select the \"Gender\" column from the fake_dat data set, like so:\n\nAlthough primarily used for filtering data, the subset function can also select columns by name. And all it takes is two arguments:\n• None x: an object to be subsetted and\n• None select: an expression where you can indicate which columns to select from a data frame. So, we can rewrite the syntax from option 1 to select the Gender column like so:\n\nIn tidyverse, the best way to select a single column is using the select function from dplyr. The select function extracts columns from a data frame by their name or their properties (i.e., type). To select a column by name, simply:\n• None reference the data frame (or tibble) containing the column followed by the pipe operator ( %>% );\n• None type the name select and, within parentheses, So, if you wanted to select the Gender column from our created data set, you could write:\n\nBut what if you want to select more than one column by name? Say we wanted to select both the Gender and the HS_Grad columns. Luckily, you have many options at your disposal. You can still use single square brackets to select multiple columns in Base R. However, you must also enclose each name in quotations and combine them with the c() function, separating each element with a comma. For example, to select both Gender and HS_Grad, you can write:\n\nOption #7: which and %in% If you are looking for a more creative albeit complex solution, you can also turn to the which function and %in% operator. The which function allows you to identify elements within an object that meet a given condition. On the other hand, the %in% operator evaluates whether elements of a vector exist in another vector and returns a logical vector (TRUE / FALSE), indicating whether a match was found. Using both which and %in%, you can select the Gender and HS_Grad columns by:\n• None writing a which function that returns the location of each column in a data frame;\n• None referencing the name of the data frame followed by square brackets; and\n• None enclosing the vector of column names within the square brackets:"
    },
    {
        "link": "https://geeksforgeeks.org/how-to-filter-r-dataframe-by-values-in-a-column",
        "document": "In R Programming Language, dataframe columns can be subjected to constraints, and produce smaller subsets. However, while the conditions are applied, the following properties are maintained :\n• Rows are considered to be a subset of the input.\n• Rows in the subset appear in the same order as the original dataframe.\n• The number of groups may be reduced, based on conditions.\n\nAny dataframe column in the R programming language can be referenced either through its name df$col-name or using its index position in the dataframe df[col-index]. The cell values of this column can then be subjected to constraints, logical or comparative conditions, and then a dataframe subset can be obtained. These conditions are applied to the row index of the dataframe so that the satisfied rows are returned.\n• Selection based on a check of missing values or NA\n\nCells in dataframe can contain missing values or NA as its elements, and they can be verified using is.na() method in R language.\n\nColumn values can be subjected to constraints to filter and subset the data. The values can be mapped to specific occurrences or within a range.\n\nColumn values can be subjected to constraints to filter and subset the data. The conditions can be combined by logical & or | operators. The %in% operator is used here, in order to check values that match to any of the values within a specified vector.\n\nThe dplyr library can be installed and loaded into the working space which is used to perform data manipulation.\n\nThe filter() function is used to produce a subset of the dataframe, retaining all rows that satisfy the specified conditions. The filter() method in R can be applied to both grouped and ungrouped data. The expressions include comparison operators (==, >, >= ) , logical operators (&, |, !, xor()) , range operators (between(), near()) as well as NA value check against the column values. The subset dataframe has to be retained in a separate variable.\n\nAlso, the values can be checked using the %in% operator to match the column cell values with the elements contained in the input specified vector."
    },
    {
        "link": "https://rdocumentation.org/packages/tseries/versions/0.10-58/topics/portfolio.optim",
        "document": "The computed portfolio has the desired expected return and no other portfolio exists, which has the same mean return, but a smaller variance. Inequality restrictions of the form \\(w_l \\le w \\le w_h\\) can be imposed using the and vectors. An alternative covariance matrix estimate can be supplied via the argument. To solve the quadratic program, is used.\n\nis a generic function with methods for multivariate and for matrix."
    },
    {
        "link": "https://rdrr.io/cran/tseries/man/portfolio.optim.html",
        "document": "Computes an efficient portfolio from the given return series in the mean-variance sense.\n\na numeric matrix or multivariate time series consisting of a series of returns. a logical indicating whether there is a riskless lending and borrowing rate. a logical indicating whether shortsales on the risky securities are allowed. a vector specifying the (optional) lower bound on allowed portfolio weights. a vector specifying the (optional) upper bound on allowed portfolio weights. further arguments to be passed from or to methods.\n\nThe computed portfolio has the desired expected return and no other portfolio exists, which has the same mean return, but a smaller variance. Inequality restrictions of the form can be imposed using the and vectors. An alternative covariance matrix estimate can be supplied via the argument. To solve the quadratic program, is used.\n\nis a generic function with methods for multivariate and for matrix.\n\nA list containing the following components:\n\nC. Huang and R. H. Litzenberger (1988): Foundations for Financial Economics, Elsevier, NY, pp. 59-82."
    },
    {
        "link": "https://search.r-project.org/CRAN/refmans/tseries/html/portfolio.optim.html",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/20096571/portfolio-optimization-tseries-r",
        "document": "i want to do a simple backtest with the package tseries in R. Let me give you a small example\n\nThere is a timeseries of in sample data and a timeseries of out of sample data, which contains 2 stocks and 3 returns.\n\nNow i compute a loop which take the in sample data and add a new row to this data from the out of sample data in every step of the loop. Then it optimizes my portfolio every time with the new timeseries.\n\nI get the following Output with $pw=optimal weights, $px=returns of the portfolio on every day, $ps=mean return of the portfolio in the complete periode, $ps=standard deviation of the portfolio on the whole periode\n\nin sample data plus data of first day out of sample data\n\nin sample data plus 2 days of out of sample data\n\nin sample data plus 3 days of out of sample data\n\nSo now my Question. Is it possible to extract the last number of $px in every loop step and store it in an empty vector.\n\nIf i do it this way, the whole portfolio optimizations get safed in an vector\n\nI want to do that backtesting on a timeseries with 257 in sample data and 253 out of sample data so this extraction is kind of necessary\n\nI hope you can help me with my problem"
    },
    {
        "link": "https://search.r-project.org/CRAN/refmans/tseries/help/portfolio.optim.html",
        "document": ""
    },
    {
        "link": "https://reddit.com/r/algotrading/comments/ndldvt/optimizing_portfolio_with_sharpe_ratio",
        "document": "A place for redditors to discuss quantitative trading, statistical methods, econometrics, programming, implementation, automated strategies, and bounce ideas off each other for constructive criticism. Feel free to submit papers/links of things you find interesting."
    },
    {
        "link": "https://cran.r-project.org/web/packages/SharpeR/vignettes/SharpeR.pdf",
        "document": ""
    },
    {
        "link": "https://rpubs.com/neeraj1990/HM_model_R",
        "document": ""
    },
    {
        "link": "https://codingfinance.com/post/2018-05-31-portfolio-opt-in-r",
        "document": "Portfolio optimization is an important topic in Finance. Modern portfolio theory (MPT) states that investors are risk averse and given a level of risk, they will choose the portfolios that offer the most return. To do that we need to optimize the portfolios.\n\nTo perform the optimization we will need\n\nNext lets select a few stocks to build our portfolios.\n\nWe will choose the following 5 stocks\n\nNext we will calculate the daily returns for these stocks. We will use the logarithmic returns.\n\nLets look at the first few rows.\n\nAs you can see that this data is in tidy format. We will use the function to convert it to a wide format. And we will also convert it into a time series object using function.\n\nThis is better for our purpose.\n\nNext lets calculate the mean daily returns for each asset.\n\nNext we will calculate the covariance matrix for all these stocks. We will annualize it by multiplying by 252.\n\nBefore we apply our methods to thousands of random portfolio, let us demonstrate the steps on a single portfolio.\n\nTo calculate the portfolio returns and risk (standard deviation) we will us need\n\nWe created some random weights, but the problem is that their sum is more than 1. We can fix this as shown below.\n\nNext we will calculate the annualized portfolio returns.\n\nNext we will calculate the portfolio risk (Standard deviation). This will be annualized Standard deviation for the portfolio. We will use linear algebra to calculate our portfolio risk.\n\nNext we will assume 0% risk free rate to calculate the Sharpe Ratio.\n\nLets put all these steps together.\n\nWe have everything we need to perform our optimization. All we need now is to run this code on 5000 random portfolios. For that we will use a for loop.\n\nBefore we do that, we need to create empty vectors and matrix for storing our values.\n\nNext lets run the for loop 5000 times.\n\nAll the heavy lifting has been done and now we can create a data table to store all the values together.\n\nLets look at the first few values.\n\nWe have the weights in each asset with the risk and returns along with the Sharpe ratio of each portfolio.\n\nNext lets look at the portfolios that matter the most.\n• The tangency portfolio (the portfolio with highest sharpe ratio)\n\nLets plot the weights of each portfolio. First with the minimum variance portfolio.\n\nAs we can observe the Minimum variance portfolio has no allocation to Netflix and very little allocation to Amazon. The majority of the portfolio is invested in Exxon Mobil and AT&T stock.\n\nNext lets look at the tangency portfolio or the the portfolio with the highest sharpe ratio.\n\nNot surprisingly, the portfolio with the highest sharpe ratio has very little invested in Exxon Mobil and AT&T. This portfolio has most of the assets invested in Amazon, Netflix and Apple. Three best performing stocks in the last decade.\n\nFinally lets plot all the random portfolios and visualize the efficient frontier.\n\nIn the chart above we can observe all the 5000 portfolios. As mentioned above, a risk averse investor will demand a highest return for a given level of risk. In other words he/she will try to obtain portfolios that lie on the efficient frontier."
    },
    {
        "link": "https://bookdown.org/palomar/portfoliooptimizationbook/7.2-MSRP.html",
        "document": "Markowitz’s mean–variance framework provides portfolios along the efficient frontier, that is, formulations (7.1), (7.2), and (7.3), by varying the hyper-parameters \\(\\lambda\\), \\(\\alpha\\), and \\(\\beta\\), respectively. The specific choice of a point on the efficient frontier depends on the risk aversion of the investor. Nevertheless, the most widely used performance measure is the Sharpe ratio and there is only one portfolio on the efficient frontier that achieves the maximum value, as indicated in Figure 7.2 under MSRP.\n\nPrecisely, in 1966, Sharpe proposed the maximum Sharpe ratio portfolio (MSRP) formulation (Sharpe, 1966) as \\[\\begin{equation} \\begin{array}{ll} \\underset{\\w}{\\textm{maximize}} & \\dfrac{\\w^\\T\\bmu - r_\\textm{f}}{\\sqrt{\\w^\\T\\bSigma\\w}}\\\\ \\textm{subject to} & \\begin{array}{l} \\bm{1}^\\T\\w=1, \\quad \\w\\ge\\bm{0},\\end{array} \\end{array} \\tag{7.7} \\end{equation}\\] where \\(r_\\textm{f}\\) is the return of the risk-free asset.\n\nThis problem is not convex, but it belongs to the class of fractional programs (FPs) for which many solving methods are available, namely, the bisection, Dinkelbach, and Schaible transform methods as described next (see Section A.5 in Appendix A for a description of FPs and Section B.5 in Appendix B for more details on the algorithms).\n\nConcave–convex FP can be conveniently solved via a sequence of convex feasibility problems, termed the bisection method (see Section A.4 for details). For problem (7.7), the sequence of convex feasibility problems are of the form \\[\\begin{equation} \\begin{array}{ll} \\underset{\\w}{\\textm{find}} & \\begin{array}{c} \\w \\end{array}\\\\ \\textm{subject to} & \\begin{array}[t]{l} t \\sqrt{\\w^\\T\\bSigma\\w} \\leq \\w^\\T\\bmu - r_\\textm{f},\\\\ \\bm{1}^\\T\\w=1, \\quad \\w\\ge\\bm{0}, \\end{array} \\end{array} \\tag{7.8} \\end{equation}\\] where \\(t>0\\) is a fixed parameter (not an optimization variable). This problem is convex and, in fact, a second-order cone program (SOCP) since the volatility can be written as an \\(\\ell_2\\)-norm, \\(\\sqrt{\\w^\\T\\bSigma\\w} = \\|\\bSigma^{1/2}\\w\\|_2\\) (see Section A.5). Note that this convex feasibility reformulation can be infeasible in practice (e.g., if all the elements of \\(\\bmu\\) are negative), so care has to be taken for such a case. The method is summarized in Algorithm 7.1. Algorithm 7.1: Bisection method to solve the MSRP in (7.7). Choose interval \\([l,u]\\) (with \\(l>0\\)) that contains the optimal Sharpe ratio, tolerance \\(\\epsilon>0\\);\n\n repeat\n• if feasible, then and keep solution ; else ;\n\nConcave–convex FPs can be solved via the Dinkelbach method (Dinkelbach, 1967) by solving a sequence of simpler convex problems (see Section B.5.2 for details). For problem (7.7), the sequence of convex problems is, in fact, a sequence of SOCPs of the form: \\[\\begin{equation} \\begin{array}{ll} \\underset{\\w}{\\textm{maximize}} & \\w^\\T\\bmu - r_\\textm{f} - y^{k}\\sqrt{\\w^\\T\\bSigma\\w}\\\\ \\textm{subject to} & \\begin{array}{l} \\bm{1}^\\T\\w=1, \\quad \\w\\ge\\bm{0},\\end{array} \\end{array} \\tag{7.9} \\end{equation}\\] where the parameter \\(y^k\\) is sequentially updated as \\[\\begin{equation} y^{k} = \\dfrac{(\\w^k) ^\\T \\bmu - r_\\textm{f}}{\\sqrt{(\\w^k)^\\T\\bSigma\\w^k}} \\tag{7.10} \\end{equation}\\] with \\(k\\) the iteration index. This is summarized in Algorithm 7.2. Algorithm 7.2: Dinkelbach method to solve the MSRP in (7.7).\n• Solve the convex problem (7.9) and keep current solution as ;\n\nConcave–convex FPs can be more efficiently solved via the Schaible transform (Schaible, 1974) without the need to resort to iterative schemes (see Section B.5.3 for details). It turns out that problem (7.7) can be rewritten as \\[ \\begin{array}{ll} \\underset{\\bm{y},t}{\\textm{maximize}} & \\bm{y}^\\T\\left(\\bmu - r_\\textm{f}\\bm{1}\\right)\\\\ \\textm{subject to} & \\sqrt{\\bm{y}^\\T\\bSigma\\bm{y}} \\le 1,\\\\ & t > 0,\\\\ & \\bm{1}^\\T\\bm{y}=t, \\quad \\bm{y}\\ge\\bm{0}, \\end{array} \\] which can be further simplified (eliminating variable \\(t\\)) to \\[\\begin{equation} \\begin{array}{ll} \\underset{\\bm{y}}{\\textm{maximize}} & \\bm{y}^\\T\\left(\\bmu - r_\\textm{f}\\bm{1}\\right)\\\\ \\textm{subject to} & \\bm{y}^\\T\\bSigma\\bm{y} \\le 1,\\\\ & \\bm{1}^\\T\\bm{y} > 0, \\quad \\bm{y}\\ge\\bm{0}, \\end{array} \\tag{7.11} \\end{equation}\\] from which the original variable \\(\\w\\) can be easily recovered from \\(\\bm{y}\\), and \\(t=\\bm{1}^\\T\\bm{y}\\) as \\(\\w = \\bm{y}/\\left(\\bm{1}^\\T\\bm{y}\\right).\\) Note that, since \\(\\bm{y}\\ge\\bm{0}\\), the constraint \\(\\bm{1}^\\T\\bm{y} > 0\\) can be safely ignored when solving the problem with an interior-point method (see Section B.4 for details). Interestingly, if we reformulate problem (7.7) as the minimization of \\(\\sqrt{\\w^\\T\\bSigma\\w}/\\left(\\w^\\T\\bmu - r_\\textm{f}\\right)\\), the Schaible transform leads to \\[\\begin{equation} \\begin{array}{ll} \\underset{\\bm{y}}{\\textm{minimize}} & \\bm{y}^\\T\\bSigma\\bm{y}\\\\ \\textm{subject to} & \\bm{y}^\\T\\left(\\bmu - r_\\textm{f}\\bm{1}\\right) \\ge 1,\\\\ & \\bm{1}^\\T\\bm{y} > 0, \\quad \\bm{y}\\ge\\bm{0}, \\end{array} \\tag{7.12} \\end{equation}\\] where the inequality \\(\\bm{y}^\\T\\left(\\bmu - r_\\textm{f}\\bm{1}\\right) \\ge 1\\) can be alternatively written as equality. Observe that the Schaible transform requires the denominator to be nonnegative, which in this case means \\(\\bm{y}^\\T\\left(\\bmu - r_\\textm{f}\\bm{1}\\right) > 0\\) or \\(\\w^\\T\\bmu - r_\\textm{f} > 0\\); in other words, this alternative reformulation may or may not be feasible and care has to be taken for this case. Problem (7.11) is a (convex) QCQP, which can be easily solved with a QCQP solver. However, the alternative problem reformulation in (7.12) is a simpler QP, which is preferred since it can be solved with more efficient QP solvers (see Section B.1 for details). Example 7.2 (MSRP with return and upper bound constraints) Consider the MSRP formulation with minimum return \\(\\beta>0\\) and upper bound \\(\\bm{u}\\) constraints: \\[\\begin{array}{ll} \\underset{\\w}{\\textm{maximize}} & \\dfrac{\\w^\\T\\bmu}{\\sqrt{\\w^\\T\\bSigma\\w}}\\\\ \\textm{subject to} & \\begin{array}[t]{l} \\w^\\T\\bmu \\geq \\beta,\\\\ \\bm{1}^\\T\\w=1, \\quad \\bm{0} \\leq \\w \\leq \\bm{u}. \\end{array} \\end{array} \\] After applying the Schaible transform, the problem simplifies to the QP \\[\\begin{array}{ll} \\underset{\\bm{y}}{\\textm{minimize}} & \\bm{y}^\\T\\bSigma\\bm{y}\\\\ \\textm{subject to} & \\bm{y}^\\T\\bmu \\ge 1,\\\\ & 0 < \\bm{1}^\\T\\bm{y} \\leq \\beta^{-1}, \\quad \\bm{0} \\leq \\bm{y} \\leq \\bm{u} \\cdot \\left(\\bm{1}^\\T\\bm{y}\\right), \\end{array} \\] from which the portfolio is obtained as \\(\\w = \\bm{y}/\\left(\\bm{1}^\\T\\bm{y}\\right)\\). Example 7.3 (MSRP with shorting and return constraint) Consider the MSRP formulation with minimum return \\(\\beta>0\\) and with shorting allowed: \\[\\begin{array}{ll} \\underset{\\w}{\\textm{maximize}} & \\dfrac{\\w^\\T\\bmu}{\\sqrt{\\w^\\T\\bSigma\\w}}\\\\ \\textm{subject to} & \\begin{array}[t]{l} \\w^\\T\\bmu \\geq \\beta\\\\ \\|\\w\\|_1=1. \\end{array} \\end{array} \\] After applying the Schaible transform, the problem simplifies to the QP \\[\\begin{array}{ll} \\underset{\\bm{y}}{\\textm{minimize}} & \\bm{y}^\\T\\bSigma\\bm{y}\\\\ \\textm{subject to} & \\bm{y}^\\T\\bmu \\ge 1\\\\ & 0 < \\|\\bm{y}\\|_1 \\leq \\beta^{-1}, \\end{array} \\] from which the portfolio is obtained as \\(\\w = \\bm{y}/\\|\\bm{y}\\|_1\\)."
    }
]