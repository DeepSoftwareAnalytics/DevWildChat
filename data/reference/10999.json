[
    {
        "link": "https://docs.python.org/3/library/math.html",
        "document": "This module provides access to the mathematical functions defined by the C standard.\n\nThese functions cannot be used with complex numbers; use the functions of the same name from the module if you require support for complex numbers. The distinction between functions which support complex numbers and those which don’t is made since most users do not want to learn quite as much mathematics as required to understand complex numbers. Receiving an exception instead of a complex result allows earlier detection of the unexpected complex number used as a parameter, so that the programmer can determine how and why it was generated in the first place.\n\nThe following functions are provided by this module. Except when explicitly noted otherwise, all return values are floats.\n\nReturn the number of ways to choose k items from n items without repetition and without order. Evaluates to when and evaluates to zero when . Also called the binomial coefficient because it is equivalent to the coefficient of k-th term in polynomial expansion of . Raises if either of the arguments are not integers. Raises if either of the arguments are negative. Return n factorial as an integer. Raises if n is not integral or is negative. Changed in version 3.10: Floats with integral values (like ) are no longer accepted. Return the greatest common divisor of the specified integer arguments. If any of the arguments is nonzero, then the returned value is the largest positive integer that is a divisor of all arguments. If all arguments are zero, then the returned value is . without arguments returns . Changed in version 3.9: Added support for an arbitrary number of arguments. Formerly, only two arguments were supported. Return the integer square root of the nonnegative integer n. This is the floor of the exact square root of n, or equivalently the greatest integer a such that a² ≤ n. For some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using . Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is . without arguments returns . Return the number of ways to choose k items from n items without repetition and with order. Evaluates to when and evaluates to zero when . If k is not specified or is , then k defaults to n and the function returns . Raises if either of the arguments are not integers. Raises if either of the arguments are negative.\n\nReturn the ceiling of x, the smallest integer greater than or equal to x. If x is not a float, delegates to , which should return an value. Return the absolute value of x. Return the floor of x, the largest integer less than or equal to x. If x is not a float, delegates to , which should return an value. Fused multiply-add operation. Return , computed as though with infinite precision and range followed by a single round to the format. This operation often provides better accuracy than the direct expression . This function follows the specification of the fusedMultiplyAdd operation described in the IEEE 754 standard. The standard leaves one case implementation-defined, namely the result of and . In these cases, returns a NaN, and does not raise any exception. Return the floating-point remainder of , as defined by the platform C library function . Note that the Python expression may not return the same result. The intent of the C standard is that be exactly (mathematically; to infinite precision) equal to for some integer n such that the result has the same sign as x and magnitude less than . Python’s returns a result with the sign of y instead, and may not be exactly computable for float arguments. For example, is , but the result of Python’s is , which cannot be represented exactly as a float, and rounds to the surprising . For this reason, function is generally preferred when working with floats, while Python’s is preferred when working with integers. Return the fractional and integer parts of x. Both results carry the sign of x and are floats. Note that has a different call/return pattern than its C equivalents: it takes a single argument and return a pair of values, rather than returning its second return value through an ‘output parameter’ (there is no such thing in Python). Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference , where is the closest integer to the exact value of the quotient . If is exactly halfway between two consecutive integers, the nearest even integer is used for . The remainder thus always satisfies . Special cases follow IEEE 754: in particular, is x for any finite x, and and raise for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating point, the result of this operation is always exactly representable: no rounding error is introduced. Return x with the fractional part removed, leaving the integer part. This rounds toward 0: is equivalent to for positive x, and equivalent to for negative x. If x is not a float, delegates to , which should return an value. For the , , and functions, note that all floating-point numbers of sufficiently large magnitude are exact integers. Python floats typically carry no more than 53 bits of precision (the same as the platform C double type), in which case any float x with necessarily has no fractional bits.\n\nReturn a float with the magnitude (absolute value) of x but the sign of y. On platforms that support signed zeros, returns -1.0. Return the mantissa and exponent of x as the pair . m is a float and e is an integer such that exactly. If x is zero, returns , otherwise . This is used to “pick apart” the internal representation of a float in a portable way. Note that has a different call/return pattern than its C equivalents: it takes a single argument and return a pair of values, rather than returning its second return value through an ‘output parameter’ (there is no such thing in Python). Return if the values a and b are close to each other and otherwise. Whether or not two values are considered close is determined according to given absolute and relative tolerances. If no errors occur, the result will be: . rel_tol is the relative tolerance – it is the maximum allowed difference between a and b, relative to the larger absolute value of a or b. For example, to set a tolerance of 5%, pass . The default tolerance is , which assures that the two values are the same within about 9 decimal digits. rel_tol must be nonnegative and less than . abs_tol is the absolute tolerance; it defaults to and it must be nonnegative. When comparing to , is computed as , which is for any nonzero and rel_tol less than . So add an appropriate positive abs_tol argument to the call. The IEEE 754 special values of , , and will be handled according to IEEE rules. Specifically, is not considered close to any other value, including . and are only considered close to themselves. Return if x is neither an infinity nor a NaN, and otherwise. (Note that is considered finite.) Return if x is a positive or negative infinity, and otherwise. Return if x is a NaN (not a number), and otherwise. Return . This is essentially the inverse of function . Return the floating-point value steps steps after x towards y. If x is equal to y, return y, unless steps is zero.\n• None goes up: towards positive infinity.\n• None goes down: towards minus infinity.\n• None goes towards zero.\n• None goes away from zero. Return the value of the least significant bit of the float x:\n• None If x is a NaN (not a number), return x.\n• None If x is equal to zero, return the smallest positive denormalized representable float (smaller than the minimum positive normalized float, ).\n• None If x is equal to the largest positive representable float, return the value of the least significant bit of x, such that the first float smaller than x is .\n• None Otherwise (x is a positive finite number), return the value of the least significant bit of x, such that the first float bigger than x is . ULP stands for “Unit in the Last Place”. See also and .\n\nReturn e raised to the power x, where e = 2.718281… is the base of natural logarithms. This is usually more accurate than or . Return e raised to the power x, minus 1. Here e is the base of natural logarithms. For small floats x, the subtraction in can result in a significant loss of precision; the function provides a way to compute this quantity to full precision: With one argument, return the natural logarithm of x (to base e). With two arguments, return the logarithm of x to the given base, calculated as . Return the natural logarithm of 1+x (base e). The result is calculated in a way which is accurate for x near zero. Return the base-2 logarithm of x. This is usually more accurate than . returns the number of bits necessary to represent an integer in binary, excluding the sign and leading zeros. Return the base-10 logarithm of x. This is usually more accurate than . Return x raised to the power y. Exceptional cases follow the IEEE 754 standard as far as possible. In particular, and always return , even when x is a zero or a NaN. If both x and y are finite, x is negative, and y is not an integer then is undefined, and raises . Unlike the built-in operator, converts both its arguments to type . Use or the built-in function for computing exact integer powers. Changed in version 3.11: The special cases and were changed to return instead of raising , for consistency with IEEE 754.\n\nReturn the Euclidean distance between two points p and q, each given as a sequence (or iterable) of coordinates. The two points must have the same dimension. Return an accurate floating-point sum of values in the iterable. Avoids loss of precision by tracking multiple intermediate partial sums. The algorithm’s accuracy depends on IEEE-754 arithmetic guarantees and the typical case where the rounding mode is half-even. On some non-Windows builds, the underlying C library uses extended precision addition and may occasionally double-round an intermediate sum causing it to be off in its least significant bit. For further discussion and two alternative approaches, see the ASPN cookbook recipes for accurate floating-point summation. Return the Euclidean norm, . This is the length of the vector from the origin to the point given by the coordinates. For a two dimensional point , this is equivalent to computing the hypotenuse of a right triangle using the Pythagorean theorem, . Changed in version 3.8: Added support for n-dimensional points. Formerly, only the two dimensional case was supported. Changed in version 3.10: Improved the algorithm’s accuracy so that the maximum error is under 1 ulp (unit in the last place). More typically, the result is almost always correctly rounded to within 1/2 ulp. Calculate the product of all the elements in the input iterable. The default start value for the product is . When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. Return the sum of products of values from two iterables p and q. Raises if the inputs do not have the same length. For float and mixed int/float inputs, the intermediate products and sums are computed with extended precision.\n\nThe mathematical constant π = 3.141592…, to available precision. The mathematical constant e = 2.718281…, to available precision. The mathematical constant τ = 6.283185…, to available precision. Tau is a circle constant equal to 2π, the ratio of a circle’s circumference to its radius. To learn more about Tau, check out Vi Hart’s video Pi is (still) Wrong, and start celebrating Tau day by eating twice as much pie! A floating-point positive infinity. (For negative infinity, use .) Equivalent to the output of . A floating-point “not a number” (NaN) value. Equivalent to the output of . Due to the requirements of the IEEE-754 standard, and are not considered to equal to any other numeric value, including themselves. To check whether a number is a NaN, use the function to test for NaNs instead of or . Example: Changed in version 3.11: It is now always available. CPython implementation detail: The module consists mostly of thin wrappers around the platform C math library functions. Behavior in exceptional cases follows Annex F of the C99 standard where appropriate. The current implementation will raise for invalid operations like or (where C99 Annex F recommends signaling invalid operation or divide-by-zero), and for results that overflow (for example, ). A NaN will not be returned from any of the functions above unless one or more of the input arguments was a NaN; in that case, most functions will return a NaN, but (again following C99 Annex F) there are some exceptions to this rule, for example or . Note that Python makes no effort to distinguish signaling NaNs from quiet NaNs, and behavior for signaling NaNs remains unspecified. Typical behavior is to treat all NaNs as though they were quiet. Complex number versions of many of these functions."
    },
    {
        "link": "https://geeksforgeeks.org/python-math-cos-function",
        "document": "math.cos() function in Python is part of the built-in math module, which provides access to mathematical functions. The math.cos() function is used to calculate the cosine of an angle, which is a fundamental trigonometric function widely used in various fields like physics, engineering and computer graphics.\n• None This code calculates the cosine of the angle pi/6 using Python’s math.cos() function.\n• None math.cos(a) computes the cosine of the angle a (which is pi/6 radians).\n• x: This parameter represents the angle in radians for which the cosine value is to be calculated.\n\nThe math.cos() function returns the cosine of the given angle in radians. The value will always be between -1 and 1, inclusive.\n\nThis example calculates the cosine of several angles ranging from 0 to 2π (full circle) in steps of π/4.\n• None This code calculates the cosine for angles 0, π/4, π/2, π, 3π/2, and 2π.\n• None It prints the cosine value for each angle."
    },
    {
        "link": "https://docs.scipy.org/doc/scipy/tutorial/interpolate.html",
        "document": "There are several general facilities available in SciPy for interpolation and smoothing for data in 1, 2, and higher dimensions. The choice of a specific interpolation routine depends on the data: whether it is one-dimensional, is given on a structured grid, or is unstructured. One other factor is the desired smoothness of the interpolator. In short, routines recommended for interpolation can be summarized as follows:"
    },
    {
        "link": "https://southampton.ac.uk/~fangohr/teaching/python/book/html/16-scipy.html",
        "document": "The core Python language (including the standard libraries) provide enough functionality to carry out computational research tasks. However, there are dedicated (third-party) Python libraries that provide extended functionality which\n• None which are convenient to use\n• None and are more efficient in terms of CPU time and memory requirements than using the code Python functionality alone. We list three such modules in particular:\n• None The module provides a data type specialised for “number crunching” of vectors and matrices (this is the type provided by “ ” as introduced in 14-numpy.ipynb), and linear algebra tools.\n• None The package (also knows as ) provides plotting and visualisation capabilities (see 15-visualising-data.ipynb) and the\n• None package (SCIentific PYthon) which provides a multitude of numerical algorithms and which is introduced in this chapter. Many of the numerical algorithms available through and are provided by established compiled libraries which are often written in Fortran or C. They will thus execute much faster than pure Python code (which is interpreted). As a rule of thumb, we expect compiled code to be two orders of magnitude faster than pure Python code. You can use the help function for each numerical method to find out more about the source of the implementation. is built on . All functionality from seems to be available in as well. For example, instead of\n\nOften we need to find the maximum or minimum of a particular function f(x) where f is a scalar function but x could be a vector. Typical applications are the minimisation of entities such as cost, risk and error, or the maximisation of productivity, efficiency and profit. Optimisation routines typically provide a method to minimise a given function: if we need to maximise f(x) we create a new function g(x) that reverses the sign of f, i.e. g(x)= − f(x) and we minimise g(x). Below, we provide an example showing (i) the definition of the test function and (ii) the call of the function which takes as argument a function f to minimise and an initial value x from which to start the search for the minimum, and which returns the value of x for which f(x) is (locally) minimised. Typically, the search for the minimum is a local search, i.e. the algorithm follows the local gradient. We repeat the search for the minimum for two values (x = 1.0 and x = 2.0, respectively) to demonstrate that depending on the starting value we may find different minimar of the function f. The majority of the commands (after the two calls to ) in the file creates the plot of the function, the start points for the searches and the minima obtained:"
    },
    {
        "link": "https://machinelearningplus.com/nlp/cosine-similarity",
        "document": "Cosine similarity is a metric used to measure how similar the documents are irrespective of their size. Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space.\n\nThe cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean distance (due to the size of the document), chances are they may still be oriented closer together. The smaller the angle, higher the cosine similarity.\n\nBy the end of this tutorial you will know:\n• What is cosine similarity is and how it works?\n• How to compute cosine similarity of documents in python?\n• What is soft cosine similarity and how its different from cosine similarity?\n• When to use soft cosine similarity and how to compute it in python?\n\nCosine Similarity – Understanding the math and how it works. Photo by Matt Lamers\n\n1. Introduction\n\n 2. What is Cosine Similarity and why is it advantageous?\n\n 3. Cosine Similarity Example\n\n 4. How to Compute Cosine Similarity in Python?\n\n 5. Soft Cosine Similarity 6. Conclusion\n\nA commonly used approach to match similar documents is based on counting the maximum number of common words between the documents.\n\nBut this approach has an inherent flaw.\n\nThat is, as the size of the document increases, the number of common words tend to increase even if the documents talk about different topics. The cosine similarity helps overcome this fundamental flaw in the ‘count-the-common-words’ or Euclidean distance approach.\n\n2. What is Cosine Similarity and why is it advantageous?\n\nCosine similarity is a metric used to determine how similar the documents are irrespective of their size.\n\nMathematically, Cosine similarity measures the cosine of the angle between two vectors projected in a multi-dimensional space.\n\nIn this context, the two vectors I am talking about are arrays containing the word counts of two documents.\n\nAs a similarity metric, how does cosine similarity differ from the number of common words?\n\nWhen plotted on a multi-dimensional space, where each dimension corresponds to a word in the document, the cosine similarity captures the orientation (the angle) of the documents and not the magnitude. If you want the magnitude, compute the Euclidean distance instead.\n\nThe cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean distance because of the size (like, the word ‘cricket’ appeared 50 times in one document and 10 times in another) they could still have a smaller angle between them. Smaller the angle, higher the similarity.\n\nLet’s suppose you have 3 documents based on a couple of star cricket players – Sachin Tendulkar and Dhoni.\n\nTwo of the documents (A) and (B) are from the wikipedia pages on the respective players and the third document (C) is a smaller snippet from Dhoni’s wikipedia page.\n\nAs you can see, all three documents are connected by a common theme – the game of Cricket.\n\nOur objective is to quantitatively estimate the similarity between the documents.\n\nFor ease of understanding, let’s consider only the top 3 common words between the documents: ‘Dhoni’, ‘Sachin’ and ‘Cricket’.\n\nYou would expect and , that is the two documents on Dhoni would have a higher similarity over and , because, is essentially a snippet from itself.\n\nHowever, if we go by the number of common words, the two larger documents will have the most common words and therefore will be judged as most similar, which is exactly what we want to avoid.\n\nThe results would be more congruent when we use the cosine similarity score to assess the similarity.\n\nLet’s project the documents in a 3-dimensional space, where each dimension is a frequency count of either: ‘Sachin’, ‘Dhoni’ or ‘Cricket’. When plotted on this space, the 3 documents would appear something like this.\n\nAs you can see, and the main are oriented closer together in 3-D space, even though they are far apart by magnitiude.\n\nIt turns out, the closer the documents are by angle, the higher is the Cosine Similarity (Cos theta).\n\nAs you include more words from the document, it’s harder to visualize a higher dimensional space. But you can directly compute the cosine similarity using this math formula. Enough with the theory. Let’s compute the cosine similarity with Python’s scikit learn.\n\n4. How to Compute Cosine Similarity in Python?\n\nWe have the following 3 texts:\n\n 1. Doc Trump (A) : Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin.\n\n2. Doc Trump Election (B) : President Trump says Putin had no political interference is the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election.\n\n3. Doc Putin (C) : Post elections, Vladimir Putin became President of Russia.\n\nPresident Putin had served as the Prime Minister earlier in his political career.\n\nSince, Doc B has more in common with Doc A than with Doc C, I would expect the Cosine between A and B to be larger than (C and B).\n\nTo compute the cosine similarity, you need the word count of the words in each document.\n\nThe or the from scikit learn lets us compute this.\n\nThe output of this comes as a .\n\nOn this, am optionally converting it to a pandas dataframe to see the word frequencies in a tabular format.\n\nEven better, I could have used the instead of , because it would have downweighted words that occur frequently across docuemnts.\n\nThen, use to get the final output.\n\nIt can take the document term matrix as a pandas dataframe as well as a sparse matrix as inputs.\n\nSuppose if you have another set of documents on a completely different topic, say ‘food’, you want a similarity metric that gives higher scores for documents belonging to the same topic and lower scores when comparing docs from different topics.\n\nIn such case, we need to consider the semantic meaning should be considered.\n\nThat is, words similar in meaning should be treated as similar.\n\nFor Example, ‘President’ vs ‘Prime minister’, ‘Food’ vs ‘Dish’, ‘Hi’ vs ‘Hello’ should be considered similar.\n\nFor this, converting the words into respective word vectors, and then, computing the similarities can address this problem.\n\nTo get the word vectors, you need a word embedding model. Let’s download the model using gensim’s downloader api.\n\nTo compute soft cosines, you need the dictionary (a map of word to unique id), the corpus (word counts) for each sentence and the similarity matrix.\n\nIf you want the soft cosine similarity of 2 documents, you can just call the function\n\nBut, I want to compare the soft cosines for all documents against each other. So, create the soft cosine similarity matrix.\n\nAs one might expect, the similarity scores amongst similar documents are higher (see the red boxes).\n\nNow you should clearly understand the math behind the computation of cosine similarity and how it is advantageous over magnitude based metrics like Euclidean distance.\n\nSoft cosines can be a great feature if you want to use a similarity metric that can help in clustering or classification of documents. If you want to dig in further into natural language processing, the gensim tutorial is highly recommended."
    },
    {
        "link": "https://stackoverflow.com/questions/42147776/producing-2d-perlin-noise-with-numpy",
        "document": "I'm trying to produce 2D perlin noise using numpy, but instead of something smooth I get this :\n\nmy broken perlin noise, with ugly squares everywhere\n\nFor sure, I'm mixing up my dimensions somewhere, probably when I combine the four gradients ... But I can't find it and my brain is melting right now. Anyone can help me pinpoint the problem ?\n\nAnyway, here is the code:"
    },
    {
        "link": "https://github.com/pvigier/perlin-numpy",
        "document": "I wrote two articles on my blog about this project, the first one is about the generation of 2D noise while the second one is about the generation of 3D noise, feel free to read them!\n\nYou can find implementations using numba here.\n\nYou can install this package via:\n\nThe function generates a 2D texture of perlin noise. Its parameters are:\n• : shape of the generated array (tuple of 2 ints)\n• : number of periods of noise to generate along each axis (tuple of 2 ints)\n• : if the noise should be tileable along each axis (tuple of 2 bools)\n\nNote: must be a multiple of\n\nThe function combines several octaves of 2D perlin noise to make 2D fractal noise. Its parameters are:\n• : shape of the generated array (tuple of 2 ints)\n• : number of periods of noise to generate along each axis (tuple of 2 ints)\n• : number of octaves in the noise (int)\n• : if the noise should be tileable along each axis (tuple of 2 bools)\n\nNote: must be a multiple of\n\nThe function generates a 3D texture of perlin noise. Its parameters are:\n• : shape of the generated array (tuple of 3 ints)\n• : number of periods of noise to generate along each axis (tuple of 3 ints)\n• : if the noise should be tileable along each axis (tuple of 3 bools)\n\nNote: must be a multiple of\n\nThe function combines several octaves of 3D perlin noise to make 3D fractal noise. Its parameters are:\n• : shape of the generated array (tuple of 3 ints)\n• : number of periods of noise to generate along each axis (tuple of 3 ints)\n• : number of octaves in the noise (int)\n• : if the noise should be tileable along each axis (tuple of 3 bools)\n\nNote: must be a multiple of"
    },
    {
        "link": "https://rtouti.github.io/graphics/perlin-noise-algorithm",
        "document": "This article is my humble attempt to explain how the algorithm works and how to use it.\n\nIt took me quite some time to understand how the algorithm works and a lot of resources helped me along the way. This is my way to return the favor.\n\nPerlin noise is a popular procedural generation algorithm invented by Ken Perlin. It can be used to generate things like textures and terrain procedurally, meaning without them being manually made by an artist or designer. The algorithm can have 1 or more dimensions, which is basically the number of inputs it gets. In this article, I will use 2 dimensions because it’s easier to visualize than 3 dimensions. There is also a lot of confusion about what Perlin noise is and what it is not. It is often confused with value noise and simplex noise. There is basically 4 type of noise that are similar and that are often confused with one another : classic Perlin noise, improved Perlin noise, simplex noise, and value noise. Improved Perlin noise is an improved version of classic Perlin noise. Simplex noise is different but is also made by Ken Perlin. Value noise is also different. A rule of thumb is that if the noise algorithm uses a (pseudo-)random number generator, it’s probably value noise. This article is about improved Perlin noise.\n\nFirst, how to use it. The algorithm takes as input a certain number of floating point parameters (depending on the dimension) and return a value in a certain range (for Perlin noise, that range is generally said to be between -1.0 and +1.0 but it’s actually a bit different). Let’s say it is in 2 dimensions, so it takes 2 parameters: x and y. Now, x and y can be anything but they are generally a position. To generate a texture, x and y would be the coordinates of the pixels in the texture (multiplied by a small number called the frequency but we will see that at the end). So for texture generation, we would loop through every pixel in the texture, calling the Perlin noise function for each one and decide, based on the return value, what color that pixel would be.\n\nAn example implementation would look like this:\n\nThis code would result in an image like this:\n\nThe above code is in a C++-like language, where as all the rest of the code is in ES6 javascript.\n\nAlso, the code has been written for readability, not performance. It creates a lot of unnecessary temporary Vector2 objects. If you want to use Perlin noise for a real-world project, I recommend using a more standard (and faster) implementation, like Ken Perlin’s reference implementation. You could even use some noise functions that are implemented entirely on the GPU, which is generally much faster than a CPU implementation.\n\nAs you can see, each pixel don’t just have a random color, instead they follow a smooth transition from pixel to pixel and the texture don’t look random at the end. That is because Perlin noise (and other kinds of noise) has this property that if 2 inputs are near each other (e.g. (3.1, 2.5) and (3.11, 2.51)), the results of the noise function will be near each other too.\n\nSo, how does it work?\n\nI’ll give a quick explanation first and explain it in details later:\n\nThe inputs are considered to be on an integer grid (see Figure 2). Each floating point input lies within a square of this grid. For each of the 4 corners of that square, we generate a value. Then we interpolate between those 4 values and we have a final result. The difference between Perlin noise and value noise is how those 4 values are obtained. Where value noise uses a pseudo-random number generator, Perlin noise does a dot product between 2 vectors.\n\nThe first vector is the one pointing from the grid point (the corners) to the input point. The other vector is a constant vector assigned to each grid point (see Figure 3). That one must always be the same for the same grid point, but it can change if you change the seed of the algorithm (we’ll see how in a moment).\n\nAn implementation to get the first vector would look like this:\n\nGenerally, in Perlin noise implementations, the noise will “wrap” after every multiple of 256 (let’s call this number w), meaning it will repeat. That’s because, to give every grid point a constant vector, we’ll soon need something called a permutation table. It’s an array of size w containing all the integers between 0 and w-1 but shuffled (i.e. a permutation). The index for this array (the value between the square brackets [ ]) is X or Y (or a value near them) so it need to be less than 256. The noise “wraps” because if, for example, the input x is 256, X will be equal to 0. This 0 will be used to index the permutation table and then to generate a random vector. Since X is 0 at every multiple of 256, the random vector will be the same at all those points, so the noise repeats. You can if you want have a larger permutation table (say, of size 512) and in that case the noise would wrap at every multiple of 512.\n\nThe thing is, that’s just the technique used by Ken Perlin to get those constant vectors for each corner point. You can absolutely use another way, and you would maybe not have the limitation of the wrapping. You could for example use a pseudo random number generator to generate the constant vectors, but in this case you would probably fair better by just using value noise.\n\nWe first create the permutation table and shuffle it. I’ll show you the code and I’ll explain just after:\n\nAn example of a shuffle function is given in the complete code at the end of the article.\n\nNext, we need a value from that table for each of the corners. There is a restriction however: a corner must always get the same value, no matter which of the 4 grid cells that has it as a corner contains the input value. For example, if the top-right corner of the grid cell (0, 0) has a value of 42, then the top-left corner of grid cell (1, 0) must also have the same value of 42. It’s the same grid point, so same value no matter from which grid cell it’s calculated:\n\nThe way we selected the values for the corners in the code above respect this restriction. If we are in grid cell (0, 0), “valueBottomRight” will be equal to P[P[0+1]+0] = P[P[1]+0]. Whereas in the grid cell (1, 0), “valueBottomLeft” will be equal to P[P[1]+0]. “valueBottomRight” and “valueBottomLeft” are the same. The restriction is respected.\n\nWe also want to double the table for the noise to wrap at each multiple of 256. If we are computing P[X+1] and X is 255 (so X+1 is 256), we would get an overflow if we didn’t double the array because the max index of a size 256 array is 255. What is important is that we must not double the array and then shuffle it. Instead, we must shuffle it and then double it. In the example of P[X+1] where X is 255, we want P[X+1] to have the same value as P[0] so the noise can wrap.\n\nNow is the time to get those constant vectors. Ken Perlin’s original implementation used a strange function called “grad” that calculated the dot product for each corner directly. We are gonna make things simpler by creating a function that just returns the constant vector given a certain value from the permutation table and calculate the dot product later.\n\nAlso, since it’s easier to generate them, those constant vectors can be 1 of 4 different vectors: (1.0, 1.0), (1.0, -1.0), (-1.0, -1.0) and (-1.0, 1.0).\n\nTo find the constant vectors given a value from a permutation table, we can do something like that:\n\nSince v is between 0 and 255 and we have 4 possible vectors, we can do a & 3 (equivalent to % 4) to get 4 possible values of h (0, 1, 2 and 3). Depending of that value, we return one of the possible vectors.\n\nWe can now calculate the dot products:\n\nNow that we have to dot product for each corner, we need to somehow mix them to get a single value. For this, we’ll use interpolation. Interpolation is a way to find what value lies between 2 other values (say, a1 and a2), given some other value t between 0.0 and 1.0 (a percentage basically, where 0.0 is 0% and 1.0 is 100%). For example: if a1 is 10, a2 is 20 and t is 0.5 (so 50%), the interpolated value would be 15 because it’s midway between 10 and 20 (50% or 0.5). Another example: a1=50, a2=100 and t=0.4. Then the interpolated value would be at 40% of the way between 50 and 100, that is 70. This is called linear interpolation because the interpolated values are in a linear curve.\n\nNow we have 4 values that we need to interpolate but we can only interpolate 2 values at a time. So to way we use interpolation for Perlin noise is that we interpolate the values of top-left and bottom-left together to get a value we’ll call v1. After that we do the same for top-right and bottom-right to get v2. Then finally we interpolate between v1 and v2 to get a final value. This is the value we want our noise function to return.\n\nNote that if we change the input point just a little bit, the vectors between each corner and the input point will change just a little bit too, whereas the constant vector will not change at all. The dot products will also change just a little bit, and so will the final value return by the noise function. Even if the input changes grid square, like from (3.01, 2.01) to (2.99, 1.99), the final values will still be very close because even if 2 (or 3) of the corners change, the other 2 (or 1) would not and since with both inputs we are close to the corner(s), interpolation will cause the final value to be really close to that of the corner(s). Since with both inputs that corner will have the same value, the final results will be really close.\n\nHere is the code for a function that does linear interpolation (also called lerp):\n\nWe could use linear interpolation but that would not give great results because it would feel unnatural, like in this image that shows 1 dimensional linear interpolation :\n\n[Figure 4] The abrupt transition that results from linear interpolation\n\nAs you can see, the change between what is inferior to 1 and what is superior to 1 is abrupt. What we want is something smoother, like this:\n\n[Figure 5] The smooth transition that results from non-linear interpolation\n\n[Figure 6] The smooth transition between the corners of a grid square\n\nWith linear interpolation, we would use xf as an interpolation value (t). Instead we are going to transform xf and yf into u and v. We will do it in a way that, given a value of t between 0.0 and 0.5 (excluded), the transformed value will be something a little bit smaller (but capped at 0.0). Also, given a value of t between 0.5 (excluded) and 1.0, the transformed value would be a little larger (but capped at 1.0). For 0.5, the transformed value should be 0.5. Doing this will result in a curvy transition, like in figures 5 and 6.\n\nTo do this, we need something called an ease curve: it’s just a mathematical curve that looks like this:\n\nIf you look closely, you can see that for an input (xf or yf, the x axis) between 0.0 and 0.5, the output (u or v, the y axis) is a little bit closer to 0.0. And for a value between 0.5 and 1.0, the output is a little bit closer to 1.0. For x=0.5, y=0.5. That will do the work perfectly.\n\nThe curve above is the ease function used by Ken Perlin in his implementation of Perlin Noise. The equation is 6t5-15t4+10t3. This is also called a fade function. In code, it looks like that:\n\nNow, we just have to do linear interpolation the way we said before, but with u and v as interpolation values (t). Here is the code:\n\nIf you run the code and try to generate something like a texture, giving to the Noise function the coordinates of it’s pixels, you will probably get a completely black texture.\n\nWhen all the input to the algorithm are integers, say (5,3), the vector from the grid point (5,3) to the input will be the vector (0,0), because the input is also (5,3). The dot product for that grid point will be 0, and since the input lies exactly on that grid point, the interpolation will cause the result to be exactly that dot product, that is, 0. To solve this small issue, we generally multiply the inputs by a small value called the frequency.\n\nHere is an example of Perlin noise for generating a heightmap.\n\nFractal brownian motion is not part of the core Perlin noise algorithm, but it is (as far as I know) almost always used with it. It gives MUCH better results:\n\nSo how does it work?\n\nThe second image doesn’t look good because it is way too smooth, which make it unrealistic. Real life terrain is more noisy.\n\nSo to go from the second image to the first, we need to add some noise, and luckily for us, this is basically what FBM does.\n\nHere is what 1 dimensional Perlin noise might look like with the input x being a real number between 0 and 3, and with a frequency of 1 :\n\nIf we take another curve with an input x between 0 and 3 but use a frequency of 2, it will look like this :\n\nEven though the input is still between 0 and 3, the curve look a lot bumpier because multiplying the input by 2 made it effectively go from 0 to 6. What if we multiplied this curve by some value between 0 and 1 (let’s say 0.5) and added it to the first curve?\n\nWe would get this :\n\nIf we add another of these curves, also doubling the frequency and decreasing the multiplier (which is called the amplitude), we would get something like this :\n\nIf we keep doing this a few more times, we would get this :\n\nThis is exactly what we want. A curve with an overall smooth shape, but with a lot of smaller details. This look like a realistic chain of moutains. If you do this in 2d, it’s exactly how you get the heightmap from Figure 8.\n\nWe just added multiple “layers” of noise together, each with a different amplitude and frequency, and when one layer has a frequency that is double the frequency of the previous layer, this layer is called an octave. Though you will probably often see the term “octave” used more loosely for when the frequency is multiplied by a number other than 2.\n\nThe first octave constitute the overall shape of our chain of mountains. It has a small frequency (so there is not a million moutains) and an amplitude of 1. The second octave will add smaller (so we decrease the amplitude) more noisy details to the mountain range (so we increase the frequency). We can keep doing this - adding smaller and smaller details to the moutains - until we have our final (and beautiful) result.\n\nYou don’t have to worry about the final value exceeding the typical range of Perlin noise because even though we keep adding stuff, those stuff are not all positive, they can also be negative, so it balances out. Also, we keep decreasing the amplitude so we are adding smaller and smaller numbers, which diminishes the chances of overflowing the range. But still, it will happen sometimes.\n\nIn code, it would look something like this:\n\nThere you go. This is Perlin noise in a nutshell. You can use it to generate all kinds of things, from moutains ranges to heightmaps.\n\nHope you liked. Thanks for reading :)"
    },
    {
        "link": "https://docs.godotengine.org/en/stable/tutorials/math/interpolation.html",
        "document": "Interpolation is a common operation in graphics programming, which is used to blend or transition between two values. Interpolation can also be used to smooth movement, rotation, etc. It's good to become familiar with it in order to expand your horizons as a game developer.\n\nThe basic idea is that you want to transition from A to B. A value , represents the states in-between.\n\nFor example, if is 0, then the state is A. If is 1, then the state is B. Anything in-between is an interpolation.\n\nBetween two real (floating-point) numbers, an interpolation can be described as:\n\nAnd often simplified to:\n\nThe name of this type of interpolation, which transforms a value into another at constant speed is \"linear\". So, when you hear about Linear Interpolation, you know they are referring to this formula.\n\nThere are other types of interpolations, which will not be covered here. A recommended read afterwards is the Bezier page.\n\nVector types (Vector2 and Vector3) can also be interpolated, they come with handy functions to do it Vector2.lerp() and Vector3.lerp(). For cubic interpolation, there are also Vector2.cubic_interpolate() and Vector3.cubic_interpolate(), which do a Bezier style interpolation. Here is example pseudo-code for going from point A to B using interpolation: It will produce the following motion:\n\nIt is also possible to interpolate whole transforms (make sure they have either uniform scale or, at least, the same non-uniform scale). For this, the function Transform3D.interpolate_with() can be used. Here is an example of transforming a monkey from Position1 to Position2: Using the following pseudocode: And again, it will produce the following motion:\n\nInterpolation can be used to smoothly follow a moving target value, such as a position or a rotation. Each frame, moves the current value towards the target value by a fixed percentage of the remaining difference between the values. The current value will smoothly move towards the target, slowing down as it gets closer. Here is an example of a circle following the mouse using interpolation smoothing: This is useful for smoothing camera movement, for allies following the player (ensuring they stay within a certain range), and for many other common game patterns. Despite using , the formula used above is framerate-dependent, because the parameter of represents a percentage of the remaining difference in values, not an absolute amount to change. In , this is usually fine because physics is expected to maintain a constant framerate, and therefore is expected to remain constant. For a framerate-independent version of interpolation smoothing that can also be used in , use the following formula instead: Deriving this formula is beyond the scope of this page. For an explanation, see Improved Lerp Smoothing or watch Lerp smoothing is broken."
    },
    {
        "link": "https://docs.pyvista.org/examples/01-filter/sampling_functions_2d",
        "document": "Go to the end to download the full example code.\n\nHere we use to sample Perlin noise over a region to generate random terrain.\n\nPerlin noise is atype of gradient noise often used by visual effects artists to increase the appearance of realism in computer graphics. Source: Perlin Noise Wikipedia\n\nThe development of Perlin Noise has allowed computer graphics artists to better represent the complexity of natural phenomena in visual effects for the motion picture industry."
    },
    {
        "link": "https://medium.com/@yvanscher/playing-with-perlin-noise-generating-realistic-archipelagos-b59f004d8401",
        "document": "In the python noise module there are a few parameters that affect what you see when you generate your perlin noise:\n• scale: number that determines at what distance to view the noisemap.\n• octaves: the number of levels of detail you want you perlin noise to have.\n• lacunarity: number that determines how much detail is added or removed at each octave (adjusts frequency).\n• persistence: number that determines how much each octave contributes to the overall shape (adjusts amplitude).\n\nWe won’t worry about scale too much, you can use it to zoom out (bigger scale) or in (smaller scale).\n\nPerlin noise combines multiple functions called ‘octaves’ to produce natural looking surfaces. Each octave adds a layer of detail to the surface. For example: octave 1 could be mountains, octave 2 could be boulders, octave 3 could be the rocks.\n\nLacunarity of more than 1 means that each octave will increase it’s level of fine grained detail (increased frqeuency). Lacunarity of 1 means that each octave will have the sam level of detail. Lacunarity of less than one means that each octave will get smoother. The last two are usually undesirable so a lacunarity of 2 works quite well.\n\nPersistence determines how much each octave contributes to the overall structure of the noise map. If your persistence is 1 all octaves contribute equally. If you persistence is more than 1 sucessive octaves contribute more and you get something closer to regular noise (spoiler the regular noise image above is actually a perlin noise with a presistence of 5.0). A more default setting would be a presistance of less than 1.0 which will decrease the effect of later octaves.\n\nEnough chatting though! Let’s run some experiments. First let’s start with default perlin noise, and its accompanying image:\n\nThe way this perlin noise looks in our script is a 2D array of values between -1 and 1. The values that are darker on the map are lower values, the values that are close to 1 are lighter. What I want to try next is assigning two colors to different ranges of values in this map to produce some terrain:\n\nThis terrain map is pretty neat; it has jagged coasts, beaches, and lots of water. while I have never observed natural terrain that looks like this if we look at any one part of the map it seems ‘realistic.’ Let’s take it a step further and add mountains and snow:\n\nThis is cool but this terrain pattern is clearly not natural. To make it more natural we will use a circular filter to get rid of all the preipheral perlin noise:\n\nHere I was trying to create an island so I made a circular filter and then applied it to the color_world perlin noise array. What I ended up was a planet floating in an ocean. I changed the ocean color to black and it looks pretty cool! That said what I wanted was an island so let’s try again. This time we’re going to calculate a circular gradient and then apply that over the perlin noise as a filter.\n\nI struggled a lot with this part. I’m sure there is a more efficient way to get the gradient like this but the above was what I came up with. I calculated a distance metric from the center of the map and then normalized, shrunk, and renomalized those distances to produce this spherical gradient. Again lighter means the value is closer to 1, darker colors are closer to 0. Next I apply this circular gradient to the perlin noise we created before.\n\nThis part was less tricky but still a pain. I multiply the perlin noise by the circle gradient and then I increase the contrast by multiplying positive (lighter values) by 20. Then I renormalize to make it 0–1 again.\n\nThis is really cool and it looks like a much more natural archipelago. I encourage you to try different shading methods and maybe randomly removing some sections. I’m going to change the threshold value and set it as . That will produce a smaller but more realistic archipelago as so:\n\nThere we are! We have a natural looking island archipelago! So now that we have our islands you may notice that no matter how often you rerun this script perlin noise will produce the same islands. To get new islands you can set the parameter of the pnoise2 function to a random integer number, let’s try :"
    },
    {
        "link": "https://stackoverflow.com/questions/17779480/python-random-map-generation-with-perlin-noise",
        "document": "Recently, I've been attempting to defeat one of my main weaknesses in programming in general, random generation. I thought it would be an easy thing to do, but the lack of simple information is killing me on it. I don't want to sound dumb, but it feels to me like most of the information from places like this are written for mathematicians who went to college to graduate in theoretical mathematics. I just don't understand what I'm meant to do with that information in order to apply it to programming in a language such as python.\n\nI've been working a few days staring at equations and attempting attempt after attempt, but still after all those days, after ripping my code apart again and again, all that's been working properly this entire time is this noise generator to generate basic noise:\n\nI'm wanting it to eventually produce something like this:\n\nHow can I manage to smooth out the white-noise I generate, and turn it into islands? Can anyone explain it in a very simplistic way for me?\n\nI may be thinking about all of this very wrong."
    },
    {
        "link": "https://reddit.com/r/roguelikedev/comments/127v72s/help_needed_with_perlin_noise_implementation_in",
        "document": "I need help with my code in implementing a simple Perlin noise generator in python for my game's terrain. The output map looks like it's biased along the rows. I think it looks quit wrong. Look below:\n\nAnd here's the mathutils helper script that you would need to run the above:\n\nWhere am I going wrong in the Perlin noise script?"
    },
    {
        "link": "https://stackoverflow.com/questions/2890403/good-perlin-noise-resources-implementation",
        "document": "Are there any good resources out there detailing Perlin noise generation? I understand that most languages have noise generating libraries available, but I'm interested in creating my own for fun/experience. I've already looked at this, which seems pretty popular, but it only gives an in-depth explanation of one dimensional noise. Google searches have been relatively unhelpful so far, as most of them focus on applications instead of how to create a generator.\n\nBooks and/or websites are welcome, even if their focus is not the generation itself so long as it gives a thorough explanation of an implementation, or at least the concepts involved so I can \"discover\" my own."
    },
    {
        "link": "https://softwareengineering.stackexchange.com/questions/278357/weighted-perlin-noise-generation",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    }
]