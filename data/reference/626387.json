[
    {
        "link": "https://requests.readthedocs.io/en/master/user/quickstart",
        "document": "Eager to get started? This page gives a good introduction in how to get started with Requests.\n\nFirst, make sure that:\n\nLet’s get started with some simple examples.\n\nMaking a request with Requests is very simple. Now, let’s try to get a webpage. For this example, let’s get GitHub’s public timeline: Now, we have a object called . We can get all the information we need from this object. Requests’ simple API means that all forms of HTTP request are as obvious. For example, this is how you make an HTTP POST request: Nice, right? What about the other HTTP request types: PUT, DELETE, HEAD and OPTIONS? These are all just as simple: That’s all well and good, but it’s also only the start of what Requests can do.\n\nYou often want to send some sort of data in the URL’s query string. If you were constructing the URL by hand, this data would be given as key/value pairs in the URL after a question mark, e.g. . Requests allows you to provide these arguments as a dictionary of strings, using the keyword argument. As an example, if you wanted to pass and to , you would use the following code: You can see that the URL has been correctly encoded by printing the URL: Note that any dictionary key whose value is will not be added to the URL’s query string. You can also pass a list of items as a value:\n\nWe can read the content of the server’s response. Consider the GitHub timeline again: Requests will automatically decode content from the server. Most unicode charsets are seamlessly decoded. When you make a request, Requests makes educated guesses about the encoding of the response based on the HTTP headers. The text encoding guessed by Requests is used when you access . You can find out what encoding Requests is using, and change it, using the property: If you change the encoding, Requests will use the new value of whenever you call . You might want to do this in any situation where you can apply special logic to work out what the encoding of the content will be. For example, HTML and XML have the ability to specify their encoding in their body. In situations like this, you should use to find the encoding, and then set . This will let you use with the correct encoding. Requests will also use custom encodings in the event that you need them. If you have created your own encoding and registered it with the module, you can simply use the codec name as the value of and Requests will handle the decoding for you.\n\nThere’s also a builtin JSON decoder, in case you’re dealing with JSON data: In case the JSON decoding fails, raises an exception. For example, if the response gets a 204 (No Content), or if the response contains invalid JSON, attempting raises . This wrapper exception provides interoperability for multiple exceptions that may be thrown by different python versions and json serialization libraries. It should be noted that the success of the call to does not indicate the success of the response. Some servers may return a JSON object in a failed response (e.g. error details with HTTP 500). Such JSON will be decoded and returned. To check that a request is successful, use or check is what you expect.\n\nIn the rare case that you’d like to get the raw socket response from the server, you can access . If you want to do this, make sure you set in your initial request. Once you do, you can do this: In general, however, you should use a pattern like this to save what is being streamed to a file: Using will handle a lot of what you would otherwise have to handle when using directly. When streaming a download, the above is the preferred and recommended way to retrieve the content. Note that can be freely adjusted to a number that may better fit your use cases. An important note about using versus . will automatically decode the and transfer-encodings. is a raw stream of bytes – it does not transform the response content. If you really need access to the bytes as they were returned, use .\n\nIf you’d like to add HTTP headers to a request, simply pass in a to the parameter. For example, we didn’t specify our user-agent in the previous example: Note: Custom headers are given less precedence than more specific sources of information. For instance:\n• None Authorization headers set with will be overridden if credentials are specified in , which in turn will be overridden by the parameter. Requests will search for the netrc file at , , or at the path specified by the environment variable.\n• None Authorization headers will be removed if you get redirected off-host.\n• None Proxy-Authorization headers will be overridden by proxy credentials provided in the URL.\n• None Content-Length headers will be overridden when we can determine the length of the content. Furthermore, Requests does not change its behavior at all based on which custom headers are specified. The headers are simply passed on into the final request. Note: All header values must be a , bytestring, or unicode. While permitted, it’s advised to avoid passing unicode header values.\n\nTypically, you want to send some form-encoded data — much like an HTML form. To do this, simply pass a dictionary to the argument. Your dictionary of data will automatically be form-encoded when the request is made: The argument can also have multiple values for each key. This can be done by making either a list of tuples or a dictionary with lists as values. This is particularly useful when the form has multiple elements that use the same key: There are times that you may want to send data that is not form-encoded. If you pass in a instead of a , that data will be posted directly. For example, the GitHub API v3 accepts JSON-Encoded POST/PATCH data: Please note that the above code will NOT add the header (so in particular it will NOT set it to ). If you need that header set and you don’t want to encode the yourself, you can also pass it directly using the parameter (added in version 2.4.2) and it will be encoded automatically: Note, the parameter is ignored if either or is passed.\n\nYou can set the filename, content_type and headers explicitly: If you want, you can send strings to be received as files: In the event you are posting a very large file as a request, you may want to stream the request. By default, does not support this, but there is a separate package which does - . You should read the toolbelt’s documentation for more details about how to use it. For sending multiple files in one request refer to the advanced section. It is strongly recommended that you open files in binary mode. This is because Requests may attempt to provide the header for you, and if it does this value will be set to the number of bytes in the file. Errors may occur if you open the file in text mode.\n\nWe can view the server’s response headers using a Python dictionary: The dictionary is special, though: it’s made just for HTTP headers. According to RFC 7230, HTTP Header names are case-insensitive. So, we can access the headers using any capitalization we want: It is also special in that the server could have sent the same header multiple times with different values, but requests combines them so they can be represented in the dictionary within a single mapping, as per RFC 7230: A recipient MAY combine multiple header fields with the same field name into one “field-name: field-value” pair, without changing the semantics of the message, by appending each subsequent field value to the combined field value in order, separated by a comma.\n\nYou can tell Requests to stop waiting for a response after a given number of seconds with the parameter. Nearly all production code should use this parameter in nearly all requests. Failure to do so can cause your program to hang indefinitely: is not a time limit on the entire response download; rather, an exception is raised if the server has not issued a response for seconds (more precisely, if no bytes have been received on the underlying socket for seconds). If no timeout is specified explicitly, requests do not time out.\n\nIn the event of a network problem (e.g. DNS failure, refused connection, etc), Requests will raise a exception. will raise an if the HTTP request returned an unsuccessful status code. If a request times out, a exception is raised. If a request exceeds the configured number of maximum redirections, a exception is raised. All exceptions that Requests explicitly raises inherit from . Ready for more? Check out the advanced section."
    },
    {
        "link": "https://requests.readthedocs.io",
        "document": "Requests is an elegant and simple HTTP library for Python, built for human beings.\n\nRequests allows you to send HTTP/1.1 requests extremely easily. There’s no need to manually add query strings to your URLs, or to form-encode your POST data. Keep-alive and HTTP connection pooling are 100% automatic, thanks to urllib3."
    },
    {
        "link": "https://realpython.com/python-requests",
        "document": "The Requests library is the de facto standard for making HTTP requests in Python. It abstracts the complexities of making requests behind a beautiful, simple API so that you can focus on interacting with services and consuming data in your application.\n\nThroughout this tutorial, you’ll see some of the most useful features that Requests has to offer as well as ways to customize and optimize those features for different situations that you may come across. You’ll also learn how to use Requests in an efficient way as well as how to prevent requests to external services from slowing down your application.\n\nIn this tutorial, you’ll learn how to:\n• Make requests using the most common HTTP methods\n• Customize your requests’ headers and data using the query string and message body\n• Inspect data from your requests and responses\n• Configure your requests to help prevent your application from backing up or slowing down\n\nFor the best experience working through this tutorial, you should have basic general knowledge of HTTP. That said, you still may be able to follow along fine without it.\n\nIn the upcoming sections, you’ll see how you can install and use in your application. If you want to play with the code examples that you’ll see in this tutorial, as well as some additional ones, then you can download the code examples and work with them locally:\n\nEven though the Requests library is a common staple for many Python developers, it’s not included in Python’s standard library. There are good reasons for that decision, primarily that the library can continue to evolve more freely as a self-standing project. Note: Requests doesn’t support asynchronous HTTP requests directly. If you need async support in your program, you should try out AIOHTTP or HTTPX. The latter library is broadly compatible with Requests’ syntax. Because Requests is a third-party library, you need to install it before you can use it in your code. As a good practice, you should install external packages into a virtual environment, but you may choose to install into your global environment if you’re planning to use it across multiple projects. Whether you’re working in a virtual environment or not, you’ll need to install : Once has finished installing , you can use it in your application. Importing looks like this: Now that you’re all set up, it’s time to begin your journey through Requests. Your first goal will be learning how to make a request.\n\nA is a powerful object for inspecting the results of the request. Make that same request again, but this time store the return value in a variable so that you can get a closer look at its attributes and behaviors: In this example, you’ve captured the return value of , which is an instance of , and stored it in a variable called . You can now use to see a lot of information about the results of your request. The first bit of information that you can gather from is the status code. A status code informs you of the status of the request. For example, a status means that your request was successful, whereas a status means that the resource you were looking for wasn’t found. There are many other possible status codes as well to give you specific insights into what happened with your request. By accessing , you can see the status code that the server returned: returned , which means that your request was successful and the server responded with the data that you were requesting. Sometimes, you might want to use this information to make decisions in your code: With this logic, if the server returns a status code, then your program will print . If the result is a , then your program will print . Requests goes one step further in simplifying this process for you. If you use a instance in a conditional expression, then it’ll evaluate to if the status code was smaller than , and otherwise. Therefore, you can simplify the last example by rewriting the statement: In the code snippet above, you implicitly check whether the of is between and . If it’s not, then you raise an exception that includes the non-success status code in an f-string. Note: This truth value test is possible because is an overloaded method on . This means that the adapted default behavior of takes the status code into account when determining the truth value of the object. Keep in mind that this method is not verifying that the status code is equal to . The reason for this is that other status codes within the to range, such as and , are also considered successful in the sense that they provide some workable response. For example, the status code tells you that the response was successful, but there’s no content to return in the message body. So, make sure you use this convenient shorthand only if you want to know if the request was generally successful. Then, if necessary, you’ll need to handle the response appropriately based on the status code. Let’s say you don’t want to check the response’s status code in an statement. Instead, you want to use Request’s built-in capacities to raise an exception if the request was unsuccessful. You can do this using : If you invoke , then Requests will raise an for status codes between and . If the status code indicates a successful request, then the program will proceed without raising that exception. Now, you know a lot about how to deal with the status code of the response that you got back from the server. However, when you make a request, you rarely only care about the status code of the response. Usually, you want to see more. Next, you’ll see how to view the actual data that the server sent back in the body of the response. The response of a request often has some valuable information, known as a payload, in the message body. Using the attributes and methods of , you can view the payload in a variety of different formats. To see the response’s content in , you use : While gives you access to the raw bytes of the response payload, you’ll often want to convert them into a string using a character encoding such as UTF-8. will do that for you when you access : Because the decoding of to a requires an encoding scheme, Requests will try to guess the encoding based on the response’s headers if you don’t specify one. You can provide an explicit encoding by setting before accessing : If you take a look at the response, then you’ll see that it’s actually serialized JSON content. To get a dictionary, you could take the that you retrieved from and deserialize it using . However, a simpler way to accomplish this task is to use : The of the return value of is a dictionary, so you can access values in the object by key: You can do a lot with status codes and message bodies. But, if you need more information, like metadata about the response itself, then you’ll need to look at the response’s headers. The response headers can give you useful information, such as the content type of the response payload and a time limit on how long to cache the response. To view these headers, access : returns a dictionary-like object, allowing you to access header values by key. For example, to see the content type of the response payload, you can access : There’s something special about this dictionary-like headers object, though. The HTTP specification defines headers as case-insensitive, which means that you’re able to access these headers without worrying about their capitalization: Whether you use the key or , you’ll get the same value. Now that you’ve seen the most useful attributes and methods of in action, you already have a good overview of Requests’ basic usage. You can get content from the Internet and work with the response that you receive. But there’s more to the Internet than plain and straightforward URLs. In the next section, you’ll take a step back and see how your responses change when you customize your requests to account for query string parameters.\n\nAccording to the HTTP specification, , , and the less common requests pass their data through the message body rather than through parameters in the query string. Using Requests, you’ll pass the payload to the corresponding function’s parameter. takes a dictionary, a list of tuples, bytes, or a file-like object. You’ll want to adapt the data that send in the body of your request to the specific needs of the service that you’re interacting with. For example, if your request’s content type is , then you can send the form data as a dictionary: You can also send that same data as a list of tuples: If, however, you need to send JSON data, then you can use the parameter. When you pass JSON data via , Requests will serialize your data and add the correct header for you. Like you learned earlier, the httpbin service accepts test requests and responds with data about the requests. For instance, you can use it to inspect a basic request: You can see from the response that the server received your request data and headers as you sent them. Requests also provides this information to you in the form of a that you’ll inspect in more detail in the next section.\n\nAuthentication helps a service understand who you are. Typically, you provide your credentials to a server by passing data through the header or a custom header defined by the service. All the functions of Requests that you’ve seen to this point provide a parameter called , which allows you to pass your credentials: The request succeeds if the credentials that you pass in the tuple to are valid. When you pass your credentials in a tuple to the parameter, Requests applies the credentials using HTTP’s Basic access authentication scheme under the hood. You may wonder where the string that Requests set as the value for your header comes from. In short, it’s a Base64-encoded string of the username and password with the prefix :\n• First, Requests combines the username and password that you provided, putting a colon in between them. So for the username and password , this becomes .\n• Then, Requests encodes this string in Base64 using . The encoding converts the string to .\n• Finally, Requests adds in front of this Base64 string. This is how the final value for the header becomes in the example shown above. HTTP Basic authentication isn’t very secure, because you can decode the username and password from the Base64 string. That’s why it’s important to always send these requests over HTTPS, which provides an additional layer of security by encrypting the entire HTTP request. You could make the same request by passing explicit Basic authentication credentials using : Though you don’t need to be explicit for Basic authentication, you may want to authenticate using another method. Requests provides other methods of authentication out of the box, such as and . A real-world example of an API that requires authentication is GitHub’s authenticated user API. This endpoint provides information about the authenticated user’s profile. If you try to make a request without credentials, then you’ll see that the status code is : If you don’t provide authentication credentials when accessing a service that requires them, then you’ll get an HTTP error code as a response. To make a request to GitHub’s authenticated user API, you first need to generate a personal access token with the read:user scope. Then you can pass this token as the second element in a tuple to : Like you learned previously, this approach passes the credentials to , which expects a username and a password and sends the credentials as a Base64-encoded string with the prefix : This works, but it’s not the right way to authenticate with a Bearer token—and using an empty string input for the superfluous username is awkward. With Requests, you can supply your own authentication mechanism to fix that. To try this out, create a subclass of and implement : \"\"\"Attach an API token to the Authorization header.\"\"\" Here, your custom mechanism receives a token, then includes that token in the header of your request, also setting the recommended prefix to the string. You can now use this custom token authentication to make your call to GitHub’s authenticated user API: Your custom created a well-formatted string for the header. You can now use this more intuitive way of interacting with a token-based authentication scheme such as the one that parts of GitHub’s API require. Note: While you could construct the authentication string outside of a custom authentication class and pass it directly with , this appoach is discouraged because it can lead to unexpected behavior. When you attempt to set your authentication credentials directly using , then Requests may internally overwrite your input. This can happen, for example, if you have a file that provides authentication credentials. Requests will attempt to get the credentials from the file if you don’t provide an authentication method using . Bad authentication mechanisms can lead to security vulnerabilities. Unless a service requires a custom authentication mechanism for some reason, you’ll always want to use a tried-and-true auth scheme like the built-in Basic authentication or OAuth, for example through Requests-OAuthlib. While you’re thinking about security, consider dealing with SSL certificates using Requests.\n\nAnytime the data that you’re trying to send or receive is sensitive, security is important. The way that you communicate with secure sites over HTTP is by establishing an encrypted connection using SSL, which means that verifying the target server’s SSL certificate is critical. The good news is that Requests does this for you by default. However, there are some cases where you might want to change this behavior. If you want to disable SSL certificate verification, then you pass to the parameter of the request function: InsecureRequestWarning: Unverified HTTPS request is being made to host Requests even warns you when you’re making an insecure request to help you keep your data safe! Note: Requests uses a package called to provide certificate authorities. This lets Requests know which authorities it can trust. Therefore, you should update frequently to keep your connections as secure as possible. Now that you know how to make all sorts of HTTP requests using Requests, authenticated or not, you may wonder about how you can make sure that your program works as quickly as possible. In the next section, you’ll learn about a few ways that you can improve performance with the help of Requests.\n\nWhen using Requests, especially in a production application environment, it’s important to consider performance implications. Features like timeout control, sessions, and retry limits can help you keep your application running smoothly. When you make an inline request to an external service, your system will need to wait for the response before moving on. If your application waits too long for that response, requests to your service could back up, your user experience could suffer, or your background jobs could hang. By default, Requests will wait indefinitely on the response, so you should almost always specify a timeout duration to prevent these issues from happening. To set the request’s timeout, use the parameter. can be an integer or float representing the number of seconds to wait on a response before timing out: In the first request, the request will time out after 1 second. In the second request, the request will time out after 3.05 seconds. You can also pass a tuple to with the following two elements:\n• Connect timeout: The time it allows for the client to establish a connection to the server\n• Read timeout: The time it’ll wait on a response once your client has established a connection Both of these elements should be numbers, and can be of type or : If the request establishes a connection within 3.05 seconds and receives data within 5 seconds of the connection being established, then the response will be returned as it was before. If the request times out, then the function will raise a exception: \"The request did not time out\" Your program can catch the exception and respond accordingly. Until now, you’ve been dealing with high-level APIs such as and . These functions are abstractions of what’s going on when you make your requests. They hide implementation details, such as how connections are managed, so that you don’t have to worry about them. Underneath those abstractions is a class called . If you need to fine-tune your control over how requests are being made or improve the performance of your requests, you may need to use a instance directly. Sessions are used to persist parameters across requests. For example, if you want to use the same authentication across multiple requests, then you can use a session: In this code example, you use a context manager to ensure that the session releases the resources when it doesn’t need them anymore. In line 7, you log in using your custom . You only need to log in once per session, and then you can make multiple authenticated requests. Requests will persist the credentials while the session exists. You then make two requests to the authenticated user API in lines 9 and 10 using instead of . The primary performance optimization of sessions comes in the form of persistent connections. When your app makes a connection to a server using a , it keeps that connection around in a connection pool. When your app wants to connect to the same server again, it’ll reuse a connection from the pool rather than establishing a new one. When a request fails, you may want your application to retry the same request. However, Requests won’t do this for you by default. To apply this functionality, you need to implement a custom transport adapter. Transport adapters let you define a set of configurations for each service that you’re interacting with. For example, say you want all requests to to retry two times before finally raising a . You’d build a transport adapter, set its parameter, and mount it to an existing : In this example, you’ve set up your session so that it’ll retry a maximum of two times when your request to GitHub’s API doesn’t work as expected. When you mount the —in this case, —to , then will adhere to its configuration for each request to . Note: While the implementation shown above works, you won’t see any effect of the retry behavior unless there’s something wrong with your network connection or GitHub’s servers. If you want to play around with code that builds on top of this example, and you’d like to inspect when the retries happen, then you’re in luck. You can download the materials of this tutorial and take a look at : Get Your Code: Click here to download the free sample code that shows you how to use Python’s Requests library. The code in this file improves on the example shown above by using the underlying to further customize the retry functionality. It also adds logging to display debugging output, which gives you a chance to monitor when Python attempted the retries. Requests comes packaged with intuitive implementations for timeouts, transport adapters, and sessions that can help you keep your code efficient and your application resilient."
    },
    {
        "link": "https://docs.python.org/3/library/json.html",
        "document": "JSON (JavaScript Object Notation), specified by RFC 7159 (which obsoletes RFC 4627) and by ECMA-404, is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript ).\n\nexposes an API familiar to users of the standard library and modules.\n\nUsing from the shell to validate and pretty-print:\n\nSerialize obj as a JSON formatted stream to fp (a -supporting file-like object) using this Python-to-JSON conversion table. Unlike and , JSON is not a framed protocol, so trying to serialize multiple objects with repeated calls to using the same fp will result in an invalid JSON file.\n• None obj (object) – The Python object to be serialized.\n• None fp (file-like object) – The file-like object obj will be serialized to. The module always produces objects, not objects, therefore must support input.\n• None skipkeys (bool) – If , keys that are not of a basic type ( , , , , ) will be skipped instead of raising a . Default .\n• None ensure_ascii (bool) – If (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If , these characters will be outputted as-is.\n• None check_circular (bool) – If , the circular reference check for container types is skipped and a circular reference will result in a (or worse). Default .\n• None allow_nan (bool) – If , serialization of out-of-range values ( , , ) will result in a , in strict compliance with the JSON specification. If (the default), their JavaScript equivalents ( , , ) are used.\n• None cls (a subclass) – If set, a custom JSON encoder with the method overridden, for serializing into custom datatypes. If (the default), is used.\n• None indent (int | str | None) – If a positive integer or string, JSON array elements and object members will be pretty-printed with that indent level. A positive integer indents that many spaces per level; a string (such as ) is used to indent each level. If zero, negative, or (the empty string), only newlines are inserted. If (the default), the most compact representation is used.\n• None separators (tuple | None) – A two-tuple: . If (the default), separators defaults to if indent is , and otherwise. For the most compact JSON, specify to eliminate whitespace.\n• None default (callable | None) – A function that is called for objects that can’t otherwise be serialized. It should return a JSON encodable version of the object or raise a . If (the default), is raised.\n• None sort_keys (bool) – If , dictionaries will be outputted sorted by key. Default . Changed in version 3.2: Allow strings for indent in addition to integers. Changed in version 3.4: Use as default if indent is not . Changed in version 3.6: All optional parameters are now keyword-only. Serialize obj to a JSON formatted using this conversion table. The arguments have the same meaning as in . Keys in key/value pairs of JSON are always of the type . When a dictionary is converted into JSON, all the keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON and then back into a dictionary, the dictionary may not equal the original one. That is, if x has non-string keys. Deserialize fp to a Python object using the JSON-to-Python conversion table.\n• None fp (file-like object) – A -supporting text file or binary file containing the JSON document to be deserialized.\n• None cls (a subclass) – If set, a custom JSON decoder. Additional keyword arguments to will be passed to the constructor of cls. If (the default), is used.\n• None object_hook (callable | None) – If set, a function that is called with the result of any object literal decoded (a ). The return value of this function will be used instead of the . This feature can be used to implement custom decoders, for example JSON-RPC class hinting. Default .\n• None object_pairs_hook (callable | None) – If set, a function that is called with the result of any object literal decoded with an ordered list of pairs. The return value of this function will be used instead of the . This feature can be used to implement custom decoders. If object_hook is also set, object_pairs_hook takes priority. Default .\n• None parse_float (callable | None) – If set, a function that is called with the string of every JSON float to be decoded. If (the default), it is equivalent to . This can be used to parse JSON floats into custom datatypes, for example .\n• None parse_int (callable | None) – If set, a function that is called with the string of every JSON int to be decoded. If (the default), it is equivalent to . This can be used to parse JSON integers into custom datatypes, for example .\n• None parse_constant (callable | None) – If set, a function that is called with one of the following strings: , , or . This can be used to raise an exception if invalid JSON numbers are encountered. Default .\n• None JSONDecodeError – When the data being deserialized is not a valid JSON document.\n• None UnicodeDecodeError – When the data being deserialized does not contain UTF-8, UTF-16 or UTF-32 encoded data.\n• None All optional parameters are now keyword-only.\n• None fp can now be a binary file. The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.11: The default parse_int of now limits the maximum length of the integer string via the interpreter’s integer string conversion length limitation to help avoid denial of service attacks. Identical to , but instead of a file-like object, deserialize s (a , or instance containing a JSON document) to a Python object using this conversion table. Changed in version 3.6: s can now be of type or . The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.9: The keyword argument encoding has been removed.\n\nPerforms the following translations in decoding by default: It also understands , , and as their corresponding values, which is outside the JSON spec. object_hook is an optional function that will be called with the result of every JSON object decoded and its return value will be used in place of the given . This can be used to provide custom deserializations (e.g. to support JSON-RPC class hinting). object_pairs_hook is an optional function that will be called with the result of every JSON object decoded with an ordered list of pairs. The return value of object_pairs_hook will be used instead of the . This feature can be used to implement custom decoders. If object_hook is also defined, the object_pairs_hook takes priority. parse_float is an optional function that will be called with the string of every JSON float to be decoded. By default, this is equivalent to . This can be used to use another datatype or parser for JSON floats (e.g. ). parse_int is an optional function that will be called with the string of every JSON int to be decoded. By default, this is equivalent to . This can be used to use another datatype or parser for JSON integers (e.g. ). parse_constant is an optional function that will be called with one of the following strings: , , . This can be used to raise an exception if invalid JSON numbers are encountered. If strict is false ( is the default), then control characters will be allowed inside strings. Control characters in this context are those with character codes in the 0–31 range, including (tab), , and . If the data being deserialized is not a valid JSON document, a will be raised. Changed in version 3.6: All parameters are now keyword-only. Return the Python representation of s (a instance containing a JSON document). will be raised if the given JSON document is not valid. Decode a JSON document from s (a beginning with a JSON document) and return a 2-tuple of the Python representation and the index in s where the document ended. This can be used to decode a JSON document from a string that may have extraneous data at the end. Supports the following objects and types by default: Changed in version 3.4: Added support for int- and float-derived Enum classes. To extend this to recognize other objects, subclass and implement a method with another method that returns a serializable object for if possible, otherwise it should call the superclass implementation (to raise ). If skipkeys is false (the default), a will be raised when trying to encode keys that are not , , or . If skipkeys is true, such items are simply skipped. If ensure_ascii is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is. If check_circular is true (the default), then lists, dicts, and custom encoded objects will be checked for circular references during encoding to prevent an infinite recursion (which would cause a ). Otherwise, no such check takes place. If allow_nan is true (the default), then , , and will be encoded as such. This behavior is not JSON specification compliant, but is consistent with most JavaScript based encoders and decoders. Otherwise, it will be a to encode such floats. If sort_keys is true (default: ), then the output of dictionaries will be sorted by key; this is useful for regression tests to ensure that JSON serializations can be compared on a day-to-day basis. If indent is a non-negative integer or string, then JSON array elements and object members will be pretty-printed with that indent level. An indent level of 0, negative, or will only insert newlines. (the default) selects the most compact representation. Using a positive integer indent indents that many spaces per level. If indent is a string (such as ), that string is used to indent each level. Changed in version 3.2: Allow strings for indent in addition to integers. If specified, separators should be an tuple. The default is if indent is and otherwise. To get the most compact JSON representation, you should specify to eliminate whitespace. Changed in version 3.4: Use as default if indent is not . If specified, default should be a function that gets called for objects that can’t otherwise be serialized. It should return a JSON encodable version of the object or raise a . If not specified, is raised. Changed in version 3.6: All parameters are now keyword-only. Implement this method in a subclass such that it returns a serializable object for o, or calls the base implementation (to raise a ). For example, to support arbitrary iterators, you could implement like this: # Let the base class default method raise the TypeError Return a JSON string representation of a Python data structure, o. For example: Encode the given object, o, and yield each string representation as available. For example:\n\nThe JSON format is specified by RFC 7159 and by ECMA-404. This section details this module’s level of compliance with the RFC. For simplicity, and subclasses, and parameters other than those explicitly mentioned, are not considered. This module does not comply with the RFC in a strict fashion, implementing some extensions that are valid JavaScript but not valid JSON. In particular:\n• None Infinite and NaN number values are accepted and output;\n• None Repeated names within an object are accepted, and only the value of the last name-value pair is used. Since the RFC permits RFC-compliant parsers to accept input texts that are not RFC-compliant, this module’s deserializer is technically RFC-compliant under default settings. The RFC requires that JSON be represented using either UTF-8, UTF-16, or UTF-32, with UTF-8 being the recommended default for maximum interoperability. As permitted, though not required, by the RFC, this module’s serializer sets ensure_ascii=True by default, thus escaping the output so that the resulting strings only contain ASCII characters. Other than the ensure_ascii parameter, this module is defined strictly in terms of conversion between Python objects and , and thus does not otherwise directly address the issue of character encodings. The RFC prohibits adding a byte order mark (BOM) to the start of a JSON text, and this module’s serializer does not add a BOM to its output. The RFC permits, but does not require, JSON deserializers to ignore an initial BOM in their input. This module’s deserializer raises a when an initial BOM is present. The RFC does not explicitly forbid JSON strings which contain byte sequences that don’t correspond to valid Unicode characters (e.g. unpaired UTF-16 surrogates), but it does note that they may cause interoperability problems. By default, this module accepts and outputs (when present in the original ) code points for such sequences. The RFC does not permit the representation of infinite or NaN number values. Despite that, by default, this module accepts and outputs , , and as if they were valid JSON number literal values: # Neither of these calls raises an exception, but the results are not valid JSON In the serializer, the allow_nan parameter can be used to alter this behavior. In the deserializer, the parse_constant parameter can be used to alter this behavior. The RFC specifies that the names within a JSON object should be unique, but does not mandate how repeated names in JSON objects should be handled. By default, this module does not raise an exception; instead, it ignores all but the last name-value pair for a given name: The object_pairs_hook parameter can be used to alter this behavior. The old version of JSON specified by the obsolete RFC 4627 required that the top-level value of a JSON text must be either a JSON object or array (Python or ), and could not be a JSON null, boolean, number, or string value. RFC 7159 removed that restriction, and this module does not and has never implemented that restriction in either its serializer or its deserializer. Regardless, for maximum interoperability, you may wish to voluntarily adhere to the restriction yourself. Some JSON deserializer implementations may set limits on:\n• None the maximum level of nesting of JSON objects and arrays\n• None the range and precision of JSON numbers\n• None the content and maximum length of JSON strings This module does not impose any such limits beyond those of the relevant Python datatypes themselves or the Python interpreter itself. When serializing to JSON, beware any such limitations in applications that may consume your JSON. In particular, it is common for JSON numbers to be deserialized into IEEE 754 double precision numbers and thus subject to that representation’s range and precision limitations. This is especially relevant when serializing Python values of extremely large magnitude, or when serializing instances of “exotic” numerical types such as .\n\nThe module provides a simple command line interface to validate and pretty-print JSON objects. If the optional and arguments are not specified, and will be used respectively: Changed in version 3.5: The output is now in the same order as the input. Use the option to sort the output of dictionaries alphabetically by key. The JSON file to be validated or pretty-printed: python -m json.tool mp_films.json \"title\": \"And Now for Something Completely Different\", If infile is not specified, read from . Write the output of the infile to the given outfile. Otherwise, write it to . Sort the output of dictionaries alphabetically by key. Disable escaping of non-ascii characters, see for more information."
    },
    {
        "link": "https://geeksforgeeks.org/response-json-python-requests",
        "document": "Python requests are generally used to fetch the content from a particular resource URL. Whenever we make a request to a specified URL through Python, it returns a response object. Now, this response object would be used to access certain features such as content, headers, etc. This article revolves around how to check the response.json() out of a response object. It is one of the most used methods in the requests module.\n\nHow to use response.json() using Python requests?\n\nresponse.json() is a part of the requests module in Python so, firstly we have to install the requests module in Python. response.json() is widely used to fetch data from APIs. In this article, we will explore how to use response.json() to load JSON data into Python objects.\n\nIn the below code, firstly we imported the requests module and then fetch the data from an API using requests.get() method and store in variable ‘response’. When we print the response it prints ‘<Response [200]>’ which is the HTTP code that indicates success. To print the JSON data fetched we have used json() method which prints the JSON data in the Python dictionary format as seen in the output. In this way, we can pas parse JSON responses in Python.\n\nIn the below code, we will parse the JSON data and print that data same as we access the keys and values of a dictionary. After making the get request to an API we store the JSON data in a variable “API_Data” using the response.json() method. Then we iterate over the JSON data using for loop and print the data by using the keys.\n\nHow to Pretty Print a JSON Object From Python Requests\n\nIn the below code, we will pretty print the JSON object that we got from an API using request.get() method. For that after converting the JSON object to the dictionary and stored into “response_dict” we will apply the json.dumps() method on data stored in “response_dict”. We will apply indentation on data by passing the argument “indent=4” and sorting the keys by setting “sort_keys=True” and then printing the data. We can see in the output that data is sorted in increasing order and with indentation.\n\nThere are many libraries to make an HTTP request in Python, which are httplib, urllib, httplib2, treq, etc., but requests are one of the best with cool features. If any attribute of requests shows NULL, check the status code using the below attribute.\n\nIf status_code doesn’t lie in the range of 200-29. You probably need to check the method begin used for making a request + the URL you are requesting for resources."
    },
    {
        "link": "https://realpython.com/python-json",
        "document": "Python’s module provides you with the tools you need to effectively handle JSON data. You can convert Python data types to a JSON-formatted string with or write them to files using . Similarly, you can read JSON data from files with and parse JSON strings with .\n\nJSON, or JavaScript Object Notation, is a widely-used text-based format for data interchange. Its syntax resembles Python dictionaries but with some differences, such as using only double quotes for strings and lowercase for Boolean values. With built-in tools for validating syntax and manipulating JSON files, Python makes it straightforward to work with JSON data.\n\nBy the end of this tutorial, you’ll understand that:\n• JSON in Python is handled using the standard-library module, which allows for data interchange between JSON and Python data types.\n• JSON is a good data format to use with Python as it’s human-readable and straightforward to serialize and deserialize, which makes it ideal for use in APIs and data storage.\n• You write JSON with Python using to serialize data to a file.\n• You can minify and prettify JSON using Python’s module.\n\nSince its introduction, JSON has rapidly emerged as the predominant standard for the exchange of information. Whether you want to transfer data with an API or store information in a document database, it’s likely you’ll encounter JSON. Fortunately, Python provides robust tools to facilitate this process and help you manage JSON data efficiently.\n\nWhile JSON is the most common format for data distribution, it’s not the only option for such tasks. Both XML and YAML serve similar purposes. If you’re interested in how the formats differ, then you can check out the tutorial on how to serialize your data with Python.\n\nThe acronym JSON stands for JavaScript Object Notation. As the name suggests, JSON originated from JavaScript. However, JSON has transcended its origins to become language-agnostic and is now recognized as the standard for data interchange. The popularity of JSON can be attributed to native support by the JavaScript language, resulting in excellent parsing performance in web browsers. On top of that, JSON’s straightforward syntax allows both humans and computers to read and write JSON data effortlessly. To get a first impression of JSON, have a look at this example code: You’ll learn more about the JSON syntax later in this tutorial. For now, recognize that the JSON format is text-based. In other words, you can create JSON files using the code editor of your choice. Once you set the file extension to , most code editors display your JSON data with syntax highlighting out of the box: The screenshot above shows how VS Code displays JSON data using the Bearded color theme. You’ll have a closer look at the syntax of the JSON format next! In the previous section, you got a first impression of how JSON data looks. And as a Python developer, the JSON structure probably reminds you of common Python data structures, like a dictionary that contains a string as a key and a value. If you understand the syntax of a dictionary in Python, you already know the general syntax of a JSON object. Note: Later in this tutorial, you’ll learn that you’re free to use lists and other data types at the top level of a JSON document. The similarity between Python dictionaries and JSON objects is no surprise. One idea behind establishing JSON as the go-to data interchange format was to make working with JSON as convenient as possible, independently of which programming language you use: [A collection of key-value pairs and arrays] are universal data structures. Virtually all modern programming languages support them in one form or another. It makes sense that a data format that is interchangeable with programming languages is also based on these structures. (Source) To explore the JSON syntax further, create a new file named and add a more complex JSON structure as the content of the file: In the code above, you see data about a dog named Frieda, which is formatted as JSON. The top-level value is a JSON object. Just like Python dictionaries, you wrap JSON objects inside curly braces ( ). In line 1, you start the JSON object with an opening curly brace ( ), and then you close the object at the end of line 20 with a closing curly brace ( ). Note: Although whitespace doesn’t matter in JSON, it’s customary for JSON documents to be formatted with two or four spaces to indicate indentation. If the file size of the JSON document is important, then you may consider minifying the JSON file by removing the whitespace. You’ll learn more about minifying JSON data later in the tutorial. Inside the JSON object, you can define zero, one, or more key-value pairs. If you add multiple key-value pairs, then you must separate them with a comma ( ). A key-value pair in a JSON object is separated by a colon ( ). On the left side of the colon, you define a key. A key is a string you must wrap in double quotes ( ). Unlike Python, JSON strings don’t support single quotes ( ). The values in a JSON document are limited to the following data types: Either or without quotes Just like in dictionaries and lists, you’re able to nest data in JSON objects and arrays. For example, you can include an object as the value of an object. Also, you’re free to use any other allowed value as an item in a JSON array. As a Python developer, you may need to pay extra attention to the Boolean values. Instead of using or in title case, you must use the lowercase JavaScript-style Booleans or . Unfortunately, there are some other details in the JSON syntax that you may stumble over as a developer. You’ll have a look at them next. The JSON standard doesn’t allow any comments, trailing commas, or single quotes for strings. This can be confusing to developers who are used to Python dictionaries or JavaScript objects. Here’s a smaller version of the JSON file from before with invalid syntax:\n• Line 5 has a trailing comma after the final key-value pair.\n• Line 10 contains a trailing comma in the array. Using double quotes is something you can get used to as a Python developer. Comments can be helpful in explaining your code, and trailing commas can make moving lines around in your code less fragile. This is why some developers like to use Human JSON (Hjson) or JSON with comments (JSONC). Hjson gives you the freedom to use comments, ditch commas between properties, or create quoteless strings. Apart from the curly braces ( ), the Hjson syntax look like a mix of YAML and JSON. JSONC is a bit stricter than Hjson. Compared to regular JSON, JSONC allows you to use comments and trailing commas. You may have encountered JSONC when editing the file of VS Code. Inside its configuration files, VS Code works in a JSONC mode. For common JSON files, VS Code is more strict and points out JSON syntax errors. If you want to make sure you write valid JSON, then your coding editor can be of great help. The invalid JSON document above contains marks for each occurrence of incorrect JSON syntax: When you don’t want to rely on your code editor, you can also use online tools to verify that the JSON syntax you write is correct. Popular online tools for validating JSON are JSON Lint and JSON Formatter. Later in the tutorial, you’ll learn how to validate JSON documents from the comfort of your terminal. But before that, it’s time to find out how you can work with JSON data in Python.\n\nPython supports the JSON format through the built-in module named . The module is specifically designed for reading and writing strings formatted as JSON. That means you can conveniently convert Python data types into JSON data and the other way around. The act of converting data into the JSON format is referred to as serialization. This process involves transforming data into a series of bytes for storage or transmission over a network. The opposite process, deserialization, involves decoding data from the JSON format back into a usable form within Python. You’ll start with the serialization of Python code into JSON data with the help of the module. One of the most common actions when working with JSON in Python is to convert a Python dictionary into a JSON object. To get an impression of how this works, hop over to your Python REPL and follow along with the code below: After importing the module, you can use to convert a Python dictionary to a JSON-formatted string, which represents a JSON object. It’s important to understand that when you use , you get a Python string in return. In other words, you don’t create any kind of JSON data type. The result is similar to what you’d get if you used Python’s built-in function: Using gets more interesting when your Python dictionary doesn’t contain strings as keys or when values don’t directly translate to a JSON format: In the dictionary, the keys , , and are numbers. Once you use , the dictionary keys become strings in the JSON-formatted string. Note: When you convert a dictionary to JSON, the dictionary keys will always be strings in JSON. The Boolean Python values of your dictionary become JSON Booleans. As mentioned before, the tiny but significant difference between JSON Booleans and Python Booleans is that JSON Booleans are lowercase. The cool thing about Python’s module is that it takes care of the conversion for you. This can come in handy when you’re using variables as dictionary keys: When converting Python data types into JSON, the module receives the evaluated values. While doing so, sticks tightly to the JSON standard. For example, when converting integer keys like to the string . The module allows you to convert common Python data types to JSON. Here’s an overview of all Python data types and values that you can convert to JSON values: Note that different Python data types like lists and tuples serialize to the same JSON data type. This can cause problems when you convert JSON data back to Python, as the data type may not be the same as before. You’ll explore this pitfall later in this tutorial when you learn how to read JSON. Dictionaries are probably the most common Python data type that you’ll use as a top-level value in JSON. But you can convert the data types listed above just as smoothly as dictionaries using . Take a Boolean or a list, for example: A JSON document may contain a single scalar value, like a number, at the top level. That’s still valid JSON. But more often than not, you want to work with a collection of key-value pairs. Similar to how not every data type can be used as a dictionary key in Python, not all keys can be converted into JSON key strings: You can’t use dictionaries, lists, or tuples as JSON keys. For dictionaries and lists, this rule makes sense as they’re not hashable. But even when a tuple is hashable and allowed as a key in a dictionary, you’ll get a when you try to use a tuple as a JSON key: : keys must be str, int, float, bool or None, not tuple By providing the argument, you can prevent getting a when creating JSON data with unsupported Python keys: When you set in to , then Python skips the keys that are not supported and would otherwise raise a . The result is a JSON-formatted string that only contains a subset of the input dictionary. In practice, you usually want your JSON data to resemble the input object as close as possible. So, you must use with caution to not lose information when calling . Note: If you’re ever in a situation where you need to convert an unsupported object into JSON, then you can consider creating a subclass of the and implementing a method. When you use , you can use additional arguments to control the look of the resulting JSON-formatted string. For example, you can sort the dictionary keys by setting the parameter to : When you set to , then Python sorts the keys alphabetically for you when serializing a dictionary. Sorting the keys of a JSON object can come in handy when your dictionary keys formerly represented the column names of a database, and you want to display them in an organized fashion to the user. Another notable parameter of is , which you’ll probably use the most when serializing JSON data. You’ll explore later in this tutorial in the prettify JSON section. When you convert Python data types into the JSON format, you usually have a goal in mind. Most commonly, you’ll use JSON to persist and exchange data. To do so, you need to save your JSON data outside of your running Python program. Conveniently, you’ll explore saving JSON data to a file next. The JSON format can come in handy when you want to save data outside of your Python program. Instead of spinning up a database, you may decide to use a JSON file to store data for your workflows. Again, Python has got you covered. To write Python data into an external JSON file, you use . This is a similar function to the one you saw earlier, but without the s at the end of its name: In lines 3 to 22, you define a dictionary that you write to a JSON file in line 25 using a context manager. To properly indicate that the file contains JSON data, you set the file extension to . When you use , then it’s good practice to define the encoding. For JSON, you commonly want to use as the encoding when reading and writing files: The RFC requires that JSON be represented using either UTF-8, UTF-16, or UTF-32, with UTF-8 being the recommended default for maximum interoperability. (Source) The function has two required arguments:\n• The object you want to write\n• The file you want to write into Other than that, there are a bunch of optional parameters for . The optional parameters of are the same as for . You’ll investigate some of them later in this tutorial when you prettify and minify JSON files.\n\nIn the former sections, you learned how to serialize Python data into JSON-formatted strings and JSON files. Now, you’ll see what happens when you load JSON data back into your Python program. In parallel to and , the library provides two functions to deserialize JSON data into a Python object: As a rule of thumb, you work with when your data is already present in your Python program. You use with external files that are saved on your disk. The conversion from JSON data types and values to Python follows a similar mapping as before when you converted Python objects into the JSON format: When you compare this table to the one in the previous section, you may recognize that Python offers a matching data type for all JSON types. That’s very convenient because this way, you can be sure you won’t lose any information when deserializing JSON data to Python. Note: Deserialization is not the exact reverse of the serialization process. The reason for this is that JSON keys are always strings, and not all Python data types can be converted to JSON data types. This discrepancy means that certain Python objects may not retain their original type when serialized and then deserialized. To get a better feeling for the conversion of data types, you’ll start with serializing a Python object to JSON and then convert the JSON data back to Python. That way, you can spot differences between the Python object you serialize and the Python object you end up with after deserializing the JSON data. To investigate how to load a Python dictionary from a JSON object, revisit the example from before. Start by creating a dictionary and then serialize the Python dictionary to a JSON string using : By passing into , you’re creating a string with a JSON object that you save in . If you want to convert back to a Python dictionary, then you can use : By using , you can convert JSON data back into Python objects. With the knowledge about JSON that you’ve gained so far, you may already suspect that the content of the dictionary is not identical to the content of : The difference between and is subtle but can be impactful in your Python programs. In JSON, the keys must always be strings. When you converted to using , the integer key became the string . When you used , there was no way for Python to know that the string key should be an integer again. That’s why your dictionary key remained a string after deserialization. You’ll investigate a similar behavior by doing another conversion roundtrip with other Python data types! To explore how different data types behave in a roundtrip from Python to JSON and back, take a portion of the dictionary from a former section. Note how the dictionary contains different data types as values: The dictionary contains a bunch of common Python data types as values. For example, a string in line 2, a Boolean in line 3, a in line 7, and a tuple in line 8, just to name a few. Next, convert to a JSON-formatted string and back to Python again. Afterward, have a look at the newly created dictionary: You can convert every JSON data type perfectly into a matching Python data type. The JSON Boolean deserializes into , converts back into , and objects and arrays become dictionaries and lists. Still, there’s one exception that you may encounter in roundtrips: When you serialize a Python tuple, it becomes a JSON array. When you load JSON, a JSON array correctly deserializes into a list because Python has no way of knowing that you want the array to be a tuple. Problems like the one described above can always be an issue when you’re doing data roundtrips. When the roundtrip happens in the same program, you may be more aware of the expected data types. Data type conversions may be even more obfuscated when you’re dealing with external JSON files that originated in another program. You’ll investigate a situation like this next! In a previous section, you created a file that saved a file. If you need to refresh your memory, you can expand the collapsible section below that shows the code again: Take a look at the data types of the dictionary. Is there a data type in a value that the JSON format doesn’t support? When you want to write content to a JSON file, you use . The counterpart to is . As the name suggests, you can use to load a JSON file into your Python program. Jump back into the Python REPL and load the JSON file from before: Just like when writing files, it’s a good idea to use a context manager when reading a file in Python. That way, you don’t need to bother with closing the file again. When you want to read a JSON file, then you use inside the statement’s block. The argument for the function must be either a text file or a binary file. The Python object that you get from depends on the top-level data type of your JSON file. In this case, the JSON file contains an object at the top level, which deserializes into a dictionary. When you deserialize a JSON file as a Python object, then you can interact with it natively—for example, by accessing the value of the key with square bracket notation ( ). Still, there’s a word of caution here. Import the original dictionary from before and compare it to : When you load a JSON file as a Python object, then any JSON data type happily deserializes into Python. That’s because Python knows about all data types that the JSON format supports. Unfortunately, it’s not the same the other way around. As you learned before, there are Python data types like that you can convert into JSON, but you’ll end up with an data type in the JSON file. Once you convert the JSON data back to Python, then an array deserializes into the Python data type. Generally, being cautious about data type conversions should be the concern of the Python program that writes the JSON. With the knowledge you have about JSON files, you can always anticipate which Python data types you’ll end up with as long as the JSON file is valid. If you use , then the content of the file you load must contain valid JSON syntax. Otherwise, you’ll receive a . Luckily, Python caters to you with more tools you can use to interact with JSON. For example, it allows you to check a JSON file’s validity from the convenience of the terminal.\n\nSo far, you’ve explored the JSON syntax and have already spotted some common JSON pitfalls like trailing commas and single quotes for strings. When writing JSON, you may have also spotted some annoying details. For example, neatly indented Python dictionaries end up being a blob of JSON data. In the last section of this tutorial, you’ll try out some techniques to make your life easier as you work with JSON data in Python. To start, you’ll give your JSON object a well-deserved glow-up. One huge advantage of the JSON format is that JSON data is human-readable. Even more so, JSON data is human-writable. This means you can open a JSON file in your favorite text editor and change the content to your liking. Well, that’s the idea, at least! Editing JSON data by hand is not particularly easy when your JSON data looks like this in the text editor: Even with word wrapping and syntax highlighting turned on, JSON data is hard to read when it’s a single line of code. And as a Python developer, you probably miss some whitespace. But worry not, Python has got you covered! When you call or to serialize a Python object, then you can provide the argument. Start by trying out with different indentation levels: The default value for is . When you call without or with as a value, you’ll end up with one line of a compact JSON-formatted string. If you want linebreaks in your JSON string, then you can set to or provide an empty string. Although probably less useful, you can even provide a negative number as the indentation or any other string. More commonly, you’ll provide values like or for : When you use positive integers as the value for when calling , then you’ll indent every level of the JSON object with the given count as spaces. Also, you’ll have newlines for each key-value pair. Note: To actually see the whitespace in the REPL, you can wrap the calls in function calls. The parameter works exactly the same for as it does for . Go ahead and write the dictionary into a JSON file with an indentation of spaces: When you set the indentation level when serializing JSON data, then you end up with prettified JSON data. Have a look at how the file looks in your editor: Python can work with JSON files no matter how they’re indented. As a human, you probably prefer a JSON file that contains newlines and is neatly indented. A JSON file that looks like this is way more convenient to edit. The convenience of being able to edit JSON data in the editor comes with a risk. When you move key-value pairs around or add strings with one quote instead of two, you end up with an invalid JSON. To swiftly check if a JSON file is valid, you can leverage Python’s . You can run the module as an executable in the terminal using the switch. To see in action, also provide as the positional argument: When you run only with an option, then Python validates the JSON file and outputs the JSON file’s content in the terminal if the JSON is valid. Running in the example above means that contains valid JSON syntax. Note: The prints the JSON data with an indentation of 4 by default. You’ll explore this behavior in the next section. To make complain, you need to invalidate your JSON document. You can make the JSON data of invalid by removing the comma ( ) between the key-value pairs: After saving , run again to validate the file: The module successfully stumbles over the missing comma in . Python notices that there’s a delimiter missing once the property name enclosed in double quotes starts in line 3 at position 5. Go ahead and try fixing the JSON file again. You can also be creative with invalidating and check how reports your error. But keep in mind that only reports the first error. So you may need to go back and forth between fixing a JSON file and running . Once is valid, you may notice that the output always looks the same. Of course, like any well-made command-line interface, offers you some options to control the program. In the previous section, you used to validate a JSON file. When the JSON syntax was valid, showed the content with newlines and an indentation of four spaces. To control how prints the JSON, you can set the option. If you followed along with the tutorial, then you’ve got a file that doesn’t contain newlines or indentation. Alternatively, you can download in the materials by clicking the link below: Free Bonus: Click here to download the free sample code that shows you how to work with JSON data in Python. When you pass in to , then you can pretty print the content of the JSON file in your terminal. When you set , then you can control which indentation level uses to display the code: Seeing the prettified JSON data in the terminal is nifty. But you can step up your game even more by providing another option to the run! By default, writes the output to , just like you commonly do when calling the function. But you can also redirect the output of into a file by providing a positional argument: With as the value of the option, you write the output into the JSON file instead of showing the content in the terminal. If the file doesn’t exist yet, then Python creates the file on the way. If the target file already exists, then you overwrite the file with the new content. Note: You can prettify a JSON file in place by using the same file as and arguments. You can verify that the file exists by running the terminal command: The whitespace you added to comes with a price. Compared to the original, unindented file, the file size of is now around double that. Here, the 308-byte increase may not be significant. But when you’re dealing with big JSON data, then a good-looking JSON file will take up quite a bit of space. Having a small data footprint is especially useful when serving data over the web. Since the JSON format is the de facto standard for exchanging data over the web, it’s worth keeping the file size as small as possible. And again, Python’s has got your back! As you know by now, Python is a great helper when working with JSON. You can minify JSON data with Python in two ways:\n• Use the module in your Python code Before, you used with the option to add whitespace. Instead of using here, you can use provide to do the opposite and remove any whitespace between the key-value pairs of your JSON: After calling the module, you provide a JSON file as the and another JSON file as the . If the target JSON file exists, then you overwrite its contents. Otherwise, you create a new file with the filename you provide. Just like with , you provide the same file as a source and target file to minify the file in-place. In the example above, you minify into . Run the command to see how many bytes you squeezed out of the original JSON file: Compared to , the file size of is 337 bytes smaller. That’s even 29 bytes less than the original file that didn’t contain any indentation. To investigate where Python managed to remove even more whitespace from the original JSON, open the Python REPL again and minify the content of the original file with Python’s module: In the code above, you use Python’s to get the content of as text. Then, you use to deserialize to , which is a Python dictionary. You could use to get a Python dictionary right away, but you need the JSON data as a string first to compare it properly. That’s also why you use to create and then use instead of leveraging directly to save the minified JSON data in . As you learned before, needs JSON data as the first argument and then accepts a value for the indentation. The default value for is , so you could skip setting the argument explicitly like you do above. But with , you’re making your intention clear that you don’t want any indentation, which will be a good thing for others who read your code later. The parameter for allows you to define a tuple with two values:\n• The separator between the key-value pairs or list items. By default, this separator is a comma followed by a space ( ).\n• The separator between the key and the value. By default, this separator is a colon followed by a space ( ). By setting to , you continue to use valid JSON separators. But you tell Python not to add any spaces after the comma ( ) and the colon ( ). That means that the only whitespace left in your JSON data can be whitespace appearing in key names and values. That’s pretty tight! With both and containing your JSON strings, it’s time to compare them: You can already spot the difference between and when you look at the output. You then use the function to verify that the size of is indeed smaller. If you’re curious about why the length of the JSON strings almost exactly matches the file size of the written files, then looking into Unicode & character encodings in Python is a great idea. Both and are excellent helpers when you want to make JSON data look prettier, or if you want to minify JSON data to save some bytes. With the module, you can conveniently interact with JSON data in your Python programs. That’s great when you need to have more control over the way you interact with JSON. The module comes in handy when you want to work with JSON data directly in your terminal."
    },
    {
        "link": "https://geeksforgeeks.org/reading-and-writing-json-to-a-file-in-python",
        "document": "The full form of JSON is Javascript Object Notation. It means that a script (executable) file which is made of text in a programming language, is used to store and transfer the data. Python supports JSON through a built-in package called JSON. To use this feature, we import the JSON package in Python script. The text in JSON is done through quoted-string which contains the value in key-value mapping within { }. It is similar to the dictionary in Python.\n\nSerializing JSON refers to the transformation of data into a series of bytes (hence serial) to be stored or transmitted across a network. To handle the data flow in a file, the JSON library in Python uses dump() or dumps() function to convert the Python objects into their respective JSON object, so it makes it easy to write data to files. See the following table given below.\n\nMethod 1: Writing JSON to a file in Python using json.dumps()\n\nThe JSON package in Python has a function called json.dumps() that helps in converting a dictionary to a JSON object. It takes two parameters:\n• dictionary – the name of a dictionary which should be converted to a JSON object.\n• indent – defines the number of units for indentation\n\nAfter converting the dictionary to a JSON object, simply write it to a file using the “write” function.\n\nMethod 2: Writing JSON to a file in Python using json.dump()\n\nAnother way of writing JSON to a file is by using json.dump() method The JSON package has the “dump” function which directly writes the dictionary to a file in the form of JSON, without needing to convert it into an actual JSON object. It takes 2 parameters:\n• dictionary – the name of a dictionary which should be converted to a JSON object.\n• file pointer – pointer of the file opened in write or append mode.\n\nDeserialization is the opposite of Serialization, i.e. conversion of JSON objects into their respective Python objects. The load() method is used for it. If you have used JSON data from another program or obtained it as a string format of JSON, then it can easily be deserialized with load(), which is usually used to load from a string, otherwise, the root object is in a list or Dict.\n\nThe JSON package has json.load() function that loads the JSON content from a JSON file into a dictionary. It takes one parameter:"
    },
    {
        "link": "https://stackoverflow.com/questions/12309269/how-do-i-write-json-data-to-a-file",
        "document": "TypeError: must be string or buffer, not dict\n\nHow do I write JSON data stored in the dictionary data to a file?\n\nis a Python dictionary. It needs to be encoded as JSON before writing. Use this for maximum compatibility (Python 2 and 3): On a modern system (i.e. Python 3 and UTF-8 support), you can write a nicer file using:\n\nTo get utf8-encoded file as opposed to ascii-encoded in the accepted answer for Python 2 use: The code is simpler in Python 3: On Windows, the argument to is still necessary. To avoid storing an encoded copy of the data in memory (result of ) and to output utf8-encoded bytestrings in both Python 2 and 3, use: The call is redundant in Python 3 but required for Python 2 The use of gives better readability and smaller size: Further improve readability by adding flags (as suggested by dinos66) to arguments of or . This way you'll get a nicely indented sorted structure in the json file at the cost of a slightly larger file size.\n\nI don't have enough reputation to add in comments, so I just write some of my findings of this annoying TypeError here: Basically, I think it's a bug in the function in Python 2 only - It can't dump a Python (dictionary / list) data containing non-ASCII characters, even you open the file with the parameter. (i.e. No matter what you do). But, works on both Python 2 and 3. To illustrate this, following up phihag's answer: the code in his answer breaks in Python 2 with exception TypeError: must be unicode, not str , if contains non-ASCII characters. (Python 2.7.6, Debian): It however works fine in Python 3.\n\nFor people liking oneliners (hence statement is not an option), a cleaner method than leaving a dangling opened file descriptor behind can be to use from and do something like below: This can be handy in some cases in contexts where statements are not allowed like: I'm not claiming it should be preferred to (and it's likely slower), just another option.\n\nBefore write a dictionary into a file as a json, you have to turn that dict onto json string using library. And also you can add indent to json data to look prettier. If you want to sort keys before turning into json, You can use the combination of these two also. Refer the json documentation here for much more features Finally you can write into a json file\n\nIf you like prettified (indented) and keys sorted json with optional encoding: In case you're working on the written file, make sure to either flush or close so that all data caches are written to the disk: fp2.flush() # you may still keep working on the file after this fp2.close() # guaranteed data written to the disk Below example json loading is if you don't already have the json loaded as a dictionary. j1 = json.loads(\"\"\" { \"glossary\": { \"title\": \"example glossary\", \"GlossDiv\": { \"title\": \"S\", \"GlossList\": { \"GlossEntry\": { \"ID\": \"SGML\", \"SortAs\": \"SGML\", \"GlossTerm\": \"Standard Generalized Markup Language\", \"Acronym\": \"SGML\", \"Abbrev\": \"ISO 8879:1986\", \"GlossDef\": { \"para\": \"A meta-markup language, used to create markup languages such as DocBook.\", \"GlossSeeAlso\": [\"GML\", \"XML\"] }, \"GlossSee\": \"markup\" } } } } } \"\"\")\n\nThis is just an extra hint at the usage of (this is not an answer to the problem of the question, but a trick for those who have to dump numpy data types): If there are NumPy data types in the dictionary, needs an additional parameter, credits go to TypeError: Object of type 'ndarray' is not JSON serializable, and it will also fix errors like TypeError: Object of type int64 is not JSON serializable and so on: You may also want to return a string instead of a list in case of a np.array() since arrays are printed as lists that are spread over rows which will blow up the output if you have large or many arrays. The caveat: it is more difficult to access the items from the dumped dictionary later to get them back as the original array. Yet, if you do not mind having just a string of an array, this makes the dictionary more readable. Then exchange:"
    },
    {
        "link": "https://medium.com/@ryan_forrester_/writing-json-to-a-file-in-python-a-step-by-step-guide-630584957d07",
        "document": "JSON (JavaScript Object Notation) is a lightweight data-interchange format that is easy for humans to read and write, and easy for machines to parse and generate. In Python, working with JSON is straightforward thanks to the built-in `json` module. This article will guide you through the process of writing JSON to a file in Python with detailed explanations and practical code examples, making it easy for novice learners to grasp the concept.\n\nBefore we dive into the code, it’s essential to understand the structure of JSON. JSON represents data as key-value pairs, which is similar to dictionaries in Python. Here’s a simple example of JSON data:\n\nIn this example:\n\n- Keys: Strings (e.g., `”name”`, `”age”`, `”is_student”`, `”courses”`)\n\n- Values: Can be strings, numbers, booleans, arrays, or even nested objects.\n\nJSON is widely used for APIs, configuration files, and data exchange between languages. Now, let’s move on to how you can write JSON data to a file in Python.\n\nThe first step in writing JSON data to a file is to import the `json` module. This module contains methods for parsing and writing JSON data.\n\n- The `import` statement brings in the `json` module, which allows us to use its functions without having to write them from scratch.\n\nNext, you need to prepare the data you want to write. This data should be in a format that can be serialized to JSON, typically a dictionary or a list.\n\n- Here, we define a dictionary called `data` that contains information about a person. This dictionary can be easily converted to JSON format.\n\nNow that we have our data, we can write it to a file. We will use the `json.dump()` function to do this.\n\n- `open(‘data.json’, ‘w’)`: This line opens a file named `data.json` in write mode (`’w’`). If the file does not exist, it will be created.\n\n- `with` statement: This ensures that the file is properly closed after its suite finishes, even if an error is raised.\n\n- `json.dump(data, json_file)`: This function takes two arguments: the data you want to write (in our case, the `data` dictionary) and the file object (`json_file`). It converts the dictionary to a JSON string and writes it to the specified file.\n\nAfter running the above code, you can check the contents of `data.json` to ensure it has been written correctly. The file should look like this:\n\n- You can open the `data.json` file using any text editor to verify that the JSON format is correctly structured. Note that `false` in JSON corresponds to `False` in Python.\n\nOne practical use of writing JSON to a file is storing configuration settings for your application. For instance, you might want to save user preferences such as theme color, notification settings, or API keys.\n\n- In this example, we create a configuration dictionary called `config` that contains nested dictionaries for notifications and API keys.\n\n- The `indent=4` parameter in the `json.dump()` function makes the output JSON more readable by formatting it with an indentation of 4 spaces.\n\nWhen working with files, it’s essential to handle exceptions that may arise, such as file permission issues or incorrect data types. Here’s how you can enhance your code to manage exceptions:\n\n- `try…except`: This construct allows you to catch exceptions and handle them gracefully.\n\n- `IOError`: This exception is raised if an I/O operation (like writing to a file) fails.\n\n- `TypeError`: This exception is raised if the data cannot be serialized to JSON format, such as trying to serialize a Python set.\n\nWriting JSON to a file in Python is a simple and effective way to store data. By using the `json` module, you can easily convert Python dictionaries to JSON format and save them for later use. This functionality is especially useful in applications where configuration settings or data exchange are required.\n\nWith the steps outlined above, you should be able to write JSON data to a file confidently. Whether you’re working on personal projects, developing applications, or just learning Python, understanding how to handle JSON data is a valuable skill."
    },
    {
        "link": "https://medium.com/jungletronics/efficient-file-handling-in-python-0d952971ebc9",
        "document": "Handling files in Python can be done efficiently using several methods. Here are some of the best practices and commonly used methods:\n\nThe function is the most basic way to handle files in Python. It allows you to open a file and perform read, write, or append operations.\n\nThe statement is used to ensure that the file is properly closed after its suite finishes, even if an exception is raised. This is a best practice for file handling.\n\nThe module provides an object-oriented interface for handling file paths.\n\nThe module provides a way to interact with the operating system, including file operations.\n\nThe module provides a high-level interface for file operations, such as copying and moving files.\n\nThe module provides functionality to read from and write to CSV files.\n\nThe module provides functionality to read from and write to JSON files.\n\nThe module allows you to serialize and deserialize Python objects to and from binary files.\n• Always use the statement to ensure files are properly closed.\n• Use for handling file paths in a cross-platform manner.\n• Use appropriate modules like , , and for specific file types.\n\nBy following these methods and best practices, you can handle files efficiently and effectively in Python.\n• Use a shell script file (e.g., ) for temporary or session-specific settings.\n• Use a file for Python projects and load it with .\n\nChoose the method that best fits your needs and workflow.\n\n01#Episode#PurePythonSeries — Send Email in Python — Using Jupyter Notebook — How To Send Gmail In Python\n\n02#Episode#PurePythonSeries — Automate Your Email With Python & Outlook — How To Create An Email Trigger System in Python\n\n03#Episode#PurePythonSeries — Manipulating Files With Python — Manage Your Lovely Photos With Python!\n\n05#Episode#PurePythonSeries — Is This Leap Year? Python Calendar — How To Calculate If The Year Is Leap Year and How Many Days Are In The Month\n\n08#Episode#PurePythonSeries — Decorator in Python — How To Simplifying Your Code And Boost Your Function\n\n11#Episode#PurePythonSeries — Python — Send Email Using SMTP — Send Mail To Any Internet Machine (SMTP or ESMTP)\n\n15#Episode#PurePythonSeries — ISS Tracking Project — Get an Email alert when International Space Station (ISS) is above of us in the sky, at night\n\n18#Episode#PurePythonSeries — Python —Efficient File Handling in Python — Best Practices and Common Methods (this one)\n\n19#Episode#PurePythonSeries — Python — How To Securely Save Credentials in Python — Like API tokens, passwords, or other sensitive data"
    }
]