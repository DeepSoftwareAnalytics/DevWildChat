[
    {
        "link": "https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html",
        "document": "In this article, we will learn\n• To find the different features of contours, like area, perimeter, centroid, bounding box etc\n• You will see plenty of functions related to contours.\n\nImage moments help you to calculate some features like center of mass of the object, area of the object etc. Check out the wikipedia page on Image Moments\n\nThe function cv.moments() gives a dictionary of all moment values calculated. See below:\n\nFrom this moments, you can extract useful data like area, centroid etc. Centroid is given by the relations, \\(C_x = \\frac{M_{10}}{M_{00}}\\) and \\(C_y = \\frac{M_{01}}{M_{00}}\\). This can be done as follows:\n\nContour area is given by the function cv.contourArea() or from moments, M['m00'].\n\nIt is also called arc length. It can be found out using cv.arcLength() function. Second argument specify whether shape is a closed contour (if passed True), or just a curve.\n\nIt approximates a contour shape to another shape with less number of vertices depending upon the precision we specify. It is an implementation of Douglas-Peucker algorithm. Check the wikipedia page for algorithm and demonstration.\n\nTo understand this, suppose you are trying to find a square in an image, but due to some problems in the image, you didn't get a perfect square, but a \"bad shape\" (As shown in first image below). Now you can use this function to approximate the shape. In this, second argument is called epsilon, which is maximum distance from contour to approximated contour. It is an accuracy parameter. A wise selection of epsilon is needed to get the correct output.\n\nBelow, in second image, green line shows the approximated curve for epsilon = 10% of arc length. Third image shows the same for epsilon = 1% of the arc length. Third argument specifies whether curve is closed or not.\n\nConvex Hull will look similar to contour approximation, but it is not (Both may provide same results in some cases). Here, cv.convexHull() function checks a curve for convexity defects and corrects it. Generally speaking, convex curves are the curves which are always bulged out, or at-least flat. And if it is bulged inside, it is called convexity defects. For example, check the below image of hand. Red line shows the convex hull of hand. The double-sided arrow marks shows the convexity defects, which are the local maximum deviations of hull from contours.\n\nThere is a little bit things to discuss about it its syntax:\n• points are the contours we pass into.\n• hull is the output, normally we avoid it.\n• clockwise : Orientation flag. If it is True, the output convex hull is oriented clockwise. Otherwise, it is oriented counter-clockwise.\n• returnPoints : By default, True. Then it returns the coordinates of the hull points. If False, it returns the indices of contour points corresponding to the hull points.\n\nSo to get a convex hull as in above image, following is sufficient:\n\nBut if you want to find convexity defects, you need to pass returnPoints = False. To understand it, we will take the rectangle image above. First I found its contour as cnt. Now I found its convex hull with returnPoints = True, I got following values: [[[234 202]], [[ 51 202]], [[ 51 79]], [[234 79]]] which are the four corner points of rectangle. Now if do the same with returnPoints = False, I get following result: [[129],[ 67],[ 0],[142]]. These are the indices of corresponding points in contours. For eg, check the first value: cnt[129] = [[234, 202]] which is same as first result (and so on for others).\n\nYou will see it again when we discuss about convexity defects.\n\nThere is a function to check if a curve is convex or not, cv.isContourConvex(). It just return whether True or False. Not a big deal.\n\nThere are two types of bounding rectangles.\n\nIt is a straight rectangle, it doesn't consider the rotation of the object. So area of the bounding rectangle won't be minimum. It is found by the function cv.boundingRect().\n\nLet (x,y) be the top-left coordinate of the rectangle and (w,h) be its width and height.\n\nHere, bounding rectangle is drawn with minimum area, so it considers the rotation also. The function used is cv.minAreaRect(). It returns a Box2D structure which contains following details - ( center (x,y), (width, height), angle of rotation ). But to draw this rectangle, we need 4 corners of the rectangle. It is obtained by the function cv.boxPoints()\n\nBoth the rectangles are shown in a single image. Green rectangle shows the normal bounding rect. Red rectangle is the rotated rect.\n\nNext we find the circumcircle of an object using the function cv.minEnclosingCircle(). It is a circle which completely covers the object with minimum area.\n\nNext one is to fit an ellipse to an object. It returns the rotated rectangle in which the ellipse is inscribed.\n\nSimilarly we can fit a line to a set of points. Below image contains a set of white points. We can approximate a straight line to it."
    },
    {
        "link": "https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html",
        "document": "In this article, we will learn\n• To find the different features of contours, like area, perimeter, centroid, bounding box etc\n• You will see plenty of functions related to contours.\n\nImage moments help you to calculate some features like center of mass of the object, area of the object etc. Check out the wikipedia page on Image Moments\n\nThe function cv.moments() gives a dictionary of all moment values calculated. See below:\n\nFrom this moments, you can extract useful data like area, centroid etc. Centroid is given by the relations, \\(C_x = \\frac{M_{10}}{M_{00}}\\) and \\(C_y = \\frac{M_{01}}{M_{00}}\\). This can be done as follows:\n\nContour area is given by the function cv.contourArea() or from moments, M['m00'].\n\nIt is also called arc length. It can be found out using cv.arcLength() function. Second argument specify whether shape is a closed contour (if passed True), or just a curve.\n\nIt approximates a contour shape to another shape with less number of vertices depending upon the precision we specify. It is an implementation of Douglas-Peucker algorithm. Check the wikipedia page for algorithm and demonstration.\n\nTo understand this, suppose you are trying to find a square in an image, but due to some problems in the image, you didn't get a perfect square, but a \"bad shape\" (As shown in first image below). Now you can use this function to approximate the shape. In this, second argument is called epsilon, which is maximum distance from contour to approximated contour. It is an accuracy parameter. A wise selection of epsilon is needed to get the correct output.\n\nBelow, in second image, green line shows the approximated curve for epsilon = 10% of arc length. Third image shows the same for epsilon = 1% of the arc length. Third argument specifies whether curve is closed or not.\n\nConvex Hull will look similar to contour approximation, but it is not (Both may provide same results in some cases). Here, cv.convexHull() function checks a curve for convexity defects and corrects it. Generally speaking, convex curves are the curves which are always bulged out, or at-least flat. And if it is bulged inside, it is called convexity defects. For example, check the below image of hand. Red line shows the convex hull of hand. The double-sided arrow marks shows the convexity defects, which are the local maximum deviations of hull from contours.\n\nThere is a little bit things to discuss about it its syntax:\n• points are the contours we pass into.\n• hull is the output, normally we avoid it.\n• clockwise : Orientation flag. If it is True, the output convex hull is oriented clockwise. Otherwise, it is oriented counter-clockwise.\n• returnPoints : By default, True. Then it returns the coordinates of the hull points. If False, it returns the indices of contour points corresponding to the hull points.\n\nSo to get a convex hull as in above image, following is sufficient:\n\nBut if you want to find convexity defects, you need to pass returnPoints = False. To understand it, we will take the rectangle image above. First I found its contour as cnt. Now I found its convex hull with returnPoints = True, I got following values: [[[234 202]], [[ 51 202]], [[ 51 79]], [[234 79]]] which are the four corner points of rectangle. Now if do the same with returnPoints = False, I get following result: [[129],[ 67],[ 0],[142]]. These are the indices of corresponding points in contours. For eg, check the first value: cnt[129] = [[234, 202]] which is same as first result (and so on for others).\n\nThere is a function to check if a curve is convex or not, cv.isContourConvex(). It just return whether True or False. Not a big deal.\n\nThere are two types of bounding rectangles.\n\nIt is a straight rectangle, it doesn't consider the rotation of the object. So area of the bounding rectangle won't be minimum. It is found by the function cv.boundingRect().\n\nLet (x,y) be the top-left coordinate of the rectangle and (w,h) be its width and height.\n\nHere, bounding rectangle is drawn with minimum area, so it considers the rotation also. The function used is cv.minAreaRect(). It returns a Box2D structure which contains following details - ( center (x,y), (width, height), angle of rotation ). But to draw this rectangle, we need 4 corners of the rectangle. It is obtained by the function cv.boxPoints()\n\nBoth the rectangles are shown in a single image. Green rectangle shows the normal bounding rect. Red rectangle is the rotated rect.\n\nNext we find the circumcircle of an object using the function cv.minEnclosingCircle(). It is a circle which completely covers the object with minimum area.\n\nNext one is to fit an ellipse to an object. It returns the rotated rectangle in which the ellipse is inscribed.\n\nSimilarly we can fit a line to a set of points. Below image contains a set of white points. We can approximate a straight line to it."
    },
    {
        "link": "http://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html",
        "document": "Image moments help you to calculate some features like center of mass of the object, area of the object etc. Check out the wikipedia page on Image Moments The function cv2.moments() gives a dictionary of all moment values calculated. See below: From this moments, you can extract useful data like area, centroid etc. Centroid is given by the relations, and . This can be done as follows:\n\nIt approximates a contour shape to another shape with less number of vertices depending upon the precision we specify. It is an implementation of Douglas-Peucker algorithm. Check the wikipedia page for algorithm and demonstration. To understand this, suppose you are trying to find a square in an image, but due to some problems in the image, you didn’t get a perfect square, but a “bad shape” (As shown in first image below). Now you can use this function to approximate the shape. In this, second argument is called , which is maximum distance from contour to approximated contour. It is an accuracy parameter. A wise selection of is needed to get the correct output. Below, in second image, green line shows the approximated curve for . Third image shows the same for . Third argument specifies whether curve is closed or not.\n\nConvex Hull will look similar to contour approximation, but it is not (Both may provide same results in some cases). Here, cv2.convexHull() function checks a curve for convexity defects and corrects it. Generally speaking, convex curves are the curves which are always bulged out, or at-least flat. And if it is bulged inside, it is called convexity defects. For example, check the below image of hand. Red line shows the convex hull of hand. The double-sided arrow marks shows the convexity defects, which are the local maximum deviations of hull from contours. There is a little bit things to discuss about it its syntax:\n• points are the contours we pass into.\n• hull is the output, normally we avoid it.\n• clockwise : Orientation flag. If it is , the output convex hull is oriented clockwise. Otherwise, it is oriented counter-clockwise.\n• returnPoints : By default, . Then it returns the coordinates of the hull points. If , it returns the indices of contour points corresponding to the hull points. So to get a convex hull as in above image, following is sufficient: But if you want to find convexity defects, you need to pass . To understand it, we will take the rectangle image above. First I found its contour as . Now I found its convex hull with , I got following values: which are the four corner points of rectangle. Now if do the same with , I get following result: . These are the indices of corresponding points in contours. For eg, check the first value: which is same as first result (and so on for others). You will see it again when we discuss about convexity defects.\n\nThere are two types of bounding rectangles. It is a straight rectangle, it doesn’t consider the rotation of the object. So area of the bounding rectangle won’t be minimum. It is found by the function cv2.boundingRect(). Let (x,y) be the top-left coordinate of the rectangle and (w,h) be its width and height. Here, bounding rectangle is drawn with minimum area, so it considers the rotation also. The function used is cv2.minAreaRect(). It returns a Box2D structure which contains following detals - ( top-left corner(x,y), (width, height), angle of rotation ). But to draw this rectangle, we need 4 corners of the rectangle. It is obtained by the function cv2.boxPoints() Both the rectangles are shown in a single image. Green rectangle shows the normal bounding rect. Red rectangle is the rotated rect."
    },
    {
        "link": "https://quora.com/How-can-I-detect-a-rectangle-using-OpenCV-code-in-Python",
        "document": "Something went wrong. Wait a moment and try again."
    },
    {
        "link": "https://learnopencv.com/contour-detection-using-opencv-python-c",
        "document": "Using contour detection, we can detect the borders of objects, and localize them easily in an image. It is often the first step for many interesting applications, such as image-foreground extraction, simple-image segmentation, detection and recognition.\n\nSo let’s learn about contours and contour detection, using OpenCV, and see for ourselves how they can be used to build various applications.\n• Steps for finding and drawing contours using OpenCV.\n\nSome really cool applications have been built, using contours for motion detection or segmentation. Here are some examples:\n• Motion Detection: In surveillance video, motion detection technology has numerous applications, ranging from indoor and outdoor security environments, traffic control, behaviour detection during sports activities, detection of unattended objects, and even compression of video. In the figure below, see how detecting the movement of people in a video stream could be useful in a surveillance application. Notice how the group of people standing still in the left side of the image are not detected. Only those in motion are captured. Do refer to this paper to study this approach in detail.\n• Unattended object detection: Any unattended object in public places is generally considered as a suspicious object. An effective and safe solution could be: (Unattended Object Detection through Contour Formation using Background Subtraction).\n• Background / Foreground Segmentation: To replace the background of an image with another, you need to perform image-foreground extraction (similar to image segmentation). Using contours is one approach that can be used to perform segmentation. Refer to this post for more details. The following images show simple examples of such an application:\n\nWhen we join all the points on the boundary of an object, we get a contour. Typically, a specific contour refers to boundary pixels that have the same color and intensity. OpenCV makes it really easy to find and draw contours in images. It provides two simple functions:\n\nAlso, it has two different algorithms for contour detection:\n\nWe will cover these in detail, in the examples below. The following figure shows how these algorithms can detect the contours of simple objects.\n\nNow that you have been introduced to contours, let’s discuss the steps involved in their detection.\n\nSteps for Detecting and Drawing Contours in OpenCV\n\nOpenCV makes this a fairly simple task. Just follow these steps:\n• Read the Image and convert it to Grayscale Format\n\nRead the image and convert the image to grayscale format. Converting the image to grayscale is very important as it prepares the image for the next step. Converting the image to a single channel grayscale image is important for thresholding, which in turn is necessary for the contour detection algorithm to work properly.\n\nWhile finding contours, first always apply binary thresholding or Canny edge detection to the grayscale image. Here, we will apply binary thresholding.\n\nThis converts the image to black and white, highlighting the objects-of-interest to make things easy for the contour-detection algorithm. Thresholding turns the border of the object in the image completely white, with all pixels having the same intensity. The algorithm can now detect the borders of the objects from these white pixels.\n\nNote: The black pixels, having value 0, are perceived as background pixels and ignored.\n\nAt this point, one question may arise. What if we use single channels like R (red), G (green), or B (blue) instead of grayscale (thresholded) images? In such a case, the contour detection algorithm will not work well. As we discussed previously, the algorithm looks for borders, and similar intensity pixels to detect the contours. A binary image provides this information much better than a single (RGB) color channel image. In a later portion of the blog, we have resultant images when using only a single R, G, or B channel instead of grayscale and thresholded images.\n\nUse the function to detect the contours in the image.\n\nOnce contours have been identified, use the function to overlay the contours on the original RGB image.\n\nThe above steps will make much more sense, and become even clearer when we will start to code.\n\nStart by importing OpenCV, and reading the input image.\n\nWe assume that the image is inside the input folder of the current project directory. The next step is to convert the image into a grayscale image (single channel format).\n\nNote: All the C++ code is contained within the main() function.\n\nNext, use the function to convert the original RGB image to a grayscale image.\n\nNow, use the function to apply a binary threshold to the image. Any pixel with a value greater than 150 will be set to a value of 255 (white). All remaining pixels in the resulting image will be set to 0 (black). The threshold value of 150 is a tunable parameter, so you can experiment with it.\n\nAfter thresholding, visualize the binary image, using the function as shown below.\n\nCheck out the image below! It is a binary representation of the original RGB image. You can clearly see how the pen, the borders of the tablet and the phone are all white. The contour algorithm will consider these as objects, and find the contour points around the borders of these white objects.\n\nNote how the background is completely black, including the backside of the phone. Such regions will be ignored by the algorithm. Taking the white pixels around the perimeter of each object as similar-intensity pixels, the algorithm will join them to form a contour based on a similarity measure.\n\nNow, let’s find and draw the contours, using the method.\n\nStart with the function. It has three required arguments, as shown below. For optional arguments, please refer to the documentation page here.\n• : The binary input image obtained in the previous step.\n• : This is the contour-retrieval mode. We provided this as , which means the algorithm will retrieve all possible contours from the binary image. More contour retrieval modes are available, we will be discussing them too. You can learn more details on these options here.\n• : This defines the contour-approximation method. In this example, we will use .Though slightly slower than , we will use this method here tol store ALL contour points.\n\nIt’s worth emphasizing here that refers to the type of contours that will be retrieved, while refers to which points within a contour are stored. We will be discussing both in more detail below.\n\nIt is easy to visualize and understand results from different methods on the same image.\n\nIn the code samples below, we therefore make a copy of the original image and then demonstrate the methods (not wanting to edit the original).\n\nNext, use the function to overlay the contours on the RGB image. This function has four required and several optional arguments. The first four arguments below are required. For the optional arguments, please refer to the documentation page here.\n• : This is the input RGB image on which you want to draw the contour.\n• : Indicates the obtained from the function.\n• : The pixel coordinates of the contour points are listed in the obtained contours. Using this argument, you can specify the index position from this list, indicating exactly which contour point you want to draw. Providing a negative value will draw all the contour points.\n• : This indicates the color of the contour points you want to draw. We are drawing the points in green.\n• : This is the thickness of contour points.\n\nExecuting the above code will produce and display the image shown below. We also save the image to disk.\n\nThe following figure shows the original image (on the left), as well as the original image with the contours overlaid (on the right).\n\nAs you can see in the above figure, the contours produced by the algorithm do a nice job of identifying the boundary of each object. However, if you look closely at the phone, you will find that it contains more than one contour. Separate contours have been identified for the circular areas associated with the camera lens and light. There are also ‘secondary’ contours, along portions of the edge of the phone.\n\nKeep in mind that the accuracy and quality of the contour algorithm is heavily dependent on the quality of the binary image that is supplied (look at the binary image in the previous section again, you can see the lines associated with these secondary contours). Some applications require high quality contours. In such cases, experiment with different thresholds when creating the binary image, and see if that improves the resulting contours.\n\nThere are other approaches that can be used to eliminate unwanted contours from the binary maps prior to contour generation. You can also use more advanced features associated with the contour algorithm that we will be discussing here.\n\nJust to get an idea, the following are some results when using red, green and blue channels separately, while detecting contours. We discussed this in the contour detection steps previously. The following are the Python and C++ code for the same image as above.\n\nThe following figure shows the contour detection results for all the three separate color channels.\n\nIn the above image we can see that the contour detection algorithm is not able to find the contours properly. This is because it is not able to detect the borders of the objects properly, and also the intensity difference between the pixels is not well defined. This is the reason we prefer to use a grayscale, and binary thresholded image for detecting contours.\n\nLet’s find out now how the algorithm works and what makes it different from the algorithm.\n\nHere’s the code for it:\n\nThe only difference here is that we specify the for as instead of .\n\nThe algorithm compresses horizontal, vertical, and diagonal segments along the contour and leaves only their end points. This means that any of the points along the straight paths will be dismissed, and we will be left with only the end points. For example, consider a contour, along a rectangle. All the contour points, except the four corner points will be dismissed. This method is faster than the because the algorithm does not store all the points, uses less memory, and therefore, takes less time to execute.\n\nThe following image shows the results.\n\nIf you observe closely, there are almost no differences between the outputs of CHAIN_APPROX_NONE and CHAIN_APPROX_SIMPLE.\n\nNow, why is that?\n\nThe credit goes to the function. Although the method typically results in fewer points, the function automatically connects adjacent points, joining them even if they are not in the list.\n\nSo, how do we confirm that the algorithm is actually working?\n• The most straightforward way is to loop over the contour points manually, and draw a circle on the detected contour coordinates, using OpenCV.\n• Also, we use a different image that will actually help us visualize the results of the algorithm.\n\nThe following code uses the above image to visualize the effect of the algorithm. Almost everything is the same as in the previous code example, except the two additional for loops and some variable names.\n• The first loop cycles over each contour area present in the list.\n• The second loops over each of the coordinates in that area.\n• We then draw a green circle on each coordinate point, using the function from OpenCV.\n• Finally, we visualize the results and save it to disk.\n\nExecuting the code above, produces the following result:\n\nObserve the output image, which is on the right-hand side in the above figure. Note that the vertical and horizontal sides of the book contain only four points at the corners of the book. Also observe that the letters and bird are indicated with discrete points and not line segments.\n\nHierarchies denote the parent-child relationship between contours. You will see how each contour-retrieval mode affects contour detection in images, and produces hierarchical results.\n\nObjects detected by contour-detection algorithms in an image could be:\n• Single objects scattered around in an image (as in the first example), or\n• Objects and shapes inside one another\n\nIn most cases, where a shape contains more shapes, we can safely conclude that the outer shape is a parent of the inner shape.\n\nTake a look at the following figure, it contains several simple shapes that will help demonstrate contour hierarchies.\n\nNow see below figure, where the contours associated with each shape in Figure 10 have been identified. Each of the numbers in Figure 11 have a significance.\n• All the individual numbers, i.e., 1, 2, 3, and 4 are separate objects, according to the contour hierarchy and parent-child relationship.\n• We can say that the 3a is a child of 3. Note that 3a represents the interior portion of contour 3.\n• Contours 1, 2, and 4 are all parent shapes, without any associated child, and their numbering is thus arbitrary. In other words, contour 2 could have been labeled as 1 and vice-versa.\n\nYou’ve seen that the function returns two outputs: The contours list, and the hierarchy. Let’s now understand the contour hierarchy output in detail.\n\nThe contour hierarchy is represented as an array, which in turn contains arrays of four values. It is represented as:\n\nSo, what do all these values mean?\n\n: Denotes the next contour in an image, which is at the same hierarchical level. So,\n• For contour 1, the next contour at the same hierarchical level is 2. Here, will be 2.\n• Accordingly, contour 3 has no contour at the same hierarchical level as itself. So, it’s value will be -1.\n\n: Denotes the previous contour at the same hierarchical level. This means that contour 1 will always have its value as -1.\n\n: Denotes the first child contour of the contour we are currently considering.\n• Contours 1 and 2 have no children at all. So, the index values for their will be -1.\n• But contour 3 has a child. So, for contour 3, the position value will be the index position of 3a.\n\n: Denotes the parent contour’s index position for the current contour.\n• Contours 1 and 2, as is obvious, do not have any contour.\n• For the contour 3a, its is going to be contour 3\n• For contour 4, the parent is contour 3a\n\nThe above explanations make sense, but how do we actually visualize these hierarchy arrays? The best way is to:\n• Use a simple image with lines and shapes like the previous image\n• Detect the contours and hierarchies, using different retrieval modes\n• Then print the values to visualize them\n\nThus far, we used one specific retrieval technique, to find and draw contours, but there are three more contour-retrieval techniques in OpenCV, namely, , and .\n\nSo let’s now use the image in Figure 10 to review each of these four methods, along with their associated code to get the contours.\n\nThe following code reads the image from disk, converts it to grayscale, and applies binary thresholding.\n\nThe contour retrieval method does not create any parent child relationship between the extracted contours. So, for all the contour areas that are detected, the and index position values are always -1.\n\nAll the contours will have their corresponding and contours as discussed above.\n\nSee how the method is implemented in code.\n\nExecuting the above code produces the following output:\n\nYou can clearly see that the 3rd and 4th index positions of all the detected contour areas are -1, as expected.\n\nThe contour retrieval method is a really interesting one. It only detects the parent contours, and ignores any child contours. So, all the inner contours like 3a and 4 will not have any points drawn on them.\n\nThe above code produces the following output:\n\nThe above output image shows only the points drawn on contours 1, 2, and 3. Contours 3a and 4 are omitted as they are child contours.\n\nUnlike retrieves all the contours in an image. Along with that, it also applies a 2-level hierarchy to all the shapes or objects in the image.\n• All the outer contours will have hierarchy level 1\n• All the inner contours will have hierarchy level 2\n\nBut what if we have a contour inside another contour with hierarchy level 2? Just like we have contour 4 after contour 3a.\n• Again, contour 4 will have hierarchy level 1.\n• If there are any contours inside contour 4, they will have hierarchy level 2.\n\nIn the following image, the contours have been numbered according to their hierarchy level, as explained above.\n\nThe above image shows the hierarchy level as HL-1 or HL-2 for levels 1 and 2 respectively. Now, let us take a look at the code and the output hierarchy array also.\n\nExecuting the above code produces the following output:\n\nHere, we see that all the , , , and relationships are maintained, according to the contour-retrieval method, as all the contours are detected. As expected, the of the first contour area is -1. And the contours which do not have any , also have the value -1\n\nJust like also retrieves all the contours. It also creates a complete hierarchy, with the levels not restricted to 1 or 2. Each contour can have its own hierarchy, in line with the level it is on, and the corresponding parent-child relationship that it has.\n\nFrom the above figure, it is clear that:\n• Contours 1, 2, and 3 are at the same level, that is level 0.\n• Contour 3a is present at hierarchy level 1, as it is a child of contour 3.\n• Contour 4 is a new contour area, so its hierarchy level is 2.\n\nThe following code uses mode to retrieve contours.\n\nExecuting the above code produces the following output:\n\nFinally, let’s look at the complete image with all the contours drawn when using mode.\n\nAll the contours are drawn as expected, and the contour areas are clearly visible. You also infer that contours 3 and 3a are two separate contours, as they have different contour boundaries and areas. At the same time, it is very evident that contour 3a is a child of contour 3.\n\nNow that you are familiar with all the contour algorithms available in OpenCV, along with their respective input parameters and configurations, go experiment and see for yourself how they work.\n\nIt’s not enough to know the contour-retrieval methods. You should also be aware of their relative processing time. The following table compares the runtime for each method discussed above.\n\nSome interesting conclusions emerge from the above table:\n• and take the least amount of time to execute, since does not define any hierarchy and only retrieves the parent contours\n• takes the second highest time to execute. It retrieves all the contours and defines a two-level hierarchy.\n• takes the maximum time to execute for it retrieves all the contours, and defines the independent hierarchy level for each parent-child relationship as well.\n\nAlthough the above times may not seem significant, it is important to be aware of the differences for applications that may require a significant amount of contour processing. It is also worth noting that this processing time may vary, depending to an extent on the contours they extract, and the hierarchy levels they define.\n\nSo far, all the examples we explored seemed interesting, and their results encouraging. However, there are cases where the contour algorithm might fail to deliver meaningful and useful results. Let’s consider such an example too.\n• When the objects in an image are strongly contrasted against their background, you can clearly identify the contours associated with each object. But what if you have an image, like Figure 16 below. It not only has a bright object (puppy), but also a background cluttered with the same value (brightness) as the object of interest (puppy). You find that the contours in the right-hand image are not even complete. Also, there are multiple unwanted contours standing out in the background area.\n• Contour detection can also fail, when the background of the object in the image is full of lines.\n\nIf you think that you have learned something interesting in this article and would like to expand your knowledge, then you may like the Computer Vision 1 course offered by OpenCV. This is a great course to get started with OpenCV and Computer Vision which will be very hands-on and perfect to get you started and up to speed with OpenCV. The best part, you can take it in either Python or C++, whichever you choose. You can visit the course page here to know more about it.\n\nYou started with contour detection, and learned to implement that in OpenCV. Saw how applications use contours for mobility detection and segmentation. Next, we demonstrated the use of four different retrieval modes and two contour-approximation methods. You also learned to draw contours. We concluded with a discussion of contour hierarchies, and how different contour-retrieval modes affect the drawing of contours on an image.\n• The contour-detection algorithms in OpenCV work very well, when the image has a dark background and a well-defined object-of-interest.\n• But when the background of the input image is cluttered or has the same pixel intensity as the object-of-interest, the algorithms don’t fare so well.\n\nYou have all the code here, why not experiment with different images now! Try images containing varied shapes, and experiment with different threshold values. Also, explore different retrieval modes, using test images that contain nested contours. This way, you can fully appreciate the hierarchical relationships between objects."
    },
    {
        "link": "https://stackoverflow.com/questions/64002869/how-to-combine-bounding-boxes-in-opencv-python",
        "document": "Hello I have an array of rectangles that represent the bounding boxes for detected objects. Often, these rectangles overlap and I would like to merge all rectangles that are intersecting into one big rectangle (and have multiple rectangles on screen if there are two separate clusters for example). Is there a way to do this?\n\nI have already tried , but clusters of rectangles are grouped into one rectangle in the middle that is the same size as the original rectangles.\n\nHere is the pic without grouping:\n\nHere is the pic with grouping and the method described below\n\nTo clarify a little more about what I am looking for I would just want red boxes over the individual blocks (Or ideally one box over the entire row), instead of in the middle, just so can condense the amount of boxes that I need to do computations for to speed up the program"
    },
    {
        "link": "https://stackoverflow.com/questions/66490374/how-to-merge-nearby-bounding-boxes-opencv",
        "document": "I started with your code as a base to get the green rectangles. I filtered the boxes by size to get rid of the big ones that contained large chunks of the image (there's even one that goes around the entire image). From there I iteratively merged nearby boxes until there were no more overlapping boxes. I used the merge_margin variable to set how close two boxes needed to be before they counted as \"overlapping\".\n\nEach Step (I highlighted the last merged box and the points it found inside) (This gif is heavily compressed so you'll see some artifacting)\n\nEdit: The inefficiency of this bothered me a bit. The order that the boxes gets merged in doesn't really make sense. You can see that there are a lot of steps where little boxes are merging into a big box, rather than a big box eating everything inside of itself and growing. Turns out this was a really easy code fix. Since the new merged boxes are appended to the end of the boxes list, we can just index in reverse to make it so that we go from big to small.\n\nI changed the merge_margin to 15 since I think that's closer to the target solution in the question."
    },
    {
        "link": "https://answers.opencv.org/question/194536/python-merge-overlapping-bounding-boxes-replace-by-surrounding-bounding-box",
        "document": ""
    },
    {
        "link": "https://answers.opencv.org/question/59217/multiple-contour-bounding-box",
        "document": ""
    },
    {
        "link": "https://reddit.com/r/computervision/comments/emtbut/dilation_of_bounding_boxes_how_to_merge_all_red",
        "document": "Computer Vision is the scientific subfield of AI concerned with developing algorithms to extract meaningful information from raw images, videos, and sensor data. This community is home to the academics and engineers both advancing and applying this interdisciplinary field, with backgrounds in computer science, machine learning, robotics, mathematics, and more. We welcome everyone from published researchers to beginners!"
    }
]