[
    {
        "link": "https://mongoosejs.com/docs/connections.html",
        "document": "You can connect to MongoDB with the method.\n\nThis is the minimum needed to connect the database running locally on the default port (27017). For local MongoDB databases, we recommend using instead of . That is because Node.js 18 and up prefer IPv6 addresses, which means, on many machines, Node.js will resolve to the IPv6 address and Mongoose will be unable to connect, unless the mongodb instance is running with ipv6 enabled.\n\nYou can also specify several more parameters in the :\n\nSee the mongodb connection string spec for more details.\n\nMongoose lets you start using your models immediately, without waiting for mongoose to establish a connection to MongoDB.\n\nThat's because mongoose buffers model function calls internally. This buffering is convenient, but also a common source of confusion. Mongoose will not throw any errors by default if you use a model without connecting.\n\nTo disable buffering, turn off the option on your schema. If you have on and your connection is hanging, try turning off to see if you haven't opened a connection properly. You can also disable globally:\n\nNote that buffering is also responsible for waiting until Mongoose creates collections if you use the option. If you disable buffering, you should also disable the option and use to create capped collections or collections with collations.\n\nThere are two classes of errors that can occur with a Mongoose connection.\n• Error on initial connection: If initial connection fails, Mongoose will emit an 'error' event and the promise returns will reject. However, Mongoose will not automatically try to reconnect.\n• Error after initial connection was established: Mongoose will attempt to reconnect, and it will emit an 'error' event.\n\nTo handle initial connection errors, you should use or with async/await.\n\nTo handle errors after initial connection was established, you should listen for error events on the connection. However, you still need to handle initial connection errors as shown above.\n\nNote that Mongoose does not necessarily emit an 'error' event if it loses connectivity to MongoDB. You should listen to the event to report when Mongoose is disconnected from MongoDB.\n\nThe method also accepts an object which will be passed on to the underlying MongoDB driver.\n\nA full list of options can be found on the MongoDB Node.js driver docs for . Mongoose passes options to the driver without modification, modulo a few exceptions that are explained below.\n• - This is a mongoose-specific option (not passed to the MongoDB driver) that disables Mongoose's buffering mechanism\n• / - The username and password for authentication. These options are Mongoose-specific, they are equivalent to the MongoDB driver's and options.\n• - By default, mongoose will automatically build indexes defined in your schema when it connects. This is great for development, but not ideal for large production deployments, because index builds can cause performance degradation. If you set to false, mongoose will not automatically build indexes for any model associated with this connection.\n• - Specifies which database to connect to and overrides any database specified in the connection string. This is useful if you are unable to specify a default database in the connection string like with some syntax connections.\n\nBelow are some of the options that are important for tuning Mongoose.\n• - The maximum number of sockets the MongoDB driver will keep open for this connection. By default, is 100. Keep in mind that MongoDB only allows one operation per socket at a time, so you may want to increase this if you find you have a few slow queries that are blocking faster queries from proceeding. See Slow Trains in MongoDB and Node.js. You may want to decrease if you are running into connection limits.\n• - The minimum number of sockets the MongoDB driver will keep open for this connection. The MongoDB driver may close sockets that have been inactive for some time. You may want to increase if you expect your app to go through long idle times and want to make sure your sockets stay open to avoid slow trains when activity picks up.\n• - How long the MongoDB driver will wait before killing a socket due to inactivity after initial connection. A socket may be inactive because of either no activity or a long-running operation. defaults to 0, which means Node.js will not time out the socket due to inactivity. This option is passed to Node.js function after the MongoDB driver successfully completes.\n• - Whether to connect using IPv4 or IPv6. This option passed to Node.js' function. If you don't specify this option, the MongoDB driver will try IPv6 first and then IPv4 if IPv6 fails. If your call takes a long time, try\n• - The database to use when authenticating with and . In MongoDB, users are scoped to a database. If you are getting an unexpected login failure, you may need to set this option.\n• - The MongoDB driver will try to find a server to send any given operation to, and keep retrying for milliseconds. If not set, the MongoDB driver defaults to using (30 seconds).\n• - The MongoDB driver sends a heartbeat every to check on the status of the connection. A heartbeat is subject to , so the MongoDB driver will retry failed heartbeats for up to 30 seconds by default. Mongoose only emits a event after a heartbeat has failed, so you may want to decrease this setting to reduce the time between when your server goes down and when Mongoose emits . We recommend you do not set this setting below 1000, too many heartbeats can lead to performance degradation.\n\nThe option is extremely important: it controls how long the MongoDB Node.js driver will attempt to retry any operation before erroring out. This includes initial connection, like , as well as any operations that make requests to MongoDB, like or .\n\nBy default, is 30000 (30 seconds). This means that, for example, if you call when your standalone MongoDB server is down, your call will only throw an error after 30 seconds.\n\nSimilarly, if your standalone MongoDB server goes down after initial connection, any or calls will error out after 30 seconds, unless your MongoDB server is restarted.\n\nWhile 30 seconds seems like a long time, means you're unlikely to see any interruptions during a replica set failover. If you lose your replica set primary, the MongoDB Node driver will ensure that any operations you send during the replica set election will eventually execute, assuming that the replica set election takes less than .\n\nTo get faster feedback on failed connections, you can reduce to 5000 as follows. We don't recommend reducing unless you are running a standalone MongoDB server rather than a replica set, or unless you are using a serverless runtime like AWS Lambda.\n\nThere is no way to tune independently for vs for queries. If you want to reduce for queries and other operations, but still retry for longer, you are responsible for retrying the calls yourself using a loop or a tool like p-retry.\n\nThe function also accepts a callback parameter and returns a promise.\n\nYou can also specify driver options in your connection string as parameters in the query string portion of the URI. This only applies to options passed to the MongoDB driver. You can't set Mongoose-specific options like in the query string.\n\nThe disadvantage of putting options in the query string is that query string options are harder to read. The advantage is that you only need a single configuration option, the URI, rather than separate options for , etc. Best practice is to put options that likely differ between development and production, like or , in the connection string, and options that should remain constant, like or , in the options object.\n\nThe MongoDB docs have a full list of supported connection string options. Below are some options that are often useful to set in the connection string because they are closely associated with the hostname and authentication information.\n• - The database to use when authenticating with and . In MongoDB, users are scoped to a database. If you are getting an unexpected login failure, you may need to set this option.\n• - Whether to connect using IPv4 or IPv6. This option passed to Node.js' function. If you don't specify this option, the MongoDB driver will try IPv6 first and then IPv4 if IPv6 fails. If your call takes a long time, try\n\nConnections inherit from Node.js' class, and emit events when something happens to the connection, like losing connectivity to the MongoDB server. Below is a list of events that a connection may emit.\n• : Emitted when Mongoose starts making its initial connection to the MongoDB server\n• : Emitted when Mongoose successfully makes its initial connection to the MongoDB server, or when Mongoose reconnects after losing connectivity. May be emitted multiple times if Mongoose loses connectivity.\n• : Emitted after and is executed on all of this connection's models. May be emitted multiple times if Mongoose loses connectivity.\n• : Your app called to disconnect from MongoDB. This includes calling , which calls on all connections.\n• : Emitted when Mongoose lost connection to the MongoDB server. This event may be due to your code explicitly closing the connection, the database server crashing, or network connectivity issues.\n• : Emitted after successfully closes the connection. If you call , you'll get both a 'disconnected' event and a 'close' event.\n• : Emitted if Mongoose lost connectivity to MongoDB and successfully reconnected. Mongoose attempts to automatically reconnect when it loses connection to the database.\n• : Emitted if an error occurs on a connection, like a due to malformed data or a payload larger than 16MB.\n\nWhen you're connecting to a single MongoDB server (a \"standalone\"), Mongoose will emit if it gets disconnected from the standalone server, and if it successfully connects to the standalone. In a replica set, Mongoose will emit if it loses connectivity to the replica set primary, and if it manages to reconnect to the replica set primary.\n\nIf you are using , you can use the following to listen to the above events:\n\nWith , use the following instead:\n\nBefore Mongoose 5.2.0, you needed to enable the option to initiate TCP keepalive to prevent errors. However, has been by default since Mongoose 5.2.0, and the is deprecated as of Mongoose 7.2.0. Please remove and options from your Mongoose connections.\n\nTo connect to a replica set you pass a comma delimited list of hosts to connect to rather than a single host.\n\nTo connect to a single node replica set, specify the option.\n\nThe underlying MongoDB driver uses a process known as server selection to connect to MongoDB and send operations to MongoDB. If the MongoDB driver can't find a server to send an operation to after , you'll get the below error:\n\nYou can configure the timeout using the option to :\n\nA has a property that explains why server selection timed out. For example, if you're connecting to a standalone server with an incorrect password, will contain an \"Authentication failed\" error.\n\nMongoDB replica sets rely on being able to reliably figure out the domain name for each member.\n\nOn Linux and OSX, the MongoDB server uses the output of the command to figure out the domain name to report to the replica set. This can cause confusing errors if you're connecting to a remote MongoDB replica set running on a machine that reports its as :\n\nIf you're experiencing a similar error, connect to the replica set using the shell and run the command to check the host names of each replica set member. Follow this page's instructions to change a replica set member's host name.\n\nYou can also check the property of to see what the MongoDB Node driver thinks the state of your replica set is. The property contains a map of server descriptions.\n\nYou can also connect to multiple mongos instances for high availability in a sharded cluster. You do not need to pass any special options to connect to multiple mongos in mongoose 5.x.\n\nSo far we've seen how to connect to MongoDB using Mongoose's default connection. Mongoose creates a default connection when you call . You can access the default connection using .\n\nYou may need multiple connections to MongoDB for several reasons. One reason is if you have multiple databases or multiple MongoDB clusters. Another reason is to work around slow trains. The function takes the same arguments as and returns a new connection.\n\nThis connection object is then used to create and retrieve models. Models are always scoped to a single connection.\n\nThe function returns a connection instance, not a promise. If you want to use to make sure Mongoose successfully connects to MongoDB, use the function:\n\nIf you use multiple connections, you should make sure you export schemas, not models. Exporting a model from a file is called the export model pattern. The export model pattern is limited because you can only use one connection.\n\nIf you use the export schema pattern, you still need to create models somewhere. There are two common patterns. The first is to create a function that instantiates a new connection and registers all models on that connection. With this pattern, you may also register connections with a dependency injector or another inversion of control (IOC) pattern.\n\nExporting a function that creates a new connection is the most flexible pattern. However, that pattern can make it tricky to get access to your connection from your route handlers or wherever your business logic is. An alternative pattern is to export a connection and register the models on the connection in the file's top-level scope as follows.\n\nYou can create separate files for each connection, like and if you want to create separate connections for your web API backend and your mobile API backend. Your business logic can then or the connection it needs.\n\nEach , whether created with or are all backed by an internal configurable connection pool defaulting to a maximum size of 100. Adjust the pool size using your connection options:\n\nThe connection pool size is important because MongoDB currently can only process one operation per socket. So functions as a cap on the number of concurrent operations.\n\nIn the context of Mongoose, a multi-tenant architecture typically means a case where multiple different clients talk to MongoDB through a single Mongoose application. This typically means each client makes queries and executes updates through a single Mongoose application, but has a distinct MongoDB database within the same MongoDB cluster.\n\nWe recommend reading this article about multi-tenancy with Mongoose; it has a good description of how we define multi-tenancy and a more detailed overview of our recommended patterns.\n\nThere are two patterns we recommend for multi-tenancy in Mongoose:\n• Maintain one connection pool, switch between tenants using the method.\n• Maintain a separate connection pool per tenant, store connections in a map or POJO.\n\nThe following is an example of pattern (1). We recommend pattern (1) for cases where you have a small number of tenants, or if each individual tenant's workload is light (approximately < 1 request per second, all requests take < 10ms of database processing time). Pattern (1) is simpler to implement and simpler to manage in production, because there is only 1 connection pool. But, under high load, you will likely run into issues where some tenants' operations slow down other tenants' operations due to slow trains.\n\nThe following is an example of pattern (2). Pattern (2) is more flexible and better for use cases with > 10k tenants and > 1 requests/second. Because each tenant has a separate connection pool, one tenants' slow operations will have minimal impact on other tenants. However, this pattern is harder to implement and manage in production. In particular, MongoDB does have a limit on the number of open connections, and MongoDB Atlas has separate limits on the number of open connections, so you need to make sure the total number of sockets in your connection pools doesn't go over MongoDB's limits.\n\nNow that we've covered connections, let's take a look at models."
    },
    {
        "link": "https://stackoverflow.com/questions/6676499/is-there-a-mongoose-connect-error-callback",
        "document": "As we can see on the mongoose documentation for Error Handling, since the connect() method returns a Promise, the promise is the option to use with a mongoose connection.\n\nSo, to handle initial connection errors, you should use or with .\n\nIn this way, we have two options:\n\nIMHO, I think that using is a cleaner way."
    },
    {
        "link": "https://mongodb.com/docs/atlas/troubleshoot-connection",
        "document": "This page outlines common connection issues and possible resolutions.\n\nTo learn more about connecting to an Atlas cluster, see the Get Started with Atlas tutorial.\n\nYour cluster's Connect button may be disabled if your cluster is in the provisioning state. Your cluster needs to provision when it is first deployed. Clusters also must provision when you scaled them up or down. The provisoning process can take up to 10 minutes, after which the Connect button will become enabled.\n\nToo many open connections to your cluster Atlas sets limits for concurrent incoming connections to a cluster. For clusters, this is based on the cluster tier. If you try to connect when you are at this limit, MongoDB displays an error stating connection refused because too many open connections . For a detailed comparision of cluster tiers and their maximum concurrent connections, see Connection Limits and Cluster Tier .\n• None Close any open connections to your cluster not currently in use.\n• None Scale your cluster to a higher tier to support more concurrent connections.\n• None To prevent this issue in the future, consider using the connection string option to limit the number of connections in the connection pool. To learn how to fix this issue, see Fix Connection Issues .\n\nDegraded performance in sharded clusters during spikes in connection counts Atlas can generate an optimized SRV connection string for sharded clusters using the load balancers from your private endpoint service. When you use an optimized connection string, Atlas limits the number of connections per between your application and your sharded cluster. The limited connections per improve performance during spikes in connection counts. To learn more about optimized connection strings for sharded clusters behind a private endpoint, see Improve Connection Performance for Sharded Clusters Behind a Private Endpoint .\n\nAttempting to connect from behind a firewall Atlas uses a CDN to serve content quickly. If your organization uses a firewall, add the following Atlas CDN host to the firewall's allow list to prevent issues accessing the Atlas UI: . Atlas clusters operate on port . You must be able to reach this port to connect to your clusters. Additionally, ensure that the appropriate ports are open for the following: You can check your ability to reach a port using the third-party Outgoing port tester. To check your ability to reach port 27017, visit http://portquiz.net:27017 . If you can't access these ports, check your system firewall settings and ensure that they are not blocking access to these ports.\n\nIf you use MongoDB Compass to connect to your cluster and experience issues, see:\n• None Connection Refused using SRV Connection String in this section. If you use a self-managed X.509 certificate or an auto-generated X.509 certificate managed by Atlas to authenticate to the MongoDB database, when you connect to MongoDB Compass , you must:\n• None In the SSL dropdown, select Server and Client Validation.\n• None Add the same path to the downloaded Atlas -managed certificate, or the self-managed certificate (depending on which you use) to each of these fields: Certificate Authority, Client Certificate, and Client Private Key. To learn more, see Connect to MongoDB in the MongoDB Compass documentation.\n\nThe connection string format you use to connect to Atlas depends on several factors, including:\n• None Your version. To learn more, see Connect via .\n• None Your driver version. To learn more, see Connect via Drivers . Verify your connection string in a test environment before putting it into production. If your password includes special characters, and you are using your password in a connection string URI, encode the special characters. If you try to update a password with a special character that requires percent encoding , the following error message appears: This password contains special characters which will be URL-encoded. The following characters and the space character must be converted using percent encoding if included in a username or password: For example, if your password in plain-text is , you need to encode your password as: ➤ Use the Select your language drop-down menu to set the language of the encoding example in this section. Do not encode special characters in your password if you are using your password outside of a connection string URI (for example, pasting it into ). If you see this error message, your driver is likely out of date. For instructions on updating your driver, refer to your specific Driver Documentation . When you use the DNS seed list connection string format to connect to Atlas , you might see the following error: DNSHostNotFound: Failed to look up service \"<MongoDB service name>\" This error may occur when using the default DNS server that your ISP provides. That DNS server might not support SRV lookups that the DNS seed list connection string format uses. To resolve the issue, you can try changing your DNS configuration to use a public DNS server . You can configure your network settings to use Google Public DNS instead of your ISP's DNS servers. After you update your network settings to use a public DNS server, connect to the cluster . If running Ubuntu 18.04 and using the DNS seed list connection string format ( ) to connect to Atlas from one of the MongoDB Database Tools ( , , etc), you might see the following error: If so, use one of the following connection options instead:\n• None use the option with a non-SRV connection string ( ).\n• None use the option to specify the host to connect. When using the DNS seed list connection string format ( ) with a driver or Compass, you may receive in the following error: To begin troubleshooting you will need both the DNS SRV name and the nodes' individual hostnames and port numbers from the seed list connection string for the cluster. To find the DNS SRV name:\n• None Follow the Steps 1-6 in Connect Your Application.\n• None In Step 7 select the latest version of the driver you chose.\n• None The DNS SRV name begins after the symbol following the password and ends with . - For example, . To find the nodes' hostnames and port numbers:\n• None Follow the Steps 1-6 in Connect Your Application.\n• None In Step 7 select the latest version of the driver you chose.\n• None In Step 7 select the oldest driver version under Non-Stable API\n• None Each of the hostnames is in a comma-separated list beginning after the symbol following the password and ending with .\n• None Note the port numbers after each of the hostnames.\n• None The cluster's connection string may have a variety of hostnames and ports, depending on its topology and the connection method.\n• None For more information on how Private Endpoints work, see Configure Private Endpoints. Run the following commands in a terminal or command prompt on the application server experiencing the issue:\n• None Under the ANSWER SECTION in the response, you should see one result for each of the nodes in the cluster. - For example:\n• None For each hostname in the cluster run this command: Under the ANSWER SECTION in the response, you should see the IP address that the DNS hostname resolved to.\n• None ICMP requests may be blocked by the cloud provider across Private Endpoint connections. For each hostname in the cluster run this command:"
    },
    {
        "link": "https://stackoverflow.com/questions/11864482/error-handling-with-mongoose",
        "document": "Simpler and more up to date solution IMO:\n\nHandle connection level errors when you instantiate your db:\n\nQuery level errors may appear if you write fields with wrong types or use query options (populate, sort...) incorrectly. We can use a more readable/up to date over the old syntax (mongoose doc)\n\n=> Use an error handler across all your app\n\nError handling in the 2 example above are not very relevant because you loose all contextual informations (mongo error msg, stack trace, database name, userId...)\n\nYou may handle errors in a centralized way so that you can pass contextual informations alongside the error message like so:\n\nList of all error types thrown by mongoose\n\n=> Use a request handler to handle all mongoose queries the same way\n\nA common pattern to avoid duplicating code is to create a function to handle the execution of mongoose promise for you:\n\nSo we can now use it like:\n\nThis pattern has the advantage of:\n• handling all in the same place, so it's the safest place to add custom code for security handling or validation for example\n• easily exposing some options like pagination... to api or some services that you may not want to deal directly with mongoose requests\n\nThe above is juste a very simplified example, but to go further, here are some features we could implement:\n• check if the user has the permission to populate\n• masking certain fields in filter or updated/created fields related to user permissions (a simple user may not been able to write his permissions for example)\n• force certain filters (companyAdmin may have access only to their company so we want to enforce filter"
    },
    {
        "link": "https://mongoosejs.com/docs/7.x/docs/connections.html",
        "document": "You can connect to MongoDB with the method.\n\nThis is the minimum needed to connect the database running locally on the default port (27017). For local MongoDB databases, we recommend using instead of . That is because Node.js 18 and up prefer IPv6 addresses, which means, on many machines, Node.js will resolve to the IPv6 address and Mongoose will be unable to connect, unless the mongodb instance is running with ipv6 enabled.\n\nYou can also specify several more parameters in the :\n\nSee the mongodb connection string spec for more details.\n\nMongoose lets you start using your models immediately, without waiting for mongoose to establish a connection to MongoDB.\n\nThat's because mongoose buffers model function calls internally. This buffering is convenient, but also a common source of confusion. Mongoose will not throw any errors by default if you use a model without connecting.\n\nTo disable buffering, turn off the option on your schema. If you have on and your connection is hanging, try turning off to see if you haven't opened a connection properly. You can also disable globally:\n\nNote that buffering is also responsible for waiting until Mongoose creates collections if you use the option. If you disable buffering, you should also disable the option and use to create capped collections or collections with collations.\n\nThere are two classes of errors that can occur with a Mongoose connection.\n• Error on initial connection: If initial connection fails, Mongoose will emit an 'error' event and the promise returns will reject. However, Mongoose will not automatically try to reconnect.\n• Error after initial connection was established: Mongoose will attempt to reconnect, and it will emit an 'error' event.\n\nTo handle initial connection errors, you should use or with async/await.\n\nTo handle errors after initial connection was established, you should listen for error events on the connection. However, you still need to handle initial connection errors as shown above.\n\nNote that Mongoose does not necessarily emit an 'error' event if it loses connectivity to MongoDB. You should listen to the event to report when Mongoose is disconnected from MongoDB.\n\nThe method also accepts an object which will be passed on to the underlying MongoDB driver.\n\nA full list of options can be found on the MongoDB Node.js driver docs for . Mongoose passes options to the driver without modification, modulo a few exceptions that are explained below.\n• - This is a mongoose-specific option (not passed to the MongoDB driver) that disables Mongoose's buffering mechanism\n• / - The username and password for authentication. These options are Mongoose-specific, they are equivalent to the MongoDB driver's and options.\n• - By default, mongoose will automatically build indexes defined in your schema when it connects. This is great for development, but not ideal for large production deployments, because index builds can cause performance degradation. If you set to false, mongoose will not automatically build indexes for any model associated with this connection.\n• - Specifies which database to connect to and overrides any database specified in the connection string. This is useful if you are unable to specify a default database in the connection string like with some syntax connections.\n\nBelow are some of the options that are important for tuning Mongoose.\n• - The maximum number of sockets the MongoDB driver will keep open for this connection. By default, is 100. Keep in mind that MongoDB only allows one operation per socket at a time, so you may want to increase this if you find you have a few slow queries that are blocking faster queries from proceeding. See Slow Trains in MongoDB and Node.js. You may want to decrease if you are running into connection limits.\n• - The minimum number of sockets the MongoDB driver will keep open for this connection. The MongoDB driver may close sockets that have been inactive for some time. You may want to increase if you expect your app to go through long idle times and want to make sure your sockets stay open to avoid slow trains when activity picks up.\n• - How long the MongoDB driver will wait before killing a socket due to inactivity after initial connection. A socket may be inactive because of either no activity or a long-running operation. defaults to 0, which means Node.js will not time out the socket due to inactivity. This option is passed to Node.js function after the MongoDB driver successfully completes.\n• - Whether to connect using IPv4 or IPv6. This option passed to Node.js' function. If you don't specify this option, the MongoDB driver will try IPv6 first and then IPv4 if IPv6 fails. If your call takes a long time, try\n• - The database to use when authenticating with and . In MongoDB, users are scoped to a database. If you are getting an unexpected login failure, you may need to set this option.\n• - The MongoDB driver will try to find a server to send any given operation to, and keep retrying for milliseconds. If not set, the MongoDB driver defaults to using (30 seconds).\n• - The MongoDB driver sends a heartbeat every to check on the status of the connection. A heartbeat is subject to , so the MongoDB driver will retry failed heartbeats for up to 30 seconds by default. Mongoose only emits a event after a heartbeat has failed, so you may want to decrease this setting to reduce the time between when your server goes down and when Mongoose emits . We recommend you do not set this setting below 1000, too many heartbeats can lead to performance degradation.\n\nThe option is extremely important: it controls how long the MongoDB Node.js driver will attempt to retry any operation before erroring out. This includes initial connection, like , as well as any operations that make requests to MongoDB, like or .\n\nBy default, is 30000 (30 seconds). This means that, for example, if you call when your standalone MongoDB server is down, your call will only throw an error after 30 seconds.\n\nSimilarly, if your standalone MongoDB server goes down after initial connection, any or calls will error out after 30 seconds, unless your MongoDB server is restarted.\n\nWhile 30 seconds seems like a long time, means you're unlikely to see any interruptions during a replica set failover. If you lose your replica set primary, the MongoDB Node driver will ensure that any operations you send during the replica set election will eventually execute, assuming that the replica set election takes less than .\n\nTo get faster feedback on failed connections, you can reduce to 5000 as follows. We don't recommend reducing unless you are running a standalone MongoDB server rather than a replica set, or unless you are using a serverless runtime like AWS Lambda.\n\nThere is no way to tune independently for vs for queries. If you want to reduce for queries and other operations, but still retry for longer, you are responsible for retrying the calls yourself using a loop or a tool like p-retry.\n\nThe function also accepts a callback parameter and returns a promise.\n\nYou can also specify driver options in your connection string as parameters in the query string portion of the URI. This only applies to options passed to the MongoDB driver. You can't set Mongoose-specific options like in the query string.\n\nThe disadvantage of putting options in the query string is that query string options are harder to read. The advantage is that you only need a single configuration option, the URI, rather than separate options for , etc. Best practice is to put options that likely differ between development and production, like or , in the connection string, and options that should remain constant, like or , in the options object.\n\nThe MongoDB docs have a full list of supported connection string options. Below are some options that are often useful to set in the connection string because they are closely associated with the hostname and authentication information.\n• - The database to use when authenticating with and . In MongoDB, users are scoped to a database. If you are getting an unexpected login failure, you may need to set this option.\n• - Whether to connect using IPv4 or IPv6. This option passed to Node.js' function. If you don't specify this option, the MongoDB driver will try IPv6 first and then IPv4 if IPv6 fails. If your call takes a long time, try\n\nConnections inherit from Node.js' class, and emit events when something happens to the connection, like losing connectivity to the MongoDB server. Below is a list of events that a connection may emit.\n• : Emitted when Mongoose starts making its initial connection to the MongoDB server\n• : Emitted when Mongoose successfully makes its initial connection to the MongoDB server, or when Mongoose reconnects after losing connectivity. May be emitted multiple times if Mongoose loses connectivity.\n• : Emitted after and is executed on all of this connection's models.\n• : Your app called to disconnect from MongoDB\n• : Emitted when Mongoose lost connection to the MongoDB server. This event may be due to your code explicitly closing the connection, the database server crashing, or network connectivity issues.\n• : Emitted after successfully closes the connection. If you call , you'll get both a 'disconnected' event and a 'close' event.\n• : Emitted if Mongoose lost connectivity to MongoDB and successfully reconnected. Mongoose attempts to automatically reconnect when it loses connection to the database.\n• : Emitted if an error occurs on a connection, like a due to malformed data or a payload larger than 16MB.\n• : Emitted when you're connecting to a replica set and Mongoose has successfully connected to the primary and at least one secondary.\n• : Emitted when you're connecting to a replica set and Mongoose has successfully connected to all servers specified in your connection string.\n\nWhen you're connecting to a single MongoDB server (a \"standalone\"), Mongoose will emit 'disconnected' if it gets disconnected from the standalone server, and 'connected' if it successfully connects to the standalone. In a replica set, Mongoose will emit 'disconnected' if it loses connectivity to the replica set primary, and 'connected' if it manages to reconnect to the replica set primary.\n\nBefore Mongoose 5.2.0, you needed to enable the option to initiate TCP keepalive to prevent errors errors. However, has been by default since Mongoose 5.2.0, and the is deprecated as of Mongoose 7.2.0. Please remove and options from your Mongoose connections.\n\nTo connect to a replica set you pass a comma delimited list of hosts to connect to rather than a single host.\n\nTo connect to a single node replica set, specify the option.\n\nThe underlying MongoDB driver uses a process known as server selection to connect to MongoDB and send operations to MongoDB. If the MongoDB driver can't find a server to send an operation to after , you'll get the below error:\n\nYou can configure the timeout using the option to :\n\nA has a property that explains why server selection timed out. For example, if you're connecting to a standalone server with an incorrect password, will contain an \"Authentication failed\" error.\n\nMongoDB replica sets rely on being able to reliably figure out the domain name for each member.\n\nOn Linux and OSX, the MongoDB server uses the output of the command to figure out the domain name to report to the replica set. This can cause confusing errors if you're connecting to a remote MongoDB replica set running on a machine that reports its as :\n\nIf you're experiencing a similar error, connect to the replica set using the shell and run the command to check the host names of each replica set member. Follow this page's instructions to change a replica set member's host name.\n\nYou can also check the property of to see what the MongoDB Node driver thinks the state of your replica set is. The property contains a map of server descriptions.\n\nYou can also connect to multiple mongos instances for high availability in a sharded cluster. You do not need to pass any special options to connect to multiple mongos in mongoose 5.x.\n\nSo far we've seen how to connect to MongoDB using Mongoose's default connection. Mongoose creates a default connection when you call . You can access the default connection using .\n\nYou may need multiple connections to MongoDB for several reasons. One reason is if you have multiple databases or multiple MongoDB clusters. Another reason is to work around slow trains. The function takes the same arguments as and returns a new connection.\n\nThis connection object is then used to create and retrieve models. Models are always scoped to a single connection.\n\nThe function returns a connection instance, not a promise. If you want to use to make sure Mongoose successfully connects to MongoDB, use the function:\n\nIf you use multiple connections, you should make sure you export schemas, not models. Exporting a model from a file is called the export model pattern. The export model pattern is limited because you can only use one connection.\n\nIf you use the export schema pattern, you still need to create models somewhere. There are two common patterns. First is to export a connection and register the models on the connection in the file:\n\nAnother alternative is to register connections with a dependency injector or another inversion of control (IOC) pattern.\n\nEach , whether created with or are all backed by an internal configurable connection pool defaulting to a maximum size of 100. Adjust the pool size using your connection options:\n\nThe connection pool size is important because MongoDB currently can only process one operation per socket. So functions as a cap on the number of concurrent operations.\n\nIn the context of Mongoose, a multi-tenant architecture typically means a case where multiple different clients talk to MongoDB through a single Mongoose application. This typically means each client makes queries and executes updates through a single Mongoose application, but has a distinct MongoDB database within the same MongoDB cluster.\n\nWe recommend reading this article about multi-tenancy with Mongoose; it has a good description of how we define multi-tenancy and a more detailed overview of our recommended patterns.\n\nThere are two patterns we recommend for multi-tenancy in Mongoose:\n• Maintain one connection pool, switch between tenants using the method.\n• Maintain a separate connection pool per tenant, store connections in a map or POJO.\n\nThe following is an example of pattern (1). We recommend pattern (1) for cases where you have a small number of tenants, or if each individual tenant's workload is light (approximately < 1 request per second, all requests take < 10ms of database processing time). Pattern (1) is simpler to implement and simpler to manage in production, because there is only 1 connection pool. But, under high load, you will likely run into issues where some tenants' operations slow down other tenants' operations due to slow trains.\n\nThe following is an example of pattern (2). Pattern (2) is more flexible and better for use cases with > 10k tenants and > 1 requests/second. Because each tenant has a separate connection pool, one tenants' slow operations will have minimal impact on other tenants. However, this pattern is harder to implement and manage in production. In particular, MongoDB does have a limit on the number of open connections, and MongoDB Atlas has separate limits on the number of open connections, so you need to make sure the total number of sockets in your connection pools doesn't go over MongoDB's limits.\n\nNow that we've covered connections, let's take a look at models."
    },
    {
        "link": "https://thegeekplanets.medium.com/managing-environment-variables-in-node-js-using-the-dotenv-package-2a5c8eee61a8",
        "document": "When developing a Node.js application, managing environment variables is crucial for maintaining different configurations for various environments like development, testing, staging, and production. Environment variables allow the storing of sensitive information such as API keys, database credentials, and other configuration data outside the source code. This enhances security, flexibility, and maintainability.\n\nThe dotenv package makes it easy to manage environment variables across different environments by loading them from a .env file into process.env.\n\n1. Security: Sensitive data (e.g., passwords, and API keys) are kept out of the source code.\n\n2. Flexibility: You can easily switch between environments (e.g., development, testing, production) without changing the code.\n\n3. Configuration: Environment-specific settings (e.g., database URLs, and third-party service credentials) can be adjusted without altering the application’s logic.\n\nFirst, install the package in your Node.js project:\n\nCreate a .env file in the root of your project, and specify key-value pairs for your environment variables. For example:\n\nYou can also create separate .env files for different environments:\n\nEach file will contain environment-specific values. For example:\n\nTo load the variables from a specific .env file, you will require the dotenv package in your Node.js code. The best place to initialize this is usually at the very start of your application’s entry file (app.js or server.js). This will automatically load the variables from the .env file into process.env.\n\nA good practice is to load different environment variables based on the NODE_ENV value. You can use the dotenv package dynamically by specifying which file to load based on the environment.\n\nNow, based on the NODE_ENV value, the application will load the appropriate .env file.\n\nRunning the Application with Different Environments\n\nThere are several methods to assign the value of the .env variable; however, we will utilize the direct assignment approach by specifying it within the .env file. If you wish to gain further insights on this topic, consider investigating alternative methods and sharing your findings in the comments section.\n• Don’t Commit .env Files to Version Control: The .env files contain sensitive information, so they should not be committed to version control (e.g., Git). Add the .env file to your .gitignore.\n\n2. Use Environment Variables in CI/CD: Instead of storing environment variables in files in your production environment, consider configuring them directly in your hosting platform (e.g., AWS, Heroku, Azure) or your CI/CD pipeline.\n\n3. Validate Environment Variables: It’s a good practice to validate the presence of required environment variables to avoid unexpected issues.\n\nManaging environment variables in a Node.js application using the dotenv package simplifies switching between different environments and ensures secure handling of sensitive information. By organizing .env files and loading them dynamically based on NODE_ENV, you can create a flexible and maintainable configuration system that scales with your application.\n\n1. Install and use dotenv to manage environment variables in Node.js.\n\n2. Create separate .env files for different environments (development, testing, staging, production).\n\n3. Use NODE_ENV to load environment-specific variables dynamically.\n\n4. Never commit .env files to version control. (Note: I’ve committed the environment files to the GitHub repository mentioned below to give you an idea. but it should not be there in your application source code.)\n\nThank you for taking the time to read this post. I appreciate your engagement with my content. Feel free to share your thoughts in the comments section. Stay tuned for more updates. 🔖"
    },
    {
        "link": "https://medium.com/the-node-js-collection/making-your-node-js-work-everywhere-with-environment-variables-2da8cdf6e786",
        "document": "People ask me a lot how I decide what to learn and invest my time in, and what to let slide. For me, this starts with these two same questions (e.g., asking why and when). I’ll bet you do something similar, don’t you?\n\nWhy and When?\n\nWhen someone tells you something is important, and you should use it, I recommend asking two simple questions.\n• Why should I use it?\n• When should I use it (or not use it)?\n\nNow it is time for you to ask me why you should use environment variables. Go on; it’s OK.\n\nIf you care about making your app run on any computer or cloud (aka your environments), then you should use them. Why? Because they externalize all environment specific aspects of your app and keep your app encapsulated. Now you can run your app anywhere by modifying the environment variables without changing your code and without rebuilding it!\n\nOK, so now you ask me when you should use them. In short, any place in your code that will change based on the environment. When you see these situations, use environment variables for anything you need to change or configure.\n\nHere are some specific examples of common scenarios when you should consider using environment variables.\n• Which HTTP port to listen on\n• What path and folder your files are located in, that you want to serve\n\nOther examples might be URLs to server resources, CDNs for testing vs. production, and even a marker to label your app in the UI by the environment it lives in.\n\nLet’s explore how you can use environment variables in Node.js code.\n\nYou may be setting a port number for an Express server. Often the port in a different environment (e.g.; staging, testing, production) may have to be changed based on policies and to avoid conflicts with other apps. As a developer, you shouldn’t care about this, and really, you don’t need to. Here is how you can use an environment variable in code to grab the port.\n\nGo ahead and try this. Create an empty folder named . Then create a file named and add the code above to it. Now when you execute node server.js you should see a message that says “Your port is undefined”.\n\nYour environment variable isn’t there because we need to pass them in. Let’s consider some ways we can fix this.\n\nThe simplest way to pass the port into your code is to use it from the command line. Indicate the name of the variable, followed by the equal sign, and then the value. Then invoke your Node.js app.\n\nYou will see the port displayed in the message like this “Your port is 8626”.\n\nYou can repeat this pattern and add other variables too. Here is an example of passing in two environment variables.\n\nFollow the pattern of environment variable name followed by the equal sign followed by the value. This is easy to do, but also far too easy to make a typing mistake. Which leads to the next option.\n\nOnce you define several of these, the next thought that may cross your mind is how you can manage them, so they don’t become a maintenance nightmare. Imagine several of these for database connectivity and ports and keys. This doesn’t scale well when you type them all on one line. And there could be private information such as keys, usernames, passwords, and other secrets.\n\nRunning them from a command line is convenient, sure. But it has its drawbacks:\n• there is no good place to see the list of variables\n• it’s far too easy to make a typing mistake from the command line\n• it’s not ideal to remember all of the variables and their values\n• even with npm scripts, you still have to keep them current\n\nA popular solution to how you can organize and maintain your environment variables is to use a file. I really like this technique as it makes it super easy to have one place where I can quickly read and modify them.\n\nCreate the file in the root of your app and add your variables and values to it.\n\nA file is a great way to see all of your environment variables in one place. Just be sure not to put them into source control. Otherwise, your history will contain references to your secrets!\n\nCreate a file (or edit your existing one, if you have one already) and add to it, as shown in the following image. The file tells source control to ignore the files (or file patterns) you list.\n\nYou can add a file to your file by using the command palette in Visual Studio Code (VS Code). Follow these steps:\n• Open the file you want to add to the in VS Code\n• Open the Command Palette with + + on a Mac or + + on Windows\n• Select “Git: Add file to from the menu”\n\nThis will add the name of the current file you have open to the file. If you have not created a file, it will create it for you!\n\nIf you use VS Code you’ll want to add the dotenv extension. This lights up the contents of your file with syntax highlighting and just plain old does it easier to work with the variables inside of a file.\n\nHere is a glimpse of the file in VS Code with the dotenv extension installed.\n\nRight about now you’re probably thinking that something has to look for the file, and you’re right!\n\nYou could write your own code to find the file, parse it, and read them into your Node.js app. Or you could look to npm and find a convenient way to read the variables into your Node.js app in one fell swoop. You’d likely run across the dotenv package on npm, which is a favorite of mine and what I recommend you use. You can install it like this .\n\nYou could then require this package in your project and use it’s function (config also has an alias of load, in case you see that in the wild) to look for the file, read the variables you defined and make them available to your application.\n• write the code to read the\n\nYou will want a package.json file to configure your versions, track your dependencies, and contain your npm scripts. Try this by running the following command\n\nThis creates a file with the basic settings filled in for you.\n\nYou want to read the file and the dotenv package on npm does this very well. Install the dotenv package by running the following command\n\nThis will add the dotenv package and its files to your folder and create an entry in your file for dotenv.\n\nIt’s time to read the file with a little bit of code. Replace the contents of your file with the following code.\n\nThe code displays the initial value of the environment variable, which will be undefined. Then it requires the dotenv package and executes its function, which reads the file and sets the environment variables. The final line of code displays the as 8626.\n\nNow run the code from the command line without passing the port, using the following command\n\nNotice the console log messages show the port is initially undefined and then later 8626. The dotenv package is reading the values and setting them, effectively doing the dirty work for you!\n\nNow that we have a single place to create our variables in a file, it might be nice to consider how we can make it easy to retrieve all of these variables in our Node.js code. Why? Good question! Well, you can refer to the variables in code using the following syntax:\n\nBut do you want to do this everywhere you need it (and you may need them in multiple places)? Or should you gather all of our environmental variables in one place? The latter of course! Why? If you do reference the variables everywhere that you need them it could make refactoring and maintenance more difficult than if they are in one place.\n\nI recommend creating a module that has the responsibility of gathering environment variables. This makes it easy to see them all at once and map them to readable names.\n\nHere are two good options to consider:\n• setting and exporting them manually in a module\n• use a library to read and export them in a module\n\nBoth techniques involve creating a module, but they differ in how the environment variables are mapped and exposed. Let’s take a closer look at the techniques and weigh the differences.\n\nCreate a module (the example below shows ) where you gather the variables, map them well-named and readable properties, and export them.\n\nLet’s create a new module in a file named . Then copy and paste the following code into the file.\n\nThis example shows how we can consolidate our environment variables in one file.\n\nLet’s modify once again, this time to import the config.js module and use it to access our environment variables. Replace the contents of with the following code.\n\nRun the code using and you will see the message “Your port is 8626”. The environment variables are being read by the dotenv code in the file. Your file imports the module in and extracts the port variable.\n\nYou can import the file where you need it and use destructuring to pull out what you need. You only pulled out port, but you could certainly pull out any of the values that are exported from the module.\n\nWhat’s the value in this technique?\n• clarity on how all environment variables are being mapped\n• you can rename variables to more readable properties\n• you can add other configuration properties from non-environment variables\n\nThe key point here is that the config module’s purpose becomes to gather and expose all configuration, regardless of where it comes from.\n\nA consequence of the manual technique is that when you add a new environment variable you have to add it to the config module. For example, if you need to make a new variable you’d need to go into this config module and add something like this\n\nI don’t mind this consequence, as I’d have to go through my code anyway and use the new value. But I point this out because there is a way to gather them automatically.\n\nThe function from the dotenv npm package will read the file, assign the variables to , and return an object (named ) containing the content. it will also throw an error if it failed.\n\nThe following code reads the file and collects the variables in the object.\n\nYou can then export this object from a module and make it easily accessible in your app once again. Your code to access the variables might look like this\n\nWhich option should you use? That’s for you to decide. But consider if you want to make the npm package dotenv a runtime dependency or not. Perhaps there are other ways to get to the environment variables in higher environments (such as production) where security is paramount. Do you even want code in your node app being able to read such an important file? You might be cool with that, but what if there was a way to read the variables and make the dotenv package a devDependency in your file?\n\nI recommend that you use the first technique where you manually set the environment variables in a module, such as . This allows you to remove dotenv as a runtime dependency — assuming you do one more thing: preloading your environment variables. This also allows you to reduce your runtime dependencies.\n\nYou have a lot of dependencies on packages from npm. Every one of these is something you should consider as you plan the lifetime and maintenance of your application. You may already be thinking about how you can reduce your dependencies to the bare minimum. I do this too.\n\nThe dotenv package is fantastic, but we don’t need it to be a runtime dependency. The dotenv package provides an option where you can preload the variables outside of your code. You can load the variables and eliminate the code that reads the file from our code. Less code is fewer lines that could break or be maintained.\n\nNot sold yet? Have you thought about how you will access these environment variables in the cloud? Do you want your code trying to read a file? I vote a resounding “no” to that. I prefer my code not to try to read a file because if I take it to the cloud, I want those solutions to not even have a file.\n\nHow do you remove the runtime dependency of dotenv from our code but not lose the value you gained already? First, when installing the dotenv npm package, you can save it as a dev dependency like this\n\nThen remove any code that uses require on dotenv. This includes the code mentioned previously in this article.\n\nThe problem now is that you previously were relying on dotenv to load the environment variables. This is where the preloading option comes into play.\n\nYou can run your node app using the ( ) command line option to preload dotenv. The following command will preload all environment variables from the file .env using dotenv and make them available in your app. So you’ve now removed all references to dotenv from your code.\n\nThis is useful when you want your app to run somewhere where the file does not (and maybe should not) exist, such as in a running docker container or a cloud server.\n\nI highly recommend putting your commands into an npm script. This makes it easier to run instead of typing all of these flags. Perhaps you create a custom script for it or use the npm start script. Here is how the script might look if you use a custom one.\n\nThe command would then kick off this command. You can name the script how you please, of course.\n\nWhy not use ? Good question. You certainly can do that. I like to reserve for how I run it in production with our without a docker container, which might simply be like this.\n\nThe key here is that with either npm script you are running the exact same node code! The difference is in how your variables get set. You’ve now abstracted your configuration from your app.\n\nHow do you memorize all of your npm scripts? That’s easy — you don’t! I rely on great tooling to help run my npm scripts. While I like to pretend I know all of my script names and what they do exactly, the fact is that I’d rather have a tool that shows me the list and I can select it.\n\nThere are two fantastic tools for this built into my code editor of choice: VS Code.\n\nThe npm scripts outline is built into VS Code and shows up in the Explorer view. Notice the following screenshot shows the npm scripts that are in my package.json file. If you do not see this in your project be sure to set the setting to true, in your for VS Code.\n\nYou can right-click an npm script and open, run or debug it.\n\nIf you like to keep your hands on the keyboard, as I do, then you may prefer the npm extension for VS Code. After installing the npm extension for VS Code, you can to run npm scripts from the command palette.\n\nJust type + + on a Mac or + + on Windows. Then start typing and select “npm: Run Script”, as shown in the image below.\n\nThen you’ll be presented with a list of your npm scripts. From here you can start typing the name of the one you want until the one you want is highlighted. Or you use the arrow to select the script you want. Then press to run it.\n\nI love this as it keeps my hands on the keyboard which feels more productive to me than swapping between mouse/trackpad and the keyboard.\n\nGive one of these a try.\n\nYour Code is the Same No Matter Where it Runs\n\nYour app has no awareness of where the environment variables come from. The way you run it, with preloading, is what provides them on your local machine.\n\nLet’s explore more about why you may want your app to not have awareness of its configuration.\n\nImagine we are running in a Docker container. The conventional guidance for containers says that the apps inside the container should not know about their configuration. This way the container can run anywhere as long as the container and whatever is running the container have an agreement on what variables must be provided.\n\nWhen you take our app to the cloud, the various cloud providers all have ways for you to set environment variables, too. So once again, if the app merely uses the variables and the thing running it (in this case the cloud provider’s services) provide you a way to define those variables, you are all set.\n• A lot of this separation of your app from its configuration comes from the guidance known as 12-factor. If you haven’t read up on this yet, please learn more here https://12factor.net.\n\nHow do your teammates know which environment variables to create for your app? Should they scour your code for those? Should they call you and ask? Certainly not, you don’t have time to visit every developer personally!\n\nWhen your file is not pushed to source control (which it shouldn’t be), it is important to make it clear to everyone what the shape of that file should look like. The technique I recommend is to create a file named that contains the variables, but with fake values. This file might look something like the following template.\n\nYour team can copy the content of this file to their own .env file and enter the values they need. It is perfectly normal to have values that are not secrets listed in the example file. Notice that the and the in the .env.example file are set, but not the . Choose what you push to source control wisely.\n\nYou can then reference this file in your where your teammates can quickly learn how to set up their own values. Problem solved.\n\nThis is just a glimpse at how you can use environment variables and some of the fantastic tools that you can use with them. In summary, I recommend that you use environment variables and follow these steps:\n• ignore it in your file\n• use VS Code to edit your file\n• install the dotenv extension for VS Code\n• install the npm extension for VS Code\n• read the file with the dotenv npm package as a dev dependency\n• use the preloading option of dotenv to remove any runtime references to it\n• use npm scripts to run your node app\n\nBut wait? Do you want your server to have a file? Do you use Docker or a cloud server? These are good questions to ask yourself. The approach you learned here is a foundation for that and can work in concert with other solutions. I’ll dive into this in a future post soon, so stay tuned.\n• Here’s how you can actually use Node environment variables\n• Source code for the app presented in the video"
    },
    {
        "link": "https://dev.to/mick_patterson_/how-to-use-environment-variables-in-nodejs-with-express-and-dotenv-23of",
        "document": "Environment variables in NodeJs are essential for setting configuration options as well as storing important values securely. NodeJs by default comes with some environment variables that describe various parts of the application and the infrastructure it is being run on.\n\nThese variables, along with any custom added ones are available inside the process.env object that can be accessed in any script file within the app.\n\nThe environment variables allow you to store API keys and other configuration secrets independently from your main codebase and separate from your git repository so they never get checked in anywhere.\n\nBeing able to configure and consume these variables is essential in creating solid, production-ready NodeJs APIs for all applications.\n\nFortunately, there are npm packages that can help us as well as DevOps configurations.\n\nDotenv is an npm package that can be added to any NodeJs application. The main purpose of the Dotenv package is to allow developers to create a .env file that has custom environment files that are added into the process.env object.\n\nIn your main app directory, create a new file simply named \".env\".\n\n.env files are treated and behave essentially the same as a plain text file.\n\nIn this file we can add our environment variable name and its value as such:\n\n\n\nThis will then allow us to access these variable values by using the process.env object:\n\n\n\nWe also need to add the .env file to our .gitignore file so that it isn't pushed up to our source repository as well. These values are designed to stay hidden.\n\nSimilar to the dotenv documentation, configuring it in your app is dead simple:\n\n\n\nThe difference, in this case, is that we're checking the environment that the app is running in and only applying the local .env values if we're in development (which NodeJs will default to when you run the app locally). process.env.NODE_ENV is one of the in-built environment variables that node ships with.\n\nNow when we run our app, all the variables from our .env are available to us.\n\nIn the past, I have configured our projects one of two ways. Either by manually adding the .env file to the server and managing any changes manually and changing the above code to use the dotenv package for all environments, or, using configuration variables provided by the hosting provider.\n\nIn Azure, each web app has its own set of configuration variables that can be manually added to. These configuration values are then used in place of the .env values when accessing the process.env object.\n\nThis way, either you or your DevOps team can manage the configuration variables independently of the codebase and keep all the values secret."
    },
    {
        "link": "https://deadsimplechat.com/blog/environment-variables-in-nodejs",
        "document": "In this article we are going to cover environment variables also known as env variables. These are basically key-value pair of data set that is stored in the operating system level\n\nIn this article we will learn about environment variables in NodeJs with examples\n• Why are env variables are important\n• Installing NodeJs and setting up a new Project\n• Initializing your first env variable with NodeJS\n• Secrets management and Security Best Practices with examples\n• Common Pitfalls and how to avoid them\n\nEnvironment variables are a key-value pair data set that are avaiable at the operating system level. These data set are available in all major operating system command line shells Windows, Mac and Linux\n• Operating System: This is where the Environment variables are stored\n• Node Js runtime: Interacts with the operating system in order to obtain environment variables\n• Your App Code: Interacts with the to get the environment variables\n\nIn this project we are going to assume the following\n\nInstalling Node and setting up the project\n\nThese are different methods of installing NodeJS on your machine. You can go to the node official website and download a version from there\n\nLet us consider installing nodejs in a linux operating system prefrably ubuntu\n\nStep 2: Use curl or wget script below to install nvm using the nvm git repository. run the script to install the nvm\n\nStep 3: Close and re-open your terminal and run the following to apply the script\n\nYou can confirm that NVM has been installed on your system by running the following command\n\ntype the below command to install the latest version of node\n\nyou can set a default version of node to be used across your system by using the following command\n\nyou can type the below command to check if the node is installed on your system\n\nIf you are looking for a JavaScript chat SDK to build chat messaging, you can consider DeadSimpleChat JavaScript SDK\n\nNow, that we have installed the node on our machine. Let us create a new project where we will be using the env variable\n\ncreate a new directory and name it and cd into the directory\n\nNow, that we have created the folder and cd into it. Type the below command to initalize a new project and fill out the fields as you see fit\n\nthis will create a package.json file for you that looks something like this:\n\nInitializing your first env variable: Step By Step\n\nNow that you have initialized the project in the above section and created a file. In your terminal type the below command to install the node package that is used to create env files\n\nThis will install the dotenv package and save it as a dependency in your file. that should look something like this\n• In your root folder create a new file and name it .\n• Open your .env file in your text editor and create some key-value pairs. These are your environment variable. I have created some for your reference below\n\nIn your root folder create an index.js file and then open your terminal and type the below command to install express js.\n\nThis installs expressjs and saves it as a dependency in your package.json file, your package,json looks like this\n\nand your project structure looks like this\n\nNow, open your index.js file and type the below command to start a simple web server.\n\nand go to localhost://4000 to get the hello world\n\nNow that we have the server running let us read the .env file that we created in the previous step and load the port details from the .env file\n\nOpen the index.js file and require the dotenv library there\n\nnow, you can access the .env file using the process.env. Let us use the process.env to access the port number in our index.js file\n\nNow let us restart the server and go to localhost://3000 . Instead of running at 4000 our server is now running on port 3000 which it took from the .env file\n\nyou can also see this in the console\n\nYou have now successfully created and saved the env file on your machine\n\nAs another example you can access the DATABASE_URL like so\n\nHere are all the files\n\nHow to use env variables in async tasks\n\nIn this section we are going to discuss about how env variables can be used in async tasks like calling an API or database operations\n\nEnv variables are especially important in these tasks, because they can be used to store credentials and endpoints securely\n\nAlso, these variables can be automated because these change between different environment such as development, staging and production.\n\nopen your file and edit it like this\n\nNext, install the axios library to make calls to the remote server like\n\nthis will install the axios and save it as a dependency in your package.json file\n\nthe package.json file should look something like this\n\nNext use the axios to make calls to the jsonplaceholder website and log them to the console\n\nType this code in your file\n\nWhat are we doing here:\n• We are importing the modules like express, dotenv, axios\n• Then we are initalizing the app and the port using the env variables\n• then we are creating the async function called\n• In this function we are using the url and the apiKey from the file. Though I have to mention you do not need apiKey to call the jsonplaceholder website. I have just put that key there for demo purposes\n• we are logging the data to the console\n• We are calling the method on the get route. So, everytime someone goes to the the method gets called and the data gets logged to the console.\n\nUsing Async/await with env variables in Database operations\n\nLet us look at another example, this time we are going to do database operations with env variables\n\nOpen the file in your text editor and type the following\n\nnext step is to install the library like so\n\nStep 3 Connect to the database and make the async query with .env file\n\nwrite the following code to connect to the database and use the .env credentials that we just created\n\nwe are not integrating this example into our regular codebase because it is an outlier and will not be useful further down the line in our tutorial\n\nThere is more to env variable than just reading and storing them. With advanced env variable manupulation we are going to learn about\n\nEncoding is used for various purposes in environment variables. This could be used for security puposes. The most popular type of encoding is done using the base64\n\nvalidation is used to check whether the code is valid or not. for example the url that you are going to use is valid url or not etc\n\nor as in this example we are checking whether the port number is within the specified range or not\n\nenv variables are always on the type : string. If often you need to use other data types as well such as int or booleans. Here type conversion helps\n\nHere is an example combining all the advanced env manipulation available in the env variables\n\nSecrets Management and Security Best Practices with examples\n\nIn this section we are going to learn about secrets management and best practices with examples. Here are the steps that you can take to secure the env variable along with their examples\n\nAlways ensure that the files are in the gitignore so they are never commited to the git repository\n\nalways hash the passwords, storing the passwords as plain text is a bad practice. You can use libraries like bcryt and others to hash the passwords\n\nAs a security measure always encode the secrets, the secrets are usually base-64 encoded\n\nfor large projects you can consider centralized secrets management services like hashicorp vault, AWS secrets manager and others\n\nThese offer advanced features like secret rotation, automated lease and rotation and audit logging\n\nhere is an example with node vault\n\nAlways follow the principle of least privilege. The api which does not require write credentials should never be given write privileges\n\nCommon Pitfalls and How to avoid them\n\nNeed Chat API for your website or app\n• Add Scalable Chat to your app in minutes\n\nYou might be interested in some of our other articles\n• Sending emails in NodeJs with NodeMailer: The Comprehensive Guide\n• CSV files with Node and PapaParse: The Complete Guide\n\nIn this article we learned about env variable and how to use them in NodeJs the complete guide\n\nWe have covered the important topics related to env management in NodeJs and this should be enough for most of the use-cases for env variables management in Node js apps\n\nI hope you liked the article and thank you for reading"
    },
    {
        "link": "https://lirantal.com/blog/environment-variables-configuration-anti-patterns-node-js-applications",
        "document": "Crafting robust and maintainable applications is no small feat. One of the fundamental pillars of building reliable Node.js applications is effective configuration management.\n\nConfiguration encompasses a wide array of parameters, from database connection details to API keys, and even application-specific settings. Regardless of the size or complexity of your Node.js project, you’ll inevitably encounter the challenge of handling configuration data.\n\nIn this blog post, we’re going to delve deep into the world of configuration patterns for Node.js applications. We’ll explore the various strategies and tools at your disposal to efficiently manage configuration data. Whether you’re a seasoned Node.js developer looking to refine your practices or a newcomer eager to learn, this post will equip you with the knowledge you need to make informed decisions regarding your application’s configuration.\n\nWhy managing configuration for Node.js application is crucial?\n\nBefore we dive into the intricacies of different configuration patterns, let’s take a moment to understand why configuration management is so crucial in Node.js applications.\n\nImagine building a Node.js application without a clear and organized way to handle configuration. You’d likely end up hardcoding sensitive information like API keys directly into your codebase (oh no! 😳), scattering configuration values throughout your application files (maintainability is 😭), and making it nearly impossible to adapt to different environments seamlessly.\n\nWhat makes a maintainable, scalable, and secure configuration management in Node.js applications? Here are some of the key pillars to consider that most often I see developers overlook:\n• Doesn’t impede security: Storing sensitive information like database credentials and API keys securely is paramount. Without proper configuration practices, your application could be susceptible to data breaches.\n• Promotes deployment portability: Your application should run consistently across various environments, such as development, testing, and production. Good patterns of configuration management do not couple your environments to your application or to your configuration. Instead, it allows your application to transparently and seamlessly deploy to different environments, unaware of the differences between them.\n• Simplifies maintenance: As your application evolves, so do its configuration requirements. Having a robust configuration management system in place makes it easier to make changes and updates without rewriting large sections of code or accessing ad-hoc configuration files or environment variables.\n\nHow to load configuration in Node.js applications?\n\nNow that we’ve highlighted the importance of configuration management, let’s review the various configuration patterns available for Node.js applications.\n\nYou might have heard about some common approaches like using files or popular packages like dotenv, convict, and env-schema. We’ll explore these options in detail.\n\nThe following depicts some of the possible ways to load configuration in Node.js applications, ordered from the least effective to the most robust configuration management traits:\n\nConcerns with the use of configuration files, such as\n\nGenerally speaking, using a dedicated configuration file to load configuration, a la , doesn’t necessarily mean that you’re missing out on some of the traits we’ve listed above. For example, you can still bake type safety and validation into your configuration file if you’re using it as a JavaScript module ( ) instead of a JSON file ( ). Or, maybe you have another step in your configuration loading process that adds type safety and validation.\n\nHowever, most often one of the anti-patterns I’ve noticed is that developers tend to hardcode configuration data directly into their source code, which is a big no-no. Another disaster is that deployment environments proliferate into your configuration file. Does this look familiar?\n\nThis is a maintenance nightmare. You’ll end up with a lot of duplicated configuration data, and it’s hard to know what configuration was used for a given deployment. You also tightly couple your deployed environment types to your application, which is not ideal.\n\nInformation security is another concern with configuration files. If they are committed to the source code repository, it only takes one mistake in misconfigured web servers or path traversal vulnerabilities, to expose sensitive information like database credentials and API keys. Here’s a timely reminder from Noor AlHomaid on X:\n\nOn first look, files may seem to suffer from similar issues as files - a specific file used per environment and so on. However, most notable to recognize about files is:\n• They aren’t committed to the Git repository, hence they are not versioned and aren’t tightly coupled to your application’s code. The hint is in the name, use a leading dot to indicate that they a special case of files.\n• They are most often used as a generic file that is populated with environment variables and is mostly relevant for production use, and a file to refer to configuration needed for local development environment variables.\n\nThat said, they are still prone to the same issues as files:\n• It’s easy to hardcode configuration data directly into your source code\n• It’s easy to copy your deployment environments into several .env files\n• It’s easy to make the mistake of committing the file to your Git repository, which is a security risk\n• They are not inherently type safe\n• They are not inherently validated\n\nASIDE Is it an advantage or disadvantage that .env files aren’t versioned in source control?\n\nOne could argue to the issue of perpetuating configuration drift. For example, files are most often not versioned via Git, so that secrets are not leaked, which is a good thing. But this means that the configuration is not versioned either, and it’s hard to know what configuration was used for a given deployment.\n\nDevelopers will also be concerned that because files aren’t committed to the Git repository, then new configuration options aren’t easily discoverable. This can lead to configuration drift, where different environments have different configuration options.\n\nNeedless to say, the npm package is a popular choice for loading configuration from files. It’s a simple and lightweight package that’s easy to use.\n\nSome of my reservations as noted above are relevant to too, but specifically I want to call out a security concern with that I’ve seen developers overlook: basing configuration on as a first-class citizen in a Node.js pattern.\n\nLet’s explain what this means with a simple use case:\n\nWhen you run this code, the package will load configuration data from the local file into the object. This means that you can access the configuration data via anywhere in your application.\n\nDevelopers following this pattern will often use as a first-class citizen in their application, from which they draw configuration items:\n\nThe security risk that is inherent here is:\n• You may inadvertently expose sensitive information like database credentials and API keys as part of error messages, stack traces, and other forms of data returned to consuming clients.\n• You may inadvertently expose sensitive information like database credentials and API keys in your application’s logs.\n\nWhat are some common anti-patterns or practices that you should avoid when handling configuration in Node.js applications?\n\nThese anti-patterns may seem tempting at times but can lead to maintenance nightmares, security vulnerabilities, and overall codebase chaos.\n\nOne of the most prevalent anti-patterns is hardcoding configuration data directly into your source code.\n\nIt sounds so naive that you might be wondering why anyone would ever do this, but more often than not, it’s a common “quick fix” that developers resort to when they’re in a hurry.\n\nWhile hardcoding configuration data may appear convenient for quick development, it has several downsides ranging from security risks of exposing sensitive information in the codebase to inflexibility and poor maintainability.\n\nNode.js configuration anti-pattern to avoid, demonstrating hardcoded configuration data in the codebase:\n\nIn this code, the database credentials (i.e., ) are hardcoded directly into the codebase. The HTTP web server port of is also hardcoded.\n\nAnother common pitfall is scattering configuration data across multiple files or modules within your application.\n\nThis haphazard approach can result in maintenance nightmares as you hunt down which part of your application is responsible for a particular configuration. It also makes it difficult to update configuration values when they’re spread across different parts of your codebase.\n\nTo add insult to injury, inconsistencies may arise when different parts of your application use different values for the same configuration parameter. Also, good luck debugging!\n\nYou’ll notice that a variation of this anti-pattern is when scattered configuration data is accessed via environment variables such as through-out the codebase.\n\nWhile environment variables are a viable option for configuration management, they can quickly become unwieldy when used in this manner.\n\nManually switching between different configuration settings based on the environment (e.g., development, staging, production) is another anti-pattern. This involves writing conditional code blocks to handle different settings, which can lead to:\n• Human error: Mistakes can happen, and you might forget to switch the environment, potentially leading to data corruption or other issues.\n• Code complexity: Your codebase can quickly become cluttered with environment-specific logic, making it harder to understand and maintain.\n\nAnother variation of this pattern is when different configuration files are used for different environments, such as , , and so on. This practice can lead to code duplication and maintenance challenges.\n\nConsider the following directory structure:\n\nIn this directory structure, there are separate configuration files for different environments.\n\nAnd here’s what the file might look like:\n\nThen, a Node.js application might load it’s environment-specific configuration data as follows, demonstrating this anti-pattern:\n\nIn fact, even the official dotenv package mentions this anti pattern as part of the README:\n\nAnother common anti-pattern I see often repeating in how configuration libraries on npm work is that they are solely based on a synchronous API.\n\nIn practice, this means that the configuration is treated as “local” and loading configuration data synchronously becomes a problem when you need to fetch configuration from a remote source, such as a database or an API. For example, you might want to load your secrets from a KMS (Key Management Service) or a secrets manager like HashiCorp Vault.\n\nSure, you can load your synchronous config first, and then have further asynchronous function calls and then wrap it all in a configuration manager factory, however most developers don’t do this to begin with because they are hard-wired to follow synchronous configuration loading due to npm packages built that way.\n\nHere are a few examples of how common this non-asynchronous configuration loading anti-pattern is, demonstrating node-config, dotenv, and convict as some examples:\n\nThe project is actually making use of the npm package name. The npm package is something else entirely.\n\nHow to load configuration from environment variables in Node.js ?\n\nOne last and closing section on configuration patterns in Node.js is loading configuration from environment variables.\n\nThrough-out this article we’ve mentioned numerous open-source npm packages dedicated to managing a Node.js configuration in various ways:\n\nYet, if you haven’t been following the latest Node.js 20 feature enhancements, then you might not be aware that Node.js now has built-in support for loading configuration from environment variables:\n\nThis new environment variables loading feature was introduced in Node.js v20.6.0 and allows you to specify an INI-compatible file format that is commonly used through-out other libraries and tools:\n\nOnce the Node.js application starts, the and environment variables defined in the file will be available to the application via: and .\n\nIn fact, if you need to pass configuration then you can now include that in your file too and Node.js will automatically pick it up:\n\nHow do we manage configuration in Node.js applications?\n\nMy goal in this write-up was specifically about raising awareness of anti-patterns, security and maintainability issues that are common when handling configuration in Node.js applications.\n\nFriends have also shared other perspectives relating to configuration management in Node.js applications, such as Colin Ihrig’s blog post on NODE_ENV Considered Harmful and Shai Yallin’s dotenv considered harmful walk-through, which I recommend your read too for further perspectives.\n\nSo, how do we do better?\n\nRead-up in my follow-up article Best Practices for Bootstrapping a Node.js Application Configuration."
    }
]