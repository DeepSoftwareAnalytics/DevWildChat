[
    {
        "link": "https://docs.python.org",
        "document": "What's new in Python 3.13?\n\n Or all \"What's new\" documents since Python 2.0\n\nTutorial\n\n Start here: a tour of Python's syntax and features\n\nPython setup and usage\n\n How to install, configure, and use Python"
    },
    {
        "link": "https://python.org/doc",
        "document": "Browse the docs online or download a copy of your own.\n\nGet started here, or scroll down for documentation broken out by type and subject.\n\nSee also Documentation Releases by Version"
    },
    {
        "link": "https://easypythondocs.com/validation.html",
        "document": ""
    },
    {
        "link": "https://docs.python.org/3/tutorial/index.html",
        "document": "Python is an easy to learn, powerful programming language. It has efficient high-level data structures and a simple but effective approach to object-oriented programming. Python’s elegant syntax and dynamic typing, together with its interpreted nature, make it an ideal language for scripting and rapid application development in many areas on most platforms.\n\nThe Python interpreter and the extensive standard library are freely available in source or binary form for all major platforms from the Python web site, https://www.python.org/, and may be freely distributed. The same site also contains distributions of and pointers to many free third party Python modules, programs and tools, and additional documentation.\n\nThe Python interpreter is easily extended with new functions and data types implemented in C or C++ (or other languages callable from C). Python is also suitable as an extension language for customizable applications.\n\nThis tutorial introduces the reader informally to the basic concepts and features of the Python language and system. It helps to have a Python interpreter handy for hands-on experience, but all examples are self-contained, so the tutorial can be read off-line as well.\n\nFor a description of standard objects and modules, see The Python Standard Library. The Python Language Reference gives a more formal definition of the language. To write extensions in C or C++, read Extending and Embedding the Python Interpreter and Python/C API Reference Manual. There are also several books covering Python in depth.\n\nThis tutorial does not attempt to be comprehensive and cover every single feature, or even every commonly used feature. Instead, it introduces many of Python’s most noteworthy features, and will give you a good idea of the language’s flavor and style. After reading it, you will be able to read and write Python modules and programs, and you will be ready to learn more about the various Python library modules described in The Python Standard Library.\n\nThe Glossary is also worth going through."
    },
    {
        "link": "https://stackoverflow.com/questions/73163352/python-documentation-input-variable-type-hints",
        "document": "I'm noticing a significant difference in the information presented by the official python docs compared to what I'm seeing in the PyCharm hover-over / quickdocs. I'm hoping someone can point me to where I can find the source of this quickdoc information such that I can use it outside of PyCharm as a general reference.\n\nFor example in the python docs for os.makedir I see:\n\nRecursive directory creation function. Like mkdir(), but makes all intermediate-level directories needed to contain the leaf directory. The mode parameter is passed to for creating the leaf directory; see the description for how it is interpreted. To set the file permission bits of any newly created parent directories you can set the umask before invoking . The file permission bits of existing parent directories are not changed.\n\nBut in the quickdocs I see:\n\nWhere is this quickdoc type hinting information coming from and where can I find a complete reference with all these type hints such that I can reference it outside of PyCharm?\n\nComing mainly from a strongly typed language like Java, I struggle to make constructive use of the python documentation with regards to function input parameter types. I am hoping someone can elucidate a standard process for resolving ambiguity compared to my current trail+[lots of]errors approach.\n\nFor example, the os.makedir function's first parameter is .\n\nIt is not apparent to me what sorts of things I can pass as here. Could it be:\n• A str? If so, how should I create this? Via a string literal, double quoted string? Does this accept separators or separators or system dependent?\n\n[Note the above are rhetorical questions and not the focus of this post]. These are all informed guesses, but if I were completely new to python and was trying to use this documentation to make some directories, I see two options:\n• Read the source code via some IDE or other indexing\n• Guess until I get it right\n\nThe first is fine for easier to understand functions like but for more complicated functions this would require gaining expertise in a library that I don't necessarily want to reuse and just want to try out. I simply don't have enough time to become an expert in everything I encounter. This seems quite inefficient.\n\nThe second also seems to be quite inefficient, with the added demerit of not knowing how to write robust code to check for inappropriate inputs.\n\nNow I don't want to bash the python docs, as they are LEAPS and BOUNDS better than a fair few other languages I've used, but is this dilemma just a case of unfinished/poor documentation, or is there a standard way of knowing/understanding what input parameters like in this case should be that I haven't outlined above?\n\nTo be fair, this may not be the optimal example, as if you look towards the end of the doc for you can see it does state:\n\nbut this is not specifically referring to . Yes, in this example it may seem rather obvious it is referring to , but with the advent of type-hinting, why are the docs not type hinted like the quickdocs from PyCharm? Is this something planned for the future, or is it too large a can of worms to try to hint all possibilities in a flexible language like python?\n\nJust as a comparison, take a look at Java's java.io.file.mkdirs where the various constructors definitely tell you all the options for specifying the path of the file:\n\nJust reading this I already know exactly how to make a File object and create directories without running/testing anything. With the quickdoc in PyCharm I can do the same, so where is this type hint information in the official docs?"
    },
    {
        "link": "https://docs.python-guide.org/writing/structure",
        "document": "By “structure” we mean the decisions you make concerning how your project best meets its objective. We need to consider how to best leverage Python’s features to create clean, effective code. In practical terms, “structure” means making clean code whose logic and dependencies are clear as well as how the files and folders are organized in the filesystem.\n\nWhich functions should go into which modules? How does data flow through the project? What features and functions can be grouped together and isolated? By answering questions like these you can begin to plan, in a broad sense, what your finished product will look like.\n\nIn this section, we take a closer look at Python’s modules and import systems as they are the central elements to enforcing structure in your project. We then discuss various perspectives on how to build code which can be extended and tested reliably.\n\nJust as Code Style, API Design, and Automation are essential for a healthy development cycle. Repository structure is a crucial part of your project’s architecture. When a potential user or contributor lands on your repository’s page, they see a few things: Only when they scroll below the fold will the user see your project’s README. If your repo is a massive dump of files or a nested mess of directories, they might look elsewhere before even reading your beautiful documentation. Dress for the job you want, not the job you have. Of course, first impressions aren’t everything. You and your colleagues will spend countless hours working with this repository, eventually becoming intimately familiar with every nook and cranny. The layout is important. tl;dr: This is what Kenneth Reitz recommended in 2013. This repository is available on GitHub. Let’s get into some specifics. Your module package is the core focus of the repository. It should not be tucked away: If your module consists of only a single file, you can place it directly in the root of your repository: Your library does not belong in an ambiguous src or python subdirectory. This is arguably the most important part of your repository, aside from the source code itself. The full license text and copyright claims should exist in this file. If you aren’t sure which license you should use for your project, check out choosealicense.com. Of course, you are also free to publish code without a license, but this would prevent many people from potentially using or contributing to your code. If your module package is at the root of your repository, this should obviously be at the root as well. A pip requirements file should be placed at the root of the repository. It should specify the dependencies required to contribute to the project: testing, building, and generating documentation. If your project has no development dependencies, or if you prefer setting up a development environment via , this file may be unnecessary. There is little reason for this to exist elsewhere. For advice on writing your tests, see Testing Your Code. Starting out, a small test suite will often exist in a single file: Once a test suite grows, you can move your tests to a directory, like so: Obviously, these test modules must import your packaged module to test it. You can do this a few ways:\n• Expect the package to be installed in site-packages.\n• Use a simple (but explicit) path modification to resolve the package properly. I highly recommend the latter. Requiring a developer to run to test an actively changing codebase also requires them to have an isolated environment setup for each instance of the codebase. Then, within the individual test modules, import the module like so: This will always work as expected, regardless of installation method. Some people will assert that you should distribute your tests within your module itself – I disagree. It often increases complexity for your users; many test suites often require additional dependencies and runtime contexts. If you look at most of my projects or any Pocoo project, you’ll notice a Makefile lying around. Why? These projects aren’t written in C… In short, make is an incredibly useful tool for defining generic tasks for your project. Other generic management scripts (e.g. or ) belong at the root of the repository as well. I’ve noticed a new trend in Django applications since the release of Django 1.4. Many developers are structuring their repositories poorly due to the new bundled application templates. How? Well, they go to their bare and fresh repository and run the following, as they always have: The resulting repository structure looks like this: Repetitive paths are confusing for both your tools and your developers. Unnecessary nesting doesn’t help anybody (unless they’re nostalgic for monolithic SVN repos).\n\nPython modules are one of the main abstraction layers available and probably the most natural one. Abstraction layers allow separating code into parts holding related data and functionality. For example, a layer of a project can handle interfacing with user actions, while another would handle low-level manipulation of data. The most natural way to separate these two layers is to regroup all interfacing functionality in one file, and all low-level operations in another file. In this case, the interface file needs to import the low-level file. This is done with the and statements. As soon as you use statements, you use modules. These can be either built-in modules such as and , third-party modules you have installed in your environment, or your project’s internal modules. To keep in line with the style guide, keep module names short, lowercase, and be sure to avoid using special symbols like the dot (.) or question mark (?). A file name like is the one you should avoid! Naming this way will interfere with the way Python looks for modules. In the case of Python expects to find a file in a folder named which is not the case. There is an example of how the dot notation should be used in the Python docs. If you like, you could name your module , but even our trusty friend the underscore, should not be seen that often in module names. However, using other characters (spaces or hyphens) in module names will prevent importing (- is the subtract operator). Try to keep module names short so there is no need to separate words. And, most of all, don’t namespace with underscores; use submodules instead. Aside from some naming restrictions, nothing special is required for a Python file to be a module. But you need to understand the import mechanism in order to use this concept properly and avoid some issues. Concretely, the statement will look for the proper file, which is in the same directory as the caller, if it exists. If it is not found, the Python interpreter will search for in the “path” recursively and raise an ImportError exception when it is not found. When is found, the Python interpreter will execute the module in an isolated scope. Any top-level statement in will be executed, including other imports if any. Function and class definitions are stored in the module’s dictionary. Then, the module’s variables, functions, and classes will be available to the caller through the module’s namespace, a central concept in programming that is particularly helpful and powerful in Python. In many languages, an directive is used by the preprocessor to take all code found in the file and ‘copy’ it into the caller’s code. It is different in Python: the included code is isolated in a module namespace, which means that you generally don’t have to worry that the included code could have unwanted effects, e.g. override an existing function with the same name. It is possible to simulate the more standard behavior by using a special syntax of the import statement: . This is generally considered bad practice. Using makes the code harder to read and makes dependencies less compartmentalized. Using is a way to pinpoint the function you want to import and put it in the local namespace. While much less harmful than because it shows explicitly what is imported in the local namespace, its only advantage over a simpler is that it will save a little typing. # Is sqrt part of modu? A builtin? Defined above? # sqrt may be part of modu, if not redefined in between As mentioned in the Code Style section, readability is one of the main features of Python. Readability means to avoid useless boilerplate text and clutter; therefore some efforts are spent trying to achieve a certain level of brevity. But terseness and obscurity are the limits where brevity should stop. Being able to tell immediately where a class or function comes from, as in the idiom, greatly improves code readability and understandability in all but the simplest single file projects.\n\nPython provides a very straightforward packaging system, which is simply an extension of the module mechanism to a directory. Any directory with an file is considered a Python package. The different modules in the package are imported in a similar manner as plain modules, but with a special behavior for the file, which is used to gather all package-wide definitions. A file in the directory is imported with the statement . This statement will look for file in and execute all of its top-level statements. Then it will look for a file named and execute all of its top-level statements. After these operations, any variable, function, or class defined in is available in the pack.modu namespace. A commonly seen issue is adding too much code to files. When the project complexity grows, there may be sub-packages and sub-sub-packages in a deep directory structure. In this case, importing a single item from a sub-sub-package will require executing all files met while traversing the tree. Leaving an file empty is considered normal and even good practice, if the package’s modules and sub-packages do not need to share any code. Lastly, a convenient syntax is available for importing deeply nested packages: . This allows you to use in place of the verbose repetition of .\n\nPython is sometimes described as an object-oriented programming language. This can be somewhat misleading and requires further clarifications. In Python, everything is an object, and can be handled as such. This is what is meant when we say, for example, that functions are first-class objects. Functions, classes, strings, and even types are objects in Python: like any object, they have a type, they can be passed as function arguments, and they may have methods and properties. In this understanding, Python can be considered as an object-oriented language. However, unlike Java, Python does not impose object-oriented programming as the main programming paradigm. It is perfectly viable for a Python project to not be object-oriented, i.e. to use no or very few class definitions, class inheritance, or any other mechanisms that are specific to object-oriented programming languages. Moreover, as seen in the modules section, the way Python handles modules and namespaces gives the developer a natural way to ensure the encapsulation and separation of abstraction layers, both being the most common reasons to use object-orientation. Therefore, Python programmers have more latitude as to not use object-orientation, when it is not required by the business model. There are some reasons to avoid unnecessary object-orientation. Defining custom classes is useful when we want to glue some state and some functionality together. The problem, as pointed out by the discussions about functional programming, comes from the “state” part of the equation. In some architectures, typically web applications, multiple instances of Python processes are spawned as a response to external requests that happen simultaneously. In this case, holding some state in instantiated objects, which means keeping some static information about the world, is prone to concurrency problems or race conditions. Sometimes, between the initialization of the state of an object (usually done with the method) and the actual use of the object state through one of its methods, the world may have changed, and the retained state may be outdated. For example, a request may load an item in memory and mark it as read by a user. If another request requires the deletion of this item at the same time, the deletion may actually occur after the first process loaded the item, and then we have to mark a deleted object as read. This and other issues led to the idea that using stateless functions is a better programming paradigm. Another way to say the same thing is to suggest using functions and procedures with as few implicit contexts and side-effects as possible. A function’s implicit context is made up of any of the global variables or items in the persistence layer that are accessed from within the function. Side-effects are the changes that a function makes to its implicit context. If a function saves or deletes data in a global variable or in the persistence layer, it is said to have a side-effect. Carefully isolating functions with context and side-effects from functions with logic (called pure functions) allows the following benefits:\n• Pure functions are deterministic: given a fixed input, the output will always be the same.\n• Pure functions are much easier to change or replace if they need to be refactored or optimized.\n• Pure functions are easier to test with unit tests: There is less need for complex context setup and data cleaning afterwards.\n• Pure functions are easier to manipulate, decorate, and pass around. In summary, pure functions are more efficient building blocks than classes and objects for some architectures because they have no context or side-effects. Obviously, object-orientation is useful and even necessary in many cases, for example when developing graphical desktop applications or games, where the things that are manipulated (windows, buttons, avatars, vehicles) have a relatively long life of their own in the computer’s memory.\n\nA context manager is a Python object that provides extra contextual information to an action. This extra information takes the form of running a callable upon initiating the context using the statement, as well as running a callable upon completing all the code inside the block. The most well known example of using a context manager is shown here, opening on a file: Anyone familiar with this pattern knows that invoking in this fashion ensures that ’s method will be called at some point. This reduces a developer’s cognitive load and makes the code easier to read. There are two easy ways to implement this functionality yourself: using a class or using a generator. Let’s implement the above functionality ourselves, starting with the class approach: This is just a regular Python object with two extra methods that are used by the statement. CustomOpen is first instantiated and then its method is called and whatever returns is assigned to in the part of the statement. When the contents of the block is finished executing, the method is then called. And now the generator approach using Python’s own contextlib: This works in exactly the same way as the class example above, albeit it’s more terse. The function executes until it reaches the statement. It then gives control back to the statement, which assigns whatever was ’ed to in the portion. The clause ensures that is called whether or not there was an exception inside the . Since the two approaches appear the same, we should follow the Zen of Python to decide when to use which. The class approach might be better if there’s a considerable amount of logic to encapsulate. The function approach might be better for situations where we’re dealing with a simple action.\n\nPython is dynamically typed, which means that variables do not have a fixed type. In fact, in Python, variables are very different from what they are in many other languages, specifically statically-typed languages. Variables are not a segment of the computer’s memory where some value is written, they are ‘tags’ or ‘names’ pointing to objects. It is therefore possible for the variable ‘a’ to be set to the value 1, then the value ‘a string’, to a function. The dynamic typing of Python is often considered to be a weakness, and indeed it can lead to complexities and hard-to-debug code. Something named ‘a’ can be set to many different things, and the developer or the maintainer needs to track this name in the code to make sure it has not been set to a completely unrelated object. Some guidelines help to avoid this issue:\n• Avoid using the same variable name for different things. Using short functions or methods helps to reduce the risk of using the same name for two unrelated things. It is better to use different names even for things that are related, when they have a different type: There is no efficiency gain when reusing names: the assignments will have to create new objects anyway. However, when the complexity grows and each assignment is separated by other lines of code, including ‘if’ branches and loops, it becomes harder to ascertain what a given variable’s type is. Some coding practices, like functional programming, recommend never reassigning a variable. In Java this is done with the keyword. Python does not have a keyword and it would be against its philosophy anyway. However, it may be a good discipline to avoid assigning to a variable more than once, and it helps in grasping the concept of mutable and immutable types.\n\nPython has two kinds of built-in or user-defined types. Mutable types are those that allow in-place modification of the content. Typical mutables are lists and dictionaries: All lists have mutating methods, like or , and can be modified in place. The same goes for dictionaries. Immutable types provide no method for changing their content. For instance, the variable x set to the integer 6 has no “increment” method. If you want to compute x + 1, you have to create another integer and give it a name. # [4, 2, 3] <- The same list has changed # The new x is another object One consequence of this difference in behavior is that mutable types are not “stable”, and therefore cannot be used as dictionary keys. Using properly mutable types for things that are mutable in nature and immutable types for things that are fixed in nature helps to clarify the intent of the code. For example, the immutable equivalent of a list is the tuple, created with . This tuple is a pair that cannot be changed in-place, and can be used as a key for a dictionary. One peculiarity of Python that can surprise beginners is that strings are immutable. This means that when constructing a string from its parts, appending each part to the string is inefficient because the entirety of the string is copied on each append. Instead, it is much more efficient to accumulate the parts in a list, which is mutable, and then glue ( ) the parts together when the full string is needed. List comprehensions are usually the fastest and most idiomatic way to do this. One final thing to mention about strings is that using is not always best. In the instances where you are creating a new string from a pre-determined number of strings, using the addition operator is actually faster. But in cases like above or in cases where you are adding to an existing string, using should be your preferred method. # This is bad, instead you should do: You can also use the % formatting operator to concatenate a pre-determined number of strings besides and . However, PEP 3101 discourages the usage of the operator in favor of the method."
    },
    {
        "link": "https://stackoverflow.com/questions/193161/what-is-the-best-project-structure-for-a-python-application",
        "document": "Doesn't too much matter. Whatever makes you happy will work. There aren't a lot of silly rules because Python projects can be simple.\n• or for that kind of command-line interface stuff\n\nAnd the top-level directory can contain README's, Config's and whatnot.\n\nThe hard choice is whether or not to use a tree. Python doesn't have a distinction between , , and like Java or C has.\n\nSince a top-level directory is seen by some as meaningless, your top-level directory can be the top-level architecture of your application.\n\nI recommend putting all of this under the \"name-of-my-product\" directory. So, if you're writing an application named , the directory that contains all this stuff is named .\n\nAnother project's , then, can include to reuse the module.\n\nIn my case, since I use Komodo Edit, my IDE cuft is a single .KPF file. I actually put that in the top-level directory, and omit adding it to SVN."
    },
    {
        "link": "https://medium.com/pythoneers/best-practices-for-structuring-a-python-project-like-a-pro-be6013821168",
        "document": "Build Python projects the right way!\n\nBest Practices for Structuring a Python Project Like a Pro! 🚀\n\nStructuring your Python project correctly can save you from headaches later. A well-organized project improves maintainability, scalability, and collaboration — whether you’re working solo or with a team.\n\nIn this article, I’ll walk you through best practices for structuring a Python project like a pro!"
    },
    {
        "link": "https://linkedin.com/advice/0/what-best-practices-structuring-games-codebase-sxldc",
        "document": ""
    },
    {
        "link": "https://aashishkumar12376.medium.com/best-practices-for-structuring-a-python-project-like-a-pro-be6013821168",
        "document": "Build Python projects the right way!\n\nBest Practices for Structuring a Python Project Like a Pro! 🚀\n\nStructuring your Python project correctly can save you from headaches later. A well-organized project improves maintainability, scalability, and collaboration — whether you’re working solo or with a team.\n\nIn this article, I’ll walk you through best practices for structuring a Python project like a pro!"
    }
]