[
    {
        "link": "https://gradio.app/docs",
        "document": "Introducing FastRTC, a new way to build real-time AI apps"
    },
    {
        "link": "https://gradio.app/docs/gradio/chatinterface",
        "document": "Basic Example: A chatbot that echoes back the users’s message\n\nCustom Chatbot: A with a custom that includes a placeholder as well as upvote/downvote buttons. The upvote/downvote buttons are automatically added when a event is attached to a . In order to attach event listeners to your custom chatbot, wrap the as well as the inside of a like this:\n\nThe format of the messages passed into the chat history parameter of `fn`. If \"messages\", passes the history as a list of dictionaries with openai-style \"role\" and \"content\" keys. The \"content\" key's value should be one of the following - (1) strings in valid Markdown (2) a dictionary with a \"path\" key and value corresponding to the file to display or (3) an instance of a Gradio component: at the moment gr.Image, gr.Plot, gr.Video, gr.Gallery, gr.Audio, and gr.HTML are supported. The \"role\" key should be one of 'user' or 'assistant'. Any other roles will not be displayed in the output. If this parameter is 'tuples' (deprecated), passes the chat history as a `list[list[str | None | tuple]]`, i.e. a list of lists. The inner list should have 2 elements: the user message and the response message.\n\nsample inputs for the function; if provided, appear within the chatbot and can be clicked to populate the chatbot input. Should be a list of strings representing text-only examples, or a list of dictionaries (with keys `text` and `files`) representing multimodal examples. If `additional_inputs` are provided, the examples must be a list of lists, where the first element of each inner list is the string or dictionary example message and the remaining elements are the example values for the additional inputs -- in this case, the examples will appear under the chatbot."
    },
    {
        "link": "https://gradio.app/docs/gradio/interface",
        "document": "Interface is Gradio's main high-level class, and allows you to create a web-based GUI / demo around a machine learning model (or any Python function) in a few lines of code. You must specify three parameters: (1) the function to create a GUI for (2) the desired input components and (3) the desired output components. Additional parameters can be used to control the appearance and behavior of the demo. \n\n\n\nthe function to wrap an interface around. Often a machine learning model's prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component. a single Gradio component, or list of Gradio components. Components can either be passed as instantiated objects, or referred to by their string shortcuts. The number of input components should match the number of parameters in fn. If set to None, then only the output components will be displayed. a single Gradio component, or list of Gradio components. Components can either be passed as instantiated objects, or referred to by their string shortcuts. The number of output components should match the number of values returned by fn. If set to None, then only the input components will be displayed. sample inputs for the function; if provided, appear below the UI components and can be clicked to populate the interface. Should be nested list, in which the outer list consists of samples and each inner list consists of an input corresponding to each input component. A string path to a directory of examples can also be provided, but it should be within the directory with the python file running the gradio app. If there are multiple input components and a directory is provided, a log.csv file must be present in the directory to link corresponding inputs. If True, caches examples in the server for fast runtime in examples. If \"lazy\", then examples are cached (for all users of the app) after their first use (by any user of the app). If None, will use the GRADIO_CACHE_EXAMPLES environment variable, which should be either \"true\" or \"false\". In HuggingFace Spaces, this parameter is True (as long as `fn` and `outputs` are also provided). The default option otherwise is False. if \"lazy\", examples are cached after their first use. If \"eager\", all examples are cached at app launch. If None, will use the GRADIO_CACHE_MODE environment variable if defined, or default to \"eager\". if examples are provided, how many to display per page. a list of labels for each example. If provided, the length of this list should be the same as the number of examples, and these labels will be used in the UI instead of rendering the example values. whether the interface should automatically rerun if any of the inputs change. a title for the interface; if provided, appears above the input and output components in large font. Also used as the tab title when opened in a browser window. a description for the interface; if provided, appears above the input and output components and beneath the title in regular font. Accepts Markdown and HTML content. an expanded article explaining the interface; if provided, appears below the input and output components in regular font. Accepts Markdown and HTML content. If it is an HTTP(S) link to a downloadable remote file, the content of this file is displayed. a Theme object or a string representing a theme. If a string, will look for a built-in theme with that name (e.g. \"soft\" or \"default\"), or will attempt to load a theme from the Hugging Face Hub (e.g. \"gradio/monochrome\"). If None, will use the Default theme. one of \"never\", \"auto\", or \"manual\". If \"never\" or \"auto\", users will not see a button to flag an input and output. If \"manual\", users will see a button to flag. If \"auto\", every input the user submits will be automatically flagged, along with the generated output. If \"manual\", both the input and outputs are flagged when the user clicks flag button. This parameter can be set with environmental variable GRADIO_FLAGGING_MODE; otherwise defaults to \"manual\". if provided, allows user to select from the list of options when flagging. Only applies if flagging_mode is \"manual\". Can either be a list of tuples of the form (label, value), where label is the string that will be displayed on the button and value is the string that will be stored in the flagging CSV; or it can be a list of strings [\"X\", \"Y\"], in which case the values will be the list of strings and the labels will [\"Flag as X\", \"Flag as Y\"], etc. path to the the directory where flagged data is stored. If the directory does not exist, it will be created. either None or an instance of a subclass of FlaggingCallback which will be called when a sample is flagged. If set to None, an instance of gradio.flagging.CSVLogger will be created and logs will be saved to a local CSV file in flagging_dir. Default to None. whether to allow basic telemetry. If None, will use GRADIO_ANALYTICS_ENABLED environment variable if defined, or default to True. if True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component. the maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True) defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None, the name of the prediction function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event. if True, then will show a 'Duplicate Spaces' button on Hugging Face Spaces. if set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to \"default\" to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `.queue()`, which itself is 1 by default). Custom css as a code string. This css will be included in the demo webpage. Custom css as a pathlib.Path to a css file or a list of such paths. This css files will be read, concatenated, and included in the demo webpage. If the `css` parameter is also set, the css from `css` will be included first. Custom js as a code string. The custom js should be in the form of a single js function. This function will automatically be executed when the page loads. For more flexibility, use the head parameter to insert js inside <script> tags. Custom html code to insert into the head of the demo webpage. This can be used to add custom meta tags, multiple scripts, stylesheets, etc. to the page. Custom html code as a pathlib.Path to a html file or a list of such paths. This html files will be read, concatenated, and included in the head of the demo webpage. If the `head` parameter is also set, the html from `head` will be included first. a single Gradio component, or list of Gradio components. Components can either be passed as instantiated objects, or referred to by their string shortcuts. These components will be rendered in an accordion below the main input components. By default, no additional input components will be displayed. if a string is provided, this is the label of the `gr.Accordion` to use to contain additional inputs. A `gr.Accordion` object can be provided as well to configure other properties of the container holding the additional inputs. Defaults to a `gr.Accordion(label=\"Additional Inputs\", open=False)`. This parameter is only used if `additional_inputs` is provided. the button to use for submitting inputs. Defaults to a `gr.Button(\"Submit\", variant=\"primary\")`. This parameter does not apply if the Interface is output-only, in which case the submit button always displays \"Generate\". Can be set to a string (which becomes the button label) or a `gr.Button` object (which allows for more customization). the button to use for stopping the interface. Defaults to a `gr.Button(\"Stop\", variant=\"stop\", visible=False)`. Can be set to a string (which becomes the button label) or a `gr.Button` object (which allows for more customization). the button to use for clearing the inputs. Defaults to a `gr.Button(\"Clear\", variant=\"secondary\")`. Can be set to a string (which becomes the button label) or a `gr.Button` object (which allows for more customization). Can be set to None, which hides the button. a tuple corresponding [frequency, age] both expressed in number of seconds. Every `frequency` seconds, the temporary files created by this Blocks instance will be deleted if more than `age` seconds have passed since the file was created. For example, setting this to (86400, 86400) will delete temporary files every day. The cache will be deleted entirely when the server restarts. If None, no cache deletion will occur. how to show the progress animation while event is running: \"full\" shows a spinner which covers the output component area as well as a runtime display in the upper right corner, \"minimal\" only shows the runtime display, \"hidden\" shows no progress animation at all whether to horizontally expand to fill container fully. If False, centers and constrains app to a maximum width. The time limit for the stream to run. Default is 30 seconds. Parameter only used for streaming images or audio if the interface is live and the input components are set to \"streaming=True\". The latency (in seconds) at which stream chunks are sent to the backend. Defaults to 0.5 seconds. Parameter only used for streaming images or audio if the interface is live and the input components are set to \"streaming=True\".\n\nLaunches a simple web server that serves the demo. Can also be used to create a public link used by anyone to access the demo from their browser by setting share=True. whether to display in the gradio app inline in an iframe. Defaults to True in python notebooks; False otherwise. whether to automatically launch the gradio app in a new tab on the default browser. whether to create a publicly shareable link for the gradio app. Creates an SSH tunnel to make your UI accessible from anywhere. If not provided, it is set to False by default every time, except when running in Google Colab. When localhost is not accessible (e.g. Google Colab), setting share=False is not supported. Can be set by environment variable GRADIO_SHARE=True. if True, blocks the main thread from running. If running in Google Colab, this is needed to print the errors in the cell output. the maximum number of total threads that the Gradio app can generate in parallel. The default is inherited from the starlette library (currently 40). If provided, username and password (or list of username-password tuples) required to access app. Can also provide function that takes username and password and returns True if valid login. By default, the gradio app blocks the main thread while the server is running. If set to True, the gradio app will not block and the gradio server will terminate as soon as the script finishes. If True, any errors in the gradio app will be displayed in an alert modal and printed in the browser console log to make app accessible on local network, set this to \"0.0.0.0\". Can be set by environment variable GRADIO_SERVER_NAME. If None, will use \"127.0.0.1\". will start gradio app on this port (if available). Can be set by environment variable GRADIO_SERVER_PORT. If None, will search for an available port starting at 7860. The height in pixels of the iframe element containing the gradio app (used if inline=True) The width in pixels of the iframe element containing the gradio app (used if inline=True) If a path to a file (.png, .gif, or .ico) is provided, it will be used as the favicon for the web page. If a path to a file is provided, will use this as the private key file to create a local server running on https. If a path to a file is provided, will use this as the signed certificate for https. Needs to be provided if ssl_keyfile is provided. If a password is provided, will use this with the ssl certificate for https. If False, skips certificate validation which allows self-signed certificates to be used. If True, shows the api docs in the footer of the app. Default True. List of complete filepaths or parent directories that gradio is allowed to serve. Must be absolute paths. Warning: if you provide directories, any files in these directories or their subdirectories are accessible to all users of your app. Can be set by comma separated environment variable GRADIO_ALLOWED_PATHS. These files are generally assumed to be secure and will be displayed in the browser when possible. List of complete filepaths or parent directories that gradio is not allowed to serve (i.e. users of your app are not allowed to access). Must be absolute paths. Warning: takes precedence over `allowed_paths` and all other directories exposed by Gradio by default. Can be set by comma separated environment variable GRADIO_BLOCKED_PATHS. The root path (or \"mount point\") of the application, if it's not served from the root (\"/\") of the domain. Often used when the application is behind a reverse proxy that forwards requests to the application. For example, if the application is served at \"https://example.com/myapp\", the `root_path` should be set to \"/myapp\". A full URL beginning with http:// or https:// can be provided, which will be used as the root path in its entirety. Can be set by environment variable GRADIO_ROOT_PATH. Defaults to \"\". Additional keyword arguments to pass to the underlying FastAPI app as a dictionary of parameter keys and argument values. For example, `{\"docs_url\": \"/docs\"}` The maximum number of sessions whose information to store in memory. If the number of sessions exceeds this number, the oldest sessions will be removed. Reduce capacity to reduce memory usage when using gradio.State or returning updated components from functions. Defaults to 10000. Use this to specify a custom FRP server and port for sharing Gradio apps (only applies if share=True). If not provided, will use the default FRP server at https://gradio.live. See https://github.com/huggingface/frp for more information. Use this to specify the protocol to use for the share links. Defaults to \"https\", unless a custom share_server_address is provided, in which case it defaults to \"http\". If you are using a custom share_server_address and want to use https, you must set this to \"https\". The path to a TLS certificate file to use when connecting to a custom share server. This parameter is not used with the default FRP server at https://gradio.live. Otherwise, you must provide a valid TLS certificate file (e.g. a \"cert.pem\") relative to the current working directory, or the connection will not use TLS encryption, which is insecure. A function that takes a FastAPI request and returns a string user ID or None. If the function returns None for a specific request, that user is not authorized to access the app (they will see a 401 Unauthorized response). To be used with external authentication systems like OAuth. Cannot be used with `auth`. The maximum file size in bytes that can be uploaded. Can be a string of the form \"<value><unit>\", where value is any positive integer and unit is one of \"b\", \"kb\", \"mb\", \"gb\", \"tb\". If None, no limit is set. Enables traffic monitoring of the app through the /monitoring endpoint. By default is None, which enables this endpoint. If explicitly True, will also print the monitoring URL to the console. If False, will disable monitoring altogether. If True, prevents external domains from making requests to a Gradio server running on localhost. If False, allows requests to localhost that originate from localhost but also, crucially, from \"null\". This parameter should normally be True to prevent CSRF attacks but may need to be False when embedding a *locally-running Gradio app* using web components. If True, the Gradio app will be rendered using server-side rendering mode, which is typically more performant and provides better SEO, but this requires Node 20+ to be installed on the system. If False, the app will be rendered using client-side rendering mode. If None, will use GRADIO_SSR_MODE environment variable or default to False. If True, the Gradio app will be set up as an installable PWA (Progressive Web App). If set to None (default behavior), then the PWA feature will be enabled if this Gradio app is launched on Spaces, but not otherwise. This listener is triggered when the Interface initially loads in the browser. the function to call when this event is triggered. Often a machine learning model's prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component. List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list. List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list. defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event. If True, will scroll to output component on completion how to show the progress animation while event is running: \"full\" shows a spinner which covers the output component area as well as a runtime display in the upper right corner, \"minimal\" only shows the runtime display, \"hidden\" shows no progress animation at all Component or list of components to show the progress animation on. If None, will show the progress animation on all of the output components. If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app. If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component. Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True) If False, will not run preprocessing of component data before running 'fn' (e.g. leaving it as a base64 string if this method is called with the `Image` component). If False, will not run postprocessing of component data before returning 'fn' output to the browser. A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish. If \"once\" (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to \"multiple\", unlimited submissions are allowed while pending, and \"always_last\" (default for `.change()` and `.key_up()` events) would allow a second submission after the pending event is complete. Optional frontend js method to run before running 'fn'. Input arguments for js method are values of 'inputs' and 'outputs', return should be a list of values for output components. If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to \"default\" to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default). If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit. whether to show this event in the \"view API\" page of the Gradio app, or in the \".view_api()\" method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps as well as the Clients to use this event. If fn is None, show_api will automatically be set to False. Class method that constructs an Interface from a Hugging Face transformers.Pipeline or diffusers.DiffusionPipeline object. The input and output components are automatically determined from the pipeline. the pipeline object to use. A catch-all method for integrating with other libraries. This method should be run after launch() If a comet_ml Experiment object is provided, will integrate with the experiment and appear on Comet dashboard If the wandb module is provided, will integrate with it and appear on WandB dashboard If the mlflow module is provided, will integrate with the experiment and appear on ML Flow dashboard By enabling the queue you can control when users know their position in the queue, and set a limit on maximum number of events allowed. If True, the REST routes of the backend will be open, allowing requests made directly to those endpoints to skip the queue. The maximum number of events the queue will store at any given moment. If the queue is full, new events will not be added and a user will receive a message saying that the queue is full. If None, the queue size will be unlimited. The default value of `concurrency_limit` to use for event listeners that don't specify a value. Can be set by environment variable GRADIO_DEFAULT_CONCURRENCY_LIMIT. Defaults to 1 if not set otherwise."
    },
    {
        "link": "https://pyimagesearch.com/2025/02/03/introduction-to-gradio-for-building-interactive-applications",
        "document": "In this tutorial, you’ll dive into Gradio and learn how it empowers Python developers to create interactive applications ideal for showcasing machine learning (ML) models. We’ll cover what makes Gradio popular, explore high-impact projects built with it, and review the latest enhancements in Gradio 5. You’ll also get hands-on with Gradio’s core classes, essential components like TextBox, Buttons, and Sliders, and learn how to handle common errors like the “AttributeError: module ‘gradio’ has no attribute ‘inputs’.” Finally, we’ll show you how to connect with external models using the Gradio API, unlocking dynamic data interactions for your applications.\n\nThis lesson is the 1st of a 2-part series on Gradio for building interactive applications:\n• Introduction to Gradio for Building Interactive Applications (this tutorial)\n\nTo learn how to get started with Gradio, explore its latest features, and work with its core components and API, just keep reading.\n\nIn the world of machine learning and AI (artificial intelligence), building a powerful model is only half the battle; the other half lies in demonstrating its impact. For machine learning engineers and data scientists, creating intuitive user interfaces (UIs) to showcase their models can be a game-changer. A well-designed interface allows end-users — who might not be technically inclined — to interact with models, provide input, and observe results in real-time. This not only enhances the model’s accessibility but also enables feedback collection, collaboration, and practical application in real-world scenarios.\n\nThis is where Gradio comes into play. Gradio is an open-source Python library that empowers developers to build interactive web interfaces for their machine learning models, APIs, or any Python functions with ease. With Gradio, engineers can go beyond code and present their work engagingly and tangibly, allowing users to test, validate, and gain insights from models firsthand. In essence, Gradio serves as a bridge between complex machine learning models and the non-technical users who can benefit from them.\n\nGradio is an open-source Python library that simplifies the creation of user-friendly web interfaces for machine learning models, APIs, or any Python function. Initially developed as a way to help machine learning practitioners showcase their models, Gradio has evolved into a powerful tool for creating interactive applications across various domains. It’s especially popular among developers, educators, and data scientists who need to demonstrate complex models to a non-technical audience.\n\nGradio was founded by Abid et al. (2019) with the goal of making machine learning models accessible to everyone. The tool quickly gained popularity due to its simplicity and the ability to create fully functional web interfaces with minimal code. In 2021, Gradio was acquired by Hugging Face, a leader in the machine learning space known for its extensive Transformers library and model hub. This acquisition further boosted Gradio’s development, adding more resources, community support, and deep integrations with Hugging Face’s powerful model ecosystem.\n\nToday, Gradio is a favorite among Python developers and machine learning practitioners. It was even the #1 trending GitHub repository at the time of writing, reflecting its strong adoption and the enthusiasm within the developer community. It has become a staple tool in machine learning, with over 6.7 million downloads per month, making it one of the most widely used libraries for building ML interfaces. Gradio’s easy setup, component versatility, and rich integration with other Python tools and frameworks have made it a top choice for prototyping, deploying, and sharing machine learning applications quickly.\n\nAUTOMATIC1111 is a widely used web interface for Stable Diffusion, built entirely with Gradio. This tool allows users to generate images from text prompts and make adjustments in real-time, highlighting Gradio’s ability to handle advanced image generation workflows in an accessible format, bypassing the need for extensive programming knowledge or hardware setup.\n\nYou can learn more about it here.\n\nThe Text Generation Web UI by oobabooga leverages Gradio to create a powerful interactive interface for large language models (LLMs). This project allows users to load pre-trained models across various formats and frameworks, including Transformers, Llama.cpp, AutoGPTQ, and more. The flexibility of model loading means users can experiment with a wide range of LLMs, making it ideal for those interested in text generation, creative writing, chatbots, and conversational AI.\n\nOne of the standout features of this Gradio-powered UI is the Training Tab, which enables users to fine-tune models directly within the interface. Techniques like Low-Rank Adaptation (LoRA) make it possible to customize models (e.g., fine-tuning a Llama model for specific tasks) without needing extensive computational resources.\n\nFor a deeper dive into its features and a step-by-step guide to training LLMs like Llama with LoRA, you can refer to our blog post, Exploring Oobabooga Text Generation Web UI.\n\nThe Next Generation of Gradio: What’s New in Version 5\n\nGradio 5 introduces several enhancements aimed at improving performance, security, and user experience for developers building machine learning applications. Key updates include the following.\n\nGradio 5 incorporates server-side rendering (SSR), enabling applications to load almost instantaneously in the browser, eliminating previous loading delays.\n\nA comprehensive security audit was conducted by Trail of Bits, leading to the identification and resolution of potential vulnerabilities. These fixes have been validated and integrated into Gradio 5, ensuring safer deployment of applications.\n\nThe new AI Playground allows developers to generate or modify Gradio applications using natural language prompts, facilitating rapid prototyping and experimentation.\n\nYou can preview the app right in your browser immediately: https://www.gradio.app/playground\n\nCore components (e.g., Buttons, Tabs, and Sliders) have been refreshed with a modern design, enhancing the visual appeal and usability of applications.\n\nGradio 5 introduces a set of built-in themes, enabling developers to create fresh-looking applications without extensive customization easily (Hugging Face).\n\nSupport for low-latency streaming has been added, allowing for real-time applications (e.g., webcam-based object detection, video streaming, and conversational chatbots).\n\nTo follow this guide, you’ll need to install the library. For the latest version (Gradio 5), ensure your Python version is 3.10 or higher.\n\nOptional Installations: If you plan to use the Gradio Client for remote API calls or experiment with text generation models, you may also want to install the following libraries:\n\nNote: These optional libraries are primarily needed for the Gradio API section. If you only need the Gradio interface, installing gradio alone will suffice.\n\nNeed Help Configuring Your Development Environment?\n\nAll that said, are you:\n• Wanting to skip the hassle of fighting with the command line, package managers, and virtual environments?\n• Ready to run the code immediately on your Windows, macOS, or Linux system?\n\nGain access to Jupyter Notebooks for this tutorial and other PyImageSearch guides pre-configured to run on Google Colab’s ecosystem right in your web browser! No installation required.\n\nAnd best of all, these Jupyter Notebooks will run on Windows, macOS, and Linux!\n\nGradio offers several foundational classes for building interfaces, each suited to different levels of complexity. The primary classes are Interface and Blocks, which allow developers to tailor Gradio to their needs, from simple demos to highly customizable applications.\n\nThe Interface class is ideal for quick, high-level demos where you want to connect a function to input and output components with minimal setup. It’s designed for simplicity, making it perfect for single-function applications.\n\nLet’s build a basic greeting app that simply takes a user’s name and returns a greeting.\n\nWith Interface, you specify the input and output types directly. The layout is handled automatically, so there’s minimal setup, but also limited control over customization.\n\nThe Blocks class, on the other hand, provides a lower-level API for greater flexibility and control. With Blocks, you can arrange multiple components, group them in custom layouts, and define interactions between them, making it the go-to choice for more complex applications.\n\nLet’s revisit the greeting app but add a button that only triggers the greeting when clicked, demonstrating how Blocks allows for customized layouts and functionality.\n• You have full control over the layout, positioning the , , and elements as desired.\n• The triggers the greeting function only when clicked, offering an interactive flow.\n• Blocks enable flexibility in designing complex workflows, which is not achievable with Interface alone.\n\nWhen to Use Each\n• Use Interface: For quick, straightforward demos without the need for custom layouts.\n• Use Blocks: When building multi-component or more interactive applications where layout customization and component control are needed.\n\nGradio also offers ChatInterface, a specialized class tailored for conversational applications. It simplifies the creation of chatbots and conversational agents by automatically managing chat history and responses, making it ideal for large language model (LLM) interactions.\n\nIn conversational AI applications, ChatInterface saves development time by handling chat history and responses intuitively.\n\nGradio offers a suite of interactive components that facilitate the creation of user-friendly interfaces for machine learning models and data applications. These components enable developers to design intuitive and responsive user experiences. Below, we explore some of the key elements:\n\nThe Textbox component allows users to input text data, making it essential for tasks (e.g., receiving user queries or textual data). It supports various configurations, including single-line and multi-line inputs, and can be customized with placeholders, labels, and default values.\n\nThe Button component triggers specific actions or functions when clicked. It’s commonly used to initiate processes like data submission, machine learning model inference, or other interactive tasks.\n\nThe Slider component enables users to select a numerical value within a specified range by dragging a handle along a track. It’s particularly useful for adjusting parameters like thresholds, learning rates, or any variable that benefits from fine-tuning.\n\nThe Dropdown component presents a list of options from which users can select. It’s ideal for scenarios where a predefined set of choices is available (e.g., selecting a model type or choosing a dataset).\n\nThe Checkbox component allows users to make binary choices (e.g., enabling or disabling a feature). It’s useful for toggling options or settings within an application.\n\nBy combining these components, developers can create rich, interactive interfaces that enhance user engagement and streamline the interaction with machine learning models and data-driven applications.\n\nAttributeError: Module ‘Gradio’ Has No Attribute ‘Inputs’ — How to Fix It\n\nThe error is common when using outdated syntax. In previous Gradio versions, components like , , and were accessed with (e.g., ). In newer Gradio versions, however, this syntax has been deprecated, and components are now called directly (e.g., ).\n\nCause of the Error\n\nThis error appears when the older structure is used with a recent Gradio version. Gradio updated its API to simplify syntax, eliminating prefixes like .\n\nTo resolve this, update the syntax by removing :\n\nIf you’re using code from an older repository where the Gradio version isn’t specified in the file, Gradio will automatically install the latest version that’s compatible with your Python environment. This can lead to errors if the code relies on the syntax but doesn’t specify an older Gradio version.\n\nTo ensure compatibility with older syntax, you may need to specify a Gradio version compatible with the syntax (e.g., Gradio 3.5):\n\nPlease keep in mind that Gradio 3.5 is not compatible with Python 3.10 and above. If you’re working with Python 3.10+, you’ll need to use a newer Gradio version and update the code syntax accordingly.\n\nThe Gradio API (a.k.a. the Gradio Python Client) enables developers to interact with Gradio applications programmatically. Rather than manually using the Gradio web interface, the API allows for remote communication with Gradio apps, making it an ideal tool for automation, integration with other applications, and backend connections.\n\nWhy Use the Gradio API?\n• Remote Interactions: With the Gradio API, you can connect to and control Gradio applications from anywhere. This is particularly useful when deploying machine learning models as remote services that other applications or scripts can access.\n• Automation and Testing: The API allows you to programmatically send inputs to the Gradio app, retrieve outputs, and automate testing workflows.\n• Data Integration: For scenarios where Gradio apps are part of a larger pipeline, the API lets you connect the app with other systems (e.g., data preprocessing or external databases).\n\nIn essence, the Gradio API makes Gradio applications far more versatile and extensible, allowing for seamless integration with a variety of use cases.\n\nExample: Creating a Gradio App and Connecting via the Gradio API\n\nNow, let’s walk through a complete example where:\n• We create a Gradio app that generates text based on input prompts.\n• We connect to it remotely using the Gradio API.\n\nThis Gradio app will take a text prompt as input and generate text completions using a Hugging Face Transformer model.\n\nIn this setup, we’re using the Hugging Face model as the text-generation pipeline, which powers the function. This function is then exposed through a Gradio interface, allowing users to enter prompts and receive generated responses. By setting , Gradio provides a public URL for easy access to the app, which we’ll use to connect through the Gradio API.\n\nStep 2: Connecting to the Gradio App Using the Gradio API (Client-Side)\n\nWith the Gradio app deployed, you can use the Gradio API to interact with it programmatically from a different script or environment.\n\nThe client connects to the Gradio app using the exact URL generated by Gradio, enabling remote interaction with the deployed app. To send data, the predict method takes a prompt and sends it to the app’s function. By specifying , we’re able to target the first function defined in the Gradio app (in this case, ) and retrieve the generated text as the output.\n\nNote: Replace with the specific URL generated when the Gradio app was launched.\n\nAlternative for Stability: For a more robust API setup, consider deploying your Gradio app to Hugging Face Spaces. Spaces provides a stable, permanent URL, and the functionality is expected to work consistently. You can run from your project directory to set this up. This deployment can prevent the issues encountered when using URLs, making it ideal for long-term applications or integrations.\n\nWhy This Gradio API Example Matters\n\nThis setup demonstrates the practical use of the Gradio API for creating and connecting to machine learning applications. By combining server-side app deployment with client-side automation, you can:\n• Automate testing and run batch processes, further extending the use of Gradio beyond a simple GUI interface.\n\nFor additional capabilities, you can refer to the official Gradio Python Client documentation here.\n\nWhen using Gradio as an API, we can think of it as a client-server model. Here, the Gradio app acts as the server, handling incoming requests and executing the functions you’ve defined (e.g., ). The Gradio Client, meanwhile, serves as the client that makes remote API calls to the app’s server-side functions.\n\nThough Gradio is primarily known as an interface library for interactive web apps, this setup demonstrates its versatility. It can function as both a user-facing application and a backend service that supports programmatic interaction, making it useful for remote API calls and automated workflows.\n\nThis guide introduced Gradio, a powerful Python library for building interactive applications to showcase machine learning models. It began with an overview of What Is Gradio, explaining its role in democratizing machine learning through accessible, user-friendly interfaces and highlighting high-impact projects that relied on it. Then, it covered What’s New in Version 5, outlining key improvements (e.g., enhanced performance, better security measures, AI-powered app creation, and low-latency streaming).\n\nFollowing that, it explored the Gradio Core Classes (e.g., Interface, Blocks, and the optional ChatInterface), which are essential for structuring applications in Gradio. Key components like Textbox, Buttons, and Sliders were discussed to help users understand how to build intuitive interfaces.\n\nA section on AttributeError: Module ‘Gradio’ Has No Attribute ‘Inputs’ addressed common errors, offering solutions and compatibility notes for older code repositories and Python versions. Finally, Understanding the Gradio API (Python Client) provided an example of connecting to a Gradio app via the API, illustrating how to send data and retrieve responses programmatically, with an explanation of why this approach is valuable for remote interactions.\n\nMartinez, H. “Introduction to Gradio for Building Interactive Applications,” PyImageSearch, P. Chugh, S. Huot, A. Sharma, and P. Thakur, eds., 2025, https://pyimg.co/8dxkj\n\nTo download the source code to this post (and be notified when future tutorials are published here on PyImageSearch), simply enter your email address in the form below!"
    },
    {
        "link": "https://gradio.app/guides/creating-a-chatbot-fast",
        "document": "How to Create a Chatbot with Gradio\n\nChatbots are a popular application of large language models (LLMs). Using Gradio, you can easily build a chat application and share that with your users, or try it yourself using an intuitive UI.\n\nThis tutorial uses , which is a high-level abstraction that allows you to create your chatbot UI fast, often with a few lines of Python. It can be easily adapted to support multimodal chatbots, or chatbots that require further customization.\n\nPrerequisites: please make sure you are using the latest version of Gradio:\n\nIf you have a chat server serving an OpenAI-API compatible endpoint (such as Ollama), you can spin up a ChatInterface in a single line of Python. First, also run . Then, with your own URL, model, and optional token:\n\nRead about in the docs. If you have your own model, keep reading to see how to create an application around any chat model in Python!\n\nTo create a chat application with , the first thing you should do is define your chat function. In the simplest case, your chat function should accept two arguments: and (the arguments can be named anything, but must be in this order).\n• : a list of openai-style dictionaries with and keys, representing the previous conversation history. May also include additional keys representing message metadata.\n\nFor example, the could look like this:\n\nwhile the next would be:\n\nYour chat function simply needs to return:\n• a value, which is the chatbot's response based on the chat and most recent , for example, in this case:\n\nLet's take a look at a few example chat functions:\n\nExample: a chatbot that randomly responds with yes or no\n\nNow, we can plug this into and call the method to create the web interface:\n\nTip: Always set type=\"messages\" in gr.ChatInterface. The default value (type=\"tuples\") is deprecated and will be removed in a future version of Gradio.\n\nThat's it! Here's our running demo, try it out:\n\nExample: a chatbot that alternates between agreeing and disagreeing\n\nOf course, the previous example was very simplistic, it didn't take user input or the previous history into account! Here's another simple example showing how to incorporate a user's input as well as the history.\n\nWe'll look at more realistic examples of chat functions in our next Guide, which shows examples of using with popular LLMs.\n\nIn your chat function, you can use to generate a sequence of partial responses, each replacing the previous ones. This way, you'll end up with a streaming chatbot. It's that simple!\n\nWhile the response is streaming, the \"Submit\" button turns into a \"Stop\" button that can be used to stop the generator function.\n\nTip: Even though you are yielding the latest message at each iteration, Gradio only sends the \"diff\" of each message from the server to the frontend, which reduces latency and data consumption over your network.\n\nIf you're familiar with Gradio's class, the includes many of the same arguments that you can use to customize the look and feel of your Chatbot. For example, you can:\n• add a title and description above your chatbot using and arguments.\n• add a theme or custom css using and arguments respectively.\n• add and even enable , which make your Chatbot easier for users to try it out.\n• customize the chatbot (e.g. to change the height or add a placeholder) or textbox (e.g. to add a max number of characters or add a placeholder).\n\nYou can add preset examples to your with the parameter, which takes a list of string examples. Any examples will appear as \"buttons\" within the Chatbot before any messages are sent. If you'd like to include images or other files as part of your examples, you can do so by using this dictionary format for each example instead of a string: . Each file will be a separate message that is added to your Chatbot history.\n\nYou can change the displayed text for each example by using the argument. You can add icons to each example as well using the argument. Both of these arguments take a list of strings, which should be the same length as the list.\n\nIf you'd like to cache the examples so that they are pre-computed and the results appear instantly, set .\n\nIf you want to customize the or that compose the , then you can pass in your own chatbot or textbox components. Here's an example of how we to apply the parameters we've discussed in this section:\n\nHere's another example that adds a \"placeholder\" for your chat interface, which appears before the user has started chatting. The argument of accepts Markdown or HTML:\n\nThe placeholder appears vertically and horizontally centered in the chatbot.\n\nYou may want to add multimodal capabilities to your chat interface. For example, you may want users to be able to upload images or files to your chatbot and ask questions about them. You can make your chatbot \"multimodal\" by passing in a single parameter ( ) to the class.\n\nWhen , the signature of your chat function changes slightly: the first parameter of your function (what we referred to as above) should accept a dictionary consisting of the submitted text and uploaded files that looks like this:\n\nThis second parameter of your chat function, , will be in the same openai-style dictionary format as before. However, if the history contains uploaded files, the key for a file will be not a string, but rather a single-element tuple consisting of the filepath. Each file will be a separate message in the history. So after uploading two files and asking a question, your history might look like this:\n\nThe return type of your chat function does not change when setting (i.e. in the simplest case, you should still return a string value). We discuss more complex cases, e.g. returning files below.\n\nIf you are customizing a multimodal chat interface, you should pass in an instance of to the parameter. You can customize the further by passing in the parameter, which is a list of sources to enable. Here's an example that illustrates how to set up and customize and multimodal chat interface:\n\nYou may want to add additional inputs to your chat function and expose them to your users through the chat UI. For example, you could add a textbox for a system prompt, or a slider that sets the number of tokens in the chatbot's response. The class supports an parameter which can be used to add additional input components.\n\nThe parameters accepts a component or a list of components. You can pass the component instances directly, or use their string shortcuts (e.g. instead of ). If you pass in component instances, and they have not already been rendered, then the components will appear underneath the chatbot within a .\n\nIf the components you pass into the have already been rendered in a parent , then they will not be re-rendered in the accordion. This provides flexibility in deciding where to lay out the input components. In the example below, we position the on top of the Chatbot UI, while keeping the slider underneath.\n\nYou can also add example values for your additional inputs. Pass in a list of lists to the parameter, where each inner list represents one sample, and each inner list should be long. The first element in the inner list should be the example value for the chat message, and each subsequent element should be an example value for one of the additional inputs, in order. When additional inputs are provided, examples are rendered in a table underneath the chat interface.\n\nIf you need to create something even more custom, then its best to construct the chatbot UI using the low-level API. We have a dedicated guide for that here.\n\nIn the same way that you can accept additional inputs into your chat function, you can also return additional outputs. Simply pass in a list of components to the parameter in and return additional values for each component from your chat function. Here's an example that extracts code and outputs it into a separate component:\n\nNote: unlike the case of additional inputs, the components passed in must be already defined in your context -- they are not rendered automatically. If you need to render them after your , you can set when they are first defined and then them in the appropriate section of your as we do in the example above.\n\nWe mentioned earlier that in the simplest case, your chat function should return a response, which will be rendered as Markdown in the chatbot. However, you can also return more complex responses as we discuss below:\n\nCurrently, the following Gradio components can be displayed inside the chat interface:\n\nSimply return one of these components from your function to use it with . Here's an example that returns an audio file:\n\nSimilarly, you could return image files with , video files with , or arbitrary files with the component.\n\nYou can return multiple assistant messages from your chat function simply by returning a of messages, each of which is a valid chat type. This lets you, for example, send a message along with files, as in the following example:\n\nThe class supports displaying intermediate thoughts or tool usage direct in the chatbot.\n\nTo do this, you will need to return a object from your chat function. Here is the schema of the data class as well as two internal typed dictionaries:\n\nAs you can see, the dataclass is similar to the openai-style message format, e.g. it has a \"content\" key that refers to the chat message content. But it also includes a \"metadata\" key whose value is a dictionary. If this dictionary includes a \"title\" key, the resulting message is displayed as an intermediate thought with the title being displayed on top of the thought. Here's an example showing the usage:\n\nYou can even show nested thoughts, which is useful for agent demos in which one tool may call other tools. To display nested thoughts, include \"id\" and \"parent_id\" keys in the \"metadata\" dictionary. Read our dedicated guide on displaying intermediate thoughts and tool usage for more realistic examples.\n\nWhen returning an assistant message, you may want to provide preset options that a user can choose in response. To do this, again, you will again return a instance from your chat function. This time, make sure to set the key specifying the preset responses.\n\nAs shown in the schema for above, the value corresponding to the key should be a list of dictionaries, each with a (a string that is the value that should be sent to the chat function when this response is clicked) and an optional (if provided, is the text displayed as the preset response instead of the ).\n\nThis example illustrates how to use preset responses:\n\nYou may wish to modify the value of the chatbot with your own events, other than those prebuilt in the . For example, you could create a dropdown that prefills the chat history with certain conversations or add a separate button to clear the conversation history. The supports these events, but you need to use the as the input or output component in such events. In this example, we use a component to prefill the the chatbot with certain conversations:\n\nUsing Your Chatbot via API\n\nOnce you've built your Gradio chat interface and are hosting it on Hugging Face Spaces or somewhere else, then you can query it with a simple API at the endpoint. The endpoint just expects the user's message and will return the response, internally keeping track of the message history.\n\nTo use the endpoint, you should use either the Gradio Python Client or the Gradio JS client. Or, you can deploy your Chat Interface to other platforms, such as a:\n\nYou can enable persistent chat history for your ChatInterface, allowing users to maintain multiple conversations and easily switch between them. When enabled, conversations are stored locally and privately in the user's browser using local storage. So if you deploy a ChatInterface e.g. on Hugging Face Spaces, each user will have their own separate chat history that won't interfere with other users' conversations. This means multiple users can interact with the same ChatInterface simultaneously while maintaining their own private conversation histories.\n\nTo enable this feature, simply set (as shown in the example in the next section). Users will then see their previous conversations in a side panel and can continue any previous chat or start a new one.\n\nTo gather feedback on your chat model, set and users will be able to thumbs-up or thumbs-down assistant responses. Each flagged response, along with the entire chat history, will get saved in a CSV file in the app working directory (this can be configured via the parameter).\n\nYou can also change the feedback options via parameter. The default options are \"Like\" and \"Dislike\", which appear as the thumbs-up and thumbs-down icons. Any other options appear under a dedicated flag icon. This example shows a ChatInterface that has both chat history (mentioned in the previous section) and user feedback enabled:\n\nNote that in this example, we set several flagging options: \"Like\", \"Spam\", \"Inappropriate\", \"Other\". Because the case-sensitive string \"Like\" is one of the flagging options, the user will see a thumbs-up icon next to each assistant message. The three other flagging options will appear in a dropdown under the flag icon.\n\nNow that you've learned about the class and how it can be used to create chatbot UIs quickly, we recommend reading one of the following:\n• Our next Guide shows examples of how to use with popular LLM libraries.\n• If you'd like to build very custom chat applications from scratch, you can build them using the low-level Blocks API, as discussed in this Guide.\n• Once you've deployed your Gradio Chat Interface, its easy to use it other applications because of the built-in API. Here's a tutorial on how to deploy a Gradio chat interface as a Discord bot."
    },
    {
        "link": "https://github.com/comfyanonymous/ComfyUI/pull/5024/files",
        "document": "Add this suggestion to a batch that can be applied as a single commit.\n\nThis suggestion is invalid because no changes were made to the code.\n\nSuggestions cannot be applied while the pull request is closed.\n\nSuggestions cannot be applied while viewing a subset of changes.\n\nOnly one suggestion per line can be applied in a batch.\n\nAdd this suggestion to a batch that can be applied as a single commit.\n\nApplying suggestions on deleted lines is not supported.\n\nYou must change the existing code in this line in order to create a valid suggestion.\n\nThis suggestion has been applied or marked resolved.\n\nSuggestions cannot be applied from pending reviews.\n\nSuggestions cannot be applied on multi-line comments.\n\nSuggestions cannot be applied while the pull request is queued to merge.\n\nSuggestion cannot be applied right now. Please check back later."
    },
    {
        "link": "https://gradio.app/guides/getting-started-with-the-python-client",
        "document": "Getting Started with the Gradio Python client\n\nThe Gradio Python client makes it very easy to use any Gradio app as an API. As an example, consider this Hugging Face Space that transcribes audio files that are recorded from the microphone.\n\nUsing the library, we can easily use the Gradio as an API to transcribe audio files programmatically.\n\nHere's the entire code to do it:\n\nThe Gradio client works with any hosted Gradio app! Although the Client is mostly used with apps hosted on Hugging Face Spaces, your app can be hosted anywhere, such as your own server.\n\nPrerequisites: To use the Gradio client, you do not need to know the library in great detail. However, it is helpful to have general familiarity with Gradio's concepts of input and output components.\n\nIf you already have a recent version of , then the is included as a dependency. But note that this documentation reflects the latest version of the , so upgrade if you're not sure!\n\nThe lightweight package can be installed from pip (or pip3) and is tested to work with Python versions 3.10 or higher:\n\nStart by connecting instantiating a object and connecting it to a Gradio app that is running on Hugging Face Spaces.\n\nYou can also connect to private Spaces by passing in your HF token with the parameter. You can get your HF token here: https://huggingface.co/settings/tokens\n\nWhile you can use any public Space as an API, you may get rate limited by Hugging Face if you make too many requests. For unlimited usage of a Space, simply duplicate the Space to create a private Space, and then use it to make as many requests as you'd like!\n\nThe includes a class method: to make this process simple (you'll need to pass in your Hugging Face token or be logged in using the Hugging Face CLI):\n\nIf you have previously duplicated a Space, re-running will not create a new Space. Instead, the Client will attach to the previously-created Space. So it is safe to re-run the method multiple times.\n\nNote: if the original Space uses GPUs, your private Space will as well, and your Hugging Face account will get billed based on the price of the GPU. To minimize charges, your Space will automatically go to sleep after 1 hour of inactivity. You can also set the hardware using the parameter of .\n\nIf your app is running somewhere else, just provide the full URL instead, including the \"http://\" or \"https://\". Here's an example of making predictions to a Gradio app that is running on a share URL:\n\nIf the Gradio application you are connecting to requires a username and password, then provide them as a tuple to the argument of the class:\n\nOnce you have connected to a Gradio app, you can view the APIs that are available to you by calling the method. For the Whisper Space, we see the following:\n\nWe see that we have 1 API endpoint in this space, and shows us how to use the API endpoint to make a prediction: we should call the method (which we will explore below), providing a parameter of type , which is a .\n\nWe should also provide the argument to the method. Although this isn't necessary if a Gradio app has only 1 named endpoint, it does allow us to call different endpoints in a single app if they are available.\n\nAs an alternative to running the method, you can click on the \"Use via API\" link in the footer of the Gradio app, which shows us the same information, along with example usage.\n\nThe View API page also includes an \"API Recorder\" that lets you interact with the Gradio UI normally and converts your interactions into the corresponding code to run with the Python Client.\n\nThe simplest way to make a prediction is simply to call the function with the appropriate arguments:\n\nIf there are multiple parameters, then you should pass them as separate arguments to , like this:\n\nIt is recommended to provide key-word arguments instead of positional arguments:\n\nThis allows you to take advantage of default arguments. For example, this Space includes the default value for the Slider component so you do not need to provide it when accessing it with the client.\n\nThe default value is the initial value of the corresponding Gradio component. If the component does not have an initial value, but if the corresponding argument in the predict function has a default value of , then that parameter is also optional in the client. Of course, if you'd like to override it, you can include it as well:\n\nFor providing files or URLs as inputs, you should pass in the filepath or URL to the file enclosed within . This takes care of uploading the file to the Gradio server and ensures that the file is preprocessed correctly:\n\nOe should note that is a blocking operation as it waits for the operation to complete before returning the prediction.\n\nIn many cases, you may be better off letting the job run in the background until you need the results of the prediction. You can do this by creating a instance using the method, and then later calling on the job to get the result. For example:\n\nAlternatively, one can add one or more callbacks to perform actions after the job has completed running, like this:\n\nThe object also allows you to get the status of the running job by calling the method. This returns a object with the following attributes: (the status code, one of a set of defined strings representing the status. See the class), (the current position of this job in the queue), (the total queue size), (estimated time this job will complete), (a boolean representing whether the job completed successfully), and (the time that the status was generated).\n\nNote: The class also has a instance method which returns a boolean indicating whether the job has completed.\n\nThe class also has a instance method that cancels jobs that have been queued but not started. For example, if you run:\n\nIf the first job has started processing, then it will not be canceled. If the second job has not yet started, it will be successfully canceled and removed from the queue.\n\nSome Gradio API endpoints do not return a single value, rather they return a series of values. You can get the series of values that have been returned at any time from such a generator endpoint by running :\n\nNote that running on a generator endpoint only gives you the first value returned by the endpoint.\n\nThe object is also iterable, which means you can use it to display the results of a generator function as they are returned from the endpoint. Here's the equivalent example using the as a generator:\n\nYou can also cancel jobs that that have iterative outputs, in which case the job will finish as soon as the current iteration finishes running.\n\nGradio demos can include session state, which provides a way for demos to persist information from user interactions within a page session.\n\nFor example, consider the following demo, which maintains a list of words that a user has submitted in a component. When a user submits a new word, it is added to the state, and the number of previous occurrences of that word is displayed:\n\nIf you were to connect this this Gradio app using the Python Client, you would notice that the API information only shows a single input and output:\n\nThat is because the Python client handles state automatically for you -- as you make a series of requests, the returned state from one request is stored internally and automatically supplied for the subsequent request. If you'd like to reset the state, you can do that by calling ."
    },
    {
        "link": "https://discuss.huggingface.co/t/is-it-possible-to-deploy-a-websocket-server-with-gradio/52964",
        "document": "I’m working on a project of a hierarchical cooperative multi-agent framework that utilizes websockets for LLM<->LLM communication. Generally it is about running a websocket server that works as a ‘brain’ of the network and utilizes API endpoint(s) as a question-answering function for messages sent by multiple agents-clients connected to that server. Project is still in an early stage of development but I have already a working communication system - and it’s possibly the only currently available way to connect together completely different LLMs and let them speak with each other. Below is link to a folder in my repository where you can find couple different servers and clients (in Python, Node.js and html) most of which you can run as they are, since I try to avoid using OpenAI API and a simple schematics of the system as it is now:\n\nAnd since I managed to get something what can be run and (more or less) works, I’m thinking about deploying the server in a HuggingFace space and (even better) get some kind of usable interface - and of course Gradio is the best way of doing it - especially that there are absolutely no issues with using a Gradio client as question-answering function for both: server and a client. Thing is that from what I learned Gradio interface uses websocket communication to have a working chat interface for LLMs - so there might be issues, is that correct?\n\nPlease help! I’m open to, any form of cooperation - it’s a quite ambitious and I’m just one guy who only just started working with code couple months ago…"
    },
    {
        "link": "https://github.com/comfyanonymous/ComfyUI/blob/master/script_examples/websockets_api_example.py",
        "document": "#This is an example that uses the websockets api to know when a prompt execution is done\n\n#Once the prompt execution is done it downloads the images using the /history endpoint\n\n# If you want to be able to decode the binary stream for latent previews, here is how you can do it:\n\n# preview_image = Image.open(bytesIO) # This is your preview in PIL image format, store it in a global\n\n. () # for in case this example is used in an environment where it will be repeatedly called, like in a Gradio app. otherwise, you'll randomly receive connection timeouts"
    },
    {
        "link": "https://medium.com/@eddieoffermann/adding-a-user-interface-to-your-python-script-with-gradio-a-beginners-guide-4f0486311162",
        "document": "As data scientists and machine learning engineers, we often spend most of our time working with complex algorithms, modeling techniques, and large datasets. However, when it comes to sharing our work or deploying our models in real-world applications, we’re frequently faced with a daunting question: how do we make our code accessible and usable for others?\n\nOne popular solution is to create web-based interfaces that allow users to interact with our models and scripts without needing to write any code themselves. This approach not only makes it easier to share our work with non-technical stakeholders, but also enables us to deploy our models in a more user-friendly way.\n\nGradio is one tool that’s made this process much simpler. By providing a simple and intuitive API for building web-based interfaces, Gradio allows data scientists and machine learning engineers to focus on what they do best — building models and writing code — while still making it easy to share their work with others.\n\nIn this article, we’ll provide a basic introduction to using Gradio to build web-based interfaces for your data science and AI applications. To make the process as self-explanatory as possible, we’ll use a simple utility script as an example: a drive speed test script that measures the read and write speeds of a computer’s hard drive.\n\nWhy start with something so mundane? The answer is that it allows us to focus on the basics of building a Gradio interface without getting bogged down in complex modeling or machine learning concepts. By using a simple script as an example, we can walk through the process of creating a Gradio interface step-by-step, highlighting the key components and features that make Gradio so powerful.\n\nThroughout this article, we’ll cover the basics of Gradio, including how to install it, create a new project, and define input and output components. We’ll also provide plenty of code snippets and examples to illustrate each concept, making it easy for you to follow along and build your own Gradio interface.\n\nBy the end of this article, you should have a solid understanding of how to use Gradio to build web-based interfaces for your data science and AI applications — and be ready to start exploring more advanced features and techniques on your own. So let’s get started!\n\nGradio is an open-source Python library that allows data scientists and machine learning engineers to create web-based interfaces for their models and scripts with ease.\n\nAt its core, Gradio provides a simple and intuitive API for building web-based interfaces that can interact with Python code. This means that you can create a user-friendly interface for your machine learning model or script without needing to write any front-end code or worry about the underlying infrastructure.\n\nSome of the key features of Gradio include:\n• Simple API: Gradio provides a simple and easy-to-use API that allows you to define input and output components, such as text boxes, sliders, and images.\n• Automatic UI Generation: Gradio automatically generates a web-based interface for your model or script based on the components you define.\n• Real-time Feedback: Gradio provides real-time feedback to users, allowing them to see the output of their inputs immediately.\n\nThe advantages of using Gradio are numerous. For one, it allows data scientists and machine learning engineers to focus on what they do best — building models and writing code — without needing to worry about the front-end development process. This can save a significant amount of time and effort, especially for those who are not familiar with front-end development.\n\nAdditionally, Gradio makes it easy to deploy machine learning models and scripts in a production-ready environment. By providing a simple and intuitive interface for users to interact with your model or script, you can make it more accessible to a wider range of users, including non-technical stakeholders.\n\nGradio also provides a number of benefits for data science teams, including:\n• Improved Collaboration: Gradio makes it easy for data scientists to collaborate with other team members, such as product managers and engineers, by providing a simple and intuitive interface for them to interact with.\n• Faster Prototyping: Gradio allows data scientists to quickly prototype and test their models and scripts, which can help to speed up the development process.\n• Better Model Interpretability: Gradio provides a number of tools and features that make it easier to interpret and understand machine learning models, such as visualizations and feature importance scores.\n\nOverall, Gradio is a powerful tool for data scientists and machine learning engineers who want to create web-based interfaces for their models and scripts without needing to write any front-end code. Its simple API, automatic UI generation, and real-time feedback make it an ideal choice for building production-ready applications quickly and easily.\n\nIn this article, we’ll be using a simple drive speed test script as an example to demonstrate how to use Gradio to create a web-based interface for a Python script. This script is a great example because it’s easy to understand and provides a clear illustration of how Gradio can make it easier to interact with a script.\n\nThe drive speed test script is designed to measure the read and write speeds of a computer’s hard drive. It does this by writing a large file to the drive, then reading it back and measuring the time it takes to complete each operation. The results are then displayed as megabytes per second (MB/s).\n\nHere’s an example of what the script might output:\n\nThis information can be useful for a variety of purposes, such as:\n• Comparing the performance of different hard drives or storage devices\n• Monitoring the health and performance of a drive over time\n\nOne reason why a UI might be useful for this type of script is that it makes it easier for non-technical users to run the test. Without a UI, users would need to have some knowledge of Python and how to use the command line to run the script. With a UI, users can simply select the drive they want to test and click a button to start the test.\n\nAnother reason why a UI is useful for this type of script is that it provides a way to visualize the results in a more user-friendly way. For example, we could use a chart or graph to display the read and write speeds over time, making it easier to see trends and patterns in the data.\n\nHere’s an example of what the code for the drive speed test script might look like:\n\nThis code snippet shows how the script measures the write and read speeds of a drive by writing and reading a large file. The results are then printed to the console.\n\nWe could add commandline arguments to make this more flexible, but that just makes it less accessible for other nontechnical users.\n\nIn the next section, we’ll show how to use Gradio to create a web-based interface for this script (and add functionality to the script), making it easier for users to interact with and visualize the results.\n\nTo start working with the Drive Speed Test script, you’ll need to create a new Conda environment and clone the repository from GitHub. Here’s how:\n• Create a new Conda environment using the following command:\n\nThis will create a new environment named with Python 3.10.11 installed.\n\n3. Activate the environment using the following command:\n\n4. Clone the repository from GitHub using the following command:\n\nThis will download the entire repository to your local machine.\n\n5. Change into the cloned repository directory using the following command:\n\nTo install the dependencies required by the script, you’ll need to run the following command:\n\nThis will install all the dependencies listed in the file.\n\nHowever, for this script, you can also manually install the required packages using pip:\n\nNow that we have our environment set up and dependencies installed, let’s add Gradio to the drive speed test script.\n\nTo create a Gradio interface for the drive speed test script, you’ll need to define an input component, an output component, and a prediction function that runs the script. Here’s how:\n\nIn this code snippet, we’re defining an input component as a dropdown menu with available drives. We’re also defining an output component as text.\n\nThe prediction function is where you’ll put your drive speed test script.\n\nIn the context of Gradio, the term “prediction function” might be slightly misleading, as it doesn’t necessarily imply making predictions in the classical sense (e.g., predicting outcomes based on input data).\n\nInstead, the “prediction function” in Gradio refers to the Python function that is executed when a user interacts with the interface. This function takes in the user’s input, processes it, and returns output that is then displayed in the interface.\n\nIn the case of the drive speed test script, the function is the prediction function because it takes in the selected drive letter as input, performs the drive speed tests, and returns the results as a string. Gradio then displays this output in the interface.\n\nThe term “prediction function” likely originated from Gradio’s roots in machine learning, where the library was initially designed to deploy and serve machine learning models. In that context, the prediction function would indeed be responsible for making predictions based on user input. However, as Gradio has evolved to support a broader range of use cases, the term “prediction function” has stuck, even though it might not always accurately convey the function’s purpose.\n\nA more accurate term might be “processing function” or “execution function,” but “prediction function” is now an established part of the Gradio ecosystem.\n\nIn this case, it’s already defined in the function:\n\nThis function takes in the selected drive letter, performs the drive speed tests, and returns the results.\n\nFinally, to launch the interface, you’ll need to call the method on the Gradio interface object:\n\nThis will open the interface in your default web browser. You can then interact with the interface by selecting a drive and clicking the “Submit” button.\n\nThat’s it! With these steps, you should now have a fully functional Gradio interface for the drive speed test script.\n\nNow that we have our script set up with Gradio, let’s talk about how to run it and what users can expect to see when they interact with the UI.\n\nTo run the script with Gradio, you’ll need to execute the Python file that contains the Gradio interface code. In this case, we’ve saved our code in a file called .\n\nTo run the script, navigate to the directory where your file is located and use the following command:\n\nThis will start the Gradio server and make the interface available in your web browser.\n\nWhen you open the interface in your web browser, you’ll see a simple UI that allows you to select a drive and run the speed test. Here’s what you can expect to see:\n• A dropdown menu that lists all available drives on your system\n• A “Submit” button that runs the speed test when clicked\n• An output display that shows the results of the speed test\n\nHere’s an example of what the UI might look like:\n\nWhen you select a drive and click the “Submit” button, Gradio will execute the function that we defined earlier and display the results in the output display.\n\nHere are some example use cases for the Drive Speed Test UI:\n• Troubleshooting slow performance issues: Run the speed test on different drives to see if there’s a problem with a specific drive or if it’s a system-wide issue.\n• Comparing drive performance: Run the speed test on multiple drives and compare the results to see which one is the fastest.\n• Monitoring drive health: Run the speed test regularly to monitor the health of your drives and detect any potential issues before they become major problems.\n\nOverall, the Drive Speed Test UI provides a simple and easy-to-use way to run speed tests on your drives and troubleshoot performance issues. With Gradio, you can easily deploy this UI as a web application and make it available to others.\n\nWhen you run the Drive Speed Test script with Gradio, you’ll notice that the UI has three buttons: Clear, Submit, and Flag. You might be wondering where these buttons came from, since we didn’t define them explicitly in our Python code.\n\nThe answer is that these buttons are automatically generated by Gradio when it creates the interface. Here’s what each button does:\n• Submit: This button is used to submit the input values and run the prediction function (in this case, the function). When you click Submit, Gradio will execute the function with the selected drive letter as input and display the results in the output field.\n• Clear: This button is used to clear the input fields and reset the interface. When you click Clear, Gradio will remove any selected values from the dropdown menu and reset the output field to its default state.\n• Flag: This button is used to flag an example as incorrect or invalid. When you click Flag, Gradio will save the current input and output to a CSV file, along with a timestamp. This feature can be useful for collecting data on examples that need further review or correction.\n\nWhen you click the Flag button, Gradio creates a new directory called if it doesn't already exist, and writes a CSV file inside it. The CSV file contains the following columns:\n• : The input value that was selected when the Flag button was clicked.\n• : The output of the prediction function (in this case, the drive speed test results).\n• : The date and time when the Flag button was clicked.\n\nThe CSV file is named , but if you flag multiple examples, Gradio will create additional files with incrementing numbers (e.g. , , etc.).\n\nHere’s an example of what the CSV file might look like:\n\nYou can use this CSV file to review the flagged examples and make any necessary corrections or updates to your script.\n\nIt’s worth noting that you can customize the behavior of the Flag button or disable it altogether if you don’t need it. However, for many use cases, the default behavior provides a convenient way to collect data on examples that need further review.\n\nIn this article, we’ve seen how Gradio can be used to add a simple yet effective UI to a Python script, making it easier to interact with and share with others. The benefits of using Gradio include:\n• Easy deployment: Gradio allows you to deploy your Python script as a web application with minimal effort.\n• User-friendly interface: Gradio provides a intuitive interface that makes it easy for users to input data and view results.\n• Customization options: Gradio offers a range of customization options, allowing you to tailor the UI to your specific needs.\n\nIf you’re interested in trying out Gradio for yourself, we encourage you to explore its capabilities and see how it can help you to share your Python scripts with others. With its simplicity and flexibility, Gradio is an excellent choice for anyone looking to add a UI to their Python projects.\n\nFor more information on Gradio, including tutorials, documentation, and examples, be sure to check out the following resources:\n• Gradio Documentation: The official Gradio documentation provides a comprehensive guide to getting started with Gradio, including tutorials, API references, and more.\n• Gradio Tutorials: The Gradio tutorials provide step-by-step guides to building your first Gradio app, as well as more advanced topics such as customization and deployment.\n• Gradio GitHub Repository: The Gradio GitHub repository provides access to the latest Gradio code, as well as issue tracking and community support.\n\nBy trying out Gradio and exploring its capabilities, you can unlock new ways to share your Python scripts with others and take your projects to the next level."
    }
]