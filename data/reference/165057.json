[
    {
        "link": "https://stackoverflow.com/questions/67512008/optimize-a-django-query-where-it-uses-prefetch-related-on-a-select-related",
        "document": "I'm trying to figure out how to optimize a Django query. I have an queryset that contains a foreign key to . That table makes references to a number of other tables. If selecting , I'd use to include them in the query, but I can't figure out how to do that in this case, since I'm doing it from a different table. Currently, it's being selected as\n\nBut I can't figure out how to attach to that. Looking at SO, I found a solution that led me to this:\n\nBut it fails with , which I traced through the source, and it looks like can't work with .\n• I'm trying to optimize an admin page with a\n\nThe ultimate goal is to optimize the query from Template through Equipment/Injury"
    },
    {
        "link": "https://medium.com/django-unleashed/optimizing-django-queries-for-performance-best-practices-9a2c1211d2de",
        "document": "As our Django application grows, database performance becomes a critical concern. Inefficient queries can lead to slow response times, high server loads, and a poor user experience. Understanding how to optimize our Django queries can significantly improve your app’s performance and scalability. This article will explore best practices for optimizing Django queries, focusing on tools and techniques that can help you write more efficient code.\n\nBefore diving into optimization techniques, it’s important to understand why query optimization is necessary. Common issues caused by inefficient queries include:\n• Slow Page Loads: Inefficient queries increase the time it takes to fetch data, resulting in slow page loads.\n• High Server Load: Unoptimized queries can load your database unnecessarily, especially under high traffic.\n• Scalability Issues: As your user base grows, inefficient queries can become a bottleneck, limiting your application’s ability to scale.\n\nBy following best practices for query optimization, you can minimize these issues and ensure your application remains fast and responsive.\n\nWhen querying related models, the Django ORM can sometimes execute multiple queries instead of a single optimized query. This is known as the N+1 query problem. Using and can help you avoid this issue.\n• : Used for single-valued relationships (one-to-one or many-to-one). It performs a single SQL join and includes the fields of the related object in the SELECT statement.\n• : Used for multi-valued relationships (many-to-many or reverse foreign key). It performs separate queries and then does the join in Python.\n\nUsing loops to fetch data can lead to multiple queries being executed. Instead, use Django’s ORM methods to filter or annotate querysets.\n\n3. Use `.values()` and `.values_list()` When Necessary\n\nIf you don’t need the entire model instance, use or to fetch only the fields you need. This reduces the amount of data transferred from the database.\n\nThese methods are particularly useful when you need to work with large datasets but only require specific fields.\n\nIndexes improve the speed of data retrieval operations. In Django, you can create indexes in your models using the or options.\n\nIndexes are particularly beneficial for fields that are frequently used in queries with , , or .\n\nFetching large querysets at once can lead to performance issues and high memory usage. Use Django’s built-in pagination to handle large datasets efficiently.\n\nLoading only a subset of the data at a time reduces memory usage and improves performance.\n\n6. Use `defer()` and `only()` for Large Models\n\nIf your model has many fields and you don’t need all of them in a particular query, use or to limit the fields retrieved from the database.\n\nWhen working with large models, these methods can significantly reduce query load time and memory usage.\n\nInstead of fetching data and performing calculations in Python, use Django’s aggregation and annotation methods to perform calculations at the database level.\n\nThis approach reduces the amount of data transferred and utilizes the database’s computational power.\n\nIf your application repeatedly makes the same query, consider using caching to store the results temporarily. Django’s caching framework allows you to store query results and reuse them, reducing database load.\n\nBy caching frequently accessed data, you can dramatically reduce the number of queries your database needs to handle.\n\nDjango supports several database backends (e.g., PostgreSQL, MySQL). Each backend has unique features that can be leveraged for optimization.\n• PostgreSQL-specific optimizations:\n\n — Use for storing lists.\n\n — Use for complex data structures.\n\nBy using these backend-specific features, you can further optimize query performance for your particular database.\n\nOptimizing Django queries is essential for ensuring your application remains fast and responsive as it scales. By using techniques like and , limiting fields with and , and leveraging database indexing and caching, you can significantly improve the performance of your Django applications. Always profile your queries and look for opportunities to optimize, as even small improvements can have a big impact on your application’s overall performance."
    },
    {
        "link": "https://reddit.com/r/django/comments/1d4acps/questioning_the_usage_of_prefetch_related_and",
        "document": "I’ve been working with Django for a while now and something has been bugging me. We often use and to optimize our database queries, especially when dealing with related objects. However, I’m wondering why we have to explicitly specify these optimizations when the information is already present in the serializers.\n\nWhen we define our serializers, we explicitly state which related fields we want to include. Given this, it seems redundant to then also specify or in our views or querysets. Is there no way to automate this process based on the serializer’s information? It feels like there should be a more streamlined way to handle this, reducing the potential for human error and making the code cleaner.\n\nHas anyone else thought about this or found a way to automate these optimizations based on the serializer’s defined fields? Are there any third-party packages or built-in Django features that I might be missing?\n\nLooking forward to hearing your thoughts and any suggestions you might have!"
    },
    {
        "link": "https://stackoverflow.com/questions/22734475/django-proper-use-of-select-related-or-prefetch-related-on-a-foreignkey",
        "document": "I'm trying to figure out how to use or to optimize a query from the other end of a foreign key. For example:\n\nSay I have some models such as the following:\n\nIf I want to print all of the , I have to iterate through all of the products and then, for each product, iterate through all of the product images. However, this produces O(n * m) database queries.\n\nI'm wondering if there is a way to utilize or to reduce this lookup to one or two queries.\n\nAs documented by Django, I can get to work when I select . As you can see, adding the creates a JOIN to the product table.\n\nHowever, how do I accomplish the reverse? For example, how do I query all of the s and have it JOIN on the s? Doing something like the following doesn't seem to work.\n\nIs something like this possible in Django?\n\nThanks for your consideration."
    },
    {
        "link": "https://loadforge.com/guides/the-ultimate-guide-to-django-performance-best-practices-for-scaling-and-optimization",
        "document": "Sometimes it's the small things that make the load testing experience better! We've rolled out an update that lets you..."
    },
    {
        "link": "https://docs.djangoproject.com/en/5.1/ref/models/querysets",
        "document": "This document describes the details of the API. It builds on the material presented in the model and database query guides, so you’ll probably want to read and understand those documents before reading this one.\n\nThroughout this reference we’ll use the example blog models presented in the database query guide.\n\nSince pickle compatibility errors can be difficult to diagnose, such as silently corrupted objects, a RuntimeWarning is raised when you try to unpickle a queryset in a Django version that is different than the one in which it was pickled.\n\nPickles of QuerySets are only valid for the version of Django that was used to generate them. If you generate a pickle using Django version N, there is no guarantee that pickle will be readable with Django version N+1. Pickles should not be used as part of a long-term archival strategy.\n\nIf you recreate QuerySet.values_list() using the pickled query attribute, it will be converted to QuerySet.values() :\n\nThe query attribute is an opaque object. It represents the internals of the query construction and is not part of the public API. However, it is safe (and fully supported) to pickle and unpickle the attribute’s contents as described here.\n\nIf you only want to pickle the necessary information to recreate the QuerySet from the database at a later time, pickle the query attribute of the QuerySet . You can then recreate the original QuerySet (without any results loaded) using some code like this:\n\nIf you pickle a QuerySet , this will force all the results to be loaded into memory prior to pickling. Pickling is usually used as a precursor to caching and when the cached queryset is reloaded, you want the results to already be present and ready for use (reading from the database can take some time, defeating the purpose of caching). This means that when you unpickle a QuerySet , it contains the results at the moment it was pickled, rather than the results that are currently in the database.\n\nNote: If you only want to determine if at least one result exists (and don’t need the actual objects), it’s more efficient to use exists() .\n\n\"There is at least one Entry with the headline Test\"\n\nbool(). Testing a QuerySet in a boolean context, such as using bool() , or , and or an if statement, will cause the query to be executed. If there is at least one result, the QuerySet is True , otherwise False . For example:\n\nlist(). Force evaluation of a QuerySet by calling list() on it. For example:\n\nNote: If you only need to determine the number of records in the set (and don’t need the actual objects), it’s much more efficient to handle a count at the database level using SQL’s SELECT COUNT(*) . Django provides a count() method for precisely this reason.\n\nlen(). A QuerySet is evaluated when you call len() on it. This, as you might expect, returns the length of the result list.\n\nrepr(). A QuerySet is evaluated when you call repr() on it. This is for convenience in the Python interactive interpreter, so you can immediately see your results when using the API interactively.\n\nPickling/Caching. See the following section for details of what is involved when pickling QuerySets . The important thing for the purposes of this section is that the results are read from the database.\n\nAlso note that even though slicing an unevaluated QuerySet returns another unevaluated QuerySet , modifying it further (e.g., adding more filters, or modifying ordering) is not allowed, since that does not translate well into SQL and it would not have a clear meaning either.\n\nSlicing. As explained in Limiting QuerySets , a QuerySet can be sliced, using Python’s array-slicing syntax. Slicing an unevaluated QuerySet usually returns another unevaluated QuerySet , but Django will execute the database query if you use the “step” parameter of slice syntax, and will return a list. Slicing a QuerySet that has been evaluated also returns a list.\n\nBoth synchronous and asynchronous iterators of QuerySets share the same underlying cache.\n\nAsynchronous iteration. A QuerySet can also be iterated over using async for :\n\nNote: Don’t use this if all you want to do is determine if at least one result exists. It’s more efficient to use exists() .\n\nIteration. A QuerySet is iterable, and it executes its database query the first time you iterate over it. For example, this will print the headline of all entries in the database:\n\nYou can evaluate a QuerySet in the following ways:\n\nInternally, a QuerySet can be constructed, filtered, sliced, and generally passed around without actually hitting the database. No database activity actually occurs until you do something to evaluate the queryset.\n\nDjango provides a range of refinement methods that modify either the types of results returned by the or the way its SQL query is executed. These methods do not run database queries, therefore they are safe to run in asynchronous code, and do not have separate asynchronous versions. Returns a new containing objects that match the given lookup parameters. The lookup parameters ( ) should be in the format described in Field lookups below. Multiple parameters are joined via in the underlying SQL statement. If you need to execute more complex queries (for example, queries with statements), you can use ( ). Returns a new containing objects that do not match the given lookup parameters. The lookup parameters ( ) should be in the format described in Field lookups below. Multiple parameters are joined via in the underlying SQL statement, and the whole thing is enclosed in a . This example excludes all entries whose is later than 2005-1-3 AND whose is “Hello”: In SQL terms, that evaluates to: This example excludes all entries whose is later than 2005-1-3 OR whose headline is “Hello”: In SQL terms, that evaluates to: Note the second example is more restrictive. If you need to execute more complex queries (for example, queries with statements), you can use ( ). Annotates each object in the with the provided list of query expressions or objects. Each object can be annotated with:\n• None a reference to a field on the model (or any related models), via ;\n• None a result from an aggregate expression (averages, sums, etc.) computed over the objects that are related to the objects in the . Each argument to is an annotation that will be added to each object in the that is returned. The aggregation functions that are provided by Django are described in Aggregation Functions below. Annotations specified using keyword arguments will use the keyword as the alias for the annotation. Anonymous arguments will have an alias generated for them based upon the name of the aggregate function and the model field that is being aggregated. Only aggregate expressions that reference a single field can be anonymous arguments. Everything else must be a keyword argument. For example, if you were manipulating a list of blogs, you may want to determine how many entries have been made in each blog: # The name of the first blog # The number of entries on the first blog The model doesn’t define an attribute by itself, but by using a keyword argument to specify the aggregate function, you can control the name of the annotation: # The number of entries on the first blog, using the name provided For an in-depth discussion of aggregation, see the topic guide on Aggregation. Same as , but instead of annotating objects in the , saves the expression for later reuse with other methods. This is useful when the result of the expression itself is not needed but it is used for filtering, ordering, or as a part of a complex expression. Not selecting the unused value removes redundant work from the database which should result in better performance. For example, if you want to find blogs with more than 5 entries, but are not interested in the exact number of entries, you could do this: can be used in conjunction with , , , , and . To use aliased expression with other methods (e.g. ), you must promote it to an annotation: and can take expressions directly, but expression construction and usage often does not happen in the same place (for example, method creates expressions, for later use in views). allows building complex expressions incrementally, possibly spanning multiple methods and modules, refer to the expression parts by their aliases and only use for the final result. By default, results returned by a are ordered by the ordering tuple given by the option in the model’s . You can override this on a per- basis by using the method. The result above will be ordered by descending, then by ascending. The negative sign in front of indicates descending order. Ascending order is implied. To order randomly, use , like so: Note: queries may be expensive and slow, depending on the database backend you’re using. To order by a field in a different model, use the same syntax as when you are querying across model relations. That is, the name of the field, followed by a double underscore ( ), followed by the name of the field in the new model, and so on for as many models as you want to join. For example: If you try to order by a field that is a relation to another model, Django will use the default ordering on the related model, or order by the related model’s primary key if there is no specified. For example, since the model has no default ordering specified: If had , then the first queryset would be identical to: You can also order by query expressions by calling or on the expression: and have arguments ( and ) that control how null values are sorted. Be cautious when ordering by fields in related models if you are also using . See the note in for an explanation of how related model ordering can change the expected results. It is permissible to specify a multi-valued field to order the results by (for example, a field, or the reverse relation of a field). Here, there could potentially be multiple ordering data for each ; each with multiple will be returned multiple times into the new that creates. In other words, using on the could return more items than you were working on to begin with - which is probably neither expected nor useful. Thus, take care when using multi-valued field to order the results. If you can be sure that there will only be one ordering piece of data for each of the items you’re ordering, this approach should not present problems. If not, make sure the results are what you expect. There’s no way to specify whether ordering should be case sensitive. With respect to case-sensitivity, Django will order results however your database backend normally orders them. You can order by a field converted to lowercase with which will achieve case-consistent ordering: If you don’t want any ordering to be applied to a query, not even the default ordering, call with no parameters. You can tell if a query is ordered or not by checking the attribute, which will be if the has been ordered in any way. Each call will clear any previous ordering. For example, this query will be ordered by and not : Ordering is not a free operation. Each field you add to the ordering incurs a cost to your database. Each foreign key you add will implicitly include all of its default orderings as well. If a query doesn’t have an ordering specified, results are returned from the database in an unspecified order. A particular ordering is guaranteed only when ordering by a set of fields that uniquely identify each object in the results. For example, if a field isn’t unique, ordering by it won’t guarantee objects with the same name always appear in the same order. Use the method to reverse the order in which a queryset’s elements are returned. Calling a second time restores the ordering back to the normal direction. To retrieve the “last” five items in a queryset, you could do this: Note that this is not quite the same as slicing from the end of a sequence in Python. The above example will return the last item first, then the penultimate item and so on. If we had a Python sequence and looked at , we would see the fifth-last item first. Django doesn’t support that mode of access (slicing from the end), because it’s not possible to do it efficiently in SQL. Also, note that should generally only be called on a which has a defined ordering (e.g., when querying against a model which defines a default ordering, or when using ). If no such ordering is defined for a given , calling on it has no real effect (the ordering was undefined prior to calling , and will remain undefined afterward). Returns a new that uses in its SQL query. This eliminates duplicate rows from the query results. By default, a will not eliminate duplicate rows. In practice, this is rarely a problem, because simple queries such as don’t introduce the possibility of duplicate result rows. However, if your query spans multiple tables, it’s possible to get duplicate results when a is evaluated. That’s when you’d use . Any fields used in an call are included in the SQL columns. This can sometimes lead to unexpected results when used in conjunction with . If you order by fields from a related model, those fields will be added to the selected columns and they may make otherwise duplicate rows appear to be distinct. Since the extra columns don’t appear in the returned results (they are only there to support ordering), it sometimes looks like non-distinct results are being returned. Similarly, if you use a query to restrict the columns selected, the columns used in any (or default model ordering) will still be involved and may affect uniqueness of the results. The moral here is that if you are using be careful about ordering by related models. Similarly, when using and together, be careful when ordering by fields not in the call. On PostgreSQL only, you can pass positional arguments ( ) in order to specify the names of fields to which the should apply. This translates to a SQL query. Here’s the difference. For a normal call, the database compares each field in each row when determining which rows are distinct. For a call with specified field names, the database will only compare the specified field names. When you specify field names, you must provide an in the , and the fields in must start with the fields in , in the same order. For example, gives you the first row for each value in column . If you don’t specify an order, you’ll get some arbitrary row. Examples (those after the first will only work on PostgreSQL): Keep in mind that uses any default related model ordering that has been defined. You might have to explicitly order by the relation or referenced field to make sure the expressions match those at the beginning of the clause. For example, if the model defined an by : …wouldn’t work because the query would be ordered by thus mismatching the expression. You’d have to explicitly order by the relation field ( in this case) or the referenced one ( ) to make sure both expressions match. Returns a that returns dictionaries, rather than model instances, when used as an iterable. Each of those dictionaries represents an object, with the keys corresponding to the attribute names of model objects. This example compares the dictionaries of with the normal model objects: <QuerySet [{'id': 1, 'name': 'Beatles Blog', 'tagline': 'All the latest Beatles news.'}]> The method takes optional positional arguments, , which specify field names to which the should be limited. If you specify the fields, each dictionary will contain only the field keys/values for the fields you specify. If you don’t specify the fields, each dictionary will contain a key and value for every field in the database table. <QuerySet [{'id': 1, 'name': 'Beatles Blog', 'tagline': 'All the latest Beatles news.'}]> The method also takes optional keyword arguments, , which are passed through to : You can use built-in and custom lookups in ordering. For example: An aggregate within a clause is applied before other arguments within the same clause. If you need to group by another value, add it to an earlier clause instead. For example: A few subtleties that are worth mentioning:\n• None If you have a field called that is a , the default call will return a dictionary key called , since this is the name of the hidden model attribute that stores the actual value (the attribute refers to the related model). When you are calling and passing in field names, you can pass in either or and you will get back the same thing (the dictionary key will match the field name you passed in).\n• None When using together with , be aware that ordering can affect the results. See the note in for details.\n• None If you use a clause after an call, any fields defined by a argument in the must be explicitly included in the call. Any call made after a call will have its extra selected fields ignored.\n• None Calling and after doesn’t make sense, so doing so will raise a .\n• None Combining transforms and aggregates requires the use of two calls, either explicitly or as keyword arguments to . As above, if the transform has been registered on the relevant field type the first can be omitted, thus the following examples are equivalent: It is useful when you know you’re only going to need values from a small number of the available fields and you won’t need the functionality of a model instance object. It’s more efficient to select only the fields you need to use. Finally, note that you can call , , etc. after the call, that means that these two calls are identical: The people who made Django prefer to put all the SQL-affecting methods first, followed (optionally) by any output-affecting methods (such as ), but it doesn’t really matter. This is your chance to really flaunt your individualism. You can also refer to fields on related models with reverse relations through , and attributes: <QuerySet [{'name': 'My blog', 'entry__headline': 'An entry'}, {'name': 'My blog', 'entry__headline': 'Another entry'}, ...]> Because attributes and reverse relations can have multiple related rows, including these can have a multiplier effect on the size of your result set. This will be especially pronounced if you include multiple such fields in your query, in which case all possible combinations will be returned. Due to the way the and SQL functions are implemented on SQLite, and lack of the data type, will return , , and instead of , , and strings for key transforms. This is similar to except that instead of returning dictionaries, it returns tuples when iterated over. Each tuple contains the value from the respective field or expression passed into the call — so the first item is the first field, etc. For example: If you only pass in a single field, you can also pass in the parameter. If , this will mean the returned results are single values, rather than 1-tuples. An example should make the difference clearer: It is an error to pass in when there is more than one field. You can pass to get results as a : Using a named tuple may make use of the results more readable, at the expense of a small performance penalty for transforming the results into a named tuple. If you don’t pass any values to , it will return all the fields in the model, in the order they were declared. A common need is to get a specific field value of a certain model instance. To achieve that, use followed by a call: and are both intended as optimizations for a specific use case: retrieving a subset of data without the overhead of creating a model instance. This metaphor falls apart when dealing with many-to-many and other multivalued relations (such as the one-to-many relation of a reverse foreign key) because the “one row, one object” assumption doesn’t hold. For example, notice the behavior when querying across a : ('George Orwell', 'Why Socialists Do Not Believe in Fun'), Authors with multiple entries appear multiple times and authors without any entries have for the entry headline. Similarly, when querying a reverse foreign key, appears for entries not having any author: Due to the way the and SQL functions are implemented on SQLite, and lack of the data type, will return , , and instead of , , and strings for key transforms. Calling will create a queryset that never returns any objects and no query will be executed when accessing the results. A queryset is an instance of . Returns a copy of the current (or subclass). This can be useful in situations where you might want to pass in either a model manager or a and do further filtering on the result. After calling on either object, you’ll definitely have a to work with. When a is evaluated, it typically caches its results. If the data in the database might have changed since a was evaluated, you can get updated results for the same query by calling on a previously evaluated . Uses SQL’s operator to combine the results of two or more s. For example: The operator selects only distinct values by default. To allow duplicate values, use the argument. , , and return model instances of the type of the first even if the arguments are s of other models. Passing different models works as long as the list is the same in all s (at least the types, the names don’t matter as long as the types are in the same order). In such cases, you must use the column names from the first in methods applied to the resulting . For example: In addition, only , , , , and specifying columns (i.e. slicing, , , , and / ) are allowed on the resulting . Further, databases place restrictions on what operations are allowed in the combined queries. For example, most databases don’t allow or in the combined queries. Uses SQL’s operator to return the shared elements of two or more s. For example: See for some restrictions. Uses SQL’s operator to keep only elements present in the but not in some other s. For example: See for some restrictions. Returns a that will “follow” foreign-key relationships, selecting additional related-object data when it executes its query. This is a performance booster which results in a single more complex query but means later use of foreign-key relationships won’t require database queries. The following examples illustrate the difference between plain lookups and lookups. Here’s standard lookup: # Hits the database again to get the related Blog object. # Doesn't hit the database, because e.blog has been prepopulated You can use with any queryset of objects: # Find all the blogs with entries scheduled to be published in the future. # Without select_related(), this would make a database query for each # loop iteration in order to fetch the related blog for each entry. The order of and chaining isn’t important. These querysets are equivalent: You can follow foreign keys in a similar way to querying them. If you have the following models: … then a call to will cache the related and the related : # Hits the database with joins to the author and hometown tables. You can refer to any or relation in the list of fields passed to . You can also refer to the reverse direction of a in the list of fields passed to — that is, you can traverse a back to the object on which the field is defined. Instead of specifying the field name, use the for the field on the related object. There may be some situations where you wish to call with a lot of related objects, or where you don’t know all of the relations. In these cases it is possible to call with no arguments. This will follow all non-null foreign keys it can find - nullable foreign keys must be specified. This is not recommended in most cases as it is likely to make the underlying query more complex, and return more data, than is actually needed. If you need to clear the list of related fields added by past calls of on a , you can pass as a parameter: Chaining calls works in a similar way to other methods - that is that is equivalent to . Returns a that will automatically retrieve, in a single batch, related objects for each of the specified lookups. This has a similar purpose to , in that both are designed to stop the deluge of database queries that is caused by accessing related objects, but the strategy is quite different. works by creating an SQL join and including the fields of the related object in the statement. For this reason, gets the related objects in the same database query. However, to avoid the much larger result set that would result from joining across a ‘many’ relationship, is limited to single-valued relationships - foreign key and one-to-one. , on the other hand, does a separate lookup for each relationship, and does the ‘joining’ in Python. This allows it to prefetch many-to-many, many-to-one, and objects which cannot be done using , in addition to the foreign key and one-to-one relationships that are supported by . It also supports prefetching of , however, the queryset for each must be provided in the parameter of . Support for prefetching with non-homogeneous set of results was added. For example, suppose you have these models: The problem with this is that every time asks for it has to query the database, so will run a query on the Toppings table for every item in the Pizza . We can reduce to just two queries using : This implies a for each ; now each time is called, instead of having to go to the database for the items, it will find them in a prefetched cache that was populated in a single query. That is, all the relevant toppings will have been fetched in a single query, and used to make that have a pre-filled cache of the relevant results; these are then used in the calls. The additional queries in are executed after the has begun to be evaluated and the primary query has been executed. Note that there is no mechanism to prevent another database query from altering the items in between the execution of the primary query and the additional queries, which could produce an inconsistent result. For example, if a is deleted after the primary query has executed, its toppings will not be returned in the additional query, and it will seem like the pizza has no toppings: # \"Hawaiian\" Pizza was deleted in another shell. If you have an iterable of model instances, you can prefetch related attributes on those instances using the function. Note that the result cache of the primary and all specified related objects will then be fully loaded into memory. This changes the typical behavior of , which normally try to avoid loading all objects into memory before they are needed, even after a query has been executed in the database. Remember that, as always with , any subsequent chained methods which imply a different database query will ignore previously cached results, and retrieve data using a fresh database query. So, if you write the following: …then the fact that has been prefetched will not help you. The implied , but is a new and different query. The prefetched cache can’t help here; in fact it hurts performance, since you have done a database query that you haven’t used. So use this feature with caution! Also, if you call the database-altering methods , , , or , on , any prefetched cache for the relation will be cleared. You can also use the normal join syntax to do related fields of related fields. Suppose we have an additional model to the example above: The following are all legal: This will prefetch all pizzas belonging to restaurants, and all toppings belonging to those pizzas. This will result in a total of 3 database queries - one for the restaurants, one for the pizzas, and one for the toppings. This will fetch the best pizza and all the toppings for the best pizza for each restaurant. This will be done in 3 database queries - one for the restaurants, one for the ‘best pizzas’, and one for the toppings. The relationship could also be fetched using to reduce the query count to 2: Since the prefetch is executed after the main query (which includes the joins needed by ), it is able to detect that the objects have already been fetched, and it will skip fetching them again. Chaining calls will accumulate the lookups that are prefetched. To clear any behavior, pass as a parameter: One difference to note when using is that objects created by a query can be shared between the different objects that they are related to i.e. a single Python model instance can appear at more than one point in the tree of objects that are returned. This will normally happen with foreign key relationships. Typically this behavior will not be a problem, and will in fact save both memory and CPU time. While supports prefetching relationships, the number of queries will depend on the data. Since a can reference data in multiple tables, one query per table referenced is needed, rather than one query for all the items. There could be additional queries on the table if the relevant rows have not already been fetched. in most cases will be implemented using an SQL query that uses the ‘IN’ operator. This means that for a large a large ‘IN’ clause could be generated, which, depending on the database, might have performance problems of its own when it comes to parsing or executing the SQL query. Always profile for your use case! If you use to run the query, calls will only be observed if a value for is provided. You can use the object to further control the prefetch operation. In its simplest form is equivalent to the traditional string based lookups: You can provide a custom queryset with the optional argument. This can be used to change the default ordering of the queryset: Or to call when applicable to reduce the number of queries even further: You can also assign the prefetched result to a custom attribute with the optional argument. The result will be stored directly in a list. This allows prefetching the same relation multiple times with a different ; for instance: Lookups created with custom can still be traversed as usual by other lookups: Using is recommended when filtering down the prefetch result as it is less ambiguous than storing a filtered result in the related manager’s cache: Custom prefetching also works with single related relations like forward or . Generally you’ll want to use for these relations, but there are a number of cases where prefetching with a custom is useful:\n• None You want to use a that performs further prefetching on related models.\n• None You want to prefetch only a subset of the related objects.\n• None You want to use performance optimization techniques like : When using multiple databases, will respect your choice of database. If the inner query does not specify a database, it will use the database selected by the outer query. All of the following are valid: # Both inner and outer queries will use the 'replica' database # Inner will use the 'replica' database; outer will use 'default' database # Inner will use 'replica' database; outer will use 'cold-storage' database Take the following examples: This works even though it’s unordered because already contains all the needed information, therefore the second argument is actually redundant. This will raise a because of the attempt to redefine the queryset of a previously seen lookup. Note that an implicit queryset was created to traverse as part of the lookup. This will trigger an because doesn’t exist yet when is being processed. This consideration is not limited to the use of objects. Some advanced techniques may require that the lookups be performed in a specific order to avoid creating extra queries; therefore it’s recommended to always carefully order arguments. Sometimes, the Django query syntax by itself can’t easily express a complex clause. For these edge cases, Django provides the modifier — a hook for injecting specific clauses into the SQL generated by a . Use this method as a last resort This is an old API that we aim to deprecate at some point in the future. Use it only if you cannot express your query using other queryset methods. If you do need to use it, please file a ticket using the QuerySet.extra keyword with your use case (please check the list of existing tickets first) so that we can enhance the QuerySet API to allow removing . We are no longer improving or fixing bugs for this method. For example, this use of : The main benefit of using is that you can set if needed. The main downside is that if you refer to some table alias of the queryset in the raw SQL, then it is possible that Django might change that alias (for example, when the queryset is used as a subquery in yet another query). You should be very careful whenever you use . Every time you use it, you should escape any parameters that the user can control by using in order to protect against SQL injection attacks. You also must not quote placeholders in the SQL string. This example is vulnerable to SQL injection because of the quotes around : You can read more about how Django’s SQL injection protection works. By definition, these extra lookups may not be portable to different database engines (because you’re explicitly writing SQL code) and violate the DRY principle, so you should avoid them if possible. Specify one or more of , , or . None of the arguments is required, but you should use at least one of them.\n• The argument lets you put extra fields in the clause. It should be a dictionary mapping attribute names to SQL clauses to use to calculate that attribute. As a result, each object will have an extra attribute, , a boolean representing whether the entry’s is greater than Jan. 1, 2006. Django inserts the given SQL snippet directly into the statement, so the resulting SQL of the above example would be something like: The next example is more advanced; it does a subquery to give each resulting object an attribute, an integer count of associated objects: In this particular case, we’re exploiting the fact that the query will already contain the table in its clause. The resulting SQL of the above example would be: Note that the parentheses required by most database engines around subqueries are not required in Django’s clauses. In some rare cases, you might wish to pass parameters to the SQL fragments in . For this purpose, use the parameter. This will work, for example: If you need to use a literal inside your select string, use the sequence .\n• You can define explicit SQL clauses — perhaps to perform non-explicit joins — by using . You can manually add tables to the SQL clause by using . and both take a list of strings. All parameters are “AND”ed to any other search criteria. …translates (roughly) into the following SQL: Be careful when using the parameter if you’re specifying tables that are already used in the query. When you add extra tables via the parameter, Django assumes you want that table included an extra time, if it is already included. That creates a problem, since the table name will then be given an alias. If a table appears multiple times in an SQL statement, the second and subsequent occurrences must use aliases so the database can tell them apart. If you’re referring to the extra table you added in the extra parameter this is going to cause errors. Normally you’ll only be adding extra tables that don’t already appear in the query. However, if the case outlined above does occur, there are a few solutions. First, see if you can get by without including the extra table and use the one already in the query. If that isn’t possible, put your call at the front of the queryset construction so that your table is the first use of that table. Finally, if all else fails, look at the query produced and rewrite your addition to use the alias given to your extra table. The alias will be the same each time you construct the queryset in the same way, so you can rely upon the alias name to not change.\n• If you need to order the resulting queryset using some of the new fields or tables you have included via use the parameter to and pass in a sequence of strings. These strings should either be model fields (as in the normal method on querysets), of the form or an alias for a column that you specified in the parameter to . This would sort all the items for which is true to the front of the result set ( sorts before in a descending ordering). This shows, by the way, that you can make multiple calls to and it will behave as you expect (adding new constraints each time).\n• The parameter described above may use standard Python database string placeholders — to indicate parameters the database engine should automatically quote. The argument is a list of any extra parameters to be substituted. Always use instead of embedding values directly into because will ensure values are quoted correctly according to your particular backend. For example, quotes will be escaped correctly. If you are performing queries on MySQL, note that MySQL’s silent type coercion may cause unexpected results when mixing types. If you query on a string type column, but with an integer value, MySQL will coerce the types of all values in the table to an integer before performing the comparison. For example, if your table contains the values , and you query for , both rows will match. To prevent this, perform the correct typecasting before using the value in a query. In some complex data-modeling situations, your models might contain a lot of fields, some of which could contain a lot of data (for example, text fields), or require expensive processing to convert them to Python objects. If you are using the results of a queryset in some situation where you don’t know if you need those particular fields when you initially fetch the data, you can tell Django not to retrieve them from the database. This is done by passing the names of the fields to not load to : A queryset that has deferred fields will still return model instances. Each deferred field will be retrieved from the database if you access that field (one at a time, not all the deferred fields at once). Deferred fields will not lazy-load like this from asynchronous code. Instead, you will get a exception. If you are writing asynchronous code, you should not try to access any fields that you . You can make multiple calls to . Each call adds new fields to the deferred set: # Defers both the body and headline fields. The order in which fields are added to the deferred set does not matter. Calling with a field name that has already been deferred is harmless (the field will still be deferred). You can defer loading of fields in related models (if the related models are loading via ) by using the standard double-underscore notation to separate related fields: If you want to clear the set of deferred fields, pass as a parameter to : Some fields in a model won’t be deferred, even if you ask for them. You can never defer the loading of the primary key. If you are using to retrieve related models, you shouldn’t defer the loading of the field that connects from the primary model to the related one, doing so will result in an error. Similarly, calling (or its counterpart ) including an argument from an aggregation (e.g. using the result of ) doesn’t make sense: doing so will raise an exception. The aggregated values will always be fetched into the resulting queryset. The method (and its cousin, , below) are only for advanced use-cases. They provide an optimization for when you have analyzed your queries closely and understand exactly what information you need and have measured that the difference between returning the fields you need and the full set of fields for the model will be significant. Even if you think you are in the advanced use-case situation, only use when you cannot, at queryset load time, determine if you will need the extra fields or not. If you are frequently loading and using a particular subset of your data, the best choice you can make is to normalize your models and put the non-loaded data into a separate model (and database table). If the columns must stay in the one table for some reason, create a model with (see the documentation) containing just the fields you normally need to load and use that where you might otherwise call . This makes your code more explicit to the reader, is slightly faster and consumes a little less memory in the Python process. For example, both of these models use the same underlying database table: If many fields need to be duplicated in the unmanaged model, it may be best to create an abstract model with the shared fields and then have the unmanaged and managed models inherit from the abstract model. When calling for instances with deferred fields, only the loaded fields will be saved. See for more details. The method is essentially the opposite of . Only the fields passed into this method and that are not already specified as deferred are loaded immediately when the queryset is evaluated. If you have a model where almost all the fields need to be deferred, using to specify the complementary set of fields can result in simpler code. Suppose you have a model with fields , and . The following two querysets are the same, in terms of deferred fields: Whenever you call it replaces the set of fields to load immediately. The method’s name is mnemonic: only those fields are loaded immediately; the remainder are deferred. Thus, successive calls to result in only the final fields being considered: # This will defer all fields except the headline. Since acts incrementally (adding fields to the deferred list), you can combine calls to and and things will behave logically: # Final result is that everything except \"headline\" is deferred. All of the cautions in the note for the documentation apply to as well. Use it cautiously and only after exhausting your other options. Using and omitting a field requested using is an error as well. On the other hand, invoking without any arguments, will return every field (including annotations) fetched by the queryset. As with , you cannot access the non-loaded fields from asynchronous code and expect them to load. Instead, you will get a exception. Ensure that all fields you might access are in your call. When calling for instances with deferred fields, only the loaded fields will be saved. See for more details. When using after the fields in will override for fields that are listed in both. This method is for controlling which database the will be evaluated against if you are using more than one database. The only argument this method takes is the alias of a database, as defined in . # queries the database with the 'default' alias. # queries the database with the 'backup' alias Takes a raw SQL query, executes it, and returns a instance. This instance can be iterated over just like a normal to provide object instances. See the Performing raw SQL queries for more information. always triggers a new query and doesn’t account for previous filtering. As such, it should generally be called from the or from a fresh instance.\n\nMethods that do not return s¶ The following methods evaluate the and return something other than a . These methods do not use a cache (see Caching and QuerySets). Rather, they query the database each time they’re called. Because these methods evaluate the QuerySet, they are blocking calls, and so their main (synchronous) versions cannot be called from asynchronous code. For this reason, each has a corresponding asynchronous version with an prefix - for example, rather than you can . There is usually no difference in behavior apart from their asynchronous nature, but any differences are noted below next to each method. Returns the object matching the given lookup parameters, which should be in the format described in Field lookups. You should use lookups that are guaranteed unique, such as the primary key or fields in a unique constraint. For example: If you expect a queryset to already return one row, you can use without any arguments to return the object for that row: If doesn’t find any object, it raises a exception: If finds more than one object, it raises a exception: Both these exception classes are attributes of the model class, and specific to that model. If you want to handle such exceptions from several calls for different models, you can use their generic base classes. For example, you can use to handle exceptions from multiple models: \"Either the blog or entry doesn't exist.\" A convenience method for creating an object and saving it all in one step. Thus: The force_insert parameter is documented elsewhere, but all it means is that a new object will always be created. Normally you won’t need to worry about this. However, if your model contains a manual primary key value that you set and if that value already exists in the database, a call to will fail with an since primary keys must be unique. Be prepared to handle the exception if you are using manual primary keys. A convenience method for looking up an object with the given (may be empty if your model has defaults for all fields), creating one if necessary. Returns a tuple of , where is the retrieved or created object and is a boolean specifying whether a new object was created. This is meant to prevent duplicate objects from being created when requests are made in parallel, and as a shortcut to boilerplatish code. For example: Here, with concurrent requests, multiple attempts to save a with the same parameters may be made. To avoid this race condition, the above example can be rewritten using like so: Any keyword arguments passed to — except an optional one called — will be used in a call. If an object is found, returns a tuple of that object and . This method is atomic assuming that the database enforces uniqueness of the keyword arguments (see or ). If the fields used in the keyword arguments do not have a uniqueness constraint, concurrent calls to this method may result in multiple rows with the same parameters being inserted. You can specify more complex conditions for the retrieved object by chaining with and using . For example, to retrieve Robert or Bob Marley if either exists, and create the latter otherwise: If multiple objects are found, raises . If an object is not found, will instantiate and save a new object, returning a tuple of the new object and . The new object will be created roughly according to this algorithm: In English, that means start with any non- keyword argument that doesn’t contain a double underscore (which would indicate a non-exact lookup). Then add the contents of , overriding any keys if necessary, and use the result as the keyword arguments to the model class. If there are any callables in , evaluate them. As hinted at above, this is a simplification of the algorithm that is used, but it contains all the pertinent details. The internal implementation has some more error-checking than this and handles some extra edge-conditions; if you’re interested, read the code. If you have a field named and want to use it as an exact lookup in , use , like so: The method has similar error behavior to when you’re using manually specified primary keys. If an object needs to be created and the key already exists in the database, an will be raised. Finally, a word on using in Django views. Please make sure to use it only in requests unless you have a good reason not to. requests shouldn’t have any effect on data. Instead, use whenever a request to a page has a side effect on your data. For more, see Safe methods in the HTTP spec. You can use through attributes and reverse relations. In that case you will restrict the queries inside the context of that relation. That could lead you to some integrity problems if you don’t use it consistently. Being the following models: You can use through Book’s chapters field, but it only fetches inside the context of that book: This is happening because it’s trying to get or create “Chapter 1” through the book “Ulysses”, but it can’t do either: the relation can’t fetch that chapter because it isn’t related to that book, but it can’t create it either because field should be unique. This method inserts the provided list of objects into the database in an efficient manner (generally only 1 query, no matter how many objects there are), and returns created objects as a list, in the same order as provided: This has a number of caveats though:\n• None The model’s method will not be called, and the and signals will not be sent.\n• None It does not work with child models in a multi-table inheritance scenario.\n• None If the model’s primary key is an and is False, the primary key attribute can only be retrieved on certain databases (currently PostgreSQL, MariaDB, and SQLite 3.35+). On other databases, it will not be set.\n• None It does not work with many-to-many relationships.\n• None It casts to a list, which fully evaluates if it’s a generator. The cast allows inspecting all objects so that any objects with a manually set primary key can be inserted first. If you want to insert objects in batches without evaluating the entire generator at once, you can use this technique as long as the objects don’t have any manually set primary keys: The parameter controls how many objects are created in a single query. The default is to create all objects in one batch, except for SQLite where the default is such that at most 999 variables per query are used. On databases that support it (all but Oracle), setting the parameter to tells the database to ignore failure to insert any rows that fail constraints such as duplicate unique values. On databases that support it (all except Oracle), setting the parameter to , tells the database to update when a row insertion fails on conflicts. On PostgreSQL and SQLite, in addition to , a list of that may be in conflict must be provided. Enabling the parameter disables setting the primary key on each model instance (if the database normally supports it). In older versions, enabling the parameter prevented setting the primary key on each model instance. On MySQL and MariaDB, setting the parameter to turns certain types of errors, other than duplicate key, into warnings. Even with Strict Mode. For example: invalid values or non-nullable violations. See the MySQL documentation and MariaDB documentation for more details. Returns an integer representing the number of objects in the database matching the . # Returns the total number of entries in the database. # Returns the number of entries whose headline contains 'Lennon' A call performs a behind the scenes, so you should always use rather than loading all of the record into Python objects and calling on the result (unless you need to load the objects into memory anyway, in which case will be faster). Note that if you want the number of items in a and are also retrieving model instances from it (for example, by iterating over it), it’s probably more efficient to use which won’t cause an extra database query like would. If the queryset has already been fully retrieved, will use that length rather than perform an extra database query. Takes a list of field values ( ) and the for those values, and returns a dictionary mapping each value to an instance of the object with the given field value. No exceptions will ever be raised by ; that is, any value not matching any instance will simply be ignored. If isn’t provided, all objects in the queryset are returned. must be a unique field or a distinct field (if there’s only one field specified in ). defaults to the primary key. If you pass an empty list, you’ll get an empty dictionary. Evaluates the (by performing the query) and returns an iterator (see PEP 234) over the results, or an asynchronous iterator (see PEP 492) if you call its asynchronous version . A typically caches its results internally so that repeated evaluations do not result in additional queries. In contrast, will read results directly, without doing any caching at the level (internally, the default iterator calls and caches the return value). For a which returns a large number of objects that you only need to access once, this can result in better performance and a significant reduction in memory. Note that using on a which has already been evaluated will force it to evaluate again, repeating the query. is compatible with previous calls to as long as is given. Larger values will necessitate fewer queries to accomplish the prefetching at the cost of greater memory usage. Support for with previous calls to was added. On some databases (e.g. Oracle, SQLite), the maximum number of terms in an SQL clause might be limited. Hence values below this limit should be used. (In particular, when prefetching across two or more relations, a should be small enough that the anticipated number of results for each prefetched relation still falls below the limit.) So long as the QuerySet does not prefetch any related objects, providing no value for will result in Django using an implicit default of 2000. Depending on the database backend, query results will either be loaded all at once or streamed from the database using server-side cursors. Oracle and PostgreSQL use server-side cursors to stream results from the database without loading the entire result set into memory. The Oracle database driver always uses server-side cursors. With server-side cursors, the parameter specifies the number of results to cache at the database driver level. Fetching bigger chunks diminishes the number of round trips between the database driver and the database, at the expense of memory. On PostgreSQL, server-side cursors will only be used when the setting is . Read Transaction pooling and server-side cursors if you’re using a connection pooler configured in transaction pooling mode. When server-side cursors are disabled, the behavior is the same as databases that don’t support server-side cursors. MySQL doesn’t support streaming results, hence the Python database driver loads the entire result set into memory. The result set is then transformed into Python row objects by the database adapter using the method defined in PEP 249. SQLite can fetch results in batches using , but since SQLite doesn’t provide isolation between queries within a connection, be careful when writing to the table being iterated over. See Isolation when using QuerySet.iterator() for more information. The parameter controls the size of batches Django retrieves from the database driver. Larger batches decrease the overhead of communicating with the database driver at the expense of a slight increase in memory consumption. So long as the QuerySet does not prefetch any related objects, providing no value for will result in Django using an implicit default of 2000, a value derived from a calculation on the psycopg mailing list: Assuming rows of 10-20 columns with a mix of textual and numeric data, 2000 is going to fetch less than 100KB of data, which seems a good compromise between the number of rows transferred and the data discarded if the loop is exited early. Returns the latest object in the table based on the given field(s). This example returns the latest in the table, according to the field: You can also choose the latest based on several fields. For example, to select the with the earliest when two entries have the same : The negative sign in means to sort in descending order. Since gets the last result, the with the earliest is selected. If your model’s Meta specifies , you can omit any arguments to or . The fields specified in will be used by default. Like , and raise if there is no object with the given parameters. Note that and exist purely for convenience and readability. Works otherwise like except the direction is changed. Returns the first object matched by the queryset, or if there is no matching object. If the has no ordering defined, then the queryset is automatically ordered by the primary key. This can affect aggregation results as described in Interaction with order_by(). Note that is a convenience method, the following code sample is equivalent to the above example: Works like , but returns the last object in the queryset. Returns a dictionary of aggregate values (averages, sums, etc.) calculated over the . Each argument to specifies a value that will be included in the dictionary that is returned. The aggregation functions that are provided by Django are described in Aggregation Functions below. Since aggregates are also query expressions, you may combine aggregates with other aggregates or values to create complex aggregates. Aggregates specified using keyword arguments will use the keyword as the name for the annotation. Anonymous arguments will have a name generated for them based upon the name of the aggregate function and the model field that is being aggregated. Complex aggregates cannot use anonymous arguments and must specify a keyword argument as an alias. For example, when you are working with blog entries, you may want to know the number of authors that have contributed blog entries: By using a keyword argument to specify the aggregate function, you can control the name of the aggregation value that is returned: For an in-depth discussion of aggregation, see the topic guide on Aggregation. Returns if the contains any results, and if not. This tries to perform the query in the simplest and fastest way possible, but it does execute nearly the same query as a normal query. is useful for searches relating to the existence of any objects in a , particularly in the context of a large . To find whether a queryset contains any items: \"There is at least one object in some_queryset\" Which will be faster than: \"There is at least one object in some_queryset\" … but not by a large degree (hence needing a large queryset for efficiency gains). Additionally, if a has not yet been evaluated, but you know that it will be at some point, then using will do more overall work (one query for the existence check plus an extra one to later retrieve the results) than using , which retrieves the results and then checks if any were returned. Returns if the contains , and if not. This tries to perform the query in the simplest and fastest way possible. is useful for checking an object membership in a , particularly in the context of a large . To check whether a queryset contains a specific item: This will be faster than the following which requires evaluating and iterating through the entire queryset: Like , if has not yet been evaluated, but you know that it will be at some point, then using will make an additional database query, generally resulting in slower overall performance. Performs an SQL delete query on all rows in the and returns the number of objects deleted and a dictionary with the number of deletions per object type. The is applied instantly. You cannot call on a that has had a slice taken or can otherwise no longer be filtered. For example, to delete all the entries in a particular blog: # Delete all the entries belonging to this Blog. By default, Django’s emulates the SQL constraint — in other words, any objects with foreign keys pointing at the objects to be deleted will be deleted along with them. For example: # This will delete all Blogs and all of their Entry objects. This cascade behavior is customizable via the argument to the . The method does a bulk delete and does not call any methods on your models. It does, however, emit the and signals for all deleted objects (including cascaded deletions). Django needs to fetch objects into memory to send signals and handle cascades. However, if there are no cascades and no signals, then Django may take a fast-path and delete objects without fetching into memory. For large deletes this can result in significantly reduced memory usage. The amount of executed queries can be reduced, too. ForeignKeys which are set to do not prevent taking the fast-path in deletion. Note that the queries generated in object deletion is an implementation detail subject to change. Class method that returns an instance of with a copy of the ’s methods. See Creating a manager with QuerySet methods for more details. Note that unlike the other entries in this section, this does not have an asynchronous variant as it does not execute a query. Returns a string of the ’s execution plan, which details how the database would execute the query, including any indexes or joins that would be used. Knowing these details may help you improve the performance of slow queries. For example, when using PostgreSQL: is supported by all built-in database backends except Oracle because an implementation there isn’t straightforward. The parameter changes the output format from the databases’s default, which is usually text-based. PostgreSQL supports , , , and formats. MariaDB and MySQL support (also called ) and formats. MySQL 8.0.16+ also supports an improved format, which is similar to PostgreSQL’s output and is used by default, if supported. Some databases accept flags that can return more information about the query. Pass these flags as keyword arguments. For example, when using PostgreSQL: On some databases, flags may cause the query to be executed which could have adverse effects on your database. For example, the flag supported by MariaDB, MySQL 8.0.18+, and PostgreSQL could result in changes to data if there are triggers or if a function is called, even for a query. Support for the option on PostgreSQL 16+ was added."
    },
    {
        "link": "https://geeksforgeeks.org/prefetch_related-and-select_related-functions-in-django",
        "document": "In Django, select_related and prefetch_related are designed to stop the deluge of database queries that are caused by accessing related objects. In this article, we will see how it reduces the number of queries and make the program much faster.\n• select_related() “follows” foreign-key relationships, selecting additional related-object data when it executes its query.\n• prefetch_related() does a separate lookup for each relationship and does the “joining” in Python.\n\nOne uses select_related when the object that you’re going to be selecting is a single object, so OneToOneField or a ForeignKey. You use prefetch_related when you’re going to get a “set” of things, so ManyToManyFields as you stated or reverse ForeignKeys. Just to clarify what I mean by “reverse ForeignKeys”.\n\nExample to illustrate the concept of Prefetch_related and select_related –\n\nThe above classification might be not so clear let’s see an example:\n\nselect_related obtains all data at one time through multi-table join Association query and improves performance by reducing the number of database queries. It uses JOIN statements of SQL to optimize and improve performance by reducing the number of SQL queries. The latter is to solve the problem in the SQL query through a JOIN statement. However, for many-to-many relationships, it is not wise to use SQL statements to solve them, because the tables obtained by JOIN will be very long, which will lead to an increase in running time and memory occupation of SQL statements. The solution to prefetch_related() is to query each table separately and then use Python to handle their relationship!\n\nHere are some examples :\n\nwe use the select_related() function:\n\nThere is only one SQL query, which obviously greatly reduces the number of SQL queries:\n\nHere we can see that Django uses INNER JOIN. I would like to clear one thing that Optimize is a name of our app. If we want to get all the city names of Hubei, we can do this:\n\nAs we can see, prefetch is implemented using the IN statement. In this way, when there are too many objects in QuerySet, performance problems may arise depending on the characteristics of the database."
    },
    {
        "link": "https://docs.djangoproject.com/en/5.1/ref/models/relations",
        "document": "A “related manager” is a manager used in a one-to-many or many-to-many related context. This happens in two cases:\n• None The “other side” of a relation. That is: In the above example, the methods below will be available on the manager .\n• In this example, the methods below will be available both on and on .\n\nAdds the specified model objects to the related object set. In the example above, in the case of a relationship, is used to perform the update. This requires the objects to already be saved. You can use the argument to instead have the related manager perform the update by calling . Using with a many-to-many relationship, however, will not call any methods (the argument doesn’t exist), but rather create the relationships using . If you need to execute some custom logic when a relationship is created, listen to the signal, which will trigger and actions. Using on a relation that already exists won’t duplicate the relation, but it will still trigger signals. For many-to-many relationships accepts either model instances or field values, normally primary keys, as the argument. Use the argument to specify values for the new intermediate model instance(s), if needed. You can use callables as values in the dictionary and they will be evaluated once before creating any intermediate instance(s).\n\nCreates a new object, saves it and puts it in the related object set. Returns the newly created object: # No need to call e.save() at this point -- it's already been saved. This is equivalent to (but simpler than): Note that there’s no need to specify the keyword argument of the model that defines the relationship. In the above example, we don’t pass the parameter to . Django figures out that the new object’s field should be set to . Use the argument to specify values for the new intermediate model instance, if needed. You can use callables as values in the dictionary.\n\nRemoves the specified model objects from the related object set: Similar to , is called in the example above to perform the update. Using with a many-to-many relationship, however, will delete the relationships using which means no model methods are called; listen to the signal if you wish to execute custom code when a relationship is deleted. For many-to-many relationships accepts either model instances or field values, normally primary keys, as the argument. For objects, this method only exists if . If the related field can’t be set to ( ), then an object can’t be removed from a relation without being added to another. In the above example, removing from is equivalent to doing , and because the doesn’t have , this is invalid. For objects, this method accepts a argument to control how to perform the operation. If (the default), is used. If , the method of each individual model instance is called instead. This triggers the and signals and comes at the expense of performance.\n\nThis method accepts a argument to control how to perform the operation. If (the default), the elements missing from the new set are removed using and only the new ones are added. If , the method is called instead and the whole set is added at once. For objects, the argument is passed on to and . Note that since is a compound operation, it is subject to race conditions. For instance, new objects may be added to the database in between the call to and the call to . For many-to-many relationships accepts a list of either model instances or field values, normally primary keys, as the argument. Use the argument to specify values for the new intermediate model instance(s), if needed. You can use callables as values in the dictionary and they will be evaluated once before creating any intermediate instance(s)."
    },
    {
        "link": "https://medium.com/django-unleashed/optimizing-django-queries-with-prefetch-related-480506870b01",
        "document": "When working with related models in Django, efficient querying is crucial for performance. and are commonly used methods to optimize database access.\n\nThis article focuses on and how to use it effectively in your Django applications.\n\nreturns a QuerySet that retrieves related objects for the specified lookups in a single batch.\n\nUnlike , which performs an SQL join and includes related fields in the same query, performs separate lookups for each relationship and \"joins\" the results in Python.\n\nThis method allows prefetching of various relationship types, including:\n\nConsider the following models for a pizza shop:"
    },
    {
        "link": "https://stackoverflow.com/questions/69955018/using-prefetch-related-and-aggregations-to-avoid-n1-issue-with-django-database",
        "document": "I am trying to avoid an obscene amount of database queries in a Django app. In the app I am monotoring a number of suggestions (model: Suggestion) that can be voted for (model: Vote).\n\nThe Vote model does not store each individual vote. Instead the total number of votes for a suggestion are stored at regular intervals. A suggestion of \"Better ice cream\" could have \"10 votes at 8:10\", \"12 votes at 8:20\", \"25 votes at 8:30\", etc.\n\nI have created a very ineffecient loop with some major n+1 issues to calculate the number of new votes per day per suggestion.\n\nI am looking for a more efficient (probably single) queryset than the current ones for the same functionality. I know that I should probably create some kind of annotation by dates of votes on \"suggestions\" in views.py and then annotate that by my aggregate function that calculates the number of votes on each day, but I cannot figure out how to actually chain this together.\n\nHere's my current working but very inefficient code:"
    }
]