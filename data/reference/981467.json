[
    {
        "link": "https://geeksforgeeks.org/handling-large-datasets-in-python",
        "document": "Handling large datasets is a common task in data analysis and modification. When working with large datasets, it's important to use efficient techniques and tools to ensure optimal performance and avoid memory issues. In this article, we will see how we can handle large datasets in Python.\n\nTo handle large datasets in Python, we can use the below techniques:\n\nBy default, Pandas assigns data types that may not be memory-efficient. For numeric columns, consider downcasting to smaller types (e.g., int32 instead of int64, float32 instead of float64). For example, if a column holds values like 0, 1, 2, 3, 4, 5, 6, 7, 8, or 9, using int8 (8 bits) instead of int64 (64 bits) is sufficient. Similarly, converting object data types to categories can also save memory.\n\nUse the chunksize parameter in pd.read_csv() to read the dataset in smaller chunks. Process each chunk iteratively to avoid loading the entire dataset into memory at once.\n\nDask is a parallel computing library that allows us to scale Pandas workflows to larger-than-memory datasets. Leverage parallel processing for efficient handling of big data.\n\nIn conclusion, handling large datasets in Python involves using streaming techniques, lazy evaluation, parallel processing, and data compression to optimize performance and memory usage. These steps helps to efficiently process and analyze large datasets for data analysis and modification."
    },
    {
        "link": "https://stackoverflow.com/questions/76318762/effective-approaches-for-optimizing-performance-with-large-datasets-in-python",
        "document": "I am currently working on a project that involves processing large datasets in Python. While I have managed to make it work, I am facing performance and efficiency challenges, especially when dealing with massive amounts of data.\n\nTo provide more context, let's assume I have a dataset with millions of records, and I need to perform complex computations or data transformations on it. Currently, my code takes a significant amount of time to process the data, and it seems to consume a considerable amount of memory, leading to potential memory errors or slowdowns.\n\nHere's a simplified example of my code structure:\n\nI would like to optimize my code and improve its efficiency when handling large datasets. Specifically, I am seeking advice on the following areas:\n\nMemory Management: What are the best practices for reducing memory usage when working with large datasets? Are there any techniques to minimize the memory footprint during data loading, processing, or storage?\n\nSpeeding up Processing: How can I accelerate the data processing tasks to improve overall performance? Are there any optimized functions or algorithms available that can handle large datasets more efficiently?\n\nAvoiding Bottlenecks: What are the common bottlenecks or performance limitations when working with large datasets in Python? Are there any specific areas of my code that could be potential bottlenecks, and how can I address them?\n\nI am open to leveraging popular libraries like pandas, NumPy, Dask, or any other relevant tools. Additionally, I am willing to explore alternative code structures, parallel processing techniques, or any other strategies that can significantly enhance the performance and efficiency of handling large datasets in Python.\n\nI would greatly appreciate any advice, suggestions, code examples, or references to relevant resources that can help me overcome these challenges and optimize my code for efficient large-scale data processing.\n\nThank you so much for your valuable assistance!"
    },
    {
        "link": "https://medium.com/@tubelwj/several-methods-for-efficiently-handling-large-datasets-in-pandas-b37e4db8256a",
        "document": "Pandas is a powerful Python package for data manipulation, frequently used in tasks involving data analysis and modification. However, standard Pandas operations can become resource-intensive and inefficient when dealing with large datasets. This post explores several methods for efficiently handling large datasets in Pandas.\n\nPandas is an excellent tool for handling small datasets, typically with an upper limit of 2 to 3 GB. For datasets exceeding this threshold, using Pandas is not recommended. This is because Pandas loads the entire dataset into memory before processing, which can be problematic if the dataset size exceeds the available RAM. Even smaller datasets can encounter memory issues due to the creation of DataFrame copies during pre-processing and modification.\n\nDespite these potential issues, Pandas can still be used to handle larger datasets in Python by employing specific techniques. These strategies enable us to use Pandas to analyze millions of records and manage large datasets efficiently in Python.\n\nHow to Handle Large Datasets in Python?\n\nReduce memory consumption by loading only the necessary columns using the `usecols` parameter in `pd.read_csv()`.\n\nThis technique only requires loading relevant columns from the dataset. It is particularly useful when dealing with datasets that have a large number of columns or when the analysis only requires a subset of the data.\n\nThe advantages of this technique are:\n• Increased Processing Efficiency: By loading only the necessary data, the processing becomes faster.\n• Reduced Memory Usage: Less memory is used since unnecessary columns are not loaded.\n\nFor exploratory data analysis or testing, consider using a sample of the dataset instead of the entire dataset.\n\nSampling is the process of randomly selecting data from a dataset for inspection. This can be used for quickly analyzing the dataset, exploring it, or creating models using a representative sample of the data.\n\nThe advantage of this technique is:\n• Faster Analysis and Experimentation: Especially useful when dealing with large datasets.\n\nAbout implementation, we randomly select rows or columns from a DataFrame, use the method in Pandas.\n\nUse more memory-efficient data types, such as `int32` instead of `int64` and `float32` instead of `float64`, to reduce memory usage.\n\nReducing memory usage in Pandas requires using efficient data types. For example, if precision allows, you can use or even instead of the standard dtype. Similarly, integer columns can be downcast to smaller integer types like , , or if the data range allows.\n\nThe advantage of this technique is:\n• Significant Memory Reduction: Especially beneficial for large datasets., we can specify the parameter in functions like or . Additionally, you can use the method to change existing columns to more memory-efficient types.\n\nAs for implementation, we can specify the parameter in functions like or when reading data.Additionally, we can use the method to change existing columns to more memory-efficient types.\n\nAfter loading the data, convert columns to more memory-efficient types using the `astype` method where appropriate.\n\nIdentify columns with data types that are not as efficient as possible and change them to types that save more memory. This can significantly improve performance and reduce memory usage.\n\nThe advantages of this technique are:\n• Maximized Memory Efficiency: Lower memory usage, which is especially beneficial for large datasets.\n\nTo convert columns to more efficient data types, use the method. For converting columns to or types, use functions like or .\n\nRead the dataset in smaller chunks using the `chunksize` parameter in `pd.read_csv()` and process each chunk iteratively.\n\nChunking involves processing the dataset in smaller, more manageable parts rather than loading the entire dataset into memory at once. This is particularly useful when dealing with datasets that are too large to fit into memory.\n\nThe advantage of this technique is:\n• Handling Large Datasets on Memory-Limited Devices: Enables processing of massive datasets using less memory.\n\nFor implementation, we could specify the number of rows to read at a time, and use the parameter in .\n\nPolars is a fast, memory-efficient data manipulation library written in Rust for data processing and analysis. It provides an API similar to Pandas but offers better performance and memory usage efficiency. Compared to Pandas, Polars can achieve over 30 times performance improvement.\n\nLeverage Dask, a parallel computing library, to scale Pandas workflows to larger datasets by utilizing parallel processing. With Dask, your Pandas workflows can scale across multiple cores or even distributed clusters.\n\nThe advantage of this technique is:\n• Parallel Execution of Pandas Operations: Significantly reduces the processing time for large datasets.\n\nFor implementation, we could perform parallel operations on large datasets by using Dask data structures such as and . Dask supports most of the well-known Pandas API, enabling a smooth transition of existing codebases to parallel execution.\n\nHere are common methods for handling large datasets in Pandas, frequently used in our projects. By choosing appropriate techniques, we can significantly improve data processing efficiency and speed, reduce memory consumption, and ensure system stability and performance even when dealing with massive datasets. By integrating tools like Pandas, Dask, and Polars, we can flexibly address various data processing challenges and provide efficient, reliable solutions.\n\nThanks for your reading."
    },
    {
        "link": "https://tilburgsciencehub.com/topics/manage-manipulate/loading/large-datasets/large-datasets-python",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/14351255/techniques-for-working-with-large-numpy-arrays",
        "document": "I feel your pain... You sometimes end up storing several times the size of your array in values you will later discard. When processing one item in your array at a time, this is irrelevant, but can kill you when vectorizing.\n\nI'll use an example from work for illustration purposes. I recently coded the algorithm described here using numpy. It is a color map algorithm, which takes an RGB image, and converts it into a CMYK image. The process, which is repeated for every pixel, is as follows:\n• Use the most significant 4 bits of every RGB value, as indices into a three-dimensional look up table. This determines the CMYK values for the 8 vertices of a cube within the LUT.\n• Use the least significant 4 bits of every RGB value to interpolate within that cube, based on the vertex values from the previous step. The most efficient way of doing this requires computing 16 arrays of uint8s the size of the image being processed. For a 24bit RGB image that is equivalent to needing storage of x6 times that of the image to process it.\n\nA couple of things you can do to handle this:\n\nMaybe you cannot process a 1,000x1,000 array in a single pass. But if you can do it with a python for loop iterating over 10 arrays of 100x1,000, it is still going to beat by a very far margin a python iterator over 1,000,000 items! It´s going to be slower, yes, but not as much.\n\nThis relates directly to my interpolation example above, and is harder to come across, although worth keeping an eye open for it. Because I am interpolating on a three-dimensional cube with 4 bits in each dimension, there are only 16x16x16 possible outcomes, which can be stored in 16 arrays of 16x16x16 bytes. So I can precompute them and store them using 64KB of memory, and look-up the values one by one for the whole image, rather than redoing the same operations for every pixel at huge memory cost. This already pays-off for images as small as 64x64 pixels, and basically allows processing images with x6 times the amount of pixels without having to subdivide the array.\n\nIf your intermediate values can fit in a single , don't use an array of s! This can turn into a nightmare of mysterious errors due to silent overflows, but if you are careful, it can provide a big saving of resources."
    },
    {
        "link": "https://studyplan.dev/intro-to-programming/std-vector",
        "document": "Inevitably, we will want to store a group of related objects. That might be a collection of characters in a party, a collection of buttons on a UI, or countless other use cases.\n\nLet's imagine we have these objects, which we want to store and manage as a single collection:\n\nProgrammers have invented a huge range of options for storing collections of objects. These containers are broadly called data structures, and which data structure we should use depends on our specific requirements. We’ll cover a much wider range of data structures in the next course. Here, we’ll introduce the most common choice - the dynamic array.\n\nUnder the hood, arrays are contiguous blocks of memory, big enough to store multiple objects in sequence.\n\nThere are hundreds of implementations of arrays in C++ that we can use, and we can even create our own once we learn more advanced topics. In this lesson, we’re using the standard library’s implementation of dynamic arrays, which is called .\n\nThe C++ standard library using the \"vector\" name for their implementation of dynamic arrays is unfortunate. When we’re working on projects that involve maths and physics, such as a video games, the constructs we use to represent things like positions, movement and forces are also called vectors.\n\nThese vectors are not related to arrays at all - the confusing naming conflict is just something we need to adapt to.\n\nTo use , we need to . We can then declare a by giving it a name, and specifying the type of objects it will contain within angled brackets: and . The following example shows how we can declare a called that stores objects:\n\nWhen we see chevrons - and - in our code, we’re typically using an advanced C++ feature called templates. Templates allow classes and functions to be written without specifying all of the data types that the class or function will be using. In this case, the standard library authors created a container called that can store a collection of any type of object. As developers using , we just need to provide the type we want to store between the chevrons. This type we provide is referred to as a template argument. When we pass as the template argument - that is, - we create an array for storing values. But we can replace with any type: Templates are particularly powerful as they allow classes and functions to be compatible with types that aren’t known or don’t exist at the time the template was written. For example, the authors of couldn’t know we would want to store a collection of objects, but their code supports it anyway: We cover templates in much more detail, including how to create our own, in the advanced course.\n\nWe can provide a with some initial values:\n\nWhen we are initializing the values at the same time we declare the array, we can optionally remove the template argument. The compiler can infer what type the vector will be storing, based on the type of objects we provided for its initial values:\n\nTo do this, the compiler is using Class Template Argument Deduction (CTAD), which we’ll cover more in our advanced course.\n\nWe can access the members of our array with the subscript operator, which uses syntax. For example, to access an object within , we’d use , where is the index of the element we want to access.\n\nThe index of an element within an array is simply its position within the array. However, in most programming contexts, indexing is zero-based, meaning we start counting from . This means the first element of the vector is at index , the second element is at index , and so on.\n\nFor example, to access the elements of our array, we would do this:\n\nAs with all values, the index can be derived from any expression that evaluates to an integer:\n\nThis code logs out elements at indices , , and in order:\n\nThe size of an array refers to the number of elements it currently contains. This is also sometimes called the length of the array.\n\nThe function returns the current size of our :\n\nNote that because indexing is zero-based, the last element of a vector is at an index of one less than its . For an array of size , the last element is at index .\n\nWe can get the last element by applying this arithmetic within the subscript operator, or by using the function:\n\nOnce our array is created, we’ll often want to add more items to it. Typically, we want to add items to the end of arrays, as this has performance benefits over adding them to the start. We’ll cover the performance characteristics of containers in more detail in the next course.\n\nand many other data structures provide two ways of adding objects:\n• Pushing an object involves moving or copying an existing object into the container\n• Emplacing an object involves creating a new object directly within the container\n\nCreating an object in place has performance benefits over creating it elsewhere and then moving it. Therefore, where possible, we should prefer emplacing over pushing.\n\nWith , we’re adding items to the back of the container, so the respective functions are called and\n\nIf an object has already been constructed, and we want to add it to the back of our array, we can use :\n\nIf the object we want to add does not already exist, we can construct it right inside of the array, using .\n\nThe arguments we call with will be passed to the constructor of the object type the vector stores:\n\nThe type also offers an method to remove objects from our array. The erase method requires we provide an iterator, which is slightly more advanced than a simple index.\n\nWe cover iterators in detail in the advanced course, but for now, note that we can get an iterator corresponding to a index using , where is the index we’re interested in.\n\nSo, for example, to erase the second item (the item at index ) from our array we’d use:\n\nThe of our array will be reduced by , and all of the objects that were after the element we erased get moved by one position to the left to fill in the gap:\n\nWe can modify objects in a in the usual ways. We can replace the object at a given index using the assignment operator, :\n\nWe can also call functions (including operators) on our objects as needed:\n\nOur above example uses vectors with values, but we can store pointers and references in arrays too:\n\nArrays can also store other arrays. This creates \"multidimensional arrays\". For example, a 3x3 grid could be represented as an array of 3 rows, each row being an array of 3 items:\n\nWe can treat a collection of objects like any other value. Below, we pass a collection to a function:\n\nAs with any other parameter, arrays are passed by value by default. The performance implications are particularly important here, as copying a collection of objects is inherently more expensive than copying a single object.\n\nWe can pass by reference in the usual way, with or without :\n\nWe can also generate and use pointers in the normal way. The following code replicates the previous example, using pointers instead of references:\n\nA common task we have when working with arrays is to perform some action on every object in the collection. We can do this with a loop:\n\nThere is an issue with using values as the index of vectors: modern computers have enough memory to store a lot of objects in an array. This means that the of the array, or the index used to reference a specific position, can be a larger number than the maximum value storable in an .\n\nTo deal with this problem, we have the data type. is guaranteed to be large enough to match the largest possible size of the array.\n\nBecause of this, it is the recommended way of storing array sizes and indices:\n\nOften, we usually don’t need to work with indices at all - we just want to iterate over everything in the array. For those scenarios, we can use this syntax:\n\nThis is known as a range-based for loop. We cover these in more detail in the next course, including how to make our custom types compatible with this syntax.\n\nSimilar to functions, range-based for loops can receive their parameters by reference or value, with value being the default. This means each item in the collection is copied into the body of the loop. We should consider passing by reference instead, particularly if the type we’re using is expensive to copy:\n\nJust like when we’re passing by reference into a function if the loop body isn’t going to modify that reference, we should consider marking it as :\n\nand other arrays keep our objects in contiguous blocks of memory on our system. As we push or emplace objects into our array, it may run out of space at its current memory location.\n\nWe can see how much of our capacity we’re currently using by comparing what is returned from the and methods:\n• returns the number of elements currently in the array.\n• returns the number of elements the array can hold in its current memory location.\n\nBelow, we see the initially has a capacity of , with all spaces being taken. When we add a 6th item, the increases to , whilst the is now :\n\nWhen we add elements beyond the current capacity, the will do some work behind the scenes to let our array grow. It will:\n• Allocate a new block of memory with a larger capacity.\n• Move all existing elements to the new location.\n\nIn our previous example, this new location has enough space to store objects. We’re currently only storing , so we have room to add one more before everything needs to be moved to a larger memory block again.\n\nMoving an array to a new location has a performance cost, so if we’re able to reduce unnecessary movements, we should consider it.\n\nIf we know approximately how many objects our is likely to need to store, we can directly enough capacity for them. Below, we ask our to move to a location with room for objects:\n\nNow, it has plenty of room to grow before it needs to move again:\n\nNaturally, a with a capacity for objects will consume more system memory than one with a capacity of only .\n\nBut if we think it’s eventually going to grow to objects anyway, we may as well just reserve that space from the start and eliminate all the expensive moving.\n• Reallocation can be expensive, especially for large vectors or complex objects.\n• Using can help avoid unnecessary reallocations.\n• However, over-reserving can waste memory if the extra capacity isn't used.\n\nIn this lesson, we've explored the essentials of dynamic arrays, with a particular focus on . You've learned how to create, access, modify, and efficiently manage collections of objects, laying a strong foundation for more advanced programming concepts.\n• Understanding the difference between static and dynamic arrays, and the flexibility of .\n• Creating, initializing, and accessing elements in a , including using and methods.\n• Techniques for modifying elements within a , and the implications of passing vectors to functions.\n• Effective looping through vectors using both traditional and range-based for loops, and the importance of in managing vector sizes.\n• How manages its capacity, and how we can interact with that mechanism using and .\n\nIn the next lesson, we introduce the main design pattern used to manage memory in complex applications. We also introduce smart pointers, the main mechanism used to implement this pattern. We cover:\n• Memory Management Simplified: We explore how smart pointers automate memory management, thereby reducing the chances of memory-related errors.\n• Understanding Memory Ownership: What smart pointers are and how they implement an ownership model for objects in dynamically allocated memory\n• Creating Unique Pointers using : How to create unique pointers using ,\n• Access and Ownership Transfer: How to give other functions access to our resources, and whether we want to maintain or transfer ownership at the same time."
    },
    {
        "link": "https://geeksforgeeks.org/vector-in-cpp-stl",
        "document": "In C++, vector is a dynamic array that stores collection of elements same type in contiguous memory. It has the ability to resize itself automatically when an element is inserted or deleted.\n\nVector is defined as the std::vector class template inside the <vector> header file.\n\nwhere T is the type of elements and v is the name assigned to the vector.\n\nCreating a vector involves creating an instance of std::vector class. This requires us to provide the type of elements as template parameter.\n\nWe can also provide the values to be stored in the vector inside {} curly braces. This process is called initialization.\n\nIn the above example,\n• vector<int> v2(5, 9) creates a vector of size 5 where each element initialized to 9.\n\nMore ways to declare and initialize vectors are discussed in this article – 8 Ways to Initialize Vector in C++\n\nAn element can be inserted into a vector using vector insert() method which takes linear time. But for the insertion at the end, the vector push_back() method can be used. It is much faster, taking only constant time.\n\nMore ways to insert an element in the vector are discussed in the article – Different Ways to Add Elements in a Vector\n\nJust like arrays, vector elements can be accessed using their index inside the [] subscript operator. This method is fast but doesn’t check whether the given index exists in the vector or not. So, there is another member method vector at() for safely accessing elements.\n\nTo know more about accessing vector elements, refer to the article – Different Ways to Access Elements in Vector\n\nUpdating elements is very similar to the accessing except that we use an assignment operator to assign a new value. It uses the same methods: [] subscript operator and vector at().\n\nMore methods to update vector elements are discussed in this article – Different Ways to Update Vector Elements\n\nOne of the common problems with arrays was to keep a separate variable to store the size information. Vector provides the solution to this problem by providing size() method.\n\nVector in C++ can be traversed using indexes in a loop. The indexes start from 0 and go up to vector size – 1. To iterate through this range, we can use a loop and determine the size of the vector using the vector size()method.\n\nWe can also use a range-based loop for simple traversal. More ways to traverse vectors are discussed in this article – Different Ways to Iterate Through Vector\n\nAn element can be deleted from a vector using vector erase() but this method needs iterator to the element to be deleted. If only the value of the element is known, then find() function is used to find the position of this element.\n\nFor the deletion at the end, the vector pop_back() method can be used, and it is much faster, taking only constant time.\n\nTo know more about the deletion of an element in the vector, refer to this article – Different Ways to Remove Elements from Vector\n\nVector is one of the most frequently used containers in C++. It is used in many situations for different purposes. The following examples aim to help you master vector operations beyond the basics.\n\nThe below table lists the time complexity of the above operations on a vector:\n\nVectors can be passed to a function as arguments just like any other variable in C++. But it is recommended to pass the vector by reference so as to avoid the copying of all elements which can be expensive if the vector is large. Refer to this article to know more – Passing Vector to a Function\n\nVector internal working is very interesting and useful to select and optimize its usage. Understanding the internal memory management also helps in modifying the default mechanism of vector to suits our needs. Refer to this article to know more – Internal Working of Vector\n\nJust like arrays, we can also create multidimensional vectors in C++. Each element of multidimensional vector can be visualized as the collection of vectors with dimension one less that the current vector. For example, 2D vectors are the collection of 1D vectors, while 3D vectors are the collection of 2D vectors and so on.\n\nWith the addition of each dimension, the complexity of operations on the vectors also increases.\n\nRefer to this article to know more – Multidimensional Vectors in C++\n\nFollowing is the list of all member functions of std::vector class in C++:\n\nAdds an element to the end of the vector. Removes the last element of the vector. Returns the number of elements in the vector. Returns the maximum number of elements that the vector can hold. Changes the size of the vector. Checks if the vector is empty. Accesses the element at a specific position, with bounds checking. Accesses the first element of the vector. Accesses the last element of the vector. Returns an iterator pointing to the first element of the vector. Returns an iterator pointing to the past-the-end element of the vector. Returns a reverse iterator pointing to the last element of the vector. Returns a reverse iterator pointing to the element preceding the first element of the vector. Inserts elements at a specific position in the vector. Removes elements from a specific position or range in the vector. Swaps the contents of the vector with those of another vector. Removes all elements from the vector. Constructs and inserts an element in the vector. Constructs and inserts an element at the end of the vector. Assigns new values to the vector elements by replacing old ones. Returns the size of the storage space currently allocated to the vector. Requests that the vector capacity be at least enough to contain a specified number of elements. Returns a direct pointer to the memory array used internally by the vector to store its owned elements. Returns a copy of the allocator object associated with the vector."
    },
    {
        "link": "https://stackoverflow.com/questions/13431567/how-to-make-an-array-with-a-dynamic-size-general-usage-of-dynamic-arrays-maybe",
        "document": "Here's some code I wrote up in C++ that does the basics.\n\nOkay, so here's what's going on in this code. We're prompting for the size of the array using std::cin and then using the new keyword to dynamically allocate some memory for the array. There's some details here that make it seem a little weird at first; it's what seems to cause confusion with a lot of new C++ developers.\n\nSo first we declared our dynamic array with a pointer instead of the array declaration, e.g. we used instead of . At first this seems kind of trivial, but there's something that you need to understand about what's going on in C and C++.\n\nWhen you statically declare an array, you are telling the program that you want to set aside that memory for you to use. It's actually there; it's yours for you to start using. When you dynamically create an array, you start with a pointer. Pointers are just a reference to some memory. That memory isn't allocated yet. If you try to access something in it with, say, , you'll get a nasty error. That's because there's nothing actually in memory at that location (at least nothing that has been given to the program to use).\n\nAlso note the use of instead of . That's the way you free up the memory when you're done with the array.\n\nIf you're doing this in C, you can pretty much think of this the same way, but instead of and you have and .\n\nKnowing the subtle differences between dynamic arrays and pointers is tricky. It took me a while before I fully understood what was going on. Good luck and keep at it."
    },
    {
        "link": "https://stackoverflow.com/questions/381621/using-arrays-or-stdvectors-in-c-whats-the-performance-gap",
        "document": "In our C++ course they suggest not to use C++ arrays on new projects anymore. As far as I know Stroustrup himself suggests not to use arrays. But are there significant performance differences?\n\nUsing C++ arrays with (that is, using dynamic arrays) should be avoided. There is the problem that you have to keep track of the size, and you need to delete them manually and do all sorts of housekeeping. Using arrays on the stack is also discouraged because you don't have range checking, and passing the array around will lose any information about its size (array to pointer conversion). You should use in that case, which wraps a C++ array in a small class and provides a function and iterators to iterate over it. Now, std::vector vs. native C++ arrays (taken from the internet): // Comparison of assembly code generated for basic indexing, dereferencing, // and increment operations on vectors and arrays/pointers. // Assembly code was generated by gcc 4.1.0 invoked with g++ -O3 -S on a // x86_64-suse-linux machine. #include <vector> struct S { int padding; std::vector<int> v; int * p; std::vector<int>::iterator i; }; int pointer_index (S & s) { return s.p[3]; } // movq 32(%rdi), %rax // movl 12(%rax), %eax // ret int vector_index (S & s) { return s.v[3]; } // movq 8(%rdi), %rax // movl 12(%rax), %eax // ret // Conclusion: Indexing a vector is the same damn thing as indexing a pointer. int pointer_deref (S & s) { return *s.p; } // movq 32(%rdi), %rax // movl (%rax), %eax // ret int iterator_deref (S & s) { return *s.i; } // movq 40(%rdi), %rax // movl (%rax), %eax // ret // Conclusion: Dereferencing a vector iterator is the same damn thing // as dereferencing a pointer. void pointer_increment (S & s) { ++s.p; } // addq $4, 32(%rdi) // ret void iterator_increment (S & s) { ++s.i; } // addq $4, 40(%rdi) // ret // Conclusion: Incrementing a vector iterator is the same damn thing as // incrementing a pointer. Note: If you allocate arrays with and allocate non-class objects (like plain ) or classes without a user defined constructor and you don't want to have your elements initialized initially, using -allocated arrays can have performance advantages because initializes all elements to default values (0 for int, for example) on construction (credits to @bernie for reminding me).\n\n\"Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%\". Don't use a C array instead of a vector (or whatever) just because you believe it's faster as it is supposed to be lower-level. You would be wrong. Use by default vector (or the safe container adapted to your need), and then if your profiler says it is a problem, see if you can optimize it, either by using a better algorithm, or changing container. This said, we can go back to the original question. The C++ array classes are better behaved than the low-level C array because they know a lot about themselves, and can answer questions C arrays can't. They are able to clean after themselves. And more importantly, they are usually written using templates and/or inlining, which means that what appears to a lot of code in debug resolves to little or no code produced in release build, meaning no difference with their built-in less safe competition. All in all, it falls on two categories: Using a pointer to a malloc-ed/new-ed array will be at best as fast as the std::vector version, and a lot less safe (see litb's post). Using a static array will be at best:\n• as fast as the std::array version Sometimes, using a instead of a raw buffer incurs a visible cost because the will initialize the buffer at construction, while the code it replaces didn't, as remarked bernie by in his answer. If this is the case, then you can handle it by using a instead of a or, if the case is not exceptional in your codeline, actually write a class that will own that memory, and give you easy and safe access to it, including bonuses like resizing it (using ?), or whatever you need.\n\nYou have even fewer reasons to use plain arrays in C++11. There are 3 kind of arrays in nature from fastest to slowest, depending on the features they have (of course the quality of implementation can make things really fast even for case 3 in the list):\n• Static with size known at compile time. ---\n• Dynamic with size known at runtime and never resized. The typical optimization here is, that if the array can be allocated in the stack directly. -- Not available. Maybe in C++ TS after C++14. In C there are VLAs For 1. plain static arrays with fixed number of elements, use in C++11. For 2. fixed size arrays specified at runtime, but that won't change their size, there is discussion in C++14 but it has been moved to a technical specification and made out of C++14 finally. For 3. will usually ask for memory in the heap. This could have performance consequences, though you could use to improve the situation with a custom allocator. The advantage compared to is that you can resize it and that it will not decay to a pointer, as plain arrays do. Use the standard library types mentioned to avoid arrays decaying to pointers. You will save debugging time and the performance is exactly the same as with plain arrays if you use the same set of features.\n\nThe performance difference between the two is very much implementation dependent - if you compare a badly implemented std::vector to an optimal array implementation, the array would win, but turn it around and the vector would win... As long as you compare apples with apples (either both the array and the vector have a fixed number of elements, or both get resized dynamically) I would think that the performance difference is negligible as long as you follow got STL coding practise. Don't forget that using standard C++ containers also allows you to make use of the pre-rolled algorithms that are part of the standard C++ library and most of them are likely to be better performing than the average implementation of the same algorithm you build yourself. That said, IMHO the vector wins in a debug scenario with a debug STL as most STL implementations with a proper debug mode can at least highlight/cathc the typical mistakes made by people when working with standard containers. Oh, and don't forget that the array and the vector share the same memory layout so you can use vectors to pass data to legacy C or C++ code that expects basic arrays. Keep in mind that most bets are off in that scenario, though, and you're dealing with raw memory again.\n\nThere isn't any argument about which of them is the best or good to use. They both have there own use cases, and they both have their pros and cons. The behavior of both containers are different in different places. One of the main difficulties with arrays is that they are fixed in size. If once they are defined or initialized, then you can not change values and on the other side, vectors are flexible; you can change vectors value whenever you want. It's not fixed in size like arrays, because an array has static memory allocation and vector has dynamic memory or heap memory allocation (we can push and pop elements into/from vector) and the creator of C++, Bjarne Stroustrup, said that vectors are flexible to use more than arrays: Using C++ arrays with new (that is, using dynamic arrays) should be avoided. There is the problem you have to keep track of the size, and you need to delete them manually and do all sort of housekeeping. We can also insert, push and pull values easily in vectors which is not easily possible in arrays. If we talk about performance-wise then if you are working with small values then you should use arrays and if you are working with big scale code then you should go with vector (vectors are better at handling big values than arrays)."
    },
    {
        "link": "https://medium.com/@devjubr/mastering-c-vectors-dynamic-arrays-explained-with-practical-examples-834f0771ad07",
        "document": "A Step-by-Step Guide to Understanding and Using in C++ for Efficient Dynamic Arrays\n\nWhere Does It Come From?\n• The in refers to the Standard Namespace in C++.\n• C++ organizes its libraries into namespaces to prevent name collisions. The Standard Library, where is defined, resides in the namespace.\n• Defined in the header, is a template class, meaning it is a generic container that can store elements of any type (e.g., , , , or even user-defined types).\n• Before , programmers had to manually allocate and resize arrays using and . This process was error-prone and inefficient.\n• automates memory management, making it easier and safer to work with dynamic arrays.\n\nTo use vectors, you include the header:\n\nVectors are perfect when the number of elements isn’t known at compile-time. For example:\n\nVectors store elements sequentially in memory, ensuring fast access using an index:\n\nThe vector automatically manages its memory. When elements are added or removed, it reallocates memory as needed without requiring explicit calls to or .\n• Use to add elements to the end of the vector:\n• Use the subscript operator ( ) or the method:\n• Use to remove the last element:\n• Use to get the number of elements in the vector:\n• Use to remove all elements:\n• Use to set the size of the vector:\n\nVectors can store user-defined data types. For example:\n\nYou can sort a vector using from the header:\n• returns the current storage capacity of the vector.\n• Use to add elements at specific positions:\n• Use to remove elements at specific positions:\n\nWhy Use Over Regular Arrays?\n\nUtility Functions:\n\nVectors come with a rich set of functions for easy manipulation (e.g., adding, sorting, resizing).\n\nPerformance:\n\nVectors are optimized for performance and ensure contiguous memory allocation, which is faster for sequential access."
    }
]