[
    {
        "link": "https://tarekraafat.github.io/autoComplete.js",
        "document": ""
    },
    {
        "link": "https://github.com/TarekRaafat/autoComplete.js",
        "document": "autoComplete.js is a simple, pure vanilla Javascript library progressively designed for speed, high versatility, and seamless integration with a wide range of projects & systems.\n• Powerful Search Engine with two different modes\n• Works on anything ( , and elements)\n\nTechnical questions and support, please post your question on Stack Overflow using the below tag\n\nGeneral questions or new ideas for please start a discussion on Github using the below link"
    },
    {
        "link": "https://github.com/TarekRaafat/autoComplete.js/blob/master/README.md",
        "document": "autoComplete.js is a simple, pure vanilla Javascript library progressively designed for speed, high versatility, and seamless integration with a wide range of projects & systems.\n• Powerful Search Engine with two different modes\n• Works on anything ( , and elements)\n\nTechnical questions and support, please post your question on Stack Overflow using the below tag\n\nGeneral questions or new ideas for please start a discussion on Github using the below link"
    },
    {
        "link": "https://npmjs.com/package/autocomplete.js?activeTab=readme",
        "document": "This JavaScript library adds a fast and fully-featured auto-completion menu to your search box displaying results \"as you type\". It can easily be combined with Algolia's realtime search engine. The library is available as a jQuery plugin, an Angular.js directive or a standalone library.\n• FAQ\n• How can I -click on results and have them open in a new tab?\n• Displays suggestions to end-users as they type\n• Supports custom templates to allow for UI flexibility\n• Works well with RTL languages and input method editors\n\nThe library must be included after jQuery, Zepto or Angular.js (with jQuery). Else, it will use the embedded Zepto.\n\nYou can find the built version in dist/.\n\nYou can require it and use Browserify:\n\nWarning: is not compatible with the latest version algoliasearch v4 out of the box, but you can create a compatibility source by yourself like this:\n\nWarning: is not compatible with the latest version algoliasearch v4, therefore we highly recommend you use algoliasearch v3 as specified in the code snippet below.\n• Add the , and the optional attribute to your search bar\n\nWarning: is not compatible with the latest version algoliasearch v4, therefore we highly recommend you use algoliasearch v3 as specified in the code snippet below.\n\nNote: You need to rely on , the lite version embedded in Angular.js won't work.\n\nBelow is a faux mustache template describing the DOM structure of an autocomplete dropdown menu. Keep in mind that , , , and come from the provided templates detailed here.\n\nWhen an end-user mouses or keys over a , the class will be added to it. You can use this class as a hook for styling the \"under cursor\" state of suggestions.\n\nAdd the following CSS rules to add a default style:\n\nHere is what the basic example looks like:\n\nWhen initializing an autocomplete, there are a number of global options you can configure.\n• – If , the first rendered suggestion in the dropdown will automatically have the class, and pressing will select it.\n• – If , when the input is blurred, the first rendered suggestion in the dropdown will automatically have the class, and pressing will select it. This option should be used on mobile, see #113\n• – If , pressing tab will select the first rendered suggestion in the dropdown. Defaults to .\n• – If , the autocomplete will not show a hint. Defaults to .\n• – If , the autocomplete will not close on . Defaults to .\n• – If , the autocomplete will empty the search box when a suggestion is selected. This is useful if you want to use this as a way to input tags using the event.\n• – If , the dropdown menu will open when the input is focused. Defaults to .\n• – If set with a DOM selector, doesn't wrap the input and appends the wrapper and dropdown menu to the first DOM element matching the selector. It automatically positions the wrapper under the input, and sets it to the same width as the input. Can't be used with , because requires the wrapper around the input.\n• – If set with a DOM selector, it overrides the container of the dropdown menu.\n• \n• – the dropdown menu template. The template should include all dataset placeholders.\n• – the header to prepend to the dropdown menu\n• – the footer to append to the dropdown menu\n• – the template to display when none of the datasets are returning results. The templating function is called with a context containing the underlying .\n• \n• – the CSS class prefix of all nested elements. Defaults to .\n• - set this to true if you wish to not use any prefix. Without this option, all nested elements classes will have a leading dash. Defaults to .\n• - Array of shortcut that will focus the input. For example if you want to bind and you can specify:\n• - An optional string that will populate the attribute.\n• – The minimum character length needed before suggestions start getting rendered. Defaults to .\n• – This option allow you to control the width of autocomplete wrapper. When the autocomplete wrapper will not have the width style attribute and you are be able to put your specific width property in your css to control the wrapper. Default value is .\n\nOne scenario for use this option. e.g. You have a css attribute in your and you need to width grows until fill the . In this scenario you put a in your autocomplete wrapper css class and the in your autocomplete dropdown class and all done.\n\nAn autocomplete is composed of one or more datasets. When an end-user modifies the value of the underlying input, each dataset will attempt to render suggestions for the new value.\n\nDatasets can be configured using the following options.\n• – The backing data source for suggestions. Expected to be a function with the signature . It is expected that the function will compute the suggestion set (i.e. an array of JavaScript objects) for and then invoke with said set. can be invoked synchronously or asynchronously.\n• – The name of the dataset. This will be appended to to form the class name of the containing DOM element. Must only consist of underscores, dashes, letters ( ), and numbers. Defaults to a random number.\n• – For a given suggestion object, determines the string representation of it. This will be used when setting the value of the input control after a suggestion is selected. Can be either a key string or a function that transforms a suggestion object into a string. Defaults to . Example function usage:\n• – A hash of templates to be used when rendering the dataset. Note a precompiled template is a function that takes a JavaScript object as its first argument and returns a HTML string.\n• – Rendered when suggestions are available for the given query. Can be either a HTML string or a precompiled template. The templating function is called with a context containing , , and any optional arguments that may have been forwarded by the source: .\n• – Rendered at the bottom of the dataset. Can be either a HTML string or a precompiled template. The templating function is called with a context containing , , and any optional arguments that may have been forwarded by the source: .\n• – Rendered at the top of the dataset. Can be either a HTML string or a precompiled template. The templating function is called with a context containing , , and any optional arguments that may have been forwarded by the source: .\n• – Used to render a single suggestion. The templating function is called with the , and any optional arguments that may have been forwarded by the source: . Defaults to the value of wrapped in a tag i.e. .\n• – If set, will postpone the source execution until after milliseconds have elapsed since the last time it was invoked.\n• - If set to , subsequent identical queries will always execute the source function for suggestions. Defaults to .\n\nA few helpers are provided by default to ease the creation of Algolia-based sources.\n\nTo build a source based on Algolia's array, just use:\n\nTo build an Amazon-like autocomplete menu, suggesting popular queries and for the most popular one displaying the associated categories, you can use the source:\n\nThe options can also take a function. It enables you to have more control of the results returned by Algolia search. The function takes 2 parameters\n• : the text typed in the autocomplete\n• : the callback to call at the end of your processing with the array of suggestions\n\nOr by reusing an existing source:\n\nMalicious users may attempt to engineer XSS attacks by storing HTML/JS in their data. It is important that user-generated data be properly escaped before using it in an autocomplete.js template.\n\nIn order to easily do that, autocomplete.js provides you with a helper function escaping all HTML code but the highlighting tags:\n\nIf you did specify custom highlighting pre/post tags, you can specify them as 2nd and 3rd parameter:\n\nHow can I -click on results and have them open in a new tab?\n\nYou'll need to update your suggestion templates to make them as links and not simple divs. -clicking on them will trigger the default browser behavior and open suggestions in a new tab.\n\nTo also support keyboard navigation, you'll need to listen to the event and change to the destination URL.\n\nNote that you might need to check the value of in first. If it's equal to , you should early, otherwise your main window will also follow the link.\n\nHere is an example of how it would look like:\n\nThe autocomplete component triggers the following custom events.\n• – Triggered when the dropdown menu of the autocomplete is opened.\n• – Triggered when the dropdown menu of the autocomplete is shown (opened and non-empty).\n• – Triggered when all datasets are empty.\n• – Triggered when the dropdown menu of the autocomplete is closed.\n• – Triggered when the dropdown menu cursor is moved to a different suggestion. The event handler will be invoked with 3 arguments: the jQuery event object, the suggestion object, and the name of the dataset the suggestion belongs to.\n• – Triggered when a suggestion from the dropdown menu is selected. The event handler will be invoked with the following arguments: the jQuery event object, the suggestion object, the name of the dataset the suggestion belongs to and a object. The contains a key that can be either , , or , depending how the suggestion was selected.\n• – Triggered when the cursor leaves the selections or its current index is lower than 0\n• – Triggered when the query is autocompleted. Autocompleted means the query was changed to the hint. The event handler will be invoked with 3 arguments: the jQuery event object, the suggestion object, and the name of the dataset the suggestion belongs to.\n• – Triggered when is used and the wrapper is resized/repositionned.\n\nAll custom events are triggered on the element initialized as the autocomplete.\n\nTurns any element into an auto-completion menu. is an options hash that's used to configure the autocomplete to your liking. Refer to Global Options for more info regarding the available configs. Subsequent arguments ( ), are individual option hashes for datasets. For more details regarding datasets, refer to Datasets.\n\nRemoves the autocomplete functionality and reverts the element back to its original state.\n\nOpens the dropdown menu of the autocomplete. Note that being open does not mean that the menu is visible. The menu is only visible when it is open and has content.\n\nCloses the dropdown menu of the autocomplete.\n\nReturns the current value of the autocomplete. The value is the text the user has entered into the element.\n\nSets the value of the autocomplete. This should be used in place of .\n\nReturns a reference to the autocomplete plugin and reverts to its previous value. Can be used to avoid naming collisions.\n\nThe standalone version API is similiar to jQuery's:\n\nYou can also pass a custom Typeahead instance in Autocomplete.js constructor:\n\nReturns a reference to the autocomplete plugin and reverts to its previous value. Can be used to avoid naming collisions.\n\nThis library has originally been forked from Twitter's typeahead.js library."
    },
    {
        "link": "https://algolia.com/doc/ui-libraries/autocomplete/introduction/getting-started",
        "document": "Get started with Autocomplete by building an Algolia search experience.\n\nThis documentation offers a few ways to learn about the Autocomplete library:\n• Read the Core Concepts to learn more about underlying principles, like Sources and State.\n• Follow the Guides to understand how to build common UX patterns.\n• Refer to API reference for a comprehensive list of parameters and options.\n• Try out the Playground where you can fork a basic implementation and play around.\n\nKeep reading to see how to install Autocomplete and build a basic implementation with Algolia.\n\nThe recommended way to get started is with the package. It includes everything you need to render a JavaScript autocomplete experience.\n\nOtherwise, you can install the package if you want to build a renderer from scratch.\n\nAll Autocomplete packages are available on the npm registry.\n\nIf you don’t want to use a package manager, you can use a standalone endpoint:\n\nAlgolia recommends using jsDelivr but is also available through unpkg.\n\nThe Autocomplete library provides the package so that you can have sleek styling out of the box.\n\nIf you want a custom theme, use this classic theme and customize it with CSS variables. You can also create an entirely new theme using the classic theme as a starting point.\n\nThis example uses the out of the box classic theme. You can import it like any other Autocomplete package.\n\nThen import it in your project:\n\nIf you don’t use a package manager, you can link the style sheet in your HTML:\n\nAlgolia doesn’t provide support regarding third party services like jsDelivr or other CDNs.\n\nDefining where to put your autocomplete\n\nTo get started, you need a container for your autocomplete to go in. If you don’t have one already, you can insert one into your markup:\n\nThen, insert your autocomplete into it by calling the function and providing the . It can be a CSS selector or an Element.\n\nMake sure to provide a container (for example, a ), not an . Autocomplete generates a fully accessible search box for you.\n\nYou may have noticed two options: and . The option defines the text to show until users start typing in the input.\n\nAutocomplete is now plugged in. But you won’t see anything appear until you define your sources.\n\nSources define where to retrieve the items to display in your Autocomplete drop-down menu. You define your sources in the function by returning an array of source objects.\n\nEach source object needs to include a and a function that returns the items to display. Sources can be static or dynamic.\n\nThis example uses an Algolia index of ecommerce products as a source. The package provides a built-in function for just this purpose.\n\nThe function requires an Algolia search client initialized with an Algolia application ID and API key. It lets you search into your Algolia index using an array of , which defines one or more queries to send to the index.\n\nThis example makes just one query to the “autocomplete” index using the from . For now, it passes one additional parameter, to define how many items to display, but you could pass any other Algolia query parameters.\n\nAlthough you’ve now declared what items to display using , you still won’t see anything until you’ve defined how to display the items you’ve retrieved.\n\nSources also define how to display items in your Autocomplete using . Templates can return a string or anything that’s a valid Virtual DOM element. The example creates a Preact component called to use as the template for each item.\n\nThe CSS classes correspond to the classic theme imported earlier.\n\nThe component uses the component to only display part of the item’s name and description, if they go beyond a certain length. Each attribute’s allowed length and the characters to show when truncated are defined in the and Algolia query parameters in .\n\nThis is what the truncated JSON record looks like:\n\nCheck out how the template displays items by searching in the input below:\n\nWhen you’re building, styling, or debugging your autocomplete experience, you might want to inspect it in your web developer tools. You can set the option to to keep the panel open when inspecting it.\n\nYou should only use the option during development.\n\nTo send click and conversion events when users interact with your autocomplete experience, set the option to .\n\nAlgolia supports the last two versions of the major browsers: Chrome, Edge, Firefox, Safari.\n\nThis is all you need for a basic implementation. To go further, you can use the to add keyboard accessibility features. It lets users open items directly from the autocomplete menu.\n\nNow give it a try: go to one of the items using your keyboard and hit . This brings you to the product detail page on bestbuy.com.\n\nThis outlines a basic autocomplete implementation. There’s a lot more you can do like:\n• Define templates for headers, footers, or when there’s no results\n• Send Algolia Insights events when a user clicks on an item or adds it to their cart\n\nTo learn about customization options, read the Core Concepts or follow one of the Guides."
    },
    {
        "link": "https://blog.logrocket.com/reading-writing-json-files-node-js-complete-tutorial",
        "document": "Editor’s note: This article was last updated by Oyinkansola Awosan on 18 October 2024 to cover handling large JSON files using and to add information about the third-party library jsonfile.\n\nNode.js provides built-in modules and third-party libraries for reading and writing JSON files. It offers flexible methods to suit various needs, such as handling small JSON objects or large datasets. These modules and libraries make it easy to work with structured data in JSON format. More often than not, this JSON data needs to be read from or written to a file for persistence, and the Node runtime environment has the built-in module specifically for working with files.\n\nIn the Node runtime environment, you can use the built-in function and modules to load or read JSON files. Because the function is available for each module, you don’t need to require it. However, you must require the module before using it.\n\nIn the following sections, we will dive into how to read JSON files using the built-in module and the function.\n\nFirst, let’s create a JSON file. To do that, we can input the data below in a file called\n\nYou can use the method to read JSON files. It asynchronously reads the contents of the entire file in memory and is therefore not the most optimal method for reading large JSON files.\n\nThe method takes three arguments. The code snippet below shows its function signature:\n• The first argument, , is the file name or the file descriptor\n• The second is an optional object argument\n• The third is a function. You can also pass a string as the second argument instead of an object. If you pass a string, then it has to be encoded\n\nThe function takes two arguments. The first argument is the object if an error occurs, and the second is the serialized JSON data:\n\nIn the example above, we import the module, then use to read our previously created JSON file, . The code retrieves the file’s content, checks for errors, and, if successful, parses the JSON data into a JavaScript object, which is then printed.\n\nMake sure to deserialize the JSON string passed to the function before you start working with the resulting JavaScript object.\n\nYou can use the function to synchronously load JSON files in Node. After loading a file using , it is cached. Therefore, loading the file again using will load the cached version. In a server environment, the file will be loaded again in the next server restart.\n\nTherefore, it is advisable to use for loading static JSON files such as configuration files that don’t change often. Don’t use if the JSON file you load keeps changing, because it will cache the loaded file, and use the cached version if you require the same file again. Your latest changes will not be reflected.\n\nAssuming you have a file with the following contents:\n\nYou can load the file in a JavaScript file using the code below. will always load the JSON data as a JavaScript object:\n\nis another built-in method for reading files in Node similar to . The difference between the two is that reads the file asynchronously while reads the file synchronously. Therefore, blocks the event loop and execution of the remaining code until all the data has been read.\n\nCheck out this article for more information about the difference between synchronous and asynchronous code.\n\nBelow is the function signature of :\n\nrefers to the location of the JSON file you wish to read. Optionally, you can provide an object as the second argument.\n\nIn the code snippet below, we are reading JSON data from the file using :\n\nHow to write to JSON files in Node.js\n\nJust like reading JSON files, the module provides built-in methods for writing to JSON files. You can use the , as discussed above, and the methods, as discussed below. The difference between the two is that:\n\nBefore writing a JSON file, make sure to serialize the JavaScript object to a JSON string using the method. will format your JSON data in a single line if you do not pass the optional formatting argument to the method specifying how to format your JSON data.\n\nTo write a JSON file, the module is also required. Here, we will use the method. The method takes four arguments. The code snippet below shows its function signature:\n\nWhen the method is given the path of an existing JSON file, it will overwrite that file’s data. It will create a new file if the file does not exist:\n\nHere, we use the method to write the JSON string to a file named and ask for a success or error message depending on which one occurs.\n\nUnlike , writes to a file synchronously. If you use , you will block the execution of the event loop and the rest of the code until the operation is successful or an error occurs. It will create a new file if the path you pass doesn’t exist and overwrite it if it does.\n\nIn the code snippet below, we are writing to the file. We wrap the code in so that we can catch any errors:\n\nNode doesn’t have a built-in function for appending or updating the fields of an existing JSON file out of the box. However, you can read the JSON file using the method of the module, update it, and overwrite the JSON file with the updated JSON.\n\nBelow is a code snippet illustrating how to do this:\n\nThere are other methods for reading and writing JSON files, which we’ll cover in the following sections.\n\nSerialization is the process of modifying an object or data structure to a format that is easy to store or transfer over the internet. You can recover the serialized data by applying the reverse process.\n\nDeserialization refers to transforming the serialized data structure to its original format. You will almost always need to serialize JSON or JavaScript objects to a JSON string in Node. You can do so with the method before writing it to a storage device or transmitting it over the internet:\n\nOn the other hand, after reading the JSON file, you will need to deserialize the JSON string to a plain JavaScript object using the method before accessing or manipulating the data:\n\nand are globally available methods in Node. You don’t need to install or require them before using them.\n\nThe module is built-in, and it provides functions that you can use to read and write data in the JSON format and much more.\n\nEach function exposed by the module has synchronous, callback, and promise-based forms. The synchronous and callback variants of a method are accessible from the synchronous and callback API. The promise-based variant of a function is accessible from the promise-based API.\n\nThe synchronous methods of the built-in module block the event loop and further execution of the remaining code until the operation has succeeded or failed. More often than not, blocking the event loop is not something you want to do.\n\nThe names of all synchronous functions end with the characters. For example, and are both synchronous functions.\n\nYou can access the synchronous API by requiring :\n\nUnlike the synchronous methods that block the execution of the remaining code until the operation has succeeded or failed, the corresponding methods of the callback API are asynchronous. You’ll pass a callback function to the method as the last argument.\n\nThe callback function is invoked with an object as the first argument if an error occurs. The remainder of the arguments to the callback function depend on the method.\n\nYou can also access the methods of the callback API by requiring like the synchronous API:\n\nThe promise-based API is asynchronous, like the callback API. It returns a promise, which you can manage via promise chaining or async/await.\n\nYou can access the promise-based API by requiring :\n\nWe used the CommonJS syntax to access the modules in the code snippets above. We’ll continue using the CommonJS syntax throughout this article. You can also use ES6 modules if you want.\n\nAccording to the Node documentation, the callback API of the built-in module is more performant than the promise-based API. Therefore, most examples in this article will use the callback API.\n\nRead and write to JSON files using third-party npm packages\n\nIn this section, we’ll look at the most popular third-party Node packages for reading and writing data in JSON format.\n\njsonfile is a popular npm package for reading and writing JSON files in Node. You can install it using the following command:\n\nIt is similar to the and methods of the built-in module, though jsonfile has some advantages over the built-in methods:\n• It serializes and deserializes JSON out of the box\n• It has a built-in utility for appending data to a JSON file\n\nYou can see the jsonfile package in action in the code snippet below:\n\nYou can also use promise chaining instead of passing a callback function like the example above:\n\nfs-extra is another popular Node package you can use to work with files. Though you can use this package for managing JSON files, it has methods whose functions extend beyond just reading and writing JSON files.\n\nAs its name suggests, fs-extra has all the functionalities provided by the module and more. According to the documentation, you can use the fs-extra package instead of the module.\n\nBefore using it, you need to first install fs-extra from npm:\n\nThe code below shows how you can read JSON files using the method of the fs-extra package. You can use a callback function, promise chaining, or async/await:\n\nThe code below illustrates how you can write JSON data using the method:\n\nJust like the module, fs-extra has both asynchronous and synchronous methods. You don’t need to stringify your JavaScript object before writing to a JSON file.\n\nSimilarly, you don’t need to parse to a JavaScript object after reading a JSON file. The module does it for you out of the box.\n\nbfj is another npm package you can use to handle data in JSON format. According to the documentation, it was created for managing large JSON datasets:\n\nTo install bfj from the npm package registry, run the following code:\n\nYou can read JSON data using the method, which is asynchronous and returns a promise.\n\n Assuming you have a file, you can use the following code to read it:\n\nSimilarly, you can use the method to write data to a JSON file:\n\nbfj was created purposely for handling large JSON data. It is also slow, so you should only use it if you are handling relatively large JSON datasets.\n\nAs explained above, the built-in functions of the synchronous and asynchronous APIs read the entire file into memory. This is inefficient in terms of both time and memory as you need to wait until the entire file is read into memory before processing. If you are dealing with a large JSON file, you may wait for a long time. Similarly, you may run out of memory while reading large JSON files.\n\nTo remedy these issues, you may want to use streams to read and process JSON data. Streams in Node.js enable you to handle data in chunks rather than loading the entire file into memory. This is useful for managing memory usage and improving performance when reading and writing large files. The stream-json package comes in handy when streaming large JSON data.\n\nThe method in Node.js’s fs (file system) module is used to read large files in chunks or streams, rather than loading the entire file into memory at once. This approach is particularly useful for efficiently handling large files, such as logs and JSON data.\n\nHere, we will look at how to use , but first, we need to install the package as seen below:\n\nIn the example below, we used with the package to read and parse . This reduces your application’s memory footprint and enables you to process chunks of data immediately after they become available:\n\nBest practices and common pitfalls when reading and writing JSON files\n• When dealing with file operations, it’s essential to first create a backup of datasets to avoid losing or corrupting the data\n• The method loads the entire JSON file into memory and caches it. For JSON files that change frequently, it’s best to avoid and use module functions instead\n• Error handling is essential, especially when using synchronous and promise-based APIs in conjunction with async/await because it prevents application failures\n• Using the parameter in improves JSON string readability, but it’s best avoided for network transmissions to reduce bundle size\n• Note that, according to Node.js documentation, the promise-based API is not thread-safe\n\nIt is not uncommon to encounter the error when serializing a JavaScript object using the function. This error occurs when you attempt to stringify a JavaScript object that references itself, as in the example below:\n\nThere is no straightforward fix to this error. However, you can manually find and replace the circular references with serializable values or use a third-party library like cycle.js, which was created by Douglas Crockford, the brain behind the JSON format.\n\nA fork of the library is maintained at the npm package registry as . You can install it like so:\n\nThen, you can use it in your application, as shown below:\n\nThe function of the package highlighted above will create a copy of the object, look for duplicate references, which might be circular references, and replace them with objects of the form .\n\nYou can then stringify and parse the resulting object without encountering the mentioned above. After that, you can store the resulting object on disk or transfer it over the network.\n\nYou can use the function of the package to get a copy of the original object.\n\nAs explained in the above sections, JSON is one of the most popular formats for data exchange over the internet. The Node runtime environment has the built-in module you can use to work with files in general. The module has methods that you can use to read and write to JSON files using the callback API, promise-based API, or synchronous API.\n\nBecause methods of the callback API are more performant than those of the promise-based API, you are better off using the callback API.\n\nIn addition to the built-in module, several popular third-party packages such as jsonfile, fs-extra, and bfj exist. They have additional utility functions that make working with JSON files a breeze. On the flip side, you should evaluate the limitations of adding third-party packages to your application."
    },
    {
        "link": "https://stackoverflow.com/questions/61110525/how-to-parse-a-file-with-array-of-json-objects-using-node-js",
        "document": "I have this project where I want to get the JSON data from a file with array of json objects with repetitive attributes:\n\nsome-file: (each object is in 1 line, for simplicity I formatted it)\n\nI would like to get some statistics for specific items, Country and AppVersion. How can I process it using NodeJs to produce this output:\n\nAlso, the input file 'some-file' is not a valid JSON file, any recommendation how to convert it to be valid (in code) ?"
    },
    {
        "link": "https://geeksforgeeks.org/how-to-read-and-write-json-file-using-node-js",
        "document": "How to read and write JSON file using Node ?\n\nNode JS is a free and versatile runtime environment that allows the execution of JavaScript code outside of web browsers. It finds extensive usage in creating APIs and microservices, catering to the needs of both small startups and large enterprises.\n\nJSON(JavaScript Object Notation) is a simple and text-based format for exchanging data between different applications. Similar to XML, it’s a commonly used method for web applications and APIs to communicate and share information.\n\nBelow are the different methods to read and write JSON files:\n\nNote: Reading and writing JSON files in Node.js is crucial for handling configuration and data storage.\n\nA straightforward way to read a JSON file in a Node JS file is by using the `require()` method to include it.\n\nExample: Create a users.json file in the same directory where index.js file present. Add following data to the users.json file and write the index.js file code:\n\nTo run the file using the command:\n\nAnother approach to read a file in Node JS is by utilizing the fs module. The fs module provides the file content as a string, requiring us to convert it into JSON format using the built-in method JSON.parse().\n\nWe can write data into a JSON file by using the nodejs fs module. We can use writeFile method to write data into a file.\n\nExample: We will add a new user to the existing JSON file, we have created in the previous example. This task will be completed in three steps:\n• None Read the file using one of the above methods.\n• None Write the new data to the file using\n\nOutput: Run the file again and you will see a message into the console:\n\nNow check your users.json file it will looks something like below:"
    },
    {
        "link": "https://stackoverflow.com/questions/39981192/node-js-load-json-array-from-file",
        "document": "Testing if a file exists before loading is not recommended and is the reason why is deprecated:\n\nUsing to check for the existence of a file before calling , or is not recommended. Doing so introduces a race condition, since other processes may change the file's state between the two calls. Instead, user code should open/read/write the file directly and handle the error raised if the file does not exist.\n\nAnd the way you use is just an equivalent to the deprecated .\n\nSo you should always assume that the file does not exits when reading it.\n\nFor a sync call you should write:\n\nAnd if you do it the async way then check the error argument of your callback function, to handle the case if the file does not exist:"
    },
    {
        "link": "https://restack.io/p/nested-json-structure-examples-answer-node-read-json-file-into-array",
        "document": "Learn how to read a JSON file into an array in Node.js using practical examples and clear explanations."
    }
]