[
    {
        "link": "https://docs.djangoproject.com/en/5.1/ref/models/fields",
        "document": "This document contains all the API references of including the field options and field types Django offers.\n\nThe following arguments are available to all field types. All are optional. If , Django will store empty values as in the database. Default is . Avoid using on string-based fields such as and . If a string-based field has , that means it has two possible values for “no data”: , and the empty string. In most cases, it’s redundant to have two possible values for “no data;” the Django convention is to use the empty string, not . One exception is when a has both and set. In this situation, is required to avoid unique constraint violations when saving multiple objects with blank values. For both string-based and non-string-based fields, you will also need to set if you wish to permit empty values in forms, as the parameter only affects database storage (see ). When using the Oracle database backend, the value will be stored to denote the empty string regardless of this attribute. If , the field is allowed to be blank. Default is . Note that this is different than . is purely database-related, whereas is validation-related. If a field has , form validation will allow entry of an empty value. If a field has , the field will be required. can be used with fields having , but this will require implementing on the model in order to programmatically supply any missing values. A mapping or iterable in the format described below to use as choices for this field. If choices are given, they’re enforced by model validation and the default form widget will be a select box with these choices instead of the standard text field. If a mapping is given, the key element is the actual value to be set on the model, and the second element is the human readable name. For example: You can also pass a sequence consisting itself of iterables of exactly two items (e.g. ). The first element in each tuple is the actual value to be set on the model, and the second element is the human-readable name. For example: can also be defined as a callable that expects no arguments and returns any of the formats described above. For example: Passing a callable for can be particularly handy when, for example, the choices are:\n• None the result of I/O-bound operations (which could potentially be cached), such as querying a table in the same or an external database, or accessing the choices from a static file.\n• None a list that is mostly stable but could vary from time to time or from project to project. Examples in this category are using third-party apps that provide a well-known inventory of values, such as currencies, countries, languages, time zones, etc. Support for mappings and callables was added. Generally, it’s best to define choices inside a model class, and to define a suitably-named constant for each value: Though you can define a choices list outside of a model class and then refer to it, defining the choices and names for each choice inside the model class keeps all of that information with the class that uses it, and helps reference the choices (e.g, will work anywhere that the model has been imported). You can also collect your available choices into named groups that can be used for organizational purposes: The key of the mapping is the name to apply to the group and the value is the choices inside that group, consisting of the field value and a human-readable name for an option. Grouped options may be combined with ungrouped options within a single mapping (such as the option in this example). You can also use a sequence, e.g. a list of 2-tuples: Note that choices can be any sequence object – not necessarily a list or tuple. This lets you construct choices dynamically. But if you find yourself hacking to be dynamic, you’re probably better off using a proper database table with a . is meant for static data that doesn’t change much, if ever. A new migration is created each time the order of changes. For each model field that has set, Django will normalize the choices to a list of 2-tuples and add a method to retrieve the human-readable name for the field’s current value. See in the database API documentation. Unless is set on the field along with a then a label containing will be rendered with the select box. To override this behavior, add a tuple to containing ; e.g. . Alternatively, you can use an empty string instead of where this makes sense - such as on a . In addition, Django provides enumeration types that you can subclass to define choices in a concise way: These work similar to from Python’s standard library, but with some modifications:\n• None Enum member values are a tuple of arguments to use when constructing the concrete data type. Django supports adding an extra string value to the end of this tuple to be used as the human-readable name, or . The can be a lazy translatable string. Thus, in most cases, the member value will be a 2-tuple. See below for an example of subclassing choices using a more complex data type. If a tuple is not provided, or the last item is not a (lazy) string, the is automatically generated from the member name.\n• None A property is added on values, to return the human-readable name.\n• None A number of custom properties are added to the enumeration classes – , , , and – to make it easier to access lists of those separate parts of the enumeration. These property names cannot be used as member names as they would conflict.\n• None The use of is enforced to ensure that values cannot be defined multiple times. This is unlikely to be expected in choices for a field. Note that using , , or to access or lookup enum members work as expected, as do the and properties on the members. If you don’t need to have the human-readable names translated, you can have them inferred from the member name (replacing underscores with spaces and using title-case): Since the case where the enum values need to be integers is extremely common, Django provides an class. For example: It is also possible to make use of the Enum Functional API with the caveat that labels are automatically generated as highlighted above: [(1, 'First'), (2, 'Second'), (3, 'Third')] If you require support for a concrete data type other than or , you can subclass and the required concrete data type, e.g. for use with : There are some additional caveats to be aware of:\n• None Because an enumeration with a concrete data type requires all values to match the type, overriding the blank label cannot be achieved by creating a member with a value of . Instead, set the attribute on the class: Support for using enumeration types directly in the was added. The name of the database column to use for this field. If this isn’t given, Django will use the field’s name. If your database column name is an SQL reserved word, or contains characters that aren’t allowed in Python variable names – notably, the hyphen – that’s OK. Django quotes column and table names behind the scenes. The database-computed default value for this field. This can be a literal value or a database function, such as : More complex expressions can be used, as long as they are made from literals and database functions: Database defaults cannot reference other fields or models. For example, this is invalid: If both and are set, will take precedence when creating instances in Python code. will still be set at the database level and will be used when inserting rows outside of the ORM or when adding a new field in a migration. If a field has a without a set and no value is assigned to the field, a object is returned as the field value on unsaved model instances. The actual value for the field is determined by the database when the model instance is saved. If , a database index will be created for this field. Use the option instead. Where possible, use the option instead. In nearly all cases, provides more functionality than . may be deprecated in the future. The name of the database tablespace to use for this field’s index, if this field is indexed. The default is the project’s setting, if set, or the of the model, if any. If the backend doesn’t support tablespaces for indexes, this option is ignored. The default value for the field. This can be a value or a callable object. If callable it will be called every time a new object is created. The default can’t be a mutable object (model instance, , , etc.), as a reference to the same instance of that object would be used as the default value in all new model instances. Instead, wrap the desired default in a callable. For example, if you want to specify a default for , use a function: s can’t be used for field options like because they can’t be serialized by migrations. See that documentation for other caveats. For fields like that map to model instances, defaults should be the value of the field they reference ( unless is set) instead of model instances. The default value is used when new model instances are created and a value isn’t provided for the field. When the field is a primary key, the default is also used when the field is set to . The default value can also be set at the database level with . If , the field will not be displayed in the admin or any other . It will also be skipped during model validation. Default is . The argument lets you override the default messages that the field will raise. Pass in a dictionary with keys matching the error messages you want to override. Error message keys include , , , , , and . Additional error message keys are specified for each field in the Field types section below. These error messages often don’t propagate to forms. See Considerations regarding model’s error_messages. Extra “help” text to be displayed with the form widget. It’s useful for documentation even if your field isn’t used on a form. Note that this value is not HTML-escaped in automatically-generated forms. This lets you include HTML in if you so desire. For example: \"Please use the following format: <em>YYYY-MM-DD</em>.\" Alternatively you can use plain text and to escape any HTML special characters. Ensure that you escape any help text that may come from untrusted users to avoid a cross-site scripting attack. If , this field is the primary key for the model. If you don’t specify for any field in your model, Django will automatically add a field to hold the primary key, so you don’t need to set on any of your fields unless you want to override the default primary-key behavior. The type of auto-created primary key fields can be specified per app in or globally in the setting. For more, see Automatic primary key fields. implies and . Only one primary key is allowed on an object. The primary key field is read-only. If you change the value of the primary key on an existing object and then save it, a new object will be created alongside the old one. The primary key field is set to when an object. If , this field must be unique throughout the table. This is enforced at the database level and by model validation. If you try to save a model with a duplicate value in a field, a will be raised by the model’s method. This option is valid on all field types except and . Note that when is , you don’t need to specify , because implies the creation of an index. Like , but requires the field to be unique with respect to the month. A human-readable name for the field. If the verbose name isn’t given, Django will automatically create it using the field’s attribute name, converting underscores to spaces. See Verbose field names. A list of validators to run for this field. See the validators documentation for more information."
    },
    {
        "link": "https://geeksforgeeks.org/imagefield-django-models",
        "document": "ImageField is a FileField with uploads restricted to image formats only. Before uploading files, one needs to specify a lot of settings so that file is securely saved and can be retrieved in a convenient manner. The default form widget for this field is a ClearableFileInput. In addition to the special attributes that are available for FileField, an ImageField also has height and width attributes.\n\n ImageField requires the Pillow library. To install the same run,\n\nThis attribute provides a way of setting the upload directory and file name, and can be set in two ways. In both cases, the value is passed to the Storage.save() method. If you specify a string value, it may contain strftime() formatting, which will be replaced by the date/time of the file upload (so that uploaded files don’t fill up the given directory). For example:\n\nIf you are using the default FileSystemStorage, the string value will be appended to your path to form the location on the local filesystem where uploaded files will be stored. If you are using different storage, check that storage’s documentation to see how it handles .\n\nmay also be a callable, such as a function. This will be called to obtain the upload path, including the filename. This callable must accept two arguments and return a Unix-style path (with forward slashes) to be passed along to the storage system. The two arguments are:\n\nName of a model field which will be auto-populated with the height of the image each time the model instance is saved.\n\nName of a model field which will be auto-populated with the width of the image each time the model instance is saved.\n\nIllustration of ImageField using an Example. Consider a project named having an app named .\n\nEnter the following code into file of geeks app."
    },
    {
        "link": "https://docs.djangoproject.com/en/5.1/topics/files",
        "document": "This document describes Django’s file access APIs for files such as those uploaded by a user. The lower level APIs are general enough that you could use them for other purposes. If you want to handle “static files” (JS, CSS, etc.), see How to manage static files (e.g. images, JavaScript, CSS).\n\nBy default, Django stores files locally, using the and settings. The examples below assume that you’re using these defaults.\n\nHowever, Django provides ways to write custom file storage systems that allow you to completely customize where and how Django stores files. The second half of this document describes how these storage systems work.\n\nWhen you use a or , Django provides a set of APIs you can use to deal with that file. Consider the following model, using an to store a photo: Any instance will have a attribute that you can use to get at the details of the attached photo: This object – in the example – is a object, which means it has all the methods and attributes described below. The file is saved as part of saving the model in the database, so the actual file name used on disk cannot be relied on until after the model has been saved. For example, you can change the file name by setting the file’s to a path relative to the file storage’s location ( if you are using the default ): # Move the file on the filesystem To save an existing file on disk to a : While non-image data attributes, such as , , and are available on the instance, the underlying image data cannot be used without reopening the image. For example:\n\nInternally, Django uses a instance any time it needs to represent a file. Most of the time you’ll use a that Django’s given you (i.e. a file attached to a model as above, or perhaps an uploaded file). If you need to construct a yourself, the easiest way is to create one using a Python built-in object: Now you can use any of the documented attributes and methods of the class. Be aware that files created in this way are not automatically closed. The following approach may be used to close files automatically: # Create a Python file object using open() and the with statement Closing files is especially important when accessing file fields in a loop over a large number of objects. If files are not manually closed after accessing them, the risk of running out of file descriptors may arise. This may lead to the following error:\n\nBehind the scenes, Django delegates decisions about how and where to store files to a file storage system. This is the object that actually understands things like file systems, opening and reading files, etc. Django’s default file storage is . If you don’t explicitly provide a storage system in the key of the setting, this is the one that will be used. See below for details of the built-in default file storage system, and see How to write a custom storage class for information on writing your own file storage system. Though most of the time you’ll want to use a object (which delegates to the proper storage for that file), you can use file storage systems directly. You can create an instance of some custom file storage class, or – often more useful – you can use the global default storage system: See File storage API for the file storage API. For example, the following code will store uploaded files under regardless of what your setting is: Custom storage systems work the same way: you can pass them in as the argument to a . You can use a callable as the parameter for or . This allows you to modify the used storage at runtime, selecting different storages for different environments, for example. Your callable will be evaluated when your models classes are loaded, and must return an instance of . In order to set a storage defined in the setting you can use :"
    },
    {
        "link": "https://stackoverflow.com/questions/66702640/django-model-fields-imagefield-and-filefield",
        "document": "Without any configuration in your settings django will in both cases, for and , save files into the base directory of the django project itself.\n\nDjango does not save file data directly into the database. A string representation of the relative path to the file/image will be stored in the model object's / column instead.\n\nIf you have a Model with a like so\n\nand you have configured your to include\n\nAn uploaded file such as would be uploaded to\n\nand the value stored in the column of the database table would be"
    },
    {
        "link": "https://docs.djangoproject.com/en/3.2/_modules/django/db/models/fields/files",
        "document": "[docs] # Older code may be expecting FileField values to be simple strings. # By overriding the == operator, it can remain backwards compatibility. # The standard File contains most of the necessary properties, but # FieldFiles can be instantiated without a name, so that needs to ' attribute has no file associated with it.\" # open() doesn't alter the file's contents, but it does reset the pointer # In addition to the standard File API, FieldFiles have extra methods # to further manipulate the underlying file, as well as update the [docs] # Save the object because it has changed, unless save is False [docs] # Only close the file if it's already open, which we know by the # FieldFile needs access to its associated model field, an instance and # the file's name. Everything else will be restored later, by The descriptor for the file attribute on the model instance. Return a FieldFile when accessed so you can write code like:: Assign a file object on assignment so you can do:: # This is slightly complicated, so worth an explanation. # instance.file`needs to ultimately return some instance of `File`, # probably a subclass. Additionally, this returned object needs to have # the FieldFile API so that users can easily do things like # instance.file.path and have that delegated to the file storage engine. # Easy enough if we're strict about assignment in __set__, but if you # peek below you can see that we're not. So depending on the current # value of the field we have to dynamically construct some sort of # The instance dict contains whatever was originally assigned # If this value is a string (instance.file = \"path/to/file\") or None # then we simply wrap it with the appropriate attribute class according # to the file field. [This is FieldFile for FileFields and # ImageFieldFile for ImageFields; it's also conceivable that user # subclasses might also want to subclass the attribute class]. This # object understands how to convert a path to a file, and also how to # Other types of files may be assigned as well, but they need to have # the FieldFile interface added to them. Thus, we wrap any other type of # File inside a FieldFile (well, the field's attr_class, which is # Finally, because of the (some would say boneheaded) way pickle works, # the underlying FieldFile might not actually itself have an associated # file. So we need to reset the details of the FieldFile in those cases. # Make sure that the instance is correct. # That was fun, wasn't it? [docs] # The class to wrap instance attributes in. Accessing the file object off # the instance will always return an instance of attr_class. # The descriptor to use for accessing the attribute off of the class. # Hold a reference to the callable for deconstruct(). .storage must be a subclass/instance of \"'primary_key' is not a valid argument for a 's 'upload_to' argument must be a relative path, not an \" # Need to convert File objects provided via a form to string for database insertion # Commit the file to storage prior to saving the model Apply (if callable) or prepend (if a string) upload_to to the filename, then delegate further processing of the name to the storage backend. Until the storage layer, all file paths are expected to be Unix style # Important: None means \"no change\", other false value means \"clear\" # This subtle distinction (rather than a more explicit marker) is # needed because we need to consume values that are also sane for a # regular (non Model-) Form to find in its cleaned_data dictionary. # This value will be converted to str and stored in the # database, so leaving False as-is is not acceptable. Just like the FileDescriptor, but for ImageFields. The only difference is assigning the width/height to the width_field/height_field, if appropriate. # To prevent recalculating image dimensions when we are instantiating # an object from the database (bug #11084), only update dimensions if # the field had a value before this assignment. Since the default # value for FileField subclasses is an instance of field.attr_class, # previous_file will only be None when we are called from # hooked up to the post_init signal handles the Model.__init__() cases. # Assignment happening outside of Model.__init__() will trigger the [docs] 'Cannot use ImageField because Pillow is not installed.' # after their corresponding image field don't stay cleared by This method is hooked up to model's post_init signal to update won't be updated if the dimensions fields are already populated. This avoids unnecessary recalculation when loading an object from the Dimensions can be forced to update with force=True, which is how # Nothing to update if the field doesn't have dimension fields or if # getattr will call the ImageFileDescriptor's __get__ method, which # coerces the assigned value into an instance of self.attr_class # Nothing to update if we have no file and not being forced to update. # When both dimension fields have values, we are most likely loading # data from the database or updating an image field that already had # an image stored. In the first case, we don't want to update the # dimension fields because we are already getting their values from the # database. In the second case, we do want to update the dimensions # fields and will skip this return because force will be True since we # file should be an instance of ImageFieldFile or should be None."
    },
    {
        "link": "https://realpython.com/image-processing-with-the-python-pillow-library",
        "document": "Python Pillow allows you to manipulate images and perform basic image processing tasks. As a fork of the Python Imaging Library (PIL), Pillow supports image formats like JPEG, PNG, and more, enabling you to read, edit, and save images. With Python Pillow, you can crop, resize, rotate, and apply filters to images, making it a versatile tool for image manipulation.\n\nPillow is often used for high-level image processing tasks and exploratory work. While not the fastest library, it offers a gentle learning curve and a comprehensive set of features for basic to intermediate image processing needs. You can enhance its capabilities by integrating it with NumPy for pixel-level manipulations and creating animations.\n\nBy the end of this tutorial, you’ll understand that:\n• Python Pillow is used for image manipulation and basic image processing.\n• Pillow offers reasonable speed for its intended use cases.\n• PIL is the original library, while Pillow is its actively maintained fork.\n• You read an image in Python Pillow using from the PIL module.\n• Pillow is used for its ease of use, versatility, and integration with NumPy.\n\nWith these insights, you’re ready to dive into the world of image processing with Python Pillow. You’ll use several images in this tutorial, which you can download from the tutorial’s image repository:\n\nWith these images in hand, you’re now ready to get started with Pillow.\n\nThe Python Pillow library is a fork of an older library called PIL. PIL stands for Python Imaging Library, and it’s the original library that enabled Python to deal with images. PIL was discontinued in 2011 and only supports Python 2. To use its developers’ own description, Pillow is the friendly PIL fork that kept the library alive and includes support for Python 3. There’s more than one module in Python to deal with images and perform image processing. If you want to deal with images directly by manipulating their pixels, then you can use NumPy and SciPy. Other popular libraries for image processing are OpenCV, scikit-image, and Mahotas. Some of these libraries are faster and more powerful than Pillow. However, Pillow remains an important tool for dealing with images. It provides image processing features that are similar to ones found in image processing software such as Photoshop. Pillow is often the preferred option for high-level image processing tasks that don’t require more advanced image processing expertise. It’s also often used for exploratory work when dealing with images. Pillow also has the advantage of being widely used by the Python community, and it doesn’t have the same steep learning curve as some of the other image processing libraries. You’ll need to install the library before you can use it. You can install Pillow using within a virtual environment: Now that you’ve installed the package, you’re ready to start familiarizing yourself with the Python Pillow library and perform basic manipulations of images. The Module and Class in Pillow The main class defined in Pillow is the class. When you read an image using Pillow, the image is stored in an object of type . For the code in this section, you’ll need the image file named (image credit), which you can find in the image repository for this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. You can place this image file in the project folder that you’re working in. When exploring images with Pillow, it’s best to use an interactive REPL environment. You’ll start by opening the image that you just downloaded: You might expect to import from Pillow instead of from PIL. You did install , after all, not . However, Pillow is a fork of the PIL library. Therefore, you’ll still need to use when importing into your code. You call the function to read the image from the file and to read the image into memory so that the file can now be closed. You use a statement to create a context manager to ensure the file is closed as soon as it’s no longer needed. In this example, the object is a JPEG image-specific type that’s a subclass of the class, as you confirm with the call to . Note that both the class and the module where the class is defined share the same name, . You can display the image using : The method saves the image as a temporary file and displays it using your operating system’s native software for dealing with images. When you run the code above, you’ll see the following image displayed: On some systems, calling will block the REPL until you close the image. This depends on the operating system and the default image viewing software that you’re using. You’ll need to be familiar with three key properties when dealing with images in the Python Pillow library. You can explore these using the class attributes , , and : The format of an image shows what type of image you’re dealing with. In this case, the format of the image is . The size shows the width and height of the image in pixels. The mode of this image is . You’ll learn more about modes shortly. Often, you may need to crop and resize images. The class has two methods that you can use to perform these operations, and : The argument to must be a 4-tuple that defines the left, upper, right, and bottom edges of the region that you wish to crop. The coordinate system used in Pillow assigns the coordinates (0, 0) to the pixel in the upper-left corner. This is the same coordinate system that’s usually used for two-dimensional arrays. The 4-tuple represents the following section of the image: The new image that returns in the code above has a size of pixels. The cropped image shows only one of the buildings from the original picture: In the code above, you also change the resolution of the cropped image using , which needs a tuple as a required argument. The tuple that you use as an argument defines the new width and height of the image in pixels. In the example above, you’re setting the new width and height to a quarter of their original values using the floor division operator ( ) and the attributes and . The final call to displays the cropped and resized image: There are additional optional parameters that you can use with to control how the image is resampled. Alternatively, you can achieve similar scaling using : The argument determines the factor by which you scale the image down. If you prefer to set a maximum size rather than a scaling factor, then you can use . The size of the thumbnail will be smaller than or equal to the size that you set. Note: The method changes the object in place and doesn’t return a new object. However, , , and all return a new object. Not all methods in the Pillow library behave in the same way. Once you’re happy with your returned image, you can save any of the objects to file using : Once you call the method, it creates the image files in your project folder. In this example, one of the images is a JPEG image and the other is a PNG image. The extension that you use as a filname automatically determines the file format, or you can specify the format as an additional optional argument. You can manipulate the image beyond cropping and resizing. Another common requirement is to rotate or flip the image. You can use the method for some transformations. Go ahead and carry on with the same REPL session that you started in the previous section: This code displays the following image: There are seven options that you can pass as arguments to :\n• : Flips the image left to right, resulting in a mirror image\n• : Rotates the image by 270 degrees counterclockwise, which is the same as 90 degrees clockwise\n• : Transposes the rows and columns using the top-left pixel as the origin, with the top-left pixel being the same in the transposed image as in the original image\n• : Transposes the rows and columns using the bottom-left pixel as the origin, with the bottom-left pixel being the one that remains fixed between the original and modified versions All the rotation options above define rotations in steps of 90 degrees. If you need to rotate an image by another angle, then you can use : This method call rotates the image by 45 degrees counterclockwise, giving the following image: The object returned is the same size as the original . Therefore, the corners of the image are missing in this display. You can change this behavior using the named parameter: This method returns a larger image that fully contains the rotated image: You can customize the rotation further with additional optional parameters. You can now change the size and orientation of an image. In the next section, you’ll learn about different types of images in the Python Pillow library. Bands and Modes of an Image in the Python Pillow Library An image is a two-dimensional array of pixels, where each pixel corresponds to a color. Each pixel can be represented by one or more values. For example, in an RGB image, each pixel is represented by three values corresponding to the red, green, and blue values for that pixel. Therefore, the object for an RBG image contains three bands, one for each color. An RGB image of size pixels is represented by a array of values. RGBA images also include the alpha value, which contains information about the transparency for each pixel. An RGBA image has four bands, one for each of the colors and a fourth one containing the alpha values. Each band has the same dimensions as the image dimensions. Therefore, an RGBA image of size pixels is represented by a array of values. The mode of an image describes what type of image you’re working with. Pillow supports most standard modes, including black-and-white (binary), grayscale, RGB, RGBA, and CMYK. You can see the full list of supported modes in the Pillow documentation on modes. You can find out how many bands are in an object using the method, and you can convert between modes using . Now you’ll use the image named (image credit) from the image repository for this tutorial: This image’s mode is also RGB. You can convert this image into other modes. This code uses the same REPL session that you started in the previous sections: You call twice to convert the RGB image into a CMYK and a grayscale version. The CMYK image looks similar to the original image but is encoded using the mode that’s common for printed material rather than digital displays. The conversion to grayscale gives the following output: The outputs from the calls to confirm that there are three bands in the RGB image, four bands in the CMYK image, and one band in the grayscale image. You can separate an image into its bands using and combine separate bands back into an object using . When you use , the method returns all the bands as separate objects. You can confirm this by displaying the string representation of one of the objects returned: The mode of the object that returns is , indicating this is a grayscale image, or an image that only displays the luminance values of each pixel. Now, you can create three new RGB images showing the red, green, and blue channels separately using , which is a function in the module: The first argument in determines the mode of the image that you want to create. The second argument contains the individual bands that you want to merge into a single image. The red band alone, stored in the variable , is a grayscale image with mode L. To create the image showing only the red channel, you merge the red band from the original image with green and blue bands that only contain zeros. To create a band containing zeros everywhere, you use the method. This method needs a function as an argument. The function that you use determines how each point transforms. In this case, you use a function to map each point to . When you merge the red band with green and blue bands containing zeros, you get an RGB image called . Therefore, the RGB image that you create only has non-zero values in the red channel, but because it’s still an RGB image, it’ll display in color. You also repeat a similar process to obtain and , which contain RGB images with the green and blue channels from the original image. The code displays the following three images: The red image contains a strong signal in the pixels that represent the strawberry, because these pixels are mostly red. The green and blue channels show these pixels as dark because they have small values. The exceptions are those pixels that represent the reflection of the light on the surface of the strawberry as these pixels are nearly white. Creating the side-by-side displays shown in this tutorialShow/Hide In this tutorial, when there are several images output in the code that need to be displayed next to one another to make comparisons easier, the images are displayed side by side rather than as separate images. These side-by-side displays were created using Pillow itself. You can use the function , shown below, to merge several images into a single display: The first parameter in uses the unpacking operator ( ) so that any number of objects of type can be used as input arguments. The keyword parameter can be set to if you want to tile the images vertically rather than horizontally. This function assumes that all images have the same size. The overall size of the display is calculated from the size of the images and the number of images used. You then create a new object with the same mode as the original images and with the size of the overal display. The loop pastes the images that you input when you call the function into the final display. The function returns the final object containing all the images side by side. The image in the main article showing the three color channels for the strawberry image was obtained by calling the function as follows: This function was used to generate all the displays that show more than one image in this tutorial.\n\nYou’ve learned how to crop and rotate images, resize them, and extract color bands from color images. However, none of the actions that you’ve taken so far have made any changes to the content of the image. In this section, you’ll learn about image processing features in the Python Pillow library. You’ll use the module in Pillow. One of the methods that’s used in image processing is image convolution using kernels. The aim of this tutorial is not to give a detailed explanation of image processing theory. If you’re interested in the science of image processing, one of the best resources that you can use is Digital Image Processing by Gonzalez and Woods. In this section, you’ll learn the basics of how you can use convolution kernels to perform image processing. But what’s a convolution kernel? A kernel is a matrix: You can consider a simple image to understand the process of convolution using kernels. The image has a size of pixels and contains a vertical line and a dot. The line is four pixels wide, and the dot consists of a pixel square. The image below is enlarged for display purposes: You can place the kernel anywhere on the image and use the location of the kernel’s central cell as a reference. The diagram below is a representation of the top-left portion of the image: The elements in this diagram represent different aspects of the image and the kernel:\n• The white squares represent pixels in the image that have a value of .\n• The red squares represent pixels in the image that have a value of . These make up the dot in the image shown above.\n• Each purple region represents the kernel. This kernel consists of a region, and each cell in the kernel has a value of . The diagram shows the kernel in three different positions labeled 1, 2, and 3. A new image can be created as a result of the convolution of the image with the kernel. You can understand the convolution process through the following steps:\n• Locate kernel: Consider one of the kernel locations and look at the image pixels covered by the kernel’s nine cells.\n• Multiply kernel and pixel values: Multiply the values in each of the kernel’s cells with the corresponding pixel values in the image. You’ll have nine values from the nine multiplications.\n• Sum results of multiplications: Add those nine values together. The result will be the value of the pixel in the new image that has the same coordinates as the kernel’s center pixel.\n• Repeat for all pixels: Repeat the process for every pixel in the image, moving the kernel each time so that the kernel’s central cell corresponds to a different image pixel each time. You can see this process with the three kernel positions labeled 1, 2, and 3 in diagram above. Consider the kernel position labeled 1. The position of this kernel is , which is the position of its central cell because it’s in the fourth row (index = ) and the third column (index = ). Each image pixel in the region covered by the kernel has a value of zero. Therefore, all the multiplications from step 2 will be zero, and their addition will also be zero. The new image will have a value of zero at pixel . The scenario is different for the other kernel positions shown. Next, consider the kernel labeled 2, located at . One of the image pixels overlapping this is not zero. The multiplication of this pixel value with the kernel value will give . The eight remaining multiplications are still zero because the image pixels are zero. Therefore, the value of the pixel at position in the new image will be . The third kernel position illustrated above is at . There are four non-zero image pixels overlapping with this kernel. Each one has a value of , so the multiplication result will again be for each of those pixel positions. The overall result for this kernel position is . The new image will have this value at . The diagram and the discussion above only consider three kernel positions. The convolution process repeats this process for every possible kernel position in the image. This gives a value for each pixel position in the new image. The result of the convolution is shown on the right in the following image, with the original image on the left: The kernel that you used is a box blur kernel. The factor of is there so that the overall weighting of the kernel is . The result of the convolution is a blurred version of the original image. There are other kernels that perform different functions, including different blurring methods, edge detection, sharpening, and more. The Python Pillow library has several built-in kernels and functions that’ll perform the convolution described above. You don’t need to understand the math of filtering through convolution to use these filters, but it always helps to know what’s happening behind the scenes when using these tools. The next sections will look at the kernels and image filtering capabilities available in the module in Pillow. You’ll return to using the image of the buildings that you used at the beginning of this tutorial. You can start a new REPL session for this section: In addition to , you also import the module from Pillow. You can use the method to apply filtering to the image. This method needs a convolution kernel as its argument, and you can use one of the several kernels available in the module in Pillow. The first set of filters that you’ll learn about deal with blurring, sharpening, and smoothing an image. You can blur the image using the predefined filter: The displayed image is a blurred version of the original one. You can zoom in to observe the difference in more detail using and then display the images again using : The two cropped images show the difference between the two versions: You can customize the type and amount of blurring that you need using or : You can see the three blurred images below, shown in the same order as in the code above: The filter is similar to the one described in the previous section introducing convolution kernels. The argument is the radius of the box blur filter. In the earlier section discussing kernels, the box blur filter that you used was a filter. This means that it had a radius of , because the filter extends by one pixel from the center. The blurred images show that the box blur filter with a radius of produces an image that’s more blurred than the image generated by the box blur filter with radius . You can also use the filter, which uses a Gaussian blur kernel. The Gaussian kernel puts more weight on the pixels at the center of the kernel than those at the edges, and this leads to smoother blurring than what’s obtained with the box blur. For this reason, Gaussian blurring can give better results in many cases. What if you want to sharpen an image? In that case, you can use the filter and compare the result with the original image: You’re comparing a cropped version of both images showing a small portion of the building. The sharpened image is on the right: Perhaps instead of sharpening an image, you need to smooth it. You can achieve this by passing as an argument for : Below, you can see the original image on the left and the smoothed image on the right: You’ll see an application of the smooth filter in the next section, in which you’ll learn about more filters in the module. These filters act on the edges of objects in the image. When you look at an image, it’s relatively easy to determine the edges of objects within that image. It’s also possible for an algorithm to detect edges automatically using edge detection kernels. The module in Pillow has a predefined kernel to achieve this. In this section, you’ll use the image of the buildings again and convert it to grayscale before you apply the edge detection filter. You can carry on with the REPL session from the previous section: The result is an image showing the edges from the original image: This filter identifies the edges in the image. You can obtain a better outcome by applying the filter before finding the edges: You can see a comparison of the original grayscale image and the two edge detection results below. The version with smoothing before edge detection is shown at the bottom: You can also enhance the edges of the original image with the filter: You used the smoothed version of the grayscale image to enhance the edges. A portion of the original grayscale image and the image with the edges enhanced are shown side by side below. The image with edge enhancement is on the right: Another predefined filter in that deals with object edges is . You can pass it as an argument to as you did with the other filters in this section: You’re using the smoothed, grayscale version as a starting point for this filter. You can see the embossed image below, which shows a different effect using the edges in the image: In this section, you’ve learned about several filters available in the module that you can apply to images. There are other filters that you can use to process images. You can see a list of all the filters available in the documentation.\n\nImage Segmentation and Superimposition: An Example In this section, you’ll use the image files named (image credit) and (image credit), which you can find in the image repository for this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. You can use the Python Pillow library to extract the cat from the first image and place it on the floor of the monastery courtyard. You’ll use a number of image processing techniques to achieve this. You’ll start by working on . You’ll need to remove the picture of the cat from the background using image segmentation techniques. In this example, you’ll segment the image using thresholding techniques. First, you can crop the image to a smaller one to remove some of the background. You can start a new REPL session for this project: The cropped image contains the cat and some of the background that’s too close to the cat for you to crop it: Each pixel in a color image is represented digitally by three numbers corresponding to the red, green, and blue values of that pixel. Thresholding is the process of converting all the pixels to either the maximum or minimum value depending on whether they’re higher or lower than a certain number. It’s easier to do this on a grayscale image: You achieve thresholding by calling to convert each pixel in the grayscale image into either or . The conversion depends on whether the value in the grayscale image is greater or smaller than the threshold value. The threshold value in this example is . The figure below shows the grayscale image and the result from the thresholding process: In this example, all the points in the grayscale image that had a pixel value greater than are converted to white, and all other pixels are changed to black. You can change the sensitivity of the thresholding process by varying the threshold value. Thresholding can be used to segment images when the object to segment is distinct from the background. You can achieve better results with versions of the original image that have higher contrast. In this example, you can achieve higher contrast by thresholding the blue channel of the original image rather than the grayscale image, because the dominant colors in the background are brown and green colors, which have a weak blue component. You can extract the red, green, and blue channels from the color image as you did earlier: The red, green, and blue channels are shown below, from left to right. All three are displayed as grayscale images: The blue channel has a higher contrast between the pixels representing the cat and those representing the background. You can use the blue channel image to threshold: You use a threshold value of in this example. You also convert the image into a binary mode using as an argument to . The pixels in a binary image can only have the values of or . Note: When dealing with certain image formats, such as JPEG, that rely on lossy compression, the images may vary slightly depending on which JPEG decoders you’re using. Different operating systems often come with different default JPEG decoders. Therefore, the results that you get when processing images may vary depending on the operating system and JPEG decoder that you’re using. You may need to slightly adjust the threshold value if your results do not match the ones shown in this tutorial. The result of thresholding is the following: You can identify the cat in this black-and-white image. However, you’d like to have an image in which all the pixels that correspond to the cat are white and all other pixels are black. In this image, you still have black regions in the area which corresponds to the cat, such as where the eyes, nose and mouth are, and you also still have white pixels elsewhere in the image. You can use the image processing techniques called erosion and dilation to create a better mask that represents the cat. You’ll learn about these two techniques in the next section. You can look at the image file called , which you can download from the repository linked to this tutorial: The left-hand side of this binary image shows a white dot on a black background, while the right-hand side shows a black hole in a solid white section. Erosion is the process of removing white pixels from the boundaries in an image. You can achieve this in a binary image by using as an argument for the method. This filter replaces the value of a pixel with the minimum value of the nine pixels in the array centered around the pixel. In a binary image, this means that a pixel will have the value of zero if any of its neighboring pixels are zero. You can see the effect of erosion by applying several times to the image. You should continue with the same REPL session as in the previous section: You’ve applied the filter three times using a loop. This code gives the following output: The dot has shrunk but the hole has grown as a result of erosion. Dilation is the opposite process to erosion. White pixels are added to the boundaries in a binary image. You can achieve dilation by using , which converts a pixel to white if any of its neighbors are white. You can apply dilation to the same image containing a dot and a hole, which you can open and load again: The dot has now grown bigger, and the hole has shrunk: You can use erosion and dilation together to fill in holes and remove small objects from a binary image. Using the image with a dot and hole, you can perform ten erosion cycles to remove the dot, followed by ten dilation cycles to restore the hole to its original size: You perform ten erosion cycles with the first loop. The image at this stage is the following: The dot has disappeared, and the hole is larger than it was in the original image. The second loop performs ten dilation cycles, which return the hole to its original size: However, the dot is no longer present in the image. The erosions and dilations have modified the image to keep the hole but remove the dot. The number of erosions and dilations needed depends on the image and what you want to achieve. Often, you’ll need to find the right combination through trial and error. You can define functions to perform several cycles of erosion and dilation: These functions make it easier to experiment with erosion and dilation for an image. You’ll use these functions in the next section as you continue working on placing the cat into the monastery. You can use a sequence of erosions and dilations on the threshold image that you obtained earlier to remove parts of the mask that don’t represent the cat and to fill in any gaps in the region containing the cat. Once you’ve experimented with erosion and dilation, you’ll be able to use educated guesses in a trial-and-error process to find the best combination of erosions and dilations to achieve the ideal mask. Starting with the image , which you obtained earlier, you can start with a series of erosions to remove the white pixels that represent the background in the original image. You should continue working in the same REPL session as in the previous sections: The eroded threshold image no longer contains white pixels representing the background of the image: However, the remaining mask is smaller than the overall outline of the cat and has holes and gaps within it. You can perform dilations to fill the gaps: The fifty-eight cycles of dilation filled all the holes in the mask to give the following image: However, this mask is too big. You can therefore finish the process with a series of erosions: The result is a mask that you can use to segment the image of the cat: You can avoid the sharp edges of a binary mask by blurring this mask. You’ll have to convert it from a binary image into a grayscale image first: The filter returns the following mask: The mask now looks like a cat! Now you’re ready to extract the image of the cat from its background: First, you create a blank image with the same size as . You create a new object from by using and setting all values to zero. Next, you use the function in to create an image made up from both and using to determine which parts of each image are used. The composite image is shown below: You’ve segmented the image of the cat and extracted the cat from its background. You can go a step further and paste the segmented image of the cat into the image of the monastery courtyard from the image repository for this tutorial: You’ve used to paste an image onto another one. This method can be used with three arguments:\n• The first argument is the image that you want to paste in. You’re resizing the image to one-fifth of its size using the integer division operator ( ).\n• The second argument is the location in the main image where you want to paste the second picture. The tuple includes the coordinates within the main image where you want to place the top-left corner of the image that you’re pasting in.\n• The third argument provides the mask that you wish to use if you don’t want to paste the entire image. You’ve used the mask that you obtained from the process of thresholding, erosion, and dilation to paste the cat without its background. The output is the following image: You’ve segmented the cat from one image and placed it into another image to show the cat sitting quietly in the monastery courtyard rather than in the field where it was sitting in the original image. Your final task in this example is to add the Real Python logo as a watermark to the image. You can get the image file with the Real Python logo from the repository accompanying this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. You should continue working in the same REPL session: This is the full-size logo in color: You can change the image to grayscale and threshold it using to transform it into a black-and-white image. You also reduce its size and transform it into a contour image: The output shows the contour from the Real Python logo. The contour is ideal for using as a watermark on your image: To use this as a watermark, you’ll need to reverse the colors so that the background is black and only the outline that you want to keep is white. You can achieve this using again: You’ve converted the pixels that had a value of and assigned them the value , converting them from white to black pixels. You set the remaining pixels to white. The reversed outline logo is shown below: Your final step is to paste this outline onto the image of the cat sitting in the monastery courtyard. You can use again: The first argument in indicates the image that you wish to paste in, and the third argument represents the mask. In this case, you’re using the same image as a mask because the image is a binary image. The second argument provides the top-left coordinates of the region where you want to paste the image. The watermark has a rectangular outline, which is a result of the contour filter that you used earlier. If you prefer to remove this outline, you can crop the image using . This is an exercise that you can try on your own.\n\nPillow has an extensive selection of built-in functions and filters. However, there are times when you need to go further and manipulate images beyond the features that are already available in Pillow. You can manipulate the image further with the help of NumPy. NumPy is a very popular Python library for dealing with numeric arrays, and it’s an ideal tool to use with Pillow. You can learn more about NumPy in NumPy Tutorial: Your First Steps Into Data Science in Python. When you convert an image into a NumPy array, you can perform any transformations that you require directly on the pixels in the array. Once you’ve completed your processing in NumPy, you can convert the array back into an object using Pillow. You need to install NumPy for this section: Now that you’ve installed NumPy, you’re ready to use Pillow and NumPy to spot the difference between two images. Using NumPy to Subtract Images From Each Other See if you can spot the differences between the following two images: This isn’t a hard one! However, you decide to cheat and write a Python program to solve the puzzle for you. You can download the image files and (image credit) from the repository accompanying this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. Your first step is to read the images using Pillow and convert them to NumPy arrays: Since and are objects of type , you can manipulate them using all the tools that you have available in NumPy. You can subtract one array from the other to show the pixels that differ between the two images: When you subtract an array from another one of the same size, the result is another array with the same shape as the original arrays. You can convert this array into an image using in Pillow: The result of subtracting one NumPy array from another and converting into a Pillow is the difference image shown below: The difference image only shows three regions from the original image. These regions highlight the differences between the two images. You can also see some noise surrounding the cloud and the fence, which is due to small changes in the original JPEG compression in the region surrounding these items. You can go further and create images from scratch using NumPy and Pillow. You can start by creating a grayscale image. In this example, you’ll create a simple image containing a square, but you can create more elaborate images in the same way: You create an array of size containing zeros everywhere. Next, you set the value of a set of pixels at the center of the array to . You can index NumPy arrays using both rows and columns. In this example, the first slice, , represents the rows to . The second slice, , which follows the comma, represents the columns to . You can use to convert the NumPy array into an object of type . The output from the code above is shown below: You’ve created a grayscale image containing a square. The mode of the image is inferred automatically when you use . In this case, mode is used, which corresponds to an image with 32-bit floating-point pixels. You can convert this to a simpler grayscale image with 8-bit pixels if you wish: You can also go further and create a color image. You can repeat the process above to create three images, one corresponding to the red channel, another to the green, and a final one corresponding to the blue channel: You create an object from each NumPy array and convert the images to mode , which represents grayscale. Now, you can combine these three separate images into one RGB image using : The first argument in is the mode of the image output. The second argument is a sequence with the individual single-band images. This code creates the following image: You’ve combined the separate bands into an RGB color image. In the next section, you’ll go a step further and create a GIF animation using NumPy and Pillow. In the previous section, you created a color image containing three overlapping squares of different colors. In this section, you’ll create an animation showing those three squares merging into a single white square. You’ll create several versions of the images containing three squares, and the location of the squares will vary slightly between successive images: You create an empty list called , which you’ll use to store the various images that you generate. Within the loop, you create NumPy arrays for the red, green, and blue channels, as you did in the previous section. The array containing the green layer is always the same and represents a square in the center of the image. The red square starts in a position displaced to the top-left of the center. In each successive frame, the red square moves closer to the center until it reaches the center in the final iteration of the loop. The blue square is initially shifted toward the bottom-right then moves towards the center with each iteration. Note that in this example, you’re iterating over , which means that the variable increases in steps of two. You learned earlier that you can save an object to file using . You can use the same function to save to a GIF file that includes a sequence of images. You call on the first image in the sequence, which is the first image that you stored in the list : The first argument in is the filename for the file that you want to save. The extension in the filename tells what file format it needs to output. You also include two keyword arguments in :\n• ensures that all the images in the sequence are saved, and not just the first one.\n• allows you to append the remaining images in the sequence to the GIF file. This code saves to file, and you can then open the GIF file with any image software. The GIF should loop by default, but on some systems you’ll need to add the keyword argument to to make sure the GIF loops. The animation that you get is the following one: The three squares with different colors merge into a single white square. Can you create your own animation using different shapes and different colors?"
    },
    {
        "link": "https://stackoverflow.com/questions/21511169/django-form-validate-pil-image-as-imagefield",
        "document": "Say I have a model and form that support file uploads:\n\nWhen POSTing from the actual browser returns , so we can call\n\nWhen I go to use to take a (specifically a ), is because says:\n\nHere's what I'm trying to do to save the form:\n\nSee what I'm doing wrong that's causing to be ?\n\nEdit: I think this issue is more about coercing to something 's parameter accepts."
    },
    {
        "link": "https://transloadit.com/devtips/creating-a-simple-image-processing-api-with-python-and-flask",
        "document": "Image processing APIs enable developers to programmatically manipulate and transform images. In this tutorial, we'll build a straightforward yet functional image processing API using Python and Flask, demonstrating how to handle common operations like resizing and format conversion. This demo also showcases robust error handling, rate limiting, and secure file validation practices.\n\nAn image processing API provides endpoints that accept image files as input, perform specified operations, and return the processed images. These APIs are essential for applications that need to handle user-uploaded images, generate thumbnails, or convert between different image formats.\n\nBegin by setting up your development environment:\n• Create a new directory for your project and a requirements.txt file:\n• Add the following dependencies to requirements.txt:\n\nCreate a file named with the following content:\n\nCreate a helper function to load and validate images. This function checks both the file extension and its MIME type, ensuring only valid image files are processed:\n\nAdd an endpoint for resizing images with appropriate error handling and validation:\n\nInclude another endpoint to handle image format conversion. This endpoint accepts a target format, converts the image accordingly, and handles any potential errors:\n\nUse cURL to test the endpoints. The following examples demonstrate how to call the resizing and conversion endpoints:\n\nFor production, comprehensive testing is essential. Create a file named with the following tests to validate the API's functionality:\n\nFor production deployment, use Gunicorn along with proper configuration. Create a Gunicorn configuration file named :\n\nWe have built a secure, efficient, and scalable image processing API using Python, Flask, and Pillow. The API incorporates essential features like file validation, error handling, rate limiting, and CORS support. To extend this solution, you might consider options such as image compression, user authentication, batch processing, cloud storage integration, or metadata extraction.\n\nFor a comprehensive solution with advanced file processing capabilities, consider exploring Transloadit, which offers a robust platform for handling and transforming files in your applications."
    },
    {
        "link": "https://stackoverflow.com/questions/15080121/how-to-use-pillow-with-django",
        "document": "The problem is that imports now work slightly differently with Pillow vs PIL. The differences are described here: http://pillow.readthedocs.org/en/latest/porting-pil-to-pillow.html\n\nDjango has also now been changed to prefer Pillow over PIL, via this ticket (https://code.djangoproject.com/ticket/19934)\n\nThis commit is present in the new Django 1.6a1 release, so the new behaviour will be present in the Django 1.6 release. For now, however, it appears that you can use a new library (initially released May 20, 2013) called Pillow-PIL which will provide a compatibility layer. This can be easily installed with pip via:"
    },
    {
        "link": "https://auth0.com/blog/image-processing-in-python-with-pillow",
        "document": "If you’re building your application with Python and it needs to process images, you have a choice of libraries, including OpenCV, scikit-image, Python Imaging Library and Pillow.\n\nWe won't debate which library is the best here; they all have their merits. This article will focus on Pillow, a powerful library that provides a wide array of image processing features and is simple to use. To make the tutorial more interactive and easy to follow, we'll run all the code using Jupyter Notebooks.\n\nPillow is a fork of the Python Imaging Library (PIL). PIL is a library that offers several standard functions for manipulating images. It's a powerful library but hasn't been updated since 2009 and doesn't support Python 3.\n\nPillow builds on PIL, adding more features and support for Python 3. It supports a range of image file formats such as PNG, JPEG, PPM, GIF, TIFF, and BMP. We'll see how to perform various operations on images using this library, such as cropping, resizing, adding text to images, rotating, greyscaling, and more.\n\nYou can follow along by downloading our sample Jupyter notebook from GitHub, or you can create your own project and install the following packages:\n\nTo follow along, you can download the images (courtesy of Unsplash) that we'll use in the article.\n\nAll the code examples will assume the required images are in the same directory as your Jupyter Notebook file.\n\nYou’ll find the code for all the Pillow exercise in this article in a Jupyter Notebook in this GitHub repository.\n\nOf all the classes in Pillow, you’ll probably use\n\nthe most. It's defined in themodule and is the class that represents images and provides methods for loading or creating them, processing them, and displaying them.\n\nTo load an image from a file, use the\n\nfunction in themodule, which takes thefor the image as its argument:\n\nRun the cell. Here’s what it should look like in Jupyter Notebook:\n\nIf you’re using a command-line Python REPL (or something similar) instead of a Jupyter Notebook, you’ll need to call on an external viewer application to see the image. You can do this with\n\nGetting information about an image\n\nlaunches your system’s external viewer, using it to display the image. On Windows, it will usually launch Paint; on macOS, it will launch Preview; and on Linux and other Unix-based systems, it will launch xv.\n\nYou can get some information about an\n\nobject using its attributes. Enter the following into a new cell and run it:\n\nFor more on what you can do with the\n\n’smethod takes a two-integer tuple argument representing the width and height of the new resized image.\n\nHere’s an example that takes the image you loaded and resizes both its width and height to 300 pixels — enter it into a new cell and run it:\n\ndoesn't modify the image but returns anotherinstance with the new dimensions.\n\nchanges the image’s dimensions to the ones you provide, it doesn’t preserve the image’s aspect ratio unless you purposely do so. The resulting image may end up looking stretched or compressed, which may not be the effect you want. You can see this in the newly-created image from the code above; it looks a bit squished horizontally:\n\nIf you want to resize images and keep their aspect ratios, use\n\n’smethod instead. Liketakes a two-integer tuple argument. However, the values in the tuple represent the maximum x- and y-sizes allowed while also preserving the image’s aspect ratio.\n\nEnter the code below into a new cell and run it:\n\n, themethod does not create a newinstance. Instead, it modifies the original. That’s why the code above first makes a copy of the image.\n\nThe code above resize the image to 300 × 200 and preserves the original’s aspect ratio:\n\nAnother significant difference between the\n\nandmethods is thatenalrges an image if given parameters that are larger than the original image, whiledoesn't.\n\nFor example, given an image of size 400 × 200, a call to\n\nwill create a larger-sized image 1200 pixels wide and 600 pixels tall, along with the expected loss of sharpness. A similar call tousing the original image will not enlarge the image since themethod cannot expand an image beyond either of its original dimensions.\n\nThe rise of retrocomputing and retrogaming has created a lot of interest in old-school “pixelated” graphics. You can use a combination of\n\n’sandmethods to turn a modern, high-resolution image into a “retro” one like the one below:\n\nHere’s the code that produces this effect:\n\nThe code above takes advantage of the\n\nmethod’s optionalparameter, which specifies how to draw pixels when resizing the image. When making an image larger, the “nearest neighbor” resampling method creates a “retro” pixel effect.\n\nclass provides themethod for quick image flipping.takes the following arguments:\n\nHere’s how you would create a horizontal mirror image of the original:\n\nThe resulting image can be seen below. Notice that the puffin with the open beak is now on the left side of the photo:\n\narguments rotate the image counterclockwise 90, 180, and 270 degrees, respectively. The following rotates the image 180 degrees:\n\nTransposing an image means mirroring it along the diagonal line that runs from the top left to the bottom right, while tranversing it means mirroring it along the diagonal line running from the bottom left to the top right. This is yet another case where showing is better than telling, so let’s make the code do that.\n\nYou can rotate images with Pillow using\n\n’smethod. This takes an integer or float argument representing the degrees to rotate an image (positive for counterclockwise, negative for clockwise) and returns a newobject for the rotated image.\n\nBy default, the rotated image keeps the dimensions of the original image. This means that for angles other than multiples of 180, the image will be cut and/or padded to fit the original dimensions. Consider this code, which rotates an image 90 degrees counterclockwise:\n\nNotice that the image has been “clipped” to fit the original height, and its sides have been padded with black background (on some operating systems, the padding will be made of transparent pixels) to fit the original width.\n\nThe example below, where the original image is rotated 18 degrees counterclockwise, shows this “clipping” effect more clearly.\n\nThe resulting image is shown below:\n\nTo expand the dimensions of the rotated image to fit the entire view, you pass a second argument to\n\nNow the contents of the image will be fully visible, and the dimensions of the image will have increased to account for this:\n\n’smethod to create a new image by cropping a section from an existing one. This method takes a 4-tuple that defines the position and size of the cropped region, as shown in the method call example below:\n\nPillow’s coordinate system starts with (0, 0) in the upper left corner, with x increasing from left to right and y increasing from top to bottom:\n\nThe cropped section includes the left column and the upper row of pixels and goes up to — but doesn't include — the right column and bottom row of pixels. This is better explained with a diagram:\n\nHere’s an example that creates a new image by cropping the rectangle described below:\n\nPasting an Image onto Another Image\n\nPillow enables you to paste an image onto another one. Some example use cases where this could be useful is in the protection of publicly available images by adding watermarks on them, the branding of images by adding a company logo, and in any other case where there is a need to merge two images.\n\nclass’method pastes another image onto the current one. This is useful for protecting publicly available images by adding watermarks, branding images with a company logo, or simply creating compositions of two or more images.\n\nis unlike manymethods (but like) in that it modifies theobject in place rather than returning a new `one. Because of this, we'll first make a copy of our puffin image before performing the paste to continue with the other examples using the original.\n\nThe code above loads a new image,\n• A 2-tuple specifying the upper left corner of the pasted image,\n• a 4-tuple defining the left, upper, right, and lower pixel coordinates of the pasted image, or\n• , which simply pastes the image at the coordinates (0, 0).\n\n, and makes a copy of the puffin image. We want to paste the logo image onto the puffin image copy at the bottom right corner. The code calculates the coordinates for pasting the logo, which can be:\n\nIn this case, we’re pasting the logo using a 2-tuple coordinate:\n\nYou can see the result below:\n\n, transparent pixels are pasted as solid pixels by default. Hence the black (white on some OSs) box surrounding the logo. Most of the time, this isn't what you want. You can't have your watermark covering the underlying image's content. We would rather have transparent pixels appear as such.\n\nTo achieve this, you need to pass in an optional third argument to the\n\nmethod. This argument is anobject that acts as an opacity mask.\n\nAn opacity mask is an\n\nobject where only the alpha value is significant, while its green, red, and blue values are ignored. If a mask is provided as an optional third argument to, the method updates only the regions the mask indicated. You can use either, orimages for masks. Pasting an RGBA image and using it as the mask pastes only the opaque portion of the image — not its transparent background.\n\nThe code below provides an example of this approach:\n\nWith Pillow, you can also draw on an image using the ImageDraw module. You can draw lines, points, ellipses, rectangles, arcs, bitmaps, chords, pie slices, polygons, shapes, and text.\n\nThe code below draws a black rectangle with a fine white outline near the lower left corner of the puffin image from the previous code example. It then draws the text message “Hello, puffins!” in large white text inside the rectangle:\n\nConverting an image from color to grayscale\n\n’smethod can convert images between different pixel representations, such as the RGB (red-green-blue) format used by screens and the CMYK (cyan-magenta-yellow-black) format used in printing. Like mostmethods,returns a newobject.\n\nalso supports converting images to the(luminance) format, which is a grayscale image format. The code below converts our puffin image from color to grayscale monochrome:\n\nReducing the number of colors in an image\n\nIn addition to pixelation, another way to make an image look “retro” is to reduce the number of colors it uses to 256 or fewer. You can do this with a single call to\n\nThe code below reduces the number of colors in our puffin photo to 16, producing an effect that should remind you of 1990s computer graphics:\n\nmethod of Pillow’sclass makes it possible to split a multi-band image into individual bands, such as the R, G, and B bands from an RGB image.creates new images, each containing one band from the original image.\n\nhas an inverse function,, which merges a set of single band images into a new multi-band image.takes a mode and a tuple of images and combines them into a new image.\n\nThe code below takes the original “puffin” image, splits it into three images — one for each of the R, G, and B bands — and then merges them so that:\n\nPillow allows you to enhance an image by adjusting its contrast, color, brightness, and sharpness using classes in the\n\nHere’s code that boosts the contrast of the “puffin” image:\n\nHere’s the image after enhancing its contrast:\n\nThe code above adjusts the image contrast by a factor of 3; smaller values will produce more subtle effects. A factor of 1.0 returns a copy of the original image; lower factors produce images with lower contrast.\n\nBelow, we increase the color of the image. If we used a factor of\n\n, we would get a black and white image.\n\nBelow we make the image brighter. A factor of\n\nBelow, we make the image sharper. An enhancement factor of\n\nTo save an image, use\n\n’smethod. For example, here’s how you’d save the image from the Enhancing sharpness exercise above as a PNG file:\n\nPillow sees the file extension has been specified as\n\nand converts it to PNG before saving it to a file.\n\nTo save it as a JPEG image, use this:\n\nYou can provide a second argument to\n\nto explicitly specify a file format.will do the same thing as the previous save(). Usually, it's unnecessary to supply this second argument as Pillow will determine the file storage format to use from the filename extension, but if you're using non-standard extensions, you should always specify the format this way.\n\nIn this article, we've covered some of the more common image-processing operations in applications. Pillow is a powerful library, and we have yet to discuss everything it can do. If you want to find out more, be sure to read the documentation."
    },
    {
        "link": "https://stackoverflow.com/questions/57111648/how-to-resize-an-imagefield-image-before-saving-it-in-python-django-model",
        "document": "I am trying to implement a Django ImageField class function for resizing images however I am not certain where this function accepts my new image dimensions\n\nI've had a look at this documentation, but can't quite make sense of it: https://docs.djangoproject.com/en/1.11/_modules/django/db/models/fields/files/#ImageField\n\nI'd really appreciate it if someone can show me an example of how to use this function.\n\nI haven't successfully managed to resize my image dimensions yet, which is what i am trying to achieve. How may I resize this image before I save it given it is being fetched by (I found the class function for however i cant figure out how to use it)"
    },
    {
        "link": "https://stackoverflow.com/questions/24373341/django-image-resizing-and-convert-before-upload",
        "document": "First, it's best to establish the correct language. Django and Python exist only on the server side. Therefore, anything they manipulate, save, or otherwise use, has to be first sent to the server. If Django or Python is to manage the photo, the user MUST upload this photo to the server first. Once the photo is uploaded, Django is free to make changes before storing the file.\n\nIf your concern is with upload bandwidth, and you don't want large files being uploaded, you will have to resize and reformat the photo on the client side. If this is a web application, this can be done using Javascript, but can not be done with Python, since Python does not operate on the client side for an application like yours.\n\nIf your concern is not with bandwidth, then you're free to have the user \"upload\" the file, but then have Django resize and reformat it before saving.\n\nYou are correct that you will want to override your save function for the photo object. I would recommend using a library to handle the resizing and reformatting, such as sorl.\n\nSorl is just a library I am confident and familiar with, but it takes some tuning and configuration. You can check out Pillow or something instead, and just replace the line overriding .\n\nEdit: saw the update to your comment response above. Also note that if your webserver is handling Django, and your files are being saved to some CDN, this method will work. The image will be resized on the webserver before being uploaded to your CDN (assuming your configuration is as I'm assuming)."
    },
    {
        "link": "https://dev.to/doridoro/in-django-model-save-an-image-with-pillow-pil-library-5hbo",
        "document": "The method in Django models is designed to persist the model instance to the database. By default, it handles basic saving operations, but it can be overridden to add additional functionality or to customize the saving process. In this model, we have overridden the method to include specific image handling logic before the actual save operation is performed.\n\nThe primary purpose of this custom method is to:\n• Validate the Image: Ensure that the uploaded file is a valid image.\n• Process the Image: If necessary, convert and resize the image to meet specific criteria.\n• Optimize the Image: Save the image in a specific format with optimized settings.\n\nHandling image files can be tricky because they come in various formats and sizes. Furthermore, user-uploaded images might not always be in the desired format or resolution. This custom logic ensures that:\n• The image is verified and valid.\n• The image is processed to maintain a consistent format (JPEG).\n• The resolution of the image is controlled to optimize load times and storage requirements.\n• None Image Verification: The method first tries to open and verify the uploaded image to ensure that it is a valid image file.\n• None Reopen Image: Since the method moves the file pointer to the end, the image file is reopened to reset the pointer.\n• None Image Mode Adjustment: If the image is in a mode other than RGB, such as RGBA or P, it is converted to RGB. This is often done to standardize the image format, as certain modes like RGBA include alpha channels which might not be needed.\n• None Resizing the Image: The image is resized to a width of 800 pixels while maintaining the aspect ratio. This ensures that all images have a consistent width, which can be important for display purposes and performance optimization on the website.\n• None Saving the Image: The processed image is then saved as a JPEG file with a specific quality setting. The new file is temporarily stored in memory using before being saved to the model's field.\n• None Exception Handling: If any errors occur during these processes (either during verification, reopening, or processing), specific exceptions are raised with meaningful error messages. This helps in diagnosing issues with uploaded files.\n\nFinally, the overridden method calls to ensure that the default saving behavior is executed, and the model instance is saved to the database.\n\nBy implementing this custom save method, we ensure better control and consistency over how images are handled and stored, thus improving the robustness and reliability of the application.\n\n# reopen because img.verify() moves pointer to the end of the file # Calculate new dimensions to maintain aspect ratio with a width of 800 # Save the BytesIO object to the ImageField with the new filename The uploaded file is not a valid image. --"
    },
    {
        "link": "https://forum.djangoproject.com/t/django-filefield-resize-image-before-save-to-s3botostorage/7595",
        "document": "I have a FileField which acutally stores an image.\n\n However, when the image is added or changed, I need to resize the image.\n\n Storage backend is s3botostorage.\n\n Here’s the mixin I wrote to resize the image which works well with local FileSystemStorage.\n\nAnd this is my model’s save() method\n\nHere’s my problem.\n\n I upload png file on django admin.\n\n After saving the model, I see both png file and jpg file of same image on s3 bucket.\n\n I don’t need png file as I convert all images to jpeg.\n\n And it actually writes to s3 twice - one png and one jpg.\n\n I want to resize before it is acutally written to storage so it only writes once to storage.\n\nHow can I solve this?\n\n Any help would be appreicated.\n\n @KenWhitesell , maybe this would be an easy fix for you. Any advice?"
    },
    {
        "link": "https://medium.com/@pedro_kpaxo/resizing-images-with-python-c6ba9c4f19f5",
        "document": "Resizing images is a very common task for any backend system that works with them. In this article, we will approach how to resize images with python in a generic way, and how to apply this concept on django models.\n\nYou can also check my first tutorial using Django Rest Framework for a intro to Django.\n\nMake sure that you have PIL and Django installed on your system. You can run the following command to install it:\n\nfrom io import BytesIO\n\nfrom typing import Union, Tuple\n\n\n\nfrom django.core.files.base import ContentFile, File\n\nfrom PIL import Image\n\n\n\n\n\ndef resize_thumbnail(image: Union[str, File], size: Tuple[int, int] = (300, 300)) -> bytes: # noqa\n\n \"\"\"Resize the image to the specified size.\n\n\n\n Args:\n\n image: A path to the image or a file-like object.\n\n size: A tuple specifying the width and height to resize the image to.\n\n\n\n Returns:\n\n A bytes object containing the resized image.\n\n \"\"\"\n\n # Open the image depending on the type of the 'image' argument\n\n if isinstance(image, str):\n\n img = Image.open(image)\n\n else:\n\n img = Image.open(image.file)\n\n\n\n # Convert image to RGB if it's RGBA (to remove alpha channel)\n\n if img.mode in (\"RGBA\", \"LA\"):\n\n background = Image.new(img.mode[:-1], img.size, \"#FFFFFF\")\n\n # Paste using alpha channel as mask\n\n background.paste(img, img.split()[-1])\n\n img = background.convert('RGB')\n\n\n\n img.thumbnail(size, Image.ANTIALIAS)\n\n\n\n thumb_io = BytesIO()\n\n img.save(thumb_io, format='JPEG', quality=85)\n\n\n\n return ContentFile(thumb_io.getvalue())\n\nThis Python function accepts either a file path or a file-like object representing an image, along with a tuple defining the desired size for the thumbnail, defaulting to 300x300 pixels.\n\nAlso determines the type of the input image and opens it accordingly. If the image has an alpha channel (indicating transparency, as found in ‘RGBA’ or ‘LA’ modes), the function removes it by pasting the image onto a white background, converting it to a standard RGB format. This step ensures compatibility with the JPEG format, which does not support transparency.\n\nWhen working with files on Django, is better to first define some functions to point to the disk folder structure:\n\nThese functions, like and , serve as dynamic file path generators. They accept an instance (usually a model instance) and a filename, and return a formatted string representing the file's storage path.\n\nAnd then we can define some models like this, and override the save methods on the model to generate the thumbnails on the fly:\n\nPay attention the the primary attribute, , is an linked to a custom directory through the function, ensuring organized file storage. This field is marked as unique, emphasizing that each image in the system should be distinct. So change this functionality to your taste."
    }
]