[
    {
        "link": "https://docs.unity3d.com/Manual/Shaders.html",
        "document": "Resources for using or writing programs that run on the GPU to control the appearance of objects in a sceneA Scene contains the environments and menus of your game. Think of each unique Scene file as a unique level. In each Scene, you place your environments, obstacles, and decorations, essentially designing and building your game in pieces. More info\n\nSee in Glossary.\n• Search the Unity blog for posts about shaders"
    },
    {
        "link": "https://docs.unity3d.com/Manual/SL-ShadingLanguage.html",
        "document": "How you write custom shadersA program that runs on the GPU. More info\n\nSee in Glossary in Unity depends on the render pipelineA series of operations that take the contents of a Scene, and displays them on a screen. Unity lets you choose from pre-built render pipelines, or write your own. More info\n\nSee in Glossary you use:\n• For guidance and examples for the Built-in Render Pipeline, see Example shaders for the Built-in Render Pipeline.\n• For guidance and examples for the the Universal Render Pipeline (URP), see URP: Writing custom shaders.\n• It is not recommended to write your own shader programs for HDRP, due to the complexity of the code. Instead, use Shader Graph to create Shader objects without writing code.\n• For an example of a simple vertex and fragment shader for a custom Scriptable Render Pipeline, see Creating a simple render loop in a custom render pipeline.\n\nWhen you write shaders for Unity, you use the following languages:\n• A programming language called HLSL. Use this to write the shader programs themselves. For more information on HLSL, see HLSL in Unity.\n• A Unity-specific language called ShaderLab. Use this to define a Shader object \n\n An instance of the Shader class, a Shader object is container for shader programs and GPU instructions, and information that tells Unity how to use them. Use them with materials to determine the appearance of your scene. More info , which acts as a container for your shader programs. For more information on ShaderLab, see ShaderLab \n\n Unity’s language for defining the structure of Shader objects. More info .\n\nYou do not need to use different languages for different platforms; Unity compiles your HLSL and ShaderLab code into different languages for different graphics APIs. For more information, see Shader compilation.\n\nNote: You can also directly write your shader programs in GLSL and Metal if you want. This is not recommended or needed as part of a normal workflow. For more information on using GLSL, see GLSL in Unity.\n\nShaderLab is a declarative language that you use in shader source files. It uses a nested-braces syntax to describe a Shader object.\n\nThere are many things that you can define in ShaderLab, but the most common are:\n• Defining the overall structure of the Shader object. See ShaderLab: creating a Shader, ShaderLab: creating a SubShader, and ShaderLab: creating a Pass.\n• Using code blocks to add shader programs written in HLSL. See ShaderLab: adding shader programs.\n• Using commands to set the render state of the GPU before it executes a shader program, or to perform an operation involving another Pass. See ShaderLab: commands.\n• Exposing properties from your shader code so you can edit them in the material Inspector \n\n A Unity window that displays information about the currently selected GameObject, asset or project settings, allowing you to inspect and edit the values. More info and save as part of a material asset. See ShaderLab: defining material properties.\n• Specifying package requirements for SubShaders and Passes. This enables Unity to run certain SubShaders and Passes only when particular packages are installed in the Unity project. See ShaderLab: specifying package requirements.\n• Defining fallback behavior for when Unity cannot run any of the SubShaders with a Shader object on the current hardware. See ShaderLab: assigning a fallback.\n\nThere are different ways of writing shaders:\n• The most common way is to write vertex and fragment shaders in HLSL. For more information, see Writing vertex and fragment shaders.\n• In the Built-in Render Pipeline, you can also write Surface Shaders. They are a simplified way of writing shaders that interact with lighting. For more information, see Surface Shaders \n\n A streamlined way of writing shaders for the Built-in Render Pipeline. More info .\n• For backwards compatibility reasons, Unity also supports “fixed function style” ShaderLab commands. These let you write shaders in ShaderLab, without using HLSL. This is no longer recommended, but it is documented on the page ShaderLab legacy functionality.\n\nIn some cases, you must write your shader code differently depending on the graphics API that you are targeting. For information on this, see Writing shaders for different graphics APIs."
    },
    {
        "link": "https://github.com/Centribo/Unity-Shader-Basics-Tutorial",
        "document": "Welcome, this tutorial is supposed to be a gentle introduction into writing shaders for Unity. It assumes you have some previous knowledge in working with Unity but have never touched shaders or materials.\n\nWe'll be building up the shader in parts, stopping along the way to show what everything does.\n\nShaders are part of the computer graphics rendering pipeline. They're small applications that tell the computer how to render and shade objects in a scene. This includes calculating the color and light values for a given object so that it can be shown on screen. Ontop of that, shaders are used to create many of the special and post-processing effects that you see in games today.\n\nIn modern game engines, (Including Unity) shaders run in a programmable GPU (Graphics Processing Unit) rendering pipeline, which allow them to run in parallel and do many shader calculations very quickly.\n\nWikipedia has a great article about shaders here.\n\nFor our purposes, we'll simplify the rendering pipeline. Here's an image showing what we'll discuss in this tutorial:\n\nI like to think of shaders as programs that transform one type of information (model data, colours, etc.) to another type of information (pixels/fragments). Object data is data that is inherit to the object. Things such as points in the model, normals, triangles, UV coordinates, etc. Custom Data/Properties are things that we can pass into a shader to use. Things such as colours, textures, numbers, etc.\n\nThe first step of the shader pipeline is the vertex function. Vertices, as you might know, are just points in 3D space. The vertex function will work with the vertices in the model (Along with other data such as normals) and prepare them for the next step, the fragment function.\n\nThe fragment function will take in vertices and shade them in. Think of it like a painter and their paint brush. It ultimately outputs pixel data, in a (R, G, B, A) format.\n\nLastly, the pixels are pushed to a frame buffer, where they may be manipulated further (even by other shaders!) until they are drawn on screen.\n\nSo before we start writing some shader code, let's setup our scene. Create a new project in Unity, and import all the assets:\n\nAdd a cube, a sphere, and the bowl model to a new scene and save the scene. Here's what your scene should look like after:\n\nNext, right click in the Project view (Or go to Create) and add a new Unlit Shader. We'll call it \"Tutorial_Shader\" for now.\n\nIf you're curious about the other kinds of shaders, I'll talk about them at the near the end.\n\nThen, right click the shader file we just made and go to Create > Material. Unity will automatically create a material that uses that shader with the correct name.\n\nNote: a \"Material\" in Unity is just a instance of a shader. It just saves the values & refences of the custom data/properties.\n\nLastly, apply the material to all the objects we've added to the scene by clicking and dragging them to each object.\n\nEverything in the scene should look white and without shadows or shading, like this:\n\nTime to start writing our shader! Let's open our Tutorial_Shader.shader file we created before. You'll see Unity automatically generates some code for us to use/build off of. For the sake of this tutorial, delete all of this and make the .shader file blank.\n\nNote: All shaders in Unity are written in language called \"ShaderLab.\" Shaderlab is a wrapper for HLSL/Cg that lets Unity cross compile shader code for many platforms and expose properties to the inspector.\n\nTo start we'll add this code:\n\nThese lines of code just specify where the shader code is. The string in quotes after the Shader keyword specify to Unity where you'll find the shader.\n\nIf you save your shader and switch back to Unity, you'll notice all our objects now are pink:\n\nThis is a fallback shader that Unity will use whenever your shader has errors in it. If you ever get pink objects, you can click on your shader file in the project window and look at the inspector to see the corresponding errors. For now, we'll have pink objects because we haven't completed our shader.\n\nNext up is the properties block:\n\nThe properties block is where we can pass in that custom data we were walking about before. Anything we declare here will be shown in the Unity editor for us to change and be exposed to scripting aswell.\n\nUnderneath our properties block we'll have our subshader:\n\nEvery shader has one or more subshaders. If you're deploying to multiple platforms it can be useful to add multiple subshaders; For example, you might want two subshaders, one of higher quality for PC/Desktop and one of lower quality but faster for mobile.\n\nThen we have our pass:\n\nEach subshader has atleast one pass, which is actually where the object gets rendered. Some effects require having multiple passes, but we'll just focus on one for now.\n\nWithin our pass, we have the actual rendering code block:\n\nAnything within CGPROGRAM and ENDCG is where we actually write our shading code. For Unity this is a variant of HLSL and CG shading languages.\n\nNext, we'll tell Unity what our vertex and fragment functions are:\n\nHere, we're saying we have a vertex function called \"vertexFunction\", and a fragment function called \"fragmentFunction\"\".\n\nBefore we start shading, we need to setup some data structures and our two functions in a way so that we can take in Unity's given data and give data back to Unity. First, we'll include UnityCG.inc. This file includes a number of helper functions that we can use. If you want a full list of them, you can go here.\n\nWe'll also add a data structure called appdata, and modify our vertex function so that it takes in an appdata structure:\n\nWhen we give Unity an argument to call the vertex function with, it will look into the structure of that argument (in this case, our appdata structure) and attempt to pass in values to it based on the model that is being drawn. We can define data that we want Unity to pass in by declaring variables like this:\n\nSo for example, we can ask Unity for the positions of the vertices of this model like this:\n\nFor now we'll ask Unity to give us the position of the vertices and the coordinates of the UV like so:\n\nIf you want to learn more about providing vertex data to vertex functions, you can read here.\n\nLastly for the vertex function setup, we'll create one more struct called v2f (which stands for vertex to fragment) that will contain the data we'll be passing into our fragment function. We'll also make sure our vertex function returns data of this struct and create and return a blank one while we're at it:\n\nJust like before we can define some data in v2f that we want to pass from our vertex function to our fragment function.\n\nIf you're curious about SV_POSITION vs POSITION, SV stands for \"system value\" and represents in our v2f struct that this will be the final transformed vertex position use for rendering.\n\nOkay we're almost ready, we just need to edit our fragment function. First, we'll modify it to take in the v2f struct and make it return a fixed4 value:\n\nOur output for the fragment function will be a colour represented by (R, G, B, A) values, hence the output of this function being a fixed4.\n\nLastly, we're going to add an output semantic SV_TARGET to our fragment function like so:\n\nThis tells Unity that we're outputting a fixed4 colour to be rendered. We're now ready to start actually coding the meat and potatoes of our vertex and fragment functions! Here's our basic skeleton that we've made up to this point:\n\nFirst thing we'll do is get the correct positions of the vertices. We'll do this using a function called UnityObjectToClipPos() like so:\n\nWhat this function does is take a vertex that is represented in local object space, and tranforms it into the rendering camera's clip space. Notice we're passing along the transformed point by setting OUT.position's value. If you want to learn more about this, here is a great discussion on what these spaces are and their purposes.\n\nNext, we'll make our fragment function return a solid green colour:\n\nAnd now, the moment you've been waiting for! Save your shader and return to Unity and you'll see our beautiful green objects!\n\nOkay, this probably not that impressive to you, so lets keep building. How about, instead of returning a basic green colour, we edit our shader to return any colour we want? What we'll need to do to achieve this is start working with custom properties.\n\nWe can add the properties in the Properties block we want to use by following this syntax:\n\nSo for example, we'll expose a colour value like so:\n\nHere we're defining a colour for us to use, called _Colour and it will be shown as \"Totally Rad Colour!\" in the Unity inspector. We're also giving it a default value of white. If you save and return to Unity now, when you inspect the material, you should see this:\n\nBefore we can use this colour, we need to actually pass it into the CG code. Unity does this automatically by binding it by variable name like so:\n\nI like to put properties after my structs to keep my code organized, but you can put it anywhere so long as its in the top scope of the CGPROGRAM\n\nWe can now use our _Colour value in our fragment function. Instead of returning that green, lets just return whatever colour we want:\n\nAnd now, we can save and return to Unity. If you inspect the material and start changing our colour value, you should see all the colours of the objects change accordingly!\n\nSince we now know how to add properties, lets try adding a standard texture map. We'll need a new property for our texture:\n\nNotice how it's of type 2D (2D Texture), and we're defaulting to a blank white texture. We've also need to get the property into CG to use it:\n\nThen, we need to give our fragment function the UV coordinates from the model. We can do this by going back to our vertex function and passing them into the v2f struct we return like so:\n\nNow in order to use the colours from the texture for our fragment function, we need to sample it at certain points. Thankfully, CG has a function that does this for us, called tex2D.\n\ntex2D takes in the texture (ie: sample2D) we want to sample, and the UV coordinate we want to sample with. In this case, we're providing it with our main texture and giving it the point on the model where we want to get the colour from, then returning that result as our final colour. Now, if you save and return back to Unity and inspect the material, we can select the bowl texture for our \"Main Texture\". You'll see the models update, and the bowl model in particular (the model the texture was made for) should look like a bowl of soup!\n\nNote: We can change how Textures in Unity are sampled by going back to the texture file and changing the filter mode in the inspector:\n\nSo now that we know the basics, we can start having some fun with shaders and achieve some simple effects. First, we're going to use our noise texture and achieve a sort of \"dissolve\" or \"cutout\" effect. We'll start by adding a texture property and a float property:\n\nNotice how we've set _DissolveCutoff to be a Range from (0, 1). This represents a float value from 0 to 1 (inclusive) and this notation also allows us to easily set it's value using a slider from within Unity's inspector. Now let's add them to our CGPROGRAM:\n\nNow we can sample the dissolve texture in our fragment function:\n\nNotice we're still using the same UV coordinates as our main texture. Now here's where the magic happens:\n\nThe clip function works by checking if the value given is less than 0. If it is, then we discard the pixel and draw nothing. If it isn't we keep the pixel and continue as normal. The way our code currently works is:\n• We sample the main texture for colour.\n• We sample the cutout texture for it's colour.\n• We subtract the cutoff value from the \"brightness\" of our cutoff sample, and...\n• If it's less than 0, we draw nothing\n\nNow, save your shader and return to Unity. Set the \"Dissolve Texture\" to our noise texture, and start moving the \"Dissolve Cutoff\" slider, you should see an effect like this:\n\nPretty cool huh? We can do more too. Let's try playing with the vertices before we pass them to our fragment function. Let's expose another property:\n\nWe're also going to using normals from the model, so lets add the field into the appdata struct so we can access them:\n\nNow let's add a single line to our vertex function:\n\nWhat we're doing here is, before we transform our vertices out of local model space, we're going to offset them a certain amount outwards by adding their normal direction times our _ExtrudeAmount. A normal is just a vector that represents the direction that the vertex is facing. Now if you save and return to Unity and play with the \"Extrude Amount\" value, you should see an effect like this:\n\nWe can even animate these properties:\n\n_Time is a variable included in UnityCG.cginc that represents the time, with the y value representing seconds. Make sure \"Animated Materials\" is checked on in the scene view in order to preview this effect in the editor:\n\nNext, we'll talk about how to control shaders with Unity scripts. For this example, we'll reuse the _Colour property we added before. First, lets set it as a colour tint for our shader by doing this in our fragment function:\n\nWe're just multiplying the output colour by our _Colour property to tint it. Here's what that looks like in the editor:\n\nAlright, lets start scripting. We'll add a new script to all the objects and we'll call it RainbowColour.cs\n\nIn our script, we'll start by declaring two private variables for our Renderer and our Material:\n\nWe'll also get references to them in our Start() function:\n\nWe will use Material.SetColor(...) to set the colour in our shader. This function's first argument is a string, which is the name of the property we want to set. The second argument is the colour we want to set the property to.\n\nNow notice when we start our game, the tint colour changes to magenta!\n\nThere are many functions for getting and setting properties for materials from within scripts, and you can find all of them here.\n\nUp to this point, we've been writing unlit shaders. Unlit shaders don't consider lights or shadows. Unity also lets you write surface shaders. Surface shaders are actually just like vertex/fragment shaders except they strip away alot of the boilerplate code that is required to make shaders interact with lighting and shadows. If you're curious about going through that process of writing code for lighting and shadows, there is a great tutorial by Jasper Flick here.\n\nWhat I'll show you in this section is how each part of the surface shader relates to our vertex/fragment shaders. If you create a new \"Standard Surface Shader\" from within Unity, you'll get this auto-generated code:\n\nLet's go through each section that is new and explain what they do. First, the tags:\n\nTags help you tell the rendering engine how and when the shader you're writing is going to be rendered. You can learn more about tags here. In this case, we're just specifying that our shader is opaque; Especially useful for producing a depth texture/map.\n\nThe shader Level of Detail or (LOD) helps specify which shader to use on certain hardware. The higher the LOD, the more \"complex\" the shader is. This value has nothing to do with model LOD. You can read more about shader LOD here.\n\nSimilar to how we defined the vertex and fragment functions, we care defining here a surface function called surf. \"Standard\" tells Unity that this shader uses the standard lighting model, and \"fullforwardshadows\" specifies that this shader should enable all regular shadow types.\n\nThis tells which lighting version to compile. The higher the value, the more complex and better looking but the higher system requirements. You can read more about this here.\n\nThis is the heart of the shader. Instead of specifying exactly the colour value of the pixel, Unity defines a SurfaceOutputStandard structure. It has attributes such as Albedo (for colour) which you will set. Since we're working with lighting and shadows now, we don't just grab the colour directly, it needs to be calculated from values held in SurfaceOutputStandard. Here are all the attributes that are part of SurfaceOutputStandard:\n\nOkay, so what about vertices?\n\nBy default, the standard surface shader doesn't expose a function for editing vertices. We can still add one though. First, we'll add to the pragma and define a vertex function:\n\nAnd also define the function:\n\nThe \"appdata_full\" structure will automatically be filled in by Unity with the attributes of the model we're rendering. This is the same as before, except instead of explicitly creating our own structure, Unity has already defined a few for us. You can see what other structures they have defined and what attributes will be passed in here.\n\nNow we can edit the vertices as normal. For example, to translate the code we had before:\n\nNote: If you notice that when you update the vertices but the shadows are not also being updated, make sure to add the \"addshadow\" pragma like this:\n\nSurface shaders have alot going on within them and are much more complex, but they ultimately compile down to vertex and fragment functions just like the ones we were writing before. I highly suggest reading the official documentation here to learn more about them. The official documenation also has a great page of examples here which is a good place to start if you want to understand them better. Alan Zucconi also has a great tutorial introducing them available here.\n\nSo far we've talked about the unlit shader and the surface shader. Let's talk about the other types of shaders we can use in Unity.\n\nThe Image Effect shader is exactly as it sounds, it's a shader for image effects. More specifically, they tend to take a texture as their input and output a texture aswell. They can be applied to cameras in Unity or any other texture to affect their look before being outputted to the screen/framebuffer. As an exercise, try creating a new one in Unity and attempting to understand the code! They are great for doing things like the \"CRT\" effect, or a black and white effect. Dan John Moran has a great video tutorial available here which introduces image effect shaders and how to create/use them. (His channel in general is a great place to start learning more about shaders!)\n\nThe Compute shader is a type of shader that is used for computing and calculating data. Remember how I said shaders run in the GPU? For some computational tasks, this can be extremely beneficial as they will run much faster in a parallel process. For example, they can be used to calculate physics, or the position of particles in a simulation. In general, most people will never need to touch compute shaders. If you'd like to learn more you can check out a tutorial by Kyle Halladay available here. (Admittedly I don't know too much about compute shaders myself.)\n\nHopefully this tutorial has helped you in getting started on writing your own shaders, but there is still alot to learn! Shaders are a vital ingredient in helping shape how your game looks and performs. My suggestion is to keep experimenting and keep learning. (That doesn't just apply to shaders either!) If you see a neat or notable effect in a game, chances are shaders have a part in achieving it, so try your hand at replicating it. This section is dedicated in listing some resources that have been useful to me for learning about shaders."
    },
    {
        "link": "https://discussions.unity.com/t/hdrp-custom-shaders-examples/743450",
        "document": ""
    },
    {
        "link": "https://learn.unity.com/tutorial/shaderlab-introduction-to-shaders",
        "document": "In this tutorial, you will learn the basics of High-Leveling Shader Language (HLSL) Shaders."
    },
    {
        "link": "https://docs.unity3d.com/Manual/Shaders.html",
        "document": "Resources for using or writing programs that run on the GPU to control the appearance of objects in a sceneA Scene contains the environments and menus of your game. Think of each unique Scene file as a unique level. In each Scene, you place your environments, obstacles, and decorations, essentially designing and building your game in pieces. More info\n\nSee in Glossary.\n• Search the Unity blog for posts about shaders"
    },
    {
        "link": "https://docs.unity3d.com/2020.1/Documentation/Manual/SL-Properties.html",
        "document": "Shaders can define a list of parameters to be set by artists in Unity’s material inspector. The Properties block in the shader file defines them.\n\nDefines the property block. Inside braces multiple properties are defined as follows.\n\nThese all defines a number (scalar) property with a default value. The form makes it be displayed as a slider between min and max ranges.\n\nDefines a color property with default value of given RGBA components, or a 4D vector property with a default value. Color properties have a color picker shown for them, and are adjusted as needed depending on the color space (see Properties in Shader Programs). Vector properties are displayed as four number fields.\n\nDefines a 2D Texture, cubemapA collection of six square textures that can represent the reflections in an environment or the skybox drawn behind your geometry. The six squares form the faces of an imaginary cube that surrounds an object; each face represents the view along the directions of the world axes (up, down, left, right, forward and back). More info\n\nSee in Glossary or 3D (volume) property respectively.\n\nEach property inside the shaderA small script that contains the mathematical calculations and algorithms for calculating the Color of each pixel rendered, based on the lighting input and the Material configuration. More info\n\nSee in Glossary is referenced by name (in Unity, it’s common to start shader property names with underscore). The property will show up in material inspectorA Unity window that displays information about the currently selected GameObject, asset or project settings, allowing you to inspect and edit the values. More info\n\nSee in Glossary as display name. For each property a default value is given after equals sign:\n• For Range and Float properties it’s just a single number, for example “13.37”.\n• For Color and Vector properties it’s four numbers in parentheses, for example “(1,0.5,0.2,1)”.\n• For 2D Textures, the default value is either an empty string, or one of the built-in default Textures: “white” (RGBA: 1,1,1,1), “black” (RGBA: 0,0,0,0), “gray” (RGBA: 0.5,0.5,0.5,0.5), “bump” (RGBA: 0.5,0.5,1,0.5) or “red” (RGBA: 1,0,0,0).\n• For non–2D Textures (Cube, 3D, 2DArray) the default value is an empty string. When a Material does not have a Cubemap/3D/Array Texture assigned, a gray one (RGBA: 0.5,0.5,0.5,0.5) is used.\n\nLater on in the shader’s fixed function parts, property values can be accessed using property name in square brackets: [name]. For example, you could make blending mode be driven by a material property by declaring two integer properties (say “SrcBlend“ and ”DstBlend”), and later on make Blend Command use them: .\n\nShader parameters that are in the block are serialized as MaterialAn asset that defines how a surface should be rendered, by including references to the Textures it uses, tiling information, Color tints and more. The available options for a Material depend on which Shader the Material is using. More info\n\nSee in Glossary data. Shader programs can actually have more parameters (like matrices, vectors and floats) that are set on the material from code at runtime, but if they are not part of the Properties block then their values will not be saved. This is mostly useful for values that are completely script code-driven (using Material.SetFloat and similar functions).\n\nIn front of any property, optional attributes in square brackets can be specified. These are either attributes recognized by Unity, or they can indicate your own MaterialPropertyDrawer classes to control how they should be rendered in the material inspector. Attributes recognized by Unity:\n• - does not show the property value in the Material inspector.\n• - material inspector will not show Texture tiling/offset fields for Texture properties with this attribute.\n• - indicates that a float/vector property is specified as sRGB value in the UI \n\n (User Interface) Allows a user to interact with your application. More info (just like colors are), and possibly needs conversion according to color space used. See Properties in Shader Programs.\n• - indicates that a property will be coming from per-renderer data in the form of a MaterialPropertyBlock. Material inspector shows these properties as read-only.\n• - indicates that a property is the main texture for a Material. By default, Unity considers a texture with the property name name as the main texture. Use this attribute if your texture has a different property name, but you want Unity to consider it the main texture. If you use this attribute more than once, Unity uses the first property and ignores subsequent ones. When the main texture is set using the attribute, it is not visible in the Inspector in Debug mode. When the main texture is set using the attribute, it is not visible in the Game view when you use the texture streaming debugging view mode or a custom debug tool.\n• - indicates that a property is the main color for a Material. By default, Unity considers a color with the property name name as the main color. Use this attribute if your color has a different property name, but you want Unity to consider it the main color. If you use this attribute more than once, Unity uses the first property and ignores subsequent ones."
    },
    {
        "link": "https://reddit.com/r/Unity3D/comments/1c8rx2w/how_did_you_guys_learn_unity_shadersshader_graphs",
        "document": "How exactly did you start doing it? Like, was it tutorials? Did you go with HLSL or Shader Graphs?\n\nHow did you go from: Not understanding what is shaders at all --> Creating special effects and shaders for your games?\n\nWhat was the process like, what helped you? How long did it take?"
    },
    {
        "link": "https://unity.com/blog/engine-platform/shader-variants-optimization-troubleshooting-tips",
        "document": ""
    },
    {
        "link": "https://discussions.unity.com/t/can-anyone-give-me-a-quick-rundown-of-the-basics-of-a-handwritten-urp-shader-vs-in-built/761144",
        "document": ""
    }
]