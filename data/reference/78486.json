[
    {
        "link": "https://stackoverflow.com/questions/54393127/v8-how-to-correctly-handle-microtasks",
        "document": "You generally shouldn't need to use MicrotasksScope.\n\nUsually you will either be using or .\n\nWith a kAuto policy, any time the script evaluation stack is emptied, microtasks will be run. With kExplicit, you have to do it yourself, using .\n\nIn most situations, the default ( ) will work. If you are chromium or node, using kExplicit will make more sense since you need to time your microtask queue with all the other platform stuff like timers and networking.\n\nAs for MicrotasksScope, I personally am not aware of any project that uses it, but it will behave the same as kAuto, except the microtask runs when the stack of MicrotasksScope objects empties, instead of Scripts."
    },
    {
        "link": "https://v8docs.nodesource.com/node-15.0/d1/d46/classv8_1_1_microtasks_scope.html",
        "document": "This scope is used to control microtasks when MicrotasksPolicy::kScoped is used on Isolate. In this mode every non-primitive call to V8 should be done inside some MicrotasksScope. Microtasks are executed when topmost MicrotasksScope marked as kRunMicrotasks exits. kDoNotRunMicrotasks should be used to annotate calls not intended to trigger microtasks."
    },
    {
        "link": "https://v8docs.nodesource.com/node-20.3/d1/d46/classv8_1_1_microtasks_scope.html",
        "document": "This scope is used to control microtasks when MicrotasksPolicy::kScoped is used on Isolate. In this mode every non-primitive call to V8 should be done inside some MicrotasksScope. Microtasks are executed when topmost MicrotasksScope marked as kRunMicrotasks exits. kDoNotRunMicrotasks should be used to annotate calls not intended to trigger microtasks.\n\nThe documentation for this class was generated from the following file:"
    },
    {
        "link": "https://v8.dev/docs",
        "document": "V8 is Google’s open source high-performance JavaScript and WebAssembly engine, written in C++. It is used in Chrome and in Node.js, among others.\n\nThis documentation is aimed at C++ developers who want to use V8 in their applications, as well as anyone interested in V8’s design and performance. This document introduces you to V8, while the remaining documentation shows you how to use V8 in your code and describes some of its design details, as well as providing a set of JavaScript benchmarks for measuring V8’s performance.\n\nV8 implements ECMAScript and WebAssembly, and runs on Windows, macOS, and Linux systems that use x64, IA-32, or ARM processors. Additional systems (IBM i, AIX) and processors (MIPS, ppcle64, s390x) are externally maintained, see ports. V8 can be embedded into any C++ application.\n\nV8 compiles and executes JavaScript source code, handles memory allocation for objects, and garbage collects objects it no longer needs. V8’s stop-the-world, generational, accurate garbage collector is one of the keys to V8’s performance.\n\nJavaScript is commonly used for client-side scripting in a browser, being used to manipulate Document Object Model (DOM) objects for example. The DOM is not, however, typically provided by the JavaScript engine but instead by a browser. The same is true of V8 — Google Chrome provides the DOM. V8 does however provide all the data types, operators, objects and functions specified in the ECMA standard.\n\nV8 enables any C++ application to expose its own objects and functions to JavaScript code. It’s up to you to decide on the objects and functions you would like to expose to JavaScript.\n• Contributing\n• Checklist for staging and shipping of WebAssembly features\n• Under the hood\n• Slack Tracking - what is it?"
    },
    {
        "link": "https://v8.github.io/api/head/classv8_1_1MicrotasksScope.html",
        "document": "This scope is used to control microtasks when MicrotasksPolicy::kScoped is used on Isolate. In this mode every non-primitive call to V8 should be done inside some MicrotasksScope. Microtasks are executed when topmost MicrotasksScope marked as kRunMicrotasks exits. kDoNotRunMicrotasks should be used to annotate calls not intended to trigger microtasks."
    },
    {
        "link": "https://stackoverflow.com/questions/79125882/runtime-error-when-running-samples-from-v8-dll",
        "document": "The above dll compilation works and runs all ok, in the context of programs already build in v8 own compile environment. It even compiles successfully with VisualStudio, but crashes at runtime as described. It is not as trivial as it looks. This direction of investigation is still in progress, so if I have some progress I will add updates.\n\n Two notes on 17 Jun 2024:\n\n Note 1: 17 Jun 2024 MSVC will be unsupported after V8 version 13.0\n\n Note 2: 17 Jun 2024 V8 will follow Chromium's lead and will stop providing infrastructure for GCC builds\n\n I had to follow at once the steps recommended for VisualStudio, to build as a single lib v8_monolith.lib, the steps requiring the least amount of investigations so far. It requires manual changes, which permanently are modified, any change on V8 causes headaches to embedders.\n\n MSVC has some degree of compatibility with clang, but there is no default V8 build configuration contained for this case. I decided to gather in this response the information valid for today date, because all info is fragmentary or outdated (guides as build v8 and not go mad, or Building Google v8 not too old, but already outdated), so it taken time until I put all of following together.\n\n Note, if you compile on an external SSD drive, the depot_tools will fail to update, and none of following steps will work. So, depot_tools should be on internal HDD or SSD, and everything else can be built on external SSD.\n• As described in v8 build documentation\n\nAn editor will open, so enter following\n• Then as described in v8-user forum , in section as of now line 95, add .\n• If above steps are successful, the is contained in the generated subfolder folder.\n\nNow, following steps for VisualStudio 2022 Community Edition. Configuring a newly created C++ project. It works with both, msvc and clang.\n• Platform toolset can be some of recent ones, or , both work.\n• C/C++->Code Generation->Runtime Library to be set to\n\nThen compiled following code from with little modifications, so far it runs ok:"
    },
    {
        "link": "https://stackoverflow.com/questions/52023157/how-would-one-enable-and-use-es6-modules-in-the-v8-javascript-engine",
        "document": "I use an embedded V8 engine in my (Windows Desktop) C++ application. I understand that V8 has support for ES6 modules. How would I go about activating and using this feature in my application?\n\nI would not expect anyone to have a complete worked example of how this works, but a high level answer pointing me (and future readers) in the right direction would entirely fulfil my hopes and aspirations for this question."
    },
    {
        "link": "https://blog.j2i.net/2023/10/24/recompiling-the-v8-javascript-engine-on-windows",
        "document": "Note Added 2025 March 10 – These instructions no longer work. Google has dropped support for using MSVC. It is still possible to build on Windows using Clang. But this presents new challenges, such as linking CLang binaries to MSVC binaries. More information on this change can be found in a Google Group discussion here.\n\nNote Added 2024 September 3 – I tried to follow my own instructions on a whim today and found that some parts of the instructions don’t work. I made my way through them with adjustments to get to success.\n\nI decided to compile the Google V8 JavaScript engine. Why? So that I could include it in another program. Google doesn’t distribute the binaries for V8, but they do make the source code available. Compiling it is, in my opinion, a bit complex. This isn’t a criticism. There are a lot of options for how V8 can be built. Rather than making available the permutations of these options for each version of V8, one could just set options themselves and build it for their platform of interest.\n\nBut Isn’t There Already Documentation on How to Do This?\n\nThere does exists documentation from Google on compiling Chrome. But there are variations from those instructions and what must actually be done. I found myself searching the Internet for a number of other issues that I encountered and made notes on what I had to do to get around compilation problems. The documentation comes close to what’s needed, but isn’t without error and deviation.\n\nBefore touching the v8 source code, ensure that you have installed Microsoft Visual Studio. I am using Microsoft Visual Studio 2022 Community Edition. There are some additional components that must be installed. In an attempt to make this setup process as scriptable as possible, I’ve have a batch file that will have the Visual Studio Installer add the necessary components. If a component is already installed, no action is taken. Though the Google V8 instructions also offer a command to type to accomplish the same thing, this is where I encountered my first variation from their instructions. Their instructions assume that the name of the Visual Studio Installer command to be (it probably was on a previous version of Visual Studio) where my installer is named . There were also additional parameters that I had to pass, possibly because I have more than one version of Visual Studio installed (Community Edition 2022, Preview Community Edition 2022, and a 2019 version).\n\nYou may need to make adjustments if your installer is located in a different path.\n\nWhile those components are installing, let’s get the code downloaded and put int place. I did the download and unpacking from powershell. All of the commands that follow were stored in a power shell script. Scripting the process makes it more repeatable and is easier to document (since the scripts are also a record of what was done). You do not have to use the same file paths that I do. But if you change them, you will need to make adjustments to the instructions when one of these paths is used.\n\nI generally avoid placing folders directly in the root. The one exception to that being a folder I make called . There’s a structure that I conform to when placing this folder on Windows machines. For this structure, Google’s code will be placed in subdirectories of . In the following script you’ll see that path used.\n\nAfter this script completes running, Visual Studio should have the necessary components and the V8/Chrome development tools are downloaded and in place.\n\nThere are some environment variables on which the build process is dependent. These variables could be set within batch files, could be set to be part of the environment for an instance of the command terminal, or set at the system level. I chose to set them at the system level. This was not my first approach. I set them at more local levels initially. But several times when I needed to open a new command terminal, I forgot to apply them, and just found it easier to set them globally.\n\nFrom here on, we will be using the command prompt, and not PowerShell. This is because some of the commands that are part of Google’s tools are batch files that only run properly in the command prompt.\n\nFrom the command terminal, run the command . This will initialize the Google Tools. Next, navigate to the folder in which you want the v8 code to download. For me, this will be . The download process will automatically make a subfolder named . Run the following command.\n\nThis command can take a while to complete. After it completes you will have a new directory named that contains the source code. Navigate to that directory.\n\nThe online documentation that I see from Google for v8 is for version 9. I wanted to compiled version 12.0.174.\n\nReviewing the instructions now, I find that the above command fails. It may be necessary to fetch the labels for the versions with the following commands to get version 13.6.9.\n\nToday I am trying to only rebuild v8 for Windows. Eventually I’ll rebuild it for ARM64 also. Run the following commands. It will make the build directories and configurations for different targets.\n\nThe build arguments for each environment are in a file named . Let’s update the configuration for the x64 debug build. To open the build configuration, type the following.\n\nThis will open the configuration in notepad. Replace the contents with the following.\n\nChances are the only difference between the above and the initial version of the file are from the line onwards. Save the file. You are ready to start your build. To kick off the build, use the following command.\n\nUpdate 2024 September 3 – Compiling this now, I’m encountering a different error. It appears the compilier I’m using takes issues with some of the nested directives in the source code. There was in in around line 1274 that was problematic. It involved a line concerning enabling V8 Drumbrake. Nope, I don’t know what that is. This was for a call to , which is not used in production builds. I just removed it. I encountered similar errors in , ,\n\nThis will also take a while to run, but this will fail. There is a third party component that will fail concerning a line in a file named . You’ll have to alter a function to fix the problem. Open the file in the path . Around line 59, you will find the following code.\n\nYou’ll need to change it so that it contains the following.\n\nSave the file, and run the build command again. While that’s running, go find something else to do. Have a meal, fly a kite, read a book. You’ve got time. When you return, the build should have been successful.\n\nNow, let’s make a hellow world program. Google already has a v8 hellow would example that we can use to see that our build was successful. We will use it for now, as I’ve not discussed anything about the v8 object library yet. Open Microsoft Visual Studio and create a new C++ Console application. Replace te code in the cpp file that it provides with Google’s code.\n\nIf you try to build this now, it will fail. You need to do some configuration. Here is a quick list of the configuration changes. If you don’t understand what to do with these, that’s find. I’ll will walk you through applying them.\n\nRight-click on the project file and select “Properties.” From the pane on the left, select . In the drop-down on the top, select . On the right there is a field named . Select it, and add the full path to your directory. For me, this will be . If you build in a different path, it will be different for you. After adding the value, select You will generally want to press after each field that you’ve changed.\n\nChange the Configuration drop-down at the top to . In the entry, add the full path to your folder and click Apple. Change the Configuration dropdown to and in add the full path to your folder.\n\nFrom the pane on the left, expand and select . On the right, set the value for to and set the value for the field to .\n\nChange the Configurations option to and set add the following values to\n\nKeep the Configurations option on . Expand and select . For enter\n\nWith that entered, press Okay. You should now be able to run the program. It will pass some values to the JavaScript engine to execute and print out the values.\n\nMy next set of objectives is to demonstrate how to project a C++ object into JavaScript. I also want to start thinning out the size of these files. On a machine that is using the v8 binaries, the entire build tools are not needed. At the end of the above process the b8 folder has 12 gigs of files. If you copy out only the build files and headers needed for other projects, the file size is reduced to 3 gigs. Further reductions could occur through changing some of the compilation options."
    },
    {
        "link": "https://github.com/danbev/learning-v8",
        "document": "The sole purpose of this project is to aid me in leaning Google's V8 JavaScript engine.\n\nAn Isolate is an independant copy of the V8 runtime which includes its own heap. Two different Isolates can run in parallel and can be seen as entirely different sandboxed instances of a V8 runtime.\n\nTo allow separate JavaScript applications to run in the same isolate a context must be specified for each one. This is to avoid them interfering with each other, for example by changing the builtin objects provided.\n\nThis is the super class of both ObjecTemplate and FunctionTemplate. Remember that in JavaScript a function can have fields just like objects.\n\nThe function can be used to have an name and a value set on an instance created from this template. The is for properties that are get/set using functions.\n\nThese allow you to create JavaScript objects without a dedicated constructor. When an instance is created using an ObjectTemplate the new instance will have the properties and functions configured on the ObjectTemplate.\n\nThis would be something like:\n\nThis class is declared in include/v8.h and extends Template:\n\nWe create an instance of ObjectTemplate and we can add properties to it that all instance created using this ObjectTemplate instance will have. This is done by calling which is member of the class. You specify a Local for the property. is a superclass for and which can be both be used as names for a property.\n\nThe implementation for can be found in :\n\nThere is an example in objecttemplate_test.cc\n\nIs a template that is used to create functions and like ObjectTemplate it inherits from Template:\n\nRememeber that a function in javascript can have properties just like object.\n\nThere is an example in functiontemplate_test.cc\n\nAn instance of a function template can be created using:\n\nAnd the function can be called using:\n\nFunction::Call can be found in :\n\nNotice that the return value of which is a will be passed to ToLocal which is defined in :\n\nSo lets take a look at which can be found in and it calls:\n\nwill return an . TODO: Take a closer look at InvokeParams.\n\nIn our case is false as we are not using and the receiver, the in the function should be set to the receiver that we passed in. After that we have\n\nThe call to f(info) is what invokes the callback, which is just a normal function call.\n\nBack in we have:\n\nNotice that if there was an exception an empty object is returned. Later in in a:\n\nLooking at this is looks like passing back an empty object will cause an exception to be triggered?\n\ncan be found in :\n\nis an optional type specified in and is capable of storing a data pointer. It is an unsigned integer type that any valid pointer to void can be converted to this type (and back).\n\nThis class is declared in `src/objects/tagged-impl.h and has a single private member which is declared as:\n\nAn instance can be created using:\n\nStorage type can also be which is defined in globals.h:\n\nIt looks like it can be a different value when using pointer compression.\n\nSee tagged_test.cc for an example.\n\nAn Object can be created using the default constructor, or by passing in an Address which will delegate to TaggedImpl constructors. Object itself does not have any members (apart from which is inherited from TaggedImpl that is). So if we create an Object on the stack this is like a pointer/reference to an object:\n\nNow, is a StorageType so it could be a in which case it would just contains the value directly, for example a small integer:\n\nSee object_test.cc for an example.\n\nSee objectslot_test.cc for an example.\n\nA Maybe is like an optional which can either hold a value or nothing.\n\nI first thought that name was a little confusing but if you read this like:\n\nI think it makes more sense. There are functions that check if the Maybe is nothing and crash the process if so. You can also check and return the value by using .\n\nThe usage of Maybe is where api calls can fail and returning Nothing is a way of signaling this.\n\nSee maybe_test.cc for an example.\n\nwill crash the process if is a nullptr. If you want to avoid a crash one can use .\n\nSee maybelocal_test.cc for an example.\n\nIs the super class of all objects that can exist the V8 heap:\n\nValue extends and adds a number of methods that check if a Value is of a certain type, like , , etc. It also has useful methods to convert to a Local, for example:\n\nA Handle is similar to a Object and ObjectSlot in that it also contains an Address member (called and declared in ), but with the difference is that Handles acts as a layer of abstraction and can be relocated by the garbage collector. Can be found in .\n\nAnd this is the same as the value in obj:\n\nAnd we can access the int using any of the pointers:\n\nSee handle_test.cc for an example.\n\nContains a number of Local/Handle's (think pointers to objects but is managed by V8) and will take care of deleting the Local/Handles for us. HandleScopes are stack allocated\n\nWhen ~HandleScope is called all handles created within that scope are removed from the stack maintained by the HandleScope which makes objects to which the handles point being eligible for deletion from the heap by the GC.\n\nA HandleScope only has three members:\n\nLets take a closer look at what happens when we construct a HandleScope:\n\nThe constructor call will end up in and the constructor simply delegates to :\n\nEvery has member of type HandleScopeData:\n\nNotice that there are two pointers (Address*) to next and a limit. When a HandleScope is Initialized the current handle_scope_data will be retrieved from the internal isolate. The HandleScope instance that is getting created stores the next/limit pointers of the current isolate so that they can be restored when this HandleScope is closed (see CloseScope).\n\nSo with a HandleScope created, how does a Local interact with this instance?\n\nWhen a Local is created this will/might go through FactoryBase::NewStruct which will allocate a new Map and then create a Handle for the InstanceType being created:\n\nThis will land in the constructor Handlesrc/handles/handles-inl.h\n\nNotice that is used to pass the Address to HandleBase. And also notice that HandleBase sets its location_ to the result of HandleScope::GetHandle.\n\nWhich will call in this case and this function will retrieve the current isolate's handle_scope_data:\n\nIn this case both next and limit will be 0x0 so Extend will be called. Extend will also get the isolates handle_scope_data and check the current level and after that get the isolates HandleScopeImplementer:\n\nHandleScope:CreateHandle will get the handle_scope_data from the isolate:\n\nNotice that is set to the address passed in + the size of an Address.\n\nThe destructor for HandleScope will call CloseScope. See handlescope_test.cc for an example.\n\nLocal handles are located on the stack and are deleted when the appropriate destructor is called. If there is a local HandleScope then it will take care of this when the scope returns. When there are no references left to a handle it can be garbage collected. This means if a function has a HandleScope and wants to return a handle/local it will not be available after the function returns. This is what EscapableHandleScope is for, it enable the value to be placed in the enclosing handle scope to allow it to survive. When the enclosing HandleScope goes out of scope it will be cleaned up.\n\nSo when an EscapableHandleScope is created it will create a handle with the hole value and store it in the which is of type Address. This Handle will be created in the current HandleScope, and EscapableHandleScope can later set a value for that pointer/address which it want to be escaped. Later when that HandleScope goes out of scope it will be cleaned up. It then calls Initialize just like a normal HandleScope would.\n\nWhen Escape is called the following happens (v8.h):\n\nIf the escape_value is null, the that is a pointer into the parent HandleScope is set to the undefined_value() instead of the hole value which is was previously, and nullptr will be returned. This returned address/pointer will then be returned after being casted to T*. Next, we take a look at what happens when the EscapableHandleScope goes out of scope. This will call HandleScope::~HandleScope which makes sense as any other Local handles should be cleaned up.\n\ncopies the value of its argument into the enclosing scope, deletes alli its local handles, and then gives back the new handle copy which can safely be returned.\n\nHas a single member which is of type pointer to :\n\nNotice that this is a pointer to T. We could create a local using:\n\nSo a Local contains a pointer to type T. We can access this pointer using and .\n\nWe can cast from a subtype to a supertype using Local::Cast:\n\nAnd there is also the\n\nSee local_test.cc for an example.\n\nUsing _v8_internal_Print_Object from c++:\n\nNotice that this function does not have a namespace. We can use this as:\n\nLets take a closer look at the above:\n\nWe use the dereference operator to get the value of a Local (*global), which is just of type , a pointer to the type the Local:\n\nWe are then casting that to be of type pointer-to-pointer to Object.\n\nAn instance of only has a single data member which is a field named of type :\n\nLets take a look at one of these functions and see how it is implemented. For example in the OBJECT_TYPE_LIST we have:\n\nSo the object class will have a function that looks like:\n\nAnd in src/objects/objects-inl.h we will have the implementations:\n\nThe macro can be found in src/common/globals.h:\n\nSo we are casting which is of type Address into type which is defined in src/common/global.h and can be different depending on if compressed pointers are used or not. If they are not supported it is the same as Address:\n\nThe HeapObjectReferenceType can be either WEAK or STRONG. And the storage type is in this case. So Object itself only has one member that is inherited from its only super class and this is .\n\nSo the following is telling the compiler to treat the value of our Local, , as a pointer (which it already is) to a pointer that points to a memory location that adhers to the layout of an type, which we know now has a member. And we want to dereference it and pass it into the function.\n\nBut I'm still missing the connection between ObjectTemplate and object. When we create it we use:\n\nIn we have:\n\nWhat is a in this context?\n\n\n\nNotice that the include is specifying include which can be found . So, somewhere there must be an call to the executable which generates the Code Stub Assembler C++ headers and sources before compiling the main source files. There is and there is a section about this in . The macro can be found in and expands to:\n\nSo what does the TorqueGeneratedStruct look like?\n\nWhere D is Struct and P is HeapObject in this case. But the above is the declartion of the type but what we have in the .h file is what was generated.\n\nThis type is defined in :\n\ncan be found in\n\nEvery object that is stored on the v8 heap has a Map ( ) that describes the structure of the object being stored.\n\nSo this is the connection, what we see as a Local is a HandleBase. TODO: dig into this some more when I have time.\n\nYou can reload using the following command:\n\nThis can be useful when debugging a lldb command. You can set a breakpoint and break at that location and make updates to the command and reload without having to restart lldb.\n\nCurrently, the lldb-commands.py that ships with v8 contains an extra operation of the parameter pased to :\n\nNotice that is the object that we want to print, for example lets say it is a local named obj:\n\nThis will then be \"passed\"/formatted into the command string:\n\nV8 is single threaded (the execution of the functions of the stack) but there are supporting threads used for garbage collection, profiling (IC, and perhaps other things) (I think). Lets see what threads there are:\n\nSo at startup there is only one thread which is what we expected. Lets skip ahead to where we create the platform:\n\nNext there is a check for 0 and the number of processors -1 is used as the size of the thread pool:\n\nThis is all that does. After this we have:\n\nwill create a new pthread (on my system which is MacOSX):\n\nThreadEntry can be found in src/base/platform/platform-posix.\n\nInternational Components for Unicode (ICU) deals with internationalization (i18n). ICU provides support locale-sensitve string comparisons, date/time/number/currency formatting etc.\n\nThere is an optional API called ECMAScript 402 which V8 suppports and which is enabled by default. i18n-support says that even if your application does not use ICU you still need to call InitializeICU :\n\nSo what is script_name. Well it is an object reference that is managed by the v8 GC. The GC needs to be able to move things (pointers around) and also track if things should be GC'd. Local handles as opposed to persistent handles are light weight and mostly used local operations. These handles are managed by HandleScopes so you must have a handlescope on the stack and the local is only valid as long as the handlescope is valid. This uses Resource Acquisition Is Initialization (RAII) so when the HandleScope instance goes out of scope it will remove all the Local instances.\n\nThe class (in ) only has one member which is of type pointer to the type . So for the above example it would be:\n\nYou can find the available operations for a Local in .\n\nA Local has overloaded a number of operators, for example ->:\n\nWhere Length is a method on the v8 String class.\n\nThe handle stack is not part of the C++ call stack, but the handle scopes are embedded in the C++ stack. Handle scopes can only be stack-allocated, not allocated with new.\n\nhttps://v8.dev/docs/embed: Persistent handles provide a reference to a heap-allocated JavaScript Object, just like a local handle. There are two flavors, which differ in the lifetime management of the reference they handle. Use a persistent handle when you need to keep a reference to an object for more than one function call, or when handle lifetimes do not correspond to C++ scopes. Google Chrome, for example, uses persistent handles to refer to Document Object Model (DOM) nodes.\n\nA persistent handle can be made weak, using PersistentBase::SetWeak, to trigger a callback from the garbage collector when the only references to an object are from weak persistent handles.\n\nA UniquePersistent handle relies on C++ constructors and destructors to manage the lifetime of the underlying object. A Persistent can be constructed with its constructor, but must be explicitly cleared with Persistent::Reset.\n\nSo how is a persistent object created?\n\n Let's write a test and find out ( ):\n\nNow, to create an instance of Persistent we need a Local instance or the Persistent instance will just be empty.\n\ncan be found in :\n\nThe first thing that happens is that the public Isolate pointer is cast to an pointer to the internal type. is a macro in the same source file (src/api/api.cc):\n\nIf our case the preprocessor would expand that to:\n\nis a macro that can be found in :\n\nAnd this would expand to:\n\nSo with the LOG_API macro expanded we have:\n\nNext we have :\n\nSo with the macros expanded we have:\n\nFirst, is called and the result passed to . is generated by a macro named :\n\nis a macro in and it c\n\nI'm not clear on the different types of context, there is a native context, a \"normal/public\" context. In we have the native_context function:\n\nextends so the get function is the get function of FixedArray and is the index into the array where the native context is stored.\n\nNow, lets take a closer look at . If you search for NewJSObject in :\n\nSo we have created a new map\n\nSo an HeapObject contains a pointer to a Map, or rather has a function that returns a pointer to Map. I can't see any member map in the HeapObject class.\n\nLets take a look at when a map is created.\n\nWe can see that the above is calling on the heap instance passing a size of and specifying the :\n\nThe default value for is . Reading the docs in the header it says that this function will try to perform an allocation of size in the and if it fails a full GC will be performed and the allocation retried. Lets take a look at :\n\ncan be found in . There are different paths that will be taken depending on the parameteter. Since it is in our case we will focus on that path:\n\ncan be found in :\n\nThe default value for is . So lets take a look at :\n\nRecall that in our case is .\n\nNotice that first the top is set to the new_top and then the current_top is returned and that will be a pointer to the start of the object in memory (which in this case is of v8::internal::Map which is also of type HeapObject). I've been wondering why Map (and other HeapObject) don't have any member fields and only/mostly getters/setters for the various fields that make up an object. Well the answer is that pointers to instances of for example Map point to the first memory location of the instance. And the getters/setter functions use indexed to read/write to memory locations. The indexes are mostly in the form of enum fields that define the memory layout of the type.\n\nNext, in we have the macro:\n\ncan be found in and stands for and would only be used if is defined. The returned will be used to construct an when returned. Back in we have:\n\nThis will return us in :\n\nThis will return us back in :\n\nAnd that return will return to in :\n\ncan be found in objects.cc:\n\nSo, the first thing that will happen is will be called. This is function that is generated by the preprocessor.\n\nLets look closer at in in object-inl.h:\n\ncan be found in :\n\nThe preprocessor will expand to:\n\nNotice that will be called first which looks like this:\n\nFirst thing that will happen is\n\nThis will get expanded by the preprocessor to:\n\nSo this will do an atomoic load of the ptr with the memory order of __ATOMIC_RELELAXED.\n\nWhat does do?\n\nWhich would expand into:\n\nLets take a look at what does:\n\nTo see what the above is doing we can do the same thing in the debugger: Note that I got below from\n\nThe above command will break in :\n\nThe preprocessor will expand that to:\n\nSo where can we find ?\n\n It is generated by a macro in :\n\nAlright, lets see what preprocessor expands that to:\n\nSo this would create a struct with an enum and it could be accessed using: The next part of the macro is\n\nWhich will get expanded to:\n\nSo this is how is declared and notice that it is of type which can be found in :\n\nAnd the result of that is passed to :\n\nSo, is the current Map instance, and we are going to read from.\n\nWhich will get expanded to:\n\nThe instance_size is the instance_size_in_words << kPointerSizeLog2 (3 on my machine):\n\nis 8 on my system which is used in the `DEFINE_FIELD_OFFSET_CONSTANTS:\n\nSo we can use this information to read the directly from memory using:\n\nInspect the visitor_id (which is the last of the first byte):\n\nInspect the instance_type (which is part of the second byte):\n\nNotice that is a short so that will take up 2 bytes\n\nVerify that the above is correct:\n\nSo we know that a Map instance is a pointer allocated by the Heap and with a specific size. Fields are accessed using indexes (remember there are no member fields in the Map class). We also know that all HeapObject have a Map. The Map is sometimes referred to as the HiddenClass and sometimes the shape of an object. If two objects have the same properties they would share the same Map. This makes sense and I've see blog post that show this but I'd like to verify this to fully understand it. I'm going to try to match https://v8project.blogspot.com/2017/08/fast-properties.html with the code.\n\nSo, lets take a look at adding a property to a JSObject. We start by creating a new Map and then use it to create a new JSObject:\n\nLets take a closer look at and how it interacts with the Map. This function can be found in :\n\nFirst we have the LookupIterator constructor ( ) but since this is a new property which we know does not exist it will not find any property.\n\nLets take a closer look the Decriptor which can be found in :\n\nis declared in and describes the elements in a instance-descriptor array. These are returned when calling . Let check some of the arguments:\n\nThe Descriptor class contains three members:\n\nLets take a closer look which only has a single member named\n\nIt also declares a number of classes the extend BitField, for example:\n\nThe Type T of KindField will be , the will be 0 , and the 1. Notice that is using as its shift. This is a static class constant of type and is defined as:\n\nSo would get the value from KindField which should be:\n\nThe constructor for PropertyDetails looks like this:\n\nSo what does KindField::encode(kind) actualy do then?\n\nThis value is later returned by calling :\n\nSo we have all this information about this property, its type (Representation), constness, if it is read-only, enumerable, deletable, sealed, frozen. After that little detour we are back in :\n\nHere we are using the key (name of the property), the wrapped_field_type, and PropertyDetails we created. What is again?\n\n If we back up a few frames back into we can see that the type passed in is taken from the following code:\n\nSo this is only taking the type of the field:\n\nThis makes sense as the map only deals with the shape of the propery and not the value. Next in we have:\n\nLets take a closer look at\n\nTODO: Take a closer look at LayoutDescritpor\n\nLater when actually adding the value in :\n\nThis call will end up in and in our case the path will be the following call:\n\nTODO: Take a closer look at LookupIterator. can be found in :\n\ncan be found in :\n\nNotice that this is calling on the passed-in map. This as we recall from earlier returns and DescriptorArray (which is a type of WeakFixedArray). A Descriptor array\n\nOur DecsriptorArray only has one entry:\n\nWe can also use on the DescriptorArray:\n\nIn our case we are accessing the PropertyDetails and then getting the which I think tells us where in the object the value for this property is stored. The last call in is `ForProperty:\n\nI was expecting to be 1 here but it is 0:\n\nWhy is that, what am I missing?\n\n These in-object properties are stored directly on the object instance and not do not use the properties array. All get back to an example of this later to clarify this. TODO: Add in-object properties example.\n\nIn our case we know that the index is not inobject()\n\nSo, will be called.\n\nJSObject inherits from JSReceiver which is where the property_array() function is declared.\n\nLooking at the above values printed we should see the property be written to entry 0.\n\nSo a map has an pointer array of instance of DescriptorArray\n\nEach Map has int that tells us the number of properties it has. This is the number specified when creating a new Map, for example:\n\nBut at this stage we don't really have any properties. The value for a property is associated with the actual instance of the Object. What the Map specifies is index of the value for a particualar property.\n\nLets take a look at when a map is created.\n\nWe can see that the above is calling on the heap instance passing a size of and specifying the :\n\nThe default value for is . Reading the docs in the header it says that this function will try to perform an allocation of size in the and if it fails a full GC will be performed and the allocation retried. Lets take a look at :\n\ncan be found in . There are different paths that will be taken depending on the parameteter. Since it is in our case we will focus on that path:\n\ncan be found in :\n\nThe default value for is . So lets take a look at :\n\nRecall that in our case is .\n\nNotice that first the top is set to the new_top and then the current_top is returned and that will be a pointer to the start of the object in memory (which in this case is of v8::internal::Map which is also of type HeapObject). I've been wondering why Map (and other HeapObject) don't have any member fields and only/mostly getters/setters for the various fields that make up an object. Well the answer is that pointers to instances of for example Map point to the first memory location of the instance. And the getters/setter functions use indexed to read/write to memory locations. The indexes are mostly in the form of enum fields that define the memory layout of the type.\n\nNext, in we have the macro:\n\ncan be found in and stands for and would only be used if is defined. The returned will be used to construct an when returned. Back in we have:\n\nThis will return us in :\n\nThis will return us back in :\n\nAnd that return will return to in :\n\nContext extends ( ). So an instance of this Context is a FixedArray and we can use Get(index) etc to get entries in the array.\n\nThis can be found in quite a few places in v8 source code. For example:\n\nWhat is this?\n\n It is a preprocessor macro which looks like this:\n\nSo we can see that if , and , and also if , is set to . But in all other cases is empty and the preprocessor does not insert anything (nothing will be there come compile time). But what about the what is this?\n\nIn the GNU compiler collection (GCC) environment, the term that is used for exporting is visibility. As it applies to functions and variables in a shared object, visibility refers to the ability of other shared objects to call a C/C++ function. Functions with default visibility have a global scope and can be called from other shared objects. Functions with hidden visibility have a local scope and cannot be called from other shared objects.\n\nVisibility can be controlled by using either compiler options or visibility attributes. In your header files, wherever you want an interface or API made public outside the current Dynamic Shared Object (DSO) , place in struct, class and function declarations you wish to make public. With , you are telling GCC that every declaration not explicitly marked with a visibility attribute has a hidden visibility. There is such a flag in build/common.gypi\n\nYou'll see a few of these calls in the hello_world example:\n\nNewFromUtf8 actually returns a Local wrapped in a MaybeLocal which forces a check to see if the Local<> is empty before using it. NewStringType is an enum which can be kNormalString (k for constant) or kInternalized.\n\nThe following is after running the preprocessor (clang -E src/api.cc):\n\nI was wondering where the Utils::ToLocal was defined but could not find it until I found:\n\nThe above can be found in . The same goes for etc.\n\nReading through v8.h I came accross Smi stands for small integers.\n\nA pointer is really just a integer that is treated like a memory address. We can use that memory address to get the start of the data located in that memory slot. But we can also just store an normal value like 18 in it. There might be cases where it does not make sense to store a small integer somewhere in the heap and have a pointer to it, but instead store the value directly in the pointer itself. But that only works for small integers so there needs to be away to know if the value we want is stored in the pointer or if we should follow the value stored to the heap to get the value.\n\nA word on a 64 bit machine is 8 bytes (64 bits) and all of the pointers need to be aligned to multiples of 8. So a pointer could be:\n\nRemember that we are talking about the pointers and not the values store at the memory location they point to. We can see that there are always three bits that are zero in the pointers. So we can use them for something else and just mask them out when using them as pointers.\n\nTagging involves borrowing one bit of the 32-bit, making it 31-bit and having the leftover bit represent a tag. If the tag is zero then this is a plain value, but if tag is 1 then the pointer must be followed. This does not only have to be for numbers it could also be used for object (I think)\n\nInstead the small integer is represented by the 32 bits plus a pointer to the 64-bit number. V8 needs to know if a value stored in memory represents a 32-bit integer, or if it is really a 64-bit number, in which case it has to follow the pointer to get the complete value. This is where the concept of tagging comes in.\n\nTake the following object:\n\nThe above object has two named properties. Named properties differ from integer indexed which is what you have when you are working with arrays.\n\nWe can see that properies and elements are stored in different data structures. Elements are usually implemented as a plain array and the indexes can be used for fast access to the elements. But for the properties this is not the case. Instead there is a mapping between the property names and the index into the properties.\n\nIn we can find JSObject:\n\nAnd looking a the macro:\n\nNotice that JSObject extends JSReceiver which is extended by all types that can have properties defined on them. I think this includes all JSObjects and JSProxy. It is in JSReceiver that the we find the properties array:\n\nNow properties (named properties not elements) can be of different kinds internally. These work just like simple dictionaries from the outside but a dictionary is only used in certain curcumstances at runtime.\n\nEach JSObject has as its first field a pointer to the generated HiddenClass. A hiddenclass contain mappings from property names to indices into the properties data type. When an instance of JSObject is created a is passed in. As mentioned earlier JSObject inherits from JSReceiver which inherits from HeapObject\n\nFor example,in jsobject_test.cc we first create a new Map using the internal Isolate Factory:\n\nWhen we call this will delegate to the map instance:\n\nHow do you add a property to a JSObject instance? Take a look at jsobject_test.cc for an example.\n\nAre ways to optimize polymorphic function calls in dynamic languages, for example JavaScript.\n\nSending a message to a receiver requires the runtime to find the correct target method using the runtime type of the receiver. A lookup cache maps the type of the receiver/message name pair to methods and stores the most recently used lookup results. The cache is first consulted and if there is a cache miss a normal lookup is performed and the result stored in the cache.\n\nUsing a lookup cache as described above still takes a considerable amount of time since the cache must be probed for each message. It can be observed that the type of the target does often not vary. If a call to type A is done at a particular call site it is very likely that the next time it is called the type will also be A. The method address looked up by the system lookup routine can be cached and the call instruction can be overwritten. Subsequent calls for the same type can jump directly to the cached method and completely avoid the lookup. The prolog of the called method must verify that the receivers type has not changed and do the lookup if it has changed (the type if incorrect, no longer A for example).\n\nThe target methods address is stored in the callers code, or \"inline\" with the callers code, hence the name \"inline cache\".\n\nIf V8 is able to make a good assumption about the type of object that will be passed to a method, it can bypass the process of figuring out how to access the objects properties, and instead use the stored information from previous lookups to the objects hidden class.\n\nA polymorfic call site is one where there are many equally likely receiver types (and thus call targets).\n• Monomorfic means there is only one receiver type\n\nThis type of caching extends inline caching to not just cache the last lookup, but cache all lookup results for a given polymorfic call site using a specially generated stub. Lets say we have a method that iterates through a list of types and calls a method. If all the types are the same (monomorfic) a PIC acts just like an inline cache. The calls will directly call the target method (with the method prolog followed by the method body). If a different type exists in the list there will be a cache miss in the prolog and the lookup routine called. In normal inline caching this would rebind the call, replacing the call to this types target method. This would happen each time the type changes.\n\nWith PIC the cache miss handler will generate a small stub routine and rebinds the call to this stub. The stub will check if the receiver is of a type that it has seen before and branch to the correct targets. Since the type of the target is already known at this point it can directly branch to the target method body without the need for the prolog. If the type has not been seen before it will be added to the stub to handle that type. Eventually the stub will contain all types used and there will be no more cache misses/lookups.\n\nThe problem is that we don't have type information so methods cannot be called directly, but instead be looked up. In a static language a virtual table might have been used. In JavaScript there is no inheritance relationship so it is not possible to know a vtable offset ahead of time. What can be done is to observe and learn about the \"types\" used in the program. When an object is seen it can be stored and the target of that method call can be stored and inlined into that call. Bascially the type will be checked and if that particular type has been seen before the method can just be invoked directly. But how do we check the type in a dynamic language? The answer is hidden classes which allow the VM to quickly check an object against a hidden class.\n\nThe inline caching source are located in .\n\nLoadIC (0->.) means that it has transitioned from unititialized state (0) to pre-monomophic state (.) monomorphic state is specified with a . These states can be found in src/ic/ic.cc. What we are doing caching knowledge about the layout of the previously seen object inside the StoreIC/LoadIC calls.\n\nThis class describes heap allocated objects. It is in this class we find information regarding the type of object. This information is contained in .\n• contains information about the number of properties that this Map has, a pointer to an DescriptorArray. The DescriptorArray contains information like the name of the property, and the posistion where the value is stored in the JSObject. I noticed that this information available in src/objects/map.h.\n\nCan be found in src/objects/descriptor-array.h. This class extends FixedArray and has the following entries:\n\nEach Internal Isolate has a Factory which is used to create instances. This is because all handles needs to be allocated using the factory (src/heap/factory.h)\n\nThis class extends HeapObject and describes , , , and objects.\n\nExtends HeapObject and all heap objects have a Map which describes the objects structure. This is where you can find the size of the instance, access to the inobject_properties.\n\nWhen a script is compiled all of the top level code is parsed. These are function declarartions (but not the function bodies).\n\nThe non top level code must be pre-parsed to check for syntax errors. The top level code is parsed and compiles by the full-codegen compiler. This compiler does not perform any optimizations and it's only task is to generate machine code as quickly as possible (this is pre turbofan)\n\nSo the whole script is parsed even though we only generated code for the top-level code. The pre-parse (the syntax checking) was not stored in any way. The functions are lazy stubs that when/if the function gets called the function get compiled. This means that the function has to be parsed (again, the first time was the pre-parse remember).\n\nIf a function is determined to be hot it will be optimized by one of the two optimizing compilers crankshaft for older parts of JavaScript or Turbofan for Web Assembly (WASM) and some of the newer es6 features.\n\nThe first time V8 sees a function it will parse it into an AST but not do any further processing of that tree until that function is used.\n\nInline Cachine (IC) is done here which also help to gather type information. V8 also has a profiler thread which monitors which functions are hot and should be optimized. This profiling also allows V8 to find out information about types using IC. This type information can then be fed to Crankshaft/Turbofan. The type information is stored as a 8 bit value.\n\nWhen a function is optimized the unoptimized code cannot be thrown away as it might be needed since JavaScript is highly dynamic the optimzed function migth change and the in that case we fallback to the unoptimzed code. This takes up alot of memory which may be important for low end devices. Also the time spent in parsing (twice) takes time.\n\nThe idea with Ignition is to be an bytecode interpreter and to reduce memory consumption, the bytecode is very consice compared to native code which can vary depending on the target platform. The whole source can be parsed and compiled, compared to the current pipeline the has the pre-parse and parse stages mentioned above. So even unused functions will get compiled. The bytecode becomes the source of truth instead of as before the AST.\n\nIn src/ast/ast.h. You can print the ast using the option for d8.\n\nLets take the following javascript and look at the ast:\n\nYou can find the declaration of EXPRESSION in ast.h.\n\nCan be found in\n• StackCheck checks that stack limits are not exceeded to guard against overflow.\n• Store content in accumulator regiser in register (the operand).\n• Ldar LoaD accumulator from Register argument a1 which is b\n\nThe registers are not machine registers, apart from the accumlator as I understand it, but would instead be stack allocated.\n\nParsing is the parsing of the JavaScript and the generation of the abstract syntax tree. That tree is then visited and bytecode generated from it. This section tries to figure out where in the code these operations are performed.\n\nFor example, take the script example.\n\nLets take a look at the following line:\n\nThis will land us in\n\ncan be found in src/globals.h and it is an enum with three values:\n\nmode, I assume, is the mode when there is no . Remember that this can go inside a function and does not have to be at the top level of the file.\n\nThere is a unit test that shows how a ParseInfo instance can be created and inspected.\n\nThis will call ParseInfo's constructor (in src/parsing/parse-info.cc), and which will call :\n\nI was curious about these ast_string_constants:\n\nSo these are constants that are set on the new ParseInfo instance using the values from the isolate. Not exactly sure what I want with this but I might come back to it later. So, we are back in ParseInfo's constructor:\n\nScript is of type v8::internal::Script which can be found in src/object/script.h\n\nBack now in compiler.cc and the GetSharedFunctionInfoForScript function:\n\nSo here we can see our JavaScript as a String.\n\nThis call will land in parser-base.h and its function.\n\nThis will land in (in the same file which is src/compiler.cc):\n\nThis will land in (in the same file which is src/compiler.cc):\n\nThe bytecode is register based (if that is the correct term) and we had an example previously. I'm guessing that this is what this call is about.\n\nVisitDeclarations will iterate over all the declarations in the file which in our case are:\n\nSo that call will output a stackcheck instruction, like in the example above:\n\nSay you have the expression x + y the full-codegen compiler might produce:\n\nIf x and y are integers just using the operation would be much quicker:\n\nRecall that functions are optimized so if the compiler has to bail out and unoptimize part of a function then the whole functions will be affected and it will go back to the unoptimized version.\n\nThis section will examine the bytecode for the following JavaScript:\n\nFirst have the main function which does not have a name:\n• LdaConstant Load the constant at index from the constant pool into the accumulator.\n• Star Store the contents of the accumulator register in dst.\n• Ldar Load accumulator with value from register src.\n• LdaGlobal Load the global with name in constant pool entry idx into the accumulator using FeedBackVector slot outside of a typeof.\n• Mov , Store the value of register\n\nYou can find the declarations for the these instructions in .\n\nIs attached to every function and is responsible for recording and managing all execution feedback, which is information about types enabling. You can find the declaration for this class in\n\nIs currently the only part of V8 that cares about the AST.\n\nIs a compiler backend that gets fed a control flow graph and then does instruction selection, register allocation and code generation. The code generation generates\n\nI'm not sure if V8 follows this exactly but I've heard and read that when the engine comes across a function declaration it only parses and verifies the syntax and saves a ref to the function name. The statements inside the function are not checked at this stage only the syntax of the function declaration (parenthesis, arguments, brackets etc).\n\nThe declaration of Function can be found in (just noting this as I've looked for it several times)\n\nThe declarations for the Symbol class can be found in and the internal implementation in .\n\nThe well known Symbols are generated using macros so you won't find the just by searching using the static function names like 'GetToPrimitive`.\n\nSo GetToPrimitive would become:\n\nThere is an example in symbol-test.cc.\n\nAre JavaScript functions/objects that are provided by V8. These are built using a C++ DSL and are passed through:\n\nBuiltins need to have bytecode generated for them so that they can be run in TurboFan.\n\nAll the builtins are declared in by the macro. There are different type of builtins (TF = Turbo Fan):\n• TFJ JavaScript linkage which means it is callable as a JavaScript function\n• TFS CodeStub linkage. A builtin with stub linkage can be used to extract common code into a separate code object which can then be used by multiple callers. These is useful because builtins are generated at compile time and included in the V8 snapshot. This means that they are part of every isolate that is created. Being able to share common code for multiple builtins will save space.\n\nTo see how this works in action we first need to disable snapshots. If we don't, we won't be able to set breakpoints as the the heap will be serialized at compile time and deserialized upon startup of v8.\n\nTo find the option to disable snapshots use:\n\nAfter building we should be able to set a break point in bootstrapper.cc and its function :\n\nLets take a look at how the object is setup:\n\nmeans that this object should be allocated directly in the old generation.\n\nis checked by some builtin functions and if set this object will be ignored by those functions.\n\nHere we can see that we are installing a function named , which takes 2 parameters. You can find the definition in src/builtins/builtins-json.cc. What does the do?\n\nLets take as an example which was created using:\n\nSo we can see that base is our Handle to a JSObject, and name is \"debug\". Builtins::Name is Builtins:kConsoleDebug. Where is this defined?\n\n You can find a macro named in :\n\nWhat does this macro expand to?\n\n It is part of the macro in builtin-definitions.h We have to look at where BUILTIN_LIST is used which we can find in builtins.cc. In we have an array of which is declared as:\n\nWhich will expand to the creation of a BuiltinMetadata struct entry in the array. The BuildintMetadata struct looks like this which might help understand what is going on:\n\nSo the will expand to an entry in the array which would look something like this:\n\nThe third paramter is the creation on the union which might not be obvious.\n\nBack to the question I'm trying to answer which is:\n\n \"Buildtins::Name is is Builtins:kConsoleDebug. Where is this defined?\"\n\n For this we have to look at and the enum Name:\n\nThis will expand to the complete list of builtins in builtin-definitions.h using the DEF_ENUM macro. So the expansion for ConsoleDebug will look like:\n\nSo backing up to looking at the arguments to SimpleInstallFunction which are:\n\nWe know about , so lets look at len which is one, what is this?\n\n SimpleInstallFunction will call:\n\nwould be used if adapt was true but it is false in our case. This is what it would be used for if adapt was true:\n\nI'm not exactly sure what adapt is referring to here.\n\nPropertyAttributes is not specified so it will get the default value of . The last parameter which is of type BuiltinFunctionId is not specified either so the default value of will be used. This is an enum defined in .\n\nThis blog provides an example of adding a function to the String object.\n\nYou can then see the generated code from this. This will produce a code stub that can be called through C++. Lets update this to have it be called from JavaScript:\n\nWe also have to update builtins/builtins-definitions.h:\n\nIf you now build using 'ninja -C out.gn/learning_v8' you should be able to run d8 and try this out:\n\nNow lets take a closer look at the code that is generated for this:\n\nLooking at the output generated I was surprised to see two entries for GetStringLength (I changed the name just to make sure there was not something else generating the second one). Why two?\n\nThe following uses Intel Assembly syntax which means that no register/immediate prefixes and the first operand is the destination and the second operand the source.\n\nIs a macro to defining Turbofan (TF) builtins and can be found in\n\nIf we take a look at the file src/builtins/builtins-bigint-gen.cc and the following function:\n\nLet's take our GetStringLength example from above and see what this will be expanded to after processing this macro:\n\nFrom the resulting class you can see how can be used from within macro.\n\nYou'll need to have checked out the Google V8 sources to you local file system and build it by following the instructions found here.\n\nThere is a make target that can generate a build configuration for V8 that is specific to this project. It can be run using the following command:\n\nThen to compile this configuration:\n\nis llvm's C++ runtime. This runtime has a namespace. I looks like the static library above was compiled with clangs/llvm's as we are seeing the namespace.\n\nSo we can see that the namespace is used which we now know is the namespace that libc++ which is clangs libc++ library. I guess we could go about this in two ways, either we can change v8 build of to use glibc++ when compiling so that the symbols are correct when we want to link against it, or we can update our linker (ld) to use libc++.\n\nWe need to include the correct libraries to link with during linking, which means specifying:\n\nIf we look in $(v8_build_dir) we find . We also need to this library to be found at runtime by the dynamic linker using :\n\nNotice that this is using from our path. We can tell clang to use a different search path with the option:\n\nis GCC low level runtime library. I've been confusing this with glibc++ libraries for some reason but they are not the same.\n\nTo get a list of the available tests:\n\nYou can then and see the changes.\n\nSo when we run gn it will generate Ninja build file. GN itself is written in C++ but has a python wrapper around it.\n\nA group in gn is just a collection of other targets which enables them to have a name.\n\nSo when we run gn there will be a number of .ninja files generated. If we look in the root of the output directory we find two .ninja files:\n\nBy default ninja will look for and when we run ninja we usually specify the . If no targets are specified on the command line ninja will execute all outputs unless there is one specified as default. V8 has the following default target:\n\nA rule can be used to create an alias for other targets. The in ninja is an escape character so in the case of the all target it escapes the new line, like using \\ in a shell script.\n\nLets take a look at :\n\nThe format of the ninja build statement is:\n\nWe are again seeing the ninja escape character but this time it is escaping the colon which would otherwise be interpreted as separating file names. The output in this case is bytecode_builtins_list_generator. And I'm guessing, as I can't find a connection between and\n\nThe default in this case is //out/x64.release_gcc/obj. The executable in BUILD.gn which generates this does not specify any output directory so I'm assuming that it the generated .ninja file is place in the target_out_dir in this case where we can find This file has a label named:\n\nHmm, notice that in build.ninja there is the following command:\n\nAnd in we have:\n\nThis is what is making available.\n\nAlright, so I'd like to understand when in the process torque is run to generate classes like TorqueGeneratedStruct:\n\nLike before we can find that obj/torque.ninja in included by the subninja command in toolchain.ninja:\n\nSo this is building the executable , but it has not been run yet.\n\nIf we look in toolchain.ninja we have a rule named\n\nAnd there is a build that specifies the .h and cc files in gen/torque-generated which has this rule in it if they change.\n\nWhen making changes to V8 you might need to verify that your changes have not broken anything in Chromium.\n\nGenerate Your Project (gpy) : You'll have to run this once before building:\n\nAn error I got when building the first time:\n\nI was able to get around this by:\n\nThe instructions below work but it is also possible to create a soft link from chromium/src/v8 to local v8 repository and the build/test.\n\nSo, we want to include our updated version of V8 so that we can verify that it builds correctly with our change to V8. While I'm not sure this is the proper way to do it, I was able to update DEPS in src (chromium) and set the v8 entry to git@github.com:danbev/v8.git@064718a8921608eaf9b5eadbb7d734ec04068a87:\n\nYou'll have to run after this.\n\nAnother way is to not updated the file, which is a version controlled file, but instead update and add a entry:\n\nYou may have to compile this project (in addition to chromium to verify that changes in v8 are not breaking code in pdfium.\n\nYou should be able to update the .gclient file adding a custom_deps entry:\n\n] cache_dir = None You'll have to run after this too.\n\nhello-world is heavily commented and show the usage of a static int being exposed and accessed from JavaScript.\n\ninstances shows the usage of creating new instances of a C++ class from JavaScript.\n\nrun-script is basically the same as instance but reads an external file, script.js and run the script.\n\nThe test directory contains unit tests for individual classes/concepts in V8 to help understand them.\n\nSee Googles contributing-code for more details.\n\nThere are a number of useful functions in which can also be used in lldb.\n\nCreate a file named .lldbinit (in your project director or home directory). This file can now be found in v8's tools directory.\n\nThis is the source used for the following examples:\n\nWhat happens when the v8_shell is run?\n\nFirst v8::base::debug::EnableInProcessStackDumping() is called followed by some windows specific code guarded by macros. Next is all the options are set using\n\nSetOptions will call which is found in src/api.cc:\n\nThis function can be found in src/flags.cc. The flags themselves are defined in src/flag-definitions.h\n\nNext a new SourceGroup array is create:\n\nThere are then checks performed to see if the args is or , or and if not (like in our case)\n\nTODO: I'm not exactly sure what SourceGroups are about but just noting this and will revisit later.\n\nThis will take us back in src/d8.cc\n\nSee ICU a little more details.\n\nNext the default V8 platform is initialized:\n\nv8::platform::CreateDefaultPlatform() will be called in our case.\n\nWe are then back in Main and have the following lines:\n\nThis is very similar to what I've seen in the Node.js startup process.\n\nWe did not specify any natives_blob or snapshot_blob as an option on the command line so the defaults will be used:\n\nthis call will bring us into api.cc line 8185:\n\nSo, we are invoking the Isolate constructor (in src/isolate.cc).\n\nsrc/builtins/builtins.cc, this is where the builtins are defined. TODO: sort out what these macros do.\n\nIn src/v8.cc we have a couple of checks for if the options passed are for a stress_run but since we did not pass in any such flags this code path will be followed which will call RunMain:\n\nthis will end up calling:\n\nWhich will delegate to ScriptCompiler(Local, Source* source, CompileOptions options):\n\nSo I was a little confused when I first read this function name and thought it had something to do with the length of the string. But the byte is the type of the chars that make up the string. For example, a one byte char would be reinterpreted as uint8_t:\n• gdbinit has been updated. Check if there is something that should be ported to lldbinit\n\nThis section will go through calling a Script to understand what happens in V8.\n\nI'll be using run-scripts.cc as the example for this.\n\nI'll step through until the following call:\n\nSo, Script::Run is defined in api.cc First things that happens in this function is a macro:\n\nSo, what does the preprocessor replace this with then:\n\nI'm skipping TRACE_EVENT_CALL_STATS_SCOPED for now. will be replaced with:\n\nThe code for i::JSFunction is generated in src/api.h. Lets take a closer look at this.\n\nOPEN_HANDLE_LIST looks like this:\n\nSo lets expand this for JSFunction and it should become:\n\nSo there will be an function named OpenHandle that will take a const pointer to Script.\n\nA little further down in src/api.h there is another macro which looks like this:\n\nAnd remember that JSFunction is included in the so there will be the following in the source after the preprocessor has processed this header: A concrete example would look like this:\n\nYou can inspect the output of the preprocessor using:\n\nSo where is JSFunction declared? It is defined in objects.h\n\nUser JavaScript also needs to have bytecode generated for them and they also use the C++ DLS and use the CodeStubAssembler -> CodeAssembler -> RawMachineAssembler just like builtins.\n\nAfter rebasing I've seen the following issue:\n\nThe \"solution\" was to remove the out directory and rebuild.\n\nTo find suitable task you can use at bugs.chromium.org.\n\nWhat does this call do:\n\nWhich is a macro defined in src/api.h:\n\nIf we take a closer look at the macro is should expand to something like this in our case:\n\nSo this is returning a new v8::internal::Handle, the constructor is defined in src/handles.h:95.\n\nsrc/objects.cc Handle WeakFixedArray::Add(Handle maybe_array, 10167 Handle value, 10168 int* assigned_index) { Notice the name of the first parameter but it is not of type maybe?\n\nJavaScript provides a set of builtin functions and objects. These functions and objects can be changed by user code. Each context is separate collection of these objects and functions.\n\nAnd internal::Context is declared in and extends FixedArray\n\nA Context can be create by calling:\n\ncan be found in :\n\nThe declaration of this function can be found in :\n\nSo we can see the reason why we did not have to specify . What is ?\n\n This class can be found in and only has two members, a count of the extension names and an array with the names.\n\nIf specified these will be installed by which will delegate to , both can be found in . Where are extensions registered?\n\n This is done once per process and called from :\n\nThe extensions can be found in . You register your own extensions and an example of this can be found in test/context_test.cc.\n\nThis output was taken\n\nCreating a new Context is done by\n\nThis will later end up in :\n\nSo we can see here that the Context is deserialized from the snapshot. What does the Context contain at this stage:\n\nLets take a look at an entry:\n\nSo we can see that this is of type which we can cast using:\n\nSo this is the JSFunction associated with the deserialized context. Not sure what this is about as looking at the source code it looks like an empty function. A function can also be set on the context so I'm guessing that this give access to the function of a context once set. Where is function set, well it is probably deserialized but we can see it be used in :\n\nis a RAII class used to Enter/Exit a context. Lets take a closer look at :\n\nSo the current context is saved and then the this context is set as the current on the isolate. will push the passed-in context (deps/v8/src/api.cc):\n\nNow, is using the current context, not context ( ) and pushing that to the end of the saved_contexts_ vector. We can look at this as we entered context_scope2 from context_scope1:\n\nAnd looks like:\n\nA context can have embedder data set on it. Like decsribed above a Context is internally A FixedArray. in Context is implemented in :\n\nis only used for logging and we can ignore it for now. :\n\nWe can find in\n\nSo the preprocessor would expand this to:\n\nWe can take a look at the initial data:\n\nThis was taken while debugging ContextTest::EmbedderData.\n\nThis macro is used in (src/api.cc) and the call in this function looks like this:\n\nThis section will take a look at the following call:\n\nLets take a closer look at this function which can be found in :\n\nIf we take a look at factory.h we can see the default values for elements_kind and inobject_properties:\n\nIf we expand the CALL_HEAP_FUNCTION macro we will get:\n\nSo, lets take a look at in 'src/heap/heap.cc':\n\ncan be found in src/heap/heap-inl.h:\n\ncan be found in\n\nIs an abstract super class for all classes in the object hierarch and both Smi and HeapObject are subclasses of Object so there are no data members in object only functions. For example:\n\nExtends v8::internal::Object and are not allocated on the heap. There are no members as the pointer itself is used to store the information.\n\nIn our case the calling v8::Isolate::New which is done by the test fixture:\n\nBefore this call all the roots are uninitialized. Reading this blog it says that the Isolate class contains a roots table. It looks to me that the Heap contains this data structure but perhaps that is what they meant.\n\nIn we can find :\n\nAfter If we take a look in we can find the read-only roots in Heap. If we take the 10 value, which is:\n\nwe can then inspect this value:\n\nSo this entry is a pointer to objects on the managed heap which have been deserialized from the snapshot.\n\nThe heap class has a lot of members that are initialized during construction by the body of the constructor looks like this:\n\nWe can see that roots_ is filled with 0 values. We can inspect using:\n\nNow they are all 0 at this stage, so when will this array get populated?\n\n These will happen in :\n\nThis will delegate to which will call Heap::ConfigureHeap:\n\nFound in an instace of a MemoryChunk represents a region in memory that is owned by a specific space.\n\nIn the blog post explains how the builtins are embedded into the executable in to the .TEXT section which is readonly and therefore can be shared amoung multiple processes. We know that builtins are compiled and stored in the snapshot but now it seems that the are instead placed in to and the combined with the object files from the compile to produce the libv8.dylib. V8 has a configuration option named which which case will be added to the list of sources. This is done in and the target. If is false then will be included instead. Both of these files have the following functions:\n\nThese functions are used by and declared :\n\nAnd the usage of can be see in Isolate::Isolate where is sets the embedded blob:\n\nLets set a break point there and see if this is empty of not.\n\nSo we can see that we are not using the empty one. Isolate::SetEmbeddedBlob\n\nWe can see in (line 552) we have a check for the embedded_blob():\n\nEmbeddedData can be found in src/snapshot/snapshot.h` and the implementation can be found in snapshot-common.cc.\n\nSo, is it possible for us to verify that this information is in the .text section?\n\nSo what we have is a pointer to the .text segment which is returned:\n\nAnd we can compare this with :\n\nThe macro can be found :\n\nAnd would be expanded by the preprocessor into:\n\nBack in we are on this line:\n\nThere are a lot of symbols listed above but the point is that in the object file of these symbols were compiled in. Now, when we compile v8 and the tests we are using and we have to use the same when compiling gtest. Lets try that. Just adding that does not help in this case. We need to check which c++ headers are being used:\n\nLets search for the header and inspect the namespace in that header:\n\nSo this looks alright and thinking about this a little more I've been bitten by the linking with different libc++ symbols issue (again). When we compile using Make we are using the c++ headers that are shipped with v8 (clang libc++). Take the string header for example in v8/buildtools/third_party/libc++/trunk/include/string which is from clang's c++ library which does not use namespaces (__11 or __14 etc).\n\nBut when I compiled gtest did not specify the istystem include path and the default would be used adding symbols with __11 into them. When the linker tries to find these symbols it fails as it does not have any such symbols in the libraries that it searches.\n\nCreate a simple test linking with the standard build of gtest to see if that compiles and runs:\n\nThat worked and does not segfault.\n\nBut when I run the version that is built using the makefile I get:\n\nThis issue came up when linking a unit test with gtest:\n\nSo this indicated that the object files in where infact using headers from libc++ and not libstc++. This was a really stupig mistake on my part, I'd not specified the output file explicitly (-o) so this was getting added into the current working directory, but the file included in the archive was taken from within deps/googltest/googletest/ directory which was old and compiled using libc++.\n\nThis issue was seen in Node.js when compiling with GCC. It can also been see if building V8 using GCC and also enabling in BUILD.gn:\n\nThere are unit tests in V8 that also produce this warning, for example : Original:\n\nThis commit suggests adding a pragma specifically for GCC to suppress this warning. The motivation for this is that there were quite a few of these warnings in the Node.js build, but these have been suppressed by adding a similar pragma but around the include of v8.h [1].\n\nCurrently, we have added a pragma to avoid this warning in node.js but we'd like to add this in v8 and closer to the actual code that is causing it. In node we have to set the praga on the header.\n\nNotice the second parameter is which is a typedef:\n\nThis is a function declaration for which is a function that takes a reference to a const WeakCallbackInfo and returns void. So we could define it like this:\n\nAnd the trying to cast it into:\n\nThis is done as V8::MakeWeak has the following signature:\n\nThis can be worked around by specifying the argument to gdb:\n\nNext I got the following error when trying to compile:\n\nI still got an error because of a warning but I'm trying to build using:\n\nLets see how that works out. I also had to use gnus linker by disableing gold:\n\nThis history of this is that JavaScript builtins used be written in assembly which gave very good performance but made porting V8 to different architectures more difficult as these builtins had to have specific implementations for each supported architecture, so it dit not scale very well. With the addition of features to the JavaScript specifications having to support new features meant having to implement them for all platforms which made it difficult to keep up and deliver these new features.\n\nThe goal is to have the perfomance of handcoded assembly but not have to write it for every platform. So a portable assembly language was build on top of Tubofans backend. This is an API that generates Turbofan's machine-level IR. This IR can be used by Turbofan to produce very good machine code on all platforms. So one \"only\" has to implement one component/function/feature (not sure what to call this) and then it can be made available to all platforms. They no longer have to maintain all that handwritten assembly.\n\nJust to be clear CSA is a C++ API that is used to generate IR which is then compiled in to machine code for the target instruction set architectur.\n\nTorque is a DLS language to avoid having to use the CodeStubAssembler directly (it is still used behind the scene). This language is statically typed, garbage collected, and compatible with JavaScript.\n\nThe JavaScript standard library was implemented in V8 previously using hand written assembly. But as we mentioned in the previous section this did not scale.\n\nIt could have been written in JavaScript too, and I think this was done in the past but this has some issues as builtins would need warmup time to become optimized, there were also issues with monkey-patching and exposing VM internals unintentionally.\n\nIs torque run a build time, I'm thinking yes as it would have to generate the c++ code.\n\nThere is a main function in torque.cc which will be built into an executable\n\nThe files that are processed by torque are defined in BUILD.gc in the section. There is also a template named . I've noticed that this template and others in GN use the script . This is apperently because GN can only execute scripts at the moment and what this script does is use python to create a subprocess with the passed in argument:\n\nAnd a template is way to reuse code in GN.\n\nThere is a make target that shows what is generated by torque:\n\nThis will create a directory in the current directory named . Notice that this directory contains c++ headers and sources.\n\nIt take torque-example.tq as input. For this file the following header will be generated:\n\nThis is only to show the generated files and make it clear that torque will generate these file which will then be compiled during the v8 build. So, lets try copying to v8/src/builtins directory.\n\nThis is not enough to get it included in the build, we have to update BUILD.gn and add this file to the list. After running the build we can see that there is a file named generated along with a .cc.\n\nTo understand how this works I'm going to use https://v8.dev/docs/torque-builtins as a starting point:\n\nThis has been updated to work with the latest V8 version.\n\nNext, we need to update to add/install this function on the math object:\n\nAfter this we need to rebuild v8:\n\nIf we look at the generated code that Torque has produced in (we can run it through the preprocessor using):\n\nIf we open math.cc.pp and search for we can find:\n\nSo this is what gets generated by the Torque compiler and what we see above is CodeStubAssemble class.\n\nIf we take a look in out/x64.release_gcc/gen/torque-generated/builtin-definitions-tq.h we can find the following line that has been generated:\n\nNow, there is a section about the TF_BUILTIN macro, and it will create function declarations, and function and class definitions:\n\nNow, in src/builtins/builtins.h we have the following macros:\n\nAnd is declared in src/builtins/builtins-definitions.h and this file includes:\n\nNotice , this is how our MathIs42 gets included from builtin-definitions-tq.h. This is in turn included by builtins.h.\n\nIf we take a look at the this header after it has gone through the preprocessor we can see what has been generated for MathIs42:\n\nFirst MathIs42 will be come a member in the Name enum of the Builtins class:\n\nWe should also take a look in as the BUILTIN_LIST is used there two and specifically to our current example there is a macro used:\n\nSo the above will generate the following code but this time for builtins.cc:\n\nBuiltinMetadata is a struct defined in builtins.cc and in our case the name is passed, then the type, and the last struct is specifying the number of parameters and the last 0 is unused as far as I can tell and only there make it different from the constructor that takes an Address parameter.\n\nSo, where is used:\n\ncan be found in\n\nLets add a conditional break point so that we can stop in this function when is passed in:\n\nWe can see that we first create a new , which we say previously was that type that the function takes. TODO: look into this class a litte more. After this will be called with the newly created state passed in:\n\nTODO: Take a closer look at generate and how that code works. After generate returns we will have the following call:\n\nThen next thing that will happen is the code returned will be added to the builtins by calling :\n\ncan be found in src/builtins/builtins.cc` and looks like this:\n\nSo this is how the builtins_table is populated.\n\nAnd when is called?\n\n It is called from which is called from Isolate::Init.\n\nJust to recap before I loose track of what is going on...We have math.tq, which is the torque source file. This is parsed by the torque compiler/parser and it will generate c++ headers and source files, one of which will be a CodeStubAssembler class for our MathI42 function. It will also generate the \"torque-generated/builtin-definitions-tq.h. After this has happened the sources need to be compiled into object files. After that if a snapshot is configured to be created, mksnapshot will create a new Isolate and in that process the MathIs42 builtin will get added. Then a context will be created and saved. The snapshot can then be deserialized into an Isoalte as some later point.\n\nAlright, so we have seen what gets generated for the function MathIs42 but how does this get \"hooked\" but to enable us to call ?\n\nIn bootstrapper.cc we can see a number of lines:\n\nAnd we are going to add a line like the following:\n\nThe signature for looks like this\n\nSo we see that the function is added as a property to the Math object. Notice that we also have to add to the Builtins class which is now part of the builtins_table_ array which we went through above.\n\nIn torgue source files we can sometimes see types declared as , and functions that have a specifier. In V8 HeapObjects can change at runtime (I think an example of this would be deleting an element in an array which would transition it to a different type of array HoleyElementArray or something like that. TODO: verify and explain this). And a function that calls JavaScript which cause such a transition is marked with transitioning.\n\nAre like functions is js/c++ but have some additional capabilities and there are several different types of callables:\n\nThese correspond to generated CodeStubAssebler C++ that will be inlined at the callsite.\n\nThese will become V8 builtins with info added to builtin-definitions.h (via the include of torque-generated/builtin-definitions-tq.h). There is only one copy of this and this will be a call instead of being inlined as is the case with macros.\n\nmacros and builtins can have parameters. For example:\n\nAnd we can call this from another macro like this:\n\nIn the previous section we showed explicit parameters but we can also have implicit parameters:\n\nDoes this need i18n perhaps?\n\nV8_Fatal is referenced but not defined in v8_monolith.a:\n\nAnd I thought it might be defined in libv8_libbase.a but it is the same there. Actually, I was looking at the wrong symbol. This was not from the logging.o object file. If we look at it we find:\n\nIn out/x64.release/obj/logging.o we can find it defined:\n\nmeans that the symbol is in the text section. So if the linker is able to find libv8_libbase.a it should be able to resolve this.\n\nSo we need to make sure the linker can find the directory where the libraries are located ('-Wl,-Ldir'), and also that it will include the library ('-Wl,-llibname')\n\nWith this in place I can see that the linker can open the archive:\n\nBut I'm still getting the same linking error. If we look closer at the error message we can see that it is maybe-handles.h that is complaining. Could it be that the order is incorrect when linking. libv8_libbase.a needs to come after libv8_monolith Something I noticed is that even though the library libv8_libbase.a is found it does not look like the linker actually reads the object files. I can see that it does this for libv8_monolith.a:\n\nHmm, actually looking at the signature of the function it is V8_Fatal(char const*, ...) and not char const*, int, char const*, ...)\n\nFor a debug build it will be:\n\nSo it looks like I need to set debug to false. With this the V8_Fatal symbol in logging.o is:\n\nWhat is actually build when you specify v8_monolithic: When this type is chosen the build cannot be a component build, there is an assert for this. In this case a static library build:\n\nNotice that the builtin function is called so is a template that can be found in\n\nv8_static_library: This will use source_set instead of creating a static library when compiling. When set to false, the object files that would be included in the linker command. The can speed up the build as the creation of the static libraries is skipped. But this does not really help when linking to v8 externally as from this project.\n\nis_component_build: This will compile targets declared as components as shared libraries. All the v8_components in BUILD.gn will be built as .so files in the output director (not the obj directory which is the case for static libraries).\n\nSo the only two options are the v8_monolith or is_component_build where it might be an advantage of being able to build a single component and not have to rebuild the whole monolith at times.\n\ncan be produced which is a library which only supports WebAssembly and does not support JavaScript.\n\nis where you can find the v8::internal::Isolate.\n\nAnd HiddenFactory is just to allow Isolate to inherit privately from Factory which can be found in src/heap/factory.h.\n\nThis section will walk through the start up on V8 by using the hello_world example in this project:\n\nThis call will land in which will just delegate the call to and internal (internal namespace that is). If you try to step into this function you will just land on the next line in hello_world. This is because we compiled v8 without external start up data so this function will be empty:\n\nNext, we have:\n\nThis will land in which will create a new DefaultPlatform.\n\nRemember that the internal Isolate can be found in . In we find\n\nSo we first create an IsolateAllocator instance which will allocate memory for a single Isolate instance. This is then passed into the Isolate constructor, notice the usage of here, this is just a normal heap allocation.\n\nThe default new operator has been deleted and an override provided that takes a void pointer, which is just returned:\n\nIn this case it just returns the memory allocateed by isolate-memory(). The reason for doing this is that using the new operator not only invokes the new operator but the compiler will also add a call the types constructor passing in the address of the allocated memory.\n\nNotice that will be populated by calling the constructor which takes an pointer to an Isolate.\n\nBack in Isolate's constructor we have:\n\nSo lets expand the first entry to understand what is going on:\n\nSo all of the entries in this list will become private members of the Isolate class after the preprocessor is finished. There will also be public assessor to get and set these initial values values (which is the last entry in the ISOLATE_INIT_LIST above.\n\nBack in isolate.cc constructor we have:\n\nAfter that we have created a new Isolate, we were in this function call:\n\nAfter this we will be back in :\n\nWe are not using any external snapshot data so the following will be false:\n\nis also one of the members that was set up with ISOLATE_INIT_LIST. So we are setting up the Isolate instance for creation.\n\nSo we get the blob and create deserializers for it which are then passed to which delegated to . The blob will have be create previously using (more on this can be found later).\n\nThis will use a macro to assign to the field:\n\nAfter this we have a number of members that are assigned to:\n\nAfter this we have:\n\nThis will land in where we have:\n\nNow, lets take a look at :\n\nWhat are ExternalReferences?\n\n They represent c++ addresses used in generated code.\n\nAfter that we have AddBuiltins:\n\nI can see that the function declaration is in external-reference.h but the implementation is not there. Instead this is defined in :\n\nThe macro can be found in :\n\nThis does nothing in the current code path and the code comment says that the heap will be deserialized from the snapshot and true will be returned.\n\nIn we find IterateSmiRoots RootVistor`. RootVisitor is used for visiting and modifying (optionally) the pointers contains in roots. This is used in garbage collection and also in serializing and deserializing snapshots.\n\nRoot is an enum in . This enum is generated by a macro and expands to:\n\nThese can be displayed using:\n\nJust to keep things clear for myself here, these visitor roots are only used for GC and serialization/deserialization (at least I think so) and should not be confused with the RootIndex enum in .\n\nLets set a break point in and see if we can find where one of the above Root enum elements is used to make it a little more clear what these are used for.\n\nWhat this does is that it creates an V8 environment (Platform, Isolate, Context) and then saves it to a file, either a binary file on disk but it can also save it to a .cc file that can be used in programs in which case the binary is a byte array. It does this in much the same way as the hello-world example create a platform and then initializes it, and the creates and initalizes a new Isolate. After the Isolate a new Context will be create using the Isolate. If there was an embedded-src flag passed to mksnaphot it will be run.\n\nStartupSerializer will use the Root enum elements for example and the deserializer will use the same enum elements.\n\nSo the VisitRootPointers function takes one of these Root's and visits all those roots. In our case the first Root to be visited is Heap::IterateSmiRoots:\n\nAnd here we can see that it is using , and passing nullptr for the description argument (I wonder what this is used for?). Next, comes the start and end arguments.\n\nWe can list all the values of roots_table using:\n\nIn we can find VisitRootPointers:\n\nNotice that description is never used. is in the same source file:\n\nThe class SnapshotByteSource has a member that is initialized upon construction from a const char* or a Vector. Where is this done?\n\n This was done back in :\n\nAll the roots in a heap are declared in src/roots/roots.h. You can access the roots using RootsTable via the Isolate using isolate_data->roots() or by using isolate->roots_table. The roots_ field is an array of Address elements:\n\nThe complete enum can be displayed using:\n\nLets take a look at an entry:\n\nNow, there are functions in factory which can be used to retrieve these addresses, like factory->Error_string():\n\nThese accessor functions declarations are generated by the macros:\n\nAnd the definitions can be found in and look like this The implementations then look like this:\n\nThe unit test roots_test shows and example of this.\n\nThis shows the usage of root entries but where are the roots added to this array. is a member of in :\n\nWe can inspect the roots_ content by using the interal Isolate:\n\nSo we can see that the roots are intially zero:ed out. And the type of is an array of 's.\n\nThis will land us in ReadOnlyRoots::Iterate(RootVisitor* visitor):\n\nDeserializer::VisitRootPointers calls and the roots_ array is still zero:ed out when we enter this function.\n\nNotice that we called VisitRootPointer and pased in , nullptr (the description), and start and end addresses as FullObjectSlots. The signature of looks like this:\n\nIn our case we are using the address of from and the end is found by using the static member of ReadOnlyRoots::kEntrysCount.\n\nThe switch statement in is generated by macros so lets take a look at an expanded snippet to understand what is going on:\n\nSo current is the start address of the read_only_list and limit the end. is a member of and is of type SnapshotByteSource.\n\nAnd extends (src/snapshot/deserializer.h) which has a constructor that sets the source_ member to data->Payload(). So is will be pointer to an instance of which can be found in :\n\nAlright, so we are calling source_.Get() which we can see returns the current entry from the byte array data_ and increment the position. So with that in mind lets take closer look at the switch statment:\n\nWe can see that switch statement will assign the passed-in with a new instance of .\n\nNotice that kNewObject is the type of SerializerDeserliazer::Bytecode that is to be read (I think), this enum can be found in . I think stands for the \"Type of Slot\", which in our case is a FullMaybyObjectSlot.\n\nReadObject is also in deserializer.cc :\n\nWe can verify that location actually contains the address of :\n\nThe first entry is free_space_map.\n\nNext, we will go through the while loop again:\n\nNotice that in Deserializer::Write we have:\n\nAnd it's current value is:\n\nWhich is the same address as roots_[1] that we just wrote to.\n\nIf we know the type that an Address points to we can use the Type::cast(Object obj) to cast it into a pointer of that type. I think this works will all types.\n\nYou can also just cast it to an object and try printing it:\n\nThis is actually the Oddball UndefinedValue so it makes sense in this case I think. With this value in the roots_ array we can use the function ReadOnlyRoots::undefined_value():\n\nSo how are these roots used, take the above for example?\n\n Well most things (perhaps all) that are needed go via the Factory which the internal Isolate is a type of. In factory we can find:\n\nNotice that this is basically what we did in the debugger before but here it is wrapped in Handle so that it can be tracked by the GC.\n\nThe unit test isolate_test explores the internal isolate and has example of usages of the above mentioned methods.\n\nLets take a look at the expanded code in Isolate::Init:\n\nThen functions, like handler_address() are implemented as:\n\nAt this point in the program we have only set the entries to point contain the addresses specified in ThreadLocalTop, At the time there are initialized the will mostly be initialized to :\n\nAnd notice that the functions above return pointers so later these pointers can be updated to point to something. What/when does this happen? Lets continue and find out...\n\nBack in Isolate::Init we have:\n\nLets take a look at\n\nThis will expand to a number of function declarations that looks like this:\n\nThe Map class is what all HeapObject use to describe their structure. Notice that there is also a Handle declared. These are generated by a macro in roots-inl.h:\n\nNotice that this is using the RootIndex enum that was mentioned earlier:\n\nIn object/map.h there is the following line:\n\nWhich can be found in objects/object-macros.h:\n\nThis will expand to something like\n\nAnd the part is the Object contructor that takes an Address:\n\nThat leaves the at function which is a private function in ReadOnlyRoots:\n\nSo we are now back in Isolate::Init after the call to InitializeThreadLocal we have:\n\nIn the following line in api.cc, where does come from:\n\nThe enum is defined in :\n\nAnd in we can find:\n\nThere is list in :\n\nIf we look in in map.cc we find:\n\nNow, we know that our type is:\n\nAnd we can inspect the output of the preprocessor of roots.cc and find:\n\nAnd this is something we have seen before.\n\nOne things I ran into was wanting to print the InstanceType using the overloaded << operator which is defined for the InstanceType in objects.cc.\n\nThe code I'm using is the followig:\n\nThis will cause the function to be called and a Fatal error thrown. But note that the following line works:\n\nIn the switch/case block above the case for this value is:\n\nWhen map.instance_type() is called, it returns a value of but the value of OBJECT_TEMPLATE_INFO_TYPE is:\n\nAnd we can confirm this using:\n\nWhen we create a new context using:\n\nThe Context class in declares New as follows:\n\nWhen a step into Context::New(isolate_, nullptr, global) this will first break in the constructor of DeserializeInternalFieldsCallback in v8.h which has default values for the callback function and data_args (both are nullptr). After that gdb will break in MaybeLocal and setting val_ to nullptr. Next it will break in Local::operator* for the value of which is then passed to the MaybeLocalv8::ObjectTemplate constructor. After those break points the break point will be in api.cc and v8::Context::New. New will call NewContext in api.cc.\n\nThere will be some checks and logging/tracing and then a call to CreateEnvironment:\n\nThe first line in CreateEnironment is:\n\nWhich is a macro defined in api.cc\n\nSo the first break point we break on will be the execution/vm-state-inl.h and VMState's constructor:\n\nIn gdb you'll see this:\n\nNotice that VMState's constructor sets its to isolate->current_vm_state() which is generated by the macro THREAD_LOCAL_TOP_ACCESSOR. The next break point will be:\n\nWe can find that is defined in src/common/assert-scope.h as:\n\nAfter all that we can start to look at the code in CreateEnvironment.\n\nBootstrapper can be found in :\n\nNotice that the break point will be in the HandleScope constructor. Then a new instance of Genesis is created which performs some actions in its constructor.\n\nThis will land in factory.cc:\n\nwill be 16 in this case. is declared in factory.h which has default values for its parameters:\n\nIn Factory::InitializeMap we have the following check:\n\nRemember that I called with the following arguments:\n\nHas a single private member which is declared as:\n\nAn instance can be created using:\n\nStorage type can also be which is defined in globals.h:\n\nIt looks like it can be a different value when using pointer compression.\n\nAn Object can be created using the default constructor, or by passing in an Address which will delegate to TaggedImpl constructors. Object itself does not have any members (apart from ptr_ which is inherited from TaggedImpl that is). So if we create an Object on the stack this is like a pointer/reference to an object:\n\nNow, is a TaggedImpl so it would be a Smi in which case it would just contains the value directly, for example a small integer:\n\nA Handle is similar to a Object and ObjectSlot in that it also contains an Address member (called location_ and declared in HandleBase), but with the difference is that Handles can be relocated by the garbage collector.\n\nWhen we create a new context using:\n\nThe above is using the static function New declared in\n\nThe implementation for this function can be found in How does a Local become a MaybeLocal in this above case?\n\n This is because MaybeLocal has a constructor that takes a and this will be casted into the member of the MaybeLocal instance.\n\nCurrently, the torque generator will generate Print functions that look like the following:\n\nNotice the last line where the newline character is printed as a string. This would just be a char instead .\n\nThere are a number of things that need to happen only once upon startup for each process. These things are placed in which can be found in . This is called by v8::V8::Initialize().\n\nElementsAccessor populates the accessor_array with Elements listed in . TODO: take a closer look at Elements.\n\nv8::Isolate::Initialize will set up the heap.\n\nIt is when we create an new Context that Genesis is created. This will call Snapshot::NewContextFromSnapshot. So the context is read from the StartupData* blob with ExtractContextData(blob).\n\nWhat is the global proxy?\n\nBuiltins is a member of Isolate and an instance is created by the Isolate constructor. We can inspect the value of and that it is false:\n\nThe above is printed form Isolate's constructor and it is not changes in the contructor.\n\nThis is very strange, while I though that the was being updated it now looks like there might be two instances, one with has this value as false and the other as true. And also one has a nullptr as the isolate and the other as an actual value. For example, when I run the hello-world example:\n\nNotice that these are poiting to the same location in memory.\n\nAlright, so after looking into this closer I noticed that I was including internal headers in the test itself. When I include I will get an implementation of isolate->builtins() in the object file which is in the shared library libv8.so, but the field is part of object file that is part of the cctest. This will be a different method and not the method that is in libv8_v8.so shared library.\n\nAs I'm only interested in exploring v8 internals and my goal is only for each unit test to verify my understanding I've statically linked those object files needed, like builtins.o and code.o to the test.\n\nThe issue here is that I'm including the header in the test, which means that code will be in the object code of the test, while the implementation part will be in the linked dynamic library which is why these are pointing to different areas in memory. The one retreived by the function call will use the\n\nI've goma referenced in a number of places so just makeing a note of what it is here: Goma is googles internal distributed compile service.\n\nThis section is going to take a closer look at how wasm works in V8.\n\nWe can use a wasm module like this:\n\nWhere is the WebAssembly object setup? We have sen previously that objects and function are added in and for Wasm there is a function named Genisis::InstallSpecialObjects which calls:\n\nThis call will land in where we can find:\n\nAnd all the rest of the functions that are available on the object are setup in the same function.\n\nNow, lets also set a break point in WebAssemblyModule:\n\nNotice the function which is a function that is setup on the internal Isolate in :\n\nSo this would be expanded by the preprocessor into:\n\nAlso notice that if return true the fuction will return and no further processing of the instructions in that function will be done. is a function that looks like this:\n\nAnd is set as the default function for module/instance callbacks.\n\nLooking a little further we can see checks for WASM Threads support (TODO: take a look at this). And then we have:\n\ncan be found in and will call which can be found in .\n\nThis will land in consume_little_endian(name):\n\nA wasm module has the following preamble:\n\nThese can be found as a constant in :\n\nAfter the DecodeModuleHeader the code will iterate of the sections (type, import, function, table, memory, global, export, start, element, code, data, custom). For each section will be called:\n\nThere is an enum named in which contains the various sections which is used in switch statement in DecodeSection . Depending on the there are DecodeSection methods that will be called. In our case section_code is:\n\nAnd this will match the and will be called.\n\nValueType can be found in and there are types for each of the currently supported types:\n\nis declared with a statement in value-type.h:\n\nWe can find in src/codegen/signature.h:\n\nThe return count can be zero, one (or greater if multi-value return types are enabled). The parameter count also makes sense, but reps is not clear to me what that represents.\n\nBefore the call to s construtor we have:\n\nSo contains the return (re?) and the params (ps?).\n\nAfter the DecodeWasmModule has returned in SyncCompile we will have a ModuleResult. This will be compiled to NativeModule:\n\ncan be found in\n\nThere is an example in wasm_test.cc.\n\nTODO: This section should describe the functions calls below.\n\nSubclasses of CustomArguments, like PropertyCallbackArguments and FunctionCallabackArguments are used for setting up and accessing values on the stack, and also the subclasses provide methods to call various things like for PropertyCallbackArguments and for FunctionCallbackArguments.\n\nThis class is in the namespace v8::internal so I'm curious why the explicit namespace is used here?\n\ncan be found in and is templated with the a type of (in ):\n\nAn instance of Arguments only has a length which is the number of arguments, and an Address pointer which points to the first argument. The functions it provides allows for getting/setting specific arguments and handling various types (like , smi, etc). It also overloads the operator[] allowing to specify an index and getting back an Object to that argument. In the constants specify the index's and provides functions to get them:\n\nCan be found in and has the following definition:\n\nBut I can't find any usages of this enum?\n\nWhen you see something like [[Notation]] you can think of this as a field in an object that is not exposed to JavaScript user code but internal to the JavaScript engine. These can also be used for internal methods."
    },
    {
        "link": "https://gist.github.com/surusek/4c05e4dcac6b82d18a1a28e6742fc23e",
        "document": "This is a not great piece of code I've wrote few years ago (I didn't have better things to do when I was 17, apperantly), when I was fiddling around with the V8 JS Engine. It doesn't work with newer versions of V8, since the library doesn't have a stable API. Time, where I had time to fight with the and lackluster MSVC support for fun is long gone. I've tried to redo this example once in the past, after I've got an email notification that someone got interested in stuff that I've put on the net and have forgotten about. Toolset got even more picky than I remember it being and my attention for personal programming projects drifted away somewhere else, so it's highly unlikely that I'll update it to the newer API. But I'm leaving the code there, maybe someone will make good use of it."
    }
]