[
    {
        "link": "https://sqlshack.com/using-sql-server-cursors-advantages-and-disadvantages",
        "document": "In relational databases, operations are made on a set of rows. For example, a SELECT statement returns a set of rows which is called a result set. Sometimes the application logic needs to work with a row at a time rather than the entire result set at once. In T-SQL, one way of doing this is using a CURSOR.\n\nIf you possess programming skills, you would probably use a loop like FOR or WHILE to iterate through one item at a time, do something with the data and the job is done. In T-SQL, a CURSOR is a similar approach, and might be preferred because it follows the same logic. But be advised, take this path and trouble may follow.\n\nThere are some cases, when using CURSOR doesn’t make that much of a mess, but generally they should be avoided. Below, we will show some examples where using a CURSOR creates performance issues and we will see that the same job can be done in many other ways.\n\nFor the purpose of this demonstration we will use AdventureWorks2012 database, and let’s say we want to get some data from [Production].[ProductInventory] table, for every product that requires less than a day to manufacture, that is from table [Production].[Product].\n\nLet’s start by using a CURSOR, and write the following syntax:\n\nAfter a short coffee break, the query finished executing, returning 833 rows in the time shown below. It’s important to mention the chosen syntaxes above are only for demo purposes, and I made no index tuning to speed things up.\n\nIn the cursor execution, we have two steps. Step one, the positioning, when the cursor sets its position to a row from the result set. Step two, the retrieval, when it gets the data from that specific row in an operation called the FETCH.\n\nIn our example, the cursor sets its position to the first row returned by the first SELECT and fetches the ProductID value that matches WHERE condition in @id variable. Then the second SELECT uses the variable value to get data from [Production].[ProductInventory] and the next row is fetched. These operations are repeated until there are no more rows to work with.\n\nFinally, CLOSE syntax releases the current result set and removes the locks from the rows used by the cursor, and DEALLOCATE removes cursor reference.\n\nOur demo tables are relative small containing roughly 1,000 and 500 rows. If we had to loop through tables with millions of rows it would last a considerable amount of time and the results would not please us.\n\nLet’s give our cursor another chance and uncomment the line –LOCAL STATIC. There are many arguments we can use in a cursor definition, more on that on this link CURSOR Arguments, but for now let’s focus on what this two words mean.\n\nWhen we specify LOCAL keyword, the scope of the cursor is local to the batch in which it was created and it is valid only in this scope. After the batch finishes executing, the cursor is automatically deallocated. Also, the cursor can be referenced by a stored procedure, trigger or by a local cursor variable in a batch.\n\nThe STATIC keyword makes a temporary copy of the data used by the cursor in tempdb in a temporary table. Here we have some gotchas. A STATIC cursor is read-only and is also referred to as a snapshot cursor because it only works with the data from the time it was opened, meaning that it won’t display any changes made in database on the set of data used by the cursor. Basically, no updates, deletes or inserts made after the cursor was open will be visible in the cursors result set unless we close and reopen the cursor.\n\nBe aware of this before using these arguments and check if it matches your needs. But let’s see if our cursor is faster. Below we have the results:\n\n12 seconds are a lot better that 4 minutes and 47 seconds, but keep in mind the restrictions explained above.\n\nIf we run the syntax using this argument LOCAL READ_ONLY FORWARD_ONLY we get the same results. READ_ONLY FORWARD_ONLY cursor can be scrolled only from the first row to the last one. If the STATIC keyword is missing, the cursor is dynamic and uses a dynamic plan if available. But there are cases when a dynamic plan is worse than a static one.\n\nWhat happens when we uncomment –LOCAL FAST_FORWARD?\n\nFAST_FORWARD is equivalent to READ_ONLY and FORWARD_ONLY cursor but has the ability to choose the better plan from either a static or a dynamic one.\n\nLOCAL FAST_FORWARD seems to be the best choice because of its flexibility to choose between a static or dynamic plan, but FORWARD_ONLY also does the job very good. Although we got the result in an average of 12 seconds using both of this methods, these arguments should be properly tested before choosing one of them.\n\nThere are many ways of obtaining the same result, much quicker and with less impact on performance.\n\nOne method is using a JOIN, and as we can see next, the results are considerable better.\n\nFirst, we have to enable statistics time to measure SQL Server execution time, and make an INNER JOIN between two tables, [Production].[ProductInventory] and [Production].[Product] on ProductID column. After hitting the EXECUTE button, we produced the same results in 330 ms, compared to 04:47 time from the cursor method, and we have a smile on our face.\n\nWe do not need to iterate through every row to get what we need, we have no more loops, no while clause, no iterations, we are working with sets of data instead, getting what we want faster and writing less code.\n\nAn appropriate use of cursor\n\nNow that we’ve seen how much damage a cursor can do, let’s see an example where we can make use of it.\n\nLet’s assume we want to select the size and number of rows for only certain tables from a database. To achieve this, we will get all table names based on criteria from information_schema.tables and using a CURSOR we will loop through each of that table name and execute the stored procedure sp_spaceused by passing one table name at a time to get the information we need.\n\nWe will use the same AdventureWorks2012 database, and get all tables from Sales schema that contains the name ‘Sales‘. For every table name returned, we want to see all the info from information_schema.tables.\n\nBelow we have the T-SQL syntax and the obtained results:\n\nThis is one method where CURSOR is helpful by iterating through some data one row at a time and gets the result needed. In this particular case, the cursor gets the job done without having implications on performance and is easy to use.\n\nThere we have it. We showed some examples with the good, the bad and the ugly when using cursors. In most cases, we can use JOINS, even WHILE clauses, SSIS packages or other alternative methods to get the same result quicker, with less impact on performance output and even writing fewer lines of syntax.\n\nWhen we are dealing with OLTP environment and large sets of data to process, the word ‘CURSOR’ should not be spoken.\n\nIn SQL, it’s a good practice to think at making operations on sets of data, rather than think in a programmatic way, using iterations or loops, because this kind of approach is not recommended nor intended for this use. Trying to use loops like FOR or FOREACH from programming languages and associate that logic with SQL operations, is an obstacle for getting the right solution to our needs. We have to think at set-based operations rather than one row at a time to get the data we need.\n\nCursors could be used in some applications for serialized operations as shown in example above, but generally they should be avoided because they bring a negative impact on performance, especially when operating on a large sets of data."
    },
    {
        "link": "https://stackoverflow.com/questions/58141/why-is-it-considered-bad-practice-to-use-cursors-in-sql-server",
        "document": "I knew of some performance reasons back in the SQL 7 days, but do the same issues still exist in SQL Server 2005? If I have a resultset in a stored procedure that I want to act upon individually, are cursors still a bad choice? If so, why?\n\nBecause cursors take up memory and create locks. What you are really doing is attempting to force set-based technology into non-set based functionality. And, in all fairness, I should point out that cursors do have a use, but they are frowned upon because many folks who are not used to using set-based solutions use cursors instead of figuring out the set-based solution. But, when you open a cursor, you are basically loading those rows into memory and locking them, creating potential blocks. Then, as you cycle through the cursor, you are making changes to other tables and still keeping all of the memory and locks of the cursor open. All of which has the potential to cause performance issues for other users. So, as a general rule, cursors are frowned upon. Especially if that's the first solution arrived at in solving a problem.\n\nThe above comments about SQL being a set-based environment are all true. However there are times when row-by-row operations are useful. Consider a combination of metadata and dynamic-sql. As a very simple example, say I have 100+ records in a table that define the names of tables that I want to copy/truncate/whatever. Which is best? Hardcoding the SQL to do what I need to? Or iterate through this resultset and use dynamic-SQL (sp_executesql) to perform the operations? There is no way to achieve the above objective using set-based SQL. So, to use cursors or a while loop (pseudo-cursors)? SQL Cursors are fine as long as you use the correct options: INSENSITIVE will make a temporary copy of your result set (saving you from having to do this yourself for your pseudo-cursor). READ_ONLY will make sure no locks are held on the underlying result set. Changes in the underlying result set will be reflected in subsequent fetches (same as if getting TOP 1 from your pseudo-cursor). Read about the available options before ruling all cursors as evil.\n\nThere is a work around about cursors that I use every time I need one. I create a table variable with an identity column in it. insert all the data i need to work with in it. Then make a while block with a counter variable and select the data I want from the table variable with a select statement where the identity column matches the counter. This way i dont lock anything and use alot less memory and its safe, i will not lose anything with a memory corruption or something like that. And the block code is easy to see and handle. This is a simple example: DECLARE @TAB TABLE(ID INT IDENTITY, COLUMN1 VARCHAR(10), COLUMN2 VARCHAR(10)) DECLARE @COUNT INT, @MAX INT, @CONCAT VARCHAR(MAX), @COLUMN1 VARCHAR(10), @COLUMN2 VARCHAR(10) SET @COUNT = 1 INSERT INTO @TAB VALUES('TE1S', 'TE21') INSERT INTO @TAB VALUES('TE1S', 'TE22') INSERT INTO @TAB VALUES('TE1S', 'TE23') INSERT INTO @TAB VALUES('TE1S', 'TE24') INSERT INTO @TAB VALUES('TE1S', 'TE25') SELECT @MAX = @@IDENTITY WHILE @COUNT <= @MAX BEGIN SELECT @COLUMN1 = COLUMN1, @COLUMN2 = COLUMN2 FROM @TAB WHERE ID = @COUNT IF @CONCAT IS NULL BEGIN SET @CONCAT = '' END ELSE BEGIN SET @CONCAT = @CONCAT + ',' END SET @CONCAT = @CONCAT + @COLUMN1 + @COLUMN2 SET @COUNT = @COUNT + 1 END SELECT @CONCAT\n\nCursors are usually not the disease, but a symptom of it: not using the set-based approach (as mentioned in the other answers). Not understanding this problem, and simply believing that avoiding the \"evil\" cursor will solve it, can make things worse. For example, replacing cursor iteration by other iterative code, such as moving data to temporary tables or table variables, to loop over the rows in a way like: Such an approach, as shown in the code of another answer, makes things much worse and doesn't fix the original problem. It's an anti-pattern called cargo cult programming: not knowing WHY something is bad and thus implementing something worse to avoid it! I recently changed such code (using a #temptable and no index on identity/PK) back to a cursor, and updating slightly more than 10000 rows took only 1 second instead of almost 3 minutes. Still lacking set-based approach (being the lesser evil), but the best I could do that moment. Another symptom of this lack of understanding can be what I sometimes call \"one object disease\": database applications which handle single objects through data access layers or object-relational mappers. Typically code like: The first will usually flood the database with tons of SELECTs, one round trip for each, especially when object trees/graphs come into play and the infamous SELECT N+1 problem strikes. This is the application side of not understanding relational databases and set based approach, just the same way cursors are when using procedural database code, like T-SQL or PL/SQL!\n\nThere are very, very few cases where the use of a cursor is justified. There are almost no cases where it will outperform a relational, set-based query. Sometimes it is easier for a programmer to think in terms of loops, but the use of set logic, for example to update a large number of rows in a table, will result in a solution that is not only many less lines of SQL code, but that runs much faster, often several orders of magnitude faster. Even the fast forward cursor in Sql Server 2005 can't compete with set-based queries. The graph of performance degradation often starts to look like an n^2 operation compared to set-based, which tends to be more linear as the data set grows very large.\n\nSometimes the nature of the processing you need to perform requires cursors, though for performance reasons it's always better to write the operation(s) using set-based logic if possible. I wouldn't call it \"bad practice\" to use cursors, but they do consume more resources on the server (than an equivalent set-based approach) and more often than not they aren't necessary. Given that, my advice would be to consider other options before resorting to a cursor. There are several types of cursors (forward-only, static, keyset, dynamic). Each one has different performance characteristics and associated overhead. Make sure you use the correct cursor type for your operation. Forward-only is the default. One argument for using a cursor is when you need to process and update individual rows, especially for a dataset that doesn't have a good unique key. In that case you can use the FOR UPDATE clause when declaring the cursor and process updates with UPDATE ... WHERE CURRENT OF. Note that \"server-side\" cursors used to be popular (from ODBC and OLE DB), but ADO.NET does not support them, and AFAIK never will."
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/t-sql/language-elements/declare-cursor-transact-sql?view=sql-server-ver16",
        "document": "Defines the attributes of a Transact-SQL server cursor, such as its scrolling behavior and the query used to build the result set on which the cursor operates. accepts both a syntax based on the ISO standard and a syntax using a set of Transact-SQL extensions.\n\nThe name of the Transact-SQL server cursor defined. cursor_name must conform to the rules for identifiers.\n\nDefines a cursor that makes a temporary copy of the data to be used by the cursor. All requests to the cursor are answered from this temporary table in . Therefore, base table modifications aren't reflected in the data returned by fetches made to this cursor, and this cursor doesn't allow modifications. When ISO syntax is used, if is omitted, committed deletes and updates made to the underlying tables (by any user) are reflected in subsequent fetches.\n\nSpecifies that all fetch options ( , , , , , ) are available. If isn't specified in an ISO , is the only fetch option supported. can't be specified if is also specified. If isn't specified, then only the fetch option is available, and the cursor becomes .\n\nA standard statement that defines the result set of the cursor. The keywords , and aren't allowed within select_statement of a cursor declaration.\n\nSQL Server implicitly converts the cursor to another type if clauses in select_statement conflict with the functionality of the requested cursor type.\n\nPrevents updates made through this cursor. The cursor can't be referenced in a clause in an or statement. This option overrides the default capability of a cursor to be updated.\n\nDefines updatable columns within the cursor. If is specified, only the columns listed allow modifications. If is specified without a column list, all columns can be updated.\n\nThe name of the Transact-SQL server cursor defined. cursor_name must conform to the rules for identifiers.\n\nSpecifies that the scope of the cursor is local to the batch, stored procedure, or trigger in which the cursor was created. The cursor name is only valid within this scope. The cursor can be referenced by local cursor variables in the batch, stored procedure, or trigger, or a stored procedure parameter. An parameter is used to pass the local cursor back to the calling batch, stored procedure, or trigger, which can assign the parameter to a cursor variable to reference the cursor after the stored procedure terminates. The cursor is implicitly deallocated when the batch, stored procedure, or trigger terminates, unless the cursor was passed back in an parameter. If it passes back in an parameter, the cursor is deallocated when the last variable referencing it is deallocated or goes out of scope.\n\nSpecifies that the scope of the cursor is global to the connection. The cursor name can be referenced in any stored procedure or batch executed by the connection. The cursor is only implicitly deallocated at disconnect.\n\nSpecifies that the cursor can only move forward and be scrolled from the first to the last row. is the only supported fetch option. All insert, update, and delete statements made by the current user (or committed by other users) that affect rows in the result set, are visible as the rows are fetched. Because the cursor can't be scrolled backward, however, changes made to rows in the database after the row was fetched aren't visible through the cursor. Forward-only cursors are dynamic by default, meaning that all changes are detected as the current row is processed. This provides faster cursor opening and enables the result set to display updates made to the underlying tables. While forward-only cursors don't support backward scrolling, applications can return to the beginning of the result set by closing and reopening the cursor.\n\nIf is specified without the , , or keywords, the cursor operates as a dynamic cursor. When or aren't specified, is the default, unless the keywords , , or are specified. , , and cursors default to . Unlike database APIs such as ODBC and ADO, is supported with , , and Transact-SQL cursors.\n\nSpecifies that the cursor always displays the result set as it was when the cursor was first opened, and makes a temporary copy of the data to be used by the cursor. All requests to the cursor are answered from this temporary table in . Therefore inserts, updates, and deletes made to base tables aren't reflected in the data returned by fetches made to this cursor, and this cursor doesn't detect changes made to the membership, order, or values of the result set after the cursor is opened. Static cursors might detect their own updates, deletes, and inserts, although they aren't required to do so.\n\nFor example, suppose a static cursor fetches a row, and another application then updates that row. If the application refetches the row from the static cursor, the values it sees are unchanged, despite the changes made by the other application. All types of scrolling are supported.\n\nSpecifies that the membership and order of rows in the cursor are fixed when the cursor is opened. The set of keys that uniquely identify the rows is built into a table in known as the keyset. This cursor provides functionality between a static and a dynamic cursor in its ability to detect changes. Like a static cursor, it doesn't always detect changes to the membership and order of the result set. Like a dynamic cursor, it does detect changes to the values of rows in the result set.\n\nKeyset-driven cursors are controlled by a set of unique identifiers (keys) known as the keyset. The keys are built from a set of columns that uniquely identify the rows in the result set. The keyset is the set of key values from all the rows returned by the query statement. With keyset-driven cursors, a key is built and saved for each row in the cursor and stored either on the client workstation or on the server. When you access each row, the stored key is used to fetch the current data values from the data source. In a keyset-driven cursor, result set membership is frozen when the keyset is fully populated. Thereafter, additions or updates that affect membership aren't a part of the result set until it reopens.\n\nChanges to data values (made either by the keyset owner or other processes) are visible as the user scrolls through the result set:\n• None If a row is deleted, an attempt to fetch the row returns an of because the deleted row appears as a gap in the result set. The key for the row exists in the keyset, but the row no longer exists in the result set.\n• None Inserts made outside the cursor (by other processes) are visible only if the cursor is closed and reopened. Inserts made from inside the cursor are visible at the end of the result set.\n• None Updates of key values from outside the cursor resemble a delete of the old row followed by an insert of the new row. The row with the new values isn't visible, and attempts to fetch the row with the old values return an of . The new values are visible if the update is done through the cursor by specifying the clause.\n\nDefines a cursor that reflects all data changes made to the rows in its result set as you scroll around the cursor and fetch a new record, regardless of whether the changes occur from inside the cursor or by other users outside the cursor. Therefore all insert, update, and delete statements made by all users are visible through the cursor. The data values, order, and membership of the rows can change on each fetch. The fetch option isn't supported with dynamic cursors. Updates made outside the cursor aren't visible until they're committed (unless the cursor transaction isolation level is set to ).\n\nFor example, suppose a dynamic cursor fetches two rows, and another application then updates one of those rows and deletes the other. If the dynamic cursor then fetches those rows, it doesn't find the deleted row, but it displays the new values for the updated row.\n\nSpecifies a , cursor with performance optimizations enabled. can't be specified if or is also specified. This type of cursor doesn't allow data modifications from inside the cursor.\n\nPrevents updates made through this cursor. The cursor can't be referenced in a clause in an or statement. This option overrides the default capability of a cursor to be updated.\n\nSpecifies that positioned updates or deletes made through the cursor are guaranteed to succeed. SQL Server locks the rows as they are read into the cursor to ensure their availability for later modifications. can't be specified if or is also specified.\n\nSpecifies that positioned updates or deletes made through the cursor don't succeed, if the row was updated since it was read into the cursor. SQL Server doesn't lock rows as they're read into the cursor. It instead uses comparisons of timestamp column values, or a checksum value if the table has no timestamp column, to determine whether the row was modified after it was read into the cursor.\n\nIf the row was modified, the attempted positioned update or delete fails. can't be specified if is also specified.\n\nIf is specified along with the cursor argument, the combination of the two are implicitly converted to the equivalent of the combination of using and arguments, or the and arguments.\n\nSpecifies that a warning message is sent to the client when the cursor is implicitly converted from the requested type to another.\n\nNo warning is sent to the client when the combination of and cursor arguments are used, and the cursor is implicitly converted to the equivalent of a or cursor. The conversion to turns into a and cursor from a clients' perspective.\n\nA standard statement that defines the result set of the cursor. The keywords , , , and aren't allowed within select_statement of a cursor declaration.\n\nSQL Server implicitly converts the cursor to another type if clauses in select_statement conflict with the functionality of the requested cursor type.\n\nDefines updatable columns within the cursor. If is supplied, only the columns listed allow modifications. If is specified without a column list, all columns can be updated, unless the concurrency option was specified.\n\ndefines the attributes of a Transact-SQL server cursor, such as its scrolling behavior and the query used to build the result set on which the cursor operates. The statement populates the result set, and returns a row from the result set. The statement releases the current result set associated with the cursor. The statement releases the resources used by the cursor.\n\nThe first form of the statement uses the ISO syntax for declaring cursor behaviors. The second form of uses Transact-SQL extensions that allow you to define cursors using the same cursor types used in the database API cursor functions of ODBC or ADO.\n\nYou can't mix the two forms. If you specify the or keywords before the keyword, you can't use any keywords between the and keywords. If you specify any keywords between the and keywords, you can't specify or before the keyword.\n\nIf a using Transact-SQL syntax doesn't specify , , or , the default is as follows:\n• None If the statement doesn't support updates (insufficient permissions, accessing remote tables that don't support updates, and so on), the cursor is .\n\nCursor names can only be referenced by other Transact-SQL statements. They can't be referenced by database API functions. For example, after declaring a cursor, the cursor name can't be referenced from OLE DB, ODBC, or ADO functions or methods. The cursor rows can't be fetched using the fetch functions or methods of the APIs; the rows can only be fetched by Transact-SQL statements.\n\nAfter a cursor is declared, these system stored procedures can be used to determine the characteristics of the cursor.\n\nVariables might be used as part of the select_statement that declares a cursor. Cursor variable values don't change after a cursor is declared.\n\nPermissions of default to any user that has permissions on the views, tables, and columns used in the cursor.\n\nYou can't use cursors or triggers on a table with a clustered columnstore index. This restriction doesn't apply to nonclustered columnstore indexes. You can use cursors and triggers on a table with a nonclustered columnstore index.\n\nThe result set generated at the opening of this cursor includes all rows and all columns in the table. This cursor can be updated, and all updates and deletes are represented in fetches made against this cursor. is the only fetch available because the option isn't specified.\n\nThe following example shows how cursors can be nested to produce complex reports. The inner cursor is declared for each vendor."
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/cursors?view=sql-server-ver16",
        "document": "Operations in a relational database act on a complete set of rows. For example, the set of rows returned by a statement consists of all the rows that satisfy the conditions in the clause of the statement. This complete set of rows returned by the statement is known as the result set. Applications, especially interactive online applications, can't always work effectively with the entire result set as a unit. These applications need a mechanism to work with one row or a small block of rows at a time. Cursors are an extension to result sets that provide that mechanism.\n• None Allowing positioning at specific rows of the result set.\n• None Retrieving one row or block of rows from the current position in the result set.\n• None Supporting data modifications to the rows at the current position in the result set.\n• None Supporting different levels of visibility to changes made by other users to the database data that is presented in the result set.\n• None Providing Transact-SQL statements in scripts, stored procedures, and triggers access to the data in a result set.\n\nIn some scenarios, if there's a primary key on a table, a loop can be used instead of a cursor, without incurring in the overhead of a cursor.\n\nHowever, there are scenarios where cursors aren't only unavoidable, they're actually needed. When that is the case, if there's no requirement to update tables based on the cursor, then use firehose cursors, meaning fast-forward and read-only cursors.\n\nCursors can use worktables. Just like aggregation or sort operations that spill, these incur I/O costs, and are a potential performance bottleneck. cursors use worktables from its inception. For more information, see the worktables section in the Query processing architecture guide.\n\nA forward-only cursor is specified as and and doesn't support scrolling. These are also called firehose cursors and support only fetching the rows serially from the start to the end of the cursor. The rows aren't retrieved from the database until they're fetched. The effects of all , , and statements made by the current user or committed by other users that affect rows in the result set are visible as the rows are fetched from the cursor.\n\nBecause the cursor can't be scrolled backward, most changes made to rows in the database after the row was fetched aren't visible through the cursor. In cases where a value used to determine the location of the row within the result set is modified, such as updating a column covered by a clustered index, the modified value is visible through the cursor.\n\nAlthough the database API cursor models consider a forward-only cursor to be a distinct type of cursor, SQL Server doesn't. SQL Server considers both forward-only and scroll as options that can be applied to static, keyset-driven, and dynamic cursors. Transact-SQL cursors support forward-only static, keyset-driven, and dynamic cursors. The database API cursor models assume that static, keyset-driven, and dynamic cursors are always scrollable. When a database API cursor attribute or property is set to forward-only, SQL Server implements this as a forward-only dynamic cursor.\n\nThe complete result set of a static cursor is built in when the cursor is opened. A static cursor always displays the result set as it was when the cursor was opened. Static cursors detect few or no changes, but consume relatively few resources while scrolling.\n\nThe cursor doesn't reflect any changes made in the database that affect either the membership of the result set or changes to the values in the columns of the rows that make up the result set. A static cursor doesn't display new rows inserted in the database after the cursor was opened, even if they match the search conditions of the cursor statement. If rows making up the result set are updated by other users, the new data values aren't displayed in the static cursor. The static cursor displays rows deleted from the database after the cursor was opened. No , , or operations are reflected in a static cursor (unless the cursor is closed and reopened), not even modifications made using the same connection that opened the cursor.\n\nBecause the result set of a static cursor is stored in a worktable in , the size of the rows in the result set can't exceed the maximum row size for a SQL Server table.\n\nFor more information, see the worktables section in the Query processing architecture guide. For more information on max row size, see Maximum capacity specifications for SQL Server.\n\nTransact-SQL uses the term insensitive for static cursors. Some database APIs identify them as snapshot cursors.\n\nThe membership and order of rows in a keyset-driven cursor are fixed when the cursor is opened. Keyset-driven cursors are controlled by a set of unique identifiers, or keys, known as the keyset. The keys are built from a set of columns that uniquely identify the rows in the result set. The keyset is the set of the key values from all the rows that qualified for the statement at the time the cursor was opened. The keyset for a keyset-driven cursor is built in when the cursor is opened.\n\nDynamic cursors are the opposite of static cursors. Dynamic cursors reflect all changes made to the rows in their result set when scrolling through the cursor. The data values, order, and membership of the rows in the result set can change on each fetch. All , , and statements made by all users are visible through the cursor. Updates are visible immediately if they're made through the cursor using either an API function such as or the Transact-SQL clause. Updates made outside the cursor aren't visible until they're committed, unless the cursor transaction isolation level is set to read uncommitted. For more information on isolation levels, see SET TRANSACTION ISOLATION LEVEL (Transact-SQL).\n• The Transact-SQL language supports a syntax for using cursors modeled after the ISO cursor syntax.\n• SQL Server supports the cursor functionality of these database APIs:\n\nAn application should never mix these two methods of requesting a cursor. An application that uses the API to specify cursor behaviors shouldn't then execute a Transact-SQL statement to also request a Transact-SQL cursor. An application should only execute if it sets all the API cursor attributes back to their defaults.\n\nIf neither a Transact-SQL nor API cursor is requested, SQL Server defaults to returning a complete result set, known as a default result set, to the application.\n\nTransact-SQL cursors and API cursors have different syntax, but the following general process is used with all SQL Server cursors:\n• None Associate a cursor with the result set of a Transact-SQL statement, and define characteristics of the cursor, such as whether the rows in the cursor can be updated.\n• None Execute the Transact-SQL statement to populate the cursor.\n• None Retrieve the rows in the cursor you want to see. The operation to retrieve one row or one block of rows from a cursor is called a fetch. Performing a series of fetches to retrieve rows in either a forward or backward direction is called scrolling.\n• None Optionally, perform modification operations (update or delete) on the row at the current position in the cursor."
    },
    {
        "link": "https://mssqltips.com/sqlservertip/1599/cursor-in-sql-server",
        "document": "I know SQL cursors exist, but I am not sure how or why to use them. Can you provide a SQL cursor example? Can you give any guidance on when to use a SQL Server cursor?\n\nSQL cursors are rarely used in many organizations. In others, they are a last resort. And, in other groups, they are used regularly. Each of these camps, have different reasons for their stand on cursor usage in the DBMS. Regardless, they probably have a place in particular circumstances and not others. It boils down to your understanding of the coding technique, then your understanding of the problem at hand to decide if cursor-based processing is appropriate.\n\nLet’s do the following in this SQL tutorial:\n• Look at an example cursor\n• Break down the components of the cursor\n• Analyze the pros and cons of cursor usage\n\nLet’s first provide a SQL Server cursor example and then answer all pertinent questions in this SQL tutorial.\n\nThis SQL Server cursor example (Simple script to backup all SQL Server databases) issues backups in a serial manner:\n\nA SQL Server cursor is a set of T-SQL logic that loops over a predetermined number of rows one at a time. The purpose of the cursor may be to update one row at a time or perform an administrative process, such as SQL Server database backups, in a sequential manner. Development, DBA, and ETL processes rely on SQL Server cursors.\n\nThere are many options and types of cursors, such as:\n\nHow to Write a Cursor in SQL Server with Transact-SQL\n\nCreating a SQL Server cursor with T-SQL is a consistent method that can process data on a set of rows. Once you learn the steps, you can easily duplicate them with various sets of logic to loop through data. Let’s walk through the steps:\n\nDeclare the variables (file names, database names, account numbers, etc.) needed in the logic and initialize the variables. Specify the variable name and data type.\n• Update the logic based on your needs.\n\nDeclare the cursor with a specific name (i.e., db_cursor in this tip) that you will use throughout the logic along with the business logic (SELECT SQL statement) to populate the records.\n• Update the logic based on your needs.\n\nFetch a record from the cursor to begin the data processing.\n\nThe data process is unique to each set of logic. Logic includes inserting, updating or deleting, for each fetched row.\n• Update the logic based on your needs.\n\nFetch the next record from the cursor and repeat step 3 and step 4.\n\nClose the cursor once all the data has been processed. As a final and important step, you need to deallocate the cursor to release all the internal resources SQL Server is holding.\n\nBased on the code and explanations above, let’s break down the SQL Server cursor example and notate which sections need to be updated when using this code.\n\nBased on the SQL cursor example above, cursors include these components:\n• DECLARE statements – Declare variables used in the code block.\n• SET\\SELECT statements – Initialize the variables to a specific value.\n• DECLARE CURSOR statement – Populate the cursor with values that will be evaluated.\n• NOTE – There are an equal number of variables in the DECLARE CURSOR FOR statement as there are in the SELECT statement. This could be one or many variables and associated columns.\n• FETCH statements – Assign the specific values from the cursor to the variables to match the DECLARE CURSOR FOR and SELECT statement.\n• NOTE – This logic is used for the initial population before the WHILE statement and then again during each loop in the process as a portion of the WHILE statement.\n• WHILE statement – Condition to begin and continue data processing.\n• BEGIN…END statement – Start and end of the code block.\n• NOTE – Based on the data processing, multiple BEGIN…END statements can be used.\n• Data processing – In this example, this logic is to backup a database to a specific path and file name, but this could be any DML or administrative logic.\n• CLOSE statement – Releases the current data and associated locks, but permits the cursor to be re-opened.\n\nWhy Use a Cursor in SQL Server?\n\nAlthough using an INSERT, UPDATE, or DELETE statement to modify all of the applicable data in one transaction is generally the best way to work with data in SQL Server, a cursor may be needed for:\n• Iterating over data one row at a time\n• Completing a process in a serial manner, such as SQL Server database backups\n• Correcting data with a predefined set of data as the input to the cursor\n\nWhen to Use a SQL Server Cursor\n\nThe analysis below is intended to serve as insight into various scenarios where cursor-based logic may or may not be beneficial:\n\nIn most OLTP environments, SET based logic (INSERT, UPDATE, or DELETE on applicable rows) makes the most sense for short transactions. Our team has run into a third-party application that uses cursors for all its processing, which has caused issues, but this has been a rare occurrence. Typically, SET based logic is more than feasible, and cursors are rarely needed.\n\nBased on the design of the reports and the underlying design, cursors are typically not needed. However, our team has seen reporting requirements where referential integrity does not exist on the underlying database, and it is necessary to use a cursor to correctly calculate the reporting values. We have had the same experience when needing to aggregate data for downstream processes. A cursor-based approach was quick to develop and performed in an acceptable manner to meet the need.\n\nIf you need to complete a process in a serialized manner, cursors are a viable option.\n\nMany administrative tasks, such as database backups or Database Consistency Checks, need to be executed in a serial manner, which fits nicely into cursor-based logic. But, other system-based objects exist to fulfill the need. In some of those circumstances, cursors are used to complete the process.\n\nWith large data sets you could run into one or more of the following:\n• Cursor based logic may not scale to meet the processing needs.\n• With large set-based operations on servers with a minimal amount of memory, the data may be paged or monopolize the SQL Server, which is time-consuming and can cause contention and memory issues. As such, a cursor-based approach may meet the need.\n• Some tools inherently cache the data to a file under the covers, so processing the data in memory may or may not actually be the case.\n• If the data can be processed in a staging SQL Server database, the impacts to the production environment only occur when the final data is processed. All resources on the staging server can be used for the ETL processes then the final data can be imported.\n• SSIS supports batching sets of data, which may resolve the overall need to break up a large data set into more manageable sizes and perform better than a row-by-row approach with a cursor.\n• Depending on how the cursor or SSIS logic is coded, it may be possible to restart at the point of failure based on a checkpoint or marking each row with the cursor. However, with a set-based approach, that may not be the case until an entire set of data is completed. As such, troubleshooting the row with the problem may be more difficult.\n\nSimon Liew has written a detailed technical tip on five Different ways to Write a Cursor (read here), which includes the following:\n\nThis tip provides sample code that can be used to expand SQL Server cursor options beyond the syntax in this tip.\n\nLearn more about SQL Server cursors and alternatives:\n• The Many Uses of Coalesce in SQL Server\n\nHow to Avoid Cursors in SQL Server\n• Set based logic\n• INSERT or SELECT INTO or INSERT… SELECT to add records to a table as a single transaction.\n• UPDATE to modify one or many rows in a single transaction.\n• DELETE or TRUNCATE to remove records from a table.\n• MERGE branching logic to INSERT, UPDATE, or DELETE data based on criteria.\n• Consider SQL Server Integration Services (SSIS) to loop through data primarily for data extraction, transformation, and loading processes between databases.\n• WHILE command to loop over records in a sequential manner.\n• Optimize Large SQL Server Insert, Update and Delete Processes by Using Batches\n• COALSCE command to process NON-NULL values.\n• The Many Uses of Coalesce in SQL Server\n• sp_MSforeachdb SQL Server system stored procedure to loop over each database on an instance.\n• Run The Same SQL Command Against All SQL Server Databases\n• sp_MSforeachtable SQL Server system stored procedure to loop over each table in a database.\n• CASE expression, which can include some branching logic to process data with a SELECT statement.\n• Using the CASE expression instead of dynamic SQL in SQL Server\n• Repeat a batch with the GO command.\n\nDifference Between While Loop and Cursor in SQL Server\n\nDaniel Farina wrote an interesting article (SQL Server Loop through Table Rows without Cursor) comparing the SQL Server While Loop and Cursors. He covers the following:\n• Using a While Loop Instead of Cursors in SQL Server\n• Pros and Cons of Using Cursors to Iterate Through Table Rows in SQL Server\n• Pros and Cons of Using a While Loop to Iterate Through Table Rows in SQL Server\n• Example of a Basic Cursor to Loop through Table Rows in SQL Server\n• Example of a Basic While Loop to Cycle through Table Rows in SQL Server\n\nThe code samples in this tip are valuable to illustrate the differences between cursors in SQL Server and the While Loop.\n\nIn the example above, backups are issued via a cursor. Check out these other tips that leverage cursor-based logic:\n• SQL Server script to rebuild all indexes for all tables and all databases\n• SQL Server Index Analysis Script for All Indexes on All Tables\n• Standardize your SQL Server data with this text lookup and replace function\n• Searching and finding a string value in all columns in a SQL Server table\n• Script to create commands to disable, enable, drop and recreate Foreign Key constraints in SQL Server\n• Automate Restoration of Log Shipping Databases for Failover in SQL Server\n• Determining space used for each table in a SQL Server database\n• SQL Server Find and Replace Values in All Tables and All Text Columns\n• What is the use of a cursor in SQL Server?\n• When you are faced with a data processing decision, determine where you stand with SQL Server cursor usage. They may or may not have a place in your application or operational processes. There are many ways to complete a task. Using a cursor could be a reasonable alternative or not. You be the judge.\n• If you run into issues with another coding technique and need to get something done quickly, using a cursor may be a viable alternative. It may take longer to process the data, but the coding time might be much less. If you have a one-time process or nightly processing, this could do the trick.\n• If cursors are shunned in your environment, be sure to select another viable alternative. Be sure the process will not cause other issues. As an example, if a cursor is used and millions of rows are processed, will this potentially flush all of the data from cache and cause further contention? Or, with a large data set, will the data be paged to disk or written to a temporary directory?\n• As you evaluate a cursor-based approach versus other alternatives, make a fair comparison of the techniques in terms of time, contention, and resources needed. Hopefully, these factors will drive you to the proper technique."
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/system-stored-procedures/sp-executesql-transact-sql?view=sql-server-ver16",
        "document": "Applies to: SQL Server Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics Analytics Platform System (PDW) SQL analytics endpoint in Microsoft Fabric Warehouse in Microsoft Fabric\n\nExecutes a Transact-SQL statement or batch that can be reused many times, or one that is built dynamically. The Transact-SQL statement or batch can contain embedded parameters.\n\nThe code samples in this article use the or sample database, which you can download from the Microsoft SQL Server Samples and Community Projects home page.\n\nA Unicode string that contains a Transact-SQL statement or batch. @stmt must be either a Unicode constant or a Unicode variable. More complex Unicode expressions, such as concatenating two strings with the operator, aren't allowed. Character constants aren't allowed. Unicode constants must be prefixed with an . For example, the Unicode constant is valid, but the character constant isn't. The size of the string is limited only by available database server memory. On 64-bit servers, the size of the string is limited to 2 GB, the maximum size of nvarchar(max).\n\n@stmt can contain parameters having the same form as a variable name. For example:\n\nEach parameter included in @stmt must have a corresponding entry in both the @params parameter definition list and the parameter values list.\n\nA string that contains the definitions of all parameters that are embedded in @stmt. The string must be either a Unicode constant or a Unicode variable. Each parameter definition consists of a parameter name and a data type. n is a placeholder that indicates more parameter definitions. Every parameter specified in @stmt must be defined in @params. If the Transact-SQL statement or batch in @stmt doesn't contain parameters, @params isn't required. The default value for this parameter is .\n\nA value for the first parameter that is defined in the parameter string. The value can be a Unicode constant or a Unicode variable. There must be a parameter value supplied for every parameter included in @stmt. The values aren't required when the Transact-SQL statement or batch in @stmt has no parameters.\n\nIndicates that the parameter is an output parameter. text, ntext, and image parameters can be used as parameters, unless the procedure is a common language runtime (CLR) procedure. An output parameter that uses the keyword can be a cursor placeholder, unless the procedure is a CLR procedure.\n\nA placeholder for the values of extra parameters. Values can only be constants or variables. Values can't be more complex expressions such as functions, or expressions built by using operators.\n\nReturns the result sets from all the SQL statements built into the SQL string.\n\nparameters must be entered in the specific order as described in the Syntax section earlier in this article. If the parameters are entered out of order, an error message occurs.\n\nhas the same behavior as regarding batches, the scope of names, and database context. The Transact-SQL statement or batch in the @stmt parameter isn't compiled until the statement is executed. The contents of @stmt are then compiled and executed as an execution plan separate from the execution plan of the batch that called . The batch can't reference variables declared in the batch that calls . Local cursors or variables in the batch aren't visible to the batch that calls . Changes in database context last only to the end of the statement.\n\ncan be used instead of stored procedures to execute a Transact-SQL statement many times when the change in parameter values to the statement is the only variation. Because the Transact-SQL statement itself remains constant and only the parameter values change, the SQL Server query optimizer is likely to reuse the execution plan it generates for the first execution. In this scenario, performance is equivalent to that of a stored procedure.\n\nsupports the setting of parameter values separately from the Transact-SQL string, as shown in the following example.\n\nOutput parameters can also be used with . The following example retrieves a job title from the table in the sample database, and returns it in the output parameter .\n\nBeing able to substitute parameters in offers the following advantages over using the statement to execute a string:\n• None Because the actual text of the Transact-SQL statement in the string doesn't change between executions, the query optimizer probably matches the Transact-SQL statement in the second execution with the execution plan generated for the first execution. Therefore, SQL Server doesn't have to compile the second statement.\n• None The Transact-SQL string is built only once.\n• None The integer parameter is specified in its native format. Casting to Unicode isn't required.\n\nWhen the OPTIMIZED_SP_EXECUTESQL database scoped configuration is enabled, the compilation behavior of batches submitted using becomes identical to the serialized compilation behavior that objects such as stored procedures and triggers currently employ.\n\nWhen batches are identical (excluding any parameter differences), the option tries to obtain a compile lock as an enforcement mechanism to guarantee that the compilation process is serialized. This lock ensures that if multiple sessions invoke simultaneously, those sessions will wait while trying to obtain an exclusive compile lock after the first session starts the compilation process. The first execution of compiles and inserts its compiled plan into the plan cache. Other sessions abort waiting on the compile lock and reuse the plan once it becomes available.\n\nWithout the option, multiple invocations of identical batches executed via compile in parallel and place their own copies of a compiled plan into the plan cache, which replace or duplicate plan cache entries in some cases.\n\nis off by default. To enable at the database level, use the following Transact-SQL statement:\n\nThe following example creates and executes a statement that contains an embedded parameter named .\n\nThe following example shows using to execute a dynamically built string. The example stored procedure is used to insert data into a set of tables that are used to partition sales data for a year. There's one table for each month of the year that has the following format:\n\nThis sample stored procedure dynamically builds and executes an statement to insert new orders into the correct table. The example uses the order date to build the name of the table that should contain the data, and then incorporates that name into an statement.\n\nUsing in this procedure is more efficient than using to execute the dynamically built string, because it allows for the use of parameter markers. Parameter markers make it more likely that the Database Engine reuses the generated query plan, which helps to avoid additional query compilations. With , each string is unique because the parameter values are different, and would be appended to the end of the dynamically generated string. When executed, the query wouldn't be parameterized in a way that encourages plan reuse, and would have to be compiled before each statement is executed, which would add a separate cached entry of the query in the plan cache.\n\nC. Use the OUTPUT parameter\n\nThe following example uses an parameter to store the result set generated by the statement in the parameter. Two statements are then executed that use the value of the parameter.\n\nThe following example creates and executes a statement that contains an embedded parameter named ."
    },
    {
        "link": "https://sqlshack.com/introduction-to-sp_executesql-stored-procedure-with-examples",
        "document": "The sp_executesql is a built-in stored procedure in SQL Server that enables to execute of the dynamically constructed SQL statements or batches. Executing the dynamically constructed SQL batches is a technique used to overcome different issues in SQL programming sometimes. For example, when we want to determine the displayed columns in our reports, this procedure might be a solution option for us. In the simplest sense, this procedure takes a dynamically constructed SQL batch and other parameters, then execute it in the runtime and, finally, it returns the result.\n• Note: In this article’s examples, the sample AdventureWorks database will be used.\n\nThe following code describes the syntax:\n\n@stmt parameter is used to specify dynamically generated SQL statement or batch. The data type of this parameter must be Unicode strings, for this reason, we have to add N prefix for the direct text usage or have to use nvarchar or nchar data typed variables.\n\n@parameternameN_datatype defines the parameter’s name and data type that has been used in the dynamically constructed SQL statements.\n\nWith the help of the @parameternameN=’ValueN’ expression, we can assign a value to the defined parameters which are placed in the SQL statement. In the following sections of the article, we will explore the usage details with examples from easy to difficult.\n\nThe purpose of this example is, retrieving data from the Person table which is taking part under the same schema on the AdventureWorks database:\n\nThe dynamically constructed SQL statement will be assigned to the @SqlStatment variable. The @ColName variable is used to specify the column names, that we want to display in the result set of the query. As a last, we will filter the Person table data with the @PerType parameter. This parameter data type will be nchar(2) and filter the data whose Persontype column expressions equal to “EM”. As the last step, we will execute the query and achieve the result:\n\nThe result set of the query shows only FirstName, MiddleName and LastName columns because of the assigned value of the @ColNames variable. At the same time, we can adjust the displaying column names with this parameter. For example, the following example will be displayed only FirstName column:\n\nsp_executesql provides to return execution result of the dynamically constructed SQL statement or batch. The OUTPUT parameter plays a key role to resolve this case. In this example, we will count the row number of the PersonPhone table and then we will set the return value to a variable with the OUTPUT parameter. The trick of this usage is to indicate the @RowNumber parameter as an OUTPUT parameter and then we assigned this internal parameter value to the @Result parameter:\n\nThe EXEC statement is another option to execute the dynamic SQL statements. For example, we can execute the following dynamically constructed SQL statement through the EXEC statement:\n\nIn the previous example, we executed the dynamically constructed query with the EXEC statement but we need to take account one point about it. We could not parametrize the EXEC statement and this is the main drawback of it.\n\nsp_executesql has some advantages comparing to the EXEC statement. Now, let’s take a glance at these:\n• sp_executesql has the ability to reuse the cached query plans\n\nEach query executed in SQL Server is compiled before it is executed. This query compilation process generates an output that is called the query plan. However, this query compilation process might be very expensive sometimes. For this reason, SQL Server wishes to reuse the cached query plans as possible as for the same queries in order to degrade the query compilation costs. Now, we will prove this idea.\n\nAt first, we will clear all the cached plans with FREEPROCCACHE. However, do not execute this command in the production environment because it could be damage to the performance of the SQL Server:\n\nIn this step, we will execute the following query 3 times with the random parameters.\n\nNow we will check out the generated query plans in the sys.dm_exec_cached_plans:\n\nNow, we will repeat a similar test scenario for the EXEC statement:\n\nIn this step, we will execute the dynamically constructed query 3 times for the random parameters with the EXEC statement:\n\nNow, we will re-check sys.dm_exec_cached_plans view to see how many query plans were created:\n\nAs a result, sp_executesql generated a one query plan in the first execution of the query and then it used the same query plan again and again. In spite of that, the EXEC statement created new query plans for each query execution. This type of usage could consume SQL Server resources and could be caused by performance issues.\n• Note: sp_executesql allows for generating parameterized dynamic queries. So that it is more secure to SQL injection attacks. EXEC statement is more vulnerable in terms of SQL injections.\n\nIn this article, we explored the sp_executesql procedure details and learned the usage methods. This procedure is very useful to resolve the dynamic query issues however, we have to consider the SQL injection issues when we decide to use dynamic queries in SQL Server."
    },
    {
        "link": "https://sqlshack.com/dynamic-sql-in-sql-server",
        "document": "In this article, we will review how to construct and execute dynamic SQL statements in SQL Server with different examples.\n\nDynamic SQL is the SQL statement that is constructed and executed at runtime based on input parameters passed. Let us go through some examples using the EXEC command and sp_executesql extended stored procedure.\n\nEXEC command executes a stored procedure or string passed to it. Please refer to EXEC SQL overview and examples for more details and examples on the EXEC command.\n\nThe following example demonstrates constructing the SQL statement using the input variable and executing the SQL statement using the EXEC command.\n\nThere is a possibility of SQL injection when you construct the SQL statement by concatenating strings from user input values. I hope to cover the SQL injection and some methods to prevent SQL Injection in my future articles.\n\nWe should take care of null values when concatenating strings from parameters using ‘+’ operator. In the below example, I commented out the statement that sets a value to variable “@pid”.\n\nBy default, the variable “@pid” is NULL as we did not set any value. The final statement constructed after concatenation is blank as ‘+’ operator does not handle null values. Please refer to the below image that shows the final value of “@SQL” variable is blank.\n\nIn this case, use the ISNULL function to construct a proper SQL statement while concatenating strings using ‘+’ operator.\n\nEXEC command does not re-use the compiled plan stored in the plan cache. Execute the following query and check for the cached plans.\n\nPlease refer to the below image that shows two separate plans created when the above query is executed for two different parameters.\n\nsp_executesql is an extended stored procedure that can be used to execute dynamic SQL statements in SQL Server. we need to pass the SQL statement and definition of the parameters used in the SQL statement and finally set the values to the parameters used in the query.\n\nFollowing is the syntax of executing dynamic SQL statements using sp_executesql extended stored procedure.\n\nBelow example demonstrates executing dynamic SQL statement by passing parameters to sp_executesql extended stored procedure.\n\nsp_executesql reuses the compiled plan when the statement is executed for different parameters. Execute the following query and check for the cached plan.\n\nPlease refer to the below image that shows the same plan is being used when the statement is executed with different parameters.\n\nFollowing is the example of using dynamic SQL inside a stored procedure. For demo purpose, I used the Product table from the AdventureWorksLT database. This stored procedure is used to search for products based on different columns like name, color, productid, and the product number. The dynamic SQL statement is constructed based on the input parameters passed to the stored procedure and is executed by the EXEC command.\n\nWhen we execute the stored procedure with input parameter productid only, the SQL statement is constructed as shown in the below image.\n\nPlease refer to the below image that shows a different SQL statement constructed when productid and product number are passed as input parameters to the stored procedure.\n\nLet us re-write the stored procedure to form dynamic SQL and execute it using sp_executesql extended stored procedure. Please refer to the below sample script.\n\nLet us execute below sample thread that will retrieve all the products that are red.\n\nsp_executesql extended stored procedure supports the output parameter to store the value returned by the select query and use the output variable in another statement.\n\nFollowing is the example script which shows the usage of the output variable in sp_executesql.\n\nThe local temp table created by executing dynamic SQL cannot be accessed outside the execution of dynamic SQL. It throws invalid object error as shown in the below image.\n\nA workaround for this is to create the local temp table outside and use it in the dynamic SQL. Following is the example that demonstrates this scenario.\n\nPlease refer to the below image. we can see that the data is inserted in the temp table and can be accessed again.\n\nIn this article, we explored how to construct and execute dynamic SQL in SQL Server using the EXEC command and sp_executesql extended stored procedure with different examples. In case you have any questions, please feel free to ask in the comment section below."
    },
    {
        "link": "https://stackoverflow.com/questions/28481189/exec-sp-executesql-with-multiple-parameters",
        "document": "How to pass the parameters to the statement correctly?\n\nThis is what I have now, but i'm getting errors:\n\nRequestTypeID is a comma delimited list of integers, like so: \"1,2,3,4,5\"\n\nhere is my try #2, also unsuccessful"
    },
    {
        "link": "https://mssqltips.com/sqlservertip/1160/execute-dynamic-sql-commands-in-sql-server",
        "document": "In some applications, having hard coded SQL statements is not appealing because of the dynamic nature of the T-SQL queries being issued against the Microsoft SQL Server DBMS. Because of this, sometimes there is a need to dynamically create a SQL statement on the fly and then run that command. This can be done quite simply from the application perspective where the SQL statement is built on the fly whether you are using ASP.NET, ColdFusion, PHP, Java or any other programming language. But how do you do this from within a SQL Server stored procedure? Read on to learn how to use SQL Server to execute dynamic SQL commands.\n\nHow to build dynamic SQL statement in SQL Server\n\nSQL Server offers a few ways of running a dynamically built SQL statement. Here are a few options for SQL Server to execute dynamic SQL:\n\nWe will use the AdventureWorks database for the below examples.\n\nAlthough generating SQL code on the fly is an easy way to dynamically build statements, it does have some drawbacks.\n\nOne issue is the potential for SQL Injection Attacks where malicious code is inserted into the command that is being built. The examples below are very simple to get you started, but you should be aware of SQL Injection and ways to prevent it by making sure your code is robust to check for any issues before executing the statement that is being built.\n\nAnother issue is the possible performance issues by generating the code on the fly. You don’t really know how a user may use the code and therefore there is a potential for a query to do something you did not expect and therefore become a performance issue. So once again, you should make sure your code checks for any potential problems before just executing the generated code at runtime.\n\nThis first approach is pretty straight forward if you only need to pass parameters into your WHERE clause of your SQL statement in Microsoft SQL Server. Let’s say we have a simple example where need to find all records from the customers table where City = ‘London’. See the example below.\n\nWe can turn the above SQL query into a stored procedure with the following syntax:\n\nTo learn more about SQL Server stored proc development (parameter values, output parameters, code reuse, etc.) check out this Transact-SQL tutorial.\n\nWith the Execute Statement you are building the SQL statement on the fly and can pretty much do whatever you need to in order to construct the statement. Let’s say we want to be able to pass in the column list along with the city.\n\nFor this example, we want to get columns AddressID, AddressLine1 and City where City = ‘London’.\n\nAs you can see from this Dynamic SQL query example handling the @city value is not at straight forward, because you also need to define the extra quotes in order to pass a character value into the query. The extra quotes could be done within the statement, but either way you need to specify the extra single quotes in order for the query to be built correctly and run.\n\nWith the EXEC sp_executesql approach you have the ability to still dynamically build the query, but you are also able to use parameters as you could in example 1. This saves the need to have to deal with the extra quotes to get the query to build correctly. In addition, using this approach you can ensure that the data values being passed into the query are the correct datatypes, which are SQL strings in this example:\n\nHere is the result set:\n\nSo here are three different ways of writing dynamic queries. In addition to the above, here are some other articles that give you other perspectives on setting up and using dynamic SQL functionality in your T-SQL code:\n• Protecting Yourself from SQL Injection in SQL Server – Part 1\n• Protecting Yourself from SQL Injection in SQL Server – Part 2\n• If at all possible, try to avoid the use of dynamic SQL especially where you start to manipulate the overall query string. This could potentially open up other areas of concern such as SQL Injection and performance issues.\n• Look into using dynamic SQL in your stored procedures by employing one of the three techniques above instead having the code generated from your front-end application."
    }
]