[
    {
        "link": "http://etudes.tiao.io/auto_examples/misc/plot_hartmann.html",
        "document": ""
    },
    {
        "link": "https://github.com/oxfordcontrol/Bayesian-Optimization/blob/master/benchmark_functions.py",
        "document": "To see all available qualifiers, see our documentation .\n\nSaved searches Use saved searches to filter your results more quickly\n\nWe read every piece of feedback, and take your input very seriously.\n\nYou signed in with another tab or window. Reload to refresh your session.\n\nYou signed out in another tab or window. Reload to refresh your session.\n\nYou switched accounts on another tab or window. Reload to refresh your session."
    },
    {
        "link": "https://scikit-optimize.github.io/dev//_downloads/scikit-optimize-docs.pdf",
        "document": ""
    },
    {
        "link": "https://arxiv.org/html/2305.06709v2",
        "document": "Mike Diessner \n\nSchool of Computing \n\nNewcastle University \n\nNewcastle upon Tyne, UK \n\n \n\n&Kevin Wilson \n\nSchool of Mathematics, Statistics and Physics \n\nNewcastle University \n\nNewcastle upon Tyne, UK \n\n \n\n&Richard D. Whalley \n\nSchool of Engineering \n\nNewcastle University \n\nNewcastle upon Tyne, UK \n\n \n\n\n\nThe optimization of expensive black-box functions is a common problem encountered by researchers in a wide range of disciplines, such as engineering, computing, and natural sciences. These functions are characterized by an unknown or not analytically solvable mathematical expression and high evaluation costs. The principal way to gather information about a black-box function is to provide it with some inputs and observe its corresponding output. However, this process produces high costs, for example, material costs for physical experiments, computing costs for simulators, or time costs in general . Many optimization algorithms, such as Adam , L-BFGS-B , and differential evolution , rely either on derivative information about the objective function or large numbers of function evaluations. Neither is typically feasible when working with an expensive black-box function, requiring us to search elsewhere for a cost-effective and sample-efficient alternative. Bayesian optimization takes a surrogate model-based approach to optimize expensive black-box functions in a minimum number of function evaluations. Although the genesis of Bayesian optimization can be traced back to the middle of the 20th century , it gained considerable popularity in the last two decades . Recently, it has been applied to simulators and experiments in various research areas. For example, Bayesian optimization was used in the field of computational fluid dynamics to maximize the drag reduction via the active control of blowing actuators , in chemical engineering for molecular design, drug discovery, molecular modeling, electrolyte design, and additive manufacturing , and in computer science to fine-tune hyper-parameters of machine learning models and for architecture search of neural networks . With NUBO, we provide an open-source implementation of Bayesian optimization aimed at researchers with expertise in disciplines other than statistics and computer science. To ensure that our target audience can understand and use Bayesian optimization to its full potential, NUBO focuses particularly on (a) transparency through clean and understandable code, precise references, and thorough documentation and (b) user experience through a modular and flexible design, easy syntax, and a careful selection of implemented algorithms. Various Python packages for Bayesian optimization exist as listed in Table 1. Most of them only support sequential single-point optimization, i.e., every point suggested by the algorithm has to be evaluated by the objective function before moving on to the next iteration. However, parallelism can be exploited in many cases to speed up the optimization process. For example, consider a simulator that can be run in parallel. Evaluating all points in parallel would save time as it would only take as long as evaluating a single point sequentially. pyGPGO , bayes_opt , Spearmint , and SMAC3 do not allow parallel multi-point optimization. Furthermore, Spearmint is not modular, resulting in less flexible implementations and giving the user less control when tailoring Bayesian optimization to unique research problems. To our knowledge, the closest available package to NUBO is BoTorch as it also supports parallel and asynchronous optimization through the use of Monte Carlo approximations of the acquisition functions. However, compared to the lightweight implementation of NUBO, BoTorch uses a very large code base that makes code comprehension difficult, as it often requires retracing various functions and objects through many files. This can be quantified by the huge codebase represented in Table 1 as the total number of lines of code : NUBO implements Bayesian optimization in only 1,322 lines of code over 20 files, while BoTorch uses 38,419 lines of code—roughly 29 times more than NUBO—and spreads them between 160 files. It also provides a large number of functions and methods that enforce decisions non-expert users do not have the knowledge and experience to make. NUBO lightens this burden of the user by limiting itself to the most important methods. Table 1 also includes GPyOpt ; however, it is no longer maintained and has recently been archived. The number of code lines regards the underlying code bases of the packages and not the lines of code a user must write to apply Bayesian optimization. When talking about a transparent implementation, the former is a better proxy as it reflects the complexity of the whole package, that is, all functions and algorithms of the package. If a package has many thousands of lines—such as BoTorch—it is intuitive that it is more complex and thus more challenging to fully comprehend than a package with only a few hundred lines of code—such as NUBO. The number of code lines it takes to apply Bayesian optimization is less informative as it can easily be biased and distorted. Consider, for example, a very complex algorithm with many lines of code. It would be possible to wrap this algorithm into one function that can be called with one line of code. While this reduces the lines of code, it does not change the algorithm’s complexity. Thus, the comparison in this article focuses on the number of lines of the underlying code bases to give an idea of the size and complexity of the packages. Overview of available Bayesian optimization packages in . We compare whether individual packages have a modular design and support sequential single-point, parallel multi-point, and asynchronous optimization. We also list the number of lines of code of the core package (without comments, examples, tests, etc.) and the version number. Although it is difficult to provide an exhaustive comparison of the relative efficiency of each of the packages, we have undertaken a limited comparison of the following form. We compare NUBO to four of the packages mentioned above—BoTorch, bayes_opt, SMAC3 and pyGPGO—representing a reasonably wide range of complexity. All methods use Gaussian processes (introduced in Section 2.1) as the surrogate model and upper confidence bound (introduced in Section 2.2) as the acquisition function. Please see the replication materials published alongside this article for further details on the algorithms and the benchmarking. Two synthetic test functions from were selected to benchmark the five packages. The first row of plots in Figure 1 compares the performance of sequential single-point optimization on A) the two-dimensional Levy function and B) the six-dimensional Hartmann function. The second row of plots compares the performance of parallel multi-point optimization with batches of four points on C) the two-dimensional Levy function and D) the six-dimensional Hartmann function. All functions are negated to transform them from their initial minimization problem into a maximization problem in line with the convention of Bayesian optimization. The plots provide the best observation at the current evaluation, averaging over ten replication runs. The results show that all packages converge towards the global optimum of 0.00 for the Levy and 3.32 for the Hartmann function. While NUBO requires more evaluations to find the global optimum for the Hartmann function (B) and D)) than the more complex packages such as BoTorch, it gets closest to the true optimum in all cases after all evaluations and shows low variance in these results (Table 2). These results show that the simplicity of NUBO’s implementation does not come at a cost in performance. NUBO can outperform packages with a similar level of complexity, such as pyGPGO and bayes_opt, and compares well against more complex packages, such as BoTorch and SMAC3. This is not to say that NUBO is the superior package for any problem, but rather that NUBO performs competitively while focusing on a transparent and simple design. This makes NUBO a good candidate for optimizing expensive black-box functions in the sciences—such as physical experiments and computer simulators—where transparency is vital. Comparison of different packages for Bayesian optimization. A) Sequential single-point optimization on the 2D Levy function; B) Sequential single-point optimization on the 6D Hartmann function; C) Parallel multi-point optimization with a batch size of four on the 2D Levy function; D) Parallel multi-point optimization with a batch size of four on the 6D Hartmann function. Comparison of different packages for Bayesian optimization. The best observations averaged across the ten runs with corresponding standard errors are given for each package. However, the time NUBO requires to complete one iteration with a maximum of 2.20s for D) is, on average, higher than for the other packages (Table 3). While this might be important for some areas of optimization, it is negligible when optimizing expensive black-box functions, as these functions are much more resource-intensive to evaluate. Thus, the small number of additional seconds that NUBO requires per iteration is insignificant compared to the resources required to conduct an experiment or a simulation. Comparison of different packages for Bayesian optimization. The elapsed time per iteration averaged across the ten runs is given for each package. Besides implementations in Python, there are also some implementations in other programming languages. For example, rBayesianOptimization and ParBayesianOptimization implement basic Bayesian optimization algorithms for hyper-parameter tuning similar to bayes_opt and pyGPGO in R. ParBayesianOptimization provides additional support for parallel optimization and follows . The remainder of this paper is structured as follows. In Section 2, we introduce the Bayesian optimization algorithm, including Gaussian processes that form the surrogate model and acquisition functions that guide the optimization. The implementation of Bayesian optimization in NUBO is discussed in Section 3 before we illustrate how NUBO can be used to optimize expensive black-box functions through a non-trivial case study in Section 4. Finally, we draw conclusions and give an outlook on future work in Section 5.\n\nwhere the input space is usually continuous and bounded by a hyper-rectangle with . The function is most commonly a derivative-free, expensive-to-evaluate black-box function that allows inputs to be queried and outputs to be observed without gaining any further insights into the underlying system . We assume any noise introduced when taking measurements to be independent and identically distributed Gaussian noise such that . Hence, a set of pairs of input data points and corresponding observations is defined as We further define training inputs as the matrix and their training outputs as the vector . Simulators and experiments in various disciplines can be formulated to fit this description, including but not limited to the examples given in the introduction. Bayesian optimization is a surrogate model-based optimization algorithm that aims to maximize the objective function in a minimum number of function evaluations. Typically, the objective function does not have a known or analytical solvable mathematical expression, and every function evaluation is expensive. Such problems require a cost-effective and sample-efficient optimization strategy. Bayesian optimization meets these criteria by representing the objective function through a surrogate model , often a Gaussian process. This representation can be used to find the input points to be evaluated sequentially by maximizing a criterion specified through an acquisition function . A popular criterion is the upper confidence bound (UCB). This acquisition function can be classed as an optimistic acquisition function that considers the upper bound of the uncertainty around the surrogate model’s prediction to be true . Bayesian optimization is performed in a loop, where training data is used to fit the surrogate model before the next point suggested by the acquisition function is evaluated and added to the training data (see the Algorithm 1 below). The process then restarts and gathers more information about the objective function with each iteration. Bayesian optimization is run for as many iterations as the evaluation budget allows, as shown in Algorithm 1, until a satisfactory solution is found or until a predefined stopping criterion is met. Find that maximizes an acquisition criterion based on model . Figure 2 illustrates how the Bayesian optimization algorithm works for an optimization loop that runs for eight iterations and starts with two initial training points. In this example, NUBO finds an approximation of the global optimum ( ) for a simple 1-dimensional problem on iteration seven. The surrogate model uses the available observations to provide a prediction and associated uncertainty (here shown as 95% confidence intervals around the prediction). This is our best estimate of the underlying objective function. This estimate is then used in the acquisition function to evaluate which input value will likely return a high output. Maximizing the acquisition function provides the next candidate point to be observed from the objective function before it is added to the training data and the whole process is repeated. Figure 2 shows how the surrogate model converges to the true objective function with each iteration. The acquisition function covers the input space by exploring regions with high uncertainty and exploiting regions with a high prediction. This property, the exploration-exploitation trade-off, is a cornerstone of the acquisition functions provided in NUBO. Bayesian optimization applied to a 1-dimensional function with one local and one global maximum. Upper confidence bound is used as the acquisition function. The input space is bounded by . A popular choice for the surrogate model that acts as a representation of the objective function is a Gaussian process , a flexible non-parametric regression model. A Gaussian process is a finite collection of random variables that has a joint Gaussian distribution and is defined by a prior mean function and a prior covariance kernel resulting in the prior distribution where is the mean vector of length over all training inputs and is the covariance matrix between all training inputs. Popular choices for the prior mean function are the zero and constant mean functions given in Equations 4 and 5. For the prior covariance function , the squared exponential kernel, also called the radial basis function (RBF) kernel, and the Matérn kernel are popular options. The covariance kernels in Equations 6 and 7 are based on the distance and have two parameters: the signal variance , sometimes also referred to as the output-scale, and the characteristic length-scale . The former will scale the function with larger values, resulting in a more significant deviation from its mean, while the latter indicates how long function values are correlated along the input axes; the smaller the length-scale , the shorter the correlation . Covariance functions can be extended to include one characteristic length-scale for each input dimension . In this case, input dimensions with large length scales are correlated for longer distances and are less relevant for changes in the prediction. This means that varying the values of the input dimension affects the prediction little. Input dimensions with small length scales are correlated for shorter distances, and even small changes in the input values can affect the prediction significantly. Gaussian processes with covariance functions that include multiple length scales are characterized by automatic relevance determination (ARD) of the input dimensions . Here, the inverse of the length scales can be interpreted as the relevance of the corresponding dimensions . The Gaussian process will estimate large length scales for irrelevant dimensions, automatically assigning them less importance. The posterior distribution for test points can be computed as the multivariate Gaussian distribution conditional on training data where is the mean vector of length over all test inputs, is the covariance matrix, is the covariance matrix, is the covariance matrix between training inputs and test inputs respectively, and is the noise variance of the Gaussian process. The hyper-parameters of the Gaussian process, for example, the constant in the mean function, the signal variance and characteristic length-scales in the covariance kernel, and the noise variance , can be estimated by maximizing the log-marginal likelihood in Equation 11 via maximum likelihood estimation (MLE) . Acquisition functions use the posterior distribution of the Gaussian process to compute a criterion that assesses if a test point is a good potential candidate point to evaluate via the objective function . Thus, maximizing the acquisition function suggests the test point that, based on the current training data , has the highest potential and information gain to get closer to the global optimum while exploring the input space. To do this, an acquisition function balances exploration and exploitation. The former is characterized by areas with no or only a few observed data points where the uncertainty of the Gaussian process is high and the latter by areas where the posterior mean of the Gaussian process is large. This exploration-exploitation trade-off ensures that Bayesian optimization does not converge to the first (potentially local) maximum it encounters but efficiently explores the entire input space. NUBO supports two of the most popular acquisition functions whose performance has been demonstrated in both theoretical and empirical research. Expected improvement (EI) selects points with the biggest potential to improve on the current best observation, while upper confidence bound (UCB) takes an optimistic view of the posterior uncertainty and assumes it to be true to a user-defined level. Expected improvement (EI) is defined as where , and are the mean and the standard deviation of the posterior distribution of the Gaussian process, is the current best observation, and and are the cumulative distribution function and probability density function of the standard normal distribution . The upper confidence bound (UCB) acquisition function can be computed as where is a predefined trade-off parameter, and and are the mean and the standard deviation of the posterior distribution of the Gaussian process. For guidance on the choice of , consult the theoretical properties in or empirical conclusions in . Both of these acquisition functions can be maximized with a deterministic optimizer, such as L-BFGS-B for bounded unconstrained problems or SLSQP for bounded constrained problems. However, the use of analytical acquisition functions is restricted to sequential single-point problems for which every point suggested by Bayesian optimization is observed via the objective function immediately before the optimization loop is repeated. For parallel multi-point batches or asynchronous optimization, the analytical acquisition functions are generally intractable. To use Bayesian optimization in these cases, NUBO supports approximating the analytical acquisition function through Monte Carlo sampling . The idea is to draw many samples directly from the posterior distribution and then approximate the acquisition functions by averaging these Monte Carlo samples. This method is made viable by reparameterizing the acquisition functions and the computation of samples from the posterior distribution via base samples randomly drawn from a standard normal distribution . Thus, the analytical acquisition functions from in Equations 12 and 13 can be approximated as where is the mean of the posterior distribution of the Gaussian process, is the lower triangular matrix of the Cholesky decomposition of the covariance matrix , are samples from the multivariate standard normal distribution , is the current best observation, is the user-defined trade-off parameter, and is the rectified linear unit function that zeros all values below zero and leaves the rest unchanged. Due to the randomness in the Monte Carlo samples, these acquisition functions can only be optimized by stochastic optimizers, such as Adam . However, there is some empirical evidence that fixing the base samples for individual Bayesian optimization loops does not affect the performance negatively . This method would allow deterministic optimizers, such as L-BFGS-B and SLSQP , to be used but could potentially introduce bias due to sampling randomness. Two optimization strategies for multi-point batches are proposed in the literature : The first is a joint optimization approach, where the acquisition functions are optimized over all batch points simultaneously. The second option is a greedy sequential approach where one point after another is selected, holding all previous points fixed until the batch is complete. Empirical evidence shows that both methods approximate the acquisition successfully. However, the greedy approach seems to have a slight edge over the joint strategy for some examples . It is also faster to compute for larger batches. Asynchronous optimization leverages the same property as sequential greedy optimization: the pending points that have not yet been evaluated can be added to the test points but are treated as fixed. In this way, they affect the joint multivariate normal distribution but are not considered directly in the optimization. Asynchronous optimization is particularly beneficial for objective functions for which the evaluation time varies. In these cases, the optimization can be continued while some points are still being evaluated.\n\nNUBO is a Bayesian optimization package in Python that focuses on transparency and user experience to make Bayesian optimization accessible to researchers from a wide range of disciplines whose expertise is not necessarily statistics or computer science. With this overall goal in mind, NUBO ensures transparency by implementing clean and comprehensible code, precise references, and thorough documentation within this research article and on our website at www.nubopy.com. We avoid implementing overly complex and convoluted functions and objects that require the retracing of individual elements through multiple files to be fully understood. We prioritize user experience defined by a modular and flexible design that can be intuitively tailored to unique problems, easy-to-read and write syntax, and a careful selection of Bayesian optimization algorithms. The latter is essential as we try not to overwhelm the user with a larger number of options but instead focus on what is essential to successfully optimize computer simulators and physical experiments. To create a powerful package with good longevity, starting with a strong foundation is important. NUBO is built upon the Torch ecosystem that provides a strong scientific computation framework for working with tensors, a selection of powerful optimization algorithms, such as torch.Adam , automatic differentiation capabilities to compute gradients of acquisition functions via torch.autograd, and GPU acceleration. Furthermore, GPyTorch , the package we use to implement Gaussian processes for our surrogate modeling, is also based in Torch and combines seamlessly with NUBO. We borrow the L-BFGS-B and SLSQP optimization algorithms from SciPy for the deterministic optimization of the acquisition functions and use NumPy to make data suitable for these optimizers. NUBO and all its required dependencies can be installed from the Python Package Index (PyPI) with the packet installer pip via the terminal: NUBO uses the GPyTorch package to implement Gaussian processes for surrogate modeling. While GPyTorch allows the definition of many different Gaussian processes through its various mean functions, covariance kernels, and methods for hyper-parameter estimation, we provide a predefined Gaussian process in the nubo.models module that follows the work of . The GaussianProcess is specified by a constant mean function, and the Matérn ARD kernel that, due to its flexibility, is well suited for practical optimization as it can represent a wide variety of real-world objective functions. The code below implements a Gaussian process and estimates its hyper-parameters from some training inputs x_train and training outputs y_train by maximizing the log-marginal likelihood in Equation 11 with the fit_gp function. The hyper-parameters include the constant in the mean function, the output scale and length scales in the covariance kernel, and the noise in the Gaussian likelihood. The training inputs and training outputs are specified as a torch.Tensor of size and length , respectively, where is the number of points, and is the number of input dimensions. Calling the function fit_gp results in a trained Gaussian process that can subsequently be used for Bayesian optimization. >>> from nubo.models import GaussianProcess, fit_gp >>> from gpytorch.likelihoods import GaussianLikelihood >>> >>> >>> likelihood = GaussianLikelihood() >>> gp = GaussianProcess(x_train, y_train, likelihood=likelihood) >>> fit_gp(x_train, y_train, gp=gp, likelihood=likelihood)While Gaussian processes can estimate noise, for example, observational noise occurring when taking measurements from the data, we might prefer specifying the noise explicitly if it is known. We can exchange the GaussianLikelihood for the FixedNoiseGaussianLikelihood and specify the noise for each training point. The FixedNoiseGaussianLikelihood allows us to decide if any additional noise should be estimated by setting the learn_additional_noise attribute to True or False. The snippet below fixes the observational noise of each training point at 2.5% and estimates any additional noise. Before describing the individual optimization options in detail, we want to illustrate NUBO’s user experience—its easy-to-read and write syntax, flexibility, and modularity—on a simple Bayesian optimization step that can be further divided into four substeps. First, we define the input space. Here, we want to optimize a six-dimensional objective function that is bounded by the hyper-rectangle specified as bounds, a torch.Tensor, where the first row provides the lower bounds and the second row the upper bounds for all six input dimensions. Second, we load the training inputs x_train and the training outputs y_train. This training data can be manually selected or generated using a space-filling design, such as Latin hypercube sampling introduced in Section 3.3. Third, we define and train the Gaussian process implemented in NUBO as discussed in Section 3.1, or set up a custom Gaussian process with GPyTorch. Fourth, we specify an acquisition function that takes the fitted Gaussian process as an argument and chooses an optimization method. In this case, we use the upper confidence bound introduced in Equation 13 and optimize it with the L-BFGS-B algorithm using the single function. >>> import torch >>> from nubo.acquisition import UpperConfidenceBound >>> from nubo.models import GaussianProcess, fit_gp >>> from nubo.optimization import single >>> from gpytorch.likelihoods import GaussianLikelihood >>> >>> >>> bounds = torch.tensor([[0., 0., 0., 0., 0., 0.], ... [1., 1., 1., 1., 1., 1.]]) >>> >>> x_train = # load inputs as torch.Tensor >>> y_train = # load outputs as torch.Tensor >>> >>> likelihood = GaussianLikelihood() >>> gp = GaussianProcess(x_train, y_train, likelihood=likelihood) >>> fit_gp(x_train, y_train, gp=gp, likelihood=likelihood) >>> >>> acq = UpperConfidenceBound(gp=gp, beta=4) >>> x_new, _ = single(func=acq, method=\"L-BFGS-B\", bounds=bounds)NUBO is very flexible and allows users to swap out individual elements for other options. For example, we can substitute the UpperConfidenceBound acquisition function or the single optimization strategy without changing any other code lines. This makes it easy and fast to tailor Bayesian optimization to specific problems. The remainder of this section introduces NUBO’s optimization strategies. Figure 3 shows a flowchart that helps users decide on the correct acquisition function and optimizer for their specific problem. flowchart. Overview of the recommended algorithms for specific problems. Start in yellow, decisions in blue, and recommended algorithm in green. In NUBO, we differentiate between two optimization strategies: single-point and multi-point optimization. When using the single-point strategy via the single function, NUBO uses the analytical acquisition functions discussed in Section 2.2 to find the next point to be evaluated by the objective function. The corresponding observation must be gathered before the next iteration of the optimization loop can begin. The code below shows how the analytical expected improvement (EI) and the analytical upper confidence bound (UCB) can be specified with NUBO. The former takes the best training output to date as the argument y_best, while the latter accepts the trade-off hyper-parameter as the beta argument. For bounded optimization problems with analytical acquisition functions, the optimization method of the single function should be set to method=\"L-BFGS-B\". The arguments num_starts (default 10) and num_samples (default 100) can be set to enable multi-start optimization, where the selected optimization algorithm is run multiple times. Each start is initialized at the best points from a large number of points sampled from a Latin hypercube. This reduces the risk of getting stuck in a local optimum. Section 3.3 introduces Latin hypercube sampling in more detail. The single function only returns the best start and its acquisition value. Sequential single-point optimization can be paired with constrained and mixed optimization, as detailed in this section. The second optimization strategy is multi-point optimization. This strategy uses the Monte Carlo acquisition functions outlined in Section 2.2 to find multiple points, also called batches, in each iteration of the Bayesian optimization loop. This strategy is particularly beneficial for objective functions that support parallel evaluations, as points can be queried simultaneously, speeding up the optimization process. NUBO uses the Monte Carlo versions of expected improvement MCExpectedImprovement and upper confidence bound MCUpperConfidenceBound in unison with either the multi_joint or multi_sequential function to compute batches. The two different options for the multi-point optimization strategy are discussed in Section 2.2. In addition to the arguments of the analytical acquisition functions, both Monte Carlo acquisition functions accept the number of Monte Carlo samples to be used to approximate the acquisition function as the samples argument (default 512). For the optimization functions, the number of points to be computed can be passed to the batch_size argument, while the method should be set to \"Adam\" to enable stochastic optimization via the Adam algorithm . The Adam algorithm can be fine-tuned by setting the learning rate lr (default 0.1) and the number of optimization steps steps (default 100). Parallel multi-point optimization can be paired with asynchronous, constrained, and mixed optimization, as detailed in this section. >>> from nubo.acquisition import MCExpectedImprovement, ... MCUpperConfidenceBound >>> from nubo.optimization import multi_joint, multi_sequential >>> >>> >>> acq = MCExpectedImprovement(gp=gp, y_best=torch.max(y_train), ... samples=256) >>> acq = MCUpperConfidenceBound(gp=gp, beta=4, samples=256) >>> x_new, _ = multi_joint(func=acq, method=\"Adam\", lr=0.1, ... steps=100, batch_size=4, bounds=bounds) >>> x_new, _ = multi_sequential(func=acq, method=\"Adam\", lr=0.1, ... steps=100, batch_size=4, bounds=bounds)To enable the use of deterministic optimizers, such as L-BFGS-B and SLSQP , the base samples used to compute the Monte Carlo samples can be fixed by setting fix_base_samples=True (default False). NUBO supports asynchronous optimization, that is, the continuation of the optimization loop while some points are being evaluated by the objective function. In this case, the Monte Carlo acquisition functions MCExpectedImprovement or MCUpperConfidenceBound are used as outlined in Section 2.2. The code snippet below assumes that the two points x_pend are currently being evaluated. To continue the optimization, these points can be fed into the acquisition function by setting x_pending=x_pend and NUBO will take them into account for the subsequent iteration. >>> import torch >>> from nubo.acquisition import MCUpperConfidenceBound >>> from nubo.optimization import multi_joint, multi_sequential >>> >>> >>> x_pend = torch.tensor([[0.2, 0.9, 0.8, 0.4, 0.4, 0.1], ... [0.1, 0.3, 0.7, 0.2, 0.1, 0.2]]) >>> acq = MCUpperConfidenceBound(gp=gp, beta=4, x_pending=x_pend) >>> x_new, _ = multi_joint(func=acq, method=\"Adam\", ... batch_size=4, bounds=bounds) >>> x_new, _ = multi_sequential(func=acq, method=\"Adam\", ... batch_size=4, bounds=bounds)While Monte Carlo acquisition functions are approximations of the analytical functions, they are mainly used for computing multiple points, where analytical functions are generally intractable. The Monte Carlo approach can also be used for single-point asynchronous optimization by setting batch_size=1. The simple maximization problem in Equation 1 can be extended by including one or more input constraints In these instances, NUBO allows constrained Bayesian optimization by using the SLSQP algorithm to optimize the acquisition function. Implementing this method requires the additional step of specifying the constraints cons as a dictionary for one constraint or a list of dictionaries for multiple constraints. Each constraint requires two entries. The first is \"type\" and can either be set to \"ineq\" for inequality constraints or \"eq\" for equality constraints. The second is \"fun\", which takes a function representing the constraint. The optimizer only selects points for which the constraint functions are greater than or equal to zero for inequality constraints and exactly zero for equality constraints. The code snippet below specifies two constraints: The first is an inequality constraint that requires the first two input dimensions to be smaller than or equal to 0.5. The second is an equality constraint that requires dimensions four, five, and six to sum to 1.2442. >>> import torch >>> >>> >>> bounds = torch.tensor([[0., 0., 0., 0., 0., 0.], ... [1., 1., 1., 1., 1., 1.]]) >>> cons = [{\"type\": \"ineq\", \"fun\": lambda x: 0.5 - x[0] - x[1]}, ... {\"type\": \"eq\", \"fun\": lambda x: 1.2442 - x[3] - x[4] - x[5]}]After setting up the input space using the bounds and constraints, the Bayesian optimization loop is similar to before. We need to set the method argument of the optimization function to \"SLSQP\" and provide the function with the constraints cons. >>> from nubo.acquisition import UpperConfidenceBound >>> from nubo.optimization import single >>> >>> >>> acq = UpperConfidenceBound(gp=gp, beta=4) >>> x_new, _ = single(func=acq, method=\"SLSQP\", ... bounds=bounds, constraints=cons)Constrained Bayesian optimization can be used with analytical and Monte Carlo acquisition functions and single-point, multi-point, asynchronous, and mixed optimization, as detailed in this section. Bayesian optimization predominantly focuses on problems with continuous input parameters since the Gaussian process models all input dimensions as continuous variables. However, NUBO supports optimizing mixed input parameter spaces via a workaround. To do this, NUBO first computes all possible combinations of the discrete parameters. Then, it maximizes the acquisition function for all continuous parameters while holding one combination of the discrete parameters fixed. Once the acquisition function is maximized for each possible discrete combination, the best overall solution is returned. This can be very time-consuming for many discrete dimensions or discrete values. To implement mixed optimization in NUBO, bounds are specified as before, but the discrete dimensions are additionally defined in a dictionary where the keys are the dimensions (starting from zero), and the values are a list of all possible values for the discrete inputs. The code below specifies dimensions one and five as disc. >>> import torch >>> >>> >>> bounds = torch.tensor([[0., 0., 0., 0., 0., 0.], ... [1., 1., 1., 1., 1., 1.]]) >>> disc = {0: [0.2, 0.4, 0.6, 0.8], ... 4: [0.3, 0.6, 0.9]}After setting up the input space specified by the bounds and discrete values, the Bayesian optimization loop is similar to before. We only need to provide the function with the dictionary specifying the discrete dimensions discrete=disc. >>> from nubo.acquisition import UpperConfidenceBound >>> from nubo.optimization import single >>> >>> >>> acq = UpperConfidenceBound(gp=gp, beta=4) >>> x_new, _ = single(func=acq, method=\"L-BFGS-B\", ... bounds=bounds, discrete=disc)Mixed Bayesian optimization can be used in unison with analytical and Monte Carlo acquisition functions as well as single-point, multi-point, asynchronous, and constrained optimization, all of which are detailed in this section. NUBO provides a selection of test functions and utilities to make implementing and testing Bayesian optimization algorithms more convenient. The ten test functions were selected from the virtual library of and represent a variety of challenges, such as bowl-shaped, plate-shaped, valley-shaped, uni-modal, and multi-modal functions. The functions can be imported from the nubo.test_functions module and instantiated by providing the number of dimensions (except for the Hartmann function that comes in 3D and 6D versions), the standard deviation of any noise that should be added, and whether the function should be minimized or maximized. These functions are equipped with the following attributes: the number of dimensions dims, the bounds bounds, and the inputs and outputs of the global optimum optimum. >>> from nubo.test_functions import Ackley, Hartmann6D >>> >>> >>> func = Ackley(dims=5, noise_std=0.1, minimise=False) >>> func = Hartmann6D(minimise=False) >>> dims = func.dims >>> bounds = func.boundsThe gen_inputs function from the nubo.utils module allows us to generate input data that covers the input space efficiently by sampling a larger number of random Latin hypercube designs and returning the design with the largest minimal distance between all points. Figure 4 compares Latin hypercube sampling to random sampling for two input dimensions. While many random points are near each other, points from the Latin hypercube design effectively cover the whole input space by placing only one point in each row and column. The exact position of the point within the selected square is random. The code snippet below generates five points for each input dimension of the Hartmann function initiated above and uses func to compute the corresponding outputs. Finally, we discuss three convenience functions that can be used for data transformation. normalise and unnormalise can be used to scale input data to the unit cube and back to its original domain by providing the bounds of the input space. Furthermore, the outputs can be centered at zero with a standard deviation of one with the standardise function.\n\nWe present the general workflow for optimizing an expensive-to-evaluate black-box function with NUBO by providing a detailed case study in which a test function with six input dimensions is optimized. This case study demonstrates how the user can specify the parameter input space, generate initial training data, and define and run the Bayesian optimization loop. So that the case study is reproducible, we set the seed for the pseudo-number generator within Torch to 123. We set some format options for the print function such that values are rounded to the fourth decimal place and are not formatted in scientific notation to increase readability. >>> import torch >>> >>> >>> torch.manual_seed(123) >>> torch.set_printoptions(precision=4, sci_mode=False)A typical objective function optimized with Bayesian optimization is expensive to evaluate and thus not feasible to use in a case study that aims to illustrate how NUBO can be applied. Hence, we will use one of the synthetic test functions provided by NUBO as a surrogate expensive-to-evaluate black-box function. We use the six-dimensional Hartmann function that possesses multiple local and one global minimum. Its input space is bounded by the hyper-rectangle . Observational noise, such as measurement error, is represented by adding a small amount of random Gaussian noise to the function output by setting noise_std=0.1. minimise is set to False to transform the minimization into a maximization problem as required for Bayesian optimization with NUBO. >>> from nubo.test_functions import Hartmann6D >>> >>> >>> black_box = Hartmann6D(noise_std=0.1, minimise=False)With our objective function specified, we can focus on defining the input space. Our objective function has six inputs, all bounded by . As introduced in Section 3.2, the bounds are defined as a torch.tensor, where the first row specifies the lower bounds and the second row specifies the upper bounds. This case study also highlights the mixed parameter optimization capabilities of NUBO (see Section 3.2) by assuming that the first input is a discrete parameter restricted to 0.2, 0.4, 0.6, and 0.8. We can implement this by specifying a dictionary, where the key is the input dimension and the value is a list of possible values the input can take, that is {0: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}. Note that indexing starts at zero in Python. >>> dims = 6 >>> bounds = torch.tensor([[0., 0., 0., 0., 0., 0.], ... [1., 1., 1., 1., 1., 1.]]) >>> discrete = {0: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, ... 0.6, 0.7, 0.8, 0.9, 1.0]}The Bayesian optimization loop requires initial training data. This is important to train the Gaussian process that tries to emulate the objective function. This case study uses the gen_inputs function introduced in Section 3.3 to generate 30 initial data points from a Latin hypercube design. We round the first input dimension to fit the discrete values specified above as Latin hypercube designs return continuous values. These points are evaluated by the objective function to complete our training data pairs consisting of input parameters x_train and observations y_train. >>> from nubo.utils import gen_inputs >>> >>> >>> x_train = gen_inputs(num_points=dims * 5, ... num_dims=dims, ... bounds=bounds) >>> x_train[:, 0] = torch.round(x_train[:, 0], decimals=1) >>> y_train = black_box(x_train)Next, we specify the Bayesian optimization algorithm we plan to use in our optimization loop. We define the bo function that takes our training pairs (x_train, y_train) and returns the next candidate point x_new which is evaluated by the objective function in four steps. First, we set up our surrogate model as the Gaussian process provided by NUBO with a Gaussian likelihood as discussed in Section 3.1. Second, we train the Gaussian process gp with our training data by maximizing the likelihood with the Adam algorithm via the fit_gp function. Here, we set a custom learning rate lr and the number of optimization steps steps. Third, we define an acquisition function that will guide our optimization. Assuming that our objective function allows parallel function evaluations, we compute multi-point batches at each iteration and choose a Monte Carlo acquisition function, in this case MCUpperConfidenceBound. The acquisition function acq is instantiated by providing it with the fitted Gaussian process gp, a value for the trade-off hyper-parameter beta, and the number of Monte Carlo samples used to approximate the acquisition function. For further details, refer to Section 2.2. Fourth, we maximize the acquisition function acq with the multi_sequential function that uses the sequential strategy for computing multiple candidate points. We compute four candidate points at each iteration by setting batch_size=4 and providing the previously specified bounds and discrete values. The Adam optimizer is used as Monte Carlo acquisition functions require a stochastic optimizer due to their inherent randomness introduced by drawing the Monte Carlo samples. The optimizer is initialized at two different initial points chosen as the two points with the highest acquisition value out of 100 potential points sampled from a Latin hypercube design. We chose two initializations to keep the computational overhead within the replication script low. In practice, a higher number of initializations might be beneficial. >>> from nubo.acquisition import MCUpperConfidenceBound >>> from nubo.models import GaussianProcess, fit_gp >>> from nubo.optimization import multi_sequential >>> from gpytorch.likelihoods import GaussianLikelihood >>> >>> >>> def bo(x_train, y_train): >>> >>> likelihood = GaussianLikelihood() >>> gp = GaussianProcess(x_train, y_train, likelihood=likelihood) >>> >>> fit_gp(x_train, y_train, gp=gp, likelihood=likelihood, ... lr=0.1, steps=200) >>> >>> acq = MCUpperConfidenceBound(gp=gp, beta=4, samples=128) >>> >>> x_new, _ = multi_sequential(func=acq, ... method=\"Adam\", ... batch_size=4, ... bounds=bounds, ... discrete=discrete, ... lr=0.1, ... steps=200, ... num_starts=2, ... num_samples=100) >>> >>> return x_newFinally, we specify the entire optimization loop, that is, a simple for-loop that computes the next batch of candidate points using the defined Bayesian optimization algorithm bo, evaluates the candidate points by the objective function black_box, and adds the new data pairs (x_new, y_new) to the training data. We let the optimization loop run for ten iterations and print all evaluations, where the first six columns are the inputs and the final column is the output from the objective function. The first 30 rows give the initial training data generated by the Latin hypercube design, while the last 40 rows were chosen by the Bayesian optimization algorithm. The results show that NUBO improves upon the initial space-filling design and produces points consistent with the bounds and discrete values that specify the parameter input space. tensor([[0.2000, 0.6523, 0.1574, 0.7822, 0.3039, 0.8603, 0.1251], [0.5000, 0.9127, 0.8746, 0.4787, 0.6523, 0.1249, 2.2907], [0.4000, 0.5638, 0.0459, 0.6200, 0.7056, 0.2929, 0.6744], [0.2000, 0.3003, 0.2290, 0.8110, 0.9529, 0.2384, 0.0442], [0.1000, 0.7809, 0.5374, 0.1381, 0.5655, 0.5679, 0.6123], [0.7000, 0.3454, 0.9352, 0.0283, 0.7969, 0.7874, 0.0732], [0.9000, 0.0395, 0.4250, 0.2010, 0.8243, 0.9836, -0.0281], [0.1000, 0.2542, 0.8055, 0.0806, 0.0381, 0.1833, 0.0791], [0.2000, 0.8412, 0.2388, 0.0388, 0.8542, 0.4247, 0.1126], [0.8000, 0.7370, 0.3922, 0.5172, 0.3952, 0.6280, 0.2454], [0.6000, 0.1313, 0.5940, 0.6993, 0.2744, 0.0337, -0.0489], [0.9000, 0.8016, 0.2760, 0.9357, 0.4104, 0.7371, 0.0214], [0.6000, 0.6316, 0.9115, 0.3722, 0.0273, 0.0787, 0.5736], [0.7000, 0.8821, 0.1944, 0.1973, 0.6821, 0.2330, 0.0460], [0.4000, 0.6779, 0.8546, 0.8716, 0.7558, 0.6497, 0.0783], [1.0000, 0.5682, 0.1289, 0.4361, 0.1452, 0.4574, 0.0586], [0.3000, 0.2194, 0.6718, 0.2631, 0.4686, 0.3043, 0.6239], [1.0000, 0.3801, 0.7743, 0.7396, 0.8837, 0.8693, -0.0627], [0.4000, 0.9939, 0.6117, 0.2750, 0.9850, 0.8189, 0.0045], [0.6000, 0.4286, 0.9720, 0.3607, 0.5942, 0.4977, 0.2505], [0.9000, 0.1827, 0.6516, 0.1159, 0.9271, 0.3751, 0.0581], [0.5000, 0.7077, 0.4601, 0.9771, 0.2619, 0.5356, -0.0289], [0.0000, 0.4767, 0.3555, 0.6558, 0.1989, 0.0162, 0.1569], [0.3000, 0.4371, 0.7413, 0.9112, 0.0723, 0.9252, 0.9560], [0.5000, 0.5276, 0.0843, 0.7266, 0.2118, 0.5302, 0.2011], [0.7000, 0.1468, 0.3188, 0.3087, 0.3526, 0.3344, 0.5923], [0.0000, 0.9432, 0.5099, 0.5586, 0.6024, 0.6905, -0.0087], [0.1000, 0.0802, 0.0017, 0.4008, 0.5019, 0.1411, 0.2529], [0.8000, 0.0221, 0.7221, 0.8440, 0.1240, 0.9540, 0.2324], [0.5000, 0.2958, 0.4872, 0.5731, 0.4418, 0.7037, 0.7130], [0.2000, 0.9085, 0.8757, 0.4770, 0.6390, 0.1237, 1.1281], [0.7000, 0.0000, 0.3683, 0.0712, 0.0515, 0.4062, 0.1484], [0.3000, 0.7281, 0.9619, 0.0431, 0.0000, 0.1199, 0.0894], [0.8000, 1.0000, 0.8457, 1.0000, 1.0000, 0.0000, -0.0373], [0.8000, 0.9280, 0.8906, 0.4856, 0.6641, 0.1195, 0.1296], [0.8000, 1.0000, 1.0000, 0.5266, 0.6308, 0.0358, 0.3261], [1.0000, 0.5787, 0.4309, 0.1291, 0.4129, 0.5590, 0.2360], [0.3000, 0.0000, 1.0000, 0.5009, 0.6804, 0.1289, 0.0289], [0.4000, 0.9628, 0.9097, 0.4806, 0.4525, 0.0000, 2.6153], [0.5000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, -0.0507], [1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, -0.1304], [0.3000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.1087], [0.4000, 1.0000, 1.0000, 0.5046, 1.0000, 0.0000, 2.5231], [0.4000, 1.0000, 1.0000, 0.4928, 0.0000, 1.0000, 0.0980], [0.4000, 1.0000, 1.0000, 0.4467, 1.0000, 1.0000, -0.0251], [0.5000, 1.0000, 0.0000, 0.5280, 0.0000, 0.0000, 2.2291], [0.4000, 0.9658, 0.0000, 0.4804, 0.0000, 0.0898, 2.5967], [0.4000, 0.8883, 1.0000, 0.5189, 0.0000, 0.0000, 3.1767], [0.4000, 1.0000, 0.0000, 0.3745, 1.0000, 0.0000, 1.6312], [0.7000, 0.0000, 1.0000, 0.5100, 1.0000, 1.0000, -0.0249], [0.4000, 0.8786, 0.0161, 0.5639, 0.0581, 0.0000, 3.1551], [0.5000, 0.8284, 1.0000, 0.6011, 0.0000, 0.0000, 2.5988], [0.4000, 0.9136, 1.0000, 0.5669, 0.0000, 0.0802, 3.2133], [0.6000, 1.0000, 0.0000, 0.7980, 1.0000, 1.0000, -0.0130], [0.4000, 0.8908, 1.0000, 0.5868, 0.0000, 0.0000, 3.0625], [0.4000, 0.8291, 1.0000, 0.5621, 0.0000, 0.0862, 2.8820], [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0447], [0.3000, 0.8511, 1.0000, 0.7110, 0.0000, 0.0000, 2.1879], [0.4000, 0.8976, 0.4139, 0.5711, 1.0000, 0.0425, 2.9899], [0.5000, 0.9286, 0.0000, 0.6761, 0.0000, 0.1140, 2.2584], [0.4000, 0.9195, 0.0000, 0.6349, 0.0000, 0.1203, 2.5906], [0.1000, 0.2126, 1.0000, 0.5955, 0.0000, 1.0000, 0.4850], [0.4000, 0.8943, 1.0000, 0.5565, 0.0000, 0.0097, 2.9492], [0.2000, 0.4618, 0.0000, 0.1665, 1.0000, 1.0000, 0.1278], [0.2000, 1.0000, 1.0000, 0.9451, 0.0000, 0.0000, 0.4609], [0.5000, 1.0000, 1.0000, 0.5839, 0.0000, 0.3425, 0.7659], [0.4000, 0.8899, 1.0000, 0.5622, 0.0000, 0.0421, 3.1330], [0.4000, 0.8026, 0.0000, 0.5356, 0.0000, 0.0000, 2.7828], [0.2000, 0.0556, 1.0000, 1.0000, 0.0000, 0.6695, 0.1134], [0.4000, 0.7124, 1.0000, 0.6842, 0.0000, 0.0000, 2.3028]], dtype=torch.float64) NUBO efficiently explores the parameter space by switching between exploring areas with high uncertainty and high predictions. This means the algorithm does not monotonically converge to a single solution as conventional optimization algorithms would. Thus, the approximate solution to an objective function is the best value found during optimization. In this case study, the approximate solution, i.e., the solution with the highest output (last column in the Python output above), was found at iteration 53, and the inputs and outputs are printed below. Approximate solution -------------------- Evaluation: 53 Inputs: tensor([0.4000, 0.9136, 1.0000, 0.5669, 0.0000, 0.0802], dtype=torch.float64) Output: 3.2133 We compare the results provided by NUBO with the results from random sampling and using a space-filling design, in this case, Latin hypercube sampling (LHS). The code below generates results for the total budget of 70 evaluations for both sampling methods and plots the results against each other, with the number of evaluations on the x-axis and the accumulative best output for each method on the y-axis. Figure 5 shows that NUBO (green line) provides a better solution than either alternative approach and is very close to the true maximum of 3.32237. NUBO succeeds in accurately approximating the true optimum. Results of the Bayesian optimization algorithm implemented with , as defined in this case study, compared to random sampling and Latin hypercube sampling. >>> import matplotlib.pyplot as plt >>> import numpy as np >>> >>> >>> torch.manual_seed(123) >>> random = black_box(torch.rand((70, dims))) >>> lhs = black_box(gen_inputs(num_points=70, ... num_dims=dims, ... bounds=bounds)) >>> >>> plt.plot(range(1, 71), np.maximum.accumulate(random), label=\"Random\") >>> plt.plot(range(1, 71), np.maximum.accumulate(lhs), label=\"LHS\") >>> plt.plot(range(1, 71), np.maximum.accumulate(y_train), label=\"NUBO\") >>> plt.hlines(3.32237, 0, 71, colors=\"red\", linestyles=\"dashed\", ... label=\"Maximum\") >>> plt.title(\"Comparison against random designs\") >>> plt.xlabel(\"Evaluations\") >>> plt.ylabel(\"Output\") >>> plt.legend(loc=’lower center’, ncol=4, bbox_to_anchor=(0.5, -0.275)) >>> plt.xlim(0, 71) >>> plt.tight_layout()"
    },
    {
        "link": "https://docs.scipy.org/doc/scipy/reference/optimize.html",
        "document": "SciPy provides functions for minimizing (or maximizing) objective functions, possibly subject to constraints. It includes solvers for nonlinear problems (with support for both local and global optimization algorithms), linear programming, constrained and nonlinear least-squares, root finding, and curve fitting.\n\nCommon functions and objects, shared across different solvers, are:\n\nLocal minimization of scalar function of one variable. The function supports the following methods: Minimization of scalar function of one or more variables. The function supports the following methods: Constraints are passed to function as a single object or as a list of objects from the following classes: Simple bound constraints are handled separately and there is a special class for them: Quasi-Newton strategies implementing interface can be used to approximate the Hessian in function (available only for the ‘trust-constr’ method). Available quasi-Newton methods implementing this interface are: Find the global minimum of a function using the basin-hopping algorithm. Minimize a function over a given range by brute force. Finds the global minimum of a function using SHG optimization. Find the global minimum of a function using Dual Annealing. Finds the global minimum of a function using the DIRECT algorithm.\n\nFind a root of a function in a bracketing interval using Brent's method. Find a root of a function in a bracketing interval using Brent's method with hyperbolic extrapolation. Find a root of a function in an interval using Ridder's method. Find root of a function within an interval using bisection. Find a root of a real or complex function using the Newton-Raphson (or secant or Halley's) method. The function supports the following methods: The table below lists situations and appropriate methods, along with asymptotic convergence rates per iteration (and per function evaluation) for successful convergence to a simple root(*). Bisection is the slowest of them all, adding one bit of accuracy for each function evaluation, but is guaranteed to converge. The other bracketing methods all (eventually) increase the number of accurate bits by about 50% for every function evaluation. The derivative-based methods, all built on , can converge quite quickly if the initial value is close to the root. They can also be applied to functions defined on (a subset of) the complex plane. The function supports the following methods:\n\nThe functions below are not recommended for use in new scripts; all of these methods are accessible via a newer, more consistent interfaces, provided by the interfaces above. Unconstrained minimization of a function using the Newton-CG method. Minimize a function with variables subject to bounds, using gradient information in a truncated Newton algorithm. Minimize a function using the Constrained Optimization By Linear Approximation (COBYLA) method. Given a function of one variable and a possible bracket, return a local minimizer of the function isolated to a fractional precision of tol. Return the minimizer of a function of one variable using the golden section method. Minimize the sum of squares of a set of equations. Find a root of a function, using Broyden's first Jacobian approximation. Find a root of a function, using Broyden's second Jacobian approximation. Exception raised when nonlinear solver fails to converge within the specified maxiter. Find a root of a function, using Krylov approximation for inverse Jacobian. Find a root of a function, using Broyden's first Jacobian approximation. A simple wrapper that inverts the Jacobian using the solve method. Find a root of a function, using Krylov approximation for inverse Jacobian."
    },
    {
        "link": "https://numpy.org/doc/2.1/reference/generated/numpy.linalg.inv.html",
        "document": "Broadcasting rules apply, see the documentation for details.\n\nIf a is detected to be singular, a is raised. If a is ill-conditioned, a may or may not be raised, and results may be inaccurate due to floating-point errors.\n\nIf a is a matrix object, then the return value is a matrix as well:\n\nInverses of several matrices can be computed at once:\n\nIf a matrix is close to singular, the computed inverse may not satisfy even if a is not raised:\n\nTo detect ill-conditioned matrices, you can use to compute its condition number [1]. The larger the condition number, the more ill-conditioned the matrix is. As a rule of thumb, if the condition number , then you may lose up to digits of accuracy on top of what would be lost to the numerical method due to loss of precision from arithmetic methods.\n\nIt is also possible to detect ill-conditioning by inspecting the matrix’s singular values directly. The ratio between the largest and the smallest singular value is the condition number:"
    },
    {
        "link": "https://stackoverflow.com/questions/69311225/inverse-matrix-with-variables",
        "document": "I'm trying to generate the inverse of a hessian matrix and running into issues. I define both the gradient and hessian matrix as functions with variables x1 and x2 in order to use different values at future iterations. These functions work fine but when I attempt to take the inverse, it returns the following:\n\nIs this not a functionality of numpy? Any help would be appreciated."
    },
    {
        "link": "https://quora.com/How-do-you-calculate-the-Hessian-matrix-of-a-function-in-Python",
        "document": "Something went wrong. Wait a moment and try again."
    },
    {
        "link": "https://stackoverflow.com/questions/78199806/how-can-i-compute-the-following-hessian-using-numpy-functions-to-speed-up-the-co",
        "document": "I have to implement an equivalent function to compute the hessian of the logistic loss, written as a sum of logarithm of exponential terms. I have implemented the following function in python:\n\nMy question is how i can code an equivalent, but faster function, without using the slow python for?\n\nSince i am not so confident with numpy, i tried to code the following function:\n\nBy debugging this function, i saw that there is a fundamental problem. For small values of the number of features(say less than 200), the two implementations of the hessian are not equal. When i increase the number of features, the two functions seems to be equal. The problem is that when testing those implementations using Newton's method to optimize the log loss, the faster implementations converges in more iterations than the first(but slower in terms of runtime) implementation."
    },
    {
        "link": "https://geeksforgeeks.org/how-to-inverse-a-matrix-using-numpy",
        "document": "In this article, we will see NumPy Inverse Matrix in Python before that we will try to understand the concept of it. The inverse of a matrix is just a reciprocal of the matrix as we do in normal arithmetic for a single number which is used to solve the equations to find the value of unknown variables. The inverse of a matrix is that matrix which when multiplied with the original matrix will give an identity matrix.\n\nThe inverse of a matrix exists only if the matrix is non-singular i.e., the determinant should not be 0. Using determinant and adjoint, we can easily find the inverse of a square matrix using the below formula,\n\nPython provides a very easy method to calculate the inverse of a matrix. The function numpy.linalg.inv() is available in the NumPy module and is used to compute the inverse matrix in Python.\n\nExample 1: In this example, we will create a 3 by 3 NumPy array matrix and then convert it into an inverse matrix using the np.linalg.inv() function.\n\nExample 2: In this example, we will create a 4 by 4 NumPy array matrix and then convert it using np.linalg.inv() function into an inverse Matrix in Python.\n\nExample 3: In this example, we will create multiple NumPy array matrices and then convert them into their inverse matrices using np.linalg.inv() function."
    }
]