[
    {
        "link": "https://learn.microsoft.com/en-us/cpp/cpp/fastcall?view=msvc-170",
        "document": "The calling convention specifies that arguments to functions are to be passed in registers, when possible. This calling convention only applies to the x86 architecture. The following list shows the implementation of this calling convention.\n\nUsing the /Gr compiler option causes each function in the module to compile as unless the function is declared by using a conflicting attribute, or the name of the function is .\n\nThe keyword is accepted and ignored by the compilers that target ARM and x64 architectures; on an x64 chip, by convention, the first four arguments are passed in registers when possible, and additional arguments are passed on the stack. For more information, see x64 Calling Convention. On an ARM chip, up to four integer arguments and eight floating-point arguments may be passed in registers, and additional arguments are passed on the stack.\n\nFor nonstatic class functions, if the function is defined out-of-line, the calling convention modifier doesn't have to be specified on the out-of-line definition. That is, for class non-static member methods, the calling convention specified during declaration is assumed at the point of definition. Given this class definition:\n\nis equivalent to this:\n\nFor compatibility with previous versions, is a synonym for unless compiler option /Za (Disable language extensions) is specified.\n\nIn the following example, the function is passed arguments in registers:"
    },
    {
        "link": "https://andrewjohnson4.substack.com/p/understanding-cdecl-and-fastcall",
        "document": "Calling conventions are an essential part of computer programming, especially when dealing with functions and subroutines. They define the rules for how arguments are passed to functions, how the function receives those arguments, and how the return value is handled. Two common calling conventions are cdecl and fastcall, and understanding the difference between them is crucial for efficient and correct code execution.\n\nThe cdecl (or __cdecl) calling convention is the default calling convention for C and C++ programs on most platforms, including Windows and Linux. It follows a specific set of rules:\n• None Argument Passing: Arguments are pushed onto the stack from right to left, meaning the last argument is pushed first, and the first argument is pushed last.\n• None Caller Responsibility: The caller is responsible for cleaning up (removing) the arguments from the stack after the function returns.\n• None Return Value: The return value from the function is stored in a specific register, typically the EAX register for 32-bit x86 architectures or the RAX register for 64-bit x86 architectures.\n\nHere’s an example of a cdecl function call in C:\n\nIn this example, when is called, the value is pushed onto the stack first, followed by . The function retrieves these values from the stack, performs the addition, and stores the result in the EAX register. After the function returns, the caller is responsible for cleaning up the stack by removing the arguments ( and ) from it.\n\nThe fastcall (or __fastcall) calling convention is a Microsoft-specific convention designed to improve performance by reducing the overhead of calling functions. It follows a different set of rules:\n• None Argument Passing: The first two arguments (or three arguments on 64-bit systems) are passed in registers (ECX and EDX on 32-bit systems, RCX, RDX, and R8 on 64-bit systems). Any remaining arguments are pushed onto the stack from right to left, just like in cdecl.\n• None Callee Responsibility: The callee (the function being called) is responsible for cleaning up the stack and any registers used for argument passing.\n• None Return Value: The return value is stored in the same register as cdecl (EAX or RAX).\n\nHere’s an example of a fastcall function call in C++:\n\nIn this example, when is called, the value is passed in the ECX register, and is passed in the EDX register. The function retrieves these values from the registers, performs the addition, and stores the result in the EAX register. After the function returns, the function is responsible for cleaning up any registers or stack space used for argument passing.\n\nThe fastcall convention is generally faster than cdecl because it reduces the number of memory accesses required to pass arguments, especially for functions with a small number of arguments. However, it is not portable across different platforms and compilers, and it may not provide significant performance improvements for functions with many arguments or complex logic.\n\nIn conclusion, cdecl and fastcall are two different calling conventions that define how arguments are passed to functions and how return values are handled. cdecl is the standard C calling convention and is widely portable, while fastcall is a Microsoft-specific convention designed for performance optimization but with limited portability. Understanding these conventions is essential for writing efficient and correct code, especially when working with low-level programming languages like C and C++."
    },
    {
        "link": "https://stackoverflow.com/questions/5479362/why-is-fastcall-slower-than-stdcall",
        "document": "I found following question: Is fastcall really faster?\n\nNo clear answers for x86 were given so I decided to create benchmark.\n\nHere is the code:\n\nIn case of no optimization result in MSVC 10 is:\n\nWith max optimization is sometimes faster, but I guess it is multitasking noise. Here is average result (with )\n\nHere are results for GCC: http://ideone.com/hHcfP Again, lost race.\n\nHere is part of disassembly in case of :\n\nthis is for :\n\nis passed via , instead of stack, but saved into stack in the body! So all the effect is neglected! this simple function can be calculated using only registers! And there is no real difference between them.\n\nCan anyone explain what is reason for ? Why doesn't it give speedup?\n\nEdit: With optimization it turned out that both functions are inlined. When I turned inlining off they both are compiled to:\n\nThis looks like great optimization, indeed, but it doesn't respect calling conventions at all, so test is not fair."
    },
    {
        "link": "https://learn.microsoft.com/en-us/cpp/cpp/calling-conventions?view=msvc-170",
        "document": "The Visual C/C++ compiler provides several different conventions for calling internal and external functions. Understanding these different approaches can help you debug your program and link your code with assembly-language routines.\n\nThe topics on this subject explain the differences between the calling conventions, how arguments are passed, and how values are returned by functions. They also discuss naked function calls, an advanced feature that enables you to write your own prolog and epilog code.\n\nFor information on calling conventions for x64 processors, see Calling Convention.\n• None Argument Passing and Naming Conventions ( , , , and others)"
    },
    {
        "link": "https://stackoverflow.com/questions/37487011/when-to-use-fastcall-calling-convention",
        "document": "A good optimizing compiler that supports whole-program optimization (aka link-time code generation) doesn't care about the calling convention for internal functions*. It will use whatever calling convention is the fastest/best in that situation, including inventing a custom calling convention or inlining the function altogether.\n\nThe only time a calling convention matters is for functions that form part of a public API. And in that case, is probably a poor choice. Use a more standard calling convention like or , widely supported by Windows toolchains. is an especially poor choice for interoperability, since it was never standardized and therefore is implemented differently by different vendors. This becomes a nightmare the minute you try to use your DLL with an application compiled with a different toolchain, much less in a different language.\n\nExcept, of course, when you're working with the VCL APIs that are documented as requiring the convention. For example, the documentation says that member functions for VCL classes use the convention, so you need to use the same calling convention in all of your overrides.\n\nOr when you need caller clean-up, e.g., to support variadic arguments. Then you need .\n\nIf you do want to use a particular calling convention for internal functions (i.e., those that are not part of a public API), you should really prefer to specify that globally with a compiler switch. This will then specify the calling convention to be used for all functions whose prototypes do not specifically override it. This has several advantages. For one, it avoids cluttering your code with a bunch of calling-convention boilerplate. Second, it allows you to easily make changes later (for example, if profiling reveals that your original choice of calling convention is a bottleneck that the optimizer is unable to resolve).\n\nAnecdotally, is superior to because of a reduction of binary size, made possible by the fact that the callee adjusts the stack instead of the caller (and there are fewer callees than callers), but as the article you linked mentions, may not always be faster than . The article doesn't go into any technical details, but the issue is basically the extremely limited numbers of registers available on 32-bit x86. Passing values in registers instead of on the stack is generally a performance win, but can become a pessimization in certain cases when the function is large and runs out of registers, forcing it to spill the arguments back to the stack, doing double work (which evokes a speed penalty) and further inflating the code (which evokes a cache penalty and, indirectly, a speed penalty). It is also a pessimization in cases where the values are already on the stack, but need to be moved into registers in order to make a function call, hindering the optimization potential in both places.\n\nDo note that this all becomes irrelevant when you start targeting 64-bit x86 architectures. The calling convention is finally standardized there for all Windows applications, regardless of vendor. The x64 calling convention is somewhat akin to , but works much better there because of the larger number of available registers. The optimizer is not required to go through as many contortions to free up registers for passing parameters as it is on x86-32.\n\n* Note that when I say \"internal\" functions here, I refer not to a particular access modifier, but rather to functions that are within a single compiland and/or those that are never called into by external code."
    },
    {
        "link": "https://en.cppreference.com/w/cpp/language/dynamic_cast",
        "document": "Safely converts pointers and references to classes up, down, and sideways along the inheritance hierarchy.\n\nFor the convenience of description, “expression or the result is a reference to ” means that “it is a glvalue of type ”, which follows the convention of (since C++11).\n\nOnly the following conversions can be done with dynamic_cast, except when such conversions would cast away constness (or volatility).\n\nIf the type of is exactly or a less cv-qualified version of , the result is the value of with type . In other words, can be used to add constness. An implicit conversion and can perform this conversion as well.\n\nIf is “reference to (possibly cv-qualified) ” and the type of is “(possibly cv-qualified) ” such that is a base class of , the result is the unique subobject of the object referred to by . In other words, can be used to upcast references, from derived to base. An implicit conversion and can perform this conversion as well.\n\nOtherwise a runtime check is applied to see if the object pointed/referred to by can be converted to the type , pointed or referred to by :\n\nIf, in the most derived object pointed/referred to by , points/refers to a public base class subobject of a object, and if only one object of type is derived from the subobject pointed/referred to by , the result points/refers to that object. In other words, can be used to downcast pointers/references, from base to derived.\n\nOtherwise, if points/refers to a public base class subobject of the most derived object, and the type of the most derived object has an unambiguous and public base class of type , the result points/refers to the subobject of the most derived object. In other words, can be used to crosscast (or side-cast) pointers/references, between two types derived from the same base.\n\nWhen dynamic_cast is used in a constructor or a destructor (directly or indirectly), and expression refers to the object that's currently under construction/destruction, the object is considered to be the most derived object. If target-type is not a pointer or reference to the constructor's/destructor's own class or one of its bases, the behavior is undefined.\n\nSimilar to other cast expressions, the result is:\n\nA downcast can also be performed with static_cast, which avoids the cost of the runtime check, but it is only safe if the program can guarantee (through some other logic) that the object pointed to by expression is definitely .\n\nSome forms of dynamic_cast rely on run-time type identification (RTTI), that is, information about each polymorphic class in the compiled program. Compilers typically have options to disable the inclusion of this information.\n\nThe following behavior-changing defect reports were applied retroactively to previously published C++ standards."
    },
    {
        "link": "https://stackoverflow.com/questions/55781006/how-to-use-dynamic-cast",
        "document": "I am trying to use dynamic_cast - with no success. I have a BASE class, and a class A derived from BASE. I want to have a pointer to a BASE class object which I later want to cast to class A. I clearly am not doing this correctly. The following code compiles:\n\nbut running it gives:\n\nI am sure I'm missing something very basic, but I keep staring at the code and can't see what I'm doing wrong. Any help would be very much appreciated.\n\nWhen should static_cast, dynamic_cast, const_cast and reinterpret_cast be used?\n\nbut don't understand why dynamic_cast doesn't work - isn't this just a simple downcast?"
    },
    {
        "link": "https://stackoverflow.com/questions/4050901/performance-of-dynamic-cast",
        "document": "Before reading the question:\n\n This question is not about how useful it is to use . Its just about its performance.\n\nI've recently developed a design where is used a lot.\n\n When discussing it with co-workers almost everyone says that shouldn't be used because of its bad performance (these are co-workers which have different backgrounds and in some cases do not know each other. I'm working in a huge company)\n\nI decided to test the performance of this method instead of just believing them.\n\nThe following code was used:\n\nThe above code uses methods from on Linux to get usable values.\n\n I've done 3 in one execution, the code for measuring them is the same.\n\nThe results of 1 execution were the following:\n\n Cast1 lasts: 74 microsec\n\n Cast2 lasts: 2 microsec\n\n Cast3 lasts: 1 microsec\n\nThe first cast always took 74-111 microsec, the following casts in the same execution took 1-3 microsec.\n\nSo finally my questions:\n\n Is really performing bad?\n\n According to the testresults its not. Is my testcode correct?\n\n Why do so much developers think that it is slow if it isn't?"
    },
    {
        "link": "https://devtalk.blender.org/t/usage-of-dynamic-cast-in-blender-code/35609",
        "document": "The topic of this thread is to decide whether using (in the context of a polymorphic C++ types hierarchy) should be discouraged altogether in Blender code, or to define the situations where it would be acceptable or even encouraged to use it. This topic rose up from discussions in PR 124405 and some informal follow-up chats with some Blender devs. Given that the feedback was very mixed, it felt worth having a discussion here about it. When looking online on e.g. stackoverflow about this topic, there also seems to be quite mixed views on usage of . Three main reasons are often given for why it is usually discouraged:\n• It seems to have a reputation of only being needed in ‘badly designed’ code.\n• It is slower than (and gets slower the more the type hierarchy gets complex). NOTE: Blender codebase already has a fair amount of usages of , including recent areas like implicit sharing or geometry nodes… The two main alternatives to using , while preserving type safety, are:\n• Asserting that the result of and are the same.\n\nI’ll share my personal view and understanding on this topic here. In summary, I do not see any good reason to prevent using in most of the code. It’s a cheap, easy, safe way to add some type-safety checks. The only case where it can become a problem is when millions of castings need to be performed per second. The terrible performances of in debug build context (when the Undefined Behavior Sanitizer is enabled) would also be a reason to prefer in most cases to me (although admittedly, the same reasoning applies to this case as to the usage of in release builds - the overhead should not matter anyway in ‘common’ cases). I find this point fairly moot and irrelevant. This usually applies to designs where an abstract base type is implemented by one or more sub-types, in some form of ‘interface’ paradigm. I think that the ‘bad design’ here is not the need to use , but the need to down-cast in general. Code using also typically has its own handling of type info to decide to which sub-type to cast a base pointer. As such, I see as a simple, fairly efficient and safe way to double-check and validate the correctness of the ‘type management’ performed by the code. Even if there is no validation of the cast pointer, will create an immediate crash situation, fairly clear and easy to understand. On the other hand, will give ‘something’ that may or may not crash, immediately or ten function calls later, etc. Dynamic (down) casting does require some additional operations on the CPU. This cost depends on the complexity and deepness of the type hierarchy. On modern hardware and compiler, a typically takes a few nanoseconds to a few tens of nanoseconds. While most benchmark available online are fairly old (10 years or more), this one is more recent (alas it does not seem to specify the compiler used). I also ran a small experiment with the (relatively simple) new type hierarchy from PR 124405 on my machine (Ryzen 9 5950X, Debian testing, clang 16). Results with a release build are in the 5 nanoseconds area per on average (and virtually 0 nanoseconds for as expected).\n\n A debug build (with undefined behavior sanitizer) gives… interesting results: is about 20 nanosecond on average, and is 3600 nanoseconds! With a few reports about invalid down-casting. As a conclusion regarding performances, while it should be avoided in critical areas of the code (where there would be millions of castings per seconds), typically does not have a significant impact on performances. In debugging context, when using an undefined behavior sanitizer, it can actually be several orders of magnitude more efficient than a . While using and asserting that its result matches is likely a good thing to do in performance critical areas, I am not convinced the added verbosity (and lesser bug-discoverability) is worth it. Not to mention the consequences of using an UBSAN build on . The virtual methods approach offers the same level of type-safety than , but with better performances (about twice as fast in simple cases, and performances remain relatively constant when the type hierarchy complexity grows). However, it adds a lot of clutter to the code, and requires way more maintenance from the dev team, especially as the type hierarchy gets more complex. I am even tempted to consider that, if using becomes a problem and implementing virtual casting methods becomes a solution, then it is a good sign that the current polymorphism-based design is a wrong choice.\n\nIt is not intrinsic to the to have the scent of “smelly code”, is more like any time you need to go down by the hierarchy. So to me neither nor are the winners when it comes to down-casting. I think there is a missing alternative solution: just a virtual method, which takes care of some “business logic” (which is a bit different from virtual casting methods). Having proper hierarchy with proper abstraction and API will always be the winner for me, as then you can much more clearly see early on that some code needs adjustment. Trying to hunt all places in the code which needs to be updated once hierarchy has hanged is not fun or robust process. I think this has quite good summary of this matter:\n\n https://google.github.io/styleguide/cppguide.html#Run-Time_Type_Information__RTTI_\n\nThe C++ core guidelines are pretty clear here: C.146: Use dynamic_cast where class hierarchy navigation is unavoidable Forbidding would be a strange choice to me. It’s a feature that increases type safety, avoids errors and makes it easier to add new derived types. Flat out forbidding it for performance reasons is premature micro optimization for practically no benefit. (Although you can pad yourself on the back for saving a few hundred nanoseconds, maybe even microseconds in otherwise badly optimized code that isn’t even a bottleneck </snarky>). Of course there are cases where it can matter (measure first). Sure in an ideal world you don’t need to use … or any cast at all. In practice you do. There is a lot of Blender code that defeats all design dogmatism. For example there’s a lot of C style inheritance in Blender, with manual type tagging. Converting these types to C++ style polymorphic types is an easy change with a number of benefits. Converting (spaghetti) code to also use virtual functions to replace all type checks is often much more difficult, I’ve spent plenty of time on this in the past. The former should be possible without requiring the latter. Otherwise certain improvements will just not happen. BTW, it’s been pointed out that Google’s guidelines are to not use RTTI, i.e. no . However, the guideline ends by saying this: Do not hand-implement an RTTI-like workaround. The arguments against RTTI apply just as much to workarounds like class hierarchies with type tags. Moreover, workarounds disguise your true intent. This is essentially an argument against much of Blender’s existing code design (“class hierarchies with type tags”). Following this guideline would require major refactors. Forbidding in favor of other casts only hides the issue (and doesn’t follow the guideline either). For new code/designs shouldn’t be needed, for old code it’s preferred for polymorphic types. Completely forbidding it doesn’t make sense. My preference would be a guideline along the lines of:\n\n “Avoid designs where is needed. Otherwise prefer it over manual type tagging.” This follows the C++ core guidelines and moves towards the Google guidelines too.\n\nThere must be an assert in there. It serves the purpose of showing to a programmer that the dynamic cast should never fail. If they think it is possible for it to fail they will do pretty awful things with the code to work around that possibility. Yea if you are paranoid you can follow the assert by a dynamic cast instead of a static one. I have generally seen crashes by bad casts. Your example of bad ids in files has to be handled anyway, it is best to assume anything in a file may be garbage. Any id’s have to be determined to really point to an object. After that it might be a good idea to use dynamic cast to make sure it is the right object. I have generally not seen any improvement to putting dynamic cast after an assert. There is also the need to make the arguments to both line up, but a macro that does both the assert and dynamic cast can fix this.\n\nWhat do you think about the following guideline (which I think summarizes what has been said)? I found it easiest to represent it as a decision tree instead of as a paragraph. Instead of having the decision for performance sensitive code we could also have a new method that does one or the other depending on whether one is in a debug build. flowchart can_avoid_downcast[\"Is design without down-casting appropriate?\n\nE.g. using virtual methods.\"] use_no_cast[\"Don't use explicit casting.\"] is_type_check_necessary[\"Is a type check necessary?\"] use_dynamic_cast_ptr[\"Use dynamic_cast with a pointer type.\n\nAlways check the returned pointer.\"] is_performance_sensitive[\"Is performance sensitive?\"] use_static_cast[\"Use static_cast for best performance.\n\nHard to find bug if assumption is wrong.\"] use_dynamic_cast_ref[\"Use dynamic_cast with a reference type.\n\nThrows an exception if type is wrong.\"] can_avoid_downcast --\"yes\"--> use_no_cast can_avoid_downcast --\"no\"--> is_type_check_necessary is_type_check_necessary --\"yes\"--> use_dynamic_cast_ptr is_type_check_necessary --\"no\"--> is_performance_sensitive is_performance_sensitive --\"yes\"--> use_static_cast is_performance_sensitive --\"no\"--> use_dynamic_cast_ref"
    },
    {
        "link": "https://doulos.com/knowhow/arm-embedded/cplusplus-casting",
        "document": "The purpose of this article is to clear up issues with casting in C++.\n\nWhen calling subroutines or assigning results from returns, the situation arises in which types don't match, and strict C++ typing appears to get in the way. Several solutions to this problem include implicit conversions, explicit conversions, and casting. Some of these are more dangerous than others. This article clarifies and guides you to make good decisions.\n\nSome general comments are appropriate before proceeding.\n\nFirst, good C++ programmers avoid casting whenever possible. Casting often has terrible results, including runtime overhead and incorrect conversions, unless adequately understood.\n\nSecond, these same programmers rightfully criticize any casting they see during code reviews unless it is justified adequately with comment blocks.\n\nThird, be afraid whenever you see or feel the need for casting. Usually, there are better alternatives.\n\nConversions come in two varieties. Implicit conversions include things like to and visa versa.\n\nUnfortunately, implicit conversions can get you in trouble. For instance, is considered to be an 8-bit integer. Consider the following legal, but highly likely bug:\n\nTo avoid this problem, you can use explicit conversions using the target type as an operator function. For instance:\n\nWhen creating classes, you should create needed conversions. Single argument constructors act as conversions to a class, which must also be designated as . You can use definitions to define conversions to other classes. With modern C++, you should also require single argument operators to be explicit by adding the explicit keyword. In the following, omit the keyword for operators for C++ before C++11.\n\nSometimes, a conversion does not exist, but you believe you know more than the compiler. In these situations, it may be appropriate to use a cast. For these situations, C++ supplies four types of casting with various levels of safety.\n\nC provides a cast of the form , but this is extremely dangerous! There are two reasons. First, it says, I know more than the compiler. Second, because the syntax is terse (few characters), it is easy to overlook. Consider the following disaster:\n\nThe C++ standard interprets this as applying it's named casts; however, no ordering is specified. The generally accepted order is: const_cast, static_cast, reinterpret_cast, and dynamic_cast. These are discussed in the following sections.\n\nC++ programmers NEVER use C-style casts. There is another section on this ahead. Read on…\n\nis the first cast you should attempt to use if conversion or construction does not work. This type of cast is called static because the C++ standard requires compilers to validate s at compile-time. If the compiler cannot resolve the type conversion as valid, it won't compile. The is a type name such as , a name, or a name.\n\ndoes things like implicit conversions between compatible types (such as to or pointer ), and it can also use explicit conversion functions (or implicit ones).\n\nIn many cases, explicitly stating isn't necessary. Still, it's important to note that the syntax may be equivalent to (see ISO-IEC-14882-2011 section 5.2.3) and should be avoided (more on that later). A (i.e., two or more arguments) is safe and guaranteed to call a constructor. With C++11, you may also safely use uniform initialization of the form .\n\ncan also be cast through inheritance hierarchies. It is unnecessary when casting upwards (towards a base class), but when casting downwards, it can be used as long as it doesn't cast through inheritance, which requires . However, it does not do run-time checking, and it is an undefined behavior to down a hierarchy to a type that isn't the object type. Thus should not be used for downcasting even if on some compilers it appears to work. Use instead (discussed later in this article).\n\ncan be used to remove or add to a variable, and no other C++ cast has this ability (not even ). It is important to note that using it is only undefined if the original variable is ; if you use it to take the off a reference to something that wasn't declared with , it is safe. For instance, this can be useful when overloading member functions based on const. It can also add to an object, such as to call a member function overload. Although occasionally good reasons exist to use , many experts suggest it is dangerous. The danger comes because you can remove the property from something that should never be changed. This will create undefined behavior.\n\nIt would be best not to use the const_cast\n\nalso works similarly on , though that's less common.\n\nGuideline: Avoid const_cast if at all possible.\n\nis almost exclusively used for handling polymorphism. You can cast a pointer or a reference to any polymorphic type to any other class type (a polymorphic type has at least one function, declared or inherited). You don't have to use it to cast downwards; you can attempt to cast sideways or even up another chain if multiple inheritance is involved. The will seek out the desired object and return it if possible. If it can't, it will return in the case of a pointer or throw in the case of a bad reference.\n\nIf type-id is not , a run-time check is made to see if the object pointed to by the expression can be converted to the type pointed to by .\n\nhas some limitations, though. It doesn't work if you don’t use virtual inheritance and multiple objects of the same type are in the inheritance hierarchy (i.e., the so-called dreaded diamond inheritance). also can only go through inheritance - it will always fail to travel through or inheritance. However, this is rarely an issue as such forms of inheritance are rare.\n\nAlthough conversions are safer than , only works on pointers or references, and the run-time type check is overhead.\n\nis the most severe cast and should be used sparingly. It turns one type directly into another - such as casting the value from one pointer to another, storing a pointer in an , or all sorts of other nasty things. Essentially, the only guarantee you get with is that you will get the same value if you cast the result back to the original type. There are several conversions that cannot do, too. It's used primarily for weird conversions and bit manipulations, like turning a raw data stream into actual data or storing it in an aligned pointer's low bits. It is also used for embedded software to convert absolute hardware addresses into pointers, although there are alternatives.\n\nThis is essentially how the fast inverse square root works.\n\nC-style casts are casts using . A C-style cast used in C++ is usually defined as the first of the following which succeeds:\n\nThe C++ standard does not guarantee the above ordering.\n\nBecause of the preceding table, C++ coders should never use C-style casting. You should know explicitly which type of cast is needed and be able to justify its use.\n\nC-style casts also ignore access control when performing a , which means they can perform an operation that no other cast can. This is bad; therefore, avoid C-style casts.\n• Whenever possible, avoid using any casting. Explicit conversion is preferable.\n• Use C++ uniform initialization syntax and auto whenever possible to avoid implicit conversions.\n• During code reviews, be especially suspicious of casts and require good comments or documentation demonstrating the need. Polymorphism is a reasonable justification.\n• If casting is unavoidable, then justify the decision with well-written comment blocks next to every cast or group of casts.\n• Use for converting pointers/references within an inheritance hierarchy. Runtime overhead is insignificant compared to the bugs it may avert.\n• Use for a low-level reinterpretation of bit patterns. Use with extreme caution. This type of casting is often non-portable due to endianess issues.\n• Use for casting away const/volatile. Avoid this unless you are stuck using a const-incorrect API.\n• Use conversion operators (e.g., ) or constructors (e.g., ) when possible, but be sure they are conversions and not devolved C-style casts.\n\nYou can find some code, with expanded tests, for this example at https://github.com/Doulos/cpp_casting."
    },
    {
        "link": "https://unstop.com/blog/dynamic-memory-allocation-in-cpp",
        "document": "Static Member Function In C++: How to Use Them, Properties, & More\n\nC++ Find() In Vector | How To Find Element In Vector With Examples\n\nUnderstand The While Loop In C++ & Its Variations With Examples!\n\nThe 'this' Pointer In C++ | Declare, Use, Code Examples & More\n\nDynamic Memory Allocation In C++ Explained In Detail (With Examples)\n\nMaster the technical aspects of dynamic memory allocation in C++. Learn the syntax and techniques to manage memory dynamically, optimizing your code for efficiency and robust performance.\n\nIn the C++ programming language, we can allocate the memory to an array or variable at some point during the run time. This is what we mean by dynamic memory allocation. In other words, dynamic memory allocation & de-allocation is the process of allocating or de-allocating a block of memory in the course of the execution of a program/ software. In this article, we will discuss ways to carry out dynamic allocation in C++ i.e. new and delete operators, allocation ways for arrays, allocation of objects, and so on.\n\nWhat is Memory Allocation in C++?\n\nMemory allocation is basically a way of booking a partial or entire part of system memory space for the execution of applications. Memory allocation may be executed through a method known as memory management.\n\nThere are two types of memory spaces in our device- static memory and dynamic memory.\n• Static Memory: In static memory allocation, memory is allotted and deallocated by the compiler on its very own. It's miles of permanent space allotted through the operating system which speeds up the time of execution of a program. We want to outline the required size of memory and it cannot reallocate the memory storage space consumed by means of the program until its execution is over.\n• Dynamic Memory: In dynamic allocation, the allocation and deallocation of the memory happen at runtime. That is, the memory must be allocated or de-allocated by the program all through the run-time of a C++ program. So the programmer is required to deallocate the dynamically allocated memory which is not in use.\n\nIn the case of static memory allocation for variables and arrays, the syntax is as follows:\n\nIn this kind of memory allocation, the operating system automatically allocates the memory at compile time and de-allocates it when the program, block, or function finishes.\n\nIn comparison, in the case of dynamic memory allocation in cpp, the programmer must first create the dynamic space in the heap memory. Here, heap memory refers to the unused memory space available for dynamic allocation for a program, at runtime. They then allocate and de-allocate the memory. This is how the memory is dynamically allocated in C++, for variables and arrays, and an example of this is-\n\nDynamically allocated memory will continue to be in use until the whole code or program terminates. So, a programmer needs to deallocate the memory, when it is not required. The need for this arises because memory leaks can occur when a programmer fails to de-allocate a dynamically allocated memory.\n\nAlso read- History Of C++ | Detailed Explanation (With Timeline Infographic)\n\nThe “new\" Operator In C++\n\nThe new operator is a unary operator used to dynamically allocate a block of memory and keep its address in a pointer variable at some point during the execution of a program. In other words, this operator is like a request for memory allocation on the heap memory (or the free store). And if sufficient memory is available, the dynamic space is initialized to the newly created variable or pointer.\n\nHere, pointer_variable indicates the pointer of type data_type. The new operator thus allocates a block of memory to type data_type. Note that the data_type here could either be any built-in data type (like an array) or a user-defined data type (like class, or structure).\n\nExample to C++ program to apply the new operator\n\nHere we have dynamically allocated a block of memory using the new operator, for the int variable. Within this, we have allocated the memory in heap by using the Var pointer. The new operator returns the address of the memory location.\n\nIn the case of an array, the new operator returns the address of the first element of the array. From the above example, we can see the syntax for using the new operator.\n\nWhat happens when there isn't enough space for the allocation of memory?\n\nThe new keyword in C++ will throw an exception of type std::bad_alloc when there is insufficient memory available for dynamic memory allocation. The program segment won't receive a valid pointer to the requested memory block and as a result, the block of memory fails allocation, as indicated by this signal. In this case, the program should be terminated or the user should see an error message if developers notice this exception and handle the failure event appropriately.\n\nYou might also be interested in reading- Strings In C++ | Functions, How To Convert & More (With Examples)\n\nThe \"delete\" Operator In C++\n\nWhat happens once we do not need the variable that we've got declared dynamically? Well, we must deallocate the space in memory occupied by means of the variable.\n\nFor this, we use the delete operator and de-allocate the block of memory, that was dynamically allotted with the use of the new operator. In view of that, a programmer must de-allocate a block of memory, as soon as it is not required within the program or code or it will lead to memory leaks. So, we require to use the delete operator to avoid memory leaks.\n\nExample to apply the delete operator\n\nProgram to use the delete operator:\n\nAs you can see in the code above, we have dynamically allocated the memory for the int variable, by using the Var pointer. So after printing the contents of Var, we free the memory with delete.\n\nGenerally, we aren't sure of the exact size/ length of an array till runtime. And this is where dynamic memory allocation makes memory management extra efficient. Say you want to allocate memory for an array of integers, that is, an array of n integers. The syntax and example for getting this done are given below:\n\nThis was the syntax for normal arrays, now let's look at the syntax for multidimensional arrays. Note that in the syntax and example, we use the square brackets after the data_type to indicate that we are dynamically allocating for an array.\n\nWhile the syntax to allocate the memory is different for a single element/ single dimension array and the multi-dimensional array, it remains the same for the deallocation process.\n\ndelete []var; // Delete array pointed to by means of var\n• We first include the iostream header file in our program.\n• Include the std namespace in our program so you can use its classes without calling it.\n• Call the main() function. The program logic should be added to the function body.\n• Declare a dynamic array with an array name using an initializer list. This integer array will contain 5 integer elements. Note that we didn't use the \"=\" operator between the field length and the initializer list.\n• Print some text to the console. Endl is a C++ keyword that means the end of the line and it brings the cursor to the next sentence.\n• Use a for loop to iterate over the elements of an array.\n• Print the contents of the field named field to the console.\n• End of the for loop.\n• The program must return a value.\n\nNow let's look at an example that shows how to deallocate memory to arrays in C++.\n\nAn array of integers is created by this C++ program, and each element is printed out. Prior to creating the array, we use the new operator and assign the array pointer to a variable. It first reads the length of the array from standard input. The array is then filled with values that are multiples of 10, rising by 10 for each entry starting at 10. Finally, we use the pointer notation and for loop to print out each element of the array. Then the delete[] operator is used to deallocate the memory that the array was occupying.\n\nCheck this out- Boosting Career Opportunities For Engineers Through E-School Competitions\n\nIt is also possible to dynamically allocate memory to objects. To begin with, the default constructor function initializes the object of class. And once the job is done, a default destructor function which is also a class member function deallocates the memory. Let us look at an example wherein we are going to use an array of objects to make the concept clear.\n\nExample of dynamic memory allocation for objects\n\nObserve that given that we allotted an array of three test objects, the default constructor is called on thrice. In addition, while freeing these objects, the destructor is also called on three times.\n\nDeallocation of memory may be carried out with the use of delete operators. The delete operator is used to deallocate, that is, it releases the memory which is turned into allotted through the new operator via its pointer ptr. The memory is then released in order that it can be used by a few different objects and no memory leak can arise.\n\nHere we use the Var pointer for the dynamic allocation of memory blocks, for the int variable. Then after printing the contents of Var, we free/ de-allocate memory blocks with the delete operator.\n\nThe C language makes use of the malloc() function and calloc() function to allocate memory dynamically at run time. These are both C standard library functions. It then makes use of a free() function to free dynamically allocated memory. While C++ also supports these features, the use of operators new and delete, carry out the task of allocating and releasing the memory in a better, less complicated, and more efficient manner.\n\nDynamic Memory Allocation In C++ | Uses\n\nUsing dynamically allocated memory is to allocate memory of variable length, which is not possible with compiler-allocated memory besides for variable-duration arrays.\n• The amount of freedom and liberty programmers get with a dynamic allocation is one of the important uses. It makes it possible for users to allocate and deallocate memory as and when they need to.\n• Dynamic memory allocation in C++ is also possible with the help of C standard library functions malloc() and calloc(), and deallocation with functions loose() and unfastened(). This can have its own benefits.\n• Since dynamic memory allocation happens at runtime, it makes it possible to efficiently allocate memory even when we don't know the variable size in advance. This also allows for allocation to varying sizes without any issues.\n• The use of dynamic memory allocation is especially beneficial in special cases like trees, hyperlink-listing, and many others.\n\nIn C++, there are important ways to dynamically allocate memory i.e. with the use of the new operator and the delete operator. A memory block is allocated using the new operator and de-allocated using the delete operator. And for C-style functions malloc and free functions are used. We also saw examples of how dynamic memory allocation is done for arrays and objects. Dynamic memory allocation in C++ is an essential concept in the discipline of data systems which includes related lists, stacks, queues, trees, etc.\n\nQ. What is dynamic memory allocation in CPP?\n\nDynamic memory allocation in C++ is a manner to allocate memory at some stage in program execution, instead of at compile time. It permits this system to request memory from the running device at runtime, after which it releases that memory when it is not in use. Dynamic memory allocation is typically used when the exact size of the data to be stored is not known at compile time, or when the size may change during program execution.\n\nUsing new and delete, you can allocate and deallocate memory for single objects or arrays of objects, while malloc and free can be used to allocate and deallocate blocks of memory of a particular length.\n\nIt is critical to note that with dynamic memory allocation, it is the programmer's responsibility to control the memory efficiently. In this, it is critical to deallocate memory to avoid the possibility of memory leaks. This may be achieved by calling delete or free on the pointer returned with the aid of the memory allocation function, once the memory is not wanted.\n\nQ. How many types of dynamic memory allocation are there in C++?\n\nDynamic memory allocation is a critical idea in C++ programming, as it allows developers to allocate memory at runtime, rather than during the compile time. In C++, there are two fundamental forms of dynamic memory allocation: using the \"new\" keyword and the usage of the \"malloc\" function.\n\nThe usage of the \"new\" keyword\n\nThe \"new\" keyword is used to allocate memory dynamically in the course of runtime. It is used to allocate a single item or an array of items on the heap memory. The syntax for using the \"new\" is as follows:\n\nThis syntax pronounces a pointer variable of the specified facts type and allocates memory on the heap to store the object of that data type. The \"new\" keyword returns a pointer to the allocated memory block, which is then assigned to the pointer variable.\n\nThe usage of the \"malloc()\" function\n\nThe \"malloc\" feature is borrowed from C programming and is used to allocate memory dynamically for the duration of runtime. It is used to allocate a block of memory of a unique length on the heap. The syntax for using the \"malloc\" function is as follows:\n\nThis syntax proclaims a pointer variable of the specified datatype and allocates a block of memory on the heap of \"num_bytes” size. The \"malloc\" function returns a pointer to the primary bytes of memory (allocated memory block), which is then assigned to the pointer variable. Observe that we need to cast the pointer to the right datatype.\n\nQ. What is the syntax to allocate memory in C++?\n\nIn C++, you can dynamically allocate memory using the \"new\" keyword, which returns a pointer to the new memory. The syntax for dynamically allocating memory in C++ is as follows:\n\nWhere \"datatype\" is the data type variable to allocate memory and \"pointer\" is the name of the pointer to which the new memory is allocated. The above syntax allocates memory for a variable of type \"data type\".\n\nIf you want to allocate memory for a different array, you can use the following syntax:\n\nwhere \"element_num\" is the number of elements in the array. The above syntax allocates memory for the variable array 'num_elements' of type 'datatype'.\n\nWhen you have finished using the dynamically allocated memory, you must free it using the \"delete\" keyword as follows:\n\nOr the variable array allocates memory. This frees up memory and frees it for other uses.\n\nQ. What is dynamic RAM with an example?\n\nDynamic Random Access Memory (DRAM) is a type of computer memory that is commonly used in modern devices like pc, mobile, and gaming consoles. DRAM is risky, which means that it requires a constant delivery of power to preserve the stored records.\n\nDRAM is made up of cells that consist of memory, each of which stores a bit of data as an electrical charge on a capacitor. The charge on the capacitor is refreshed regularly by a circuit within the DRAM chip to maintain the data's integrity.\n\nAn instance of DRAM in a computer gadget is the primary memory or RAM that stores records briefly at the same time as the computer is strolling. When you open a utility or file on your pc, the record is loaded from the hard drive or solid-state drive (SSD) into the DRAM, wherein it can be accessed quickly by means of the CPU. The more DRAM a system has, the more information it can store in memory, which ultimately enhances the system's average overall performance.\n\nQ. Can you use smart pointers to dynamically allocate memory?\n\nYes, smart pointers are a C++ language feature that can be used to dynamically allocate memory on the heap. Smart pointers are a form of RAII (Resource Acquisition Is Initialization) item that robotically manages the life of the dynamically allocated memory. This allows you to save memory leaks and dangling pointers that may occur when memory isn't well managed.\n\nThere are three types of smart pointers in C++:\n• unique_ptr: This smart pointer gives extraordinary possession of the dynamically allocated memory. One unique_ptr can only point to a given object at a time, and whilst the unique_ptr is destroyed, it routinely releases the memory it owns.\n• shared_ptr: This smart pointer allows more than one pointer to share ownership of the dynamically allocated memory. The memory is robotically released when the last shared_ptr pointing to its miles is destroyed.\n• weak_ptr: This smart pointer is used in conjunction with shared_ptr to break circular references. It provides a non-owning reference to the shared_ptr object and can be used to check if the object still exists.\n\nYou might also be interested in reading the following:\n• Difference Between C And C++| Features | Application & More!\n• C++ Interview Questions- The Basics, Uses, And More!\n• Find In Strings C++ | Examples To Find Substrings, Character & More!\n• Ways To Find String Length In C++ Simplified (With Examples)\n• Typedef In C++ | Syntax, Application & How To Use It (With Examples)"
    },
    {
        "link": "https://geeksforgeeks.org/new-and-delete-operators-in-cpp-for-dynamic-memory",
        "document": "Dynamic memory allocation in C/C++ refers to performing memory allocation manually by a programmer. Dynamically allocated memory is allocated on Heap, and non-static and local variables get memory allocated on Stack (Refer to Memory Layout C Programs for details).\n• None One use of dynamically allocated memory is to allocate memory of variable size, which is not possible with compiler allocated memory except for\n• None The most important use is the flexibility provided to programmers. We are free to allocate and deallocate memory whenever we need it and whenever we don’t need it anymore. There are many cases where this flexibility helps. Examples of such cases are\n\nHow is it different from memory allocated to normal variables?\n\nFor normal variables like “int a”, “char str[10]”, etc, memory is automatically allocated and deallocated. For dynamically allocated memory like “int *p = new int[10]”, it is the programmer’s responsibility to deallocate memory when no longer needed. If the programmer doesn’t deallocate memory, it causes a memory leak (memory is not deallocated until the program terminates).\n\nHow is memory allocated/deallocated in C++? \n\nC uses the malloc() and calloc() function to allocate memory dynamically at run time and uses a free() function to free dynamically allocated memory. C++ supports these functions and also has two operators new and delete, that perform the task of allocating and freeing the memory in a better and easier way.\n\nThe new operator denotes a request for memory allocation on the Free Store. If sufficient memory is available, a new operator initializes the memory and returns the address of the newly allocated and initialized memory to the pointer variable.\n\nSyntax to use new operator\n\nHere, the pointer variable is the pointer of type data-type. Data type could be any built-in data type including array or any user-defined data type including structure and class. \n\nExample:\n\nInitialize memory: We can also initialize the memory for built-in data types using a new operator. For custom data types, a constructor is required (with the data type as input) for initializing the value. Here’s an example of the initialization of both data types :\n\nAllocate a block of memory: a new operator is also used to allocate a block(an array) of memory of type data type.\n\nwhere size(a variable) specifies the number of elements in an array.\n\nDynamically allocates memory for 10 integers continuously of type int and returns a pointer to the first element of the sequence, which is assigned top(a pointer). p[0] refers to the first element, p[1] refers to the second element, and so on.\n\nNormal Array Declaration vs Using new \n\nThere is a difference between declaring a normal array and allocating a block of memory using new. The most important difference is, that normal arrays are deallocated by the compiler (If the array is local, then deallocated when the function returns or completes). However, dynamically allocated arrays always remain there until either they are deallocated by the programmer or the program terminates.\n\nWhat if enough memory is not available during runtime? \n\nIf enough memory is not available in the heap to allocate, the new request indicates failure by throwing an exception of type std::bad_alloc, unless “nothrow” is used with the new operator, in which case it returns a NULL pointer (scroll to section “Exception handling of new operator” in this article). Therefore, it may be a good idea to check for the pointer variable produced by the new before using its program.\n\nSince it is the programmer’s responsibility to deallocate dynamically allocated memory, programmers are provided delete operator in C++ language.\n\nHere, the pointer variable is the pointer that points to the data object created by new.\n\nTo free the dynamically allocated array pointed by pointer variable, use the following form of delete:\n\nTime Complexity: O(n), where n is the given memory size.\n• None Quiz on new and delete"
    },
    {
        "link": "https://design-reuse.com/articles/25090/dynamic-memory-allocation-fragmentation-c.html",
        "document": "In C and C++, it can be very convenient to allocate and de-allocate blocks of memory as and when needed. This is certainly standard practice in both languages and almost unavoidable in C++. However, the handling of such dynamic memory can be problematic and inefficient. For desktop applications, where memory is freely available, these difficulties can be ignored. For embedded - generally real time - applications, ignoring the issues is not an option.\n\nDynamic memory allocation tends to be nondeterministic; the time taken to allocate memory may not be predictable and the memory pool may become fragmented, resulting in unexpected allocation failures. In this session the problems will be outlined in detail and an approach to deterministic dynamic memory allocation detailed.\n\nIt may be useful to think in terms of data memory in C and C++ as being divided into three separate spaces:\n\nStatic memory. This is where variables, which are defined outside of functions, are located. The keyword static does not generally affect where such variables are located; it specifies their scope to be local to the current module. Variables that are defined inside of a function, which are explicitly declared static, are also stored in static memory. Commonly, static memory is located at the beginning of the RAM area. The actual allocation of addresses to variables is performed by the embedded software development toolkit: a collaboration between the compiler and the linker. Normally, program sections are used to control placement, but more advanced techniques, like Fine Grain Allocation, give more control. Commonly, all the remaining memory, which is not used for static storage, is used to constitute the dynamic storage area, which accommodates the other two memory spaces.\n\nAutomatic variables. Variables defined inside a function, which are not declared static, are automatic. There is a keyword to explicitly declare such a variable – auto – but it is almost never used. Automatic variables (and function parameters) are usually stored on the stack. The stack is normally located using the linker. The end of the dynamic storage area is typically used for the stack. Compiler optimizations may result in variables being stored in registers for part or all of their lifetimes; this may also be suggested by using the keyword register.\n\nThe heap. The remainder of the dynamic storage area is commonly allocated to the heap, from which application programs may dynamically allocate memory, as required.\n\nIn C, dynamic memory is allocated from the heap using some standard library functions. The two key dynamic memory functions are malloc() and free().\n\nThe malloc() function takes a single parameter, which is the size of the requested memory area in bytes. It returns a pointer to the allocated memory. If the allocation fails, it returns NULL. The prototype for the standard library function is like this:\n\nThe free() function takes the pointer returned by malloc() and de-allocates the memory. No indication of success or failure is returned. The function prototype is like this:\n\nTo illustrate the use of these functions, here is some code to statically define an array and set the fourth element’s value:\n\nThe following code does the same job using dynamic memory allocation:\n\nThe pointer de-referencing syntax is hard to read, so normal array referencing syntax may be used, as [ and ] are just operators:\n\nWhen the array is no longer needed, the memory may be de-allocated thus:\n\nAssigning NULL to the pointer is not compulsory, but is good practice, as it will cause an error to be generated if the pointer is erroneous utilized after the memory has been de-allocated.\n\nThe amount of heap space actually allocated by malloc() is normally one word larger than that requested. The additional word is used to hold the size of the allocation and is for later use by free(). This “size word” precedes the data area to which malloc() returns a pointer.\n\nThere are two other variants of the malloc() function: calloc() and realloc().\n\nThe calloc() function does basically the same job as malloc(), except that it takes two parameters – the number of array elements and the size of each element – instead of a single parameter (which is the product of these two values). The allocated memory is also initialized to zeros. Here is the prototype:\n\nThe realloc() function resizes a memory allocation previously made by malloc(). It takes as parameters a pointer to the memory area and the new size that is required. If the size is reduced, data may be lost. If the size is increased and the function is unable to extend the existing allocation, it will automatically allocate a new memory area and copy data across. In any case, it returns a pointer to the allocated memory. Here is the prototype:\n\nManagement of dynamic memory in C++ is quite similar to C in most respects. Although the library functions are likely to be available, C++ has two additional operators – new and delete – which enable code to be written more clearly, succinctly and flexibly, with less likelihood of errors. The new operator can be used in three ways:\n\np_var = new typename;\n\n p_var = new type(initializer);\n\n p_array = new type [size];\n\nIn the first two cases, space for a single object is allocated; the second one includes initialization. The third case is the mechanism for allocating space for an array of objects.\n\nThe delete operator can be invoked in two ways:\n\nThe first is for a single object; the second deallocates the space used by an array. It is very important to use the correct de-allocator in each case.\n\nThere is no operator that provides the functionality of the C realloc() function.\n\nHere is the code to dynamically allocate an array and initialize the fourth element:\n\nUsing the array access notation is natural. De-allocation is performed thus:\n\nAgain, assigning NULL to the pointer after deallocation is just good programming practice. Another option for managing dynamic memory in C++ is the use the Standard Template Library. This may be inadvisable for real time embedded systems.\n\nAs a general rule, dynamic behavior is troublesome in real time embedded systems. The two key areas of concern are determination of the action to be taken on resource exhaustion and nondeterministic execution performance.\n\nThere are a number of problems with dynamic memory allocation in a real time system. The standard library functions (malloc() and free()) are not normally reentrant, which would be problematic in a multithreaded application. If the source code is available, this should be straightforward to rectify by locking resources using RTOS facilities (like a semaphore). A more intractable problem is associated with the performance of malloc(). Its behavior is unpredictable, as the time it takes to allocate memory is extremely variable. Such nondeterministic behavior is intolerable in real time systems.\n\nWithout great care, it is easy to introduce memory leaks into application code implemented using malloc() and free(). This is caused by memory being allocated and never being deallocated. Such errors tend to cause a gradual performance degradation and eventual failure. This type of bug can be very hard to locate.\n\nMemory allocation failure is a concern. Unlike a desktop application, most embedded systems do not have the opportunity to pop up a dialog and discuss options with the user. Often, resetting is the only option, which is unattractive. If allocation failures are encountered during testing, care must be taken with diagnosing their cause. It may be that there is simply insufficient memory available – this suggests various courses of action. However, it may be that there is sufficient memory, but not available in one contiguous chunk that can satisfy the allocation request. This situation is called memory fragmentation.\n\nThe best way to understand memory fragmentation is to look at an example. For this example, it is assumed hat there is a 10K heap. First, an area of 3K is requested, thus:\n\nThen, a further 4K is requested:\n\n3K of memory is now free.\n\nSome time later, the first memory allocation, pointed to by p1, is de-allocated:\n\nThis leaves 6K of memory free in two 3K chunks. A further request for a 4K allocation is issued:\n\nThis results in a failure – NULL is returned into p1 – because, even though 6K of memory is available, there is not a 4K contiguous block available. This is memory fragmentation.\n\nIt would seem that an obvious solution would be to de-fragment the memory, merging the two 3K blocks to make a single one of 6K. However, this is not possible because it would entail moving the 4K block to which p2 points. Moving it would change its address, so any code that has taken a copy of the pointer would then be broken. In other languages (such as Visual Basic, Java and C#), there are defragmentation (or “garbage collection”) facilities. This is only possible because these languages do not support direct pointers, so moving the data has no adverse effect upon application code. This defragmentation may occur when a memory allocation fails or there may be a periodic garbage collection process that is run. In either case, this would severely compromise real time performance and determinism.\n\nA real time operating system may provide a service which is effectively a reentrant form of malloc(). However, it is unlikely that this facility would be deterministic.\n\nMemory management facilities that are compatible with real time requirements – i.e. they are deterministic – are usually provided. This is most commonly a scheme which allocates blocks – or “partitions” – of memory under the control of the OS.\n\nTypically, block memory allocation is performed using a “partition pool”, which is defined statically or dynamically and configured to contain a specified number of blocks of a specified fixed size. For Nucleus OS, the API call to define a partition pool has the following prototype:\n\nThis is most clearly understood by means of an example:\n\nThis creates a partition pool with the descriptor MyPool, containing 2000 bytes of memory, filled with partitions of size 40 bytes (i.e. there are 50 partitions). The pool is located at address 0xB000. The pool is configured such that, if a task attempts to allocate a block, when there are none available, and it requests to be suspended on the allocation API call, suspended tasks will be woken up in a first-in, first-out order. The other option would have been task priority order.\n\nAnother API call is available to request allocation of a partition. Here is an example using Nucleus OS:\n\nThis requests the allocation of a partition from MyPool. When successful, a pointer to the allocated block is returned in ptr. If no memory is available, the task is suspended, because NU_SUSPEND was specified; other options, which may have been selected, would have been to suspend with a timeout or to simply return with an error.\n\nWhen the partition is no longer required, it may be de-allocated thus:\n\nIf a task of higher priority was suspended pending availability of a partition, it would now be run. There is no possibility for fragmentation, as only fixed size blocks are available. The only failure mode is true resource exhaustion, which may be controlled and contained using task suspend, as shown.\n\nAdditional API calls are available which can provide the application code with information about the status of the partition pool – for example, how many free partitions are currently available. Care is required in allocating and de-allocating partitions, as the possibility for the introduction of memory leaks remains.\n\nThe potential for programmer error resulting in a memory leak when using partition pools is recognized by vendors of real time operating systems. Typically, a profiler tool is available which assists with the location and rectification of such bugs.\n\nHaving identified a number of problems with dynamic memory behavior in real time systems, some possible solutions and better approaches can be proposed.\n\nIt is possible to use partition memory allocation to implement malloc() in a robust and deterministic fashion. The idea is to define a series of partition pools with block sizes in a geometric progression; e.g. 32, 64, 128, 256 bytes. A malloc() function may be written to deterministically select the correct pool to provide enough space for a given allocation request. This approach takes advantage of the deterministic behavior of the partition allocation API call, the robust error handling (e.g. task suspend) and the immunity from fragmentation offered by block memory.\n\nC and C++ use memory in various ways, both static and dynamic. Dynamic memory includes stack and heap.\n\nDynamic behavior in embedded real time systems is generally a source of concern, as it tends to be non-deterministic and failure is hard to contain.\n\nUsing the facilities provided by most real time operating systems, a dynamic memory facility may be implemented which is deterministic, immune from fragmentation and with good error handling."
    },
    {
        "link": "https://educatedguesswork.org/posts/memory-management-2",
        "document": "This is the second post in my planned multipart series on memory management. In part I we covered the basics of memory allocation and how it works in C, where the programmer is responsible for manually allocating and freeing memory. In this post, we'll start looking at memory management in C++, which provides a number of much fancier affordances.\n\nAs the name suggests, C++ is a derivative of C. The original version of C++ was basically an object oriented version of C (\"C with classes\") but at this point it has been around for 40-odd years and so has diverged very significantly (though modern C is a lot more like original C than C++ is) and accreted a lot of features beyond what you'd think of in an object oriented language, such as generic programming via templates and closures (lambdas).\n\nDespite this, C++ preserves a huge amount of C heritage and many C programs will compile just fine with a C++ compiler; in fact, C++ was originally implemented with a pre-processor called \"cfront\" which compiled C++ code down into C code, though that's not how things work now. This is actually a source of a lot of issues with C++, when programmers do things the C way—or even the older C++ way—even though modern C++ has better methods. We'll see some examples of this later in this post.\n\nThe most obvious change in C++ is the introduction of the idea of objects and classes. At a high level, an object is a data type that has both data and code associated with it, where code means functions. But let's start by looking at a type which just has data associated with it, but where that data is somewhat complex.\n\nComplex data types are already a feature in C. For instance, consider the following example type:\n\nEven if you don't know C, if you've done any programming you can probably figure out what this means: it's defining a new type that represents a rectangle and has two values, the height and the width of the rectangle, each of which are integers ( being one of the C integer types). Obviously you could just have two variables, and , but this lets you group them together, like so:\n\nIn this example, we've defined a function called area that takes a rectangle as an argument and returns the product of the width and the height. Note that the notation for accessing a one of the values inside a C is the where is the name of the variable containing the struct and is the name of the inside the struct (e.g., ).\n\nI've actually done something new here that you might not have noticed, which is that I've passed our struct to the function. All function calls in C are what's called \"call by value\", which is to say that C makes a copy of the data element that is available to the function but is disconnected from the original value. The called function can change its arguments without affecting the caller. Consider, for instance, the following example.\n\nAs expected, this prints out:\n\nbecause just modified its own copy of . Function calls are just a special case of generically how assignments in work: they make a copy of whatever memory was associated with the source and stuff it into the target.\n\nC does provide a way for the called function to modify memory associated with the caller: the caller just passes a pointer to the callee rather than the variable itself, as in the following code:\n\nNote the new notation here:\n• takes a pointer to a variable so is a pointer to\n• accesses a variable in a struct when you have a pointer to the struct. This is what is known as \"syntactic sugar\" because you could just do , but it's used all the time.\n\nThis snippet does what we expect, which is to say modifies the value in the outer function:\n\nIt's important to realize, though, that C was still doing call-by-value; it's just that the value we passed was a pointer to rather than itself, which allowed the function to manipulate the memory that the argument pointed to rather than its local copy of that variable.\n\nEverything we've seen here is still normal C, but often we want to associate a function with a type. For instance, the area function we have shown above only works with rectangles, but what if we had circles as well? We'd end up with two functions, one called and one called . Objects give us another option, which is to associate the function with the type, so that we can do something like this:\n\nWe've got some new syntax here, but it's basically an extension of the old syntax. Instead of referring to a data element with we are now referring to the function with the the syntax . Also we don't have to pass the data values to because it just gets them as part of the function call, which is very convenient if we also have circles, because then we can do:\n\nNote that the call to is exactly the same in both cases. This syntax hides what kind of object we are working with, which lets us reason about the logic of the program without worrying about what shape we are working with. Which function gets called depends on the type of object ( or ). This type of function is called a method or a member function of the type it's associated with.\n\nOf course, we still have to define and . The definition of looks like this:\n\nThe first part of this is basically the same as , except for the line, which we can ignore for now. Just as before, we have and . What's new here is the function. This is also almost exactly the same as before, except for two things:\n• We don't need to pass a copy of as an argument because the and fields are automatically available to any member function.\n\nThe definition of is similar, except with the standard π r2 area formula\n\nTo recap the terminology here: the class is the type definition and an object is a given instance of the class.\n\nWe won't really need this in this post, but I'd be remiss if I didn't mention one of the most important features of classes, which is inheritance. The idea here is to say that a given class, say is itself derived from a more general class, such as . Anywhere you could use a pointer to you can use a pointer to a instead. For example, we could define a as having an function like so:\n\nNotice that we haven't provided a definition (body) for , instead we have the keyword in front and there is in place of the body. Together these mean that all classes derived from have to define for themselves. We then modify to indicate that it is derived from and we'll need in front of here for some technical reasons which we don't need to go into.\n\nThe result of all this is we can now write a function which can take any shape and do stuff, as in:\n\nIf we have a then can be called just like you would expect:\n\nIf you've been paying attention, you'll have noticed that I said you can use a pointer to wherever you could have used a pointer to . You cannot, however, use a wherever you would have used a . If you try to assign a to a you end up with something with the properties of but not . This is called object slicing and it's usually not what you want.\n\nThere's one more C++ feature we need in order to understand basic C++ memory management, and that's constructors (often abbreviated ctors) and destructors (dtors). So far we've initialized stuff just by setting the fields, but C++ lets us do more: a class can have a function that runs whenever an object of that class is created. That's not really that useful with this simple an object, but just as an example suppose we wanted to print something out for debugging purposes whenever someone created a . Then we could do:\n\nThe constructor also has to initialize the fields in the object, as we've done here. Then when you want to create a you could do:\n\nThis creates a on the stack. If you want to create a on the heap, you don't use but instead a new operator called , as in:\n\ntells the C++ compiler that this is an object and should run the constructor (conceptually it's like calling and then calling the constructor). If you used you would just get uninitialized memory of the right size.\n\nC++ also supports destructors, which are functions that run before the object is destroyed. But when is an object destroyed, you might ask. Remember how I said that in C freeing an object just means that you release the memory for another use? C++, however, has a richer concept of object lifecycle: whenever a C object would just have its memory returned, C++ thinks of this as an object being destroyed. This means:\n• If the object is on the stack, when the object goes out of scope (e.g., when the function returns).\n• If the object is on the heap, when it is explicitly destroyed with (note: not If you have a pointer to an object on the stack and it goes out of scope, you get a leak, just like in C.\n\nA destructor gets written like this:\n\nThe prefix indicates that it's a destructor. Note that the destructor still has access to the member variables, which is why it's able to print them out. As long as they're regular variables and not pointers, it doesn't need to do anything with them, as they'll just be destroyed when the object is finally destroyed. If they're pointers, however, the destructor needs to call or there will likely be a memory leak (unless the data is referenced elsewhere). In either case, the destructors of the member variables will themselves be run as part of the destruction process.\n\nPutting it all together, if we have the following program:\n\nWe would expect to see:\n\nYou'll notice that I'm not checking for errors when I do , unlike with C where we had to check that hadn't failed. By default, if isn't able to allocate memory it will crash the program rather than returning an error (or rather a null pointer). The technical term for this is that is \"infallible\" whereas is \"fallible\", thus forcing you to handle allocation failures. It's possible to tell C++ that you want to be fallible using , in which case will return (0) the way does. Infallible memory allocation is a pretty common pattern in newer languages, many of which don't even really let you detect memory failure; they just crash the program. Whether this is good or bad is a matter of opinion.\n\nWe now have the pieces we need to significantly improve memory allocation. Let's go back to our previous program and instead of just having a raw pointer, we're going to define a class that holds the list of lines. It looks like this:\n\nThis is the same data structure as before, except that we've:\n• Moved the local variables into the class.\n• Put the initialization logic in the constructor and the teardown logic in the destructor.\n\nThe rest of the program remains the same, except that we have to access and via the object. Note that we never have to explicitly call the destructor, it just runs automatically when we return from the function. This may seem like a small improvement, but let's go back to the case we looked at in part I where we had an error handling block. Recall that that code looked like this:\n\nWe had to have the special cased and error prone block that did cleanup. Now let's look at (almost) the same code in C++:\n\nBy using the destructor, we've gotten rid of the potential memory leak entirely: anything that causes to go out of scope automatically invokes the destructor, and so the memory we've allocated gets cleaned up. We do, however, still have a leak: the file pointer , which gets cleaned up properly in the normal case but not in the error case. If we wanted, we could address this by making a new class to wrap , but C++ has already done this for us using the , which gets used like this:\n\nIf we use we don't need to clean up the file at all because it will just happen automatically, and the final block just looks like:\n\nThis style of memory management is often called \"RAII\", which stands for \"Resource Acquisition is Initialization\". RAII is not exactly winning any records for the clearest name, and mostly people just say \"RAII\". The idea here is that the process of creating the object (e.g., or ) allocates its resources and the process of destroying the object deallocates its resources, so as long as you have a valid copy of the object, you know it's safe to use and once the object goes out of scope, things will automatically get cleaned up. As you can see, RAII really simplifies memory management and is generally considered to be the most convenient way to do C++ memory management (though there are also vocal RAII opponents).\n\nNote that what makes RAII work here is that the object is on the stack but it's holding resources on the heap. That way when the function returns, the object is automatically destroyed. If instead you were to allocate the object on the heap and stored a pointer on the stack, we would still have a problem. I'll be getting to how to address in a later post.\n\nStuffing our list of stored lines into a class helps some, but it's not really ideal. We've had to make this new class and then we have to reach into the class to add new lines and to sort the lines. We could of course add new interfaces to but C++ has already done the heavy listing for us by providing containers. A container is basically just a fancy term for an object whose purpose is to holds some number of other objects like a list, vector, or map. Remember from our original Python version? That's a container. Here's our new program rewritten with some C++ containers.\n\nThe key line to look at here is the following:\n\nWhat this does is to make a \"vector\" called which is basically a self-growing container that can be indexed like an array. will contain an arbitrary number of objects of type , which, unsurprisingly, is a C++ object that contains a string of characters. This is loosely analogous to the Python code except that Python lists can contain mixed types of objects, as in:\n\nwhich contains a string and an integer; this vector can only contain strings.\n\nContainers massively simplify things because now when we want to add a line that we read in to our list of lines it's a one-liner:\n\nThis replaces all the complicated machinery we had before where we had to manually make room in and then make a copy of the string to add to lines, because C++ does all of that for us. Moreover, we don't need to worry about the string being too big because will automatically grow our buffer ( ) to whatever size is needed, which eliminates a lot of the error cases. However, if we did have an error for some reason, then RAII would of course clean up. For instance, the following code returns an error if lines are more than 1024 characters long.\n\nBecause we are using RAII this is totally fine and both the file and the list of strings will be cleaned up properly.\n\nThe sort is a one-liner too, though the syntax is kind of gross. You can sort of see what's happening here, namely that we're providing the first and last items in the vector and then figures it out. The actual details are sort of subtle and out of scope for this post.\n\nThis leaves us with the last clause, where we iterate over the list of sorted lines and print them out. This code is the most similar to the previous version, differing mostly in that we don't have to remember how many lines there are because the function lets you ask a vector how big it is:\n\nThe other change is that we have to use method to get the underlying to pass it to because doesn't know what to do with a C++ string.\n\nThis isn't really that idiomatic C++ for several reasons:\n• C++ has its own functions to print stuff to the console and most programmers prefer those. Those functions will also take a string directly rather than needing .\n• In modern C++, you would use an iterator ( ).\n\nThe more modern code would look like this:\n\nI've written it the less idiomatic way for two reasons. First, it's more familiar and I'm trying not to introduce too many new things at once. Understanding what's happening here requires a bunch of new concepts. Second, and more importantly, it illustrates something important about C++, which is that while the better modern techniques are available to you, you're not required to use them, and in fact C++ lets you do all kinds of unsafe stuff. For example:\n• Array-style accesses to vector elements aren't bounds checked, so if I did after reading one line, anything could happen, up to and including the compiler deciding to delete all your files, start mining Bitcoin, or call 911 (the technical term here is undefined behavior).\n• returns a pointer to whatever internal storage the string object is using to store its value (as of C++11), which means that we have to worry about all the same lifetime issues as before. For instance, if we were to return the value of from this function, that value would not be safe to use because it would be pointing to storage that had been destroyed when the string went out of scope.\n\nThe key point is that C++ provides safe ways to work with these objects, but it also lets you do all the old unsafe C stuff.\n\nRecall that I said above that when you assign one variable to another, C just copies the internal values. This includes structs, so that, for instance, when we do:\n\njust becomes a copy of , and they're totally independent, so in the following code:\n\nWe would get the output:\n\nThe situation is no different when one of the fields in a struct is a pointer. For instance:\n\nAttention: I added because I got tired of writing out the error checking and I thought it distracted from the main flow of the code. In a real program, you might do better.\n\nWait, what? The sizes are different but the name is the same. This happens because when we did the assignment we just assigned the pointer's value not the string's value (i.e., ), so and are pointing at the same object. just overwrites that memory, with the result that both objects end up with . By contrast, because and are just values, then there are separate values in and , as shown below:\n\nThis is what's often called a \"shallow copy\" as opposed to a \"deep copy\", where there would be two different strings in and . Doing a deep copy in this case obviously requires allocating new memory for and then copying the contents of the string into it (presumably via some API like ). If we want a deep copy in C, we need to do it explicitly. For instance:\n\nThe result looks like this:\n\nBy default, C++ also does shallow copies, but it provides a facility that lets you do better. When you make one C++ object starting from another of the same type, the compiler invokes what's called the \"copy constructor\", which is a special method of the new object that takes the object you're copying from as an argument. For instance, if we just wanted to do a shallow copy of it would look like this (recall that the unqualified names of member variables in methods just refer to the current object):\n\nThis is just the same thing that happened above, but we've done it explicitly. If you don't supply your own copy constructor, C++ will make one that does a shallow copy, which is to say basically this code. But you can also provide a copy constructor that will do anything you want. For instance, here's a deep copy:\n\nNote that we don't need to do anything special for and because they aren't pointers to anything, just values. However, because we've replaced the copy constructor we do need to explicitly copy them. But for we want to allocate new memory and copy into it. Now let's do the do the same thing as before where we mess with the values in :\n\nThis has the result we want:\n\nAt this point you could be forgiven for thinking that this is all just syntactic sugar. After all, and the copy constructor are basically the same code and how hard is it to just write instead of ? At some level this is true of course, in the sense that all programming languages are syntactic sugar on top of assembly, but this is very useful syntactic sugar.\n\nConsider what happens if we have the following class:\n\nIf we now do:\n\nThis will just work because the default copy constructor for calls the copy constructors for when we try to make from . By contrast, without this feature we would need to write :\n\nBasically, as long as you are working with objects which contain only other objects which have copying implemented correctly then they will behave properly when you try to copy them without you having to do anything special. This isn't that big an issue in a small system but once things get large it's pretty convenient not to have to think about writing all the boilerplate to recursively copy everything. As with our method before, the idea is to free you to focus on the program logic.\n\nHowever, this only works if the object contains objects. If it contains pointers then those pointers will be copied directly as usual without invoking the copy constructor. Fortunately, C++ has an extensive set of container classes so that you can often—though not always—get away without having to store pointers in your objects. In this specific case, if we just used the C++ class instead of C-style , as shown below, then the default copy constructor would work fine and we wouldn't have to do anything (which is why I showed the worse version that uses );\n\nNerd sniping alert: this section is going to go a bit into some nitpicky C++ detail. You can safely skip it without missing the main point.\n\nLet's go back to our above code where we use the copy constructor:\n\nWhat if we alter it slightly so that we construct first and then assign to :\n\nThis is superficially similar to the previous code but actually does something quite different. Instead of invoking the copy constructor, in this case it invokes the copy assignment operator, which is used whenever you assign one object to another. The reason that the copy constructor was invoked in the first example is that was still under construction, but in the second example, it's already fully constructed and so we instead invoke the copy assignment operator. In case all that's not clear, look at the following code\n\nAs with the copy constructor, the copy assignment operator can in principle do anything, but in practice what you usually want it to do is to clean up the destination object (similar to what you do do with the destructor) and then copy the source object onto it, similar to what the copy constructor would do.\n\nThere are two important things to notice about this code.\n\nFirst, before we do anything else, we check to see if we are assigning to ourself, as in:\n\nIf so, we just return early without doing anything else. This may seem like an optimization but it's actually critical for correctness. To see this, take the assignment operator code and fill in the actual concrete values for a self-assignment of to itself. In this case, the lines where we copy over the name look like this:\n\nNote that we've just freed and then right away we try to copy it. Holy use-after-free Batman!\n\nIn the copy constructor we just assigned , but here we have to free first. Why?\n\nThe reason is that in the copy constructor we knew that the target object was uninitialized and so isn't holding onto any valid memory—though it might be filled with a random pointer to nothing in particular—but when we are doing copy assignment, the target object already exists which means that it might have something in and so we need to free it first to prevent a memory leak (the opposite of the use after free in the previous section).\n\nWe just glossed over the odd syntax declaring this function:\n\nWhat's going on here is that C++ allows for what's called operator overloading, which means that you can supply new implementations for existing \"operators\" like or . This is very useful because it allows for idiomatic code in some situations that would otherwise be confusing.\n\nA common example here is complex numbers. These aren't built into C++, which means that it doesn't know how to add or subtract them. You can use operator overloading to provide implementations for and so you can write:\n\nwhich is what you would do in C.\n\nIn this case we are overloading the default copy assignment operator implementation which would do fieldwise copy just like the copy constructor.\n\nWhy do I need this anyway? #\n\nOne natural question to ask is why we need to overload the operator. The obvious alternative is to have the compiler run the target's destructor and then the copy constructor (after checking for self-assignment, of course).\n\nTo be honest, I don't really have a clear picture of whether this is actually infeasible or whether instead it's just a matter of maintaining maximum programmer flexibility. I've spent a bunch of time searching online and had a number of somewhat frustrating conversations with ChatGPT and the overall impression I am getting is that it would violate some pre-existing commitments in C++ (ChatGPT gave me a bunch of stuff about \"object identity\" and performance), but it's not clear to me how serious these issues are. It's certainly true that C++ has so much history that any new feature needs to exist within a complex web of existing constraints, so it's possible that this approach would violate one, and it often takes a lot of analysis to determine if that's true. If someone has a better! answer, email me!\n\nDisclaimer: The feature I am about to describe was introduced in C++ comparatively late (by which I mean in the past 15 years) and I haven't really worked with it, so I'm writing based on what I've read online. Don't write code based on this section (or really, on the rest of this post either).\n\nC++-11 introduced the concept of moving on assignment rather than copying. Consider the following somewhat contrived code.\n\nUnder normal circumstances, transferring and into would involve calling the copy constructor to copy them into . and aren't used after this point but just hang around until they go out of scope at the end of the function, where they are destroyed, at the same time as . This isn't a correctness issue because we eventually clean up, but is wasteful because we copy them unnecessarily (including allocating new memory to copy ) even though they're only used via thereafter.\n\nIn modern C++ you can instead move and into . The details are complicated, but the high order idea is that the source of the move isn't required to continue to be usable and so you can make move more efficient than copying, in this case by just coping the pointer to rather than allocating new memory; you just copy and as usual. The source is left in an \"unspecified but valid state\", which seems to leave a lot of room for implementation discretion.\n\nFor obvious reasons you can't just go moving stuff around any time someone assigns one variable to another, as before move was introduced in C++-11 they would have been copied and it would be very surprising to have the source variable suddenly become unusable. There are some specific circumstances where the compiler will do a move automatically, but otherwise you have to tell it you want a move by wrapping the source in a wrapper, like so:\n\nImportantly, nothing stops you from using the source object after moving it, so in this case you could use , but with unpredictable results. You probably don't want to do this, because, as noted above, it is left in a \"valid but unspecified state\", but the compiler assumes you know what you're doing (in a future post we'll look at Rust, where using a value after a move is explicitly forbidden and the compiler will stop you).\n\nIn many cases you can implement move with a shallow copy by just copying the fields, because we don't need the original version to be valid. A shallow copy is obviously more efficient, but there are some situations where it doesn't work. One common example is when the object contains an internal reference. Consider the following example:\n\nNow is a pointer to the internal field . This is obviously a contrived example, but there are real situations where it makes sense.\n\nThe result is that if you were to just assign the fields of one to another, then will end up pointing to the field in the original object not the new one.\n\nIf the original is destroyed, points to free memory, which brings us back to use-after-free problems. Obviously, if you are using this kind of class you will need to provide a smarter move assignment implementation; the point is just that you need to do that.\n\nC++ is full of this kind of situation, where the compiler allows things that are unwise or even dangerous and you're just supposed to know to not do them. To a great extent this is a result of the way C++ developed: it used to be that these were the only way to do things and so they're allowed even though we have better ways now. When we get to Rust we'll see that it just doesn't let you do dangerous stuff—unless you ask it very nicely—because it was designed from the ground up to be safe.\n\nRAII is a powerful technique but what we've seen so far is only a partial solution. Things are (mostly) fine when working with objects but if we want to work with pointers, as in our example, then we need to implement custom copy constructors, copy assignment operators, etc. if we want them to be safe. This is true even if we want to store on object on the heap but have a pointer on the stack. In the next post I'll be covering a technique called \"smart pointers\" that helps address these problems."
    },
    {
        "link": "https://cmp99.medium.com/modern-c-memory-allocation-35b00529ad8d",
        "document": "Memory allocation is an important concept for systems programmers to understand, especially when working in environments where resources are limited. This article will go over the differences between the different types of memory allocation and the best practices in modern C++.\n\nWhen learning about memory allocation, you may have heard of terms like “the stack” and “the heap”, as well as “static memory” and “dynamic memory”, but what do these terms actually mean?\n\nMemory is split into a few major sections:\n• Data Segment: A section of memory used to store global and static variables, managed by the compiler. Memory allocated here is known as static memory and the lifetime of these variables are tied to the lifetime of the program.\n• The Stack: A region of memory organized in a last-in-first-out (LIFO) fashion, managed by the operating system and the compiler. The stack pointer ( ) keeps track of the top of The Stack. As functions are called, stack frames are pushed onto The Stack, storing data such as the return address, local variables, and more.\n\nMemory allocated on The Stack is known as automatic memory or “stack memory” and includes local variables for a function. To allocate memory for local variables, the simply moves a fixed amount, making stack memory allocation just as fast…"
    }
]