[
    {
        "link": "https://keras.io/api/losses",
        "document": "The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.\n\nNote that all losses are available both via a class handle and via a function handle. The class handles enable you to pass configuration arguments to the constructor (e.g. ), and they perform reduction by default when used in a standalone way (see details below).\n\nThis is the class to subclass in order to create new custom losses.\n• reduction: Type of reduction to apply to the loss. In almost all cases this should be . Supported options are , , , or . sums the loss, and sum the loss and divide by the sample size, and sums the loss and divides by the sum of the sample weights. and perform no aggregation. Defaults to .\n• name: Optional name for the loss instance.\n• dtype: The dtype of the loss's computations. Defaults to , which means using . is a unless set to different value (via ). If a is provided, then the will be utilized.\n\nTo be implemented by subclasses:\n• : Contains the logic for loss calculation using , .\n\nA loss function is one of the two arguments required for compiling a Keras model:\n\nAll built-in loss functions may also be passed via their string identifier:\n\nLoss functions are typically created by instantiating a loss class (e.g. ). All losses are also provided as function handles (e.g. ).\n\nUsing classes enables you to pass configuration arguments at instantiation time, e.g.:\n• y_true: Ground truth values, of shape . For sparse loss functions, such as sparse categorical crossentropy, the shape should be\n• sample_weight: Optional acts as reduction weighting coefficient for the per-sample losses. If a scalar is provided, then the loss is simply scaled by the given value. If is a tensor of size , then the total loss for each sample of the batch is rescaled by the corresponding element in the vector. If the shape of is (or can be broadcasted to this shape), then each loss element of is scaled by the corresponding value of . (Note on : all loss functions reduce by 1 dimension, usually .)\n\nBy default, loss functions return one scalar loss value for each input sample in the batch dimension, e.g.\n\nHowever, loss class instances feature a constructor argument, which defaults to (i.e. average). Allowable values are \"sum_over_batch_size\", \"sum\", and \"none\":\n• \"sum_over_batch_size\" means the loss instance will return the average of the per-sample losses in the batch.\n• \"sum\" means the loss instance will return the sum of the per-sample losses in the batch.\n• \"none\" means the loss instance will return the full array of per-sample losses.\n\nNote that this is an important difference between loss functions like and default loss class instances like : the function version does not perform reduction, but by default the class instance does.\n\nWhen using , this difference is irrelevant since reduction is handled by the framework.\n\nHere's how you would use a loss class instance as part of a simple training loop:\n\nAny callable with the signature that returns an array of losses (one of sample in the input batch) can be passed to as a loss. Note that sample weighting is automatically supported for any such loss.\n\nLoss functions applied to the output of a model aren't the only way to create losses.\n\nWhen writing the method of a custom layer or a subclassed model, you may want to compute scalar quantities that you want to minimize during training (e.g. regularization losses). You can use the layer method to keep track of such loss terms.\n\nHere's an example of a layer that adds a sparsity regularization loss based on the L2 norm of the inputs:\n\nLoss values added via can be retrieved in the list property of any or (they are recursively retrieved from every underlying layer):\n\nThese losses are cleared by the top-level layer at the start of each forward pass – they don't accumulate. So always contain only the losses created during the last forward pass. You would typically use these losses by summing them before computing your gradients when writing a training loop.\n\nWhen using , such loss terms are handled automatically.\n\nWhen writing a custom training loop, you should retrieve these terms by hand from , like this:\n\nSee the documentation for more details."
    },
    {
        "link": "https://saturncloud.io/blog/creating-custom-loss-functions-in-kerastensorflow",
        "document": "In the world of machine learning, loss functions play a pivotal role. They measure the inconsistency between predicted and actual outcomes, guiding the model towards accuracy. While Keras and TensorFlow offer a variety of pre-defined loss functions, sometimes, you may need to design your own to cater to specific project needs. This blog post will guide you through the process of creating custom loss functions in Keras/TensorFlow.\n\nIn the world of machine learning, loss functions play a pivotal role. They measure the inconsistency between predicted and actual outcomes, guiding the model towards accuracy. While Keras and TensorFlow offer a variety of pre-defined loss functions, sometimes, you may need to design your own to cater to specific project needs. This blog post will guide you through the process of creating custom loss functions in Keras/TensorFlow.\n\nBefore we dive into creating custom loss functions, let’s briefly understand what they are. A loss function, also known as a cost function, quantifies how well your model’s predictions align with the actual data. The objective of any machine learning model is to minimize this loss value.\n\nKeras and TensorFlow provide several built-in loss functions like , , , etc. However, these may not always be suitable for your unique problem sets.\n\nCustom loss functions allow you to incorporate domain knowledge and specific characteristics of your data into your model. They can help improve your model’s performance when standard loss functions fall short.\n\nCreating a custom loss function in Keras/TensorFlow involves defining a new function using TensorFlow operations. This function should take two arguments: the true values ( ) and the model’s predictions ( ).\n\nIn this example, we’ve created a simple custom loss function equivalent to Mean Squared Error. The function computes the mean of elements across dimensions of a tensor, and computes the square of its input.\n\nOnce you’ve defined your custom loss function, you can use it in your model by passing it as an argument to the method.\n\nLet’s create a more complex custom loss function. Suppose we want to penalize false negatives more than false positives in a binary classification problem. We can create a custom loss function to reflect this.\n\nIn this example, we’ve used the function to apply different weights to the loss depending on whether the prediction is a false positive or a false negative.\n\nDescription: The shapes of and do not align, causing a shape mismatch error.\n\nSolution: Ensure that the shapes of and match, and consider using functions like or to obtain scalar values.\n\nDescription: The loss function involves undefined tensors or operations, leading to runtime errors.\n\nSolution: Explicitly handle edge cases and ensure that all tensors used in the loss computation are well-defined. Consider using functions like to handle conditionals.\n\nDescription: The loss function results in vanishing or exploding gradients during training.\n\nSolution: Normalize the gradients by using techniques like gradient clipping or choosing appropriate activation functions to prevent extreme values.\n\nCreating custom loss functions in Keras/TensorFlow can be a powerful tool to improve your model’s performance. It allows you to incorporate domain-specific knowledge and cater to the unique characteristics of your data. Remember, the key to a good loss function is that it should be differentiable and should accurately represent the cost associated with an incorrect prediction.\n\nSaturn Cloud is your all-in-one solution for data science & ML development, deployment, and data pipelines in the cloud. Spin up a notebook with 4TB of RAM, add a GPU, connect to a distributed cluster of workers, and more. Request a demo today to learn more."
    },
    {
        "link": "https://cnvrg.io/keras-custom-loss-functions",
        "document": ""
    },
    {
        "link": "https://tensorflow.org/api_docs/python/tf/keras/losses",
        "document": "Save and categorize content based on your preferences.\n\nStay organized with collections Save and categorize content based on your preferences.\n\nThis file was autogenerated. Do not edit it by hand, since your modifications would be overwritten.\n\n: Computes the cross-entropy loss between true labels and predicted labels.\n\n: Computes the crossentropy loss between the labels and predictions.\n\n: Computes the Dice loss value between and .\n\n: Computes the logarithm of the hyperbolic cosine of the prediction error.\n\n: Computes the mean of absolute difference between labels and predictions.\n\n: Computes the mean absolute percentage error between & .\n\n: Computes the mean of squares of errors between labels and predictions.\n\n: Computes the mean squared logarithmic error between & .\n\n: Computes the crossentropy loss between the labels and predictions.\n\n: Computes the Tversky loss value between and .\n\n: Computes the mean absolute error between labels and predictions.\n\n: Computes the mean absolute percentage error between & .\n\n: Computes the mean squared error between labels and predictions.\n\n: Computes the mean squared logarithmic error between & .\n\n: Computes the cosine similarity between labels and predictions.\n\n: Computes the Dice loss value between and .\n\n: Logarithm of the hyperbolic cosine of the prediction error.\n\n: Computes the mean absolute error between labels and predictions.\n\n: Computes the mean absolute percentage error between & .\n\n: Computes the mean squared error between labels and predictions.\n\n: Computes the mean squared logarithmic error between & .\n\n: Computes the Poisson loss between y_true and y_pred.\n\n: Computes the Tversky loss value between and ."
    },
    {
        "link": "https://stackoverflow.com/questions/61729000/documentation-for-add-loss-method-of-tf-keras-model",
        "document": "You can find the official documentation of here. Add loss tensor(s), potentially dependent on layer inputs. This method can be used inside a subclassed layer or model's call function, in which case losses should be a Tensor or list of Tensors. There are few example in the documentation to explain the .\n\nYou can find the source code of in tf.keras.layers.Layer. This is the class from which all layers inherit. Click on \"View source on GitHub\" and search for .\n\nYou can find good example using add_loss here and here with explanations.\n\nloss functions in Tensorflow always take two parameters and . Using has no such restriction and allows you to write much more complex losses that depend on many other tensors, but it has the inconvenience of being more dependent on the model, whereas the standard loss functions work with just any model."
    },
    {
        "link": "https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html",
        "document": "The Colormap instance or registered colormap name used to map scalar data to colors. This parameter is ignored if X is RGB(A).\n\nThe normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. By default, a linear scaling is used, mapping the lowest value to 0 and the highest to 1. If given, this can be one of the following:\n• None An instance of or one of its subclasses (see Colormap normalization).\n• None A scale name, i.e. one of \"linear\", \"log\", \"symlog\", \"logit\", etc. For a list of available scales, call . In that case, a suitable subclass is dynamically generated and instantiated. This parameter is ignored if X is RGB(A).\n\nWhen using scalar data and no explicit norm, vmin and vmax define the data range that the colormap covers. By default, the colormap covers the complete value range of the supplied data. It is an error to use vmin/vmax when a norm instance is given (but using a norm name together with vmin/vmax is acceptable). This parameter is ignored if X is RGB(A).\n\nThe aspect ratio of the Axes. This parameter is particularly relevant for images since it determines whether data pixels are square. This parameter is a shortcut for explicitly calling . See there for further details.\n• None 'equal': Ensures an aspect ratio of 1. Pixels will be square (unless pixel sizes are explicitly made non-square in data coordinates using extent).\n• None 'auto': The Axes is kept fixed and the aspect is adjusted so that the data fit in the Axes. In general, this will result in non-square pixels. Normally, None (the default) means to use (default: ). However, if the image uses a transform that does not contain the axes data transform, then None means to not modify the axes aspect at all (in that case, directly call if desired).\n\nThe data X is resampled to the pixel size of the image on the figure canvas, using the interpolation method to either up- or downsample the data. If interpolation is 'none', then for the ps, pdf, and svg backends no down- or upsampling occurs, and the image data is passed to the backend as a native image. Note that different ps, pdf, and svg viewers may display these raw pixels differently. On other backends, 'none' is the same as 'nearest'. If interpolation is the default 'auto', then 'nearest' interpolation is used if the image is upsampled by more than a factor of three (i.e. the number of display pixels is at least three times the size of the data array). If the upsampling rate is smaller than 3, or the image is downsampled, then 'hanning' interpolation is used to act as an anti-aliasing filter, unless the image happens to be upsampled by exactly a factor of two or one. See Interpolations for imshow for an overview of the supported interpolation methods, and Image resampling for a discussion of image antialiasing. Some interpolation methods require an additional radius parameter, which can be set by filterrad. Additionally, the antigrain image resize filter is controlled by the parameter filternorm.\n\nPlace the [0, 0] index of the array in the upper left or lower left corner of the Axes. The convention (the default) 'upper' is typically used for matrices and images. Note that the vertical axis points upward for 'lower' but downward for 'upper'. See the origin and extent in imshow tutorial for examples and a more detailed description.\n\nThe bounding box in data coordinates that the image will fill. These values may be unitful and match the units of the Axes. The image is stretched individually along x and y to fill the box. The default extent is determined by the following conditions. Pixels have unit size in data coordinates. Their centers are on integer coordinates, and their center coordinates range from 0 to columns-1 horizontally and from 0 to rows-1 vertically. Note that the direction of the vertical axis and thus the default values for top and bottom depend on origin:\n• None For the default is .\n• None For the default is . See the origin and extent in imshow tutorial for examples and a more detailed description.\n\nA parameter for the antigrain image resize filter (see the antigrain documentation). If filternorm is set, the filter normalizes integer values and corrects the rounding errors. It doesn't do anything with the source floating point values, it corrects only integers according to the rule of 1.0 which means that any sum of pixel weights must be equal to 1.0. So, the filter function must produce a graph of the proper shape."
    },
    {
        "link": "https://geeksforgeeks.org/matplotlib-pyplot-imshow-in-python",
        "document": "Matplotlib is a library in Python and it is numerical – mathematical extension for NumPy library. Pyplot is a state-based interface to a Matplotlib module which provides a MATLAB-like interface.\n\nThe imshow() function in pyplot module of matplotlib library is used to display data as an image; i.e. on a 2D regular raster.\n\nParameters: This method accept the following parameters that are described below:\n• X: This parameter is the data of the image.\n• cmap : This parameter is a colormap instance or registered colormap name.\n• norm : This parameter is the Normalize instance scales the data values to the canonical colormap range [0, 1] for mapping to colors\n• vmin, vmax : These parameter are optional in nature and they are colorbar range.\n• alpha : This parameter is a intensity of the color.\n• aspect : This parameter is used to controls the aspect ratio of the axes.\n• interpolation : This parameter is the interpolation method which used to display an image.\n• origin : This parameter is used to place the [0, 0] index of the array in the upper left or lower left corner of the axes.\n• resample : This parameter is the method which is used for resembling.\n• extent : This parameter is the bounding box in data coordinates.\n• filternorm : This parameter is used for the antigrain image resize filter.\n• filterrad : This parameter is the filter radius for filters that have a radius parameter.\n• url : This parameter sets the url of the created AxesImage. Returns: This returns the following:\n\nBelow examples illustrate the matplotlib.pyplot.imshow() function in matplotlib.pyplot:"
    },
    {
        "link": "https://matplotlib.org/stable/tutorials/images.html",
        "document": "First, let's start IPython. It is a most excellent enhancement to the standard Python prompt, and it ties in especially well with Matplotlib. Start IPython either directly at a shell, or with the Jupyter Notebook (where IPython as a running kernel). With IPython started, we now need to connect to a GUI event loop. This tells IPython where (and how) to display plots. To connect to a GUI loop, execute the %matplotlib magic at your IPython prompt. There's more detail on exactly what this does at IPython's documentation on GUI event loops. If you're using Jupyter Notebook, the same commands are available, but people commonly use a specific argument to the %matplotlib magic: This turns on inline plotting, where plot graphics will appear in your notebook. This has important implications for interactivity. For inline plotting, commands in cells below the cell that outputs a plot will not affect the plot. For example, changing the colormap is not possible from cells below the cell that creates a plot. However, for other backends, such as Qt, that open a separate window, cells below those that create the plot will change the plot - it is a live object in memory. This tutorial will use Matplotlib's implicit plotting interface, pyplot. This interface maintains global state, and is very useful for quickly and easily experimenting with various plot settings. The alternative is the explicit, which is more suitable for large application development. For an explanation of the tradeoffs between the implicit and explicit interfaces see Matplotlib Application Interfaces (APIs) and the Quick start guide to start using the explicit interface. For now, let's get on with the implicit approach:\n\nMatplotlib relies on the Pillow library to load image data. Here's the image we're going to play with: It's a 24-bit RGB PNG image (8 bits for each of R, G, B). Depending on where you get your data, the other kinds of image that you'll most likely encounter are RGBA images, which allow for transparency, or single-channel grayscale (luminosity) images. Download stinkbug.png to your computer for the rest of this tutorial. We use Pillow to open an image (with ), and immediately convert the object into an 8-bit ( ) numpy array. Each inner list represents a pixel. Here, with an RGB image, there are 3 values. Since it's a black and white image, R, G, and B are all similar. An RGBA (where A is alpha, or transparency) has 4 values per inner list, and a simple luminance image just has one value (and is thus only a 2-D array, not a 3-D array). For RGB and RGBA images, Matplotlib supports float32 and uint8 data types. For grayscale, Matplotlib supports only float32. If your array data does not meet one of these descriptions, you need to rescale it."
    },
    {
        "link": "https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.imshow.html",
        "document": "The Colormap instance or registered colormap name used to map scalar data to colors. This parameter is ignored if X is RGB(A).\n\nThe normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. By default, a linear scaling is used, mapping the lowest value to 0 and the highest to 1. If given, this can be one of the following:\n• None An instance of or one of its subclasses (see Colormap normalization).\n• None A scale name, i.e. one of \"linear\", \"log\", \"symlog\", \"logit\", etc. For a list of available scales, call . In that case, a suitable subclass is dynamically generated and instantiated. This parameter is ignored if X is RGB(A).\n\nWhen using scalar data and no explicit norm, vmin and vmax define the data range that the colormap covers. By default, the colormap covers the complete value range of the supplied data. It is an error to use vmin/vmax when a norm instance is given (but using a norm name together with vmin/vmax is acceptable). This parameter is ignored if X is RGB(A).\n\nThe aspect ratio of the Axes. This parameter is particularly relevant for images since it determines whether data pixels are square. This parameter is a shortcut for explicitly calling . See there for further details.\n• None 'equal': Ensures an aspect ratio of 1. Pixels will be square (unless pixel sizes are explicitly made non-square in data coordinates using extent).\n• None 'auto': The Axes is kept fixed and the aspect is adjusted so that the data fit in the Axes. In general, this will result in non-square pixels. Normally, None (the default) means to use (default: ). However, if the image uses a transform that does not contain the axes data transform, then None means to not modify the axes aspect at all (in that case, directly call if desired).\n\nThe data X is resampled to the pixel size of the image on the figure canvas, using the interpolation method to either up- or downsample the data. If interpolation is 'none', then for the ps, pdf, and svg backends no down- or upsampling occurs, and the image data is passed to the backend as a native image. Note that different ps, pdf, and svg viewers may display these raw pixels differently. On other backends, 'none' is the same as 'nearest'. If interpolation is the default 'auto', then 'nearest' interpolation is used if the image is upsampled by more than a factor of three (i.e. the number of display pixels is at least three times the size of the data array). If the upsampling rate is smaller than 3, or the image is downsampled, then 'hanning' interpolation is used to act as an anti-aliasing filter, unless the image happens to be upsampled by exactly a factor of two or one. See Interpolations for imshow for an overview of the supported interpolation methods, and Image resampling for a discussion of image antialiasing. Some interpolation methods require an additional radius parameter, which can be set by filterrad. Additionally, the antigrain image resize filter is controlled by the parameter filternorm.\n\nPlace the [0, 0] index of the array in the upper left or lower left corner of the Axes. The convention (the default) 'upper' is typically used for matrices and images. Note that the vertical axis points upward for 'lower' but downward for 'upper'. See the origin and extent in imshow tutorial for examples and a more detailed description.\n\nThe bounding box in data coordinates that the image will fill. These values may be unitful and match the units of the Axes. The image is stretched individually along x and y to fill the box. The default extent is determined by the following conditions. Pixels have unit size in data coordinates. Their centers are on integer coordinates, and their center coordinates range from 0 to columns-1 horizontally and from 0 to rows-1 vertically. Note that the direction of the vertical axis and thus the default values for top and bottom depend on origin:\n• None For the default is .\n• None For the default is . See the origin and extent in imshow tutorial for examples and a more detailed description.\n\nA parameter for the antigrain image resize filter (see the antigrain documentation). If filternorm is set, the filter normalizes integer values and corrects the rounding errors. It doesn't do anything with the source floating point values, it corrects only integers according to the rule of 1.0 which means that any sum of pixel weights must be equal to 1.0. So, the filter function must produce a graph of the proper shape."
    },
    {
        "link": "https://mpl-interactions.readthedocs.io/en/stable/examples/imshow.html",
        "document": "is great for seeing how a 2D function will respond to parameters, or for tasks like thresholding an image. If you want to look at a slices of a precomputed array you should consider using hyperslicer, which was created for exactly that purpose.\n\nYou can also embed the interactive plot into an existing figure\n\nThe if you do not specify vmin/vmax and your function does not return an RGB(A) image then the default behavior is to rescale the colormap for each parameter change. This can disabled using this argument.\n\nHere we use the argument along with the syntax for a RangeSlider to easily threshold the image. For more on how to use RangeSliders see their example page. Additionally you do not need to use a function to provide the image, you can also provide an array"
    }
]