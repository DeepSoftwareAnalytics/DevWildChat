[
    {
        "link": "https://blog.logrocket.com/async-await-typescript",
        "document": "Editor’s note: This article was last reviewed and updated by Ikeh Akinyemi in January 2025 to introduce advanced techniques for working with , such as handling multiple async operations concurrently using and managing async iterations with , as well as how to apply async/await within higher-order functions.\n\nAsynchronous programming is a way of writing code that can carry out tasks independently of each other, not needing one task to be completed before another gets started. When you think of asynchronous programming, think of multitasking and effective time management.\n\nIf you’re reading this, you probably have some familiarity with asynchronous programming in JavaScript, and you may be wondering how it works in TypeScript. That’s what we’ll explore in this guide.\n\nBefore diving into , it’s important to mention that promises form the foundation of asynchronous programming in JavaScript/TypeScript. A promise represents a value that might not be immediately available but will be resolved at some point in the future. A promise can be in one of the following three states:\n\nHere’s how to create and work with promises in TypeScript:\n\nPromises can be chained using for successful operations and for error handling:\n\nWe’ll revisit the concept of promises later, where we’ll discuss how to possibly execute asynchronous operations in parallel.\n\nTypeScript is a superset of JavaScript, so works the same, but with some extra goodies and type safety. TypeScript enables you to ensure type safety for the expected result and even check for type errors, which helps you detect bugs earlier in the development process.\n\nis essentially a syntactic sugar for promises, which is to say that the keyword is a wrapper over promises. An function always returns a promise. Even if you omit the keyword, the compiler will wrap your function in an immediately resolved promise.\n\nAlthough they look different, the code snippets above are more or less equivalent.\n\nsimply enables you to write the code more synchronously and unwraps the promise within the same line of code for you. This is powerful when you’re dealing with complex asynchronous patterns.\n\nTo get the most out of the syntax, you’ll need a basic understanding of promises.\n\nAs explained earlier, a promise refers to the expectation that something will happen at a particular time, enabling your app to use the result of that future event to perform certain other tasks.\n\nTo demonstrate what I mean, I’ll break down a real-world example and translate it into pseudocode, followed by the actual TypeScript code.\n\nLet’s say I have a lawn to mow. I contact a mowing company that promises to mow my lawn in a couple of hours. In turn, I promise to pay them immediately afterward, provided the lawn is properly mowed.\n\nCan you spot the pattern? The first obvious thing to note is that the second event relies entirely on the previous one. If the first event’s promise is fulfilled, the next event’s will be executed. The promise in that event is then either fulfilled, rejected, or remains pending.\n\nLet’s look at this sequence step by step and then explore its code:\n\nBefore we write out the full code, it makes sense to examine the syntax for a promise — specifically, an example of a promise that resolves into a string.\n\nWe declared a with the keyword, which takes in the and arguments. Now let’s write a promise for the flow chart above:\n\nIn the code above, we declared both the company’s promises and our promises. The company promise is either resolved after 100,000ms or rejected. A is always in one of three states: if there is no error, if an error is encountered, or if the has been neither rejected nor fulfilled. In our case, it falls within the period.\n\nBut how can we execute the task sequentially and synchronously? That’s where the keyword comes in. Without it, the functions simply run in the order they resolve.\n\nChaining promises allows them to run in sequence using the keyword. This functions like a normal human language — do this and then that and then that, and so on.\n\nThe code below will run the . If there is no error, it’ll run the . If there is an error in either of the two promises, it’ll be caught in the block:\n\nNow let’s look at a more technical example. A common task in frontend programming is to make network requests and respond to the results accordingly.\n\nBelow is a request to fetch a list of employees from a remote server:\n\nThere may be times when you need numerous promises to execute in parallel or sequence. Constructs such as or are especially helpful in these scenarios.\n\nFor example, imagine that you need to fetch a list of 1,000 GitHub users, and then make an additional request with the ID to fetch avatars for each of them. You don’t necessarily want to wait for each user in the sequence; you just need all the fetched avatars. We’ll examine this in more detail later when we discuss .\n\nNow that you have a fundamental grasp of promises, let’s look at the syntax.\n\nThe syntax simplifies working with promises in JavaScript. It provides an easy interface to read and write promises in a way that makes them appear synchronous.\n\nAn will always return a . Even if you omit the keyword, the compiler will wrap the function in an immediately resolved . This enables you to treat the return value of an function as a , which is useful when you need to resolve numerous asynchronous functions.\n\nAs the name implies, always goes hand in hand with . That is, you can only inside an function. The function informs the compiler that this is an asynchronous function.\n\nIf we convert the promises from above, the syntax looks like this:\n\nAs you can immediately see, this looks more readable and appears synchronous. We told the compiler to await the execution of before doing anything else. Then, we return the response from the .\n\nYou may have noticed that we omitted error handling. We could do this with the block after the in a promise. But what happens if we encounter an error? That leads us to .\n\nWe’ll refer to the employee fetching example to see the error handling in action, as it is likely to encounter an error over a network request.\n\nLet’s say, for example, that the server is down, or perhaps we sent a malformed request. We need to pause execution to prevent our program from crashing. The syntax will look like this:\n\nWe initiated the function as an function. We expect the return value to be either an array of employees or a string of error messages. Therefore, the type of promise is .\n\nInside the block are the expressions we expect the function to run if there are no errors. Meanwhile, the block captures any errors that arise. In that case, we’d just return the property of the object.\n\nThe beauty of this is that any error that first occurs within the block is thrown and caught in the block. An uncaught exception can lead to hard-to-debug code or even break the entire program.\n\nWhile traditional blocks are effective for catching errors at the local level, they can become repetitive and clutter the main business logic when used too frequently. This is where higher-order functions come into play.\n\nA higher-order function is a function that takes one or more functions as arguments or returns a function. In the context of error handling, a higher-order function can wrap an asynchronous function and handle any errors it might throw, thereby abstracting the logic away from the core business logic.\n\nThe main idea behind using higher-order functions for error handling in is to create a wrapper function that takes an async function as an argument along with any parameters that the async function might need. Inside this wrapper, we implement a block. This approach allows us to handle errors in a centralized manner, making the code cleaner and more maintainable.\n\nLet’s refer to the employee fetching example:\n\nIn this example, the function uses the higher-order function to wrap the original function.\n\nThis setup automatically handles any errors that might occur during the API call, logging them and returning to indicate an error state. The consumer of can then check if the returned value is to determine if the operation was successful or if an error occurred.\n\nAs mentioned earlier, there are times when we need promises to execute in parallel.\n\nLet’s look at an example from our employee API. Say we first need to fetch all employees, then fetch their names, and then generate an email from the names. Obviously, we’ll need to execute the functions in a synchronous manner and also in parallel so that one doesn’t block the other.\n\nIn this case, we would make use of . According to Mozilla, “ is typically used after having started multiple asynchronous tasks to run concurrently and having created promises for their results so that one can wait for all the tasks being finished.”\n\nIn pseudocode, we’d have something like this:\n• Wait for all user data. Extract the from each user. Fetch each user =>\n• Generate an email for each user from their username\n\nIn the above code, fetches all the employees from the . We the response, convert it to , and then return the converted data.\n\nThe most important concept to keep in mind is how we sequentially executed the code line by line inside the function with the keyword. We’d get an error if we tried to convert data to JSON that has not been fully awaited. The same concept applies to , except that we’d only fetch a single employee. The more interesting part is the , where we run all the async functions concurrently.\n\nFirst, wrap all the methods within inside a block. Next, the result of fetching all the employees. We need the of each employee to fetch their respective data, but what we ultimately need is information about the employees.\n\nThis is where we can call upon to handle all the concurrently. Each is executed concurrently for all the employees. The awaited data from the employees’ information is then used to generate an email for each employee with the function.\n\nIn the case of an error, it propagates as usual, from the failed promise to , and then becomes an exception we can catch inside the block.\n\nis great when we need all promises to succeed, but real-world applications often need to handle situations where some operations might fail while others succeed. Let’s consider our employee management system: What if we need to update multiple employee records, but some updates might fail due to validation errors or network issues?\n\nThis is where comes in handy. Unlike , which fails completely if any promise fails, will wait for all promises to complete, regardless of whether they succeed or fail. It gives us information about both successful and failed operations.\n\nThink of like a project manager tracking multiple tasks. Instead of stopping everything when one task fails (like would), the manager continues monitoring all tasks and provides a complete report of what succeeded and what failed. This is particularly useful when you need to:\n• Generate reports even if some data fetching fails\n\nSometimes we need to process large amounts of data that come in chunks or pages. Imagine you’re exporting employee data from a large enterprise system – there might be thousands of records that come in batches to prevent memory overload.\n\nThe loop is perfect for this scenario. It allows us to process asynchronous data streams one item at a time, making our code both efficient and readable. Here’s how we can use it with our employee system:\n\nThink of like a conveyor belt in a factory. Instead of waiting for all products (data) to be manufactured before starting to pack them (process them), we can pack each product as it comes off the belt. This approach has several benefits:\n• Memory efficient: We process one employee at a time instead of loading all data at once\n• Real-time processing: We can start working with data as soon as it’s available\n• Progress tracking: We can easily monitor and report progress as we process each item\n\nWhen working with our employee management system, we often need to process arrays of data asynchronously. Let’s see how we can effectively use array methods with :\n\nWhen working with these array methods, there are some important considerations:\n• with async operations returns an array of promises that need to be handled with\n• requires special handling because we can’t directly use the promise result as a filter condition\n• with async operations needs careful promise handling for the accumulator\n\nThere are use cases where utility functions are needed to carry out some operations on responses returned from asynchronous calls. We can create reusable higher-order functions that wrap async operations with these additional functionalities:\n\nIn this above snippet, the higher-order function adds caching capability to any async function that fetches data by ID. If the same ID is requested multiple times within five seconds (the default TTL), the function returns the cached result instead of making another API call. This significantly reduces unnecessary network requests when the same employee data is needed multiple times in quick succession.\n\nis a utility type that models operations like in functions. It unwraps the resolved value of a promise, discarding the promise itself, and works recursively, thereby removing any nested promise layers.\n\nis the type of value that you expect to get after awaiting a promise. It helps your code understand that once you use , you’re not dealing with a promise anymore, but with the actual data you wanted.\n\nThe type does not exactly model the method in promises, however can be relevant when using in functions. If you use inside a callback, helps infer the type of the awaited value, avoiding the need for additional type annotations.\n\ncan help clarify the type of and in functions, even when using for promise chaining. However, it doesn’t replace the functionality of itself.\n\nand enable us to write asynchronous code in a way that looks and behaves like synchronous code. This makes the code much easier to read, write, and understand.\n\nHere are some key concepts to keep in mind as you’re working on your next asynchronous project in TypeScript:\n• The function marked with the keyword always returns a\n• If the return value inside doesn’t return a , it will be wrapped in an immediately resolved\n• Execution is paused when an keyword is encountered until a is completed\n• will either return a result from a fulfilled or throw an exception from a rejected"
    },
    {
        "link": "https://freecodecamp.org/news/learn-async-programming-in-typescript-promises-asyncawait-and-callbacks",
        "document": "Async programming is a programming paradigm that allows you to write code that runs . In contrast to synchronous programming, which executes code sequentially, async programming allows code to run in the background while the rest of the program continues to execute. This is particularly useful for tasks that may take a long time to complete, such as fetching data from a remote API.\n\nis essential for creating responsive and efficient applications in JavaScript. TypeScript, a superset of JavaScript, makes it even easier to work with async programming.\n\nThere are several approaches to in TypeScript, including using , , and . We will cover each of these approaches in detail so that you can choose the best one(s) for your use case.\n• None How to Use Promises in TypeScript\n• None How to Use Async / Await in TypeScript\n• None How to Use Callbacks in TypeScript\n\nAsync programming is crucial for building responsive and efficient web applications. It allows tasks to run in the background while the rest of the program continues, keeping the user interface responsive to input. Also, async programming can boost overall performance by letting multiple tasks run at the same time.\n\nThere are many real-world examples of async programming, such as accessing user cameras and microphones and handling user input events. Even if you don't frequently create asynchronous functions, it's important to know how to use them correctly to make sure your application is reliable and performs well.\n\nTypeScript offers several features that simplify async programming, including , , , and .\n\nWith type safety, you can ensure your code behaves as expected, even when dealing with asynchronous functions. For instance, TypeScript can catch errors related to null and undefined values at compile time, saving you time and effort in debugging.\n\nTypeScript's type inference and checking also reduce the amount of boilerplate code you need to write, making your code more concise and easier to read.\n\nAnd TypeScript's type annotations provide clarity and documentation for your code, which is especially helpful when working with asynchronous functions that can be complex to understand.\n\nNow let’s dive in and learn about these three key features of asynchronous programming: promises, async/await, and callbacks.\n\nHow to Use Promises in TypeScript\n\nPromises are a powerful tool for handling asynchronous operations in TypeScript. For instance, you might use a promise to fetch data from an external API or to perform a time-consuming task in the background while your main thread keeps running.\n\nTo use a Promise, you create a new instance of the class and pass it a function that carries out the asynchronous operation. This function should call the resolve method with the result when the operation succeeds or the reject method with an error if it fails.\n\nOnce the Promise is created, you can attach callbacks to it using the method. These callbacks will be triggered when the Promise is fulfilled, with the resolved value passed as a parameter. If the Promise is rejected, you can attach an error handler using the catch method, which will be called with the reason for the rejection.\n\nUsing Promises offers several advantages over traditional callback-based methods. For example, Promises can help prevent \"callback hell,\" a common issue in asynchronous code where nested callbacks become hard to read and maintain.\n\nPromises also make error handling in asynchronous code easier, as you can use the catch method to manage errors that occur anywhere in the Promise chain.\n\nFinally, Promises can simplify your code by providing a consistent, composable way to handle asynchronous operations, regardless of their underlying implementation.\n\nIn the example above, we have a function called that returns a . We use the constructor to create the promise, which takes a with and arguments. If the asynchronous operation is successful, we call the resolve function. If it fails, we call the reject function.\n\nThe promise object returned by the constructor has a method, which takes success and failure callback functions. If the promise resolves successfully, the success callback function is called with the result. If the promise is rejected, the failure callback function is called with an error message.\n\nThe promise object also has a method used to handle errors that occur during the promise chain. The method takes a callback function, which is called if any error occurs in the promise chain.\n\nNow, let's move on to how to chain promises in TypeScript.\n\nChaining promises allows you to perform in sequence or in parallel. This is helpful when you need to carry out several async tasks one after another or at the same time. For instance, you might need to fetch data asynchronously and then process it asynchronously.\n\nLet's look at an example of how to chain promises:\n\nIn the example above, we have two promises: and . resolves after 1 second with the string \"This is the first promise function.\" takes a number as input and returns a promise that resolves after 1 second with a string that combines the input number and the string \"This is the second promise function.\"\n\nWe chain the two promises together using the method. The output is passed as input to . Finally, we use the method again to log the output of to the console. If either or rejects, the error will be caught by the method.\n\nCongratulations! You have learned how to create and chain promises in TypeScript. You can now use promises to perform asynchronous operations in TypeScript. Now, let's explore how works in TypeScript.\n\nHow to Use Async / Await in TypeScript\n\nAsync/await is a syntax introduced in ES2017 to make working with Promises easier. It allows you to write asynchronous code that looks and feels like synchronous code.\n\nIn TypeScript, you can define an asynchronous function using the keyword. This tells the compiler that the function is asynchronous and will return a Promise.\n\nNow, let's see how to use async/await in TypeScript.\n\nIn the example above, is an async function that returns a Promise of . The the keyword is used to wait for the promise to resolve before moving to the next line of code.\n\nThe block is used to handle any errors that occur while running the code inside the async function. If an error happens, it will be caught by the catch block, where you can handle it appropriately.\n\nYou can also use arrow functions with async/await syntax in TypeScript:\n\nIn the example above, is defined as an arrow function that returns a Promise of . The async keyword indicates that this is an asynchronous function, and the await keyword is used to wait for the promise to resolve before moving to the next line of code.\n\nNow, let's go beyond the syntax and fetch some data from an API using async/await.\n\nHere, we’re fetching data from the JSONPlaceholder API, converting it to JSON, and then logging it to the console. This is a real-world example of how to use async/await in TypeScript.\n\nYou should see user information in the console. This image shows the output:\n\nIn the example above, we define the function using async/await and the method to make an HTTP GET request to the specified URL. We use await to wait for the response, then extract the data using the data property of the response object. Finally, we log the data to the console with . Any errors that occur are caught and logged to the console with .\n\nWe can achieve this using Axios, so you should see the same result in the console.\n\nThis image shows the output when using Axios in the console:\n\nNote: Before you try the code above, you need to install Axios using npm or yarn.\n\nIf you're not familiar with Axios, you can learn more about it here.\n\nYou can see that we used a and block to handle errors. The and block is a method for managing errors in TypeScript. So, whenever you make API calls like we just did, make sure you use a and block to handle any errors.\n\nNow, let's explore a more advanced use of the and block in TypeScript:\n\nIn the example above, we define an that outlines the structure of the data we expect from the API. We then create the function using async/await and the fetch() method to make an HTTP GET request to the specified API endpoint.\n\nWe use a block to handle any errors that might occur during the API request. If the request is successful, we extract the data property from the response using await and return it. If an error occurs, we check for an error message and return it as a string if it exists.\n\nFinally, we call the function and use to log the returned data to the console. This example demonstrates how to use with blocks to handle errors in a more advanced scenario, where we need to extract data from a response object and return a custom error message.\n\nThis image shows the output result of the code:\n\nis a method that takes an array of promises as input (an iterable) and returns a single Promise as output. This Promise resolves when all the input promises have been resolved or if the input iterable contains no promises. It rejects immediately if any of the input promises are rejected or if non-promises throw an error, and it will reject with the first rejection message or error.\n\nIn the code above, we used to fetch multiple APIs at the same time. If you have several APIs to fetch, you can use to get them all at once. As you can see, we used to loop through the array of APIs and then pass it to to fetch them simultaneously.\n\nThe image below shows the output from the API calls:\n\nLet's see how to use with Axios:\n\nIn the example above, we're using to fetch data from two different URLs at the same time. First, we create an array of URLs, then use the map to create an array of Promises from the calls. We pass this array to , which returns an array of responses. Finally, we use the map again to get the data from each response and log it to the console.\n\nHow to Use Callbacks in TypeScript\n\nA callback is a function passed as an argument to another function. The callback function is executed inside the other function. Callbacks ensure that a function doesn't run before a task is completed – but that it then runs right after the task finishes. They help us write asynchronous JavaScript code and prevent problems and errors.\n\nThe image below shows the callback function:\n\nLet's see another example of using callbacks in TypeScript:\n\nIn the example above, we have a function called that takes an and a as parameters. This is a function with two parameters: an error and a user.\n\nThe function retrieves user data from a JSONPlaceholder API endpoint using the . If the fetch is successful, it creates an object and passes it to the callback function with a null error. If there's an error during the fetch, it sends the error to the callback function with a null user.\n\nTo use the function with a callback, we provide an and a callback function as arguments. The callback function checks for errors and logs the user data if there are no errors.\n\nThe image below shows the output of the API calls:\n\nHow to Use Callbacks Responsibly\n\nWhile callbacks are fundamental to asynchronous programming in TypeScript, they require careful management to avoid \"callback hell\" – the pyramid-shaped, deeply nested code that becomes hard to read and maintain. Here's how to use callbacks effectively:\n• \n• None Flatten your code structure by breaking complex operations into named functions\n• None Use promises or async/await for complex async workflows (more on this below)\n• \n• None Always follow the Node.js convention of parameters\n• None Check for errors at every level of nested callbacks\n• None Consider control flow libraries\n\n For complex async operations, use utilities like for:\n\nWhen to Use Callbacks vs. Alternatives\n\nThere are times when callbacks are a great choice, and other times when they’re not.\n\nCallbacks are helpful when you’re working with async operations (single completion), interfacing with older libraries or APIs that expect callbacks, handling event listeners (like click listeners or websocket events) or creating lightweight utilities with simple async needs.\n\nIn other scenarios where you need to focus on writing maintainable code with a clear async flow, callbacks cause trouble and you should prefer promises or async-await. For example, when you need to chain multiple operations, handle complex error propagation, work with modern APIs (like the Fetch API or FS Promises), or use for parallel execution.\n\nExample migration from callbacks to promises:\n\nModern TypeScript projects often use a mix: callbacks for event-driven patterns and promises/async-await for complex async logic. The key is choosing the right tool for your specific use case while maintaining code clarity.\n\nIn this article, we have learned about the different ways to handle asynchronous code in TypeScript. We have learned about callbacks, promises, async/await, and how to use them in TypeScript. We have also learned about this concept.\n\nIf you want to learn more about programming and how to become a better software engineer, you can subscribe to my YouTube channel CliffTech.\n\nThank you for reading my article. I hope you enjoyed it. If you have any questions, feel free to reach out to me.\n\nConnect with me on social media:"
    },
    {
        "link": "https://stackoverflow.com/questions/63163441/async-await-control-flow-in-javascript-typescript-in-node-js",
        "document": "So, the control flow to another operation is not when is called. It's when the running piece of Javascript returns back to the event loop and the event loop can then service the next waiting event. Resolved promises work via the event loop too (a special queue, but still in the event loop).\n\nSo, when you hit in an function, that doesn't immediately jump control somewhere else. It executes the expression that follows the and gets the returned promise from that and then suspends further execution of that function and then causes the function to immediately return a promise and control continues with a promise being returned to the caller of the function. The caller's code continues to execute after receiving that promise. Only when the caller or the caller of the caller or the caller of the caller of the caller (depending upon how deep the call stack is) returns back to the event loop from whatever event started this whole chain of execution does the event loop get a chance to serve the next event and start a new chain of execution.\n\nSome time later when the underlying asynchronous operation connected to that original finishes it will insert an event into the event queue. When other Javascript execution returns control back to the event loop and this event gets to the start of the event queue, it will get executed and will resolve the promise that the was waiting for. Only then does the code within the function after the get a chance to run. When that function that contained the finally finishes it's internal execution, then the promise that was originally returned from the function when that first was hit will resolve and the caller will be notified that the promise it got back has been resolved (assuming it used either or on that promise).\n\nSo, there's no jumping of flow from one place to another. The current thread of Javascript execution returns control back to the event loop (by returning and unwinding its call stack) and the event loop can then serves the next waiting event and start a new chain of execution. Only when that chain of execution finishes and returns can the event loop go get the next event and start another chain of execution. In this way, there's just the one call stack frame going at a time.\n\nIn your code, I don't quite follow what you're concerned about. There is no pre-emptive switching in Javascript. If your function does an , then its execution will be suspended at that point (after executing the statement following the and other code can run before the promise gets resolved and it continues execution after the statement including the . But, there's no pre-emptive switching that could change the context and run other code in this thread without your code calling some asynchronous operation and then continuing in the complete callback or after the .\n\nSo, from a pure Javascript point of view, there's no worry between pure local Javascript statements that don't involve asynchronous operations. Those are guaranteed to be sequential and uninterrupted (we're assuming there's none of your code involved that uses shared memory and worker threads - which there is no sign of in the code you posted).\n\nIt ensures that there is no jump of the control flow position at any time except when you return back the event loop (unwind the call stack). It does not occur at . may lead to your function returning and may lead to the caller then returning back to the event loop while it waits for the returned promise to resolve, but it's important to understand that the control flow change only happens when the stack unwinds and returns control back to the event loop so the next event can be pulled from the event queue and processed.\n\nAssuming we're not talking about Worker Threads, there is no pre-emptive Javascript thread switching in nodejs. Execution to another piece of Javascript changes only when the current thread of Javascript returns back to the event loop.\n\nNo, you do not need a mutex for that. There is no return back to the event loop between the test and set so they are guaranteed to be not interrupted by any other code."
    },
    {
        "link": "https://metered.ca/blog/async-await-in-typescript-a-step-by-step-guide",
        "document": "Async/Await is built on top promises, these offer a more readable and concise way for working with asynchronous operations\n\nPromises represents a future value that can be rejected or resolved, serving as placeholders for the result of async operations\n\nAsync/Await simplifies working with promises by providing the synthetic sugar, thus making it easier to work with promises\n\nWe can compare promises with traditional callback patterns to better understand the differences\n• Callback Patterns: A callback is a function that is passed to another function as an argument. This function is then called by the outer function to perform some kind of operation or a routine action.\n\nIf you have a lot of callbacks, this could lead to a lot of deeply nested code which is hard to read or maintain and debug. This is often reffered to as \"callback hell\"\n• Promises: Promises were introduced in order to solve the callback hell problem.\n\nA promise is a JavaScript Object that represents a temporary or an intermediate state in an asynchronous operation. (A promise that is yet to be fulfilled)\n\nSo, it is basically a placeholder for the result of an asynchronous operation. Promises allow chaining of operations and have dedicated functions for handing of success (`then`) and failures (`catch`) thus improving readability and error handling.\n\nThe Async/Await improves promises by providing a synthetic sugar over promises and makes it easier to write.\n\nDevelopers can write the code that feels and appears synchronous but operates asynchronously and avoid the nested chaining of callback methods.\n• Best Practices for Using Async/Await with Native Promises\n• Async Keyword: The keyword returns a promise. When you declare a function, basically write async before the function declaration, then it wraps the function in a promise\n\nIf the function throws an error then the promise will be rejected with that error\n• Await Keyword: Within the async function you can use the keyword to pause the execution of the function untill the Promise is resolved.\n\nThe keyword basically waits for the promise to be resolved and then returns the result of the promoise, which could either be success or failure.\n\nExample with promise without async/await\n\nSame Example with async/await\n\nIn the above example as you can see the async/await code is easy to understand. The await keyword pauses the execution of the function until the promise is resolved\n\nWe also have the try catch block in order to catch any errors, that could be occurring during the fetch operation.\n\nError handling is an important aspect of writing code especially when dealing with asynchronous operations.\n\nHere are some of the techniques with which you can handle error in typescript\n• Try/Catch Blocks: The most easy and common method of catching errors is the try/catch block. Whenever the async operation throws an error, the await function that is waiting for the fulfillment of the promise will throw the rejected values. You can wrap the await expression in a try/catch block and you can handle these errors gracefully.\n• Error Propagation: You can have flexibility on where you handle the error. This is because the async errors are propagated to the caller if they are not caught inside the function. So, you can handle the error outside the function if that is what you wish.\n• Finally Block: You can also have a finally block, this is similar to synchronous code. the finally block executes some code regardless of the out code of the async/await.\n\nExample 2: Propogating error to a higher level and then catching them\n\nWith Async/Await you have to option to opt for sequential or parrallel execution. This option can be good for optimizing the performance or benefiting from resource utilization\n\nStrategies for managing the execution flow wither Parallel or Sequential\n• Sequential execution: When you use the keyword in a loop or use multiple keywords one after the another the code executes in a sequential order.\n\nThis is because the await keywords waits for the fulfillment of the promise before moving forward.\n\nHence, each operation will only start when the previous one has completed. This is important when the execution of one operation depends on the result of the previous one.\n• Parallel Execution: You can also run all the async operations in parallel as well and then wait for all of them to complete using the\n\nThis is a good idea when all the async operations are independent of each other\n\nLet us consider some example of each of these\n\nWe are using the to wait for all the fetch operations to complete in parallel. This is more efficient approach if your Async operations are not dependent on one another.\n\nBest Practices for Using Async/Await with Native Promises\n• Use async/await for Most Async Code\n\nExample of how to convert the Promise based code to Async/Await\n• Avoiding unnecessary await: Using await unnecessarily can lead to performance bottlenecks. Whenever possible consider using\n• Using for parallel execution whenever feasible\n• Cache the results of async operations: Because async operations take time, this be because they need to acquire data from a server etc. Consider caching data which does not change much\n\nIn this example we are going to improve the API response time. Consider an app where the app needs to fetch data from time to time and from multiple endpoints before rendering data.\n\nThis fetching is implemented sequentially which leads to longer load times\n\nAsync generators and async iternations allow you to handle streams of data asynchronously. This helps you work with large datasets and streaming data.\n\nAsync Generators are functions that return values asynchronously, these functions return something called as an Asynciterator, which produces an stream of promises\n\nlets see an example for Async Generator for Paginated Data\n\nWith async iteration, you can use the loop to iterate over the async iteratable objects that are produced by the async generator\n\nexample of consuming the Paginated data\n• API: TURN server management with powerful API. You can do things like Add/ Remove credentials via the API, Retrieve Per User / Credentials and User metrics via the API, Enable/ Disable credentials via the API, Retrive Usage data by date via the API.\n• Global Geo-Location targeting: Automatically directs traffic to the nearest servers, for lowest possible latency and highest quality performance. less than 50 ms latency anywhere around the world\n• Servers in 12 Regions of the world: Toronto, Miami, San Francisco, Amsterdam, London, Frankfurt, Bangalore, Singapore,Sydney, Seoul\n• Low Latency: less than 50 ms latency, anywhere across the world.\n• Cost-Effective: pay-as-you-go pricing with bandwidth and volume discounts available.\n• Easy Administration: Get usage logs, emails when accounts reach threshold limits, billing records and email and phone support.\n• Standards Compliant: Conforms to RFCs 5389, 5769, 5780, 5766, 6062, 6156, 5245, 5768, 6336, 6544, 5928 over UDP, TCP, TLS, and DTLS.\n• Multi‑Tenancy: Create multiple credentials and separate the usage by customer, or different apps. Get Usage logs, billing records and threshold alerts.\n• Enterprise Scale: With no limit on concurrent traffic or total traffic. Metered TURN Servers provide Enterprise Scalability\n• 5 GB/mo Free: Get 5 GB every month free TURN server usage with the Free Plan\n• Support TURNS + SSL to allow connections through deep packet inspection firewalls.\n\nNeed Chat API for your website or app\n• Add Scalable Chat to your app in minutes"
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function",
        "document": "An declaration creates an object. Each time when an async function is called, it returns a new which will be resolved with the value returned by the async function, or rejected with an exception uncaught within the async function.\n\nAsync functions can contain zero or more expressions. Await expressions make promise-returning functions behave as though they're synchronous by suspending execution until the returned promise is fulfilled or rejected. The resolved value of the promise is treated as the return value of the await expression. Use of and enables the use of ordinary / blocks around asynchronous code.\n\nNote: The keyword is only valid inside async functions within regular JavaScript code. If you use it outside of an async function's body, you will get a . can be used on its own with JavaScript modules.\n\nAsync functions always return a promise. If the return value of an async function is not explicitly a promise, it will be implicitly wrapped in a promise.\n\nFor example, consider the following code:\n\nIt is similar to:\n\nNote that even though the return value of an async function behaves as if it's wrapped in a , they are not equivalent. An async function will return a different reference, whereas returns the same reference if the given value is a promise. It can be a problem when you want to check the equality of a promise and a return value of an async function.\n\nThe body of an async function can be thought of as being split by zero or more await expressions. Top-level code, up to and including the first await expression (if there is one), is run synchronously. In this way, an async function without an await expression will run synchronously. If there is an await expression inside the function body, however, the async function will always complete asynchronously.\n\nIt is also equivalent to:\n\nCode after each await expression can be thought of as existing in a callback. In this way a promise chain is progressively constructed with each reentrant step through the function. The return value forms the final link in the chain.\n\nIn the following example, we successively await two promises. Progress moves through function in three stages.\n• The first line of the body of function is executed synchronously, with the await expression configured with the pending promise. Progress through is then suspended and control is yielded back to the function that called .\n• Some time later, when the first promise has either been fulfilled or rejected, control moves back into . The result of the first promise fulfillment (if it was not rejected) is returned from the await expression. Here is assigned to . Progress continues, and the second await expression is evaluated. Again, progress through is suspended and control is yielded.\n• Some time later, when the second promise has either been fulfilled or rejected, control re-enters . The result of the second promise resolution is returned from the second await expression. Here is assigned to . Control moves to the return expression (if any). The default return value of is returned as the resolution value of the current promise.\n\nNote how the promise chain is not built-up in one go. Instead, the promise chain is constructed in stages as control is successively yielded from and returned to the async function. As a result, we must be mindful of error handling behavior when dealing with concurrent asynchronous operations.\n\nFor example, in the following code an unhandled promise rejection error will be thrown, even if a handler has been configured further along the promise chain. This is because will not be \"wired into\" the promise chain until control returns from .\n\ndeclarations behave similar to declarations — they are hoisted to the top of their scope and can be called anywhere in their scope, and they can be redeclared only in certain contexts."
    },
    {
        "link": "https://prisma.io/docs/orm/reference/prisma-client-reference",
        "document": "The Prisma Client API reference documentation is based on the following schema:\n\nAll example generated types (such as and ) are based on the model.\n\nThis section describes the constructor and its parameters.\n\nProgrammatically overrides properties of the block in the file - for example, as part of an integration test. See also: Data sources\n\nFrom version 5.2.0 and upwards, you can also use the property to programmatically override the database connection string.\n• You must re-generate Prisma Client each time you add or rename a data source. Datasource names are included in the generated client.\n• If you named your block something else in the schema, replace with the name of your block.\n\nBased on the following block:\n\nProgrammatically overrides the block in the file.\n\nDetermines the type and level of logging. See also: Logging\n\nNote that for MongoDB, the and fields will be undefined.\n\nDetermines the level and formatting of errors returned by Prisma Client.\n\nDefines an instance of a driver adapter. See also Database drivers .\n\nThe example below uses the Neon driver adapter\n\nUse the parameter to configure and/or to throw an error if the record was not found. By default, both operations return if the record is not found.\n• You can configure on a per-request level for both and\n\nAllows to set transaction options globally on the constructor level.\n• The transaction levels can be overridden on a per-transaction level.\n\nUse model queries to perform CRUD operations on your models. See also: CRUD\n• Prisma Client's dataloader automatically batches queries with the same and parameters.\n• If you want the query to throw an error if the record is not found, then consider using instead.\n• You cannot use filter conditions (e.g. , , ) to filter fields of the JSON data type. Using filter conditions will likely result in a response for that field.\n\nretrieves a single record in the same way as . However, if the query does not find the requested record, it throws a .\n\nNote that before Prisma v6, it would throw a .\n\nHere’s an example of its usage:\n\ndiffers from as follows:\n• Its return type is non-nullable. For example, can return or , but always returns .\n• It is not compatible with sequential operations in the API. If the query throws a , then the API will not roll back any operations in the array of calls. As a workaround, you can use interactive transactions with the API, as follows:\n\nreturns the first record in a list that matches your criteria.\n• If you want the query to throw an error if the record is not found, then consider using instead.\n• calls behind the scenes and accepts the same query options.\n• Passing in a negative value when you use a query reverses the order of the list.\n\nSee Filter conditions and operators for examples of how to filter results.\n\nretrieves a single data record in the same way as . However, if the query does not find a record, it throws a .\n\nNote that before Prisma v6, it would throw a .\n\ndiffers from as follows:\n• Its return type is non-nullable. For example, can return or , but always returns .\n• It is not compatible with sequential operations in the API. If the query returns , then the API will not roll back any operations in the array of calls. As a workaround, you can use interactive transactions with the API, as follows:\n\nSee Filter conditions and operators for examples of how to filter results.\n• You can also perform a nested - for example, add a and two records at the same time.\n\nIn most cases, you can carry out batch inserts with the or queries. However, there are scenarios where is the best option to insert multiple records.\n\nThe following example results in two statements:\n• To perform arithmetic operations on update (add, subtract, multiply, divide), use atomic updates to prevent race conditions.\n• You can also perform a nested - for example, update a user and that user's posts at the same time.\n\ndoes the following:\n• If an existing database record satisfies the condition, it updates that record\n• If no database record satisfies the condition, it creates a new database record\n• To perform arithmetic operations on update (add, subtract, multiply, divide), use atomic updates to prevent race conditions.\n• If two or more upsert operations happen at the same time and the record doesn't already exist, then a race condition might happen. As a result, one or more of the upsert operations might throw a unique key constraint error. Your application code can catch this error and retry the operation. Learn more.\n• From version 4.6.0, Prisma ORM hands over upsert queries to the database where possible. Learn more.\n\nIf multiple upsert operations happen at the same time and the record doesn't already exist, then one or more of the operations might return a unique key constraint error.\n\nWhen Prisma Client does an upsert, it first checks whether that record already exists in the database. To make this check, Prisma Client performs a read operation with the clause from the upsert operation. This has two possible outcomes, as follows:\n• If the record does not exist, then Prisma Client creates that record.\n• If the record exists, then Prisma Client updates it.\n\nWhen your application tries to perform two or more concurrent upsert operations, then a race condition might happen where two or more operations do not find the record and therefore try to create that record. In this situation, one of the operations successfully creates the new record but the other operations fail and return a unique key constraint error.\n\nHandle the P2002 error in your application code. When it occurs, retry the upsert operation to update the row.\n\nWhere possible, Prisma Client hands over an query to the database. This is called a database upsert.\n\nDatabase upserts have the following advantages:\n• They are faster than upserts handled by Prisma Client\n\nPrisma Client uses a database upsert automatically when specific criteria are met. When these criteria are not met, Prisma Client handles the .\n\nTo use a database upsert, Prisma Client sends the SQL construction to the database.\n\nPrisma Client can use database upserts if your stack meets the following criteria:\n• You use Prisma ORM version 4.6.0 or later\n• Your application uses a CockroachDB, PostgreSQL, or SQLite data source\n\nPrisma Client uses a database upsert for an query when the query meets the following criteria:\n• There are no nested queries in the 's and options\n• The query does not include a selection that uses a nested read\n• The query modifies only one model\n• There is only one unique field in the 's option\n• The unique field in the option and the unique field in the option have the same value\n\nIf your query does not meet these criteria, then Prisma Client handles the upsert itself.\n\nThe following examples use this schema:\n\nThe following query meets all of the criteria, so Prisma Client uses a database upsert.\n\nIn this situation, Prisma uses the following SQL query:\n\nThe following query has multiple unique values in the clause, so Prisma Client does not use a database upsert:\n\nIn the following query, the values for in the and options are different, so Prisma Client does not use a database upsert.\n\nIn the following query, the selection on the field in is a nested read, so Prisma Client does not use a database upsert.\n\ndeletes an existing database record. You can delete a record:\n\nTo delete records that match a certain criteria, use with a filter.\n• To delete multiple records based on some criteria (for example, all records with a email address, use )\n\nThe following query deletes a specific user record and uses to return the and of the deleted user:\n• As of Prisma ORM version 5.12.0, is now supported by SQLite.\n• The option is not supported by MongoDB, SQLServer, or SQLite.\n• You cannot create or connect relations by using nested , , , queries inside a top-level query. See here for a workaround.\n• You can use a nested query inside an or query - for example, add a and two records with a nested at the same time.\n• The option is not supported by SQLite.\n• You cannot create or connect relations by using nested , , , queries inside a top-level query. See here for a workaround.\n• When relations are included via , a separate query is generated per relation.\n\nupdates a batch of existing database records in bulk and returns the number of updated records.\n\nSee Filter conditions and operators for examples of how to filter the records to delete.\n• A count of all records with non- fields\n• A count of all records with non- fields\n\nSee also: Aggregation, grouping, and summarizing\n\nSee also: Aggregation, grouping, and summarizing\n\nThe query also returns a count of records in each group, and all records with non- field values in each group.\n\ndefines which fields are included in the object that Prisma Client returns. See: Select fields and include relations .\n• You cannot combine and on the same level.\n• In 3.0.1 and later, you can select a of relations.\n\nThe following example demonstrates how to use the with :\n\ndefines which relations are included in the result that Prisma Client returns. See: Select fields and include relations .\n• In 3.0.1 and later, you can a of relations\n\nThe following example demonstrates how to use the with :\n\ndefines which fields are excluded in the object that Prisma Client returns.\n• You cannot combine and since they serve opposite purposes\n• was released into General Availability with Prisma ORM 6.2.0. It was available via the Preview feature in Prisma ORM versions through .\n\nThe following example demonstrates how to use the with :\n\nspecifies how a relation should be loaded from the database. It has two possible values:\n• (default): Uses a database-level (PostgreSQL) or correlated subqueries (MySQL) and fetches all data with a single query to the database.\n• : Sends multiple queries to the database (one per table) and joins them on the application level.\n\nYou can learn more about join strategies here.\n\nBecause the option is currently in Preview, you need to enable it via the preview feature flag in your Prisma schema file:\n\nAfter adding this flag, you need to run again to re-generate Prisma Client. This feature is currently available on PostgreSQL, CockroachDB and MySQL.\n• In most situations, the default strategy will be more effective. Use if you want to save resources on your database server or if you profiling shows that the application-level join is more performant.\n• You can only specify the on the top-level in your query. The top-level choice will affect all nested sub-queries.\n\ndefines one or more filters, and can be used to filter on record properties (like a user's email address) or related record properties (like a user's top 10 most recent post titles).\n\nThe following examples demonstrate how to use the with :\n• This type works by exposing any unique fields on the model. A field assigned is considered unique, as is one assigned . From version 4.5.0, this type exposes all fields on the model. This means that when you filter for a single record based on a unique field, you can check additional non-unique and unique fields at the same time. Learn more.\n• - This type accepts a unique field (an or another assigned ) and updates any field on the model except the . The is the scalar field on the model. 'This is some updated content' \n\n 'This is a new title'\n• - This type will update the records title field where the id matches, if it doesn't exist it will create it instead. 'This is a new title' \n\n 'If the title doesnt exist, then create one with this text'\n• - This type will update all records where published is set to false.\n\nSorts a list of records. See also: Sorting\n• In 2.16.0 and later, you can order by relation fields - for example, order posts by the author's name.\n• In 3.5.0 and later, in PostgreSQL you can order by relevance. For details, see Sort by relevance.\n• In 4.1.0 and later, you can sort records first or last. For details, see Sort with nulls first or last.\n• It is for use on optional scalar fields only. If you try to sort by nulls on a required or relation field, Prisma Client throws a P2009 error.\n• It is available in version 4.1.0 and later, as a preview feature. See sort with nulls first or last for details of how to enable the feature.\n\nThe following example returns all records sorted by ascending:\n\nThe following example returns all records sorted by descending:\n\nThe following query orders posts by user name:\n\nThe following query orders posts by user name, with records first:\n\nThe following query orders posts by relevance of the search term to the title:\n\nThe following query orders users by post count:\n\nThe following example sorts users by two fields - first , then :\n\nThe order of sorting parameters matters - the following query sorts by , then . Not the difference in the results:\n\nThe following example returns all the and fields of all records, sorted by :\n\nThe following example:\n• For each record, returns the field of all nested records sorted by\n\nThe following example retrieves a single record by ID, as well as a list of nested records sorted by :\n\nThe following sorts all records by (an ):\n\nThe following examples demonstrate how to use the with :\n\nDeduplicate a list of records from or . See also: Aggregation, grouping, and summarizing\n\nThe following example returns all distinct fields, and selects only the and fields:\n\nThe following example returns all distinct and field combinations, and selects only the and fields:\n\nNote that there is now a \"Paris, Denmark\" in addition to \"Paris, France\":\n\nThe following example returns all distinct and field combinations where the user's email contains , and selects only the and fields:\n\nEnabling in your Prisma schema pushes the operation to the database layer (where supported). This can significantly improve performance. However, note that:\n• Some databases may not fully support DISTINCT on certain field combinations.\n\nSee Preview Features for more details.\n\nA nested query adds a new related record or set of records to a parent record. See: Working with relations\n• is available as a nested query when you ( ) a new parent record or ( ) an existing parent record.\n• You can use a nested or a nested to create multiple related records. If you require the query option you should use .\n\nBecause it's a one-to-many relation, you can also create multiple records at once by passing an array to :\n\nNote: You can also use a nested to achieve the same result.\n\nA nested query adds a new set of records to a parent record. See: Working with relations\n• is available as a nested query when you ( ) a new parent record or ( ) an existing parent record.\n• Available in the context of a one-to-many relation — for example, you can a user and use a nested to create multiple posts (posts have one user).\n• Not available in the context of a many-to-many relation — for example, you cannot a post and use a nested to create categories (many posts have many categories).\n• You cannot nest an additional or .\n• Allows setting foreign keys directly — for example, setting the on a post.\n• As of Prisma ORM version 5.12.0, nested is supported by SQLite.\n• You can use a nested or a nested to create multiple related records - if you do not need the query option, you should probably use .\n\noverwrites the value of a relation - for example, replacing a list of records with a different list. See: Working with relations\n\nA nested query connects a record to an existing related record by specifying an ID or unique identifier. See: Working with relations\n• is available as a nested query when you create a new parent record or update an existing parent record.\n• If the related record does not exist, Prisma Client throws an exception: The required connected records were not found. Expected 1 records to be connected, found 0.\n• When using and together, the order in which they are applied significantly impacts the result. If is used before , the connected records will only reflect the final state established by the operation, as clears all existing connections before establishes new ones. Conversely, if is applied before , the operation will override the action by clearing all connected records and replacing them with its own specified state.\n\nIn 2.11.0 and later, you can set the foreign key directly:\n\nHowever, you can't use both the direct approach and the approach in the same query. See this issue comment for details.\n\neither connects a record to an existing related record by ID or unique identifier or creates a new related record if the record does not exist. See: Working with relations\n• Multiple queries that run as concurrent transactions can result in a race condition. Consider the following example, where two queries attempt to a blog post tag named at the same time (tag names must be unique): 'How to handle schema drift in production' \n\n If query A and query B overlap in the following way, query A results in an exception: To work around this scenario, we recommend catching the unique violation exception ( , error ) and retrying failed queries.\n\nThe following example:\n• Attempts to connect the profile to a where the email address is\n• Creates a new user if a matching user does not exist\n\nThe following example:\n• Attempts to connect the user to a with an of\n• Creates a new profile if a matching profile does not exist\n\nA nested query breaks the connection between a parent record and a related record, but does not delete either record. See: Working with relations\n• is only available if the relation is optional.\n• If the relationship you are attempting to disconnect does not exist:\n• (In 2.21.0 and later ), the operation does nothing\n• (Before 2.21.0 ) Prisma Client throws an exception if the provided ID or unique identifier is not connected: The records for relation `PostToUser` between the `User` and `Post` models are not connected. \n\n\n\nA nested query updates one or more related records where the parent record's ID is . See: Working with relations\n• Nested queries are only available in the context of a top-level query (for example, ).\n• If the parent record does not exist, Prisma Client throws an exception: AssertionError(\"Expected a valid parent ID to be present for nested update to-one case.\")\n• If the related record that you want to update does not exist, Prisma Client throws an exception: AssertionError(\"Expected a valid parent ID to be present for nested update to-one case.\") \n\n\n\nA nested query updates a related record if it exists, or creates a new related record.\n\nA nested query deletes a related record. The parent record is not deleted.\n• is only available if the relation is optional.\n\nA nested updates a list of related records and supports filtering - for example, you can update a user's unpublished posts.\n\nA nested deletes related records and supports filtering. For example, you can delete a user's posts while updating other properties of that user.\n\nYou can also exclude the :\n\nThis example compares fields of the same model which is available as of version 4.3.0.\n\nValue does not equal .\n\nThe following example combines and . You can also use .\n\nValue does not exist in list.\n\nValue is less than .\n\nValue is less than or equal to .\n\nValue is greater than .\n\nValue is greater than or equal to .\n\nUse Full-Text Search to search within a field.\n• Supported by the PostgreSQL and MongoDB connectors only\n\nAll conditions must return . Alternatively, pass a list of objects into the clause - the operator is not required.\n\nThe following format returns the same results as the previous example without the operator:\n\nThe following example combines and :\n\nOne or more conditions must return .\n\nThe following example combines and :\n\nThe following example combines and :\n\nReturns all records where one or more (\"some\") related records match filtering criteria.\n• You can use without parameters to return all records with at least one relation\n\nReturns all records where all (\"every\") related records match filtering criteria.\n\nReturns all records where zero related records match filtering criteria.\n• You can use without parameters to return all records with no relations\n\nReturns all records where related record matches filtering criteria (for example, user's name Bob).\n\nReturns all records where the related record does not match the filtering criteria (for example, user's name Bob).\n\nUse to overwrite the value of a scalar list field.\n• is optional - you can set the value directly:\n\nis available in version 2.20.0 and later. Use to add one value or multiple values to a scalar list field.\n• Available for PostgreSQL and MongoDB only.\n• You can push a list of values or only a single value.\n\nUse to unset the value of a scalar list. Unlike , removes the list entirely.\n\nScalar list filters allow you to filter by the contents of a list / array field.\n• Scalar list / array filters ignore values . Using or does not return records with value lists / arrays, and results in an error.\n\nThe given value exists in the list.\n\nThe following query returns all records where the list includes :\n\nThe following query returns all records where the list does not include :\n\nEvery value exists in the list.\n\nThe following query returns all records where the list includes at least and :\n\nAt least one value exists in the list.\n\nThe following query returns all records where the list includes or :\n\nThe following query returns all records that have no tags:\n\nFilter lists to include only results that have been set (either set to a value, or explicitly set to ). Setting this filter to will exclude undefined results that are not set at all.\n\nThe following query returns all records where the have been set to either or a value:\n\nThe list matches the given value exactly.\n\nThe following query returns all records where the list includes and only:\n\nComposite type methods allow you to create, update and delete composite types.\n\nUse to overwrite the value of a composite type.\n• The keyword is optional - you can set the value directly:\n\nUse to unset the value of a composite type. Unlike , this removes the field entirely from the MongoDB document.\n\nUse to update fields within a required composite type.\n\nThe method cannot be used on optional types. Instead, use upsert\n\nUse to update an existing optional composite type if it exists, and otherwise set the composite type.\n\nThe method cannot be used on required types. Instead, use update\n\nUse to push values to the end of a list of composite types.\n\nComposite type filters allow you to filter the contents of composite types.\n\nUse to filter results by matching a composite type or a list of composite types. Requires all required fields of the composite type to match.\n\nWhen matching optional fields, you need to distinguish between undefined (missing) fields of the document, and fields that have been explicitly set to :\n• If you omit an optional field, it will match undefined fields, but not fields that have been set to\n• If you filter for values of an optional field with , then it will match only documents where the field has been set to , and not undefined fields\n\nThe ordering of fields and lists matters when using :\n• For fields, and are not considered equal\n• For lists, and are not considered equal\n\nUse to filter results by matching specific fields within composite types.\n\nUse to filter results for composite type fields that do not match.\n\nUse to filter results for an empty list of composite types.\n\nUse to filter for lists of composite types where every item in the list matches the condition\n\nUse to filter for lists of composite types where one or more items in the list match the condition.\n\nUse to filter for lists of composite types where no items in the list match the condition.\n\nAtomic operations on update is available for number field types ( and ). This feature allows you to update a field based on its current value (such as subtracting or dividing) without risking a race condition.\n• You can only perform one atomic update per field, per query.\n• If a field is , it will not be updated by , , , or .\n\nCan also be written as:\n\nFor use cases and advanced examples, see: Working with fields.\n\nThe examples in this section assumes that the value of the field is:\n• The implementation of filtering differs between database connectors\n• Filtering is case sensitive in PostgreSQL and does not yet support\n\nrepresents the location of a specific key. The following query returns all users where the nested > key equals .\n\nThe following query returns all users where the nested > array contains .\n\nThe following query returns all users where the nested > array contains an object where the value is :\n\nThe following query returns all users where the nested > key value contains :\n\nThe following query returns all users where the nested > key value starts with :\n\nThe following query returns all users where the nested > key value ends with :\n\nSpecify whether the the string filtering should be case sensitive (default) or case insensitive.\n\nThe following query returns all users where the nested > key value contains or :\n\nThe following query returns all users where the array contains the value :\n\nThe following query returns all users where the array contains all the values in the given array:\n\nThe following query returns all users where the array starts with the value :\n\nThe following query returns all users where the array ends with the value :\n• and client methods do not exist on extended client instances which are extended using\n\nThe method closes the database connections that were established when was called and stops the process that was running Prisma ORM's query engine. See Connection management for an overview of and .\n• returns a , so you should call it inside an function with the keyword.\n\nThe method establishes a physical connection to the database via Prisma ORM's query engine. See Connection management for an overview of and .\n• returns a , so you should call it inside an function with the keyword.\n\nThe method allows you to subscribe to logging events or the exit hook.\n\nrepresents the \"next level\" in the middleware stack, which could be the next middleware or the Prisma Query, depending on where in the stack you are.\n\nis an object with information to use in your middleware.\n\nPrisma Client metrics give you a detailed insight into how Prisma Client interacts with your database. You can use this insight to help diagnose performance issues with your application. Learn more: Metrics.\n\nPrisma Client metrics has the following methods:\n\nWith , you can create and use Prisma Client extensions to add functionality to Prisma Client in the following ways:\n\nUtility types are helper functions and types that live on the namespace. They are useful for keeping your application type safe.\n\nThe helps you create re-usable query parameters based on your schema models while making sure that the objects you create are valid. See also: Using\n\nThere are two ways you can use the :\n\nUsing types provides a type-level approach to validate data:\n\nWhen using the selector pattern, you use an existing Prisma Client instance to create a validator. This pattern allows you to select the model, operation, and query option to validate against.\n\nYou can also use an instance of Prisma Client that has been extended using a Prisma Client extension.\n\nThe following example shows how you can extract and validate the input for the operation you can reuse within your app:\n\nHere is an alternative syntax for the same operation:\n\nYou can compare columns in the same table directly, for non-unique filters.\n\nThis feature was moved to general availability in version 5.0.0 and was available via the Preview feature from Prisma ORM versions 4.3.0 to 4.16.2.\n\nTo compare columns in the same table, use the property. In the following example, the query returns all records where the value in the field is less than or equal to the value in the field.\n\nYou can only make comparisons on fields of the same type. For example, the following causes an error:\n\nYou can only make comparisons with the property on fields in the same model. The following example does not work:\n\nHowever, you can compare fields in separate models with standard queries.\n\nIf you use the groupBy model query with the option, then you must put your referenced fields in the argument.\n\nThe following example works:\n\nThe following example does not work, because is not in the argument:\n\nIf your data source supports scalar lists (for example in PostgreSQL), then you can search for all records where a specific field is in a list of fields. To do so, reference the scalar list with the and filters. For example:\n\nFrom version 5.0.0, the generated type on exposes all fields on the model, not just unique fields. This was available under the Preview flag between versions 4.5.0 to 4.16.2\n\nYou must specify at least one unique field in your statement outside of boolean operators, and you can specify any number of additional unique and non-unique fields. You can use this to add filters to any operation that returns a single record. For example, you can use this feature for the following:\n\nFrom version 4.6.0, you can use this feature to filter on optional one-to-one nested reads.\n\nYou can filter on non-unique fields to perform optimistic concurrency control on operations.\n\nTo perform optimistic concurrency control, we recommend that you use a field to check whether the data in a record or related record has changed while your code executes. Before version 4.5.0, you could not evaluate the field in an operation, because the field is non-unique. From version 4.5.0, you can evaluate the field.\n\nIn the following example, and first read the same record and then attempt to update it. The database only executes these updates if the value in is the same as the value when it did the initial read. When the database executes the first of these updates (which might be or , depending on timing), it increments the value in . This means that the database does not execute the second update because the value in has changed.\n\nYou can filter on non-unique fields to check permissions during an update.\n\nIn the following example, a user wants to update a post title. The statement checks the value in to confirm that the user is the author of the post. The application only updates the post title if the user is the post author.\n\nYou can filter on non-unique fields to handle soft deletes.\n\nIn the following example, we do not want to return a post if it is soft-deleted. The operation only returns the post if the value in is .\n\nWith , you must specify at least one unique field outside of the boolean operators , , . You can still use these boolean operators in conjunction with any other unique fields or non-unique fields in your filter.\n\nIn the following example, we test , a unique field, in conjunction with . This is valid.\n\nThe following example is not valid, because there is no unique field outside of any boolean operators:\n\nFrom version 4.5.0, you can filter on non-unique fields in the following operations on one-to-one relations:\n\nPrisma Client automatically uses a unique filter to select the appropriate related record. As a result, you do not need to specify a unique filter in your statement with a generated type. Instead, the statement has a generated type. You can use this to filter without the restrictions of .\n\nAll Prisma Client queries return an instance of . This is a \"thenable\" , meaning a only executes when you call or or . This behavior is different from a regular JavaScript , which starts executing immediately.\n\nWhen using the API, this behavior makes it possible for Prisma Client to pass all the queries on to the query engine as a single transaction."
    },
    {
        "link": "https://prisma.io/docs/orm/prisma-client/queries/relation-queries",
        "document": "A key feature of Prisma Client is the ability to query relations between two or more models. Relation queries include:\n• Nested reads (sometimes referred to as eager loading) via and\n\nPrisma Client also has a fluent API for traversing relations.\n\nNested reads allow you to read related data from multiple tables in your database - such as a user and that user's posts. You can:\n• Use to include related records, such as a user's posts or profile, in the query response.\n• Use a nested to include specific fields from a related record. You can also nest inside an .\n\nSince version 5.8.0 , you can decide on a per-query-level how you want Prisma Client to execute a relation query (i.e. what load strategy should be applied) via the option for PostgreSQL databases.\n\nSince version 5.10.0 , this feature is also available for MySQL.\n\nBecause the option is currently in Preview, you need to enable it via the preview feature flag in your Prisma schema file:\n\nAfter adding this flag, you need to run again to re-generate Prisma Client. This feature is currently available on PostgreSQL, CockroachDB and MySQL.\n• (default): Uses a database-level (PostgreSQL) or correlated subqueries (MySQL) and fetches all data with a single query to the database.\n• : Sends multiple queries to the database (one per table) and joins them on the application level.\n\nAnother important difference between these two options is that the strategy uses JSON aggregation on the database level. That means that it creates the JSON structures returned by Prisma Client already in the database which saves computation resources on the application level.\n\nYou can use the option on the top-level in any query that supports or .\n\nHere is an example with :\n\nAnd here is another example with :\n• The strategy (default) will be more effective in most scenarios. On PostgreSQL, it uses a combination of and JSON aggregation to reduce redundancy in result sets and delegate the work of transforming the query results into the expected JSON structures on the database server. On MySQL, it uses correlated subqueries to fetch the results with a single query.\n• There may be edge cases where could be more performant depending on the characteristics of the dataset and query. We recommend that you profile your database queries to identify these situations.\n• Use if you want to save resources on the database server and do heavy-lifting of merging and transforming data in the application server which might be easier to scale.\n\nThe following example returns a single user and that user's posts:\n\nThe following example returns a post and its author:\n\nYou can nest options to include relations of relations. The following example returns a user's posts, and each post's categories:\n\nYou can use a nested to choose a subset of fields of relations to return. For example, the following query returns the user's and the of each related post:\n\nYou can also nest a inside an - the following example returns all fields and the field of each post:\n\nNote that you cannot use and on the same level. This means that if you choose to a user's post and each post's title, you cannot only the users' :\n\nIn 3.0.1 and later, you can or a count of relations alongside fields - for example, a user's post count.\n\nWhen you use or to return a subset of the related data, you can filter and sort the list of relations inside the or .\n\nFor example, the following query returns list of titles of the unpublished posts associated with the user:\n\nYou can also write the same query using as follows:\n\nA nested write allows you to write relational data to your database in a single transaction.\n• Provide transactional guarantees for creating, updating or deleting data across multiple tables in a single Prisma Client query. If any part of the query fails (for example, creating a user succeeds but creating posts fails), Prisma Client rolls back all changes.\n• Support any level of nesting supported by the data model.\n• Are available for relation fields when using the model's create or update query. The following section shows the nested write options that are available per query.\n\nYou can create a record and one or more related records at the same time. The following query creates a record and two related records:\n\nThere are two ways to create or update a single record and multiple related records - for example, a user with multiple posts:\n\nIn most cases, a nested will be preferable unless the query option is required. Here's a quick table describing the differences between the two options:\n\nThe following query uses nested to create:\n\nThe example also uses a nested to include all posts and post categories in the returned data.\n\nHere's a visual representation of how a nested create operation can write to several tables in the database as once:\n\nThe following query uses a nested to create:\n\nThe example also uses a nested to include all posts in the returned data.\n\nNote that it is not possible to nest an additional or inside the highlighted query, which means that you cannot create a user, posts, and post categories at the same time.\n\nAs a workaround, you can send a query to create the records that will be connected first, and then create the actual records. For example:\n\nIf you want to create all records in a single database query, consider using a or type-safe, raw SQL.\n\nYou cannot access relations in a or query, which means that you cannot create multiple users and multiple posts in a single nested write. The following is not possible:\n\nThe following query creates ( ) a new record and connects that record ( ) to three existing posts:\n\nYou can an existing record to a new or existing user. The following query connects an existing post ( ) to an existing user ( )\n\nIf a related record may or may not already exist, use to connect the related record:\n• Connect a with the email address or\n• Create a new with the email address if the user does not already exist\n\nTo one out of a list of records (for example, a specific blog post) provide the ID or unique identifier of the record(s) to disconnect:\n\nTo one record (for example, a post's author), use :\n\nTo all related records in a one-to-many relation (a user has many posts), the relation to an empty list as shown:\n\nYou can use a nested to update all related records for a particular user. The following query unpublishes all posts for a specific user:\n\nThe following query uses a nested to update if that user exists, or create the user if they do not exist:\n\nYou can nest or inside an to add new related records to an existing record. The following query adds two posts to a user with an of 9:\n\nPrisma Client provides the , , and options to filter records by the properties of related records on the \"-to-many\" side of the relation. For example, filtering users based on properties of their posts.\n\nFor example, the following query returns that meet the following criteria:\n• No posts with more than 100 views\n• All posts have less than, or equal to 50 likes\n\nPrisma Client provides the and options to filter records by the properties of related records on the \"-to-one\" side of the relation. For example, filtering posts based on properties of their author.\n\nFor example, the following query returns records that meet the following criteria:\n• Author's name is not Bob\n\nFor example, the following query uses to return all users that have zero posts:\n\nThe following query returns all posts that don't have an author relation:\n\nThe following query returns all users with at least one post:\n\nThe fluent API lets you fluently traverse the relations of your models via function calls. Note that the last function call determines the return type of the entire query (the respective type annotations are added in the code snippets below to make that explicit).\n\nThis query returns all records by a specific :\n\nThis is equivalent to the following query:\n\nThe main difference between the queries is that the fluent API call is translated into two separate database queries while the other one only generates a single query (see this GitHub issue )\n\nThis request returns all categories by a specific post:\n\nNote that you can chain as many queries as you like. In this example, the chaining starts at and goes over to :\n\nThe only requirement for chaining is that the previous function call must return only a single object (e.g. as returned by a query or a \"to-one relation\" like ).\n\nThe following query is not possible because does not return a single object but a list:"
    },
    {
        "link": "https://github.com/prisma/studio/issues/370",
        "document": "\n• Logs from Developer Tools Console, if any:\n\nError Prisma Client request: Error: Invalid () ConnectorError(ConnectorError { user_facing_error: None, kind: QueryError(Error { kind: Db, cause: Some(DbError { severity: , parsed_severity: Some(Error), code: SqlState( ), message: , detail: None, hint: None, position: Some(Original(214)), where_: None, schema: None, table: None, column: None, datatype: None, constraint: None, file: Some( ), line: Some(1139), routine: Some( ) }) }) })\n• Does the issue persist even after updating to the latest alpha ( )?\n\n Yes\n\n// This is your Prisma schema file, // learn more about it in the docs: https://pris.ly/d/prisma-schema"
    },
    {
        "link": "https://prisma.io/docs/orm/prisma-client/queries/crud",
        "document": "This page describes how to perform CRUD operations with your generated Prisma Client API. CRUD is an acronym that stands for:\n\nRefer to the Prisma Client API reference documentation for detailed explanations of each method.\n\nAll examples are based on the following schema:\n\nFor relational databases, use command to push the example schema to your own database\n\nFor MongoDB, ensure your data is in a uniform shape and matches the model defined in the Prisma schema.\n\nThe following query creates ( ) a single user with two fields:\n\nThe user's is auto-generated, and your schema determines which fields are mandatory.\n\nThe following example produces an identical result, but creates a variable named outside the context of the query. After completing a simple check (\"Should posts be included in this query?\"), the variable is passed into the query:\n\nFor more information about working with generated types, see: Generated types.\n\nPrisma Client supports bulk inserts as a GA feature in 2.20.0 and later.\n\nThe following query creates multiple users and skips any duplicates ( must be unique):\n\nuses a single statement with multiple values, which is generally more efficient than a separate per row:\n\nThe following video demonstrates how to use and faker.js to seed a database with sample data:\n\nSee Working with relations > Nested writes for information about creating a record and one or more related records at the same time.\n\nYou can use in order to create many records and return the resulting objects.\n\nThe following queries return a single record ( ) by unique identifier or ID:\n\nIf you are using the MongoDB connector and your underlying ID type is , you can use the string representation of that :\n\nThe following query returns all records:\n\nYou can also paginate your results.\n\nThe following query returns the most recently created user with at least one post that has more than 100 likes:\n• Order users by descending ID (largest first) - the largest ID is the most recent\n• Return the first user in descending order with at least one post that has more than 100 likes\n\nThe following query returns all records with an email that ends in :\n\nThe following query uses a combination of operators to return users whose name start with or administrators with at least 1 profile view:\n\nThe following query returns users with an email that ends with and have at least one post ( ) that is not published:\n\nSee Working with relations for more examples of filtering on related field values.\n\nThe following query uses to return the and fields of a specific record:\n\nFor more information about including relations, refer to:\n\nThe following query uses a nested to return:\n• The field of each post\n\nFor more information about including relations, see Select fields and include relations.\n\nSee Select for information about selecting distinct field values.\n\nThe following query returns all users and includes each user's posts in the result:\n\nFor more information about including relations, see Select fields and include relations.\n\nSee Working with relations to find out how to combine and for a filtered list of relations - for example, only include a user's published posts.\n\nThe following query uses to find and update a single record by :\n\nThe following query uses to update all records that contain :\n\nYou can use in order to update many records and return the resulting objects.\n\nThe following query uses to update a record with a specific email address, or create that record if it does not exist:\n\nPrisma Client does not have a query. You can use as a workaround. To make behave like a method, provide an empty parameter to .\n\nUse atomic number operations to update a number field based on its current value - for example, increment or multiply. The following query increments the and fields by :\n\nRefer to Working with relations for information about disconnecting ( ) and connecting ( ) related records.\n\nThe following query uses to delete a single record:\n\nAttempting to delete a user with one or more posts result in an error, as every requires an author - see cascading deletes.\n\nThe following query uses to delete all records where contains :\n\nAttempting to delete a user with one or more posts result in an error, as every requires an author - see cascading deletes.\n\nThe following query uses to delete all records:\n\nBe aware that this query will fail if the user has any related records (such as posts). In this case, you need to delete the related records first.\n\nThe following query uses to delete a single record:\n\nHowever, the example schema includes a required relation between and , which means that you cannot delete a user with posts:\n\nTo resolve this error, you can:\n• Change the author of the posts to another user before deleting the user.\n• Delete a user and all their posts with two separate queries in a transaction (all queries must succeed):\n\nSometimes you want to remove all data from all tables but keep the actual tables. This can be particularly useful in a development environment and whilst testing.\n\nThe following shows how to delete all records from all tables with Prisma Client and with Prisma Migrate.\n\nWhen you know the order in which your tables should be deleted, you can use the function. This is executed synchronously in a and can be used with all types of databases.\n• Works well when you know the structure of your schema ahead of time\n• When working with relational databases, this function doesn't scale as well as having a more generic solution which looks up and s your tables regardless of their relational constraints. Note that this scaling issue does not apply when using the MongoDB connector.\n\nIf you are comfortable working with raw SQL, you can perform a query on a table using .\n\nIn the following examples, the first tab shows how to perform a on a Postgres database by using a look up that maps over the table and all tables in a single query.\n\nThe second tab shows performing the same function but with a MySQL database. In this instance the constraints must be removed before the can be executed, before being reinstated once finished. The whole process is run as a\n• Using reserved SQL key words as tables names can cause issues when trying to run a raw query\n\nIf you use Prisma Migrate, you can use , this will:"
    },
    {
        "link": "https://prisma.io/docs/orm/prisma-client/queries/transactions",
        "document": "A database transaction refers to a sequence of read/write operations that are guaranteed to either succeed or fail as a whole. This section describes the ways in which the Prisma Client API supports transactions.\n\nDevelopers take advantage of the safety guarantees provided by the database by wrapping the operations in a transaction. These guarantees are often summarized using the ACID acronym:\n• Atomic: Ensures that either all or none operations of the transactions succeed. The transaction is either committed successfully or aborted and rolled back.\n• Consistent: Ensures that the states of the database before and after the transaction are valid (i.e. any existing invariants about the data are maintained).\n• Isolated: Ensures that concurrently running transactions have the same effect as if they were running in serial.\n• Durability: Ensures that after the transaction succeeded, any writes are being stored persistently.\n\nWhile there's a lot of ambiguity and nuance to each of these properties (for example, consistency could actually be considered an application-level responsibility rather than a database property or isolation is typically guaranteed in terms of stronger and weaker isolation levels), overall they serve as a good high-level guideline for expectations developers have when thinking about database transactions.\n\nPrisma Client supports six different ways of handling transactions for three different scenarios:\n\nThe technique you choose depends on your particular use case.\n\nPrisma Client provides the following options for using transactions:\n• Nested writes: use the Prisma Client API to process multiple operations on one or more related records inside the same transaction.\n• Batch / bulk transactions: process one or more operations in bulk with , , and .\n• The API in Prisma Client:\n• Sequential operations: pass an array of Prisma Client queries to be executed sequentially inside a transaction, using .\n• Interactive transactions: pass a function that can contain user code including Prisma Client queries, non-Prisma code and other control flow to be executed in a transaction, using\n\nA nested write lets you perform a single Prisma Client API call with multiple operations that touch multiple related records. For example, creating a user together with a post or updating an order together with an invoice. Prisma Client ensures that all operations succeed or fail as a whole.\n\nThe following example demonstrates a nested write with :\n\nThe following example demonstrates a nested write with :\n\nThe following bulk operations run as transactions:\n\nThe API can be used in two ways:\n• Sequential operations: Pass an array of Prisma Client queries to be executed sequentially inside of a transaction.\n• Interactive transactions: Pass a function that can contain user code including Prisma Client queries, non-Prisma code and other control flow to be executed in a transaction.\n\nThe following query returns all posts that match the provided filter as well as a count of all posts:\n\nYou can also use raw queries inside of a :\n\nInstead of immediately awaiting the result of each operation when it's performed, the operation itself is stored in a variable first which later is submitted to the database with a method called . Prisma Client will ensure that either all three operations succeed or none of them succeed.\n\nFrom version 4.4.0, the sequential operations transaction API has a second parameter. You can use the following optional configuration option in this parameter:\n• : Sets the transaction isolation level. By default this is set to the value currently configured in your database.\n\nSometimes you need more control over what queries execute within a transaction. Interactive transactions are meant to provide you with an escape hatch.\n\nTo use interactive transactions, you can pass an async function into .\n\nThe first argument passed into this async function is an instance of Prisma Client. Below, we will call this instance . Any Prisma Client call invoked on this instance is encapsulated into the transaction.\n\nLet's look at an example:\n\nImagine that you are building an online banking system. One of the actions to perform is to send money from one person to another.\n\nAs experienced developers, we want to make sure that during the transfer,\n\nThis is a great use-case for interactive transactions because we need to perform logic in-between the writes to check the balance.\n\nIn the example below, Alice and Bob each have $100 in their account. If they try to send more money than they have, the transfer is rejected.\n\nAlice is expected to be able to make 1 transfer for $100 while the other transfer would be rejected. This would result in Alice having $0 and Bob having $200.\n\nIn the example above, both queries run within a database transaction. When the application reaches the end of the function, the transaction is committed to the database.\n\nIf your application encounters an error along the way, the async function will throw an exception and automatically rollback the transaction.\n\nTo catch the exception, you can wrap in a try-catch block:\n\nThe transaction API has a second parameter. For interactive transactions, you can use the following optional configuration options in this parameter:\n• : The maximum amount of time Prisma Client will wait to acquire a transaction from the database. The default value is 2 seconds.\n• : The maximum amount of time the interactive transaction can run before being canceled and rolled back. The default value is 5 seconds.\n• : Sets the transaction isolation level. By default this is set to the value currently configured in your database.\n\nYou can also set these globally on the constructor-level:\n\nYou can set the transaction isolation level for transactions.\n\nTo set the transaction isolation level, use the option in the second parameter of the API.\n\nPrisma Client supports the following isolation levels if they are available in the underlying database:\n\nThe isolation levels available for each database connector are as follows:\n\nBy default, Prisma Client sets the isolation level to the value currently configured in your database.\n\nThe isolation levels configured by default in each database are as follows:\n\nSee the following resources:\n\nCockroachDB and SQLite only support the isolation level.\n\nWhen two or more transactions run concurrently in certain isolation levels, timing issues can cause write conflicts or deadlocks, such as the violation of unique constraints. For example, consider the following sequence of events where Transaction A and Transaction B both attempt to execute a and a operation:\n• Transaction A: The application commits transaction A. The new rows conflict with the rows that transaction B added at step 2.\n\nThis conflict can occur at the isolation level , which is the default isolation level in PostgreSQL and Microsoft SQL Server. To avoid this problem, you can set a higher isolation level ( or ). You can set the isolation level on a transaction. This overrides your database isolation level for that transaction.\n\nTo avoid transaction write conflicts and deadlocks on a transaction:\n• On your transaction, use the parameter to . This ensures that your application commits multiple concurrent or parallel transactions as if they were run serially. When a transaction fails due to a write conflict or deadlock, Prisma Client returns a P2034 error.\n• In your application code, add a retry around your transaction to handle any P2034 errors, as shown in this example:\n\nIf you wrap a inside a call to , the queries inside the transaction will be executed serially (i.e. one after another):\n\nThis may be counterintuitive because usually parallelizes the calls passed into it.\n\nThe reason for this behaviour is that:\n• One transaction means that all queries inside it have to be run on the same connection.\n• A database connection can only ever execute one query at a time.\n• As one query blocks the connection while it is doing its work, putting a transaction into effectively means that queries should be ran one after another.\n\nWrites are considered dependent on each other if:\n• Operations depend on the result of a preceding operation (for example, the database generating an ID)\n\nThe most common scenario is creating a record and using the generated ID to create or update a related record. Examples include:\n• Creating a user and two related blog posts (a one-to-many relationship) - the author ID must be known before creating blog posts\n• Creating a team and assigning members (a many-to-many relationship) - the team ID must be known before assigning members\n\nDependent writes must succeed together in order to maintain data consistency and prevent unexpected behavior, such as blog post without an author or a team without members.\n\nPrisma Client's solution to dependent writes is the nested writes feature, which is supported by and . The following nested write creates one user and two blog posts:\n\nIf any operation fails, Prisma Client rolls back the entire transaction. Nested writes are not currently supported by top-level bulk operations like and .\n\nConsider using nested writes if:\n• ✔ You want to create two or more records related by ID at the same time (for example, create a blog post and a user)\n• ✔ You want to update and create records related by ID at the same time (for example, change a user's name and create a new blog post)\n\nConsider the Slack sign-up flow, which:\n• Adds one user to that team, which automatically becomes that team's administrator\n\nThis scenario can be represented by the following schema - note that users can belong to many teams, and teams can have many users (a many-to-many relationship):\n\nThe most straightforward approach is to create a team, then create and attach a user to that team:\n\nHowever, this code has a problem - consider the following scenario:\n• Creating the team succeeds - \"Aurora Adventures\" is now taken\n• Creating and connecting the user fails - the team \"Aurora Adventures\" exists, but has no users\n• Going through the sign-up flow again and attempting to recreate \"Aurora Adventures\" fails - the team already exists\n\nCreating a team and adding a user should be one atomic operation that succeeds or fails as a whole.\n\nTo implement atomic writes in a low-level database clients, you must wrap your inserts in , and statements. Prisma Client solves the problem with nested writes. The following query creates a team, creates a user, and connects the records in a single transaction:\n\nFurthermore, if an error occurs at any point, Prisma Client rolls back the entire transaction.\n\nThe API does not allow you to pass IDs between distinct operations. In the following example, is not available yet:\n\nIt is correct to say that because you know the ID of the team, you can update the team and its team members independently within a . The following example performs both operations in a :\n\nHowever, you can achieve the same result with a nested write:\n\nYes, but this is a combination of scenarios and techniques:\n• Creating a team and assigning users is a dependent write - use nested writes\n• Creating all teams and users at the same time is an independent write because team/user combination #1 and team/user combination #2 are unrelated writes - use the API\n\nWrites are considered independent if they do not rely on the result of a previous operation. The following groups of independent writes can occur in any order:\n• Updating the status field of a list of orders to \"Dispatched\"\n\nDepending on your requirements, Prisma Client has four options for handling independent writes that should succeed or fail together.\n\nBulk writes allow you to write multiple records of the same type in a single transaction - if any operation fails, Prisma Client rolls back the entire transaction. Prisma Client currently supports:\n\nConsider bulk operations as a solution if:\n• ✔ You want to update a batch of the same type of record, like a batch of emails\n\nYou are building a service like gmail.com, and your customer wants a \"Mark as read\" feature that allows users to mark all emails as read. Each update to the status of an email is an independent write because the emails do not depend on one another - for example, the \"Happy Birthday! 🍰\" email from your aunt is unrelated to the promotional email from IKEA.\n\nIn the following schema, a can have many received emails (a one-to-many relationship):\n\nBased on this schema, you can use to mark all unread emails as read:\n\nNo - neither nor currently supports nested writes. For example, you cannot delete multiple teams and all of their members (a cascading delete):\n\nYes — for example, you can include multiple operations inside a .\n\nThe API is generic solution to independent writes that allows you to run multiple operations as a single, atomic operation - if any operation fails, Prisma Client rolls back the entire transaction.\n\nIts also worth noting that operations are executed according to the order they are placed in the transaction.\n\nAs Prisma Client evolves, use cases for the API will increasingly be replaced by more specialized bulk operations (such as ) and nested writes.\n\nConsider the API if:\n• ✔ You want to update a batch that includes different types of records, such as emails and users. The records do not need to be related in any way.\n• ✔ You want to batch raw SQL queries ( ) - for example, for features that Prisma Client does not yet support.\n\nGDPR and other privacy legislation give users the right to request that an organization deletes all of their personal data. In the following example schema, a can have many posts and private messages:\n\nIf a user invokes the right to be forgotten, we must delete three records: the user record, private messages, and posts. It is critical that all delete operations succeed together or not at all, which makes this a use case for a transaction. However, using a single bulk operation like is not possible in this scenario because we need to delete across three models. Instead, we can use the API to run three operations together - two and one :\n\nDependent writes are not supported by the API - if operation A relies on the ID generated by operation B, use nested writes. However, if you pre-computed IDs (for example, by generating GUIDs), your writes become independent. Consider the sign-up flow from the nested writes example:\n\nInstead of auto-generating IDs, change the fields of and to a (if you do not provide a value, a UUID is generated automatically). This example uses UUIDs:\n\nRefactor the sign-up flow example to use the API instead of nested writes:\n\nTechnically you can still use nested writes with pre-computed APIs if you prefer that syntax:\n\nThere's no compelling reason to switch to manually generated IDs and the API if you are already using auto-generated IDs and nested writes.\n\nIn some cases you may need to perform custom logic as part of an atomic operation - also known as the read-modify-write pattern . The following is an example of the read-modify-write pattern:\n• Read a value from the database\n• Run some logic to manipulate that value (for example, contacting an external API)\n• Write the value back to the database\n\nAll operations should succeed or fail together without making unwanted changes to the database, but you do not necessarily need to use an actual database transaction. This section of the guide describes two ways to work with Prisma Client and the read-modify-write pattern:\n\nIdempotency is the ability to run the same logic with the same parameters multiple times with the same result: the effect on the database is the same whether you run the logic once or one thousand times. For example:\n• NOT IDEMPOTENT: Upsert (update-or-insert) a user in the database with email address . The table does not enforce unique email addresses. The effect on the database is different if you run the logic once (one user created) or ten times (ten users created).\n• IDEMPOTENT: Upsert (update-or-insert) a user in the database with the email address . The table does enforce unique email addresses. The effect on the database is the same if you run the logic once (one user created) or ten times (existing user is updated with the same input).\n\nIdempotency is something you can and should actively design into your application wherever possible.\n• ✔ You need to be able to retry the same logic without creating unwanted side-effects in the databases\n\nYou are creating an upgrade flow for Slack that allows teams to unlock paid features. Teams can choose between different plans and pay per user, per month. You use Stripe as your payment gateway, and extend your model to store a . Subscriptions are managed in Stripe.\n\nThe upgrade flow looks like this:\n• Create a subscription in Stripe that includes the number of users\n• Associate the team with the Stripe customer ID to unlock paid features\n\nThis example has a problem: you can only run the logic once. Consider the following scenario:\n• Stripe creates a new customer and subscription, and returns a customer ID\n• Updating the team fails - the team is not marked as a customer in the Slack database\n• The customer is charged by Stripe, but paid features are not unlocked in Slack because the team lacks a valid\n• Running the same code again either:\n• Results in an error because the team (defined by ) already exists - Stripe never returns a customer ID\n• If is not subject to a unique constraint, Stripe creates yet another subscription (not idempotent)\n\nYou cannot re-run this code in case of an error and you cannot change to another plan without being charged twice.\n\nThe following refactor (highlighted) introduces a mechanism that checks if a subscription already exists, and either creates the description or updates the existing subscription (which will remain unchanged if the input is identical):\n\nYou can now retry the same logic multiple times with the same input without adverse effect. To further enhance this example, you can introduce a mechanism whereby the subscription is cancelled or temporarily deactivated if the update does not succeed after a set number of attempts.\n\nOptimistic concurrency control (OCC) is a model for handling concurrent operations on a single entity that does not rely on 🔒 locking. Instead, we optimistically assume that a record will remain unchanged in between reading and writing, and use a concurrency token (a timestamp or version field) to detect changes to a record.\n\nIf a ❌ conflict occurs (someone else has changed the record since you read it), you cancel the transaction. Depending on your scenario, you can then:\n• Throw an error (alert the user that they are about to overwrite changes made by someone else)\n\nThis section describes how to build your own optimistic concurrency control. See also: Plans for application-level optimistic concurrency control on GitHub\n• ✔ You anticipate that conflicts between those concurrent requests will be rare\n\nAvoiding locks in an application with a high number of concurrent requests makes the application more resilient to load and more scalable overall. Although locking is not inherently bad, locking in a high concurrency environment can lead to unintended consequences - even if you are locking individual rows, and only for a short amount of time. For more information, see:\n• Why ROWLOCK Hints Can Make Queries Slower and Blocking Worse in SQL Server\n\nYou are creating a booking system for a cinema. Each movie has a set number of seats. The following schema models movies and seats:\n\nThe following sample code finds the first available seat and assigns that seat to a user:\n\nHowever, this code suffers from the \"double-booking problem\" - it is possible for two people to book the same seats:\n\nEven though Sorcha has successfully booked the seat, the system ultimately stores Ellen's claim. To solve this problem with optimistic concurrency control, add a field to the seat:\n\nNext, adjust the code to check the field before updating:\n\nIt is now impossible for two people to book the same seat:\n• Seat 3A claimed by Sorcha ( is incremented to 1, booking succeeds)\n• Seat 3A claimed by Ellen (in-memory (0) does not match database (1) - booking does not succeed)\n\nIf you have an existing application, it can be a significant undertaking to refactor your application to use optimistic concurrency control. Interactive Transactions offers a useful escape hatch for cases like this.\n\nTo create an interactive transaction, pass an async function into $transaction.\n\nThe first argument passed into this async function is an instance of Prisma Client. Below, we will call this instance . Any Prisma Client call invoked on this instance is encapsulated into the transaction.\n\nIn the example below, Alice and Bob each have $100 in their account. If they try to send more money than they have, the transfer is rejected.\n\nThe expected outcome would be for Alice to make 1 transfer for $100 and the other transfer would be rejected. This would result in Alice having $0 and Bob having $200.\n\nIn the example above, both queries run within a database transaction. When the application reaches the end of the function, the transaction is committed to the database.\n\nIf the application encounters an error along the way, the async function will throw an exception and automatically rollback the transaction.\n\nYou can learn more about interactive transactions in this section.\n\nPrisma Client supports multiple ways of handling transactions, either directly through the API or by supporting your ability to introduce optimistic concurrency control and idempotency into your application. If you feel like you have use cases in your application that are not covered by any of the suggested options, please open a GitHub issue to start a discussion."
    }
]