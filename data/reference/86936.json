[
    {
        "link": "https://glfw.org/docs/3.3/window_guide.html",
        "document": "This guide introduces the window related functions of GLFW. For details on a specific function in this category, see the Window reference. There are also guides for the other areas of GLFW.\n\nThe GLFWwindow object encapsulates both a window and a context. They are created with glfwCreateWindow and destroyed with glfwDestroyWindow, or glfwTerminate, if any remain. As the window and context are inseparably linked, the object pointer is used as both a context and window handle.\n\nTo see the event stream provided to the various window related callbacks, run the test program.\n\nA window and its OpenGL or OpenGL ES context are created with glfwCreateWindow, which returns a handle to the created window object. For example, this creates a 640 by 480 windowed mode window:\n\nIf window creation fails, will be returned, so it is necessary to check the return value.\n\nThe window handle is passed to all window related functions and is provided to along with all input events, so event handlers can tell which window received the event.\n\nTo create a full screen window, you need to specify which monitor the window should use. In most cases, the user's primary monitor is a good choice. For more information about retrieving monitors, see Retrieving monitors.\n\nFull screen windows cover the entire display area of a monitor, have no border or decorations.\n\nWindowed mode windows can be made full screen by setting a monitor with glfwSetWindowMonitor, and full screen ones can be made windowed by unsetting it with the same function.\n\nEach field of the GLFWvidmode structure corresponds to a function parameter or window hint and combine to form the desired video mode for that window. The supported video mode most closely matching the desired video mode will be set for the chosen monitor as long as the window has input focus. For more information about retrieving video modes, see Video modes.\n\nOnce you have a full screen window, you can change its resolution, refresh rate and monitor with glfwSetWindowMonitor. If you only need change its resolution you can also call glfwSetWindowSize. In all cases, the new video mode will be selected the same way as the video mode chosen by glfwCreateWindow. If the window has an OpenGL or OpenGL ES context, it will be unaffected.\n\nBy default, the original video mode of the monitor will be restored and the window iconified if it loses input focus, to allow the user to switch back to the desktop. This behavior can be disabled with the GLFW_AUTO_ICONIFY window hint, for example if you wish to simultaneously cover multiple monitors with full screen windows.\n\nIf a monitor is disconnected, all windows that are full screen on that monitor will be switched to windowed mode. See Monitor configuration changes for more information.\n\nIf the closest match for the desired video mode is the current one, the video mode will not be changed, making window creation faster and application switching much smoother. This is sometimes called windowed full screen or borderless full screen window and counts as a full screen window. To create such a window, request the current video mode.\n\nThis also works for windowed mode windows that are made full screen.\n\nNote that glfwGetVideoMode returns the current video mode of a monitor, so if you already have a full screen window on that monitor that you want to make windowed full screen, you need to have saved the desktop resolution before.\n\nWhen a window is no longer needed, destroy it with glfwDestroyWindow.\n\nWindow destruction always succeeds. Before the actual destruction, all callbacks are removed so no further events will be delivered for the window. All windows remaining when glfwTerminate is called are destroyed as well.\n\nWhen a full screen window is destroyed, the original video mode of its monitor is restored, but the gamma ramp is left untouched.\n\nThere are a number of hints that can be set before the creation of a window and context. Some affect the window itself, others affect the framebuffer or context. These hints are set to their default values each time the library is initialized with glfwInit. Integer value hints can be set individually with glfwWindowHint and string value hints with glfwWindowHintString. You can reset all at once to their defaults with glfwDefaultWindowHints.\n\nSome hints are platform specific. These are always valid to set on any platform but they will only affect their specific platform. Other platforms will ignore them. Setting these hints requires no platform specific headers or calls.\n\nSome window hints are hard constraints. These must match the available capabilities exactly for window and context creation to succeed. Hints that are not hard constraints are matched as closely as possible, but the resulting context and framebuffer may differ from what these hints requested.\n\nThe following hints are always hard constraints:\n\nThe following additional hints are hard constraints when requesting an OpenGL context, but are ignored when requesting an OpenGL ES context:\n\nGLFW_RESIZABLE specifies whether the windowed mode window will be resizable by the user. The window will still be resizable using the glfwSetWindowSize function. Possible values are and . This hint is ignored for full screen and undecorated windows.\n\nGLFW_VISIBLE specifies whether the windowed mode window will be initially visible. Possible values are and . This hint is ignored for full screen windows.\n\nGLFW_DECORATED specifies whether the windowed mode window will have window decorations such as a border, a close widget, etc. An undecorated window will not be resizable by the user but will still allow the user to generate close events on some platforms. Possible values are and . This hint is ignored for full screen windows.\n\nGLFW_FOCUSED specifies whether the windowed mode window will be given input focus when created. Possible values are and . This hint is ignored for full screen and initially hidden windows.\n\nGLFW_AUTO_ICONIFY specifies whether the full screen window will automatically iconify and restore the previous video mode on input focus loss. Possible values are and . This hint is ignored for windowed mode windows.\n\nGLFW_FLOATING specifies whether the windowed mode window will be floating above other regular windows, also called topmost or always-on-top. This is intended primarily for debugging purposes and cannot be used to implement proper full screen windows. Possible values are and . This hint is ignored for full screen windows.\n\nGLFW_MAXIMIZED specifies whether the windowed mode window will be maximized when created. Possible values are and . This hint is ignored for full screen windows.\n\nGLFW_CENTER_CURSOR specifies whether the cursor should be centered over newly created full screen windows. Possible values are and . This hint is ignored for windowed mode windows.\n\nGLFW_TRANSPARENT_FRAMEBUFFER specifies whether the window framebuffer will be transparent. If enabled and supported by the system, the window framebuffer alpha channel will be used to combine the framebuffer with the background. This does not affect window decorations. Possible values are and .\n\nGLFW_FOCUS_ON_SHOW specifies whether the window will be given input focus when glfwShowWindow is called. Possible values are and .\n\nGLFW_SCALE_TO_MONITOR specified whether the window content area should be resized based on the monitor content scale of any monitor it is placed on. This includes the initial placement when the window is created. Possible values are and .\n\nThis hint only has an effect on platforms where screen coordinates and pixels always map 1:1 such as Windows and X11. On platforms like macOS the resolution of the framebuffer is changed independently of the window size.\n\nGLFW_RED_BITS, GLFW_GREEN_BITS, GLFW_BLUE_BITS, GLFW_ALPHA_BITS, GLFW_DEPTH_BITS and GLFW_STENCIL_BITS specify the desired bit depths of the various components of the default framebuffer. A value of means the application has no preference.\n\nGLFW_ACCUM_RED_BITS, GLFW_ACCUM_GREEN_BITS, GLFW_ACCUM_BLUE_BITS and GLFW_ACCUM_ALPHA_BITS specify the desired bit depths of the various components of the accumulation buffer. A value of means the application has no preference.\n\nAccumulation buffers are a legacy OpenGL feature and should not be used in new code.\n\nGLFW_AUX_BUFFERS specifies the desired number of auxiliary buffers. A value of means the application has no preference.\n\nAuxiliary buffers are a legacy OpenGL feature and should not be used in new code.\n\nGLFW_STEREO specifies whether to use OpenGL stereoscopic rendering. Possible values are and . This is a hard constraint.\n\nGLFW_SAMPLES specifies the desired number of samples to use for multisampling. Zero disables multisampling. A value of means the application has no preference.\n\nGLFW_SRGB_CAPABLE specifies whether the framebuffer should be sRGB capable. Possible values are and .\n\nGLFW_DOUBLEBUFFER specifies whether the framebuffer should be double buffered. You nearly always want to use double buffering. This is a hard constraint. Possible values are and .\n\nGLFW_REFRESH_RATE specifies the desired refresh rate for full screen windows. A value of means the highest available refresh rate will be used. This hint is ignored for windowed mode windows.\n\nGLFW_CLIENT_API specifies which client API to create the context for. Possible values are , and . This is a hard constraint.\n\nGLFW_CONTEXT_CREATION_API specifies which context creation API to use to create the context. Possible values are , and . This is a hard constraint. If no client API is requested, this hint is ignored.\n\nAn extension loader library that assumes it knows which API was used to create the current context may fail if you change this hint. This can be resolved by having it load functions via glfwGetProcAddress.\n\nGLFW_CONTEXT_VERSION_MAJOR and GLFW_CONTEXT_VERSION_MINOR specify the client API version that the created context must be compatible with. The exact behavior of these hints depend on the requested client API.\n\nWhile there is no way to ask the driver for a context of the highest supported version, GLFW will attempt to provide this when you ask for a version 1.0 context, which is the default for these hints.\n\nDo not confuse these hints with GLFW_VERSION_MAJOR and GLFW_VERSION_MINOR, which provide the API version of the GLFW header.\n\nGLFW_OPENGL_FORWARD_COMPAT specifies whether the OpenGL context should be forward-compatible, i.e. one where all functionality deprecated in the requested version of OpenGL is removed. This must only be used if the requested OpenGL version is 3.0 or above. If OpenGL ES is requested, this hint is ignored.\n\nForward-compatibility is described in detail in the OpenGL Reference Manual.\n\nGLFW_OPENGL_DEBUG_CONTEXT specifies whether the context should be created in debug mode, which may provide additional error and diagnostic reporting functionality. Possible values are and .\n\nDebug contexts for OpenGL and OpenGL ES are described in detail by the GL_KHR_debug extension.\n\nGLFW_OPENGL_PROFILE specifies which OpenGL profile to create the context for. Possible values are one of or , or to not request a specific profile. If requesting an OpenGL version below 3.2, must be used. If OpenGL ES is requested, this hint is ignored.\n\nOpenGL profiles are described in detail in the OpenGL Reference Manual.\n\nGLFW_CONTEXT_ROBUSTNESS specifies the robustness strategy to be used by the context. This can be one of or , or to not request a robustness strategy.\n\nGLFW_CONTEXT_RELEASE_BEHAVIOR specifies the release behavior to be used by the context. Possible values are one of , or . If the behavior is , the default behavior of the context creation API will be used. If the behavior is , the pipeline will be flushed whenever the context is released from being the current one. If the behavior is , the pipeline will not be flushed on release.\n\nContext release behaviors are described in detail by the GL_KHR_context_flush_control extension.\n\nGLFW_CONTEXT_NO_ERROR specifies whether errors should be generated by the context. Possible values are and . If enabled, situations that would have generated errors instead cause undefined behavior.\n\nThe no error mode for OpenGL and OpenGL ES is described in detail by the GL_KHR_no_error extension.\n\nGLFW_COCOA_RETINA_FRAMEBUFFER specifies whether to use full resolution framebuffers on Retina displays. Possible values are and . This is ignored on other platforms.\n\nGLFW_COCOA_FRAME_NAME specifies the UTF-8 encoded name to use for autosaving the window frame, or if empty disables frame autosaving for the window. This is ignored on other platforms. This is set with glfwWindowHintString.\n\nGLFW_COCOA_GRAPHICS_SWITCHING specifies whether to in Automatic Graphics Switching, i.e. to allow the system to choose the integrated GPU for the OpenGL context and move it between GPUs if necessary or whether to force it to always run on the discrete GPU. This only affects systems with both integrated and discrete GPUs. Possible values are and . This is ignored on other platforms.\n\nSimpler programs and tools may want to enable this to save power, while games and other applications performing advanced rendering will want to leave it disabled.\n\nA bundled application that wishes to participate in Automatic Graphics Switching should also declare this in its by setting the key to .\n\nGLFW_X11_CLASS_NAME and GLFW_X11_INSTANCE_NAME specifies the desired ASCII encoded class and instance parts of the ICCCM window property. Both hints need to be set to something other than an empty string for them to take effect. These are set with glfwWindowHintString.\n\nEach window has a user pointer that can be set with glfwSetWindowUserPointer and queried with glfwGetWindowUserPointer. This can be used for any purpose you need and will not be modified by GLFW throughout the life-time of the window.\n\nThe initial value of the pointer is .\n\nWhen the user attempts to close the window, for example by clicking the close widget or using a key chord like Alt+F4, the close flag of the window is set. The window is however not actually destroyed and, unless you watch for this state change, nothing further happens.\n\nThe current state of the close flag is returned by glfwWindowShouldClose and can be set or cleared directly with glfwSetWindowShouldClose. A common pattern is to use the close flag as a main loop condition.\n\nIf you wish to be notified when the user attempts to close a window, set a close callback.\n\nThe callback function is called directly after the close flag has been set. It can be used for example to filter close requests and clear the close flag again unless certain conditions are met.\n\nThe size of a window can be changed with glfwSetWindowSize. For windowed mode windows, this sets the size, in screen coordinates of the content area or content area of the window. The window system may impose limits on window size.\n\nFor full screen windows, the specified size becomes the new resolution of the window's desired video mode. The video mode most closely matching the new desired video mode is set immediately. The window is resized to fit the resolution of the set video mode.\n\nIf you wish to be notified when a window is resized, whether by the user, the system or your own code, set a size callback.\n\nThe callback function receives the new size, in screen coordinates, of the content area of the window when the window is resized.\n\nThere is also glfwGetWindowSize for directly retrieving the current size of a window.\n\nThe above functions work with the size of the content area, but decorated windows typically have title bars and window frames around this rectangle. You can retrieve the extents of these with glfwGetWindowFrameSize.\n\nThe returned values are the distances, in screen coordinates, from the edges of the content area to the corresponding edges of the full window. As they are distances and not coordinates, they are always zero or positive.\n\nWhile the size of a window is measured in screen coordinates, OpenGL works with pixels. The size you pass into , for example, should be in pixels. On some machines screen coordinates and pixels are the same, but on others they will not be. There is a second set of functions to retrieve the size, in pixels, of the framebuffer of a window.\n\nIf you wish to be notified when the framebuffer of a window is resized, whether by the user or the system, set a size callback.\n\nThe callback function receives the new size of the framebuffer when it is resized, which can for example be used to update the OpenGL viewport.\n\nThere is also glfwGetFramebufferSize for directly retrieving the current size of the framebuffer of a window.\n\nThe size of a framebuffer may change independently of the size of a window, for example if the window is dragged between a regular monitor and a high-DPI one.\n\nThe content scale for a window can be retrieved with glfwGetWindowContentScale.\n\nThe content scale is the ratio between the current DPI and the platform's default DPI. This is especially important for text and any UI elements. If the pixel dimensions of your UI scaled by this look appropriate on your machine then it should appear at a reasonable size on other machines regardless of their DPI and scaling settings. This relies on the system DPI and scaling settings being somewhat correct.\n\nOn systems where each monitors can have its own content scale, the window content scale will depend on which monitor the system considers the window to be on.\n\nIf you wish to be notified when the content scale of a window changes, whether because of a system setting change or because it was moved to a monitor with a different scale, set a content scale callback.\n\nThe callback function receives the new content scale of the window.\n\nOn platforms where pixels and screen coordinates always map 1:1, the window will need to be resized to appear the same size when it is moved to a monitor with a different content scale. To have this done automatically both when the window is created and when its content scale later changes, set the GLFW_SCALE_TO_MONITOR window hint.\n\nThe minimum and maximum size of the content area of a windowed mode window can be enforced with glfwSetWindowSizeLimits. The user may resize the window to any size and aspect ratio within the specified limits, unless the aspect ratio is also set.\n\nTo specify only a minimum size or only a maximum one, set the other pair to .\n\nTo disable size limits for a window, set them all to .\n\nThe aspect ratio of the content area of a windowed mode window can be enforced with glfwSetWindowAspectRatio. The user may resize the window freely unless size limits are also set, but the size will be constrained to maintain the aspect ratio.\n\nThe aspect ratio is specified as a numerator and denominator, corresponding to the width and height, respectively. If you want a window to maintain its current aspect ratio, use its current size as the ratio.\n\nTo disable the aspect ratio limit for a window, set both terms to .\n\nYou can have both size limits and aspect ratio set for a window, but the results are undefined if they conflict.\n\nThe position of a windowed-mode window can be changed with glfwSetWindowPos. This moves the window so that the upper-left corner of its content area has the specified screen coordinates. The window system may put limitations on window placement.\n\nIf you wish to be notified when a window is moved, whether by the user, the system or your own code, set a position callback.\n\nThe callback function receives the new position, in screen coordinates, of the upper-left corner of the content area when the window is moved.\n\nThere is also glfwGetWindowPos for directly retrieving the current position of the content area of the window.\n\nAll GLFW windows have a title, although undecorated or full screen windows may not display it or only display it in a task bar or similar interface. You can set a UTF-8 encoded window title with glfwSetWindowTitle.\n\nThe specified string is copied before the function returns, so there is no need to keep it around.\n\nAs long as your source file is encoded as UTF-8, you can use any Unicode characters directly in the source.\n\nIf you are using C++11 or C11, you can use a UTF-8 string literal.\n\nDecorated windows have icons on some platforms. You can set this icon by specifying a list of candidate images with glfwSetWindowIcon.\n\nThe image data is 32-bit, little-endian, non-premultiplied RGBA, i.e. eight bits per channel with the red channel first. The pixels are arranged canonically as sequential rows, starting from the top-left corner.\n\nTo revert to the default window icon, pass in an empty image array.\n\nFull screen windows are associated with a specific monitor. You can get the handle for this monitor with glfwGetWindowMonitor.\n\nThis monitor handle is one of those returned by glfwGetMonitors.\n\nFor windowed mode windows, this function returns . This is how to tell full screen windows from windowed mode windows.\n\nYou can move windows between monitors or between full screen and windowed mode with glfwSetWindowMonitor. When making a window full screen on the same or on a different monitor, specify the desired monitor, resolution and refresh rate. The position arguments are ignored.\n\nWhen making the window windowed, specify the desired position and size. The refresh rate argument is ignored.\n\nThis restores any previous window settings such as whether it is decorated, floating, resizable, has size or aspect ratio limits, etc.. To restore a window that was originally windowed to its original size and position, save these before making it full screen and then pass them in as above.\n\nWindows can be iconified (i.e. minimized) with glfwIconifyWindow.\n\nWhen a full screen window is iconified, the original video mode of its monitor is restored until the user or application restores the window.\n\nIconified windows can be restored with glfwRestoreWindow. This function also restores windows from maximization.\n\nWhen a full screen window is restored, the desired video mode is restored to its monitor as well.\n\nIf you wish to be notified when a window is iconified or restored, whether by the user, system or your own code, set an iconify callback.\n\nThe callback function receives changes in the iconification state of the window.\n\nYou can also get the current iconification state with glfwGetWindowAttrib.\n\nWindows can be maximized (i.e. zoomed) with glfwMaximizeWindow.\n\nFull screen windows cannot be maximized and passing a full screen window to this function does nothing.\n\nMaximized windows can be restored with glfwRestoreWindow. This function also restores windows from iconification.\n\nIf you wish to be notified when a window is maximized or restored, whether by the user, system or your own code, set a maximize callback.\n\nThe callback function receives changes in the maximization state of the window.\n\nYou can also get the current maximization state with glfwGetWindowAttrib.\n\nBy default, newly created windows are not maximized. You can change this behavior by setting the GLFW_MAXIMIZED window hint before creating the window.\n\nWindowed mode windows can be hidden with glfwHideWindow.\n\nThis makes the window completely invisible to the user, including removing it from the task bar, dock or window list. Full screen windows cannot be hidden and calling glfwHideWindow on a full screen window does nothing.\n\nHidden windows can be shown with glfwShowWindow.\n\nBy default, this function will also set the input focus to that window. Set the GLFW_FOCUS_ON_SHOW window hint to change this behavior for all newly created windows, or change the behavior for an existing window with glfwSetWindowAttrib.\n\nYou can also get the current visibility state with glfwGetWindowAttrib.\n\nBy default, newly created windows are visible. You can change this behavior by setting the GLFW_VISIBLE window hint before creating the window.\n\nWindows created hidden are completely invisible to the user until shown. This can be useful if you need to set up your window further before showing it, for example moving it to a specific location.\n\nWindows can be given input focus and brought to the front with glfwFocusWindow.\n\nKeep in mind that it can be very disruptive to the user when a window is forced to the top. For a less disruptive way of getting the user's attention, see attention requests.\n\nIf you wish to be notified when a window gains or loses input focus, whether by the user, system or your own code, set a focus callback.\n\nThe callback function receives changes in the input focus state of the window.\n\nYou can also get the current input focus state with glfwGetWindowAttrib.\n\nBy default, newly created windows are given input focus. You can change this behavior by setting the GLFW_FOCUSED window hint before creating the window.\n\nIf you wish to notify the user of an event without interrupting, you can request attention with glfwRequestWindowAttention.\n\nThe system will highlight the specified window, or on platforms where this is not supported, the application as a whole. Once the user has given it attention, the system will automatically end the request.\n\nIf you wish to be notified when the contents of a window is damaged and needs to be refreshed, set a window refresh callback.\n\nThe callback function is called when the contents of the window needs to be refreshed.\n\nGLFW supports two kinds of transparency for windows; framebuffer transparency and whole window transparency. A single window may not use both methods. The results of doing this are undefined.\n\nBoth methods require the platform to support it and not every version of every platform GLFW supports does this, so there are mechanisms to check whether the window really is transparent.\n\nWindow framebuffers can be made transparent on a per-pixel per-frame basis with the GLFW_TRANSPARENT_FRAMEBUFFER window hint.\n\nIf supported by the system, the window content area will be composited with the background using the framebuffer per-pixel alpha channel. This requires desktop compositing to be enabled on the system. It does not affect window decorations.\n\nYou can check whether the window framebuffer was successfully made transparent with the GLFW_TRANSPARENT_FRAMEBUFFER window attribute.\n\nGLFW comes with an example that enabled framebuffer transparency called .\n\nThe opacity of the whole window, including any decorations, can be set with glfwSetWindowOpacity.\n\nThe opacity (or alpha) value is a positive finite number between zero and one, where 0 (zero) is fully transparent and 1 (one) is fully opaque. The initial opacity value for newly created windows is 1.\n\nThe current opacity of a window can be queried with glfwGetWindowOpacity.\n\nIf the system does not support whole window transparency, this function always returns one.\n\nGLFW comes with a test program that lets you control whole window transparency at run-time called .\n\nWindows have a number of attributes that can be returned using glfwGetWindowAttrib. Some reflect state that may change as a result of user interaction, (e.g. whether it has input focus), while others reflect inherent properties of the window (e.g. what kind of border it has). Some are related to the window and others to its OpenGL or OpenGL ES context.\n\nThe GLFW_DECORATED, GLFW_RESIZABLE, GLFW_FLOATING, GLFW_AUTO_ICONIFY and GLFW_FOCUS_ON_SHOW window attributes can be changed with glfwSetWindowAttrib.\n\nGLFW_FOCUSED indicates whether the specified window has input focus. See Window input focus for details.\n\nGLFW_ICONIFIED indicates whether the specified window is iconified. See Window iconification for details.\n\nGLFW_MAXIMIZED indicates whether the specified window is maximized. See Window maximization for details.\n\nGLFW_HOVERED indicates whether the cursor is currently directly over the content area of the window, with no other windows between. See Cursor enter/leave events for details.\n\nGLFW_VISIBLE indicates whether the specified window is visible. See Window visibility for details.\n\nGLFW_RESIZABLE indicates whether the specified window is resizable by the user. This can be set before creation with the GLFW_RESIZABLE window hint or after with glfwSetWindowAttrib.\n\nGLFW_DECORATED indicates whether the specified window has decorations such as a border, a close widget, etc. This can be set before creation with the GLFW_DECORATED window hint or after with glfwSetWindowAttrib.\n\nGLFW_AUTO_ICONIFY indicates whether the specified full screen window is iconified on focus loss, a close widget, etc. This can be set before creation with the GLFW_AUTO_ICONIFY window hint or after with glfwSetWindowAttrib.\n\nGLFW_FLOATING indicates whether the specified window is floating, also called topmost or always-on-top. This can be set before creation with the GLFW_FLOATING window hint or after with glfwSetWindowAttrib.\n\nGLFW_TRANSPARENT_FRAMEBUFFER indicates whether the specified window has a transparent framebuffer, i.e. the window contents is composited with the background using the window framebuffer alpha channel. See Window transparency for details.\n\nGLFW_FOCUS_ON_SHOW specifies whether the window will be given input focus when glfwShowWindow is called. This can be set before creation with the GLFW_FOCUS_ON_SHOW window hint or after with glfwSetWindowAttrib.\n\nGLFW_CLIENT_API indicates the client API provided by the window's context; either , or .\n\nGLFW_CONTEXT_CREATION_API indicates the context creation API used to create the window's context; either , or .\n\nGLFW_CONTEXT_VERSION_MAJOR, GLFW_CONTEXT_VERSION_MINOR and GLFW_CONTEXT_REVISION indicate the client API version of the window's context.\n\nGLFW_OPENGL_FORWARD_COMPAT is if the window's context is an OpenGL forward-compatible one, or otherwise.\n\nGLFW_OPENGL_DEBUG_CONTEXT is if the window's context is in debug mode, or otherwise.\n\nGLFW_OPENGL_PROFILE indicates the OpenGL profile used by the context. This is or if the context uses a known profile, or if the OpenGL profile is unknown or the context is an OpenGL ES context. Note that the returned profile may not match the profile bits of the context flags, as GLFW will try other means of detecting the profile when no bits are set.\n\nGLFW_CONTEXT_RELEASE_BEHAVIOR indicates the release used by the context. Possible values are one of , or . If the behavior is , the default behavior of the context creation API will be used. If the behavior is , the pipeline will be flushed whenever the context is released from being the current one. If the behavior is , the pipeline will not be flushed on release.\n\nGLFW_CONTEXT_NO_ERROR indicates whether errors are generated by the context. Possible values are and . If enabled, situations that would have generated errors instead cause undefined behavior.\n\nGLFW_CONTEXT_ROBUSTNESS indicates the robustness strategy used by the context. This is or if the window's context supports robustness, or otherwise.\n\nGLFW does not expose attributes of the default framebuffer (i.e. the framebuffer attached to the window) as these can be queried directly with either OpenGL, OpenGL ES or Vulkan.\n\nIf you are using version 3.0 or later of OpenGL or OpenGL ES, the function can be used to retrieve the number of bits for the red, green, blue, alpha, depth and stencil buffer channels. Otherwise, the function can be used.\n\nThe number of MSAA samples are always retrieved with . For contexts supporting framebuffer objects, the number of samples of the currently bound framebuffer is returned.\n\nWhen calling , the red, green, blue and alpha sizes are queried from the , while the depth and stencil sizes are queried from the and attachments, respectively.\n\nGLFW windows are by default double buffered. That means that you have two rendering buffers; a front buffer and a back buffer. The front buffer is the one being displayed and the back buffer the one you render to.\n\nWhen the entire frame has been rendered, it is time to swap the back and the front buffers in order to display what has been rendered and begin rendering a new frame. This is done with glfwSwapBuffers.\n\nSometimes it can be useful to select when the buffer swap will occur. With the function glfwSwapInterval it is possible to select the minimum number of monitor refreshes the driver should wait from the time glfwSwapBuffers was called before swapping the buffers:\n\nIf the interval is zero, the swap will take place immediately when glfwSwapBuffers is called without waiting for a refresh. Otherwise at least interval retraces will pass between each buffer swap. Using a swap interval of zero can be useful for benchmarking purposes, when it is not desirable to measure the time it takes to wait for the vertical retrace. However, a swap interval of one lets you avoid tearing.\n\nNote that this may not work on all machines, as some drivers have user-controlled settings that override any swap interval the application requests.\n\nA context that supports either the or the extension also accepts negative swap intervals, which allows the driver to swap immediately even if a frame arrives a little bit late. This trades the risk of visible tears for greater framerate stability. You can check for these extensions with glfwExtensionSupported."
    },
    {
        "link": "https://glfw.org/docs/3.3/intro_guide.html",
        "document": "This guide introduces the basic concepts of GLFW and describes initialization, error handling and API guarantees and limitations. For a broad but shallow tutorial, see Getting started instead. For details on a specific function in this category, see the Initialization, version and error reference.\n\nThere are also guides for the other areas of GLFW.\n\nBefore most GLFW functions may be called, the library must be initialized. This initialization checks what features are available on the machine, enumerates monitors and joysticks, initializes the timer and performs any required platform-specific initialization.\n\nOnly the following functions may be called before the library has been successfully initialized, and only from the main thread.\n\nCalling any other function before successful initialization will cause a GLFW_NOT_INITIALIZED error.\n\nThe library is initialized with glfwInit, which returns if an error occurred.\n\nIf any part of initialization fails, any parts that succeeded are terminated as if glfwTerminate had been called. The library only needs to be initialized once and additional calls to an already initialized library will return immediately.\n\nOnce the library has been successfully initialized, it should be terminated before the application exits. Modern systems are very good at freeing resources allocated by programs that exit, but GLFW sometimes has to change global system settings and these might not be restored without termination.\n\nInitialization hints are set before glfwInit and affect how the library behaves until termination. Hints are set with glfwInitHint.\n\nThe values you set hints to are never reset by GLFW, but they only take effect during initialization. Once GLFW has been initialized, any values you set will be ignored until the library is terminated and initialized again.\n\nSome hints are platform specific. These may be set on any platform but they will only affect their specific platform. Other platforms will ignore them. Setting these hints requires no platform specific headers or functions.\n\nGLFW_JOYSTICK_HAT_BUTTONS specifies whether to also expose joystick hats as buttons, for compatibility with earlier versions of GLFW that did not have glfwGetJoystickHats. Possible values are and .\n\nGLFW_COCOA_CHDIR_RESOURCES specifies whether to set the current directory to the application to the subdirectory of the application's bundle, if present. Set this with glfwInitHint.\n\nGLFW_COCOA_MENUBAR specifies whether to create a basic menu bar, either from a nib or manually, when the first window is created, which is when AppKit is initialized. Set this with glfwInitHint.\n\nGLFW_WAYLAND_LIBDECOR specifies whether to use libdecor for window decorations where available. Possible values are and . This is ignored on other platforms.\n\nBefore your application exits, you should terminate the GLFW library if it has been initialized. This is done with glfwTerminate.\n\nThis will destroy any remaining window, monitor and cursor objects, restore any modified gamma ramps, re-enable the screensaver if it had been disabled and free any other resources allocated by GLFW.\n\nOnce the library is terminated, it is as if it had never been initialized, therefore you will need to initialize it again before being able to use GLFW. If the library was not initialized or had already been terminated, it returns immediately.\n\nSome GLFW functions have return values that indicate an error, but this is often not very helpful when trying to figure out what happened or why it occurred. Other functions have no return value reserved for errors, so error notification needs a separate channel. Finally, far from all GLFW functions have return values.\n\nThe last error code for the calling thread can be queried at any time with glfwGetError.\n\nIf no error has occurred since the last call, GLFW_NO_ERROR (zero) is returned. The error is cleared before the function returns.\n\nThe error code indicates the general category of the error. Some error codes, such as GLFW_NOT_INITIALIZED has only a single meaning, whereas others like GLFW_PLATFORM_ERROR are used for many different errors.\n\nGLFW often has more information about an error than its general category. You can retrieve a UTF-8 encoded human-readable description along with the error code. If no error has occurred since the last call, the description is set to .\n\nThe retrieved description string is only valid until the next error occurs. This means you must make a copy of it if you want to keep it.\n\nYou can also set an error callback, which will be called each time an error occurs. It is set with glfwSetErrorCallback.\n\nThe error callback receives the same error code and human-readable description returned by glfwGetError.\n\nThe error callback is called after the error is stored, so calling glfwGetError from within the error callback returns the same values as the callback argument.\n\nThe description string passed to the callback is only valid until the error callback returns. This means you must make a copy of it if you want to keep it.\n\nReported errors are never fatal. As long as GLFW was successfully initialized, it will remain initialized and in a safe state until terminated regardless of how many errors occur. If an error occurs during initialization that causes glfwInit to fail, any part of the library that was initialized will be safely terminated.\n\nDo not rely on a currently invalid call to generate a specific error, as in the future that same call may generate a different error or become valid.\n\nGLFW has two primary coordinate systems: the virtual screen and the window content area or content area. Both use the same unit: virtual screen coordinates, or just screen coordinates, which don't necessarily correspond to pixels.\n\nBoth the virtual screen and the content area coordinate systems have the X-axis pointing to the right and the Y-axis pointing down.\n\nWindow and monitor positions are specified as the position of the upper-left corners of their content areas relative to the virtual screen, while cursor positions are specified relative to a window's content area.\n\nBecause the origin of the window's content area coordinate system is also the point from which the window position is specified, you can translate content area coordinates to the virtual screen by adding the window position. The window frame, when present, extends out from the content area but does not affect the window position.\n\nAlmost all positions and sizes in GLFW are measured in screen coordinates relative to one of the two origins above. This includes cursor positions, window positions and sizes, window frame sizes, monitor positions and video mode resolutions.\n\nTwo exceptions are the monitor physical size, which is measured in millimetres, and framebuffer size, which is measured in pixels.\n\nPixels and screen coordinates may map 1:1 on your machine, but they won't on every other machine, for example on a Mac with a Retina display. The ratio between screen coordinates and pixels may also change at run-time depending on which monitor the window is currently considered to be on.\n\nThis section describes the conditions under which GLFW can be expected to function, barring bugs in the operating system or drivers. Use of GLFW outside these limits may work on some platforms, or on some machines, or some of the time, or on some versions of GLFW, but it may break at any time and this will not be considered a bug.\n\nGLFW will never free any pointer you provide to it, and you must never free any pointer it provides to you.\n\nMany GLFW functions return pointers to dynamically allocated structures, strings or arrays, and some callbacks are provided with strings or arrays. These are always managed by GLFW and should never be freed by the application. The lifetime of these pointers is documented for each GLFW function and callback. If you need to keep this data, you must copy it before its lifetime expires.\n\nMany GLFW functions accept pointers to structures or strings allocated by the application. These are never freed by GLFW and are always the responsibility of the application. If GLFW needs to keep the data in these structures or strings, it is copied before the function returns.\n\nPointer lifetimes are guaranteed not to be shortened in future minor or patch releases.\n\nGLFW event processing and object destruction are not reentrant. This means that the following functions must not be called from any callback function:\n\nThese functions may be made reentrant in future minor or patch releases, but functions not on this list will not be made non-reentrant.\n\nMost GLFW functions must only be called from the main thread (the thread that calls main), but some may be called from any thread once the library has been initialized. Before initialization the whole library is thread-unsafe.\n\nThe reference documentation for every GLFW function states whether it is limited to the main thread.\n\nInitialization, termination, event processing and the creation and destruction of windows, cursors and OpenGL and OpenGL ES contexts are all restricted to the main thread due to limitations of one or several platforms.\n\nBecause event processing must be performed on the main thread, all callbacks except for the error callback will only be called on that thread. The error callback may be called on any thread, as any GLFW function may generate errors.\n\nThe error code and description may be queried from any thread.\n\nEmpty events may be posted from any thread.\n\nThe window user pointer and close flag may be read and written from any thread, but this is not synchronized by GLFW.\n\nThese functions for working with OpenGL and OpenGL ES contexts may be called from any thread, but the window object is not synchronized by GLFW.\n\nThe raw timer functions may be called from any thread.\n\nThe regular timer may be used from any thread, but reading and writing the timer offset is not synchronized by GLFW.\n\nLibrary version information may be queried from any thread.\n\nAll Vulkan related functions may be called from any thread.\n\nGLFW uses synchronization objects internally only to manage the per-thread context and error states. Additional synchronization is left to the application.\n\nFunctions that may currently be called from any thread will always remain so, but functions that are currently limited to the main thread may be updated to allow calls from any thread in future releases.\n\nGLFW uses Semantic Versioning. This guarantees source and binary backward compatibility with earlier minor versions of the API. This means that you can drop in a newer version of the library and existing programs will continue to compile and existing binaries will continue to run.\n\nOnce a function or constant has been added, the signature of that function or value of that constant will remain unchanged until the next major version of GLFW. No compatibility of any kind is guaranteed between major versions.\n\nUndocumented behavior, i.e. behavior that is not described in the documentation, may change at any time until it is documented.\n\nIf the reference documentation and the implementation differ, the reference documentation will almost always take precedence and the implementation will be fixed in the next release. The reference documentation will also take precedence over anything stated in a guide.\n\nThe order of arrival of related events is not guaranteed to be consistent across platforms. The exception is synthetic key and mouse button release events, which are always delivered after the window defocus event.\n\nGLFW provides mechanisms for identifying what version of GLFW your application was compiled against as well as what version it is currently running against. If you are loading GLFW dynamically (not just linking dynamically), you can use this to verify that the library binary is compatible with your application.\n\nThe compile-time version of GLFW is provided by the GLFW header with the , and macros.\n\nThe run-time version can be retrieved with glfwGetVersion, a function that may be called regardless of whether GLFW is initialized.\n\nGLFW 3 also provides a compile-time generated version string that describes the version, platform, compiler and any platform-specific compile-time options. This is primarily intended for submitting bug reports, to allow developers to see which code paths are enabled in a binary.\n\nThe version string is returned by glfwGetVersionString, a function that may be called regardless of whether GLFW is initialized.\n\nDo not use the version string to parse the GLFW library version. The glfwGetVersion function already provides the version of the running library binary.\n\nThe format of the string is as follows:\n• The name of the window system API\n• The name of the context creation API\n\nFor example, when compiling GLFW 3.3.9 with MinGW for Windows, may result in a version string like this:"
    },
    {
        "link": "https://glfw.org/docs/latest/window_guide.html",
        "document": "This guide introduces the window related functions of GLFW. For details on a specific function in this category, see the Window reference. There are also guides for the other areas of GLFW.\n\nThe GLFWwindow object encapsulates both a window and a context. They are created with glfwCreateWindow and destroyed with glfwDestroyWindow, or glfwTerminate, if any remain. As the window and context are inseparably linked, the object pointer is used as both a context and window handle.\n\nTo see the event stream provided to the various window related callbacks, run the test program.\n\nA window and its OpenGL or OpenGL ES context are created with glfwCreateWindow, which returns a handle to the created window object. For example, this creates a 640 by 480 windowed mode window:\n\nIf window creation fails, will be returned, so it is necessary to check the return value.\n\nThe window handle is passed to all window related functions and is provided to along with all input events, so event handlers can tell which window received the event.\n\nTo create a full screen window, you need to specify which monitor the window should use. In most cases, the user's primary monitor is a good choice. For more information about retrieving monitors, see Retrieving monitors.\n\nFull screen windows cover the entire display area of a monitor, have no border or decorations.\n\nWindowed mode windows can be made full screen by setting a monitor with glfwSetWindowMonitor, and full screen ones can be made windowed by unsetting it with the same function.\n\nEach field of the GLFWvidmode structure corresponds to a function parameter or window hint and combine to form the desired video mode for that window. The supported video mode most closely matching the desired video mode will be set for the chosen monitor as long as the window has input focus. For more information about retrieving video modes, see Video modes.\n\nOnce you have a full screen window, you can change its resolution, refresh rate and monitor with glfwSetWindowMonitor. If you only need change its resolution you can also call glfwSetWindowSize. In all cases, the new video mode will be selected the same way as the video mode chosen by glfwCreateWindow. If the window has an OpenGL or OpenGL ES context, it will be unaffected.\n\nBy default, the original video mode of the monitor will be restored and the window iconified if it loses input focus, to allow the user to switch back to the desktop. This behavior can be disabled with the GLFW_AUTO_ICONIFY window hint, for example if you wish to simultaneously cover multiple monitors with full screen windows.\n\nIf a monitor is disconnected, all windows that are full screen on that monitor will be switched to windowed mode. See Monitor configuration changes for more information.\n\nIf the closest match for the desired video mode is the current one, the video mode will not be changed, making window creation faster and application switching much smoother. This is sometimes called windowed full screen or borderless full screen window and counts as a full screen window. To create such a window, request the current video mode.\n\nThis also works for windowed mode windows that are made full screen.\n\nNote that glfwGetVideoMode returns the current video mode of a monitor, so if you already have a full screen window on that monitor that you want to make windowed full screen, you need to have saved the desktop resolution before.\n\nWhen a window is no longer needed, destroy it with glfwDestroyWindow.\n\nWindow destruction always succeeds. Before the actual destruction, all callbacks are removed so no further events will be delivered for the window. All windows remaining when glfwTerminate is called are destroyed as well.\n\nWhen a full screen window is destroyed, the original video mode of its monitor is restored, but the gamma ramp is left untouched.\n\nThere are a number of hints that can be set before the creation of a window and context. Some affect the window itself, others affect the framebuffer or context. These hints are set to their default values each time the library is initialized with glfwInit. Integer value hints can be set individually with glfwWindowHint and string value hints with glfwWindowHintString. You can reset all at once to their defaults with glfwDefaultWindowHints.\n\nSome hints are platform specific. These are always valid to set on any platform but they will only affect their specific platform. Other platforms will ignore them. Setting these hints requires no platform specific headers or calls.\n\nSome window hints are hard constraints. These must match the available capabilities exactly for window and context creation to succeed. Hints that are not hard constraints are matched as closely as possible, but the resulting context and framebuffer may differ from what these hints requested.\n\nThe following hints are always hard constraints:\n\nThe following additional hints are hard constraints when requesting an OpenGL context, but are ignored when requesting an OpenGL ES context:\n\nGLFW_RESIZABLE specifies whether the windowed mode window will be resizable by the user. The window will still be resizable using the glfwSetWindowSize function. Possible values are and . This hint is ignored for full screen and undecorated windows.\n\nGLFW_VISIBLE specifies whether the windowed mode window will be initially visible. Possible values are and . This hint is ignored for full screen windows.\n\nGLFW_DECORATED specifies whether the windowed mode window will have window decorations such as a border, a close widget, etc. An undecorated window will not be resizable by the user but will still allow the user to generate close events on some platforms. Possible values are and . This hint is ignored for full screen windows.\n\nGLFW_FOCUSED specifies whether the windowed mode window will be given input focus when created. Possible values are and . This hint is ignored for full screen and initially hidden windows.\n\nGLFW_AUTO_ICONIFY specifies whether the full screen window will automatically iconify and restore the previous video mode on input focus loss. Possible values are and . This hint is ignored for windowed mode windows.\n\nGLFW_FLOATING specifies whether the windowed mode window will be floating above other regular windows, also called topmost or always-on-top. This is intended primarily for debugging purposes and cannot be used to implement proper full screen windows. Possible values are and . This hint is ignored for full screen windows.\n\nGLFW_MAXIMIZED specifies whether the windowed mode window will be maximized when created. Possible values are and . This hint is ignored for full screen windows.\n\nGLFW_CENTER_CURSOR specifies whether the cursor should be centered over newly created full screen windows. Possible values are and . This hint is ignored for windowed mode windows.\n\nGLFW_TRANSPARENT_FRAMEBUFFER specifies whether the window framebuffer will be transparent. If enabled and supported by the system, the window framebuffer alpha channel will be used to combine the framebuffer with the background. This does not affect window decorations. Possible values are and .\n\nGLFW_FOCUS_ON_SHOW specifies whether the window will be given input focus when glfwShowWindow is called. Possible values are and .\n\nGLFW_SCALE_TO_MONITOR specified whether the window content area should be resized based on content scale changes. This can be because of a global user settings change or because the window was moved to a monitor with different scale settings.\n\nThis hint only has an effect on platforms where screen coordinates and pixels always map 1:1, such as Windows and X11. On platforms like macOS the resolution of the framebuffer can change independently of the window size.\n\nGLFW_SCALE_FRAMEBUFFER specifies whether the framebuffer should be resized based on content scale changes. This can be because of a global user settings change or because the window was moved to a monitor with different scale settings.\n\nThis hint only has an effect on platforms where screen coordinates can be scaled relative to pixel coordinates, such as macOS and Wayland. On platforms like Windows and X11 the framebuffer and window content area sizes always map 1:1.\n\nThis is the new name, introduced in GLFW 3.4. The older name is also available for compatibility. Both names modify the same hint value.\n\nGLFW_MOUSE_PASSTHROUGH specifies whether the window is transparent to mouse input, letting any mouse events pass through to whatever window is behind it. This is only supported for undecorated windows. Decorated windows with this enabled will behave differently between platforms. Possible values are and .\n\nGLFW_POSITION_X and GLFW_POSITION_Y specify the desired initial position of the window. The window manager may modify or ignore these coordinates. If either or both of these hints are set to then the window manager will position the window where it thinks the user will prefer it. Possible values are any valid screen coordinates and .\n\nGLFW_RED_BITS, GLFW_GREEN_BITS, GLFW_BLUE_BITS, GLFW_ALPHA_BITS, GLFW_DEPTH_BITS and GLFW_STENCIL_BITS specify the desired bit depths of the various components of the default framebuffer. A value of means the application has no preference.\n\nGLFW_ACCUM_RED_BITS, GLFW_ACCUM_GREEN_BITS, GLFW_ACCUM_BLUE_BITS and GLFW_ACCUM_ALPHA_BITS specify the desired bit depths of the various components of the accumulation buffer. A value of means the application has no preference.\n\nAccumulation buffers are a legacy OpenGL feature and should not be used in new code.\n\nGLFW_AUX_BUFFERS specifies the desired number of auxiliary buffers. A value of means the application has no preference.\n\nAuxiliary buffers are a legacy OpenGL feature and should not be used in new code.\n\nGLFW_STEREO specifies whether to use OpenGL stereoscopic rendering. Possible values are and . This is a hard constraint.\n\nGLFW_SAMPLES specifies the desired number of samples to use for multisampling. Zero disables multisampling. A value of means the application has no preference.\n\nGLFW_SRGB_CAPABLE specifies whether the framebuffer should be sRGB capable. Possible values are and .\n\nGLFW_DOUBLEBUFFER specifies whether the framebuffer should be double buffered. You nearly always want to use double buffering. This is a hard constraint. Possible values are and .\n\nGLFW_REFRESH_RATE specifies the desired refresh rate for full screen windows. A value of means the highest available refresh rate will be used. This hint is ignored for windowed mode windows.\n\nGLFW_CLIENT_API specifies which client API to create the context for. Possible values are , and . This is a hard constraint.\n\nGLFW_CONTEXT_CREATION_API specifies which context creation API to use to create the context. Possible values are , and . This is a hard constraint. If no client API is requested, this hint is ignored.\n\nAn extension loader library that assumes it knows which API was used to create the current context may fail if you change this hint. This can be resolved by having it load functions via glfwGetProcAddress.\n\nGLFW_CONTEXT_VERSION_MAJOR and GLFW_CONTEXT_VERSION_MINOR specify the client API version that the created context must be compatible with. The exact behavior of these hints depend on the requested client API.\n\nWhile there is no way to ask the driver for a context of the highest supported version, GLFW will attempt to provide this when you ask for a version 1.0 context, which is the default for these hints.\n\nDo not confuse these hints with GLFW_VERSION_MAJOR and GLFW_VERSION_MINOR, which provide the API version of the GLFW header.\n\nGLFW_OPENGL_FORWARD_COMPAT specifies whether the OpenGL context should be forward-compatible, i.e. one where all functionality deprecated in the requested version of OpenGL is removed. This must only be used if the requested OpenGL version is 3.0 or above. If OpenGL ES is requested, this hint is ignored.\n\nForward-compatibility is described in detail in the OpenGL Reference Manual.\n\nGLFW_CONTEXT_DEBUG specifies whether the context should be created in debug mode, which may provide additional error and diagnostic reporting functionality. Possible values are and .\n\nDebug contexts for OpenGL and OpenGL ES are described in detail by the GL_KHR_debug extension.\n\nGLFW_OPENGL_PROFILE specifies which OpenGL profile to create the context for. Possible values are one of or , or to not request a specific profile. If requesting an OpenGL version below 3.2, must be used. If OpenGL ES is requested, this hint is ignored.\n\nOpenGL profiles are described in detail in the OpenGL Reference Manual.\n\nGLFW_CONTEXT_ROBUSTNESS specifies the robustness strategy to be used by the context. This can be one of or , or to not request a robustness strategy.\n\nGLFW_CONTEXT_RELEASE_BEHAVIOR specifies the release behavior to be used by the context. Possible values are one of , or . If the behavior is , the default behavior of the context creation API will be used. If the behavior is , the pipeline will be flushed whenever the context is released from being the current one. If the behavior is , the pipeline will not be flushed on release.\n\nContext release behaviors are described in detail by the GL_KHR_context_flush_control extension.\n\nGLFW_CONTEXT_NO_ERROR specifies whether errors should be generated by the context. Possible values are and . If enabled, situations that would have generated errors instead cause undefined behavior.\n\nThe no error mode for OpenGL and OpenGL ES is described in detail by the GL_KHR_no_error extension.\n\nGLFW_WIN32_KEYBOARD_MENU specifies whether to allow access to the window menu via the Alt+Space and Alt-and-then-Space keyboard shortcuts. This is ignored on other platforms.\n\nGLFW_WIN32_SHOWDEFAULT specifies whether to show the window the way specified in the program's when it is shown for the first time. This is the same information as the option in the shortcut properties window. If this information was not specified when the program was started, GLFW behaves as if this hint was set to . Possible values are and . This is ignored on other platforms.\n\nGLFW_COCOA_FRAME_NAME specifies the UTF-8 encoded name to use for autosaving the window frame, or if empty disables frame autosaving for the window. This is ignored on other platforms. This is set with glfwWindowHintString.\n\nGLFW_COCOA_GRAPHICS_SWITCHING specifies whether to in Automatic Graphics Switching, i.e. to allow the system to choose the integrated GPU for the OpenGL context and move it between GPUs if necessary or whether to force it to always run on the discrete GPU. This only affects systems with both integrated and discrete GPUs. Possible values are and . This is ignored on other platforms.\n\nSimpler programs and tools may want to enable this to save power, while games and other applications performing advanced rendering will want to leave it disabled.\n\nA bundled application that wishes to participate in Automatic Graphics Switching should also declare this in its by setting the key to .\n\nGLFW_WAYLAND_APP_ID specifies the Wayland app_id for a window, used by window managers to identify types of windows. This is set with glfwWindowHintString.\n\nGLFW_X11_CLASS_NAME and GLFW_X11_INSTANCE_NAME specifies the desired ASCII encoded class and instance parts of the ICCCM window property. Both hints need to be set to something other than an empty string for them to take effect. These are set with glfwWindowHintString.\n\nEach window has a user pointer that can be set with glfwSetWindowUserPointer and queried with glfwGetWindowUserPointer. This can be used for any purpose you need and will not be modified by GLFW throughout the life-time of the window.\n\nThe initial value of the pointer is .\n\nWhen the user attempts to close the window, for example by clicking the close widget or using a key chord like Alt+F4, the close flag of the window is set. The window is however not actually destroyed and, unless you watch for this state change, nothing further happens.\n\nThe current state of the close flag is returned by glfwWindowShouldClose and can be set or cleared directly with glfwSetWindowShouldClose. A common pattern is to use the close flag as a main loop condition.\n\nIf you wish to be notified when the user attempts to close a window, set a close callback.\n\nThe callback function is called directly after the close flag has been set. It can be used for example to filter close requests and clear the close flag again unless certain conditions are met.\n\nThe size of a window can be changed with glfwSetWindowSize. For windowed mode windows, this sets the size, in screen coordinates of the content area or content area of the window. The window system may impose limits on window size.\n\nFor full screen windows, the specified size becomes the new resolution of the window's desired video mode. The video mode most closely matching the new desired video mode is set immediately. The window is resized to fit the resolution of the set video mode.\n\nIf you wish to be notified when a window is resized, whether by the user, the system or your own code, set a size callback.\n\nThe callback function receives the new size, in screen coordinates, of the content area of the window when the window is resized.\n\nThere is also glfwGetWindowSize for directly retrieving the current size of a window.\n\nThe above functions work with the size of the content area, but decorated windows typically have title bars and window frames around this rectangle. You can retrieve the extents of these with glfwGetWindowFrameSize.\n\nThe returned values are the distances, in screen coordinates, from the edges of the content area to the corresponding edges of the full window. As they are distances and not coordinates, they are always zero or positive.\n\nWhile the size of a window is measured in screen coordinates, OpenGL works with pixels. The size you pass into , for example, should be in pixels. On some machines screen coordinates and pixels are the same, but on others they will not be. There is a second set of functions to retrieve the size, in pixels, of the framebuffer of a window.\n\nIf you wish to be notified when the framebuffer of a window is resized, whether by the user or the system, set a size callback.\n\nThe callback function receives the new size of the framebuffer when it is resized, which can for example be used to update the OpenGL viewport.\n\nThere is also glfwGetFramebufferSize for directly retrieving the current size of the framebuffer of a window.\n\nThe size of a framebuffer may change independently of the size of a window, for example if the window is dragged between a regular monitor and a high-DPI one.\n\nThe content scale for a window can be retrieved with glfwGetWindowContentScale.\n\nThe content scale can be thought of as the ratio between the current DPI and the platform's default DPI. It is intended to be a scaling factor to apply to the pixel dimensions of text and other UI elements. If the dimensions scaled by this factor looks appropriate on your machine then it should appear at a reasonable size on other machines with different DPI and scaling settings.\n\nThis relies on the DPI and scaling settings on both machines being appropriate.\n\nThe content scale may depend on both the monitor resolution and pixel density and on user settings like DPI or a scaling percentage. It may be very different from the raw DPI calculated from the physical size and current resolution.\n\nOn systems where each monitors can have its own content scale, the window content scale will depend on which monitor or monitors the system considers the window to be \"on\".\n\nIf you wish to be notified when the content scale of a window changes, whether because of a system setting change or because it was moved to a monitor with a different scale, set a content scale callback.\n\nThe callback function receives the new content scale of the window.\n\nOn platforms where pixels and screen coordinates always map 1:1, the window will need to be resized to appear the same size when it is moved to a monitor with a different content scale. To have this done automatically both when the window is created and when its content scale later changes, set the GLFW_SCALE_TO_MONITOR window hint.\n\nOn platforms where pixels do not necessarily equal screen coordinates, the framebuffer will instead need to be sized to provide a full resolution image for the window. When the window moves between monitors with different content scales, the window size will remain the same but the framebuffer size will change. This is done automatically by default. To disable this resizing, set the GLFW_SCALE_FRAMEBUFFER window hint.\n\nBoth of these hints also apply when the window is created. Every window starts out with a content scale of one. A window with one or both of these hints set will adapt to the appropriate scale in the process of being created, set up and shown.\n\nThe minimum and maximum size of the content area of a windowed mode window can be enforced with glfwSetWindowSizeLimits. The user may resize the window to any size and aspect ratio within the specified limits, unless the aspect ratio is also set.\n\nTo specify only a minimum size or only a maximum one, set the other pair to .\n\nTo disable size limits for a window, set them all to .\n\nThe aspect ratio of the content area of a windowed mode window can be enforced with glfwSetWindowAspectRatio. The user may resize the window freely unless size limits are also set, but the size will be constrained to maintain the aspect ratio.\n\nThe aspect ratio is specified as a numerator and denominator, corresponding to the width and height, respectively. If you want a window to maintain its current aspect ratio, use its current size as the ratio.\n\nTo disable the aspect ratio limit for a window, set both terms to .\n\nYou can have both size limits and aspect ratio set for a window, but the results are undefined if they conflict.\n\nBy default, the window manager chooses the position of new windowed mode windows, based on its size and which monitor the user appears to be working on. This is most often the right choice. If you need to create a window at a specific position, you can set the desired position with the GLFW_POSITION_X and GLFW_POSITION_Y window hints.\n\nTo restore the previous behavior, set these hints to .\n\nThe position of a windowed mode window can be changed with glfwSetWindowPos. This moves the window so that the upper-left corner of its content area has the specified screen coordinates. The window system may put limitations on window placement.\n\nIf you wish to be notified when a window is moved, whether by the user, the system or your own code, set a position callback.\n\nThe callback function receives the new position, in screen coordinates, of the upper-left corner of the content area when the window is moved.\n\nThere is also glfwGetWindowPos for directly retrieving the current position of the content area of the window.\n\nAll GLFW windows have a title, although undecorated or full screen windows may not display it or only display it in a task bar or similar interface. You can set a new UTF-8 encoded window title with glfwSetWindowTitle.\n\nThe specified string is copied before the function returns, so there is no need to keep it around.\n\nAs long as your source file is encoded as UTF-8, you can use any Unicode characters directly in the source.\n\nIf you are using C++11 or C11, you can use a UTF-8 string literal.\n\nThe current window title can be queried with glfwGetWindowTitle.\n\nDecorated windows have icons on some platforms. You can set this icon by specifying a list of candidate images with glfwSetWindowIcon.\n\nThe image data is 32-bit, little-endian, non-premultiplied RGBA, i.e. eight bits per channel with the red channel first. The pixels are arranged canonically as sequential rows, starting from the top-left corner.\n\nTo revert to the default window icon, pass in an empty image array.\n\nFull screen windows are associated with a specific monitor. You can get the handle for this monitor with glfwGetWindowMonitor.\n\nThis monitor handle is one of those returned by glfwGetMonitors.\n\nFor windowed mode windows, this function returns . This is how to tell full screen windows from windowed mode windows.\n\nYou can move windows between monitors or between full screen and windowed mode with glfwSetWindowMonitor. When making a window full screen on the same or on a different monitor, specify the desired monitor, resolution and refresh rate. The position arguments are ignored.\n\nWhen making the window windowed, specify the desired position and size. The refresh rate argument is ignored.\n\nThis restores any previous window settings such as whether it is decorated, floating, resizable, has size or aspect ratio limits, etc.. To restore a window that was originally windowed to its original size and position, save these before making it full screen and then pass them in as above.\n\nWindows can be iconified (i.e. minimized) with glfwIconifyWindow.\n\nWhen a full screen window is iconified, the original video mode of its monitor is restored until the user or application restores the window.\n\nIconified windows can be restored with glfwRestoreWindow. This function also restores windows from maximization.\n\nWhen a full screen window is restored, the desired video mode is restored to its monitor as well.\n\nIf you wish to be notified when a window is iconified or restored, whether by the user, system or your own code, set an iconify callback.\n\nThe callback function receives changes in the iconification state of the window.\n\nYou can also get the current iconification state with glfwGetWindowAttrib.\n\nWindows can be maximized (i.e. zoomed) with glfwMaximizeWindow.\n\nFull screen windows cannot be maximized and passing a full screen window to this function does nothing.\n\nMaximized windows can be restored with glfwRestoreWindow. This function also restores windows from iconification.\n\nIf you wish to be notified when a window is maximized or restored, whether by the user, system or your own code, set a maximize callback.\n\nThe callback function receives changes in the maximization state of the window.\n\nYou can also get the current maximization state with glfwGetWindowAttrib.\n\nBy default, newly created windows are not maximized. You can change this behavior by setting the GLFW_MAXIMIZED window hint before creating the window.\n\nWindowed mode windows can be hidden with glfwHideWindow.\n\nThis makes the window completely invisible to the user, including removing it from the task bar, dock or window list. Full screen windows cannot be hidden and calling glfwHideWindow on a full screen window does nothing.\n\nHidden windows can be shown with glfwShowWindow.\n\nBy default, this function will also set the input focus to that window. Set the GLFW_FOCUS_ON_SHOW window hint to change this behavior for all newly created windows, or change the behavior for an existing window with glfwSetWindowAttrib.\n\nYou can also get the current visibility state with glfwGetWindowAttrib.\n\nBy default, newly created windows are visible. You can change this behavior by setting the GLFW_VISIBLE window hint before creating the window.\n\nWindows created hidden are completely invisible to the user until shown. This can be useful if you need to set up your window further before showing it, for example moving it to a specific location.\n\nWindows can be given input focus and brought to the front with glfwFocusWindow.\n\nKeep in mind that it can be very disruptive to the user when a window is forced to the top. For a less disruptive way of getting the user's attention, see attention requests.\n\nIf you wish to be notified when a window gains or loses input focus, whether by the user, system or your own code, set a focus callback.\n\nThe callback function receives changes in the input focus state of the window.\n\nYou can also get the current input focus state with glfwGetWindowAttrib.\n\nBy default, newly created windows are given input focus. You can change this behavior by setting the GLFW_FOCUSED window hint before creating the window.\n\nIf you wish to notify the user of an event without interrupting, you can request attention with glfwRequestWindowAttention.\n\nThe system will highlight the specified window, or on platforms where this is not supported, the application as a whole. Once the user has given it attention, the system will automatically end the request.\n\nIf you wish to be notified when the contents of a window is damaged and needs to be refreshed, set a window refresh callback.\n\nThe callback function is called when the contents of the window needs to be refreshed.\n\nGLFW supports two kinds of transparency for windows; framebuffer transparency and whole window transparency. A single window may not use both methods. The results of doing this are undefined.\n\nBoth methods require the platform to support it and not every version of every platform GLFW supports does this, so there are mechanisms to check whether the window really is transparent.\n\nWindow framebuffers can be made transparent on a per-pixel per-frame basis with the GLFW_TRANSPARENT_FRAMEBUFFER window hint.\n\nIf supported by the system, the window content area will be composited with the background using the framebuffer per-pixel alpha channel. This requires desktop compositing to be enabled on the system. It does not affect window decorations.\n\nYou can check whether the window framebuffer was successfully made transparent with the GLFW_TRANSPARENT_FRAMEBUFFER window attribute.\n\nGLFW comes with an example that enabled framebuffer transparency called .\n\nThe opacity of the whole window, including any decorations, can be set with glfwSetWindowOpacity.\n\nThe opacity (or alpha) value is a positive finite number between zero and one, where 0 (zero) is fully transparent and 1 (one) is fully opaque. The initial opacity value for newly created windows is 1.\n\nThe current opacity of a window can be queried with glfwGetWindowOpacity.\n\nIf the system does not support whole window transparency, this function always returns one.\n\nGLFW comes with a test program that lets you control whole window transparency at run-time called .\n\nIf you want to use either of these transparency methods to display a temporary overlay like for example a notification, the GLFW_FLOATING and GLFW_MOUSE_PASSTHROUGH window hints and attributes may be useful.\n\nWindows have a number of attributes that can be returned using glfwGetWindowAttrib. Some reflect state that may change as a result of user interaction, (e.g. whether it has input focus), while others reflect inherent properties of the window (e.g. what kind of border it has). Some are related to the window and others to its OpenGL or OpenGL ES context.\n\nThe GLFW_DECORATED, GLFW_RESIZABLE, GLFW_FLOATING, GLFW_AUTO_ICONIFY and GLFW_FOCUS_ON_SHOW window attributes can be changed with glfwSetWindowAttrib.\n\nGLFW_FOCUSED indicates whether the specified window has input focus. See Window input focus for details.\n\nGLFW_ICONIFIED indicates whether the specified window is iconified. See Window iconification for details.\n\nGLFW_MAXIMIZED indicates whether the specified window is maximized. See Window maximization for details.\n\nGLFW_HOVERED indicates whether the cursor is currently directly over the content area of the window, with no other windows between. See Cursor enter/leave events for details.\n\nGLFW_VISIBLE indicates whether the specified window is visible. See Window visibility for details.\n\nGLFW_RESIZABLE indicates whether the specified window is resizable by the user. This can be set before creation with the GLFW_RESIZABLE window hint or after with glfwSetWindowAttrib.\n\nGLFW_DECORATED indicates whether the specified window has decorations such as a border, a close widget, etc. This can be set before creation with the GLFW_DECORATED window hint or after with glfwSetWindowAttrib.\n\nGLFW_AUTO_ICONIFY indicates whether the specified full screen window is iconified on focus loss, a close widget, etc. This can be set before creation with the GLFW_AUTO_ICONIFY window hint or after with glfwSetWindowAttrib.\n\nGLFW_FLOATING indicates whether the specified window is floating, also called topmost or always-on-top. This can be set before creation with the GLFW_FLOATING window hint or after with glfwSetWindowAttrib.\n\nGLFW_TRANSPARENT_FRAMEBUFFER indicates whether the specified window has a transparent framebuffer, i.e. the window contents is composited with the background using the window framebuffer alpha channel. See Window transparency for details.\n\nGLFW_FOCUS_ON_SHOW specifies whether the window will be given input focus when glfwShowWindow is called. This can be set before creation with the GLFW_FOCUS_ON_SHOW window hint or after with glfwSetWindowAttrib.\n\nGLFW_MOUSE_PASSTHROUGH specifies whether the window is transparent to mouse input, letting any mouse events pass through to whatever window is behind it. This can be set before creation with the GLFW_MOUSE_PASSTHROUGH window hint or after with glfwSetWindowAttrib. This is only supported for undecorated windows. Decorated windows with this enabled will behave differently between platforms.\n\nGLFW_CLIENT_API indicates the client API provided by the window's context; either , or .\n\nGLFW_CONTEXT_CREATION_API indicates the context creation API used to create the window's context; either , or .\n\nGLFW_CONTEXT_VERSION_MAJOR, GLFW_CONTEXT_VERSION_MINOR and GLFW_CONTEXT_REVISION indicate the client API version of the window's context.\n\nGLFW_OPENGL_FORWARD_COMPAT is if the window's context is an OpenGL forward-compatible one, or otherwise.\n\nGLFW_CONTEXT_DEBUG is if the window's context is in debug mode, or otherwise.\n\nThis is the new name, introduced in GLFW 3.4. The older name is also available for compatibility.\n\nGLFW_OPENGL_PROFILE indicates the OpenGL profile used by the context. This is or if the context uses a known profile, or if the OpenGL profile is unknown or the context is an OpenGL ES context. Note that the returned profile may not match the profile bits of the context flags, as GLFW will try other means of detecting the profile when no bits are set.\n\nGLFW_CONTEXT_RELEASE_BEHAVIOR indicates the release used by the context. Possible values are one of , or . If the behavior is , the default behavior of the context creation API will be used. If the behavior is , the pipeline will be flushed whenever the context is released from being the current one. If the behavior is , the pipeline will not be flushed on release.\n\nGLFW_CONTEXT_NO_ERROR indicates whether errors are generated by the context. Possible values are and . If enabled, situations that would have generated errors instead cause undefined behavior.\n\nGLFW_CONTEXT_ROBUSTNESS indicates the robustness strategy used by the context. This is or if the window's context supports robustness, or otherwise.\n\nGLFW does not expose most attributes of the default framebuffer (i.e. the framebuffer attached to the window) as these can be queried directly with either OpenGL, OpenGL ES or Vulkan. The one exception is GLFW_DOUBLEBUFFER, as this is not provided by OpenGL ES.\n\nIf you are using version 3.0 or later of OpenGL or OpenGL ES, the function can be used to retrieve the number of bits for the red, green, blue, alpha, depth and stencil buffer channels. Otherwise, the function can be used.\n\nThe number of MSAA samples are always retrieved with . For contexts supporting framebuffer objects, the number of samples of the currently bound framebuffer is returned.\n\nWhen calling , the red, green, blue and alpha sizes are queried from the , while the depth and stencil sizes are queried from the and attachments, respectively.\n\nGLFW_DOUBLEBUFFER indicates whether the specified window is double-buffered when rendering with OpenGL or OpenGL ES. This can be set before creation with the GLFW_DOUBLEBUFFER window hint.\n\nGLFW windows are by default double buffered. That means that you have two rendering buffers; a front buffer and a back buffer. The front buffer is the one being displayed and the back buffer the one you render to.\n\nWhen the entire frame has been rendered, it is time to swap the back and the front buffers in order to display what has been rendered and begin rendering a new frame. This is done with glfwSwapBuffers.\n\nSometimes it can be useful to select when the buffer swap will occur. With the function glfwSwapInterval it is possible to select the minimum number of monitor refreshes the driver should wait from the time glfwSwapBuffers was called before swapping the buffers:\n\nIf the interval is zero, the swap will take place immediately when glfwSwapBuffers is called without waiting for a refresh. Otherwise at least interval retraces will pass between each buffer swap. Using a swap interval of zero can be useful for benchmarking purposes, when it is not desirable to measure the time it takes to wait for the vertical retrace. However, a swap interval of one lets you avoid tearing.\n\nNote that this may not work on all machines, as some drivers have user-controlled settings that override any swap interval the application requests.\n\nA context that supports either the or the extension also accepts negative swap intervals, which allows the driver to swap immediately even if a frame arrives a little bit late. This trades the risk of visible tears for greater framerate stability. You can check for these extensions with glfwExtensionSupported."
    },
    {
        "link": "https://learnopengl.com/Getting-started/Hello-Window",
        "document": "Let's see if we can get GLFW up and running. First, create a file and add the following includes to the top of your newly created file.\n\nNext, we create the function where we will instantiate the GLFW window:\n\nIn the main function we first initialize GLFW with , after which we can configure GLFW using . The first argument of tells us what option we want to configure, where we can select the option from a large enum of possible options prefixed with . The second argument is an integer that sets the value of our option. A list of all the possible options and its corresponding values can be found at GLFW's window handling documentation. If you try to run the application now and it gives a lot of undefined reference errors it means you didn't successfully link the GLFW library.\n\nSince the focus of this book is on OpenGL version 3.3 we'd like to tell GLFW that 3.3 is the OpenGL version we want to use. This way GLFW can make the proper arrangements when creating the OpenGL context. This ensures that when a user does not have the proper OpenGL version GLFW fails to run. We set the major and minor version both to . We also tell GLFW we want to explicitly use the core-profile. Telling GLFW we want to use the core-profile means we'll get access to a smaller subset of OpenGL features without backwards-compatible features we no longer need. Note that on Mac OS X you need to add to your initialization code for it to work.\n\nNext we're required to create a window object. This window object holds all the windowing data and is required by most of GLFW's other functions.\n\nThe function requires the window width and height as its first two arguments respectively. The third argument allows us to create a name for the window; for now we call it but you're allowed to name it however you like. We can ignore the last 2 parameters. The function returns a object that we'll later need for other GLFW operations. After that we tell GLFW to make the context of our window the main context on the current thread.\n\nIn the previous chapter we mentioned that GLAD manages function pointers for OpenGL so we want to initialize GLAD before we call any OpenGL function:\n\nWe pass GLAD the function to load the address of the OpenGL function pointers which is OS-specific. GLFW gives us that defines the correct function based on which OS we're compiling for.\n\nBefore we can start rendering we have to do one last thing. We have to tell OpenGL the size of the rendering window so OpenGL knows how we want to display the data and coordinates with respect to the window. We can set those dimensions via the function:\n\nThe first two parameters of set the location of the lower left corner of the window. The third and fourth parameter set the width and height of the rendering window in pixels, which we set equal to GLFW's window size.\n\nWe could actually set the viewport dimensions at values smaller than GLFW's dimensions; then all the OpenGL rendering would be displayed in a smaller window and we could for example display other elements outside the OpenGL viewport.\n\nHowever, the moment a user resizes the window the viewport should be adjusted as well. We can register a callback function on the window that gets called each time the window is resized. This resize callback function has the following prototype:\n\nThe framebuffer size function takes a as its first argument and two integers indicating the new window dimensions. Whenever the window changes in size, GLFW calls this function and fills in the proper arguments for you to process.\n\nWe do have to tell GLFW we want to call this function on every window resize by registering it:\n\nWhen the window is first displayed gets called as well with the resulting window dimensions. For retina displays and will end up significantly higher than the original input values.\n\nThere are many callbacks functions we can set to register our own functions. For example, we can make a callback function to process joystick input changes, process error messages etc. We register the callback functions after we've created the window and before the render loop is initiated.\n\nWe don't want the application to draw a single image and then immediately quit and close the window. We want the application to keep drawing images and handling user input until the program has been explicitly told to stop. For this reason we have to create a while loop, that we now call the , that keeps on running until we tell GLFW to stop. The following code shows a very simple render loop:\n\nThe function checks at the start of each loop iteration if GLFW has been instructed to close. If so, the function returns and the render loop stops running, after which we can close the application.\n\n The function checks if any events are triggered (like keyboard input or mouse movement events), updates the window state, and calls the corresponding functions (which we can register via callback methods). The will swap the color buffer (a large 2D buffer that contains color values for each pixel in GLFW's window) that is used to render to during this render iteration and show it as output to the screen.\n\nAs soon as we exit the render loop we would like to properly clean/delete all of GLFW's resources that were allocated. We can do this via the function that we call at the end of the function.\n\nThis will clean up all the resources and properly exit the application. Now try to compile your application and if everything went well you should see the following output:\n\nIf it's a very dull and boring black image, you did things right! If you didn't get the right image or you're confused as to how everything fits together, check the full source code here (and if it started flashing different colors, keep reading).\n\nIf you have issues compiling the application, first make sure all your linker options are set correctly and that you properly included the right directories in your IDE (as explained in the previous chapter). Also make sure your code is correct; you can verify it by comparing it with the full source code.\n\nWe also want to have some form of input control in GLFW and we can achieve this with several of GLFW's input functions. We'll be using GLFW's function that takes the window as input together with a key. The function returns whether this key is currently being pressed. We're creating a function to keep all input code organized:\n\nHere we check whether the user has pressed the escape key (if it's not pressed, returns ). If the user did press the escape key, we close GLFW by setting its property to using . The next condition check of the main loop will then fail and the application closes.\n\nWe then call every iteration of the render loop:\n\nThis gives us an easy way to check for specific key presses and react accordingly every . An iteration of the render loop is more commonly called a .\n\nWe want to place all the rendering commands in the render loop, since we want to execute all the rendering commands each iteration or frame of the loop. This would look a bit like this:\n\nJust to test if things actually work we want to clear the screen with a color of our choice. At the start of frame we want to clear the screen. Otherwise we would still see the results from the previous frame (this could be the effect you're looking for, but usually you don't). We can clear the screen's color buffer using where we pass in buffer bits to specify which buffer we would like to clear. The possible bits we can set are , and . Right now we only care about the color values so we only clear the color buffer.\n\nNote that we also specify the color to clear the screen with using . Whenever we call and clear the color buffer, the entire color buffer will be filled with the color as configured by . This will result in a dark green-blueish color.\n\nThe full source code of the application can be found here.\n\nSo right now we got everything ready to fill the render loop with lots of rendering calls, but that's for the next chapter. I think we've been rambling long enough here."
    },
    {
        "link": "https://glfw.org/docs/3.3",
        "document": "GLFW is a free, Open Source, multi-platform library for OpenGL, OpenGL ES and Vulkan application development. It provides a simple, platform-independent API for creating windows, contexts and surfaces, reading input, handling events, etc.\n\nRelease notes for version 3.3 list new features, caveats and deprecations.\n\nGetting started is a guide for users new to GLFW. It takes you through how to write a small but complete program.\n\nThere are guides for each section of the API:\n• Introduction to the API – initialization, error handling and high-level design\n• Window guide – creating and working with windows and framebuffers\n• Monitor guide – enumerating and working with monitors and video modes\n\nOnce you have written a program, see Compiling GLFW and Building applications.\n\nThe reference documentation provides more detailed information about specific functions.\n\nMoving from GLFW 2 to 3 explains what has changed and how to update existing code to use the new API.\n\nThere is a section on Guarantees and limitations for pointer lifetimes, reentrancy, thread safety, event order and backward and forward compatibility.\n\nThe FAQ answers many common questions about the design, implementation and use of GLFW.\n\nFinally, Standards conformance explains what APIs, standards and protocols GLFW uses and what happens when they are not present on a given machine.\n\nThis documentation was generated with Doxygen. The sources for it are available in both the source distribution and GitHub repository."
    },
    {
        "link": "https://vkguide.dev/docs/gpudriven/code_architecture",
        "document": "To find the code that implements all of the draw indirect improvements, it’s on the “engine” branch of the github repo. For a direct link, here it is: Repo\n\nThe codebase continues from where Chapter 5 left off, but a lot of improvements and abstractions were added to it. Everything in the “Extra” chapter is on here, and there are a few things that don’t have an article on Extra chapter.\n• Imgui support: Added imgui UI to the engine, can be found mostly on VulkanEngine class. Explained here\n• CVars.h/cpp: Implements a CVar system for some configuration variables. Explained in here. The implementation in here also has support for tweaking the variables in Imgui.\n• player_camera.h : Small camera system to be able to fly on the maps.\n• logger.h : Log system to have more nice info/error messages in the console.\n• vk_pushbuffer : Adds data into a buffer for use with dynamic descriptors.\n• vk_profiler : Adds a timing profiler to know how much each pass takes, also can display how many triangles are handled by the gpu. Connects to Imgui.\n• vk_engine_scenerender.cpp : Separates the draw and cull logic from the main vk_engine.cpp . Here it executes the culling and draw commands.\n• vk_scene : Contains the scene management for the draw indirect buffers and the different mesh passes.\n• material_system : New material system to allow for a given material to render in multiple mesh passes and abstracts pipelines and descriptors.\n• vk_shaders : shader compiling code. It uses spirv-reflect to automatically build Pipeline Layouts from the shaders and grab other info.\n• Asset System and baker: Coming from the one explained here. But it has support for more optimized mesh formats, and supports prefabs and materials. It can now load arbitrary GLTF files and FBX files. A prefab is a list of scenenodes, and gets converted into multiple renderable objects on load.\n• Compute Shaders : Logic for compute shaders was added into the main Vulkan Engine class. There is now a ComputePipelineBuilder and more features around memory synchronization.\n• Improved buffer handling: Uniform Buffers and Storage Buffers now have a few improvements with things like a Reallocate function for growing buffers. Mostly on vk_engine.cpp\n\nThe main engine render loop is similar to the one after the chapters, but a lot of things were added to it. First, the handling of renderable objects goes through vk_scene, and is loaded from prefabs.\n\nWhen the engine initializes, it loads some prefabs and spawns them into the world as MeshObjects, which it injects into the RenderScene that will then add the objects into the multiple mesh passes according to materials and configuration.\n\nThere are 3 mesh passes handled. Forward pass handles the “opaque” rendering of objects, Transparent handles the translucent objects, and draws after the opaque objects are finished. Then there is the Shadow pass that will render a sun shadow. MeshObjects will register into these 3 passes according to their setup. Opaque objects will be added to Forward and Shadow passes, while translucent objects will only register into the Transparent pass, as we don’t want the translucent objects to cast shadow.\n\nOnce the engine is loaded, and are called at the end of engine initialization. build_batches will process all the mesh passes and prepare their indirect draw commands. merge_meshes will grab the vertex buffers of each of the meshes registered with the RenderScene, and merge them into a huge vertex buffer. This allows us to bind the vertex buffer once per mesh pass and never touch it again.\n\nWith the initialization done, we go into the frame loop.\n\nAt the start of the frame loop, we flush the descriptor cache and frame deletion queue to make sure dynamic things are reset. Then it calls that will process the changes on object data and upload everything to the GPU. This is the main step that uploads the data processed in RenderScene to the GPU.\n\nOnce that is finished, we start preparing the data for the compute culling pass. is called for each of the mesh passes in the RenderScene, this will reset the gpu draw state to its “default” state, ready to then be written to by the cull compute shader.\n\nWhen the multiple ready_cull calls are finished, we execute a pipeline barrier to make sure that all the memory transfers are finished before the compute shaders begin execution.\n\nAfter that, culling is executed for the 3 passes. Forward and Transparent pass use the same settings as they are both culling from the main camera view, while shadow pass uses different logic.\n\nWith the compute shaders for the cull executed, we do another barrier on the GPU to make sure that the gpu finishes the execution of the compute shaders before starting the draw commands.\n\nWe then execute the draw commands themselves. First shadow_pass() executes, which renders the scene depth from the sun location into a depth texture. Then the forward pass executes, and begins by rendering all of the opaque meshes, and then following by rendering all of the transparent meshes.\n\nOnce the rendering ends, the depth buffer is converted into a depth pyramid, which is what will be used for the culling in the next frame.\n\nAlso we copy the rendered image into the swapchain to get it ready for presenting."
    },
    {
        "link": "https://zeux.io/2020/02/27/writing-an-efficient-vulkan-renderer",
        "document": "In 2018, I wrote an article “Writing an efficient Vulkan renderer” for GPU Zen 2 book, which was published in 2019. In this article I tried to aggregate as much information about Vulkan performance as I could - instead of trying to focus on one particular aspect or application, this is trying to cover a wide range of topics, give readers an understanding of the behavior of different APIs on real hardware and provide a range of options for each problem that needs to be solved.\n\nAt the time of publishing this article, the Kindle edition of the book is available for $2.99 on Amazon - that’s cheaper than a cup of coffee and it’s definitely worth your time and money. It contains many great articles about rendering effects and design.\n\nThis, however, is the full, free of charge copy of the article - hopefully it will help graphics programmers to understand and use Vulkan to the full of its ability. The article has been lightly edited to mention Vulkan 1.1/1.2 promotions where applicable - fortunately, not much has changed in the last two years for Vulkan performance, so the content should still be mostly accurate.\n\nVulkan is a new explicit cross-platform graphics API. It introduces many new concepts that may be unfamiliar to even seasoned graphics programmers. The key goal of Vulkan is performance – however, attaining good performance requires in-depth knowledge about these concepts and how to apply them efficiently, as well as how particular driver implementations implement these. This article will explore topics such as memory allocation, descriptor set management, command buffer recording, pipeline barriers, render passes and discuss ways to optimize CPU and GPU performance of production desktop/mobile Vulkan renderers today as well as look at what a future looking Vulkan renderer could do differently.\n\nModern renderers are becoming increasingly complex and must support many different graphics APIs with varying levels of hardware abstraction and disjoint sets of concepts. This sometimes makes it challenging to support all platforms at the same level of efficiency. Fortunately, for most tasks Vulkan provides multiple options that can be as simple as reimplementing concepts from other APIs with higher efficiency due to targeting the code specifically towards the renderer needs, and as hard as redesigning large systems to make them optimal for Vulkan. We will try to cover both extremes when applicable – ultimately, this is a tradeoff between maximum efficiency on Vulkan-capable systems and implementation and maintenance costs that every engine needs to carefully pick. Additionally, efficiency is often application-dependent – the guidance in this article is generic and ultimately best performance is achieved by profiling the target application on a target platform and making an informed implementation decision based on the results.\n\nThis article assumes that the reader is familiar with the basics of Vulkan API, and would like to understand them better and/or learn how to use the API efficiently.\n\nMemory management remains an exceedingly complex topic, and in Vulkan it gets even more so due to the diversity of heap configurations on different hardware. Earlier APIs adopted a resource-centric concept – the programmer doesn’t have a concept of graphics memory, only that of a graphics resource, and different drivers are free to manage the resource memory based on API usage flags and a set of heuristics. Vulkan, however, forces to think about memory management up front, as you must manually allocate memory to create resources.\n\nA perfectly reasonable first step is to integrate (henceforth abbreviated as VMA), which is an open-source library developed by AMD that solves some memory management details for you by providing a general purpose resource allocator on top of Vulkan functions. Even if you do use that library, there are still multiple performance considerations that apply; the rest of this section will go over memory caveats without assuming you use VMA; all of the guidance applies equally to VMA.\n\nWhen creating a resource in Vulkan, you have to choose a heap to allocate memory from. Vulkan device exposes a set of memory types where each memory type has flags that define the behavior of that memory, and a heap index that defines the available size.\n\nMost Vulkan implementations expose two or three of the following flag combinations:\n• – this is generally referring to GPU memory that is not directly visible from CPU; it’s fastest to access from the GPU and this is the memory you should be using to store all render targets, GPU-only resources such as buffers for compute, and also all static resources such as textures and geometry buffers.\n• – on AMD hardware, this memory type refers to up to 256 MB of video memory that the CPU can write to directly, and is perfect for allocating reasonable amounts of data that is written by CPU every frame, such as uniform buffers or dynamic vertex/index buffers\n• – this is referring to CPU memory that is directly visible from GPU; reads from this memory go over PCI-express bus. In absence of the previous memory type, this generally speaking should be the choice for uniform buffers or dynamic vertex/index buffers, and also should be used to store staging buffers that are used to populate static resources allocated with with data.\n• – this is referring to GPU memory that might never need to be allocated for render targets on tiled architectures. It is recommended to use lazily allocated memory to save physical memory for large render targets that are never stored to, such as MSAA images or depth images. On integrated GPUs, there is no distinction between GPU and CPU memory – these devices generally expose that you can allocate all static resources through as well.\n\nWhen dealing with dynamic resources, in general allocating in non-device-local host-visible memory works well – it simplifies the application management and is efficient due to GPU-side caching of read-only data. For resources that have a high degree of random access though, like dynamic textures, it’s better to allocate them in and upload data using staging buffers allocated in memory – similarly to how you would handle static textures. In some cases you might need to do this for buffers as well – while uniform buffers typically don’t suffer from this, in some applications using large storage buffers with highly random access patterns will generate too many PCIe transactions unless you copy the buffers to GPU first; additionally, host memory does have higher access latency from the GPU side that can impact performance for many small draw calls.\n\nWhen allocating resources from , in case of VRAM oversubscription you can run out of memory; in this case you should fall back to allocating the resources in non-device-local memory. Naturally you should make sure that large frequently used resources such as render targets are allocated first. There are other things you can do in an event of an oversubscription, such as migrating resources from GPU memory to CPU memory for less frequently used resources – this is outside of the scope of this article; additionally, on some operating systems like Windows 10 correct handling of oversubscription requires APIs that are not currently available in Vulkan.\n\nUnlike some other APIs that allow an option to perform one memory allocation per resource, in Vulkan this is impractical for large applications – drivers are only required to support up to 4096 individual allocations. In addition to the total number being limited, allocations can be slow to perform, may waste memory due to assuming worst case possible alignment requirements, and also require extra overhead during command buffer submission to ensure memory residency. Because of this, suballocation is necessary. A typical pattern of working with Vulkan involves performing large (e.g. 16 MB – 256 MB depending on how dynamic the memory requirements are) allocations using , and performing suballocation of objects within this memory, effectively managing it yourself. Critically, the application needs to handle alignment of memory requests correctly, as well as limit that restricts valid configurations of buffers and images.\n\nBriefly, restricts the relative placement of buffer and image resources in the same allocation, requiring additional padding between individual allocations. There are several ways to handle this:\n• Always over-align image resources (as they typically have larger alignment to begin with) by bufferImageGranularity, essentially using a maximum of required alignment and for address and size alignment.\n• Track resource type for each allocation, and have the allocator add the requisite padding only if the previous or following resource is of a different type. This requires a somewhat more complex allocation algorithm.\n• Allocate images and buffers in separate Vulkan allocations, thus sidestepping the entire problem. This reduces internal fragmentation due to smaller alignment padding but can waste more memory if the backing allocations are too big (e.g. 256 MB).\n\nOn many GPUs the required alignment for image resources is substantially bigger than it is for buffers which makes the last option attractive – in addition to reducing waste due to lack of extra padding between buffers and images, it reduces internal fragmentation due to image alignment when an image follows a buffer resource. VMA provides implementations for option 2 (by default) and option 3 (see ).\n\nWhile the memory management model that Vulkan provides implies that the application performs large allocations and places many resources within one allocation using suballocation, on some GPUs it’s more efficient to allocate certain resources as one dedicated allocation. That way the driver can allocate the resources in faster memory under special circumstances.\n\nTo that end, Vulkan provides an extension (core in 1.1) to perform dedicated allocations – when allocating memory, you can specify that you are allocating this memory for this individual resource instead of as an opaque blob. To know if this is worthwhile, you can query the extended memory requires via or ; the resulting struct, , will contain (which might be set if the allocated resource needs to be shared with other processes) and flags.\n\nIn general, applications may see performance improvements from dedicated allocations on large render targets that require a lot of read/write bandwidth depending on the hardware and drivers.\n\nVulkan provides two options when mapping memory to get a CPU-visible pointer:\n• Do this before CPU needs to write data to the allocation, and unmap once the write is complete\n• Do this right after the host-visible memory is allocated, and never unmap memory\n\nThe second option is otherwise known as persistent mapping and is generally a better tradeoff – it minimizes the time it takes to obtain a writeable pointer ( is not particularly cheap on some drivers), removes the need to handle the case where multiple resources from the same memory object need to be written to simultaneously (calling on an allocation that’s already been mapped and not unmapped is not valid) and simplifies the code in general.\n\nThe only downside is that this technique makes the 256 MB chunk of VRAM that is host visible and device local on AMD GPU that was described in “Memory heap selection” less useful – on systems with Windows 7 and AMD GPU, using persistent mapping on this memory may force WDDM to migrate the allocations to system memory. If this combination is a critical performance target for your users, then mapping and unmapping memory when needed might be more appropriate.\n\nUnlike earlier APIs with a slot-based binding model, in Vulkan the application has more freedom in how to pass resources to shaders. Resources are grouped into descriptor sets that have an application-specified layout, and each shader can use several descriptor sets that can be bound individually. It’s the responsibility of the application to manage the descriptor sets to make sure that CPU doesn’t update a descriptor set that’s in use by the GPU, and to provide the descriptor layout that has an optimal balance between CPU-side update cost and GPU-side access cost. In addition, since different rendering APIs use different models for resource binding and none of them match Vulkan model exactly, using the API in an efficient and cross-platform way becomes a challenge. We will outline several possible approaches to working with Vulkan descriptor sets that strike different points on the scale of usability and performance.\n\nWhen working with Vulkan descriptor sets, it’s useful to have a mental model of how they might map to hardware. One such possibility – and the expected design – is that descriptor sets map to a chunk of GPU memory that contains descriptors – opaque blobs of data, 16-64 bytes in size depending on the resource, that completely specify all resource parameters necessary for shaders to access resource data. When dispatching shader work, CPU can specify a limited number of pointers to descriptor sets; these pointers become available to shaders as the shader threads launch.\n\nWith that in mind, Vulkan APIs can map more or less directly to this model – creating a descriptor set pool would allocate a chunk of GPU memory that’s large enough to contain the maximum specified number of descriptors. Allocating a set out of descriptor pool can be as simple as incrementing the pointer in the pool by the cumulative size of allocated descriptors as determined by (note that such an implementation would not support memory reclamation when freeing individual descriptors from the pool; would set the pointer back to the start of pool memory and make the entire pool available for allocation again). Finally, would emit command buffer commands that set GPU registers corresponding to descriptor set pointers.\n\nNote that this model ignores several complexities, such as dynamic buffer offsets, limited number of hardware resources for descriptor sets, etc. Additionally, this is just one possible implementation – some GPUs have a less generic descriptor model and require the driver to perform additional processing when descriptor sets are bound to the pipeline. However, it’s a useful model to plan for descriptor set allocation/usage.\n\nGiven the mental model above, you can treat descriptor sets as GPU-visible memory – it’s the responsibility of the application to group descriptor sets into pools and keep them around until GPU is done reading them.\n\nA scheme that works well is to use free lists of descriptor set pools; whenever you need a descriptor set pool, you allocate one from the free list and use it for subsequent descriptor set allocations in the current frame on the current thread. Once you run out of descriptor sets in the current pool, you allocate a new pool. Any pools that were used in a given frame need to be kept around; once the frame has finished rendering, as determined by the associated fence objects, the descriptor set pools can reset via and returned to free lists. While it’s possible to free individual descriptors from a pool via , this complicates the memory management on the driver side and is not recommended.\n\nWhen a descriptor set pool is created, application specifies the maximum number of descriptor sets allocated from it, as well as the maximum number of descriptors of each type that can be allocated from it. In Vulkan 1.1, the application doesn’t have to handle accounting for these limits – it can just call and handle the error from that call by switching to a new descriptor set pool. Unfortunately, in Vulkan 1.0 without any extensions, it’s an error to call if the pool does not have available space, so application must track the number of sets and descriptors of each type to know beforehand when to switch to a different pool.\n\nDifferent pipeline objects may use different numbers of descriptors, which raises the question of pool configuration. A straightforward approach is to create all pools with the same configuration that uses the worst-case number of descriptors for each type – for example, if each set can use at most 16 texture and 8 buffer descriptors, one can allocate all pools with maxSets=1024, and pool sizes 16*1024 for texture descriptors and 8*1024 for buffer descriptors. This approach can work but in practice it can result in very significant memory waste for shaders with different descriptor count – you can’t allocate more than 1024 descriptor sets out of a pool with the aforementioned configuration, so if most of your pipeline objects use 4 textures, you’ll be wasting 75% of texture descriptor memory.\n\nTwo alternatives that provide a better balance wrt memory use are:\n• Measure an average number of descriptors used in a shader pipeline per type for a characteristic scene and allocate pool sizes accordingly. For example, if in a given scene we need 3000 descriptor sets, 13400 texture descriptors, and 1700 buffer descriptors, then the average number of descriptors per set is 4.47 textures (rounded up to 5) and 0.57 buffers (rounded up to 1), so a reasonable configuration of a pool is maxSets=1024, 5*1024 texture descriptors, 1024 buffer descriptors. When a pool is out of descriptors of a given type, we allocate a new one – so this scheme is guaranteed to work and should be reasonably efficient on average.\n• Group shader pipeline objects into size classes, approximating common patterns of descriptor use, and pick descriptor set pools using the appropriate size class. This is an extension of the scheme described above to more than one size class. For example, it’s typical to have large numbers of shadow/depth prepass draw calls, and large numbers of regular draw calls in a scene – but these two groups have different numbers of required descriptors, with shadow draw calls typically requiring 0 to 1 textures per set and 0 to 1 buffers when dynamic buffer offsets are used. To optimize memory use, it’s more appropriate to allocate descriptor set pools separately for shadow/depth and other draw calls. Similarly to general-purpose allocators that can have size classes that are optimal for a given application, this can still be managed in a lower-level descriptor set management layer as long as it’s configured with application specific descriptor set usages beforehand.\n\nFor each resource type, Vulkan provides several options to access these in a shader; application is responsible for choosing an optimal descriptor type.\n\nFor buffers, application must choose between uniform and storage buffers, and whether to use dynamic offsets or not. Uniform buffers have a limit on the maximum addressable size – on desktop hardware, you get up to 64 KB of data, however on mobile hardware some GPUs only provide 16 KB of data (which is also the guaranteed minimum by the specification). The buffer resource can be larger than that, but shader can only access this much data through one descriptor.\n\nOn some hardware, there is no difference in access speed between uniform and storage buffers, however for other hardware depending on the access pattern uniform buffers can be significantly faster. Prefer uniform buffers for small to medium sized data especially if the access pattern is fixed (e.g. for a buffer with material or scene constants). Storage buffers are more appropriate when you need large arrays of data that need to be larger than the uniform buffer limit and are indexed dynamically in the shader.\n\nFor textures, if filtering is required, there is a choice of combined image/sampler descriptor (where, like in OpenGL, descriptor specifies both the source of the texture data, and the filtering/addressing properties), separate image and sampler descriptors (which maps better to Direct3D 11 model), and image descriptor with an immutable sampler descriptor, where the sampler properties must be specified when pipeline object is created.\n\nThe relative performance of these methods is highly dependent on the usage pattern; however, in general immutable descriptors map better to the recommended usage model in other newer APIs like Direct3D 12, and give driver more freedom to optimize the shader. This does alter renderer design to a certain extent, making it necessary to implement certain dynamic portions of the sampler state, like per-texture LOD bias for texture fade-in during streaming, using shader ALU instructions.\n\nA simplistic alternative to Vulkan binding model is Metal/Direct3D11 model where an application can bind resources to slots, and the runtime/driver manage descriptor memory and descriptor set parameters. This model can be implemented on top of Vulkan descriptor sets; while not providing the most optimal results, it generally is a good model to start with when porting an existing renderer, and with careful implementation it can be surprisingly efficient.\n\nTo make this model work, application needs to decide how many resource namespaces are there and how they map to Vulkan set/slot indices. For example, in Metal each stage (VS, FS, CS) has three resource namespaces – textures, buffers, samplers – with no differentiation between e.g. uniform buffers and storage buffers. In Direct3D 11 the namespaces are more complicated since read-only structured buffers belong to the same namespace as textures, but textures and buffers used with unordered access reside in a separate one.\n\nVulkan specification only guarantees a minimum of 4 descriptor sets accessible to the entire pipeline (across all stages); because of this, the most convenient mapping option is to have resource bindings match across all stages – for example, a texture slot 3 would contain the same texture resource no matter what stage it’s accessed from – and use different descriptor sets for different types, e.g. set 0 for buffers, set 1 for textures, set 2 for samplers. Alternatively, an application can use one descriptor set per stage and perform static index remapping (e.g. slots 0-16 would be used for textures, slots 17-24 for uniform buffers, etc.) – this, however, can use much more descriptor set memory and isn’t recommended. Finally, one could implement optimally compact dynamic slot remapping for each shader stage (e.g. if a vertex shader uses texture slots 0, 4, 5, then they map to Vulkan descriptor indices 0, 1, 2 in set 0, and at runtime application extracts the relevant texture information using this remapping table.\n\nIn all these cases, the implementation of setting a texture to a given slot wouldn’t generally run any Vulkan commands and would just update shadow state; just before the draw call or dispatch you’d need to allocate a descriptor set from the appropriate pool, update it with new descriptors, and bind all descriptor sets using . Note that if a descriptor set has 5 resources, and only one of them changed since the last draw call, you still need to allocate a new descriptor set with 5 resources and update all of them.\n\nTo reach good performance with this approach, you need to follow several guidelines:\n• Don’t allocate or update descriptor sets if nothing in the set changed. In the model with slots that are shared between different stages, this can mean that if no textures are set between two draw calls, you don’t need to allocate/update the descriptor set with texture descriptors.\n• Batch calls to if possible – on some drivers, each call has measurable overhead, so if you need to update multiple sets, allocating both in one call can be faster\n• To update descriptor sets, either use with descriptor write array, or use from Vulkan 1.1. Using the descriptor copy functionality of is tempting with dynamic descriptor management for copying most descriptors out of a previously allocated array, but this can be slow on drivers that allocate descriptors out of write-combined memory. Descriptor templates can reduce the amount of work application needs to do to perform updates – since in this scheme you need to read descriptor information out of shadow state maintained by application, descriptor templates allow you to tell the driver the layout of your shadow state, making updates substantially faster on some drivers.\n• Finally, prefer dynamic uniform buffers to updating uniform buffer descriptors. Dynamic uniform buffers allow to specify offsets into buffer objects using argument of without allocating and updating new descriptors. This works well with dynamic constant management where constants for draw calls are allocated out of large uniform buffers, substantially reduce CPU overhead, and can be more efficient on GPU. While on some GPUs the number of dynamic buffers must be kept small to avoid extra overhead in the driver, one or two dynamic uniform buffers should work well in this scheme on all architectures.\n\nIn general, the approach outlined above can be very efficient in terms of performance – it’s not as efficient as approaches with more static descriptor sets that are described below, but it can still run circles around older APIs if implemented carefully. On some drivers, unfortunately the allocate & update path is not very optimal – on some mobile hardware, it may make sense to cache descriptor sets based on the descriptors they contain if they can be reused later in the frame.\n\nWhile slot-based resource binding model is simple and familiar, it doesn’t result in optimal performance. Some mobile hardware may not support multiple descriptor sets; however, in general Vulkan API and driver expect an application to manage descriptor sets based on frequency of change.\n\nA more Vulkan centric renderer would organize data that the shaders need to access into groups by frequency of change, and use individual sets for individual frequencies, with set=0 representing least frequent change, and set=3 representing most frequent. For example, a typical setup would involve:\n• Set=0 descriptor set containing uniform buffer with global, per-frame or per-view data, as well as globally available textures such as shadow map texture array/atlas\n• Set=1 descriptor set containing uniform buffer and texture descriptors for per-material data, such as albedo map, Fresnel coefficients, etc.\n• Set=2 descriptor set containing dynamic uniform buffer with per-draw data, such as world transform array\n\nFor set=0, the expectation is that it only changes a handful of times per frame; it’s sufficient to use a dynamic allocation scheme similar to the previous section.\n\nFor set=1, the expectation is that for most objects, the material data persists between frames, and as such could be allocated and updated only when the gameplay code changes material data.\n\nFor set=2, the data would be completely dynamic; due to the use of a dynamic uniform buffer, we’d rarely need to allocate and update this descriptor set – assuming dynamic constants are uploaded to a series of large per-frame buffers, for most draws we’d need to update the buffer with the constant data, and call with new offsets.\n\nNote that due to compatibility rules between pipeline objects, in most cases it’s enough to bind sets 1 and 2 whenever a material changes, and only set 2 when material is the same as that for the previous draw call. This results in just one call to per draw call.\n\nFor a complex renderer, different shaders might need to use different layouts – for example, not all shaders need to agree on the same layout for material data. In rare cases it might also make sense to use more than 3 sets depending on the frame structure. Additionally, given the flexibility of Vulkan it’s not strictly required to use the same resource binding system for all draw calls in the scene. For example, post-processing draw call chains tend to be highly dynamic, with texture/constant data changing completely between individual draw calls. Some renderers initially implement the dynamic slot-based binding model from the previous section and proceed to additionally implement the frequency-based sets for world rendering to minimize the performance penalty for set management, while still keeping the simplicity of slot-based model for more dynamic parts of the rendering pipeline.\n\nThe scheme described above assumes that in most cases, per-draw data is larger than the size that can be efficiently set via push constants. Push constants can be set without updating or rebinding descriptor sets; with a guaranteed limit of 128 bytes per draw call, it’s tempting to use them for per-draw data such as a 4x3 transform matrix for an object. However, on some architectures the actual number of constants available to push quickly depends on the descriptor setup the shaders use, and is closer to 12 bytes or so. Exceeding this limit can force the driver to spill the push constants into driver-managed ring buffer, which can end up being more expensive than moving this data to a dynamic uniform buffer on the application side. While limited use of push constants may still be a good idea for some designs, it’s more appropriate to use them in a fully bindless scheme described in the next section.\n\nFrequency-based descriptor sets reduce the descriptor set binding overhead; however, you still need to bind one or two descriptor sets per draw call. Maintaining material descriptor sets requires a management layer that needs to update GPU-visible descriptor sets whenever material parameters change; additionally, since texture descriptors are cached in material data, this makes global texture streaming systems hard to deal with – whenever some mipmap levels in a texture get streamed in or out, all materials that refer to this texture need to be updated. This requires complex interaction between material system and texture streaming system and introduces extra overhead whenever a texture is adjusted – which partially offsets the benefits of the frequency-based scheme. Finally, due to the need to set up descriptor sets per draw call it’s hard to adapt any of the aforementioned schemes to GPU-based culling or command submission.\n\nIt is possible to design a bindless scheme where the number of required set binding calls is constant for the world rendering, which decouples texture descriptors from materials, making texture streaming systems easier to implement, and facilitates GPU-based submission. As with the previous scheme, this can be combined with dynamic ad-hoc descriptor updates for parts of the scene where the number of draw calls is small, and flexibility is important, such as post-processing.\n\nTo fully leverage bindless, core Vulkan may or may not be sufficient; some bindless implementations require updating descriptor sets without rebinding them after the update, which is not available in core Vulkan 1.0 or 1.1 but is possible to achieve with extension (core in Vulkan 1.2). However, basic design described below can work without extensions, given high enough descriptor set limits. This requires double buffering for the texture descriptor array described below to update individual descriptors since the array would be constantly accessed by GPU.\n\nSimilarly to the frequency-based design, we’ll split the shader data into global uniforms and textures (set 0), material data and per-draw data. Global uniforms and textures can be specified via a descriptor set the same way as described the previous section.\n\nFor per-material data, we will move the texture descriptors into a large texture descriptor array (note: this is a different concept than a texture array – texture array uses one descriptor and forces all textures to have the same size and format; descriptor array doesn’t have this limitation and can contain arbitrary texture descriptors as array elements, including texture array descriptors). Each material in the material data will have an index into this array instead of texture descriptor; the index will be part of the material data, which will also have other material constants.\n\nAll material constants for all materials in the scene will reside in one large storage buffer; while it’s possible to support multiple material types with this scheme, for simplicity we’ll assume that all materials can be specified using the same data. An example of material data structure is below:\n\nSimilarly, all per-draw constants for all objects in the scene can reside in another large storage buffer; for simplicity, we’ll assume that all per-draw constants have identical structure. To support skinned objects in a scheme like this, we’ll extract transform data into a separate, third storage buffer:\n\nSomething that we’ve ignored so far is the vertex data specification. While Vulkan provides a first-class way to specify vertex data by calling , having to bind vertex buffers per-draw would not work for a fully bindless design. Additionally, some hardware doesn’t support vertex buffers as a first-class entity, and the driver has to emulate vertex buffer binding, which causes some CPU-side slowdowns when using . In a fully bindless design, we need to assume that all vertex buffers are suballocated in one large buffer and either use per-draw vertex offsets ( argument to ) to have hardware fetch data from it, or pass an offset in this buffer to the shader with each draw call and fetch data from the buffer in the shader. Both approaches can work well, and might be more or less efficient depending on the GPU; here we will assume that the vertex shader will perform manual vertex fetching.\n\nThus, for each draw call we need to specify three integers to the shader:\n• Material index; used to look up material data from material storage buffer. The textures can then be accessed using the indices from the material data and the descriptor array.\n• Transform data index; used to look up transform data from transform storage buffer\n• Vertex data offset; used to look up vertex attributes from vertex storage buffer\n\nWe can specify these indices and additional data, if necessary, via draw data:\n\nThe shader will need to access storage buffers containing , , as well as a storage buffer containing vertex data. These can be bound the shader via the global descriptor set; the only remaining piece of information is the draw data index, that can be passed via a push constant.\n\nWith this scheme, we’d need to update the storage buffers used by materials and draw calls each frame and bind them once using our global descriptor set; additionally, we need to bind index data – assuming that, like vertex data, index data is allocated in one large index buffer, we only need to bind it once using . With the global setup complete, for each draw call we need to call if the shader changes, followed by to specify an index into the draw data buffer, followed by .\n\nIn a GPU-centric design, we can use or (provided by extension, promoted to core Vulkan 1.2) and fetch per-draw constants using (provided by extension) as an index instead of push constants. The only caveat is that for GPU-based submission, we’d need to bucket draw calls based on pipeline object on CPU since there’s no support for switching pipeline objects otherwise.\n\nWith this, vertex shader code to transform the vertex could look like this:\n\nFragment shader code to sample material textures could look like this:\n\nThis scheme minimizes the CPU-side overhead. Of course, fundamentally it’s a balance between multiple factors:\n• While the scheme can be extended to multiple formats of material, draw and vertex data, it gets harder to manage\n• Using storage buffers exclusively instead of uniform buffers can increase GPU time on some architectures\n• Fetching texture descriptors from an array indexed by material data indexed by material index can add an extra indirection on GPU compared to some alternative designs\n• On some hardware, various descriptor set limits may make this technique impractical to implement; to be able to index an arbitrary texture dynamically from the shader, should be large enough to accomodate all material textures - while many desktop drivers expose a large limit here, the specification only guarantees a limit of 16, so bindless remains out of reach on some hardware that otherwise supports Vulkan\n\nAs the renderers get more and more complex, bindless designs will become more involved and eventually allow moving even larger parts of rendering pipeline to GPU; due to hardware constraints this design is not practical on every single Vulkan-compatible device, but it’s definitely worth considering when designing new rendering paths for future hardware.\n\nIn older APIs, there is a single timeline for GPU commands; commands executed on CPU execute on the GPU in the same order, as there is generally only one thread recording them; there is no precise control over when CPU submits commands to GPU, and the driver is expected to manage memory used by the command stream as well as submission points optimally.\n\nIn contrast, in Vulkan the application is responsible for managing command buffer memory, recording commands in multiple threads into multiple command buffers, and submitting them for execution with appropriate granularity. While with carefully written code a single-core Vulkan renderer can be significantly faster than older APIs, the peak efficiency and minimal latency is obtained by utilizing many cores in the system for command recording, which requires careful memory management.\n\nSimilarly to descriptor sets, command buffers are allocated out of command pools; it’s valuable to understand how a driver might implement this to be able to reason about the costs and usage implications.\n\nCommand pool has to manage memory that will be filled with commands by CPU and subsequently read by GPU command processor. The amount of memory used by the commands can’t be statically determined; a typical implementation of a pool would involve thus a free list of fixed-size pages. Command buffer would contain a list of pages with actual commands, with special jump commands that transfer control from each page to the next one so that GPU can execute all of them in sequence. Whenever a command needs to be allocated from a command buffer, it will be encoded into the current page; if the current page doesn’t have space, the driver would allocate the next page using a free list from the associated pool, encode a jump to that page into the current page and switch to the next page for subsequent command recording.\n\nEach command pool can only be used from one thread concurrently, so the operations above don’t need to be thread-safe. Freeing the command buffer using may return the pages used by the command buffer into the pool by adding them to the free list. Resetting the command pool may put all pages used by all command buffers into the pool free list; when is used, the pages can be returned to the system so that other pools can reuse them.\n\nNote that there is no guarantee that actually returns memory to the pool; alternative designs may involve multiple command buffers allocating chunks within larger pages, which would make it hard for to recycle memory. Indeed, on one mobile vendor, is necessary to reuse memory for future command recording in a default setup when pools are allocated without .\n\nTwo crucial restrictions in Vulkan for command pool usage are:\n• Command buffers allocated from one pool may not be recorded concurrently by multiple threads\n• Command buffers and pools can not be freed or reset while GPU is still executing the associated commands\n\nBecause of these, a typical threading setup requires a set of command buffer pools. The set has to contain F*T pools, where F is the frame queue length – F is usually 2 (one frame is recorded by the CPU while another frame is being executed by the GPU) or 3; T is the number of threads that can concurrently record commands, which can be as high as the core count on the system. When recording commands from a thread, the thread needs to allocate a command buffer using the pool associated with the current frame & thread and record commands into it. Assuming that command buffers aren’t recorded across a frame boundary, and that at a frame boundary the frame queue length is enforced by waiting for the last frame in the queue to finish executing, we can then free all command buffers allocated for that frame and reset all associated command pools.\n\nAdditionally, instead of freeing command buffers, it’s possible to reuse them after calling - which would mean that command buffers don’t have to be allocated again. While in theory allocating command buffers could be cheap, some driver implementations have a measurable overhead associated with command buffer allocation. This also makes sure that the driver doesn’t ever need to return command memory to the system which can make submitting commands into these buffers cheaper.\n\nNote that depending on the frame structure, the setup above may result in unbalanced memory consumption across threads; for example, shadow draw calls typically require less setup and less command memory. When combined with effectively random workload distribution across threads that many job schedulers produce, this can result in all command pools getting sized for the worst-case consumption. If an application is memory constrained and this becomes a problem, it’s possible to limit the parallelism for each individual pass and select the command buffer/pool based on the recorded pass to limit the waste.\n\nThis requires introducing the concept of size classes to the command buffer manager. With a command pool per thread and a manual reuse of allocated command buffers as suggested above, it’s possible to keep a free list per size class, with size classes defined based on the number of draw calls (e.g. “<100”, “100-400”, etc.) and/or the complexity of individual draw calls (depth-only, gbuffer). Picking the buffer based on the expected usage leads to a more stable memory consumption. Additionally, for passes that are too small it is worthwhile to reduce the parallelism when recording these - for example, if a pass has <100 draw calls, instead of splitting it into 4 recording jobs on a 4-core system, it can be more efficient to record it in one job since that can reduce the overhead of command memory management and command buffer submission.\n\nWhile it’s important to record multiple command buffers on multiple threads for efficiency, since state isn’t reused across command buffers and there are other scheduling limitations, command buffers need to be reasonably large to make sure GPU is not idle during command processing. Additionally, each submission has some overhead both on the CPU side and on the GPU side. In general a Vulkan application should target <10 submits per frame (with each submit accounting for 0.5ms or more of GPU workload), and <100 command buffers per frame (with each command buffer accounting for 0.1ms or more of GPU workload). This might require adjusting the concurrency limits for command recording for individual passes, e.g. if a shadow pass for a specific light has <100 draw calls, it might be necessary to limit the concurrency on the recording for this pass to just one thread; additionally, for even shorter passes combining them with neighboring passes into one command buffer becomes beneficial. Finally, the fewer submissions a frame has the better – this needs to be balanced with submitting enough GPU work earlier in the frame to increase CPU and GPU parallelism though, for example it might make sense to submit all command buffers for shadow rendering before recording commands for other parts of the frame.\n\nCrucially, the number of submissions refers to the total number of structured submitted in all calls in a frame, not to the number of calls per se. For example, when submitting 10 command buffers, it’s much more efficient to use one that submits 10 command buffers compared to 10 structures with one command buffer per each, even if in both cases only one call is performed. Essentially, is a unit of synchronization/scheduling on GPU since it has its own set of fences/semaphores.\n\nWhen one of the render passes in the application contains a lot of draw calls, such as the gbuffer pass, for CPU submission efficiency it’s important to split the draw calls into multiple groups and record them on multiple threads. There are two ways to do this:\n• Record primary command buffers that render chunks of draw calls into the same framebuffer, using and ; execute the resulting command buffers using (batching submits for efficiency)\n• Record secondary command buffers that render chunks of draw calls, passing the render pass to along with ; use with in the primary command buffer, followed by to execute all recorded secondary command buffers\n\nWhile on immediate mode GPUs the first approach can be viable, and it can be a bit easier to manage wrt synchronization points on the CPU, it’s vital to use the second approach on GPUs that use tiled rendering instead. Using the first approach on tilers would require that the contents of the tiles is flushed to memory and loaded back from memory between each command buffer, which is catastrophic for performance.\n\nWith the guidance on the command buffer submission above, in most cases submitting a single command buffer multiple times after recording becomes impractical. In general approaches that pre-record command buffers for parts of the scene are counter-productive since they can result in excessive GPU load due to inefficient culling required to keep command buffer workload large and can trigger inefficient code paths on some tiled renderers, and instead applications should focus on improving the threading and draw call submission cost on the CPU. As such, applications should use to make sure the driver has freedom to generate commands that don’t need to be replayed more than once.\n\nThere are occasional exceptions for this rule. For example, for VR rendering, an application might want to record the command buffer for the combined frustum between left and right eye once. If the per-eye data is read out of a single uniform buffer, this buffer can then be updated between the command buffers using , followed by if secondary command buffers are used, or . Having said that, for VR it might be worthwhile to explore extension if available (core in Vulkan 1.1), since it should allow the driver to perform a similar optimization.\n\nPipeline barriers remain one of the most challenging parts of Vulkan code. In older APIs, the runtime and driver were responsible for making sure appropriate hardware-specific synchronization was performed in case of hazards such as fragment shader reading from the texture that was previously rendered to. This required meticulous tracking of every single resource binding and resulted in an unfortunate mix of excessive CPU overhead to perform a sometimes excessive amount of GPU synchronization (for example, Direct3D 11 driver typically inserts a barrier between any two consecutive compute dispatches that use the same UAV, even though depending on the application logic the hazards may be absent). Because inserting barriers quickly and optimally can require knowledge about the application’s use of resources, Vulkan requires the application to do this.\n\nFor optimal rendering, the pipeline barrier setup must be perfect. A missing barrier risks the application encountering a timing-dependent bug on an untested – or, worse, not-yet-existing – architecture, that in the worst case could cause a GPU crash. An unnecessary barrier can reduce the GPU utilization by reducing potential opportunity for parallel execution – or, worse, trigger very expensive decompression operations or the like. To make matters worse, while the cost of excessive barriers can be now visualized by tools like Radeon Graphics Profiler, missing barriers are generally not detected by validation tools.\n\nBecause of this, it’s vital to understand the behavior or barriers, the consequences of overspecifying them as well as how to work with them.\n\nThe specification describes barriers in terms of execution dependencies and memory visibility between pipeline stages (e.g. a resource was previously written to by a compute shader stage, and will be read by the transfer stage), as well as layout changes for images (e.g. a resource was previously in the format that is optimal to write via the color attachment output and should be transitioned to a format that is optimal to read from the shader). However, it might be easier to think about barriers in terms of their consequences – as in, what can happen on a GPU when a barrier is used. Note that the GPU behavior is of course dependent on the specific vendor and architecture, but it helps to map barriers that are specified in an abstract fashion to more concrete constructs to understand their performance implications.\n\nA barrier can cause three different things to happen:\n• Stalling execution of a specific stage until another stage is drained of all current work. For example, if a render pass renders data to a texture, and a subsequent render pass uses a vertex shader to read from this shader, GPU must wait for all pending fragment shader and ROP work to complete before launching shader threads for the vertex work in a subsequent pass. Most barrier operations will lead to execution stalling for some stages.\n• Flushing or invalidating an internal GPU-side cache and waiting for the memory transactions to finish to make sure another stage can read the resulting work. For example, on some architectures ROP writes might go through the L2 texture cache, but transfer stage might operate directly on memory. If a texture has been rendered to in a render pass, then the following transfer operation might read stale data unless the cache is flushed before the copy. Similarly, if a texture stage needs to read an image that was copied using transfer stage, L2 texture cache may need to get invalidated to make sure it doesn’t contain stale data. Not all barrier operations will need to do this.\n• Converting the format the resource is stored in, most commonly to decompress the resource storage. For example, MSAA textures on some architectures are stored in a compressed form where each pixel has a sample mask indicating how many unique colors this pixel contains, and a separate storage for sample data. Transfer stage or shader stage might be unable to read directly from a compressed texture, so a barrier that transitions from to or might need to decompress the texture, writing all samples for all pixels to memory. Most barrier operations won’t need to do this, but the ones that do can be incredibly expensive.\n\nWith this in mind, let’s try to understand the guidance for using barriers.\n\nWhen generating commands for each individual barrier, the driver only has a local view of the barrier and is unaware of past or future barriers. Because of this, the first important rule is that barriers need to be batched as aggressively as possible. Given a barrier that implies a wait-for-idle for fragment stage and an L2 texture cache flush, the driver will dutifully generate that every time you call . If you specify multiple resources in a single call, the driver will only generate one L2 texture cache flush command if it’s necessary for any transitions, reducing the cost.\n\nTo make sure the cost of the barriers isn’t higher than it needs to be, only relevant stages need to be included. For example, one of the most common barrier types is one that transitions a resource from to . When specifying this barrier, you should specify the shader stages that will actually read this resource via . It’s tempting to specify the stage mask as to support compute shader or vertex shader reads. Doing so, however, would mean that vertex shader workload from the subsequent draw commands can not start, which is problematic:\n• On immediate mode renderers, this slightly reduces the parallelism between draw calls, requiring all fragment threads to finish before vertex threads can start, which leads to GPU utilization dropping to 0 at the end of the pass and gradually rising from 0 to, hopefully, 100% as the next render pass begins;\n• On tiled mode renderers, for some designs the expectation is that all vertex work from the subsequent pass executes to completion before fragment work can start; waiting for fragment work to end for any vertex work to begin thus completely eliminates the parallelism between vertex and fragment stages and is one of the largest potential performance problems that a naively ported Vulkan title can encounter.\n\nNote that even if the barriers are specified correctly – in this case, assuming the texture is read from the fragment stage, should be – the execution dependency is still present, and it can still lead to reduced GPU utilization. This can come up in multiple situations including compute, where to read data from a compute shader generated by another compute shader you need to express an execution dependency between CS and CS but specifying a pipeline barrier is guaranteed to drain the GPU of compute work entirely, followed by slowly filling it with compute work again. Instead, it can be worthwhile to specify the dependency via what’s called a split barrier: instead of using , use after the write operation completes, and before the read operations starts. Of course, using immediately after is counter-productive and can be slower than ; instead you should try to restructure your algorithm to make sure there’s enough work submitted between Set and Wait, so that by the time GPU needs to process Wait, the event is most likely already signaled and there is no efficiency loss.\n\nAlternatively, in some cases the algorithm can be restructured to reduce the number of synchronization points while still using pipeline barriers, making the overhead less significant. For example, a GPU-based particle simulation might need to run two compute dispatches for each particle effect: one to emit new particles, and another one to simulate particles. These dispatches require a pipeline barrier between them to synchronize execution, which requires a pipeline barrier per particle system if particle systems are simulated sequentially. A more optimal implementation would first submit all dispatches to emit particles (that would not depend on each other), then submit a barrier to synchronize emission and simulation dispatches, then submit all dispatches to simulate particles - which would keep GPU well utilized for longer. From there on using split barriers could help completely hide the synchronization cost.\n\nAs far as resource decompression goes, it’s hard to give a general advice – on some architectures this never happens, and on some it does but depending on the algorithm it might not be avoidable. Using vendor specific tools such as Radeon Graphics Profiler is critical to understanding the performance impact decompression has on your frame; in some cases, it may be possible to adjust the algorithm to not require the decompression in the first place, for example by moving the work to a different stage. Of course it should be noted that resource decompression may happen in cases where it’s completely unnecessary and is a result of overspecifying barriers – for example, if you render to a framebuffer that contains a depth buffer and never read depth contents in the future, you should leave the depth buffer in layout instead of needlessly transitioning it into which might trigger a decompression (remember, the driver doesn’t know if you are going to read the resource in the future!).\n\nWith all the complexity involved in specifying barriers, it helps to have examples of commonly required barriers. Fortunately, Khronos Group provides many examples of valid and optimal barriers for various types of synchronization as part of Vulkan-Docs repository on GitHub. These can serve to improve the understanding of general barrier behavior, and can also be used directly in a shipping application.\n\nAdditionally, for cases not covered by these examples and, in general, to simplify the specification code and make it more correct, it is possible to switch to a simpler model where, instead of fully specifying access masks, stages and image layouts, the only concept that needs to be known about a resource is the resource state that encapsulates the stages that can use the resource and the usage mode for most common types of access. Then all transitions involve transitioning a resource from state A from state B, which is much easier to understand. To that end, Tobias Hector, a member of Khronos Group and a co-author of the Vulkan specification, wrote an open-source library, simple_vulkan_synchronization, that translates resource state (otherwise known as access type in the library) transitions into Vulkan barrier specification. The library is small and simple and provides support for split barriers as well as full pipeline barriers.\n\nThe performance guidelines outlined in the previous section are hard to follow in practice, especially given conventional immediate mode rendering architectures.\n\nTo make sure that the stages and image layout transitions are not overspecified, it’s important to know how the resource is going to be used in the future – if you want to emit a pipeline barrier after render pass ends, without this information you’re generally forced to emit a barrier with all stages in the destination stage mask, and an inefficient target layout.\n\nTo solve this problem, it’s tempting to instead emit the barriers before the resource is read, since at that point it’s possible to know how the resource was written to; however, this makes it hard to batch barriers. For example, in a frame with 3 render passes, A, B, and C, where C reads A’s output and B’s output in two separate draw calls, to minimize the number of texture cache flushes and other barrier work it’s generally beneficial specify a barrier before C that correctly transitions outputs of both A and B; instead what would happen is that there’s a barrier before each of C’s draw calls. Split barriers in some cases can reduce the associated costs, but in general just-in-time barriers will be overly expensive.\n\nAdditionally, using just-in-time barriers requires tracking the resource state to know the previous layout; this is very hard to do correctly in a multithreaded system since the final execution order on GPU can only be known once all commands are recorded and linearized.\n\nDue to the aforementioned problems, many modern renderers are starting to experiment with render graphs as a way to declaratively specify all dependencies between frame resources. Based on the resulting DAG structure, it’s possible to establish correct barriers, including barriers required for synchronizing work across multiple queues, and allocate transient resources with minimal use of physical memory.\n\nA full description of a render graph system is out of scope of this article, but interested readers are encouraged to refer to the following talks and articles:\n\nDifferent engines pick different parameters of the solution, for example Frostbite render graph is specified by the application using the final execution order (which the author of this article finds more predictable and preferable), whereas two other presentations linearize the graph based on certain heuristics to try to find a more optimal execution order. Regardless, the important part is that dependencies between passes must be declared ahead of time for the entire frame to make sure that barriers can be emitted appropriately. Importantly, the frame graph systems work well for transient resources that are limited in number and represent the bulk of required barriers; while it’s possible to specify barriers required for resource uploads and similar streaming work as part of the same system, this can make the graphs too complex and the processing time too large, so these are generally best handled outside of a frame graph system.\n\nOne concept that is relatively unique to Vulkan compared to both older APIs and new explicit APIs is render passes. Render passes allow an application to specify a large part of their render frame as a first-class object, splitting the workload into individual sub-passes and explicitly enumerating dependencies between sub-passes to allow the driver to schedule the work and place appropriate synchronization commands. In that sense, render passes are similar to render graphs described above and can be used to implement these with some limitations (for example, render passes currently can only express rasterization workloads which means that multiple render passes should be used if compute workloads are necessary to support). This section, however, will focus on simpler uses of render passes that are more practical to integrate into existing renderers, and still provide performance benefits.\n\nOne of the most important features of render passes is the ability to specify load and store operations. Using these, the application can choose whether the initial contents of each framebuffer attachments needs to be cleared, loaded from memory, or remain unspecified and unused by the application, and whether after the render pass is done the attachment needs to be stored to memory.\n\nThese operations are important to get right – on tiled architectures, using redundant load or store operations leads to wasted bandwidth which reduces performance and increases power consumption. On non-tiled architectures, driver can still use these to perform certain optimizations for subsequent rendering – for example, if the previous contents of an attachment is irrelevant but the attachment has associated compression metadata, driver may clear this metadata to make subsequent rendering more efficient.\n\nTo allow maximum freedom for the driver, it’s important to specify the weakest load/store operations necessary – for example, when rendering a full-screen quad to the attachment that writes all pixels, on tiled GPUs is likely to be faster than , and on immediate mode GPUs LOAD is likely to be faster – specifying is important so that the driver can perform an optimal choice. In some cases can be better than either LOAD or CLEAR since it allows the driver to avoid an expensive clear operation for the image contents, but still clear image metadata to accelerate subsequent rendering.\n\nSimilarly, should be used in case the application is not expecting to read the data rendered to the attachment - this is commonly the case for depth buffers and MSAA targets.\n\nAfter rendering data to an MSAA texture, it’s common to resolve it into a non-MSAA texture for further processing. If fixed-function resolve functionality is sufficient, there are two ways to implement this in Vulkan:\n• Using for the MSAA texture and after the render pass ends\n• Using for the MSAA texture and specifying the resolve target via member of\n\nIn the latter case, the driver will perform the necessary work to resolve MSAA contents as part of work done when subpass/renderpass ends.\n\nThe second approach can be significantly more efficient. On tiled architectures, using the first approach requires storing the entire MSAA texture to main memory, followed by reading it from memory and resolving to the destination; the second approach can perform in-tile resolve in the most efficient manner. On immediate mode architectures, some implementation may not support reading compressed MSAA textures using the transfer stage – the API requires a transition into layout before calling , which may lead to decompression of the MSAA texture, wasting bandwidth and performance. With , the driver can perform the resolve operation at maximum performance regardless of the architecture.\n\nIn some cases, fixed function MSAA resolve is insufficient. In this case, it’s necessary to transition the texture to and do the resolve in a separate render pass. On tiled architectures, this has the same efficiency issues as fixed-function method; on immediate mode architectures the efficiency depends on GPU and driver. One possible alternative is to use an extra subpass that reads the MSAA texture via an input attachment.\n\nFor this to work, the first subpass that renders to MSAA texture has to specify the MSAA texture via , with as the store op. The second subpass that performs the resolve needs to specify MSAA texture via pInputAttachments and the resolve target via pColorAttachments; the subpass then needs to render a full-screen quad or triangle with a shader that uses subpassInputMS resource to read MSAA data. Additionally, the application needs to specify a dependency between two subpasses that indicates the stage/access masks, similarly to pipeline barriers, and dependency flags . With this, the driver should have enough information to arrange the execution such that on tiled GPUs, the MSAA contents never leaves the tile memory and instead is resolved in-tile, with the resolve result being written to main memory. Note that whether this happens depends on the driver and is unlikely to result in significant savings on immediate mode GPUs.\n\nOlder APIs typically used to split the GPU state into blocks based on functional units – for example, in Direct3D 11 the full state of GPUs modulo resource bindings can be described using the set of shader objects for various stages (VS, PS, GS, HS, DS) as well as a set of state objects (rasterizer, blend, depth stencil), input assembly configuration (input layout, primitive topology) and a few other implicit bits like output render target formats. The API user then could set individual bits of the state separately, without regards to the design or complexity of the underlying hardware.\n\nUnfortunately, this model doesn’t match the model hardware typically uses, with several performance pitfalls that can occur:\n• While an individual state object is supposed to model parts of GPU state and could be directly transferred to commands that setup GPU state, on some GPUs the configuration of the GPU state required data from multiple different state blocks. Because of this, drivers typically must keep a shadow copy of all state and convert the state to the actual GPU commands at the time of Draw/DrawIndexed\n• With the rasterization pipeline getting more complex and gaining more programmable stages, some GPUs didn’t map them directly to hardware stages, which means that the shader microcode can depend on whether other shader stages are active and, in some cases, on the specific microcode for other stages; this meant that the driver might have to compile new shader microcode from state that can only be discovered at the time of Draw/DrawIndexed\n• Similarly, on some GPUs, fixed functional units from the API description were implemented as part of one of the shader stages – changing the vertex input format, blending setup, or render target format could affect the shader microcode. Since the state is only known at the time of Draw/DrawIndexed, this, again, is where the final microcode had to be compiled\n\nWhile the first problem is more benign, the second and third problem can lead to significant stalls during rendering as, due to the complexity of modern shaders and shader compilation pipelines, shader compilation can take tens to hundreds of milliseconds depending on hardware. To solve this, Vulkan and other new APIs introduce the concept of pipeline object – it encapsulates most GPU state, including vertex input format, render target format, state for all stages and shader modules for all stages. The expectation is that on every supported GPU, this state is sufficient to build final shader microcode and GPU commands required to set the state up, so the driver never has to compile microcode at draw time and can optimize pipeline object setup to the extent possible.\n\nThis model, however, presents challenges when implementing renderers on top of Vulkan. There are multiple ways to solve this problem, with different tradeoffs wrt complexity, efficiency, and renderer design.\n\nThe most straightforward way to support Vulkan is to use just-in-time compilation for pipeline objects. In many engines due to the lack of first-class concepts that match Vulkan, the rendering backend must gather information about various parts of the pipeline state as a result of various state setup calls, similarly to what a Direct3D 11 driver might do. Then, just before the draw/dispatch where the full state is known, all individual bits of state would be grouped together and looked up in a hash table; if there’s already a pipeline state object in the cache, it can be used directly, otherwise a new object can be created.\n\nThis scheme works to get the application running but suffers from two performance pitfalls.\n\nA minor concern is that the state that needs to be hashed together is potentially large; doing this for every draw call can be time consuming when the cache already contains all relevant objects. This can be mitigated by grouping state into objects and hashing pointers to these objects, and in general simplifying the state specification from the high-level API point of view.\n\nA major concern, however, is that for any pipeline state object that must be created, the driver might need to compile multiple shaders to the final GPU microcode. This process is time consuming; additionally, it can not be optimally threaded with a just-in-time compilation model – if the application only uses one thread for command submission, this thread would typically also compile pipeline state objects; even with multiple threads, often multiple threads would request the same pipeline object, serializing compilation, or one thread would need several new pipeline objects, which increases the overall latency of submission since other threads would finish first and have no work to do.\n\nFor multi-threaded submission, accessing the cache can result in contention between cores even when the cache is full. Fortunately, this can be solved by a two-level cache scheme as follows:\n\nThe cache would have two parts, the immutable part that never changes during the frame, and the mutable part. To perform a pipeline cache lookup, we first check if the immutable cache has the object – this is done without any synchronization. In the event of the cache miss, we lock a critical section and check if the mutable cache has the object; if it doesn’t, we unlock the critical section, create the pipeline object, and then lock it again and insert the object into the cache, potentially displacing another object (additional or synchronization might be required if, when two threads request the same object, only one compilation request is issued to the driver). At the end of the frame, all objects from the mutable cache are added to the immutable cache and the mutable cache is cleared, so that on the next frame access to these objects can be free-threaded.\n\nWhile just-in-time compilation can work, it results in significant amount of stuttering during gameplay. Whenever an object with a new set of shaders/state enters the frame, we end up having to compile a pipeline object for it which could be slow. This is a similar problem to what Direct3D 11 titles would have, however in Direct3D 11 the drivers did a lot of work behind the scenes to try to hide the compilation latency, precompiling some shaders earlier and implementing custom schemes for patching bytecode on the fly that didn’t require a full recompilation. In Vulkan, the expectation is that the application handles pipeline object creation manually and intelligently, so a naive approach doesn’t work very well.\n\nTo make just-in-time compilation more practical, it’s important to use the Vulkan pipeline cache, serialize it between runs, and pre-warm the in-memory cache described in the previous section at application startup from multiple threads.\n\nVulkan provides a pipeline cache object, , that can store driver-specific bits of state and shader microcode to improve compilation time for pipeline objects. For example, if an application creates two pipeline objects with identical setup except for culling mode, the shader microcode would typically be the same. To make sure the driver only compiles the object once, the application should pass the same instance of to in both calls, in which case the first call would compile the shader microcode and the second call would be able to reuse it. If these calls happen concurrently in different threads the driver might still compile the shaders twice since the data would only be added to the cache when one of the calls finishes.\n\nIt’s vital to use the same object when creating all pipeline objects and serialize it to disk between runs using and member of . This makes sure that the compiled objects are reused between runs and minimizes the frame spikes during subsequent application runs.\n\nUnfortunately, during the first play through the shader compilation spikes will still occur since the pipeline cache will not contain all used combinations. Additionally, even when the pipeline cache contains the necessary microcode, isn’t free and as such compilation of new pipeline objects can still increase the frame time variance. To solve that, it’s possible to pre-warm the in-memory cache (and/or ) during load time.\n\nOne possible solution here is that at the end of the gameplay session, the renderer could save the in-memory pipeline cache data – which shaders were used with which state – to a database. Then, during QA playthroughs, this database could be populated with data from multiple playthroughs at different graphics settings etc. – effectively gathering the set of states that are likely to be used during the actual gameplay.\n\nThis database can then be shipped with the game; at game startup, the in-memory cache could be prepopulated with all states created using the data from that database (or, depending on the amount of pipeline states, this pre-warming phase could be limited to just the states for the current graphics settings). This should happen on multiple threads to reduce the load time impact; the first run would still have a longer load time (which can be further reduced with features like Steam pre-caching), but frame spikes due to just-in-time pipeline object creation can be mostly avoided.\n\nIf a particular set of state combinations wasn’t discovered during QA playthroughs, the system can still function correctly – at the expense of some amount of stuttering. The resulting scheme is more or less universal and practical – but requires a potentially large effort to play through enough levels with enough different graphics settings to capture most realistic workloads, making it somewhat hard to manage.\n\nThe “perfect” solution – one that Vulkan was designed for – is to remove just-in-time compilation caches and pre-warming, and instead just have every single possible pipeline object available ahead of time.\n\nThis typically requires changing the renderer design and integrating the concept of the pipeline state into the material system, allowing a material to specify the state completely. There are different possible designs; this section will outline just one, but the important thing is the general principle.\n\nAn object is typically associated with the material that specifies the graphics state and resource bindings required to render the object. In this case, it’s important to separate resource bindings from the graphics state as the goal is to be able to enumerate all combinations of graphics state in advance. Let’s call the collection of the graphics state a “technique” (this terminology is intentionally similar to terminology from Direct3D Effect Framework, although there the state was stored in the pass). Techniques can then be grouped into effects, and a material would be referring to the effect, and to some sort of key to specify the technique from the effect.\n\nThe set of effects and set of techniques in an effect would be static; the set of effects would also be static. Effects are not as vital to being able to precompile pipeline objects as techniques but can serve as useful semantical grouping of techniques – for example, often material is assigned an effect at material creation time, but technique can vary based on where the object is rendered (e.g. shadow pass, gbuffer pass, reflection pass) or on the gameplay effects active (e.g. highlight).\n\nCrucially, the technique must specify all state required to create a pipeline object, statically, ahead of time – typically as part of the definition in some text file, whether in a D3DFX-like DSL, or in a JSON/XML file. It must include all shaders, blend states, culling states, vertex format, render target formats, depth state. Here’s an example of how this might look:\n\nAssuming all draw calls, including ones used for post-effects etc, use the effect system to specify render state, and assuming the set of effects and techniques is static, it’s trivial to precreate all pipeline objects – each technique needs just one – at load time using multiple threads, and at runtime use very efficient code with no need for in-memory caches or possibility of frame spikes.\n\nIn practice, implementing this system in a modern renderer is an exercise in complexity management. It’s common to use complex shader or state permutations – for example, for two-sided rendering you typically need to change culling state and perhaps change the shaders to implement two-sided lighting. For skinned rendering, you need to change vertex format and add some code to the vertex shader to transform the attributes using skinned matrices. On some graphics settings, you might decide that the render target format needs to be floating-point R10G11B10 instead of RGBA16F, to conserve bandwidth. All these combinations multiply and require you to be able to represent them concisely and efficiently when specifying technique data (for example, by allowing #ifdef sections inside technique declarations as shown above), and – importantly – being aware of the steadily growing amount of combinations and refactoring/simplifying them as appropriate. Some effects are rare enough that they could be rendered in a separate pass without increasing the number of permutations. Some computations are simple enough that always running them in all shaders can be a better tradeoff than increasing the number of permutations. And some rendering techniques offer better decoupling and separation of concerns, which can also reduce the number of permutations.\n\nImportantly though, adding state permutations to the mix makes the problem harder but doesn’t make it different – many renderers have to solve the problem of a large number of shader permutations anyway, and once you incorporate all render state into shader/technique specification and focus on reducing the number of technique permutations, the same complexity management solutions apply equally to both problems. The benefit of implementing a system like this is perfect knowledge of all required combinations (as opposed to having to rely on fragile permutation discovery systems), great performance with minimal frame-to-frame variance including the first load, and a forcing function to keep the complexity of rendering code at bay.\n\nVulkan API shifts a large amount of responsibility from driver developers onto application developers. Navigating the landscape of various rendering features becomes more challenging when many implementation options are available; it’s challenging enough to write a correct Vulkan renderer, but performance and memory consumption is paramount. This article tried to discuss various important considerations when dealing with specific problems in Vulkan, present multiple implementation approaches that provide different tradeoffs between complexity, ease of use and performance, and span the range between porting existing renderers to redesigning renderers around Vulkan.\n\nUltimately, it’s hard to give a general advice that works across all vendors and is applicable to all renderers. For this reason, it’s vital to profile the resulting code on the target platform/vendor – for Vulkan, it’s important to monitor the performance across all vendors that the game is planning to ship on as the choices the application makes are even more important, and in some cases a specific feature, like fixed-function vertex buffer bindings, is the fast path on one vendor but a slow path on another.\n\nBeyond using validation layers to ensure code correctness and vendor-specific profiling tools, such as AMD Radeon Graphics Profiler or NVidia Nsight Graphics, many open-source libraries that can help optimize your renderer for Vulkan are available:\n• VulkanMemoryAllocator - provides convenient and performant memory allocators for Vulkan as well as other memory-related algorithms such as defragmentation.\n• volk - provides an easy way to use driver-provided Vulkan entrypoints from the driver directly which can reduce function call overhead\n• simple_vulkan_synchronization - provides a way to specify Vulkan barriers using a simplified access type model, which helps balance correctness and performance\n• Fossilize - provides serialization support for various Vulkan objects, most notably for pipeline state creation info which can be used to implement pre-warming for a pipeline cache.\n• perfdoc - provides layers similar to validation layers, that analyze the stream of rendering command and identify potential performance problems on ARM GPUs\n• niagara - provides an example bindless renderer that follows some of the advice from this article (but not all of it!)\n• Vulkan-Samples - provides many samples that explore various tradeoffs in implementation of Vulkan rendering techniques along with details on the performance on mobile.\n\nFinally, some vendors develop open-source Vulkan drivers for Linux; studying their sources can help gain more insight into performance of certain Vulkan constructs:\n\nGPUOpen-Drivers for AMD - contains xgl which has the Vulkan driver source, and PAL which is a library used by xgl; many Vulkan function calls end up going through both xgl and PAL"
    },
    {
        "link": "https://reddit.com/r/GraphicsProgramming/comments/iq6762/designing_a_proper_vulkan_3d_renderer",
        "document": "I have just started learning graphics programming and am currently building a game engine to apply my knowledge of it and other software engineering topics I'm interested in learning. I've been looking through different vulkan resources but they all have one or more of the following problems\n• They only teach upto rendering a triangle in one giant source file and call it a day. How does one then organize that code into a proper renderer?\n• They talk about specific self contained topics and not how it would fit into a renderer e.g talking about deferred shading or ray traced screen space reflections without proper implementation details and how to integrate that with a renderer.\n• The tutorials are horribly old\n\nTo my beginner eyes, they seem like very interesting topics but I don't know how to design a Renderer API for my engine that I can use to draw scenes and then change the implementation to include new interesting features. There are open source projects on GitHub but again as a beginner they seem too complex for me to make sense of without at least documentation to guide me.\n\nI am basically looking for resources that would help me with the architecture of a 3d Vulkan renderer so that I can later fill in the details with the various topics I learn eg. put in forward shading, deferred shading, ambient occlusion etc\n\nAny and all help would be greatly appreciated."
    },
    {
        "link": "https://edw.is/learning-vulkan",
        "document": "tl;dr: I learned some Vulkan and made a game engine with two small game demos in 3 months.\n\nThe code for the engine and the games can be found here: https://github.com/eliasdaler/edbr\n\nThis article documents my experience of learning Vulkan and writing a small game/engine with it. It took me around 3 months to do it without any previous knowledge of Vulkan (I had previous OpenGL experience and some experience with making game engines, though).\n\nThe engine wasn’t implemented as a general purpose engine, which is probably why it took me a few months (and not years) to achieve this. I started by making a small 3D game and separated reusable parts into the “engine” afterwards. I can recommend everyone to follow the same process to not get stuck in the weeds (see “Bike-shedding” section below for more advice).\n\nI’m a professional programmer, but I’m self-taught in graphics programming. I started studying graphics programming around 1.5 years ago by learning OpenGL and writing a 3D engine in it.\n\nThe engine I wrote in Vulkan is mostly suited for smaller level-based games. I’ll explain things which worked for me, but they might not be the most efficient. My implementation would probably still be a good starting point for many people.\n\nIf you haven’t done any graphics programming before, you should start with OpenGL. It’s much easier to learn it and not get overwhelmed by all the complexity that Vulkan has. A lot of your OpenGL and graphics programming knowledge will be useful when you start doing things with Vulkan later.\n\nIdeally, you should at least get a textured model displayed on the screen with some simple Blinn-Phong lighting. I can also recommend doing some basic shadow mapping too, so that you learn how to render your scene from a different viewpoint and to a different render target, how to sample from depth textures and so on.\n\nI can recommend using the following resources to learn OpenGL:\n• Thorsten Thormählen’s lectures lectures (watch the first 6 videos, the rest might be a bit too advanced)\n\nSadly, most OpenGL resources don’t teach the latest OpenGL 4.6 practices. They make writing OpenGL a lot more enjoyable. If you learn them, transitioning to Vulkan will be much easier (I only learned about OpenGL 3.3 during my previous engine development, though, so it’s not a necessity).\n\nHere are some resources which teach you the latest OpenGL practices:\n\nBike-shedding and how to avoid it\n\nAh, bike-shedding… Basically, it’s a harmful pattern of overthinking and over-engineering even the simplest things. It’s easy to fall into this trap when doing graphics programming (especially when doing Vulkan since you need to make many choices when implementing an engine with it).\n• Always ask yourself “Do I really need this?”, “Will this thing ever become a bottleneck?”.\n• Remember that you can always rewrite any part of your game/engine later.\n• Don’t implement something unless you need it right now. Don’t think “Well, a good engine needs X, right…?”.\n• Don’t try to make a general purpose game engine. It’s probably even better to not think about “the engine” at first and write a simple game.\n• Make a small game first - a Breakout clone, for example. Starting your engine development by doing a Minecraft clone with multiplayer support is probably not a good idea.\n• Be wary of people who tend to suggest complicated solutions to simple problems.\n• Don’t look too much at what other people do. I’ve seen many over-engineered engines on GitHub - sometimes they’re that complex for a good reason (and there are years of work behind them). But you probably don’t need most of that complexity, especially for simpler games.\n• Don’t try to make magical wrappers around Vulkan interfaces prematurely, especially while you’re still learning Vulkan.\n\nGet it working first. Leave “TODO”/“FIXME” comments in some places. Then move on to the next thing. Try to fix “TODO”/“FIXME” places only when they really become problematic or bottleneck your performance. You’ll be surprised to see how many things won’t become a problem at all.\n\nThe situation with graphic APIs in 2024 is somewhat complicated. It all depends on the use case: DirectX seems like the most solid choice for most AAA games. WebGL or WebGPU are the only two choices for doing 3D graphics on the web. Metal is the go-to graphics API on macOS and iOS (though you can still do Vulkan there via MoltenVK).\n\nMy use case is simple: I want to make small 3D games for desktop platforms (Windows and Linux mostly). I also love open source technology and open standards. So, it was a choice between OpenGL and Vulkan for me.\n\nOpenGL is a good enough choice for many small games. But it’s very unlikely that it’ll get new versions in the future (so you can’t use some newest GPU capabilities like ray tracing), it’s deprecated on macOS and its future is uncertain.\n\nWebGPU was also a possible choice. Before learning Vulkan, I learned some of it. It’s a pretty solid API, but I had some problems with it:\n• It’s still not stable and there’s not a lot of tutorials and examples for it. This tutorial is fantastic, though.\n• WGSL is an okay shading language, but I just find its syntax not as pleasant as GLSL’s (note that you can write in GLSL and then load compiled SPIR-V on WebGPU native).\n• On desktop, it’s essentially a wrapper around other graphic APIs (DirectX, Vulkan, Metal).This introduces additional problems for me:\n• It can’t do things some things that Vulkan or DirectX can do.\n• It has more limitations than native graphic APIs since it needs to behave similarly between them.\n• RenderDoc captures become confusing as they differ between the platforms (you can get DirectX capture on Windows and Vulkan capture on Linux) and you don’t have 1-to-1 mapping between WebGPU calls and native API calls.\n• Using Dawn and WGPU feels like using bgfx or sokol. You don’t get the same degree of control over the GPU and some of the choices/abstractions might not be the most pleasant for you.\n\nStill, I think that WebGPU is a better API than OpenGL/WebGL and can be more useful to you than Vulkan in some use cases:\n• Validation errors are much better than in OpenGL/WebGL and not having global state helps a lot.\n• It’s also kind of similar to Vulkan in many things, so learning a bit of it before diving into Vulkan also helped me a lot.\n• It requires a lot less boilerplate to get things on the screen (compared to Vulkan).\n• You don’t have to deal with explicit synchronization which makes things much simpler.\n• You can make your games playable inside the browser.\n\nLearning Vulkan seemed like an impossible thing for me previously. It felt like you needed to have many years of AAA game graphics programming experience to be able to do things in it. You also hear people saying “you’re basically writing a graphics driver when writing in Vulkan” which also made Vulkan sounds like an incredibly complicated thing.\n\nI have also checked out some engines written in Vulkan before and was further demotivated by seeing tons of scary abstractions and files named like or which had thousands of lines of scary C++ code.\n\nThe situation has changed over the years. Vulkan is not as complicated as it was before. First of all, Khronos realized that some parts of Vulkan were indeed very complex and introduced some newer features which made many things much simpler (for example, dynamic rendering). Secondly, some very useful libraries which reduce boilerplate were implemented. And finally, there are a lot of fantastic resources which make learning Vulkan much easier than it was before.\n\nThe best Vulkan learning resource which helped me get started was vkguide. If you’re starting from scratch, just go through it all (you might stop at “GPU driver rendering” chapter at first - many simple games probably won’t need this level of complexity)\n\nVulkan Lecture Series by TU Wien also nicely teaches Vulkan basics (you can probably skip “Real-Time Ray Tracing” chapter for now). I especially found a lecture on synchronization very helpful.\n\nHere are some more advanced Vulkan books that also helped me:\n• 3D Graphics Rendering Cookbook by Sergey Kosarevsky and Viktor Latypov. There is the second edition in the writing and it’s promising to be better than the first one. The second edition is not released yet, but the source code for it can be found here: https://github.com/PacktPublishing/3D-Graphics-Rendering-Cookbook-Second-Edition\n• Mastering Graphics Programming with Vulkan by Marco Castorina, Gabriel Sassone. Very advanced book which explains some of the “cutting edge” graphics programming concepts (I mostly read it to understand where to go further, but didn’t have time to implement most of it). The source code for it can be found here: https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan\n\nHere’s the result of my first month of learning Vulkan:\n\nBy this point I had:\n\nOf course, doing it for the 3rd time (I had it implemented it all in OpenGL and WebGPU before) certainly helped. Once you get to this point, Vulkan won’t seem as scary anymore.\n\nLet’s see how the engine works and some useful things I learned.\n\nMy engine is called EDBR (Elias Daler’s Bikeshed Engine) and was initially started as a project for learning Vulkan. It quickly grew into a somewhat usable engine which I’m going to use for my further projects.\n\nI copy-pasted some non-graphics related stuff from my previous engine (e.g. input handling and audio system) but all of the graphics and many other core systems were rewritten from scratch. I feel like it was a good way to do it instead of trying to cram Vulkan into my old OpenGL abstractions.\n\nLet’s see how this frame in rendered:\n\nFirst, models with skeletal animations are skinned in the compute shader. The compute shader takes unskinned mesh and produces a buffer of vertices which are then used instead of the original mesh in later rendering steps. This allows me to treat static and skinned meshes similarly in shaders and not do skinning repeatedly in different rendering steps.\n\nI use a 4096x4096 depth texture with 3 slices for cascaded shadow mapping. The first slice looks like this:\n\nAll the models are drawn and shading is calculated using the shadow map and light info. I use a PBR model which is almost identical to the one described in Physically Based Rendering in Filament. The fragment shader is quite big and does calculation for all the lights affecting the drawn mesh in one draw call:\n\nEverything is drawn into a multi-sampled texture. Here’s how it looks after resolve:\n\nDepth resolve step is performed manually via a fragment shader. I just go through all the fragments of multi-sample depth texture and write the minimum value into the non-MS depth texture (it’ll be useful in the next step).\n\nSome post FX is applied - right now it’s only depth fog (I use “depth resolve” texture from the previous step here), afterwards tone-mapping and bloom will also be done here.\n\nDialogue UI is drawn. Everything is done in one draw call (more is explained in “Drawing many sprites” section)\n\nAnd that’s it! It’s pretty basic right now and would probably become much more complex in the future (see “Future work” section).\n\nThere are a couple of libraries which greatly improve the experience of writing Vulkan. Most of them are already used in vkguide, but I still want to highlight how helpful they were to me.\n\nvk-bootstrap simplifies a lot of Vulkan boilerplate: physical device selection, swapchain creation and so on.\n\nI don’t like big wrappers around graphic APIs because they tend to be very opinionated. Plus, you need to keep a mental map of “wrapper function vs function in the API spec” in your head at all times.\n\nThankfully, vk-bootstrap is not like this. It mostly affects the initialization step of your program and doesn’t attempt to be a wrapper around every Vulkan function.\n\nI’ll be honest, I used VMA without even learning about how to allocate memory in Vulkan manually. I read about it in the Vulkan spec later - I’m glad that I didn’t have to do it on my own.\n\nVolk was very useful for me for simplifying extension function loading. For example, if you want to use very useful for setting debug names for your objects (useful for RenderDoc captures and validation errors), you’ll need to do this if you don’t use volk:\n\nWith volk, all the extensions are immediately loaded after you call and you don’t need to store these pointers everywhere. You just include and call - beautiful!\n\nI have a class which encapsulates most of the commonly used functionality and stores many objects that you need for calling Vulkan functions ( , and so on). A single instance is created on the startup and then gets passed around.\n• returns a new which is later used in all the drawing steps.\n• does drawing to the swapchain and does sync between the frames.\n\nThat’s… a lot of things. However, it’s not that big: is only 714 lines at the time of writing this article. It’s more convenient to pass one object into the function instead of many ( , , and so on).\n\nIn Vulkan, you can use any shading language which compiles to SPIR-V - that means that you can use GLSL, HLSL and others. I chose GLSL because I already knew it from my OpenGL experience.\n\nYou can pre-compile your shaders during the build step or compile them on the fly. I do it during the build so that my shader loading runtime code is simpler. I also don’t have an additional runtime dependency on the shader compiler. Also, shader errors are detected during the build step and I don’t get compile errors during the runtime.\n\nI use glslc (from shaderc project, it’s included in Vulkan SDK) which allows you to specify a in CMake which is incredibly useful when you use shader includes. If you change a shader file, all files which include it are recompiled automatically. Without the , CMake won’t be able to see which files shader files need to be recompiled and will only recompile the file which was changed.\n\nMy CMake script for building shaders looks like this:\n\nand then in the main CMakeLists file:\n\nNow, when you build a target, shaders get built automatically and the resulting SPIR-V files are put into the binary directory.\n\nPassing data to shaders in OpenGL is much simpler than it is in Vulkan. In OpenGL, you could just do this:\n\nYou can also use explicit uniform location like this.\n\nIn Vulkan, you need to group your uniforms into “descriptor sets”:\n\nNow, this makes things a lot more complicated, because you need to specify descriptor set layout beforehand, use descriptor set pools and allocate descriptor sets with them, do the whole + thing, call for each descriptor set and so on.\n\nI’ll explain later how I avoided using descriptor sets by using bindless descriptors and buffer device access. Basically, I only have one “global” descriptor set for bindless textures and samplers, and that’s it. Everything else is passed via push constants which makes everything much easier to handle.\n\nMost of them look like this:\n\nThe function is usually called once during the engine initialization. abstraction is described in vkguide here. I modified it a bit to use the Builder pattern to be able to chain the calls.\n• does all the needed cleanup. It usually simply destroys the pipeline and its layout:\n• is called each frame and all the needed inputs are passed as arguments. It’s assumed that the sync is performed outside of the call (see “Synchronization” section below). Some pipelines are only called once per frame - some either take of objects to draw or are called like this:\n\nThe typical function looks like this:\n\nNote another thing: it’s assumed that is called between and - the render pass itself doesn’t care what texture it renders to - the caller of is responsible for that. It makes things simpler and allows you to do several draws to the same render target, e.g.:\n\nI have one vertex type for all the meshes. It looks like this:\n\nThe vertices are accessed in the shader like this:\n\nPVP frees you from having to define vertex format (no more VAOs like in OpenGL or + in Vulkan). BDA also frees you from having to bind a buffer to a descriptor set - you just pass an address to your buffer which contains vertices in push constants and that’s it.\n\nTextures were painful to work with even in OpenGL - you had “texture slots” which were awkward to work with. You couldn’t just sample any texture from the shader if it wasn’t bound to a texture slot beforehand. changed that and made many things easier.\n\nVulkan doesn’t have the exact same functionality, but it has something similar. You can create big descriptor sets which look like this:\n\nYou’ll need to maintain a list of all your textures using some “image manager” and when a new texture is loaded, you need to insert it into the array. The index at which you inserted it becomes a bindless “texture id” which then can be used to sample it in shaders. Now you can pass these ids in your push constants like this:\n\nand then you can sample your texture in the fragment shader like this:\n• I chose separate image samplers so that I could sample any texture using different samplers. Common samplers (nearest, linear with anisotropy, depth texture samplers) are created and put into array on the startup.\n• The wrapper function makes the process of sampling a lot more convenient.\n\nI use bindless ids for the mesh material buffer which looks like this:\n\nNow I can only pass material ID in my push constants and then sample texture like this in the fragment shader:\n\nNeat! No more bulky descriptor sets, just one int per material in the push constants.\n\nYou can also put different texture types into the same set like this (this is needed for being able to access textures of types other than ):\n\nAnd here’s how you can sample with a linear sampler (note that we use here instead of ):\n\nHere’s a very good article on using bindless textures in Vulkan:\n\nHandling dynamic data which needs to be uploaded every frame\n\nI find it useful to pre-allocate big arrays of things and push stuff to them in every frame. Basically, you can pre-allocate an array of N structs (or matrices) and then start at index 0 at each new frame and push things to it from the CPU. Then, you can access all these items in your shaders. For example, I have all joint matrices stored in one big array and the skinning compute shader accesses joint matrices of a particular mesh using start index passed via push constants (more about it will be explained later).\n\nHere are two ways of doing this:\n• \n• Have N buffers on GPU and swap between them.\n\nvkguide explains the concept of “in flight” frames pretty well. To handle this parallelism properly, you need to have one buffer for the “currently drawing” frame and one buffer for “currently recording new drawing commands” frame to not have races. (If you have more frames in flight, you’ll need to allocate more than 2 buffers)\n\nThis means that you need to preallocate 2 buffers on GPU. You write data from CPU to GPU to the first buffer during the first frame. While you record the second frame, GPU reads from the first buffer while you write new data to the second buffer. On the third frame, GPU reads from the second buffer and you write new info to the first buffer… and so on.\n• \n• One buffer on GPU and N “staging” buffers on CPU\n\nThis might be useful if you need to conserve some memory on the GPU.\n\nLet’s see how it works in my engine:\n\nNote how staging buffers are created using VMA’s flag and the “main” buffer from which we read in the shader is using the flag.\n\nHere’s how new data is uploaded (full implementation):\n\nI’d go with the first approach for most cases (more data on GPU, but no need for manual sync) unless you need to conserve GPU memory for some reason. I’ve found no noticeable difference in performance between two approaches, but it might matter if you are uploading huge amounts of data to GPU on each frame.\n\nNow, this might be somewhat controversial… but I didn’t find much use of the deletion queue pattern used in vkguide. I don’t really need to allocated/destroy new objects on every frame.\n\nUsing C++ destructors for Vulkan object cleanup is not very convenient either. You need to wrap everything in custom classes, add move constructors and move … It adds an additional layer of complexity.\n\nIn most cases, the cleanup of Vulkan objects happens in one place - and you don’t want to accidentally destroy some in-use object mid-frame by accidentally destroying some wrapper object.\n\nIt’s also harder to manage lifetimes when you have cleanup in happening in the destructor. For example, suppose you have a case like this:\n\nIf you want to cleanup resources (e.g. the instance of has a object) during , you can’t do that if the cleanup of is performed in its destructor.\n\nOf course, you can do this:\n\n… but I don’t like how it introduces a dynamic allocation and requires you to do write more code (and it’s not that much different from calling a function manually).\n\nRight now, I prefer to clean up stuff directly, e.g.\n\nThis approach is not perfect - first of all, it’s easy to forget to call function, This is not a huge problem since you get a validation error in case you forget to cleanup some Vulkan resources on shutdown:\n\nVMA also triggers asserts if you forget to free some buffer/image allocated with it.\n\nI find it convenient to have all the Vulkan cleanup happening explicitly in one place. It makes it easy to track when the objects get destroyed.\n\nSynchronization in Vulkan is difficult. OpenGL and WebGPU do it for you - if you read from some texture/buffer, you know that it will have the correct data and you won’t get problems with data races. With Vulkan, you need to be explicit and this is usually where things tend to get complicated.\n\nRight now I manage most of the complexities of sync manually in one place. I separate my drawing into “passes”/pipelines (as described above) and then insert barriers between them. For example, the skinning pass writes new vertex data into GPU memory. Shadow mapping pass reads this data to render skinned meshes into the shadow map. Sync in my code looks like this:\n\nOf course, this can be automated/simplified using render graphs. This is something that I might implement in the future. Right now I’m okay with doing manual sync. vkconfig’s “synchronization” validation layer also helps greatly in finding sync errors.\n\nThe following resources were useful for understanding synchronization:\n\nWith bindless textures, it’s easy to draw many sprites using one draw call without having to allocate vertex buffers at all.\n\nFirst of all, you can emit vertex coordinates and UVs using in your vertex shader like this:\n\nThis snippet produces this set of values:\n\nAll the sprite draw calls are combined into which looks like this in GLSL:\n\nOn CPU/C++ side, it looks almost the same:\n\nI create two fixed size buffers on the GPU and then upload the contents of (using techniques described above in the “Handling dynamic data” section).\n\nThe sprite renderer is used like this:\n\nAnd finally, here’s how the command to do the drawing looks like inside :\n\nThe complete sprite.vert looks like this:\n\nAll the parameters of the sprite draw command are self-explanatory, but needs a bit of clarification. Currently, I use it to branch inside the fragment shader:\n\nThis allows me to draw sprites differently depending on this ID without having to change pipelines. Of course, it can be potentially bad for the performance. This can be improved by drawing sprites with the same shader ID in batches. You’ll only need to switch pipelines when you encounter a draw command with a different shader ID.\n\nThe sprite renderer is very efficient: it can draw 10 thousand sprites in just 315 microseconds.\n\nI do skinning for skeletal animation in a compute shader. This allows me to have the same vertex format for all the meshes.\n\nBasically, I just take the mesh’s vertices (not skinned) and joint matrices and produce a new buffer of vertices which are used in later rendering stages.\n\nSuppose you spawn three cats with identical meshes:\n\nAll three of them can have different animations. They all have an identical “input” mesh. But the “output” vertex buffer will differ between them, which means that you need to pre-allocate a vertex buffer for each instance of the mesh.\n\nHere’s how the skinning compute shader looks like:\n• I store all joint matrices in a big array and populate it every frame (and also pass the starting index in the array for each skinned mesh, ).\n• Skinning data is not stored inside each mesh vertex, a separate buffer of elements is used.\n\nAfter the skinning is performed, all the later rendering stages use this set of vertices Thee rendering process for static and skinned meshes becomes identical, thanks to that.\n\nI have a game/renderer separation which uses a simple concept of “draw commands”. In the game logic, I use entt, but the renderer doesn’t know anything about entities or “game objects”. It only knows about the lights, some scene parameters (like fog, which skybox texture to use etc) and meshes it needs to draw.\n\nThe renderer’s API looks like this in action:\n\nWhen you call or , the renderer creates a mesh draw command and puts it in which are then iterated through during the drawing process. The looks like this:\n• is used for looking up static meshes in - it’s a simple of references to vertex buffers on GPU.\n• If the mesh has a skeleton, is used during compute skinning and is used for all the rendering afterwards (instead of )\n• is used for frustum culling.\n\nThis separation is nice because the renderer is clearly separated from the game logic. You can also do something more clever as described here if sorting draw commands becomes a bottleneck.\n\nI use Blender as a level editor and export it as glTF. It’s easy to place objects, colliders and lights there. Here’s how it looks like:\n\nWriting your own level editor would probably take months (years!), so using Blender instead saved me quite a lot of time.\n\nIt’s important to mention how I use node names for spawning some objects. For example, you can see an object named selected in the screenshot above. The part before the first dot is the prefab name (in this case “Interact”). The “Sphere” part is used by the physics system to create a sphere physics body for the object (“Capsule” and “Box” can also be used, otherwise the physics shape is created using mesh vertices).\n\nSome models are pretty complex and I don’t want to place them directly into the level glTF file as it’ll greatly increase each level’s size. I just place an “Empty->Arrows” object and name it something like “Cat.NearStore”. This will spawn “Cat” prefab and attach “NearStore” tag to it for runtime identification.\n\nPrefabs are written in JSON and look like this:\n\nDuring the level loading process, if the node doesn’t have a corresponding prefab, it’s loaded as-is and its mesh data is taken from the glTF file itself (this is mostly used for static geometry). If the node has a corresponding prefab loaded, it’s created instead. Its mesh data is loaded from the external glTF file - only transform is copied from the original glTF node (the one in the level glTF file).\n\nUsing forward rendering allowed me to easily implement MSAA. Here’s a comparison of how the game looks without AA and with MSAA on:\n\nMSAA is explained well here: https://vulkan-tutorial.com/Multisampling\n\nHere’s another good article about MSAA: https://therealmjp.github.io/posts/msaa-overview/ and potential problems you can have with it (especially with HDR and tone-mapping).\n\nMy UI system was inspired by Roblox’s UI API: https://create.roblox.com/docs/ui\n\nBasically, the UI can calculate its own layout without me having to hard code each individual element’s size and position. Basically it relies on the following concepts:\n• Origin is an anchor around which the UI element is positioned. If origin is , setting UI element’s position to be will make its upper-left pixel have (x,y) pixel coordinate. If the origin is , then the element’s bottom-right corner will be positioned at . If the origin is (0.5, 1) then it will be positioned using bottom-center point as the reference.\n• Relative size makes the children’s be proportional to parent’s size. If (1,1) then the child element will have the same size as the parent element. If it’s (0.5, 0.5) then it’ll have half the size of the parent. If the parent uses children’s size as a guide, then if a child has (0.5, 0.25) relative size, the parent’s width will be 2x larger and the height will be 4x larger.\n• Relative position uses parent’s size as a guide for positioning. It’s useful for centering elements, for example if you have an element with (0.5, 0.5) origin and (0.5, 0.5) relative position, it’ll be centered inside its parent element.\n• You can also set pixel offsets for both position and size separately (they’re called and in my codebase).\n• You can also set a fixed size for the elements if you don’t want them to ever be resized.\n• The label/image element size is determined using its content.\n\nHere are some examples of how it can be used to position child elements:\n\na) The child (yellow) has relative size (0.5, 1), relative position of (0.5, 0.5) and origin (0.5, 0.5) (alternatively, the relative position can be (0.5, 0.0) and origin at (0.5, 0.0) in this case). Its parent (green) will be two times wider, but will have the same height. The child element will be centered inside the parent.\n\nb) The child (yellow) has origin (1, 1), fixed size (w,h) and absolute offset of (x,y) - this way, the item can be positioned relative to the bottom-right corner of its parent (green)\n\nLet’s see how sizes and positions of UI elements are calculated (implementation in EDBR).\n\nFirst, sizes of all elements are calculated recursively. Then positions are computed based on the previously computed sizes and specified offset positions. Afterwards all elements are drawn recursively - parent element first, then its children etc.\n\nWhen calculating the size, most elements either have a “fixed” size (which you can set manually, e.g. you can set some button to always be 60x60 pixels) or their size is computed based on their content. For example, for label elements, their size is computed using the text’s bounding box. For image elements, their size equals the image size and so on.\n\nIf an element has an “Auto-size” property, it needs to specify which child will be used to calculate its size. For example, the menu nine-slice can have several text labels inside the “vertical layout” element - the bounding boxes will be calculated first, then their sizes will be summed up - then, the parent’s size is calculated.\n\nLet’s take a look at a simple menu with bounding boxes displayed:\n\nHere, root is marked as “Auto-size”. To compute its size, it first computes the size of its child ( ). This recursively computes the sizes of each button, sums them up and adds some padding ( also makes the width of each button the same based on the maximum width in the list).\n\nI love Dear ImGui. I used it to implement many useful dev and debug tools (open the image in a new tab to see them better):\n\nIt has some problems with sRGB, though. I won’t explain it in detail, but basically if you use sRGB framebuffer, Dear ImGui will look wrong in many ways, see the comparison:\n\nSometimes you can see people doing hacks by doing with Dear ImGui’s colors but it still doesn’t work properly with alpha and produces incorrect color pickers.\n\nI ended up writing my own Dear ImGui backend and implementing DilligentEngine’s workaround which is explained in detail here and here.\n\nThere are some additional benefits of having my own backend:\n• It supports bindless texture ids, so I can draw images by simply calling . Dear ImGui’s Vulkan backend requires you to “register” textures by calling for each texture before you can call .\n• It can properly draw linear and non-linear images by passing their format into backend (so that sRGB images are not gamma corrected twice when they’re displayed)\n• Initializing and dealing with it is easier as it does Vulkan things in the same way as the rest of my engine.\n\nThere are many parts of the engine not covered there because they’re not related to Vulkan. I still feel like it’s good to mention them briefly for the sake of completion.\n\nIntegrating it into the engine was pretty easy. Right now I mostly use it for collision resolution and basic character movement.\n\nThe samples are fantastic. The docs are very good too.\n\nI especially want to point out how incredible is. It handles basic character movement so well. I remember spending days trying to get proper slope movement in Bullet to work. With Jolt, it just worked “out of the box”.\n\nHere’s how it basically works (explaining how it works properly would probably require me to write quite a big article):\n• You add your shapes to Jolt’s world.\n• You get new positions of your physics objects and use these positions to render objects in their current positions.\n• I use entt for the entity-component-system part.\n\nIt has worked great for me so far. Previously I had my own ECS implementation, but decided to experiment with a 3rd party ECS library to have less code to maintain.\n• I use openal-soft, libogg and libvorbis for audio.\n\nThe audio system is mostly based on these articles: https://indiegamedev.net/2020/02/15/the-complete-guide-to-openal-with-c-part-1-playing-a-sound/\n\nIntegrating it was very easy (read the PDF doc, it’s fantastic!) and it helped me avoid tons of bike-shedding by seeing how little time something, which I thought was “inefficient”, really took.\n\nWhat I gained from switching to Vulkan\n\nThere are many nice things I got after switching to Vulkan:\n\nThis makes abstractions a lot easier. With OpenGL abstractions/engines, you frequently see “shader.bind()” calls, state trackers, magic RAII, which automatically binds/unbinds objects and so on. There’s no need for that in Vulkan - it’s easy to write functions which take some objects as an input and produce some output - stateless, more explicit and easier to reason about.\n• API is more pleasant to work with overall - I didn’t like “binding” things and the whole “global state machine” of OpenGL.\n• You need to write less abstractions overall.\n\nWith OpenGL, you need to write a lot of abstractions to make it all less error-prone… Vulkan’s API requires a lot less of this, in my experience. And usually the abstractions that you write map closer to Vulkan’s “raw” functions, compared to OpenGL abstractions which hide manipulation of global state and usually call several functions (and might do some stateful things for optimization).\n\nValidation errors are very good in Vulkan. While OpenGL has , it doesn’t catch that many issues and you’re left wondering why your texture looks weird, why your lighting is broken and so on. Vulkan has more extensive validation which makes the debugging process much better.\n\nI can now debug shaders in RenderDoc. It looks like this:\n\nWith OpenGL I had to output the values to some texture and color-pick them… which took a lot of time. But now I can debug vertex and fragment shaders easily.\n• More consistent experience across different GPUs and OSes.\n\nWith OpenGL, drivers on different GPUs and OSes worked differently from each other which made some bugs pop up only on certain hardware configurations. It made the process of debugging them hard. I still experienced some slight differences between different GPUs in Vulkan, but it’s much less prevalent compared to OpenGL.\n• Ability to use better shading languages in the future\n\nGLSL is a fine shading language, but there are some new shading languages which promise to be more feature-complete, convenient and readable, for example:\n\nI might explore them in the future and see if they offer me something that GLSL lacks.\n• More control over every aspect of the graphics pipeline.\n\nMy first OpenGL engine was written during the process of learning graphics programming from scratch. Many abstractions were not that good and rewriting them with some graphics programming knowledge (and some help from vkguide) helped me implement a much cleaner system.\n\nAnd finally, it makes me proud to be able to say “I have a custom engine written in Vulkan and it works”. Sometimes people start thinking about you as a coding wizard and it makes me happy and proud of my work. :)\n\nThere are many things that I plan to do in the future, here’s a list of some of them:\n• Loading many images and generating mipmaps in parallel (or use image formats which already have mipmaps stored inside of them)\n\nOverall, I’m quite satisfied with what I managed to accomplish. Learning Vulkan was quite difficult, but it wasn’t as hard as I imagined. It taught me a lot about graphics programming and modern APIs and now I have a strong foundation to build my games with."
    },
    {
        "link": "https://reddit.com/r/vulkan/comments/n2w9w0/how_do_you_design_structure_your_vulkan",
        "document": "I've been following the Vulkan Tutorial website and have been referencing Overv's Hello Triange GitHub repo. The tutorial website seems like a great reference and starting point, and it seems that Overv has followed it as well. My one concern is how this tutorial (and Overv) puts all of the Vulkan related code into one class. It seems very messy and hard to manage.\n\nI am wondering how you all prefer to organize your Vulkan code? Do you do what this tutorial does and put it all into one class or do you break it into multiple classes (window, device, etc ...)? Do you make your own api/wrapper for interfacing with Vulkan or do you directly use the Vulkan calls everywhere?"
    },
    {
        "link": "https://github.com/g-truc/glm",
        "document": "OpenGL Mathematics (GLM) is a header only C++ mathematics library for graphics software based on the OpenGL Shading Language (GLSL) specifications.\n\nGLM provides classes and functions designed and implemented with the same naming conventions and functionality than GLSL so that anyone who knows GLSL, can use GLM as well in C++.\n\nThis project isn't limited to GLSL features. An extension system, based on the GLSL extension conventions, provides extended capabilities: matrix transformations, quaternions, data packing, random numbers, noise, etc...\n\nThis library works perfectly with OpenGL but it also ensures interoperability with other third party libraries and SDK. It is a good candidate for software rendering (raytracing / rasterisation), image processing, physics simulations and any development context that requires a simple and convenient mathematics library.\n\nGLM is written in C++98 but can take advantage of C++11 when supported by the compiler. It is a platform independent library with no dependence and it officially supports the following compilers:\n\nFor more information about GLM, please have a look at the manual and the API reference documentation. The source code and the documentation are licensed under either the Happy Bunny License (Modified MIT) or the MIT License.\n\nThanks for contributing to the project by submitting pull requests.\n\nAnd then in your :\n\nIf your prefer to use header-only version of GLM\n\nYou can add glm to your CMake project to be built together.\n• Unit tests are not build by default, set to required.\n• Enables only warnings as errors while building unit tests\n• Added and to GLM_EXT_scalar_common and GLM_EXT_vector_common\n• Added GLM_FORCE_UNRESTRICTED_FLOAT to prevent static asserts when using other scalar types with function expecting floats.\n• Fixed discards the sign of result for angles in range (2pi-1, 2pi) #1038\n• Removed ban on using with CUDA host code #1041\n• Added , , and function to and extensions with tests\n• Added to store quat data as w,x,y,z instead of x,y,z,w #983\n• Added GLM_EXT_scalar_integer extension with power of two and multiple scalar functions\n• Added GLM_EXT_vector_integer extension with power of two and multiple vector functions\n• Fixed for g++6 where -std=c++1z sets __cplusplus to 201500 instead of 201402 #921\n• Added GLM_FORCE_INTRINSICS to enable SIMD instruction code path. By default, it's disabled allowing constexpr support by default. #865\n• Fixed being defined as unsigned char with some compiler #839\n• Added and overload with max ULPs parameters for scalar numbers #121\n• Added to silent GLM warnings when using language extensions but using W4 or Wpedantic warnings #814 #775\n• Added to enable aligned types and SIMD instruction are not enabled. This disable #816\n• Fixed default initialization with vector and quaternion types using #812\n• Added missing and with epsilon for quaternion types to GLM_GTC_quaternion\n• Added GLM_EXT_matrix_relational: and with epsilon for matrix types\n• Added a section to the manual for contributing to GLM\n• Redesigned constexpr support which excludes both SIMD and #783\n• Clarified refract valid range of the indices of refraction, between -1 and 1 inclusively #806\n• Fixed invalid conversion from int scalar with vec4 constructor when using SSE instruction\n• Fixed infinite loop in random functions when using negative radius values using an assert #739\n• Added GLM_GTX_matrix_factorisation to factor matrices in various forms #654\n• Added GLM_EXT_vector_relational: extend and to take an epsilon argument\n• Added separate functions to use both negative one and zero near clip plans #680\n• Added to use GLM on platforms that don't support double #627\n• No more default initialization of vector, matrix and quaternion types\n• Added error for including of different versions of GLM #619\n• Added GLM_FORCE_IGNORE_VERSION to ignore error caused by including different version of GLM #619\n• Reduced warnings when using very strict compilation flags #646\n• Removed doxygen references to GLM_GTC_half_float which was removed in 0.9.4\n• Fixed references to which was removed #642\n• Fixed when OpenMP is not enabled\n• Fixed Visual C++ internal error when declaring a global vec type with siwzzle expression enabled #594\n• Fixed with Clang and libstlc++ which wasn't using C++11 STL features. #604\n• Added warning messages when using but the compiler is known to not fully support the requested C++ version #555\n• Added right and left handed projection and clip control support #447 #415 #119\n• Added and to GLM_GTC_packing for RGB9E5 #416\n• Added and to GLM_GTC_integer, fast round on positive values\n• Improved SIMD and swizzle operators interactions with GCC and Clang #474\n• Use Cuda built-in function for abs function implementation with Cuda compiler\n• No more warnings for use of long long\n• Fixed to not do any unintentional backface culling\n• Fixed long long warnings when using C++98 on GCC and Clang #482\n• Fixed long long warnings when using C++98 on GCC and Clang #482\n• Fixed to_string when used with GLM_FORCE_INLINE #506\n• Fixed intersectRayTriangle to not do any unintentional backface culling\n• Fixed outerProduct definitions and operator signatures for mat2x4 and vec4 #475\n• Fixed various 'X is not defined' warnings #468\n• Added to_string for quat and dual_quat in GTX_string_cast #375\n• Fixed builtin bitscan never being used #392\n• Added static components and precision members to all vector and quat types #350\n• Added support of defaulted functions to GLM types, to use them in unions #366\n• Don't show status message in 'FindGLM' if 'QUIET' option is set. #317\n• Fixed use of libstdc++ with Clang #351\n• Added display of GLM version with other GLM_MESSAGES\n• Clean up GLM_MESSAGES compilation log to report only detected capabilities\n• Fixed missing explicit conversion when using integer log2 with *vec1 types\n• Fixed Android build issue, STL C++11 is not supported by the NDK #284\n• Added GTX_scalar_multiplication for C++ 11 compiler only #242\n• Added GTX_range for C++ 11 compiler only #240\n• Added support of precision and integers to linearRand #230\n• Rely on C++11 to implement isinf and isnan\n• Undetected C++ compiler automatically compile with GLM_FORCE_CXX98 and GLM_FORCE_PURE\n• Added not function (from GLSL specification) on VC12\n• Used std features within GLM without redeclaring\n• Added explicit cast from quat to mat3 and mat4 #275\n• Fixed std::nextafter not supported with C++11 on Android #217\n• Fixed implicit conversion from another tvec2 type to another tvec2 #241\n• Fixed lack of consistency of quat and dualquat constructors\n• Fixed glm::isinf and glm::isnan for with Android NDK 9d #191\n• Fixed lerp when cosTheta is close to 1 in quaternion slerp #210\n• Fixed std::nextafter not supported with C++11 on Android #213\n• Fixed corner cases in exp and log functions for quaternions #199\n• Added instruction set auto detection with Visual C++ using _M_IX86_FP - /arch compiler argument\n• Added support for all extensions but GTX_string_cast to CUDA\n• Fixed non power of two matrix products\n• Fixed angle and orientedAngle that sometimes return NaN values (#145)\n• Fixed error 'inverse' is not a member of 'glm' from glm::unProject (#146)\n• Fixed mismatch between some declarations and definitions\n• Replaced C cast by C++ casts\n• Fixed .length() that should return a int and not a size_t\n• Removed the normalization of the up argument of lookAt function (#114)\n• Replaced GLM traits by STL traits when possible\n• Added creating of a quaternion from two vectors\n• Fixed detection to select the last known compiler if newer version #106\n• Fixed is_int and is_uint code duplication with GCC and C++11 #107\n• Fixed test suite build while using Clang in C++11 mode\n• Removed ms extension mode to CMake when no using Visual C++\n• Added pedantic mode to CMake test suite for Clang and GCC\n• Added use of GCC frontend on Unix for ICC and Visual C++ fronted on Windows for ICC\n• Fixed language detection on GCC when the C++0x mode isn't enabled #95\n• Fixed slerp when costheta is close to 1 #65\n• Added assert in inversesqrt to detect division by zero #61\n• Fixed glm::perspective when zNear is zero #71\n• Fixed C++11 mode for GCC, couldn't be enabled without MS extensions\n• Clarify the license applying on the manual\n• Fixed isnan and isinf on Android with Clang\n• Autodetected C++ version using __cplusplus value\n• Fixed mix for bool and bvec* third parameter\n• Fixed 0x2013 dash character in comments that cause issue in Windows Japanese mode\n• Fixed quat slerp using mix function when cosTheta close to 1\n• Added GLM_FORCE_RADIANS so that all functions takes radians for arguments\n• Fixed detection of Clang and LLVM GCC on MacOS X\n• Removed VIRTREV_xstream and the incompatibility generated with GCC\n• Fixed many warnings across platforms and compilers\n• Fixed errors and warnings in VC with C++ extensions disabled\n• Clarify that GLM is a header only library.\n• Added == and != operators for every types.\n• New method to use extension."
    },
    {
        "link": "http://glm.g-truc.net/glm.pdf",
        "document": ""
    },
    {
        "link": "https://glm.g-truc.net/0.9.8/index.html",
        "document": "OpenGL Mathematics (GLM) is a header only C++ mathematics library for graphics software based on the OpenGL Shading Language (GLSL) specifications. GLM provides classes and functions designed and implemented with the same naming conventions and functionalities than GLSL so that anyone who knows GLSL, can use GLM as well in C++. This project isn't limited to GLSL features. An extension system, based on the GLSL extension conventions, provides extended capabilities: matrix transformations, quaternions, data packing, random numbers, noise, etc... This library works perfectly with OpenGL but it also ensures interoperability with other third party libraries and SDK. It is a good candidate for software rendering (raytracing / rasterisation), image processing, physic simulations and any development context that requires a simple and convenient mathematics library.\n• GLM is written in C++98 but can take advantage of C++11 when supported by the compiler. It is a platform independent library with no dependence and it officially supports the following compilers: For more information about GLM, please have a look at the manual and the API reference documentation. The source code and the documentation, including this manual, are licensed under the Happy Bunny License (Modified MIT) or the MIT License. Thanks for contributing to the project by submitting issues for bug reports and feature requests. Any feedback is welcome at glm@g-truc.net."
    },
    {
        "link": "http://opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices",
        "document": "\n• Putting it all together\n\nThis is the single most important tutorial of the whole set. Be sure to read it at least eight times.\n\nUntil then, we only considered 3D vertices as a (x,y,z) triplet. Let’s introduce w. We will now have (x,y,z,w) vectors.\n\nThis will be more clear soon, but for now, just remember this:\n• If w == 1, then the vector (x,y,z,1) is a position in space.\n• If w == 0, then the vector (x,y,z,0) is a direction.\n\nWhat difference does this make? Well, for a rotation, it doesn’t change anything. When you rotate a point or a direction, you get the same result. However, for a translation (when you move the point in a certain direction), things are different. What could mean “translate a direction”? Not much.\n\nHomogeneous coordinates allow us to use a single mathematical formula to deal with these two cases.\n\nSimply put, a matrix is an array of numbers with a predefined number of rows and colums. For instance, a 2x3 matrix can look like this:\n\nIn 3D graphics we will mostly use 4x4 matrices. They will allow us to transform our (x,y,z,w) vertices. This is done by multiplying the vertex with the matrix:\n\nThis isn’t as scary as it looks. Put your left finger on the a, and your right finger on the x. This is ax. Move your left finger to the next number (b), and your right finger to the next number (y). You’ve got by. Once again: cz. Once again: dw. ax + by + cz + dw. You’ve got your new x! Do the same for each line, and you’ll get your new (x,y,z,w) vector.\n\nNow this is quite boring to compute, and we will do this often, so let’s ask the computer to do it instead.\n\nIn C++, with GLM:\n\nThese are the most simple tranformation matrices to understand. A translation matrix look like this:\n\nwhere X,Y,Z are the values that you want to add to your position.\n\nSo if we want to translate the vector (10,10,10,1) of 10 units in the X direction, we get:\n\n…and we get a (20,10,10,1) homogeneous vector! Remember, the 1 means that it is a position, not a direction. So our transformation didn’t change the fact that we were dealing with a position, which is good.\n\nLet’s now see what happens to a vector that represents a direction towards the -z axis: (0,0,-1,0)\n\n…i.e. our original (0,0,-1,0) direction, which is great because, as I said ealier, moving a direction does not make sense.\n\nSo, how does this translate to code?\n\nIn C++, with GLM:\n\nWell, in fact, you almost never do this in GLSL. Most of the time, you use glm::translate() in C++ to compute your matrix, send it to GLSL, and do only the multiplication:\n\nThis one is special. It doesn’t do anything. But I mention it because it’s as important as knowing that multiplying A by 1.0 gives A.\n\nScaling matrices are quite easy too:\n\nSo if you want to scale a vector (position or direction, it doesn’t matter) by 2.0 in all directions:\n\nand the w still didn’t change. You may ask: what is the meaning of “scaling a direction”? Well, often, not much, so you usually don’t do such a thing, but in some (rare) cases it can be handy.\n\nThese are quite complicated. I’ll skip the details here, as it’s not important to know their exact layout for everyday use. For more information, please have a look to the Matrices and Quaternions FAQ (popular resource, probably available in your language as well). You can also have a look at the Rotations tutorials.\n\nSo now we know how to rotate, translate, and scale our vectors. It would be great to combine these transformations. This is done by multiplying the matrices together, for instance:\n\n!!! BEWARE!!! This lines actually performs the scaling FIRST, and THEN the rotation, and THEN the translation. This is how matrix multiplication works.\n\nWriting the operations in another order wouldn’t produce the same result. Try it yourself:\n• make one step ahead (beware of your computer) and turn left;\n\nAs a matter of fact, the order above is what you will usually need for game characters and other items: Scale it first if needed; then set its direction, then translate it. For instance, given a ship model (rotations have been removed for simplification):\n• The wrong way:\n• You translate the ship by (10,0,0). Its center is now at 10 units of the origin.\n• You scale your ship by 2. Every coordinate is multiplied by 2 relative to the origin, which is far away… So you end up with a big ship, but centered at 2*10 = 20. Which you don’t want.\n• The right way:\n• You scale your ship by 2. You get a big ship, centered on the origin.\n• You translate your ship. It’s still the same size, and at the right distance.\n\nMatrix-matrix multiplication is very similar to matrix-vector multiplication, so I’ll once again skip some details and redirect you the the Matrices and Quaternions FAQ if needed. For now, we’ll simply ask the computer to do it:\n\nin C++, with GLM:\n\nFor the rest of this tutorial, we will suppose that we know how to draw Blender’s favourite 3d model: the monkey Suzanne.\n\nThe Model, View and Projection matrices are a handy tool to separate transformations cleanly. You may not use this (after all, that’s what we did in tutorials 1 and 2). But you should. This is the way everybody does, because it’s easier this way.\n\nThis model, just as our beloved red triangle, is defined by a set of vertices. The X,Y,Z coordinates of these vertices are defined relative to the object’s center: that is, if a vertex is at (0,0,0), it is at the center of the object.\n\nWe’d like to be able to move this model, maybe because the player controls it with the keyboard and the mouse. Easy, you just learnt do do so: , and done. You apply this matrix to all your vertices at each frame (in GLSL, not in C++!) and everything moves. Something that doesn’t move will be at the center of the world.\n\nYour vertices are now in World Space. This is the meaning of the black arrow in the image below: We went from Model Space (all vertices defined relatively to the center of the model) to World Space (all vertices defined relatively to the center of the world).\n\nWe can sum this up with the following diagram:\n\nWhen you think about it, the same applies to cameras. It you want to view a moutain from another angle, you can either move the camera…or move the mountain. While not practical in real life, this is really simple and handy in Computer Graphics.\n\nSo initially your camera is at the origin of the World Space. In order to move the world, you simply introduce another matrix. Let’s say you want to move your camera of 3 units to the right (+X). This is equivalent to moving your whole world (meshes included) 3 units to the LEFT! (-X). While you brain melts, let’s do it:\n\nAgain, the image below illustrates this: We went from World Space (all vertices defined relatively to the center of the world, as we made so in the previous section) to Camera Space (all vertices defined relatively to the camera).\n\nBefore you head explodes from this, enjoy GLM’s great glm::lookAt function:\n\nThis is not over yet, though.\n\nWe’re now in Camera Space. This means that after all theses transformations, a vertex that happens to have x==0 and y==0 should be rendered at the center of the screen. But we can’t use only the x and y coordinates to determine where an object should be put on the screen: its distance to the camera (z) counts, too! For two vertices with similar x and y coordinates, the vertex with the biggest z coordinate will be more on the center of the screen than the other.\n\nAnd luckily for us, a 4x4 matrix can represent this projection:\n\nWe went from Camera Space (all vertices defined relatively to the camera) to Homogeneous Space (all vertices defined in a small cube. Everything inside the cube is onscreen).\n\nHere’s another diagram so that you understand better what happens with this Projection stuff. Before projection, we’ve got our blue objects, in Camera Space, and the red shape represents the frustum of the camera: the part of the scene that the camera is actually able to see.\n\nMultiplying everything by the Projection Matrix has the following effect:\n\nIn this image, the frustum is now a perfect cube (between -1 and 1 on all axes, it’s a little bit hard to see it), and all blue objects have been deformed in the same way. Thus, the objects that are near the camera ( = near the face of the cube that we can’t see) are big, the others are smaller. Seems like real life!\n\nLet’s see what it looks like from the “behind” the frustum:\n\nHere you get your image! It’s just a little bit too square, so another mathematical transformation is applied (this one is automatic, you don’t have to do it yourself in the shader) to fit this to the actual window size:\n\nAnd this is the image that is actually rendered!\n\n…Just a standard matrix multiplication as you already love them!\n\nPutting it all together\n• Second step: generating our MVP matrix. This must be done for each model you render. // Or, for an ortho camera: // Camera is at (4,3,3), in World Space // and looks at the origin // Head is up (set to 0,-1,0 to look upside-down) // Model matrix: an identity matrix (model will be at the origin) // Our ModelViewProjection: multiplication of our 3 matrices // Remember, matrix multiplication is the other way around\n• Third step: give it to GLSL // Get a handle for our \"MVP\" uniform // Only during the initialisation // Send our transformation to the currently bound shader, in the \"MVP\" uniform // This is done in the main loop since each model will have a different MVP matrix (At least for the M part)\n• Fourth step: use it in GLSL to transform our vertices in // Input vertex data, different for all executions of this shader. // Values that stay constant for the whole mesh. // Output position of the vertex, in clip space: MVP * position\n• Done! Here is the same triangle as in tutorial 2, still at the origin (0,0,0), but viewed in perspective from point (4,3,3), heads up (0,1,0), with a 45° field of view.\n\nIn tutorial 6 you’ll learn how to modify these values dynamically using the keyboard and the mouse to create a game-like camera, but first, we’ll learn how to give our 3D models some colour (tutorial 4) and textures (tutorial 5).\n• Instead of using a perspective projection, use an orthographic projection (glm::ortho)\n• Modify ModelMatrix to translate, rotate, then scale the triangle\n• Do the same thing, but in different orders. What do you notice? What is the “best” order that you would want to use for a character?"
    },
    {
        "link": "https://stackoverflow.com/questions/70834223/tranforming-3d-matrices-with-translate-rotate-and-scale-in-glm",
        "document": "In the program I'm developing using Vulkan, I have the camera orbiting an object, where the object model (transformation) matrix is initialized like so:\n\nUsing the code below, I can change the rotation of the object through mouse motion events that calculate the changes in rotation and applying them to the matrix. There are no problems up to this point.\n\nHowever, when I try to apply translations to the model matrix using the code below, other than when the rotation = 0.f, the translation messes up completely (Every frame, changes in rotation are applied before changes in translation).\n\nBut when I use the first set of code shown previously (that was used to initialize the matrix) to recreate the entire model transformation matrix, the translation applies properly.\n\nI've reached this point by researching independently so far, but I would really appreciate any advice or feedback I could get to see what exactly I'm doing wrong.\n\nEDIT: I am also able to apply the translation successfully using the code below. Why does this work and not the one above?"
    }
]