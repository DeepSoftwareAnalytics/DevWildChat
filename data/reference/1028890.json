[
    {
        "link": "https://blog.fernvenue.com/archives/nginx-reverse-proxy",
        "document": "This is actually a part of an old archived article. I archived it mainly because the official documentation of Nginx is very comprehensive, providing detailed explanations for each section. However, lately I have received some private messages and emails requesting me to bring back some of the archived articles, including this one. Perhaps articles of this nature, which involve summaries and discussions, are helpful for quickly solving problems in daily work scenarios? So, let’s take a look at some common issues in Nginx reverse proxy scenarios by borrowing some content from the old article.\n\nReverse proxy is perhaps one of the most common use cases for Nginx. However, a common mistake in many reverse proxy configurations is not enabling keepalive connections during the process of proxying requests to upstream servers. This issue is even mentioned in Avoiding the Top 10 Nginx Configuration Mistakes by Nginx. Quoting a key excerpt from Mistake 3: Not Enabling Keepalive Connections to Upstream Servers:\n\nIt is evident that the process of handshaking and establishing a new connection incurs unavoidable efficiency drawbacks, which can even be unacceptable in high-performance, high-concurrency scenarios. Therefore, it is highly necessary to introduce keepalive connections in Nginx reverse proxy configurations.\n\nIn addition to the issue of keepalive connections, by default, Nginx only performs domain name resolution during startup. This means that even if there are changes in domain name resolution in subsequent configurations, Nginx will still only request the initially resolved address. To re-resolve the domain, you would need to reload or restart Nginx. This is not ideal for scenarios where the backend server addresses are dynamic, and many people are not even aware of this. To address this issue, it is recommended to include the directive in Nginx configuration.\n\nBy the way, many Nginx reverse proxy configurations are often in the “just working” stage. For example, they may not consider the actual IP address of the forwarded requests, resulting in the upstream servers only seeing requests coming from Nginx. This can cause unnecessary complications for debugging and data statistics. Another example is the issue with the Host request header. If the reverse proxy doesn’t handle or configure the Host request header properly, it may work just by luck. However, this approach can lead to unforeseen issues in the future.\n\nBy considering the common issues mentioned above, here’s the best practice for Nginx reverse proxy:\n\nFor WebSocket reverse proxy, we just need to pay attention to the and headers based on the above configuration:\n\nSometime the administrator of upstream server doesn’t wanna change configuration or give us access permission to help us do more on reverse proxy, here we can use to make things easier. By default, is addtional module, so we need to install it first:\n\nIf you’re not using Debian or Debian based distribution, you may need to compile Nginx with this module by yourself.\n\nAnd here’s an example configuration:\n\nAs you can see, we use to handle HTTPS thing (you may not need), and specificly handle the cookie for two sites by , in the end we use to replace all in response from upstream to then return it to the client.\n\nBy the way, you can uncomment lines to send some client side information to the upstream server.\n\nNext, let’s talk about the situation where the reverse proxy configuration becomes more and more extensive. Nginx’s virtual hosting and modular design allow us to handle requests for different sites on the same port based on the Host request header. This makes it possible to integrate these configurations by determining the specific reverse proxy targets:\n\nWhen we are dealing with HTTPS requests, the situation becomes quite different, especially when the HTTPS certificate configuration for the reverse proxy target is on the upstream server and not on Nginx. In such cases, we can’t obtain the Host information without disrupting the encrypted connection. This is when reverse proxy based on SNI is needed:\n\nThe directive here allows Nginx to preemptively read the SNI information from the HTTPS connection, making it possible for us to handle it through the variable in a block.\n\nAnd module required here so:\n\nBy the way, when using HTTPS on Nginx, don’t forget to configure automatic redirection from HTTP to HTTPS:\n\nIn today’s world, where HTTPS-only is not yet mainstream, it is essential to help users automatically accomplish this step.\n\nSometimes, we may not wanna directly return the upstream server’s response. The ability to handle requests and perform targeted actions is itself an advantage of Nginx in the reverse proxy position. When the upstream server returns an error for various reasons, replacing the upstream server’s status code is another scenario in the reverse proxy process:\n\nFirst, we use to intercept responses with a status code greater than or equal to 300 and hand them over to for handling. We use in the directive to complete the status code replacement process. Of course, 404 here is just an example, and we can configure specific status codes as needed.\n\nAlthough this is not a limitation specific to reverse proxying, it is particularly common here, especially when the upstream server doesn’t have restrictions on the size of user uploads. This often confuses people when encountering a error. To address this issue, you can adjust the directive to an appropriate size."
    },
    {
        "link": "https://stackoverflow.com/questions/12102110/nginx-to-reverse-proxy-websockets-and-enable-ssl-wss",
        "document": "I'm so lost and new to building NGINX on my own but I want to be able to enable secure websockets without having an additional layer.\n\nI don't want to enable SSL on the websocket server itself but instead I want to use NGINX to add an SSL layer to the whole thing.\n\nEvery web page out there says I can't do it, but I know I can! Thanks to whoever (myself) can show me how!"
    },
    {
        "link": "https://f5.com/company/blog/nginx/websocket-nginx",
        "document": ""
    },
    {
        "link": "https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy",
        "document": "This article describes the basic configuration of a proxy server. You will learn how to pass a request from NGINX to proxied servers over different protocols, modify client request headers that are sent to the proxied server, and configure buffering of responses coming from the proxied servers.\n\nProxying is typically used to distribute the load among several servers, seamlessly show content from different websites, or pass requests for processing to application servers over protocols other than HTTP.\n\nWhen NGINX proxies a request, it sends the request to a specified proxied server, fetches the response, and sends it back to the client. It is possible to proxy requests to an HTTP server (another NGINX server or any other server) or a non-HTTP server (which can run an application developed with a specific framework, such as PHP or Python) using a specified protocol. Supported protocols include FastCGI, uwsgi, SCGI, and memcached.\n\nTo pass a request to an HTTP proxied server, the proxy_pass directive is specified inside a location. For example:\n\nThis example configuration results in passing all requests processed in this location to the proxied server at the specified address. This address can be specified as a domain name or an IP address. The address may also include a port:\n\nNote that in the first example above, the address of the proxied server is followed by a URI, . If the URI is specified along with the address, it replaces the part of the request URI that matches the location parameter. For example, here the request with the URI will be proxied to . If the address is specified without a URI, or it is not possible to determine the part of URI to be replaced, the full request URI is passed (possibly, modified).\n\nTo pass a request to a non-HTTP proxied server, the appropriate directive should be used:\n\nNote that in these cases, the rules for specifying addresses may be different. You may also need to pass additional parameters to the server (see the reference documentation for more detail).\n\nThe proxy_pass directive can also point to a named group of servers. In this case, requests are distributed among the servers in the group according to the specified method.\n\nBy default, NGINX redefines two header fields in proxied requests, “Host” and “Connection”, and eliminates the header fields whose values are empty strings. “Host” is set to the variable, and “Connection” is set to .\n\nTo change these setting, as well as modify other header fields, use the proxy_set_header directive. This directive can be specified in a location or higher. It can also be specified in a particular server context or in the http block. For example:\n\nIn this configuration the “Host” field is set to the $host variable.\n\nTo prevent a header field from being passed to the proxied server, set it to an empty string as follows:\n\nBy default NGINX buffers responses from proxied servers. A response is stored in the internal buffers and is not sent to the client until the whole response is received. Buffering helps to optimize performance with slow clients, which can waste proxied server time if the response is passed from NGINX to the client synchronously. However, when buffering is enabled NGINX allows the proxied server to process responses quickly, while NGINX stores the responses for as much time as the clients need to download them.\n\nThe directive that is responsible for enabling and disabling buffering is proxy_buffering. By default it is set to and buffering is enabled.\n\nThe proxy_buffers directive controls the size and the number of buffers allocated for a request. The first part of the response from a proxied server is stored in a separate buffer, the size of which is set with the proxy_buffer_size directive. This part usually contains a comparatively small response header and can be made smaller than the buffers for the rest of the response.\n\nIn the following example, the default number of buffers is increased and the size of the buffer for the first portion of the response is made smaller than the default.\n\nIf buffering is disabled, the response is sent to the client synchronously while it is receiving it from the proxied server. This behavior may be desirable for fast interactive clients that need to start receiving the response as soon as possible.\n\nTo disable buffering in a specific location, place the proxy_buffering directive in the location with the parameter, as follows:\n\nIn this case NGINX uses only the buffer configured by proxy_buffer_size to store the current part of a response.\n\nA common use of a reverse proxy is to provide load balancing. Learn how to improve power, performance, and focus on your apps with rapid deployment in the free Five Reasons to Choose a Software Load Balancer ebook.\n\nIf your proxy server has several network interfaces, sometimes you might need to choose a particular source IP address for connecting to a proxied server or an upstream. This may be useful if a proxied server behind NGINX is configured to accept connections from particular IP networks or IP address ranges.\n\nSpecify the proxy_bind directive and the IP address of the necessary network interface:\n\nThe IP address can be also specified with a variable. For example, the variable passes the IP address of the network interface that accepted the request:"
    },
    {
        "link": "https://betterstack.com/community/questions/nginx-to-reverse-proxy-websockets-and-enable-ssl",
        "document": "To configure Nginx as a reverse proxy for WebSocket connections and enable SSL/TLS (for ), you'll need to set up both WebSocket-specific configuration and SSL/TLS settings. Here's a step-by-step guide to achieve this:\n\nEnsure that Nginx is installed with SSL/TLS support. You can verify this by checking if the module is available:\n\nIf it is not installed, you may need to install Nginx from a package that includes SSL support or compile it with the option.\n\nYou need SSL/TLS certificates for your domain to enable . You can obtain certificates from a Certificate Authority (CA) or use a tool like Let's Encrypt to get a free SSL certificate.\n• None Let's Encrypt: You can use tools like to obtain and automatically renew certificates.\n• None Manually: If you have your own certificates, ensure you have the certificate file ( ) and the private key file ( ).\n\nHere’s a sample Nginx configuration to set up SSL and reverse proxy WebSocket connections:\n• SSL/TLS Setup:\n• : Configures Nginx to listen on port 443 with SSL enabled.\n• and : Specify the paths to your SSL certificate and private key.\n• WebSocket Configuration:\n• : Ensures the header is passed through, which is necessary for WebSocket connections.\n• : Sets the header to for WebSocket connections.\n• HTTP to HTTPS Redirection:\n• The second server block listens on port 80 and redirects all HTTP traffic to HTTPS.\n\nAfter configuring Nginx, it’s crucial to test your configuration for syntax errors and then reload or restart Nginx to apply the changes.\n\nEnsure that your WebSocket connections are working over by using a WebSocket client or testing tool. For example, you can use the browser’s developer tools to monitor WebSocket traffic and verify that it is being upgraded and proxied correctly.\n• None Check Nginx Logs: If there are issues, check the Nginx error and access logs for troubleshooting.\n• None Firewall and Network: Ensure that ports 80 and 443 are open and accessible through your firewall and network configuration.\n\nBy following these steps, you can successfully configure Nginx to reverse proxy WebSocket connections over SSL ( ), ensuring secure and efficient communication between clients and your WebSocket server."
    },
    {
        "link": "https://nginx.org/en/docs",
        "document": ""
    },
    {
        "link": "http://nginx.org/en/CHANGES",
        "document": ""
    },
    {
        "link": "https://docs.nginx.com/nginx/releases",
        "document": "NGINX provides technical support for F5 NGINX Plus releases for 24 months from the initial date of each release. With each new NGINX Plus release, the previously released version enters End of Software Development (EoSD). We do not issue updates for releases that have reached EoSD. For this reason, we advise customers to run the most recent release. The initial release dates for NGINX Plus are noted in this document. New releases are announced on the NGINX Product Support Announcements mailing list.\n• Licensing: Each NGINX Plus instance now requires a JWT license file. The JWT must be obtained from MyF5 and is expected to be located at for Linux or for FreeBSD or at the path specified by the in the context.\n• NGINX usage reporting: Usage report is sent to F5 licensing endpoint every hour using the secure connection. The initial usage report should be sent once NGINX Plus starts after installation or upgrade to R33. If the initial usage report is not received by the endpoint, NGINX Plus will stop processing traffic. A 180-day grace period can be enabled to submit the initial usage report. Optionally, for network-restricted environments, reporting can be configured to NGINX Instance Manager from which the report can be sent to F5 licensing endpoint. For more information about licensing and usage reporting, see About subscription licenses article and module documentation.\n• OCSP stapling support and client certificate validation with OCSP in the stream module with the and directives.\n• SSL key logging with the directive for http, stream, proxy, grpc, uwsgi that allows logging SSL keys created during client and upstream connections to the file. The argument is a file name in the format compatible with Wireshark.\n• SSL Certificate Caching: Fixed loading of trusted CA bundles containing entries with duplicate Distinguished Name (DN).\n• Change: the directive is not required for client SSL certificates verification.\n• Response trailers support in proxy with the directive that allows passing trailer fields from a proxied server to a client.\n• The NGINX JavaScript module was updated to version 0.8.7, featuring QuickJS runtime support.\n\nNGINX Plus R33 is supported on:\n• Alpine Linux 3.20 is new in this release\n• the Lua module is no longer available for SUSE Linux Enterprise Server 12\n\nThis is a bugfix release for NGINX Plus R33.\n• Resolved an issue related to product code detection on Azure Marketplace VMs.\n\nThis is a security release for NGINX Plus R33.\n• Security Fix CVE-2025-23419 in SNI that adds a restriction for TLSv1.3 cross-SNI session resumption.\n• SSL certificate caching that improves the NGINX startup time and memory usage in cases of configurations with large number of locations with relatively small number of unique certificate/key pairs\n• The module that allows passing the accepted connection directly to any configured listening socket in , , , and other similar modules\n• The , , and parameters of the listen directive in the module\n• \n• Heap Overflow w/ write (CVE-2024-32760): Undisclosed HTTP/3 encoder instructions can cause NGINX worker processes to terminate or cause other possible impacts\n• Stack Overflow / Use after free (CVE-2024-31079): Undisclosed HTTP/3 requests can cause NGINX worker processes to terminate or cause other possible impacts. This attack requires that a request be specifically timed during the connection draining process, which the attacker has no visibility and limited influence over\n• Null Pointer Dereference w/ Empty Header (CVE-2024-35200): Undisclosed HTTP/3 requests can cause NGINX worker processes to terminate or cause other possible impacts\n• Memory Disclosure during QUIC handshake (CVE-2024-34161): When the network infrastructure supports a Maximum Transmission Unit (MTU) of 4096 or greater without fragmentation, undisclosed QUIC messages can cause NGINX worker processes to terminate or cause leakage of previously freed memory\n• \n• in the MQTT Filter module: malformed packets when using default properties\n• in the zone_sync module: memory leak on configuration reload\n• Unexpected connection closure while using 0-RTT in QUIC\n• Connections with pending AIO operations might be closed prematurely during graceful shutdown of old worker processes\n• Socket leak alerts no longer logged when fast shutdown was requested after graceful shutdown of old worker processes\n• A socket descriptor error, a socket leak, or a segmentation fault in a worker process (for SSL proxying) might occur if AIO was used in a subrequest\n• A segmentation fault might occur in a worker process if SSL proxying was used along with the image_filter directive and errors with code 415 were redirected with the error_page directive\n• New features and bugfixes in njs:\n\nNGINX Plus R32 is supported on:\n• Ubuntu 24.04 LTS is new in this release\n• OpenTracing dynamic module (package name is ) is deprecated\n• ModSecurity WAF dynamic module (package name is ) reached end of support and is no longer available\n\nThese are security releases for NGINX Plus R32.\n• \n• In the MQTT Filter module, undisclosed requests can cause an increase in memory resource utilization (CVE-2024-39792)\n• In the MP4 module, a specially crafted file can cause NGINX worker memory over-read resulting in its termination by using a specially crafted file (CVE-2024-7347)\n• Security Fix CVE-2025-23419 in SNI that adds a restriction for TLSv1.3 cross-SNI session resumption.\n• Native usage reporting of NGINX Plus installations to NGINX Instance Manager\n• The $upstream_last_server_name variable that keeps the name of the last selected upstream server and allows passing it to the proxied server through SNI\n• Notable startup speedup when using a large number of locations\n• \n• the directive for http and stream that allows specifying a JS handler to run at regular intervals\n• \n• the message was rejected when a password was not provided\n• the message parsing is stopped when the message length is less than the number of bytes received\n• added the topic and payload for MQTT Version 3.1.1 if the message is rewritten\n• \n• the response header line with an empty reason phrase from the backend was handled incorrectly\n• memory leak during reconfiguration when using the PCRE2 library\n• improved detection of misbehaving clients when using HTTP/2\n• The OpenTracing module introduced in NGINX Plus R18 is deprecated, it recommended to use the OpenTelemetry Distributed Tracing module that incorporates all the features of the OpenTracing module.\n\nNGINX Plus R31 is supported on:\n• Alpine Linux 3.19 is new in this release\n• FreeBSD 14 is new in this release\n• OpenTracing dynamic module (package name is ) is deprecated\n\nThis is an improvement release for NGINX Plus R31.\n• Security: a segmentation fault might occur in a worker process if HTTP/3 was used (CVE-2024-24989, CVE-2024-24990)\n• Management module: fixed a potential crash that might happen while using a system resolver\n\nMore information: Updating NGINX for the Vulnerabilities in the HTTP/3 Module\n• \n• Heap Overflow w/ write (CVE-2024-32760): Undisclosed HTTP/3 encoder instructions can cause NGINX worker processes to terminate or cause other possible impacts\n• Stack Overflow / Use after free (CVE-2024-31079): Undisclosed HTTP/3 requests can cause NGINX worker processes to terminate or cause other possible impacts. This attack requires that a request be specifically timed during the connection draining process, which the attacker has no visibility and limited influence over\n• Null Pointer Dereference w/ Empty Header (CVE-2024-35200): Undisclosed HTTP/3 requests can cause NGINX worker processes to terminate or cause other possible impacts\n• Memory Disclosure during QUIC handshake (CVE-2024-34161): When the network infrastructure supports a Maximum Transmission Unit (MTU) of 4096 or greater without fragmentation, undisclosed QUIC messages can cause NGINX worker processes to terminate or cause leakage of previously freed memory\n• \n• In the MQTT Filter module, undisclosed requests can cause an increase in memory resource utilization (CVE-2024-39792)\n• In the MP4 module, a specially crafted file can cause NGINX worker memory over-read resulting in its termination by using a specially crafted file (CVE-2024-7347)\n• The Prometheus-njs module now supports version of the API\n• DNS reload optimization: now DNS name expiry time for dynamically-resolved upstream hosts is preserved across reloads\n• The new directive in the MQTT Filter module that specifies the number of buffers allocated per connection, the directive also supersedes the directive\n• The directive deprecated in NGINX Plus Release 16 was removed, the parameter of the directive should be used instead\n• The new directive obsoletes the parameter of the directive which is now deprecated\n• Optional NGINX diagnostic scripts that collect the data required for troubleshooting are available as a separate download package\n• \n• the directive for http and stream that allows declaring a dictionary shared between worker processes\n• The GeoIP2 module is no longer available for Amazon Linux 2 as the EPEL repository doesn’t provide the library required to build the module\n\nNGINX Plus R30 is supported on:\n• Alpine Linux 3.18 is new in this release\n• Debian 12 is new in this release\n• The GeoIP2 dynamic module (package name is ) for Amazon Linux 2 is no longer provided\n\nThis is an improvement release for NGINX Plus R30.\n• Additional protection against HTTP/2 Rapid Reset Attack vulnerability (CVE-2023-44487) that may affect NGINX only when it is configured with the keepalive requests value substantially higher than the default value. Limitations in HTTP/2 protocol allow clients to produce a higher RPS rate than expected from a configured HTTP/2 max concurrent streams setting which can be exploited to trigger a Denial-of-Service attack.\n• Security: a segmentation fault might occur in a worker process if HTTP/3 was used (CVE-2024-24990)\n\nMore information: Updating NGINX for the Vulnerabilities in the HTTP/3 Module\n• MQTT messaging protocol support with the MQTT Preread and MQTT Filter modules\n• OpenTelemetry Distributed Tracing module, distributed in NGINX Plus packages (package name is ) and is available as a dynamic module\n• Experimental support for HTTP/3 and QUIC, distributed in NGINX Plus packages (package name is )\n• TLS 1.3 is enabled by default (the parameter of the ssl_protocols directive)\n• The internal_redirect directive and module that allows internal redirects after checking request and connection processing limits, and access limits\n• New feature in OpenID Connect reference implementation: support for access token\n• The Prometheus-njs module now supports version of the API, including SSL extended statistics for each HTTP upstream and stream upstream, SSL extended statistics for each HTTP server zone and stream server zone, and extended statistics for SSL\n• The NGINX JavaScript (njs) module for NGINX Plus was updated to version 0.7.12, featuring extended Fetch API and WebCrypto API, XML module to parse and modify XML documents, Zlib module to support compression\n\nNGINX Plus R29 is supported on:\n• Amazon Linux 2023 is new in this release\n• The ModSecurity dynamic module (package name is ) is no longer supported\n\nThis is an improvement release for NGINX Plus R29.\n• Additional protection against HTTP/2 Rapid Reset Attack vulnerability (CVE-2023-44487) that may affect NGINX only when it is configured with the keepalive requests value substantially higher than the default value. Limitations in HTTP/2 protocol allow clients to produce a higher RPS rate than expected from a configured HTTP/2 max concurrent streams setting which can be exploited to trigger a Denial-of-Service attack.\n• \n• SSL extended statistics for each HTTP upstream and stream upstream\n• SSL extended statistics for each HTTP server zone and stream server zone\n• PROXY protocol v2 TLV variables for Amazon Web Services, Google Cloud Platform, and Microsoft Azure in HTTP and stream\n• The variable for HTTP and stream that can keep different TLV types from the PROXY protocol header including SSL TLV types\n• Sticky cookie load-balancing method now can accept variables in the SameSite attribute in addition to , ,or values\n• NGINX Plus live activity monitoring dashboard now supports HTTP status code statistics and extended SSL statistics for upstreams and server zones\n• TLS session tickets encryption keys are now automatically rotated when using shared memory in the directive\n• Looking up of IPv4 addresses while resolving now can be disabled with the parameter of the directive.\n• Changes in handling multiple headers with identical names.\n• Most of the known duplicate upstream response headers are now ignored with a warning.\n• Duplicate and headers are now rejected as well as the responses with invalid or headers, or if both and are present in the response.\n\nNGINX Plus R28 is supported on:\n• AlmaLinux 8 and 9 are new in this release\n• Alpine Linux 3.17 is new in this release\n• Oracle Linux 9 is new in this release\n• Rocky Linux 8 and 9 are new in this release\n• \n• SSL statistics for each HTTP upstream and stream upstream\n• SSL statistics for each HTTP server zone and stream server zone\n• JWT Authentication: error code can be customized with the parameter of the directive if any additional condition of JWT validation fails\n• HTTP health checks: the parameter of the directive that enables keepalive connections for health checks and specifies the time during which requests can be processed through one keepalive connection\n• The Prometheus-njs module now supports version of the API, including , , data, and HTTP status code statistics for upstreams, server zones and location zones\n• kTLS is now also available on RHEL 9.0 and Ubuntu 22.04\n\nNGINX Plus R27 is supported on:\n• Alpine Linux 3.16 is new in this release\n• RHEL 9.0+ is new in this release\n• Ubuntu 22.04 LTS is new in this release\n\nThis is a bug‑fix release for NGINX Plus R27.\n• In HLS (CVE-2022-41743) and MP4 (CVE-2022-41741) modules when processing specially crafted video files a memory corruption, or a memory disclosure in MP4 module (CVE-2022-41742) could happen.\n• Enhanced ALPN support with the directive for stream, and the variable for HTTP and stream\n• The variable that returns the negotiated curve used for SSL handshake key exchange process\n• The directive for stream that allows closing one side of a connection while the data is still transmitted\n• The directive in the MP4 module that forces a video to always start with a key frame\n\nNGINX Plus R26 is supported on:\n• Alpine Linux 3.15 is new in this release\n• Added support for IBM Z (s390x) for CentOS 8+, RHEL 8+, and Ubuntu 20.04 LTS\n• The directive was removed, the directive should be used instead\n• The directive was removed, the directive should be used instead\n• The third-party was removed from the dynamic modules repository, the directive should be used instead\n• Swagger UI with REST API YAML specification is not included into NGINX Plus packages by default any more and now is a part of docs.nginx.com\n\nThis is a bug‑fix release for NGINX Plus R26.\n• In HLS (CVE-2022-41743) and MP4 (CVE-2022-41741) modules when processing specially crafted video files a memory corruption, or a memory disclosure in MP4 module (CVE-2022-41742) could happen.\n• \n• support for signed and then encrypted Nested JWT with the parameter of the auth_jwt_type directive\n• additional conditions for JWT validation can be specified with the auth_jwt_require directive\n• the $jwt_payload variable that returns either enclosed JWS token for Nested JWT, or JSON with claims for JWE\n• now it is possible to have multiple auth_jwt_key_file and auth_jwt_key_request directives within the same context\n• API version 7: HTTP status code statistics are now collected per-code, in addition to aggregation per-class, for upstreams, server zones, and location zones\n• Stream health checks: introduced the persistent parameter in the health_check directive that enables persistence of mandatory health check status during configuration reload\n• TCP Fast Open support with the parameter of the listen directive in the stream module\n• \n• the number of errors before closing the connection can be specified with the max_errors directive to mitigate against ALPACA attack\n• the and header lines are now passed to the mail proxy authentication server\n• Security hardening of HTTP request parsing. NGINX Plus will return an error if:\n• spaces or control characters are found in the request line, header names, or the request header line\n• the method is used\n• both and header lines are present in the request\n• Request body filters API now permits buffering of the data being processed.\n• Support for dynamic SSL certificate loading for http, grpc, and uwsgi backends\n\nNGINX Plus R25 is supported on:\n• Alpine 3.14 is new in this release\n• Debian 11 is new in this release\n\nThis is a bug‑fix release for NGINX Plus R25.\n• Fixed a crash that might happen when an upstream server was updated via the API\n• Support for JSON Web Encryption added to the JSON Web Token (JWT) module\n• HTTP health checks: introduced the persistent parameter in the health_check directive that enables persistence to mandatory health checks after reload\n• Flags in the proxy_cookie_flags directive can now contain variables\n• Support for PROXY Protocol in mail (the parameter of the listen directive, proxy_protocol and set_real_ip_from directives)\n• If free worker connections are exhausted, NGINX Plus starts closing not only keepalive connections, but also connections in lingering_close\n• The maximum duration of a persistent connection can be limited with the directive for http and upstream servers\n• New variable, $connection_time, that keeps connection time\n\nNGINX Plus R24 is supported on:\n• FreeBSD 13 is new in this release\n• Alpine 3.13 is new in this release\n• SUSE Linux Enterprise Server 15 SP2 is new in this release\n• CentOS 7 (aarch64) is new in this release\n\nNGINX Plus repositories have been separated into individual repositories based on operating system distribution and license subscription. Before upgrading from previous NGINX Plus versions, you must first reconfigure your repositories to point to the correct location. To reconfigure your repository, follow the installation instructions for your operating system.\n\nThese are bug‑fix releases for NGINX Plus R24.\n• Resolver: an issue in NGINX resolver may allow an attacker who is able to forge UDP packets from the specified DNS server to cause a 1-byte memory overwrite, resulting in a worker process interruption or other unspecified impact (CVE-2021-23017)\n• gRPC health checks: introduced the type=grpc parameter in the health_check directive that enables active health checks of gRPC upstream servers\n• Sticky cookie load-balancing method now can accept the SameSite attribute with , ,or values\n• Support for cookie flags with the proxy_cookie_flags and userid_flags directives\n• Introduced script that performs unprivileged installation of NGINX Plus\n• New command-line switch to redefine an error log file: -e\n• New set directive for stream that allows setting a value for a variable\n• Added support for arbitrary OpenSSL configuration commands with the ssl_conf_command directive\n• The ssl_reject_handshake directive that allows rejecting the SSL handshake in the block\n• Support for proxy_smtp_auth user authentication on the SMTP backend in mail proxy\n• Cache manager improved to monitor the minimum amount of free space (the parameter of the proxy_cache_path directive)\n\nNGINX Plus R23 is supported on:\n• Alpine 3.12 is new in this release\n• Debian 10 (aarch64) is new in this release\n\nThis is a bug‑fix release for NGINX Plus R23.\n• Resolver: an issue in NGINX resolver may allow an attacker who is able to forge UDP packets from the specified DNS server to cause a 1-byte memory overwrite, resulting in a worker process interruption or other unspecified impact (CVE-2021-23017)\n\nNGINX Plus R22 is supported on:\n• Support for a variable parameter to the grpc_pass directive enables dynamic gRPC routing\n\nNGINX Plus R21 is supported on:\n• Alpine 3.11 is new in this release\n• Ubuntu 20.04 is new in this release\n• NGINX Plus is no longer available for 32‑bit (i386) platforms. Applies to:\n• Enhancements to rate limiting: endpoint in NGINX Plus API for real‑time metrics, $limit_req_status variable captures request’s rate‑limiting status in access log\n• Enhancements to connection limiting: endpoint in NGINX Plus API for real‑time metrics, $limit_conn_status variable captures request’s connection‑limiting status in access log, dry‑run mode with limit_conn_dry_run directive\n• Support in key‑value store for matching on start of character strings (new parameter to keyval_zone directive)\n• Security improvements for HTTP/2: better detection of invalid client behavior, improved error responses, improved functioning of proxy_request_buffering and worker_shutdown_timeout directives\n\nNGINX Plus R20 R20 is supported on:\n• CentOS 8.0+ is new in this release\n• FreeBSD 12.1 is new in this release\n• RHEL 8.1 is new in this release\n• Ubuntu 19.10 is new in this release\n• Metrics about DNS resolver functionality (new parameter to resolver directive)\n• Two new tabs on NGINX Plus live activity monitoring dashboard for metrics about DNS and clustering; per‑location metrics are also reported\n• Dry‑run mode for testing effects of request‑rate limits on production traffic without actually enforcing them (new limit_req_dry_run directive)\n• Support in key‑value store for IP address ranges in CIDR notation as well as individual addresses (new parameter to keyval_zone directive)\n• Expiration time can be set for each key‑value entry to override default expiration time, either at creation time for new entry or as a modification to existing entry\n• The parameter to the limit_rate, limit_rate_after, proxy_download_rate, and proxy_upload_rate directives can be a variable\n\nNGINX Plus R19 is supported on:\n• Alpine Linux 3.10 is new in this release\n• Debian 10 is new in this release\n• Ubuntu 14.04 LTS and 18.10 are no longer supported\n• Ubuntu 19.04 is new in this release\n• Dynamic SSL certificate loading, either from file or from key-value storage (for the latter case, prefix the variable with )\n• New features in OpenID Connect reference implementation: opaque session tokens as a browser cookie, refresh tokens to refresh expired ID tokens without user interaction, and a logout URL\n• Additional logic for verifying arbitrary variables in active health checks (new parameter to match directive)\n• Wildcard support for listen directive means same zone_sync configuration can now be used for all instances in a cluster\n• For TCP/UDP, existing connections to proxied upstream server can be explicitly closed after server is removed from upstream group due to health check failure, API call, or re-resolve action (new proxy_session_drop directive)\n• New variable, $upstream_bytes_sent, contains number of bytes sent to an upstream server\n• New or updated dynamic modules:\n• OpenTracing (New): Ability to instrument NGINX Plus with OpenTracing‑compliant requests for a range of distributed tracing services, such as Datadog, Jaeger, and Zipkin\n• Lua (Updated): Scripting language for NGINX Plus, updated to use LuaJIT 2.1\n• NGINX JavaScript (Updated): JavaScript module for NGINX Plus, updated to version 0.3.0\n\nNGINX Plus R18 is supported on:\n• Amazon Linux 2017.09 is no longer supported; minimum supported version is now 2018.03\n• CentOS/Oracle/Red Hat Enterprise Linux 7.3 is no longer supported; minimum supported version is now 7.4\n• Debian 8.0 will be removed at NGINX Plus R19\n• Ubuntu 14.04 will be removed at NGINX Plus R19\n\nThis is a bug‑fix release for NGINX Plus R18.\n• Security patch: When using HTTP/2 a client might cause excessive memory consumption and CPU usage (CVE-2019-9511, CVE-2019-9513, CVE-2019-9516)\n• Support for TLS 1.3 using parameter to ssl_protocols directive\n• Two‑stage rate limiting with the new parameter; excessive requests are initially delayed and then ultimately rejected\n• Support for the Ed25519 and Ed448 cryptographic algorithms added to the JSON Web Token (JWT) module\n• Ability to fetch JSON Web Keys (JWK) directly from identity provider (IdP) when using OpenID Connect (new auth_jwt_key_request directive)\n• TCP keepalives between NGINX Plus and the proxied server (new proxy_socket_keepalive directive)\n• Control over how long HTTP keepalive connection between NGINX Plus and proxied server can be idle before being closed (new keepalive_timeout directive)\n• For UDP, number of packets sent from NGINX Plus to proxied server before new UDP “session” to that server is started can be set explicitly (new proxy_requests directive)\n• Zone Synchronization module can now pass server name using SNI when connecting to cluster nodes for server name verification (new zone_sync_ssl_server_name directive)\n• The NGINX JavaScript module has been updated:\n• Variables and functions can be redeclared\n• Integration with the NGINX Stream module for TCP/UDP applications has been refactored to use various return functions, including a method for modifying ingress trafficl egress traffic is now available through a callback\n\nNGINX Plus R17 is supported on:\n• Alpine Linux 3.8 and 3.9 are new in this release\n• CentOS/Oracle Linux/RHEL 7.3 will be removed at NGINX Plus R18\n• FreeBSD 11.2 and 12.0 are new in this release; versions 10.4 and 11.1 are no longer supported\n• Ubuntu 14.04 will be removed at NGINX Plus R19\n• Ubuntu 18.10 is new in this release\n• New random load‑balancing algorithm with Random with Two Choices variant, for which least_time or least_conn can be used to decide between the two choices\n• UDP load balancing (stream module) enhanced with support for multiple UDP packets from the client, enabling use of more complex UDP protocols such as OpenVPN, VoIP, and VDI\n• Support for PROXY Protocol v2 (PPv2) header, and ability to inspect custom TLV values in header\n• Support for AWS PrivateLink, Amazon’s technology for creating secure tunnels into a VPC\n• New $ssl_preread_protocol variable to distinguish between SSL/TLS and other protocols when forwarding traffic using a TCP (stream) proxy\n• The NGINX JavaScript module has been updated:\n• Single object ( ) is used to access both request and response attributes associated with each HTTP request\n\nNGINX Plus R16 is supported on:\n• FreeBSD 10.4+ and 11.1+ are new in this release; versions 10.3 and 11.0 are no longer supported\n• Amazon Linux 2 (LTS) is updated to the GA version.\n• The Upstream Conf and Extended Status modules are superseded by the NGINX Plus API module and are no longer distributed in NGINX Plus (see our transition guide for details)\n• The New Relic plug‑in for NGINX has been updated to use the new NGINX Plus API, but is no longer supported by NGINX, Inc.\n\nThis is a bug‑fix release for NGINX Plus R16.\n• Security patch: When using HTTP/2 a client might cause excessive memory consumption (CVE-2018-16843) and CPU usage (CVE-2018-16844)\n• Security patch: Processing of a specially crafted MP4 file with the ngx_http_mp4_module might result in worker process memory disclosure (CVE-2018-16845)\n• Sticky learn session persistence in a cluster using new Zone Synchronization module, which synchronizes shared memory zones across a cluster of NGINX Plus instances\n• OpenID Connect (OIDC) authorization code flow, enabling integration with CA Single Sign-On (formerly SiteMinder), ForgeRock OpenAM, Keycloak, Okta, and other identity providers\n• Crypto libraries in NGINX JavaScript module with support for common hash functions MD5, SHA-1, and SHA-256\n• Inheritance of the Linux capability so that transparent proxying does not require worker processes to have root privileges\n• New auth_jwt_leeway directive to compensate for clock skew between NGINX Plus and identity provider\n• New $upstream_queue_time variable to hold the amount of time a request spends in the upstream queue\n• New $ssl_preread_alpn_protocols variable to hold the Application Layer Protocol Negotiation (ALPN) protocols presented by client\n\nNGINX Plus R15 is supported on:\n• nginScript is now known as the NGINX JavaScript module\n• The NGINX Plus API version has been incremented to 3; all previous versions of the NGINX Plus API are still supported\n• This is the last release to support the deprecated dynamic (on-the-fly) reconfiguration and extended status APIs (see our transition guide for details)\n\nThese are bug‑fix releases for NGINX Plus R15.\n• Security patch: When using HTTP/2 a client might cause excessive memory consumption (CVE-2018-16843) and CPU usage (CVE-2018-16844)\n• Security patch: Processing of a specially crafted mp4 file with the ngx_http_mp4_module might result in worker process memory disclosure (CVE-2018-16845)\n• Third‑party modules might not be loaded due to signature incompatibility\n• Nested JSON Web Token (JWT) claims, array data, and longer key sizes (256‑, 384‑, and 512‑bit) for JWT signing algorithms, providing more flexibility and security when validating JWTs\n• Clustering support for the sticky_learn method of session persistence, as a technology preview of distribution of session state data in a cluster\n• Key‑value store and NGINX Plus API in the context, making the same key‑value store features are available for TCP/UDP applications as for HTTP applications\n• New NGINX Plus dashboard utilizing the NGINX Plus API which was introduced in NGINX Plus R13\n• Improvements to NGINX JavaScript module, including the ability to manage JSON objects, read content from filesystems, and backtrace to errors and exceptions to further improve troubleshooting\n• Ability to encode client certificates in a HTTP header and send them to backend applications with the $ssl_client_escaped_cert variable\n• Enhanced DNS resolver that preserves the list of upstream IP addresses across a reload of the NGINX Plus configuration\n• Ability to drain upstream servers extended to file‑based configurations with the drain parameter to the upstream directive\n\nNGINX Plus R14 is supported on:\n• Ubuntu 17.10 is new in this release\n• The Upstream Conf and Extended Status APIs were deprecated in NGINX Plus R13; support will continue only through NGINX Plus R15 (see our transition guide for details)\n\nThis is a bug‑fix release for NGINX Plus R14.\n• Live activity monitoring: Reinstated some missing tooltips for the dashboard\n• Ability to send duplicate all incoming traffic to a dedicated server (the mirror directive)\n• Improvements to NGINX JavaScript module, including the new interactive shell to facilitate development of NGINX JavaScript code\n• New NGINX Plus API that incorporates the functionality of the previous upstream_conf and (extended) status APIs; it includes a Swagger specification and adds support for key‑value stores\n• New build tool (download here) that creates installable packages of the many third‑party modules available for NGINX and NGINX Plus\n• Ability to gracefully shut down all live client connections when restarting NGINX Plus (the worker_shutdown_timeout directive)\n• Improvement to session persistence: quicker establishment of sticky sessions between clients and upstream groups (the parameter to the sticky learn directive)\n• Support for the third‑party HTTP Substitutions Filter module, distributed in NGINX Plus packages and available on the Dynamic Modules page\n\nNGINX Plus R13 is supported on:\n• Ubuntu 12.04 LTS and 16.10 are no longer supported\n• Ubuntu 17.04 is new in this release\n• The directive (deprecated in NGINX Plus R2) has been removed\n• The upstream_conf and (extended) status APIs are deprecated by the new NGINX Plus API and will be removed in a future release\n• Synchronization of NGINX Plus configuration across instances in a cluster, from a single primary node (new package)\n• Updates to Extended Status module data set, including NGINX Plus version ( ), usage statistics for shared memory zones (under the subtree), and additional upstream fields ( , )\n• New statistics displayed on live activity monitoring dashboard: NGINX Plus version, response time metrics, shared memory zones usage, and server names for upstreams\n• Support for the and extensions to the header, as defined by RFC 5861\n• Ability to bypass cache for byte range requests after a specified offset (the proxy_cache_max_range_offset directive)\n• Length of and cache headers increased to 128 bytes; note that the on‑disk cache format has changed, so cached content is invalidated after the upgrade and must be refreshed from the origin server\n• parameter to the directive (HTTP and Stream) which requires servers newly added to an group to pass the associated health check before receiving real traffic\n• “Zero config” UDP health check which does not require specifying a match block\n• Support in the Stream module for verification of client SSL certificates for TCP applications\n• SSL variables representing various details about client certificates and capabilities ( , , , , and )\n• The variable includes the reason for failure\n• The and variables comply with RFC 2253; legacy variants are available as and\n• Support for JSON escaping in access logs (the parameter to the log_format directive)\n• Output from the command excludes duplicated sections of configuration\n\nNGINX Plus R12 is supported on:\n• CentOS/Oracle Linux/RHEL 5.10+ will be removed at NGINX Plus R13\n• Debian 9 is new in this release\n• Ubuntu 12.04 LTS will be removed at NGINX Plus R13\n\nThese are bug‑fix releases for NGINX Plus R12.\n• Live activity monitoring: Response time metric was miscalculated under certain conditions\n• Live activity monitoring: Dashboard might hang with certain configurations\n• Dynamic modules binary compatibility between NGINX Plus and the corresponding version of open source NGINX\n• Enhancements to the Stream module: custom logging with a number of additional variables, PROXY protocol support for incoming connections, support for obtaining real IP address and port from PROXY protocol header, and ability to extract the server name from SNI into a variable for purposes such as custom routing\n• Cache manager support for iterative operations mode when deleting old cache files, reducing the disk load (see the , , and parameters of the proxy_cache_path directive)\n• Support for variables in the parameter to the sticky directive\n• New variable for both Stream and HTTP)\n\nNGINX Plus R11 is supported on:\n• FreeBSD 11.0 is new in this release\n• Ubuntu 16.10 is new in this release\n• The package is no longer provided; migrate to the package and then install the needed dynamic modules\n• New dynamic module: ModSecurity (package name is ) built on an early release of ModSecurity 3.0\n• New dynamic module: nginScript (package name is )\n• Enhancements to the Stream module used for TCP/UDP load balancing (more NGINX variables, resolver support, map module, geo module, geoip module, and split_clients A/B testing support)\n• Support for dual‑stack RSA/ECC certificates by defining multiple ssl_certificate and ssl_certificate_key directives on the same virtual server\n• Support for IP Transparency and Direct Server Return (DSR) using the parameter to the proxy_bind directive. DSR only supported for UDP load balancing.\n• Support for the socket option where available, allowing for many more upstream connections (requires Linux kernel 4.2 or later)\n• Modules updated (both in and as dynamic modules):\n\nNGINX Plus R10 is supported on:\n• NGINX Plus R10 is the last release to include the package; if using this package, migrate to the package and then install the needed dynamic modules\n• Dynamic loading of modules (both NGINX‑authored and third‑party). The NGINX‑authored modules supported in this release: The third‑party modules supported in this release:\n• Support for retrieving upstream servers configuration via DNS records, configured with the new parameter to the server directive\n• Automatic retrying of DNS requests over TCP when UDP responses are truncated\n• Failed nonidempotent HTTP requests ( , , ) are no longer retried with the other servers in the group, unless the parameter is included in the proxy_next_upstream directive\n• Automatic binding of worker processes to available CPUs using the new parameter of the worker_cpu_affinity directive\n• Optional offloading of some cache write operations to thread pools, configured with the aio_write on directive\n• Support for customizing the response header, as well as the signature in standard error messages\n\nNGINX Plus R9 is supported on:\n\nThis is a bug‑fix release for NGINX Plus R9.\n• Segmentation fault might occur when writing a client request body to a temporary file\n• Specially crafted request might cause NGINX worker process to crash due to a NULL pointer dereference (CVE-2016-4450)\n• Improved HTTP/2 implementation now included in the and packages; the package is deprecated\n• Caching improvements, including support for caching HEAD requests and more effective caching of large files with the Cache Slice module\n• Changes to upstream groups made with the on‑the‑fly reconfiguration API can now be configured to persist across restarts and configuration reloads\n• Support for sending health check requests to a specified port (the parameter to the health_check directive)\n• Enhancement to the Real IP module: the new variable represents the original client IP address\n• Enhancement to syslog logging: the parameter disables logging of the hostname field, which is unnecessary when logging to a local server\n\nNGINX Plus R8 is supported on:\n\nNGINX Plus R8 does not include the package; if you previously used this package, migrate to the package\n\nThese are bug‑fix releases for NGINX Plus R8.\n• Resolver: Limit resolutions to prevent remote attackers from causing a denial of service (CVE-2016-0747)\n• Support for HTTP/2 in the new package (the and packages continue to support SPDY) Note: Before installing the package, you must remove the parameter on all directives in your configuration (replace it with the and parameters to enable support for HTTP/2). NGINX Plus fails to start if any directives have the parameter.\n• \n• Ability to set local IP address of origin for outgoing connections\n• New parameter to listen directive to limit size of queue of pending connections\n• New tcp_nodelay directive to control use of OS option\n• More efficient distribution of connections across NGINX Plus worker processes (new parameter to the listen directive)\n• Thread pools for multithreaded reading and sending of files without blocking worker processes\n• Additional arguments to playlist and fragment URIs in the HLS module ( , , and )\n• New flag on command to dump the configuration to standard output in a standardized format\n• New $upstream_connect_time variable to capture the connection time to upstream servers\n• sub_filter directive now supports variables in both the string being replaced and the replacement string; multiple directives can appear at a configuration level\n• \n• New Redis module for access to Redis databases through Lua\n\nNGINX Plus R7 is supported on:\n• Ubuntu 10.04 LTS and 14.10 are no longer supported\n• NGINX Plus R7 is the last release that includes the package; customers using the package will have to migrate to the package in NGINX Plus R8\n\nMore information and important upgrade information for users of the Phusion Passenger Open Source module: Announcing NGINX Plus Release 7\n• Proxy cache enhancements (variables in value of proxy_cache directive, new parameter to proxy_cache_path directive)\n\nNGINX Plus R6 is supported on:\n\nMore information: Announcing NGINX Plus Release 6 with Enhanced Load Balancing, High Availability, and Monitoring Features\n• Proxying and load balancing of raw TCP traffic (the Stream module)\n• Sticky session timeout now applies from the most recent request in the session\n• Upstream “draining” can be used to remove an upstream server without interrupting any user sessions (new parameter to the upstream_conf directive)\n• Improved control over request retries in the event of failure, based on number of tries and time; also available for FastCGI, memcached, SCGI, and uwsgi modules\n• field in response header is correctly handled for caching (multiple variants of the same resource can be cached); note that the on‑disk cache format has changed, so upgrading to R5 invalidates cached content\n\nNGINX Plus R5 is supported on:\n\nThe and packages have additional dependencies.\n• Support for SNI while working with SSL backends\n• Passphrases for SSL private keys can now be stored in an external file\n• New load‑balancing method based on user‑defined keys with optional consistency (hash directive)\n• Cache revalidation now uses header field when possible\n• Conditional logging for requests (new parameter to the access_log directive)\n• Ability to retrieve a subset of the live activity monitoring data\n• MP4 module now supports the argument in request URIs, which sets the end point of playback\n\nNGINX Plus R4 is supported on:\n\nThe and packages have additional dependencies.\n• Automatic re‑resolution of hostnames in upstream groups allows group members to be updated on‑the‑fly using DNS\n• New connection limits and an internal connection queue protect servers from connection overload and improve connection scheduling by NGINX Plus’ load balancing\n• Additional controls over SSL have been added to control the use of session tickets and reduce time to first byte\n\nNGINX Plus R3 is supported on:\n\nThe and packages have additional dependencies.\n• Cache purge support (also available for FastCGI)\n• Support for authorization based on the result of a subrequest (new ngx_http_auth_request_module module)\n\nSecurity Update to NGINX Plus Release R2 21 March 2014\n\n Based on NGINX Open Source 1.5.7‑4\n• Fixes vulnerability in experimental SPDY implementation in NGINX Open Source 1.5.7‑3 and earlier.\n\nFunctional Update to NGINX Plus R2 5 March 2014\n\n Based on NGINX Open Source 1.5.7‑3\n• NGINX Plus now correctly applies the value set with the client_max_body_size directive when processing HTTP requests that contain chunk‑encoded body data.\n\nFunctional Update to NGINX Plus R2 13 February 2014\n\n Based on NGINX Open Source 1.5.7‑2\n• Fix for premature closing of connections when using SPDY with proxy cache\n• Added status.html file for live activity monitoring, missing from some packages\n\nNGINX Plus is the fully supported, commercial version of NGINX. It includes most NGINX open source modules and adds further features:"
    },
    {
        "link": "http://nginx.org/en/docs/http/ngx_http_proxy_module.html",
        "document": "The directive also defines what is considered an unsuccessful attempt of communication with a server. The cases of , and are always considered unsuccessful attempts, even if they are not specified in the directive. The cases of , , , , and are considered unsuccessful attempts only if they are specified in the directive. The cases of and are never considered unsuccessful attempts.\n\nAllows redefining or appending fields to the request header passed to the proxied server. The can contain text, variables, and their combinations. These directives are inherited from the previous configuration level if and only if there are no directives defined on the current level. By default, only two fields are redefined:"
    },
    {
        "link": "https://github.com/nginxinc/nginx-gateway-fabric/blob/main/CHANGELOG.md",
        "document": "This document includes a curated changelog for each release. We also publish a changelog as the description of a GitHub release, which, by contrast, is auto-generated and includes links to all PRs that went into the release.\n• The version of the Helm chart is now 1.6.2\n• The version of the Helm chart is now 1.6.1\n• Add UpstreamSettingsPolicy to allow users to configure upstream settings for Services. 2941\n• Use state files for NGINX Plus upstream servers instead of the NGINX config. 2897\n• Fix an issue where updating upstreams with the NGINX Plus API would not occur if metrics were disabled. 2897\n• Support updating stream upstreams with the NGINX Plus API instead of reloading NGINX. 2897\n• Add how-to guide for configuring upstream settings for services using the UpstreamSettingsPolicy API. Find it here. 2987\n• The version of the Helm chart is now 1.6.0\n• The Gateway API version has been updated to 1.2.1. 2868\n• ObservabilityPolicy API version has been increased to due to a strengthening of validation rules. 2998\n• The version of the Helm chart is now 1.5.1\n• NGINX Plus R33 support added. The NGINX Plus release now requires a valid JSON Web Token (JWT) in order to run. Users of NGINX Plus must have this JWT added to a Secret before installing NGINX Gateway Fabric v1.5.0. See the NGINX Plus JWT guide for information on setting this up. 2760\n• Introduce SnippetsFilter API, which allows users to inject custom NGINX configuration via an HTTPRoute or GRPCRoute filter. See the SnippetsFilter guide for information on how to use SnippetsFilters. 2604\n• Stream status_zone directive is no longer set if its value is empty. 2684\n• Fix an issue with upstream names when split clients are used with a namespace name that starts with a number. 2730\n• A 503 http response code is now returned to the client when a service has no ready endpoints. 2696\n• Fix indentation in lifecycle examples. 2588. Thanks to Derek F.\n• The version of the Helm chart is now 1.5.0\n• Add to helm parameters to use during install/upgrade. 2773\n• Add as a helm parameter to use during install/upgrade. 2766\n• Add capability to configure . 2703. Thanks to Robsta86\n• NGINX Plus was updated to R33. 2760\n• Update to v1.2.0 of the Gateway API. 2694\n• Fixed issue where NGF Pod cannot recover if NGINX master process fails without cleaning up. 2131\n• Disallow routes from attaching to listeners if not present in allowed routes. 2314\n• Honor ReferenceGrants that allow GRPCRoutes to reference Services in different namespaces. 2337\n• Fixed an issue that prevented ClientSettingsPolicies and ObservabilityPolicies from working when attached to an HTTPRoute where matching conditions were defined. 2318\n• Enhanced the troubleshooting guide with more details and scenarios. 2141\n• Add info on setting up host network access. 2263. Thanks fardarter.\n• The version of the Helm chart is now 1.4.0\n• Add capability to set resource requests and limits on nginx-gateway deployment. 2216. Thanks to anwbtom.\n• Add capability to configure custom annotations for the nginx-gateway-fabric pod(s). 2250. Thanks to Robsta86.\n• NginxProxy CRD added to configure global settings (such as tracing endpoint) at the GatewayClass level. 1870\n• Add configuration option to disable HTTP2 to the NginxProxy CRD. 1925\n• Introduce ClientSettingsPolicy CRD. This CRD allows users to configure the behavior of the connection between the client and NGINX. 1940\n• Introduce support for the HTTP filter , enabling the modification of response headers within HTTPRoutes. 1880. With help from Kai-Hsun Chen.\n• Fixed issue when using BackendTLSPolicy that led to failed connections. 1934.\n• Add SecurityContextConstraints so NGF can run on Openshift. 1976\n• Add guide on how to configure tracing for HTTPRoutes and GRPCRoutes. 2026.\n• Add guide on how to use the ClientSettingsPolicy API. 2071.\n• Document how to upgrade from Open Source NGINX to NGINX Plus. 2104\n• Add overview of how custom policies work in NGINX Gateway Fabric. 2088\n• The version of the Helm chart is now 1.3.0\n• Use kustomize to install Gateway API and NGINX Gateway Fabric CRDs. 1886 and 2011\n• Annotations for GatewayClass and NginxGateway are now configurable. 1993. Thanks to sgavrylenko.\n• Fix RBAC ServiceAccount ImagePullSecrets template which caused errors when running NGF with NGINX+. 1953\n• The minimum supported version of Kubernetes is now 1.25. 1885\n• NGINX Plus was updated to R32. 2057\n• Update to v1.1.0 of the Gateway API. This includes a breaking change to BackendTLSPolicies - see the release notes for further details. 1975\n• This version of NGINX Gateway Fabric is not compatible with v1.0.0 of the Gateway API. You must upgrade the Gateway API CRDs to v1.1.0 before upgrading NGINX Gateway Fabric. For instructions, see the upgrade documentation for helm or manifests. If you are using the v1.0.0 or earlier experimental versions of GRPCRoute or BackendTLSPolicy, see v1.1.0 Upgrade Notes for instructions on upgrading the Gateway API CRDs.\n• Tracing does not work on HTTPRoutes with matching conditions. 2105\n• ClientSettingsPolicy does not work on HTTPRoutes with matching conditions. 2079\n• In restrictive environments, the NGF Pod may fail to become ready due to a permissions issue that causes nginx reloads to fail. 1695\n• Gateway API version: . This release is not compatible with v1.0.0 of the Gateway API. See the UPGRADE section above for instructions on how to upgrade.\n• NGINX Plus can now be used as the data plane. PR-1394\n• NGINX Gateway Fabric will collect and report product telemetry to an F5 telemetry service every 24h. Read https://docs.nginx.com/nginx-gateway-fabric/overview/product-telemetry/ for more info, including what gets collected and how to opt out. PR-1699\n• Stop processing resources that haven't changed. PR-1422 Thanks to Kai-Hsun Chen.\n• Prevent paths in HTTPRoute matches from conflicting with internal locations in NGINX. PR-1445\n• Add a document about how to get support. PR-1388\n• Documentation on how to build or install the NGINX Plus image.\n• The version of the Helm chart is now 1.2.0\n• nodeSelector is now configurable. PR-1531 Thanks to Leandro Martins\n• Too many matching conditions can cause reload errors. 1107\n• NGF Pod fails to become ready due to nginx reload failure. 1695\n\nThis release updates NGINX Gateway Fabric to support version 1.0.0 of the Gateway API in addition to bug fixes and documentation updates. Our docs are now available at https://docs.nginx.com/nginx-gateway-fabric.\n• Update to v1.0.0 of the Gateway API. PR-1250\n• Validate header names and report validation errors in the HTTPRoute status. PR-1239\n• Set the Gateway Listener status AttachedRoutes field to the number of Routes associated with a Listener regardless of Gateway or Route status. PR-1275\n• Set file mode explicitly for regular NGINX configuration files. PR-1323. Thanks to Kai-Hsun Chen.\n• Documentation is now available on docs.nginx.com. Link\n• The version of the Helm chart is now 1.1.0.\n• Add tolerations to the helm chart. PR-1192. Thanks to Jerome Brown.\n• Add extra volume mounts to the helm chart. PR-1193. Thanks to Jerome Brown.\n• This version of NGINX Gateway Fabric is not compatible with v0.8.0 of the Gateway API. You must upgrade the Gateway API CRDs to v1.0.0 before upgrading NGINX Gateway Fabric. For instructions, see the upgrade documentation for helm or manifests.\n\nThis is the official v1.0.0 release of NGINX Gateway Fabric.\n• Rename the product from NGINX Kubernetes Gateway to NGINX Gateway Fabric. PR-1070\n• Fix failure to recover if conf files are unexpectedly removed. PR-1132\n• Only update a resource's status if it has changed. PR-1151\n\nThis release adds a Helm chart, dynamic control plane logging, Prometheus metrics, and in-depth guides for various use cases.\n\nThis release completes all v1beta1 Core features of the Gateway API resources. See the Gateway Compatibility doc\n• Set redirect port in location header according to the scheme. PR-801\n• Set proxy host header to the exact value of the request host header. PR-827\n\n*the installation manifests use the image, which always points to the latest version of 1.25.x releases.\n• Support for more features of the Gateway API resources. See the Gateway Compatibility doc\n• Support for running the conformance test suite. See the Conformance tests README.\n• Defined Enhancement Proposal process for NGINX Kubernetes Gateway project. See the Enhancement Proposal README.\n• Improved developer documentation for contributing to the project. See the Development quickstart.\n• Architecture document that explains how NGINX Kubernetes Gateway works at a high level. See the Architecture doc\n• Update route condition where listener is not found. PR-675\n• Fix binding to multiple listeners with empty section name. PR-730\n• Set ResolvedRefs/False/InvalidKind condition on the HTTPRoute if a BackendRef specifies an unknown kind. PR-800\n\n*the installation manifests use the image, which always points to the latest version of 1.25.x releases.\n• Extensive validation of Gateway API resources for robustness, security and correctness. See the validation doc for more details.\n• Defined open-source development process for NGINX Kubernetes Gateway project. See the Issue lifecycle doc.\n• Report proper Conditions in status of HTTPRoute and Gateway when GatewayClass is invalid or doesn't exist. PR-576\n• Always generate a root \"/\" location block in NGINX config to handle unmatched requests with 404 response. PR-356\n• Fix status for parentRef with invalid listener in HTTPRoute. PR-350\n• Fix initContainer failure during pod restart. PR-337. Thanks to Tom Plant\n• Generate default http server in NGINX if http listener exists in Gateway. PR-320\n\n*the installation manifests use the image, which always points to the latest version of 1.23.x releases.\n\nThis release extends the support of the features of the Gateway API resources.\n• Support the Pod IPs instead of the virtual IP of a Service in the NGINX upstream. Additionally, NGINX Gateway Fabric will pick up any changes to the Pod IPs and update the NGINX upstream accordingly. PR-221\n• Support the redirect filter in an HTTPRoute rule. PR-218\n• Support weights in backendRefs in the HTTPRoute (traffic splitting). PR-261\n• Support the ObservedGeneration field in the HTTPRoute status. PR-254\n• Do not require the namespace in the cli argument. PR-235\n\n*the installation manifests use the image, which always points to the latest version of 1.21.x releases.\n\nThis is an initial release of NGINX Kubernetes Gateway project.\n• A control plane agent (a Kubernetes controller) that updates date plane (NGINX) configuration based on the state of the resources in the cluster.\n• Kubernetes manifests for a Deployment with a single Pod with the control plane and data plane containers as well as Services to enable external connectivity to that Pod.\n• Support for a subset of features of GatewayClass, Gateway and HTTPRoute resources (see the Gateway API Compatibility doc).\n\nWe expect that the architecture of NGINX Kubernetes Gateway -- the number of pods and containers and their interaction -- will change as the project evolves.\n\nNGINX Kubernetes Gateway is ready for experimental usage. We included the docs as well as examples.\n\nIf you'd like to give us feedback or get involved, see the README to learn how."
    }
]