[
    {
        "link": "https://docs.oracle.com/javase/tutorial/i18n/format/decimalFormat.html",
        "document": "The Java Tutorials have been written for JDK 8. Examples and practices described in this page don't take advantage of improvements introduced in later releases and might use technology no longer available. See Dev.java for updated tutorials taking advantage of the latest releases. See Java Language Changes for a summary of updated language features in Java SE 9 and subsequent releases. See JDK Release Notes for information about new features, enhancements, and removed or deprecated options for all JDK releases.\n\nYou can use the class to format decimal numbers into locale-specific strings. This class allows you to control the display of leading and trailing zeros, prefixes and suffixes, grouping (thousands) separators, and the decimal separator. If you want to change formatting symbols, such as the decimal separator, you can use the in conjunction with the class. These classes offer a great deal of flexibility in the formatting of numbers, but they can make your code more complex.\n\nThe text that follows uses examples that demonstrate the and classes. The code examples in this material are from a sample program called .\n\nYou specify the formatting properties of with a pattern . The pattern determines what the formatted number looks like. For a full description of the pattern syntax, see Number Format Pattern Syntax.\n\nThe example that follows creates a formatter by passing a pattern to the constructor. The method accepts a value as an argument and returns the formatted number in a :\n\nThe output for the preceding lines of code is described in the following table. The is the number, a , that is to be formatted. The is the that specifies the formatting properties. The , which is a , represents the formatted number.\n\nThe preceding example created a object for the default . If you want a object for a non-default , you instantiate a and then cast it to . Here's an example:\n\nRunning the previous code example results in the output that follows. The formatted number, which is in the second column, varies with :\n\nSo far the formatting patterns discussed here follow the conventions of U.S. English. For example, in the pattern ###,###.## the comma is the thousands-separator and the period represents the decimal point. This convention is fine, provided that your end users aren't exposed to it. However, some applications, such as spreadsheets and report generators, allow the end users to define their own formatting patterns. For these applications the formatting patterns specified by the end users should use localized notation. In these cases you'll want to invoke the method on the object.\n\nYou can use the DecimalFormatSymbols class to change the symbols that appear in the formatted numbers produced by the method. These symbols include the decimal separator, the grouping separator, the minus sign, and the percent sign, among others.\n\nThe next example demonstrates the class by applying a strange format to a number. The unusual format is the result of the calls to the , , and methods.\n\nWhen run, this example prints the number in a bizarre format:\n\nYou can design your own format patterns for numbers by following the rules specified by the following BNF diagram:\n\nThe notation used in the preceding diagram is explained in the following table:\n\nIn the preceding BNF diagram, the first subpattern specifies the format for positive numbers. The second subpattern, which is optional, specifies the format for negative numbers.\n\nAlthough not noted in the BNF diagram, a comma may appear within the integer portion.\n\nWithin the subpatterns, you specify formatting with special symbols. These symbols are described in the following table:"
    },
    {
        "link": "https://docs.oracle.com/javase/8/docs/api/java/text/DecimalFormat.html",
        "document": "is a concrete subclass ofthat formats decimal numbers. It has a variety of features designed to make it possible to parse and format numbers in any locale, including support for Western, Arabic, and Indic digits. It also supports different kinds of numbers, including integers (123), fixed-point numbers (123.4), scientific notation (1.23E4), percentages (12%), and currency amounts ($123). All of these can be localized.\n\nTo obtain a for a specific locale, including the default locale, call one of 's factory methods, such as . In general, do not call the constructors directly, since the factory methods may return subclasses other than . If you need to customize the format object, do something like this:\n\nA comprises a pattern and a set of symbols. The pattern may be set directly using , or indirectly using the API methods. The symbols are stored in a object. When using the factory methods, the pattern and symbols are read from localized s.\n\npatterns have the following syntax:\n\nA pattern contains a positive and negative subpattern, for example, . Each subpattern has a prefix, numeric part, and suffix. The negative subpattern is optional; if absent, then the positive subpattern prefixed with the localized minus sign ( in most locales) is used as the negative subpattern. That is, alone is equivalent to . If there is an explicit negative subpattern, it serves only to specify the negative prefix and suffix; the number of digits, minimal digits, and other characteristics are all the same as the positive pattern. That means that produces precisely the same behavior as .\n\nThe prefixes, suffixes, and various symbols used for infinity, digits, thousands separators, decimal separators, etc. may be set to arbitrary values, and they will appear properly during formatting. However, care must be taken that the symbols and strings do not conflict, or parsing will be unreliable. For example, either the positive and negative prefixes or the suffixes must be distinct for to be able to distinguish positive from negative values. (If they are identical, then will behave as if no negative subpattern was specified.) Another example is that the decimal separator and thousands separator should be distinct characters, or parsing will be impossible.\n\nThe grouping separator is commonly used for thousands, but in some countries it separates ten-thousands. The grouping size is a constant number of digits between the grouping characters, such as 3 for 100,000,000 or 4 for 1,0000,0000. If you supply a pattern with multiple grouping characters, the interval between the last one and the end of the integer is the one that is used. So == == .\n\nMany characters in a pattern are taken literally; they are matched during parsing and output unchanged during formatting. Special characters, on the other hand, stand for other characters, strings, or classes of characters. They must be quoted, unless noted otherwise, if they are to appear in the prefix or suffix as literals.\n\nThe characters listed here are used in non-localized patterns. Localized patterns use the corresponding characters taken from this formatter's object instead, and these characters lose their special status. Two exceptions are the currency sign and quote, which are not localized.\n\nNumbers in scientific notation are expressed as the product of a mantissa and a power of ten, for example, 1234 can be expressed as 1.234 x 10^3. The mantissa is often in the range 1.0 ≤ x < 10.0, but it need not be. can be instructed to format and parse scientific notation only via a pattern; there is currently no factory method that creates a scientific notation format. In a pattern, the exponent character immediately followed by one or more digit characters indicates scientific notation. Example: formats the number 1234 as .\n• The number of digit characters after the exponent character gives the minimum exponent digit count. There is no maximum. Negative exponents are formatted using the localized minus sign, not the prefix and suffix from the pattern. This allows patterns such as .\n• The minimum and maximum number of integer digits are interpreted together:\n• If the maximum number of integer digits is greater than their minimum number and greater than 1, it forces the exponent to be a multiple of the maximum number of integer digits, and the minimum number of integer digits to be interpreted as 1. The most common use of this is to generate engineering notation, in which the exponent is a multiple of three, e.g., . Using this pattern, the number 12345 formats to , and 123456 formats to .\n• Otherwise, the minimum number of integer digits is achieved by adjusting the exponent. Example: 0.00123 formatted with yields .\n• The number of significant digits in the mantissa is the sum of the minimum integer and maximum fraction digits, and is unaffected by the maximum integer digits. For example, 12345 formatted with is . To show all digits, set the significant digits count to zero. The number of significant digits does not affect parsing.\n• Exponential patterns may not contain grouping separators.\n\nprovides rounding modes defined in for formatting. By default, it uses For formatting,uses the ten consecutive characters starting with the localized zero digit defined in theobject as digits. For parsing, these digits as well as all Unicode decimal digits, as defined by , are recognized.\n\nis formatted as a string, which typically has a single character . This string is determined by the object. This is the only value for which the prefixes and suffixes are not used.\n\nInfinity is formatted as a string, which typically has a single character , with the positive or negative prefixes and suffixes applied. The infinity string is determined by the object.\n• if is false and is true,\n• if both and are false.\n\nDecimal formats are generally not synchronized. It is recommended to create separate format instances for each thread. If multiple threads access a format concurrently, it must be synchronized externally."
    },
    {
        "link": "https://stackoverflow.com/questions/2538787/how-to-print-a-float-with-2-decimal-places-in-java",
        "document": "Can I do it with System.out.print ?\n\nYou can use the method, like so: In short, the syntax tells Java to return your variable ( ) with 2 decimal places ( ) in decimal representation of a floating-point number ( ) from the start of the format specifier ( ). There are other conversion characters you can use besides :\n\nYou can use . One way to use it: Another one is to construct it using the format. I find all formatting options less readable than calling the formatting methods, but that's a matter of preference.\n\nI would suggest using String.format() if you need the value as a in your code. For example, you can use in the following way:\n\nA simple trick is to generate a shorter version of your variable by multiplying it with e.g. , rounding it and dividing it by again. This way you generate a variable, with 2 decimal places: This \"cheap trick\" was always good enough for me, and works in any language (I am not a Java person, just learning it).\n\nHere is an example from the tutorial: If you choose a pattern like \"###.##\", you will get two decimal places, and I think that the values are rounded up. You will want to look at the link to get the exact format you want (e.g., whether you want trailing zeros)\n\nOne issue that had me for an hour or more, on - It handles double and float inputs differently. Even change of RoundingMode did not help. I am no expert but thought it may help someone like me. Ended up using instead. See below: DecimalFormat df = new DecimalFormat(\"#.##\"); double d = 0.7750; System.out.println(\" Double 0.7750 -> \" +Double.valueOf(df.format(d))); float f = 0.7750f; System.out.println(\" Float 0.7750f -> \"+Float.valueOf(df.format(f))); // change the RoundingMode df.setRoundingMode(RoundingMode.HALF_UP); System.out.println(\" Rounding Up Double 0.7750 -> \" +Double.valueOf(df.format(d))); System.out.println(\" Rounding Up Float 0.7750f -> \" +Float.valueOf(df.format(f)));\n\nJust do if you want to ensure that independently of the Locale of the user, you will always get / display a \".\" as decimal separator. This is a must if you don't want to make your program crash if you later do some kind of conversion like"
    },
    {
        "link": "https://stackoverflow.com/questions/12806278/double-decimal-formatting-in-java",
        "document": "An alternative method is use the method from the class.\n\nHere you basically specify how many numbers you want to appear after the decimal point.\n\nSo an input of would produce , assuming your specified amount was 2.\n\nBut, if your input contains more than the amount specified, it will take the minimum amount specified, then add one more digit rounded up/down\n\nFor example, with a minimum amount of 2 specified will produce"
    },
    {
        "link": "https://baeldung.com/java-decimalformat",
        "document": "In this article, we’re going to explore the DecimalFormat class along with its practical usages.\n\nThis is a subclass of NumberFormat, which allows formatting decimal numbers’ String representation using predefined patterns.\n\nIt can also be used inversely, to parse Strings into numbers.\n\n2. How Does It Work?\n\nIn order to format a number, we have to define a pattern, which is a sequence of special characters potentially mixed with text.\n\nThere are 11 Special Pattern Characters, but the most important are:\n• # – prints a digit if provided, nothing otherwise\n• . – indicate where to put the decimal separator\n• , – indicate where to put the grouping separator\n\nWhen the pattern gets applied to a number, its formatting rules are executed, and the result is printed according to the DecimalFormatSymbol of our JVM’s Locale unless a specific Locale is specified.\n\nThe following examples’ outputs are from a JVM running on an English Locale.\n\nLet’s now see which outputs are produced when formatting the same number with the following patterns.\n\nAs we can see, the integer part is never discarded, no matter if the pattern is smaller than the number.\n\nIf the pattern instead is bigger than the number, zeros get added, while hashes get dropped, both in the integer and in the decimal parts.\n\nIf the decimal part of the pattern can’t contain the whole precision of the input number, it gets rounded.\n\nHere, the .89 part has been rounded to .90, then the 0 has been dropped:\n\nHere, the .89 part has been rounded to 1.00, then the .00 has been dropped and the 1 has been summed to the 7:\n\nThe default rounding mode is HALF_EVEN, but it can be customized through the setRoundingMode method.\n\nThe grouping separator is used to specify a sub-pattern which gets repeated automatically:\n\nSome countries have a variable number of grouping patterns in their numbering systems.\n\nThe Indian Numbering System uses the format #,##,###.##, in which only the first grouping separator holds three numbers, while all the others hold two numbers.\n\nThis isn’t possible to achieve using the DecimalFormat class, which keeps only the latest pattern encountered from left to right, and applies it to the whole number, ignoring previous grouping patterns.\n\nAn attempt to use the pattern #,##,##,##,### would result in a regroup to #######,### and end in a redistribution to #,###,###,###.\n\nTo achieve multiple grouping pattern matching, it’s necessary to write our own String manipulation code, or alternatively to try the Icu4J’s DecimalFormat, which allows that.\n\nIt’s possible to mix String literals within the pattern:\n\nIt’s also possible to use special characters as String literals, through escaping:\n\nMany countries don’t use English symbols and use the comma as decimal separator and the dot as grouping separator.\n\nRunning the #,###.## pattern on a JVM with an Italian Locale, for example, would output 1.234.567,89.\n\nWhile this could be a useful i18n feature in some cases, in others we might want to enforce a specific, JVM-independent format.\n\nHere’s how we can do that:\n\nIf the Locale we’re interested in is not among the ones covered by the DecimalFormatSymbols constructor, we can specify it with the getInstance method:\n\nThe Scientific Notation represents the product of a Mantissa and an exponent of ten. The number 1234567.89 can also be represented as 12.3456789 * 10^5 (the dot is shifted by 5 positions).\n\nIt’s possible to express a number in Scientific Notation using the E pattern character representing the exponent of ten:\n\nWe should keep in mind that the number of characters after the exponent is relevant, so if we need to express 10^12, we need E00 and not E0.\n\nIt’s common to use a particular form of Scientific Notation called Engineering Notation, which adjusts results in order to be expressed as multiple of three, for example when using measuring units like Kilo (10^3), Mega (10^6), Giga (10^9), and so on.\n\nWe can enforce this kind of notation by adjusting the maximum number of integer digits (the characters expressed with the # and on the left of the decimal separator) so that it’s higher than the minimum number (the one expressed with the 0) and higher than 1.\n\nThis forces the exponent to be a multiple of the maximum number, so for this use-case we want the maximum number to be three:\n\nLet’s see how is possible to parse a String into a Number with the parse method:\n\nSince the returned value isn’t inferred by the presence of a decimal separator, we can use the methods like .doubleValue(), .longValue() of the returned Number object to enforce a specific primitive in output.\n\nWe can also obtain a BigDecimal as follows:\n\nDecimalFormat isn’t thread-safe, thus we should pay special attention when sharing the same instance between threads.\n\nWe’ve seen the major usages of the DecimalFormat class, along with its strengths and weaknesses."
    },
    {
        "link": "https://stackoverflow.com/questions/54474749/creating-a-dice-class-that-returns-a-random-value",
        "document": "We were given this task which I am having a hard time trying to finish because I am usually more comfortable with my way of programming but the code given is unfinished.\n\nThe task is to create a Dice class using only the Dice() as the constructor and and the roll() as a method. We must use the imported Random class. Random has a method called which takes an integer as a parameter and returns a random integer between 0(inclusive) and the given parameter(exclusive). For example:\n\nThe given code was:"
    },
    {
        "link": "https://stackoverflow.com/questions/12860398/basic-random-rolling-dice-java",
        "document": "I am trying to write a method rollDice(int number, int nSides) which returns the total result of rolling the number dice with nSides sides.\n\nSo for example rollDice(3, 6) should return the result of rolling 3 six-sided dice (adding to a number between 3 and 18 inclusive).\n\nBelow method returns negative numbers when I type 1 for what do I need to do to fix this?"
    },
    {
        "link": "https://hackmd.io/@bu-csci-205/spring2025Archived/%2F2OtpEcxWTByAdk1oJ8vnaQ",
        "document": "<!-- markdownlint-disable line-length single-h1 no-inline-html --> <!-- markdownlint-configure-file { \"ul-indent\": { \"indent\": 4 }, \"link-fragments\": {\"ignore_case\": true} } --> Archived Jams: CSCI 205 Spring 2025 === Archived --- - [Return to - CSCI 205 Spring 2025](https://hackmd.io/@bu-csci-205/spring2025/) [target=_blank] Jam04 - Due 2/20 --- - [📚 Full Assignment](/QfGqoQflQlC8Vry0RkF4VQ) - [✅ Task Checklist](/xJuc3f6wQI-ePwPZ5ZzOOg) - [Exercise 1 - Setting up Gradle](/eLyEKqP7TLCQOtunO6UWRQ) - [Exercise 2 - Git Branching and Calculator Implementation](/bUjJKCRQRb-KBqFW865qnA) - [Exercise 3 - Array Operations](/UaMuu4D3T12Trpu8Kfb2ug) - [Exercise 4 - Statistical Analysis with Skewness](/8VbVzNvgR52ORUB90BSA0Q) - [Summary and Submission](/OwwFSsfnSiyhf4_BqMi6gg) Jam03 - Due 2/13 --- - [📚 Full Assignment](/z0hpnt2fT_Kbex4SOY1duQ) - [✅ Task Checklist](/rOmnEuaXS_WEYVvnkmX0AA) - [Exercise 1 - Regular Expression Fundamentals](/9KZ9RNybQDeZvyPVMyk2JQ) - [Exercise 2 - Basic Debugging Tools](/xMav1K5jReOHIysXxftHMQ) - [Exercise 3 - Scientific Debugging & Pattern Analysis](/YCrMVVFSTH2t-BbAFjBwVw) - [Exercise 4 - Log Analysis and Refactoring](/Vi5azNdTTta2q8gKr_zy4Q) - [Exercise 5 - Base-3 Converter with Regex and Refactoring](/62OQ-rqFQAqUHqEjfiz6Mw) - [Summary and Submission](/A8lp_dwHRk6qwskIa6LG5g) Jam02 - Due 2/6 --- - [📚 Full Assignment](/xyi54rFkQC-i0tbvNBnKtg) - [✅ Task Checklist](/q-RCaT2SRcW64j7hYq1anQ) - [Exercise 1 - Understanding Java Types](/yUwn_gVmQW-NEvpqnT1QZw) - [Exercise 1.5 - Code Style Configuration](/jWsPyo0ETA2cWKHWzf2n0g) - [Exercise 2 - Measuring Performance Impact](/UZrs0J78TBi_suhVnNFPpw) - [Exercise 3 - Simulating Dice Rolls](/2OtpEcxWTByAdk1oJ8vnaQ) - [Exercise 4 - Understanding Methods and Recursion](/V7qpdAQaSvenCAKu41Tm-w) - [Exercise 5 - Fibonacci and BigInteger](/hIjNBxWqRYG61v7mW-Q4oA) - [Summary and Submission](/u4IZXZewTj2lBzyE0KGdRw) Jam01 --- - [📚 Full Assignment](/CFt2bC6lRRObOBCk1h49Xw) - [✅ Task Checklist](/tcxUMG0dQO6jwkAI8bZQGw) - [Exercise 1 - IDE Setup & Configuration](/U-puet-5SNS28bmKVU4AiA) - [Exercise 2 - Hello World & Java Fundamentals](/j9GgdHxoQ4yCPF5VuYREdQ) - [Exercise 3 - Understanding the Java API Documentation](/gPqU-3YPT0aAZHj3vhKebA) - [Exercise 4 - User Input & System Properties](/QLkaW8DYSEqVMIb_ZS5VDA) - [Exercise 5 - Decision Making with Java](/akOZMcXESvuw98gXAaRW0A) - [Exercise 6 - Circle Calculator & java.lang.Math](/JoDDiBoZTumYbxErYC6nog) - [Summary to Submission](/nZ6NFNZxS5eZ1neLsF9XWA) Jam00 --- - [📚 Full Assignment](/pi5TAscMTO2XLvIC8ckfiw) - [✅ Task Checklist](/0nAFlkbJQ0mjtEpg-x1ZLA) - [Exercise 1 - Learning the Shell](/hB16VzUDQl6cuCYYUk2FUg) - [Exercise 2 - Development Environment Setup](/wd8nfwOMRXKoD0lJPpQRMQ) - [Exercise 3 - Project Structure Setup](/yfMdx0s7TR6tJNp0ZFrp4A) - [Exercise 4 - Git Setup and Configuration](/5guwAyQWTFSaVQo2MVnaHA) - [Exercise 5 - Creating Your Project README](/Ufns-udtRSSnkOOsGCZdfg) - [Exercise 6 - Honor Code and Final Submission](/omTVl50qRcKsJRMxSNXkEQ)"
    },
    {
        "link": "https://quora.com/How-do-I-get-dice-numbers-in-Java",
        "document": "Something went wrong. Wait a moment and try again."
    },
    {
        "link": "https://github.com/cmrfrd/Random-Java/blob/master/DiceSimulation.java",
        "document": "You can’t perform that action at this time."
    },
    {
        "link": "https://codegym.cc/groups/posts/integer-division-java",
        "document": "What is Integer Division in Java?\n\n1 Example of Integer Division in Java [ Remainder is 0 ]\n\nExample 2 [ Remainder is not 0 ]\n• None First, you need to convert the dividend to a double.\n• None Round off the quotient using the Math.round() method.\n• None Use long datatype to store the rounded quotient.\n• None There you go! You have your desired output as the quotient.\n\nBenefits of Using Integer Division in Java\n\nInteger division offers several advantages, making it a preferred choice in many programming scenarios:\n\nInteger division is computationally efficient because it avoids the additional overhead associated with floating-point operations. When exact integer results are sufficient, using integer division can speed up calculations, especially in performance-critical applications.\n\nWhen working with integer data types, integer division eliminates the need for type casting or handling fractional results. This simplifies the code and reduces potential errors related to type mismatches or unexpected precision issues.\n\nThere are specific scenarios where integer division is the ideal choice due to its nature of truncating results:\n\nInteger division is useful in scenarios where precision is not required, and results need to be discrete. For example, calculating the number of complete groups or evenly dividing tasks:\n\nWhen working with arrays or data partitions, integer division is often used to calculate indices or boundaries:\n\nInteger division is often used to allocate resources efficiently, such as distributing workloads evenly among threads or processors.\n\nInteger division plays a crucial role in simplifying and solving complex mathematical problems. By truncating results, it provides a quick way to handle discrete values without additional precision calculations.\n\nInteger division is commonly paired with the modulus operator ( ) to calculate quotients and remainders:\n\nInteger division simplifies fractions by reducing them to their integral parts:\n\nTo reinforce what you learned, we suggest you watch a video lesson from our Java Course\n\nUnderstanding Pitfalls and Best Practices in Integer Division in Java\n\nInteger division is a commonly used operation in Java that can produce unexpected results if not handled carefully. Let's take a look key issues like truncation, overflow, and the importance of choosing correct data types. By understanding these aspects, programmers can avoid common pitfalls and write more robust code.\n\nInteger division in Java truncates the fractional part of the result, returning only the integer portion. This behavior can lead to unexpected results if developers expect a more precise value.\n\nIn this example, the result of dividing 7 by 3 is truncated to , with the fractional part discarded.\n\nTo avoid truncation, use floating-point types like or for the division:\n\nOverflow occurs when the result of an arithmetic operation exceeds the range of the data type. In integer division, this can happen when dividing the smallest possible integer by .\n\nHere, dividing by results in an overflow because the positive result cannot be represented in the range.\n\nTo prevent overflow, explicitly check for cases where the dividend is and the divisor is :\n\nChoosing the right data type is crucial for ensuring accurate results in integer division. Using an inappropriate data type can lead to precision loss, overflow, or unexpected behavior.\n\nIn this example, the division is performed as an integer operation before being assigned to a , causing precision loss.\n\nTo maintain precision, ensure one or both operands are of a floating-point type:"
    },
    {
        "link": "https://stackoverflow.com/questions/7220681/division-of-integers-in-java",
        "document": "This is a basic question but I can't find an answer. I've looked into floating point arithmetic and a few other topics but nothing has seemed to address this. I'm sure I just have the wrong terminology.\n\nBasically, I want to take two quantities - completed, and total - and divide them to come up with a percentage (of how much has been completed). The quantities are s. Here's the setup:\n\nI've tried reassigning the result to a double - it prints . Where am I going wrong?\n\nIncidentally, the next step is to multiply this result by 100, which I assume should be easy once this small hurdle is stepped over.\n\nBTW not homework here just plain old numskull-ness (and maybe too much coding today)."
    },
    {
        "link": "https://stackoverflow.com/questions/7446710/how-to-round-up-integer-division-and-have-int-result-in-java",
        "document": "I just wrote a tiny method to count the number of pages for cell phone SMS. I didn't have the option to round up using , and honestly it seems to be very ugly.\n\nHere is my code:\n\nI don't really like this piece of code and I'm looking for a more elegant way of doing this. With this, I'm expecting 3 and not 3.0000000. Any ideas?"
    },
    {
        "link": "https://math.nist.gov/javanumerics/reports/jgfnwg-01.html",
        "document": "\n• Development of Core Classes and Interfaces for Numerical Computing\n\nIf Java is to become the environment of choice for high-performance scientific applications, then it must provide performance comparable to what is achieved in currently used programming languages (C or Fortran). In addition, it must have language features and core libraries that enable the convenient expression of mathematical algorithms. The goal of the Numerics Working Group (JGNWG) of the Java Grande Forum is to assess the suitability of Java for numerical computation, and to work towards community consensus on actions which can be taken to overcome deficiencies of the language and its run-time environment.\n\nThe proposals we put forth operate under a number of constraints.\n• Relatively small, but visible, changes to Java and JVM can be made. Upward compatibility should be maintained, as well as a worthwhile amount of backward compatibility.\n• The proposals should support good execution speed on widely available microprocessors. However, while improved performance is important, predictability of results should be maintained. JGNWG proposals provide different levels of performance/predictability tradeoff.\n\nWe begin by outlining critical requirements for numerical computing that are not currently served well by Java's design and implementation. Unless these requirements are met it is unlikely that Java will have much impact on the numerical computation community. This would be detrimental to the entire Java enterprise by slowing the dissemination of high quality components for solving commonly occurring mathematical and statistical problems.\n\nElaborations of each underlying issue, along with proposed solutions are presented in the following section. In suggesting solutions, the working group has been careful to balance the needs of the numerical community with those of Java's wider audience. Although the proposed solutions require some additions to the current Java and JVM design, we have tried to avoid change, relying on compiler technology whenever feasible. This minimizes the changes that affect all Java platforms, and enables implementers to optimize for high numerical performance only in those environments where such an effort is warranted.\n\nUsing complex numbers conveniently means that expressions on complex numbers must look and behave like expressions on or values. This is critical for code understanding and reuse. Efficient complex arithmetic operations are only a few times slower than their real counterparts; ideally, the speed of a complex computation should be limited by the speed of the underlying floating-point arithmetic and not the speed of memory allocation or object copying.\n\nProviding a straightforward complex class using existing Java object mechanisms fails to provide an acceptable solution.\n• The object overhead of complex methods makes them unacceptably inefficient.\n• The semantics of complex objects are different than those of and . For example, the = and == operators manipulate references rather than values. Such differences lead to many errors.\n• Use of method calls for elementary arithmetic operations leads to inscrutable code that is very tedious to write and debug. Users would simply stay away.\n\nThe second and third items also mean that code reuse is severely limited. In the LAPACK project, much of complex code is identical to its real counterparts and this greatly eased the generation and maintenance of the library. Such economies are much more difficult to obtain if the syntax and semantics of complex is significantly different than that of the primitive types.\n\nAn alternative that solves both the convenience and speed issues would be to add as a new primitive type in Java. However, this approach also has a number of drawbacks. While could be added naturally to the language, adding support for a type in the JVM is more problematic. Either the JVM would have to directly support , or expressions and variables in a Java program would have to be mapped into existing JVM instructions in a predetermined way. Fundamental changes to the JVM should be avoided if the existing functionality is sufficient to implement a given feature. However, translating the type into a pair of values (a real and an imaginary component) in the JVM presents a number of difficulties.\n• How are numbers passed into a method?\n\n Since the desired behavior of is analogous to a primitive type, numbers should be passed by value. One way to accomplish that is to represent each parameter as a pair of parameters. Unfortunately, this approach circumvents Java method type checking at the JVM level; it would not be possible in the bytecode to distinguish between a method that took a argument and a method with the same name that took a pair of arguments. (It would be possible to mangle the names of methods with parameters, but then the mangled name might conflict with a different Java method.)\n• How are numbers returned from a method?\n\n The JVM cannot directly return a pair of s from a method. The method could return a two-element array or an object with two fields. However, these approaches could introduce additional memory allocation and copying overhead.\n\nEven if numbers can be accommodated with some variation of the above approach, this would only solve the problem for . Many other numeric types such as decimal, interval, and arbitrary precision have similar requirements. Thus, instead of merely providing a specialized solution for , a better approach is to make Java extensible enough to add new numeric types that can be operated on conveniently and efficiently. To meet this goal, Java needs two capabilities: lightweight classes and operator overloading.\n\nLightweight classes allow the creation of a new kind of Java object. The goal of lightweight classes is to allow the runtime use of what appears to be a C , that is:\n• Lightweight objects have \"value\" semantics; the operator performs a deep copy (instead of changing a pointer) and the operator performs a deep comparison (instead of comparing pointer values).\n• A variable of a lightweight class is never ; such variables always have a value.\n• No dynamic dispatch overhead is needed for the methods of a lightweight class; these classes are always . (This also removes the necessity to store a dispatch pointer for lightweight objects.)\n• Introduce what amounts to an explicit at the JVM level (a very large change), or\n• Translate lightweight classes in Java classes to normal JVM classes with the Java to JVM compiler enforcing restrictions that hide the fact that lightweight classes are implemented as regular Java classes. The back-end compiler should heavily optimize lightweight classes for speed and space (e.g. using escape analysis to allow stack allocation instead of heap allocation, see Storage issues).\n\nSince requiring large JVM changes reduces the likelihood of acceptance, and due to its greater backward compatibility, Java Grande recommends the second approach to implementing lightweight classes.\n\nImplementation implications. Complex numbers can be implemented as a lightweight class. By implementing as a lightweight class, type checking is preserved at both the Java and JVM level. Lightweight classes reuse Java's existing facility to create new types; the compiler is responsible for the tedious job of disguising what appears (to extant JVMs) to be a normal Java object as a lightweight object. To the programmer, lightweight classes appear to be outside of the Java class hierarchy rooted at . However, lightweight classes can be implemented in a way backward compatible with existing virtual machines. Additional class attributes could be included in a file to indicate to new VMs that optimizations tailored to lightweight classes can be used. When compiling programs using lightweight classes, the Java compiler is responsible for enforcing the following restrictions:\n• A lightweight object cannot be observed to have a value. This implies the following.\n• A lightweight object cannot be assigned or compared to . All such expressions are caught as compile-time errors.\n• A compiler-generated non-overridable default constructor is used to initialize lightweight objects. The default constructor initializes the fields of the lightweight object to the default value for that type (zero of numeric types, for reference types). The compiler inserts calls to the default constructor before any code that can access the object. These default constructors are not dependent on any external program state. For local variables, each call of the default constructor for a lightweight class is wrapped with a block that catches and rethrows the exception as . Although user code may try to recover from an an attempt to recover from a is unlikely. Failure to allocate memory for a local lightweight object variable corresponds to running out of stack space.\n• A lightweight class cannot define a method. In Java, methods are run when an object is garbage collected. Lightweight objects are intended to have semantics similar to the semantics of primitive types. Therefore, lightweight classes do not need methods.\n• A user-defined lightweight class constructor must not explicitly invoke . In a constructor, calling invokes the constructor of the superclass. Since lightweight objects are defined to be outside of the class hierarchy, it is not meaningful for a lightweight class constructor to call .\n• Lightweight objects cannot be cast to or any other reference type. Other types cannot be cast to the type of a lightweight class. Casts between primitive types construct a new value whereas casts between reference types reinterpret a pointer; no new value is constructed. However, user-defined conversions between lightweight classes are other types are permissible.\n• It is a compile-time error to apply the operator to an expression having the type of a lightweight class and it is a compile-time error to use to test for the type of a lightweight class.\n• Lightweight classes can overload the assignment ( ) and equality ( ) operators (see Operator Overloading).\n\nVirtual machines are encouraged to inline the methods of lightweight classes where appropriate.\n\nTo behave like primitive types, lightweight classes should be passed by value, that is, when given as an argument to a method or when returned from a method, a lightweight object is copied. C++'s copy constructor performs this task. However, references were added to C++ to avoid the overhead of copying small objects like [Str]. Objects in Java are already passed by reference. Therefore, for performance reasons it may be acceptable (but somewhat contradictory semantically) to pass lightweight objects by reference.\n\nStorage issues. Since lightweight classes are and since references to lightweight objects are not , there is no need to store a dispatch pointer at runtime.\n\nHeap allocation is potentially more expensive than stack allocation. Additionally, stack-allocated objects may be cheaper to garbage collect than heap allocated ones. Therefore, it is preferable to allocate lightweight objects on the stack instead of the heap. Replacing heap allocation with stack allocation is an oft-discussed optimization. An object can be allocated on the stack if it can be determined that the object cannot be accessed outside of the lifetime of the scope that allocated it. Escape analysis [ParG] makes this determination. Recent work suggests escape analysis may be useful in Java [Deu, Bla]. The related problem of compile-time garbage collection is addressed by region inference [Tol] and its extensions [Aik].\n\nOperator overloading is necessary to allow user-defined numeric types, such as , to be used reasonably. Without it, many numeric codes would be extremely difficult to develop, understand and maintain. For example, codes using complex arithmetic class would look very different than similar code using real arithmetic, burdening library developers and users alike. A simple statement such as\n\nmight be expressed as\n\nFaced with coding like this, a large portion of the scientific computing community would choose to avoid Java as being too unfriendly.\n\nAt a minimum, a useful subset of the existing operators must be overloadable. It is useful, but not a requirement of the working group, to allow novel operators to be overloaded as well. (Allowing novel operators to be overloaded does not have to introduce the language complications and programmer difficulties found in ML and Haskell, see [Dar].)\n\nWhat operators can be overloaded. The arithmetic, comparison, assignment, and subscripting operators can be overloaded. Neither the , , field access, nor method call operators can be overloaded. The and operators cannot be overloaded because they have different expression evaluation rules than all other operators.\n\nIf normal classes are also allowed to use operator overloading, it may be convenient to have Pascal's as a supplemental assignment operator. Java's can be used to indicate the current semantics of moving a pointer while can be used for a deep assignment (deep copy, by convention the current semantics of a class' method). If can be overloaded, it can be used for a copy operator appropriate for a given class. For example, even when performing a deep copy, an arbitrary precision arithmetic class may want to use a copy-on-write policy for the bits of the number to avoiding copying the (possibly large) data structure unnecessarily.\n\nIf is introduced for classes, should designate normal assignment on the existing primitive types. That way code using primitive types can more easily be converted to using a user-defined type instead. For example, if roundoff problems on numbers were suspected of causing loss of accuracy problems, it would be convenient to replace with a floating-point type with more precision to see if the roundoff problems abate. With sufficiently powerful operator overloading, potentially only the variable declarations would need to be changed.\n\nHow to name methods corresponding to overloaded operators. The strings making up operators, \" \", \" \", etc., are outside of the set of strings Java allows to form an Identifier. Therefore, to add operator overloading to Java, some technique must be used to allow operator methods to be declared. Either the text of the operator can be included in the method declaration (as with C++'s syntax for an addition operator) or there can be an implicit mapping from textual names to operators (as with Sather's [StoO] mapping of \" \" to ).\n\nIf the latter implicit mapping is used, it is important to have a separate name for each target operator. This avoids the Sather problem where is defined as . Sather's scheme is problematical for IEEE style numbers since and are both false. To overload operators such as , the corresponding name should be instead of . This names the operator according to what it does instead of what characters constitute the text of operator. In general, allowing each operator to be separately overloaded provides the flexibility to model mathematical entities other than traditional fields.\n\nHow to resolve overloaded methods. For normal Java classes, operator overloading can easily be mapped into method dispatch. For example, the compiler can translate into\n\nHowever, this level of support is not sufficient for more general uses of operator overloading. For example, this technique does not work if the type of is a primitive type like or since these types do not have corresponding classes. Clearly, from an orthogonality and usability perspective, the programmer wants to be able to write as well as . Therefore, in addition to letting operators be instance methods (methods dispatched from an object), operators must also be methods (methods not dispatched from an object). However, using operator methods for regular Java classes presents name resolution problems.\n\nIn regular Java code, if a method is used outside the defining class the class name (and possibly the package name) must be prefixed to the method call. For example, instead of writing\n\neven if an statement is used the Java programmer must write\n\nto allow the Java compiler to properly determine the location of the method. Using class name prefixes for operators would ruin the readability of operator overloading. However, since lightweight classes are , the problems of using methods can be circumvented.\n\nSince lightweight classes are , all method calls can be resolved at compile time; there need not be any dynamic dispatch at runtime. Therefore, even if used outside of the defining class, operators on lightweight objects do not need to be prefixed with the class name; the compiler can use a rule of looking for operator methods defined in the lightweight class of the left-hand operand.\n\nAdditionally, using operators allows for better software engineering. If operator methods can be located from either the class of the left hand operand or the class of the right hand operand, new lightweight classes can be made to interact with existing lightweight classes. Otherwise, for symmetric treatment of the classes of and must be written concurrently.\n\nRecently, Sun released for public comment a Proposal for Extension of Java Floating Point Semantics, Revision 1 [PEJ] (abbreviated in this document as PEJFPS). PEJFPS is primarily targeted at improving Java's floating-point performance on the x86 line of processors. (No explicit license is granted (yet) to use the fused mac (multiply-accumulate) instruction, which would benefit users of the PowerPC, among other architectures.)\n\nAssiduously implementing Java's current strict floating-point semantics on the x86 using previously published techniques is very expensive, potentially more than an order of magnitude slower than slightly different semantics [Gol]. A less expensive technique developed recently [Gol98] will be discussed later. PEJFPS grants partial access to the floating-point format found on the x86 in order to overcome the speed problem. However, the reckless license to use or not to use granted by PEJFPS destroys Java's predictability (see recent submissions to the numeric-interest mailing list, http://www.validgh.com/java/).\n\nJava has been billed as providing \"write once, run anywhere\" program development. For both theoretical and practical reasons, Java programs are not nearly so portable nor reproducible as programmers would naively expect. However, by exercising discipline (using single threaded code, using default methods), it is far easier to produce a Java program whose behavior can be predicted than to produce an analogous C or C++ program with the same property. Dropping Java's predictability would be a significant loss. Therefore, the JGNWG recommends that PEJFPS not be incorporated into Java. Instead, JGNWG presents a counter-proposal that works within similar constraints as PEJFPS but maintains the predictability of the language and addresses additional numeric programming needs omitted from PEJFPS.\n\nWhat is the problem on the x86? x86 processors most naturally operate on 80-bit floating-point values. A precision control word can be set to make the processor round to single or double precision. However, even when rounding to a reduced precision, the floating-point registers still use the full 15 exponent bits of the format (instead of the 11 exponent bits for true and 8 bits for true ). A store to memory is required to narrow the exponent as well. Since the register is not changed by the store, for further computation the stored value must be loaded back from memory. This memory traffic degrades Java's floating-point performance on the x86. Moreover, this technique suffers from a small discrepancy between operating on true values and values with increased exponent range. Values that would be subnormal s are not subnormal in with extended exponent range. When such a number is stored to true , it can be rounded twice, leading to a difference in the last bit, about 10-324. Published techniques to remove this remaining minor discrepancy can lead to an order of magnitude slowdown, so Java VMs on the x86 generally set the precision control to precision and allow double rounding on underflow, at variance with Java's specification [Gol].\n\nThe 10-fold potential performance degradation for exact floating-point conformance on the x86 is largely a hypothetical concern since in practice VMs on the x86 use the store-reload technique. PEJFPS aims to eliminate the smaller 2-fold to 4-fold penalty from store-reload. PEJFPS would remove this speed penalty by allowing the x86's registers to be used at full precision and range. However, PEJFPS would put too few constraints on when, where, and whether extended precision is used, leading to unpredictability.\n\nThere are two issues for exact reproducibility stemming from the x86's wider exponent range: maintaining the proper overflow threshold and preserving the proper gradual underflow behavior. The store-reload technique solves the former problem but not the latter. Since additions and subtractions resulting in subnormal values are exact, the underflow threshold is properly preserved. Using the store-reload technique, double rounding on underflow can only occur for multiplication and division.\n\nRecently, a refinement of the store-reload technique that eliminates the double rounding problem has been developed [Gol98]. To avoid double rounding during multiplication, the new technique scales down one of the operands by 2(E - E ) where E is the largest exponent for a given floating point format. After this scaling, all operations that would result in subnormals in true also result in subnormals in with extended exponent range. This result is then rescaled back up by the same quantity; normal results are unaffected and subnormals are properly rounded once. A store of the product after being scaled enforces the overflow threshold.\n\nThe procedure for division is analogous; the dividend can be scaled down or the divisor can be scaled up. In both cases, the resulting quotient is rescaled up to the proper magnitude.\n\nThis new technique has many advantages over previous approaches to making the x86 exactly round to true :\n• The new technique is only marginally more expensive than the currently used store-reload method. Therefore, exact emulation of true only entails a factor of 2 to 4 slowdown instead of a factor of 10.\n• No special testing is needed to handle , infinities, and NaN.\n• Since the scalings up and down are exact, the proper IEEE sticky flags are set.\n• Also due to the exact scalings, the technique works under dynamic rounding modes.\n\nWhat capabilities are needed? Different numeric applications have different needs. Some, like certain implementations of higher precision arithmetic using standard floating point formats, depend on strict floating-point semantics and could easily break if \"optimized.\" Other calculations, such as dot product and matrix multiply, are relatively insensitive to aggressive optimization; meaningful answers result even when blocking and other answer-changing optimizations are applied. The vendor-supplied BLAS are heavily optimized for a given architecture; vendors would not spend considerable resources creating optimized BLAS, sometimes included hand-coded assembly, if there were not demand for such faster programs. The needs of the typical Java programmer fall somewhere between these extremes; there is a desire for floating-point computation that is not unnecessarily slow, but the programmer doesn't want to be surprised when his computed results misbehave unpredictably.\n\nSince Java is aimed at a wide audience, the JGNWG proposal changes Java's default floating-point semantics to allow somewhat better performance on the x86 and PowerPC. However, for most programs on most inputs the change in numerical results will not be noticed. Like PEJFPS, the JGNWG proposal adds a \"strict floating-point\" declaration to indicate current Java semantics must be used. JGNWG also includes a second declaration to allow optimizers to rearrange certain floating-point operations as if they were associative. Associativity enables many useful optimizations, including aggressive code scheduling and blocking.\n\nPEJFPS would mingle increased speed and increased precision. In PEJFPS \" \", which allows use of float extended and double extended formats, presumably yields code that runs faster and may incidentally use increased precision and range. Although it my have been intended only for the sake of fast register spilling, PEJFPS would allow almost arbitrary truncation of results from extended to base formats. In any case, the programmer is faced with an unpredictable program, leading to the resurrection of bugs from earlier systems, like the Sun III (see the recent comp.compilers thread \"inlining + optimization = nuisance bugs\" for a contemporary example). JGNWG's proposal does not mix speed and precision, rather, as a concession to the x86, JGNWG allows extended exponent range in some circumstances.\n\nSome architectures, such as the PowerPC, include a fused mac instruction that multiplies two numbers exactly and then adds a third number, with a single rounding error at the end. Machines with this instruction run faster when it is used. Current Java semantics prohibit fused macs from being used.\n\nThere are three degrees of fused mac usage to support:\n• do not use fused macs at all,\n• use fused macs if they are fast (i.e. if there is hardware support), and\n• used fused mac even if it requires (slow) software simulation.\n\nFused mac must be forbidden in some sensitive calculations. For example, using fused mac recklessly can also lead to inappropriately negative discriminants in quadratic formula calculations [Kah]. Using a fused mac if available would give more accurate and faster dot products and matrix multiplies. Some algorithms require a fused mac to work properly. Mandating a fused mac is necessary to simulate a fused mac capable machine on one that isn't.\n\nJava Grande Counter Proposal. The JGNWG proposal is based upon an analysis that finds very few of the diverse floating-point semantics allowed by PEJFPS to be both useful and necessary. On the other hand, each of the few semantics of the JGNWG proposal is necessary because dropping one would either\n• hobble the performance of a commercially important family of computers, or\n\nThe semantic contexts proposed by the JGNWG are as follows.\n• Java's present semantics. All floating-point values are true and true values.\n• The present Java semantics except that some subexpressions that would have over/underflow in option 1 remain representable; and if underflow is signaled then some underflowed values may be rounded twice instead of once, differing from option 1 by around 10-324. These semantics are used by default on the x86 to ameliorate some of the performance implications of exactly implementing Java's present floating-point semantics on that line of processors. (This can be accomplished by allowing the use of 15-bit exponents in the representation of values on the JVM operand stack.)\n• Permission to use fused mac (multiply-accumulate) where available. This can be used with either of the above.\n• Permission to use associativity with any of the above granted by the code's author.\n\nThere are three kinds of floating-point semantics in JGNWG, strict, default, and \"associative.\" The following table illustrates what effect these have on current processors.\n\nStrict semantics are indicated by the new class and method modifier. Strict semantics are the current Java floating point semantics; fused mac is not permitted in strict code (unless the compiler can prove the same answer results). On the x86, using stores to restrict the exponent range can readily give exactly Java-conforming results for the format. Using the new technique described above, exactly Java-conforming results for the format can also be implemented at a tolerable cost.\n\nLike PEJFPS, JGNWG proposes to modify the default Java floating-point semantics, i.e. those used in the absence of a or declaration.\n\nThe and declarations are mutually exclusive. In general, default semantics allow increased exponent range of anonymous expressions (on the x86) or use of fused mac (on the PowerPC). In default mode on the x86, anonymous and values created during expression evaluation are allowed to use the larger exponent range of . If the extended exponent range is used in code with default semantics, it must be consistently used for all anonymous values (this implies that anonymous values spilled to memory must be spilled as 80 bit quantities to preserve the exponent values). All explicit stores must be respected and only true and true can be stored into programmer-declared variables.\n\nSystem properties indicate whether fused mac and extended exponent range are used by a particular VM. It is always permissible to implement the default semantics as the \"strict\" Java 1.0 semantics. Therefore, on a SPARC there is no difference between the two kinds of floating-point semantics.\n\nIt is possible that a program intended for strict semantics will fail under the non-strict JGNWG default semantics. To ease detection of such cases, JVMs should provide a runtime flag to force default semantics to be implemented as strict.\n\nFinally, JGNWG also includes an declaration to allow optimizers to rearrange floating-point operations as if they were associative if the operations would be associative in the absence of over/underflow and roundoff. Associativity is an important property for optimization and parallelization of numerical codes that may change the numerical outcome of a computation.\n\nOn machines with fused mac instructions, chained multiply and add/subtract operations in the source code can be fused at runtime in default mode. Expressions are fused preferring fusing a product that is the right hand argument to an addition over the left hand argument; for example, the expression\n\nis treated as and not . Such fusing operations must occur if fused mac is in use; this prevents programmer surprises. Otherwise, optimizers could potentially fuse unexpected expressions or prevent an expression from being fused (e.g., common subexpression elimination reusing a product that prevents a fused mac). The arguments to fused mac must be evaluated in left to right order.\n\nProgrammers can require fused mac to be used by an explicit method call to a new method .\n\nWhen fused mac is being used, the programmer can explicitly store each intermediate result to locally implement strict semantics.\n\nUnresolved issues regarding additional optimizations. There is agreement within the working group that, at a minimum, allowing the use of associativity should be permitted as described above. Disagreement remains as to whether compilers should be allowed to employ additional types of optimizations that can, in some cases, cause incorrect results. Under current Java semantics, for example, common transformations such as to (wrong if is NaN) or to (requires distributivity) are disallowed.\n\nSome have argued strongly in favor of allowing wide latitude for optimizations, provided that the software developer and user concur on their use. From their point of view, as long as both parties have the option to disable potentially harmful optimizations, then compiler writers should not be barred from providing them. Gosling has proposed an [Gos] mode that would allow any transformation that would preserve results on the real number field, for example. Others argue that the predictability of the Java language is its key feature and that users are not served well if potentially harmful optimizations are admitted.\n\nA related issue is whether the strict exception model of Java should be relaxed in mode to give additional freedom to the optimizer. and would still be thrown and caught by the same handlers but the values in variables might not be in the same state as in an unoptimized version of the code. Others have argued that the strict exception model should be preserved so that programming styles that rely on exceptions would behave correctly. An example is the following somewhat unusual code for computing the dot product of two vectors.\n\nFinally, some issues regarding the interplay between and the fused multiply-add must be resolved.\n\nThese issues will require further discussion, and public comment is encouraged.\n\nCode Examples for the x86. The dot product loop\n\ncan be compiled differently under strict and default semantics. In the examples that follow, loop tests and other integer calculations are omitted and are assumed to overlap with the floating-point calculations. Under strict Java 1.0 semantics on the x86, one compilation of the dot product loop is:\n\n// x86 code for strict dot product loop\n\n // rounding precision set to double\n\n // assume scaling factors are in the register stack \n\n push scaling factor\n\n load a[i] and multiply with scaling factor\n\n load b[i] and multiply with a[i]scaled down\n\n multiply to rescale product\n\n store product to restrict exponent\n\n reload back restricted product\n\n add product to s\n\n store s to restrict exponent\n\n load back restricted s \n\n increment i\n\n loop\n\n\n\nAs shown above, the product ( ) and the sum ( ) both need to be stored to memory and loaded back in. As shown below, under default semantics, only the sum needs to be written out to memory, halving the excess memory traffic and removing two multiplications.\n\n// x86 code for default dot product loop\n\n // rounding precision set to double\n\n load a[i] \n\n load b[i] and multiply with a[i]\n\n // product does not need to be stored/reloaded and scaled\n\n add product to s\n\n store s to restrict exponent\n\n reload s \n\n increment i\n\n loop\n\n\n\nA larger number of anonymous values in an expression results in a greater reduction in the number of excess stores. A VM might also be able to use trap handlers to achieve faster average execution. For example, trapping on overflow could remove a load from the loop above, yielding\n\n// x86 code for default dot product loop\n\n // rounding precision set to double\n\n // VM is using an overflow trap handler to remove a load\n\n load a[i]\n\n load b[i] and multiply with a[i]\n\n add product to s\n\n store s to restrict exponent // dummy store, reload if store overflows\n\n // reload of s elided\n\n increment i\n\n loop\n\n\n\nThis trap handler is used by the compiler and not visible to the applications programmer. The functionality of this trap handler is simple; the trap handler just has to reload the stored value.\n\nOn the x86, if an expression (and all its subexpressions) neither overflows nor underflows for a given input, executing the default compilation of the expression will give the same result as the executing the strict compilation. As when using fused mac, explicitly storing each intermediate result can be used to implement strict semantics in a limited area. In default mode, both and expressions can use the extended exponent range. Method arguments and return values from methods must be strict or values to prevent programmers from being ambushed by greater exponent range they neither intended nor anticipated.\n\nCost of strictness Using the new scaling technique, a matrix multiply with strict semantics can be a little more than twice as slow as a matrix multiply with default semantics. In both the loops below, an overflow trap handler is used to remove excess loads in the common case. The sum variables are already in the stack. For better instruction scheduling, two elements of the matrix product are calculated simultaneously:\n\n// x86 code for fast matrix multiply using default semantics\n\n // rounding precision set to double\n\n // VM is using an overflow trap handler\n\n // the loop has approximately an 8 or 9 cycle latency on a Pentium\n\n load b[i]\n\n dup b[i]\n\n load a [i] and multiply with b[i]\n\n swap top two stack elements\n\n load a [i] and multiply with b[i]\n\n swap top two stack elements\n\n add with pop a [i] * b[i] to sum \n\n add with pop a [i] * b[i] to sum \n\n loop\n\n\n\n// x86 code for fast matrix multiply using strict semantics\n\n // rounding precision set to double\n\n // VM is using an overflow trap handler\n\n // the loop has approximately a 19 cycle latency on a Pentium\n\n // assume scaling constants are already in the register stack\n\n put scaling constant on the top of the stack\n\n load b[i] and multiply with scaling factor\n\n dup b[i]scaled down\n\n load a [i] and multiply with b[i]scaled down\n\n swap top two stack elements\n\n load a [i] and multiply with b[i]scaled down\n\n swap top two stack elements\n\n rescale a [i] * b[i]scaled down\n\n swap\n\n rescale a [i] * b[i]scaled down\n\n dummy store of a [i] * b[i]\n\n swap\n\n dummy store of a [i] * b[i]\n\n add with pop a [i] * b[i] to sum \n\n add with pop a [i] * b[i] to sum \n\n store sum \n\n swap\n\n store sum \n\n swap\n\n loop\n\n\n\nScoping. Whatever new floating-point semantics are expressible in Java need to be expressible in the JVM too. PEJFPS uses spare bits in a method descriptor to indicate which kind of floating-point semantics a methods has; JGNWG can use the same approach. This provides method-level control of floating-point semantics. This would be the coarsest level acceptable to the JGNWG.\n\nIt may also be convenient to have a finer granularity block-level control. While this is not critical to the JGNWG proposal, it should be considered. Such a declaration is easily added to Java, but it is not immediate apparent how to encode such information in the JVM. Java compilers can include extra attributes in a file ([JVM] § 4.7.1). These attributes can be used to support things such as improved debugging facilities. JVMs are required to ignore unknown attributes. Therefore, JGNWG could represent the different floating-point semantics of different portions of code using a table emitted as an extra file attribute. Strict semantics is always a permissible policy under the JGNWG proposal; so, in this respect a JGNWG-style class file would be backward compatible with existing VMs.\n\nDiscussion. The JGNWG proposal allows improved hardware utilization over standard Java while preserving program predictability. Programmers can test system properties to determine the VM's behavior.\n\nA reasonable question is that if Java Grande is opposed to PEJFPS due to its unpredictability, why does Java Grande's proposal also allow some unpredictability by default? JGNWG permits much less unpredictability than PEJFPS and JGNWG has fewer differences between strict and default semantics. For example, in JGNWG a floating-point feature must be used consistently; fused mac or extended exponent range cannot be used on one call to a method and not used on the next (something allowed by PEJFPS). On the x86, between allowing extended exponent range and allowing extra precision, allowing extended exponent range results in many fewer visible differences between strict code and default code.\n\nThe differences arising from extended exponent range on the x86 are visible only if the calculation would over/underflow on a machine like the SPARC. Over/underflow is comparatively rare in practice; therefore the Java Grande differences would be observed at most rarely. PEJFPS allows extended precision for intermediate results. Differences stemming from extended precision would almost always be visible. For example,\n\n// implicit widefp under PEJFPS\n\n // default semantics under Java Grande\n\n static foo(){\n\n double one = 1.0;\n\n double three = 3.0;\n\n \n\n double a;\n\n double b[] = new double[1];\n\n \n\n a = one/three;\n\n b[0] = a;\n\n }\n\nIf is calculated to extended precision and is treated as an extended precision value, then will be false under PEJFPS since arrays are always stored in the base format (32 bit or 64 bit ). If is stored as precision, will be false if is calculated to precision. The Java Grande proposal would always return true for these cases. In short, on the x86 the cases where the JGNWG proposal allows differences between default and strict semantics are where overflow or underflow would occur; the cases where PEJFPS allows differences between default and strict semantics are (approximately) where an operation is inexact, as most are.\n\nAdditional Floating-point Types. The JGNWG proposal thus far does not provide any access to the format found on the x86. Consistent access to this format is important to allow good hardware utilization and to ease writing numerical programs; having access to several more bits of precision than the input data often allows simpler (and sometimes faster) algorithms to be used. To access , JGNWG proposes that Java include a third primitive floating-point type called \" .\" The floating-point type corresponds to the widest IEEE 754 floating-point format that directly executes on the underlying processor. On the x86, corresponds to the format; on most other processors, corresponds to the format. (The type must be at least as wide as .) For a particular VM, class variables indicate whether is implemented as or .\n\nThe and floating-point types have hardware support. Adding a type would require costly simulation on most architectures other than the x86. Having an type preserves the performance predictability of a program and keeps a close correspondence between floating-point types in a language and floating-point formats on a processor.\n\nImplementing at the JVM level can be done either by adding new JVM instructions or (as an interim measure) using the operator overloading and lightweight classes described earlier.\n\nAdditional Floating-point Expression Evaluation Policies. To better utilize certain processors and to lessen the impact of rounding errors, it is useful for the programmer to conveniently be able to evaluate a floating-point expression in a wider format. For example, a programmer may want to evaluate an expression consisting of variables in precision. Pre-ANSI C used this floating-point expression evaluation policy exclusively.\n\nJGNWG adds a new declaration, FloatingPointType, to control the expression evaluation policy:\n• gives the original C expression evaluation; all values are promoted to .\n• promotes and values to . Using makes best use of the x86's double extended registers.\n• specifies to use the existing Java expression evaluation policy.\n\nOur goal is to provide Java with the functionality and performance associated with Fortran arrays.\n\nMultidimensional arrays are n-dimensional rectangular collections of elements. An array is characterized by its rank (number of dimensions or axes), its elemental data type (all elements of an array are of the same type), and its shape (the extents along its axes).\n\nElements of an array are identified by their indices along each axis. Let a k-dimensional array A of elemental type T have extent n along its j-th axis, i = 0,...,k-1. Then, a valid index i along the j-th axis must be greater than or equal to zero and less than n . An attempt to reference an element A[i ,i ,...,i ] with any invalid index i causes an to be thrown.\n\nRank, type, and shape are immutable properties of an array. Immutable rank and type are important properties for effective code optimization using techniques developed for Fortran and C. Immutable shape is an important property for the optimization of run-time bounds checking according to recent techniques developed for Java [MiMS98,MoMG98].\n\nWe can understand the differences between multidimensional arrays and Java arrays of arrays through an example. Consider the following declaration and definition of a Java array of arrays.\n\nWhile arrays of arrays are important data structures for their flexibility, this flexibility comes at a performance cost. The potential aliasing between rows of an array of arrays forces compilers to generate additional stores and loads. The potential shape changing in arrays of arrays complicates bounds checking optimization, by requiring array privatization [MiMS98,MoMG98]. True rectangular, multidimensional arrays solve both these problems.\n\nProposal. We propose the development of standard Java classes that implement multidimensional rectangular arrays. These classes can be included as a subpackage in or in their own package . Standardizing the classes as part of Java is important for maximum compiler optimization. (In particular, it enables semantic inlining techniques [WMMG98].)\n\nThe rank and type of an array are defined by its class. That is, for each rank and type there is a different class. (This is necessary for traditional compiler optimizations, since Java does not support templates.) Supported types must include all of Java primitive types ( , , , , , , , and ), one or more complex types (at least the class in this proposal), and . Supported ranks must include 0- (scalar), 1-, 2-, 3-, and possible 4- to 7-dimensional arrays. (Rank 7 is the current standard limit for Fortran.)\n\nThe shape of an array is specified at its creation, and it is immutable. An example might be\n\nThe array classes should support the concept of regular array sections. A regular array section corresponds to a subarray of another array, which we call the master array. Each element of an array section corresponds to a unique element of its master array. Referencing one element of an array section (for reading or writing) has the effect of referencing the corresponding element of the master array. Regular array sections have the same type as, and rank less than or equal to, their master arrays. Regular array sections behave exactly like regular arrays for all operations, including sectioning. (In fact, there are no separate classes for array sections.)\n\nA regular array section is defined by specifying a subset of the elements of its master array. For each axis of the master array, the specification can be (i) a single index, or (ii) a regular range of indices. A regular range is an arithmetic progression defined by a first element, a last element, and a stride. The rank of an array section is equal to the number of regular ranges in its definition. The shape is defined by the number of elements in those ranges. Note that indices for an axis of an array section must be greater than or equal to 0 and less than the extent of that axis. Array sections might be referenced as follows, for example.\n\nThe array classes should also support the concept of irregular array sections, although in a more limited fashion. An irregular array section is defined by specifying, for at least one of the axis of a master array, a generic set of indices. Operations on an irregular array section are limited to extracting and setting the values of its elements. (These correspond to the gather and scatter operations typical in vector codes.) For example, these might be specified as follows.\n\nThe array classes provide methods that implement Fortran-like functionality for arrays. In particular, the following operations must be provided:\n• Get and set the values of an array element, array regular section, or array irregular section.\n• Operations to query the rank and shape of an array.\n• Operations to reshape and transpose an array.\n• Elemental conversion functions (e.g., the equivalent of Fortran and , that convert complex arrays into arrays).\n• Operations that correspond to array expressions (addition, multiplication, etc.)\n\nDiscussion. The array classes can be implemented with no changes in Java or JVM. However, it is essential that the get and set methods be implemented as efficiently as array indexing operations are in Fortran or in C. We expect that inlining will be used for this purpose, and that garbage collectors will treat rectangular arrays efficiently. Multidimensional arrays are extremely common in numerical computing, and hence we expect that efficient multidimensional array classes will be heavily used.\n\nThe inclusion of standard array classes in or does not require any change to the Java language. However, the use of explicit method invocation to effect all array operations will significantly decrease the readability of Java code and incur the wrath of users. The introduction of a simple notation for multidimensional arrays which maps to the standard array classes would make the use of such arrays much more natural. A multi-index notation, like to refer to such array elements would be ideal. This would allow statements like\n\nto be more naturally expressed as\n\nThe front-end compiler could disambiguate the expression according to the type of . This requires changes in the Java language or fancier operator overloading mechanisms.\n\nAdditional facilities that would be very helpful, but are not strictly necessary are the following.\n• Facilitating indexing operations by explicitly triplet notation, e.g. referring to the section of the one-dimensional array from element to element in steps of . This requires new syntax, or fancy overloading of the indexing.\n\nUnresolved issues. While most working group members see benefit from the provision of multidimensional array classes, disagreement remains regarding a number of critical implementation issues.\n\nThe first issue regards the internal implementation of the array class. Library developers want the simplicity of Fortran arrays. They would like to see the requirement that multidimensional arrays be implemented using a one-dimensional native Java array with elements filled in, say, row-major order. The simplicity of such a scheme would benefit both optimizers and library developers, leading to better overall performance of codes. Library developers, for example, would know exactly how to traverse the array to maximize locality of reference. Some developers even want the ability to extract the internal 1D array, manipulate it, and then put it back.\n\nOthers feel that it is a mistake to expose the internal storage scheme. Compiler developers want the flexibility to decide on the layout based on their own analysis. They argue, for example, that packing everything in a 1D array would artificially limit the size of multidimensional arrays based on indexing considerations. One proposal would provide an additional array attribute called the preferred access mode. This could have values of (i) row major, for C-style coding, (ii) column major, for Fortran-style coding, and (iii) block major, for block-oriented recursive algorithms. The access mode would provide a hint to the compiler regarding the most likely access order for the array. The default would be row-major. Compilers could ignore the access mode attribute.\n\nLibrary developers counter that it is unreasonable to expect them to provide optimized routines for each type of access mode (and for all combinations in case of array-array operations), and that the alternative of casting to and from differing access modes adds unacceptable overhead.\n\nAnother issue that must be considered further is the semantics of array sections. Array sections can be either aliases to the master array or copies extracted from the master array. In either case, the effect on the master array of writes to the section, and vice versa, must be carefully spelled out.\n\nFinally, many array operations will result in an array of output. The best way of providing the output array is not clear. Providing a new array object as output is sometimes convenient, but may be inefficient. Providing a separate parameter to contain the output may be better.\n\nThe following additional problems were addressed by the Working Group.\n• Alternative definition of the library of transcendental functions. The current operational definition is imprecise and suboptimal. (The functions are defined in terms of compatibility with a particular implementation, C's fdlibm source, interpreted using Java's strict semantics). Alternative definitions are\n• precise rounding -- result is as if computed in infinite precision arithmetic, then rounded;\n• within fixed bound of precise result; or The first definition is very desirable if it can be achieved with acceptable performance overhead. The second weakens bitwise reproducibility. Note that current Java implementations are not in strict adherence to this aspect of the Java standard: most JVMs use their native C math library. As a compromise, we propose that fdlibm be translated to Java and that this particular implementation be mandated when Java's strict semantics are being enforced. Otherwise, a looser, implementation-dependent alternative which conform to the requirements of C9X (as fdlibm does) should be allowed.\n• Access to additional IEEE floating-point features. The high reliability required in certain sensitive floating-point computations requires the ability to manipulate IEEE floating-point flags. The sticky flags can also be used to create significantly faster robust linear algebra algorithms [Dem]. The Working Group proposes that standard methods to sense, save, clear and raise all IEEE floating-point flags be included in Java. Similarly, reliability concerns, as well as the ability to efficiently implement interval arithmetic, requires the ability to set rounding modes for floating-point operations. It is sufficient to provide methods to set (and get) the global rounding mode to accomplish these goals. In order for such features to be used reliably, compilers and JVMs must respect the semantics of the special methods used to implement these operations. In particular, the floating-point state must be saved and restored across thread context switches, and compiler and JVM optimizations must be modestly limited.\n• Implementation of additional elementary functions and predicates. The functions and predicates recommended in the IEEE 754 standards document, as well as others commonly available in C, should be provided in . Equivalents of two of the ten IEEE 754 recommended functions are already available in the Java API ( and ). The following six should also be added. returns with the sign of . returns the next representable neighbor of in the direction towards . Returns true is one of its arguments is unordered with respect to the other. This occurs when at least one is a NaN. Returns an integer that indicates which of the nine \"kinds\" of IEEE floating-point numbers is. The description of the functions given above is quite terse and ignores some subtleties for extreme arguments. (The same is true of the IEEE 754 document itself.) For a detailed discussion of how these functions can be implemented in Java, see [Dar98]. In addition, several elementary functions which are provided in C should also be included in the Java API, the following, for example. returns without overflow whenever the result does not overflow. Note that it is important that functions for and be put in the same class (e.g., the class). Currently, separate and methods are found in the and classes. Because of this, the type of the argument has to be part of the function call, e.g. and . If both were in the same class, then the function names could be overloaded, allowing for easier maintenance of codes that are provided in both and versions.\n• Extensions to support multiple NaN values. This seems to be already in the making.\n\nIV. Development of Core Classes and Interfaces for Numerical Computing\n\nThe Numerics Working Group has agreed to begin the development of a variety of core numerical classes and interfaces to support the development of substantial Java applications in the sciences and engineering. The main purpose of this work is to standardize the interfaces to common mathematical operations. A reference implementation will be developed in each case. The purpose of the implementation will be to clearly document the class and its methods. Although we expect these to be reasonably efficient, we expect that highly tuned implementations or those relying on native methods will be developed by others. Also, the simple methods, such as get or set, will not provide reasonable performance unless they are inlined, because the method invocation overhead will be amortized over very few machine instructions. Unless otherwise specified, we will initially only define classes based on s, since computations with Java s are less useful in numerical computing.\n\nThe classes identified for first consideration are the following.\n• Complex This implements a complex data type for Java. It includes methods for complex arithmetic, assignment, as well as the elementary functions. A strawman proposal has already been developed and released for comment.\n• Multidimensional arrays This implements one, two and three-dimensional arrays for Java as described above. A strawman proposal has already been developed and released for comment.\n• Linear algebra This implements matrices (in the linear algebraic sense) and operations on matrices such as the computation of norms, standard decompositions, the solution of linear systems, and eigenvalue problems. A strawman proposal has already been developed and released for comment.\n• Basic Linear Algebra Subroutines (BLAS) These implement elementary operations on vectors and matrices of use to developers of linear algebra software (rather than to average users). This work will be done in conjunction with the BLAS Technical Forum. Some working notes on this effort can be found at http://math.nist.gov/javanumerics/blas.html\n• Higher Mathematical Functions This includes functions such as the hyperbolics, erf, gamma, Bessel functions, etc. A strawman proposal has already been developed and released for comment.\n• Fourier Transforms This includes not only a general complex transform, but specialized real, sine and cosine transforms.\n• Interval Arithmetic This implements an interval real data type for Java. It includes methods for interval arithmetic, assignment, as well as elementary functions. An API is actively under development.\n• Multiprecision Arithmetic This implements a multiprecision real data type for Java. It includes methods for arithmetic, assignment, as well as elementary functions.\n\nThe working group will review these proposals and open them up for public comment. It will also set standards for testing and documentation for numeric classes. It will work with Sun and others to have such classes widely distributed.\n\nThe following individuals contributed to the development of this document at the Java Grande Forum meetings on May 9-10 and August 6-7 in Palo Alto, California.\n\nThe working group also acknowledges helpful discussions with and input from the following individuals."
    },
    {
        "link": "https://reddit.com/r/ProgrammingLanguages/comments/1elr42w/is_there_any_reason_to_have_integer_division",
        "document": "Since I cannot edit the post's title and it causes confusion: it should read \"Is there any reason to use the same operator for float and integer division?\"\n\nMany languages overload the same division operator for integers and floats:\n\nIn practice I often see the following issues with using the same operator:\n• New developers always get confused by it, expecting float outcomes from integer division.\n• More seasoned developers occasionally forget to convert integers to floats before dividing them.\n• Such issues go unnoticed due to type inference or implicit conversions: given ints and , both and may compile without issues, depending on the language.\n• If a language has implicit conversions, there is no one obvious way to write typecasts: , and all mean the same thing.\n• In some rare cases when we really need integer division, I would still prefer to explicitly the result for the sake of future readers of this code.\n\nI can see several alternatives:\n• Do not implement division for integers at all. This is a bit annoying, but keeps them closed under arithmetic operations. If you need to divide integers, you write something like .\n• Make integer division always return a float. This may cause issues with widening (e.g. may not fit into ). It also makes the type not closed under arithmetic operations, but I'm not sure if this is an issue.\n• Make a separate function or operator for integer division, like Python's . This is also a good option, but prevents us from writing generic code that divides numbers of arbitrary types. That said, most times I write generic functions on numbers, I expect inputs to be float types ( , , etc) in practice.\n\nThis leads me to a question: is there any actual value in overloading the operation for integers? Do languages just implement this out of habit? Is there a \"best\" solution that prevents accidental mistakes while still allowing writing generic code?"
    }
]