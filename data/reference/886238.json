[
    {
        "link": "https://stackoverflow.com/questions/4364851/using-loop-invariants-to-prove-the-correctness-of-heap-sort",
        "document": "Loop Invariants are very simple yet powerful techniques to prove if your algorithm or a set of instruction is correct. They work wonderfully in iterations.\n\nWe set up an invariant property, which is a desired property in your iterations that you would want to maintain throughout the execution. For example if you started off with a correct state and maintained it throughout the course of algorithm, then you know that you have a correct algorithm\n\nSo you would need to show that you have a desired property, the invariance in 3 steps:\n\ni. Initialization: Can you show that you have the invariant property of the algorithm in the first step of the iteration of the loop?\n\nii. Maintenance: Are you maintaining the invariance? If it was true for the iteration up to that point, is it true for the next iteration?\n\niii.Termination: When your loop finally terminates, the invariant will be used to show that the algorithm you wrote is correct.\n\nLet us use this knowledge to prove BuildMaxHeap is correct, since it is used in the HeapSort algorithm.\n\nFor example, How do we know that building of max heap actually builds a max heap! If our BuildMaxHeap algorithm worked correctly, we could use this to sort correctly.\n\nFollowing our above intuition, we need to decide on a desired property that we maintain throughout the algorithm. What is the desired property in the MaxHeap? heap[i]>= heap[i*2]. No matter how much you mess around with the heap, if it still has that property, then it is a MaxHeap.\n\nSo we need to make sure that our BuildMaxHeap algorithm used for the sorting maintains that invariant throughout the algorithm.\n\nInitialization : Prior to the first iteration. Everything is a leaf so it is already a heap.\n\nMaintainence : Let us assume that we have a working solution till now. The children of node i are numbered higher than i. MaxHeapify preserves the loop invariant as well. We maintain the invariance at each step.\n\nTermination : Terminates when the i drops down to 0 and by the loop invariant, each node is the root of a max-heap.\n\nHence the algorithm you wrote is correct.\n\nIntroduction to Algorithms (CLRS) has a very good treatment of this technique."
    },
    {
        "link": "https://columbia.edu/~cs2035/courses/csor4231.F05/heap-invariant.pdf",
        "document": ""
    },
    {
        "link": "https://ime.usp.br/~pf/algorithms/chapters/heapsort.html",
        "document": "Consider the sorting problem discussed in another chapter. Namely, consider the problem of permuting the elements of an array to put them in increasing order. In other words, rearrange the elements of the array so that ≤ . . . ≤ .\n\nThe other chapter analysed some simple algorithms for the problem. The present chapter examines Heapsort, an algorithm discovered by J. W. J. Williams in 1964. Unlike the simple algorithms, Heapsort is linearithmic, even in the worst case.\n\nWe shall assume that the indices of the array are , rather than the usual . This convention will make the code a little simpler.\n\nIn order to discuss the Heapsort, we must learn to see the binary tree hidden in any array. The set of indices of any array can be understood as a binary tree in the following way:\n• the index is the root of the tree;\n• the parent of any index is (of course has no parent);\n• the left child of um index is (this child exists only if ;\n• the right child of is (this child exists only if ).\n\nTo make the binary tree stand out, we can draw the array in layers, so that every child sits in the layer immediately below that of its parent. The figure below is such a drawing of the array . (The numbers in the boxes are the indices rather than the values .) Observe that each layer, except perhaps the last, has twice as many elements as the previous one. It follows that the number of layers in an array is exactly , where is the floor of log .\n\nThe mechanism behind the Heapsort algorithm is a data structure, known as heap, that sees the array as a binary tree. There are two flavors of the structure: max-heap and min-heap; we shall consider here only the first flavor and omit the prefix.\n\nA heap, then, is an array in which the value of each parent is greater than or equal to the value of each of its two children. More precisely, an array is a if\n\nfor = , . . . , . Here, as in the rest of this chapter, we shall agree that expressions figuring as indices of arrays are always computed in integer arithmetic. Hence, the value of the expression is , i.e., the floor of .\n\nOccasionally, we consider certain heaps: we say that an array is a heap except perhaps for index if the inequality holds for every distinct from .\n\nIt is easy to rearrange the elements of an array of integers so that it becomes a heap. Just repeat the following process: while the value of a child is larger than the value of its parent, swap the values of parent and child and move one step up, towards the root. More precisely, while , do and then . The swap operation is\n\nHere is the complete code:\n\nAt the beginning of every iteration controlled by the , the array is a heap. In the course of the iteration, moves up the heap (towards the root) until it finds its correct place and is thus incorporated into the heap.\n\nIn each repetition of the pair of lines , the index jumps from one layer of the array to the previous layer. Hence, this pair of lines can be repeated at most times for each fixed . As a consequence, the total number of comparisons (line of the code) between elements of the array is at most\n\nThe core of many algorithms that manipulate heaps is a function that, unlike , moves down the heap, away from the root. This function, which we call , receives an arbitrary array and\n\nmoves down to its correct position,\n\njumping from one layer to the next. How is this done? If and , nothing needs to be done. If and , just swap with and move down to its correct position. In the other two cases, do something similar. (See a draft of the algorithm in pseudocode.) In the following example, each line of the figure shows the state of the array at the beginning of an iteration:\n\nWe can now write the code of the function. Each iteration begins with an index and chooses a child of which has the largest value:\n\nThe function will be applied to arrays that are heaps except perhaps for one or two indices. The function can, therefore, be documented as follows:\n\nThe following version is a little better, because it moves fewer elements of the array from one place to another (and does fewer divisions of by ):\n\nPerformance. The function is very fast. It does at most iterations, since the array has layers. Each iteration involves two comparisons between elements of the array and therefore the total number of comparisons is at most\n\nThe time spent is proportional to the number de comparisons and therefore proportional to log in the worst case.\n\nWe can now put together all the pieces discussed above and write an algorithm that will rearrange an array in increasing order. The algorithm has two phases: the first transforms the array into a heap and the second pulls elements from the heap in decreasing order. (See a draft of the algorithm.)\n\nAt the beginning of each iteration of the , the following invariant properties hold:\n• is in increasing order, and\n• is a permutation of the original array.\n\nThe expression is a shorthand for each element of is smaller than or equal to every element of .\n\nIt follows that will be in increasing order when becomes equal to . This shows that the algorithm is correct.\n\nThe animation at right (copied from Simon Waldherr / Golang Sorting Visualization) shows Heapsort running on an array of positive numbers. Each element of the array is represented by a point ( , ). (For some reason, the animation does not execute the last two iterations.)\n\nHere is a sample of other animations:\n• Animation of 15 sorting algorithms, by Timo Bingmann, on YouTube.\n\nHow many comparisons between elements of the array does the function execute? The auxiliary function does at most comparisons. Next, the function is called approximately times and each of these calls does at most comparisons. Hence, the total number of comparisons is at most\n\nThe time consumed by is proportional to the number of comparisons between elements of the array, and therefore proportional to log in the worst case. (But the proportionality factor is larger than that of Mergesort and Quicksort.)"
    },
    {
        "link": "https://columbia.edu/~cs2035/courses/csor4231.F15/heap-invariant.pdf",
        "document": ""
    },
    {
        "link": "https://dl.ebooksworld.ir/books/Introduction.to.Algorithms.4th.Leiserson.Stein.Rivest.Cormen.MIT.Press.9780262046305.EBooksWorld.ir.pdf",
        "document": ""
    },
    {
        "link": "https://geeksforgeeks.org/python-program-for-heap-sort",
        "document": "Heapsort is a comparison-based sorting technique based on a Binary Heap data structure. It is similar to selection sort where we first find the maximum element and place the maximum element at the end. We repeat the same process for the remaining element.\n\nFirst convert the array into a max heap using heapify, Please note that this happens in-place. The array elements are re-arranged to follow heap properties. Then one by one delete the root node of the Max-heap and replace it with the last node and heapify. Repeat this process while size of heap is greater than 1.\n• None Rearrange array elements so that they form a Max Heap.\n• None Repeat the following steps until the heap contains only one element:\n• None Swap the root element of the heap (which is the largest element in current heap) with the last element of the heap.\n• None Remove the last element of the heap (which is now in the correct position). We mainly reduce heap size and do not remove element from the actual array.\n• None Heapify the remaining elements of the heap.\n\nWe first need to visualize the array as a complete binary tree. For an array of size n, the root is at index 0, the left child of an element at index i is at 2i + 1, and the right child is at 2i + 2.\n\nBelow are the detailed steps to heapify the tree:\n\nStep 3: Sort the array by placing largest element at end of unsorted array.\n\nBelow are the detailed steps to sort the array:\n\nIn the illustration above, we have shown some steps to sort the array. We need to keep repeating these steps until there’s only one element left in the heap.\n\nThe given Python code implements the Heap Sort algorithm, which is an efficient comparison-based sorting method.\n• None The time complexity of heapify is O(log(n))\n• None And, hence the overall time complexity of Heap Sort is O(n*log(n))\n\nTime Complexity: O(n log n), where “n” is the size of the input list. \n\nAuxiliary Space: O(1)."
    },
    {
        "link": "https://geeksforgeeks.org/heap-sort",
        "document": "Heap sort is a comparison-based sorting technique based on Binary Heap Data Structure. It can be seen as an optimization over selection sort where we first find the max (or min) element and swap it with the last (or first). We repeat the same process for the remaining elements. In Heap Sort, we use Binary Heap so that we can quickly find and move the max element in O(Log n) instead of O(n) and hence achieve the O(n Log n) time complexity.\n\nFirst convert the array into a max heap using heapify, Please note that this happens in-place. The array elements are re-arranged to follow heap properties. Then one by one delete the root node of the Max-heap and replace it with the last node and heapify. Repeat this process while size of heap is greater than 1.\n• None Rearrange array elements so that they form a Max Heap.\n• None Repeat the following steps until the heap contains only one element:\n• None Swap the root element of the heap (which is the largest element in current heap) with the last element of the heap.\n• None Remove the last element of the heap (which is now in the correct position). We mainly reduce heap size and do not remove element from the actual array.\n• None Heapify the remaining elements of the heap.\n\nWe first need to visualize the array as a complete binary tree. For an array of size n, the root is at index 0, the left child of an element at index i is at 2i + 1, and the right child is at 2i + 2.\n\nStep 3: Sort the array by placing largest element at end of unsorted array.\n\nIn the illustration above, we have shown some steps to sort the array. We need to keep repeating these steps until there’s only one element left in the heap.\n\n// C++ program for implementation of Heap Sort using vector // which is an index in arr[]. // If left child is larger than root // If right child is larger than largest so far // If largest is not root // One by one extract an element from heap // which is an index in arr[]. // If left child is larger than root // If right child is larger than largest so far // If largest is not root // One by one extract an element from heap // which is an index in arr[]. // If left child is larger than root // If right child is larger than largest so far // If largest is not root // One by one extract an element from heap # which is an index in arr[]. # If left child is larger than root # If right child is larger than largest so far # One by one extract an element from heap // which is an index in arr[]. // If left child is larger than root // If right child is larger than largest so far // If largest is not root // One by one extract an element from heap // which is an index in arr[]. // If left child is larger than root // If right child is larger than largest so far // If largest is not root // One by one extract an element from heap // which is an index in arr[]. // If left child is larger than root // If right child is larger than largest so far // If largest is not root // One by one extract an element from heap\n\nTime Complexity: O(n log n) \n\nAuxiliary Space: O(log n), due to the recursive call stack. However, auxiliary space can be O(1) for iterative implementation.\n• None Its typical implementation is not stable but can be made stable (See\n• None . The reason for slowness is a lack of locality of reference.\n• Efficient Time Complexity: Heap Sort has a time complexity of O(n log n) in all cases. This makes it efficient for sorting large datasets. The log n factor comes from the height of the binary heap, and it ensures that the algorithm maintains good performance even with a large number of elements.\n• Memory Usage: Memory usage can be minimal (by writing an iterative heapify() instead of a recursive one). So apart from what is necessary to hold the initial list of items to be sorted, it needs no additional memory space to work\n• Simplicity: It is simpler to understand than other equally efficient sorting algorithms because it does not use advanced computer science concepts such as recursion.\n• Costly : Heap sort is costly as the constants are higher compared to merge sort even if the time complexity is O(n Log n) for both.\n• Unstable : Heap sort is unstable. It might rearrange the relative order.\n• Inefficient: Heap Sort is not very efficient because of the high constants in the time complexity.\n\nWhat are the two phases of Heap Sort?\n\nWhy Heap Sort is not stable?\n\nIs Heap Sort an example of the “Divide and Conquer” algorithm?\n\nWhich sorting algorithm is better – Heap sort or Merge Sort?\n\nWhy is Heap sort better than Selection sort?"
    },
    {
        "link": "https://medium.com/@allan.sioson/max-heapify-build-max-heap-and-heapsort-algorithm-in-python-42c4dec70829",
        "document": "In this short article, we discuss what a max heap is and how algorithms used to build a max heap can be used to sort an array of values. The algorithms discussed are Max-Heapify, Build-Max-Heap, and Heapsort. These algorithms are implemented in python.\n\nA max heap is a complete binary tree with the property that the key value in each node is greater than or equal to the respective keys of its children. A binary tree is said to be complete if each level is filled except possibly the last level. The last level is always filled from left to right.\n\nAn example of max heap is shown in Fig 1. Note that the key of each node is greater than or equal to the key of each of its children. The root of the max heap has a key equals to 25. The respective keys of the left child and right child of the root are 17 and 20. Furthermore, the last level is filled from left to right.\n\nThe max heap of n nodes can be represented as an array of n items. For example, the max heap (with 9 nodes) shown in Fig 1 can be represented as an array A with 9 items.\n\nAssume that A is a zero-based array, meaning the first item is at index 0. In the array representation of max heap, the left and right child of each item at index i are in indexes 2i+1 and 2i+2, respectively. Fig 2 shows the array representation of the max heap in Fig 1. Observe that the left and right child of the item at index 1 (i.e., node with key = 17 and the left child of the root) are in indexes 2(1)+1 = 3 and 2(1)+2 = 4, respectively.\n\nIf we swap the keys of the root and the last node in the max heap, and then remove the last node, the resulting complete binary tree is no longer a max heap. The corresponding array would now have 8 items. In Fig 3 (and in Fig 4), the removed item is greyed out.\n\nThe Max-Heapify algorithm can be used to transform the current complete binary tree to a max heap. The basic idea is to start the process from the root. Here, the key value of the root is swapped with the child with the maximum key value. The process is repeated with the node involved in the swapping of keys unless the said node is already a leaf node. Fig 5 shows how this process is done. The swap done is denoted by the double headed blue arrow.\n\nThe process as represented in an array is shown in Fig 6. Note that at the end of process, the resulting array is now a max heap.\n\nThe Max-Heapify algorithm can implemented recursively in python. Fig 7 shows an implementation.\n\nAny given array A can be transformed to a max heap by repeatedly using the Max-Heapify algorithm. Let’s call this algorithm as the Build-Max-Heap algorithm. The implementation uses the Max-Heapify algorithm starting from the last node with at least one child up to the root node. An implementation in python is given below:\n\nThe largest value in a max heap represented by a zero-based array A is guaranteed to be at index 0. With this guarantee, we can sort a zero-based array A in ascending order by doing the following procedure.\n\nInitially, we let the current last node be the last item in array A. We can then repeatedly swap the key of the root with the key of the current last node and then use the Max-Heapify algorithm on the slice of array A from index 0 up to the node before the current last node. The node before the current last node will become the new current last node. We do this up until the size of the slice is only one item. The python code below is an implementation of a version of the Heapsort algorithm.\n\nThe running time of Max-Heapify is θ(lg n). It follows that Build-Max-Heap and Heapsort would both have a running time of θ(n lg n).\n\nFor in depth discussion of ideas and algorithms related to Heapsort, I refer the readers to [1] and [2].\n• Cormen, Leiserson, Rivest, and Stein, Introduction to Algorithms, 2/E, Chapter 6: Heapsort, pp. 127–164, © 2001 by The MIT Press.\n• Baase and Gelder, Computer Algorithms — Introduction to Design and Analysis, 3/E, Section 4.8 Heapsort, pp. 182–197, © 2000 by Addison Wesley Longman."
    },
    {
        "link": "https://stackoverflow.com/questions/13979714/heap-sort-how-to-sort",
        "document": "I'm trying to implement Heap Sort in Python, but I can't seem to get it right. I've tried to implement this pseudo code, but my code does not sort! It just sifts to ridiculous effect. I'm inclined to think that the problem is in this line:\n\nHow do I get the maximum value?\n\nThat is what I have:\n\nAnd I found an example with almost the same problem:\n\nThe results are different, but both are ridiculous:"
    },
    {
        "link": "https://hackernoon.com/heap-sort-algorithm-your-complete-implementation-guide",
        "document": "\n• Learn when to choose Heap Sort over other sorting algorithms\n• Get practical code examples in Python and JavaScript\n\nHeap Sort is an efficient, comparison-based sorting algorithm that uses a binary heap data structure to sort elements. It combines the speed of Quick Sort with the consistent performance of Merge Sort, making it an excellent choice for systems requiring guaranteed O(n log n) time complexity. In this guide, I’ll walk you through how Heap Sort works, where it shines, and provide code examples in Python and JavaScript to help you put theory into practice.\n\nBefore diving into Heap Sort, let's understand the heap data structure:\n• Parent nodes are greater (max-heap) or smaller (min-heap) than children\n• Can be efficiently represented in an array\n• def handle_edge_cases(arr): if not arr or len(arr) <= 1: return arr\n\nA: Heap Sort may change the relative order of equal elements due to the heap structure and extraction process.\n\nQ2: When should I use Heap Sort over Quick Sort?\n\nA: Use Heap Sort when you need guaranteed O(n log n) performance and memory usage is a concern.\n\nA: The heapify process can be partially parallelized, but the sequential nature of extraction limits full parallelization.\n• Key Points\n• Not stable but efficient for large datasets\n• Introduction to Algorithms by Cormen et al."
    }
]