[
    {
        "link": "https://stackoverflow.com/questions/20108011/using-layered-rendering-with-default-framebuffer",
        "document": "I know that we can attach a layered texture which is:\n\nto a FBO and do layered rendering.\n\nThe OpenGL wiki also says \"Layered rendering is the process of having the GS send specific primitives to different layers of a layered framebuffer.\"\n\nCan default framebuffer be a layered framebuffer? i.e Can I bind a 3d texture to the default FB and use a geometry shader to render to different layers of this texture? I tried writing such a program but the screen is blank and I am not sure if this is right.\n\nIf it is not, what is possibly happening when I bind default FB for layered rendering?"
    },
    {
        "link": "https://learnopengl.com/Advanced-OpenGL/Framebuffers",
        "document": "So far we've used several types of screen buffers: a color buffer for writing color values, a depth buffer to write and test depth information, and finally a stencil buffer that allows us to discard certain fragments based on some condition. The combination of these buffers is stored somewhere in GPU memory and is called a . OpenGL gives us the flexibility to define our own framebuffers and thus define our own color (and optionally a depth and stencil) buffer.\n\nThe rendering operations we've done so far were all done on top of the render buffers attached to the . The default framebuffer is created and configured when you create your window (GLFW does this for us). By creating our own framebuffer we can get an additional target to render to.\n\nThe application of framebuffers may not immediately make sense, but rendering your scene to a different framebuffer allows us to use that result to create mirrors in a scene, or do cool post-processing effects for example. First we'll discuss how they actually work and then we'll use them by implementing those cool post-processing effects.\n\nJust like any other object in OpenGL we can create a framebuffer object (abbreviated to FBO) by using a function called :\n\nThis pattern of object creation and usage is something we've seen dozens of times now so their usage functions are similar to all the other object's we've seen: first we create a framebuffer object, bind it as the active framebuffer, do some operations, and unbind the framebuffer. To bind the framebuffer we use :\n\nBy binding to the target all the next read and write framebuffer operations will affect the currently bound framebuffer. It is also possible to bind a framebuffer to a read or write target specifically by binding to or respectively. The framebuffer bound to is then used for all read operations like and the framebuffer bound to is used as the destination for rendering, clearing and other write operations. Most of the times you won't need to make this distinction though and you generally bind to both with .\n\nUnfortunately, we can't use our framebuffer yet because it is not . For a framebuffer to be complete the following requirements have to be satisfied:\n• We have to attach at least one buffer (color, depth or stencil buffer).\n• There should be at least one color attachment.\n• All attachments should be complete as well (reserved memory).\n• Each buffer should have the same number of samples.\n\nDon't worry if you don't know what samples are, we'll get to those in a later chapter.\n\nFrom the requirements it should be clear that we need to create some kind of attachment for the framebuffer and attach this attachment to the framebuffer. After we've completed all requirements we can check if we actually successfully completed the framebuffer by calling with . It then checks the currently bound framebuffer and returns any of these values found in the specification. If it returns we're good to go:\n\nAll subsequent rendering operations will now render to the attachments of the currently bound framebuffer. Since our framebuffer is not the default framebuffer, the rendering commands will have no impact on the visual output of your window. For this reason it is called when rendering to a different framebuffer. If you want all rendering operations to have a visual impact again on the main window we need to make the default framebuffer active by binding to :\n\nWhen we're done with all framebuffer operations, do not forget to delete the framebuffer object:\n\nNow before the completeness check is executed we need to attach one or more attachments to the framebuffer. An is a memory location that can act as a buffer for the framebuffer, think of it as an image. When creating an attachment we have two options to take: textures or objects.\n\nWhen attaching a texture to a framebuffer, all rendering commands will write to the texture as if it was a normal color/depth or stencil buffer. The advantage of using textures is that the render output is stored inside the texture image that we can then easily use in our shaders.\n\nCreating a texture for a framebuffer is roughly the same as creating a normal texture:\n\nThe main differences here is that we set the dimensions equal to the screen size (although this is not required) and we pass as the texture's parameter. For this texture, we're only allocating memory and not actually filling it. Filling the texture will happen as soon as we render to the framebuffer. Also note that we do not care about any of the wrapping methods or mipmapping since we won't be needing those in most cases.\n\nNow that we've created a texture, the last thing we need to do is actually attach it to the framebuffer:\n\nThe function has the following parameters:\n• : the framebuffer type we're targeting (draw, read or both).\n• : the type of attachment we're going to attach. Right now we're attaching a color attachment. Note that the at the end suggests we can attach more than 1 color attachment. We'll get to that in a later chapter.\n• : the type of the texture you want to attach.\n• : the mipmap level. We keep this at .\n\nNext to the color attachments we can also attach a depth and a stencil texture to the framebuffer object. To attach a depth attachment we specify the attachment type as . Note that the texture's and type should then become to reflect the depth buffer's storage format. To attach a stencil buffer you use as the second argument and specify the texture's formats as .\n\nIt is also possible to attach both a depth buffer and a stencil buffer as a single texture. Each 32 bit value of the texture then contains 24 bits of depth information and 8 bits of stencil information. To attach a depth and stencil buffer as one texture we use the type and configure the texture's formats to contain combined depth and stencil values. An example of attaching a depth and stencil buffer as one texture to the framebuffer is given below:\n\nwere introduced to OpenGL after textures as a possible type of framebuffer attachment, Just like a texture image, a renderbuffer object is an actual buffer e.g. an array of bytes, integers, pixels or whatever. However, a renderbuffer object can not be directly read from. This gives it the added advantage that OpenGL can do a few memory optimizations that can give it a performance edge over textures for off-screen rendering to a framebuffer.\n\nRenderbuffer objects store all the render data directly into their buffer without any conversions to texture-specific formats, making them faster as a writeable storage medium. You cannot read from them directly, but it is possible to read from them via the slow . This returns a specified area of pixels from the currently bound framebuffer, but not directly from the attachment itself.\n\nBecause their data is in a native format they are quite fast when writing data or copying data to other buffers. Operations like switching buffers are therefore quite fast when using renderbuffer objects. The function we've been using at the end of each frame may as well be implemented with renderbuffer objects: we simply write to a renderbuffer image, and swap to the other one at the end. Renderbuffer objects are perfect for these kind of operations.\n\nCreating a renderbuffer object looks similar to the framebuffer's code:\n\nAnd similarly we want to bind the renderbuffer object so all subsequent renderbuffer operations affect the current :\n\nSince renderbuffer objects are write-only they are often used as depth and stencil attachments, since most of the time we don't really need to read values from them, but we do care about depth and stencil testing. We need the depth and stencil values for testing, but don't need to sample these values so a renderbuffer object suits this perfectly. When we're not sampling from these buffers, a renderbuffer object is generally preferred.\n\nCreating a depth and stencil renderbuffer object is done by calling the function:\n\nCreating a renderbuffer object is similar to texture objects, the difference being that this object is specifically designed to be used as a framebuffer attachment, instead of a general purpose data buffer like a texture. Here we've chosen as the internal format, which holds both the depth and stencil buffer with 24 and 8 bits respectively.\n\nThe last thing left to do is to actually attach the renderbuffer object:\n\nRenderbuffer objects can be more efficient for use in your off-screen render projects, but it is important to realize when to use renderbuffer objects and when to use textures. The general rule is that if you never need to sample data from a specific buffer, it is wise to use a renderbuffer object for that specific buffer. If you need to sample data from a specific buffer like colors or depth values, you should use a texture attachment instead.\n\nNow that we know how framebuffers (sort of) work it's time to put them to good use. We're going to render the scene into a color texture attached to a framebuffer object we created and then draw this texture over a simple quad that spans the whole screen. The visual output is then exactly the same as without a framebuffer, but this time it's all printed on top of a single quad. Now why is this useful? In the next section we'll see why.\n\nFirst thing to do is to create an actual framebuffer object and bind it, this is all relatively straightforward:\n\nNext we create a texture image that we attach as a color attachment to the framebuffer. We set the texture's dimensions equal to the width and height of the window and keep its data uninitialized:\n\nWe also want to make sure OpenGL is able to do depth testing (and optionally stencil testing) so we have to make sure to add a depth (and stencil) attachment to the framebuffer. Since we'll only be sampling the color buffer and not the other buffers we can create a renderbuffer object for this purpose.\n\nCreating a renderbuffer object isn't too hard. The only thing we have to remember is that we're creating it as a depth and stencil attachment renderbuffer object. We set its internal format to which is enough precision for our purposes:\n\nOnce we've allocated enough memory for the renderbuffer object we can unbind the renderbuffer.\n\nThen, as a final step before we complete the framebuffer, we attach the renderbuffer object to the depth and stencil attachment of the framebuffer:\n\nThen we want to check if the framebuffer is complete and if it's not, we print an error message.\n\nBe sure to unbind the framebuffer to make sure we're not accidentally rendering to the wrong framebuffer.\n\nNow that the framebuffer is complete, all we need to do to render to the framebuffer's buffers instead of the default framebuffers is to simply bind the framebuffer object. All subsequent render commands will then influence the currently bound framebuffer. All the depth and stencil operations will also read from the currently bound framebuffer's depth and stencil attachments if they're available. If you were to omit a depth buffer for example, all depth testing operations will no longer work.\n\nSo, to draw the scene to a single texture we'll have to take the following steps:\n• Render the scene as usual with the new framebuffer bound as the active framebuffer.\n• Draw a quad that spans the entire screen with the new framebuffer's color buffer as its texture.\n\nWe'll render the same scene we've used in the depth testing chapter, but this time with the old-school container texture.\n\nTo render the quad we're going to create a fresh set of simple shaders. We're not going to include fancy matrix transformations since we'll be supplying the vertex coordinates as normalized device coordinates so we can directly forward them as output of the vertex shader. The vertex shader looks like this:\n\nNothing too fancy. The fragment shader is even more basic since the only thing we have to do is sample from a texture:\n\nIt is then up to you to create and configure a VAO for the screen quad. A single render iteration of the framebuffer procedure has the following structure:\n\nThere are a few things to note. First, since each framebuffer we're using has its own set of buffers, we want to clear each of those buffers with the appropriate bits set by calling . Second, when drawing the quad, we're disabling depth testing since we want to make sure the quad always renders in front of everything else; we'll have to enable depth testing again when we draw the normal scene though.\n\nThere are quite some steps that could go wrong here, so if you have no output, try to debug where possible and re-read the relevant sections of the chapter. If everything did work out successfully you'll get a visual result that looks like this:\n\nThe left shows the visual output, exactly the same as we've seen in the depth testing chapter, but this time rendered on a simple quad. If we render the scene in wireframe it's obvious we've only drawn a single quad in the default framebuffer.\n\nYou can find the source code of the application here.\n\nSo what was the use of this again? Well, because we can now freely access each of the pixels of the completely rendered scene as a single texture image, we can create some interesting effects in the fragment shader.\n\nNow that the entire scene is rendered to a single texture we can create cool effects by manipulating the scene texture. In this section we'll show you some of the more popular post-processing effects and how you may create your own with some added creativity.\n\nLet's start with one of the simplest post-processing effects.\n\nWe have access to each of the colors of the render output so it's not so hard to return the inverse of these colors in the fragment shader. We can take the color of the screen texture and inverse it by subtracting it from :\n\nWhile inversion is a relatively simple post-processing effect it already creates funky results:\n\nThe entire scene now has all its colors inversed with a single line of code in the fragment shader. Pretty cool huh?\n\nAnother interesting effect is to remove all colors from the scene except the white, gray and black colors; effectively grayscaling the entire image. An easy way to do this is by taking all the color components and averaging their results:\n\nThis already creates pretty good results, but the human eye tends to be more sensitive to green colors and the least to blue. So to get the most physically accurate results we'll need to use weighted channels:\n\nYou probably won't notice the difference right away, but with more complicated scenes, such a weighted grayscaling effect tends to be more realistic.\n\nAnother advantage about doing post-processing on a single texture image is that we can sample color values from other parts of the texture not specific to that fragment. We could for example take a small area around the current texture coordinate and sample multiple texture values around the current texture value. We can then create interesting effects by combining them in creative ways.\n\nA (or convolution matrix) is a small matrix-like array of values centered on the current pixel that multiplies surrounding pixel values by its kernel values and adds them all together to form a single value. We're adding a small offset to the texture coordinates in surrounding directions of the current pixel and combine the results based on the kernel. An example of a kernel is given below:\n\nThis kernel takes 8 surrounding pixel values and multiplies them by and the current pixel by . This example kernel multiplies the surrounding pixels by several weights determined in the kernel and balances the result by multiplying the current pixel by a large negative weight.\n\nKernels are an extremely useful tool for post-processing since they're quite easy to use and experiment with, and a lot of examples can be found online. We do have to slightly adapt the fragment shader a bit to actually support kernels. We make the assumption that each kernel we'll be using is a 3x3 kernel (which most kernels are):\n\nIn the fragment shader we first create an array of 9 offsets for each surrounding texture coordinate. The offset is a constant value that you could customize to your liking. Then we define the kernel, which in this case is a kernel that sharpens each color value by sampling all surrounding pixels in an interesting way. Lastly, we add each offset to the current texture coordinate when sampling and multiply these texture values with the weighted kernel values that we add together.\n\nThis particular sharpen kernel looks like this:\n\nThis could be the base of some interesting effects where your player may be on a narcotic adventure.\n\nA kernel that creates a effect is defined as follows:\n\nBecause all values add up to 16, directly returning the combined sampled colors would result in an extremely bright color so we have to divide each value of the kernel by . The resulting kernel array then becomes:\n\nBy only changing the kernel array in the fragment shader we can completely change the post-processing effect. It now looks something like this:\n\nSuch a blur effect creates interesting possibilities. We could vary the blur amount over time to create the effect of someone being drunk, or increase the blur whenever the main character is not wearing glasses. Blurring can also be a useful tool for smoothing color values which we'll see use of in later chapters.\n\nYou can see that once we have such a little kernel implementation in place it is quite easy to create cool post-processing effects. Let's show you a last popular effect to finish this discussion.\n\nBelow you can find an kernel that is similar to the sharpen kernel:\n\nThis kernel highlights all edges and darkens the rest, which is pretty useful when we only care about edges in an image.\n\nIt probably does not come as a surprise that kernels like this are used as image-manipulating tools/filters in tools like Photoshop. Because of a graphic card's ability to process fragments with extreme parallel capabilities, we can manipulate images on a per-pixel basis in real-time with relative ease. Image-editing tools therefore tend to use graphics cards for image-processing.\n• Can you use framebuffers to create a rear-view mirror? For this you'll have to draw your scene twice: one with the camera rotated 180 degrees and the other as normal. Try to create a small quad at the top of your screen to apply the mirror texture on, something like this; solution.\n• Play around with the kernel values and create your own interesting post-processing effects. Try searching the internet as well for other interesting kernels."
    },
    {
        "link": "https://khronos.org/opengl/wiki/Framebuffer_Object",
        "document": "Framebuffer Objects are OpenGL Objects, which allow for the creation of user-defined Framebuffers. With them, one can render to non-Default Framebuffer locations, and thus render without disturbing the main screen.\n\nFramebuffer objects are a collection of attachments. To help explain lets explicitly define certain terminology.\n\nAs standard OpenGL Objects, FBOs have the usual glGenFramebuffers and glDeleteFramebuffers functions. As expected, it also has the usual glBindFramebuffer function, to bind an FBO to the context.\n\nThe target​ parameter for this object can take one of 3 values: GL_FRAMEBUFFER, GL_READ_FRAMEBUFFER, or GL_DRAW_FRAMEBUFFER. The last two allow you to bind an FBO so that reading commands (glReadPixels, etc) and writing commands (all rendering commands) can happen to two different framebuffers. The GL_FRAMEBUFFER binding target simply sets both the read and the write to the same FBO.\n\nThe default framebuffer has buffer names like GL_FRONT, GL_BACK, GL_AUXi, GL_ACCUM, and so forth. FBOs do not use these.\n\nInstead, FBOs have a different set of image names. Each FBO image represents an attachment point, a location in the FBO where an image can be attached. FBOs have the following attachment points:\n• : These are an implementation-dependent number of attachment points. You can query to determine the number of color attachments that an implementation will allow. The minimum value for this is 8, so you are guaranteed to be able to have at least color attachments 0-7. These attachment points can only have images bound to them with color-renderable formats. All compressed image formats are not color-renderable, and thus cannot be attached to an FBO.\n• : This attachment point can only have images with depth formats bound to it. The image attached becomes the Depth Buffer for the FBO. Note that if no depth image is attached, Depth Testing will be disabled when rendering to this FBO.\n• : This attachment point can only have images with stencil formats bound to it. The image attached becomes the stencil buffer for the FBO.\n• : This is shorthand for \"both depth and stencil\". The image attached becomes both the depth and stencil buffers.\n\nNow that we know where images can be attached to FBOs, we can start talking about how to actually attach images to these. In order to attach images to an FBO, we must first bind the FBO to the context with glBindFramebuffer.\n\nYou can attach images from most texture types to the framebuffer object. However, framebuffers are designed for 2D rendering. So there is a need to consider how different texture types map to framebuffer images. Remember that textures are a set of images. Textures can have mipmaps, and individual mipmap levels could contain one or more images.\n\nThe way different texture types map to framebuffer images is as follows:\n• Images in a 1D texture are considered 2D images with a vertical height of 1. Each individual image can be uniquely identified by a mipmap .\n• Images in a 2D texture are taken as normal. Each individual image can be uniquely identified by a mipmap .\n• A mipmap level of a 3D texture is considered to be a set of 2D images, with the number of these images being the extent of the Z coordinate for that mipmap level. Each integer value for the Z of a 3D texture mipmap level is a separate 2D layer. So each image in a 3D texture is uniquely identified by a and a mipmap . Recall that different mipmap levels in a 3D texture will have different counts of Z coordinates.\n• Rectangle Textures contain a single 2D image, which is identified by a of 0.\n• Cubemap Textures contain 6 2D images per mipmap. Thus, each image in a cubemap texture can be uniquely identified by a face and a mipmap . However, in some API functions, individual faces in a mipmap level are identified by a index instead of a .\n• Each mipmap level of 1D or 2D Array Textures contains a number of images, equal to the count images in the array. Thus, each individual image is uniquely identified by a (the array index) and a mipmap . For 1D array textures, each image has a height of 1. Unlike 3D textures, the doesn't change when going down the mipmap hierarchy.\n• Cubemap Array Textures work like 2D array textures, only with an image count 6 times the number of its layers. A 2D image in the cubemap array is identified by the layer-face index and a mipmap .\n• Buffer Textures cannot be attached to framebuffers.\n\nThe words level​, layer​, and target​ above are significant, as they match the parameters of the following functions used for attaching textures:\n\n\n\n The target​ parameter here is the same as the one for bind. However, GL_FRAMEBUFFER doesn't mean both read and draw (as that would make no sense); instead, it is the same as GL_DRAW_FRAMEBUFFER. The attachment​ parameter is one of the above attachment points.\n\nThe texture​ argument is the texture object name you want to attach from. If you pass zero as texture​, this has the effect of clearing the attachment for this attachment​, regardless of what kind of image was attached there.\n\nBecause texture objects can hold multiple images, you must specify exactly which image to attach to this attachment point. The parameters match their above definitions, with the exception of textarget​.\n\nWhen attaching a non-cubemap, textarget​ should be the proper texture type: GL_TEXTURE_1D, GL_TEXTURE_2D_MULTISAMPLE, etc. When attaching a (non-array) cubemap, you must use the Texture2D function, and the textarget​ must be one of the 6 targets for cubemap binding. When attaching an image from a cubemap array, you must use TextureLayer, with the layer​ being a layer-face.\n\nRenderbuffers can also be attached to FBOs. Indeed, this is the only way to use them besides just creating the storage for them.\n\nOnce you have created a renderbuffer object and made storage for it (given a size and format), you can attach it to an FBO with this function:\n\nThe parameters work mostly the same as with texture attachment. The renderbuffertarget​ param must be GL_RENDERBUFFER. The renderbuffer​ parameter is the renderbuffer object's name.\n\nA layered image, as previously defined, is an ordered sequence of images of a particular size. A number of different kinds of textures can be considered layered. Layered images are used with Layered Rendering, which sends different primitives to different layers within the framebuffer.\n\nA single mipmap level of a 1D or 2D Array Texture can be attached as a layered image, where the number of layers is the array size. A single mipmap level of a 3D texture likewise can be attached as a layered image, where the number of layers is the depth of that particular mipmap level. Also, a mipmap level of a Cubemap Texture can be attached as a layered image. For cubemaps, you get exactly 6 layers, one for each face. And the order of the faces is the same as the order of the enumerators:\n\nFor cubemap arrays, the value that gl_Layer represents is the layer-face index. Thus it is the face within a layer, ordered as above. So if you want to render to the 3rd layer, +z face, you would set gl_Layer to (2 * 6) + 4, or 16.\n\nEach mipmap level, when can be attached as a layered image, has a specific number of layers. For 1D and 2D array textures, it is the number of layers in the texture as a whole. For 3D textures, this is the depth of that particular mipmap level. For cubemaps, this is always exactly 6 layers: one per face. Cubemap arrays have 6 * the number of layers, which is the number of layer-faces.\n\nTo attach a mipmap level of a texture as a layered image, use the following command:\n\nThe parameters have the same meaning as above. Indeed, this function can replace many of the uses for glFramebufferTexture1D, 2D, or Layer, as long as you do not intend to attach specific layers of array textures, cubemaps, or 3D textures as regular, non-layered images. If the texture​ is one of these kinds of textures, then the given mipmap level​ will be attached as a layered image with the number of layers that the given texture has.\n\nIt is possible to render to a framebuffer object that has no attachments. Obviously none of the fragment shader outputs will be written to anywhere in this case, but rendering can otherwise proceed as normal. This is useful for using arbitrary reading and writing of image data from shaders, rather than writing to a bound framebuffer.\n\nHowever, the rasterization of primitives is always based on the area and characteristics of the bound framebuffer. These characteristics (size, number of samples for multisample rendering, etc) would normally be defined by the attached images. If no images are attached, these characteristics must be defined in some other fashion.\n\nThe characteristics for an FBO with no attachments can be set with this function:\n\ntarget​ is the location where the framebuffer object is bound. To set the width, set pname​ to GL_FRAMEBUFFER_DEFAULT_WIDTH; to set the height, use GL_FRAMEBUFFER_DEFAULT_HEIGHT.\n\nLayered framebuffers can be simulated by setting GL_FRAMEBUFFER_DEFAULT_LAYERS to a layer count other than 0. Multisample framebuffers can be simulated by setting GL_FRAMEBUFFER_DEFAULT_SAMPLES to a number of samples other than 0. Fixed multisample location can similarly be simulated by setting GL_FRAMEBUFFER_DEFAULT_FIXED_SAMPLE_LOCATIONS to a non-zero value.\n\nNote that rendering is only limited to these parameters if no images are attached to the FBO. If images are attached, then these parameters are ignored. You should only set these values if you intend to use the FBO without images.\n\nEach attachment point in a FBO has specific restrictions on the format of images that can be attached to it. However, it is not an immediate GL error to attach an image to an attachment point that doesn't support that format. It is an error to try to use an FBO that has been improperly set up. There are also a number of other issues with regard to sizes of images and so forth that must be detected in order to be able to safely use the FBO.\n\nAn FBO that is valid for use is said to be \"framebuffer complete\". To test framebuffer completeness, call this function:\n\nYou are not required to call this manually. However, using an incomplete FBO is an error, so it's always a good idea to check.\n\nThe return value is GL_FRAMEBUFFER_COMPLETE if the FBO can be used. If it is something else, then there is a problem. Below are the rules for completeness and the associated return values you will receive if they are not followed.\n\nEach attachment point itself must be complete according to these rules. Empty attachments (attachments with no image attached) are complete by default. If an image is attached, it must adhere to the following rules:\n• The source object for the image still exists and has the same type it was attached with.\n• The image has a non-zero width and height (the height of a 1D image is assumed to be 1). The width/height must also be less than and respectively (if GL 4.3/ARB_framebuffer_no_attachments).\n• The layer for 3D or array textures attachments is less than the depth of the texture. It must also be less than (if GL 4.3/ARB_framebuffer_no_attachments).\n• The number of samples must be less than (if GL 4.3/ARB_framebuffer_no_attachments).\n• The image's format must match the attachment point's requirements, as defined above. Color-renderable formats for color attachments, etc.\n\nThese are the rules for framebuffer completeness. The order of these rules matters.\n• If the of references the Default Framebuffer (ie: FBO object number 0 is bound), and the default framebuffer does not exist, then you will get . If the default framebuffer exists, then you always get . The rest of the rules apply when an FBO is bound.\n• All attachments must be attachment complete. ( when false).\n• There must be at least one image attached to the FBO, or if OpenGL 4.3 ARB_framebuffer_no_attachments is available, the and parameters of the framebuffer must both be non-zero. ( when false).\n• Each draw buffer must either specify color attachment points that have images attached or must be . ( when false). Note that this test is not performed if OpenGL 4.1 ARB_ES2_compatibility is available.\n• If the read buffer is set, then it must specify an attachment point that has an image attached. ( when false). Note that this test is not performed if OpenGL 4.1 ARB_ES2_compatibility is available.\n• All images must have the same number of multisample samples. All images must also use the same fixed sample layout setting. ( when false).\n• If a layered image is attached to one attachment, then all attachments must be layered attachments. The attached layers do not have to have the same number of layers, nor do the layers have to come from the same kind of texture (a cubemap color texture can be paired with an array depth texture) ( when false).\n\nNotice that there is no restriction based on size. The effective size of the FBO is the intersection of all of the sizes of the bound images (ie: the smallest in each dimension).\n\nThese rules are all code-based. If you ever get any of these values from glCheckFramebufferStatus, it is because your program has done something wrong in setting up the FBO. Each one has a specific remedy for it.\n\nThere's one more rule that can trip you up:\n• The implementation likes your combination of attached image formats. ( when false).\n\nOpenGL allows implementations to state that they do not support some combination of image formats for the attached images; they do this by returning GL_FRAMEBUFFER_UNSUPPORTED when you attempt to use an unsupported format combination.\n\nHowever, the OpenGL specification also requires that implementations support certain format combinations; if you use these, implementations are forbidden to return GL_FRAMEBUFFER_UNSUPPORTED. Implementations must allow any combination of color formats, so long as all of those color formats come from the required set of color formats.\n\nThese color formats can be combined with a depth attachment with any of the required depth formats. Stencil attachments can also be used, again with the required stencil formats, as well as the combined depth/stencil formats. However, implementations are only required to support both a depth and stencil attachment simultaneously if both attachments refer to the same image.\n\nThis means that if you want stencil with no depth, you can use one of the required stencil formats. If you want depth with no stencil, you can use one of the required depth formats. But if you want depth and stencil, you must use a depth/stencil format and the same image in that texture must be attached to both the depth and stencil attachments.\n\nStaying within these limits means you won't see GL_FRAMEBUFFER_UNSUPPORTED. Going outside of these limits makes it entirely possible to get this incompleteness.\n\nIt is possible to bind a texture to an FBO, bind that same texture to a shader, and then try to render with it at the same time.\n\nIt is perfectly valid to bind one image from a texture to an FBO and then render with that texture, as long as you prevent yourself from sampling from that image. If you do try to read and write to the same image, you get undefined results. Meaning it may do what you want, the sampler may get old data, the sampler may get half old and half new data, or it may get garbage data. Any of these are possible outcomes.\n\nDo not do this. What you will get is undefined behavior.\n\nOpenGL OpenGL 4.5 or ARB_texture_barrier reduces the cases of feedback loops to just reading/writing from the same pixels, and even allows a limited ability to read/write the same pixels.\n\nA pseudo implementation will make framebuffers much easier to understand.\n\nWhere Attachment can be one of\n\nAttaching a texture or renderbuffer works like this\n\nSetting the draw buffers and read buffer settings works like this\n\nThe original form of FBOs was this extension. It lacked quite a bit of the above functionality, which later extensions granted. The biggest difference is that it has more hard-coded restrictions on framebuffer completeness. All of the images have to be the same size in the EXT spec, for example. Some of these limitations were hardware-based. So there may be hardware that supports EXT_FBO and not ARB_FBO, even thought they support things like EXT_FBO_blit and other parts of ARB_FBO.\n• Framebuffer Object Extension Examples Note that these examples use the (old) syntax for the extension, not the core functionality.\n• Category:Core API Ref Framebuffer Objects: Reference documentation for functions that deal with framebuffer objects and renderbuffer objects."
    },
    {
        "link": "https://learnopengl.com/In-Practice/Text-Rendering",
        "document": "At some stage of your graphics adventures you will want to draw text in OpenGL. Contrary to what you may expect, getting a simple string to render on screen is all but easy with a low-level API like OpenGL. If you don't care about rendering more than 128 different same-sized characters, then it's probably not too difficult. Things are getting difficult as soon as each character has a different width, height, and margin. Based on where you live, you may also need more than 128 characters, and what if you want to express special symbols for like mathematical expressions or sheet music symbols, and what about rendering text from top to bottom? Once you think about all these complicated matters of text, it wouldn't surprise you that this probably doesn't belong in a low-level API like OpenGL.\n\nSince there is no support for text capabilities within OpenGL, it is up to us to define a system for rendering text to the screen. There are no graphical primitives for text characters, we have to get creative. Some example techniques are: drawing letter shapes via , create 3D meshes of letters, or render character textures to 2D quads in a 3D environment.\n\nMost developers choose to render character textures onto quads. Rendering textured quads by itself shouldn't be too difficult, but getting the relevant character(s) onto a texture could prove challenging. In this chapter we'll explore several methods and implement a more advanced, but flexible technique for rendering text using the FreeType library.\n\nIn the early days, rendering text involved selecting a font (or create one yourself) you'd like for your application and extracting all relevant characters out of this font to place them within a single large texture. Such a texture, that we call a , contains all character symbols we want to use in predefined regions of the texture. These character symbols of the font are known as . Each glyph has a specific region of texture coordinates associated with them. Whenever you want to render a character, you select the corresponding glyph by rendering this section of the bitmap font to a 2D quad.\n\nHere you can see how we would render the text 'OpenGL' by taking a bitmap font and sampling the corresponding glyphs from the texture (carefully choosing the texture coordinates) that we render on top of several quads. By enabling blending and keeping the background transparent, we will end up with just a string of characters rendered to the screen. This particular bitmap font was generated using Codehead's Bitmap Font Generator.\n\nThis approach has several advantages and disadvantages. It is relatively easy to implement and because bitmap fonts are pre-rasterized, they're quite efficient. However, it is not particularly flexible. When you want to use a different font, you need to recompile a complete new bitmap font and the system is limited to a single resolution; zooming will quickly show pixelated edges. Furthermore, it is limited to a small character set, so Extended or Unicode characters are often out of the question.\n\nThis approach was quite popular back in the day (and still is) since it is fast and works on any platform, but as of today more flexible approaches exist. One of these approaches is loading TrueType fonts using the FreeType library.\n\nFreeType is a software development library that is able to load fonts, render them to bitmaps, and provide support for several font-related operations. It is a popular library used by Mac OS X, Java, PlayStation, Linux, and Android to name a few. What makes FreeType particularly attractive is that it is able to load TrueType fonts.\n\nA TrueType font is a collection of character glyphs not defined by pixels or any other non-scalable solution, but by mathematical equations (combinations of splines). Similar to vector images, the rasterized font images can be procedurally generated based on the preferred font height you'd like to obtain them in. By using TrueType fonts you can easily render character glyphs of various sizes without any loss of quality.\n\nFreeType can be downloaded from their website. You can choose to compile the library yourself or use one of their precompiled libraries if your target platform is listed. Be sure to link to and make sure your compiler knows where to find the header files.\n\nThen include the appropriate headers:\n\nFreeType loads these TrueType fonts and, for each glyph, generates a bitmap image and calculates several metrics. We can extract these bitmap images for generating textures and position each character glyph appropriately using the loaded metrics.\n\nTo load a font, all we have to do is initialize the FreeType library and load the font as a as FreeType likes to call it. Here we load the TrueType font file that was copied from the directory:\n\nEach of these FreeType functions returns a non-zero integer whenever an error occurred.\n\nOnce we've loaded the face, we should define the pixel font size we'd like to extract from this face:\n\nThe function sets the font's width and height parameters. Setting the width to lets the face dynamically calculate the width based on the given height.\n\nA FreeType face hosts a collection of glyphs. We can set one of those glyphs as the active glyph by calling . Here we choose to load the character glyph 'X':\n\nBy setting as one of the loading flags, we tell FreeType to create an 8-bit grayscale bitmap image for us that we can access via .\n\nEach of the glyphs we load with FreeType however, do not have the same size (as we had with bitmap fonts). The bitmap image generated by FreeType is just large enough to contain the visible part of a character. For example, the bitmap image of the dot character '.' is much smaller in dimensions than the bitmap image of the character 'X'. For this reason, FreeType also loads several metrics that specify how large each character should be and how to properly position them. Next is an image from FreeType that shows all of the metrics it calculates for each character glyph:\n\nEach of the glyphs reside on a horizontal (as depicted by the horizontal arrow) where some glyphs sit exactly on top of this baseline (like 'X') or some slightly below the baseline (like 'g' or 'p'). These metrics define the exact offsets to properly position each glyph on the baseline, how large each glyph should be, and how many pixels we need to advance to render the next glyph. Next is a small list of the properties we'll be needing:\n• width: the width (in pixels) of the bitmap accessed via .\n• height: the height (in pixels) of the bitmap accessed via .\n• bearingX: the horizontal bearing e.g. the horizontal position (in pixels) of the bitmap relative to the origin accessed via .\n• bearingY: the vertical bearing e.g. the vertical position (in pixels) of the bitmap relative to the baseline accessed via .\n• advance: the horizontal advance e.g. the horizontal distance (in 1/64th pixels) from the origin to the origin of the next glyph. Accessed via .\n\nWe could load a character glyph, retrieve its metrics, and generate a texture each time we want to render a character to the screen, but it would be inefficient to do this each frame. We'd rather store the generated data somewhere in the application and query it whenever we want to render a character. We'll define a convenient that we'll store in a :\n\nFor this chapter we'll keep things simple by restricting ourselves to the first 128 characters of the ASCII character set. For each character, we generate a texture and store its relevant data into a struct that we add to the map. This way, all data required to render each character is stored for later use.\n\nWithin the for loop we list over all the 128 characters of the ASCII set and retrieve their corresponding character glyphs. For each character: we generate a texture, set its options, and store its metrics. What is interesting to note here is that we use as the texture's and arguments. The bitmap generated from the glyph is a grayscale 8-bit image where each color is represented by a single byte. For this reason we'd like to store each byte of the bitmap buffer as the texture's single color value. We accomplish this by creating a texture where each byte corresponds to the texture color's red component (first byte of its color vector). If we use a single byte to represent the colors of a texture we do need to take care of a restriction of OpenGL:\n\nOpenGL requires that textures all have a 4-byte alignment e.g. their size is always a multiple of 4 bytes. Normally this won't be a problem since most textures have a width that is a multiple of 4 and/or use 4 bytes per pixel, but since we now only use a single byte per pixel, the texture can have any possible width. By setting its unpack alignment to we ensure there are no alignment issues (which could cause segmentation faults).\n\nBe sure to clear FreeType's resources once you're finished processing the glyphs:\n\nTo render the glyphs we'll be using the following vertex shader:\n\nWe combine both the position and texture coordinate data into one . The vertex shader multiplies the coordinates with a projection matrix and forwards the texture coordinates to the fragment shader:\n\nThe fragment shader takes two uniforms: one is the mono-colored bitmap image of the glyph, and the other is a color uniform for adjusting the text's final color. We first sample the color value of the bitmap texture. Because the texture's data is stored in just its red component, we sample the component of the texture as the sampled alpha value. By varying the output color's alpha value, the resulting pixel will be transparent for all the glyph's background colors and non-transparent for the actual character pixels. We also multiply the RGB colors by the uniform to vary the text color.\n\nWe do need to enable blending for this to work though:\n\nFor the projection matrix we'll be using an orthographic projection matrix. For rendering text we (usually) do not need perspective, and using an orthographic projection matrix also allows us to specify all vertex coordinates in screen coordinates if we set it up as follows:\n\nWe set the projection matrix's bottom parameter to and its top parameter equal to the window's height. The result is that we specify coordinates with values ranging from the bottom part of the screen ( ) to the top part of the screen ( ). This means that the point ( , ) now corresponds to the bottom-left corner.\n\nLast up is creating a VBO and VAO for rendering the quads. For now we reserve enough memory when initiating the VBO so that we can later update the VBO's memory when rendering characters:\n\nThe 2D quad requires vertices of floats each, so we reserve floats of memory. Because we'll be updating the content of the VBO's memory quite often we'll allocate the memory with .\n\nTo render a character, we extract the corresponding struct of the map and calculate the quad's dimensions using the character's metrics. With the quad's calculated dimensions we dynamically generate a set of 6 vertices that we use to update the content of the memory managed by the VBO using .\n\nWe create a function called that renders a string of characters:\n\nMost of the content of the function should be relatively self-explanatory: we first calculate the origin position of the quad (as and ) and the quad's size (as and ) and generate a set of 6 vertices to form the 2D quad; note that we scale each metric by . We then update the content of the VBO and render the quad.\n\nThe following line of code requires some extra attention though:\n\nSome characters (like 'p' or 'g') are rendered slightly below the baseline, so the quad should also be positioned slightly below 's value. The exact amount we need to offset below the baseline can be figured out from the glyph metrics:\n\nTo calculate this distance e.g. offset we need to figure out the distance a glyph extends below the baseline; this distance is indicated by the red arrow. As you can see from the glyph metrics, we can calculate the length of this vector by subtracting from the glyph's (bitmap) height. This value is then for characters that rest on the baseline (like 'X') and positive for characters that reside slightly below the baseline (like 'g' or 'j').\n\nIf you did everything correct you should now be able to successfully render strings of text with the following statements:\n\nThis should then look similar to the following image:\n\nYou can find the code of this example here.\n\nTo give you a feel for how we calculated the quad's vertices, we can disable blending to see what the actual rendered quads look like:\n\nHere you can clearly see most quads resting on the (imaginary) baseline while the quads that corresponds to glyphs like 'p' or '(' are shifted downwards.\n\nThis chapter demonstrated a text rendering technique with TrueType fonts using the FreeType library. The approach is flexible, scalable, and works with many character encodings. However, this approach is likely going to be overkill for your application as we generate and render textures for each glyph. Performance-wise, bitmap fonts are preferable as we only need one texture for all our glyphs. The best approach would be to combine the two approaches by dynamically generating a bitmap font texture featuring all character glyphs as loaded with FreeType. This saves the renderer from a significant amount of texture switches and, based on how tight each glyph is packed, could save quite some performance.\n\nAnother issue with FreeType font bitmaps is that the glyph textures are stored with a fixed font size, so a significant amount of scaling may introduce jagged edges. Furthermore, rotations applied to the glyphs will cause them to appear blurry. This can be mitigated by, instead of storing the actual rasterized pixel colors, storing the distance to the closest glyph outline per pixel. This technique is called and Valve published a paper a few years ago about their implementation of this technique which works surprisingly well for 3D rendering applications.\n• 70+ Best Free Fonts for Designers: summarized list of a large group of fonts to use in your project for personal or commercial use."
    },
    {
        "link": "https://reddit.com/r/opengl/comments/qtpl0g/drawing_text_onto_a_separate_framebuffer",
        "document": "What I'm trying to do is basically an optimisation,\n• Draw some text onto a framebuffer on a GL_COLOR_ATTACHMENT0 with a texture attached.\n• Save this in the memory and re-use these bytes whenever someone tries to draw the exact same text again.\n\nThis way I don't have to loop through each character and draw them again if they've already been drawn before.\n\nI can't get this to work though.\n\nBUT, if I render anything besides a texture onto the framebuffer, it works.\n\nLike, if I just draw a colored quad; that get's perfectly written to the framebuffer and I can re-use tit as a texture later.\n\nBut if I try to draw textures onto the framebuffer (characters loaded using freetype2) , it's just completely blank.\n\nMy code is abstracted in multiple layers so would be difficult to share it here.\n\nBut I did everything mentioned here: https://learnopengl.com/code_viewer_gh.php?code=src/4.advanced_opengl/5.1.framebuffers/framebuffers.cpp\n\nOnce the framebuffer is bound, I draw some text, then I call .\n\nAppreciate any kind of help, thanks!\n\nI guess it's good to mention that the text is being rendered if I don't do any framebuffer trickery, so nothing weird going on there.\n\nFinally got it to work.\n\nThere was multiple reasons why it didn't work.\n• The viewport was to small within the bound framebuffer\n• Didn't call \"glClearColor\" with the values needed for the enabled blend Mode.\n\nThank you everyone for your help, very much appreciated!"
    },
    {
        "link": "https://learnopengl.com/Advanced-OpenGL/Stencil-testing",
        "document": "Once the fragment shader has processed the fragment a so called is executed that, just like the depth test, has the option to discard fragments. After that the remaining fragments are passed to the depth test where OpenGL could possibly discard even more fragments. The stencil test is based on the content of yet another buffer called the that we're allowed to update during rendering to achieve interesting effects.\n\nA stencil buffer (usually) contains bits per that amounts to a total of different stencil values per pixel. We can set these stencil values to values of our liking and we can discard or keep fragments whenever a particular fragment has a certain stencil value.\n\nA simple example of a stencil buffer is shown below (pixels not-to-scale):\n\nThe stencil buffer is first cleared with zeros and then an open rectangle of s is stored in the stencil buffer. The fragments of the scene are then only rendered (the others are discarded) wherever the stencil value of that fragment contains a .\n\nStencil buffer operations allow us to set the stencil buffer at specific values wherever we're rendering fragments. By changing the content of the stencil buffer while we're rendering, we're writing to the stencil buffer. In the same (or following) frame(s) we can read these values to discard or pass certain fragments. When using stencil buffers you can get as crazy as you like, but the general outline is usually as follows:\n• Render objects, updating the content of the stencil buffer.\n• Render (other) objects, this time discarding certain fragments based on the content of the stencil buffer.\n\nBy using the stencil buffer we can thus discard certain fragments based on the fragments of other drawn objects in the scene.\n\nYou can enable stencil testing by enabling . From that point on, all rendering calls will influence the stencil buffer in one way or another.\n\nNote that you also need to clear the stencil buffer each iteration just like the color and depth buffer:\n\nAlso, just like the depth testing's function, there is an equivalent function for the stencil buffer. The function allows us to set a bitmask that is ed with the stencil value about to be written to the buffer. By default this is set to a bitmask of all s not affecting the output, but if we were to set this to all the stencil values written to the buffer end up as s. This is equivalent to depth testing's :\n\nMost of the cases you'll only be using or as the stencil mask, but it's good to know there are options to set custom bit-masks.\n\nSimilar to depth testing, we have a certain amount of control over when a stencil test should pass or fail and how it should affect the stencil buffer. There are a total of two functions we can use to configure stencil testing: and .\n\nThe has three parameters:\n• : sets the stencil test function that determines whether a fragment passes or is discarded. This test function is applied to the stored stencil value and the 's value. Possible options are: , , , , , , and . The semantic meaning of these is similar to the depth buffer's functions.\n• : specifies the reference value for the stencil test. The stencil buffer's content is compared to this value.\n• : specifies a mask that is ed with both the reference value and the stored stencil value before the test compares them. Initially set to all s.\n\nSo in the case of the simple stencil example we've shown at the start, the function would be set to:\n\nThis tells OpenGL that whenever the stencil value of a fragment is equal ( ) to the reference value , the fragment passes the test and is drawn, otherwise discarded.\n\nBut only describes whether OpenGL should pass or discard fragments based on the stencil buffer's content, not how we can actually update the buffer. That is where comes in.\n\nThe contains three options of which we can specify for each option what action to take:\n• : action to take if the stencil test fails.\n• : action to take if the stencil test passes, but the depth test fails.\n• : action to take if both the stencil and the depth test pass.\n\nThen for each of the options you can take any of the following actions:\n\nBy default the function is set to so whatever the outcome of any of the tests, the stencil buffer keeps its values. The default behavior does not update the stencil buffer, so if you want to write to the stencil buffer you need to specify at least one different action for any of the options.\n\nSo using and we can precisely specify when and how we want to update the stencil buffer and when to pass or discard fragments based on its content.\n\nIt would be unlikely if you completely understood how stencil testing works from the previous sections alone so we're going to demonstrate a particular useful feature that can be implemented with stencil testing alone called .\n\nObject outlining does exactly what it says it does. For each object (or only one) we're creating a small colored border around the (combined) objects. This is a particular useful effect when you want to select units in a strategy game for example and need to show the user which of the units were selected. The routine for outlining your objects is as follows:\n• Set the stencil op to before drawing the (to be outlined) objects, updating the stencil buffer with s wherever the objects' fragments are rendered.\n• Scale each of the objects by a small amount.\n• Use a different fragment shader that outputs a single (border) color.\n• Draw the objects again, but only if their fragments' stencil values are not equal to .\n• Enable depth testing again and restore stencil func to .\n\nThis process sets the content of the stencil buffer to s for each of the object's fragments and when it's time to draw the borders, we draw scaled-up versions of the objects only where the stencil test passes. We're effectively discarding all the fragments of the scaled-up versions that are part of the original objects' fragments using the stencil buffer.\n\nSo we're first going to create a very basic fragment shader that outputs a border color. We simply set a hardcoded color value and call the shader :\n\nUsing the scene from the previous chapter we're going to add object outlining to the two containers, so we'll leave the floor out of it. We want to first draw the floor, then the two containers (while writing to the stencil buffer), and then draw the scaled-up containers (while discarding the fragments that write over the previously drawn container fragments).\n\nWe first need to enable stencil testing:\n\nAnd then in each frame we want to specify the action to take whenever any of the stencil tests succeed or fail:\n\nIf any of the tests fail we do nothing; we simply keep the currently stored value that is in the stencil buffer. If both the stencil test and the depth test succeed however, we want to replace the stored stencil value with the reference value set via which we later set to .\n\nWe clear the stencil buffer to s at the start of the frame and for the containers we update the stencil buffer to for each fragment drawn:\n\nBy using as the stencil op function we make sure that each of the containers' fragments update the stencil buffer with a stencil value of . Because the fragments always pass the stencil test, the stencil buffer is updated with the reference value wherever we've drawn them.\n\nNow that the stencil buffer is updated with s where the containers were drawn we're going to draw the upscaled containers, but this time with the appropriate test function and disabling writes to the stencil buffer:\n\nWe set the stencil function to to make sure that we're only drawing parts of the containers that are not equal to . This way we only draw the part of the containers that are outside the previously drawn containers. Note that we also disable depth testing so the scaled up containers (e.g. the borders) do not get overwritten by the floor. Make sure to enable the depth buffer again once you're done.\n\nThe total object outlining routine for our scene looks something like this:\n\nAs long as you understand the general idea behind stencil testing this shouldn't be too hard to understand. Otherwise try to carefully read the previous sections again and try to completely understand what each of the functions does now that you've seen an example of it can be used.\n\nThe result of the outlining algorithm then looks like this:\n\nCheck the source code here to see the complete code of the object outlining algorithm.\n\nThe object outlining algorithm you've seen is commonly used in games to visualize selected objects (think of strategy games) and an algorithm like this can easily be implemented within a model class. You could set a boolean flag within the model class to draw either with borders or without. If you want to be creative you could even give the borders a more natural look with the help of post-processing filters like Gaussian Blur.\n\nStencil testing has many more purposes (beside outlining objects) like drawing textures inside a rear-view mirror so it neatly fits into the mirror shape, or rendering real-time shadows with a stencil buffer technique called . Stencil buffers give us with yet another nice tool in our already extensive OpenGL toolkit."
    },
    {
        "link": "https://open.gl/depthstencils",
        "document": "Up until now there is only one type of output buffer you've made use of, the color buffer. This chapter will discuss two additional types, the depth buffer and the stencil buffer. For each of these a problem will be presented and subsequently solved with that specific buffer.\n\nTo best demonstrate the use of these buffers, let's draw a cube instead of a flat shape. The vertex shader needs to be modified to accept a third coordinate:\n\nWe're also going to need to alter the color again later in this chapter, so make sure the fragment shader multiplies the texture color by the color attribute:\n\nVertices are now 8 floats in size, so you'll have to update the vertex attribute offsets and strides as well. Finally, add the extra coordinate to the vertex array:\n\nConfirm that you've made all the required changes by running your program and checking if it still draws a flat spinning image of a kitten blended with a puppy. A single cube consists of 36 vertices (6 sides * 2 triangles * 3 vertices), so I will ease your life by providing the array here.\n\nWe will not make use of element buffers for drawing this cube, so you can use to draw it. If you were confused by this explanation, you can compare your program to this reference code.\n\nIt immediately becomes clear that the cube is not rendered as expected when seeing the output. The sides of the cube are being drawn, but they overlap each other in strange ways! The problem here is that when OpenGL draws your cube triangle-by-triangle, it will simply write over pixels even though something else may have been drawn there before. In this case OpenGL will happily draw triangles in the back over triangles at the front.\n\nLuckily OpenGL offers ways of telling it when to draw over a pixel and when not to. I'll go over the two most important ways of doing that, depth testing and stencilling, in this chapter.\n\nZ-buffering is a way of keeping track of the depth of every pixel on the screen. The depth is an increasing function of the distance between the screen plane and a fragment that has been drawn. That means that the fragments on the sides of the cube further away from the viewer have a higher depth value, whereas fragments closer have a lower depth value.\n\nIf this depth is stored along with the color when a fragment is written, fragments drawn later can compare their depth to the existing depth to determine if the new fragment is closer to the viewer than the old fragment. If that is the case, it should be drawn over and otherwise it can simply be discarded. This is known as depth testing.\n\nOpenGL offers a way to store these depth values in an extra buffer, called the depth buffer, and perform the required check for fragments automatically. The fragment shader will not run for fragments that are invisible, which can have a significant impact on performance. This functionality can be enabled by calling .\n\nIf you enable this functionality now and run your application, you'll notice that you get a black screen. That happens because the depth buffer is filled with 0 depth for each pixel by default. Since no fragments will ever be closer than that they are all discarded.\n\nThe depth buffer can be cleared along with the color buffer by extending the call:\n\nThe default clear value for the depth is , which is equal to the depth of your far clipping plane and thus the furthest depth that can be represented. All fragments will be closer than that, so they will no longer be discarded.\n\nWith the depth test capability enabled, the cube is now rendered correctly. Just like the color buffer, the depth buffer has a certain amount of bits of precision which can be specified by you. Less bits of precision reduce the extra memory use, but can introduce rendering errors in more complex scenes.\n\nThe stencil buffer is an optional extension of the depth buffer that gives you more control over the question of which fragments should be drawn and which shouldn't. Like the depth buffer, a value is stored for every pixel, but this time you get to control when and how this value changes and when a fragment should be drawn depending on this value. Note that if the depth test fails, the stencil test no longer determines whether a fragment is drawn or not, but these fragments can still affect values in the stencil buffer!\n\nTo get a bit more acquainted with the stencil buffer before using it, let's start by analyzing a simple example.\n\nIn this case the stencil buffer was first cleared with zeroes and then a rectangle of ones was drawn to it. The drawing operation of the cube uses the values from the stencil buffer to only draw fragments with a stencil value of 1.\n\nNow that you have an understanding of what the stencil buffer does, we'll look at the relevant OpenGL calls.\n\nStencil testing is enabled with a call to , just like depth testing. You don't have to add this call to your code just yet. I'll first go over the API details in the next two sections and then we'll make a cool demo.\n\nRegular drawing operations are used to determine which values in the stencil buffer are affected by any stencil operation. If you want to affect a rectangle of values like in the sample above, simply draw a 2D quad in that area. What happens to those values can be controlled by you using the , and functions.\n\nThe call is used to specify the conditions under which a fragment passes the stencil test. Its parameters are discussed below.\n• : The test function, can be , , , , , , , and .\n• : A value to compare the stencil value to using the test function.\n• : A bitwise AND operation is performed on the stencil value and reference value with this mask value before comparing them.\n\nIf you don't want stencils with a value lower than 2 to be affected, you would use:\n\nThe mask value is set to all ones (in case of an 8 bit stencil buffer), so it will not affect the test.\n\nThe call specifies what should happen to stencil values depending on the outcome of the stencil and depth tests. The parameters are:\n• : Action to take if the stencil test fails.\n• : Action to take if the stencil test is successful, but the depth test failed.\n• : Action to take if both the stencil test and depth tests pass.\n\nStencil values can be modified in the following ways:\n• : The current value is kept.\n• : The stencil value is set to 0.\n• : The stencil value is set to the reference value in the call.\n• : The stencil value is increased by 1 if it is lower than the maximum value.\n• : Same as , with the exception that the value is set to 0 if the maximum value is exceeded.\n• : The stencil value is decreased by 1 if it is higher than 0.\n• : Same as , with the exception that the value is set to the maximum value if the current value is 0 (the stencil buffer stores unsigned integers).\n• : A bitwise invert is applied to the value.\n\nFinally, can be used to control the bits that are written to the stencil buffer when an operation is run. The default value is all ones, which means that the outcome of any operation is unaffected.\n\nIf, like in the example, you want to set all stencil values in a rectangular area to 1, you would use the following calls:\n\nIn this case the rectangle shouldn't actually be drawn to the color buffer, since it is only used to determine which stencil values should be affected.\n\nThe function allows you to specify which data is written to the color buffer during a drawing operation. In this case you would want to disable all color channels (red, green, blue, alpha). Writing to the depth buffer needs to be disabled separately as well with , so that cube drawing operation won't be affected by leftover depth values of the rectangle. This is cleaner than simply clearing the depth buffer again later.\n\nWith the knowledge about setting values, using them for testing fragments in drawing operations becomes very simple. All you need to do now is re-enable color and depth writing if you had disabled those earlier and setting the test function to determine which fragments are drawn based on the values in the stencil buffer.\n\nIf you use this call to set the test function, the stencil test will only pass for pixels with a stencil value equal to 1. A fragment will only be drawn if it passes both the stencil and depth test, so setting the is not necessary. In the case of the example above only the stencil values in the rectangular area were set to 1, so only the cube fragments in that area will be drawn.\n\nOne small detail that is easy to overlook is that the cube draw call could still affect values in the stencil buffer. This problem can be solved by setting the stencil bit mask to all zeroes, which effectively disables stencil writing.\n\nLet's spice up the demo we have right now a bit by adding a floor with a reflection under the cube. I'll add the vertices for the floor to the same vertex buffer the cube is currently using to keep things simple:\n\nNow add the extra draw call to your main loop:\n\nTo create the reflection of the cube itself, it is sufficient to draw it again but inverted on the Z-axis:\n\nI've set the color of the floor vertices to black so that the floor does not display the texture image, so you'll want to change the clear color to white to be able to see it. I've also changed the camera parameters a bit to get a good view of the scene.\n\nTwo issues are noticeable in the rendered image:\n• The floor occludes the reflection because of depth testing.\n• The reflection is visible outside of the floor.\n\nThe first problem is easy to solve by temporarily disabling writing to the depth buffer when drawing the floor:\n\nTo fix the second problem, it is necessary to discard fragments that fall outside of the floor. Sounds like it's time to see what stencil testing is really worth!\n\nIt can be greatly beneficial at times like these to make a little list of the rendering stages of the scene to get a proper idea of what is going on.\n• Enable stencil testing and set test function and operations to write ones to all selected stencils.\n• Set stencil function to pass if stencil value equals 1.\n\nThe new drawing code looks like this:\n\nI've annotated the code above with comments, but the steps should be mostly clear from the stencil buffer section.\n\nNow just one final touch is required, to darken the reflected cube a little to make the floor look a little less like a perfect mirror. I've chosen to create a uniform for this called in the vertex shader:\n\nAnd in the drawing code for the reflected cube\n\nwhere is the return value of a call.\n\nAwesome! I hope that, especially in chapters like these, you get the idea that working with an API as low-level as OpenGL can be a lot of fun and pose interesting challenges! As usual, the final code is available here.\n\nThere are no real exercises for this chapter, but there are a lot more interesting effects you can create with the stencil buffer. I'll leave researching the implementation of other effects, such as stencil shadows and object outlining as an exercise to you."
    },
    {
        "link": "https://en.wikipedia.org/wiki/Stencil_buffer",
        "document": "A stencil buffer is an extra data buffer, in addition to the color buffer and Z-buffer, found on modern graphics hardware. The buffer is per pixel and works on integer values, usually with a depth of one byte per pixel. The Z-buffer and stencil buffer often share the same area in the RAM of the graphics hardware.\n\nIn the simplest case, the stencil buffer is used to limit the area of rendering (stenciling). More advanced usage of the stencil buffer makes use of the strong connection between the Z-buffer and the stencil buffer in the rendering pipeline. For example, stencil values can be automatically increased/decreased for every pixel that fails or passes the depth test.\n\nThe simple combination of depth test and stencil modifiers make a vast number of effects possible (such as stencil shadow volumes, Two-Sided Stencil,[1] compositing, decaling, dissolves, fades, swipes, silhouettes, outline drawing, or highlighting of intersections between complex primitives) though they often require several rendering passes and, therefore, can put a heavy load on the graphics hardware.\n\nThe most typical application is still to add shadows to 3D applications. It is also used for planar reflections.\n\nOther rendering techniques, such as portal rendering, use the stencil buffer in other ways; for example, it can be used to find the area of the screen obscured by a portal and re-render those pixels correctly.\n\nThe stencil buffer and its modifiers can be accessed in computer graphics by using APIs like OpenGL, Direct3D, Vulkan or Metal.\n\nThe stencil buffer typically shares the same memory space as the Z-buffer, and typically the ratio is 24 bits for Z-buffer + 8 bits for stencil buffer or, in the past, 15 bits for Z-buffer + 1 bit for stencil buffer. Another variant is 4 + 24, where 28 of the 32 bits are used and 4 ignored. Stencil and Z-buffers are part of the frame buffer, coupled to the color buffer. The first chip available to a wider market was 3Dlabs' Permedia II, which supported a one-bit stencil buffer.\n\nThe bits allocated to the stencil buffer can be used to represent numerical values in the range [0, 2n-1], and also as a Boolean matrix (n is the number of allocated bits), each of which may be used to control the particular part of the scene. Any combination of these two ways of using the available memory is also possible.\n\nStencil test or stenciling is among the operations on the pixels/fragments (Per-pixel operations), located after the alpha test, and before the depth test. The stencil test ensures undesired pixels do not reach the depth test. This saves processing time for the scene. Similarly, the alpha test can prevent corresponding pixels to reach the stencil test.\n\nThe test itself is carried out over the stencil buffer to some value in it, or altered or used it, and carried out through the so-called stencil function and stencil operations. The stencil function is a function by which the stencil value of a certain pixel is compared to a given reference value. If this comparison is logically true, the stencil test passes. Otherwise not.\n\nIn doing so, the possible reaction caused by the result of comparing three different state-depth and stencil buffer:\n• Stencil test is passed but not the depth test\n• Both tests are passed (or stencil test is passed, and the depth is not enabled)\n\nFor each of these cases can be set different operations over the examined pixel. In the OpenGL stencil functions, the reference value and mask, respectively, define the function glStencilFunc. In Direct3D each of these components is adjusted individually using methods SetRenderState devices currently in control. This method expects two parameters, the first of which is a condition that is set and the other its value. In the order that was used above, these conditions are called D3DRS_STENCILFUNC, D3DRS_STENCILREF, and D3DRS_STENCILMASK.\n\nStencil operations in OpenGL adjust glStencilOp function that expects three values. In Direct3D, again, each state sets a specific method SetRenderState. The three states that can be assigned to surgery are called D3DRS_STENCILFAIL, D3DRENDERSTATE_STENCILZFAIL, and D3DRENDERSTATE_STENCILPASS.\n\nDue to the lack of precision in the Z-buffer, coplanar polygons that are short-range, or overlapping, can be portrayed as a single plane with a multitude of irregular cross-sections. These sections can vary depending on the camera position and other parameters and are rapidly changing. This is called Z-fighting. There exist multiple solutions to this issue:\n\n- Bring the far plane closer to restrict the scene's depth, thus increasing the accuracy of the Z-buffer, or reducing the distance at which objects are visible in the scene.\n\n- Increase the number of bits allocated to the Z-buffer, which is possible at the expense of memory for the stencil buffer.\n\n- Move polygons farther apart from one another, which restricts the possibilities for the artist to create an elaborate scene.\n\nAll of these approaches to the problem can only reduce the likelihood that the polygons will experience Z-fighting, and do not guarantee a definitive solution in the general case.\n\nA solution that includes the stencil buffer is based on the knowledge of which polygon should be in front of the others. The silhouette of the front polygon is drawn into the stencil buffer. After that, the rest of the scene can be rendered only where the silhouette is negative, and so will not clash with the front polygon.\n\nShadow volume is a technique used in 3D computer graphics to add shadows to a rendered scene. They were first proposed by Frank Crow in 1977[2] as the geometry describing the 3D shape of the region occluded from a light source. A shadow volume divides the virtual world in two: areas that are in shadow and areas that are not.\n\nThe stencil buffer implementation of shadow volumes is generally considered among the most practical general-purpose real-time shadowing techniques for use on modern 3D graphics hardware. It has been popularised by the video game Doom 3, and a particular variation of the technique used in this game has become known as Carmack's Reverse.\n\nReflection of a scene is drawn as the scene itself transformed and reflected relative to the \"mirror\" plane, which requires multiple render passes and using of stencil buffer to restrict areas where the current render pass works:\n• Draw the scene excluding mirror areas – for each mirror lock the Z-buffer and color buffer\n• Depth test is set up so that each pixel is passed to enter the maximum value and always passes\n• for each mirror:\n• Depth test is set so that it passes only if the distance of a pixel is less than the current (default behavior)\n• The matrix transformation is changed to reflect the scene relative to the mirror plane\n• Draw the scene, but only the part of it that lies between the mirror plane and the camera. In other words, a mirror plane is also a clipping plane\n• Again locks color buffer, depth test is set so that it always passes, reset stencil for the next mirror.\n\nWhile drawing a plane of shadows, there are two dominant problems: The first concerns the problem of deep struggle in case the flat geometry is not awarded on the part covered with the shadow of shadows and outside. See the section that relates to this. Another problem relates to the extent of the shadows outside the area where the plane there.\n\nAnother problem, which may or may not appear, depending on the technique, the design of more polygons in one part of the shadow, resulting in darker and lighter parts of the same shade. All three problems can be solved geometrically, but because of the possibility that hardware acceleration is directly used, it is a far more elegant implementation using the stencil buffer: 1. Enable lights and the lights 2. Draw a scene without any polygon that should be projected shadows 3. Draw all polygons which should be projected shadows, but without lights. In doing so, the stencil buffer, the pixel of each polygon to be assigned to a specific value for the ground to which they belong. The distance between these values should be at least two, because for each plane to be used two values for two states: in the shadows and bright. 4. Disable any global illumination (to ensure that the next steps will affect only individual selected light) For each plane: For each light: 1. Edit a stencil buffer and only the pixels that carry a specific value for the selected level. Increase the value of all the pixels that are projected objects between the date of a given level and bright. 2. Allow only selected light for him to draw level at which part of her specific value was not changed.\n\nStencil buffer implementation of spatial drawing shadows is any shadow of a geometric body that its volume includes part of the scene that is in it. If any part of the scene belongs to this volume, light is not illuminated given, otherwise it is. This problem is compounded by the increase in the number of lights but does not address the number of areas on which the shadows fall. There are several solutions to the problem, but we followed the following algorithm: 1. Draw a scene without light 2. Lock the Z-buffer and color buffer, so that the two can not make changes For each light 1. Using in-depth information about the scene (Z-buffer) to fill the stencil buffer only on parts of the scene where volume shadow does not exist or are not visible from the existing buildings. 2. Unlock buffer for color, and adjust the function of the Z-buffer to allow amendments only where the depth value equal to an existing 3. Draw the scene illuminated only by this light, but only for part of the scene passing the stencil test\n\nEach of these passages implies that a clean stencil buffer can be used.\n\nAs for the shadows, this technique can be used to illuminate parts of space that are under strong light. For example, the brightness of the spotlight in a dark room with a large presence of dust in the air could be seen illuminating the appropriate volume of space.\n\nA further example is the so-called soft shadow, in which the transition between the illuminated and shadowed part of the scene is out of focus. Specifically, one way to achieve this effect stencil buffer is to multiply the volume of the shadow, and that as the copies, respectively are scaled according to a geometric series with a low magnification, e.g.,. 1.04. The Center of scaling can be the center of gravity of the polygon that represents the top volume. This in itself will give a series of composite shadows that give the desired effect.\n\nAnother implementation includes the field of visualization during the modeling technique solids Constructive Solid Geometry (CSG), wherein stencil buffer, together with the Z-buffer, can successfully solve the problems of the Boolean operations of the SOLiD .\n\nDepending on the three possible conditions of the stencil function/depth function.\n\nTypically Stencil buffer is initialized by setting Z-buffer and color buffer masks to false. and then setting appropriate ref value to stencil buffer by failing the stencil test every time.\n\nNow use the initialized stencil buffer and stencil test to write only in the locations where the stencil value is 1:"
    },
    {
        "link": "https://khronos.org/opengl/wiki/Stencil_Test",
        "document": "The Stencil Test is a per-sample operation performed after the Fragment Shader. The fragment's stencil value is tested against the value in the current stencil buffer; if the test fails, the fragment is culled.\n\nIn order to use the stencil test, the current Framebuffer must have a stencil buffer. The stencil buffer is an image that uses a stencil image format. The Default Framebuffer may have a stencil buffer, and user-defined framebuffers can attach stencil formatted images (either depth/stencil or stencil-only) to the GL_STENCIL_ATTACHMENT attachment point.\n\nIf the current framebuffer has no stencil buffer, then the stencil test will always behave as if it is disabled.\n\nIf there is a stencil buffer, that buffer has a certain bitdepth. This specifies the number of stencil bits available.\n\nEach Fragment has a stencil value, which is an unsigned integer. The stencil test operation will test this stencil value against the value from the current framebuffer at the fragment's position.\n\nThis value is usually defined by the same function that sets the stencil test, below. This means that every fragment from every primitive for every object in a draw call gets the same fragment stencil value (with the front/backface point noted below).\n\nTo enable stencil testing, call glEnable with GL_STENCIL_TEST. When the stencil test is disabled, no testing happens and the stencil value in the framebuffer is not modified.\n\nWhen rendering to a framebuffer that has no a stencil buffer, stenciling will always behave as if it is disabled.\n\nStenciling operations take into account the fact that triangles have two sides. Therefore, all stencil tests and operation functions have two sets of data: one for the front side of triangles and one for the back. Which side is used depends on whether the fragments generated from the primitive came from the front or back face.\n\nThese functions all take a face​ parameter, which specifies which facing state is set by that function. The face​ can be GL_FRONT or GL_BACK, but it can also set both sides at once with GL_FRONT_AND_BACK.\n\nFor Primitives that have no facing, the front side stencil state are always used.\n\nThe stencil test itself is set by this function:\n\nThe ref​ defines the fragment's stencil value for all fragments generated for the given facing. The fragment stencil value will be clamped to the range defined by the stencil buffer's bitdepth.\n\nThe first step of the stencil test is to get the destination stencil value from the stencil buffer (called Ds). This is an unsigned integer value. The fragment's stencil value will be called Fs.\n\nThe next step is to perform a bitwise AND with both Fs and Ds, against the mask​ parameter for both. This allows the user to mask off certain stencil bits, reserving them for different conditional tests. This results in two masked unsigned integers, Fm and Dm.\n\nThen the stencil test itself is performed between Fm and Dm, based on the func​ parameter. The test is of the form (Fm FUNC Dm); the masked fragment value is on the left-hand side. The available functions are:\n\nglStencilFunc can be used to set both face operations in one call, if you don't like to use GL_FRONT_AND_BACK.\n\nThe stencil operation uses the result of the stencil test to decide how to modify the stencil value in the framebuffer. If stencil testing is disabled, then this step is skipped and framebuffer's stencil value is unmodified.\n\nIf the stencil test fails, the fragment is discarded. Normally, discarding a fragment means that it has no visible effects. However, the stencil buffer can be updated even from discarded fragments, if the depth or stencil tests discard them.\n\nThere are three possible cases involved here:\n• The stencil test fails. The fragment will be discarded. Remember that the stencil test happens before the depth test, so the result of that is never computed if the stencil test fails.\n• The stencil test passes, but the Depth Test fails. The fragment will be discarded (due to the depth failure). This case only applies if the depth test is enabled.\n• The stencil test passes, and the Depth Test passes. If the depth test is disabled, then it is always assumed to pass.\n\nTo define how the stencil value in the framebuffer is modified in each case, use the following function:\n\nThe parameters sfail​, dpfail​, and dppass​ define the stencil update operations to perform in the three cases above, respectively. Each case can use any of the following operations (\"current value\" here means the value already in the stencil buffer):\n\n1: Meaning that it stops at the maximum representable integer at the stencil buffer's bitdepth. For an 8-bit stencil buffer, that would be 255.\n\nglStencilOp can be used to set both face operations in one call, if you don't like to use GL_FRONT_AND_BACK."
    },
    {
        "link": "https://webgl.brown37.net/12_advanced_rendering/09_stencils.html",
        "document": "A WebGL draw buffer is composed of three buffers: 1) a color buffer, 2) a depth buffer, and 3) an optional stencil buffer. This lesson describes how stencil buffers can be manipulated by the graphics pipeline and demonstrates their use in two example WebGL programs.\n\nThis lesson is longer than most. Sorry! Understanding stencil buffers will take some time and require attention to detail. Therefore, please take your time and study carefully.\n\nA stencil buffer provides fine-grain control over which pixels are processed by the graphics pipeline after they have been processed by a fragment shader. Stencil buffer functionality is hard-coded into the graphics pipeline and is controlled by a programmer through stencil buffer parameters. Understanding the parameter settings is non-trivial, so they will be explained in the simplest possible terms and then details will be added to provide the “total picture.” There are two fundamental ideas:\n• Using a “stencil test” to determine if a fragment should be allowed to modify the color buffer. Before discussing these two issues, let’s discuss the structure and nature of a stencil buffer.\n\nA stencil buffer must be created when a WebGL context is created for a canvas. It is a 2D array of unsigned bytes that must have the same dimensions as the draw buffer’s color buffer and depth buffer. Here is an example of creating a that contains a stencil buffer: A or value can be represented using a single bit. Typically means and means . Since a stencil buffer stores an unsigned byte for each pixel, it can potentially represent eight different “stencils” at any given time. WebGL allows a programmer to specify a “mask” that determines which bits are tested when a stencil test is performed. When a value from a stencil buffer is retrieved, a bit-wise operation is always performed with a “mask” before it is used. A “mask” is typically specified in hexadecimal notation by starting the value with . The following table shows the eight masks that can be used to differentiate the eight bits in an unsigned byte: If each stencil buffer value is treated as a single value, the “mask” can be set to (all ones). Other division of the bits are possible. For example, two stencils could be created, where the high order four bits (using a mask of ) represent one stencil and the low order fours bits (using a mask of ) represents the other stencil. You can conceptualize the stencil buffer as a single “mask”, as eight separate “masks”, or any number in-between.\n\nWhen the stencil test is enabled, pixels are allowed to modify the color buffer and the depth buffer only if they pass a “stencil test.” The following pseudocode describes the internal logic of the graphics pipeline and demonstrates that the stencil test happens before the depth test (assuming that the “depth test” has been enabled by ). The “stencil test” is a comparison between a “reference value” and the current value stored in the stencil buffer at a pixel’s location. A programmer does not implement this logic, but rather specifies the type of comparison, the reference value, and a mask using a call to . The following pseudocode demonstrates the functionality. // DEFAULT - all bits are ones For example, would configure the stencil test to be true for a pixel at , if the value at has its low order 2nd bit set to 1. Note that performing a bit-wise AND operation using a mask of will produce either a value of or . For another example, would configure the stencil test to be true for a pixel at , if the value at has any of its four high order bits set to one. Note that performing a bit-wise AND operation using a mask of will produce one of the following 16 values: 0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240. As the above pseudocode indicates, the stencil test can be configured to perform one of eight possible comparisons. In addition, it makes sure that only certain bits are used in the comparison. By default, WebGL considers a triangle whose vertices are ordered counter-clockwise as “front-facing” and triangles whose vertices are ordered clockwise as “back-facing”. The graphics pipeline always passes a boolean input variable called to a fragment shader. If is , the pipeline should render the “front” side of a triangle, otherwise the “back” side. (The value can be used or ignored by a fragment shader.) Note that OpenGL ES 2.0 allows stencil testing to be performed differently for front and back facing triangles, but WebGL does not. Therefore calls to should not be used in WebGL.\n\nEach pixel in a stencil buffer is assigned a value by clearing the buffer with a specific value and then rendering a scene. As with the “stencil test,” the work of defining a stencil is hard-coded into the graphics pipeline. The programmer’s responsibilities is to assign appropriate parameters to the stencil operation parameters before a rendering is performed. Please study the following pseudocode which describes the internal workings of the graphics pipeline and shows when a stencil operation is performed and the data it uses. Please notice the following:\n• To simplify the pseudocode, tests to determine if the is enabled have been left out. However, stencil operations are only performed when the has been enabled.\n• The stencil buffer is updated once by each invocation of a fragment shader. Stencil operation parameters define a separate operation for fragments that failed the “stencil test,” or that passed the “stencil test” but either passed or failed the “depth test.”\n• Updating the stencil buffer is performed after the stencil test and the depth test have been completed. This takes some contemplation! A stencil buffer’s value is used, and then updated to possibly a different value! In typical usage this rarely happens. The “stencil test” parameters and the “stencil operation” parameters are typically configured to perform one or the other, but not both at the same time. Updating the stencil buffer is described by the following pseudocode. Please study the pseudocode carefully. (Note that the operation uses the value set by . In addition, the limits the bits that can be modified in the stencil buffer’s value. Stencil operations that change the values in a stencil buffer are more complex than described above because they can be set to process front-facing and back-facing triangles differently using the function . Passing for the parameter sets the stencil operations for front-facing triangles, while passing sets the stencil operations for back-facing triangles. The following pseudocode describes the full range of stencil operations. The variables prefixed with are for processing back-facing triangles. The OpenGL ES 2.0 and WebGL 1.0 specifications do not specify whether the , , , and functionality is based on a and of an 8-bit unsigned integer, or limited by the minimum and maximum values based on the .\n\nWhen using a stencil buffer, a rendering is typically performed by a series of “rendering passes.” The first rendering pass creates a desired stencil buffer while follow-on renderings use the stencil buffer to control which pixels in a color buffer are modified. WebGL provides fine-grain control of the draw buffers to allow a scene to be “rendered” but only change specific buffers. The function determines whether individual components of a color buffer can be updated. The function determines whether the depth buffer can be modified. And the function determines which bits in a stencil buffer value can be modified. Our final pseudocode to describe the internal logic of the graphics pipeline demonstrates this fine-grain control. When a stencil buffer value is modified, which bits are changed is controlled by the . Pseudocode that simulates this might look like:\n\nThe following two WebGL programs provide examples of tasks that use a stencil buffer. The stencil buffer can be used to mark the pixels that surround a model and then color those pixels to indicate that the model has been selected by a user (or “marked” for some other reason). The basic steps to render a border around a model are:\n• Enable the stencil buffer, disable changes to the color buffer, render the model scaled to a slightly larger size, and “mark” each pixel that is rendered in the stencil buffer.\n• Render the model at its normal size and “un-mark” each pixel that is rendered. (This leaves only the pixels surrounding the model as “marked.”)\n• Render the model at its larger size and simply color each pixel that is “marked” in the stencil buffer. Experiment with the following WebGL program and study the function in the code file. /** * stencil_outline_render.js, By Wayne Brown, Spring 2018 */ /** * The MIT License (MIT) * * Copyright (c) 2015 C. Wayne Brown * * Permission is hereby granted, free of charge, to any person obtaining a copy * of this software and associated documentation files (the \"Software\"), to deal * in the Software without restriction, including without limitation the rights * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell * copies of the Software, and to permit persons to whom the Software is * furnished to do so, subject to the following conditions: * * The above copyright notice and this permission notice shall be included in all * copies or substantial portions of the Software. * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE * SOFTWARE. */ \"use strict\"; /** ----------------------------------------------------------------------- * Create a WebGL 3D scene, store its state, and render its models. * * @param id The id of the webglinteractive directive * @param download An instance of the SceneDownload class * @param vshaders_dictionary A dictionary of vertex shaders. * @param fshaders_dictionary A dictionary of fragment shaders. * @param models A dictionary of models. * @constructor */ window.StencilOutlineScene = function (id, download, vshaders_dictionary, fshaders_dictionary, models) { // Private variables let self = this; let out = download.out; let gl = null; let select_program = null; let visible_program = null; let cube = null; let select_cube = null; let gpuModel; let number_cubes = 30; let all_cubes = new Array(number_cubes); let matrix = new GlMatrix4x4(); let transform = matrix.create(); let camera_model_transform = matrix.create(); let projection = matrix.createPerspective(45.0, 1.0, 0.1, 100.0); let camera = matrix.create(); let scale_matrix = matrix.create(); let translate_matrix = matrix.create(); let rotate_x_matrix = matrix.create(); let rotate_y_matrix = matrix.create(); // Public variables that will possibly be used or changed by event handlers. self.canvas = null; self.angle_x = 0.0; self.angle_y = 0.0; self.animate_active = true; self.border_size = 0.2; // Light model let P4 = new GlPoint4(); let V = new GlVector3(); self.light_position = P4.create(10, 10, 10, 1); self.light_color = V.create(1, 1, 1); // white light self.shininess = 30; self.ambient_color = V.create(0.2, 0.2, 0.2); // low level white light let convert = null; let pixel = new window.Uint8Array(4); // A single RGBA value let selected_object_id = -1; let red = [1.0, 0.0, 0.0, 1.0]; //----------------------------------------------------------------------- function _renderSelected() { let size, position, size_plus; size = all_cubes[selected_object_id].size; position = all_cubes[selected_object_id].position; // Render the model at a slightly larger size and set the stencil buffer. gl.enable(gl.STENCIL_TEST); gl.colorMask(false, false, false, false); gl.depthMask(false); gl.stencilFunc(gl.ALWAYS, 1, 0xFF); gl.stencilOp(gl.KEEP, gl.KEEP, gl.REPLACE); gl.stencilMask(0xFF); size_plus = size + self.border_size; matrix.scale(scale_matrix, size_plus, size_plus, size_plus); matrix.translate(translate_matrix, position[0], position[1], position[2]); matrix.multiplySeries(transform, projection, camera, rotate_x_matrix, rotate_y_matrix, translate_matrix, scale_matrix); select_cube.render(transform, red); // Render the cube at regular size to un-select the interior of the model // in the stencil buffer. gl.stencilFunc(gl.EQUAL, 1, 0xFF); gl.stencilOp(gl.KEEP, gl.DECR, gl.DECR); matrix.scale(scale_matrix, size, size, size); matrix.translate(translate_matrix, position[0], position[1], position[2]); matrix.multiplySeries(transform, projection, camera, rotate_x_matrix, rotate_y_matrix, translate_matrix, scale_matrix); select_cube.render(transform, red); // Render the model at its larger size, but only color the pixels that are // still selected in the stencil buffer. gl.colorMask(true, true, true, true); gl.stencilFunc(gl.EQUAL, 1, 0xFF); gl.stencilMask(0x00); matrix.scale(scale_matrix, size_plus, size_plus, size_plus); matrix.translate(translate_matrix, position[0], position[1], position[2]); matrix.multiplySeries(transform, projection, camera, rotate_x_matrix, rotate_y_matrix, translate_matrix, scale_matrix); select_cube.render(transform, red); // Restore the graphics pipeline state for normal rendering. gl.disable(gl.STENCIL_TEST); gl.depthMask(true); } //----------------------------------------------------------------------- self.render = function (select_mode = false) { let size, position, color; // Clear the entire canvas window background with the clear color gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT | gl.STENCIL_BUFFER_BIT); // Rotate the models about the origin matrix.rotate(rotate_x_matrix, self.angle_x, 1.0, 0.0, 0.0); matrix.rotate(rotate_y_matrix, self.angle_y, 0.0, 1.0, 0.0); if (! select_mode) { // - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - // Set the location of the light source gl.useProgram(visible_program); gl.uniform3f(visible_program.u_Light_position, self.light_position[0], self.light_position[1], self.light_position[2]); gl.uniform3fv(visible_program.u_Light_color, self.light_color); gl.uniform3fv(visible_program.u_Ambient_color, self.ambient_color); gl.uniform1f(visible_program.u_Shininess, self.shininess); } // Draw a set of spheres with different locations, sizes, and colors. for (let j = 0; j < number_cubes; j += 1) { size = all_cubes[j].size; position = all_cubes[j].position; color = all_cubes[j].color; matrix.scale(scale_matrix, size, size, size); matrix.translate(translate_matrix, position[0], position[1], position[2]); // Combine the transforms into a single transformation matrix.multiplySeries(camera_model_transform, camera, rotate_x_matrix, rotate_y_matrix, translate_matrix, scale_matrix); matrix.multiplySeries(transform, projection, camera_model_transform); if (select_mode) { // Render a single cube using its array index converted into a color. select_cube.render(transform, convert.createColor(j)); } else { // Render a single cube. cube.render(transform, camera_model_transform, color); } } if (selected_object_id >= 0 && selected_object_id < number_cubes) { _renderSelected(); } }; //----------------------------------------------------------------------- /** * Given the location of a mouse click, get the object that is rendered * at that location. * @param mouse_x Number The x-component of the mouse's location. * @param mouse_y Number The y-component of the mouse's location. */ self.select = function (mouse_x, mouse_y) { // Render the scene to put each object's ID number into the color buffer. self.render(true); // Convert the canvas coordinate system into an image coordinate system. mouse_y = self.canvas.clientHeight - mouse_y; // Get the color value from the rendered color buffer. gl.readPixels(mouse_x, mouse_y, 1, 1, gl.RGBA, gl.UNSIGNED_BYTE, pixel); // Convert the RGBA color array into a single integer selected_object_id = convert.getID(pixel[0], pixel[1], pixel[2], pixel[3]); // Now render the scene for the user's view. self.render(false); }; //----------------------------------------------------------------------- self.delete = function () { // Clean up shader programs gl.deleteShader(select_program.vShader); gl.deleteShader(select_program.fShader); gl.deleteProgram(select_program); gl.deleteShader(visible_program.vShader); gl.deleteShader(visible_program.fShader); gl.deleteProgram(visible_program); // Delete each model's VOB cube.delete(gl); select_cube.delete(gl); events.removeAllEventHandlers(); // Disable any animation self.animate_active = false; }; //----------------------------------------------------------------------- // Object constructor. One-time initialization of the scene. // Get the rendering context for the canvas self.canvas = download.getCanvas(id + \"_canvas\"); if (self.canvas) { gl = download.getWebglContext(self.canvas, {\"stencil\" : true}); } if (!gl) { return; } // Make the cursor be a pointer in the canvas window. $(self.canvas).css(\"cursor\", \"pointer\"); $('#' + id + '_animate').prop('checked', self.animate_active); $('#' + id + '_border_size').val(self.border_size); // Set up the rendering programs select_program = download.createProgram(gl, vshaders_dictionary[\"uniform_color\"], fshaders_dictionary[\"uniform_color\"]); visible_program = download.createProgram(gl, vshaders_dictionary[\"uniform_color_with_lighting\"], fshaders_dictionary[\"uniform_color_with_lighting\"]); gl.enable(gl.DEPTH_TEST); gl.clearColor(0.98, 0.98, 0.98, 1.0); matrix.lookAt(camera, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0); // Create Vertex Object Buffers for the models gpuModel = new ModelArraysGPU(gl, models[\"cube2\"], out); select_cube = new RenderUniformColor(gl, select_program, gpuModel, download.out); cube = new RenderUniformColorWithLighting(gl, visible_program, gpuModel, download.out); // Create a set of random positions, colors, and sizes for a group of cubes. let position_x, position_y, position_z; for (let j = 0; j < number_cubes; j += 1) { position_x = Math.random() * 10 - 5.0; position_y = Math.random() * 10 - 5.0; position_z = Math.random() * 10 - 5.0; all_cubes[j] = { position: [position_x, position_y, position_z], size: Math.random() + 0.2, color: new Float32Array([0.0, Math.random(), Math.random(), 1.0]) }; } // Set up callbacks for user and timer events let events; events = new StencilOutlineEvents(id, self); events.animate(); // Create an object to convert between integer identifiers and colors. convert = new ColorToID(gl); }; Experiment with \"Model Outlining\" using the Stencil Buffer.\n• Right-click to select an object. The currently selected object is outlined in red. Please use a browser that supports \"canvas\" \n\n Animate \n\n Open this webgl program in a new tab or window Note that the size of the border is in “world units”. Given a different scene with models of different sizes, the border size would need to be adjusted accordingly. The following is a detailed description of the program and specifically the function. The details are non-trivial and require studying. A stencil buffer is created when the is created for the canvas. Clear all three draw buffers, including the stencil buffer. If a model has been selected by the user using a mouse right-click, the function is called to render a border around the model. disables changes to the color buffer so that the renderings that create the stencil do not change the visible image. disables changes to the depth buffer. Why? A larger model will be rendered to mark pixels in the stencil buffer and then the original sized model will be rendered to “unmark” the pixels in the interior of the masked region. The larger model will have pixels closer to the camera and depth testing will prevent the original model from being rendered. In addition, changing the depth buffer so that other models can be rendered correctly is not needed because the entire scene has already been rendered. makes the “stencil test” always true, ( ), because this rendering pass is creating the stencil mask. The parameter is the “reference value” to set pixels in the stencil buffer. The mask allows all bits in the stencil buffer values to be changed. sets a stencil buffer pixel every time the “depth test” is true. The pixels are set to because of the “reference value” parameter in the previous function call. For every pixel that is colored by the rendering, its associated stencil buffer value will be set to . allows the stencil buffer values to be changed. This is important because the first rendering pass is creating the mask in the stencil buffer. Render the model at a slightly larger scale than its original size. In preparation for the 2nd model rendering, makes the “stencil test” pass if the pixel’s stencil value is equal to . This makes sure that all pixels from the previous rendering are processed. In preparation for the 2nd model rendering, decrements a stencil buffer’s value whether the “depth test” passes or fails. This guarantees that all interior pixels are returned back to zero in the stencil buffer Render the model again, but this time at its normal scale. In preparation for the 3rd rendering pass, enables modifications to the color buffer to allow the border to be rendered. The stencil test is set to only process pixels if their associated stencil buffer value is equal to . ( ) This rendering pass should not modify the stencil buffer. Therefore clear the stencil mask, . On the 3rd and final rendering pass, render the model at its larger size and color every pixel that has a stencil buffer value of 1. Now that you partially understand the program, experiment with it to verify your understanding. The following WebGL program simulates the reflection of a model in a flat plane. This is accomplished by rendering a “mirror” of the model and restricting the drawing to only those pixels that compose the flat plane. Restricting the drawing to the flat plane, which can take on various shapes based on the scene’s camera location, is done using the stencil buffer. The basic steps are:\n• Render a flat plane with the stencil test enabled. This remembers which pixels the flat plane covers.\n• Render the model mirrored about the flat plane, but with the stencil test enabled. This prevents the mirrored version from being rendered outside the plane’s pixels. Please experiment with the following WebGL program. /** * stencil_reflect_scene.js, By Wayne Brown, Spring 2018 */ /** * The MIT License (MIT) * * Copyright (c) 2015 C. Wayne Brown * * Permission is hereby granted, free of charge, to any person obtaining a copy * of this software and associated documentation files (the \"Software\"), to deal * in the Software without restriction, including without limitation the rights * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell * copies of the Software, and to permit persons to whom the Software is * furnished to do so, subject to the following conditions: * * The above copyright notice and this permission notice shall be included in all * copies or substantial portions of the Software. * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE * SOFTWARE. */ \"use strict\"; /** ----------------------------------------------------------------------- * Create a WebGL 3D scene, store its state, and render its models. * * @param id {string} The id of the webglinteractive directive * @param download {SceneDownload} An instance of the SceneDownload class * @param vshaders_dictionary {object} A dictionary of vertex shaders. * @param fshaders_dictionary {object} A dictionary of fragment shaders. * @param models {object} A dictionary of models. * @constructor */ window.StencilReflectScene = function (id, download, vshaders_dictionary, fshaders_dictionary, models) { // Private variables let self = this; let canvas; let gl = null; let visible_program = null; let render_models; let model_gpu; let plane; let cube_model_names = [\"cubex\", \"textx\", \"cubey\", \"texty\", \"cubez\", \"textz\", \"cube_center\"]; let matrix = new GlMatrix4x4(); let to_clipping_space = matrix.create(); let camera_model_transform = matrix.create(); let projection; let camera = matrix.create(); let rotate_x_matrix = matrix.create(); let rotate_y_matrix = matrix.create(); let scale = matrix.create(); let translate = matrix.create(); // Public variables that will possibly be used or changed by event handlers. self.angle_x = 30.0; self.angle_y = -45.0; self.animate_active = true; // Light model let P3 = new GlPoint3(); let V = new GlVector3(); let light = { \"position\" : P3.create(10, 10, 10), \"color\" : V.create(1, 1, 1), // white light \"ambient\" : V.create(0.3, 0.3, 0.3) }; let model_shininess = 30; let reflection_light = { \"color\" : V.create(0.6, 0.6, 0.6), // darker white light \"ambient\" : V.create(0.05, 0.05, 0.05) }; //----------------------------------------------------------------------- function _render_cubes(to_clipping_space, to_camera_space) { for (let j = 0; j < render_models.length; j += 1) { render_models[j].render(to_clipping_space, to_camera_space); } } //----------------------------------------------------------------------- self.render = function () { // Clear the draw buffers. gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT | gl.STENCIL_BUFFER_BIT); // - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - // Step 1: Render the main model. gl.disable(gl.STENCIL_TEST); gl.depthMask(true); matrix.rotate(rotate_x_matrix, self.angle_x, 1.0, 0.0, 0.0); matrix.rotate(rotate_y_matrix, self.angle_y, 0.0, 1.0, 0.0); matrix.multiplySeries(camera_model_transform, camera, rotate_x_matrix, rotate_y_matrix); matrix.multiplySeries(to_clipping_space, projection, camera_model_transform); gl.uniform3fv(visible_program.u_Light_color, light.color); gl.uniform3fv(visible_program.u_Ambient_intensities, light.ambient); _render_cubes(to_clipping_space, camera_model_transform); // - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - // Step 2: Render the plane and set the stencil buffer to be 1 for every pixel. gl.enable(gl.STENCIL_TEST); gl.stencilFunc(gl.ALWAYS, // The STENCIL_TEST is always true. 1, // Set the stencil_buffer to 1 when it is updated. 0xFF); // All bits in the stencil_buffer are used for the STENCIL_TEST. gl.stencilOp(gl.KEEP, // If the STENCIL_TEST failed, keep the stencil_buffer's current value gl.KEEP, // If the DEPTH_TEST failed, keep the stencil_buffer's current value gl.REPLACE); // If the DEPTH_TEST passed, replace the stencil_buffer's current value gl.stencilMask(0xFF); // Allow all bits of the stencil_buffer to be modified gl.depthMask(false); // The depth-buffer can't be modified. (The DEPTH TEST is still performed.) plane.render(to_clipping_space, camera_model_transform); // Don't render the reflected model if the viewing angle is below the plane. if (self.angle_x >= 0.0) { // - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - // Step 3: Render the reflection of the model. gl.stencilFunc(gl.EQUAL, // The STENCIL_TEST passes only if the stencil_buffer is equal to the reference value. 1, // The reference value. 0xFF); // All bits in the stencil_buffer are used for the STENCIL_TEST. gl.stencilMask(0x00); // No bits in the stencil_buffer can be modified. gl.depthMask(true); // The depth-buffer is modified. gl.uniform3fv(visible_program.u_Light_color, reflection_light.color); gl.uniform3fv(visible_program.u_Ambient_intensities, reflection_light.ambient); matrix.scale(scale, 1.0, -1.0, 1.0); // Mirror about y axis. matrix.translate(translate, 0.0, -1.0, 0.0); // Translate to position below the plane. matrix.multiplySeries(camera_model_transform, camera, rotate_x_matrix, rotate_y_matrix, translate, scale); matrix.multiplySeries(to_clipping_space, projection, camera_model_transform); _render_cubes(to_clipping_space, camera_model_transform); } }; //----------------------------------------------------------------------- self.delete = function () { // Clean up shader programs gl.deleteShader(visible_program.vShader); gl.deleteShader(visible_program.fShader); gl.deleteProgram(visible_program); // Delete each model's VOB for (let j = 0; j < render_models.length; j += 1) { render_models[j].delete(gl); } plane.delete(gl); events.removeAllEventHandlers(); // Disable any animation self.animate_active = false; }; //----------------------------------------------------------------------- // Object constructor. One-time initialization of the scene. // Get the rendering context for the canvas canvas = download.getCanvas(id + \"_canvas\"); if (canvas) { gl = download.getWebglContext(canvas, {\"stencil\" : true}); } if (!gl) { return; } $('#' + id + '_animate').prop('checked', self.animate_active); // Set up the rendering programs visible_program = download.createProgram(gl, vshaders_dictionary[\"lighting\"], fshaders_dictionary[\"lighting\"]); gl.useProgram(visible_program); gl.enable(gl.DEPTH_TEST); gl.clearColor(0.98, 0.98, 0.98, 1.0); matrix.lookAt(camera, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0); projection = matrix.createPerspective(45.0, 1.0, 0.1, 100.0); // Create Vertex Object Buffers for the models render_models = new Array(cube_model_names.length); for (let j = 0; j < cube_model_names.length; j += 1) { model_gpu = new ModelArraysGPU(gl, models[cube_model_names[j]], download.out); render_models[j] = new RenderLighting(gl, visible_program, model_gpu, download.out); } model_gpu = new ModelArraysGPU(gl, models[\"plane\"], download.out); plane = new RenderLighting(gl, visible_program, model_gpu, download.out); // Set up callbacks for user and timer events let events; events = new StencilReflectEvents(id, self); events.animate(); // - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - // Set the location of the light source, which does not change. gl.useProgram(visible_program); gl.uniform3fv(visible_program.u_Light_position, light.position); gl.uniform1f(visible_program.u_Shininess, model_shininess); }; Example using the Stencil Buffer. Please use a browser that supports \"canvas\" \n\n Animate \n\n Open this webgl program in a new tab or window The following is a detailed, line-by-line description of the rendering function. The details are non-trivial and require studying. Clear all three draw buffers, including the stencil buffer. The stencil buffer is not needed to render the model, so disable it. Writing to the depth buffer is turned on and off during the rendering. Make sure the depth buffer can be modified so that hidden surface removal is performed properly. Render the plane and “mark” every pixel that it colors by setting its associated value in the stencil buffer. sets the “stencil test” parameters. makes the stencil test always true. This basically disables the “stencil test”. Why? Because this rendering pass does not want to use the stencil buffer to control which pixels are rendered. It wants to set the pixels of the stencil buffer. The parameter is the value that will be placed in the stencil buffer when it is changed. Control of changing the stencil buffer is done by the parameters to in line 117. The mask, , allows all bits of each stencil buffer pixel value to be modified. For this example the mask could have been set to because only the low order bit is actually used. sets the “stencil update” parameters. The first two parameters say “leave the stencil buffer alone when the “stencil test” fails or the “depth test” fails. The parameter says to “replace the stencil buffer value using the ‘reference value’” set in the call – when the “depth test” passed and the color buffer is modified. (The “reference value” is used for both the “stencil test” and the “stencil updating” functionality, but it is only specified in the call.) allows all bits of each stencil buffer value to be modified. Since this example only uses the lower order bit, would have worked as well. Why is this needed? When the is enabled, both “stencil testing” and “stencil updating” is enabled. But some rendering passes only want to set the stencil buffer, while other rendering passes only want to use the stencil buffer for a “stencil test.” When the stencil mask is set to , the rendering pass can set the stencil buffer values. When the stencil mask is set to , the rendering pass can’t set values in the stencil buffer and is therefore only “stencil testing.” disables modifications to the depth buffer – but the “depth test” still happens. Therefore, when the plane is rendered, it will only be rendered in pixels that are closer to the camera than the model that is already in the scene. This allows the plane to “wrap around” the model correctly using the “depth test”. But it prevents the depth buffer values from being updated so that at a later time the “mirrored” model can be rendered over the plane’s pixels. For this specfic example, the reflection of the model should only be visible when the top of the plane is visible. Therefore, the “mirrored” model is only rendered when the top of the flat plane is visible. The angle of viewing rotation is an easy test. The direction of the normal vector for the plane could have also been used, but that test would require more calculations. changes the “stencil test” to be: “Is the stencil buffer value equal to 1?”. This restricts rendering to only those pixels whose color was modified when the plane was rendered, since that is the rendering pass that set the values of the stencil buffer. disables modifications to the stencil buffer. The next rendering pass is going to use a “stencil test” but not modify the stencil buffer. enables modifications to the depth buffer. The next rendering pass needs hidden surface removal and this allows the “mirrored” model to be rendered correctly. When the “mirrored” model is rendered as a “reflection” the colors of the model should not be as bright as the original model. By lowering the lighting ambient intensities and by using a light color that has a lower intensity the reflected model appears darker. Modifying the light values could produce a wide range of “reflected” effects. You could experiment with this WebGL program in many ways. Comment out some of the settings, or change some of the settings and investigate what happens. For example, comment out the if-statement that tests for viewing above the plane in line 126. What happens?"
    }
]