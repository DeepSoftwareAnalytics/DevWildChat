[
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D",
        "document": "This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015 . * Some parts of this feature may have varying levels of support.\n\nThe interface, part of the Canvas API, provides the 2D rendering context for the drawing surface of a element. It is used for drawing shapes, text, images, and other objects. The interface's properties and methods are described in the reference section of this page. The Canvas tutorial has more explanation, examples, and resources, as well. For , there is an equivalent interface that provides the rendering context. The offscreen rendering context inherits most of the same properties and methods as the and is described in more detail in the reference page.\n\nTo get a instance, you must first have an HTML element to work with: To get the canvas' 2D rendering context, call on the element, supplying as the argument: With the context in hand, you can draw anything you like. This code draws a house: The resulting drawing looks like this:\n\nThe following methods can be used to manipulate paths of objects. Starts a new path by emptying the list of sub-paths. Call this method when you want to create a new path. Causes the point of the pen to move back to the start of the current sub-path. It tries to draw a straight line from the current point to the start. If the shape has already been closed or has only one point, this function does nothing. Moves the starting point of a new sub-path to the (x, y) coordinates. Connects the last point in the current sub-path to the specified (x, y) coordinates with a straight line. Adds an arc to the current path with the given control points and radius, connected to the previous point by a straight line. Adds an elliptical arc to the current path. Creates a path for a rectangle at position (x, y) with a size that is determined by width and height. Creates a path for a rounded rectangle with a specified position, width, height, and corner radii.\n\nObjects in the rendering context have a current transformation matrix and methods to manipulate it. The transformation matrix is applied when creating the current default path, painting text, shapes and objects. The methods listed below remain for historical and compatibility reasons as objects are used in most parts of the API nowadays and will be used in the future instead. Retrieves the current transformation matrix being applied to the context. Adds a rotation to the transformation matrix. The angle argument represents a clockwise rotation angle and is expressed in radians. Adds a scaling transformation to the canvas units by x horizontally and by y vertically. Adds a translation transformation by moving the canvas and its origin x horizontally and y vertically on the grid. Multiplies the current transformation matrix with the matrix described by its arguments. Resets the current transform to the identity matrix, and then invokes the method with the same arguments. Resets the current transform by the identity matrix.\n\nThe rendering context contains a variety of drawing style states (attributes for line styles, fill styles, shadow styles, text styles). The following methods help you to work with that state: Saves the current drawing style state using a stack so you can revert any change you make to it using . Restores the drawing style state to the last element on the 'state stack' saved by . A read-only back-reference to the . Might be if it is not associated with a element. Returns an object containing the context attributes used by the browser. Context attributes can be requested when using to create the 2D context. Resets the rendering context, including the backing buffer, the drawing state stack, path, and styles. Returns if the rendering context was lost."
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/getContext",
        "document": "This feature is well established and works across many devices and browser versions. It’s been available across browsers since July 2015 . * Some parts of this feature may have varying levels of support.\n\nThe method returns a drawing context on the canvas, or if the context identifier is not supported, or the canvas has already been set to a different context mode. Later calls to this method on the same canvas element, with the same argument, will always return the same drawing context instance as was returned the first time the method was invoked. It is not possible to get a different drawing context object on a given canvas element."
    },
    {
        "link": "https://w3schools.com/tags/ref_canvas.asp",
        "document": "You can add a canvas element anywhere in an HTML page with the tag:\n\nYou can access a element with the HTML DOM method .\n\nTo draw in the canvas you need to create a 2D context object:\n\nAfter you have created a 2D context, you can draw on the canvas.\n\nThe fillRect() method draws a black rectangle with a top-left corner at position 20,20. The rectangle is 150 pixel wide and 100 pixels high.\n\nThe fillStyle property sets the fill color of the drawing object:\n\nYou can also create a new element with the method, and add the element to an existing HTML page:\n\nThe common way to draw on the canvas is to:\n\nThere are only 3 methods to draw directly on the canvas:\n\nThe canvas object also supports the standard properties and events.\n\nThe element is an HTML5 standard (2014).\n\nis supported in all modern browsers:"
    },
    {
        "link": "https://docs.tizen.org/application/web/guides/w3c/graphics/canvas",
        "document": "The HTML5 canvas allows you to use graphics on the screen, and draw and manage various shapes. The HTML Canvas 2D Context API (in mobile, wearable, and TV applications) defines a special canvas element that expresses images or shapes with JavaScript.\n\nThe main features of the Canvas Element API include the following:\n• To draw and manage shapes, you must insert a <canvas> element in the HTML page.\n• You can use images on the canvas by using the applicable method of the HTML Canvas 2D Context API.\n• With the HTML Canvas 2D Context API, you can draw various shapes, such as rectangles, circles, and lines to a canvas. You can also draw and mask objects on the canvas.\n• You can use a canvas to create text or lines other than images and shapes.\n\nFor all canvas objects (images, shapes, text, and lines), you can define colors (the and attributes), shadows (the and attributes), and gradation (the method). You can also use the transformation methods, such as , , , and , to implement, for example, transparency or shape gradient transformations.\n\nIn mobile applications only, in HTML5, the Scalable Vector Graphics (SVG) 2 API provides similar features as the canvas. Their difference is that SVG expresses graphics using vectors, while the canvas is based on pixels. To express complex graphics, use the canvas, and to express graphics with a liberal expansion or reduction, use SVG.\n\nTo create a canvas in your application, follow these steps:\n• The canvas assigns the region (canvas context) where images are drawn with JavaScript: If no and attributes are inserted, the default value is .\n• To check the information on the image connected to the canvas, use the method to restore the URL of the image used on the canvas. To create a blob object of the image file, use the method.\n• Use the interface (in mobile, wearable, and TV applications) to connect to the canvas and get the canvas context: The interface has various methods and attributes for expressing images and shapes.\n• To manage the work stack of the canvas, use the following methods:\n• : Pushes the current state onto the stack.\n• : Pops the top state on the stack, restoring the context to that state.\n\nThere is a need to separately check whether the canvas 2D context can be used by using the method:\n\nFor the complete source code related to this use case, see the following files:\n\nUse images on the canvas\n\nTo use images on the canvas, use the method of the HTML Canvas 2D Context API. The method receives information, such as the image URL and position, and where it is indicated, and then creates the image on the canvas. The created image is pixel-based.\n\nTo use images on a canvas, follow these steps:\n• Use the method to express an image on the canvas. When you define the URL of the image to be imported and its coordinates, the original image is imported as it is. You can hide certain parts of the image by assigning its size accordingly:\n• When the image is connected to the canvas, extract the color value through the method. Re-input the transformed values with the method:\n• Use the interface to transform the selected object, for example, its size, angle, or position. By connecting to the image used on the canvas, you can also rotate it: The following figure applies to mobile applications only.\n\nFor the complete source code related to this use case, see the following files:\n\nWith the HTML Canvas 2D Context API, you can draw various shapes, such as rectangles ( ), circles ( and ), and lines ( and ), to a canvas. You can define the position and size of the shapes, and also merge shapes with other shape objects.\n\nTo create and draw shapes on a canvas, follow these steps:\n• Use the method to create a rectangle. Use the canvas context to assign the rectangle attributes, such as position and size: The following figure applies to mobile applications only.\n• Use the method to create a circle. Use the canvas context to assign the circle attributes, such as position and radius. (The following figure applies to mobile applications only.)\n• Use the interface to transform the created shapes. With compositing, a certain part of the shape can be made transparent. The following figure applies to mobile applications only.\n\nFor the complete source code related to this use case, see the following file:\n\nTo draw masks on a canvas, follow these steps:\n• Create the HTML layout with a canvas and 2 button input elements for brush selection:\n• Define the CSS style for the background image:\n• Declare the JavaScript variables needed in the application. The and variables indicate the last position of a user event. The variable indicates whether a button or touch event has occurred, and the variable indicates the current brush size:\n• Draw an image on the canvas using the method. The user is able to replace the image with another using a brush. Create a new object, including the path of the image file. Define the line width to be based on the brush size selected by the user:\n• The and events only store the event coordinates, the and events define the position and direction of the drawing, and the and events indicate that the user event ends, as illustrated in the following figure.\n• Use the method to update the and variable values. The real coordinates can be calculated by reducing the offset position of the canvas element from the touch position coordinates. The string indicates that the event is a touch event:\n• When the user starts drawing, the or event calls the method, which updates the event position, sets the composite operations property to make the drawing a mask, begins to draw a new path, moves the drawing point to the selected coordinates, and sets the button or touch event state to :\n• While the user is drawing, the and events are handled with the method based on the button state retrieved from the variable. The method calls the method only when the mouse or finger is being moved. Use the method to make the drawn line visible:\n• When the touch event ends or the mouse button is released, use the method to stop drawing:\n\nFor the complete source code related to this use case, see the following file:\n\nCreat text and lines on the canvas\n\nTo create text and lines on a canvas, follow these steps:\n• To draw a line, use the method to assign the beginning point of the line, and the method to assign the end point of the line. The method draws the full line:\n• When adding text on the canvas, use various attributes and methods to define how the text looks and where it is located. The attribute defines the font style, and the attribute the vertical alignment of the text:\n• Use the attribute and the method to position the text in the assigned location:\n\nFor the complete source code related to this use case, see the following files:\n\nPerformance comparison of Canvas 2D and WebGL™ in mobile applications\n\nIn Web documents prior to HTML5, only simple image loading was supported. To create graphic animations, you had to use a separate plug-in. However, as the graphic-related APIs have become more standardized, you can now express graphics by using only JavaScript, without a separate plug-in.\n\nWhen developing Web applications that need to express complex graphics, such as games, the most important issue to consider is graphic performance. Currently, the HTML Canvas 2D Context API and WebGL™ are used to express graphic elements in many games. The following example illustrates how to create an effective graphic animation by comparing the performance of the renderers in the Canvas 2D Context API and WebGL™.\n\nTo compare the performance, 2 simple Web applications must be created, using the Canvas 2D Context API and WebGL™:\n• Create the applications with the following logic:\n• Render the loaded image in the random location of the canvas.\n• Use the method of the Timing control for script-based animations API (in mobile, wearable, and TV applications) to change the color of the loaded image, based on different times.\n• Create a logic that measures FPS (frames per second) in order to check the performance.\n• Execute the applications and measure the FPS.\n• Increase only the number of objects so that the same 1~N images, under the same conditions, are shown repeatedly based on 1~N.\n• Measure the FPS as the number of repeatedly shown objects increase.\n\nThe following figure shows the result of the test: As the number of objects increase, the performance of the Canvas 2D Context API rapidly decreases compared to WebGL™ (the result is subject to change according to the complexity of the application logic). As such, when expressing many graphic objects all differently, it is much more efficient to use WebGL™ than the Canvas 2D Context API.\n\nThere is one problem with using WebGL™; the ratio of mobile browsers supporting it is quite low compared to the Canvas 2D Context API, and even when it is supported, usually only partial features are included (support for 3D acceleration, reflection effect, and camera effect is particularly low). The following figure shows the support status of WebGL™ in computer (top) and mobile (bottom) browsers, as published in http://webglstats.com/ in June 2013.\n\nMany mobile browsers do not support WebGL™ or only partially support WebGL™. Even though Tizen supports WebGL™, it is recommended to use the Canvas 2D Context API for small numbers of 2D drawings, since the API is supported in most mobile browsers. However, for performance critical applications, use WebGL™ for faster 2D performance."
    },
    {
        "link": "https://html.spec.whatwg.org/multipage/canvas.html",
        "document": "The element provides scripts with a resolution-dependent bitmap canvas, which can be used for rendering graphs, game graphics, art, or other visual images on the fly.\n\nAuthors should not use the element in a document when a more suitable element is available. For example, it is inappropriate to use a element to render a page heading: if the desired presentation of the heading is graphically intense, it should be marked up using appropriate elements (typically ) and then styled using CSS and supporting technologies such as shadow trees.\n\nWhen authors use the element, they must also provide content that, when presented to the user, conveys essentially the same function or purpose as the 's bitmap. This content may be placed as content of the element. The contents of the element, if any, are the element's fallback content.\n\nIn interactive visual media, if scripting is enabled for the element, and if support for elements has been enabled, then the element represents embedded content consisting of a dynamically created image, the element's bitmap.\n\nIn non-interactive, static, visual media, if the element has been previously associated with a rendering context (e.g. if the page was viewed in an interactive visual medium and is now being printed, or if some script that ran during the page layout process painted on the element), then the element represents embedded content with the element's current bitmap and size. Otherwise, the element represents its fallback content instead.\n\nIn non-visual media, and in visual media if scripting is disabled for the element or if support for elements has been disabled, the element represents its fallback content instead.\n\nWhen a element represents embedded content, the user can still focus descendants of the element (in the fallback content). When an element is focused, it is the target of keyboard interaction events (even though the element itself is not visible). This allows authors to make an interactive canvas keyboard-accessible: authors should have a one-to-one mapping of interactive regions to focusable areas in the fallback content. (Focus has no effect on mouse interaction events.) [UIEVENTS]\n\nAn element whose nearest element ancestor is being rendered and represents embedded content is an element that is being used as relevant canvas fallback content .\n\nThe element has two attributes to control the size of the element's bitmap: and . These attributes, when specified, must have values that are valid non-negative integers. The rules for parsing non-negative integers must be used to . If an attribute is missing, or if parsing its value returns an error, then the default value must be used instead. The attribute defaults to 300, and the attribute defaults to 150.\n\nWhen setting the value of the or attribute, if the context mode of the element is set to placeholder, the user agent must throw an \" \" and leave the attribute's value unchanged.\n\nThe natural dimensions of the element when it represents embedded content are equal to the dimensions of the element's bitmap.\n\nThe user agent must use a square pixel density consisting of one pixel of image data per coordinate space unit for the bitmaps of a and its rendering contexts.\n\nA element can be sized arbitrarily by a style sheet, its bitmap is then subject to the 'object-fit' CSS property.\n\nThe bitmaps of elements, the bitmaps of objects, as well as some of the bitmaps of rendering contexts, such as those described in the sections on the , , and objects below, have an flag, which can be set to true or false. Initially, when the element or object is created, its bitmap's origin-clean flag must be set to true.\n\nA element can have a rendering context bound to it. Initially, it does not have a bound rendering context. To keep track of whether it has a rendering context or not, and what kind of rendering context it is, a also has a , which is initially but can be changed to either , , , , , or by algorithms defined in this specification.\n\nWhen its canvas context mode is none, a element has no rendering context, and its bitmap must be transparent black with a natural width equal to the numeric value of the element's attribute and a natural height equal to the numeric value of the element's attribute, those values being interpreted in CSS pixels, and being updated as the attributes are set, changed, or removed.\n\nWhen its canvas context mode is placeholder, a element has no rendering context. It serves as a placeholder for an object, and the content of the element is updated by the object's rendering context.\n\nWhen a element represents embedded content, it provides a paint source whose width is the element's natural width, whose height is the element's natural height, and whose appearance is the element's bitmap.\n\nWhenever the and content attributes are set, removed, changed, or redundantly set to the value they already have, then the user agent must perform the action from the row of the following table that corresponds to the element's context mode.\n\nThe and IDL attributes must reflect the respective content attributes of the same name, with the same defaults.\n\nThe method of the element, when invoked, must run these steps:\n• None If is not an object, then set to null.\n• None Set to the result of converting to a JavaScript value.\n• Run the steps in the cell of the following table whose column header matches this element's canvas context mode and whose row header matches :\n• None Let be the result of running the 2D context creation algorithm given this and . Return the same object as was returned the last time the method was invoked with this same first argument.\n• None Let be the result of running the creation algorithm given this and . Return the same object as was returned the last time the method was invoked with this same first argument. \" \" or \" \", if the user agent supports the WebGL feature in its current configuration\n• None Let be the result of following the instructions given in the WebGL specifications' Context Creation sections. [WEBGL]\n• None If is null, then return null; otherwise set this's context mode to webgl or webgl2. Return the same object as was returned the last time the method was invoked with this same first argument. \" \", if the user agent supports the WebGPU feature in its current configuration\n• None Let be the result of following the instructions given in 's Canvas Rendering section. [WEBGPU]\n• None If is null, then return null; otherwise set this's context mode to webgpu. Return the same object as was returned the last time the method was invoked with this same first argument. * For example, the \" \" or \" \" value in the case of a user agent having exhausted the graphics hardware's abilities and having no software fallback implementation.\n\nThe method, when invoked, must run these steps:\n• None If this element's bitmap's origin-clean flag is set to false, then throw a \" \" .\n• None If this element's bitmap has no pixels (i.e. either its horizontal dimension or its vertical dimension is zero) then return the string \" \". (This is the shortest URL; it represents the empty string in a resource.)\n• None Let be a serialization of this element's bitmap as a file, passing and if given.\n• None If is null then return \" \".\n\nThe method, when invoked, must run these steps:\n• None If this element's bitmap's origin-clean flag is set to false, then throw a \" \" .\n• None If this element's bitmap has pixels (i.e., neither its horizontal dimension nor its vertical dimension is zero), then set to a copy of this element's bitmap.\n• \n• None If is non-null, then set to a serialization of as a file with and if given.\n• Queue an element task on the given the element to run these steps:\n• None If is non-null, then set to a new object, created in the relevant realm of this element, representing . [FILEAPI]\n\nThe method, when invoked, must run these steps:\n• None If this element's context mode is not set to none, throw an \" \" .\n• None Let be a new object with its width and height equal to the values of the and content attributes of this element.\n• None Set the 's placeholder element to a weak reference to this element.\n• None Set the 's inherited language to the language of this element.\n• None Set the 's inherited direction to the directionality of this element.\n\nTo maintain compatibility with existing web content, user agents need to enumerate methods defined in immediately after the method on objects.\n\nThe 2D rendering context represents a flat linear Cartesian surface whose origin (0,0) is at the top left corner, with the coordinate space having values increasing when going right, and values increasing when going down. The -coordinate of the right-most edge is equal to the width of the rendering context's output bitmap in CSS pixels; similarly, the -coordinate of the bottom-most edge is equal to the height of the rendering context's output bitmap in CSS pixels.\n\nThe size of the coordinate space does not necessarily represent the size of the actual bitmaps that the user agent will use internally or during rendering. On high-definition displays, for instance, the user agent may internally use bitmaps with four device pixels per unit in the coordinate space, so that the rendering remains at high quality throughout. Anti-aliasing can similarly be implemented using oversampling with bitmaps of a higher resolution than the final image on the display.\n\nThe , which is passed a (a element) and , consists of running these steps:\n• None Let be the result of converting to the dictionary type . (This can throw an exception.).\n• None Let be a new object.\n• None Set 's output bitmap to the same bitmap as 's bitmap (so that they are shared).\n• None Set bitmap dimensions to the numeric values of 's and content attributes.\n• None Run the canvas settings output bitmap initialization algorithm, given and .\n\nWhen the user agent is to to and , it must run these steps:\n• None Reset the rendering context to its default state.\n• None Resize the output bitmap to the new and .\n• None Let be the element to which the rendering context's attribute was initialized.\n• None If the numeric value of 's content attribute differs from , then set 's content attribute to the shortest possible string representing as a valid non-negative integer.\n• None If the numeric value of 's content attribute differs from , then set 's content attribute to the shortest possible string representing as a valid non-negative integer.\n\nThe attribute must return the value it was initialized to when the object was created.\n\nThe enumeration is used to specify the color space of the canvas's backing store.\n\nThe \" \" value indicates the 'srgb' color space.\n\nThe \" \" value indicates the 'display-p3' color space.\n\nThe algorithm for converting between color spaces can be found in the Converting Colors section of . [CSSCOLOR]\n\nThe enumeration is used to specify the color type of the canvas's backing store.\n\nThe \" \" value indicates that the type for all color components is 8-bit unsigned normalized.\n\nThe \" \" value indicates that the type for all color components is 16-bit floating point.\n\nThe enumeration is used to select the algorithm by which to determine if a point is inside or outside a path.\n\nThe \" \" value indicates the nonzero winding rule, wherein a point is considered to be outside a shape if the number of times a half-infinite straight line drawn from that point crosses the shape's path going in one direction is equal to the number of times it crosses the path going in the other direction.\n\nThe \" \" value indicates the even-odd rule, wherein a point is considered to be outside a shape if the number of times a half-infinite straight line drawn from that point crosses the shape's path is even.\n\nIf a point is not outside a shape, it is inside the shape.\n\nThe enumeration is used to express a preference for the interpolation quality to use when smoothing images.\n\nThe \" \" value indicates a preference for a low level of image interpolation quality. Low-quality image interpolation may be more computationally efficient than higher settings.\n\nThe \" \" value indicates a preference for a medium level of image interpolation quality.\n\nThe \" \" value indicates a preference for a high level of image interpolation quality. High-quality image interpolation may be more computationally expensive than lower settings.\n\nBilinear scaling is an example of a relatively fast, lower-quality image-smoothing algorithm. Bicubic or Lanczos scaling are examples of image-smoothing algorithms that produce higher-quality output. This specification does not mandate that specific interpolation algorithms be used.\n\nThe output bitmap, when it is not directly displayed by the user agent, implementations can, instead of updating this bitmap, merely remember the sequence of drawing operations that have been applied to it until such time as the bitmap's actual data is needed (for example because of a call to , or the factory method). In many cases, this will be more memory efficient.\n\nThe bitmap of a element is the one bitmap that's pretty much always going to be needed in practice. The output bitmap of a rendering context, when it has one, is always just an alias to a element's bitmap.\n\nAdditional bitmaps are sometimes needed, e.g. to enable fast drawing when the canvas is being painted at a different size than its natural size, or to enable double buffering so that graphics updates, like page scrolling for example, can be processed concurrently while canvas draw commands are being executed.\n\nA object has an that is initialized when the object is created.\n\nThe output bitmap has an origin-clean flag, which can be set to true or false. Initially, when one of these bitmaps is created, its origin-clean flag must be set to true.\n\nThe object also has an boolean. When a object's alpha is false, then its alpha component must be fixed to 1.0 (fully opaque) for all pixels, and attempts to change the alpha component of any pixel must be silently ignored.\n\nThus, the bitmap of such a context starts off as opaque black instead of transparent black; always results in opaque black pixels, every fourth byte from is always 255, the method effectively ignores every fourth byte in its input, and so on. However, the alpha component of styles and images drawn onto the canvas are still honoured up to the point where they would impact the output bitmap's alpha component; for instance, drawing a 50% transparent white square on a freshly created output bitmap with its alpha set to false will result in a fully-opaque gray square.\n\nThe object also has a boolean. When a object's desynchronized is true, then the user agent may optimize the rendering of the canvas to reduce the latency, as measured from input events to rasterization, by desynchronizing the canvas paint cycle from the event loop, bypassing the ordinary user agent rendering algorithm, or both. Insofar as this mode involves bypassing the usual paint mechanisms, rasterization, or both, it might introduce visible tearing artifacts.\n\nThe user agent usually renders on a buffer which is not being displayed, quickly swapping it and the one being scanned out for presentation; the former buffer is called back buffer and the latter front buffer. A popular technique for reducing latency is called front buffer rendering, also known as single buffer rendering, where rendering happens in parallel and racily with the scanning out process. This technique reduces the latency at the price of potentially introducing tearing artifacts and can be used to implement in total or part of the desynchronized boolean. [MULTIPLEBUFFERING]\n\nThe desynchronized boolean can be useful when implementing certain kinds of applications, such as drawing applications, where the latency between input and rasterization is critical.\n\nThe object also has a boolean. When a object's will read frequently is true, the user agent may optimize the canvas for readback operations.\n\nOn most devices the user agent needs to decide whether to store the canvas's output bitmap on the GPU (this is also called \"hardware accelerated\"), or on the CPU (also called \"software\"). Most rendering operations are more performant for accelerated canvases, with the major exception being readback with , , or . objects with will read frequently equal to true tell the user agent that the webpage is likely to perform many readback operations and that it is advantageous to use a software canvas.\n\nThe object also has a setting of type . The object's color space indicates the color space for the output bitmap.\n\nThe object also has a setting of type . The object's color type indicates the data type of the color and alpha components of the pixels of the output bitmap.\n\nTo , given a and a :\n\nThe method steps are to return «[ \" \" → this's alpha, \" \" → this's desynchronized, \" \" → this's color space, \" \" → this's color type, \" \" → this's will read frequently ]».\n\nObjects that implement the interface maintain a stack of drawing states. consist of:\n• None The current letter spacing, word spacing, fill style, stroke style, filter, global alpha, compositing and blending operator, and shadow color.\n• None The current values of the following attributes: , , , , , , , , , , , , , , , , , , .\n\nThe rendering context's bitmaps are not part of the drawing state, as they depend on whether and how the rendering context is bound to a element.\n\nObjects that implement the mixin have a boolean, that is initialized to false when the object is created. The context lost value is updated in the context lost steps.\n\nThe method steps are to push a copy of the current drawing state onto the drawing state stack.\n\nThe method steps are to pop the top entry in the drawing state stack, and reset the drawing state it describes. If there is no saved state, then the method must do nothing.\n\nThe method steps are to reset the rendering context to its default state.\n\nTo reset the rendering context to its default state :\n• None Empty the list of subpaths in context's current default path.\n• None Reset everything that drawing state consists of to their initial values.\n\nThe method steps are to return this's context lost.\n\nObjects that implement the interface have attributes and methods (defined in this section) that control how lines are treated by the object.\n\nThe attribute gives the width of lines, in coordinate space units. On getting, it must return the current value. On setting, zero, negative, infinite, and NaN values must be ignored, leaving the value unchanged; other values must change the current value to the new value.\n\nWhen the object implementing the interface is created, the attribute must initially have the value 1.0.\n\nThe attribute defines the type of endings that UAs will place on the end of lines. The three valid values are \" \", \" \", and \" \".\n\nOn getting, it must return the current value. On setting, the current value must be changed to the new value.\n\nWhen the object implementing the interface is created, the attribute must initially have the value \" \".\n\nThe attribute defines the type of corners that UAs will place where two lines meet. The three valid values are \" \", \" \", and \" \".\n\nOn getting, it must return the current value. On setting, the current value must be changed to the new value.\n\nWhen the object implementing the interface is created, the attribute must initially have the value \" \".\n\nWhen the attribute has the value \" \", strokes use the miter limit ratio to decide how to render joins. The miter limit ratio can be explicitly set using the attribute. On getting, it must return the current value. On setting, zero, negative, infinite, and NaN values must be ignored, leaving the value unchanged; other values must change the current value to the new value.\n\nWhen the object implementing the interface is created, the attribute must initially have the value 10.0.\n\nEach object has a , which is either empty or consists of an even number of non-negative numbers. Initially, the dash list must be empty.\n\nThe method, when invoked, must run these steps:\n• None If any value in is not finite (e.g. an Infinity or a NaN value), or if any value is negative (less than zero), then return (without throwing an exception; user agents could show a message on a developer console, though, as that would be helpful for debugging).\n• None If the number of elements in is odd, then let be the concatenation of two copies of .\n• None Let the object's dash list be .\n\nWhen the method is invoked, it must return a sequence whose values are the values of the object's dash list, in the same order.\n\nIt is sometimes useful to change the \"phase\" of the dash pattern, e.g. to achieve a \"marching ants\" effect. The phase can be set using the attribute. On getting, it must return the current value. On setting, infinite and NaN values must be ignored, leaving the value unchanged; other values must change the current value to the new value.\n\nWhen the object implementing the interface is created, the attribute must initially have the value 0.0.\n\nWhen a user agent is to , given an object that implements the interface, it must run the following algorithm. This algorithm returns a new path.\n• None Let be a copy of the path being traced.\n• None Remove from any subpaths containing no lines (i.e. subpaths with just one point).\n• None Replace each point in each subpath of other than the first point and the last point of each subpath by a join that joins the line leading to that point to the line leading out of that point, such that the subpaths all consist of two points (a starting point with a line leading out of it, and an ending point with a line leading into it), one or more lines (connecting the points and the joins), and zero or more joins (each connecting one line to another), connected together such that each subpath is a series of one or more lines with a join between each one and a point on each end.\n• None Add a straight closing line to each closed subpath in connecting the last point and the first point of that subpath; change the last point to a join (from the previously last line to the newly added closing line), and change the first point to a join (from the newly added closing line to the first line).\n• None If 's dash list is empty, then jump to the step labeled convert.\n• None Let be the concatenation of all the entries of 's dash list, in coordinate space units.\n• None For each subpath in , run the following substeps. These substeps mutate the subpaths in in vivo.\n• None Let be the length of all the lines of , in coordinate space units.\n• None Let be the value of 's , in coordinate space units.\n• While is greater than , decrement it by . While is less than zero, increment it by .\n• None Define to be a linear coordinate line defined along all lines in , such that the start of the first line in the subpath is defined as coordinate 0, and the end of the last line in the subpath is defined as coordinate .\n• None Let be zero minus .\n• None Let be off (the other states being on and zero-on).\n• None Dash on: Let be the value of 's dash list's th entry.\n• None If is greater than , then end these substeps for this subpath and start them again for the next subpath; if there are no more subpaths, then jump to the step labeled convert instead.\n• None If is nonzero, then let be on.\n• None Dash off: Let be the value of 's dash list's th entry.\n• None Let be the offset on .\n• None If is less than zero, then jump to the step labeled post-cut.\n• None If is less than zero, then let be zero.\n• None If is greater than , then let be the offset on . Otherwise, let be the offset on .\n• Jump to the first appropriate step: If is zero and is off Do nothing, just continue to the next step. If is off Cut the line on which finds itself short at and place a point there, cutting in two the subpath that it was in; remove all line segments, joins, points, and subpaths that are between and ; and finally place a single point at with no lines connecting to it. The point has a directionality for the purposes of drawing line caps (see below). The directionality is the direction that the original line had at that point (i.e. when was defined above). Cut the line on which finds itself into two at and place a point there, cutting in two the subpath that it was in, and similarly cut the line on which finds itself short at and place a point there, cutting in two the subpath that it was in, and then remove all line segments, joins, points, and subpaths that are between and . If and are the same point, then this results in just the line being cut in two and two points being inserted there, with nothing being removed, unless a join also happens to be at that point, in which case the join must be removed.\n• None Post-cut: If is greater than , then jump to the step labeled convert.\n• None Increment by one. If it is equal to the number of entries in 's dash list, then let be 0.\n• None Return to the step labeled dash on.\n• Convert: This is the step that converts the path to a new path that represents its stroke. Create a new path that describes the edge of the areas that would be covered if a straight line of length equal to 's was swept along each subpath in while being kept at an angle such that the line is orthogonal to the path being swept, replacing each point with the end cap necessary to satisfy 's attribute as described previously and elaborated below, and replacing each join with the join necessary to satisfy 's type, as defined below. Caps: Each point has a flat edge perpendicular to the direction of the line coming out of it. This is then augmented according to the value of 's . The \" \" value means that no additional line cap is added. The \" \" value means that a semi-circle with the diameter equal to 's width must additionally be placed on to the line coming out of each point. The \" \" value means that a rectangle with the length of 's width and the width of half 's width, placed flat against the edge perpendicular to the direction of the line coming out of the point, must be added at each point. Points with no lines coming out of them must have two caps placed back-to-back as if it was really two points connected to each other by an infinitesimally short straight line in the direction of the point's directionality (as defined above). Joins: In addition to the point where a join occurs, two additional points are relevant to each join, one for each line: the two corners found half the line width away from the join point, one perpendicular to each line, each on the side furthest from the other line. A triangle connecting these two opposite corners with a straight line, with the third point of the triangle being the join point, must be added at all joins. The attribute controls whether anything else is rendered. The three aforementioned values have the following meanings: The \" \" value means that this is all that is rendered at joins. The \" \" value means that an arc connecting the two aforementioned corners of the join, abutting (and not overlapping) the aforementioned triangle, with the diameter equal to the line width and the origin at the point of the join, must be added at joins. The \" \" value means that a second triangle must (if it can given the miter length) be added at the join, with one line being the line between the two aforementioned corners, abutting the first triangle, and the other two being continuations of the outside edges of the two joining lines, as long as required to intersect without going over the miter length. The miter length is the distance from the point where the join occurs to the intersection of the line edges on the outside of the join. The miter limit ratio is the maximum allowed ratio of the miter length to half the line width. If the miter length would cause the miter limit ratio (as set by 's attribute) to be exceeded, then this second triangle must not be added. The subpaths in the newly created path must be oriented such that for any point, the number of times a half-infinite straight line drawn from that point crosses a subpath is even if and only if the number of times a half-infinite straight line drawn from that same point crosses a subpath going in one direction is equal to the number of times it crosses a subpath going in the other direction.\n\nObjects that implement the interface have attributes (defined in this section) that control how text is laid out (rasterized or outlined) by the object. Such objects can also have a . For objects, this is the element given by the value of the context's attribute. For objects, this is the associated object.\n\nFont resolution for the font style source object requires a font source. This is determined for a given implementing by the following steps: [CSSFONTLOAD]\n• None If 's font style source object is a element, return the element's node document.\n• Otherwise, 's font style source object is an object:\n• None If is a object, then return 's associated .\n\nThe IDL attribute, on setting, must be parsed as a CSS <'font'> value (but without supporting property-independent style sheet syntax like 'inherit'), and the resulting font must be assigned to the context, with the 'line-height' component forced to 'normal', with the 'font-size' component converted to CSS pixels, and with system fonts being computed to explicit values. If the new value is syntactically incorrect (including using property-independent style sheet syntax like 'inherit' or 'initial'), then it must be ignored, without assigning a new font value. [CSS]\n\nFont family names must be interpreted in the context of the font style source object when the font is to be used; any fonts embedded using or loaded using objects that are visible to the font style source object must therefore be available once they are loaded. (Each font style source object has a font source, which determines what fonts are available.) If a font is used before it is fully loaded, or if the font style source object does not have that font in scope at the time the font is to be used, then it must be treated as if it was an unknown font, falling back to another as described by the relevant CSS specifications. [CSSFONTS] [CSSFONTLOAD]\n\nOn getting, the attribute must return the serialized form of the current font of the context (with no 'line-height' component). [CSSOM]\n\nWhen the object implementing the interface is created, the font of the context must be set to 10px sans-serif. When the 'font-size' component is set to lengths using percentages, 'em' or 'ex' units, or the 'larger' or 'smaller' keywords, these must be interpreted relative to the computed value of the 'font-size' property of the font style source object at the time that the attribute is set, if it is an element. When the 'font-weight' component is set to the relative values 'bolder' and 'lighter', these must be interpreted relative to the computed value of the 'font-weight' property of the font style source object at the time that the attribute is set, if it is an element. If the computed values are undefined for a particular case (e.g. because the font style source object is not an element or is not being rendered), then the relative keywords must be interpreted relative to the normal-weight 10px sans-serif default.\n\nThe IDL attribute, on getting, must return the current value. On setting, the current value must be changed to the new value. When the object implementing the interface is created, the attribute must initially have the value .\n\nThe IDL attribute, on getting, must return the current value. On setting, the current value must be changed to the new value. When the object implementing the interface is created, the attribute must initially have the value .\n\nObjects that implement the interface have an associated value used to localize font rendering. Valid values are a BCP 47 language tag, the empty string, or \" \" where the language comes from the element's language, or the associated document element when there is no element. Initially, the language must be \" \".\n\nThe getter steps are to return this's language.\n\nThe setter steps are to set this's language to the given value.\n\nThe IDL attribute, on getting, must return the current value. On setting, the current value must be changed to the new value. When the object implementing the interface is created, the attribute must initially have the value \" \".\n\nObjects that implement the interface have attributes that control the spacing between letters and words. Such objects have associated and values, which are CSS <length> values. Initially, both must be the result of parsing \" \" as a CSS <length>.\n\nThe getter steps are to return the serialized form of this's letter spacing.\n• None Let be the result of parsing the given value as a CSS <length>.\n• None If is failure, then return.\n\nThe getter steps are to return the serialized form of this's word spacing.\n• None Let be the result of parsing the given value as a CSS <length>.\n• None If is failure, then return.\n\nThe IDL attribute, on getting, must return the current value. On setting, the current value must be changed to the new value. When the object implementing the interface is created, the attribute must initially have the value \" \".\n\nThe IDL attribute, on getting, must return the current value. On setting, the current value must be changed to the new value. When the object implementing the interface is created, the attribute must initially have the value \" \".\n\nThe IDL attribute, on getting, must return the current value. On setting, the current value must be changed to the new value. When the object implementing the interface is created, the attribute must initially have the value \" \".\n\nThe IDL attribute, on getting, must return the current value. On setting, the current value must be changed to the new value. When the object implementing the interface is created, the attribute must initially have the value \" \".\n\nThe attribute's allowed keywords are as follows:\n\nThe attribute's allowed keywords correspond to alignment points in the font:\n\nThe keywords map to these alignment points as follows:\n\nThe attribute's allowed keywords are as follows:\n\nThe attribute's allowed keywords are as follows:\n\nThe attribute's allowed keywords are as follows:\n\nThe attribute's allowed keywords are as follows:\n\nThe attribute's allowed keywords are as follows:\n\nThe is as follows. It takes as input a string , a object , and an optional length . It returns an array of glyph shapes, each positioned on a common coordinate space, a whose value is one of left, right, and center, and an inline box. (Most callers of this algorithm ignore the and the inline box.)\n• None If was provided but is less than or equal to zero or equal to NaN, then return an empty array.\n• None Replace all ASCII whitespace in with U+0020 SPACE characters.\n• None Let be the current font of , as given by that object's attribute.\n• None Let be the 's language.\n• \n• None If is a element, then set to the 's language.\n• None If is the empty string, then set to explicitly unknown.\n• Apply the appropriate step from the following list to determine the value of : If the object's attribute has the value \" \" If the object's attribute has the value \" \" If the object's attribute has the value \" \"\n• None If is a element, then let be 's directionality.\n• Form a hypothetical infinitely-wide CSS line box containing a single inline box containing the text , with the CSS content language set to , and with its CSS properties set as follows: and with all other properties set to their initial values.\n• None If was provided and the hypothetical width of the inline box in the hypothetical line box is greater than CSS pixels, then change to have a more condensed font (if one is available or if a reasonably readable one can be synthesized by applying a horizontal scale factor to the font) or a smaller font, and return to the previous step.\n• The is a point on the inline box, and the is one of the values left, right, and center. These variables are determined by the and values as follows: If is If is and is 'ltr' If is and is 'rtl' Let the 's horizontal position be the left edge of the inline box, and let be left. If is If is and is 'ltr' If is and is 'rtl' Let the 's horizontal position be the right edge of the inline box, and let be right. Let the 's horizontal position be half way between the left and right edges of the inline box, and let be center. Let the 's vertical position be the top of the em box of the first available font of the inline box. Let the 's vertical position be the hanging baseline of the first available font of the inline box. Let the 's vertical position be half way between the bottom and the top of the em box of the first available font of the inline box. Let the 's vertical position be the alphabetic baseline of the first available font of the inline box. Let the 's vertical position be the ideographic-under baseline of the first available font of the inline box. Let the 's vertical position be the bottom of the em box of the first available font of the inline box.\n• Let be an array constructed by iterating over each glyph in the inline box from left to right (if any), adding to the array, for each glyph, the shape of the glyph as it is in the inline box, positioned on a coordinate space using CSS pixels with its origin at the .\n\nObjects that implement the interface have a path. A has a list of zero or more subpaths. Each subpath consists of a list of one or more points, connected by straight or curved , and a flag indicating whether the subpath is closed or not. A closed subpath is one where the last point of the subpath is connected to the first point of the subpath by a straight line. Subpaths with only one point are ignored when painting the path.\n\nPaths have a flag. When this flag is set, certain APIs create a new subpath rather than extending the previous one. When a path is created, its need new subpath flag must be set.\n\nWhen an object implementing the interface is created, its path must be initialized to zero subpaths.\n\nThe following methods allow authors to manipulate the paths of objects implementing the interface.\n\nFor objects implementing the and interfaces, the points passed to the methods, and the resulting lines added to current default path by these methods, must be transformed according to the current transformation matrix before being added to the path.\n\nThe method, when invoked, must run these steps:\n• None If either of the arguments are infinite or NaN, then return.\n• None Create a new subpath with the specified point as its first (and only) point.\n\nWhen the user agent is to for a coordinate ( , ) on a path, the user agent must check to see if the path has its need new subpath flag set. If it does, then the user agent must create a new subpath with the point ( , ) as its first (and only) point, as if the method had been called, and must then unset the path's need new subpath flag.\n\nThe method, when invoked, must do nothing if the object's path has no subpaths. Otherwise, it must mark the last subpath as closed, create a new subpath whose first point is the same as the previous subpath's first point, and finally add this new subpath to the path.\n\nIf the last subpath had more than one point in its list of points, then this is equivalent to adding a straight line connecting the last point back to the first point of the last subpath, thus \"closing\" the subpath.\n\nNew points and the lines connecting them are added to subpaths using the methods described below. In all cases, the methods only modify the last subpath in the object's path.\n\nThe method, when invoked, must run these steps:\n• None If either of the arguments are infinite or NaN, then return.\n• None If the object's path has no subpaths, then ensure there is a subpath for ( , ).\n• None Otherwise, connect the last point in the subpath to the given point ( , ) using a straight line, and then add the given point ( , ) to the subpath.\n\nThe method, when invoked, must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• None Ensure there is a subpath for ( , )\n• None Connect the last point in the subpath to the given point ( , ) using a quadratic Bézier curve with control point ( , ). [BEZIER]\n• None Add the given point ( , ) to the subpath.\n\nThe method, when invoked, must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• None Ensure there is a subpath for ( , ).\n• None Connect the last point in the subpath to the given point ( , ) using a cubic Bézier curve with control points ( , ) and ( , ). [BEZIER]\n• None Add the point ( , ) to the subpath.\n\nThe method, when invoked, must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• None Ensure there is a subpath for ( , ).\n• None If is negative, then throw an \" \" .\n• None Let the point ( , ) be the last point in the subpath, transformed by the inverse of the current transformation matrix (so that it is in the same coordinate system as the points passed to the method).\n• None If the point ( , ) is equal to the point ( , ), or if the point ( , ) is equal to the point ( , ), or if is zero, then add the point ( , ) to the subpath, and connect that point to the previous point ( , ) by a straight line.\n• None Otherwise, if the points ( , ), ( , ), and ( , ) all lie on a single straight line, then add the point ( , ) to the subpath, and connect that point to the previous point ( , ) by a straight line.\n• None Otherwise, let be the shortest arc given by circumference of the circle that has radius , and that has one point tangent to the half-infinite line that crosses the point ( , ) and ends at the point ( , ), and that has a different point tangent to the half-infinite line that ends at the point ( , ) and crosses the point ( , ). The points at which this circle touches these two lines are called the start and end tangent points respectively. Connect the point ( , ) to the start tangent point by a straight line, adding the start tangent point to the subpath, and then connect the start tangent point to the end tangent point by , adding the end tangent point to the subpath.\n\nThe method, when invoked, must run the ellipse method steps with this, , , , , 0, , , and .\n\nThis makes it equivalent to except that both radii are equal and is 0.\n\nThe method, when invoked, must run the ellipse method steps with this, , , , , , , , and .\n\nThe determine the point on an ellipse steps , given , and , are:\n• None Let be the circle that shares its origin with , with a radius equal to the semi-major axis of .\n• None Let be the point on 's circumference at measured in radians clockwise from 's semi-major axis.\n• None Let be the line perpendicular to 's major axis between this axis and .\n• None Return the point on that crosses 's circumference.\n\nThe , given , , , , , , , , and , are:\n• None If any of the arguments are infinite or NaN, then return.\n• None If either or are negative, then throw an \" \" .\n• None If 's path has any subpaths, then add a straight line from the last point in the subpath to the start point of the arc.\n• Add the start and end points of the arc to the subpath, and connect them with an arc. The arc and its start and end points are defined as follows: Consider an ellipse that has its origin at ( , ), that has a major-axis radius and a minor-axis radius , and that is rotated about its origin such that its semi-major axis is inclined radians clockwise from the x-axis. If is false and − is greater than or equal to 2π, or, if is true and − is greater than or equal to 2π, then the arc is the whole circumference of this ellipse, and both the start point and the end point are the result of running the determine the point on an ellipse steps given this ellipse and . Otherwise, the start point is the result of running the determine the point on an ellipse steps given this ellipse and , the end point is the result of running the determine the point on an ellipse steps given this ellipse and , and the arc is the path along the circumference of this ellipse from the start point to the end point, going counterclockwise if is true, and clockwise otherwise. Since the points are on the ellipse, as opposed to being simply angles from zero, the arc can never cover an angle greater than 2π radians. Even if the arc covers the entire circumference of the ellipse and there are no other points in the subpath, the path is not closed unless the method is appropriately invoked.\n\nThe method, when invoked, must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• None Create a new subpath containing just the four points ( , ), ( + , ), ( + , + ), ( , + ), in that order, with those four points connected by straight lines.\n• None Create a new subpath with the point ( , ) as the only point in the subpath.\n• None If any of , , , or are infinite or NaN, then return.\n• None If is an or , then set to « ».\n• None If is not a list of size one, two, three, or four, then throw a .\n• None Let be an empty list.\n• For each of :\n• \n• None If [\" \"] or [\" \"] is infinite or NaN, then return.\n• None If [\" \"] or [\" \"] is negative, then throw a .\n• \n• None If is infinite or NaN, then return.\n• None If is negative, then throw a .\n• None Let , , , and be null.\n• None If 's size is 4, then set to [0], set to [1], set to [2], and set to [3].\n• None If 's size is 3, then set to [0], set and to [1], and set to [2].\n• None If 's size is 2, then set and to [0] and set and to [1].\n• None If 's size is 1, then set , , , and to [0].\n• Corner curves must not overlap. Scale all radii to prevent this:\n• None Let be the minimum value of the ratios / , / , / , / .\n• None If is less than 1, then set the and members of , , , and to their current values multiplied by .\n• \n• None Draw an arc to the point ( + , + [\" \"]).\n• None Draw an arc to the point ( + − [\" \"], + ).\n• None Draw an arc to the point ( , + − [\" \"]).\n• None Draw an arc to the point ( + [\" \"], ).\n• None Create a new subpath with the point ( , ) as the only point in the subpath.\n\nThis is designed to behave similarly to the CSS 'border-radius' property.\n\nobjects can be used to declare paths that are then later used on objects implementing the interface. In addition to many of the APIs described in earlier sections, objects have methods to combine paths, and to add text to paths.\n\nThe constructor, when invoked, must run these steps:\n• None Let be a new object.\n• None If is not given, then return .\n• None If is a object, then add all subpaths of to and return . (In other words, it returns a copy of the argument.)\n• Let be the result of parsing and interpreting according to 's rules for path data. [SVG] The resulting path could be empty. SVG defines error handling rules for parsing and applying path data.\n• None Let ( , ) be the last point in .\n• None Add all the subpaths, if any, from to .\n• None Create a new subpath in with ( , ) as the only point in the subpath.\n\nThe method, when invoked on a object , must run these steps:\n• None If the object has no subpaths, then return.\n• None Let be the result of creating a from the 2D dictionary .\n• None If one or more of 's m11 element, m12 element, m21 element, m22 element, m41 element, or m42 element are infinite or NaN, then return.\n• None Create a copy of all the subpaths in . Let this copy be known as .\n• None Transform all the coordinates and lines in by the transform matrix .\n• None Let ( , ) be the last point in the last subpath of .\n• None Add all the subpaths in to .\n• None Create a new subpath in with ( , ) as the only point in the subpath.\n\nObjects that implement the interface have a , as well as methods (described in this section) to manipulate it. When an object implementing the interface is created, its transformation matrix must be initialized to the identity matrix.\n\nThe current transformation matrix is applied to coordinates when creating the current default path, and when painting text, shapes, and objects, on objects implementing the interface.\n\nThe transformations must be performed in reverse order.\n\nFor instance, if a scale transformation that doubles the width is applied to the canvas, followed by a rotation transformation that rotates drawing operations by a quarter turn, and a rectangle twice as wide as it is tall is then drawn on the canvas, the actual result will be a square.\n\nThe method, when invoked, must run these steps:\n• None If either of the arguments are infinite or NaN, then return.\n• None Add the scaling transformation described by the arguments to the current transformation matrix. The argument represents the scale factor in the horizontal direction and the argument represents the scale factor in the vertical direction. The factors are multiples.\n\nThe method, when invoked, must run these steps:\n• None If is infinite or NaN, then return.\n• None Add the rotation transformation described by the argument to the current transformation matrix. The argument represents a clockwise rotation angle expressed in radians.\n\nThe method, when invoked, must run these steps:\n• None If either of the arguments are infinite or NaN, then return.\n• None Add the translation transformation described by the arguments to the current transformation matrix. The argument represents the translation distance in the horizontal direction and the argument represents the translation distance in the vertical direction. The arguments are in coordinate space units.\n\nThe method, when invoked, must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• Replace the current transformation matrix with the result of multiplying the current transformation matrix with the matrix described by:\n\nThe arguments , , , , , and are sometimes called , , , , , and or , , , , , and . Care ought to be taken in particular with the order of the second and third arguments ( and ) as their order varies from API to API and APIs sometimes use the notation / and sometimes / for those positions.\n\nThe method, when invoked, must return a newly created representing a copy of the current transformation matrix matrix of the context.\n\nThis returned object is not live, so updating it will not affect the current transformation matrix, and updating the current transformation matrix will not affect an already returned .\n\nThe method, when invoked, must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• Reset the current transformation matrix to the matrix described by:\n\nThe method, when invoked, must run these steps:\n• None Let be the result of creating a from the 2D dictionary .\n• None If one or more of 's m11 element, m12 element, m21 element, m22 element, m41 element, or m42 element are infinite or NaN, then return.\n\nThe method, when invoked, must reset the current transformation matrix to the identity matrix.\n\nSome methods on the and interfaces take the union type as an argument.\n\nThis union type allows objects implementing any of the following interfaces to be used as image sources:\n\nAlthough not formally specified as such, SVG elements are expected to be implemented nearly identical to elements. That is, SVG elements share the fundamental concepts and features of elements.\n\nThe interface can be created from a number of other image-representing types, including .\n\nTo check the usability of the argument , where is a object, run these steps:\n• If 's current request's state is broken, then throw an \" \" . If is not fully decodable, then return bad. If has a natural width or natural height (or both) equal to zero, then return bad. If 's attribute is either or , then return bad. If has either a horizontal dimension or a vertical dimension equal to zero, then throw an \" \" . If 's [[Detached]] internal slot value is set to true, then throw an \" \" .\n\nWhen a object represents an , the element's image must be used as the source image.\n\nSpecifically, when a object represents an animated image in an , the user agent must use the default image of the animation (the one that the format defines is to be used when animation is not supported or is disabled), or, if there is no such image, the first frame of the animation, when rendering the image for APIs.\n\nWhen a object represents an , then the frame at the current playback position when the method with the argument is invoked must be used as the source image when rendering the image for APIs, and the source image's dimensions must be the natural width and natural height of the media resource (i.e., after any aspect-ratio correction has been applied).\n\nWhen a object represents an , the element's bitmap must be used as the source image.\n\nWhen a object represents an element that is being rendered and that element has been resized, the original image data of the source image must be used, not the image as it is rendered (e.g. and attributes on the source element have no effect on how the object is interpreted when rendering the image for APIs).\n\nWhen a object represents an , the object's bitmap image data must be used as the source image.\n\nWhen a object represents an , the object's bitmap must be used as the source image.\n\nWhen a object represents a , the object's pixel data must be used as the source image, and the source image's dimensions must be the object's [[display width]] and [[display height]].\n\nAn object if, switching on 's type:\n\nObjects that implement the interface have attributes and methods (defined in this section) that control how shapes are treated by the object.\n\nSuch objects have associated and values, which are either CSS colors, s, or s. Initially, both must be the result of parsing the string \" \".\n\nWhen the value is a CSS color, it must not be affected by the transformation matrix when used to draw on bitmaps.\n\nWhen set to a or object, changes made to the object after the assignment do affect subsequent stroking or filling of shapes.\n• None If this's fill style is a CSS color, then return the serialization of that color with HTML-compatible serialization requested.\n• If the given value is a string, then:\n• None Let be this's attribute's value, if that is an element; otherwise null.\n• None Let be the result of parsing the given value with if non-null.\n• None If is failure, then return.\n• None If the given value is a object that is marked as not origin-clean, then set this's origin-clean flag to false.\n• None Set this's fill style to the given value.\n• None If this's stroke style is a CSS color, then return the serialization of that color with HTML-compatible serialization requested.\n• If the given value is a string, then:\n• None Let be this's attribute's value, if that is an element; otherwise null.\n• None Let be the result of parsing the given value with if non-null.\n• None If is failure, then return.\n• None If the given value is a object that is marked as not origin-clean, then set this's origin-clean flag to false.\n• None Set this's stroke style to the given value.\n\nThere are three types of gradients, linear gradients, radial gradients, and conic gradients, represented by objects implementing the opaque interface.\n\nOnce a gradient has been created (see below), stops are placed along it to define how the colors are distributed along the gradient. The color of the gradient at each stop is the color specified for that stop. Between each such stop, the colors and the alpha component must be linearly interpolated over the RGBA space without premultiplying the alpha value to find the color to use at that offset. Before the first stop, the color must be the color of the first stop. After the last stop, the color must be the color of the last stop. When there are no stops, the gradient is transparent black.\n\nThe method on the , when invoked, must run these steps:\n• None If the is less than 0 or greater than 1, then throw an \" \" .\n• Let be the result of parsing . No element is passed to the parser because objects are -neutral — a object created by one can be used by another, and there is therefore no way to know which is the \"element in question\" at the time that the color is specified.\n• Place a new stop on the gradient, at offset relative to the whole gradient, and with the color . If multiple stops are added at the same offset on a gradient, then they must be placed in the order added, with the first one closest to the start of the gradient, and each subsequent one infinitesimally further along towards the end point (in effect causing all but the first and last stop added at each point to be ignored).\n\nThe method takes four arguments that represent the start point ( , ) and end point ( , ) of the gradient. The method, when invoked, must return a linear initialized with the specified line.\n\nLinear gradients must be rendered such that all points on a line perpendicular to the line that crosses the start and end points have the color at the point where those two lines cross (with the colors coming from the interpolation and extrapolation described above). The points in the linear gradient must be transformed as described by the current transformation matrix when rendering.\n\nIf = and = , then the linear gradient must paint nothing.\n\nThe method takes six arguments, the first three representing the start circle with origin ( , ) and radius , and the last three representing the end circle with origin ( , ) and radius . The values are in coordinate space units. If either of or are negative, then an \" \" must be thrown. Otherwise, the method, when invoked, must return a radial initialized with the two specified circles.\n\nRadial gradients must be rendered by following these steps:\n• None If = and = and = , then the radial gradient must paint nothing. Return.\n• Let the color at be the color at that position on the gradient (with the colors coming from the interpolation and extrapolation described above).\n• None For all values of where r( ) > 0, starting with the value of nearest to positive infinity and ending with the value of nearest to negative infinity, draw the circumference of the circle with radius r( ) at position (x( ), y( )), with the color at , but only painting on the parts of the bitmap that have not yet been painted on by earlier circles in this step for this rendering of the gradient.\n\nThis effectively creates a cone, touched by the two circles defined in the creation of the gradient, with the part of the cone before the start circle (0.0) using the color of the first offset, the part of the cone after the end circle (1.0) using the color of the last offset, and areas outside the cone untouched by the gradient (transparent black).\n\nThe resulting radial gradient must then be transformed as described by the current transformation matrix when rendering.\n\nThe method takes three arguments, the first argument, , represents the angle in radians at which the gradient begins, and the last two arguments, ( , ), represent the center of the gradient in CSS pixels. The method, when invoked, must return a conic initialized with the specified center and angle.\n\nIt follows the same rendering rule as CSS 'conic-gradient' and it is equivalent to CSS 'conic-gradient(from rad at px px, )'. Here:\n• None is given by + π/2;\n• None is given by the color stops that have been added to the using , with the color stop offsets interpreted as percentages.\n\nGradients must be painted only where the relevant stroking or filling effects requires that they be drawn.\n\nPatterns are represented by objects implementing the opaque interface.\n\nThe method, when invoked, must run these steps:\n• None Let be the result of checking the usability of .\n• None If is bad, then return null.\n• None If is the empty string, then set it to \" \".\n• None If is not identical to one of \" \", \" \", \" \", or \" \", then throw a \" \" .\n• None Let be a new object with the image and the repetition behavior given by .\n• None If is not origin-clean, then mark as .\n\nModifying the used when creating a object after calling the method must not affect the pattern(s) rendered by the object.\n\nPatterns have a transformation matrix, which controls how the pattern is used when it is painted. Initially, a pattern's transformation matrix must be the identity matrix.\n\nThe method, when invoked, must run these steps:\n• None Let be the result of creating a from the 2D dictionary .\n• None If one or more of 's m11 element, m12 element, m21 element, m22 element, m41 element, or m42 element are infinite or NaN, then return.\n\nWhen a pattern is to be rendered within an area, the user agent must run the following steps to determine what is rendered:\n• Place a copy of the image on the bitmap, anchored such that its top left corner is at the origin of the coordinate space, with one coordinate space unit per CSS pixel of the image, then place repeated copies of this image horizontally to the left and right, if the repetition behavior is \" \", or vertically up and down, if the repetition behavior is \" \", or in all four directions all over the bitmap, if the repetition behavior is \" \". If the original image data is a bitmap image, then the value painted at a point in the area of the repetitions is computed by filtering the original image data. When scaling up, if the attribute is set to false, then the image must be rendered using nearest-neighbor interpolation. Otherwise, the user agent may use any filtering algorithm (for example bilinear interpolation or nearest-neighbor). User agents which support multiple filtering algorithms may use the value of the attribute to guide the choice of filtering algorithm. When such a filtering algorithm requires a pixel value from outside the original image data, it must instead use the value from wrapping the pixel's coordinates to the original image's dimensions. (That is, the filter uses 'repeat' behavior, regardless of the value of the pattern's repetition behavior.)\n• None Transform the resulting bitmap according to the pattern's transformation matrix.\n• None Transform the resulting bitmap again, this time according to the current transformation matrix.\n• None Replace any part of the image outside the area in which the pattern is to be rendered with transparent black.\n• None The resulting bitmap is what is to be rendered, with the same origin and same scale.\n\nIf a radial gradient or repeated pattern is used when the transformation matrix is singular, then the resulting style must be transparent black (otherwise the gradient or pattern would be collapsed to a point or line, leaving the other pixels undefined). Linear gradients and solid colors always define all points even with singular transformation matrices.\n\nObjects that implement the interface provide the following methods for immediately drawing rectangles to the bitmap. The methods each take four arguments; the first two give the and coordinates of the top left of the rectangle, and the second two give the width and height of the rectangle, respectively.\n\nThe current transformation matrix must be applied to the following four coordinates, which form the path that must then be closed to get the specified rectangle: ( , ), ( + , ), ( + , + ), ( , + ).\n\nShapes are painted without affecting the current default path, and are subject to the clipping region, and, with the exception of , also shadow effects, global alpha, and the current compositing and blending operator.\n\nThe method, when invoked, must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• None Let be the set of pixels in the specified rectangle that also intersect the current clipping region.\n• None Clear the pixels in to a transparent black, erasing any previous image.\n\nIf either height or width are zero, this method has no effect, since the set of pixels would be empty.\n\nThe method, when invoked, must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• None If either or are zero, then return.\n• None Paint the specified rectangular area using this's fill style.\n\nThe method, when invoked, must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• None Take the result of tracing the path described below, using the interface's line styles, and fill it with this's stroke style.\n\nIf both and are zero, the path has a single subpath with just one point ( , ), and no lines, and this method thus has no effect (the trace a path algorithm returns an empty path in that case).\n\nIf just one of either or is zero, then the path has a single subpath consisting of two points, with coordinates ( , ) and ( + , + ), in that order, connected by a single straight line.\n\nOtherwise, the path has a single subpath consisting of four points, with coordinates ( , ), ( + , ), ( + , + ), and ( , + ), connected to each other in that order by straight lines.\n\nObjects that implement the interface provide the following methods for rendering text.\n\nThe and methods render the given at the given ( , ) coordinates ensuring that the text isn't wider than if specified, using the current , , and values. Specifically, when the methods are invoked, the user agent must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• None Run the text preparation algorithm, passing it , the object implementing the interface, and, if the argument was provided, that argument. Let be the result.\n• None Move all the shapes in to the right by CSS pixels and down by CSS pixels.\n• Paint the shapes given in , as transformed by the current transformation matrix, with each CSS pixel in the coordinate space of mapped to one coordinate space unit. For , this's fill style must be applied to the shapes and this's stroke style must be ignored. For , the reverse holds: this's stroke style must be applied to the result of tracing the shapes using the object implementing the interface for the line styles, and this's fill style must be ignored. These shapes are painted without affecting the current path, and are subject to shadow effects, global alpha, the clipping region, and the current compositing and blending operator.\n\nThe method steps are to run the text preparation algorithm, passing it and the object implementing the interface, and then using the returned inline box must return a new object with members behaving as described in the following list: [CSS]\n\nGlyphs rendered using and can spill out of the box given by the font size and the width returned by (the text width). Authors are encouraged to use the bounding box values described above if this is an issue.\n\nA future version of the 2D context API might provide a way to render fragments of documents, rendered using CSS, straight to the canvas. This would be provided in preference to a dedicated way of doing multiline layout.\n\nObjects that implement the interface have a . There is only one current default path, it is not part of the drawing state. The current default path is a path, as described above.\n\nThe method steps are to empty the list of subpaths in this's current default path so that it once again has zero subpaths.\n\nWhere the following method definitions use the term for a -or-null , it means itself if it is a object, or the current default path otherwise.\n\nWhen the intended path is a object, the coordinates and lines of its subpaths must be transformed according to the current transformation matrix on the object implementing the interface when used by these methods (without affecting the object itself). When the intended path is the current default path, it is not affected by the transform. (This is because transformations already affect the current default path when it is constructed, so applying it when it is painted as well would result in a double transformation.)\n\nThe method steps are to run the fill steps given this, null, and .\n\nThe method steps are to run the fill steps given this, , and .\n\nThe , given a , a -or-null , and a fill rule , are to fill all the subpaths of the intended path for , using 's fill style, and using the fill rule indicated by . Open subpaths must be implicitly closed when being filled (without affecting the actual subpaths).\n\nThe method steps are to run the stroke steps given this and null.\n\nThe method steps are to run the stroke steps given this and .\n\nThe , given a and a -or-null , are to trace the intended path for , using 's line styles as set by its mixin, and then fill the resulting path using 's stroke style, using the nonzero winding rule.\n\nAs a result of how the algorithm to trace a path is defined, overlapping parts of the paths in one stroke operation are treated as if their union was what was painted.\n\nThe stroke style is affected by the transformation during painting, even if the current default path is used.\n\nPaths, when filled or stroked, must be painted without affecting the current default path or any objects, and must be subject to shadow effects, global alpha, the clipping region, and the current compositing and blending operator. (The effect of transformations is described above and varies based on which path is being used.)\n\nThe method steps are to run the clip steps given this, null, and .\n\nThe method steps are to run the clip steps given this, , and .\n\nThe , given a , a -or-null , and a fill rule , are to create a new by calculating the intersection of 's current clipping region and the area described by the intended path for , using the fill rule indicated by . Open subpaths must be implicitly closed when computing the clipping region, without affecting the actual subpaths. The new clipping region replaces the current clipping region.\n\nWhen the context is initialized, its current clipping region must be set to the largest infinite surface (i.e. by default, no clipping occurs).\n\nThe method steps are to return the result of the is point in path steps given this, null, , , and .\n\nThe method steps are to return the result of the is point in path steps given this, , , , and .\n\nThe , given a , a -or-null , two numbers and , and a fill rule , are:\n• None If or are infinite or NaN, then return false.\n• None If the point given by the and coordinates, when treated as coordinates in the canvas coordinate space unaffected by the current transformation, is inside the intended path for as determined by the fill rule indicated by , then return true. Open subpaths must be implicitly closed when computing the area inside the path, without affecting the actual subpaths. Points on the path itself must be considered to be inside the path.\n\nThe method steps are to return the result of the is point in stroke steps given this, null, , and .\n\nThe method steps are to return the result of the is point in stroke steps given this, , , and .\n\nThe , given a , a -or-null , and two numbers and , are:\n• None If or are infinite or NaN, then return false.\n• None If the point given by the and coordinates, when treated as coordinates in the canvas coordinate space unaffected by the current transformation, is inside the path that results from tracing the intended path for , using the nonzero winding rule, and using 's line styles as set by its mixin, then return true. Points on the resulting path must be considered to be inside the path.\n\nObjects that implement the interface provide the following methods to draw focus rings.\n\nThe method steps are to draw focus if needed given this, , and this's current default path.\n\nThe method steps are to draw focus if needed given this, , and .\n\nTo , given an object implementing , an element , and a path :\n• None If is not focused or is not a descendant of 's element, then return.\n• Draw a focus ring of the appropriate style along , following platform conventions. Some platforms only draw focus rings around elements that have been focused from the keyboard, and not those focused from the mouse. Other platforms simply don't draw focus rings around some elements at all unless relevant accessibility features are enabled. This API is intended to follow these conventions. User agents that implement distinctions based on the manner in which the element was focused are encouraged to classify focus driven by the method based on the kind of user interaction event from which the call was triggered (if any). The focus ring should not be subject to the shadow effects, the global alpha, the current compositing and blending operator, the fill style, the stroke style, or any of the members in the , interfaces, but should be subject to the clipping region. (The effect of transformations is described above and varies based on which path is being used.)\n• None Inform the user that the focus is at the location given by the intended path. User agents may wait until the next time the event loop reaches its step to optionally inform the user.\n\nUser agents should not implicitly close open subpaths in the intended path when drawing the focus ring.\n\nThis might be a moot point, however. For example, if the focus ring is drawn as an axis-aligned bounding rectangle around the points in the intended path, then whether the subpaths are closed or not has no effect. This specification intentionally does not specify precisely how focus rings are to be drawn: user agents are expected to honor their platform's native conventions.\n\n\"Inform the user\", as used in this section, does not imply any persistent state change. It could mean, for instance, calling a system accessibility API to notify assistive technologies such as magnification tools so that the user's magnifier moves to the given area of the canvas. However, it does not associate the path with the element, or provide a region for tactile feedback, etc.\n\nObjects that implement the interface have the method to draw images.\n\nThis method can be invoked with three different sets of arguments:\n\nWhen the method is invoked, the user agent must run these steps:\n• None If any of the arguments are infinite or NaN, then return.\n• None Let be the result of checking the usability of .\n• None If is bad, then return (without drawing anything).\n• Establish the source and destination rectangles as follows: If not specified, the and arguments must default to the values of and , interpreted such that one CSS pixel in the image is treated as one unit in the output bitmap's coordinate space. If the , , , and arguments are omitted, then they must default to 0, 0, the image's natural width in image pixels, and the image's natural height in image pixels, respectively. If the image has no natural dimensions, then the concrete object size must be used instead, as determined using the CSS \"Concrete Object Size Resolution\" algorithm, with the specified size having neither a definite width nor height, nor any additional constraints, the object's natural properties being those of the argument, and the default object size being the size of the output bitmap. [CSSIMAGES] The source rectangle is the rectangle whose corners are the four points ( , ), ( + , ), ( + , + ), ( , + ). The destination rectangle is the rectangle whose corners are the four points ( , ), ( + , ), ( + , + ), ( , + ). When the source rectangle is outside the source image, the source rectangle must be clipped to the source image and the destination rectangle must be clipped in the same proportion. When the destination rectangle is outside the destination image (the output bitmap), the pixels that land outside the output bitmap are discarded, as if the destination was an infinite canvas whose rendering was clipped to the dimensions of the output bitmap.\n• None If one of the or arguments is zero, then return. Nothing is painted.\n• Paint the region of the argument specified by the source rectangle on the region of the rendering context's output bitmap specified by the destination rectangle, after applying the current transformation matrix to the destination rectangle. The image data must be processed in the original direction, even if the dimensions given are negative. When scaling up, if the attribute is set to true, the user agent should attempt to apply a smoothing algorithm to the image data when it is scaled. User agents which support multiple filtering algorithms may use the value of the attribute to guide the choice of filtering algorithm when the attribute is set to true. Otherwise, the image must be rendered using nearest-neighbor interpolation. This specification does not define the precise algorithm to use when scaling an image down, or when scaling an image up when the attribute is set to true. When a element is drawn onto itself, the drawing model requires the source to be copied before the image is drawn, so it is possible to copy parts of a element onto overlapping parts of itself. If the original image data is a bitmap image, then the value painted at a point in the destination rectangle is computed by filtering the original image data. The user agent may use any filtering algorithm (for example bilinear interpolation or nearest-neighbor). When the filtering algorithm requires a pixel value from outside the original image data, it must instead use the value from the nearest edge pixel. (That is, the filter uses 'clamp-to-edge' behavior.) When the filtering algorithm requires a pixel value from outside the source rectangle but inside the original image data, then the value from the original image data must be used. Thus, scaling an image in parts or in whole will have the same effect. This does mean that when sprites coming from a single sprite sheet are to be scaled, adjacent images in the sprite sheet can interfere. This can be avoided by ensuring each sprite in the sheet is surrounded by a border of transparent black, or by copying sprites to be scaled into temporary elements and drawing the scaled sprites from there. Images are painted without affecting the current path, and are subject to shadow effects, global alpha, the clipping region, and the current compositing and blending operator.\n• None If is not origin-clean, then set the 's origin-clean flag to false.\n\nObjects that implement the interface provide the following methods for reading and writing pixel data to the bitmap.\n• None If one or both of and are zero, then throw an \" \" .\n• None Initialize this given , , and settings set to .\n• None Initialize the image data of this to transparent black.\n• None Let be the number of bytes in .\n• None If is not a nonzero integral multiple of four, then throw an \" \" .\n• None Let be divided by four.\n• If is not an integral multiple of , then throw an \" \" . At this step, the length is guaranteed to be greater than zero (otherwise the second step above would have aborted the steps), so if is zero, this step will throw the exception and return.\n• None Let be divided by .\n• None If was given and its value is not equal to , then throw an \" \" .\n• Initialize this given , , settings set to , and source set to . This step does not set this's data to a copy of . It sets it to the actual object passed as .\n• None If one or both of and are zero, then throw an \" \" .\n• None Let be a new object.\n• None Initialize given the absolute magnitude of , the absolute magnitude of , settings set to , and defaultColorSpace set to this's color space.\n• None Initialize the image data of to transparent black.\n• None Let be a new object.\n• None Initialize given the value of 's attribute, the value of 's attribute, and defaultColorSpace set to the value of 's attribute.\n• None Initialize the image data of to transparent black.\n• None If either the or arguments are zero, then throw an \" \" .\n• None If the 's origin-clean flag is set to false, then throw a \" \" .\n• None Let be a new object.\n• None Initialize given , , settings set to , and defaultColorSpace set to this's color space.\n• None Let the source rectangle be the rectangle whose corners are the four points ( , ), ( + , ), ( + , + ), ( , + ).\n• None Set the pixel values of to be the pixels of this's output bitmap in the area specified by the source rectangle in the bitmap's coordinate space units, converted from this's color space to 's using 'relative-colorimetric' rendering intent.\n• None Set the pixels values of for areas of the source rectangle that are outside of the output bitmap to transparent black.\n\nTo , given a positive integer number of rows , a positive integer number of pixels per row , an optional , an optional , and an optional :\n• None If was given, then initialize the attribute of to .\n• Otherwise ( was not given), initialize the attribute of to a new object. The object must use a new Canvas Pixel for its storage, and must have a zero start offset and a length equal to the length of its storage, in bytes. The Canvas Pixel must have the correct size to store × pixels. If the Canvas Pixel cannot be allocated, then rethrow the thrown by JavaScript, and return.\n• None Initialize the attribute of to .\n• None Initialize the attribute of to .\n• None If was given and [\" \"] exists, then initialize the attribute of to [\" \"].\n• None Otherwise, if was given, then initialize the attribute of to .\n• None Otherwise, initialize the attribute of to \"srgb\".\n\nobjects are serializable objects. Their serialization steps, given and , are:\n• None Set .[[Data]] to the sub-serialization of the value of 's attribute.\n• None Set .[[Width]] to the value of 's attribute.\n• None Set .[[Height]] to the value of 's attribute.\n• None Set .[[ColorSpace]] to the value of 's attribute.\n\nTheir deserialization steps, given , , and , are:\n• None Initialize 's attribute to the sub-deserialization of .[[Data]].\n\nA is an whose data is represented in left-to-right order, row by row top to bottom, starting with the top left, with each pixel's red, green, blue, and alpha components being given in that order for each pixel. Each component of each pixel represented in this array must be in the range 0..255, representing the 8 bit value for that component. The components must be assigned consecutive indices starting with 0 for the top left pixel's red component.\n\nThe method steps are to put pixels from an onto a bitmap, given , this's output bitmap, , , 0, 0, 's , and 's .\n\nThe method steps are to put pixels from an onto a bitmap, given , this's output bitmap, , , , , , and .\n\nTo put pixels from an onto a bitmap , given an , an output bitmap , and numbers , , , , , and :\n• None If IsDetachedBuffer( ) is true, then throw an \" \" .\n• If is negative, then let be + , and let be equal to the absolute magnitude of . If is negative, then let be + , and let be equal to the absolute magnitude of .\n• If is negative, then let be + , and let be zero. If is negative, then let be + , and let be zero.\n• If + is greater than the attribute of the argument, then let be the value of that attribute, minus the value of . If + is greater than the attribute of the argument, then let be the value of that attribute, minus the value of .\n• If, after those changes, either or are negative or zero, then return without affecting any bitmaps.\n• None For all integer values of and where ≤ < + and ≤ < + , set the pixel with coordinate ( + , + ) in to the color of the pixel at coordinate ( , ) in the data structure's Canvas Pixel , converted from 's to the color space of using 'relative-colorimetric' rendering intent.\n\nDue to the lossy nature of converting between color spaces and converting to and from premultiplied alpha color values, pixels that have just been set using , and are not completely opaque, might be returned to an equivalent as different values.\n\nThe current path, transformation matrix, shadow attributes, global alpha, the clipping region, and current compositing and blending operator must not affect the methods described in this section.\n\nObjects that implement the interface have a global alpha value and a current compositing and blending operator value that both affect all the drawing operations on this object.\n\nThe value gives an alpha value that is applied to shapes and images before they are composited onto the output bitmap. The value ranges from 0.0 (fully transparent) to 1.0 (no additional transparency). It must initially have the value 1.0.\n\nThe getter steps are to return this's global alpha.\n• None If the given value is either infinite, NaN, or not in the range 0.0 to 1.0, then return.\n• None Otherwise, set this's global alpha to the given value.\n\nThe value controls how shapes and images are drawn onto the output bitmap, once they have had the global alpha and the current transformation matrix applied. Initially, it must be set to \" \".\n\nThe getter steps are to return this's current compositing and blending operator.\n• None If the given value is not identical to any of the values that the <blend-mode> or the <composite-mode> properties are defined to take, then return. [COMPOSITE]\n• None Otherwise, set this's current compositing and blending operator to the given value.\n\nObjects that implement the interface have attributes that control how image smoothing is performed.\n\nThe attribute, on getting, must return the last value it was set to. On setting, it must be set to the new value. When the object implementing the interface is created, the attribute must be set to true.\n\nThe attribute, on getting, must return the last value it was set to. On setting, it must be set to the new value. When the object implementing the interface is created, the attribute must be set to \" \".\n\nAll drawing operations on an object which implements the interface are affected by the four global shadow attributes.\n\nObjects which implement the interface have an associated , which is a CSS color. Initially, it must be transparent black.\n\nThe getter steps are to return the serialization of this's shadow color with HTML-compatible serialization requested.\n• None Let be this's attribute's value, if that is an element; otherwise null.\n• None Let be the result of parsing the given value with if non-null.\n• None If is failure, then return.\n\nThe and attributes specify the distance that the shadow will be offset in the positive horizontal and positive vertical distance respectively. Their values are in coordinate space units. They are not affected by the current transformation matrix.\n\nWhen the context is created, the shadow offset attributes must initially have the value 0.\n\nOn getting, they must return their current value. On setting, the attribute being set must be set to the new value, except if the value is infinite or NaN, in which case the new value must be ignored.\n\nThe attribute specifies the level of the blurring effect. (The units do not map to coordinate space units, and are not affected by the current transformation matrix.)\n\nWhen the context is created, the attribute must initially have the value 0.\n\nOn getting, the attribute must return its current value. On setting, the attribute must be set to the new value, except if the value is negative, infinite or NaN, in which case the new value must be ignored.\n\nShadows are only drawn if the opacity component of the alpha component of the shadow color is nonzero and either the is nonzero, or the is nonzero, or the is nonzero.\n\nWhen shadows are drawn, they must be rendered as follows:\n• None Let be an infinite transparent black bitmap on which the source image for which a shadow is being created has been rendered.\n• None Let be an infinite transparent black bitmap, with a coordinate space and an origin identical to .\n• None Copy the alpha component of to , offset by in the positive direction, and in the positive direction.\n• If is greater than 0:\n• None Let be half the value of .\n• None Perform a 2D Gaussian Blur on , using as the standard deviation. User agents may limit values of to an implementation-specific maximum value to avoid exceeding hardware limitations during the Gaussian blur operation.\n• None Set the red, green, and blue components of every pixel in to the red, green, and blue components (respectively) of the shadow color.\n• None Multiply the alpha component of every pixel in by the alpha component of the shadow color.\n• None The shadow is in the bitmap , and is rendered as part of the drawing model described below.\n\nIf the current compositing and blending operator is \" \", then shadows effectively won't render (since the shape will overwrite the shadow).\n\nAll drawing operations on an object which implements the interface are affected by the global attribute.\n\nSuch objects have an associated , which is a string. Initially the current filter is set to the string \" \". Whenever the value of the current filter is the string \" \" filters will be disabled for the context.\n\nThe getter steps are to return this's current filter.\n• None If the given value is \" \", then set this's current filter to \" \" and return.\n• None Let be the result of parsing the given values as a <filter-value-list>. If any property-independent style sheet syntax like 'inherit' or 'initial' is present, then this parsing must return failure.\n• None If is failure, then return.\n• None Set this's current filter to the given value.\n\nThough will disable filters for the context, , , and are all treated as unparseable inputs and the value of the current filter is left unchanged.\n\nCoordinates used in the value of the current filter are interpreted such that one pixel is equivalent to one SVG user space unit and to one canvas coordinate space unit. Filter coordinates are not affected by the current transformation matrix. The current transformation matrix affects only the input to the filter. Filters are applied in the output bitmap's coordinate space.\n\nWhen the value of the current filter is a string parsable as a <filter-value-list> which defines lengths using percentages or using 'em' or 'ex' units, these must be interpreted relative to the computed value of the 'font-size' property of the font style source object at the time that the attribute is set. If the computed values are undefined for a particular case (e.g. because the font style source object is not an element or is not being rendered), then the relative keywords must be interpreted relative to the default value of the attribute. The 'larger' and 'smaller' keywords are not supported.\n\nIf the value of the current filter is a string parseable as a <filter-value-list> with a reference to an SVG filter in the same document, and this SVG filter changes, then the changed filter is used for the next draw operation.\n\nIf the value of the current filter is a string parseable as a <filter-value-list> with a reference to an SVG filter in an external resource document and that document is not loaded when a drawing operation is invoked, then the drawing operation must proceed with no filtering.\n\nSince drawing is performed using filter value \" \" until an externally-defined filter has finished loading, authors might wish to determine whether such a filter has finished loading before proceeding with a drawing operation. One way to accomplish this is to load the externally-defined filter elsewhere within the same page in some element that sends a event (for example, an SVG element), and wait for the event to be dispatched.\n\nWhen a shape or image is painted, user agents must follow these steps, in the order given (or act as if they do):\n• None Render the shape or image onto an infinite transparent black bitmap, creating image , as described in the previous sections. For shapes, the current fill, stroke, and line styles must be honored, and the stroke must itself also be subjected to the current transformation matrix.\n• None Multiply the alpha component of every pixel in by .\n• When the current filter is set to a value other than \" \" and all the externally-defined filters it references, if any, are in documents that are currently loaded, then use image as the input to the current filter, creating image . If the current filter is a string parseable as a <filter-value-list>, then draw using the current filter in the same manner as SVG. Otherwise, let be an alias for .\n• None When shadows are drawn, render the shadow from image , using the current shadow styles, creating image .\n• None When shadows are drawn, composite within the clipping region over the current output bitmap using the current compositing and blending operator.\n• None Composite within the clipping region over the current output bitmap using the current compositing and blending operator.\n\nWhen compositing onto the output bitmap, pixels that would fall outside of the output bitmap must be discarded.\n\nWhen a canvas is interactive, authors should include focusable elements in the element's fallback content corresponding to each focusable part of the canvas, as in the example above.\n\nWhen rendering focus rings, to ensure that focus rings have the appearance of native focus rings, authors should use the method, passing it the element for which a ring is being drawn. This method only draws the focus ring if the element is focused, so that it can simply be called whenever drawing the element, without checking whether the element is focused or not first.\n\nAuthors should avoid implementing text editing controls using the element. Doing so has a large number of disadvantages:\n• Mouse placement of the caret has to be reimplemented.\n• Keyboard movement of the caret has to be reimplemented (possibly across lines, for multiline text input).\n• Scrolling of the text control has to be implemented (horizontally for long lines, vertically for multiline input).\n• Native features such as copy-and-paste have to be reimplemented.\n• Native features such as spell-checking have to be reimplemented.\n• Native features such as drag-and-drop have to be reimplemented.\n• Native features such as page-wide text search have to be reimplemented.\n• Native features specific to the user, for example custom text services, have to be reimplemented. This is close to impossible since each user might have different services installed, and there is an unbounded set of possible such services.\n• Bidirectional text editing has to be reimplemented.\n• For multiline text editing, line wrapping has to be implemented for all relevant languages.\n• Text selection has to be reimplemented.\n• Dragging of bidirectional text selections has to be reimplemented.\n• Platform-native keyboard shortcuts have to be reimplemented.\n• Platform-native input method editors (IMEs) have to be reimplemented.\n• Undo and redo functionality has to be reimplemented.\n• Accessibility features such as magnification following the caret or selection have to be reimplemented.\n\nThis is a huge amount of work, and authors are most strongly encouraged to avoid doing any of it by instead using the element, the element, or the attribute.\n\nis a performance-oriented interface that provides a low overhead method for displaying the contents of objects. It uses transfer semantics to reduce overall memory consumption. It also streamlines performance by avoiding intermediate compositing, unlike the method of .\n\nUsing an element as an intermediate for getting an image resource into a canvas, for example, would result in two copies of the decoded image existing in memory at the same time: the element's copy, and the one in the canvas's backing store. This memory cost can be prohibitive when dealing with extremely large images. This can be avoided by using .\n\nThe attribute must return the value it was initialized to when the object was created.\n\nAn object has an , which is a reference to bitmap data.\n\nAn object has a , which can be set to or . A value of valid indicates that the context's output bitmap refers to bitmap data that was acquired via . A value blank indicates that the context's output bitmap is a default transparent bitmap.\n\nAn object also has an flag, which can be set to true or false. When an object has its alpha flag set to false, the contents of the element to which the context is bound are obtained by compositing the context's output bitmap onto an opaque black bitmap of the same size using the source-over compositing operator. If the alpha flag is set to true, then the output bitmap is used as the contents of the element to which the context is bound. [COMPOSITE]\n\nThe step of compositing over an opaque black bitmap ought to be elided whenever equivalent results can be obtained more efficiently by other means.\n\nWhen a user agent is required to , with a argument that is an object and an optional argument that refers to bitmap data, it must run these steps:\n• None If a argument was not provided, then:\n• None Let be the element to which is bound.\n• None Set 's output bitmap to be transparent black with a natural width equal to the numeric value of 's attribute and a natural height equal to the numeric value of 's attribute, those values being interpreted in CSS pixels.\n• None If a argument was provided, then:\n• Set 's output bitmap to refer to the same underlying bitmap data as , without making a copy. The origin-clean flag of is included in the bitmap data to be referenced by 's output bitmap.\n\nThe , which is passed a and , consists of running these steps:\n• None Let be the result of converting to the dictionary type . (This can throw an exception.)\n• None Let be a new object.\n• None Set 's output bitmap to the same bitmap as 's bitmap (so that they are shared).\n• None Run the steps to set an 's output bitmap with .\n• Process each of the members of as follows: If false, then set 's alpha flag to false.\n\nThe method, when invoked, must run these steps:\n• None Let be the object on which the method was called.\n• None If is null, then run the steps to set an ImageBitmapRenderingContext's output bitmap, with as the argument and no argument, then return.\n• None If the value of 's [[Detached]] internal slot is set to true, then throw an \" \" .\n• None Run the steps to set an 's output bitmap, with the argument equal to , and the argument referring to 's underlying bitmap data.\n• None Set the value of 's [[Detached]] internal slot to true.\n\nis an , so both and WebGL can fire events at it. can fire and , and WebGL can fire and . [WEBGL]\n\nobjects are used to create rendering contexts, much like an , but with no connection to the DOM. This makes it possible to use canvas rendering contexts in workers.\n\nAn object may hold a weak reference to a , which is typically in the DOM, whose embedded content is provided by the object. The bitmap of the object is pushed to the placeholder element as part of the 's relevant agent's event loop's steps.\n\nAn object has an internal that is initialized when the object is created. The width and height of the bitmap are equal to the values of the and attributes of the object. Initially, all the bitmap's pixels are transparent black.\n\nAn object has an internal and set when the is created.\n\nAn object can have a rendering context bound to it. Initially, it does not have a bound rendering context. To keep track of whether it has a rendering context or not, and what kind of rendering context it is, an object also has a , which is initially but can be changed to either , , , , , or by algorithms defined in this specification.\n• None Initialize the bitmap of this to a rectangular array of transparent black pixels of the dimensions specified by and .\n• None Initialize the of this to .\n• None Initialize the of this to .\n• None Let be the relevant global object of this.\n• \n• None Let be the document element of 's associated .\n• If is not null:\n• None Set the inherited language of this to 's language.\n• None Set the inherited direction of this to 's directionality.\n\nobjects are transferable. Their transfer steps, given and , are as follows:\n• None If 's context mode is not equal to none, then throw an \" \" .\n• None Let and be the dimensions of 's bitmap.\n• None Let and be the values of 's inherited language and inherited direction.\n• None Set .[[Width]] to and .[[Height]] to .\n• None Set .[[Language]] to and .[[Direction]] to .\n• None Set .[[PlaceholderCanvas]] to be a weak reference to 's placeholder element, if has one, or null if it does not.\n\nTheir transfer-receiving steps, given and , are:\n• None Initialize 's bitmap to a rectangular array of transparent black pixels with width given by .[[Width]] and height given by .[[Height]].\n• None Set 's inherited language to .[[Language]] and inherited direction to .[[Direction]].\n• None If .[[PlaceholderCanvas]] is not null, set 's placeholder element to .[[PlaceholderCanvas]] (while maintaining the weak reference semantics).\n\nThe method of an object, when invoked, must run these steps:\n• None If is not an object, then set to null.\n• None Set to the result of converting to a JavaScript value.\n• Run the steps in the cell of the following table whose column header matches this object's context mode and whose row header matches :\n• None Let be the result of running the offscreen 2D context creation algorithm given this and . Return the same object as was returned the last time the method was invoked with this same first argument.\n• None Let be the result of running the creation algorithm given this and . Return the same object as was returned the last time the method was invoked with this same first argument.\n• None Let be the result of following the instructions given in the WebGL specifications' Context Creation sections. [WEBGL]\n• None If is null, then return null; otherwise set this's context mode to webgl or webgl2. Return the same value as was returned the last time the method was invoked with this same first argument.\n• None Let be the result of following the instructions given in 's Canvas Rendering section. [WEBGPU]\n• None If is null, then return null; otherwise set this's context mode to webgpu. Return the same value as was returned the last time the method was invoked with this same first argument.\n\nIf either the or attributes of an object are set (to a new value or to the same value as before) and the object's context mode is 2d, then reset the rendering context to its default state and resize the object's bitmap to the new values of the and attributes.\n\nThe resizing behavior for \" \" and \" \" contexts is defined in the WebGL specifications. [WEBGL]\n\nThe resizing behavior for \" \" context is defined in . [WEBGPU]\n\nIf an object whose dimensions were changed has a placeholder element, then the placeholder element's natural size will only be updated during the 's relevant agent's event loop's steps.\n• None If the value of this's [[Detached]] internal slot is true, then return a promise rejected with an \" \" .\n• None If this's context mode is 2d and the rendering context's output bitmap's origin-clean flag is set to false, then return a promise rejected with a \" \" .\n• None If this's bitmap has no pixels (i.e., either its horizontal dimension or its vertical dimension is zero), then return a promise rejected with an \" \" .\n• None Let be a copy of this's bitmap.\n• None Let be a new promise object.\n• \n• None Let be a serialization of as a file, with 's and if present.\n• Queue a global task on the canvas blob serialization task source given to run these steps:\n• None If is null, then reject with an \" \" .\n• None Otherwise, resolve with a new object, created in 's relevant realm, representing . [FILEAPI]\n\nThe method, when invoked, must run the following steps:\n• None If the value of this object's [[Detached]] internal slot is set to true, then throw an \" \" .\n• None If this object's context mode is set to none, then throw an \" \" .\n• None Let be a newly created object that references the same underlying bitmap data as this object's bitmap.\n• Set this object's bitmap to reference a newly created bitmap of the same dimensions and color space as the previous bitmap, and with its pixels initialized to transparent black, or opaque black if the rendering context's alpha is false. This means that if the rendering context of this is a , the value of will have no effect. [WEBGL]\n\nThe following are the event handlers (and their corresponding event handler event types) that must be supported, as event handler IDL attributes, by all objects implementing the interface:\n\nThe object is a rendering context for drawing to the bitmap of an object. It is similar to the object, with the following differences:\n• None there is no support for user interface features;\n• None its attribute refers to an object rather than a element;\n\nAn object has an , which is the object from which the object was created.\n\nThe , which is passed a (an object) and optionally some arguments, consists of running the following steps:\n• None If the algorithm was passed some arguments, let be the first such argument. Otherwise, let be undefined.\n• None Let be the result of converting to the dictionary type . (This can throw an exception.).\n• None Let be a new object.\n• None Run the canvas settings output bitmap initialization algorithm, given and .\n• None Set 's output bitmap to a newly created bitmap with the dimensions specified by the and attributes of , and set 's bitmap to the same bitmap (so that they are shared).\n• None If 's alpha flag is set to true, initialize all the pixels of 's output bitmap to transparent black. Otherwise, initialize the pixels to opaque black.\n\nImplementations are encouraged to short-circuit the graphics update steps of the window event loop for the purposes of updating the contents of a placeholder element to the display. This could mean, for example, that the bitmap contents are copied directly to a graphics buffer that is mapped to the physical display location of the placeholder element. This or similar short-circuiting approaches can significantly reduce display latency, especially in cases where the is updated from a worker event loop and the window event loop of the placeholder element is busy. However, such shortcuts cannot have any script-observable side-effects. This means that the committed bitmap still needs to be sent to the placeholder element, in case the element is used as a , as an , or in case or are called on it.\n\nThe attribute, on getting, must return this 's associated object.\n\nThe APIs provide mechanisms for specifying the color space of the canvas's backing store. The default backing store color space for all canvas APIs is 'srgb'.\n\nColor space conversion must be applied to the canvas's backing store when rendering the canvas to the output device. This color space conversion must be identical to the color space conversion that would be applied to an element with a color profile that specifies the same color space as the canvas's backing store.\n\nWhen drawing content to a 2D context, all inputs must be converted to the context's color space before drawing. Interpolation of gradient color stops must be performed on color values after conversion to the context's color space. Alpha blending must be performed on values after conversion to the context's color space.\n\nThere do not exist any inputs to a 2D context for which the color space is undefined. The color space for CSS colors is defined in . The color space for images that specify no color profile information is assumed to be 'srgb', as specified in the Color Spaces of Untagged Colors section of . [CSSCOLOR]\n\nWhen a user agent is to create a serialization of the bitmap as a file , given a and an optional , it must create an image file in the format given by . If an error occurs during the creation of the image file (e.g. an internal encoder error), then the result of the serialization is null. [PNG]\n\nThe image file's pixel data must be the bitmap's pixel data scaled to one image pixel per coordinate space unit, and if the file format used supports encoding resolution metadata, the resolution must be given as 96dpi (one image pixel per CSS pixel).\n\nIf is supplied, then it must be interpreted as a MIME type giving the format to use. If the type has any parameters, then it must be treated as not supported.\n\nFor example, the value \" \" would mean to generate a PNG image, the value \" \" would mean to generate a JPEG image, and the value \" \" would mean to generate an SVG image (which would require that the user agent track how the bitmap was generated, an unlikely, though potentially awesome, feature).\n\nUser agents must support PNG (\" \"). User agents may support other types. If the user agent does not support the requested type, then it must create the file using the PNG format. [PNG]\n\nUser agents must convert the provided type to ASCII lowercase before establishing if they support that type.\n\nFor image types that do not support an alpha component, the serialized image must be the bitmap image composited onto an opaque black background using the source-over compositing operator.\n\nFor image types that support color profiles, the serialized image must include a color profile indicating the color space of the underlying bitmap. For image types that do not support color profiles, the serialized image must be converted to the 'srgb' color space using 'relative-colorimetric' rendering intent.\n\nThus, in the 2D context, calling the method to render the output of the or method to the canvas, given the appropriate dimensions, has no visible effect beyond, at most, clipping colors of the canvas to a more narrow gamut.\n\nFor image types that support multiple bit depths, the serialized image must use the bit depth that best preserves content of the underlying bitmap.\n\nFor example, when serializing a 2D context that has color type of float16 to \" \", the resulting image would have 16 bits per sample. This serialization will still lose significant detail (all values less than 0.5/65535 would be clamped to 0, and all values greater than 1 would be clamped to 1).\n\nIf is an image format that supports variable quality (such as \" \"), is given, and is not \" \", then, if is a Number in the range 0.0 to 1.0 inclusive, the user agent must treat as the desired quality level. Otherwise, the user agent must use its default quality value, as if the argument had not been given.\n\nThe use of type-testing here, instead of simply declaring as a Web IDL , is a historical artifact.\n\nDifferent implementations can have slightly different interpretations of \"quality\". When the quality is not specified, an implementation-specific default is used that represents a reasonable compromise between compression ratio, image quality, and encoding time.\n\nInformation leakage can occur if scripts from one origin can access information (e.g. read pixels) from images from another origin (one that isn't the same).\n\nTo mitigate this, bitmaps used with elements, objects, and objects are defined to have a flag indicating whether they are origin-clean. All bitmaps start with their origin-clean set to true. The flag is set to false when cross-origin images are used.\n\nThe , , and methods check the flag and will throw a \" \" rather than leak cross-origin data.\n\nThe value of the origin-clean flag is propagated from a source's bitmap to a new object by . Conversely, a destination element's bitmap will have its origin-clean flags set to false by if the source image is an object whose bitmap has its origin-clean flag set to false.\n\nThe flag can be reset in certain situations; for example, when changing the value of the or the content attribute of the element to which a is bound, the bitmap is cleared and its origin-clean flag is reset.\n\nWhen using an , the value of the origin-clean flag is propagated from objects when they are transferred to the via transferFromImageBitmap().\n\nrefers to one way of representing transparency in an image, the other being non-premultiplied alpha.\n\nUnder non-premultiplied alpha, the red, green, and blue components of a pixel represent that pixel's color, and its alpha component represents that pixel's opacity.\n\nUnder premultiplied alpha, however, the red, green, and blue components of a pixel represent the amounts of color that the pixel adds to the image, and its alpha component represents the amount that the pixel obscures whatever is behind it.\n\nConverting a color value from a non-premultiplied representation to a premultiplied one involves multiplying the color's red, green, and blue components by its alpha component (remapping the range of the alpha component such that \"fully transparent\" is 0, and \"fully opaque\" is 1).\n\nConverting a color value from a premultiplied representation to a non-premultiplied one involves the inverse: dividing the color's red, green, and blue components by its alpha component.\n\nAs certain colors can only be represented under premultiplied alpha (for instance, additive colors), and others can only be represented under non-premultiplied alpha (for instance, \"invisible\" colors which hold certain red, green, and blue values even with no opacity); and division and multiplication using finite precision entails a loss of accuracy, converting between premultiplied and non-premultiplied alpha is a lossy operation on colors that are not fully opaque.\n\nA 's output bitmap and an 's output bitmap must use premultiplied alpha to represent transparent colors.\n\nIt is important for canvas bitmaps to represent colors using premultiplied alpha because it affects the range of representable colors. While additive colors cannot currently be drawn onto canvases directly because CSS colors are non-premultiplied and cannot represent them, it is still possible to, for instance, draw additive colors onto a WebGL canvas and then draw that WebGL canvas onto a 2D canvas via ."
    },
    {
        "link": "https://stackoverflow.com/questions/901677/the-definitive-best-way-to-preload-images-using-javascript-jquery",
        "document": "Unfortunately, that depends on your purpose. If you plan to use the images for purposes of style, your best bet is to use sprites. http://www.alistapart.com/articles/sprites2\n\nHowever, if you plan to use the images in <img> tags, then you'll want to pre-load them with\n\nusing does not involve the expense of using DOM methods but a new request for the image specified will be added to the queue. As the image is, at this point, not actually added to the page, there is no re-rendering involved. I would recommend, however, adding this to the end of your page (as all of your scripts should be, when possible) to prevent it from holding up more critical elements.\n\nEdit: Edited to reflect comment quite correctly pointing out that separate objects are required to work properly. Thanks, and my bad for not checking it more closely.\n\nEdit2: edited to make the reusability more obvious\n\nDue to changes in how browsers handle non-visible images (display:none or, as in this answer, never appended to the document) a new approach to pre-loading is preferred.\n\nYou can use an Ajax request to force early retrieval of images. Using jQuery, for example:\n\nOr in the context of our previous example, you could do:\n\nNote that this doesn't apply to the case of sprites which are fine as-is. This is just for things like photo galleries or sliders/carousels with images where the images aren't loading because they are not visible initially.\n\nAlso note that this method does not work for IE (ajax is normally not used to retrieve image data)."
    },
    {
        "link": "https://stackoverflow.com/questions/3646036/preloading-images-with-javascript",
        "document": "I can confirm that the approach in the question is sufficient to trigger the images to be downloaded and cached (unless you have forbidden the browser from doing so via your response headers) in, at least:\n\nTo test this, I made a small webapp with several endpoints that each sleep for 10 seconds before serving a picture of a kitten. Then I added two webpages, one of which contained a tag in which each of the kittens is preloaded using the function from the question, and the other of which includes all the kittens on the page using tags.\n\nIn all the browsers above, I found that if I visited the preloader page first, waited a while, and then went to the page with the tags, my kittens rendered instantly. This demonstrates that the preloader successfully loaded the kittens into the cache in all browsers tested.\n\nYou can see or try out the application I used to test this at https://github.com/ExplodingCabbage/preloadImage-test.\n\nNote in particular that this technique works in the browsers above even if the number of images being looped over exceeds the number of parallel requests that the browser is willing to make at a time, contrary to what Robin's answer suggests. The rate at which your images preload will of course be limited by how many parallel requests the browser is willing to send, but it will eventually request each image URL you call on."
    },
    {
        "link": "https://techrepublic.com/article/preloading-and-the-javascript-image-object",
        "document": "Lots of high-res images can really spruce up a Web site. But\n\n they can also slow it down—images are files, files use bandwidth, and bandwidth\n\n is directly related to wait times. It’s time you get yourself an education on\n\n how to speed things up with a little trick called image preloading.\n\nThe way a browser normally works, images are loaded only\n\n after an HTTP request is sent for them, either passively via an <img> tag\n\n or actively through a method call. So if you have JavaScript that swaps an image\n\n on mouseover, or changes an image automatically after a timeout, you can expect\n\n to wait anywhere from a few seconds to a few minutes while the image is\n\n retrieved from the server. This is especially noticeable if you have a slow\n\n connection to the Internet, or if the images being retrieved are very\n\n large…and the delay usually ruins the effect you were hoping for.\n\nSome browsers try to mitigate this problem by storing the\n\n images in the local cache so that subsequent calls to the image are satisfied\n\n immediately…but there’s still a delay the very first time the image is\n\n needed. Preloading is a technique where the image is downloaded to the cache\n\n before it’s needed. That way when the image is really needed it can be\n\n retrieved from the cache and displayed immediately.\n\nThe simplest way to preload an image is to instantiate a new\n\n Image() object in JavaScript and pass it the URL of the image you want\n\n preloaded. Say we have an image called heavyimagefile.jpg, which we want to\n\n display when the user mouses over an already-displayed image. In order to\n\n preload this image for faster response time, we simply create a new Image()\n\n object, called heavyImage, and load\n\n it simultaneously to the page with the onLoad() event handler:\n\nNote that the image tag does not itself handle onMouseOver()\n\n and onMouseOut() events, which is why the <img> tag in the example above\n\n has been enclosed in an <a> tag, which does include support for those\n\n event types.\n\nIn practice, you will probably need to preload more than\n\n just one image; for example, in a menu bar containing multiple image rollovers,\n\n or if you’re trying to create a smooth animation effect. This is not difficult;\n\n all you need to do is make use of JavaScript’s arrays, as in the example below:\n\nIn the above example, you define a variable i and an Image() object cleverly named imageObj. You then define a new array\n\n called images[], where each array\n\n element stores the source of the image to be preloaded. Finally, you create a\n\n for() loop to cycle through the array and assign each one of them to the\n\n Image() object, thus preloading it into the cache.\n\nLike many other objects in JavaScript, the Image() object\n\n also comes with some event handlers. The most useful of these is undoubtedly\n\n the onLoad() handler, which is invoked when the image has completed loading.\n\n This handler can be hooked up with a custom function to perform specific tasks\n\n after the image has completed loading. The following example illustrates this\n\n by displaying a “please wait” screen while the image loads, and then\n\n sending the browser to a new URL once it’s finished loading.\n\nOf course, you can also create an array of images and loop\n\n over it, preloading each one and keeping track of the number of images loaded\n\n at each stage. Once all the images are loaded, the event handler can be\n\n programmed to take the browser to the next page (or do any other task).\n\nNow, how about using all the theory you just learned in an\n\n actual application? This next one is a little piece of code I recently had\n\n occasion to write – a menu bar consisting of buttons (image links), each of\n\n which can be in any one of three states: normal, hover and click. Since the\n\n buttons have multiple states, it is necessary to use image preloading to ensure\n\n that the menu responds quickly to changes in its state. The code in Listing A illustrates this.\n\nThe HTML code in Listing A sets up a menu bar consisting of\n\n four buttons, each of which has thee states: normal, hover, and click. The\n\n requirements are as follows:\n• On\n\n mouse move over a button in normal state, it changes to hover state. On\n\n mouse out, it goes back to normal state.\n• On\n\n mouse click on a button, it changes to its click state. It remains in this\n\n state until another button is clicked.\n• If a\n\n button is clicked, no other button may be in click state. Other buttons\n\n can only be in their hover or normal states.\n• Only\n\n one button may be clicked at a time.\n• Only\n\n one button can be in hover state at a time.\n\nThe first task is to set up arrays holding the images for\n\n each state of the menu. The <img> elements corresponding to these array\n\n elements are also created in the HTML document body, and named sequentially.\n\n Note that array values are indexed starting from 0, while the corresponding\n\n <img> elements are named starting from 1—this gives rise to certain\n\n calculation adjustments in the latter half of the script.\n\nThe preloadImages() function takes care of loading all the\n\n images into the cache, so that response time on mouse movement is minimal. A\n\n for() loop is used to iterate over the images created in the first step and\n\n preload each one.\n\nThe resetAll() function is a convenient way to reset all the\n\n images to their normal state. This is necessary because, when an item of the\n\n menu is clicked, all other items in the menu must revert to their normal state\n\n before the clicked item can change to its click state.\n\nThe setNormal(), setHover() and setClick() functions take\n\n care of changing the source of a particular image (image number passed as\n\n function argument) to its normal, hover, or click state respectively. Since\n\n images which are clicked must remain in that state until another image is\n\n clicked (see rule #2), they are temporarily immune to mouse movements; thus,\n\n the setNormal() and setHover() functions include code to only change a button’s\n\n state if it is not already in its click state.\n\nThe above is just one of the many ways in which preloading\n\n can help you speed up the response time of your JavaScript effects. Use the\n\n techniques outlined above in your site, and alter them where needed to fit your\n\n requirements. Good luck!"
    },
    {
        "link": "https://bennadel.com/blog/2597-preloading-images-in-angularjs-with-promises.htm",
        "document": "When I first started using AngularJS, I was so concerned with doing things the, \"Angular Way,\" that I ended up making some poor choices. Most noticeably was the way in which I tried to preload images in my application. Thinking only of images as \"DOM\" (Document Object Model) elements, I delegated all of my preloading to the rendered HTML. But, the reality is, Image objects can exist without being attached to the DOM. And, when you start thinking about them as containers for asynchronous data loading (much like AJAX), preloading images in AngularJS becomes a whole lot easier.\n\nRun this demo in my JavaScript Demos project on GitHub.\n\nIn AngularJS, your Controllers and your Services are not supposed to know anything about the DOM (Document Object Model) or about your HTML. Their only role is to model the business logic and define behaviors for your application. If you need to do something with the DOM, you're supposed to use a View or a Directive.\n\nAs such, if you need to do something with Images, your first thought is probably that they are HTML IMG tags, and, therefore, you need to isolate image loading in a View or a Directive. But this is an over-simplified understanding of images. If you break the image lifecycle into two parts - image loading and image rendering - you can start to see that part of the image lifecycle is about the data model and, therefore, can be handled by either a Controller or, more appropriately, by a Service.\n\nIn the following demo, I am using AngularJS to render an ngRepeat list of images. But, before I execute the rendering (via Directive), I'm preloading the image binaries using a Preload service. The Preload service takes an array of source values and returns a promise. The promise is resolved when all of the image binaries have been preloaded.\n\nTrying to preload images directly in your HTML is going to make your HTML harder to read, understand, and maintain. Leave the rendering of images up to your HTML; but, if you need to preload images in your AngularJS application, do that in your business logic - the same way you would request non-binary JSON (JavaScript Object Notation) data from the server.\n\nWant to use code from this post? Check out the license."
    },
    {
        "link": "https://web.dev/articles/preload-responsive-images",
        "document": "You can preload responsive images, which can let your images load significantly faster by helping the browser identify the correct image from a before it renders the tag.\n\nSuppose you're browsing the web on a screen that's 300 pixels wide, and the page requests an image 1500 pixels wide. That page has wasted a lot of your mobile data because your screen can't do anything with all that extra resolution. Ideally, the browser would fetch a version of the image that's just a little wider than your screen size, for example, 325 pixels. This ensures a high-resolution image without wasting data, and lets the image load faster.\n\nResponsive images let browsers fetch different image resources for different devices. If you don't use an image CDN, save multiple dimensions for each image and specify them in the attribute. The value tells the browser the width of each version, so it can choose the appropriate version for any device:\n\nPreloading lets you tell the browser about critical resources that you want to load as soon as possible, before they're discovered in HTML. This is especially useful for resources that aren't readily discoverable, such as fonts included in stylesheets, background images, or resources loaded from a script.\n\nThe element uses the and attributes to preload responsive images. Use them alongside , with the and syntax used in the element.\n\nFor example, if you want to preload a responsive image specified with:\n\nYou can do that by adding the following to your HTML's :\n\nThis initiates a request using the same resource selection logic that and use.\n\nThe following are some use cases for preloading responsive images.\n\nImagine you're dynamically-loading hero images as part of a slideshow, and you know which image will be displayed first. In that case, you probably want to show that image as soon as possible, and not wait for the slideshow script to load it.\n\nYou can inspect this issue on a website with a dynamically-loaded image gallery:\n• Open this slideshow demo in a new tab.\n• Press (or on Mac) to open DevTools.\n\nUsing here lets the image start loading ahead of time, so it can be ready to display when the browser needs to display it.\n\nTo see the difference that preloading makes, inspect the same dynamically-loaded image gallery but with the first image preloaded by following the steps from the first example.\n\nIf you have different background images for different screen densities, you can specify them in your CSS with the syntax. The browser can then choose which one to display based on the screen's DPR.\n\nThe problem with CSS background images is that the browser discovers them only after it has downloaded and processed all the CSS in the page's .\n\nYou can inspect this issue on an example website with a responsive background image.\n\nLeaving out the attribute lets you ensure that browsers that don't support on the element, but do support in CSS download the correct source. However, they won't benefit from the preload in this case.\n\nYou can inspect how the previous example behaves with a preloaded responsive background image in the responsive background preload demo.\n\nPreloading your responsive images can speed them up in theory, but what does it do in practice?\n\nTo answer that I created two copies of a demo PWA shop: one that doesn't preload images, and one that preloads some of them. Because the site lazy loads images using JavaScript, it's likely to benefit from preloading the ones that appear in the initial viewport.\n\nThat produced the following results for no preload and for image preload:\n• Speed Index improved slightly (273 ms, as images arrive faster don't take up a huge chunk of the pixel area).\n\nThe Web Performance Working Group is discussing adding a preload equivalent for and , but not the element, which handles the \"art direction\" use case.\n\nThere are still a number of technical issues to sort out for preloading , but in the meantime, there are workarounds:\n\nThe element's image source selection logic goes over the attributes of the elements in order, finds the first one that matches, and uses the attached resource.\n\nBecause responsive preload has no notion of \"order\" or \"first match\", you'll need to translate the breakpoints into something like the following:\n\nThe element also supports matching on the first , to let you provide different image formats so the browser can pick the first image format it supports. This use case isn't supported with preload.\n\nFor sites using type matching, we recommend avoiding preload, and instead having the preload scanner pick up the images from the and elements instead. This is a best practice anyway, especially when using Fetch Priority for help prioritizing the appropriate image.\n\nBecause images can be Largest Contentful Paint (LCP) candidates, preloading them can improve your website's LCP.\n\nRegardless of whether the image you're preloading is responsive, preloads work best when the image resource isn't discoverable in the initial markup payload. You'll also get more LCP improvement on sites that render markup on the client side than on sites that send complete markup from the server."
    }
]