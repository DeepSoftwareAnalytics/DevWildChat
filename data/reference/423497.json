[
    {
        "link": "https://developer.android.com/media/camera/camera-deprecated/camera-api",
        "document": "Stay organized with collections Save and categorize content based on your preferences.\n\nThe Android framework includes support for various cameras and camera features available on devices, allowing you to capture pictures and videos in your applications. This document discusses a quick, simple approach to image and video capture and outlines an advanced approach for creating custom camera experiences for your users.\n\nNote: This page describes the class, which has been deprecated. We recommend using the CameraX Jetpack library or, for specific use cases, the , class. Both CameraX and Camera2 work on Android 5.0 (API level 21) and higher.\n\nBefore enabling your application to use cameras on Android devices, you should consider a few questions about how your app intends to use this hardware feature.\n• Camera Requirement - Is the use of a camera so important to your application that you do not want your application installed on a device that does not have a camera? If so, you should declare the camera requirement in your manifest.\n• Quick Picture or Customized Camera - How will your application use the camera? Are you just interested in snapping a quick picture or video clip, or will your application provide a new way to use cameras? For getting a quick snap or clip, consider Using Existing Camera Apps. For developing a customized camera feature, check out the Building a Camera App section.\n• Foreground Services Requirement - When does your app interact with the camera? On Android 9 (API level 28) and later, apps running in the background cannot access the camera. Therefore, you should use the camera either when your app is in the foreground or as part of a foreground service.\n• Storage - Are the images or videos your application generates intended to be only visible to your application or shared so that other applications such as Gallery or other media and social apps can use them? Do you want the pictures and videos to be available even if your application is uninstalled? Check out the Saving Media Files section to see how to implement these options.\n\nThe Android framework supports capturing images and video through the API or camera . Here are the relevant classes:\n\nBefore starting development on your application with the Camera API, you should make sure your manifest has the appropriate declarations to allow use of camera hardware and other related features.\n• Camera Permission - Your application must request permission to use a device camera. Note: If you are using the camera by invoking an existing camera app, your application does not need to request this permission.\n• Camera Features - Your application must also declare use of camera features, for example: For a list of camera features, see the manifest Features Reference. Adding camera features to your manifest causes Google Play to prevent your application from being installed to devices that do not include a camera or do not support the camera features you specify. For more information about using feature-based filtering with Google Play, see Google Play and Feature-Based Filtering. If your application can use a camera or camera feature for proper operation, but does not require it, you should specify this in the manifest by including the attribute, and setting it to :\n• Storage Permission - Your application can save images or videos to the device's external storage (SD Card) if it targets Android 10 (API level 29) or lower and specifies the following in the manifest.\n• Audio Recording Permission - For recording audio with video capture, your application must request the audio capture permission.\n• Location Permission - If your application tags images with GPS location information, you must request the permission. Note that, if your app targets Android 5.0 (API level 21) or higher, you also need to declare that your app uses the device's GPS: <uses-permission android:name=\"android.permission.ACCESS_FINE_LOCATION\" /> ... <!-- Needed only if your app targets Android 5.0 (API level 21) or higher. --> <uses-feature android:name=\"android.hardware.location.gps\" /> For more information about getting user location, see Location Strategies.\n\nA quick way to enable taking pictures or videos in your application without a lot of extra code is to use an to invoke an existing Android camera application. The details are described in the training lessons Taking Photos Simply and Recording Videos Simply.\n\nSome developers may require a camera user interface that is customized to the look of their application or provides special features. Writing your own picture-taking code can provide a more compelling experience for your users.\n\nNote: The following guide is for the older, deprecated API. For new or advanced camera applications, the newer API is recommended.\n\nThe general steps for creating a custom camera interface for your application are as follows:\n• Detect and Access Camera - Create code to check for the existence of cameras and request access.\n• Create a Preview Class - Create a camera preview class that extends and implements the interface. This class previews the live images from the camera.\n• Build a Preview Layout - Once you have the camera preview class, create a view layout that incorporates the preview and the user interface controls you want.\n• Setup Listeners for Capture - Connect listeners for your interface controls to start image or video capture in response to user actions, such as pressing a button.\n• Capture and Save Files - Setup the code for capturing pictures or videos and saving the output.\n• Release the Camera - After using the camera, your application must properly release it for use by other applications.\n\nCamera hardware is a shared resource that must be carefully managed so your application does not collide with other applications that may also want to use it. The following sections discusses how to detect camera hardware, how to request access to a camera, how to capture pictures or video and how to release the camera when your application is done using it.\n\nCaution: Remember to release the object by calling the when your application is done using it! If your application does not properly release the camera, all subsequent attempts to access the camera, including those by your own application, will fail and may cause your or other applications to be shut down.\n\nIf your application does not specifically require a camera using a manifest declaration, you should check to see if a camera is available at runtime. To perform this check, use the method, as shown in the example code below:\n\nAndroid devices can have multiple cameras, for example a back-facing camera for photography and a front-facing camera for video calls. Android 2.3 (API Level 9) and later allows you to check the number of cameras available on a device using the method.\n\nIf you have determined that the device on which your application is running has a camera, you must request to access it by getting an instance of (unless you are using an intent to access the camera).\n\nTo access the primary camera, use the method and be sure to catch any exceptions, as shown in the code below:\n\nCaution: Always check for exceptions when using . Failing to check for exceptions if the camera is in use or does not exist will cause your application to be shut down by the system.\n\nOn devices running Android 2.3 (API Level 9) or higher, you can access specific cameras using . The example code above will access the first, back-facing camera on a device with more than one camera.\n\nOnce you obtain access to a camera, you can get further information about its capabilities using the method and checking the returned object for supported capabilities. When using API Level 9 or higher, use the to determine if a camera is on the front or back of the device, and the orientation of the image.\n\nFor users to effectively take pictures or video, they must be able to see what the device camera sees. A camera preview class is a that can display the live image data coming from a camera, so users can frame and capture a picture or video.\n\nThe following example code demonstrates how to create a basic camera preview class that can be included in a layout. This class implements in order to capture the callback events for creating and destroying the view, which are needed for assigning the camera preview input.\n\nIf you want to set a specific size for your camera preview, set this in the method as noted in the comments above. When setting preview size, you must use values from . Do not set arbitrary values in the method.\n\nNote: With the introduction of the Multi-Window feature in Android 7.0 (API level 24) and higher, you can no longer assume the aspect ratio of the preview is the same as your activity even after calling . Depending on the window size and aspect ratio, you may may have to fit a wide camera preview into a portrait-orientated layout, or vice versa, using a letterbox layout.\n\nA camera preview class, such as the example shown in the previous section, must be placed in the layout of an activity along with other user interface controls for taking a picture or video. This section shows you how to build a basic layout and activity for the preview.\n\nThe following layout code provides a very basic view that can be used to display a camera preview. In this example, the element is meant to be the container for the camera preview class. This layout type is used so that additional picture information or controls can be overlaid on the live camera preview images.\n\nOn most devices, the default orientation of the camera preview is landscape. This example layout specifies a horizontal (landscape) layout and the code below fixes the orientation of the application to landscape. For simplicity in rendering a camera preview, you should change your application's preview activity orientation to landscape by adding the following to your manifest.\n\nNote: A camera preview does not have to be in landscape mode. Starting in Android 2.2 (API Level 8), you can use the method to set the rotation of the preview image. In order to change preview orientation as the user re-orients the phone, within the method of your preview class, first stop the preview with change the orientation and then start the preview again with .\n\nIn the activity for your camera view, add your preview class to the element shown in the example above. Your camera activity must also ensure that it releases the camera when it is paused or shut down. The following example shows how to modify a camera activity to attach the preview class shown in Creating a preview class.\n\nNote: The method in the example above refers to the example method shown in Accessing cameras.\n\nOnce you have built a preview class and a view layout in which to display it, you are ready to start capturing images with your application. In your application code, you must set up listeners for your user interface controls to respond to a user action by taking a picture.\n\nIn order to retrieve a picture, use the method. This method takes three parameters which receive data from the camera. In order to receive data in a JPEG format, you must implement an interface to receive the image data and write it to a file. The following code shows a basic implementation of the interface to save an image received from the camera.\n\nTrigger capturing an image by calling the method. The following example code shows how to call this method from a button .\n\nNote: The member in the following example refers to the example code above.\n\nCaution: Remember to release the object by calling the when your application is done using it! For information about how to release the camera, see Releasing the camera.\n\nVideo capture using the Android framework requires careful management of the object and coordination with the class. When recording video with , you must manage the and calls to allow access to the camera hardware, in addition to the and calls.\n\nNote: Starting with Android 4.0 (API level 14), the and calls are managed for you automatically.\n\nUnlike taking pictures with a device camera, capturing video requires a very particular call order. You must follow a specific order of execution to successfully prepare for and capture video with your application, as detailed below.\n• Open Camera - Use the to get an instance of the camera object.\n• Connect Preview - Prepare a live camera image preview by connecting a to the camera using .\n• Start Recording Video - The following steps must be completed in order to successfully record video:\n• Unlock the Camera - Unlock the camera for use by by calling .\n• Configure MediaRecorder - Call in the following methods in this order. For more information, see the reference documentation.\n• - Set the camera to be used for video capture, use your application's current instance of .\n• Set the video output format and encoding. For Android 2.2 (API Level 8) and higher, use the method, and get a profile instance using . For versions of Android prior to 2.2, you must set the video output format and encoding parameters:\n• - Set the output format, specify the default setting or .\n• - Set the sound encoding type, specify the default setting or .\n• - Set the video encoding type, specify the default setting or .\n• - Set the output file, use from the example method in the Saving Media Files section.\n• - Specify the preview layout element for your application. Use the same object you specified for Connect Preview. Caution: You must call these configuration methods in this order, otherwise your application will encounter errors and the recording will fail.\n• Prepare MediaRecorder - Prepare the with provided configuration settings by calling .\n• Stop Recording Video - Call the following methods in order, to successfully complete a video recording:\n• Reset MediaRecorder - Optionally, remove the configuration settings from the recorder by calling .\n• Lock the Camera - Lock the camera so that future sessions can use it by calling . Starting with Android 4.0 (API level 14), this call is not required unless the call fails.\n• Stop the Preview - When your activity has finished using the camera, stop the preview using .\n• Release Camera - Release the camera so that other applications can use it by calling .\n\nNote: It is possible to use without creating a camera preview first and skip the first few steps of this process. However, since users typically prefer to see a preview before starting a recording, that process is not discussed here.\n\nTip: If your application is typically used for recording video, set to prior to starting your preview. This setting can help reduce the time it takes to start recording.\n\nWhen using the class to record video, you must perform configuration steps in a specific order and then call the method to check and implement the configuration. The following example code demonstrates how to properly configure and prepare the class for video recording.\n\nPrior to Android 2.2 (API Level 8), you must set the output format and encoding formats parameters directly, instead of using . This approach is demonstrated in the following code:\n\nThe following video recording parameters for are given default settings, however, you may want to adjust these settings for your application:\n\nWhen starting and stopping video recording using the class, you must follow a specific order, as listed below.\n• Configure as shown in the code example above\n\nThe following example code demonstrates how to wire up a button to properly start and stop video recording using the camera and the class.\n\nNote: When completing a video recording, do not release the camera or else your preview will be stopped.\n\nNote: In the above example, the method refers to the example code shown in Configuring MediaRecorder. This method takes care of locking the camera, configuring and preparing the instance.\n\nCameras are a resource that is shared by applications on a device. Your application can make use of the camera after getting an instance of , and you must be particularly careful to release the camera object when your application stops using it, and as soon as your application is paused ( ). If your application does not properly release the camera, all subsequent attempts to access the camera, including those by your own application, will fail and may cause your or other applications to be shut down.\n\nTo release an instance of the object, use the method, as shown in the example code below.\n\nCaution: If your application does not properly release the camera, all subsequent attempts to access the camera, including those by your own application, will fail and may cause your or other applications to be shut down.\n\nMedia files created by users such as pictures and videos should be saved to a device's external storage directory (SD Card) to conserve system space and to allow users to access these files without their device. There are many possible directory locations to save media files on a device, however there are only two standard locations you should consider as a developer:\n• ( ) - This method returns the standard, shared and recommended location for saving pictures and videos. This directory is shared (public), so other applications can easily discover, read, change and delete files saved in this location. If your application is uninstalled by the user, media files saved to this location will not be removed. To avoid interfering with users existing pictures and videos, you should create a sub-directory for your application's media files within this directory, as shown in the code sample below. This method is available in Android 2.2 (API Level 8), for equivalent calls in earlier API versions, see Saving Shared Files.\n• ( ) - This method returns a standard location for saving pictures and videos which are associated with your application. If your application is uninstalled, any files saved in this location are removed. Security is not enforced for files in this location and other applications may read, change and delete them.\n\nThe following example code demonstrates how to create a or location for a media file that can be used when invoking a device's camera with an or as part of a Building a Camera App.\n\nNote: is available in Android 2.2 (API Level 8) or higher. If you are targeting devices with earlier versions of Android, use instead. For more information, see Saving Shared Files.\n\nTo make the URI support work profiles, first convert the file URI to a content URI. Then, add the content URI to of an .\n\nFor more information about saving files on an Android device, see Data Storage.\n\nAndroid supports a wide array of camera features you can control with your camera application, such as picture format, flash mode, focus settings, and many more. This section lists the common camera features, and briefly discusses how to use them. Most camera features can be accessed and set using the through object. However, there are several important features that require more than simple settings in . These features are covered in the following sections:\n\nFor general information about how to use features that are controlled through , review the Using camera features section. For more detailed information about how to use features controlled through the camera parameters object, follow the links in the feature list below to the API reference documentation.\n\nTable 1. Common camera features sorted by the Android API Level in which they were introduced.\n\nNote: These features are not supported on all devices due to hardware differences and software implementation. For information on checking the availability of features on the device where your application is running, see Checking feature availability.\n\nThe first thing to understand when setting out to use camera features on Android devices is that not all camera features are supported on all devices. In addition, devices that support a particular feature may support them to different levels or with different options. Therefore, part of your decision process as you develop a camera application is to decide what camera features you want to support and to what level. After making that decision, you should plan on including code in your camera application that checks to see if device hardware supports those features and fails gracefully if a feature is not available.\n\nYou can check the availability of camera features by getting an instance of a camera's parameters object, and checking the relevant methods. The following code sample shows you how to obtain a object and check if the camera supports the autofocus feature:\n\nYou can use the technique shown above for most camera features. The object provides a , or method to determine if (and to what extent) a feature is supported.\n\nIf your application requires certain camera features in order to function properly, you can require them through additions to your application manifest. When you declare the use of specific camera features, such as flash and auto-focus, Google Play restricts your application from being installed on devices which do not support these features. For a list of camera features that can be declared in your app manifest, see the manifest Features Reference.\n\nMost camera features are activated and controlled using a object. You obtain this object by first getting an instance of the object, calling the method, changing the returned parameter object and then setting it back into the camera object, as demonstrated in the following example code:\n\nThis technique works for nearly all camera features, and most parameters can be changed at any time after you have obtained an instance of the object. Changes to parameters are typically visible to the user immediately in the application's camera preview. On the software side, parameter changes may take several frames to actually take effect as the camera hardware processes the new instructions and then sends updated image data.\n\nImportant: Some camera features cannot be changed at will. In particular, changing the size or orientation of the camera preview requires that you first stop the preview, change the preview size, and then restart the preview. Starting with Android 4.0 (API Level 14) preview orientation can be changed without restarting the preview.\n\nOther camera features require more code in order to implement, including:\n\nA quick outline of how to implement these features is provided in the following sections.\n\nIn some photographic scenarios, automatic focusing and light metering may not produce the desired results. Starting with Android 4.0 (API Level 14), your camera application can provide additional controls to allow your app or users to specify areas in an image to use for determining focus or light level settings and pass these values to the camera hardware for use in capturing images or video.\n\nAreas for metering and focus work very similarly to other camera features, in that you control them through methods in the object. The following code demonstrates setting two light metering areas for an instance of :\n\nThe object contains two data parameters: A object for specifying an area within the camera's field of view and a weight value, which tells the camera what level of importance this area should be given in light metering or focus calculations.\n\nThe field in a object describes a rectangular shape mapped on a 2000 x 2000 unit grid. The coordinates -1000, -1000 represent the top, left corner of the camera image, and coordinates 1000, 1000 represent the bottom, right corner of the camera image, as shown in the illustration below.\n\nFigure 1. The red lines illustrate the coordinate system for specifying a within a camera preview. The blue box shows the location and shape of an camera area with the values 333,333,667,667.\n\nThe bounds of this coordinate system always correspond to the outer edge of the image visible in the camera preview and do not shrink or expand with the zoom level. Similarly, rotation of the image preview using does not remap the coordinate system.\n\nFor pictures that include people, faces are usually the most important part of the picture, and should be used for determining both focus and white balance when capturing an image. The Android 4.0 (API Level 14) framework provides APIs for identifying faces and calculating picture settings using face recognition technology.\n\nNote: While the face detection feature is running, , and have no effect.\n\nUsing the face detection feature in your camera application requires a few general steps:\n• Check that face detection is supported on the device\n• Add the face detection listener to your camera object\n• Start face detection after preview (and after every preview restart)\n\nThe face detection feature is not supported on all devices. You can check that this feature is supported by calling . An example of this check is shown in the sample method below.\n\nIn order to be notified and respond to the detection of a face, your camera application must set a listener for face detection events. In order to do this, you must create a listener class that implements the interface as shown in the example code below.\n\nAfter creating this class, you then set it into your application's object, as shown in the example code below:\n\nYour application must start the face detection function each time you start (or restart) the camera preview. Create a method for starting face detection so you can call it as needed, as shown in the example code below.\n\nYou must start face detection each time you start (or restart) the camera preview. If you use the preview class shown in Creating a preview class, add your method to both the and methods in your preview class, as shown in the sample code below.\n\nNote: Remember to call this method after calling . Do not attempt to start face detection in the method of your camera app's main activity, as the preview is not available by this point in your application's the execution.\n\nTime lapse video allows users to create video clips that combine pictures taken a few seconds or minutes apart. This feature uses to record the images for a time lapse sequence.\n\nTo record a time lapse video with , you must configure the recorder object as if you are recording a normal video, setting the captured frames per second to a low number and using one of the time lapse quality settings, as shown in the code example below.\n\nThese settings must be done as part of a larger configuration procedure for . For a full configuration code example, see Configuring MediaRecorder. Once the configuration is complete, you start the video recording as if you were recording a normal video clip. For more information about configuring and running , see Capturing videos.\n\nThe Camera2Video and HdrViewfinder samples further demonstrate the use of the APIs covered on this page.\n\nApps running Android 10 (API level 29) or higher must have the permission in order to access the values of the following fields that the method returns:\n\nTo download sample apps, see the Camera2Basic sample and Official CameraX sample app."
    },
    {
        "link": "https://developer.android.com/training/permissions/requesting",
        "document": "Stay organized with collections Save and categorize content based on your preferences.\n\nEvery Android app runs in a limited-access sandbox. If your app needs to use resources or information outside of its own sandbox, you can declare a runtime permission and set up a permission request that provides this access. These steps are part of the workflow for using permissions.\n\nIf you declare any dangerous permissions, and if your app is installed on a device that runs Android 6.0 (API level 23) or higher, you must request the dangerous permissions at runtime by following the steps in this guide.\n\nIf you don't declare any dangerous permissions, or if your app is installed on a device that runs Android 5.1 (API level 22) or lower, the permissions are automatically granted, and you don't need to complete any of the remaining steps on this page.\n\nThe basic principles for requesting permissions at runtime are as follows:\n• Ask for a permission in context, when the user starts to interact with the feature that requires it.\n• Don't block the user. Always provide the option to cancel an educational UI flow, such as a flow that explains the rationale for requesting permissions.\n• If the user denies or revokes a permission that a feature needs, gracefully degrade your app so that the user can continue using your app, possibly by disabling the feature that requires the permission.\n• Don't assume any system behavior. For example, don't assume that permissions appear in the same permission group. A permission group merely helps the system minimize the number of system dialogs that are presented to the user when an app requests closely related permissions.\n\nBefore you declare and request runtime permissions in your app, evaluate whether your app needs to do so. You can fulfill many use cases in your app, such as taking photos, pausing media playback, and displaying relevant ads, without needing to declare any permissions.\n\nIf you conclude that your app needs to declare and request runtime permissions, complete these steps:\n• In your app's manifest file, declare the permissions that your app might need to request.\n• Design your app's UX so that specific actions in your app are associated with specific runtime permissions. Let users know which actions might require them to grant permission for your app to access private user data.\n• Wait for the user to invoke the task or action in your app that requires access to specific private user data. At that time, your app can request the runtime permission that's required for accessing that data.\n• None Check whether the user has already granted the runtime permission that your app requires. If so, your app can access the private user data. If not, continue to the next step. You must check whether you have a permission every time you perform an operation that requires that permission.\n• None Check whether your app should show a rationale to the user, explaining why your app needs the user to grant a particular runtime permission. If the system determines that your app shouldn't show a rationale, continue to the next step directly, without showing a UI element. If the system determines that your app should show a rationale, however, present the rationale to the user in a UI element. In this rationale, clearly explain what data your app is trying to access and what benefits the app can provide to the user if they grant the runtime permission. After the user acknowledges the rationale, continue to the next step.\n• None Request the runtime permission that your app requires to access the private user data. The system displays a runtime permission prompt, such as the one shown on the permissions overview page.\n• None Check the user's response—whether they chose to grant or deny the runtime permission.\n• None If the user granted the permission to your app, you can access the private user data. If the user denied the permission instead, gracefully degrade your app experience so that it provides functionality to the user without the information that's protected by that permission.\n\nFigure 1 illustrates the workflow and set of decisions associated with this process:\n\nDetermine whether your app was already granted the permission\n\nTo check whether the user already granted your app a particular permission, pass that permission into the method. This method returns either or , depending on whether your app has the permission.\n\nExplain why your app needs the permission\n\nThe permissions dialog shown by the system when you call says what permission your app wants, but doesn't say why. In some cases, the user might find that puzzling. It's a good idea to explain to the user why your app wants the permissions before you call .\n\nResearch shows that users are much more comfortable with permissions requests if they know why the app needs them, such as whether the permission is needed to support a core feature of the app or for advertising. As a result, if you're only using a fraction of the API calls that fall under a permission group, it helps to explicitly list which of those permissions you're using and why. For example, if you're only using coarse location, let the user know this in your app description or in help articles about your app.\n\nUnder certain conditions, it's also helpful to let users know about sensitive data access in real time. For example, if you’re accessing the camera or microphone, it’s a good idea to let the user know by using a notification icon somewhere in your app, or in the notification tray (if the application is running in the background), so it doesn't seem like you're collecting data surreptitiously.\n\nUltimately, if you need to request a permission to make something in your app work, but the reason isn't clear to the user, find a way to let the user know why you need the most sensitive permissions.\n\nIf the method returns , call . If this method returns , show an educational UI to the user. In this UI, describe why the feature that the user wants to enable needs a particular permission.\n\nAdditionally, if your app requests a permission related to location, microphone, or camera, consider explaining why your app needs access to this information.\n\nAfter the user views an educational UI, or the return value of indicates that you don't need to show an educational UI, request the permission. Users see a system permission dialog, where they can choose whether to grant a particular permission to your app.\n\nTo do this, use the contract, included in an AndroidX library, where you allow the system to manage the permission request code for you. Because using the contract simplifies your logic, it is the recommended solution when possible. However, if needed you can also manage a request code yourself as part of the permission request and include this request code in your permission callback logic.\n\nAllow the system to manage the permission request code\n\nTo allow the system to manage the request code that's associated with a permissions request, add dependencies on the following libraries in your module's file:\n\nYou can then use one of the following classes:\n• To request multiple permissions at the same time, use .\n\nThe following steps show how to use the contract. The process is nearly the same for the contract.\n• None In your activity or fragment's initialization logic, pass in an implementation of into a call to . The defines how your app handles the user's response to the permission request. Keep a reference to the return value of , which is of type .\n• None To display the system permissions dialog when necessary, call the method on the instance of that you saved in the previous step. After is called, the system permissions dialog appears. When the user makes a choice, the system asynchronously invokes your implementation of , which you defined in the previous step. Note: Your app cannot customize the dialog that appears when you call . To provide more information or context to the user, change your app's UI so that it's easier for users to understand why a feature in your app needs a particular permission. For example, you might change the text in the button that enables the feature. Also, the text in the system permission dialog references the permission group associated with the permission that you requested. This permission grouping is designed for system ease-of-use, and your app shouldn't rely on permissions being within or outside of a specific permission group.\n\nThe following code snippet shows how to handle the permissions response:\n\nAnd this code snippet demonstrates the recommended process to check for a permission and to request a permission from the user when necessary:\n\nAs an alternative to allowing the system to manage the permission request code, you can manage the permission request code yourself. To do so, include the request code in a call to .\n\nThe following code snippet demonstrates how to request a permission using a request code:\n\nAfter the user responds to the system permissions dialog, the system then invokes your app's implementation of . The system passes in the user response to the permission dialog, as well as the request code that you defined, as shown in the following code snippet:\n\nWhen you request location permissions, follow the same best practices as for any other runtime permission. One important difference when it comes to location permissions is that the system includes multiple permissions related to location. Which permissions you request, and how you request them, depend on the location requirements for your app's use case.\n\nIf your app contains a feature that shares or receives location information only once, or for a defined amount of time, then that feature requires foreground location access. Some examples include the following:\n• Within a messaging app, a feature lets users share their current location with another user.\n\nThe system considers your app to be using foreground location if a feature of your app accesses the device's current location in one of the following situations:\n• An activity that belongs to your app is visible.\n• None Your app is running a foreground service. When a foreground service is running, the system raises user awareness by showing a persistent notification. Your app retains access when it's placed in the background, such as when the user presses the Home button on their device or turns their device's display off. On Android 10 (API level 29) and higher, you must declare a foreground service type of , as shown in the following code snippet. On earlier versions of Android, it's recommended that you declare this foreground service type. <!-- Recommended for Android 9 (API level 28) and lower. --> <!-- Required for Android 10 (API level 29) and higher. --> <service android:name=\"MyNavigationService\" android:foregroundServiceType=\"location\" ... > <!-- Any inner elements go here. --> </service>\n\nYou declare a need for foreground location when your app requests either the permission or the permission, as shown in the following snippet:\n\nAn app requires background location access if a feature within the app constantly shares location with other users or uses the Geofencing API. Several examples include the following:\n• Within an IoT app, a feature lets users configure their home devices such that they turn off when the user leaves their home and turn back on when the user returns home.\n\nThe system considers your app to be using background location if it accesses the device's current location in any situation other than the ones described in the foreground location section. The background location accuracy is the same as the foreground location accuracy, which depends on the location permissions that your app declares.\n\nOn Android 10 (API level 29) and higher, you must declare the permission in your app's manifest to request background location access at runtime. On earlier versions of Android, when your app receives foreground location access, it automatically receives background location access as well.\n\nIf the user denies a permission request, your app should help users understand the implications of denying the permission. In particular, your app should make users aware of the features that don't work because of the missing permission. When you do so, keep the following best practices in mind:\n• None Guide the user's attention. Highlight a specific part of your app's UI where there's limited functionality because your app doesn't have the necessary permission. Examples of what you could do include the following:\n• Show a message where the feature's results or data would have appeared.\n• Display a different button that contains an error icon and color.\n• None Be specific. Don't display a generic message. Instead, make clear which features are unavailable because your app doesn't have the necessary permission.\n• None Don't block the user interface. In other words, don't display a full-screen warning message that prevents users from continuing to use your app at all.\n\nAt the same time, your app should respect the user's decision to deny a permission. Starting in Android 11 (API level 30), if the user taps Deny for a specific permission more than once during your app's lifetime of installation on a device, the user doesn't see the system permissions dialog if your app requests that permission again. The user's action implies \"don't ask again.\" On previous versions, users saw the system permissions dialog each time your app requested a permission, unless they had previously selected a \"don't ask again\" checkbox or option.\n\nIf a user denies a permission request more than once, this is considered a permanant denial. It's very important to only prompt users for permissions when they need access to a specific feature, otherwise you might inadvertently lose the ability to re-request permissions.\n\nIn certain situations, the permission might be denied automatically, without the user taking any action. (A permission might be granted automatically as well.) It's important to not assume anything about automatic behavior. Each time your app needs to access functionality that requires a permission, check that your app is still granted that permission.\n\nTo provide the best user experience when asking for app permissions, also see App permissions best practices.\n\nTo identify whether an app has been permanently denied permissions (for debugging and testing purposes), use the following command:\n\nWhere is the name of the package to inspect.\n\nThe output of the command contains sections that look like this:\n\nPermissions that have been denied once by the user are flagged by . Permissions that have been denied permanently by selecting Deny twice are flagged by .\n\nTo ensure that testers see the request dialog during testing, reset these flags when you're done debugging your app. To do this, use the command:\n\nis the name of the permission you want to reset.\n\nTo view a complete list of Android app permissions, visit the permissions API reference page.\n\nStarting in Android 11 (API level 30), whenever your app requests a permission related to location, microphone, or camera, the user-facing permissions dialog contains an option called Only this time, as shown in figure 2. If the user selects this option in the dialog, your app is granted a temporary one-time permission.\n\nYour app can then access the related data for a period of time that depends on your app's behavior and the user's actions:\n• While your app's activity is visible, your app can access the data.\n• If the user sends your app to the background, your app can continue to access the data for a short period of time.\n• If you launch a foreground service while the activity is visible, and the user then moves your app to the background, your app can continue to access the data until the foreground service stops.\n\nIf the user revokes the one-time permission, such as in system settings, your app can't access the data, regardless of whether you launched a foreground service. As with any permission, if the user revokes your app's one-time permission, your app's process terminates.\n\nWhen the user next opens your app and a feature in your app requests access to location, microphone, or camera, the user is prompted for the permission again.\n\nAndroid provides several ways to reset unused runtime permissions to their default, denied state:\n• An API where you can proactively remove your app's access to an unused runtime permission.\n• A system mechanism that automatically resets the permissions of unused apps.\n\nOn Android 13 (API level 33) and higher, you can remove your app's access to runtime permissions that your app no longer requires. When you update your app, perform this step so that users are more likely to understand why your app continues to request specific permissions. This knowledge helps build user trust in your app.\n\nTo remove access to a runtime permission, pass the name of that permission into . To remove access to a group of runtime permissions at the same time, pass a collection of permission names into . The permission removal process happens asynchronously and kills all processes associated with your app's UID.\n\nFor the system to remove your app's access to the permissions, all processes tied to your app must be killed. When you call the API, the system determines when it's safe to kill these processes. Usually, the system waits until your app spends an extended period of time running in the background instead of the foreground.\n\nTo inform the user that your app no longer requires access to specific runtime permissions, show a dialog the next time the user launches your app. This dialog can include the list of permissions.\n\nIf your app targets Android 11 (API level 30) or higher and isn't used for a few months, the system protects user data by automatically resetting the sensitive runtime permissions that the user had granted your app. Learn more in the guide about app hibernation.\n\nRequest to become the default handler if necessary\n\nSome apps depend on access to sensitive user information related to call logs and SMS messages. If you want to request the permissions specific to call logs and SMS messages and publish your app to the Play Store, you must prompt the user to set your app as the default handler for a core system function before requesting these runtime permissions.\n\nFor more information on default handlers, including guidance on showing a default handler prompt to users, see the guide about permissions used only in default handlers.\n\nTo grant all runtime permissions automatically when you install an app on an emulator or test device, use the option for the command, as demonstrated in the following code snippet:\n\nFor additional information about permissions, read these articles:\n\nTo learn more about requesting permissions, review the permissions samples\n\nYou can also complete this codelab that demonstrates privacy best practices."
    },
    {
        "link": "https://medium.com/deuk/android-camera-permission-essentials-streamlining-with-baseactivity-13be6d296224",
        "document": "Welcome to an essential guide designed to transform how you manage camera permissions in your Android applications. In this tutorial, we delve into the intricacies of leveraging , an approach that not only simplifies permission management but also significantly reduces the complexity within . The integration of camera functionality stands at the forefront of mobile technology innovation, merging the realms of real-time data processing and machine learning (ML) to unlock new possibilities for what smartphones are capable of achieving.\n\nThis journey is crafted to arm you with the code insights and comprehensive understanding necessary to effortlessly integrate camera permissions into your apps, thereby unlocking new dimensions of capability and enhancing user experiences. Without further ado, let’s embark on this crucial journey to fully leverage the expansive potential of mobile camera technology.\n\nBegin by launching Android Studio and initiating a new project. Opt for the “Empty Activity” template to establish a clean slate.\n\nNext, navigate to your project’s file.\n\nIt’s time to declare the permissions and features your app will need to interact with the device’s camera. Insert the following lines within the tag but outside the tag.\n• The tag is crucial as it explicitly requests permission to use the device's camera. This step is mandatory for any app that intends to capture images or videos.\n• The tag, while not strictly necessary for running this demo, plays a vital role in the broader app ecosystem. By declaring the camera as a non-required feature, you inform the Google Play Store (and users) that your app can function without it.\n\nIn this section, we’ve already laid out the foundation for , a crucial component for streamlining camera permission handling in Android apps. This approach not only simplifies permission management in but also any other activity that requires camera access.\n\n// Your package\n\n\n\nimport android.Manifest\n\nimport android.content.Intent\n\nimport android.content.pm.PackageManager\n\nimport android.provider.MediaStore\n\nimport android.widget.Toast\n\nimport androidx.activity.ComponentActivity\n\nimport androidx.activity.result.ActivityResultLauncher\n\nimport androidx.activity.result.contract.ActivityResultContracts\n\nimport androidx.core.content.ContextCompat\n\n\n\n// Open class allowing extension, so activities like MainActivity can inherit from it\n\n// for common camera permission handling functionality\n\nopen class BaseActivity : ComponentActivity() {\n\n\n\n // Key Point 1: Camera Permission Request Launcher\n\n // Declare a launcher for the camera permission request, handling the permission result\n\n private val cameraPermissionRequestLauncher: ActivityResultLauncher<String> =\n\n registerForActivityResult(ActivityResultContracts.RequestPermission()) { isGranted: Boolean ->\n\n if (isGranted) {\n\n // Permission granted: proceed with opening the camera\n\n startDefaultCamera()\n\n } else {\n\n // Permission denied: inform the user to enable it through settings\n\n Toast.makeText(\n\n this,\n\n \"Go to settings and enable camera permission to use this feature\",\n\n Toast.LENGTH_SHORT\n\n ).show()\n\n }\n\n }\n\n\n\n // Key Point 2: Camera Intent Launcher\n\n // Declare a launcher for taking a picture, handling the result of the camera app\n\n private val takePictureLauncher: ActivityResultLauncher<Intent> =\n\n registerForActivityResult(ActivityResultContracts.StartActivityForResult()) { result ->\n\n // This can be expanded to handle the result data\n\n Toast.makeText(this, \"Photo taken\", Toast.LENGTH_SHORT).show()\n\n }\n\n\n\n // Checks camera permission and either starts the camera directly or requests permission\n\n fun handleCameraPermission() {\n\n when {\n\n ContextCompat.checkSelfPermission(\n\n this,\n\n Manifest.permission.CAMERA\n\n ) == PackageManager.PERMISSION_GRANTED -> {\n\n // Permission is already granted: start the camera\n\n startDefaultCamera()\n\n }\n\n\n\n else -> {\n\n // Permission is not granted: request it\n\n cameraPermissionRequestLauncher.launch(Manifest.permission.CAMERA)\n\n }\n\n }\n\n }\n\n\n\n // Starts the default camera app for taking a picture\n\n private fun startDefaultCamera() {\n\n Intent(MediaStore.ACTION_IMAGE_CAPTURE).also { takePictureIntent ->\n\n takePictureIntent.resolveActivity(packageManager)?.also {\n\n // Camera app is available: launch it\n\n takePictureLauncher.launch(takePictureIntent)\n\n } ?: run {\n\n // No camera app available: inform the user\n\n Toast.makeText(this, \"No camera app available\", Toast.LENGTH_SHORT).show()\n\n }\n\n }\n\n }\n\n}\n• simplifies handling permissions and activity results, avoiding the cumbersome method. It's a modern approach that streamlines the permission request flow.\n• By registering an with , developers can request permissions in a more straightforward manner. The launcher handles user responses to permission requests and returns a boolean indicating the outcome.\n• This launcher is tailored for activities that expect a result back, such as capturing a photo with the camera. It launches the camera activity and handles the return, which could include image data or confirmation of the action.\n• Unlike the permission launcher, is used for any activity result, not just permissions. It's ideal for operations like taking pictures, where you manage the outcome (e.g., displaying the captured photo) through a callback function.\n\nTo seamlessly integrate camera permission handling into your application, let’s focus on updating .\n\nUpon application launch, expect the camera permission dialogue to appear. The UI of this dialogue may differ across API levels due to variations in Android’s permission handling.\n\nIf the device does not have a compatible camera application to handle the intent, the user will be informed through a “No camera app available” message. This scenario highlights the importance of validating the presence of a camera app before attempting to capture an image.\n\nIn contrast, if a compatible camera app is available and the photo capture process completes successfully, a “Photo Taken” message will be displayed, indicating the operation’s success.\n\nCongratulations on mastering the essentials of camera permission handling in Android apps! This tutorial marks a significant step in your journey towards becoming proficient in integrating advanced functionalities into your applications. Remember, the journey in Android development is continuous, filled with endless opportunities for growth and innovation.\n\nI encourage you to keep exploring and deepening your knowledge in Android development. My collection of guides, built on over a decade of experience, is designed to help you advance your skills further. Each guide aims to not only enhance your technical abilities but also to instill best practices that will stand you in good stead throughout your career.\n\nThank you for following along. If you found this guide helpful, please show your support with claps and consider following for more insights into modern Android development. Your engagement and feedback inspire me to share more valuable content. Stay curious, keep learning, and I eagerly anticipate accompanying you on your next steps in this exciting development journey. Happy coding!\n\nAre you looking to boost your business with top-tier Android solutions?Partner with Deuk services and take your projects to unparalleled heights.\n\nNew to Notion? Discover how it can revolutionize your productivity\n\nReady to take your productivity to the next level? Integrate this content into your Notion workspace with ease:\n\n1. Access the Notion Version of this Content\n\n2. Look for the button at the top-right corner of the page\n\n3. Click on it to add this valuable resource to your Notion workspace\n\nSeamlessly integrate this guide into your Notion workspace for easy access and swift reference. Leverage Notion AI to search and extract crucial insights, enhancing your productivity. Start curating your knowledge hub with Notion AI today and maximize every learning moment."
    },
    {
        "link": "https://stackoverflow.com/questions/36349130/how-to-access-camera-in-android-6-0-marshmallow",
        "document": "I am to new to Android 6.0 Coding Please Provide a solutions For the Below Code:\n\nWhen i provide Run Time Permissions like and it shows an Exception like\n\nEither and Run Time Permissions are not working..."
    },
    {
        "link": "https://javanexus.com/blog/solving-android-camera-api-issues",
        "document": "Working with the Android Camera API can be a crucial and challenging task for developers, as it involves addressing various common issues related to camera functionality. These issues often include handling camera permissions, opening the camera device safely, managing different camera orientations, capturing high-quality images, and efficiently processing camera output. These challenges not only impact the functionality of the app but also affect the overall user experience. This guide aims to provide solutions to these common issues, ensuring developers can enhance their app's camera capabilities and provide a seamless user experience.\n\nAndroid offers two primary camera APIs: the Camera API and the Camera2 API. The original Camera API is now deprecated, and developers are encouraged to use the Camera2 API for new projects. The Camera2 API provides more extensive control over camera functionality, including manual control over camera settings, improved performance, and support for additional features such as RAW image capture and burst mode. It also addresses some of the limitations present in the older Camera API, making it a preferred choice for developers looking to leverage the full potential of the device's camera hardware.\n\nThe Camera2 API introduces several key concepts that developers must understand to effectively work with the camera functionality. These concepts include camera sessions, capture requests, and image readers. Camera sessions represent the connection between the application and the camera device, providing a platform for capturing images and processing camera data. Capture requests are used to configure the capture of a single image, including setting exposure, focus, and other parameters. Image readers facilitate the acquisition of image data from the camera for further processing or storage.\n\nLet's address the common issues related to the Android Camera API and provide comprehensive solutions for each problem.\n\nStarting from Android 6.0 (Marshmallow) and later, apps must request camera permissions at runtime to access the device's camera. Without proper permission handling, attempting to access the camera will result in a security exception, and the app's behavior will be affected.\n\nIn the code snippet above, we first check if the camera permissions have been granted. If not, we request the necessary permissions from the user using . Once the permissions are granted, the method can be called to proceed with accessing the camera.\n\nWhen opening the camera device, complications such as resource contention with other apps can occur. It's essential to handle the camera device safely to avoid conflicts and ensure proper disconnection from the camera when not in use.\n\nIn this code snippet, we use the to obtain access to the camera device. We then attempt to open the camera device using , providing a to handle the camera's state changes. This ensures that the camera device is safely opened and that appropriate actions are taken in the event of disconnection or errors.\n\nOne of the critical aspects of working with the camera is handling different device orientations. It's essential to capture images or videos that correctly match the orientation in which the device is being held, providing a seamless user experience.\n\nIn the code snippet above, we retrieve the device's current orientation using . We then calculate the required rotation for the captured image using the method and apply it to the capture request using . This ensures that the captured image aligns with the device's orientation.\n\nCapturing high-quality images involves considering factors such as resolution settings and processing options. It's crucial to configure the camera settings to capture images at the desired quality and resolution.\n\nIn this code snippet, we create an to capture high-quality JPEG images at a specified width and height. We configure the with an to handle the captured images. Additionally, we create a capture request targeting the 's surface, ensuring that the camera captures images at the desired quality and resolution.\n\nEfficiently processing camera output in the background is essential for maintaining a smooth user interface. This involves using background threads or handlers to handle camera data without blocking the main thread.\n\nIn this code snippet, we create a background thread for processing camera data using a . We then use the to execute operations related to capturing images and processing camera output. The ensures that the camera session is properly configured to capture images in the background.\n\nBest Practices for Working with the Camera2 API\n\nWhen working with the Camera2 API, developers are encouraged to follow these best practices:\n• Properly handle camera permissions to ensure the app adheres to runtime permission requirements.\n• Manage camera resources efficiently, including safely opening and releasing the camera device when not in use.\n• Implement error handling for various camera-related operations, providing informative feedback to users in case of failures.\n• Optimize battery usage by gracefully managing camera usage and releasing resources when not needed.\n• Test the app's compatibility across different Android devices to ensure consistent behavior and performance.\n\nMy Closing Thoughts on the Matter\n\nIn conclusion, addressing common issues related to the Android Camera API is crucial for developing apps with robust camera capabilities and providing an excellent user experience. By implementing the solutions provided in this guide, developers can overcome challenges such as handling camera permissions, safely opening the camera device, managing different camera orientations, capturing high-quality images, and processing camera output efficiently. Experimenting with these solutions and adapting them to specific app requirements can significantly enhance the camera functionality of Android apps.\n\nWe encourage developers to explore the Android Camera2 API documentation and leverage other resources available to further enhance their understanding of camera-related development on the Android platform.\n\nFor further reading and resources on working with the Android Camera2 API and addressing camera-related issues, we recommend the following:\n\nBy addressing common issues and providing comprehensive solutions for working with the Android Camera2 API, this article aims to equip developers with the knowledge and tools necessary to enhance their app's camera functionality. Whether it's capturing high-quality images, efficiently processing camera output, or managing camera permissions, following best practices and implementing the solutions outlined in this guide can contribute to the development of robust and user-friendly camera features within Android apps."
    },
    {
        "link": "https://stackoverflow.com/questions/11845519/android-camera-preview-in-surfaceview",
        "document": "I manage to put camera preview in surfaceview and this works great. But now i have problem with speed of other components. Because now it is really slow.\n\nDo i need to put camera in new thread? How to decrease fps or resolution? Because this what i have now does not work properly.\n\nAnd how i call in main activity:"
    },
    {
        "link": "https://stackoverflow.com/questions/16907005/android-camera-with-surfaceview",
        "document": "I am trying to use Android's Camera with a SurfaceView, so the the user can preview the camera. I followed various tutorials on StackOverflow, and finally ended up with Google's own tutorial, but my app crashed. Here is my code. I am using Eclipse's Android Virtual Device, emulated camera (which I don't think would affect anything) and 100mb sd card space alloted.\n\nThere are two classes, a CameraPreview object and the CameraActivity.\n\n06-04 14:28:07.726: W/dalvikvm(6115): threadid=1: thread exiting with uncaught exception (group=0x40a71930) 06-04 14:28:07.956: E/AndroidRuntime(6115): FATAL EXCEPTION: main 06-04 14:28:07.956: E/AndroidRuntime(6115): java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.mobilequote/com.example.mobilequote.CameraActivity}: java.lang.NullPointerException 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2180) 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2230) 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.app.ActivityThread.access$600(ActivityThread.java:141) 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1234) 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.os.Handler.dispatchMessage(Handler.java:99) 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.os.Looper.loop(Looper.java:137) 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.app.ActivityThread.main(ActivityThread.java:5041) 06-04 14:28:07.956: E/AndroidRuntime(6115): at java.lang.reflect.Method.invokeNative(Native Method) 06-04 14:28:07.956: E/AndroidRuntime(6115): at java.lang.reflect.Method.invoke(Method.java:511) 06-04 14:28:07.956: E/AndroidRuntime(6115): at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:793) 06-04 14:28:07.956: E/AndroidRuntime(6115): at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:560) 06-04 14:28:07.956: E/AndroidRuntime(6115): at dalvik.system.NativeStart.main(Native Method) 06-04 14:28:07.956: E/AndroidRuntime(6115): Caused by: java.lang.NullPointerException 06-04 14:28:07.956: E/AndroidRuntime(6115): at com.example.mobilequote.CameraActivity.onCreate(CameraActivity.java:24) 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.app.Activity.performCreate(Activity.java:5104) 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1080) 06-04 14:28:07.956: E/AndroidRuntime(6115): at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2144) 06-04 14:28:07.956: E/AndroidRuntime(6115): ... 11 more"
    },
    {
        "link": "https://developer.android.com/reference/android/view/SurfaceHolder.Callback",
        "document": "An implementation of SurfaceView that uses the dedicated surface for displaying OpenGL rendering. Convenience for implementing an activity that will be implemented purely in native code. Additional callbacks that can be received for .\n\nA client may implement this interface to receive information about changes to the surface. When used with a , the Surface being held is only available between calls to and . The Callback is set with method.\n\nThis is called immediately after any structural changes (format or size) have been made to the surface. This is called immediately after the surface is first created. This is called immediately before a surface is being destroyed.\n\nThis is called immediately after any structural changes (format or size) have been made to the surface. You should at this point update the imagery in the surface. This method is always called at least once, after . : The SurfaceHolder whose surface has changed. This value cannot be . : The new of the surface. Value is , , , , , , or android.graphics.PixelFormat.R_8 : The new width of the surface. Value is 0 or greater : The new height of the surface. Value is 0 or greater\n\nThis is called immediately after the surface is first created. Implementations of this should start up whatever rendering code they desire. Note that only one thread can ever draw into a , so you should not draw into the Surface here if your normal rendering will be in another thread. : The SurfaceHolder whose surface is being created. This value cannot be .\n\nThis is called immediately before a surface is being destroyed. After returning from this call, you should no longer try to access this surface. If you have a rendering thread that directly accesses the surface, you must ensure that thread is no longer touching the Surface before returning from this function. : The SurfaceHolder whose surface is being destroyed. This value cannot be ."
    },
    {
        "link": "https://github.com/alessandrofrancesconi/NiceCameraExample/blob/master/src/com/ale/nicecameraexample/CameraPreview.java",
        "document": ""
    },
    {
        "link": "https://developer.android.com/media/camera/camera-deprecated/camera-api",
        "document": "Stay organized with collections Save and categorize content based on your preferences.\n\nThe Android framework includes support for various cameras and camera features available on devices, allowing you to capture pictures and videos in your applications. This document discusses a quick, simple approach to image and video capture and outlines an advanced approach for creating custom camera experiences for your users.\n\nNote: This page describes the class, which has been deprecated. We recommend using the CameraX Jetpack library or, for specific use cases, the , class. Both CameraX and Camera2 work on Android 5.0 (API level 21) and higher.\n\nBefore enabling your application to use cameras on Android devices, you should consider a few questions about how your app intends to use this hardware feature.\n• Camera Requirement - Is the use of a camera so important to your application that you do not want your application installed on a device that does not have a camera? If so, you should declare the camera requirement in your manifest.\n• Quick Picture or Customized Camera - How will your application use the camera? Are you just interested in snapping a quick picture or video clip, or will your application provide a new way to use cameras? For getting a quick snap or clip, consider Using Existing Camera Apps. For developing a customized camera feature, check out the Building a Camera App section.\n• Foreground Services Requirement - When does your app interact with the camera? On Android 9 (API level 28) and later, apps running in the background cannot access the camera. Therefore, you should use the camera either when your app is in the foreground or as part of a foreground service.\n• Storage - Are the images or videos your application generates intended to be only visible to your application or shared so that other applications such as Gallery or other media and social apps can use them? Do you want the pictures and videos to be available even if your application is uninstalled? Check out the Saving Media Files section to see how to implement these options.\n\nThe Android framework supports capturing images and video through the API or camera . Here are the relevant classes:\n\nBefore starting development on your application with the Camera API, you should make sure your manifest has the appropriate declarations to allow use of camera hardware and other related features.\n• Camera Permission - Your application must request permission to use a device camera. Note: If you are using the camera by invoking an existing camera app, your application does not need to request this permission.\n• Camera Features - Your application must also declare use of camera features, for example: For a list of camera features, see the manifest Features Reference. Adding camera features to your manifest causes Google Play to prevent your application from being installed to devices that do not include a camera or do not support the camera features you specify. For more information about using feature-based filtering with Google Play, see Google Play and Feature-Based Filtering. If your application can use a camera or camera feature for proper operation, but does not require it, you should specify this in the manifest by including the attribute, and setting it to :\n• Storage Permission - Your application can save images or videos to the device's external storage (SD Card) if it targets Android 10 (API level 29) or lower and specifies the following in the manifest.\n• Audio Recording Permission - For recording audio with video capture, your application must request the audio capture permission.\n• Location Permission - If your application tags images with GPS location information, you must request the permission. Note that, if your app targets Android 5.0 (API level 21) or higher, you also need to declare that your app uses the device's GPS: <uses-permission android:name=\"android.permission.ACCESS_FINE_LOCATION\" /> ... <!-- Needed only if your app targets Android 5.0 (API level 21) or higher. --> <uses-feature android:name=\"android.hardware.location.gps\" /> For more information about getting user location, see Location Strategies.\n\nA quick way to enable taking pictures or videos in your application without a lot of extra code is to use an to invoke an existing Android camera application. The details are described in the training lessons Taking Photos Simply and Recording Videos Simply.\n\nSome developers may require a camera user interface that is customized to the look of their application or provides special features. Writing your own picture-taking code can provide a more compelling experience for your users.\n\nNote: The following guide is for the older, deprecated API. For new or advanced camera applications, the newer API is recommended.\n\nThe general steps for creating a custom camera interface for your application are as follows:\n• Detect and Access Camera - Create code to check for the existence of cameras and request access.\n• Create a Preview Class - Create a camera preview class that extends and implements the interface. This class previews the live images from the camera.\n• Build a Preview Layout - Once you have the camera preview class, create a view layout that incorporates the preview and the user interface controls you want.\n• Setup Listeners for Capture - Connect listeners for your interface controls to start image or video capture in response to user actions, such as pressing a button.\n• Capture and Save Files - Setup the code for capturing pictures or videos and saving the output.\n• Release the Camera - After using the camera, your application must properly release it for use by other applications.\n\nCamera hardware is a shared resource that must be carefully managed so your application does not collide with other applications that may also want to use it. The following sections discusses how to detect camera hardware, how to request access to a camera, how to capture pictures or video and how to release the camera when your application is done using it.\n\nCaution: Remember to release the object by calling the when your application is done using it! If your application does not properly release the camera, all subsequent attempts to access the camera, including those by your own application, will fail and may cause your or other applications to be shut down.\n\nIf your application does not specifically require a camera using a manifest declaration, you should check to see if a camera is available at runtime. To perform this check, use the method, as shown in the example code below:\n\nAndroid devices can have multiple cameras, for example a back-facing camera for photography and a front-facing camera for video calls. Android 2.3 (API Level 9) and later allows you to check the number of cameras available on a device using the method.\n\nIf you have determined that the device on which your application is running has a camera, you must request to access it by getting an instance of (unless you are using an intent to access the camera).\n\nTo access the primary camera, use the method and be sure to catch any exceptions, as shown in the code below:\n\nCaution: Always check for exceptions when using . Failing to check for exceptions if the camera is in use or does not exist will cause your application to be shut down by the system.\n\nOn devices running Android 2.3 (API Level 9) or higher, you can access specific cameras using . The example code above will access the first, back-facing camera on a device with more than one camera.\n\nOnce you obtain access to a camera, you can get further information about its capabilities using the method and checking the returned object for supported capabilities. When using API Level 9 or higher, use the to determine if a camera is on the front or back of the device, and the orientation of the image.\n\nFor users to effectively take pictures or video, they must be able to see what the device camera sees. A camera preview class is a that can display the live image data coming from a camera, so users can frame and capture a picture or video.\n\nThe following example code demonstrates how to create a basic camera preview class that can be included in a layout. This class implements in order to capture the callback events for creating and destroying the view, which are needed for assigning the camera preview input.\n\nIf you want to set a specific size for your camera preview, set this in the method as noted in the comments above. When setting preview size, you must use values from . Do not set arbitrary values in the method.\n\nNote: With the introduction of the Multi-Window feature in Android 7.0 (API level 24) and higher, you can no longer assume the aspect ratio of the preview is the same as your activity even after calling . Depending on the window size and aspect ratio, you may may have to fit a wide camera preview into a portrait-orientated layout, or vice versa, using a letterbox layout.\n\nA camera preview class, such as the example shown in the previous section, must be placed in the layout of an activity along with other user interface controls for taking a picture or video. This section shows you how to build a basic layout and activity for the preview.\n\nThe following layout code provides a very basic view that can be used to display a camera preview. In this example, the element is meant to be the container for the camera preview class. This layout type is used so that additional picture information or controls can be overlaid on the live camera preview images.\n\nOn most devices, the default orientation of the camera preview is landscape. This example layout specifies a horizontal (landscape) layout and the code below fixes the orientation of the application to landscape. For simplicity in rendering a camera preview, you should change your application's preview activity orientation to landscape by adding the following to your manifest.\n\nNote: A camera preview does not have to be in landscape mode. Starting in Android 2.2 (API Level 8), you can use the method to set the rotation of the preview image. In order to change preview orientation as the user re-orients the phone, within the method of your preview class, first stop the preview with change the orientation and then start the preview again with .\n\nIn the activity for your camera view, add your preview class to the element shown in the example above. Your camera activity must also ensure that it releases the camera when it is paused or shut down. The following example shows how to modify a camera activity to attach the preview class shown in Creating a preview class.\n\nNote: The method in the example above refers to the example method shown in Accessing cameras.\n\nOnce you have built a preview class and a view layout in which to display it, you are ready to start capturing images with your application. In your application code, you must set up listeners for your user interface controls to respond to a user action by taking a picture.\n\nIn order to retrieve a picture, use the method. This method takes three parameters which receive data from the camera. In order to receive data in a JPEG format, you must implement an interface to receive the image data and write it to a file. The following code shows a basic implementation of the interface to save an image received from the camera.\n\nTrigger capturing an image by calling the method. The following example code shows how to call this method from a button .\n\nNote: The member in the following example refers to the example code above.\n\nCaution: Remember to release the object by calling the when your application is done using it! For information about how to release the camera, see Releasing the camera.\n\nVideo capture using the Android framework requires careful management of the object and coordination with the class. When recording video with , you must manage the and calls to allow access to the camera hardware, in addition to the and calls.\n\nNote: Starting with Android 4.0 (API level 14), the and calls are managed for you automatically.\n\nUnlike taking pictures with a device camera, capturing video requires a very particular call order. You must follow a specific order of execution to successfully prepare for and capture video with your application, as detailed below.\n• Open Camera - Use the to get an instance of the camera object.\n• Connect Preview - Prepare a live camera image preview by connecting a to the camera using .\n• Start Recording Video - The following steps must be completed in order to successfully record video:\n• Unlock the Camera - Unlock the camera for use by by calling .\n• Configure MediaRecorder - Call in the following methods in this order. For more information, see the reference documentation.\n• - Set the camera to be used for video capture, use your application's current instance of .\n• Set the video output format and encoding. For Android 2.2 (API Level 8) and higher, use the method, and get a profile instance using . For versions of Android prior to 2.2, you must set the video output format and encoding parameters:\n• - Set the output format, specify the default setting or .\n• - Set the sound encoding type, specify the default setting or .\n• - Set the video encoding type, specify the default setting or .\n• - Set the output file, use from the example method in the Saving Media Files section.\n• - Specify the preview layout element for your application. Use the same object you specified for Connect Preview. Caution: You must call these configuration methods in this order, otherwise your application will encounter errors and the recording will fail.\n• Prepare MediaRecorder - Prepare the with provided configuration settings by calling .\n• Stop Recording Video - Call the following methods in order, to successfully complete a video recording:\n• Reset MediaRecorder - Optionally, remove the configuration settings from the recorder by calling .\n• Lock the Camera - Lock the camera so that future sessions can use it by calling . Starting with Android 4.0 (API level 14), this call is not required unless the call fails.\n• Stop the Preview - When your activity has finished using the camera, stop the preview using .\n• Release Camera - Release the camera so that other applications can use it by calling .\n\nNote: It is possible to use without creating a camera preview first and skip the first few steps of this process. However, since users typically prefer to see a preview before starting a recording, that process is not discussed here.\n\nTip: If your application is typically used for recording video, set to prior to starting your preview. This setting can help reduce the time it takes to start recording.\n\nWhen using the class to record video, you must perform configuration steps in a specific order and then call the method to check and implement the configuration. The following example code demonstrates how to properly configure and prepare the class for video recording.\n\nPrior to Android 2.2 (API Level 8), you must set the output format and encoding formats parameters directly, instead of using . This approach is demonstrated in the following code:\n\nThe following video recording parameters for are given default settings, however, you may want to adjust these settings for your application:\n\nWhen starting and stopping video recording using the class, you must follow a specific order, as listed below.\n• Configure as shown in the code example above\n\nThe following example code demonstrates how to wire up a button to properly start and stop video recording using the camera and the class.\n\nNote: When completing a video recording, do not release the camera or else your preview will be stopped.\n\nNote: In the above example, the method refers to the example code shown in Configuring MediaRecorder. This method takes care of locking the camera, configuring and preparing the instance.\n\nCameras are a resource that is shared by applications on a device. Your application can make use of the camera after getting an instance of , and you must be particularly careful to release the camera object when your application stops using it, and as soon as your application is paused ( ). If your application does not properly release the camera, all subsequent attempts to access the camera, including those by your own application, will fail and may cause your or other applications to be shut down.\n\nTo release an instance of the object, use the method, as shown in the example code below.\n\nCaution: If your application does not properly release the camera, all subsequent attempts to access the camera, including those by your own application, will fail and may cause your or other applications to be shut down.\n\nMedia files created by users such as pictures and videos should be saved to a device's external storage directory (SD Card) to conserve system space and to allow users to access these files without their device. There are many possible directory locations to save media files on a device, however there are only two standard locations you should consider as a developer:\n• ( ) - This method returns the standard, shared and recommended location for saving pictures and videos. This directory is shared (public), so other applications can easily discover, read, change and delete files saved in this location. If your application is uninstalled by the user, media files saved to this location will not be removed. To avoid interfering with users existing pictures and videos, you should create a sub-directory for your application's media files within this directory, as shown in the code sample below. This method is available in Android 2.2 (API Level 8), for equivalent calls in earlier API versions, see Saving Shared Files.\n• ( ) - This method returns a standard location for saving pictures and videos which are associated with your application. If your application is uninstalled, any files saved in this location are removed. Security is not enforced for files in this location and other applications may read, change and delete them.\n\nThe following example code demonstrates how to create a or location for a media file that can be used when invoking a device's camera with an or as part of a Building a Camera App.\n\nNote: is available in Android 2.2 (API Level 8) or higher. If you are targeting devices with earlier versions of Android, use instead. For more information, see Saving Shared Files.\n\nTo make the URI support work profiles, first convert the file URI to a content URI. Then, add the content URI to of an .\n\nFor more information about saving files on an Android device, see Data Storage.\n\nAndroid supports a wide array of camera features you can control with your camera application, such as picture format, flash mode, focus settings, and many more. This section lists the common camera features, and briefly discusses how to use them. Most camera features can be accessed and set using the through object. However, there are several important features that require more than simple settings in . These features are covered in the following sections:\n\nFor general information about how to use features that are controlled through , review the Using camera features section. For more detailed information about how to use features controlled through the camera parameters object, follow the links in the feature list below to the API reference documentation.\n\nTable 1. Common camera features sorted by the Android API Level in which they were introduced.\n\nNote: These features are not supported on all devices due to hardware differences and software implementation. For information on checking the availability of features on the device where your application is running, see Checking feature availability.\n\nThe first thing to understand when setting out to use camera features on Android devices is that not all camera features are supported on all devices. In addition, devices that support a particular feature may support them to different levels or with different options. Therefore, part of your decision process as you develop a camera application is to decide what camera features you want to support and to what level. After making that decision, you should plan on including code in your camera application that checks to see if device hardware supports those features and fails gracefully if a feature is not available.\n\nYou can check the availability of camera features by getting an instance of a camera's parameters object, and checking the relevant methods. The following code sample shows you how to obtain a object and check if the camera supports the autofocus feature:\n\nYou can use the technique shown above for most camera features. The object provides a , or method to determine if (and to what extent) a feature is supported.\n\nIf your application requires certain camera features in order to function properly, you can require them through additions to your application manifest. When you declare the use of specific camera features, such as flash and auto-focus, Google Play restricts your application from being installed on devices which do not support these features. For a list of camera features that can be declared in your app manifest, see the manifest Features Reference.\n\nMost camera features are activated and controlled using a object. You obtain this object by first getting an instance of the object, calling the method, changing the returned parameter object and then setting it back into the camera object, as demonstrated in the following example code:\n\nThis technique works for nearly all camera features, and most parameters can be changed at any time after you have obtained an instance of the object. Changes to parameters are typically visible to the user immediately in the application's camera preview. On the software side, parameter changes may take several frames to actually take effect as the camera hardware processes the new instructions and then sends updated image data.\n\nImportant: Some camera features cannot be changed at will. In particular, changing the size or orientation of the camera preview requires that you first stop the preview, change the preview size, and then restart the preview. Starting with Android 4.0 (API Level 14) preview orientation can be changed without restarting the preview.\n\nOther camera features require more code in order to implement, including:\n\nA quick outline of how to implement these features is provided in the following sections.\n\nIn some photographic scenarios, automatic focusing and light metering may not produce the desired results. Starting with Android 4.0 (API Level 14), your camera application can provide additional controls to allow your app or users to specify areas in an image to use for determining focus or light level settings and pass these values to the camera hardware for use in capturing images or video.\n\nAreas for metering and focus work very similarly to other camera features, in that you control them through methods in the object. The following code demonstrates setting two light metering areas for an instance of :\n\nThe object contains two data parameters: A object for specifying an area within the camera's field of view and a weight value, which tells the camera what level of importance this area should be given in light metering or focus calculations.\n\nThe field in a object describes a rectangular shape mapped on a 2000 x 2000 unit grid. The coordinates -1000, -1000 represent the top, left corner of the camera image, and coordinates 1000, 1000 represent the bottom, right corner of the camera image, as shown in the illustration below.\n\nFigure 1. The red lines illustrate the coordinate system for specifying a within a camera preview. The blue box shows the location and shape of an camera area with the values 333,333,667,667.\n\nThe bounds of this coordinate system always correspond to the outer edge of the image visible in the camera preview and do not shrink or expand with the zoom level. Similarly, rotation of the image preview using does not remap the coordinate system.\n\nFor pictures that include people, faces are usually the most important part of the picture, and should be used for determining both focus and white balance when capturing an image. The Android 4.0 (API Level 14) framework provides APIs for identifying faces and calculating picture settings using face recognition technology.\n\nNote: While the face detection feature is running, , and have no effect.\n\nUsing the face detection feature in your camera application requires a few general steps:\n• Check that face detection is supported on the device\n• Add the face detection listener to your camera object\n• Start face detection after preview (and after every preview restart)\n\nThe face detection feature is not supported on all devices. You can check that this feature is supported by calling . An example of this check is shown in the sample method below.\n\nIn order to be notified and respond to the detection of a face, your camera application must set a listener for face detection events. In order to do this, you must create a listener class that implements the interface as shown in the example code below.\n\nAfter creating this class, you then set it into your application's object, as shown in the example code below:\n\nYour application must start the face detection function each time you start (or restart) the camera preview. Create a method for starting face detection so you can call it as needed, as shown in the example code below.\n\nYou must start face detection each time you start (or restart) the camera preview. If you use the preview class shown in Creating a preview class, add your method to both the and methods in your preview class, as shown in the sample code below.\n\nNote: Remember to call this method after calling . Do not attempt to start face detection in the method of your camera app's main activity, as the preview is not available by this point in your application's the execution.\n\nTime lapse video allows users to create video clips that combine pictures taken a few seconds or minutes apart. This feature uses to record the images for a time lapse sequence.\n\nTo record a time lapse video with , you must configure the recorder object as if you are recording a normal video, setting the captured frames per second to a low number and using one of the time lapse quality settings, as shown in the code example below.\n\nThese settings must be done as part of a larger configuration procedure for . For a full configuration code example, see Configuring MediaRecorder. Once the configuration is complete, you start the video recording as if you were recording a normal video clip. For more information about configuring and running , see Capturing videos.\n\nThe Camera2Video and HdrViewfinder samples further demonstrate the use of the APIs covered on this page.\n\nApps running Android 10 (API level 29) or higher must have the permission in order to access the values of the following fields that the method returns:\n\nTo download sample apps, see the Camera2Basic sample and Official CameraX sample app."
    }
]