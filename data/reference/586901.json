[
    {
        "link": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html",
        "document": "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. Trees in the forest use the best split strategy, i.e. equivalent to passing to the underlying . The sub-sample size is controlled with the parameter if (default), otherwise the whole dataset is used to build each tree.\n\nFor a comparison between tree-based ensemble models see the example Comparing Random Forests and Histogram Gradient Boosting models.\n\nRead more in the User Guide.\n\nThe number of trees in the forest. Changed in version 0.22: The default value of changed from 10 to 100 in 0.22. The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain, see Mathematical formulation. Note: This parameter is tree-specific. The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. The minimum number of samples required to split an internal node:\n• None If int, then consider as the minimum number.\n• None If float, then is a fraction and are the minimum number of samples for each split. The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n• None If int, then consider as the minimum number.\n• None If float, then is a fraction and are the minimum number of samples for each node. The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided. The number of features to consider when looking for the best split:\n• None If int, then consider features at each split.\n• None If float, then is a fraction and features are considered at each split.\n• None If None, then . Changed in version 1.1: The default of changed from to . Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than features. Grow trees with in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes. A node will be split if this split induces a decrease of the impurity greater than or equal to this value. The weighted impurity decrease equation is the following: where is the total number of samples, is the number of samples at the current node, is the number of samples in the left child, and is the number of samples in the right child. , , and all refer to the weighted sum, if is passed. Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree. Whether to use out-of-bag samples to estimate the generalization score. By default, is used. Provide a callable with signature to use a custom metric. Only available if . The number of jobs to run in parallel. , , and are all parallelized over the trees. means 1 unless in a context. means using all processors. See Glossary for more details. Controls both the randomness of the bootstrapping of the samples used when building trees (if ) and the sampling of the features to consider when looking for the best split at each node (if ). See Glossary for details. Controls the verbosity when fitting and predicting. When set to , reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See Glossary and Fitting additional trees for details. Weights associated with classes in the form . If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y. Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}]. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown. For multi-output, the weights of each column of y will be multiplied. Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified. Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning. If bootstrap is True, the number of samples to draw from X to train each base estimator.\n• None If None (default), then draw samples.\n• None If float, then draw samples. Thus, should be in the interval . Indicates the monotonicity constraint to enforce on each feature. If monotonic_cst is None, no constraints are applied. Monotonicity constraints are not supported for: The constraints hold over the probability of the positive class. Read more in the User Guide. The child estimator template used to create the collection of fitted sub-estimators. Added in version 1.2: was renamed to . classes_ ndarray of shape (n_classes,) or a list of such arrays The classes labels (single output problem), or a list of arrays of class labels (multi-output problem). The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem). Number of features seen during fit. Names of features seen during fit. Defined only when has feature names that are all strings. The number of outputs when is performed. Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when is True. Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, might contain NaN. This attribute exists only when is True. The subset of drawn samples for each base estimator.\n\nThe default values for the parameters controlling the size of the trees (e.g. , , etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.\n\nThe features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data, and , if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, has to be fixed.\n\nNote that this method is only relevant if (see ). Please see User Guide on how the routing mechanism works. The options for each parameter are:\n• None : metadata is requested, and passed to if provided. The request is ignored if metadata is not provided.\n• None : metadata is not requested and the meta-estimator will not pass it to .\n• None : metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n• None : metadata should be passed to the meta-estimator with this given alias instead of the original name. The default ( ) retains the existing request. This allows you to change the request for some parameters and not others. This method is only relevant if this estimator is used as a sub-estimator of a meta-estimator, e.g. used inside a . Otherwise it has no effect.\n\nNote that this method is only relevant if (see ). Please see User Guide on how the routing mechanism works. The options for each parameter are:\n• None : metadata is requested, and passed to if provided. The request is ignored if metadata is not provided.\n• None : metadata is not requested and the meta-estimator will not pass it to .\n• None : metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n• None : metadata should be passed to the meta-estimator with this given alias instead of the original name. The default ( ) retains the existing request. This allows you to change the request for some parameters and not others. This method is only relevant if this estimator is used as a sub-estimator of a meta-estimator, e.g. used inside a . Otherwise it has no effect."
    },
    {
        "link": "https://scikit-learn.org/0.15/modules/generated/sklearn.ensemble.RandomForestClassifier.html",
        "document": "The number of trees in the forest. The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific. The number of features to consider when looking for the best split:\n• If int, then consider features at each split.\n• If float, then is a percentage and features are considered at each split.\n• If None, then . Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than features. Note: this parameter is tree-specific. The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. Ignored if is not None. Note: this parameter is tree-specific. The minimum number of samples required to split an internal node. Note: this parameter is tree-specific. The minimum number of samples in newly created leaves. A split is discarded if after the split, one of the leaves would contain less then samples. Note: this parameter is tree-specific. Grow trees with in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes. If not None then will be ignored. Note: this parameter is tree-specific. Whether bootstrap samples are used when building trees. Whether to use out-of-bag samples to estimate the generalization error. The number of jobs to run in parallel for both and . If -1, then the number of jobs is set to the number of cores. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by . Controls the verbosity of the tree building process."
    },
    {
        "link": "https://datacamp.com/tutorial/random-forests-classifier-python",
        "document": "Master the basics of data analysis with Python in just four hours. This online course will introduce the Python interface and explore popular packages."
    },
    {
        "link": "https://scikit-learn.sourceforge.net/dev/modules/generated/sklearn.ensemble.RandomForestClassifier.html",
        "document": "The number of trees in the forest. The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific. The number of features to consider when looking for the best split:\n• If int, then consider features at each split.\n• If float, then is a percentage and features are considered at each split.\n• If “sqrt”, then (same as “auto”).\n• If None, then . Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than features. Note: this parameter is tree-specific. The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. Ignored if is not None. Note: this parameter is tree-specific. The minimum number of samples required to split an internal node. Note: this parameter is tree-specific. The minimum number of samples in newly created leaves. A split is discarded if after the split, one of the leaves would contain less then samples. Note: this parameter is tree-specific. The minimum weighted fraction of the input samples required to be at a leaf node. Note: this parameter is tree-specific. Grow trees with in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes. If not None then will be ignored. Note: this parameter is tree-specific. Whether bootstrap samples are used when building trees. Whether to use out-of-bag samples to estimate the generalization error. The number of jobs to run in parallel for both and . If -1, then the number of jobs is set to the number of cores. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by . Controls the verbosity of the tree building process. When set to , reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. class_weight : dict, list of dicts, “balanced”, “balanced_subsample” or None, optional Weights associated with classes in the form . If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown. For multi-output, the weights of each column of y will be multiplied. Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified."
    },
    {
        "link": "https://geeksforgeeks.org/random-forest-classifier-using-scikit-learn",
        "document": "Random Forest is a method that combines the predictions of multiple decision trees to produce a more accurate and stable result. It can be used for both classification and regression tasks.\n\nIn classification tasks, Random Forest Classification predicts categorical outcomes based on the input data. It uses multiple decision trees and outputs the label that has the maximum votes among all the individual tree predictions and in this article we will learn more about it.\n\nRandom Forest Classification works by creating multiple decision trees each trained on a random subset of data. The process begins with Bootstrap Sampling where random rows of data are selected with replacement to form different training datasets for each tree.\n\nThen where only a random subset of features is used to build each tree ensuring diversity across the models.\n\nDuring the training phase Feature Sampling is applied to each tree built by recursively partitioning the data based on the features. At each split the algorithm selects the best feature from the random subset optimizing for information gain or Gini impurity. The process continues until a predefined stopping criterion is met such as reaching maximum depth or having a minimum number of samples in each leaf node. After the trees are trained each tree makes a prediction. The final prediction for classification tasks is determined by majority voting.\n• None By combining predictions from many decision trees it reduces the risk of overfitting compared to a single decision tree.\n• None It is robust to noisy data and works well with categorical data.\n\nBefore implementing random forest classifier in Python let’s first understand it’s parameters.\n• n_estimators: Number of trees in the forest.\n• max_features: Number of features considered for splitting at each node.\n• criterion: Function used to measure split quality (‘gini’ or ‘entropy’).\n• min_samples_leaf: Minimum samples required to be at a leaf node.\n• bootstrap: Whether to use bootstrap sampling when building trees (True or False).\n\nNow that we know it’s parameters we can start building it in python.\n\nWe will be importing Pandas, matplotlib, seaborn and sklearn to build the model.\n\nFor this we’ll use the Iris Dataset which is available within . This dataset contains information about three types of Iris flowers and their respective features (sepal length, sepal width, petal length and petal width).\n\nHere we will separate the features (X) and the target variable (y).\n\nWe’ll split the dataset into training and testing sets so we can train the model on one part and evaluate it on another.\n\nFeature scaling ensures that all the features are on a similar scale which is important for some machine learning models. However Random Forest is not highly sensitive to feature scaling. But it is a good practice to scale when combining models.\n\nWe will create the Random Forest Classifier model, train it on the training data and make predictions on the test data.\n\nWe will evaluate the model using the accuracy score and confusion matrix.\n\nIts perfect accuracy along with the confusion matrix shown by Random Forest Classifier has learned to classify all the instances correctly. However it’s essential to note that the Iris dataset used here is relatively simple and well-known in the machine learning\n\nRandom Forest Classifiers also provide insight into which features were the most important in making predictions. We can plot the feature importance.\n\nFrom the graph we can see that petal width (cm) is the most important feature followed closely by petal length (cm). The sepal width (cm) and sepal length (cm) have lower importance in determining the model’s predictions. This indicates that the classifier relies more on the petal measurements to make predictions about the flower species.\n\nRandom Forest Classifiers are useful for classification tasks offering high accuracy and robustness. They are easy to use, provide insights into feature importance and can handle complex datasets.\n\nWhat is the random forest classifier?\n\nCan random forest be used for regression ?\n\nWhat is the principle of random forest?"
    },
    {
        "link": "https://geeksforgeeks.org/get-financial-data-from-yahoo-finance-with-python",
        "document": "Get Financial Data from Yahoo Finance with Python\n\nThis article will show how to get financial data from Yahoo Finance using Python. We can retrieve company financial information (e.g. financial ratios), as well as historical market data by using this.\n\nLet us install them via pip commands\n\nOnce it is installed, we can import yfinance package in Python code. We need to pass as an argument of Ticker i.e. the company’s ticker.\n\nNote: A stock symbol or a ticker is a unique series of letters assigned to a security for trading purposes. For example:\n• None For Amazon, it is “AMZN”\n• None For Meta, it is “META”\n• None For Google, it is “GOOGL”\n\nBelow are various examples that depict how to retrieve Financial Data from Yahoo Finance:\n\nExample 1: Getting META Financial Information\n\nLet us take the results for Meta and hence use the “META” ticker.\n\nWe can retrieve financial key metrics like Company Sector, Price Earnings Ratio, and Company Beta from the above dictionary of items quickly.\n\nExample 3: Getting META information in key-value pairs\n\nThough we have retrieved a few financial key metrics, as it is a dictionary value, we can split that by means of key-value pair.\n\nWe can retrieve historical market prices too and display them.\n\nExample 5: Getting all the rows of META historical data\n\nIf we want to display all the rows of a ticker symbol, we will use the Python Pandas module and set the set_option() function to display maximum rows.\n\nExample 6: Getting META information for a particular period of time\n\nEven we can have the data for 1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, and ytd. Let us check out for 6 months\n\nExample 7: Getting META information for the provided date range\n\nWe have the flexibility to get historical market data for the provided start and end dates too."
    },
    {
        "link": "https://learndatasci.com/tutorials/python-finance-part-yahoo-finance-api-pandas-matplotlib",
        "document": "Less than a decade ago, financial instruments called derivatives were at the height of popularity. Financial institutions around the world were trading billions of dollars of these instruments on a daily basis, and quantitative analysts were modeling them using stochastic calculus and the all mighty C++. Fast forward nine years later and things have changed. The financial crisis has proven to be an as-to-yet derivatives-nemesis. Volumes have gone down and demand for C++ modeling has withered with them. But there is a new player in town… Python!\n\nPython has been gaining significant traction in the financial industry over the last years and with good reason. In this series of tutorials we are going to see how one can leverage the powerful functionality provided by a number of Python packages to develop and backtest a quantitative trading strategy. In detail, in the first of our tutorials, we are going to show how one can easily use Python to download financial data from free online databases, manipulate the downloaded data and then create some basic technical indicators which will then be used as the basis of our quantitative strategy. To accomplish that, we are going to use one of the most powerful and widely used Python packages for data manipulation, .\n\nPandas and matplotlib are included in the more popular distributions of Python for Windows, such as Anaconda. In case it's not included in your Python distribution, just simply use pip or conda install. Once installed, to use pandas, all one needs to do is import it. We will also need the package ( ), as well as for visualizing our results.\n\nYahoo finance has changed the structure of its website and as a result the most popular Python packages for retrieving data have stopped functioning properly. Until this is resolved, we will be using Google Finance for the rest this article so that data is taken from Google Finance instead. We are using the ETF \"SPY\" as proxy for S&P 500 on Google Finance Please note that there has been some issues with missing data in Google's API, as well as frequent, random errors that occur when pulling a lot of data.\n\nWhat does look like? returns a object, which can be thought of as a 3D matrix. The first dimension consists of the various fields Yahoo Finance returns for a given instrument, namely, the Open, High, Low, Close and Adj Close prices for each date. The second dimension contain the dates. The third one contains the instrument identifiers. Let's see what actually is by temporarily making it a dataframe and calling the top nine rows:\n\nLet us assume we are interested in working with the Close prices which have been already been adjusted by Google finance to account for stock splits. We want to make sure that all weekdays are included in our dataset, which is very often desirable for quantitative trading strategies. Of course, some of the weekdays might be public holidays in which case no price will be available. For this reason, we will fill the missing prices with the latest available prices:\n\nInitially, contains all the closing prices for all instruments and all the dates that Google returned. Some of the week days might be missing from the data Google provides. For this reason we create a Series of all the weekdays between the first and last date of interest and store them in the all_weekdays variable. Getting all the weekdays is achieved by passing the named parameter to the function. This function return a which is shown below:\n\nSuppose we would like to plot the MSFT time-series. We would also like to see how the stock behaves compared to a short and longer term moving average of its price. A simple moving average of the original time-series is calculated by taking for each date the average of the last W prices (including the price on the date of interest). pandas has , a built in function for Series which returns a rolling object for a user-defined window, e.g. 20 days. Once a rolling object has been obtained, a number of functions can be applied on it, such as , (to calculate the standard deviation of the values in the window) or . See below:"
    },
    {
        "link": "https://medium.com/@kasperjuunge/yfinance-10-ways-to-get-stock-data-with-python-6677f49e8282",
        "document": "The library offers Python users a seamless way to retrieve stock data from Yahoo Finance. Whether you're a beginner or a seasoned analyst, this library provides a range of functionalities to help you gather and analyze stock information. In this blog post, we will delve into 10 fundamental ways to retrieve stock data using .\n\nThe method is your go-to for obtaining historical data for any stock.\n\nThe class allows you to access various data for a specific stock.\n\nWant data for the most recent trading days? Here’s how:\n\nRetrieve data for multiple stocks in one go.\n\nObtain adjusted data, which accounts for stock splits, dividends, etc.\n\nRetrieve data based on specific intervals, like daily or weekly."
    },
    {
        "link": "https://algotrading101.com/learn/yfinance-guide",
        "document": "\n• Why should I use the yfinance library?\n• Why shouldn’t I use the yfinance library?\n• What are some of the alternatives to the yfinance library?\n• How do I get started with the yfinance library?\n• How do I download historical data using the yfinance library?\n• How do I download fundamental data using the yfinance library?\n• Fundamentals data with multiple tickers at once\n• How do I download trading data using the yfinance library?\n• How do I download options data using the yfinance library?\n• How do I get Expiration dates?\n• How do I get Calls Data?\n• How do I get Puts Data?\n\nyfinance is a popular open source library developed by Ran Aroussi as a means to access the financial data available on Yahoo Finance.\n\nYahoo Finance offers an excellent range of market data on stocks, bonds, currencies and cryptocurrencies. It also offers market news, reports and analysis and additionally options and fundamentals data- setting it apart from some of it’s competitors.\n\nYahoo Finance used to have their own official API, but this was decommissioned on May 15th 2017, following wide-spread misuse of data.\n\nThese days a range of unofficial APIs and libraries exist to access the same data, including of course yfinance.\n\nNote you might know of yfinance under it’s old name- fix-yahoo-finance, since it was re-named on May 26th 2019 at the same time that it went over a large overhaul to fix some usability issues.\n\nTo ensure backwards compatibility, fix-yahoo-finance now imports and uses yfinance anyway, but Ran Aroussi still recommends to install and use yfinance directly.\n\nIn this article we will focus mainly on the yfinance library, but we discuss the overall range of options and other alternative providers in more depth in our parent article, Yahoo Finance API – A Complete Guide.\n\nYes, yfinance is completely open source and free. You can find the documentation here.\n\nWhy should I use the yfinance library?\n• Quick and easy to set yourself up\n\nAs we have just mentioned yfinance is completely open source and free. There are other ways to access the Yahoo Finance data, some free and some paid, and there are certain benefits to some of the options that require paying, like being ensured a degree of maintenance to the solution, but everybody loves free!\n\nInstallation couldn’t be quicker or easier. yfinance has just 4 dependencies, all of which come with Anaconda anyway, and installs fully in a single line of code. No account creation required, or signing up for and using API keys!\n\nIts simple. yfinance is highly Pythonic in it’s design and incredibly streamlined. It’s as easy as creating a ticker object for a particular ticker/list of tickers and then just calling all the methods on this object. Like this:\n\nDon’t worry, we’ll break down that code further in a bit!\n\nFurthermore, the documentation is concise- fitting on a single page, and the method names are very self explanatory.\n\nHigh granularity of data. One cool feature of yfinance is that you can get highly refined data, all the way down to 5 minute, 3 minute and even 1 minute data! The full range of intervals available are:\n\nHowever it is important to note that the 1m data is only retrievable for the last 7 days, and anything intraday (interval <1d) only for the last 60 days.\n\nyfinance also handily returns data directly in padas dataframes or series. This is on contrast to some other options to access Yahoo Finance’s data where you will get lengthy JSONs you need parse for the specific information you want, and will have to manually convert to data-frames yourself.\n\nWhy shouldn’t I use the yfinance library?\n• Can get yourself rate limited/blacklisted\n\nLacks specialised features. Despite the fact you can use it to get a good range of core data, including options and fundamentals data, yfinance doesn’t provide a method to scrape any of the news reports/analysis that are available on Yahoo Finance.\n\nThis obviously isn’t ideal if you want to build model that relies in part on sentiment analysis, so if you want that sort of data, you might want to check out RapidAPI (which will talk about more shortly) that does offer such data.\n\nAlso, other market data alternatives often include interesting extras. For example Alpha Vantage provides modules that calculate various technical analysis indicators for you- obviously an enormous effort save if you want to build an algorithm utilising any of them! yfinance just provides the basics.\n\nSome methods are fragile. yfinance mainly makes API calls to Yahoo Finance to gather it’s data, but it does occasionally employ HTML scraping and pandas tables scraping to unofficially gather the information off the Yahoo Finance website for some of it’s methods. As such, the functionality of some of it’s methods is at the mercy of Yahoo not changing the layout or design of some of their pages. In fact, yfinance is widely known to already have a few issues.\n\nAs a quick aside, data scraping works by simply downloading the HTML code of a web page, and searching through all the HTML tags to find the specific elements of a page you want.\n\nFor instance below is the Yahoo Finance Apple (‘AAPL’) historical data page:\n\nIf the method to get the historical data HTML scraped, it would be searching the various div, class and tr tags etc. for various IDs to pick out the data that should be returned.\n\nFor instance the class ID “Py(10px) Pstart(10px)” refers to the historical prices populating the table. If in this case Yahoo Finance was to change the class ID pointing to this value, the method might return completely incorrect data, or even nothing at all. Again, this sort of vulnerability doesn’t apply to all of yfinance’s methods- most of them do in fact make direct API calls- but it does affect a few.\n\nIt’s an unofficial solution. Again, because yfinance is simply the result of one man’s hard work and not in any way affiliated with Yahoo Finance, there’s no guarantee if it breaks it will be maintained.\n\nAs we already mentioned it did have a big update to fix issues on May 26th 2019 on the same day it was renamed, but that’s no guarantee problems will be fixed in the future. Are you sure you want to build a trading algorithm on-top of data that might one day suddenly and without warning be wrong? There are already a few known issues with yfinance, which we will highlight later on in this article.\n\nYou can get yourself rate limited/blacklisted. Again because yfinance scrapes data for a few of it’s functions, you sometimes run the risk of getting rate limited or blacklisted for too many scraping attempts.\n\nThis is a risk that’s always present when trying to scrape websites, but when you’re building applications trading real money on-top of infrastructure that might be making a lot of data requests, the risk:reward changes.\n\nOverall yfinance an incredibly beginner friendly option. You’ll be able to dive right in and test out ideas without wasting time puzzling over complex documentation whilst still having access to a good range of data!\n\nThat said, the risk of getting faulty data or being blocked from getting any data at all when employing algorithms trading real money is absolutely unacceptable.\n\nWe think yfinance is great for prototyping, or if you are beginner, or just want to download a bunch of historic data.\n\nBut if you want complete confidence that a serious trading system is going to function with total reliability, we’d absolutely recommend going with a official and alternative market data provider- preferably one claiming to provide low latency data directly from exchanges.\n\nWhat are some of the alternatives to the yfinance library?\n\nOf the two alternatives to yfinance we will consider, RapidAPI is the most distinct.\n\nFirstly, whilst it does still have a limited usage free tier, you will have to pay for anything over 500 requests per month:\n\nSecondly, its not quite as simple as yfinance to get started with. You will have to sign up for an account to get your own access API keys.\n\nThat said, a big plus of RapidAPI is that you can use it with 15 different languages, if for some reason Python isn’t your thing:\n\nIt also offers more range of data than our other options, specifically the option to download market news and analysis which is fantastically useful if you want to add a degree of sentiment analysis in your model!\n\nMaking snap trading decisions based on machine scanning of news far faster than a human ever could can be one way (if slightly uncertain) to gain a trading edge.\n\nThat said RapidAPI does have a few drawbacks.\n\nAs you can see requests have an average latency of 1660ms which isn’t terrible, but alternative data providers such as polygon.io offer anything from 200ms down to 1ms delays- quite the difference.\n\nMore concerning is the fact requests only have a 98% success rate. Having 1 in 50 data requests fail could be a big deal if you have a system trading real money, especially if you are making a lower frequency of calls. Definitely something to consider.\n\nResults returned can also be in quite lengthy and nested JSONs, making the data a bit trickier to get ready for use than when using yfinance:\n\nThat said a further plus of RapidAPI is that it offers a huge range of APIs for other purposes, so familiarising yourself with how to use the their API for Yahoo Finance data might carry over into easily using another of their APIs for a different project in the future.\n\nIn summary, RapidAPI offers a very limited free tier, but perhaps by using a solution where some people are paying, it is more likely that any scraping issues from Yahoo Finance structure changes are resolved more quickly.\n\nIts also fiddlier to use and harder get started with, but does provide a bigger range of data than our other two options.\n\nyahoo_fin is an open source and free library similar to yfinance.\n\nYou can find the documentation here.\n\nIt offers a similar range of data to yfinance, but notably has a few functions that generate all the tickers for certain markets for you:\n\nwhich is a useful feature yfinance lacks.\n\nWe actually focus on the yahoo_fin library in the example sections of our parent article, Yahoo Finance API – A Complete Guide, so we won’t talk about it anymore here.\n\nHow do I get started with the yfinance library?\n\nGetting started with the yfinance library is super easy.\n\nIt has the following dependencies:\n\nThese all come as standard in an installation with Anaconda, but are really easy to install manually if for some reason you don’t have them.\n\nAfter that its as easy as:\n\nThe layout itself is also really simple, there are just three modules:\n\nAlmost all the methods are in the Tickers module.\n\nThe download module is for rapidly downloading the historical data of multiple tickers at once.\n\nAnd pandas_datareader is for back compatibility with legacy code, which we will ignore as irrelevant since if you’re reading this you are probably a new user of the library!\n\nHow do I download historical data using the yfinance library?\n\nFirstly, lets import yfinance as yf and create ourselves a ticker object for a particular ticker (stock):\n\nRemember we now use this aapl ticker object for almost everything- calling various methods on it.\n\nTo get the historical data we want to use the history() method, which is the most “complicated” method in the yfinance library.\n\nIt takes the following parameters as input:\n• period: data period to download (either use period parameter or use start and end) Valid periods are:\n• interval: data interval (1m data is only for available for last 7 days, and data interval <1d for the last 60 days) Valid intervals are:\n• start: If not using period – in the format (yyyy-mm-dd) or datetime.\n• end: If not using period – in the format (yyyy-mm-dd) or datetime.\n• prepost: Include Pre and Post regular market data in results? (Default is )- no need usually to change this from False\n• auto_adjust: Adjust all OHLC (Open/High/Low/Close prices) automatically? (Default is )- just leave this always as true and don’t worry about it\n\nThat might look a little complex but mainly you will just be changing the period (or start and end) and interval parameters.\n\nSo as an example, to get 1minute historical data for Apple between 02/06/2020 and 07/06/2020 (British format) we just use the ticker object we created and run:\n\nIt’s as simple as that!\n\nTo download the historical data for multiple tickers at once you can use the download module.\n\nIt takes mostly the same arguments as the history() method on a ticker object, but additionally:\n• group_by: group by column or ticker (‘column’/’ticker’, default is ‘column’)\n• proxy: proxy URL if you want to use a proxy server for downloading the data (optional, default is None)\n\nFor example to get the data for Amazon, Apple and Google all at once we can run:\n\nNote that the default with no interval specified is daily data.\n\nThen, if we want to group by ticker instead of Open/High/Low/Close we can do:\n\nHow do I download fundamental data using the yfinance library?\n\nYou can get the price to earnings ratio with the Ticker.info() method.\n\nTicker.info() returns a dictionary with a wide range of information about a ticker, including such things as a summary description, employee count, marketcap, volume, P/E ratios, dividends etc.- we recommend taking a look at it yourself as it takes a lot of space to show, but in short if you can’t find the information you’re looking for with the other methods, try the info() method!\n\nTo get specifically the price to earnings ratio search the dictionary for ‘forwardPE’:\n\nYou can get the yearly dividend % also by using info():\n\nAnd if you want a breakdown of each dividend payout as it occurred and on what date, you can use Ticker.dividends():\n\nFundamentals data with multiple tickers at once\n\nWe might also want to grab fundamentals (or other) data for a bunch of tickers at once.\n\nLets have a go at doing that and then try comparing our tickers by a particular attribute!\n\nTo do this we can start by creating a list of the tickers we want to get data for, and an empty dictionary to store all the data.\n\nWe will need to use the pandas library to manipulate the data frames:\n\nWe then loop through the list of the tickers, in each case adding to our dictionary a key, value pair where the key is the ticker and the value the dataframe returned by the info() method for that ticker:\n\nWe then combine this dictionary of dataframes into a single dataframe:\n\nAnd then delete the unnecessary “level_1” column and clean up the column names:\n\nGreat, so we now know how to get any data we want for multiple tickers at once into the same dataframe!\n\nBut how do we easily compare by a particular attribute?\n\nIt’s quite easy actually, lets try for one of the attributes in info()– the fullTimeEmployees count:\n\nSo now we have a dataframe of just the employee counts- one entry per ticker- and we can now order by the ‘Recent’ column:\n\nBoom! Obviously not that required with only 5 tickers in our list, but a fantastically easy and powerful way to quickly compare by a particular attribute if we had the ticker list of an entire market!\n\nYou can easily use this exact same method to compare any attribute you want!\n\nHow do I download trading data using the yfinance library?\n\nYou can find the data for all three of Market Cap, Volume and Highs and Lows from the info() method.\n\nTo get the market cap, use:\n\nTo find the current volume do:\n\nIf you want the average volume over the last 24 hours do:\n\nAnd finally if you want the average volume over the last 10 days:\n\nRemember, you can find the highs and lows for any time interval:\n\nwithin a desired period by using the history() method and adjusting the interval.\n\nFor example, to get the weekly highs and lows for all the historical data that exists, use:\n\nJust filter the dataframe with:\n\nAnd so forth to get the individual columns.\n\nAlternatively, you can use info() to get the following useful high/low information:\n\nHow do I download options data using the yfinance library?\n\nBriefly, options are contracts giving a trader the right, but not the obligation, to buy (call) or sell (put) the underlying asset they represent at a specific price on or before a certain date.\n\nTo download options data we can use the option_chain() method. It takes the parameter as input:\n• date: (YYYY-MM-DD), expiry date. If None return all options data.\n\nAnd has the opt.calls and opt.puts methods.\n\nTo get the various expiry dates for options for a particular ticker it’s as easy as:\n\nHow do I get Calls Data?\n\nTo get the calls data, we can do:\n\nHow do I get Puts Data?\n\nTo get puts data, we do:\n\nFinally, opts by itself returns a ticker object containing both the calls and puts data together, if that’s useful to you!\n\nAs we highlighted near the beginning of this article, yfinance is an unofficial scraping solution to gather data from Yahoo Finance, so is subject to breaking if Yahoo Finance changes any of its layout.\n\nUnfortunately this already seems to have happened in part, with the following problems discovered when writing this guide:\n• Tickers, the multiple tickers object for interacting with multiple tickers at once, doesn’t seem to work. We have provided a more manual workaround for this in the Fundamentals data with multiple tickers at once section.\n• The financials, quarterly_financials, balance_sheet, quarterly_balance_sheet, cashflow, quarterly_cashflow, earnings, quarterly_earnings Ticker methods do not work and return empty dataframes.\n\nThis is a big problem as in many cases there is no alternative way to the data in some of these methods from other methods in yfinance.\n\nIf you are building something that requires any of this data, for example balance sheets and income and cashflow statements and still want free access to the Yahoo Finance data, check out the yahoo_fin library in the examples section of our guide https://algotrading101.com/learn/yahoo-finance-api/ which has working methods to get all of this data!\n\nSo clearly as we have just demonstrated, yfinance is NOT a safe bet to build critical infrastructure on.\n\nIf you want to build algorithms trading real money, we absolutely recommend you use an official data source/API, preferably one connected directly to exchange data and with low latency. Something like Polygon.io or IEX might suit you better.\n\nIf you absolutely HAVE to use the Yahoo Finance data specifically, we recommend at least paying for an unofficial API like RapidAPI, where you stand a good bet there is an active team of developers constantly maintaining the API. Remember RapidAPI does still have a limited usage free tier!\n\nThat said, yfinance can be good to use to build test applications as a beginner, as the sections of it that do work are fantastically easy to get started with and use.\n\nA particular forte of yfinance is that the threads parameter of yf.download does allow very rapid downloading of historical for multiple tickers when set to True!\n\nYou can find the code used in this article here."
    },
    {
        "link": "https://saturncloud.io/blog/how-to-use-python-and-pandas-with-yahoo-finance-api",
        "document": "How to Use Python and Pandas with Yahoo Finance API\n\nIn this blog, we will explore the necessity data scientists and software engineers often face when seeking access to financial data for analysis or modeling. Yahoo Finance API emerges as a straightforward and user-friendly interface for obtaining such financial data. Within this tutorial, we will walk you through the process of leveraging Python and Pandas to retrieve and manipulate financial data seamlessly using the Yahoo Finance API.\n\nAs a data scientist or software engineer, you may have come across the need to access financial data for analysis or modeling. Yahoo Finance API provides a simple and easy-to-use interface for accessing financial data. In this tutorial, we will guide you through the steps of using Python and Pandas to retrieve and manipulate financial data using Yahoo Finance API.\n\nYahoo Finance API is a free financial data API that provides real-time stock quotes, historical data, and financial news for stocks, bonds, currencies, commodities, and indices. The API offers a range of endpoints that allow you to access data in various formats such as JSON, CSV, and XML. Yahoo Finance API is widely used by financial analysts, traders, and data scientists to retrieve financial data for analysis and modeling.\n\nBefore we begin, make sure you have the following installed:\n\nYou can install Pandas and yfinance libraries using pip:\n\nAfter its installation, the yfinance package can be imported into Python code. The Ticker, representing the company’s unique identifier, needs to be passed as an argument.\n\nNote: A stock symbol or ticker is a distinct sequence of letters assigned to a security for trading purposes. Examples include:\n\nBelow are various examples that depict how to retrieve Financial Data from Yahoo Finance:\n\nLet us take the results for Apple and hence use the “AAPL” ticker.\n\nThis Python code uses the yfinance library to retrieve the historical stock data for Apple Inc. (AAPL) for the most recent date ( corresponds to one day) using the history method of the object.\n\nTo obtain historical data, you can either specify the duration (by modifying the in the previous example to the desired period) or define a specific time range.\n\nIn the following code, we will retrieve data for multiple stocks and store it in a DataFrame named . Subsequently, we will compute the daily returns and use the Matplotlib package to plot the cumulative returns for all the stock prices.\n\nCheck for typos or ensure the ticker symbol is valid before making requests.\n\nHandle missing or incomplete data gracefully, considering options like data interpolation or filling.\n\nIn this tutorial, we have shown you how to use Python and Pandas with Yahoo Finance API to retrieve financial data. Yahoo Finance API provides a simple and easy-to-use interface for accessing financial data, making it an ideal tool for data scientists and software engineers working with financial data. By following the steps outlined in this tutorial, you can quickly and easily retrieve financial data using Python and Pandas.\n\nSaturn Cloud is your all-in-one solution for data science & ML development, deployment, and data pipelines in the cloud. Spin up a notebook with 4TB of RAM, add a GPU, connect to a distributed cluster of workers, and more. Request a demo today to learn more."
    }
]