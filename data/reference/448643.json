[
    {
        "link": "https://chromewebstore.google.com/detail/audiocontext-fingerprint/pcbjiidheaempljdefbdplebgdgpjcbe?hl=en",
        "document": "Defending against AudioContext fingerprinting by reporting a fake value.\n\nAudioContext Fingerprint Defender is an extension that let you easily hide your real audiocontext fingerprint by reporting a random fake value and protecting your privacy. This addon does NOT block AudioContext or any other web audio API methods, instead, it simply adds a small noise to the actual fingerprint and \"renews\" it every time you visit a website or reload a page. It is important to note that, this addon does not have any settings or options to adjust. Simply add it to your browser and start surfacing the internet. If you want to test this addon, please visit a website that shows your fingerprint (i.e. audiofingerprint.openwpm). Every time you reload the page, you will see a new fake fingerprint. Note: depending on your browser and platform, you may need to (Shift+Refresh) a web page to renew the AudioContext fingerprint. To report bugs, please visit the addon's homepage (https://mybrowseraddon.com/audiocontext-defender.html) and fill out the bug report form."
    },
    {
        "link": "https://fingerprint.com/blog/audio-fingerprinting",
        "document": "Did you know you can identify web browsers without cookies or asking for permissions?\n\nBrowser fingerprinting works by reading browser attributes and combining them into a single identifier removing the need for cookies or asking for permission. This identifier is stateless and works well in normal and incognito modes.\n\nWhen generating a browser identifier, we can read browser attributes directly or use attribute processing techniques first. One of the creative techniques that we’ll discuss today is audio fingerprinting.\n\nAudio fingerprinting is a valuable technique because it is relatively unique and stable. Its uniqueness comes from the internal complexity and sophistication of the Web Audio API. It is stable because the audio source we’ll use is a sequence of numbers generated mathematically and when combined into a single audio fingerprint value.\n\nBefore we dive into the technical implementation, we need to understand a few ideas from the Web Audio API and its building blocks.\n\nA brief overview of the Web Audio API\n\nThe Web Audio API is a powerful system for handling audio operations. Designed to work inside an AudioContext, the Web Audio API links together audio nodes and builds an audio graph. A single AudioContext can handle multiple types of audio sources that plug into other nodes and form chains of audio processing.\n\nA source can be an element, a stream, or an in-memory source generated mathematically with an . We’ll use the for our purposes and then connect it to other nodes for additional processing.\n\n \n\n Before we dive into the audio fingerprint implementation details, it’s helpful to review all of the building blocks of the API that we’ll be using.\n\nrepresents an entire chain built from audio nodes linked together. It controls the nodes’ creation and the audio processing execution. You always start by creating an instance of before you do anything else. It’s a good practice to create a single instance and reuse it for all future processing.\n\n \n\n has a destination property representing the destination of all audio from that context.\n\n \n\n There also exists a special type of : . The main difference is that it does not render the audio to the device hardware. Instead, it generates the audio as fast as possible and saves it into an AudioBuffer. Thus, the destination of the OfflineAudioContext will be an in-memory data structure, while with a regular AudioContext, the destination will be an audio-rendering device.\n\n \n\n When creating an instance of , we pass arguments:\n• A sample rate in samples per second\n\nAn is a small audio snippet stored within memory. Data of that snippet is represented internally in Linear PCM, with each sample represented by a -bit float between and It can hold multiple channels, but for our purposes we’ll use only one.\n\nWhen working with audio, we always need a source. An is a good candidate because it generates samples mathematically, unlike playing an audio file. generates a periodic waveform with a specified frequency in its simplest form.\n\n \n\n The default shape is a sine wave.\n\nIt’s also possible to generate other waves, such as square, sawtooth, and triangle.\n\n \n\n The default frequency is Hz, which is a standard A4 note.\n\nThe Web Audio API provides a , which lowers the volume of the loudest parts of the signal and helps prevent distortion or clipping.\n\n \n\n has many exciting properties that we’ll use. These properties will help create more variability between browsers.\n• Threshold: value in decibels above which the compressor will start taking effect.\n• Knee: value in decibels representing the range above the threshold where the curve smoothly transitions to the compressed portion.\n• Ratio: The amount of input change, in dB, needed for a dB change in the output.\n• Reduction: The float represents the amount of gain reduction currently applied by the compressor to the signal.\n• Attack: the amount of time, in seconds, required to reduce the gain by dB. This value can be a decimal.\n• Release: the amount of time, in seconds, required to increase the gain by dB.\n\nHow to calculate an audio fingerprint\n\nNow that we have all the concepts we need, we can start working on our audio fingerprinting code.\n\n \n\n Safari doesn’t support unprefixed , but does support , so we’ll use this method to make it work in Chrome and Safari:\n\nNow we create an instance. We’ll use one channel, a sample rate and samples total, which will make it about ms long.\n\nNext let’s create a sound source - an instance. It will generate a triangular-shaped sound wave that will fluctuate times per second ( ).\n\nNow let’s create a compressor to add more variety and transform the original signal. Note that the values for all these parameters are arbitrary and meant to change the source signal in interesting ways. We could use other values, and it would still work.\n\nLet’s connect our nodes together: to , and compressor to the context destination.\n\nIt is time to generate the audio snippet. We’ll use the event to get the result when it’s ready.\n\nis an array of floating-point values that represents the uncompressed sound. Now we need to calculate a single value from that array.\n\n \n\n Let’s do it by simply summing up a slice of the array values:\n\nNow we are ready to generate the audio fingerprint. When I run it on Chrome on MacOS I get the value:\n\nThat’s all there is to it. Our audio fingerprint is this number!\n\n \n\n You can check out a production implementation in our open source browser fingerprinting library.\n\n \n\n If I try executing the code in Safari, I get a different number:\n\nAnd get another unique result in Firefox:\n\nEvery browser we have on our testing laptops generates a different value. However, this value is stable and remains the same in incognito mode.\n\n \n\n This value depends on the underlying hardware and OS, and in your case, may be different.\n\nWhy the audio fingerprint varies by browser\n\nLet’s look at why the values differ in different browsers. First, we’ll examine a single oscillation wave in Chrome and Firefox.\n\n \n\n First, let’s reduce the duration of our audio snippet to of a second, corresponding to a single wave, and examine the values that make up that wave.\n\n \n\n We need to change our context duration to samples, which roughly corresponds to a of a second. We’ll skip the compressor and only examine the differences in the unmodified signal.\n\nHere is how a single triangular oscillation looks in both Chrome and Firefox now:\n\nHowever, the underlying values are different between the two browsers (I’m showing only the first values for simplicity):\n\nLet’s take a look at this demo to visually see those differences.\n\nHistorically, all major browser engines (Blink, WebKit, and Gecko) based their Web Audio API implementations on code originally developed by Google in 2011 and 2012 for the WebKit project.\n\nExamples of Google contributions to the Webkit project include:\n\n\n\n Since then browser developers have made a lot of small changes. These changes, compounded by the large number of mathematical operations involved, lead to fingerprinting differences. Audio signal processing uses floating point arithmetic, which also contributes to discrepancies in calculations.\n\n \n\n You can see how these things are implemented now in the three major browser engines:\n\nAdditionally, browsers use different implementations for different CPU architectures and OSes to leverage features like SIMD. For example, Chrome uses a separate fast Fourier transform implementation on macOS (producing a different oscillator signal) and other vector operation implementations on different CPU architectures (used in the DynamicsCompressor implementation). These platform-specific changes also contribute to differences in the final audio fingerprint.\n\nFingerprint results also depend on the Android version (it’s different in Android 9 and 10 on the same devices, for example).\n\nAccording to browser source code, audio processing doesn’t use dedicated audio hardware or OS features—the CPU does all calculations.\n\nWhen we started to use audio fingerprinting in production, we aimed to achieve good browser compatibility, stability, and performance. We also looked at privacy-focused browsers, such as Tor and Brave, for high browser compatibility.\n\nAs you can see on caniuse.com, works almost everywhere. But some cases need special handling.\n\nThe first case is iOS 11 or older. It does support , but the rendering only starts if triggered by a user action, for example, by a button click. If is not triggered by a user action, the will be suspended, and the rendering will hang indefinitely unless you add a timeout. Not many users still use this iOS version, so we decided to disable audio fingerprinting for them.\n\nThe second case is browsers on iOS 12 or newer. They can reject starting audio processing if the page is in the background. Luckily, browsers allow you to resume the processing when the page returns to the foreground. When the page is activated, we attempt calling several times until the context.state becomes running. If the processing doesn’t start after several attempts, the code stops. We use a regular in addition to our retry strategy in case of an unexpected error or freeze. You can see a code example here.\n\nIn the case of the Tor browser, everything is simple. But unfortunately, web Audio API is disabled there, so audio fingerprinting is impossible.\n\nWith Brave, the situation is more nuanced. Brave is a privacy-focused browser based on Blink. It is known to slightly randomize the audio sample values, which it calls “farbling.”\n\nBrave offers three levels of farbling (users can choose the level they want in settings):\n• Disabled: No farbling is applied. The fingerprint is the same as in other Blink browsers such as Chrome.\n• Standard: This is the default value. The audio signal values are multiplied by a fixed number, called the “fudge” factor, that is stable for a given domain within a user session. In practice, the audio wave sounds and looks the same but has tiny variations that make it challenging to use in fingerprinting.\n• Strict: The sound wave is replaced with a pseudo-random sequence.\n\nThe farbling modifies the original Blink AudioBuffer by transforming the actual audio values.\n\nTo revert the farbling, we need to obtain the fudge factor first. Then we can get back the original buffer by dividing the farbled values by the fudge factor:\n\nUnfortunately, floating point operations lack the precision to get the original samples. The table below shows restored audio fingerprints in different cases and shows how close they are to the initial values:\n\nAs you can see, the restored Brave fingerprints are closer to the original fingerprints than other browsers’ fingerprints. This restoration means that you can use a fuzzy algorithm to match them. For example, if the difference between a pair of audio fingerprint numbers is more than , you can assume that these are different devices or browsers.\n\nLook at what happens under the hood in Chrome during audio fingerprint generation. In the screenshot below, the horizontal axis is time, the rows are execution threads, and the bars are time slices when the browser is busy. You can learn more about the performance panel in this Chrome article. The audio processing starts at ms and completes at ms:\n\nThe main thread, labeled as “Main” on the image, handles user input (mouse movements, clicks, taps, etc.) and animation. When the main thread is busy, the page freezes. Therefore, it’s a good practice to avoid running blocking operations on the main thread for more than several milliseconds.\n\nAs you can see in the image above, the browser delegates some work to the OfflineAudioRender thread, freeing the main thread. Therefore the page stays responsive during most of the audio fingerprint calculation.\n\nWeb Audio API is not available in web workers, so we cannot calculate audio fingerprints there.\n\nThe table below shows the time it takes to get a fingerprint on different browsers and devices. The time is measured immediately after the cold page load.\n\nAudio fingerprinting is only a tiny part of the larger identification process.\n\nAudio fingerprinting is one of the many signals our open source library uses to generate a browser fingerprint. However, we do not blindly incorporate every signal available in the browser. Instead, we analyze the stability and uniqueness of each signal separately to determine their impact on fingerprint accuracy.\n\nFor audio fingerprinting, we found that the signal contributes only slightly to uniqueness but is highly stable, resulting in a slight net increase in fingerprint accuracy.\n\nOur beginner’s guide to browser fingerprinting further discusses stability, uniqueness, and accuracy.\n\nTry Browser Fingerprinting for Yourself\n\nBrowser fingerprinting is a valuable visitor identification method for various anti-fraud applications. Identifying malicious visitors attempting to circumvent tracking by clearing cookies, browsing in incognito mode, or using a VPN is beneficial.\n\nYou can try implementing browser fingerprinting yourself with our open source library. FingerprintJS is the most popular browser fingerprinting library, with over 17K GitHub stars.\n\nWe also developed the Fingerprint Pro API for higher identification accuracy, which uses machine learning to combine browser fingerprinting with additional identification techniques. You can try Fingerprint Pro with unlimited API requests for the first fourteen days.\n• Email us your questions at oss@fingerprint.com\n• Join our team to work on exciting research in online security."
    },
    {
        "link": "https://developer.chrome.com/docs/extensions/reference/api/audio",
        "document": "Important: This API works only on ChromeOS.\n\nThe chrome.audio API is provided to allow users to get information about and control the audio devices attached to the system. This API is currently only available in kiosk mode for ChromeOS.\n• The unique identifier of the audio device.\n• True if this is the current active device.\n• The sound level of the device, volume for output, gain for input.\n• The stable/persisted device id string when available.\n• Stream type associated with this device.\n• If set, only audio devices whose active state matches this value will satisfy the filter.\n• If set, only audio devices whose stream type is included in this list will satisfy the filter.\n• List of input devices specified by their ID. To indicate input devices should be unaffected, leave this property unset.\n• List of output devices specified by their ID. To indicate output devices should be unaffected, leave this property unset.\n• The audio device's desired sound level. Defaults to the device's current sound level. If used with audio input device, represents audio device gain. If used with audio output device, represents audio device volume.\n• ID of device whose sound level has changed.\n• Whether or not the stream is now muted.\n• The type of the stream for which the mute value changed. The updated mute value applies to all devices with this stream type. Type of stream an audio device provides.\n\nGets a list of audio devices filtered based on .\n• Device properties by which to filter the list of returned audio devices. If the filter is not set or set to , returned device list will contain all available audio devices.\n• The parameter looks like:\n• Promises are supported in Manifest V3 and later, but callbacks are provided for backward compatibility. You cannot use both on the same function call. The promise resolves with the same type that is passed to the callback. Gets the system-wide mute state for the specified stream type.\n• Stream type for which mute state should be fetched.\n• The parameter looks like:\n• Promises are supported in Manifest V3 and later, but callbacks are provided for backward compatibility. You cannot use both on the same function call. The promise resolves with the same type that is passed to the callback.\n• Specifies IDs of devices that should be active. If either the input or output list is not set, devices in that category are unaffected. It is an error to pass in a non-existent device ID.\n• The parameter looks like:\n• Promises are supported in Manifest V3 and later, but callbacks are provided for backward compatibility. You cannot use both on the same function call. The promise resolves with the same type that is passed to the callback. Sets mute state for a stream type. The mute state will apply to all audio devices with the specified audio stream type.\n• Stream type for which mute state should be set.\n• The parameter looks like:\n• Promises are supported in Manifest V3 and later, but callbacks are provided for backward compatibility. You cannot use both on the same function call. The promise resolves with the same type that is passed to the callback. Sets the properties for the input or output device.\n• The parameter looks like:\n• Promises are supported in Manifest V3 and later, but callbacks are provided for backward compatibility. You cannot use both on the same function call. The promise resolves with the same type that is passed to the callback.\n\nFired when audio devices change, either new devices being added, or existing devices being removed.\n• The parameter looks like: Fired when sound level changes for an active audio device.\n• The parameter looks like: Fired when the mute state of the audio input or output changes. Note that mute state is system-wide and the new value applies to every audio device with specified stream type.\n• The parameter looks like:"
    },
    {
        "link": "https://chromewebstore.google.com/detail/scriptsafe/oiigbmnaadbkfbmpbfijlflahbdbdgdf?hl=en-US",
        "document": "Regain control of the web and surf more securely.\n\nv1.0.8.x - \"Can't Touch This\" v1.0.8.0 - Thursday, June 30, 2016 - Revamped the design of the Update page and the Options page: wider layout, larger/more readable words, and intuitive buttons. On the new Options page you are able to toggle between Grouped and List views by clicking on the button in the top-right corner. - Fingerprinting Protection section contains the following options (all disabled by default, one or two have been added since v1.0.7.15): --- Canvas Fingerprint Protection - protect against fingerprinting attempts through <canvas> elements, with the following options: ------ Disabled ------ Blank Readout (serve an empty canvas with the original dimensions) ------ Random Readout (serve an empty canvas with random dimensions) ------ Completely Block Readout (refuse to serve any data) --- Block Audio Fingerprinting - prevent fingerprinting via the AudioContext API --- Block WebGL Fingerprinting - prevent fingerprinting via the WebGL API --- Block Battery Fingerprinting - prevent fingerprinting via the Battery API --- Block Device Enumeration - prevent having hardware devices detected via the WebRTC API --- Block Gamepad Enumeration - prevent having hardware devices detected via the Gamepad API --- Block Canvas Font Access - prevent system fonts from being enumerated through <canvas> elements --- Block Client Rectangles Fingerprinting - prevent fingerprinting through calculating element client rectangles) --- Reduce Keyboard Fingerprinting (for advanced users) - make keypress timings more random to increase anonymity (note: adds a random delay between keypresses)) --- I recommend enabling all of the above options (except the last two) for increased privacy, and based on your needs disable the options that interfere with your usage. - Added Remove Google Analytics (UTM) Tracking option (under Privacy Settings) - remove Google Analytics (UTM) tracking tokens before they're actually passed to the server (disabled by default) - Added Remove Possible Hash Tracking option (under Privacy Settings) - remove possible tracking tokens passed using hash, where there is an attribute and value (e.g. #xtor=RSS-1) (disabled by default) - Added Spoof Timezone option (under Privacy Settings) - spoof or randomize your timezone; useful if you use VPN (disabled by default) - Added Prevent Clipboard Interference option (under Behavior Settings) - prevent pages from interfering with clipboard actions (disabled by default) - Added option to apply user-agent spoofing on whitelisted domains as well (default behaviour is to disable spoofing on whitelisted domains to avoid issues, but enabling this option will spoof the user-agent regardless) - Added Save as Text File functionality to the Export Settings portion in the Options page - Fix Panel expand issue for Mac OS X users - Updated unwanted content providers list - I now have a Bitcoin address due to inquiries from people wary of PayPal but wanted to still donate! 39VJ5L9Yd6WocG6r88uE7ZZnM5J2M5bW92 (also found at the top of the Update and Options pages) =============================== Past Releases: See complete changelog here: https://www.andryou.com/scriptsafe/changelog/ ===================== Bug reports/downloads/support: https://github.com/andryou/scriptsafe An extension that gives users control of the web and more secure browsing while emphasizing simplicity and intuitiveness: -whitelisting/blacklisting functionality and granular control -protection against fingerprinting (e.g. canvas) -protect against WebRTC leaks -automatic auto-syncing of settings AND whitelist/blacklists across your devices (via Google Sync) -actually speeds up browsing because it blocks a lot of unwanted content from being downloaded -remove <SCRIPT>, <OBJECT>, <EMBED>, <IFRAME>, <FRAME>, <APPLET>, <AUDIO>, <VIDEO>, <NOSCRIPT>, and <IMG> elements, as well as webbugs -block unwanted content (MVPS HOSTS, hpHOSTS (ad / tracking servers only), Peter Lowe's HOSTS Project, MalwareDomainList.com, and DNS-BH – Malware Domain Blocklist are integrated!) -block click-through referrer data -spoof referrer/user-agent/timezone data -block unwanted cookies -\"intuitive\" icon that changes based on whether or not a page is whitelisted/blacklisted/bypassed -shows number of blocked/removed items in toolbar -shows blocked/allowed items in tab details popup (along with item type) -bulk import domains into whitelist and blacklist -option to temporarily allow a page/temporarily allow all blocked items -choose the default mode (Block All or Allow All) -option to preserve same-domain elements -option to disable automatic refresh of pages after whitelisting/blacklisting/temp. bypassing a page -support for IPv6 addresses If you like this extension, please support me by going to the Options page and clicking on the heart! Enjoy :) If you are bilingual/multilingual (english + other language), and are interested in helping translate ScriptSafe, contact me: andryou@gmail.com -Andrew Y. (creator of Decreased Productivity for Chrome)"
    },
    {
        "link": "https://reddit.com/r/programming/comments/mb0ob8/how_the_web_audio_api_is_used_for_browser",
        "document": "Create your account and connect with a world of communities.\n\nBy continuing, you agree to our\n\nand acknowledge that you understand the"
    },
    {
        "link": "https://acoustid.org/webservice",
        "document": "The AcoustID web service currently supports only two operations, searching in the fingerprint database and submitting new fingerprints into the database.\n\nRemember that this is an open source project, with hopes to provide free and useful service. Please respect the following guidelines when integrating it into your application.\n• No commercial usage — This service is provided for free for non-commercial use only. If you would like to use the service in a commercial application, please sign up here.\n• Rate limiting — Do not make more than 3 requests per second.\n• Don't do anything illegal — Don't use this service in connection with any illegal products or services.\n• Let us know — If you are deploying an application that you expect to generate significant traffic to this service, please let us know in advance.\n\nYou can use both GET and POST HTTP methods to send requests to the web service, but since the audio fingerprints get fairly long, compressed POST requests are prefered.\n\nThe web service can return results in two formats, XML and JSON. If you don't specify which one you prefer, it will return JSON.\n\nAll text returned by the web service is encoded using UTF-8.\n\nEven though compressing HTTP requests is not a common practice, our web server supports GZip-compressed bodies for HTTP POST requests. If you compress the body using GZip and set the \"Content-Encoding\" HTTP header to \"gzip\", we will decode it before parsing the parameters.\n\nThere are two kinds of API keys used by the web service.\n\nIn order to use the web service from your application, you need to register the application. This will give you an API key that you can use in the parameter. You can use the API key from the examples below for initial testing, but note that it will automatically expire after a few days, so don't use it in your actual application.\n\nWhen submitting new fingerprints the database, you also need to provide the user API key. Every user gets this key after signing in on this website. You should not store this key in your application code, each user should provide their own.\n\nIf you have an audio fingerprint generated by Chromaprint, you can use this method to lookup the MusicBrainz metadata associated with this fingerprint.\n\nAnd also additional metadata about the recordings from the MusicBrainz database (meta=recordings+releasegroups+compress):\n\nYou can also look up data connected to a track ID, wich is a cluster of fingerprints.\n\nThe AcoustID database depends on user-submitted content. This method can be used to submit new audio fingerprints and their corresponding metadata to the database. Multiple fingerprints can be submitted in one call.\n\nSubmissions are processed asynchronously by a background job. If you need to wait for the submission to be successfully imported, you need to do it on the client side by checking the submission status endpoint.\n\nWhile you can submit a fingerprint without any metadata, it is not very useful to do so. If the file has embedded MusicBrainz tags, please send the MusicBrainz recording ID. Otherwise you can send the textual metadata.\n\nIf you submitted an fingerprint and it was imported immediately, you can check the status of the submission by looking up the ID from the call.\n\nLook up the status of two previously submitted fingerprints:"
    },
    {
        "link": "https://acoustid.org",
        "document": "AcoustID is a project providing complete audio identification service, based entirely on open source software.\n\nIt consists of a client library for generating compact fingerprints from audio files, a large crowd-sourced database of audio fingerprints, many of which are linked to the MusicBrainz metadata database using their unique identifiers, and an web service that enables applications to quickly search in the fingerprint database.\n\nIf you have an unknown music file, one of the applications using AcoustID will very likely be able to tell you what song it is, who wrote it, and a lot more. In case AcoustID doesn't recognize the song yet, you can help by submitting it to the database, so that the next person trying to identify the same song will have more luck.\n• Get user API key for submitting new fingerprints If you are developing an application that needs to identify unknown audio files, you can use AcoustID to help with that. The service is completely free for non-commercial applications, all you need to do is register your application. You can also use the service in commercial applications via AcoustID OÜ."
    },
    {
        "link": "https://musicbrainz.org/doc/AcoustID",
        "document": "AcoustID is an acoustic fingerprint system built entirely on open-source technology.\n\nEach recording page in the MusicBrainz web interface has a Fingerprint tab, listing the AcoustIDs associated with the recording. Every AcoustID listed has a “link” or “unlink” link action associated with it. If you are certain that an AcoustID does not belong to a recording, you can use “unlink” to disable the association between the MusicBrainz recording and the AcoustID. This will prevent Picard from suggesting that recording when it scans an audio file and finds that AcoustID. If you find that someone else has disabled the AcoustID incorrectly, you may use “link” to reactivate this association.\n\nTo see more information about the AcoustID, including durations of submitted fingerprints, visualizations of the fingerprint, and a list of associated MusicBrainz recordings, click on the AcoustID.\n\nNote that using the link/unlink actions requires you to enter your MusicBrainz credentials into a different website. If you are not comfortable doing this, please do not use these actions.\n\nIf your files do not have MBIDs in their tags, you can use Picard to submit AcoustID fingerprints while you tag them.\n• Go to Options → Fingerprinting, select Audio Fingerprinting and Use AcoustID.\n• If you want to be able to submit fingerprints, enter your API key. If you don’t already have one, click Get API key… (you can get it from acoustid.org).\n\nUsing AcoustIDs in Picard: Scanning and submitting AcoustIDs\n\nSelect an unmatched file (or cluster) and press the Scan button. Picard will calculate the fingerprint of the file and look it up on the AcoustID server, trying to find an ID corresponding to the file's fingerprint. If the fingerprint yields a match, and it is already linked to a MusicBrainz ID, the track will be matched. You don't need to submit it! If it does not get a MB or AcoustID match, the fingerprint stays associated with the file in memory, but the file stays in the left-hand pane. Now you must manually match the track using another mechanism (e.g. Cluster/Lookup or manual search on the website).\n\nOnce the file is matched to MusicBrainz, you can press the 'Submit' button to send the information to AcoustID, thus helping future users.\n\nIf your files already have MBIDs stored in their tags, just use the AcoustID Fingerprinter (you can download it from the AcoustID website).\n\nOpen the Fingerprinter and input your API key in the key field (if you don't have one, press \"Get API key\" to do that!). Select the folders that contain the files you want to fingerprint and press \"Fingerprint\": your files will be fingerprinted and the info submitted to AcoustID. You're done!"
    },
    {
        "link": "https://github.com/acoustid/chromaprint",
        "document": "Chromaprint is an audio fingerprint library developed for the AcoustID project. It's designed to identify near-identical audio and the fingerprints it generates are as compact as possible to achieve that. It's not a general purpose audio fingerprinting solution. It trades precision and robustness for search performance. The target use cases are full audio file identifcation, duplicate audio file detection and long audio stream monitoring.\n\nThe most common way to build Chromaprint is like this:\n\nThis will build Chromaprint as a shared library and also include the utility (which is used by MusicBrainz Picard, for example). For this to work, you will need to have the FFmpeg libraries installed.\n\nSee below for other options.\n\nChromaprint can use multiple FFT libraries -- FFmpeg, FFTW3, KissFFT or vDSP (macOS).\n\nFFmpeg is preferred on all systems except for macOS, where you should use the standard vDSP framework. These are the fastest options.\n\nFFTW3 can be also used, but this library is released under the GPL license, which makes also the resulting Chromaprint binary GPL licensed.\n\nKissFFT is the slowest option, but it's distributed with a permissive license and it's very easy to build on platforms that do not have packaged versions of FFmpeg or FFTW3. We ship a copy of KissFFT, so if the build system is unable to find another FFT library it will use that as a fallback.\n\nYou can explicitly set which library to use with the option. For example:\n\nFFmpeg is as a FFT library and also for audio decoding and resampling in . If you have FFmpeg installed in a non-standard location, you can use the option to specify where:\n\nWhile we try to make sure things work also with libav, FFmpeg is preferred.\n\nYou can use Doxygen to generate a HTML version of the API documentation:\n\nThe test suite can be built and run using the following commands:\n\nIn order to build the test suite, you will need the sources of the Google Test library.\n\nBindings, wrappers and reimplementations in other languages:\n\nIf you know about a project that is not listed here, but should be, please let me know.\n\nI've learned a lot while working on this project, which would not be possible without having information from past research. I've read many papers, but the concrete ideas implemented in this library are based on the following papers:\n• Yan Ke, Derek Hoiem, Rahul Sukthankar. Computer Vision for Music Identification, Proceedings of Computer Vision and Pattern Recognition, 2005. http://www.cs.cmu.edu/~yke/musicretrieval/"
    },
    {
        "link": "https://acoustid.biz",
        "document": "AcoustID can be used for adding an automatic tagging feature to music players or music library organization applications. It can identify unknown audio files by searching in a large public database of audio fingerprints. Once it identifies an audio file, it can suggest the correct tags, for which it uses high quality metadata from the open MusicBrainz database. Thanks to the integration with MusicBrainz, it is also possible for applications to request additional metadata from either MusicBrainz itself or other services supporting MusicBrainz identifiers like the Cover Art Archive to get cover art images. Clients with large music catalogs can use AcoustID for automatic or semi-automatic metadata management. It can be used to cross-reference music files with MusicBrainz identifiers and also other metadata providers compatible with MusicBrainz. As an example, cross-referencing the music catalog with MusicBrainz artist identifiers can help solve the problem of multiple artists having the same name by avoiding the need to do text search on the artist name. AcoustID can be also used for detecting duplicate music files during the ingestion process.\n\nAt the core of AcoustID is an efficient algorithm for extracting audio fingerprints, called Chromaprint. The algorithm is optimized specifically for matching near-identical audio streams, which allows the audio fingerprints to be very compact and the extraction process to be fast. For example, it takes less than 100ms to process a two minute long audio file and the extracted audio fingerprint is just 2.5 KB of binary data. AcoustID contains a large crowd-sourced database of such audio fingerprints together with additional information about them, such as the song title, artist or links to the MusicBrainz database. You can send an audio fingerprint to the AcoustID service and it will search the database and return you information about the song. We use a custom database for indexing the audio fingerprints to make the search very fast. All of this is 100% open source and the database is available for download.\n\nThe AcoustID service is free to use in non-commercial applications. If you want to use the service in a commercial product, please subscribe to one of the plans below. All plans come with a free trial. You are not charged for the first 10k searches. If you don't need more than that, you can use the service for free! The subscription is paid monthly for the service provided in the previous month. You can easily cancel your subscription at any time. We do not provide refunds. If you are not sure which plan is right for your application, you would like a custom plan or need any help with your subscription, please contact us at [email protected]. Also, if you are a single developer and the plans are too expensive for you, feel free to get in touch, explain your situation and I'm sure we can figure something out.\n\nThe original AcoustID project was started in 2010 by Lukáš Lalinský with the goal of creating a completely open source platform for audio identification. The primary use case for the project was music file tagging in MusicBrainz Picard, but since then, it has been integrated in over one hundred other applications and used by thousands of individual users. In addition to being the first open source technology for audio identification, AcoustID also the first to make a large database of audio fingerprints freely available. Right now, it contains over 30 million audio fingerprints, with almost 10 million of them being mapped to the MusicBrainz database for very accurate metadata. In 2016, Lukáš started a company to provide better support for both existing and new commercial users of the AcoustID service, to provide funding for the open source project to make sure it keeps growing, but also to expand the options of what's possible with the AcoustID technology. We are currently developing new audio identification solutions. Expect more open source goodness soon!"
    }
]