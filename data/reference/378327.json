[
    {
        "link": "https://docs.redhat.com/en/documentation/jboss_enterprise_application_platform_common_criteria_certification/5/html/jboss_microcontainer_user_guide/chap-jboss_microcontainer_user_guide-the_virtual_file_system_classloading_and_deployers",
        "document": "Duplication of resource-handling code is a common problem for developers. In most cases, the code deals with determining information about a particular resource, which might be a file, a directory, or, in the case of a JAR, a remote URL. Another duplication problem is code for the processing of nested archives. Example 8.1, “Resource Duplication Problem” illustrates the problem.\n\nThere are also many problems with file locking on Windows systems, forcing developers to copy all hot-deployable archives to another location to prevent locking those in deploy folders (which would prevent their deletion and file-system based undeploy). File locking is a major problem whose only solution used to be centralizing all the resource loading code in one place.\n\nThe VFS project was created solve all of these issues. VFS stands for Virtual File System.\n\nAs mentioned, in plain JDK, handling and navigating resources are complex. You must always check the resource type, and these checks can be cumbersome. VFS abstracts resources into a single resource type, .\n\npublic class VirtualFile implements Serializable { /** * Get certificates. * * @return the certificates associated with this virtual file */ Certificate[] getCertificates() /** * Get the simple VF name (X.java) * * @return the simple file name * @throws IllegalStateException if the file is closed */ String getName() /** * Get the VFS relative path name (org/jboss/X.java) * * @return the VFS relative path name * @throws IllegalStateException if the file is closed */ String getPathName() /** * Get the VF URL (file://root/org/jboss/X.java) * * @return the full URL to the VF in the VFS. * @throws MalformedURLException if a url cannot be parsed * @throws URISyntaxException if a uri cannot be parsed * @throws IllegalStateException if the file is closed */ URL toURL() throws MalformedURLException, URISyntaxException /** * Get the VF URI (file://root/org/jboss/X.java) * * @return the full URI to the VF in the VFS. * @throws URISyntaxException if a uri cannot be parsed * @throws IllegalStateException if the file is closed * @throws MalformedURLException for a bad url */ URI toURI() throws MalformedURLException, URISyntaxException /** * When the file was last modified * * @return the last modified time * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ long getLastModified() throws IOException /** * Returns true if the file has been modified since this method was last called * Last modified time is initialized at handler instantiation. * * @return true if modifed, false otherwise * @throws IOException for any error */ boolean hasBeenModified() throws IOException /** * Get the size * * @return the size * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ long getSize() throws IOException /** * Tests whether the underlying implementation file still exists. * @return true if the file exists, false otherwise. * @throws IOException - thrown on failure to detect existence. */ boolean exists() throws IOException /** * Whether it is a simple leaf of the VFS, * i.e. whether it can contain other files * * @return true if a simple file. * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ boolean isLeaf() throws IOException /** * Is the file archive. * * @return true if archive, false otherwise * @throws IOException for any error */ boolean isArchive() throws IOException /** * Whether it is hidden * * @return true when hidden * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ boolean isHidden() throws IOException /** * Access the file contents. * * @return an InputStream for the file contents. * @throws IOException for any error accessing the file system * @throws IllegalStateException if the file is closed */ InputStream openStream() throws IOException /** * Do file cleanup. * * e.g. delete temp files */ void cleanup() /** * Close the file resources (stream, etc.) */ void close() /** * Delete this virtual file * * @return true if file was deleted * @throws IOException if an error occurs */ boolean delete() throws IOException /** * Delete this virtual file * * @param gracePeriod max time to wait for any locks (in milliseconds) * @return true if file was deleted * @throws IOException if an error occurs */ boolean delete(int gracePeriod) throws IOException /** * Get the VFS instance for this virtual file * * @return the VFS * @throws IllegalStateException if the file is closed */ VFS getVFS() /** * Get the parent * * @return the parent or null if there is no parent * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ VirtualFile getParent() throws IOException /** * Get a child * * @param path the path * @return the child or <code>null</code> if not found * @throws IOException for any problem accessing the VFS * @throws IllegalArgumentException if the path is null * @throws IllegalStateException if the file is closed or it is a leaf node */ VirtualFile getChild(String path) throws IOException /** * Get the children * * @return the children * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ List<VirtualFile> getChildren() throws IOException /** * Get the children * * @param filter to filter the children * @return the children * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed or it is a leaf node */ List<VirtualFile> getChildren(VirtualFileFilter filter) throws IOException /** * Get all the children recursively<p> * * This always uses {@link VisitorAttributes#RECURSE} * * @return the children * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ List<VirtualFile> getChildrenRecursively() throws IOException /** * Get all the children recursively<p> * * This always uses {@link VisitorAttributes#RECURSE} * * @param filter to filter the children * @return the children * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed or it is a leaf node */ List<VirtualFile> getChildrenRecursively(VirtualFileFilter filter) throws IOException /** * Visit the virtual file system * * @param visitor the visitor * @throws IOException for any problem accessing the virtual file system * @throws IllegalArgumentException if the visitor is null * @throws IllegalStateException if the file is closed */ void visit(VirtualFileVisitor visitor) throws IOException }\n\nAll of the usual read-only File System operations are available, plus a few options to cleanup or delete the resource. Cleanup or deletion handling is needed when dealing with some internal temporary files, such as files created to handle nested jars.\n\nTo switch from the JDK's or resource handling to new you need a root , which is provided by the class, with the help of URL or URI parameter.\n\nExample 8.3. Using the Class public class VFS { /** * Get the virtual file system for a root uri * * @param rootURI the root URI * @return the virtual file system * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL is null */ static VFS getVFS(URI rootURI) throws IOException /** * Create new root * * @param rootURI the root url * @return the virtual file * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL */ static VirtualFile createNewRoot(URI rootURI) throws IOException /** * Get the root virtual file * * @param rootURI the root uri * @return the virtual file * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL is null */ static VirtualFile getRoot(URI rootURI) throws IOException /** * Get the virtual file system for a root url * * @param rootURL the root url * @return the virtual file system * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL is null */ static VFS getVFS(URL rootURL) throws IOException /** * Create new root * * @param rootURL the root url * @return the virtual file * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL */ static VirtualFile createNewRoot(URL rootURL) throws IOException /** * Get the root virtual file * * @param rootURL the root url * @return the virtual file * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL */ static VirtualFile getRoot(URL rootURL) throws IOException /** * Get the root file of this VFS * * @return the root * @throws IOException for any problem accessing the VFS */ VirtualFile getRoot() throws IOException }\n\nThe three different methods look similar.\n\nreturns a VFS instance but does not yet create a VirtualFile instance. This is important because there are methods which help with configuring a VFS instance (see VFS class API javadocs), before instructing it to create a VirtualFile root.\n\nThe other two methods, on the other hand, use default settings for root creation. The difference between and is in caching details, which are covered later.\n\nAnother useful thing about VFS API is its implementation of a proper visitor pattern. It is very simple to recursively gather different resources, a task which is difficult to do with plain JDK resource loading."
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Web/API/File_System_API",
        "document": "This API allows interaction with files on a user's local device, or on a user-accessible network file system. Core functionality of this API includes reading files, writing or saving files, and access to directory structure.\n\nMost of the interaction with files and directories is accomplished through handles. A parent class helps define two child classes: and , for files and directories respectively.\n\nThe handles represent a file or directory on the user's system. You can first gain access to them by showing the user a file or directory picker using methods such as and . Once these are called, the file picker presents itself and the user selects either a file or directory. Once this happens successfully, a handle is returned.\n\nYou can also gain access to file handles via:\n• The method of the HTML Drag and Drop API.\n\nEach handle provides its own functionality and there are a few differences depending on which one you are using (see the interfaces section for specific details). You then can access file data, or information (including children) of the directory selected. This API opens up potential functionality the web has been lacking. Still, security has been of utmost concern when designing the API, and access to file/directory data is disallowed unless the user specifically permits it (note that this is not the case with the Origin private file system, because it is not visible to the user).\n\nNote: The different exceptions that can be thrown when using the features of this API are listed on relevant pages as defined in the spec. However, the situation is made more complex by the interaction of the API and the underlying operating system. A proposal has been made to list the error mappings in the spec, which includes useful related information."
    },
    {
        "link": "https://docs.servicestack.net/virtual-file-system",
        "document": "In order to access physical files in view engines from multiple sources, ServiceStack includes its own pluggable virtual file system API that lets it support multiple filesystem backends.\n\nThe virtual file system (VFS) is what allows ServiceStack to support view engines in a standard ASP.NET websites (e.g. serving directories from the root directory) as well in self-hosting stand-alone HttpListener websites and Windows Services serving from the output directory as well as embedded resources inside .dlls, in memory filesystems populated at runtime, remote datastores like AWS S3, or in a remote Azure Blob Storage or any combination of either.\n\nServiceStack has the following Virtual Files Sources available:\n• - Hard-disk or Network Files and Directories from a specified root directory\n• - Virtual Files and Folders that can be programmatically populated In Memory\n• - Hard-disk or Network files made available under an custom file mapping alias\n• - Any combination of any of the above Virtual File Sources under a cascading configuration\n\nTo enable ServiceStack to serve embedded resources in your Website's compiled Assembly you'll need to register either an or a in an Assembly that contains embedded resources, e.g:\n\nBy default ServiceStack automatically includes the Assembly where your is defined which since it's typically the same top-level assembly where all your Website assets are maintained, no configuration is required to serve any embedded resources which are accessible from the same path as it's defined in your VS.NET project. E.g. if you have an embedded resource in your project at it would be available from the same path where ServiceStack is mounted, e.g .\n\nCustom FileSystem mappings can be easily registered under a specific alias by overriding your AppHost's and registering a custom , e.g:\n\nThis will let you access File System Resources under the custom and routes, e.g:\n\nAs Virtual File Sources are initialized before plugins are registered your plugin will need to implement so any VFS sources are registered in its method, e.g:\n\nIf needed you can use the API to resolve a physical file path from your projects ContentPath folder.\n\nThen you can register the plugin with your AppHost as normal, e.g:\n\nWhere your AppHost will serve static files from your plugin's registered path mappings, e.g:\n\nTo enable shadowing of the cascading Virtual File Sources, an empty has been added to by default where it gets inserted at the start of , i.e:\n\nIf needed, the individual Memory and FileSystem VFS providers in the WebRoot VFS Sources can be accessed with:\n\nWhich are also available from the singleton:\n\nThe WebRoot Directory and ContentRoot Directories are also available from:\n\nWe can leverage this to provide an elegant solution for minifying static , and resources by simply pre-loading a new Memory Virtual FileSystem with minified versions of existing files and giving the Memory FS a higher precedence so any matching requests serve up the minified version first with:\n\nThe can be used to prepend additional Virtual File Sources at start giving them the highest priority whilst appends at the end giving them the lowest priority, which your AppHost or plugins can use to register additional Virtual File Sources:\n\nYou can also globally replace the VFS used by setting it in your AppHost, e.g. If you only want to use an InMemory File System:\n\nFine-grained control on which VFS to use can also be specified on any Plugins requiring access to the FileSystem like ServiceStack's built-in HTML ViewEngines, here's how you could override the VFS used in ServiceStack's Razors support:\n\nYou can change the physical root path from where ServiceStack serves your files from by changing , e.g. the current directory for self-hosts is where the .exe is run from, during development this is typically . You can change the self-host to serve files from your project folder with:\n\nThe VFS supports multiple file source locations where you can override embedded files by including your own custom files in the same location as the embedded files. We can see how this works by overriding the built-in templates used in metadata pages:\n\nThe is a particular exciting addition to the collection of available Virtual File System providers. Gist's are the perfect way to capture and share a publicly versionable snapshot of files that's validated against a authenticated user account - adding an important layer of trust and verification over an anonymous archive download.\n\nGitHub also provide public HTTP API's to access Gist's and their metadata, that scales nicely to support small fileset snapshots where all content is returned in the public API resource request, as well as supporting larger fileset snapshots where the contents of the gist are truncated and its contents are instead downloaded from its in an alternative HTTP Request.\n\nprovides a transparent VFS abstraction over GitHub's Gist APIs so they can be used interchangeably with all other VFS providers.\n\nOn its surface Gists appear to only support a flat list of text files, but is able to overcome these limitations by transparently encoding Binary files to Base 64 behind the scenes and utilizing back-slashes in file names to maintain a heirachal file structure where it's able to implement the full VFS Provider abstraction.\n\nServiceStack includes good heuristics for determining which files are binary on its extension and Content Type, if your Binary file isn't recognized you can register its extension with a known binary content type or override the predicate:\n\nIt supports both public read-only and read/write gists with a GitHub being needed in order to perform any writes:\n\nBehaviourally they differ from other VFS providers in that they're used more as a snapshot instead of a actively modified file system and their updates and are noticeably slower to both read and write then the other VFS providers.\n\nTo maximize performance the files are stored in memory after the first access and its internal cache only updated when a Write operation is performed.\n\nIf you're instead using a Gist that changes frequently you can specify how long before refreshing the cache:\n\nGitHub truncates large Gists which transparently fetches behind-the-scenes on-demand, you can also eagerly fetch all truncated content with:\n\nAs Gist HTTP API's are relatively slow, we recommend using the Batched APIs so multiple files can be updated in a single HTTP Request.\n\nThe HTML templates for the metadata pages are maintained as embedded html template resources.\n\nThe VFS lets you replace built-in ServiceStack templates with your own by simply copying the metadata or HtmlFormat Template files you want to customize and placing them in your Website Directory at:\n\nWhich you can customize locally that ServiceStack will pick up and use instead.\n\nThe Virtual File System extended interface extends the read-only interface to offer a read/write API:\n\nThe single and multi-write File APIs support content values of either , , , , and Types.\n\nAdditional allocation-efficient APIs are also available as extension methods:\n\nThe new API is available in local FileSystem, In Memory, Gists and S3 Virtual path providers:\n\nAll providers share the same VirtualPathProviderTests ensuring a consistent behavior where it's now possible to swap between different file storage backends with simple configuration as seen in the Imgur and REST Files examples.\n\nThe API allow VFS Providers to implement more efficient file access which by default returns for text files and for binary files:\n\nThe APIs also let you use the same source code to read/write both text and binary files which VFS providers can implement more efficiently:\n\nIn #Script you can access a files text or binary contents with either:\n\nAs typically when saving uploaded files you'd only want files written to a single explicit File Storage provider, ServiceStack keeps a distinction between the existing read-only Virtual File Sources it uses internally whenever a static file is requested and the new which is maintained in a separate property on and base class for easy accessibility:\n\nInternally ServiceStack only uses itself to serve static file requests. The new is a clean abstraction your Services can bind to when saving uploaded files which can be easily substituted when you want to change file storage backends. If not specified, defaults to your local filesystem at your host project's root directory.\n• AWS RazorRockstars - Serving all Razor Views and Markdown Content from a S3 bucket\n• AWS Imgur and REST Files - 1 line configuration switch between saving files to local files or S3 Bucket\n\nSee the ServiceStack.Gap project for different examples of how to create single .exe ILMerged applications with Embedded Resources and Compiled Razor Views.\n\nThe VFS is designed to be implementation agnostic so can be changed to use any file repository, e.g. it could easily be made to support a Redis, RDBMS, embedded Sqlite or other NoSQL back-ends.\n\nLike most of ServiceStack's substitutable API's, the interfaces for the VFS lives in the ServiceStack.Interfaces.dll under the ServiceStack.IO namespace.\n\nTo reduce the amount of effort to implement a VFS provider you can inherit from the that all of ServiceStack's VFS providers inherit from.\n\nOtherwise for a clean-room implementation, you'll need to implement these interfaces in order to create a new VFS Provider:\n\nIf you want your VFS provider to support writes where it can used in your , your should also implement the interface below:\n\nTo ensure behavior conformance your VFS provider, it should also be validated against the existing VirtualPathProviderTests test suite."
    },
    {
        "link": "https://stackoverflow.com/questions/919918/file-exists-returns-false-when-file-exists",
        "document": "I've encountered a bug I can't seem to find any logic behind. I have this File object, which is created like this:\n\nI then do , and it returns (!?). If the file is not found, I'm logging to a file. When I look at the path, it seems OK. I can copy-paste the complete path into the \"Run\"-window in Windows and the file opens fine.\n\nThe file exists at all times and is not deleted nor changed during the running of my application. It is located at the local machine.\n\nThis only seems to occur in certain situations. I can reproduce the fault at any time, but I'm sure the path of the file object is not changed by the actions I make to reproduce the fault.\n\nWhat can cause to return false? Does this have something to do with permissions or file locks, etc.?"
    },
    {
        "link": "https://docs.redhat.com/it/documentation/red_hat_jboss_enterprise_application_platform/5/html/microcontainer_user_guide/chap-jboss_microcontainer_user_guide-the_virtual_file_system_classloading_and_deployers",
        "document": "Duplication of resource-handling code is a common problem for developers. In most cases, the code deals with determining information about a particular resource, which might be a file, a directory, or, in the case of a JAR, a remote URL. Another duplication problem is code for the processing of nested archives. Example 8.1, “Resource Duplication Problem” illustrates the problem.\n\nThere are also many problems with file locking on Windows systems, forcing developers to copy all hot-deployable archives to another location to prevent locking those in deploy folders (which would prevent their deletion and file-system based undeploy). File locking is a major problem whose only solution used to be centralizing all the resource loading code in one place.\n\nThe VFS project was created solve all of these issues. VFS stands for Virtual File System.\n\nAs mentioned, in plain JDK, handling and navigating resources are complex. You must always check the resource type, and these checks can be cumbersome. VFS abstracts resources into a single resource type, .\n\npublic class VirtualFile implements Serializable { /** * Get certificates. * * @return the certificates associated with this virtual file */ Certificate[] getCertificates() /** * Get the simple VF name (X.java) * * @return the simple file name * @throws IllegalStateException if the file is closed */ String getName() /** * Get the VFS relative path name (org/jboss/X.java) * * @return the VFS relative path name * @throws IllegalStateException if the file is closed */ String getPathName() /** * Get the VF URL (file://root/org/jboss/X.java) * * @return the full URL to the VF in the VFS. * @throws MalformedURLException if a url cannot be parsed * @throws URISyntaxException if a uri cannot be parsed * @throws IllegalStateException if the file is closed */ URL toURL() throws MalformedURLException, URISyntaxException /** * Get the VF URI (file://root/org/jboss/X.java) * * @return the full URI to the VF in the VFS. * @throws URISyntaxException if a uri cannot be parsed * @throws IllegalStateException if the file is closed * @throws MalformedURLException for a bad url */ URI toURI() throws MalformedURLException, URISyntaxException /** * When the file was last modified * * @return the last modified time * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ long getLastModified() throws IOException /** * Returns true if the file has been modified since this method was last called * Last modified time is initialized at handler instantiation. * * @return true if modifed, false otherwise * @throws IOException for any error */ boolean hasBeenModified() throws IOException /** * Get the size * * @return the size * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ long getSize() throws IOException /** * Tests whether the underlying implementation file still exists. * @return true if the file exists, false otherwise. * @throws IOException - thrown on failure to detect existence. */ boolean exists() throws IOException /** * Whether it is a simple leaf of the VFS, * i.e. whether it can contain other files * * @return true if a simple file. * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ boolean isLeaf() throws IOException /** * Is the file archive. * * @return true if archive, false otherwise * @throws IOException for any error */ boolean isArchive() throws IOException /** * Whether it is hidden * * @return true when hidden * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ boolean isHidden() throws IOException /** * Access the file contents. * * @return an InputStream for the file contents. * @throws IOException for any error accessing the file system * @throws IllegalStateException if the file is closed */ InputStream openStream() throws IOException /** * Do file cleanup. * * e.g. delete temp files */ void cleanup() /** * Close the file resources (stream, etc.) */ void close() /** * Delete this virtual file * * @return true if file was deleted * @throws IOException if an error occurs */ boolean delete() throws IOException /** * Delete this virtual file * * @param gracePeriod max time to wait for any locks (in milliseconds) * @return true if file was deleted * @throws IOException if an error occurs */ boolean delete(int gracePeriod) throws IOException /** * Get the VFS instance for this virtual file * * @return the VFS * @throws IllegalStateException if the file is closed */ VFS getVFS() /** * Get the parent * * @return the parent or null if there is no parent * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ VirtualFile getParent() throws IOException /** * Get a child * * @param path the path * @return the child or <code>null</code> if not found * @throws IOException for any problem accessing the VFS * @throws IllegalArgumentException if the path is null * @throws IllegalStateException if the file is closed or it is a leaf node */ VirtualFile getChild(String path) throws IOException /** * Get the children * * @return the children * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ List<VirtualFile> getChildren() throws IOException /** * Get the children * * @param filter to filter the children * @return the children * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed or it is a leaf node */ List<VirtualFile> getChildren(VirtualFileFilter filter) throws IOException /** * Get all the children recursively<p> * * This always uses {@link VisitorAttributes#RECURSE} * * @return the children * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed */ List<VirtualFile> getChildrenRecursively() throws IOException /** * Get all the children recursively<p> * * This always uses {@link VisitorAttributes#RECURSE} * * @param filter to filter the children * @return the children * @throws IOException for any problem accessing the virtual file system * @throws IllegalStateException if the file is closed or it is a leaf node */ List<VirtualFile> getChildrenRecursively(VirtualFileFilter filter) throws IOException /** * Visit the virtual file system * * @param visitor the visitor * @throws IOException for any problem accessing the virtual file system * @throws IllegalArgumentException if the visitor is null * @throws IllegalStateException if the file is closed */ void visit(VirtualFileVisitor visitor) throws IOException }\n\nAll of the usual read-only File System operations are available, plus a few options to cleanup or delete the resource. Cleanup or deletion handling is needed when dealing with some internal temporary files, such as files created to handle nested jars.\n\nTo switch from the JDK's or resource handling to new you need a root , which is provided by the class, with the help of URL or URI parameter.\n\nExample 8.3. Using the Class public class VFS { /** * Get the virtual file system for a root uri * * @param rootURI the root URI * @return the virtual file system * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL is null */ static VFS getVFS(URI rootURI) throws IOException /** * Create new root * * @param rootURI the root url * @return the virtual file * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL */ static VirtualFile createNewRoot(URI rootURI) throws IOException /** * Get the root virtual file * * @param rootURI the root uri * @return the virtual file * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL is null */ static VirtualFile getRoot(URI rootURI) throws IOException /** * Get the virtual file system for a root url * * @param rootURL the root url * @return the virtual file system * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL is null */ static VFS getVFS(URL rootURL) throws IOException /** * Create new root * * @param rootURL the root url * @return the virtual file * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL */ static VirtualFile createNewRoot(URL rootURL) throws IOException /** * Get the root virtual file * * @param rootURL the root url * @return the virtual file * @throws IOException if there is a problem accessing the VFS * @throws IllegalArgumentException if the rootURL */ static VirtualFile getRoot(URL rootURL) throws IOException /** * Get the root file of this VFS * * @return the root * @throws IOException for any problem accessing the VFS */ VirtualFile getRoot() throws IOException }\n\nThe three different methods look similar.\n\nreturns a VFS instance but does not yet create a VirtualFile instance. This is important because there are methods which help with configuring a VFS instance (see VFS class API javadocs), before instructing it to create a VirtualFile root.\n\nThe other two methods, on the other hand, use default settings for root creation. The difference between and is in caching details, which are covered later.\n\nAnother useful thing about VFS API is its implementation of a proper visitor pattern. It is very simple to recursively gather different resources, a task which is difficult to do with plain JDK resource loading."
    },
    {
        "link": "https://reddit.com/r/ProgrammingLanguages/comments/edlucb/advice_for_module_system_implementation",
        "document": "I am currently developing a programming language and am having a hard time finalizing the semantics of the module system. Currently I have a few ideas but no concrete direction, so it would be valuable to have some experienced input on the issue.\n\nSo far I've thought of the following solutions:\n• Directory-based: A module lives in a directory that is referenced by name and the source files within that directory make up the module.\n• Config-based: A config file defines the module name and all of it's sources. This config file would then have to be registered with the build system.\n• Source-based: A single source file is referenced by name (minus extension) and relevant sources/modules are imported within that source.\n\nI am leaning toward (1) or (2) as (3) feels like it has little value over a basic c-style , but (3) makes references to inter-module functions explicit and I'm having a hard time coming up with good syntax to express this in (1) or (2).\n\nThe basic syntax for importing a module is as follows:\n\nThen functions are referenced like so:\n\nAny opinions on the topic are much appreciated."
    },
    {
        "link": "https://stackoverflow.com/questions/8813847/how-to-implement-a-python-virtual-filesystem-using-shelve",
        "document": "I provide some code to help you out below, but first, some overall advice that should help you with your design:\n• None The reason you're having difficulty with changing directories is that you are representing the current directory variable the wrong way. Your current directory should be something like a list, from your top level directory to your current one. Once you have that, you just make a choice about how store files using shelve based on their directory (considering that all keys in Shelve must be strings).\n• None It looks like you were planning on representing the filesystem as a series of nested dictionaries- a good choice. But note that if you change mutable objects in , you have to a) set writeback to True and b) call fs.sync() to set them.\n• None You should be structuring your entire filesystem in a class rather than in a series of functions. It will help you keep your shared data organized. The below code doesn't follow that but it is worth thinking about.\n\nSo, I fixed up and also wrote a rudimentary mkdir command for you. The critical thing for making them work is to, as I said above, have current_dir be a list that shows your current path, and also to have an easy way (the function) to get from that list to the appropriate filesystem directory.\n\nWith that, here's the code to get you started:\n\nIt's important to note that this is so far just a toy: there is still a ton left to do. Here are a few examples:\n• None Right now there is only such a thing as directories- no regular files.\n• None doesn't check if a directory already exists, it would overwrite one with an empty directory.\n• None You can't with a specific directory as an argument, (like ), only your current directory.\n\nStill, this should show you an example of a design for keeping track of your current directory. Good luck!"
    },
    {
        "link": "https://stackoverflow.com/questions/65518837/is-there-a-library-in-python-which-allows-virtual-file-system-management-in-sing",
        "document": "I was working on a program. I do not think I need to show it here, but I was wondering is it possible to create virtual file system stored on a single file. for example I have a file named , is there a way to create virtual file system into that single file only. Basically:\n\nI basically want basic filesystem interface. no owners, date or other metadata. Zip is a good idea to do that but it just reads the whole file in the system all at once and does not provide file like interface. So I rquired a very basic file system in single file, in which i am able to use files like normal IO objects.\n\nEDIT The files stored in the file system will be as big as 3 GB for a single file, and I do not have that much of a ram. TarFiles doesn't seem to make my work any better\n\nEDIT I really mean to say some filesystem just like the one with virtual box."
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-work-with-files-using-the-fs-module-in-node-js",
        "document": "The author selected the COVID-19 Relief Fund to receive a donation as part of the Write for DOnations program.\n\nWorking with files is as common for development purposes as it is for non-development purposes. In daily computer use, a user would likely read and write data to files in various directories in order to accomplish tasks like saving a downloaded file or accessing data to be used in another application. In the same way, a back-end program or command line interface (CLI) tool might need to write downloaded data to a file in order to save it, or a data-intensive application may need to export to JSON, CSV, or Excel formats. These programs would need to communicate with the filesystem of the operating system on which they are running.\n\nWith Node.js, you can programmatically manipulate files with the built-in module. The name is short for “file system,” and the module contains all the functions you need to read, write, and delete files on the local machine. This unique aspect of Node.js makes JavaScript a useful language for back-end and CLI tool programming.\n\nIn this article, you will use the module to read a file created via the command line, create and write to a new file, delete the file that you created, and move the first file into a different folder. The module supports interacting with files synchronously, asynchronously, or via streams; this tutorial will focus on how to use the asynchronous, Promise-based API, the most commonly used method for Node.js developers.\n• You must have Node.js installed on your computer to access the module and follow the tutorial. This tutorial uses Node.js version 10.22.0. To install Node.js on macOS or Ubuntu 18.04, follow the steps in How To Install Node.js and Create a Local Development Environment on macOS or the Installing Using a PPA section of How To Install Node.js on Ubuntu 18.04.\n• This article uses JavaScript Promises to work with files, particularly with the syntax. If you’re not familiar with Promises, syntax, or asynchronous programming, check out our guide on How To Write Asynchronous Code in Node.js.\n\nIn this step, you’ll write a program to read files in Node.js. To do this, you’ll need to import the module, a standard Node.js module for working with files, and then use the module’s function. Your program will read the file, store its contents in a variable, then log its contents to the console.\n\nThe first step will be to set up the coding environment for this activity and the ones in the later sections.\n\nCreate a folder to store your code. In your terminal, make a folder called :\n\nChange your working directory to the newly created folder with the command:\n\nIn this folder, you’ll create two files. The first file will be a new file with content that your program will read later. The second file will be the Node.js module that reads the file.\n\nCreate the file with the following command:\n\nThe command prints its string argument to the terminal. You use to redirect ’s output to a new file, .\n\nNow, create and open in your text editor of choice. This tutorial uses , a terminal text editor. You can open this file with like this:\n\nThe code for this file can be broken up into three sections. First, you need to import the Node.js module that allows your program to work with files. In your text editor, type this code:\n\nAs mentioned earlier, you use the module to interact with the filesystem. Notice, though, that you are importing the part of the module.\n\nWhen the module was first created, the primary way to write asynchronous code in Node.js was through callbacks. As promises grew in popularity, the Node.js team worked to support them in the module out of the box. In Node.js version 10, they created a object in the module that uses promises, while the main module continues to expose functions that use callbacks. In this program, you are importing the promise version of the module.\n\nOnce the module is imported, you can create an asynchronous function to read the file. Asynchronous functions begin with the keyword. With an asynchronous function, you can resolve promises using the keyword, instead of chaining the promise with the method.\n\nCreate a new function that accepts one argument, a string called . Your function will use the module to load the file into a variable using syntax.\n\nYou define the function with the keyword so you can later use the accompanying keyword. To capture errors in your asynchronous file reading operation, you enclose the call to with a block. Within the section, you load a file to a variable with the function. The only required argument for that function is the file path, which is given as a string.\n\nThe returns a object by default. A object can store any kind of file type. When you log the contents of the file, you convert those bytes into text by using the method of the buffer object.\n\nIf an error is caught, typically if the file is not found or the program does not have permission to read the file, you log the error you received in the console.\n\nFinally, call the function on the file with the following highlighted line:\n\nBe sure to save your contents. With , you can save and exit by pressing .\n\nYour program will now read the file you created earlier and log its contents to the terminal. Confirm this by executing your module with :\n\nYou will receive the following output:\n\nYou’ve now read a file with the module’s function using the syntax.\n\nNow that you’ve read a file with the module, you will next create a file and write text to it.\n\nIn this step, you will write files with the function of the module. You will create a CSV file in Node.js that keeps track of a grocery bill. The first time you write the file, you will create the file and add the headers. The second time, you will append data to the file.\n\nOpen a new file in your text editor:\n\nBegin your code by importing the module:\n\nYou will continue to use syntax as you create two functions. The first function will be to make the CSV file. The second function will be to add data to the CSV file.\n\nIn your text editor, enter the following highlighted code:\n\nThis asynchronous function first creates a variable that contains the column headings of your CSV file. You then use the function of the module to create a file and write data to it. The first argument is the file path. As you provided just the file name, Node.js will create the file in the same directory that you’re executing the code in. The second argument is the data you are writing, in this case the variable.\n\nNext, create a new function to add items to your grocery list. Add the following highlighted function in your text editor:\n\nThe asynchronous function accepts three arguments: the name of the grocery item, the amount you are buying, and the price per unit. These arguments are used with template literal syntax to form the variable, which is the data you are writing to the file.\n\nYou then use the method as you did in the function. However, this time you have a third argument: a JavaScript object. This object has a key with the value . Flags tell Node.js how to interact with the file on the system. By using the flag , you are telling Node.js to append to the file, not overwrite it. If you don’t specify a flag, it defaults to , which creates a new file if none exists or overwrites a file if it already exists. You can learn more about filesystem flags in the Node.js documentation.\n\nTo complete your script, use these functions. Add the following highlighted lines at the end of the file:\n\nTo call the functions, you first create a wrapper function with . Since the keyword can not be used from the global scope as of the writing of this tutorial, you must wrap the asynchronous functions in an . Notice that this function is anonymous, meaning it has no name to identify it.\n\nYour and functions are asynchronous functions. Without enclosing these calls in another function, you cannot guarantee the order of the content. The wrapper you created is defined with the keyword. Within that function you order the function calls using the keyword.\n\nFinally, the definition is enclosed in parentheses. These tell JavaScript that the code inside them is a function expression. The parentheses at the end of the function and before the semicolon are used to invoke the function immediately. This is called an Immediately-Invoked Function Expression (IIFE). By using an IIFE with an anonymous function, you can test that your code produces a CSV file with three lines: the column headers, a line for , and the last line for .\n\nNow, run your code with the command:\n\nThere will be no output. However, a new file will exist in your current directory.\n\nUse the command to display the contents of :\n\nYou will receive the following output:\n\nYour call to created a new file and added the column headings for your CSV. The subsequent calls to then added your two lines of data.\n\nWith the function, you can create and edit files. Next, you will delete files, a common operation when you have temporary files or need to make space on a hard drive.\n\nIn this step, you will delete files with the function in the module. You will write a Node.js script to delete the file that you created in the last section.\n\nIn your terminal, create a new file for this Node.js module:\n\nNow you will write code that creates an asynchronous function. That function will accept a file path as an argument, passing it to the function to remove it from your filesystem.\n\nIn your text editor, write the following code:\n\nThe function accepts one argument: the file path of the file you want to be deleted.\n\nExit , ensuring that you save the contents of the file by entering .\n\nNow, execute the program. Run the following command in your terminal:\n\nYou will receive the following output:\n\nTo confirm that the file no longer exists, use the command in your current directory:\n\nThis command will display these files:\n\nYou’ve now confirmed that your file was deleted with the function.\n\nSo far you’ve learned how to read, write, edit, and delete files. The following section uses a function to move files to different folders. After learning that function, you will be able to do the most critical file management tasks in Node.js.\n\nFolders are used to organize files, so being able to programmatically move files from one folder to another makes file management easier. You can move files in Node.js with the function. In this step, you’ll move a copy of the file into a new folder.\n\nBefore you can code your Node.js module, you need to set a few things up. Begin by creating a folder that you’ll be moving your file into. In your terminal, create a folder in your current directory:\n\nNow, copy the file that was used in the first step using the command:\n\nFinish the setup by opening a JavaScript file to contain your code:\n\nIn your Node.js module, you’ll create a function called that calls the function. When using the function, you need to provide the file path of the original file and the path of the destination location. For this example, you’ll use a function to move the file into the folder. You’ll also change its name to .\n\nEnter the following code in your open text editor:\n\nAs mentioned earlier, the function takes two arguments: the source and destination file paths. This function can move files to other folders, rename a file in its current directory, or move and rename at the same time. In your code, you are moving and renaming your file.\n\nNext, execute this program with . Enter this command to run the program:\n\nYou will receive this output:\n\nTo confirm that the file no longer exists in your current directory, you can use the command:\n\nThis command will display these files and folder:\n\nYou can now use to list the files in the subfolder:\n\nYour moved file will appear in the output:\n\nYou have now used the function to move a file from your current directory into a subfolder. You also renamed the file with the same function call.\n\nIn this article, you learned various functions to manage files with Node.js. You first loaded the contents of a file with . You then created new files and appended data to an existing file with the function. You permanently removed a file with the function, and then move and renamed a file with .\n\nWorking with files programmatically is an important function of Node.js. Programs might need to output files for a user to use, or may need to store data for an application that is not always running. With the module’s functions, developers have control of how files are used in our Node.js programs.\n\nTo learn more about the module, you can read the Node.js documentation. If you’d like to continue learning Node.js, you can return to the How To Code in Node.js series, or browse programming projects and setups on our Node topic page."
    },
    {
        "link": "https://dev.to/ndesmic/best-practice-tips-for-writing-your-js-modules-40o5",
        "document": "There's a lot of rich history for modules in Javascript and things have changed a lot. We've moved from no modules, to CJS, AMD, and now ESM. We've added Typescript and development is dominated by fancy bundler flows to the point it would not be surprising to write only ESM and yet never have actually used it natively in browser. As such I've compiled a few tips to making the lives of downstream users a bit easier, especially ones who may want to use different tools or even go buildless.\n\nYou should write your modules in ESM format (or Typescript if you'd like) and have bundler output them to CJS if you need. This naturally prevents you from using some of CJS's cursed patterns like dynamic exports\n\n\n\nYou won't always be able to immediately tell though. Bundlers like webpack have a lot of magic that can deal with mixed modules and so you can get away with having import statements and in the same module. If this is the case, you can lint for usages.\n\nESM is supported in all modern browsers, node and is native in Deno. There is no excuse not to ship your code as ESM at the very least from npm. This gives greater flexibility to clients. Anyone can use the code natively, but also, it's better for modern bundlers. The static analyzability means they can tree-shake better. It's possible to ship multiple versions of code too. Simply author your code in ESM and then when you build transpile it to CJS. Node lets your specify a which is used for CJS clients and which is used for ESM clients letting you have the best of both worlds. If you can only have one, always prefer ESM it's the easiest to transpile.\n\nWhile many have gotten into the habit of using node conventions these simply don't work well in the browser. If I import what does that mean? Node knows because it can scan the filesystem, see what exists, maybe even follow the to some other random directory. Maybe it means or maybe it's . Browsers don't do that, is simply . If you wanted you need to say that or it will not get the right path. Consumers aren't going to re-write paths in 3rd party modules, at least not without wide support of importmaps and even then it would be better to not have to use those, as large dependency trees means a lot of path rewrites. You need to do this correctly or people using your code in the browser natively won't be able to use it.\n\nSadly, Typescript (at the time of writing) does the wrong thing by default. Typescript usually prefers extensionless paths. However, you can specify imports like even if the file is actually . This is a little bit weird but you need to do this to properly export for the browser. Worse is that some typescript tools and plugins enforce extensionless paths. Please open issues against projects that do this.\n\nLuckily, if you do happen to use ESM in node natively it will not let you omit them. So start breaking the habit now.\n\nDo not use node resolving functionality\n\nMentioned above but bears repeating as it's a slightly different issue. Try not to rely on things like resolving to or other rerouting. I do realize this is quite an ask as nearly all bundler flows tend to expect everything to come from npm. It's certainly possible if you work at it though, you just need to externally host the dependencies. I won't blame you if it feels too hard though. You can try tools like Snowpack to help you with this. It will also update CJS modules you import from npm into usable ESM!\n\nDefault exports were largely created for compatibility with CJS. Since in CJS you can do things like in CJS it was thought you should be able to do things like in ESM. Unfortunately, and perhaps ironically there's a lot of subtle compatibility problems with this idea. It's not uncommon to get back a default export as when transpiled and imported into CJS, breaking your expectations. In fact, typescript has specific syntax just to work around these cases. This can be a headache to debug. Unless there's a very specific thing you're trying to do such as writing a config.js file, always prefer named exports as they work more reliably.\n\nModules are great, wouldn't it be great if we could import JSON, CSS, HTML or SVGs like that? It would indeed except (at least right now) nothing is standardized and despite it being particularly popular with bundler plugins none of those are likely to look like final syntax (see: import assertions for what this might be). The problem has to do with how urls are interpreted. isn't any different than to the browser, it's just a URL, only once downloaded does it know what it contains. Servers can also totally lie about the mime type in headers too. So You don't want to write and it turn out that, actually, a bad actor switched \"styles.css\" with a javascript module that steals your data. This is going to take syntax to fix and anything you write today is going to be forever tied to build plugins.\n\nBut even when you can add build plugins it's no fun to get and try to figure out what the intent was. What does this even mean? Is it supposed to inline those styles in the document? Is it an object of key values? A CSSStyleSheet object? You have to look at the build itself. This code is not re-usable outside your project.\n\nDo not transpile or minify published modules\n\nYes, transpilation and minification are good when you are outputting your final bundle but do not do this at the intermediate stage, let the client do it. Transpilation at the library level means that downstream clients will have to bundle in your polyfills and other boilerplate code even if they don't need it and even if they are using the same polyfills. Even downgrading to ES5 is a problem because ES5 class prototypes are substantially wordier than class syntax and increase bundle size even when not needed. Certain common polyfills like can be marked as peer-dependencies to help avoid double bundling but even better is to let that be transpiled to ES20XX and let the client figure out what to do with the standards compliant code. It may well be they don't need polyfills at all. Minification also messes up developer experience because now you're stuck with minified code to dig through. Just output the code as authored or as close to it as possible and let the client figure out if they want it minified or not.\n\nIf you are doing ESM and CJS bundles you might be tempted to export typescript code as well. Keep in mind it's unlikely the client will be able to use it directly. Typescript changes by version and differs by tsconfig. If typescript was stable like JS this wouldn't be a problem but if the user has stricter rules than the ones you authored the package with it will fail to compile. Instead, for usage, output the highest version of ECMAScript supported as well as the typing data.\n\nYou can however still include the Typescript source for the purpose of source mapping and many popular tools like VSCode will support this.\n\nis generally not a very disciplined way to go about things, you should import things by name so that it's very clear which things you actually intended to use. While modern bundlers are smart enough to catch over importing it's not always as obvious to the humans reading the code especially if they don't know what's in scope. imports can also behave strangely when mixing module types, consider a CJS module:\n\n\n\nYou should always import this like . If you tried this works, but it's really weird. The CJS export is exporting a value but the ESM is importing a namespace which shouldn't be callable (and if you updated the module to ESM it will no longer work). Another common pattern with * is re-exporting. Projects might have many files that are then re-exported under an index.js:\n\n\n\nThe purpose is to group your public interface in a single file. This is a good idea in principal, but you need to consider a few things. One thing that can happen is that you might export the same name twice which will result in an error. But even if you don't it'll often require clients to bounce between lots of files to track down where the thing actually came from and in a browser this directly ties into latency resolving the modules as you need to make more requests. That, and if some of the exports are co-dependent you can get circular dependencies (try not to reference in the modules). Depending on the bundler these might not resolve the way you think and it's best to avoid this problem if you can."
    }
]