[
    {
        "link": "https://medium.com/data-bistrot/python-procedural-programming-best-practices-bc20ffeb6e37",
        "document": "Procedural programming is a foundational paradigm in software development, emphasizing the use of well-structured sequences of instructions to achieve a desired outcome. In the context of Python, this approach is particularly valuable for tasks in AI, data science, and machine learning, where clarity, efficiency, and reproducibility are paramount. Although object-oriented programming (OOP) often takes center stage in discussions about modern software development, procedural programming remains a fundamental tool, especially for data-centric projects.\n\nThis article lays out essential best practices for procedural programming in Python, tailored specifically for applications in AI, data science, and machine learning.\n\nBy adhering to these guidelines, you can ensure that your code is not only functional but also maintainable, scalable, and understandable.\n\nThese practices include writing clear and readable code, modularizing your functions, leveraging Python’s extensive libraries and frameworks, handling exceptions gracefully, optimizing performance, testing thoroughly, and documenting comprehensively.\n\nThese best practices will enable you to build robust and efficient data pipelines, develop reliable machine learning models, and execute complex data analyses with confidence. This article is for data scientist , data analyst or business analyst that are seeking to refine their coding practices. These guidelines will help you navigate the procedural programming sea effectively.\n\nBest Practices in this Article\n• Best Practices for Spacing and Bracketing\n• Best Practices for Using Literals in AI, Data Science, and Machine\n• Best Practices for Variables and Scope in Python\n• Modularity in Python Procedural Programming with AI and Data Science Focus\n• Handling Exceptions Gracefully in Python for Data Science and AI\n• Test Your Functions and your code\n\nNaming conventions play a critical role in writing clear, maintainable, and understandable code. Proper naming makes it easier for others (and yourself) to read and understand your code, especially in complex projects related to AI, data science, and machine learning. This section presents best practices for naming conventions in Python, with code examples to illustrate these principles.\n\nReadability is crucial in Python (as it is in any other programming language). Clear, readable code is easier to debug, maintain, and collaborate on. Here are some tips to achieve this:\n• Use meaningful variable and function names: Names should be descriptive and convey the purpose of the variable or function.\n• Follow PEP 8 guidelines: PEP 8 is the style guide for Python code. It covers aspects such as indentation, line length, and naming conventions.\n• Comment your code: Write comments to explain complex sections of your code. This helps others (and future you) understand the logic.\n\nAll names (variables, functions, objects, files, etc.) must be descriptive. Descriptive names provide meaningful context, making it easier to understand the code’s purpose. Avoid using cryptic or ambiguous names like “x”, “variable”, “a1”, “a2”, etc.\n\nAn exception to the rule of descriptive names is the use of counter variables in loops. Commonly accepted names for counters include , , and .\n\nFor procedural programming, use the underscore naming convention (also known as snake_case). This involves using lowercase letters with underscores to separate words.\n\nWhile underscore naming is typical for procedural programming, camel case (also known as camelCase) is commonly used in object-oriented programming. This convention capitalizes the first letter of each word except the first.\n\nConstants should be written in all capital letters with words separated by underscores. This helps distinguish constants from variables and functions.\n\nBy adhering to these naming conventions, your code will be more readable and easier to maintain, facilitating collaboration and reducing the likelihood of errors in AI, data science, and machine learning projects.\n\nBest Practices for Spacing and Bracketing\n\nProper spacing and bracketing are essential for writing clear, readable, and maintainable code, especially in AI, data science, and machine learning projects. While Python enforces indentation rules, applying these principles consistently across your codebase is essential to enhance code clarity and maintainability. This section highlights best practices for spacing and bracketing in Python, tailored for AI, data science, and machine learning applications.\n\nIndentation and spacing highlight the hierarchical structure and logical blocks of your code. This is crucial for readability and understanding, making it easier to identify code blocks and their relationships.\n\nIn Python, while brackets are not typically used for control structures, using them appropriately in data structures (like dictionaries and lists) and complex expressions enhances readability.\n\nMaintain a consistent style throughout your codebase to enhance readability and maintainability. Do not switch styles mid-code or from module to module. Consistency helps in collaborative projects and makes your codebase uniform.\n\nUse spaces instead of tabs for indentation. Configure your editor to replace tabs with four spaces. This ensures consistency across different editors and platforms, preventing alignment issues.\n• Set up your editor: Configure your text editor or IDE to insert spaces when you press the tab key.\n• Four spaces per indent: This is the standard practice in Python and ensures uniformity.\n\nAdopt a standard of four spaces per indentation level. This practice is widely accepted and enhances the readability of nested code blocks.\n\nBy following these best practices for spacing and bracketing, you ensure that your code is clean, readable, and maintainable, especially in complex AI, data science, and machine learning projects.\n\nProper indentation, consistent use of brackets, and uniform spacing make your code easier to understand and reduce the likelihood of errors. Whether you are working on data preprocessing, model training, or evaluation, adhering to these principles will significantly improve the quality of your code.\n• Use Brackets: For logical grouping in data structures and complex expressions.\n• Spaces, Not Tabs: Configure your editor to replace tabs with spaces.\n• Four Spaces per Indent: Adopt this standard for uniformity.\n\nImplementing these practices will help you write better code and make collaboration with others smoother and more efficient in your AI, data science, and machine learning projects.\n\nBest Practices for Using Literals in AI, Data Science, and Machine Learning with Python\n\nIn programming, literals are fixed values directly embedded in the code, such as numbers, strings, and booleans. While literals can be convenient, they can also make your code harder to maintain and understand, especially in complex AI, data science, and machine learning projects. This section discusses best practices for using literals in Python, ensuring your code remains clear, maintainable, and adaptable.\n\nUsing literals directly in your code can lead to several problems:\n• Readability: It becomes difficult to understand the purpose of the literal.\n• Maintainability: Updating the value requires changing it in multiple places.\n• Reusability: Literals hardcoded in multiple places cannot be reused effectively.\n\nFor literals used in multiple scopes, define them as global constants at the beginning of your module. This practice enhances readability and maintainability.\n\nFor literals used only within a local scope, define them at the top of the function or block. This makes the code easier to read and modify.\n\nThere are few exceptions to the rule of avoiding literals:\n\n-1, 0, 1: These literals are often used in ways that are unlikely to change, such as initializing loop counters or indicating error conditions.\n\nBy adhering to these best practices, you can make your Python code for AI, data science, and machine learning projects more readable, maintainable, and adaptable. Avoid using literals directly in your code, and instead, define them as constants at the appropriate scope level.\n• Avoid Direct Literals: Refrain from embedding literals directly in your code.\n• Use Global Constants: For literals used in multiple scopes, define them at the module’s top.\n• Use Local Constants: For literals used only within a local scope, define them at the top of the function or block.\n• Recognize Exceptions: Understand the rare exceptions where literals like -1, 0, and 1 are appropriate.\n\nBest Practice for Variables and Scope in Python\n\nVariables are a fundamental concept in programming, acting as containers for storing data values. In Python, understanding how variables are scoped is essential to writing efficient, bug-free code. This section will cover what variables are, the different types of scopes, and best practices for managing variables effectively.\n\nA variable is a named location in memory used to store a value. In Python, you don’t need to declare a variable with a specific type — the type is determined automatically when you assign a value to the variable.\n\nVariables make it easier to manipulate data, perform calculations, and manage values dynamically throughout a program. However, where and how you declare these variables significantly impacts the readability, maintainability, and performance of your code.\n\nThis is where the concept of scope comes into play.\n\nScope refers to the region of the code where a variable is accessible or “visible.” In Python, there are two main types of scopes: local scope and global scope. Understanding these will help you write cleaner, more efficient code.\n\nA variable has a local scope when it is defined inside a function. These variables are only accessible within the function in which they are declared. When the function finishes execution, local variables are destroyed, and their memory is freed.\n• Accessibility: Variables cannot be accessed outside their function.\n• Isolation: Variables in different functions can have the same name but are not the same variable.\n\nIn the example above, the variable is a local variable, confined to the function. Attempting to access it outside the function will result in an error.\n\nA global variable is one that is declared outside of all functions and is accessible from any part of the code. While global variables can be useful in certain situations, they should generally be avoided due to potential side effects and code readability issues.\n• Accessibility: Available everywhere in your program.\n• Persistence: Stays in memory throughout the program’s execution.\n• Risk: Can lead to unexpected side effects if modified unintentionally.\n\nIn this example, the keyword is used to modify a global variable within a function. However, the use of global variables can make the code harder to debug and maintain.\n\nThere are very few valid reasons to use global variables. One acceptable use case is for global constants — values that are immutable and remain constant throughout the program’s execution.\n\nAn intermediate variable is a temporary variable used to store a value for use in the next line or operation.\n\nIntermediate Variables: To Use or Not to Use?\n\nWhile intermediate variables can improve readability, they sometimes add unnecessary complexity.\n\nIntermediate variables can be useful in longer or more complex code where they enhance readability by giving meaningful names to repeated values or calculations. They can also improve efficiency when they prevent recalculating complex expressions or accessing costly resources multiple times.\n\nHowever, overusing intermediate variables can make the code cluttered and harder to understand, potentially reducing performance and increasing the risk of errors.\n\nWhen you pass values into a function, the variables defined within the function are known as parameters, and the actual values passed into the function are called arguments. These parameters have a local scope.\n\nExample of Function Parameters and Arguments\n• Use Local Variables: Prefer local variables over global ones to avoid unintended side effects and make your code easier to understand.\n• Minimize Intermediate Variables: Only use intermediate variables when necessary to improve readability.\n• Use Global Constants: If you need a value that is accessible everywhere, use global constants instead of mutable global variables.\n• Pass Values to Functions: Use function parameters to pass data, ensuring variables are scoped properly and reducing reliance on global state.\n\nLet’s consider a data science example where we analyze a dataset to calculate the average income by age group. We will implement the solution by following the best practices for variable scope: using local variables, minimizing intermediate variables, using global constants, and passing values to functions.\n\nSuppose we have a dataset in a CSV file named , which contains the following columns: , , and . Our goal is to group the people by age ranges (like 20-29, 30-39, etc.) and calculate the average income for each group.\n\nExplanation of Best Practices in the Code\n• Use Local Variables: Variables such as , , and are all local to their respective functions, preventing unintended side effects and making the code easier to understand.\n• Minimize Intermediate Variables: Intermediate variables like are used only where necessary to improve readability and show the logical steps in data processing. Unnecessary intermediate variables are avoided to keep the code concise.\n• Use Global Constants: The constant is defined globally because it is a fixed value that is used throughout the script. This avoids magic numbers and makes the code more readable.\n• Pass Values to Functions: The functions , , and receive data via parameters rather than relying on global state, ensuring that variable scope is managed properly and reducing dependencies between functions.\n\nUnderstanding variables and their scope is important for writing efficient, readable, and maintainable code. Always aim to use variables with local scope, avoid unnecessary intermediate variables, minimize global variables, and prefer constants when needed. By following these best practices, you will create Python programs that are easier to understand, debug, and maintain.\n\nBoolean expressions are one of the most used logic in programming, serving as the foundation for decision-making processes. In AI, data science, and machine learning projects, boolean expressions are extensively used for data validation, model evaluation, and control flow. However, compound boolean expressions can become unwieldy and difficult to maintain if not managed properly. This article explains best practices for writing boolean expressions in Python, ensuring your code remains clear, maintainable, and efficient.\n\nCompound boolean expressions should generally not exceed 3–4 expressions. Longer boolean expressions can become difficult to read and understand, increasing the likelihood of errors.\n\nWhen compound boolean expressions extend to 5 or more expressions, it’s a sign that the logic may be too complex. Instead of chaining multiple conditions, consider breaking down the logic into smaller, more manageable parts.\n\nIf you find yourself checking 6 or more boolean expressions, it’s usually an indication that your current module is too complex. This level of complexity can make your code difficult to maintain and debug. In such cases, reconsider your approach and seek to simplify the logic.\n\nTo manage complexity, refactor your code by breaking down complex boolean expressions into smaller functions or variables that encapsulate specific conditions.\n\nIn AI, data science, and machine learning projects, boolean expressions are often used for:\n\nModel evaluation — Checking multiple performance metrics to determine if a model meets the desired standards.\n• Control flow — Directing the flow of operations based on multiple conditions.\n\nBy adhering to these best practices for boolean expressions, you ensure that your Python code for AI, data science, and machine learning projects is clear, maintainable, and efficient.\n• Manage Complexity: Refactor code with 6+ conditions to simplify and improve readability.\n• Use Practical Applications: Apply these principles in data validation, model evaluation, and control flow.\n\nBranching using if/else statements is a fundamental part of programming, allowing for decision-making based on conditions. In AI, data science, and machine learning projects, effective use of branching can enhance code clarity and maintainability.\n\nThis section outlines best practices for using if/else statements in Python, tailored for AI, data science, and machine learning applications.\n\nNested if/else statements should generally not exceed 2–3 levels deep. Excessive nesting can make your code difficult to read, understand, and maintain.\n\nNesting if/else statements 4 or more levels deep usually indicates that your code is too complex. This level of complexity can make your code prone to errors and difficult to debug. Consider refactoring your logic into smaller, more manageable functions or using other control structures.\n\nTo manage complexity, refactor nested if/else statements into smaller functions or use other control structures like dictionaries or switch-case statements.\n\nStrict if/else/if statements, also known as if/elif/else chains, can be as long as necessary. They are inherently more readable than deeply nested if/else statements and are suitable for checking multiple conditions sequentially.\n\nIn AI, data science, and machine learning projects, branching is often used for:\n• Error handling — Managing exceptions and edge cases during model training and evaluation.\n• Manage Complexity: Refactor code with 4+ levels of nesting to simplify and improve readability.\n• Use Strict If/Else/If Chains: Employ these for checking multiple conditions in sequence.\n• Practical Applications: Apply these principles in data preprocessing, model selection, and error handling.\n\nRepetition statements, or loops, are essential constructs in programming that allow for the execution of a block of code multiple times. Proper use of loops can enhance code clarity, performance, and maintainability, particularly in AI, data science, and machine learning projects.\n\nHowever, improper use of loops can lead to inefficient and difficult-to-read code. This section outlines best practices for using loops in Python, tailored for AI, data science, and machine learning applications.\n\nNested loops should generally not exceed 2–3 levels. Excessive nesting can make your code complex and difficult to understand.\n\nDo not write purposeful infinite loops like or . There is almost always a better way to accomplish what you are trying to do.\n\nUse Determinant Loops When Appropriate\n\nUse determinant loops (i.e., for loops) when you know the number of iterations. Avoid using for loops when the number of iterations is unknown.\n\nUse Indeterminate Loops When Appropriate\n\nUse indeterminate loops (i.e., while loops) when the number of iterations is unknown. Avoid using while loops when the number of iterations is known.\n\nUsing break or continue can indicate faulty logic and disrupt the logical flow of loops, making optimization difficult and potentially slowing execution.\n\nIf statements inside loops can often be avoided and their presence may indicate faulty logic, which can slow program execution unnecessarily.\n\nProper use of loops can significantly improve the readability and performance of your code.\n• Use Determinant Loops: When you know the number of iterations.\n• Use Indeterminate Loops: When the number of iterations is unknown.\n• Avoid Break or Continue: Indicate faulty logic and disrupt optimization.\n\nModularity in Python Procedural Programming with AI and Data Science Focus\n\nModularity is a fundamental principle of software engineering that involves dividing a program into distinct, manageable sections, each encapsulated within its own function. This approach is especially crucial in AI and data science projects, where code clarity, maintainability, and reusability are paramount.\n\nThis section covers best practices for achieving modularity in Python procedural programming, tailored for AI and data science applications.\n\nThis separation of concerns is a hallmark of professional software engineering, distinguishing it from simple scripting. Modularity enhances code readability, maintainability, and reusability.\n\nFunctions are the primary means of achieving modularity. A function should perform one specific task, and programs should be collections of such functions. Functions can call other functions, including themselves (recursion).\n\nThe Don’t Repeat Yourself (DRY) principle is a cornerstone of effective software development, emphasizing the importance of reducing repetition in code. In data science and AI projects, adhering to the DRY principle can significantly improve code maintainability, readability, and reliability. This article explores the DRY principle in detail and provides practical guidance on how to apply it in Python procedural programming, specifically within the context of data science and AI.\n\nWhat is the DRY Principle?\n\nThe DRY principle states that every piece of knowledge must have a single, unambiguous, authoritative representation within a system. In simpler terms, this means avoiding the duplication of code by ensuring that each piece of logic is written only once and reused wherever necessary. Code repetition often indicates faulty logic and can lead to errors, making the codebase harder to maintain and understand.\n\nHow to Apply the DRY Principle\n\nApplying the DRY principle involves identifying repeated logic and refactoring it into functions or using repetition structures like loops.\n\nHere are some strategies to implement DRY effectively:\n\nIf you find yourself writing the same or similar code in multiple places, encapsulate that logic in a function. This not only reduces repetition but also makes your code more modular and easier to test.\n\nWhen performing similar operations on multiple items, use loops instead of writing repetitive code.\n\nIn data science and AI, common tasks like data preprocessing, feature engineering, and model evaluation often involve repetitive operations. Encapsulating these tasks into reusable functions can greatly improve code quality.\n\nThe code provided is for preprocessing a dataset by filling missing values with 0 and removing any negative values from each column. The function handles the processing of individual columns, while the function applies this processing to each column in the dataset. This modular approach ensures that the data is cleaned consistently across the entire dataset.\n\nBy defining these functions, the code becomes modular and reusable:\n\nConsistent Application: The same preprocessing logic can be applied to any dataset, ensuring consistency and reducing redundancy.\n\nThe provided code demonstrates a process for training and evaluating a linear regression model using the Scikit-Learn library in Python.\n\nThe provided code respects the Don’t Repeat Yourself (DRY) principle by encapsulating the repetitive and related logic of data splitting, model training, and evaluation into a single, reusable function. Here’s how it adheres to the DRY principle:\n• Data Splitting: The logic for splitting the dataset into training and testing sets is encapsulated within the function. This avoids repeating the same splitting code whenever a model needs to be trained and evaluated.\n• Model Training: The code for initializing, training, and fitting the model is contained within the function. This ensures the training process is consistent and not duplicated elsewhere in the codebase.\n• Model Evaluation: The calculation of Mean Squared Error (MSE) for evaluating the model is also included in the function, ensuring that this evaluation logic does not have to be rewritten.\n\nBy defining the function , the code becomes modular and reusable:\n\nThis example usage demonstrates that the same function can be called with different datasets or features without rewriting the logic for data splitting, training, and evaluation each time.\n\nBy following the DRY principle, the code avoids redundancy and ensures that the logic for training and evaluating models is centralized, making it easier to manage and less error-prone.\n\nBenefits of Following the DRY Principle\n• Reduced Errors: By centralizing logic, the risk of inconsistencies and bugs is minimized.\n• Easier Maintenance: Updates and fixes need to be made in only one place, simplifying code maintenance.\n• Improved Collaboration: Clear, modular code is easier for team members to understand and work with.\n• Enhanced Performance: Reusable functions and optimized loops can lead to more efficient code execution.\n\nDo not use or in your program, except possibly at the very end. Even then, it is typically unnecessary. These functions terminate the program abruptly and can lead to difficult-to-debug issues.\n\nWhat Does One-and-Only-One Task Mean?\n\nOne-and-Only-One Task means that a function should be designed to perform only one specific task. This task should be self-contained and clearly defined, ensuring that the function focuses solely on its designated purpose without extraneous responsibilities.\n\nOne such practice revolves around the concept of Single Responsibility. This principle dictates that a function should handle only one aspect of the program’s functionality. By limiting a function to a single responsibility, the code becomes more organized and each function can be understood and tested in isolation, enhancing the overall robustness of the application.\n\nClarity is another essential tenet in function design. A well-crafted function should have a clear and descriptive name that reflects its purpose. Additionally, the implementation of the function should be straightforward and easy to comprehend. When a function’s purpose is easily understood just by reading its name and code, it simplifies the task of debugging and collaborating with other developers, as there is little ambiguity about what the function is supposed to accomplish.\n\nModularity is a significant benefit of writing functions that adhere to single responsibility and clarity principles. Functions should be self-contained and independent, allowing the program to be divided into manageable, modular components. This modularity facilitates reusability, as well as easier updates and maintenance. When each function operates independently, changes in one part of the codebase are less likely to impact other parts, reducing the risk of introducing bugs.\n\nLastly, focusing on maintainability is crucial for long-term code management. Functions that serve a single purpose are inherently easier to test, debug, and modify. When a function does only one thing, understanding its behavior and ensuring its correctness becomes more straightforward. Moreover, if a change is required, it can be implemented with minimal risk of unintended consequences, as the function’s scope is well-defined and limited.\n\nWhy is This Important in Data Science and AI?\n\nIn data science and AI, code often involves complex data manipulation, statistical analysis, and model training processes. Applying the One-and-Only-One Task principle helps manage this complexity in several ways:\n• Readability: Clear, focused functions make it easier for other developers (or your future self) to understand the code. This is critical when dealing with complex algorithms and data processing pipelines.\n• Reusability: Functions that perform a single task can be reused across different parts of the project or even in different projects. This reduces redundancy and promotes code reuse.\n• Testing: Testing individual functions is easier when they perform only one task. Unit tests can be more precise and meaningful, leading to more robust code.\n• Debugging: Isolating and fixing bugs is simpler when each function has a single responsibility. Changes in one function are less likely to introduce bugs in other parts of the code.\n• Collaboration: When working in teams, modular functions facilitate better collaboration as team members can work on different functions independently without causing conflicts.\n\nLet’s explore some practical examples to illustrate the One-and-Only-One Task principle in data science and AI.\n\nData preprocessing often involves multiple steps such as handling missing values, normalizing data, and encoding categorical variables. Each of these steps should be encapsulated in its own function.\n\nIn this example, each function handles a specific aspect of data preprocessing, making the overall code easier to understand and maintain.\n\nTraining a machine learning model involves several distinct tasks such as data splitting, model fitting, and evaluation. Each of these tasks should be encapsulated in its own function.\n\nIn this example, splitting data, training the model, and evaluating the model are handled by separate functions, making the code modular and easier to manage.\n\nAdhering to the One-and-Only-One Task principle is important for creating modular, maintainable, and efficient code in data science and AI projects. By ensuring that each function has a single, well-defined purpose, you can significantly enhance the readability, reusability, and testability of your code. This practice not only helps in managing the complexity of data-intensive projects but also facilitates collaboration and long-term maintenance.\n• Single Responsibility: A function should handle only one aspect of the program’s functionality.\n• Clarity: The function’s purpose should be easily understood by reading its name and implementation.\n• Modularity: Functions should be self-contained and independent, making the program modular.\n• Maintainability: A function with a single purpose is easier to test, debug, and modify without affecting other parts of the program.\n\nFunctions should be concise, typically no more than a couple of dozen lines. Longer functions often violate the “one-and-only-one job” rule and can be difficult to manage.\n\nThis function is too long:\n• Difficult to Understand: It’s hard to grasp what the function is doing without reading through all the code.\n• Difficult to Maintain: Any changes or debugging would require navigating through a long and complex function.\n• Violates the Single Responsibility Principle: The function should focus on one task rather than multiple tasks.\n\nTo follow best practices, we can refactor the code into smaller, more focused functions:\n\nIn programming, a “driver file” contains the “driver function,” commonly known as . This function serves as the entry point for your program. In Python, a typical driver file might be named , and within it, you'll define a function. The concept of driver files and functions is critical for structuring your code, especially in larger applications. Here, we will discuss the rules and exceptions specific to driver files and functions in Python.\n• One-and-Only-One Driver: Your application should have a single driver file. This file serves as the entry point to your program.\n• Single Function in Driver File: The driver file should contain only the function. Avoid placing other functions directly in this file to keep the structure clear and maintainable.\n• Code Directly in Driver File: In some cases, it is acceptable to have code directly in the driver file without wrapping it in a function. This is common in simple scripts or when initializing the application.\n• Length of Driver Functions: Driver functions are generally exempt from the rule limiting function length to 24 lines. While driver functions can be longer, it’s essential to avoid repeating code and to maintain clarity.\n• Use of Literals: The rule against using literals directly in your code still applies. Literals should be defined as constants at the beginning of your file or module.\n\nExample of a Driver File in Python\n\nHere’s an example of a typical driver file ( ) in Python:\n• Constants: Constants are defined at the top of the file to avoid using literals directly within the code.\n• Imports: Necessary modules are imported within the function to keep the driver file self-contained.\n• Main Function: The function contains the workflow of loading data, preprocessing, training the model, saving the model, and evaluating it.\n• Preprocessing Function: The function is defined outside for modularity, even though it's used within the driver function.\n• Driver Functions Length: Although the function can be longer than other functions, strive to keep it as concise as possible. Break down complex workflows into smaller functions when feasible.\n• Avoid Repetition: Repeated logic should still be encapsulated in functions to maintain clean and maintainable code.\n• Literals: Define literals as constants to ensure clarity and maintainability.\n\nBy following these guidelines, you can create clear, maintainable, and well-structured Python programs. The driver file and function serve as the entry point and orchestrate the flow of your application, making it easy to understand and manage.\n\nPython’s ecosystem is rich with libraries and frameworks designed to simplify AI, data science, and machine learning tasks.\n\nHandling Exceptions Gracefully in Python for Data Science and AI\n\nIn data science and AI projects, handling exceptions gracefully is crucial for maintaining robust and reliable code. Exceptions are unexpected events that disrupt the normal flow of a program.\n\nProper exception handling ensures that these disruptions are managed appropriately, allowing the program to continue running or fail gracefully without causing significant issues.\n\nWhy Exception Handling is Important in Data Science and AI\n\nException handling is a crucial aspect of programming that has significant implications in the fields of data science and artificial intelligence (AI). Its importance can be appreciated by examining its impact on data integrity, model training, user experience, and debugging.\n\nOne of the primary reasons exception handling is indispensable in data science and AI is its role in maintaining data integrity. In these fields, data is the cornerstone upon which analyses and models are built. Exception handling ensures that the processes which manipulate and transform data run smoothly, without introducing errors or corruption.\n\nFor instance, when a script encounters an unexpected data format or a missing value, proper exception handling allows the program to skip the problematic data point or use a default value, thus preventing the entire process from crashing and preserving the integrity of the dataset.\n\nModel training in AI is another area where exception handling proves its worth. Training models involves extensive computations and iterative processes, which are prone to various types of errors. These can range from simple issues like missing data to more complex problems such as numerical instability. By implementing robust exception handling mechanisms, data scientists can manage these errors gracefully.\n\nFor example, they can handle missing data by imputing values or stopping the training process when performance metrics fall below certain thresholds. This ensures that the training process is resilient and produces reliable models without being derailed by unforeseen issues.\n\nIn the context of user experience, exception handling is essential for providing meaningful feedback to users. When users interact with data science applications or AI systems, they are often not equipped to understand the technical details of any errors that may occur.\n\nWell-designed exception handling can catch errors and present user-friendly messages that explain what went wrong and how to fix it. This not only improves the user experience by making the system more transparent and easier to use but also builds trust in the system’s reliability.\n\nFinally, exception handling plays a critical role in debugging. In complex data science and AI projects, errors can arise from a multitude of sources. Without effective exception handling, identifying and troubleshooting these errors can be a daunting task.\n\nException handling helps by catching errors and providing detailed logs that pinpoint the source of the problem. This aids developers in quickly diagnosing and fixing issues, thereby enhancing the overall efficiency of the development process.\n\nIn Python, exceptions are managed using , , , and blocks.\n• try: Block where you write code that might throw an exception.\n• except: Block that catches and handles the exception.\n• else: Block that executes if no exceptions were raised in the try block.\n• finally: Block that executes no matter what, used for cleanup actions.\n\nIn data science and AI, you often deal with large datasets, complex transformations, and various machine learning models. Handling exceptions gracefully in these scenarios is vital.\n\nWhen loading data from a file, various issues can arise, such as the file not existing, incorrect formats, or read permission errors.\n\nWhen training a machine learning model, issues like data inconsistencies, convergence problems, or memory errors can occur.\n\nBest Practices for Exception Handling in Data Science and AI\n• Specific Exceptions: Catch specific exceptions rather than a generic to make debugging easier.\n• Meaningful Messages: Provide meaningful error messages to help understand the issue.\n• Logging: Use logging to record exceptions for later analysis.\n• Fail Gracefully: Ensure the program fails gracefully and cleans up resources if necessary.\n• Retries: Implement retries for transient errors, such as network issues during data loading.\n\nHandling exceptions gracefully is essential in data science and AI projects to ensure data integrity, reliable model training, and a better user experience.\n\nBy following best practices and implementing robust exception handling mechanisms, you can build more resilient and maintainable data-driven applications.\n\nComprehensive documentation is crucial for helping others understand and use your code effectively. It not only aids in collaboration but also makes it easier for you to maintain and expand your own projects. In data science and AI projects, where complexity can quickly escalate, clear documentation becomes even more vital.\n\nDocstrings are an excellent way to document your functions, classes, and modules directly within your code. They provide a convenient way to describe the purpose, usage, parameters, and return values of your code elements. Python’s built-in function can then be used to access this information.\n\nA docstring in Python is a special kind of comment used to describe the purpose, parameters, return values, and potential exceptions of a function, method, class, or module. It is placed as the first statement in the function or class definition and is enclosed in triple quotes (“”” “””).\n\nBuilding a docstring in Python is a straightforward process. A well-crafted docstring serves multiple purposes: it provides a clear explanation of the code's functionality, details the parameters and return values, and describes any exceptions that might be raised.\n\nHere is a brief guide on how to construct an effective docstring.\n\nThe first line of a docstring should be a concise summary of what the function or method does. This line should be brief and to the point, ideally not exceeding one or two sentences. This summary gives the reader an immediate understanding of the function’s purpose without needing to delve into the implementation details.\n\nThe Parameters section of a docstring describes each input parameter of the function. For each parameter, you should provide its name, type, and a brief description of its role. This helps users understand what inputs are required and what they represent.\n\n3. Specify the Return Value\n\nNext, describe the return value of the function. Clearly state what the function returns, including the type and a brief explanation of what the returned value represents. This section is important for users to understand what output they can expect from the function.\n\nFinally, include a section that lists any exceptions the function might raise. For each exception, provide the type of the exception and a brief explanation of the circumstances under which it might be raised.\n\nHere is a breakdown of how the docstring is composed for the function:\n• Description: The first line of the docstring is a brief summary of what the function does.\n• Description: This section describes the input parameters of the function. Each parameter is listed with its name, type, and a brief description of its purpose.\n• Example: Parameters: file_path (str): The path to the CSV file to be loaded.\n• Description: This section describes the return value of the function, including its type and a brief description of what it represents.\n• Example: Returns: DataFrame: A pandas DataFrame containing the loaded data.\n• Description: This section lists the exceptions that the function might raise, along with the conditions under which they are raised.\n• Example -> Raises: FileNotFoundError: If the file does not exist. pd.errors.ParserError: If the file is not in the correct format. Exception: For any other unexpected errors.\n\nAfter the docstring, the function implementation follows. The try-except block within the function handles different types of errors that might occur during the execution of the function call. The docstring serves as a helpful guide to understand what the function is intended to do, what inputs it expects, what it returns, and what exceptions it might raise.\n\nA README file is an essential component of any project. It provides an overview of the project, instructions on how to set it up, and guidance on how to use it. A well-written README can significantly reduce the learning curve for new users and collaborators. Readme file, preferably should be in markdown format, and be named README.md.\n\nBelow is a sample structure for a README file for a data science project:\n\nInclude Instructions on how to use the project, examples and command-line usage if applicable.\n\nTest Your Functions and your code\n\nTesting your code is essential to ensure it works as expected and helps prevent future bugs. This is especially important in data science and AI projects, where the complexity and importance of accurate results make thorough testing crucial. One of the most effective ways to test your code is by writing unit tests.\n\nUnit tests focus on testing individual functions or methods to ensure they work correctly. In Python, the module provides a framework for writing and running tests.\n\nConsider a function that calculates the mean of a list of numbers. We can write unit tests to validate its correctness.\n\nUsing various inputs, including edge cases, ensures that your functions handle all possible scenarios correctly. Edge cases might include empty lists, very large or small numbers, and lists with duplicate values.\n\nExample: Validating Functions with Various Inputs\n\nHere’s an example of a function that normalizes data and its corresponding tests.\n• Isolation: Each test should be independent of others. Changes in one test should not affect the outcome of another.\n• Descriptive Names: Use descriptive names for test methods to indicate what they are testing.\n• Comprehensive Coverage: Ensure tests cover all possible scenarios, including edge cases and unexpected inputs.\n• Use Assertions: Use various assertion methods provided by to check for expected outcomes.\n• Automate Testing: Integrate tests into your development workflow to run them automatically before committing code.\n\nTesting your code is a fundamental practice in software development, particularly in data science and AI projects. By writing unit tests and validating your functions with various inputs, including edge cases, you can ensure that your code behaves as expected and is robust against potential issues. Following best practices for testing will help you maintain high-quality code and facilitate easier debugging and maintenance."
    },
    {
        "link": "https://docs.python.org/3/tutorial/index.html",
        "document": "Python is an easy to learn, powerful programming language. It has efficient high-level data structures and a simple but effective approach to object-oriented programming. Python’s elegant syntax and dynamic typing, together with its interpreted nature, make it an ideal language for scripting and rapid application development in many areas on most platforms.\n\nThe Python interpreter and the extensive standard library are freely available in source or binary form for all major platforms from the Python web site, https://www.python.org/, and may be freely distributed. The same site also contains distributions of and pointers to many free third party Python modules, programs and tools, and additional documentation.\n\nThe Python interpreter is easily extended with new functions and data types implemented in C or C++ (or other languages callable from C). Python is also suitable as an extension language for customizable applications.\n\nThis tutorial introduces the reader informally to the basic concepts and features of the Python language and system. It helps to have a Python interpreter handy for hands-on experience, but all examples are self-contained, so the tutorial can be read off-line as well.\n\nFor a description of standard objects and modules, see The Python Standard Library. The Python Language Reference gives a more formal definition of the language. To write extensions in C or C++, read Extending and Embedding the Python Interpreter and Python/C API Reference Manual. There are also several books covering Python in depth.\n\nThis tutorial does not attempt to be comprehensive and cover every single feature, or even every commonly used feature. Instead, it introduces many of Python’s most noteworthy features, and will give you a good idea of the language’s flavor and style. After reading it, you will be able to read and write Python modules and programs, and you will be ready to learn more about the various Python library modules described in The Python Standard Library.\n\nThe Glossary is also worth going through."
    },
    {
        "link": "https://docs.python.org/3/howto/functional.html",
        "document": "In this document, we’ll take a tour of Python’s features suitable for implementing programs in a functional style. After an introduction to the concepts of functional programming, we’ll look at language features such as iterators and generators and relevant library modules such as and .\n\nThis section explains the basic concept of functional programming; if you’re just interested in learning about Python language features, skip to the next section on Iterators. Programming languages support decomposing problems in several different ways:\n• None Most programming languages are procedural: programs are lists of instructions that tell the computer what to do with the program’s input. C, Pascal, and even Unix shells are procedural languages.\n• None In declarative languages, you write a specification that describes the problem to be solved, and the language implementation figures out how to perform the computation efficiently. SQL is the declarative language you’re most likely to be familiar with; a SQL query describes the data set you want to retrieve, and the SQL engine decides whether to scan tables or use indexes, which subclauses should be performed first, etc.\n• None Object-oriented programs manipulate collections of objects. Objects have internal state and support methods that query or modify this internal state in some way. Smalltalk and Java are object-oriented languages. C++ and Python are languages that support object-oriented programming, but don’t force the use of object-oriented features.\n• None Functional programming decomposes a problem into a set of functions. Ideally, functions only take inputs and produce outputs, and don’t have any internal state that affects the output produced for a given input. Well-known functional languages include the ML family (Standard ML, OCaml, and other variants) and Haskell. The designers of some computer languages choose to emphasize one particular approach to programming. This often makes it difficult to write programs that use a different approach. Other languages are multi-paradigm languages that support several different approaches. Lisp, C++, and Python are multi-paradigm; you can write programs or libraries that are largely procedural, object-oriented, or functional in all of these languages. In a large program, different sections might be written using different approaches; the GUI might be object-oriented while the processing logic is procedural or functional, for example. In a functional program, input flows through a set of functions. Each function operates on its input and produces some output. Functional style discourages functions with side effects that modify internal state or make other changes that aren’t visible in the function’s return value. Functions that have no side effects at all are called purely functional. Avoiding side effects means not using data structures that get updated as a program runs; every function’s output must only depend on its input. Some languages are very strict about purity and don’t even have assignment statements such as or , but it’s difficult to avoid all side effects, such as printing to the screen or writing to a disk file. Another example is a call to the or function, neither of which returns a useful value. Both are called only for their side effects of sending some text to the screen or pausing execution for a second. Python programs written in functional style usually won’t go to the extreme of avoiding all I/O or all assignments; instead, they’ll provide a functional-appearing interface but will use non-functional features internally. For example, the implementation of a function will still use assignments to local variables, but won’t modify global variables or have other side effects. Functional programming can be considered the opposite of object-oriented programming. Objects are little capsules containing some internal state along with a collection of method calls that let you modify this state, and programs consist of making the right set of state changes. Functional programming wants to avoid state changes as much as possible and works with data flowing between functions. In Python you might combine the two approaches by writing functions that take and return instances representing objects in your application (e-mail messages, transactions, etc.). Functional design may seem like an odd constraint to work under. Why should you avoid objects and side effects? There are theoretical and practical advantages to the functional style: A theoretical benefit is that it’s easier to construct a mathematical proof that a functional program is correct. For a long time researchers have been interested in finding ways to mathematically prove programs correct. This is different from testing a program on numerous inputs and concluding that its output is usually correct, or reading a program’s source code and concluding that the code looks right; the goal is instead a rigorous proof that a program produces the right result for all possible inputs. The technique used to prove programs correct is to write down invariants, properties of the input data and of the program’s variables that are always true. For each line of code, you then show that if invariants X and Y are true before the line is executed, the slightly different invariants X’ and Y’ are true after the line is executed. This continues until you reach the end of the program, at which point the invariants should match the desired conditions on the program’s output. Functional programming’s avoidance of assignments arose because assignments are difficult to handle with this technique; assignments can break invariants that were true before the assignment without producing any new invariants that can be propagated onward. Unfortunately, proving programs correct is largely impractical and not relevant to Python software. Even trivial programs require proofs that are several pages long; the proof of correctness for a moderately complicated program would be enormous, and few or none of the programs you use daily (the Python interpreter, your XML parser, your web browser) could be proven correct. Even if you wrote down or generated a proof, there would then be the question of verifying the proof; maybe there’s an error in it, and you wrongly believe you’ve proved the program correct. A more practical benefit of functional programming is that it forces you to break apart your problem into small pieces. Programs are more modular as a result. It’s easier to specify and write a small function that does one thing than a large function that performs a complicated transformation. Small functions are also easier to read and to check for errors. Debugging is simplified because functions are generally small and clearly specified. When a program doesn’t work, each function is an interface point where you can check that the data are correct. You can look at the intermediate inputs and outputs to quickly isolate the function that’s responsible for a bug. Testing is easier because each function is a potential subject for a unit test. Functions don’t depend on system state that needs to be replicated before running a test; instead you only have to synthesize the right input and then check that the output matches expectations. As you work on a functional-style program, you’ll write a number of functions with varying inputs and outputs. Some of these functions will be unavoidably specialized to a particular application, but others will be useful in a wide variety of programs. For example, a function that takes a directory path and returns all the XML files in the directory, or a function that takes a filename and returns its contents, can be applied to many different situations. Over time you’ll form a personal library of utilities. Often you’ll assemble new programs by arranging existing functions in a new configuration and writing a few functions specialized for the current task.\n\nI’ll start by looking at a Python language feature that’s an important foundation for writing functional-style programs: iterators. An iterator is an object representing a stream of data; this object returns the data one element at a time. A Python iterator must support a method called that takes no arguments and always returns the next element of the stream. If there are no more elements in the stream, must raise the exception. Iterators don’t have to be finite, though; it’s perfectly reasonable to write an iterator that produces an infinite stream of data. The built-in function takes an arbitrary object and tries to return an iterator that will return the object’s contents or elements, raising if the object doesn’t support iteration. Several of Python’s built-in data types support iteration, the most common being lists and dictionaries. An object is called iterable if you can get an iterator for it. You can experiment with the iteration interface manually: Python expects iterable objects in several different contexts, the most important being the statement. In the statement , Y must be an iterator or some object for which can create an iterator. These two statements are equivalent: Iterators can be materialized as lists or tuples by using the or constructor functions: Sequence unpacking also supports iterators: if you know an iterator will return N elements, you can unpack them into an N-tuple: Built-in functions such as and can take a single iterator argument and will return the largest or smallest element. The and operators also support iterators: is true if X is found in the stream returned by the iterator. You’ll run into obvious problems if the iterator is infinite; , will never return, and if the element X never appears in the stream, the and operators won’t return either. Note that you can only go forward in an iterator; there’s no way to get the previous element, reset the iterator, or make a copy of it. Iterator objects can optionally provide these additional capabilities, but the iterator protocol only specifies the method. Functions may therefore consume all of the iterator’s output, and if you need to do something different with the same stream, you’ll have to create a new iterator. We’ve already seen how lists and tuples support iterators. In fact, any Python sequence type, such as strings, will automatically support creation of an iterator. Calling on a dictionary returns an iterator that will loop over the dictionary’s keys: Note that starting with Python 3.7, dictionary iteration order is guaranteed to be the same as the insertion order. In earlier versions, the behaviour was unspecified and could vary between implementations. Applying to a dictionary always loops over the keys, but dictionaries have methods that return other iterators. If you want to iterate over values or key/value pairs, you can explicitly call the or methods to get an appropriate iterator. The constructor can accept an iterator that returns a finite stream of tuples: Files also support iteration by calling the method until there are no more lines in the file. This means you can read each line of a file like this: # do something for each line Sets can take their contents from an iterable and let you iterate over the set’s elements:\n\nTwo common operations on an iterator’s output are 1) performing some operation for every element, 2) selecting a subset of elements that meet some condition. For example, given a list of strings, you might want to strip off trailing whitespace from each line or extract all the strings containing a given substring. List comprehensions and generator expressions (short form: “listcomps” and “genexps”) are a concise notation for such operations, borrowed from the functional programming language Haskell (https://www.haskell.org/). You can strip all the whitespace from a stream of strings with the following code: You can select only certain elements by adding an condition: With a list comprehension, you get back a Python list; is a list containing the resulting lines, not an iterator. Generator expressions return an iterator that computes the values as necessary, not needing to materialize all the values at once. This means that list comprehensions aren’t useful if you’re working with iterators that return an infinite stream or a very large amount of data. Generator expressions are preferable in these situations. Generator expressions are surrounded by parentheses (“()”) and list comprehensions are surrounded by square brackets (“[]”). Generator expressions have the form: Again, for a list comprehension only the outside brackets are different (square brackets instead of parentheses). The elements of the generated output will be the successive values of . The clauses are all optional; if present, is only evaluated and added to the result when is true. Generator expressions always have to be written inside parentheses, but the parentheses signalling a function call also count. If you want to create an iterator that will be immediately passed to a function you can write: The clauses contain the sequences to be iterated over. The sequences do not have to be the same length, because they are iterated over from left to right, not in parallel. For each element in , is looped over from the beginning. is then looped over for each resulting pair of elements from and . To put it another way, a list comprehension or generator expression is equivalent to the following Python code: This means that when there are multiple clauses but no clauses, the length of the resulting output will be equal to the product of the lengths of all the sequences. If you have two lists of length 3, the output list is 9 elements long: ('c', 1), ('c', 2), ('c', 3)] To avoid introducing an ambiguity into Python’s grammar, if is creating a tuple, it must be surrounded with parentheses. The first list comprehension below is a syntax error, while the second one is correct:\n\nGenerators are a special class of functions that simplify the task of writing iterators. Regular functions compute a value and return it, but generators return an iterator that returns a stream of values. You’re doubtless familiar with how regular function calls work in Python or C. When you call a function, it gets a private namespace where its local variables are created. When the function reaches a statement, the local variables are destroyed and the value is returned to the caller. A later call to the same function creates a new private namespace and a fresh set of local variables. But, what if the local variables weren’t thrown away on exiting a function? What if you could later resume the function where it left off? This is what generators provide; they can be thought of as resumable functions. Here’s the simplest example of a generator function: Any function containing a keyword is a generator function; this is detected by Python’s bytecode compiler which compiles the function specially as a result. When you call a generator function, it doesn’t return a single value; instead it returns a generator object that supports the iterator protocol. On executing the expression, the generator outputs the value of , similar to a statement. The big difference between and a statement is that on reaching a the generator’s state of execution is suspended and local variables are preserved. On the next call to the generator’s method, the function will resume executing. You could equally write , or . Inside a generator function, causes to be raised from the method. Once this happens, or the bottom of the function is reached, the procession of values ends and the generator cannot yield any further values. You could achieve the effect of generators manually by writing your own class and storing all the local variables of the generator as instance variables. For example, returning a list of integers could be done by setting to 0, and having the method increment and return it. However, for a moderately complicated generator, writing a corresponding class can be much messier. The test suite included with Python’s library, Lib/test/test_generators.py, contains a number of more interesting examples. Here’s one generator that implements an in-order traversal of a tree using generators recursively. Two other examples in produce solutions for the N-Queens problem (placing N queens on an NxN chess board so that no queen threatens another) and the Knight’s Tour (finding a route that takes a knight to every square of an NxN chessboard without visiting any square twice). In Python 2.4 and earlier, generators only produced output. Once a generator’s code was invoked to create an iterator, there was no way to pass any new information into the function when its execution is resumed. You could hack together this ability by making the generator look at a global variable or by passing in some mutable object that callers then modify, but these approaches are messy. In Python 2.5 there’s a simple way to pass values into a generator. became an expression, returning a value that can be assigned to a variable or otherwise operated on: I recommend that you always put parentheses around a expression when you’re doing something with the returned value, as in the above example. The parentheses aren’t always necessary, but it’s easier to always add them instead of having to remember when they’re needed. Values are sent into a generator by calling its method. This method resumes the generator’s code and the expression returns the specified value. If the regular method is called, the returns . Here’s a simple counter that increments by 1 and allows changing the value of the internal counter. And here’s an example of changing the counter: Because will often be returning , you should always check for this case. Don’t just use its value in expressions unless you’re sure that the method will be the only method used to resume your generator function. In addition to , there are two other methods on generators:\n• None is used to raise an exception inside the generator; the exception is raised by the expression where the generator’s execution is paused.\n• None raises a exception inside the generator to terminate the iteration. On receiving this exception, the generator’s code must either raise or ; catching the exception and doing anything else is illegal and will trigger a . will also be called by Python’s garbage collector when the generator is garbage-collected. If you need to run cleanup code when a occurs, I suggest using a suite instead of catching . The cumulative effect of these changes is to turn generators from one-way producers of information into both producers and consumers. Generators also become coroutines, a more generalized form of subroutines. Subroutines are entered at one point and exited at another point (the top of the function, and a statement), but coroutines can be entered, exited, and resumed at many different points (the statements).\n\nLet’s look in more detail at built-in functions often used with iterators. Two of Python’s built-in functions, and duplicate the features of generator expressions: returns an iterator over the sequence You can of course achieve the same effect with a list comprehension. returns an iterator over all the sequence elements that meet a certain condition, and is similarly duplicated by list comprehensions. A predicate is a function that returns the truth value of some condition; for use with , the predicate must take a single value. This can also be written as a list comprehension: counts off the elements in the iterable returning 2-tuples containing the count (from start) and each element. is often used when looping through a list and recording the indexes at which certain conditions are met: collects all the elements of the iterable into a list, sorts the list, and returns the sorted result. The key and reverse arguments are passed through to the constructed list’s method. The and built-ins look at the truth values of an iterable’s contents. returns if any element in the iterable is a true value, and returns if all of the elements are true values: takes one element from each iterable and returns them in a tuple: It doesn’t construct an in-memory list and exhaust all the input iterators before returning; instead tuples are constructed and returned only if they’re requested. (The technical term for this behaviour is lazy evaluation.) This iterator is intended to be used with iterables that are all of the same length. If the iterables are of different lengths, the resulting stream will be the same length as the shortest iterable. You should avoid doing this, though, because an element may be taken from the longer iterators and discarded. This means you can’t go on to use the iterators further because you risk skipping a discarded element.\n\nWhen writing functional-style programs, you’ll often need little functions that act as predicates or that combine elements in some way. If there’s a Python built-in or a module function that’s suitable, you don’t need to define a new function at all: If the function you need doesn’t exist, you need to write it. One way to write small functions is to use the expression. takes a number of parameters and an expression combining these parameters, and creates an anonymous function that returns the value of the expression: An alternative is to just use the statement and define a function in the usual way: Which alternative is preferable? That’s a style question; my usual course is to avoid using . One reason for my preference is that is quite limited in the functions it can define. The result has to be computable as a single expression, which means you can’t have multiway comparisons or statements. If you try to do too much in a statement, you’ll end up with an overly complicated expression that’s hard to read. Quick, what’s the following code doing? You can figure it out, but it takes time to disentangle the expression to figure out what’s going on. Using a short nested statements makes things a little bit better: But it would be best of all if I had simply used a loop: Or the built-in and a generator expression: Many uses of are clearer when written as loops. Fredrik Lundh once suggested the following set of rules for refactoring uses of :\n• None Write a comment explaining what the heck that lambda does.\n• None Study the comment for a while, and think of a name that captures the essence of the comment.\n• None Convert the lambda to a def statement, using that name. I really like these rules, but you’re free to disagree about whether this lambda-free style is better."
    },
    {
        "link": "https://appacademy.io/blog/python-coding-best-practices",
        "document": "Python is a sophisticated, widely used coding language that, for developers, acts as an artist’s paint brush to a canvas. In fact, it’s one of the most popular languages today.\n\nBut what happens when there are missing fundamentals, structure, or other components from a long string of language? It begins to distort the message. Having a strong understanding of the following 8 Python best practices will help you produce stunning works of art, translated through code.\n\nWhy Is It Important to Use Best Practices When Coding with Python?\n\nPython programming is incredibly versatile. It can be used to help build everything from a simple command prompt to a complex game development, AI, and more.\n\nLearn More: What is Python Used For?\n\nFollowing Python coding best practices ensures that your code is consistently clean and readable. It encourages code reusability, reduces the likelihood of bugs (not to mention, makes it easier to discover and repair bugs), and makes it easier to maintain and restructure.\n\nAs Python's philosophy revolves around readability and simplicity, adhering to these standards and practices can help developers harness the full potential of Python's elegant syntax.\n\nBefore digging into Python development, there are four fundamental pillars you should focus on: formatting and syntax, documentation, testing, and naming conventions. Each of these Python coding standards and best practices supports the development process by laying the foundation for more advanced concepts.\n\nOne of the easiest ways to ensure code quality is by following the PEP8 Python coding style guide for formatting and syntax. Consistent code formatting makes your code easy to read and understand, easy to maintain, reduces errors, and makes it easier to collaborate. This involves best practices around stylistic choices such as indentation, line spacing, use of white space, and comments.\n\nPython best practices for code quality include using four spaces for each indentation level. It also outlines that tabs and white spaces should not be intermixed (spaces should be used, not tabs). And lastly, indent consistently from start to finish.\n\nLine spacing guidelines for Python include using blank lines sparingly. Top-level functions and class definitions should be separated with two blank lines while method definitions should be separated by one.\n\nThese guidelines also indicate that lines should be kept reasonably short, around 79 characters (though some coders prefer 99-119). Lastly, line breaks should be used with care and incorporate things like parentheses, brackets, backslashes, and braces to break up longer strings of code.\n\nPEP 8 indicates to avoid trailing whitespace on all lines, except those that are otherwise blank. It also directs to use spaces around binary operators, such as equal signs, brackets, etc. You should also avoid extra whitespace, ensuring not to place them inside brackets or before commas.\n\nComments are another important part of basic Python best practices, as they provide insights into each piece of code. Keeping comments up-to-date is crucial, as outdated comments can be worse than having none at all.\n\nComments should be used to explain why the code is the way it is or the problem it’s solving, rather than detailing what it does. Comments should be written using docstrings, when applicable, as they can tie the code to a module, function, or class. And lastly, inline comments should be used sparingly and separated by at least two spaces from the statement, starting with a hashtag and a single space and indented to the same level for each line.\n\nVarious tools can help enforce these standards, such as PEP8 checkers and formatters, linters, and integrated development environments (IDEs). Some popular PEP8 checkers include Pylint and Flake8. Popular auto formatters include Black and YAPF. Common IDEs include PyCharm, Sublime Text, and Visual Studio Code.\n\nClear, current, and comprehensive documentation is a cornerstone of maintainable code. This extends beyond simple comments within your codebase, including module-level docstrings, function, and method explanations, plus context for more complex blocks of code. Here are some Python coding best practices when it comes to documentation:\n• Write docstrings for all public modules, functions, classes, and methods.\n• Keep docstrings current to the code.\n• Include examples when documenting more complex functions or methods.\n• Use Automated documentation generators, like Sphinx and Doxygen.\n\nWhen to Use Automated Documentation Generators\n\nThese handy tools create documentation automatically using your source code. This can save developers considerable time and effort. Some examples of when Python automated documentation generators come in handy may include when you’re using large or complex code bases, working on a collaborative project, using public APIs or libraries, working on open-source projects, and more.\n\nDocumentation is a critical component of Python coding standards and best practices because it helps explain what the code does, how it does it, and why it was written that way. This is most helpful for complex sections of code where the functionality might not be immediately apparent, or when code can be done multiple ways but a certain way was selected. It supports code understandability, maintenance, collaboration, debugging, and long-term sustainability.\n\nTesting your code is yet another essential component of Python best practices for code quality. It ensures a quality completed code, can help catch bugs early, and ensures the code behaves as expected. You can utilize automated testing libraries and frameworks as well as best practices to ensure you’re testing effectively.\n• Write Clear, Simple, and Small Tests Early and Frequently. Try writing your tests before writing your code, using the test-driven development (TDD) method and ensure each test is designed to verify a single behavior.\n• Use Consistent Testing Methodology. Choose a testing method that works best for your unique project and stick with that testing module for the entire project.\n• Automate Your Testing. Automated tests help you catch bugs early, ensure that your code works as expected, and protect against regressions. To write effective tests, you can use one of the many libraries or frameworks available. Unitest and Pytest are popular choices.\n• Test Edge Cases and Failure Modes. Testing all aspects of the code, including failure points, will help ensure your code can handle all situations.\n• Perform Isolated Testing. Use mock and stub objects to mimic the behavior of more complex objects to help isolate the component that needs testing.\n• Aim for High Test Coverage. Tools like coverage.py can help you measure how much of your code is being tested. The more you test, the better.\n\nNaming conventions will also help keep your code consistent and easy to understand and maintain. Python outlines established conventions for naming variables, functions, classes, and modules in their PEP8 guidelines. Names should be self-explanatory, and describe the information in a descriptive way. Some of the Python coding standards and best practices for naming conventions include:\n• Variables & Functions: use all lowercase letters and separate words with underscores.\n• Classes: use CapWords/CamelCase, using a capital letter for each new word but not separating the words by spaces or underscores.\n• Modules: use all lowercase. Add underscores between words if it improves readability.\n• Methods: use the function naming rules but indicate internal use methods by adding an underscore before the name.\n• Built-In Names: avoid using the Python built-in names, such as naming a variable “list.”\n\n4 More Advanced Best Practices for Python Development\n\nOnce you've mastered the basics, you can move on to more advanced practices. These involve code organization, performance optimization, security, and scalability. They help manage more complex projects and prepare your code for production environments.\n\nAs your projects get larger and more complex, organizing your code becomes even more important. This involves thoughtfully structuring your files and directories, using modules and packages effectively, and following established design patterns. Following the Python best practices for organization will help ensure your code maintains readability and is easier to debug and modify.\n• Group Related Files. Use modules and packages to organize your code into different groups. A module is a file that will house Python code while a package groups related modules together.\n• Mark Directories as Python Packages. Use init.py files to indicate your directory is a Python package and use it to execute package initiation code or to specify API.\n• Use Import Statements. Import statements allow you to use code from one module to another. This is useful for splitting your codebase into logical groups.\n• D.R.Y. Code (Don’t Repeat Yourself). If you find yourself writing the same code in multiple places, you should organize it into a function or class that can be reused more efficiently while also reducing the probability for errors.\n• Use a Defined Structure. Structuring larger projects also helps keep them organized.\n• Relative Imports. Relative imports let you reference code from one module to another.\n\nWhile Python may not be the fastest programming language, there are several ways you can optimize the code for better performance. This includes writing efficient code by avoiding unnecessary calculations, making good use of data structures and algorithms, and using tools and libraries designed for performance. Make Python better by using the performance best practices below:\n• Use Built-In Functions and Libraries. Built-in features are already optimized for performance, so use them whenever possible.\n• Use Local Variables. Local variables are faster than global variables.\n• Use List Comprehensions and Generators. These are both faster and use less memory than equivalent code written in loops.\n• Use “Slots” in Classes. Use this function to use less memory when creating multiple instances of a class.\n• Avoid Excess/Unnecessary Data Structures. Use the code that, as simply as possible, will perform what you need it to. Avoid using options that also perform other functions.\n\nThe performance of your Python code can be measured using various modules and libraries. One popular one is the built-in “timeit” module that measures execution time in small bits to help find bottlenecks. You can also try NumPy and Pandas, which provide precompiled functions for numerical tasks quickly. For slow code, you can use Cython to help gain substantial improvements.\n\nSecurity should be a priority in any development project. This means writing secure code, handling sensitive data carefully, and using libraries and tools that help protect against common vulnerabilities. Libraries such as PyCrypto and requests for secure HTTP communication can help you secure your Python applications. Python coding standards and best practices for security include:\n• Input Validation. Validate and sanitize all user input to help protect against SQL injection and cross-site scripting.\n• Secure Library Use. Only use secure and well-maintained Python libraries when it comes to tasks related to security.\n• HTTPS for Web Apps. Always use HTTPS instead of HTTP when building a web application to ensure data is encrypted.\n• Limit Exec and Eval Use. These functions can execute arbitrary code, which can be a security risk.\n• Don’t Hard Code Sensitive Information. Never include private information in the hard code; use variables or secure configuration files instead.\n\nSecurity when creating code of any kind, including Python, is paramount. For one, it ensures data protection for sensitive information, such as personal details and financial information. It also helps secure system integrity and instill trust in users. Adhering to code security standards also ensures legal compliance with regulations like GDPR and HIPAA.\n\nUsing secure libraries will help protect your code from malicious attacks. Some of the most popular and best secure Python libraries include pyOpenSSL for SSL/TLS protocol, bcrypt for password hashing, Paramiko for SSH2 protocol, and cryptography for primitives.\n\nFinally, as your application grows, you should also be thinking about scalability. This means designing your systems to handle increased loads effectively, organizing your code for large code bases, and leveraging Python's features and libraries that help with scalability. Here are some Python best practices for scalability:\n• Use Efficient Data Structures and Algorithms. Choosing the right data structures and algorithms can greatly affect the scalability of your program.\n• Concurrent and Parallel Execution. Python has several libraries, such as concurrent futures and multiprocessing, that allow for concurrent or parallel execution of tasks to utilize multiple CPU cores and threads.\n• Asynchronous Processing. For I/O-bound tasks, using asynchronous processing can make your program more scalable. Python's asyncio library provides tools for writing single-threaded concurrent code.\n• Cache Data. Caching can improve your application's performance and scalability by storing the result of expensive operations and reusing them.\n• Use a Load Balancer. For web applications, use a load balancer to distribute traffic among multiple instances of your application.\n\nWhether you’re brand new to Python or an experienced developer looking for a refresh, reviewing the newest Python best practices is a surefire way to start off on the right foot. Creating structured, organized, and readable code is a key skill needed for developers on any career path, and adhering to these guidelines will help ensure each line of code you create is clean and effective now and well into the future.\n\nDiscover what you can do when you take your Python coding skills to the next level with App Academy. Our 100% online coding bootcamps include a comprehensive curriculum designed to prepare you for the career you want. Everything from the basics to advanced techniques and concepts are covered, setting you up for success.\n\nOur courses are designed to help you become a competent, confident Python developer ready to tackle real-world challenges. Learn more about our Python courses at App Academy and start your journey to becoming a Python expert today."
    },
    {
        "link": "https://discuss.python.org/t/is-there-python-book-on-procedural-programming-if-not-how-can-you-learn-it/14859",
        "document": "I’m somewhat a newb. I read an article about python’s capabilities and one thing in particular struck me as interesting. It’s called procedural programming. Is there a python book on that? If not, where can I learn it. I tried looking through the python documentation but I couldn’t find anything about procedural programming and I looked for books on it, but found no python books on procedural programming. What I want is to dabble with it, then decide if I like the approach or not."
    },
    {
        "link": "https://geeksforgeeks.org/python-oops-concepts",
        "document": "Object Oriented Programming is a fundamental concept in Python, empowering developers to build modular, maintainable, and scalable applications. By understanding the core OOP principles (classes, objects, inheritance, encapsulation, polymorphism, and abstraction), programmers can leverage the full potential of Python OOP capabilities to design elegant and efficient solutions to complex problems.\n\nOOPs is a way of organizing code that uses objects and classes to represent real-world entities and their behavior. In OOPs, object has attributes thing that has specific data and can perform certain actions using methods.\n\nA class is a collection of objects. Classes are blueprints for creating objects. A class defines a set of attributes and methods that the created objects (instances) can have.\n• None Attributes are the variables that belong to a class.\n• None Attributes are always public and can be accessed using the dot (.) operator. Example: Myclass.Myattribute\n\nHere, the class keyword indicates that we are creating a class followed by name of the class (Dog in this case).\n• species: A class attribute shared by all instances of the class.\n• __init__ method: Initializes the name and age attributes when a new object is created.\n\nAn Object is an instance of a Class. It represents a specific implementation of the class and holds its own data.\n• State: It is represented by the attributes and reflects the properties of an object.\n• Behavior: It is represented by the methods of an object and reflects the response of an object to other objects.\n• Identity: It gives a unique name to an object and enables one object to interact with other objects.\n\nCreating an object in Python involves instantiating a class to create a new instance of that class. This process is also referred to as object instantiation.\n• dog1 = Dog(“Buddy”, 3): Creates an object of the Dog class with name as “Buddy” and age as 3.\n• dog1.name: Accesses the instance attribute name of the dog1 object.\n• dog1.species: Accesses the class attribute species of the dog1 object.\n\nself parameter is a reference to the current instance of the class. It allows us to access the attributes and methods of the object.\n• self.name: Refers to the name attribute of the object (dog1) calling the method.\n\n__init__ method is the constructor in Python, automatically called when a new object is created. It initializes the attributes of the class.\n\nIn Python, variables defined in a class can be either class variables or instance variables, and understanding the distinction between them is crucial for object-oriented programming.\n\nThese are the variables that are shared across all instances of a class. It is defined at the class level, outside any methods. All objects of the class share the same value for a class variable unless explicitly overridden in an object.\n\nVariables that are unique to each instance (object) of a class. These are defined within the __init__ method or other instance methods. Each object maintains its own copy of instance variables, independent of other objects.\n• Class Variable (species): Shared by all instances of the class. Changing Dog.species affects all objects, as it’s a property of the class itself.\n• Instance Variables (name, age): Defined in the __init__ method. Unique to each instance (e.g., dog1.name and dog2.name are different).\n• Accessing Variables: Class variables can be accessed via the class name (Dog.species) or an object (dog1.species). Instance variables are accessed via the object (dog1.name).\n• Updating Variables: Changing Dog.species affects all instances. Changing dog1.name only affects dog1 and does not impact dog2.\n\nInheritance allows a class (child class) to acquire properties and methods of another class (parent class). It supports hierarchical classification and promotes code reuse.\n• Multiple Inheritance: A child class inherits from more than one parent class.\n• Multilevel Inheritance: A child class inherits from a parent class, which in turn inherits from another class.\n• Hybrid Inheritance: A combination of two or more types of inheritance.\n• Multiple Inheritance: GoldenRetriever inherits from both Dog and Friendly.\n\nPolymorphism allows methods to have the same name but behave differently based on the object’s context. It can be achieved through method overriding or overloading.\n• Compile-Time Polymorphism : This type of polymorphism is determined during the compilation of the program. It allows methods or operators with the same name to behave differently based on their input parameters or usage. It is commonly referred to as method or operator overloading.\n• Run-Time Polymorphism : This type of polymorphism is determined during the execution of the program. It occurs when a subclass provides a specific implementation for a method already defined in its parent class, commonly known as method overriding.\n• None Demonstrated using method overriding in the Dog class and its subclasses (Labrador and Beagle).\n• None The correct sound method is invoked at runtime based on the actual type of the object in the list.\n• None Python does not natively support method overloading. Instead, we use a single method (add) with default arguments to handle varying numbers of parameters.\n• None Different behaviors (adding two or three numbers) are achieved based on how the method is called.\n\nEncapsulation is the bundling of data (attributes) and methods (functions) within a class, restricting access to some components to control interactions.\n\nA class is an example of encapsulation as it encapsulates all the data that is member functions, variables, etc.\n• Protected Members : Accessible within the class and its subclasses.\n• Private Members : Accessible only within the class.\n• Public Members: Easily accessible, such as name.\n• Protected Members : Used with a single _, such as _breed. Access is discouraged but allowed in subclasses.\n• Private Members: Used with __, such as __age. Access requires\n\nAbstraction hides the internal implementation details while exposing only the necessary functionality. It helps focus on “what to do” rather than “how to do it.”\n• Partial Abstraction: Abstract class contains both abstract and concrete methods.\n• Full Abstraction: Abstract class contains only abstract methods (like interfaces).\n• Why Use It : Abstraction ensures consistency in derived classes by enforcing the implementation of abstract methods.\n\nWhat are the 4 pillars of OOP Python?\n\nIs OOP used in Python?"
    },
    {
        "link": "https://realpython.com/python3-object-oriented-programming",
        "document": "Object-oriented programming (OOP) in Python helps you structure your code by grouping related data and behaviors into objects. You start by defining classes, which act as blueprints, and then create objects from them. OOP simplifies modeling real-world concepts in your programs and enables you to build systems that are more reusable and scalable.\n\nBy the end of this tutorial, you’ll understand that:\n• Object-oriented programming in Python involves creating classes as blueprints for objects. These objects contain data and the methods needed to manipulate that data.\n• The four key concepts of OOP in Python are encapsulation, inheritance, abstraction, and polymorphism.\n• You create an object in Python by instantiating a class, which involves calling the class name followed by parentheses.\n• Class inheritance in Python allows a class to inherit attributes and methods from another class, known as the parent class.\n• You use super() in Python to call a method from the parent class, allowing you to extend or modify inherited behavior.\n\nYou’ll explore how to define classes, instantiate classes to create objects, and leverage inheritance to build robust systems in Python.\n\nWhat Is Object-Oriented Programming in Python? Object-oriented programming is a programming paradigm that provides a means of structuring programs so that properties and behaviors are bundled into individual objects. For example, an object could represent a person with properties like a name, age, and address and behaviors such as walking, talking, breathing, and running. Or it could represent an email with properties like a recipient list, subject, and body and behaviors like adding attachments and sending. Put another way, object-oriented programming is an approach for modeling concrete, real-world things, like cars, as well as relations between things, like companies and employees or students and teachers. OOP models real-world entities as software objects that have some data associated with them and can perform certain operations. OOP also exists in other programming languages and is often described to center around the four pillars, or four tenants of OOP:\n• Encapsulation allows you to bundle data (attributes) and behaviors (methods) within a class to create a cohesive unit. By defining methods to control access to attributes and its modification, encapsulation helps maintain data integrity and promotes modular, secure code.\n• Inheritance enables the creation of hierarchical relationships between classes, allowing a subclass to inherit attributes and methods from a parent class. This promotes code reuse and reduces duplication.\n• Abstraction focuses on hiding implementation details and exposing only the essential functionality of an object. By enforcing a consistent interface, abstraction simplifies interactions with objects, allowing developers to focus on what an object does rather than how it achieves its functionality.\n• Polymorphism allows you to treat objects of different types as instances of the same base type, as long as they implement a common interface or behavior. Python’s duck typing make it especially suited for polymorphism, as it allows you to access attributes and methods on objects without needing to worry about their actual class. In this tutorial you’ll take a practical approach to understanding OOP in Python. But keeping these four concepts of object-oriented programming in mind may help you to remember the information that you gather. The key takeaway is that objects are at the center of object-oriented programming in Python. In other programming paradigms, objects only represent the data. In OOP, they additionally inform the overall structure of the program.\n\nHow Do You Define a Class in Python? In Python, you define a class by using the keyword followed by a name and a colon. Then you use to declare which attributes each instance of the class should have: But what does all of that mean? And why do you even need classes in the first place? Take a step back and consider using built-in, primitive data structures as an alternative. Primitive data structures—like numbers, strings, and lists—are designed to represent straightforward pieces of information, such as the cost of an apple, the name of a poem, or your favorite colors, respectively. What if you want to represent something more complex? For example, you might want to track employees in an organization. You need to store some basic information about each employee, such as their name, age, position, and the year they started working. One way to do this is to represent each employee as a list: There are a number of issues with this approach. First, it can make larger code files more difficult to manage. If you reference several lines away from where you declared the list, will you remember that the element with index is the employee’s name? Second, it can introduce errors if employees don’t have the same number of elements in their respective lists. In the list above, the age is missing, so will return instead of Dr. McCoy’s age. A great way to make this type of code more manageable and more maintainable is to use classes. Classes allow you to create user-defined data structures. Classes define functions called methods, which identify the behaviors and actions that an object created from the class can perform with its data. In this tutorial, you’ll create a class that stores some information about the characteristics and behaviors that an individual dog can have. A class is a blueprint for how to define something. It doesn’t actually contain any data. The class specifies that a name and an age are necessary for defining a dog, but it doesn’t contain the name or age of any specific dog. While the class is the blueprint, an instance is an object that’s built from a class and contains real data. An instance of the class is not a blueprint anymore. It’s an actual dog with a name, like Miles, who’s four years old. Put another way, a class is like a form or questionnaire. An instance is like a form that you’ve filled out with information. Just like many people can fill out the same form with their own unique information, you can create many instances from a single class. You start all class definitions with the keyword, then add the name of the class and a colon. Python will consider any code that you indent below the class definition as part of the class’s body. Here’s an example of a class: The body of the class consists of a single statement: the keyword. Python programmers often use as a placeholder indicating where code will eventually go. It allows you to run this code without Python throwing an error. Note: Python class names are written in CapitalizedWords notation by convention. For example, a class for a specific breed of dog, like the Jack Russell Terrier, would be written as . The class isn’t very interesting right now, so you’ll spruce it up a bit by defining some properties that all objects should have. There are several properties that you can choose from, including name, age, coat color, and breed. To keep the example small in scope, you’ll just use name and age. You define the properties that all objects must have in a method called . Every time you create a new object, sets the initial state of the object by assigning the values of the object’s properties. That is, initializes each new instance of the class. You can give any number of parameters, but the first parameter will always be a variable called . When you create a new class instance, then Python automatically passes the instance to the parameter in so that Python can define the new attributes on the object. Update the class with an method that creates and attributes: Make sure that you indent the method’s signature by four spaces, and the body of the method by eight spaces. This indentation is vitally important. It tells Python that the method belongs to the class. In the body of , there are two statements using the variable:\n• creates an attribute called and assigns the value of the parameter to it.\n• creates an attribute called and assigns the value of the parameter to it. Attributes created in are called instance attributes. An instance attribute’s value is specific to a particular instance of the class. All objects have a name and an age, but the values for the and attributes will vary depending on the instance. On the other hand, class attributes are attributes that have the same value for all class instances. You can define a class attribute by assigning a value to a variable name outside of . For example, the following class has a class attribute called with the value : You define class attributes directly beneath the first line of the class name and indent them by four spaces. You always need to assign them an initial value. When you create an instance of the class, then Python automatically creates and assigns class attributes to their initial values. Use class attributes to define properties that should have the same value for every class instance. Use instance attributes for properties that vary from one instance to another. Now that you have a class, it’s time to create some dogs!\n\nHow Do You Instantiate a Class in Python? Creating a new object from a class is called instantiating a class. You can create a new object by typing the name of the class, followed by opening and closing parentheses: You first create a new class with no attributes or methods, and then you instantiate the class to create a object. In the output above, you can see that you now have a new object at . This funny-looking string of letters and numbers is a memory address that indicates where Python stores the object in your computer’s memory. Note that the address on your screen will be different. Now instantiate the class a second time to create another object: The new instance is located at a different memory address. That’s because it’s an entirely new instance and is completely unique from the first object that you created. To see this another way, type the following: In this code, you create two new objects and assign them to the variables and . When you compare and using the operator, the result is . Even though and are both instances of the class, they represent two distinct objects in memory. Now create a new class with a class attribute called and two instance attributes called and : To instantiate this class, you need to provide values for and . If you don’t, then Python raises a : To pass arguments to the and parameters, put values into the parentheses after the class name: This creates two new instances—one for a four-year-old dog named Miles and one for a nine-year-old dog named Buddy. The class’s method has three parameters, so why are you only passing two arguments to it in the example? When you instantiate the class, Python creates a new instance of and passes it to the first parameter of . This essentially removes the parameter, so you only need to worry about the and parameters. Note: Behind the scenes, Python both creates and initializes a new object when you use this syntax. If you want to dive deeper, then you can read the dedicated tutorial about the Python class constructor. After you create the instances, you can access their instance attributes using dot notation: You can access class attributes the same way: One of the biggest advantages of using classes to organize data is that instances are guaranteed to have the attributes you expect. All instances have , , and attributes, so you can use those attributes with confidence, knowing that they’ll always return a value. Although the attributes are guaranteed to exist, their values can change dynamically: In this example, you change the attribute of the object to . Then you change the attribute of the object to , which is a species of cat. That makes Miles a pretty strange dog, but it’s valid Python! The key takeaway here is that custom objects are mutable by default. An object is mutable if you can alter it dynamically. For example, lists and dictionaries are mutable, but strings and tuples are immutable. Instance methods are functions that you define inside a class and can only call on an instance of that class. Just like , an instance method always takes as its first parameter. Open a new editor window in IDLE and type in the following class: This class has two instance methods:\n• returns a string displaying the name and age of the dog.\n• has one parameter called and returns a string containing the dog’s name and the sound that the dog makes. Save the modified class to a file called and press to run the program. Then open the interactive window and type the following to see your instance methods in action: In the above class, returns a string containing information about the instance . When writing your own classes, it’s a good idea to have a method that returns a string containing useful information about an instance of the class. However, isn’t the most Pythonic way of doing this. When you create a object, you can use to display a string that looks like the list: Go ahead and print the object to see what output you get: When you print , you get a cryptic-looking message telling you that is a object at the memory address . This message isn’t very helpful. You can change what gets printed by defining a special instance method called . In the editor window, change the name of the class’s method to : Save the file and press . Now, when you print , you get a much friendlier output: Methods like and are called dunder methods because they begin and end with double underscores. There are many dunder methods that you can use to customize classes in Python. Understanding dunder methods is an important part of mastering object-oriented programming in Python, but for your first exploration of the topic, you’ll stick with these two dunder methods. Note: Check out When Should You Use vs in Python? to learn more about and its cousin . If you want to reinforce your understanding with a practical exercise, then you can click on the block below and work on solving the challenge:\n• , which stores the name of the car’s color as a string\n• , which stores the number of miles on the car as an integer Then create two objects—a blue car with twenty thousand miles and a red car with thirty thousand miles—and print out their colors and mileage. Your output should look like this: There are multiple ways to solve this challenge. To effectively practice what you’ve learned so far, try to solve the task with the information about classes in Python that you’ve gathered in this section. When you’re done with your own implementation of the challenge, then you can expand the block below to see a possible solution: First, create a class with and instance attributes, and a method to format the display of objects when you pass them to : The and parameters of are assigned to and , which creates the two instance attributes. The method interpolates both instance attributes into an f-string and uses the format specifier to print the mileage grouped by thousands and separated with a comma. Now you can create the two instances: You create the instance by passing the value to the parameter and to the parameter. Similarly, you create with the values and . To print the color and mileage of each object, you can loop over a containing both objects and print each object: Because you’ve defined their string representation in , printing the objects gives you the desired text output. When you’re ready, you can move on to the next section. There, you’ll see how to take your knowledge one step further and create classes from other classes.\n\nHow Do You Inherit From Another Class in Python? Inheritance is the process by which one class takes on the attributes and methods of another. Newly formed classes are called child classes, and the classes that you derive child classes from are called parent classes. You inherit from a parent class by creating a new class and putting the name of the parent class into parentheses: In this minimal example, the child class inherits from the parent class . Because child classes take on the attributes and methods of parent classes, is also without your explicitly defining that. Note: This tutorial is adapted from the chapter “Object-Oriented Programming (OOP)” in Python Basics: A Practical Introduction to Python 3. If you enjoy what you’re reading, then be sure to check out the rest of the book and the learning path. You can also check out the Python Basics: Building Systems With Classes video course to reinforce the skills that you’ll develop in this section of the tutorial. Child classes can override or extend the attributes and methods of parent classes. In other words, child classes inherit all of the parent’s attributes and methods but can also specify attributes and methods that are unique to themselves. Although the analogy isn’t perfect, you can think of object inheritance sort of like genetic inheritance. You may have inherited your hair color from your parents. It’s an attribute that you were born with. But maybe you decide to color your hair purple. Assuming that your parents don’t have purple hair, you’ve just overridden the hair color attribute that you inherited from your parents: If you change the code example like this, then will be . You also inherit, in a sense, your language from your parents. If your parents speak English, then you’ll also speak English. Now imagine you decide to learn a second language, like German. In this case, you’ve extended your attributes because you’ve added an attribute that your parents don’t have: You’ll learn more about how the code above works in the sections below. But before you dive deeper into inheritance in Python, you’ll take a walk to a dog park to better understand why you might want to use inheritance in your own code. Pretend for a moment that you’re at a dog park. There are many dogs of different breeds at the park, all engaging in various dog behaviors. Suppose now that you want to model the dog park with Python classes. The class that you wrote in the previous section can distinguish dogs by name and age but not by breed. You could modify the class in the editor window by adding a attribute: Press to save the file. Now you can model the dog park by creating a bunch of different dogs in the interactive window: Each breed of dog has slightly different behaviors. For example, bulldogs have a low bark that sounds like woof, but dachshunds have a higher-pitched bark that sounds more like yap. Using just the class, you must supply a string for the argument of every time you call it on a instance: Passing a string to every call to is repetitive and inconvenient. Moreover, the attribute should determine the string representing the sound that each instance makes, but here you have to manually pass the correct string to every time you call it. You can simplify the experience of working with the class by creating a child class for each breed of dog. This allows you to extend the functionality that each child class inherits, including specifying a default argument for . In this section, you’ll create a child class for each of the three breeds mentioned above: Jack Russell terrier, dachshund, and bulldog. For reference, here’s the full definition of the class that you’re currently working with: After doing the dog park example in the previous section, you’ve removed again. You’ll now write code to keep track of a dog’s breed using child classes instead. To create a child class, you create a new class with its own name and then put the name of the parent class in parentheses. Add the following to the file to create three new child classes of the class: Press to save and run the file. With the child classes defined, you can now create some dogs of specific breeds in the interactive window: Instances of child classes inherit all of the attributes and methods of the parent class: To determine which class a given object belongs to, you can use the built-in : What if you want to determine if is also an instance of the class? You can do this with the built-in : Notice that takes two arguments, an object and a class. In the example above, checks if is an instance of the class and returns . The , , , and objects are all instances, but isn’t a instance, and isn’t a instance: More generally, all objects created from a child class are instances of the parent class, although they may not be instances of other child classes. Now that you’ve created child classes for some different breeds of dogs, you can give each breed its own sound. Since different breeds of dogs have slightly different barks, you want to provide a default value for the argument of their respective methods. To do this, you need to override in the class definition for each breed. To override a method defined on the parent class, you define a method with the same name on the child class. Here’s what that looks like for the class: Now is defined on the class with the default argument for set to . Update with the new class and press to save and run the file. You can now call on a instance without passing an argument to : Sometimes dogs make different noises, so if Miles gets angry and growls, you can still call with a different sound: One thing to keep in mind about class inheritance is that changes to the parent class automatically propagate to child classes. This occurs as long as the attribute or method being changed isn’t overridden in the child class. For example, in the editor window, change the string returned by in the class: Save the file and press . Now, when you create a new instance named , returns the new string: However, calling on a instance won’t show the new style of output: Sometimes it makes sense to completely override a method from a parent class. But in this case, you don’t want the class to lose any changes that you might make to the formatting of the output string. To do this, you still need to define a method on the child class. But instead of explicitly defining the output string, you need to call the class’s from inside the child class’s using the same arguments that you passed to . You can access the parent class from inside a method of a child class by using : When you call inside , Python searches the parent class, , for a method and calls it with the variable . Update with the new class. Save the file and press so you can test it in the interactive window: Now when you call , you’ll see output reflecting the new formatting in the class. Note: In the above examples, the class hierarchy is very straightforward. The class has a single parent class, . In real-world examples, the class hierarchy can get quite complicated. The function does much more than just search the parent class for a method or an attribute. It traverses the entire class hierarchy for a matching method or attribute. If you aren’t careful, can have surprising results. If you want to check your understanding of the concepts that you learned about in this section with a practical exercise, then you can click on the block below and work on solving the challenge: Start with the following code for your parent class: Create a class that inherits from the class. Give the argument of a default value of . When you’re done with your own implementation of the challenge, then you can expand the block below to see a possible solution: Create a class called that inherits from the class and overrides the method: You give as the default value to the parameter in . Then you use to call the method of the parent class with the same argument passed to as the class’s method. Nice work! In this section, you’ve learned how to override and extend methods from a parent class, and you worked on a small practical example to cement your new skills."
    },
    {
        "link": "https://medium.com/swlh/the-4-pillars-of-oop-in-python-9daaca4c0d13",
        "document": "My beautiful blue house on a quaint pond has running water, electricity, and gas- but you do not need to know how each of these things works. Instead, you flip a light switch and the lights come on; You turn the stove on and a blue circle of flame gently rolls upward; You push the faucet handle up and a stream of clear water pours out. The house's walls and foundation abstract away the details of how these things work, and you as my guest enjoy them blissfully unaware of long lengths of wire, deeply buried pipes, and large water tanks that provide you with these amenities. Abstraction in Python is the process of hiding the real implementation of an application from the user and emphasizing only how to use the application. Let’s look at examples of abstract classes in Python:\n\n# We import ABC and abstractmethod from the abc module\n\nfrom abc import ABC, abstractmethod # We extend our ABC to three new child classes\n\nclass Electricity(Amenity ): def turn_on (self):\n\n print(\"You turned the knob on the stovefront!\")\n\n # Output\n\nYou pressed the faucet up!\n\nYou flipped the light switch!\n\nYou turned the knob on the stovefront!\n\nWhat is happening here?\n\nWe know amenities must have a way to be turned on, but we don’t care how it happens. By enforcing the standard that an amenity will have an on or off method and leaving the implementation up to the child class, we are abstracting away the details and just focusing on how to use the amenity: you can turn it on. We leave the implementation of it to each of our amenity child classes."
    },
    {
        "link": "https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter07.03-Inheritance-Encapsulation-and-Polymorphism.html",
        "document": "This notebook contains an excerpt from the Python Programming and Numerical Methods - A Guide for Engineers and Scientists, the content is also available at Berkeley Python Numerical Methods.\n\nThe copyright of the book belongs to Elsevier. We also have this interactive book online for a better learning experience. The code is released under the MIT license. If you find this content useful, please consider supporting the work on Elsevier or Amazon!\n\nWe have already seen the modeling power of OOP using the class and object functions by combining data and methods. There are three more important concept, inheritance, which makes the OOP code more modular, easier to reuse and build a relationship between classes. Encapsulation can hide some of the private details of a class from other objects, while polymorphism can allow us to use a common operation in different ways. In this section, we will briefly discuss them.\n\nInheritance allows us to define a class that inherits all the methods and attributes from another class. Convention denotes the new class as child class, and the one that it inherits from is called parent class or superclass. If we refer back to the definition of class structure, we can see the structure for basic inheritance is class ClassName(superclass), which means the new class can access all the attributes and methods from the superclass. Inheritance builds a relationship between the child class and parent class, usually in a way that the parent class is a general type while the child class is a specific type. Let us try to see an example. TRY IT! Define a class named with attributes , , and that pass from the creation of an object and an attribute as an empty dictionary to store data. Create one method add_data with and as input parameters to take in timestamp and data arrays. Within this method, assign and to the attribute with ‘time’ and ‘data’ as the keys. In addition, it should have one method to delete the data. Now we have a class to store general sensor information, we can create a sensor object to store some data. Say we have one different type of sensor: an accelerometer. It shares the same attributes and methods as class, but it also has different attributes or methods need to be appended or modified from the original class. What should we do? Do we create a different class from scratch? This is where inheritance can be used to make life easier. This new class will inherit from the class with all the attributes and methods. We can whether we want to extend the attributes or methods. Let us first create this new class, , and add a new method, , to report what kind of sensor it is. I am an accelerometer! We have 10 points saved Creating this new class is very simple. We inherit from (denoted as a superclass), and the new class actually contains all the attributes and methods from the superclass. We then add a new method, , which does not exist in the class, but we can successfully extend the child class by adding the new method. This shows the power of inheritance: we have reused most part of the class in a new class, and extended the functionality. Besides, the inheritance sets up a logical relationship for the modeling of the real-world entities : the class as the parent class is more general and passes all the characteristics to the child class . When we inherit from a parent class, we can change the implementation of a method provided by the parent class, this is called method overriding. Let us see the following example. EXAMPLE: Create a class (a specific type of accelerometer that created at UC Berkeley) that inherits from but replace the method that prints out the name of the sensor. We see that, our new class actually overrides the method with new features. In this example, we are not only inheriting features from our parent class, but we are also modifying/improving some methods.\n\nEncapsulation is one of the fundamental concepts in OOP. It describes the idea of restricting access to methods and attributes in a class. This will hide the complex details from the users, and prevent data being modified by accident. In Python, this is achieved by using private methods or attributes using underscore as prefix, i.e. single “_” or double “__”. Let us see the following example. Traceback (most recent call last) : 'Sensor' object has no attribute '__version' The above example shows how the encapsulation works. With single underscore, we defined a private variable, and it should not be accessed directly. But this is just convention, nothing stops you from doing that. You can still get access to it if you want to. With double underscore, we can see that the attribute can not be accessed or modify it directly. Therefore, to get access to the double underscore attributes, we need to use getter and setter function to access it internally, as shown in the following example. The single and double underscore also apply to private methods as well, we will not discuss these as they are similar to the private attributes.\n\nPolymorphism is another fundamental concept in OOP, which means multiple forms. Polymorphism allows us to use a single interface with different underlying forms such as data types or classes. For example, we can have commonly named methods across classes or child classes. We have already seen one example above, when we override the method in the . For parent class and child class , they both have a method named , but they have different implementation. This ability of using single name with many forms acting differently in different situations greatly reduces our complexities. We will not expand to discuss more of Polymorphism, if you are interested, check more online to get a deeper understanding."
    },
    {
        "link": "https://geeksforgeeks.org/understanding-encapsulation-inheritance-polymorphism-abstraction-in-oops",
        "document": "As the name suggests, Object-Oriented Programming or OOPs refers to languages that use objects in programming. Object-oriented programming aims to implement real-world entities like inheritance, hiding, polymorphism etc in programming. The main aim of OOP is to bind together the data and the functions that operate on them so that no other part of the code can access this data except that function. In this article, we will understand all the concepts of OOP’s along with an example.\n\nLet’s assume that we have a bird class and we are creating a list of birds. Let’s understand the OOP’s concepts used in this bird creation.\n\nFor any bird, there are a set of predefined properties which are common for all the birds and there are a set of properties which are specific for a particular bird. Therefore, intuitively, we can say that all the birds inherit the common features like wings, legs, eyes, etc. Therefore, in the object-oriented way of representing the birds, we first declare a bird class with a set of properties which are common to all the birds. By doing this, we can avoid declaring these common properties in every bird which we create. Instead, we can simply inherit the bird class in all the birds which we create. The following is an example of how the concept of inheritance is implemented.\n\nAfter the bird class is implemented, if we wish to create a pigeon, then we simply inherit the above Bird class.\n\nNow, we have defined the properties of the bird class and the attributes which the birds have like colour, wings, legs can be initialized by creating an object of the bird class. However, if we simply are able to change the properties of the bird class just by the reference of the object, then the attributes lose the information by which it was initially initialized.\n\nFor example, let’s say we have initially created a pigeon with a grey colour by creating a constructor, any user with the instance of the object of the pigeon can change this colour to red or black by simply referring the attribute with “this” keyword. Therefore, in order to avoid this, we enclose the properties in the methods. These methods are called the getters and setters of the attributes. The idea is to simply enclose the initialization and retrieval of the attributes in a method instead of directly referring the attribute directly. This also gives an advantage because the setters give us complete control in setting the value to the attribute and help us to restrict the unnecessary changes. For example, if a pigeon is created(born) with a grey colour, it doesn’t change until the pigeon dies. So, a user who is using simply shouldn’t be able to change the colour as per his wish. The following is the implementation of the getters and setters for the above Bird class.\n\nThe word polymorphism is made of two words poly and morph, where poly means many and morphs means forms. In programming, polymorphism is a feature that allows one interface to be used for a general class of actions. In the above concept of a bird and pigeon, a pigeon is inherently a bird. And also, if the birds are further categorized into multiple categories like flying birds, flightless birds, etc. the pigeon also fits into the flying bird’s category. And also, if the animal class is further categorized into plant-eating animals and meat-eating animals, the pigeon again comes into the plant-eating animal’s category. Therefore, the idea of polymorphism is the ability of the same object to take multiple forms. There are two types of polymorphism:\n• Compile Time Polymorphism: It is also known as static polymorphism. This type of polymorphism is achieved by function overloading or operator overloading. It occurs when we define multiple methods with different signatures and the compiler knows which method needs to be executed based on the method signatures.\n• Run Time Polymorphism: It is also known as Dynamic Method Dispatch. It is a process in which a function call to the overridden method is resolved at Runtime. This type of polymorphism is achieved by Method Overriding. When the same method with the same parameters is overridden with different contexts, the compiler doesn’t have any idea that the method is overridden. It simply checks if the method exists and during the runtime, it executes the functions which have been overridden.\n\nIn java, we can also upcast and downcast the objects. The core idea behind this concept is also polymorphism. The idea is that the object of the bird can have the value of the pigeon because it inheriting the features of the bird. Therefore, a parent object can also be initialized with the child properties if both the objects extend each other in the following way:\n\nAbstraction in general means hiding. In the above scenario of the bird and pigeon, let’s say there is a user who wants to see pigeon fly. The user is simply interested in seeing the pigeon fly but not interested in how the bird is actually flying. Therefore, in the above scenario where the user wishes to make it fly, he will simply call the fly method by using pigeon.fly() where the pigeon is the object of the bird pigeon. Therefore, abstraction means the art of representing the essential features without concerning about the background details. In Java, the abstraction is implemented through the use of interface and abstract classes. We can achieve complete abstraction with the use of Interface whereas a partial or a complete abstraction can be achieved with the use of abstract classes. The reason why abstraction is considered as one of the important concepts is:\n• None It reduces the complexity of viewing things.\n• None Helps to increase security of an application or program as only important details are provided to the user."
    },
    {
        "link": "https://docs.python.org/3/tutorial/controlflow.html",
        "document": ""
    },
    {
        "link": "https://docs.python.org/3/library/functions.html",
        "document": "The Python interpreter has a number of functions and types built into it that are always available. They are listed here in alphabetical order.\n\nOpen file and return a corresponding file object. If the file cannot be opened, an is raised. See Reading and Writing Files for more examples of how to use this function. file is a path-like object giving the pathname (absolute or relative to the current working directory) of the file to be opened or an integer file descriptor of the file to be wrapped. (If a file descriptor is given, it is closed when the returned I/O object is closed unless closefd is set to .) mode is an optional string that specifies the mode in which the file is opened. It defaults to which means open for reading in text mode. Other common values are for writing (truncating the file if it already exists), for exclusive creation, and for appending (which on some Unix systems, means that all writes append to the end of the file regardless of the current seek position). In text mode, if encoding is not specified the encoding used is platform-dependent: is called to get the current locale encoding. (For reading and writing raw bytes use binary mode and leave encoding unspecified.) The available modes are: open for writing, truncating the file first open for exclusive creation, failing if the file already exists open for writing, appending to the end of file if it exists The default mode is (open for reading text, a synonym of ). Modes and open and truncate the file. Modes and open the file with no truncation. As mentioned in the Overview, Python distinguishes between binary and text I/O. Files opened in binary mode (including in the mode argument) return contents as objects without any decoding. In text mode (the default, or when is included in the mode argument), the contents of the file are returned as , the bytes having been first decoded using a platform-dependent encoding or using the specified encoding if given. Python doesn’t depend on the underlying operating system’s notion of text files; all the processing is done by Python itself, and is therefore platform-independent. buffering is an optional integer used to set the buffering policy. Pass 0 to switch buffering off (only allowed in binary mode), 1 to select line buffering (only usable when writing in text mode), and an integer > 1 to indicate the size in bytes of a fixed-size chunk buffer. Note that specifying a buffer size this way applies for binary buffered I/O, but (i.e., files opened with ) would have another buffering. To disable buffering in , consider using the flag for . When no buffering argument is given, the default buffering policy works as follows:\n• None Binary files are buffered in fixed-size chunks; the size of the buffer is chosen using a heuristic trying to determine the underlying device’s “block size” and falling back on . On many systems, the buffer will typically be 4096 or 8192 bytes long.\n• None “Interactive” text files (files for which returns ) use line buffering. Other text files use the policy described above for binary files. encoding is the name of the encoding used to decode or encode the file. This should only be used in text mode. The default encoding is platform dependent (whatever returns), but any text encoding supported by Python can be used. See the module for the list of supported encodings. errors is an optional string that specifies how encoding and decoding errors are to be handled—this cannot be used in binary mode. A variety of standard error handlers are available (listed under Error Handlers), though any error handling name that has been registered with is also valid. The standard names include:\n• None to raise a exception if there is an encoding error. The default value of has the same effect.\n• None ignores errors. Note that ignoring encoding errors can lead to data loss.\n• None causes a replacement marker (such as ) to be inserted where there is malformed data.\n• None will represent any incorrect bytes as low surrogate code units ranging from U+DC80 to U+DCFF. These surrogate code units will then be turned back into the same bytes when the error handler is used when writing data. This is useful for processing files in an unknown encoding.\n• None is only supported when writing to a file. Characters not supported by the encoding are replaced with the appropriate XML character reference .\n• None (also only supported when writing) replaces unsupported characters with escape sequences. newline determines how to parse newline characters from the stream. It can be , , , , and . It works as follows:\n• None When reading input from the stream, if newline is , universal newlines mode is enabled. Lines in the input can end in , , or , and these are translated into before being returned to the caller. If it is , universal newlines mode is enabled, but line endings are returned to the caller untranslated. If it has any of the other legal values, input lines are only terminated by the given string, and the line ending is returned to the caller untranslated.\n• None When writing output to the stream, if newline is , any characters written are translated to the system default line separator, . If newline is or , no translation takes place. If newline is any of the other legal values, any characters written are translated to the given string. If closefd is and a file descriptor rather than a filename was given, the underlying file descriptor will be kept open when the file is closed. If a filename is given closefd must be (the default); otherwise, an error will be raised. A custom opener can be used by passing a callable as opener. The underlying file descriptor for the file object is then obtained by calling opener with (file, flags). opener must return an open file descriptor (passing as opener results in functionality similar to passing ). The following example uses the dir_fd parameter of the function to open a file relative to a given directory: 'This will be written to somedir/spamspam.txt' The type of file object returned by the function depends on the mode. When is used to open a file in a text mode ( , , , , etc.), it returns a subclass of (specifically ). When used to open a file in a binary mode with buffering, the returned class is a subclass of . The exact class varies: in read binary mode, it returns an ; in write binary and append binary modes, it returns an , and in read/write mode, it returns an . When buffering is disabled, the raw stream, a subclass of , , is returned. See also the file handling modules, such as , (where is declared), , , , and . The and arguments may have been modified or inferred from the original call.\n• None used to be raised, it is now an alias of .\n• None is now raised if the file opened in exclusive creation mode ( ) already exists.\n• None The file is now non-inheritable.\n• None If the system call is interrupted and the signal handler does not raise an exception, the function now retries the system call instead of raising an exception (see PEP 475 for the rationale).\n• None On Windows, opening a console buffer may return a subclass of other than . Changed in version 3.11: The mode has been removed.\n\nReturn a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing inherited methods that have been overridden in a class. The object_or_type determines the method resolution order to be searched. The search starts from the class right after the type. For example, if of object_or_type is and the value of type is , then searches . The attribute of the class corresponding to object_or_type lists the method resolution search order used by both and . The attribute is dynamic and can change whenever the inheritance hierarchy is updated. If the second argument is omitted, the super object returned is unbound. If the second argument is an object, must be true. If the second argument is a type, must be true (this is useful for classmethods). When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument ”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately enclosing function (typically ). (This means that zero-argument will not work as expected within nested functions, including generator expressions, which implicitly create nested functions.) There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer to parent classes without naming them explicitly, thus making the code more maintainable. This use closely parallels the use of super in other programming languages. The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This use case is unique to Python and is not found in statically compiled languages or languages that only support single inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes implement the same method. Good design dictates that such implementations have the same calling signature in every case (because the order of calls is determined at runtime, because that order adapts to changes in the class hierarchy, and because that order can include sibling classes that are unknown prior to runtime). For both use cases, a typical superclass call looks like this: # This does the same thing as: In addition to method lookups, also works for attribute lookups. One possible use case for this is calling descriptors in a parent or sibling class. Note that is implemented as part of the binding process for explicit dotted attribute lookups such as . It does so by implementing its own method for searching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, is undefined for implicit lookups using statements or operators such as . Also note that, aside from the zero argument form, is not limited to use inside methods. The two argument form specifies the arguments exactly and makes the appropriate references. The zero argument form only works inside a class definition, as the compiler fills in the necessary details to correctly retrieve the class being defined, as well as accessing the current instance for ordinary methods. For practical suggestions on how to design cooperative classes using , see guide to using super()."
    },
    {
        "link": "https://docs.python.org/2/library/functions.html",
        "document": "The Python interpreter has a number of functions built into it that are always available. They are listed here in alphabetical order.\n\nIn addition, there are other four built-in functions that are no longer considered essential: , , , and . They are documented in the Non-essential Built-in Functions section."
    },
    {
        "link": "https://wiki.python.org/moin/ForLoop",
        "document": "There are two ways to create loops in Python: with the for-loop and the while-loop.\n\nWhen do I use for loops\n\nfor loops are used when you have a block of code which you want to repeat a fixed number of times. The for-loop is always used in combination with an iterable object, like a list or a range. The Python for statement iterates over the members of a sequence in order, executing the block each time. Contrast the for statement with the ''while'' loop, used when a condition needs to be checked each iteration or to repeat a block of code forever. For example:\n\nFor loop from 0 to 2, therefore running 3 times.\n\nWhile loop from 1 to infinity, therefore running forever.\n\nWhen running the above example, you can stop the program by pressing ctrl+c at the same time. As you can see, these loop constructs serve different purposes. The for loop runs for a fixed amount of times, while the while loop runs until the loop condition changes. In this example, the condition is the boolean True which will never change, so it will run forever.\n\nHow do they work?\n\nIf you've done any programming before, you have undoubtedly come across a for loop or an equivalent to it. Many languages have conditions in the syntax of their for loop, such as a relational expression to determine if the loop is done, and an increment expression to determine the next loop value. In Python, this is controlled instead by generating the appropriate sequence. Basically, any object with an iterable method can be used in a for loop. Even strings, despite not having an iterable method - but we'll not get on to that here. Having an iterable method basically means that the data can be presented in list form, where there are multiple values in an orderly fashion. You can define your own iterables by creating an object with next() and iter() methods. This means that you'll rarely be dealing with raw numbers when it comes to for loops in Python - great for just about anyone!\n\nWhen you have a block of code you want to run x number of times, then a block of code within that code which you want to run y number of times, you use what is known as a \"nested loop\". In Python, these are heavily used whenever someone has a list of lists - an iterable object within an iterable object.\n\nLike the while loop, the for loop can be made to exit before the given object is finished. This is done using the break statement, which will immediately drop out of the loop and continue execution at the first statement after the block. You can also have an optional else clause, which will run should the for loop exit cleanly - that is, without breaking.\n\nYour own range generator using yield\n\nThe ''range'' function is seen so often in for statements that you might think range is part of the for syntax. It is not: it is a Python built-in function that returns a sequence following a specific pattern (most often sequential integers), which thus meets the requirement of providing a sequence for the for statement to iterate over. Since for can operate directly on sequences, there is often no need to count. This is a common beginner construct (if they are coming from another language with different loop syntax):\n\nIt can be replaced with this:\n\nConsider to be a flag for possibly non-optimal Python coding.\n\nIf you'd like to learn more, try these links:\n• None Python for loop and while loop tutorial with interactive code examples"
    },
    {
        "link": "https://python101.pythonlibrary.org/chapter5_loops.html",
        "document": "Every programming language I have tried has some kind of looping construct. Most have more than one. The Python world has two types of loops:\n\nYou will find that the for loop is by far the most popular of the two. Loops are used when you want to do something many times. Usually you will find that you need to do some operation or a set of operations on a piece of data over and over. This is where loops come in. They make it really easy to apply this sort of logic to your data.\n\nLet’s get started learning how these fun structures work!\n\nAs mentioned above, you use a loop when you want to iterate over something n number of times. It’s a little easier to understand if we see an example. Let’s use Python’s builtin range function. The range function will create a list that is n in length. In Python 2.x, there is actually another function called xrange that is a number generator and isn’t as resource intensive as range. They basically changed xrange into range in Python 3. Here is an example: As you can see, the range function above took an integer and returned a range object. The range function also accepts a beginning value, an end value and a step value. Here are two more examples: The first example demonstrates that you can pass a beginning and end value and the range function will return the numbers from the beginning value up to but not including the end value. So in the case of 5-10, we get 5-9. The second example shows how to use the list function to cause the range function to return every second element between 1 and 10. So it starts with one, skips two, etc. Now you’re probably wondering what this has to do with loops. Well one easy way to show how a loop works is if we use the range function! Take a look: What happened here? Let’s read it from left to right to figure it out. For each number in a range of 5, print the number. We know that if we call range with a value of 5, it will return a list of 5 elements. So each time through the loop, it prints out each of the elements. The for loop above would be the equivalent of the following: The range function just makes it a little bit smaller. The for loop can loop over any kind of Python iterator. We’ve already seen how it can iterate over a list. Let’s see if it can also iterate over a dictionary. When you use a for loop with a dictionary, you’ll see that it automatically loops over the keys. We didn’t have to say for key in a_dict.keys() (although that would have worked too). Python just did the right thing for us. You may be wondering why the keys printed in a different order than they were defined in the dictionary. As you may recall from chapter 3, dictionaries are unordered, so when we iterate over it, the keys could be in any order. Now if you know that the keys can be sorted, then you can do that before you iterate over them. Let’s change the dictionary slightly to see how that works. Let’s take a moment to figure out what this code does. First off, we create a dictionary that has integers for keys instead of strings. Then we extract the keys from the dictionary. Whenever you call the keys() method, it will return an unordered list of the keys. If you print them out and find them to be in ascending order, then that’s just happenstance. Now we have a view of the dictionary’s keys that are stored in a variable called keys. We sort it and then we use the for loop to loop over it. Now we’re ready to make things a little bit more interesting. We are going to loop over a range, but we want to print out only the even numbers. To do this, we want to use a conditional statement instead of using the range’s step parameter. Here’s one way you could do this: You’re probably wondering what’s going on here. What’s up with the percent sign? In Python, the % is called a modulus operator. When you use the modulus operator, it will return the remainder. There is no remainder when you divide an even number by two, so we print those numbers out. You probably won’t use the modulus operator a lot in the wild, but I have found it useful from time to time. Now we’re ready to learn about the while loop.\n\nThe while loop is also used to repeat sections of code, but instead of looping n number of times, it will only loop until a specific condition is met. Let’s look at a very simple example: The while loop is kind of like a conditional statement. Here’s what this code means: while the variable i is less than ten, print it out. Then at the end, we increase i’s value by one. If you run this code, it should print out 0-9, each on its own line and then stop. If you remove the piece where we increment i’s value, then you’ll end up with an infinite loop. This is usually a bad thing. Infinite loops are to be avoided and are known as logic errors. There is another way to break out of a loop. It is by using the break builtin. Let’s see how that works: In this piece of code, we add a conditional to check if the variable i ever equals 5. If it does, then we break out of the loop. As you can see from the sample output, as soon as it reaches 5, the code stops even though we told the while loop to keep looping until it reached 10. You will also note that we changed how we increment the value by using +=. This is a handy shortcut that you can also use with other math operations, like subtraction (-=) and multiplication (*=). The break builtin is known as a flow control tool. There is another one called continue that is used to basically skip an iteration or continue with the next iteration. Here’s one way to use it: This is a little confusing, no? Basically we added a second conditional that checks if i equals 3. If it does, we increment the variable and continue with the next loop, which effectively skips printing the value 3 to the screen. As before, when we reach a value of 5, we break out of the loop. There’s one more topic we need to cover regarding loops and that’s the else statement.\n\nWhat else is for in loops¶ The else statement in loops only executes if the loop completes successfully. The primary use of the else statement is for searching for items: In this code, we break out of the loop when i equals 3. This causes the else statement to be skipped. If you want to experiment, you can change the conditional to look for a value that’s not in the list, which will cause the else statement to execute. To be honest, I have never seen anyone use this structure in all my years as a programmer. Most of the examples I have seen are bloggers trying to explain what it is used for. I have seen several who use it to raise an error if an item is not found in the iterable that you were searching. You can read a fairly in depth article by one of the Python core developers here.\n\nHopefully at this point you can see the value in Python loops. They make repetition easier and pretty easy to understand. You will likely see the for loop much more often than the while loop. In fact, we are going to look at another way for loops are used in the next chapter when we learn about comprehensions! If you’re still not quite sure how all this works, you may want to re-read this chapter before continuing."
    }
]