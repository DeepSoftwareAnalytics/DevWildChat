[
    {
        "link": "https://numpy.org/doc/2.1/reference/random/generator.html",
        "document": "The provides access to a wide range of distributions, and served as a replacement for . The main difference between the two is that relies on an additional BitGenerator to manage state and generate the random bits, which are then transformed into random values from useful distributions. The default BitGenerator used by is . The BitGenerator can be changed by passing an instantized BitGenerator to .\n\nConstruct a new Generator with the default BitGenerator (PCG64). A seed to initialize the . If None, then fresh, unpredictable entropy will be pulled from the OS. If an or is passed, then all values must be non-negative and will be passed to to derive the initial state. One may also pass in a instance. Additionally, when passed a , it will be wrapped by . If passed a , it will be returned unaltered. If is not a or a , a new is instantiated. This function does not manage a default global instance. See Seeding and entropy for more information about seeding. is the recommended constructor for the random number class . Here are several ways we can construct a random number generator using and the class. Here we use to generate a random float: Here we use to generate 3 random integers between 0 (inclusive) and 10 (exclusive): Here we specify a seed so that we have reproducible results: If we exit and restart our Python interpreter, we’ll see that we generate the same random numbers again:\n\nexposes a number of methods for generating random numbers drawn from a variety of probability distributions. In addition to the distribution-specific arguments, each method takes a keyword argument size that defaults to . If size is , then a single value is generated and returned. If size is an integer, then a 1-D array filled with generated values is returned. If size is a tuple, then an array with that shape is filled and returned. The function will instantiate a with numpy’s default . does not provide a version compatibility guarantee. In particular, as better algorithms evolve the bit stream may change. BitGenerator to use as the core generator. The Python stdlib module contains pseudo-random number generator with a number of methods that are similar to the ones available in . It uses Mersenne Twister, and this bit generator can be accessed using . , besides being NumPy-aware, has the advantage that it provides a much larger number of probability distributions to choose from.\n\nThe methods for randomly permuting a sequence are Modify an array or sequence in-place by shuffling its contents. The following table summarizes the behaviors of the methods. either (use ‘out’ for in-place) The following subsections provide more details about the differences. The main difference between and is that operates in-place, while returns a copy. By default, returns a copy. To operate in-place with , pass the same array as the first argument and as the value of the parameter. For example, Note that when is given, the return value is : An important distinction for these methods is how they handle the parameter. Both and treat the input as a one-dimensional sequence, and the parameter determines which dimension of the input array to use as the sequence. In the case of a two-dimensional array, will, in effect, rearrange the rows of the array, and will rearrange the columns. For example Note that the columns have been rearranged “in bulk”: the values within each column have not changed. The method treats the parameter similar to how treats it. Each slice along the given axis is shuffled independently of the others. Compare the following example of the use of to the above example of : In this example, the values within each row (i.e. the values along ) have been shuffled independently. This is not a “bulk” shuffle of the columns. works on non-NumPy sequences. That is, if it is given a sequence that is not a NumPy array, it shuffles that sequence in-place."
    },
    {
        "link": "https://numpy.org/doc/1.24/reference/random/index.html",
        "document": "Numpy’s random number routines produce pseudo random numbers using combinations of a to create sequences and a to use those sequences to sample from different statistical distributions:\n• None BitGenerators: Objects that generate random numbers. These are typically unsigned integer words filled with sequences of either 32 or 64 random bits.\n• None Generators: Objects that transform sequences of random bits from a BitGenerator into sequences of numbers that follow a specific probability distribution (such as uniform, Normal or Binomial) within a specified interval.\n\nSince Numpy version 1.17.0 the Generator can be initialized with a number of different BitGenerators. It exposes many different probability distributions. See NEP 19 for context on the updated random Numpy number routines. The legacy random number routines are still available, but limited to a single BitGenerator. See What’s New or Different for a complete list of improvements and differences from the legacy .\n\nFor convenience and backward compatibility, a single instance’s methods are imported into the numpy.random namespace, see Legacy Random Generation for the complete list.\n\nCall to get a new instance of a , then call its methods to obtain samples from different distributions. By default, uses bits provided by which has better statistical properties than the legacy used in . # instead of this (legacy version) can be used as a replacement for . Both class instances hold an internal instance to provide the bit stream, it is accessible as . Some long-overdue API cleanup means that legacy and compatibility methods have been removed from See What’s New or Different for more information. Something like the following code can be used to support both and , with the understanding that the interfaces are slightly different Seeds can be passed to any of the BitGenerators. The provided value is mixed via to spread a possible sequence of seeds across a wider range of initialization states for the BitGenerator. Here is used and is wrapped with a . Here we use to create an instance of to generate a random float: Here we use to create an instance of to generate 3 random integers between 0 (inclusive) and 10 (exclusive):"
    },
    {
        "link": "https://numpy.org/doc/2.1/reference/random/index.html",
        "document": "The module implements pseudo-random number generators (PRNGs or RNGs, for short) with the ability to draw samples from a variety of probability distributions. In general, users will create a instance with and call the various methods on it to obtain samples from different distributions.\n\nOur RNGs are deterministic sequences and can be reproduced by specifying a seed integer to derive its initial state. By default, with no seed provided, will seed the RNG from nondeterministic data from the operating system and therefore generate different numbers each time. The pseudo-random sequences will be independent for all practical purposes, at least those purposes for which our pseudo-randomness was good for in the first place.\n\nSeeds should be large positive integers. can take positive integers of any size. We recommend using very large, unique numbers to ensure that your seed is different from anyone else’s. This is good practice to ensure that your results are statistically independent from theirs unless you are intentionally trying to reproduce their result. A convenient way to get such a seed number is to use to get an arbitrary 128-bit integer.\n\nSee the documentation on and for more advanced options for controlling the seed in specialized scenarios.\n\nand its associated infrastructure was introduced in NumPy version 1.17.0. There is still a lot of code that uses the older and the functions in . While there are no plans to remove them at this time, we do recommend transitioning to as you can. The algorithms are faster, more flexible, and will receive more improvements in the future. For the most part, can be used as a replacement for . See Legacy random generation for information on the legacy infrastructure, What’s new or different for information on transitioning, and NEP 19 for some of the reasoning for the transition."
    },
    {
        "link": "https://numpy.org/doc/2.0/reference/random/index.html",
        "document": "The module implements pseudo-random number generators (PRNGs or RNGs, for short) with the ability to draw samples from a variety of probability distributions. In general, users will create a instance with and call the various methods on it to obtain samples from different distributions.\n\nOur RNGs are deterministic sequences and can be reproduced by specifying a seed integer to derive its initial state. By default, with no seed provided, will seed the RNG from nondeterministic data from the operating system and therefore generate different numbers each time. The pseudo-random sequences will be independent for all practical purposes, at least those purposes for which our pseudo-randomness was good for in the first place.\n\nSeeds should be large positive integers. can take positive integers of any size. We recommend using very large, unique numbers to ensure that your seed is different from anyone else’s. This is good practice to ensure that your results are statistically independent from theirs unless you are intentionally trying to reproduce their result. A convenient way to get such a seed number is to use to get an arbitrary 128-bit integer.\n\nSee the documentation on and for more advanced options for controlling the seed in specialized scenarios.\n\nand its associated infrastructure was introduced in NumPy version 1.17.0. There is still a lot of code that uses the older and the functions in . While there are no plans to remove them at this time, we do recommend transitioning to as you can. The algorithms are faster, more flexible, and will receive more improvements in the future. For the most part, can be used as a replacement for . See Legacy random generation for information on the legacy infrastructure, What’s new or different for information on transitioning, and NEP 19 for some of the reasoning for the transition."
    },
    {
        "link": "https://blog.scientific-python.org/numpy/numpy-rng",
        "document": "Given the practical challenges of achieving true randomness, deterministic algorithms, known as Pseudo Random Number Generators (RNGs), are employed in science to create sequences that mimic randomness. These generators are used for simulations, experiments, and analysis where it is essential to have numbers that appear unpredictable. I want to share here what I have learned about best practices with pseudo RNGs and especially the ones available in NumPy.\n\nA pseudo RNG works by updating an internal state through a deterministic algorithm. This internal state is initialized with a value known as a seed and each update produces a number that appears randomly generated. The key here is that the process is deterministic, meaning that if you start with the same seed and apply the same algorithm, you will get the same sequence of internal states (and numbers). Despite this determinism, the resulting numbers exhibit properties of randomness, appearing unpredictable and evenly distributed. Users can either specify the seed manually, providing a degree of control over the generated sequence, or they can opt to let the RNG object automatically derive the seed from system entropy. The latter approach enhances unpredictability by incorporating external factors into the seed.\n\nI assume a certain knowledge of NumPy and that NumPy 1.17 or greater is used. The reason for this is that great new features were introduced in the random module of version 1.17. As is usually imported as , I will sometimes use instead of . Finally, RNG will always mean pseudo RNG in the rest of this blog post.\n• Avoid using the global NumPy RNG. This means that you should avoid using and functions, such as , to generate random values.\n• Create a new RNG and pass it around using the function.\n• Be careful with parallel random number generation and use the strategies provided by NumPy.\n\nNote that, with older versions of NumPy (<1.17), the way to create a new RNG is to use which is based on the popular Mersenne Twister 19937 algorithm. This is also how the global NumPy RNG is created. This function is still available in newer versions of NumPy, but it is now recommended to use instead, which returns an instance of the statistically better PCG64 RNG. You might still see being used in tests as it has strong stability guarantees between different NumPy versions.\n\nWhen you import in your Python script, an RNG is created behind the scenes. This RNG is the one used when you generate a new random value using a function such as . I will here refer to this RNG as the global NumPy RNG.\n\nAlthough not recommended, it is a common practice to reset the seed of this global RNG at the beginning of a script using the function. Fixing the seed at the beginning ensures that the script is reproducible: the same values and results will be produced each time you run it. However, although sometimes convenient, using the global NumPy RNG is a bad practice. A simple reason is that using global variables can lead to undesired side effects. For instance one might use without knowing that the seed of the global RNG was set somewhere else in the codebase. Quoting Numpy Enhancement Proposal (NEP) 19 by Robert Kern:\n• Instead of using , which reseeds the already created global NumPy RNG, and then using functions, you should create a new RNG.\n• You should create an RNG at the beginning of your script (with your own seed if you want reproducibility) and use this RNG in the rest of the script.\n\nTo create a new RNG you can use the function as illustrated in the introduction of the random module documentation:\n\nIf you want to use a seed for reproducibility, the NumPy documentation recommends using a large random number, where large means at least 128 bits. The first reason for using a large random number is that this increases the probability of having a different seed than anyone else and thus independent results. The second reason is that relying only on small numbers for your seeds can lead to biases as they do not fully explore the state space of the RNG. This limitation implies that the first number generated by your RNG may not seem as random as expected due to inaccessible first internal states. For example, some numbers will never be produced as the first output. One possibility would be to pick the seed at random in the state space of the RNG but according to Robert Kern a 128-bit random number is large enough. To generate a 128-bit random number for your seed you can rely on the secrets module:\n\nWhen running this code I get for the number to use as my seed. This number is randomly generated so you need to copy paste the value that is returned by otherwise you will have a different seed each time you run your code and thus break reproducibility:\n\nThe reason for seeding your RNG only once (and passing that RNG around) is that with a good RNG such as the one returned by you will be ensured good randomness and independence of the generated numbers. However, if not done properly, using several RNGs (each one created with its own seed) might lead to streams of random numbers that are less independent than the ones created from the same seed. That being said, as explained by Robert Kern, with the RNGs and seeding strategies introduced in NumPy 1.17, it is considered fairly safe to create RNGs using system entropy, i.e. using multiple times. However as explained later be careful when running jobs in parallel and relying on . Another reason for seeding your RNG only once is that obtaining a good seed can be time consuming. Once you have a good seed to instantiate your generator, you might as well use it.\n\nAs you write functions that you will use on their own as well as in a more complex script it is convenient to be able to pass a seed or your already created RNG. The function allows you to do this very easily. As written above, this function can be used to create a new RNG from your chosen seed, if you pass a seed to it, or from system entropy when passing but you can also pass an already created RNG. In this case the returned RNG is the one that you passed.\n\nYou can either pass an seed or your already created RNG to . To be perfectly exact, the function returns the exact same RNG passed to it for certain kind of RNGs such at the ones created with itself. You can refer to the documentation for more details on the arguments that you can pass to this function.\n\nYou must be careful when using RNGs in conjunction with parallel processing. Let’s consider the context of Monte Carlo simulation: you have a random function returning random outputs and you want to generate these random outputs a lot of times, for instance to compute an empirical mean. If the function is expensive to compute, an easy solution to speed up the computation time is to resort to parallel processing. Depending on the parallel processing library or backend that you use different behaviors can be observed. For instance if you do not set the seed yourself it can be the case that forked Python processes use the same random seed, generated for instance from system entropy, and thus produce the exact same outputs which is a waste of computational resources. A very nice example illustrating this when using the Joblib parallel processing library is available here.\n\nIf you fix the seed at the beginning of your main script for reproducibility and then pass your seeded RNG to each process to be run in parallel, most of the time this will not give you what you want as this RNG will be deep copied. The same results will thus be produced by each process. One of the solutions is to create as many RNGs as parallel processes with a different seed for each of these RNGs. The issue now is that you cannot choose the seeds as easily as you would think. When you choose two different seeds to instantiate two different RNGs how do you know that the numbers produced by these RNGs will appear as statistically independent? The design of independent RNGs for parallel processes has been an important research question. See, for example, Random numbers for parallel computers: Requirements and methods, with emphasis on GPUs by L’Ecuyer et al. (2017) for a good summary of different methods.\n\nStarting with NumPy 1.17, it is now very easy to instantiate independent RNGs. Depending on the type of RNG you use, different strategies are available as documented in the Parallel random number generation section of the NumPy documentation. One of the strategies is to use which is an algorithm that makes sure that poor input seeds are transformed into good initial RNG states. More precisely, this ensures that you will not have a degenerate behavior from your RNG and that the subsequent numbers will appear random and independent. Additionally, it ensures that close seeds are mapped to very different initial states, resulting in RNGs that are, with very high probability, independent of each other. You can refer to the documentation of SeedSequence Spawning for examples on how to generate independent RNGs from a or an existing RNG. I here show how to apply this to the joblib example mentioned above.\n\nBy using a fixed seed you always get the same results each time you run this code and by using you have an independent RNG for each call to . Note that here you could also spawn from a that you would create with the seed instead of creating an RNG. However, in general you pass around an RNG therefore I only assume to have access to an RNG. Also note that spawning from an RNG is only possible from version 1.25 of NumPy.\n\nI hope this blog post helped you understand the best ways to use NumPy RNGs. The new Numpy API gives you all the tools you need for that. The resources below are available for further reading. Finally, I would like to thank Pamphile Roy, Stefan van der Walt and Jarrod Millman for their great feedbacks and comments which contributed to greatly improve the original version of this blog post.\n• The documentation of the NumPy random module is the best place to find information and where I found most of the information that I share here.\n• The Numpy Enhancement Proposal (NEP) 19 on the Random Number Generator Policy which lead to the changes introduced in NumPy 1.17\n• A NumPy issue about the function and RNG good practices, especially this comment by Robert Kern.\n• Check also this answer of Robert Kern to my question about what can and cannot do. This also explains why it is recommended to use very large random numbers for seeds.\n• How do I set a random_state for an entire execution? from the scikit-learn FAQ.\n• There are ongoing discussions about uniformizing the APIs used by different libraries to seed RNGs.\n• Random numbers for parallel computers: Requirements and methods, with emphasis on GPUs by L’Ecuyer et al. (2017)\n• To know more about the default RNG used in NumPy, named PCG, I recommend the PCG paper which also contains lots of useful information about RNGs in general. The pcg-random.org website is also full of interesting information about RNGs."
    },
    {
        "link": "https://matplotlib.org/3.5.2/tutorials/introductory/images.html",
        "document": "This turns on inline plotting, where plot graphics will appear in your notebook. This has important implications for interactivity. For inline plotting, commands in cells below the cell that outputs a plot will not affect the plot. For example, changing the colormap is not possible from cells below the cell that creates a plot. However, for other backends, such as Qt, that open a separate window, cells below those that create the plot will change the plot - it is a live object in memory.\n\nThis tutorial will use Matplotlib's imperative-style plotting interface, pyplot. This interface maintains global state, and is very useful for quickly and easily experimenting with various plot settings. The alternative is the object-oriented interface, which is also very powerful, and generally more suitable for large application development. If you'd like to learn about the object-oriented interface, a great place to start is our Usage guide. For now, let's get on with the imperative-style approach:"
    },
    {
        "link": "https://oreilly.com/library/view/python-data-science/9781491912126/ch04.html",
        "document": "We’ll now take an in-depth look at the Matplotlib tool for visualization in Python. Matplotlib is a multiplatform data visualization library built on NumPy arrays, and designed to work with the broader SciPy stack. It was conceived by John Hunter in 2002, originally as a patch to IPython for enabling interactive MATLAB-style plotting via gnuplot from the IPython command line. IPython’s creator, Fernando Perez, was at the time scrambling to finish his PhD, and let John know he wouldn’t have time to review the patch for several months. John took this as a cue to set out on his own, and the Matplotlib package was born, with version 0.1 released in 2003. It received an early boost when it was adopted as the plotting package of choice of the Space Telescope Science Institute (the folks behind the Hubble Telescope), which financially supported Matplotlib’s development and greatly expanded its capabilities.\n\nOne of Matplotlib’s most important features is its ability to play well with many operating systems and graphics backends. Matplotlib supports dozens of backends and output types, which means you can count on it to work regardless of which operating system you are using or which output format you wish. This cross-platform, everything-to-everyone approach has been one of the great strengths of Matplotlib. It has led to a large userbase, which in turn has led to an active developer base and Matplotlib’s powerful tools and ubiquity within the scientific Python world.\n\nIn recent years, however, the interface and style of Matplotlib have begun to show their age. Newer tools like ggplot and ggvis in the R language, along with web visualization toolkits based on D3js and HTML5 canvas, often make Matplotlib feel clunky and old-fashioned. Still, I’m of the opinion that we cannot ignore Matplotlib’s strength as a well-tested, cross-platform graphics engine. Recent Matplotlib versions make it relatively easy to set new global plotting styles (see “Customizing Matplotlib: Configurations and Stylesheets”), and people have been developing new packages that build on its powerful internals to drive Matplotlib via cleaner, more modern APIs—for example, Seaborn (discussed in “Visualization with Seaborn”), ggplot, HoloViews, Altair, and even Pandas itself can be used as wrappers around Matplotlib’s API. Even with wrappers like these, it is still often useful to dive into Matplotlib’s syntax to adjust the final plot output. For this reason, I believe that Matplotlib itself will remain a vital piece of the data visualization stack, even if new tools mean the community gradually moves away from using the Matplotlib API directly.\n\nPerhaps the simplest of all plots is the visualization of a single function . Here we will take a first look at creating a simple plot of this type. As with all the following sections, we’ll start by setting up the notebook for plotting and importing the functions we will use: For all Matplotlib plots, we start by creating a figure and an axes. In their simplest form, a figure and axes can be created as follows (Figure 4-5): In Matplotlib, the figure (an instance of the class ) can be thought of as a single container that contains all the objects representing axes, graphics, text, and labels. The axes (an instance of the class ) is what we see above: a bounding box with ticks and labels, which will eventually contain the plot elements that make up our visualization. Throughout this book, we’ll commonly use the variable name to refer to a figure instance, and to refer to an axes instance or group of axes instances. Once we have created an axes, we can use the function to plot some data. Let’s start with a simple sinusoid (Figure 4-6): Alternatively, we can use the pylab interface and let the figure and axes be created for us in the background (Figure 4-7; see “Two Interfaces for the Price of One” for a discussion of these two interfaces): If we want to create a single figure with multiple lines, we can simply call the function multiple times (Figure 4-8): That’s all there is to plotting simple functions in Matplotlib! We’ll now dive into some more details about how to control the appearance of the axes and lines. The first adjustment you might wish to make to a plot is to control the line colors and styles. The function takes additional arguments that can be used to specify these. To adjust the color, you can use the keyword, which accepts a string argument representing virtually any imaginable color. The color can be specified in a variety of ways (Figure 4-9): # specify color by name If no color is specified, Matplotlib will automatically cycle through a set of default colors for multiple lines. Similarly, you can adjust the line style using the keyword (Figure 4-10): # For short, you can use the following codes: Example of various line styles If you would like to be extremely terse, these and codes can be combined into a single nonkeyword argument to the function (Figure 4-11): Controlling colors and styles with the shorthand syntax These single-character color codes reflect the standard abbreviations in the RGB (Red/Green/Blue) and CMYK (Cyan/Magenta/Yellow/blacK) color systems, commonly used for digital color graphics. There are many other keyword arguments that can be used to fine-tune the appearance of the plot; for more details, I’d suggest viewing the docstring of the function using IPython’s help tools (see “Help and Documentation in IPython”). Matplotlib does a decent job of choosing default axes limits for your plot, but sometimes it’s nice to have finer control. The most basic way to adjust axis limits is to use the and methods (Figure 4-12): If for some reason you’d like either axis to be displayed in reverse, you can simply reverse the order of the arguments (Figure 4-13): Example of reversing the y-axis A useful related method is (note here the potential confusion between axes with an e, and axis with an i). The method allows you to set the and limits with a single call, by passing a list that specifies (Figure 4-14): The method goes even beyond this, allowing you to do things like automatically tighten the bounds around the current plot (Figure 4-15): It allows even higher-level specifications, such as ensuring an equal aspect ratio so that on your screen, one unit in is equal to one unit in (Figure 4-16): Example of an “equal” layout, with units matched to the output resolution For more information on axis limits and the other capabilities of the method, refer to the docstring. As the last piece of this section, we’ll briefly look at the labeling of plots: titles, axis labels, and simple legends. Titles and axis labels are the simplest such labels—there are methods that can be used to quickly set them (Figure 4-17): You can adjust the position, size, and style of these labels using optional arguments to the function. For more information, see the Matplotlib documentation and the docstrings of each of these functions. When multiple lines are being shown within a single axes, it can be useful to create a plot legend that labels each line type. Again, Matplotlib has a built-in way of quickly creating such a legend. It is done via the (you guessed it) method. Though there are several valid ways of using this, I find it easiest to specify the label of each line using the keyword of the plot function (Figure 4-18): As you can see, the function keeps track of the line style and color, and matches these with the correct label. More information on specifying and formatting plot legends can be found in the docstring; additionally, we will cover some more advanced legend options in “Customizing Plot Legends”. While most functions translate directly to methods (such as → , → , etc.), this is not the case for all commands. In particular, functions to set limits, labels, and titles are slightly modified. For transitioning between MATLAB-style functions and object-oriented methods, make the following changes: In the object-oriented interface to plotting, rather than calling these functions individually, it is often more convenient to use the method to set all these properties at once (Figure 4-19): Example of using ax.set to set multiple properties at once\n\nMatplotlib’s default tick locators and formatters are designed to be generally sufficient in many common situations, but are in no way optimal for every plot. This section will give several examples of adjusting the tick locations and formatting for the particular plot type you’re interested in. Before we go into examples, it will be best for us to understand further the object hierarchy of Matplotlib plots. Matplotlib aims to have a Python object representing everything that appears on the plot: for example, recall that the is the bounding box within which plot elements appear. Each Matplotlib object can also act as a container of sub-objects; for example, each can contain one or more objects, each of which in turn contain other objects representing plot contents. The tick marks are no exception. Each has attributes and , which in turn have attributes that contain all the properties of the lines, ticks, and labels that make up the axes. Within each axis, there is the concept of a major tick mark and a minor tick mark. As the names would imply, major ticks are usually bigger or more pronounced, while minor ticks are usually smaller. By default, Matplotlib rarely makes use of minor ticks, but one place you can see them is within logarithmic plots (Figure 4-73): Example of logarithmic scales and labels We see here that each major tick shows a large tick mark and a label, while each minor tick shows a smaller tick mark with no label. We can customize these tick properties—that is, locations and labels—by setting the and objects of each axis. Let’s examine these for the x axis of the plot just shown: We see that both major and minor tick labels have their locations specified by a (which makes sense for a logarithmic plot). Minor ticks, though, have their labels formatted by a ; this says that no labels will be shown. We’ll now show a few examples of setting these locators and formatters for various plots. Perhaps the most common tick/label formatting operation is the act of hiding ticks or labels. We can do this using and , as shown here (Figure 4-74): Notice that we’ve removed the labels (but kept the ticks/gridlines) from the x axis, and removed the ticks (and thus the labels as well) from the y axis. Having no ticks at all can be useful in many situations—for example, when you want to show a grid of images. For instance, consider Figure 4-75, which includes images of different faces, an example often used in supervised machine learning problems (for more information, see “In-Depth: Support Vector Machines”): # Get some face data from scikit-learn Notice that each image has its own axes, and we’ve set the locators to null because the tick values (pixel number in this case) do not convey relevant information for this particular visualization. Reducing or Increasing the Number of Ticks One common problem with the default settings is that smaller subplots can end up with crowded labels. We can see this in the plot grid shown in Figure 4-76: Particularly for the x ticks, the numbers nearly overlap, making them quite difficult to decipher. We can fix this with the , which allows us to specify the maximum number of ticks that will be displayed. Given this maximum number, Matplotlib will use internal logic to choose the particular tick locations (Figure 4-77): # For every axis, set the x and y major locator This makes things much cleaner. If you want even more control over the locations of regularly spaced ticks, you might also use , which we’ll discuss in the following section. Matplotlib’s default tick formatting can leave a lot to be desired; it works well as a broad default, but sometimes you’d like to do something more. Consider the plot shown in Figure 4-78, a sine and a cosine: There are a couple changes we might like to make. First, it’s more natural for this data to space the ticks and grid lines in multiples of . We can do this by setting a , which locates ticks at a multiple of the number you provide. For good measure, we’ll add both major and minor ticks in multiples of (Figure 4-79): But now these tick labels look a little bit silly: we can see that they are multiples of , but the decimal representation does not immediately convey this. To fix this, we can change the tick formatter. There’s no built-in formatter for what we want to do, so we’ll instead use , which accepts a user-defined function giving fine-grained control over the tick outputs (Figure 4-80): This is much better! Notice that we’ve made use of Matplotlib’s LaTeX support, specified by enclosing the string within dollar signs. This is very convenient for display of mathematical symbols and formulae; in this case, is rendered as the Greek character . The offers extremely fine-grained control over the appearance of your plot ticks, and comes in very handy when you’re preparing plots for presentation or publication. We’ve mentioned a couple of the available formatters and locators. We’ll conclude this section by briefly listing all the built-in locator and formatter options. For more information on any of these, refer to the docstrings or to the Matplotlib online documentation. Each of the following is available in the namespace: Ticks and range are a multiple of base Finds up to a max number of ticks at nice locations Set the strings from a list of labels Set the strings manually for the labels Use a format string for each value We’ll see additional examples of these throughout the remainder of the book.\n\nOne common type of visualization in data science is that of geographic data. Matplotlib’s main tool for this type of visualization is the Basemap toolkit, which is one of several Matplotlib toolkits that live under the namespace. Admittedly, Basemap feels a bit clunky to use, and often even simple visualizations take much longer to render than you might hope. More modern solutions, such as leaflet or the Google Maps API, may be a better choice for more intensive map visualizations. Still, Basemap is a useful tool for Python users to have in their virtual toolbelts. In this section, we’ll show several examples of the type of map visualization that is possible with this toolkit. Installation of Basemap is straightforward; if you’re using conda you can type this and the package will be downloaded: We add just a single new import to our standard boilerplate: Once you have the Basemap toolkit installed and imported, geographic plots are just a few lines away (the graphics in Figure 4-102 also require the package in Python 2, or the package in Python 3): The meaning of the arguments to Basemap will be discussed momentarily. The useful thing is that the globe shown here is not a mere image; it is a fully functioning Matplotlib axes that understands spherical coordinates and allows us to easily over-plot data on the map! For example, we can use a different map projection, zoom in to North America, and plot the location of Seattle. We’ll use an etopo image (which shows topographical features both on land and under the ocean) as the map background (Figure 4-103): Plotting data and labels on the map This gives you a brief glimpse into the sort of geographic visualizations that are possible with just a few lines of Python. We’ll now discuss the features of Basemap in more depth, and provide several examples of visualizing map data. Using these brief examples as building blocks, you should be able to create nearly any map visualization that you desire. The first thing to decide when you are using maps is which projection to use. You’re probably familiar with the fact that it is impossible to project a spherical map, such as that of the Earth, onto a flat surface without somehow distorting it or breaking its continuity. These projections have been developed over the course of human history, and there are a lot of choices! Depending on the intended use of the map projection, there are certain map features (e.g., direction, area, distance, shape, or other considerations) that are useful to maintain. The Basemap package implements several dozen such projections, all referenced by a short format code. Here we’ll briefly demonstrate some of the more common ones. We’ll start by defining a convenience routine to draw our world map along with the longitude and latitude lines: # lats and longs are returned as a dictionary # cycle through these lines and set the desired style The simplest of map projections are cylindrical projections, in which lines of constant latitude and longitude are mapped to horizontal and vertical lines, respectively. This type of mapping represents equatorial regions quite well, but results in extreme distortions near the poles. The spacing of latitude lines varies between different cylindrical projections, leading to different conservation properties, and different distortion near the poles. In Figure 4-104, we show an example of the equidistant cylindrical projection, which chooses a latitude scaling that preserves distances along meridians. Other cylindrical projections are the Mercator ( ) and the cylindrical equal-area ( ) projections. The additional arguments to Basemap for this view specify the latitude ( ) and longitude ( ) of the lower-left corner ( ) and upper-right corner ( ) for the desired map, in units of degrees. Pseudo-cylindrical projections relax the requirement that meridians (lines of constant longitude) remain vertical; this can give better properties near the poles of the projection. The Mollweide projection ( ) is one common example of this, in which all meridians are elliptical arcs (Figure 4-105). It is constructed so as to preserve area across the map: though there are distortions near the poles, the area of small patches reflects the true area. Other pseudo-cylindrical projections are the sinusoidal ( ) and Robinson ( ) projections. The extra arguments to here refer to the central latitude ( ) and longitude ( ) for the desired map. Perspective projections are constructed using a particular choice of perspective point, similar to if you photographed the Earth from a particular point in space (a point which, for some projections, technically lies within the Earth!). One common example is the orthographic projection ( ), which shows one side of the globe as seen from a viewer at a very long distance. Thus, it can show only half the globe at a time. Other perspective-based projections include the gnomonic projection ( ) and stereographic projection ( ). These are often the most useful for showing small portions of the map. Here is an example of the orthographic projection (Figure 4-106): A conic projection projects the map onto a single cone, which is then unrolled. This can lead to very good local properties, but regions far from the focus point of the cone may become very distorted. One example of this is the Lambert conformal conic projection ( ), which we saw earlier in the map of North America. It projects the map onto a cone arranged in such a way that two standard parallels (specified in by and ) have well-represented distances, with scale decreasing between them and increasing outside of them. Other useful conic projections are the equidistant conic ( ) and the Albers equal-area ( ) projection (Figure 4-107). Conic projections, like perspective projections, tend to be good choices for representing small to medium patches of the globe. If you’re going to do much with map-based visualizations, I encourage you to read up on other available projections, along with their properties, advantages, and disadvantages. Most likely, they are available in the Basemap package. If you dig deep enough into this topic, you’ll find an incredible subculture of geo-viz geeks who will be ready to argue fervently in support of their favorite projection for any given application! Earlier we saw the and methods for projecting global images on the map, as well as the and methods for drawing lines of constant latitude and longitude. The Basemap package contains a range of useful functions for drawing borders of physical features like continents, oceans, lakes, and rivers, as well as political boundaries such as countries and US states and counties. The following are some of the available drawing functions that you may wish to explore using IPython’s help features:\n• Draw a mask between the land and sea, for use with projecting images on one or the other Draw the map boundary, including the fill color for oceans Fill the continents with a given color; optionally fill lakes with another color\n• Draw an etopo relief image onto the map For the boundary-based features, you must set the desired resolution when creating a Basemap image. The argument of the class sets the level of detail in boundaries, either (crude), (low), (intermediate), (high), (full), or if no boundaries will be used. This choice is important: setting high-resolution boundaries on a global map, for example, can be very slow. Here’s an example of drawing land/sea boundaries, and the effect of the resolution parameter. We’ll create both a low- and high-resolution map of Scotland’s beautiful Isle of Skye. It’s located at 57.3°N, 6.2°W, and a map of 90,000×120,000 kilometers shows it well (Figure 4-108): Notice that the low-resolution coastlines are not suitable for this level of zoom, while high-resolution works just fine. The low level would work just fine for a global view, however, and would be much faster than loading the high-resolution border data for the entire globe! It might require some experimentation to find the correct resolution parameter for a given view; the best route is to start with a fast, low-resolution plot and increase the resolution as needed. Perhaps the most useful piece of the Basemap toolkit is the ability to over-plot a variety of data onto a map background. For simple plotting and text, any function works on the map; you can use the instance to project latitude and longitude coordinates to coordinates for plotting with , as we saw earlier in the Seattle example. In addition to this, there are many map-specific functions available as methods of the instance. These work very similarly to their standard Matplotlib counterparts, but have an additional Boolean argument , which if set to allows you to pass raw latitudes and longitudes to the method, rather than projected coordinates. Some of these map-specific methods are: We’ll see examples of a few of these as we continue. For more information on these functions, including several example plots, see the online Basemap documentation. Recall that in “Customizing Plot Legends”, we demonstrated the use of size and color in a scatter plot to convey information about the location, size, and population of California cities. Here, we’ll create this plot again, but using Basemap to put the data in context. We start with loading the data, as we did before: # Extract the data we're interested in Next, we set up the map projection, scatter the data, and then create a colorbar and legend (Figure 4-109): This shows us roughly where larger populations of people have settled in California: they are clustered near the coast in the Los Angeles and San Francisco areas, stretched along the highways in the flat central valley, and avoiding almost completely the mountainous regions along the borders of the state. As an example of visualizing some more continuous geographic data, let’s consider the “polar vortex” that hit the eastern half of the United States in January 2014. A great source for any sort of climatic data is NASA’s Goddard Institute for Space Studies. Here we’ll use the GIS 250 temperature data, which we can download using shell commands (these commands may have to be modified on Windows machines). The data used here was downloaded on 6/12/2016, and the file size is approximately 9 MB: The data comes in NetCDF format, which can be read in Python by the library. You can install this library as shown here: We read the data as follows: The file contains many global temperature readings on a variety of dates; we need to select the index of the date we’re interested in—in this case, January 15, 2014: Now we can load the latitude and longitude data, as well as the temperature anomaly for this index: Finally, we’ll use the method to draw a color mesh of the data. We’ll look at North America, and use a shaded relief map in the background. Note that for this data we specifically chose a divergent colormap, which has a neutral color at zero and two contrasting colors at negative and positive values (Figure 4-110). We’ll also lightly draw the coastlines over the colors for reference: The data paints a picture of the localized, extreme temperature anomalies that happened during that month. The eastern half of the United States was much colder than normal, while the western half and Alaska were much warmer. Regions with no recorded temperature show the map background.\n\nMatplotlib has proven to be an incredibly useful and popular visualization tool, but even avid users will admit it often leaves much to be desired. There are several valid complaints about Matplotlib that often come up:\n• Prior to version 2.0, Matplotlib’s defaults are not exactly the best choices. It was based off of MATLAB circa 1999, and this often shows.\n• Matplotlib’s API is relatively low level. Doing sophisticated statistical visualization is possible, but often requires a lot of boilerplate code.\n• Matplotlib predated Pandas by more than a decade, and thus is not designed for use with Pandas s. In order to visualize data from a Pandas , you must extract each and often concatenate them together into the right format. It would be nicer to have a plotting library that can intelligently use the labels in a plot. An answer to these problems is Seaborn. Seaborn provides an API on top of Matplotlib that offers sane choices for plot style and color defaults, defines simple high-level functions for common statistical plot types, and integrates with the functionality provided by Pandas s. To be fair, the Matplotlib team is addressing this: it has recently added the tools (discussed in “Customizing Matplotlib: Configurations and Stylesheets”), and is starting to handle Pandas data more seamlessly. The 2.0 release of the library will include a new default stylesheet that will improve on the current status quo. But for all the reasons just discussed, Seaborn remains an extremely useful add-on. Here is an example of a simple random-walk plot in Matplotlib, using its classic plot formatting and colors. We start with the typical imports: Now we create some random walk data: Although the result contains all the information we’d like it to convey, it does so in a way that is not all that aesthetically pleasing, and even looks a bit old-fashioned in the context of 21st-century data visualization. Now let’s take a look at how it works with Seaborn. As we will see, Seaborn has many of its own high-level plotting routines, but it can also overwrite Matplotlib’s default parameters and in turn get even simple Matplotlib scripts to produce vastly superior output. We can set the style by calling Seaborn’s method. By convention, Seaborn is imported as : Now let’s rerun the same two lines as before (Figure 4-112): # same plotting code as above! The main idea of Seaborn is that it provides high-level commands to create a variety of plot types useful for statistical data exploration, and even some statistical model fitting. Let’s take a look at a few of the datasets and plot types available in Seaborn. Note that all of the following could be done using raw Matplotlib commands (this is, in fact, what Seaborn does under the hood), but the Seaborn API is much more convenient. Often in statistical data visualization, all you want is to plot histograms and joint distributions of variables. We have seen that this is relatively straightforward in Matplotlib (Figure 4-113): Rather than a histogram, we can get a smooth estimate of the distribution using a kernel density estimation, which Seaborn does with (Figure 4-114): Histograms and KDE can be combined using (Figure 4-115): If we pass the full two-dimensional dataset to , we will get a two-dimensional visualization of the data (Figure 4-116): We can see the joint distribution and the marginal distributions together using . For this plot, we’ll set the style to a white background (Figure 4-117): There are other parameters that can be passed to —for example, we can use a hexagonally based histogram instead (Figure 4-118): When you generalize joint plots to datasets of larger dimensions, you end up with pair plots. This is very useful for exploring correlations between multidimensional data, when you’d like to plot all pairs of values against each other. We’ll demo this with the well-known Iris dataset, which lists measurements of petals and sepals of three iris species: Visualizing the multidimensional relationships among the samples is as easy as calling (Figure 4-119): A pair plot showing the relationships between four variables Sometimes the best way to view data is via histograms of subsets. Seaborn’s makes this extremely simple. We’ll take a look at some data that shows the amount that restaurant staff receive in tips based on various indicator data (Figure 4-120): Out[14]: total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 An example of a faceted histogram Factor plots can be useful for this kind of visualization as well. This allows you to view the distribution of a parameter within bins defined by any other parameter (Figure 4-121): An example of a factor plot, comparing distributions given various discrete factors Similar to the pair plot we saw earlier, we can use to show the joint distribution between different datasets, along with the associated marginal distributions (Figure 4-122): The joint plot can even do some automatic kernel density estimation and regression (Figure 4-123): Time series can be plotted with . In the following example (visualized in Figure 4-124), we’ll use the Planets data that we first saw in “Aggregation and Grouping”: We can learn more by looking at the method of discovery of each of these planets, as illustrated in Figure 4-125: Number of planets discovered by year and type (see the online appendix for a full-scale figure) For more information on plotting with Seaborn, see the Seaborn documentation, a tutorial, and the Seaborn gallery. Here we’ll look at using Seaborn to help visualize and understand finishing results from a marathon. I’ve scraped the data from sources on the Web, aggregated it and removed any identifying information, and put it on GitHub where it can be downloaded (if you are interested in using Python for web scraping, I would recommend Web Scraping with Python by Ryan Mitchell). We will start by downloading the data from the Web, and loading it into Pandas: By default, Pandas loaded the time columns as Python strings (type ); we can see this by looking at the attribute of the : Let’s fix this by providing a converter for the times: That looks much better. For the purpose of our Seaborn plotting utilities, let’s next add columns that give the times in seconds: To get an idea of what the data looks like, we can plot a over the data (Figure 4-126): The relationship between the split for the first half-marathon and the finishing time for the full marathon The dotted line shows where someone’s time would lie if they ran the marathon at a perfectly steady pace. The fact that the distribution lies above this indicates (as you might expect) that most people slow down over the course of the marathon. If you have run competitively, you’ll know that those who do the opposite—run faster during the second half of the race—are said to have “negative-split” the race. Let’s create another column in the data, the split fraction, which measures the degree to which each runner negative-splits or positive-splits the race: Where this split difference is less than zero, the person negative-split the race by that fraction. Let’s do a distribution plot of this split fraction (Figure 4-127): The distribution of split fractions; 0.0 indicates a runner who completed the first and second halves in identical times Out of nearly 40,000 participants, there were only 250 people who negative-split their marathon. Let’s see whether there is any correlation between this split fraction and other variables. We’ll do this using a , which draws plots of all these correlations (Figure 4-128): The relationship between quantities within the marathon dataset It looks like the split fraction does not correlate particularly with age, but does correlate with the final time: faster runners tend to have closer to even splits on their marathon time. (We see here that Seaborn is no panacea for Matplotlib’s ills when it comes to plot styles: in particular, the x-axis labels overlap. Because the output is a simple Matplotlib plot, however, the methods in “Customizing Ticks” can be used to adjust such things if desired.) The difference between men and women here is interesting. Let’s look at the histogram of split fractions for these two groups (Figure 4-129): The distribution of split fractions by gender The interesting thing here is that there are many more men than women who are running close to an even split! This almost looks like some kind of bimodal distribution among the men and women. Let’s see if we can suss out what’s going on by looking at the distributions as a function of age. A nice way to compare distributions is to use a violin plot (Figure 4-130): This is yet another way to compare the distributions between men and women. Let’s look a little deeper, and compare these violin plots as a function of age. We’ll start by creating a new column in the array that specifies the decade of age that each person is in (Figure 4-131): A violin plot showing the split fraction by gender and age Looking at this, we can see where the distributions of men and women differ: the split distributions of men in their 20s to 50s show a pronounced over-density toward lower splits when compared to women of the same age (or of any age, for that matter). Also surprisingly, the 80-year-old women seem to outperform everyone in terms of their split time. This is probably due to the fact that we’re estimating the distribution from small numbers, as there are only a handful of runners in that range: Back to the men with negative splits: who are these runners? Does this split fraction correlate with finishing quickly? We can plot this very easily. We’ll use , which will automatically fit a linear regression to the data (Figure 4-132): Apparently the people with fast splits are the elite runners who are finishing within ~15,000 seconds, or about 4 hours. People slower than that are much less likely to have a fast second split."
    },
    {
        "link": "https://matplotlib.org/stable/gallery/index.html",
        "document": "For an overview of the plotting methods we provide, see Plot types\n\nThis page contains example plots. Click on any image to see the full image and source code.\n\nFor longer tutorials, see our tutorials page. You can also find external resources and a FAQ in our user guide."
    },
    {
        "link": "https://analyticsvidhya.com/blog/2020/02/beginner-guide-matplotlib-data-visualization-exploration-python",
        "document": "A Beginner’s Guide to matplotlib for Data Visualization and Exploration in Python\n\nmatplotlib – The Most Popular Python Library for Data Visualization and Exploration I love working with matplotlib in Python. It was the first visualization library I learned to master and it has stayed with me ever since. There is a reason why matplotlib is the most popular Python library for data visualization and exploration – the flexibility and agility it offers is unparalleled! Matplotlib provides an easy but comprehensive visual approach to present our findings. There are a number of visualizations we can choose from to present our results, as we’ll soon see in this tutorial. From histograms to scatterplots, matplotlib lays down an array of colors, themes, palettes, and other options to customize and personalize our plots. matplotlib is useful whether you’re performing data exploration for a machine learning project or simply want to create dazzling and eye-catching charts. Note: If you’re new to the world of Python, we highly recommend taking the below popular free courses:\n\nLet’s put a formal definition to matplotlib before we dive into the crux of the article. If this is the first time you’ve heard of matplotlib, here’s the official description:\n\nYou can draw up all sorts of charts and visualization using matplotlib. I will be exploring the most common plots in the matplotlib Python library in this tutorial. We will first understand the dataset at hand and then start building different plots using matplotlib, including scatterplots and line charts!\n\nNote: If you’re looking for a matplotlib alternative or want to explore other Python visualization libraries, check out the below tutorial on Seaborn:\n• Become a Data Visualization Whiz with this Comprehensive Guide to Seaborn in Python\n\nHere are the Visualization We’ll Design using matplotlib Understanding the Dataset and the Problem Statement Before we get into the different visualizations and chart types, I want to spend a few minutes understanding the data. This is a critical part of the machine learning pipeline and we should pay full attention to it. We will be analyzing the Food Demand Forecasting project in this matplotlib tutorial. The aim of this project is to predict the number of food orders that customers will place in the upcoming weeks with the company. We will, of course, only spend time on the exploration stage of the project. Let us first import the relevant libraries: I have used a matplotlib stylesheet to make our plots look neat and pretty. Here, I have used the ‘seaborn’ stylesheet. However, there are plenty of other stylesheets in Matplotlib which you can use to best suit your presentation style. Our dataset has three dataframes: df_meal describing the meals, df_center describing the food centers, and df_food describing the overall food order. Have a look at them below: I will first merge all the three dataframes into a single dataframe. This will make it easier to manipulate the data while plotting it: Right – now let’s jump into the different chart types we can create using matplotlib in Python! First, we want to find the most popular food item that customers have bought from the company. I will be using the Pandas pivot_table function to find the total number of orders for each category of the food item: Next, I will try to visualize this using a bar graph. Bar graphs are best used when we need to compare the quantity of categorical values within the same category. Bar graph is generated using plt.bar() in matplotlib: import pandas as pd import numpy as np import matplotlib.pyplot as plt plt.style.use('seaborn') #reading the meal info csv file df_meal = pd.read_csv('meal_info.csv') # Reading fulfilment center info csv file df_center = pd.read_csv('fulfilment_center_info.csv') # Reading train food csv file df_food = pd.read_csv('train_food.csv') # Merge dataframes df = pd.merge(df_food,df_center,on='center_id') df = pd.merge(df,df_meal,on='meal_id') # Pivot table table = pd.pivot_table(data=df,index='category',values='num_orders',aggfunc=np.sum) # Barplot plt.bar(table.index,table['num_orders']) plt.xticks(rotation=70) plt.xlabel('Food item') plt.ylabel('Quantity sold') plt.title('Most popular food') plt.show() It is always important to label your axis. You can do this by employing the plt.xlabel() and plt.ylabel() functions. You can use plt.title() for naming the title of the plot. If your xticks are overlapping, rotate them using the rotate parameter in plt.xticks() so that they are easy to view for the audience. You can save your plot using the plt.savefig() function by providing the file path as a parameter. Finally, always display your plot using plt.show(). While analyzing the plot, we can see that Beverages were the most popular food item sold by the company. Wait, was it because they were sold with almost all the meals? Was Rice Bowl the most popular food item? Let’s divide the total food item order by the number of unique meals it is present in. Yes, our hypothesis was correct! Rice Bowl was indeed the most popular food item sold by the company. Bar graphs should not be used for continuous values. Let us now see the ratio of orders from each cuisine. A pie chart is suitable to show the proportional distribution of items within the same category.\n• I used plt.pie() to draw the pie chart and adjust its parameters to make it more appealing\n• The autopct parameter was used to print the values within the pie chart up to 1 decimal place\n• The explode parameter was used to offset the Italian wedge to make it stand out from the rest. This makes it instantly clear to the viewer that people love Italian food! A pie chart is rendered useless when there are a lot of items within a category. This will decrease the size of each slice and there will be no distinction between the items. Since we are discussing cuisine, let’s check out which one is the most expensive cuisine! For this, I will be using a Box Plot. Box plot gives statistical information about the distribution of numeric data divided into different groups. It is useful for detecting outliers within each group.\n• The lower, middle and upper part of the box represents the 25th, 50th, and 75th percentile values respectively Continental cuisine was the most expensive cuisine served by the company! Even its median price is higher than the maximum price of all the cuisines. Box plot does not show the distribution of data points within each group. On the topic of prices, did we forget to inspect the base price and checkout price? Don’t worry, we will do that using a histogram. A histogram shows the distribution of numeric data through a continuous interval by segmenting data into different bins. Useful for inspecting skewness in the data. Since base_price is a continuous variable, we will inspect its range in different distinct orders using a histogram. We can do this using plt.hist(). But the confusing part is what should be the number of bins? By default, it is 10. However, there is no correct answer and you can vary it according to your dataset to best visualize it. I have chosen the number of bins as 15 and it is evident that most of the orders had a base price of ~300. It is easy to confuse histograms with bar plots. But remember, histograms are used with continuous data whereas bar plots are used with categorical data. A line plot is useful for visualizing the trend in a numerical value over a continuous time interval. How are the weekly and monthly sales of the company varying? This is a critical business question that makes or breaks the marketing strategy. Before exploring that, I will create two lists for storing the week-wise and month-wise revenue of the company: I will compare the revenue of the company in every week as well as in every month using two line-plots drawn side by side. For this, I will be using the plt.subplots() function. Matplotlib subplots makes it easy to view and compare different plots in the same figure. To understand how this function works, you need to know what Figure, Axes, and Axis are in a matplotlib plot. Figure is the outermost container for the Matplotlib plot(s). There can a single or multiple plots, called Axes, within a Figure. Each of these Axes contains the x and y-axis known as the Axis. The plt.subplots() figure returns the figure and axes. You can provide as an input to the function how you want to display the axes within the figure. These will be adjusted using the nrows and ncols parameters. You can even adjust the size of the figure using the figsize parameter. Axes are returned as a list. To plot for specific axes, you can access them as a list object. The rest of the plotting is done the same way as simple plots: We can see an increasing trend in the number of food orders with the number of weeks and months, though the trend is not very strong. Finally, I will try to analyze whether the center type had any effect on the number of orders from different center types. I will do this by comparing a scatter plot, a boxplot and a bar graph in the same figure. We have already seen the use of boxplots and bar graphs, but scatter plots have their own advantages. Scatter plots are useful for showing the relationship between two variables. Any correlation between variables or outliers in the data can be easily spotted using scatter plots. The scatter plot makes it instantly visible that the optimum operation area of a center is 4 km sq. The boxplot shows that the TYPE_A center type had the most number of optimum size centers because of a compact box with a median around 4 km sq. Because of this, they had more orders placed by customers than any other center type. You are now a step closer to creating wonderful plots in Matplotlib. However, the best way to master plotting is to practice, practice and practice! For this, I suggest you go through other such amazing datasets on the DataHack platform and visualize till you dream in plots! Next, you can go through the below resources to build your existing skillset:\n\nI am on a journey to becoming a data scientist. I love to unravel trends in data, visualize it and predict the future with ML algorithms! But the most satisfying part of this journey is sharing my learnings, from the challenges that I face, with the community to make the world a better place!"
    },
    {
        "link": "https://geeksforgeeks.org/data-visualization-using-matplotlib",
        "document": "Matplotlib is a powerful and widely-used Python library for creating static, animated and interactive data visualizations. In this article, we will provide a guide on Matplotlib and how to use it for data visualization with practical implementation.\n\nMatplotlib offers a wide variety of plots such as line charts, bar charts, scatter plot and histograms making it versatile for different data analysis tasks. The library is built on top of NumPy making it efficient for handling large datasets. It provides a lot of flexibility in code.\n\nWe will use the pip command to install this module. If you do not have pip installed then refer to the article, Download and install pip Latest Version.\n\nTo install Matplotlib type the below command in the terminal.\n\nIf you are using Jupyter Notebook, you can install it within a notebook cell by using:\n\nMatplotlib provides a module called pyplot which offers a MATLAB-like interface for creating plots and charts. It simplifies the process of generating various types of visualizations by providing a collection of functions that handle common plotting tasks.\n\nMatplotlib supports a variety of plots including line charts, bar charts, histograms, scatter plots, etc. Let’s understand them with implementation using pyplot.\n\nLine chart is one of the basic plots and can be created using the plot() function. It is used to represent a relationship between two data X and Y on a different axis.\n\nA bar chart is a graph that represents the category of data with rectangular bars with lengths and heights that is proportional to the values which they represent. The bar plots can be plotted horizontally or vertically. A bar chart describes the comparisons between the different categories. It can be created using the bar() method.\n\nIn the below example we will use the tips dataset. Tips database is the record of the tip given by the customers in a restaurant for two and a half months in the early 1990s. It contains 6 columns as total_bill, tip, sex, smoker, day, time, size.\n\nA histogram is basically used to represent data provided in a form of some groups. It is a type of bar plot where the X-axis represents the bin ranges while the Y-axis gives information about frequency. The hist() function is used to compute and create histogram of x.\n\nScatter plots are used to observe relationships between variables. The scatter() method in the matplotlib library is used to draw a scatter plot.\n\nPie chart is a circular chart used to display only one series of data. The area of slices of the pie represents the percentage of the parts of the data. The slices of pie are called wedges. It can be created using the pie() method.\n\nA Box Plot is also known as a Whisker Plot and is a standardized way of displaying the distribution of data based on a five-number summary: minimum, first quartile (Q1), median (Q2), third quartile (Q3) and maximum. It can also show outliers.Let’s see an example of how to create a Box Plot using Matplotlib in Python:\n• and : Customize the appearance of the boxes and median lines respectively.\n\nThe box shows the interquartile range (IQR) the line inside the box shows the median and the “whiskers” extend to the minimum and maximum values within 1.5 * IQR from the first and third quartiles. Any points outside this range are considered outliers and are plotted as individual points.\n\nA Heatmap is a data visualization technique that represents data in a matrix form where individual values are represented as colors. Heatmaps are particularly useful for visualizing the magnitude of multiple features in a two-dimensional surface and identifying patterns, correlations and concentrations. Let’s see an example of how to create a Heatmap using Matplotlib in Python:\n• None : Displays the data as an image (heatmap). The argument specifies the color map used for the heatmap.\n• None : Ensures that each data point is shown as a block of color without smoothing.\n\nThe color bar on the side provides a scale to interpret the colors with darker colors representing lower values and lighter colors representing higher values. This type of plot is often used in fields like data analysis, bioinformatics and finance to visualize data correlations and distributions across a matrix.\n\nMatplotlib allows extensive customization and styling of plots including changing colors, adding labels and modifying plot styles.\n\nLet’s apply the customization techniques we’ve learned to the basic plots we created earlier. This will involve enhancing each plot with titles, axis labels, limits, tick labels, and legends to make them more informative and visually appealing.\n\nLet’s see how to customize the line chart. We will be using the following properties:\n• color: Changing the color of the line\n• linewidth: Customizing the width of the line\n• marker: For changing the style of actual plotted point\n• markersize: For changing the size of the markers\n• linestyle: For defining the style of the plotted line\n\nTo make bar charts more informative and visually appealing various customization options are available. Customization that is available for the Bar Chart are:\n• edgecolor: Color of edges of the bar\n\nThe lines in between the bars refer to the different values in the Y-axis of the particular value of the X-axis.\n\nTo make histogram plots more effective and tailored to your data, you can apply various customizations:\n• alpha: blending value, between 0 (transparent) and 1 (opaque)\n\nScatter plots are versatile tools for visualizing relationships between two variables. Customizations that are available for the scatter plot are to enhance their clarity and effectiveness:\n• s: marker size (can be scalar or array of size equal to size of x or y)\n• c: color of sequence of colors for markers\n• alpha: blending value, between 0 (transparent) and 1 (opaque)\n\nPie charts are a great way to visualize proportions and parts of a whole. To make your pie charts more effective and visually appealing, consider the following customization techniques:\n• explode: Moving the wedges of the plot\n• autopct: Label the wedge with their numerical value.\n• color: Attribute is used to provide color to the wedges.\n• shadow: Used to create shadow of wedge.\n\nBefore moving any further with Matplotlib let’s discuss some important classes that will be used further in the tutorial. These classes are:\n\nConsider the figure class as the overall window or page on which everything is drawn. It is a top-level container that contains one or more axes. A figure can be created using the figure() method.\n\nAxes class is the most basic and flexible unit for creating sub-plots. A given figure may contain many axes, but a given axes can only be present in one figure. The axes() function creates the axes object.\n\nJust like pyplot class, axes class also provides methods for adding titles, legends, limits, labels, etc. Let’s see a few of them –\n• None ax.set_title() is used to add title.\n• None To set the limits we use ax.set_xlim(), ax.set_ylim()\n• None ax.set_xticklabels(), ax.set_yticklabels() are used to tick labels.\n• None To add legend we use ax.legend()\n\nWe have learned about the basic components of a graph that can be added so that it can convey more information. One method can be by calling the plot function again and again with a different set of values as shown in the above example. Now let’s see how to plot multiple graphs using some functions and also how to plot subplots.\n\nThe add_axes() method method allows you to manually add axes to a figure in Matplotlib. It takes a list of four values to specify the position and size of the axes.\n\nsubplot() method adds a plot to a specified grid position within the current figure. It takes three arguments: the number of rows, columns, and the plot index. Now Let’s understand it with the help of example:\n\nThe subplot2grid() creates axes object at a specified location inside a grid and also helps in spanning the axes object across multiple rows or columns. In simpler words, this function is used to create multiple charts within the same figure.\n\nFor saving a plot in a file on storage disk, savefig() method is used. A file can be saved in many formats like .png, .jpg, .pdf, etc.\n\nIn this guide, we have explored the fundamentals of Matplotlib, from installation to advanced plotting techniques. By mastering these concepts, Whether you are working with simple line charts or complex heatmaps you can create and customize a wide range of visualizations to effectively communicate data insights.\n\nWhat is the difference between and in Matplotlib?\n\nCan Matplotlib be used for interactive visualizations?\n\nWhat are some advanced customization options available in Matplotlib?\n\nHow do I handle large datasets with Matplotlib?"
    },
    {
        "link": "https://stackoverflow.com/questions/64022473/simple-2d-perlin-noise-in-python",
        "document": "Does it need to be integers, or is double floating point precision good enough? Can you use Cython? There is a Cython wrapper for FastNoiseLite here: https://github.com/tizilogic/PyFastNoiseLite . You can convert the integers to doubles, with plenty of precision left over.\n\nI would also suggest using the OpenSimplex2 or OpenSimplex2S noise option, rather than Perlin. Perlin as a base noise is very grid-aligned looking. Simplex/OpenSimplex2(S) directly address that."
    },
    {
        "link": "https://medium.com/@yvanscher/playing-with-perlin-noise-generating-realistic-archipelagos-b59f004d8401",
        "document": "In the python noise module there are a few parameters that affect what you see when you generate your perlin noise:\n• scale: number that determines at what distance to view the noisemap.\n• octaves: the number of levels of detail you want you perlin noise to have.\n• lacunarity: number that determines how much detail is added or removed at each octave (adjusts frequency).\n• persistence: number that determines how much each octave contributes to the overall shape (adjusts amplitude).\n\nWe won’t worry about scale too much, you can use it to zoom out (bigger scale) or in (smaller scale).\n\nPerlin noise combines multiple functions called ‘octaves’ to produce natural looking surfaces. Each octave adds a layer of detail to the surface. For example: octave 1 could be mountains, octave 2 could be boulders, octave 3 could be the rocks.\n\nLacunarity of more than 1 means that each octave will increase it’s level of fine grained detail (increased frqeuency). Lacunarity of 1 means that each octave will have the sam level of detail. Lacunarity of less than one means that each octave will get smoother. The last two are usually undesirable so a lacunarity of 2 works quite well.\n\nPersistence determines how much each octave contributes to the overall structure of the noise map. If your persistence is 1 all octaves contribute equally. If you persistence is more than 1 sucessive octaves contribute more and you get something closer to regular noise (spoiler the regular noise image above is actually a perlin noise with a presistence of 5.0). A more default setting would be a presistance of less than 1.0 which will decrease the effect of later octaves.\n\nEnough chatting though! Let’s run some experiments. First let’s start with default perlin noise, and its accompanying image:\n\nThe way this perlin noise looks in our script is a 2D array of values between -1 and 1. The values that are darker on the map are lower values, the values that are close to 1 are lighter. What I want to try next is assigning two colors to different ranges of values in this map to produce some terrain:\n\nThis terrain map is pretty neat; it has jagged coasts, beaches, and lots of water. while I have never observed natural terrain that looks like this if we look at any one part of the map it seems ‘realistic.’ Let’s take it a step further and add mountains and snow:\n\nThis is cool but this terrain pattern is clearly not natural. To make it more natural we will use a circular filter to get rid of all the preipheral perlin noise:\n\nHere I was trying to create an island so I made a circular filter and then applied it to the color_world perlin noise array. What I ended up was a planet floating in an ocean. I changed the ocean color to black and it looks pretty cool! That said what I wanted was an island so let’s try again. This time we’re going to calculate a circular gradient and then apply that over the perlin noise as a filter.\n\nI struggled a lot with this part. I’m sure there is a more efficient way to get the gradient like this but the above was what I came up with. I calculated a distance metric from the center of the map and then normalized, shrunk, and renomalized those distances to produce this spherical gradient. Again lighter means the value is closer to 1, darker colors are closer to 0. Next I apply this circular gradient to the perlin noise we created before.\n\nThis part was less tricky but still a pain. I multiply the perlin noise by the circle gradient and then I increase the contrast by multiplying positive (lighter values) by 20. Then I renormalize to make it 0–1 again.\n\nThis is really cool and it looks like a much more natural archipelago. I encourage you to try different shading methods and maybe randomly removing some sections. I’m going to change the threshold value and set it as . That will produce a smaller but more realistic archipelago as so:\n\nThere we are! We have a natural looking island archipelago! So now that we have our islands you may notice that no matter how often you rerun this script perlin noise will produce the same islands. To get new islands you can set the parameter of the pnoise2 function to a random integer number, let’s try :"
    },
    {
        "link": "https://stackoverflow.com/questions/42147776/producing-2d-perlin-noise-with-numpy",
        "document": "I'm trying to produce 2D perlin noise using numpy, but instead of something smooth I get this :\n\nmy broken perlin noise, with ugly squares everywhere\n\nFor sure, I'm mixing up my dimensions somewhere, probably when I combine the four gradients ... But I can't find it and my brain is melting right now. Anyone can help me pinpoint the problem ?\n\nAnyway, here is the code:"
    },
    {
        "link": "https://garagefarm.net/blog/perlin-noise-implementation-procedural-generation-and-simplex-noise",
        "document": "In the realms of computer graphics, gaming, and animation, \"noise\" holds a special significance, shaping realistic textures, terrains, and immersive landscapes. From classic video games to cutting-edge simulations, the concept of Perlin Noise revolutionized how we approach procedural generation, influencing how environments are built, how textures are mapped, and how movement feels organic in virtual worlds. Whether you're new to noise algorithms or delving into Simplex Noise as an alternative, understanding these concepts and their implementation opens up a realm of creative possibilities.\n\nPerlin Noise, developed by Ken Perlin in 1983, is a type of gradient noise widely used for simulating natural-looking textures and phenomena. Ken Perlin, an innovator in procedural graphics, developed this algorithm during the production of Tron, which marked a significant milestone in the world of CGI. Perlin Noise generates visually smooth, natural-looking patterns, making it a mainstay in procedural generation, particularly for terrain and organic textures. Its mathematical foundation lies in generating gradients across a grid and interpolating them, which distinguishes it from \"white noise,\" where each point is entirely random and lacks continuity.\n\nHow Perlin Noise Works: A Brief Overview of the Algorithm\n\nPerlin Noise operates by taking a coordinate point (often in 2D or 3D) and mapping it to gradients, calculating a weighted average based on each gradient's direction and strength relative to the point. This process involves key mathematical components, such as dot products, linear interpolation, and gradient vectors. The dot product is especially central to Perlin Noise, determining the contribution of each gradient direction to the final noise value.\n\nThe magic of Perlin Noise lies in its ability to smoothly transition between points, avoiding sharp, unrealistic changes that would otherwise make textures appear choppy or unnatural.\n\nWhy Perlin Noise is Popular in Graphics and Game Design\n\nKen Perlin’s noise function became a game-changer because it efficiently creates organic-looking randomness that feels natural to the human eye. This capability allowed for more complex textures, animations, and entire terrains to be procedurally generated in games, movies, and simulations. In applications such as Minecraft, for example, Perlin Noise enables the seamless creation of vast, believable landscapes, enhancing the user’s immersion in the virtual world.\n\nA Perlin Noise algorithm begins with a grid of gradient vectors that each point in random directions. Each coordinate point on this grid is evaluated for noise by taking into account its relative position to the grid’s surrounding gradient points. By combining a sequence of dot products and interpolations, Perlin Noise achieves smooth, blended transitions across the surface.\n• Calculating dot products between each gradient vector and the vector pointing from the grid intersection to the input coordinate.\n• Interpolating these dot products to produce the final noise value.\n\nOptimization in Perlin Noise can be achieved by using \"octaves\" — stacking multiple noise layers at different frequencies and amplitudes to produce a richer texture. Lower frequencies provide broad, slow changes, while higher frequencies add fine details. This technique can be adapted by adding layers, adjusting the frequency, and reducing the computation by storing gradient values in an array rather than recalculating them dynamically.\n\nPerlin Noise is ideal for creating natural textures like clouds, water, and landscapes. By adjusting parameters, you can simulate waves, rolling hills, and even mountain ranges. In texture synthesis, Perlin Noise offers an approach to avoid repetition, as each coordinate produces a unique, smooth value that avoids the uniformity of tileable textures.\n\nApplications of Perlin Noise in Game Environments and Landscapes\n\nMany games, including Minecraft and Terraria, leverage Perlin Noise for procedurally generated terrain. For example, by varying amplitude and frequency, developers can define mountainous regions, plains, and valleys, contributing to the distinct, visually coherent worlds players can explore.\n\nIn addition to terrain, Perlin Noise can define biomes, generate weather patterns, and even create animated visual effects like fire, smoke, and flowing water. Procedurally generated caves and dungeons also benefit from Perlin Noise, providing an endless variety of configurations.\n\n\n\nSee CG Matter’s application of Blender’s Perlin Noise based Noise Texture node here:\n\n\n\nWhat is Simplex Noise and How Does it Differ from Perlin Noise?\n\nSimplex Noise, also created by Ken Perlin, is an improvement over classic Perlin Noise, particularly in higher dimensions. Unlike the grid structure of Perlin Noise, Simplex Noise operates within a \"simplex,\" which is a geometric shape (like a triangle in 2D or a tetrahedron in 3D). This approach reduces computation and visual artifacts, especially in four dimensions and beyond.\n\nSimplex Noise is efficient and less computationally intensive for complex applications, such as 4D textures in simulations. It requires fewer resources by covering space more compactly than a grid, making it faster and more flexible for real-time applications, like animated textures and fluid simulations.\n\nWhen to Use Simplex Noise Over Perlin Noise\n\nSimplex Noise is preferable for applications requiring low-latency noise generation or work in high-dimensional spaces, such as volumetric clouds or fluid dynamics. Its reduced grid complexity and smoother transitions make it especially suited for dynamic or complex scenes.\n\n\n\nSee Blogize’s comparison between Perlin and Simplex Noise here:\n\nTips for Working with Perlin and Simplex Noise\n\nControl over parameters like frequency, amplitude, and octaves is essential to achieving a realistic or stylistic effect. Increasing frequency adds details, while adjusting amplitude impacts how dramatic these details appear. Lower frequencies produce broader, more gradual changes ideal for natural terrains, while higher values are useful for fine textures like grass or rocky surfaces.\n\nA popular technique involves layering multiple noise functions, each with different frequencies and amplitudes, to create detailed and realistic textures. By layering Perlin or Simplex Noise with other forms, you can achieve natural-looking details, whether for wood grains, clouds, or animated fire.\n\nArtifacts can arise from improper interpolation or aliasing in Perlin Noise. Techniques like adjusting interpolation methods or using a higher-resolution grid can reduce these effects, producing smoother results.\n\nSee The Coding Train’s seminar on generating 3D Terrain with Perlin Noise:\n\n\n\nThe procedural generation powered by Perlin and Simplex Noise remains a core component of world-building in gaming. These noise functions produce limitless landscapes, level variations, and organic animations, enhancing player immersion and reducing asset creation costs.\n\nUse of Perlin and Simplex Noise in Data Visualization and Simulations\n\nOutside of gaming, these noise functions help simulate natural phenomena in scientific visualization, from fluid dynamics to cloud patterns. In data visualization, Perlin Noise can smooth transitions in heat maps or population distributions, creating a more digestible presentation of data.\n\nThe Role of Noise in Generative Art and Creative Coding\n\nNoise-based algorithms have grown popular in generative art, where they inspire unique, mathematical patterns for digital canvases. Using parameters such as octaves and amplitude, artists create visually engaging and organic shapes that serve as foundations for abstract art, making noise an essential tool for creative coders.\n\nWith Perlin Noise, Ken Perlin not only pioneered procedural textures and generation techniques but also sparked an entirely new approach to visual realism in computer graphics. Whether building immersive worlds, visualizing data, or creating generative art, understanding and harnessing the power of Perlin and Simplex Noise continues to open doors to innovation in the digital arts."
    },
    {
        "link": "https://reddit.com/r/proceduralgeneration/comments/h0vntm/python_2d_array_perlin_noise",
        "document": "Does anybody know how to produce a 2d array of perlin noise (for example 100x100) that would result in smooth terrain generation?\n\nHelp would be greatly appreciated"
    }
]