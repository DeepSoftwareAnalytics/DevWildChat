[
    {
        "link": "https://docs.spring.io/spring-framework/reference/web/webflux-functional.html",
        "document": "See equivalent in the Servlet stack In WebFlux.fn, an HTTP request is handled with a : a function that takes and returns a delayed (i.e. ). Both the request and the response object have immutable contracts that offer JDK 8-friendly access to the HTTP request and response. is the equivalent of the body of a method in the annotation-based programming model. Incoming requests are routed to a handler function with a : a function that takes and returns a delayed (i.e. ). When the router function matches, a handler function is returned; otherwise an empty Mono. is the equivalent of a annotation, but with the major difference that router functions provide not just data, but also behavior. provides a router builder that facilitates the creation of routers, as the following example shows: Create router using Coroutines router DSL; a Reactive alternative is also available via . One way to run a is to turn it into an and install it through one of the built-in server adapters: Most applications can run through the WebFlux Java configuration, see Running a Server.\n\nSee equivalent in the Servlet stack and are immutable interfaces that offer JDK 8-friendly access to the HTTP request and response. Both request and response provide Reactive Streams back pressure against the body streams. The request body is represented with a Reactor or . The response body is represented with any Reactive Streams , including and . For more on that, see Reactive Libraries. provides access to the HTTP method, URI, headers, and query parameters, while access to the body is provided through the methods. The following example extracts the request body to a : The following example extracts the body to a (or a in Kotlin), where objects are decoded from some serialized form, such as JSON or XML: The preceding examples are shortcuts that use the more general , which accepts the functional strategy interface. The utility class provides access to a number of instances. For example, the preceding examples can also be written as follows: The following example shows how to access form data: The following example shows how to access multipart data as a map: The following example shows how to access multipart data, one at a time, in streaming fashion: Flux<PartEvent> allPartEvents = request.bodyToFlux(PartEvent.class); allPartsEvents.windowUntil(PartEvent::isLast) .concatMap(p -> p.switchOnFirst((signal, partEvents) -> { if (signal.hasValue()) { PartEvent event = signal.get(); if (event instanceof FormPartEvent formEvent) { String value = formEvent.value(); // handle form field } else if (event instanceof FilePartEvent fileEvent) { String filename = fileEvent.filename(); Flux<DataBuffer> contents = partEvents.map(PartEvent::content); // handle file upload } else { return Mono.error(new RuntimeException(\"Unexpected event: \" + event)); } } else { return partEvents; // either complete or error signal } })); val parts = request.bodyToFlux<PartEvent>() allPartsEvents.windowUntil(PartEvent::isLast) .concatMap { it.switchOnFirst { signal, partEvents -> if (signal.hasValue()) { val event = signal.get() if (event is FormPartEvent) { val value: String = event.value(); // handle form field } else if (event is FilePartEvent) { val filename: String = event.filename(); val contents: Flux<DataBuffer> = partEvents.map(PartEvent::content); // handle file upload } else { return Mono.error(RuntimeException(\"Unexpected event: \" + event)); } } else { return partEvents; // either complete or error signal } } } } Note that the body contents of the objects must be completely consumed, relayed, or released to avoid memory leaks. provides access to the HTTP response and, since it is immutable, you can use a method to create it. You can use the builder to set the response status, to add response headers, or to provide a body. The following example creates a 200 (OK) response with JSON content: The following example shows how to build a 201 (CREATED) response with a header and no body: Depending on the codec used, it is possible to pass hint parameters to customize how the body is serialized or deserialized. For example, to specify a Jackson JSON view: We can write a handler function as a lambda, as the following example shows: That is convenient, but in an application we need multiple functions, and multiple inline lambda’s can get messy. Therefore, it is useful to group related handler functions together into a handler class, which has a similar role as in an annotation-based application. For example, the following class exposes a reactive repository: is a handler function that returns all objects found in the repository as JSON. is a handler function that stores a new contained in the request body. Note that returns : an empty that emits a completion signal when the person has been read from the request and stored. So we use the method to send a response when that completion signal is received (that is, when the has been saved). is a handler function that returns a single person, identified by the path variable. We retrieve that from the repository and create a JSON response, if it is found. If it is not found, we use to return a 404 Not Found response. is a handler function that returns all objects found in the repository as JSON. is a handler function that stores a new contained in the request body. Note that is a suspending function with no return type. is a handler function that returns a single person, identified by the path variable. We retrieve that from the repository and create a JSON response, if it is found. If it is not found, we return a 404 Not Found response. A functional endpoint can use Spring’s validation facilities to apply validation to the request body. For example, given a custom Spring Validator implementation for a : public class PersonHandler { private final Validator validator = new PersonValidator(); (1) // ... public Mono<ServerResponse> createPerson(ServerRequest request) { Mono<Person> person = request.bodyToMono(Person.class).doOnNext(this::validate); (2) return ok().build(repository.savePerson(person)); } private void validate(Person person) { Errors errors = new BeanPropertyBindingResult(person, \"person\"); validator.validate(person, errors); if (errors.hasErrors()) { throw new ServerWebInputException(errors.toString()); (3) } } } Handlers can also use the standard bean validation API (JSR-303) by creating and injecting a global instance based on . See Spring Validation.\n\nSee equivalent in the Servlet stack Router functions are used to route the requests to the corresponding . Typically, you do not write router functions yourself, but rather use a method on the utility class to create one. (no parameters) provides you with a fluent builder for creating a router function, whereas offers a direct way to create a router. Generally, it is recommended to use the builder, as it provides convenient short-cuts for typical mapping scenarios without requiring hard-to-discover static imports. For instance, the router function builder offers the method to create a mapping for GET requests; and for POSTs. Besides HTTP method-based mapping, the route builder offers a way to introduce additional predicates when mapping to requests. For each HTTP method there is an overloaded variant that takes a as a parameter, though which additional constraints can be expressed. You can write your own , but the utility class offers commonly used implementations, based on the request path, HTTP method, content-type, and so on. The following example uses a request predicate to create a constraint based on the header: You can compose multiple request predicates together by using: Many of the predicates from are composed. For example, is composed from and . The example shown above also uses two request predicates, as the builder uses internally, and composes that with the predicate. Router functions are evaluated in order: if the first route does not match, the second is evaluated, and so on. Therefore, it makes sense to declare more specific routes before general ones. This is also important when registering router functions as Spring beans, as will be described later. Note that this behavior is different from the annotation-based programming model, where the \"most specific\" controller method is picked automatically. When using the router function builder, all defined routes are composed into one that is returned from . There are also other ways to compose multiple router functions together: The following example shows the composition of four routes: with an header that matches JSON is routed to with an header that matches JSON is routed to with no additional predicates is mapped to , and is a router function that is created elsewhere, and added to the route built. with an header that matches JSON is routed to with an header that matches JSON is routed to with no additional predicates is mapped to , and is a router function that is created elsewhere, and added to the route built. It is common for a group of router functions to have a shared predicate, for instance a shared path. In the example above, the shared predicate would be a path predicate that matches , used by three of the routes. When using annotations, you would remove this duplication by using a type-level annotation that maps to . In WebFlux.fn, path predicates can be shared through the method on the router function builder. For instance, the last few lines of the example above can be improved in the following way by using nested routes: Note that second parameter of is a consumer that takes the router builder. Create router using Coroutines router DSL; a Reactive alternative is also available via . Though path-based nesting is the most common, you can nest on any kind of predicate by using the method on the builder. The above still contains some duplication in the form of the shared -header predicate. We can further improve by using the method together with :\n\nSee equivalent in the Servlet stack How do you run a router function in an HTTP server? A simple option is to convert a router function to an by using one of the following: You can then use the returned with a number of server adapters by following HttpHandler for server-specific instructions. A more typical option, also used by Spring Boot, is to run with a -based setup through the WebFlux Config, which uses Spring configuration to declare the components required to process requests. The WebFlux Java configuration declares the following infrastructure components to support functional endpoints:\n• : Detects one or more beans in the Spring configuration, orders them, combines them through , and routes requests to the resulting composed .\n• : Simple adapter that lets invoke a that was mapped to a request.\n• : Handles the result from the invocation of a by invoking the method of the . The preceding components let functional endpoints fit within the request processing lifecycle and also (potentially) run side by side with annotated controllers, if any are declared. It is also how functional endpoints are enabled by the Spring Boot WebFlux starter. The following example shows a WebFlux Java configuration (see DispatcherHandler for how to run it):\n\nSee equivalent in the Servlet stack You can filter handler functions by using the , , or methods on the routing function builder. With annotations, you can achieve similar functionality by using , a , or both. The filter will apply to all routes that are built by the builder. This means that filters defined in nested routes do not apply to \"top-level\" routes. For instance, consider the following example: The filter that adds a custom request header is only applied to the two GET routes. The filter that logs the response is applied to all routes, including the nested ones. val route = router { \"/person\".nest { GET(\"/{id}\", handler::getPerson) GET(\"\", handler::listPeople) before { (1) ServerRequest.from(it) .header(\"X-RequestHeader\", \"Value\").build() } POST(handler::createPerson) after { _, response -> (2) logResponse(response) } } } The filter that adds a custom request header is only applied to the two GET routes. The filter that logs the response is applied to all routes, including the nested ones. The method on the router builder takes a : a function that takes a and and returns a . The handler function parameter represents the next element in the chain. This is typically the handler that is routed to, but it can also be another filter if multiple are applied. Now we can add a simple security filter to our route, assuming that we have a that can determine whether a particular path is allowed. The following example shows how to do so: SecurityManager securityManager = ... RouterFunction<ServerResponse> route = route() .path(\"/person\", b1 -> b1 .nest(accept(APPLICATION_JSON), b2 -> b2 .GET(\"/{id}\", handler::getPerson) .GET(handler::listPeople)) .POST(handler::createPerson)) .filter((request, next) -> { if (securityManager.allowAccessTo(request.path())) { return next.handle(request); } else { return ServerResponse.status(UNAUTHORIZED).build(); } }) .build(); val securityManager: SecurityManager = ... val route = router { (\"/person\" and accept(APPLICATION_JSON)).nest { GET(\"/{id}\", handler::getPerson) GET(\"\", handler::listPeople) POST(handler::createPerson) filter { request, next -> if (securityManager.allowAccessTo(request.path())) { next(request) } else { status(UNAUTHORIZED).build(); } } } } The preceding example demonstrates that invoking the is optional. We only let the handler function be run when access is allowed. Besides using the method on the router function builder, it is possible to apply a filter to an existing router function via . CORS support for functional endpoints is provided through a dedicated ."
    },
    {
        "link": "https://stackoverflow.com/questions/49049383/how-to-register-multiple-routerfunctions-in-spring-5-webflux-via-routerfunctionm",
        "document": "Based on the webflux documents, it is possible to scan the RouterFunctions with RouterFunctionMapping:\n\nRouterFunctionMapping — detects one or more RouterFunction beans in the Spring configuration, combines them via RouterFunction.andOther, and routes requests to the resulting composed RouterFunction.\n\nAre there any good samples for registering the handlers?"
    },
    {
        "link": "https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/reactive/function/server/RouterFunctions.html",
        "document": "Exposes routing functionality, such as to create using a discoverable builder-style API, to create given aand, and to do further subrouting on an existing routing function.\n\nAdditionally, this class can transform a into an , which can be run in Servlet environments, Reactor, or Undertow."
    },
    {
        "link": "https://stackoverflow.com/questions/52112751/how-to-use-routerfunction-of-spring-5-in-web-project",
        "document": "Your application depends on , as described in the Spring Boot reference documentation, this will make your application a Spring MVC app. So you should first figure out what's bringing that dependency and remove it from your build.\n\nNext, it seems your app doesn't have a annotated class; if you want a good starting point, you should create your app using start.spring.io and select the webflux starter.\n\nNext, Spring Boot doesn't need nor support files. You should read up about Spring Boot in its reference documentation or take a look at the Spring guides.\n\nSpring WebFlux doesn't support JSPs, so there's no need to configure an internalviewresolver nor add JSP files in your app. You should instead look for a modern view technology like mustache, thymeleaf, etc (all listed on start.spring.io).\n\nYou can of course use Spring WebFlux without Spring Boot, but it requires manual setup and deployment (in an embedded or external container). I'd argue that Spring Boot is by far the easiest way."
    },
    {
        "link": "https://baeldung.com/spring-5-functional-web",
        "document": "Spring WebFlux is a new functional web framework built using reactive principles.\n\nIn this tutorial, we’ll learn how to work with it in practice.\n\nWe’ll base this off of our existing guide to Spring 5 WebFlux. In that guide, we created a simple reactive REST application using annotation-based components. Here, we’ll use the functional framework instead.\n\nWe’ll need the same spring-boot-starter-webflux dependency as defined in the previous article:\n\nThe functional web framework introduces a new programming model where we use functions to route and handle requests.\n\nAs opposed to the annotation-based model where we use annotations mappings, here we’ll use HandlerFunction and RouterFunctions.\n\nSimilarly, as in the annotated controllers, the functional endpoints approach is built on the same reactive stack.\n\nThe HandlerFunction represents a function that generates responses for requests routed to them:\n\nThis interface is primarily a Function<Request, Response<T>>, which behaves very much like a servlet.\n\nAlthough, compared to a standard Servlet#service(ServletRequest req, ServletResponse res), HandlerFunction doesn’t take a response as an input parameter.\n\nRouterFunction serves as an alternative to the @RequestMapping annotation. We can use it to route requests to the handler functions:\n\nTypically, we can import the helper function RouterFunctions.route() to create routes, instead of writing a complete router function.\n\nIt allows us to route requests by applying a RequestPredicate. When the predicate is matched, then the second argument, the handler function, is returned:\n\nBecause the route() method returns a RouterFunction, we can chain it to build powerful and complex routing schemes.\n\nIn our previous guide, we created a simple EmployeeManagement REST application using @RestController and WebClient.\n\nNow, let’s implement the same logic using router and handler functions.\n\nFirst, we need to create routes using RouterFunction to publish and consume our reactive streams of Employees.\n\nRoutes are registered as Spring beans and can be created inside any configuration class.\n\nLet’s create our first route using RouterFunction that publishes a single Employee resource:\n\nThe first argument is a request predicate. Notice how we used a statically imported RequestPredicates.GET method here. The second parameter defines a handler function that’ll be used if the predicate applies.\n\nIn other words, the above example routes all the GET requests for /employees/{id} to EmployeeRepository#findEmployeeById(String id) method.\n\nNext, for publishing a collection resource, let’s add another route:\n\nWe can also compose the routes together in a single router function.\n\nLet’s see how to combine the routes created above:\n\nHere, we’ve used RouterFunction.and() to combine our routes.\n\nFinally, we’ve implemented the complete REST API needed for our EmployeeManagement application, using routers and handlers.\n\nTo run the application, we can either use separate routes or the single, composed one that we created above.\n\nWe can use WebTestClient to test our routes.\n\nTo do so, we first need to bind the routes using the bindToRouterFunction method and then build the test client instance.\n\nWe can also test our updateEmployeeRoute by asserting that our Employee instance is updated via EmployeeRepository:\n\nFor more details on testing with WebTestClient please refer to our tutorial on working with WebClient and WebTestClient.\n\nIn this tutorial, we introduced the new functional web framework in Spring 5 and looked into its two core interfaces – RouterFunction and HandlerFunction. We also learned how to create various routes to handle the request and send the response.\n\nAdditionally, we recreated our EmployeeManagement application introduced in guide to Spring 5 WebFlux with the functional endpoints model."
    },
    {
        "link": "https://medium.com/@contactshubham/best-practices-of-using-autowired-annotation-in-spring-boot-6675cf7e8d9b",
        "document": "In this post, I will explain how to use annotation to utilize its goodness in the best and safest way by preferring Constructor Injection Over Field Injection. I will explain all the logic as simply as possible and through examples.\n\nWhat actually does?\n\nI have seen many posts/articles to avoid the use of annotation due to security concerns. That’s why I decided to write this post to show how to use it for automatically injecting dependencies without any security concerns.\n\nBefore we dive into how to use the annotation for dependency injection via Constructor Injection, let’s look at the most common way people use to inject dependencies:\n\nIn the code above, we are injecting a class into the class to access all of its methods, including sub-methods injected by the rest of the annotations.\n\nIt allows anyone (in different class outside/inside the Spring container) to create an instance using default constructor (like ), which is NOT good as you need object (as a dependency) for\n\n1. Bean Instance: The annotation injects a fully initialized instance of a bean. This implies that all dependencies of the injected bean have already been resolved and injected.\n\n2. Dependency Resolution: It finds the required beans in the application context.\n\n3. Injection: It injects the found beans into your class fields, constructors, or methods.\n\n4. Proxy Creation: If needed, it wraps beans with proxies for additional features such as transactions.\n\n5. Lifecycle Management: Spring ensures that all dependencies are ready and manages initialization and destruction.\n\nLet’s dive deeper into our main concern to properly use the annotation. The secure and efficient way to use is through constructor injection.\n\nConstructor injection ensures that the dependencies are provided when the class is instantiated, making the dependencies explicit and immutable. This approach improves code readability, maintainability, and testability.\n\nHere’s how we have to inject the dependencies using constructor injection:\n\nBenefits of using through constructor injection:\n• Explicit Dependencies: The dependencies are clearly identified. There is no way to forget one when testing, or instantiating the object in any other circumstance (like creating the bean instance explicitly in a config class)\n• Immutability: The keyword ensures that the injected dependencies cannot be changed after they’re set, which helps with robustness and thread-safety.\n• Easier Testing: You don’t need reflection to set the dependencies. InjectMocks is still usable, but not necessary. You can just create mocks by yourself and inject them by simply calling the constructor.\n\nConstructor injection does NOT allow to create object without actually resolving the dependency.\n\nFinally, I demonstrated the difference between directly injecting a class into another class using the annotation on fields and injecting the class through constructor injection using the annotation which helps you to enforce immutability, improve testability, and better manage dependencies in your Spring Boot applications. Embracing constructor injection ensures clearer code and reduces potential issues with dependency injection.\n\nPro Tip: If there is only one constructor call, there is no need to include the annotation. You can use something like this:"
    },
    {
        "link": "https://springframework.guru/best-practices-for-dependency-injection-with-spring",
        "document": "Last Updated on December 18, 2019 by jt\n\nIn this post, I’m going to show you how to use Project Lombok for best practices in dependency injection with the Spring Framework.\n\nThe Spring Framework itself has a variety of different ways we can perform dependency injection. The flexibility of options is a strength of the Spring Framework. However, not all of the dependency injection options are considered best practices. Some, are actually very poor.\n\nI’ve setup examples for us to review the different dependency injection options we have to work with.\n\nLet’s use an example Spring Service. For our purposes, the service has one method that returns a string. We’ll take our ‘service’ and use Spring to inject it into some faux controllers. Keep in mind, we’re just exploring how we can do dependency injection with the Spring Framework.\n\nOur field controller has one public property for the service. We can annotate this field, and Spring will inject an instance of the service.\n\nThis is just a public property, and does not have a setter. Clearly, this is not a good practice. Nor is it recommended.\n\nWe can improve on this slightly, and make the access to the field private. The Spring Framework does allow you to autowire private fields. You do see people doing this. And Spring will perform some reflection magic to perform dependency injection.\n\nWhile better than just using a private field, testing becomes a headache. You either need to bring up the Spring Context, or use some Spring utilities to perform dependency injection for testing. Not the end of the world, but generally annoying.\n\nWe can improve upon this by providing a setter for the private property. Getters and setters are generally considered best practices in object oriented programming. Its trivial to instruct Spring to use the setter for dependency injection by annotating the setter method.\n\nThis is a clear improvement upon using a private field. Some will complain this is too much code to write. But reality, tasks like this have been automated in modern IDEs since season one of South Park.\n\nThe next option is to use a constructor. This is the best method we have looked at so far. When using a constructor to set injected properties, you do not have to provide the autowire annotation. This is a nice feature, which saves us a bit of typing. Annotation of constructors for dependency injection has been optional since Spring Framework version 4.2.\n\nConstructor based dependency injection is certainly considered a best practice. There was a time I personally favored setter based injection, but have come around to constructor based.\n\nWe can still improve our example. There are two main concerns right now. One, the type of our service is a concrete type. Dependency injection of a hard type is not considered a best practice.\n\nThe second problem is, the property we are injecting is not declared final. Thus, in theory, the class could modify the injected property after it was instantiated.\n\nBest practices for dependency injection is to utilize interfaces, constructors, and final properties.\n\nI’ve setup a ‘best practice’ service interface, and provided a service implementation – which is annotated with the Spring Service annotation.\n\nNow, the secret sauce using Project Lombok for best practices in dependency injection is to:\n\nNow, Project Lombok will generate a constructor for all properties declared final. And Spring will automatically use the Lombok provided constructor to autowire the clase.\n\nThis is a real nice way of doing this. Your code stays very clean. When working with Spring, it’s not uncommon to need several autowired properties.\n\nWhen you need to add another bean, simply declare a final property.\n\nIf you refactor, and no longer need a Spring managed dependency, just delete the final property.\n\nYou’re no longer maintaining setters or constructor code. Project Lombok alleviates this mundane task from you.\n\nI’ve been using this technique for sometime now in my day to day coding. It’s definitely a timesaver. And leads to cleaner code. Gone are unused properties and unused constructor parameters. Refactoring is just a little less painful now!\n\nSource code for this post is available here on GitHub."
    },
    {
        "link": "https://geeksforgeeks.org/spring-autowired-annotation",
        "document": ""
    },
    {
        "link": "https://baeldung.com/spring-annotations-resource-inject-autowire",
        "document": "In this Spring Framework tutorial, we’ll demonstrate how to use annotations related to dependency injection, namely the @Resource, @Inject, and @Autowired annotations. These annotations provide classes with a declarative way to resolve dependencies:\n\nAs opposed to instantiating them directly (the imperative way):\n\nTwo of the three annotations belong to the Java extension package: javax.annotation.Resource and javax.inject.Inject. The @Autowired annotation belongs to the org.springframework.beans.factory.annotation package.\n\nEach of these annotations can resolve dependencies either by field injection or by setter injection. We’ll use a simplified, but practical example to demonstrate the distinction between the three annotations, based on the execution paths taken by each annotation.\n\nThe examples will focus on how to use the three injection annotations during integration testing. The dependency required by the test can either be an arbitrary file or an arbitrary class.\n\nThe @Resource annotation is part of the JSR-250 annotation collection, and is packaged with Jakarta EE. This annotation has the following execution paths, listed by precedence:\n\nThese execution paths are applicable to both setter and field injection.\n\nWe can resolve dependencies by field injection by annotating an instance variable with the @Resource annotation.\n\nWe’ll use the following integration test to demonstrate match-by-name field injection:\n\nLet’s go through the code. In the FieldResourceInjectionTest integration test, at line 7, we resolved the dependency by name by passing in the bean name as an attribute value to the @Resource annotation:\n\nThis configuration will resolve dependencies using the match-by-name execution path. We must define the bean namedFile in the ApplicationContextTestResourceNameType application context.\n\nNote that the bean id and the corresponding reference attribute value must match:\n\nIf we fail to define the bean in the application context, it will result in an org.springframework.beans.factory.NoSuchBeanDefinitionException being thrown. We can demonstrate this by changing the attribute value passed into the @Bean annotation in the ApplicationContextTestResourceNameType application context, or changing the attribute value passed into the @Resource annotation in the FieldResourceInjectionTest integration test.\n\nTo demonstrate the match-by-type execution path, we just remove the attribute value at line 7 of the FieldResourceInjectionTest integration test:\n\nThen we run the test again.\n\nThe test will still pass because if the @Resource annotation doesn’t receive a bean name as an attribute value, the Spring Framework will proceed with the next level of precedence, match-by-type, in order to try resolve the dependency.\n\nTo demonstrate the match-by-qualifier execution path, the integration testing scenario will be modified so that there are two beans defined in the ApplicationContextTestResourceQualifier application context:\n\nWe’ll use the QualifierResourceInjectionTest integration test to demonstrate match-by-qualifier dependency resolution. In this scenario, a specific bean dependency needs to be injected into each reference variable:\n\nWhen we run the integration test, an org.springframework.beans.factory.NoUniqueBeanDefinitionException will be thrown. This will happen because the application context will find two bean definitions of type File, and won’t know which bean should resolve the dependency.\n\nTo resolve this issue, we need to refer to line 7 to line 10 of the QualifierResourceInjectionTest integration test:\n\nWe have to add the following lines of code:\n\nSo that the code block looks as follows:\n\nWhen we run the integration test again, it should pass. Our test demonstrates that even if we define multiple beans in an application context, we can use the @Qualifier annotation to clear any confusion by allowing us to inject specific dependencies into a class.\n\nThe execution paths taken when injecting dependencies on a field are applicable to setter-based injection as well.\n\nThe only difference is the MethodResourceInjectionTest integration test has a setter method:\n\nWe resolve dependencies by setter injection by annotating a reference variable’s corresponding setter method. Then we pass the name of the bean dependency as an attribute value to the @Resource annotation:\n\nWe’ll reuse the namedFile bean dependency in this example. The bean name and the corresponding attribute value must match.\n\nWhen we run the integration test, it will pass.\n\nIn order for us to verify that the match-by-name execution path resolved the dependency, we need to change the attribute value passed to the @Resource annotation to a value of our choice and run the test again. This time, the test will fail with a NoSuchBeanDefinitionException.\n\nTo demonstrate setter-based, match-by-type execution, we will use the MethodByTypeResourceTest integration test:\n\nWhen we run this test, it will pass.\n\nIn order for us to verify that the match-by-type execution path resolved the File dependency, we need to change the class type of the defaultFile variable to another class type like String. Then we can execute the MethodByTypeResourceTest integration test again, and this time a NoSuchBeanDefinitionException will be thrown.\n\nThe exception verifies that match-by-type was indeed used to resolve the File dependency. The NoSuchBeanDefinitionException confirms that the reference variable name doesn’t need to match the bean name. Instead, dependency resolution depends on the bean’s class type matching the reference variable’s class type.\n\nWe will use the MethodByQualifierResourceTest integration test to demonstrate the match-by-qualifier execution path:\n\nOur test demonstrates that even if we define multiple bean implementations of a particular type in an application context, we can use a @Qualifier annotation together with the @Resource annotation to resolve a dependency.\n\nSimilar to field-based dependency injection, if we define multiple beans in an application context, we must use a @Qualifier annotation to specify which bean to use to resolve dependencies, or a NoUniqueBeanDefinitionException will be thrown.\n\nThe @Inject annotation belongs to the JSR-330 annotations collection. This annotation has the following execution paths, listed by precedence:\n\nThese execution paths are applicable to both setter and field injection. In order for us to access the @Inject annotation, we have to declare the javax.inject library as a Gradle or Maven dependency.\n\nWe’ll modify the integration test example to use another type of dependency, namely the ArbitraryDependency class. The ArbitraryDependency class dependency merely serves as a simple dependency and holds no further significance:\n\nUnlike the @Resource annotation, which resolves dependencies by name first, the default behavior of the @Inject annotation is to resolve dependencies by type.\n\nThis means that even if the class reference variable name differs from the bean name, the dependency will still be resolved, provided that the bean is defined in the application context. Note how the reference variable name in the following test:\n\ndiffers from the bean name configured in the application context:\n\nWhen we execute the test, we’re able to resolve the dependency.\n\nWhat if there are multiple implementations of a particular class type, and a certain class requires a specific bean? Let’s modify the integration testing example so that it requires another dependency.\n\nIn this example, we subclass the ArbitraryDependency class, used in the match-by-type example, to create the AnotherArbitraryDependency class:\n\nThe objective of each test case is to ensure that we inject each dependency correctly into each reference variable:\n\nWe can use the FieldQualifierInjectTest integration test to demonstrate match by qualifier:\n\nIf we have multiple implementations of a particular class in an application context, and the FieldQualifierInjectTest integration test attempts to inject the dependencies in the manner listed below, a NoUniqueBeanDefinitionException will be thrown:\n\nThrowing this exception is the Spring Framework’s way of pointing out that there are multiple implementations of a certain class and it is confused about which one to use. In order to elucidate the confusion, we can go to line 7 and 10 of the FieldQualifierInjectTest integration test:\n\nWe can pass the required bean name to the @Qualifier annotation, which we use together with the @Inject annotation. This is how the code block will now look:\n\nThe @Qualifier annotation expects a strict match when receiving a bean name. We must ensure that the bean name is passed to the Qualifier correctly, otherwise, a NoUniqueBeanDefinitionException will be thrown. If we run the test again, it should pass.\n\nThe FieldByNameInjectTest integration test used to demonstrate match by name is similar to the match by type execution path. The only difference is now we require a specific bean, as opposed to a specific type. In this example, we subclass the ArbitraryDependency class again to produce the YetAnotherArbitraryDependency class:\n\nIn order to demonstrate the match-by-name execution path, we will use the following integration test:\n\nIf we run the integration test, it will pass.\n\nIn order to verify that we injected the dependency by the match-by-name execution path, we need to change the value, yetAnotherFieldInjectDependency, that was passed in to the @Named annotation to another name of our choice. When we run the test again, a NoSuchBeanDefinitionException will be thrown.\n\nSetter-based injection for the @Inject annotation is similar to the approach used for the @Resource setter-based injection. Instead of annotating the reference variable, we annotate the corresponding setter method. The execution paths followed by field-based dependency injection also apply to setter based injection.\n\nThe behaviour of the @Autowired annotation is similar to the @Inject annotation. The only difference is that the @Autowired annotation is part of the Spring framework. This annotation has the same execution paths as the @Inject annotation, listed in order of precedence:\n\nThese execution paths are applicable to both setter and field injection.\n\nThe integration testing example used to demonstrate the @Autowired match-by-type execution path will be similar to the test used to demonstrate the @Inject match-by-type execution path. We use the following FieldAutowiredTest integration test to demonstrate match-by-type using the @Autowired annotation:\n\nWe list the application context for this integration test:\n\nWe use this integration test to demonstrate that match-by-type takes first precedence over the other execution paths. Notice the reference variable name on line 8 of the FieldAutowiredTest integration test:\n\nThis is different than the bean name in the application context:\n\nWhen we run the test, it should pass.\n\nIn order to confirm that the dependency was indeed resolved using the match-by-type execution path, we need to change the type of the fieldDependency reference variable and run the integration test again. This time, the FieldAutowiredTest integration test will fail, with a NoSuchBeanDefinitionException being thrown. This verifies that we used match-by-type to resolve the dependency.\n\nWhat if we’re faced with a situation where we’ve defined multiple bean implementations in the application context:\n\nIf we execute the following FieldQualifierAutowiredTest integration test, a NoUniqueBeanDefinitionException will be thrown:\n\nThe exception is due to the ambiguity caused by the two beans defined in the application context. The Spring Framework doesn’t know which bean dependency should be autowired to which reference variable. We can resolve this issue by adding the @Qualifier annotation to lines 7 and 10 of the FieldQualifierAutowiredTest integration test:\n\nso that the code block looks as follows:\n\nWhen we run the test again, it will pass.\n\nWe’ll use the same integration test scenario to demonstrate the match-by-name execution path using the @Autowired annotation to inject a field dependency. When autowiring dependencies by name, the @ComponentScan annotation must be used with the application context, ApplicationContextTestAutowiredName:\n\nWe use the @ComponentScan annotation to search packages for Java classes that have been annotated with the @Component annotation. For example, in the application context, the com.baeldung.dependency package will be scanned for classes that have been annotated with the @Component annotation. In this scenario, the Spring Framework must detect the ArbitraryDependency class, which has the @Component annotation:\n\nThe attribute value, autowiredFieldDependency, passed into the @Component annotation, tells the Spring Framework that the ArbitraryDependency class is a component named autowiredFieldDependency. In order for the @Autowired annotation to resolve dependencies by name, the component name must correspond with the field name defined in the FieldAutowiredNameTest integration test; please refer to line 8:\n\nWhen we run the FieldAutowiredNameTest integration test, it will pass.\n\nBut how do we know that the @Autowired annotation really did invoke the match-by-name execution path? We can change the name of the reference variable autowiredFieldDependency to another name of our choice, then run the test again.\n\nThis time, the test will fail and a NoUniqueBeanDefinitionException is thrown. A similar check would be to change the @Component attribute value, autowiredFieldDependency, to another value of our choice and run the test again. A NoUniqueBeanDefinitionException will also be thrown.\n\nThis exception is proof that if we use an incorrect bean name, no valid bean will be found. That’s how we know the match-by-name execution path was invoked.\n\nSetter-based injection for the @Autowired annotation is similar to the approach demonstrated for the @Resource setter-based injection. Instead of annotating the reference variable with the @Inject annotation, we annotate the corresponding setter. The execution paths followed by field-based dependency injection also apply to setter-based injection.\n\nThis raises the question of which annotation should be used and under what circumstances. The answer to these questions depends on the design scenario faced by the application in question, and how the developer wishes to leverage polymorphism based on the default execution paths of each annotation.\n\n5.1. Application-Wide Use of Singletons Through Polymorphism\n\nIf the design is such that application behaviors are based on implementations of an interface or an abstract class, and these behaviors are used throughout the application, then we can use either the @Inject or @Autowired annotation.\n\nThe benefit of this approach is that when we upgrade the application, or apply a patch in order to fix a bug, classes can be swapped out with minimal negative impact to the overall application behavior. In this scenario, the primary default execution path is match-by-type.\n\nIf the design is such that the application has complex behavior, each behavior is based on different interfaces/abstract classes, and the usage of each of these implementations varies across the application, then we can use the @Resource annotation. In this scenario, the primary default execution path is match-by-name.\n\n5.3. Dependency Injection Should Be Handled Solely by the Jakarta EE Platform\n\nIf there is a design mandate for all dependencies to be injected by the Jakarta EE Platform as opposed to Spring, then the choice is between the @Resource annotation and the @Inject annotation. We should narrow down the final decision between the two annotations based on which default execution path is required.\n\n5.4. Dependency Injection Should Be Handled Solely by the Spring Framework\n\nIf the mandate is for all dependencies to be handled by the Spring Framework, the only choice is the @Autowired annotation.\n\nThe table below summarizes our discussion.\n\nIn this article, we aimed to provide a deeper insight into the behavior of each annotation. Understanding how each annotation behaves will contribute to better overall application design and maintenance."
    },
    {
        "link": "https://docs.spring.io/spring-framework/reference/core/beans/annotation-config/autowired.html",
        "document": "Make sure that your target components (for example, or ) are consistently declared by the type that you use for your -annotated injection points. Otherwise, injection may fail due to a \"no type match found\" error at runtime. For XML-defined beans or component classes found via classpath scanning, the container usually knows the concrete type up front. However, for factory methods, you need to make sure that the declared return type is sufficiently expressive. For components that implement several interfaces or for components potentially referred to by their implementation type, consider declaring the most specific return type on your factory method (at least as specific as required by the injection points referring to your bean).\n\nalso considers self references for injection (that is, references back to the bean that is currently injected). Note, however, that self injection is a fallback mechanism. Regular dependencies on other components always have precedence. In that sense, self references do not participate in regular autowiring candidate selection and are therefore in particular never primary. On the contrary, they always end up as lowest precedence. In practice, you should use self references as a last resort only – for example, for calling other methods on the same instance through the bean’s transactional proxy. As an alternative, consider factoring out the affected methods to a separate delegate bean in such a scenario. Another alternative is to use , which may obtain a proxy back to the current bean by its unique name. Trying to inject the results from methods in the same class is effectively a self-reference scenario as well. Either lazily resolve such references in the method signature where it is actually needed (as opposed to an autowired field in the configuration class) or declare the affected methods as , decoupling them from the containing configuration class instance and its lifecycle. Otherwise, such beans are only considered in the fallback phase, with matching beans on other configuration classes selected as primary candidates instead (if available).\n\nYour target beans can implement the interface or use the or standard annotation if you want items in the array or list to be sorted in a specific order. Otherwise, their order follows the registration order of the corresponding target bean definitions in the container. You can declare the annotation at the target class level and on methods, potentially for individual bean definitions (in case of multiple definitions that use the same bean class). values may influence priorities at injection points, but be aware that they do not influence singleton startup order, which is an orthogonal concern determined by dependency relationships and declarations. Note that annotations on configuration classes just influence the evaluation order within the overall set of configuration classes on startup. Such configuration-level order values do not affect the contained methods at all. For bean-level ordering, each method needs to have its own annotation which applies within a set of multiple matches for the specific bean type (as returned by the factory method). Note that the standard annotation is not available at the level, since it cannot be declared on methods. Its semantics can be modeled through values in combination with on a single bean for each type.\n\nInjected constructor and factory method arguments are a special case since the attribute in has a somewhat different meaning due to Spring’s constructor resolution algorithm that may potentially deal with multiple constructors. Constructor and factory method arguments are effectively required by default but with a few special rules in a single-constructor scenario, such as multi-element injection points (arrays, collections, maps) resolving to empty instances if no matching beans are available. This allows for a common implementation pattern where all dependencies can be declared in a unique multi-argument constructor — for example, declared as a single public constructor without an annotation.\n\nOnly one constructor of any given bean class may declare with the attribute set to , indicating the constructor to autowire when used as a Spring bean. As a consequence, if the attribute is left at its default value , only a single constructor may be annotated with . If multiple constructors declare the annotation, they will all have to declare in order to be considered as candidates for autowiring (analogous to in XML). The constructor with the greatest number of dependencies that can be satisfied by matching beans in the Spring container will be chosen. If none of the candidates can be satisfied, then a primary/default constructor (if present) will be used. Similarly, if a class declares multiple constructors but none of them is annotated with , then a primary/default constructor (if present) will be used. If a class only declares a single constructor to begin with, it will always be used, even if not annotated. Note that an annotated constructor does not have to be public."
    }
]