[
    {
        "link": "https://openpyxl.readthedocs.io",
        "document": "It was born from lack of existing library to read/write natively from Python the Office Open XML format. All kudos to the PHPExcel team as openpyxl was initially based on PHPExcel.\n\nThis is an open source project, maintained by volunteers in their spare time. This may well mean that particular features or functions that you would like are missing. But things don’t have to stay that way. You can contribute the project Development yourself or contract a developer for particular features. Professional support for openpyxl is available from Clark Consulting & Research and Adimian. Donations to the project to support further development and maintenance are welcome. Bug reports and feature requests should be submitted using the issue tracker. Please provide a full traceback of any error you see and if possible a sample file. If for reasons of confidentiality you are unable to make a file publicly available then contact of one the developers. The repository is being provided by Octobus and Clever Cloud.\n\nAny help will be greatly appreciated, just follow those steps: 1. Please join the group and create a branch (https://foss.heptapod.net/openpyxl/openpyxl/) and follow the Merge Request Start Guide. for each independent feature, don’t try to fix all problems at the same time, it’s easier for those who will review and merge your changes ;-) 3. Don’t forget to add unit tests for your changes! (YES, even if it’s a one-liner, changes without tests will not be accepted.) There are plenty of examples in the source if you lack know-how or inspiration. 4. If you added a whole new feature, or just improved something, you can be proud of it, so add yourself to the AUTHORS file :-) 5. Let people know about the shiny thing you just implemented, update the docs! 6. When it’s done, just issue a pull request (click on the large “pull request” button on your repository) and wait for your code to be reviewed, and, if you followed all theses steps, merged into the main repository. For further information see Development There are several ways to contribute, even if you can’t code (or can’t code well):\n• None triaging bugs on the bug tracker: closing bugs that have already been closed, are not relevant, cannot be reproduced, …\n• None updating documentation in virtually every area: many large features have been added (mainly about charts and images at the moment) but without any documentation, it’s pretty hard to do anything with it\n• None proposing compatibility fixes for different versions of Python: we support 3.6, 3.7, 3.8 and 3.9."
    },
    {
        "link": "https://geeksforgeeks.org/formatting-cells-using-openpyxl-in-python",
        "document": "When it comes to managing Excel files programmatically, Python offers a powerful tool in the form of the openpyxl library. This library not only allows us to read and write Excel documents but also provides extensive support for cell formatting. From fonts and colors to alignment and borders, openpyxl makes it easy to customize our Excel sheets to fit our needs precisely. In this article, we will learn how to format cells using OpenPyxl\n\nFormatting cells in Excel using the openpyxl library involves several steps that allow us to customize the appearance and functionality of our spreadsheets programmatically. Here's a step-by-step guide to help us get started:\n\nFirst, we need to install the openpyxl library in our Python environment.\n\nWe can create a work book by creating an instance of Workbook class.\n\nEach work book is created with at least one work sheet that we can get using the Workbook.active property. Here, we are modifying the value in the A1 and B1 cell. Lastly saving the file to get the excel file named \"hello_geek.xlsx\".\n\nTo format the font, we need to import Font class from openpyxl.styles. The Font class provides all the functionality to format cell. Let us customize the font style, size, color, and more to enhance text appearance.\n\nHow to Fill Color in Cell\n\nWe can fill color using the PatternFill class from the openpyxl.styles. Here, we are changing the background color of cells to Yellow.\n\nWe can adjust the alignment of the text within cells using the Alignment class from openpyxl.styles\n\nHow to change Border Styles of a cell\n\nWe can modify borders of cells to define areas clearly by using the Border and Side classes from the openpyxl.styles.\n\nApply number formats for displaying financial figures, dates, or other formatted numbers.\n\nHow to save the Workbook\n\nWe can use the Workbook.save() method to save the workbook with a custom name.\n\nThe code demonstrates how to use openpyxl to create and format an Excel sheet. We can enhance this by adding more complex data analysis, charts, or additional formatting to meet specific business needs. This example serves as a foundational guide to creating professional, formatted reports with Python.\n\nBy following these steps, we can fully customize our Excel files using Python. This process not only enhances the presentation of the data but also allows for better readability and professional-quality reports. openpyxl is a powerful tool for anyone looking to automate or enhance their Excel-related tasks programmatically."
    },
    {
        "link": "https://openpyxl.readthedocs.io/en/stable/styles.html",
        "document": "Styles are used to change the look of your data while displayed on screen. They are also used to determine the formatting for numbers. Styles can be applied to the following aspects: The following are the default values\n\nThere are two types of styles: cell styles and named styles, also known as style templates. Cell styles are shared between objects and once they have been assigned they cannot be changed. This stops unwanted side-effects such as changing the style for lots of cells when only one changes. # If you want to change the color of a Font, you need to reassign it::\n\nColours for fonts, backgrounds, borders, etc. can be set in three ways: indexed, aRGB or theme. Indexed colours are the legacy implementation and the colours themselves depend upon the index provided with the workbook or with the application default. Theme colours are useful for complementary shades of colours but also depend upon the theme being present in the workbook. It is, therefore, advisable to use aRGB colours. RGB colours are set using hexadecimal values for red, green and blue. The alpha value refers in theory to the transparency of the colour but this is not relevant for cell styles. The default of 00 will prepended to any simple RGB value: There is also support for legacy indexed colours as well as themes and tints. The indices 64 and 65 cannot be set and are reserved for the system foreground and background colours respectively.\n\nStyles can also applied to columns and rows but note that this applies only to cells created (in Excel) after the file is closed. If you want to apply styles to entire rows and columns then you must apply the style to each cell individually. This is a restriction of the file format: Column dimensions can be grouped, although this is primarily for outline purposes, it can also be used for other attributes, which can be confusing because only the first column of the group will be listed. Use to check.\n\nIn contrast to Cell Styles, Named Styles are mutable. They make sense when you want to apply formatting to lots of different cells at once. NB. once you have assigned a named style to a cell, additional changes to the style will not affect the cell. Once a named style has been registered with a workbook, it can be referred to simply by name.\n\nOnce a named style has been created, it can be registered with the workbook: But named styles will also be registered automatically the first time they are assigned to a cell: Once registered, assign the style using just the name:\n\nThe specification includes some builtin styles which can also be used. Unfortunately, the names for these styles are stored in their localised forms. openpyxl will only recognise the English names and only exactly as written here. These are as follows:\n• None ‘Normal’ # same as no style For more information about the builtin styles please refer to the"
    },
    {
        "link": "https://stackoverflow.com/questions/60524269/formatting-excel-files-in-openpyxl",
        "document": "In my project I create .xlsx file and fill it with data using ws.append([list]). Like that:\n\nHeader row is also added using .append() method.\n\nThe next thing I need to do is to apply one style for a header row (bold font), and another style for the entire table (each cell should have simple borders).\n\nI have tried different methods to do so (primarily on openpyxl.readthedocs.io, and Googled), but none of them worked for me.\n\nIs there a way to apply style for the first row, and apply borders for all of the existing cells in the file? The difficulty is that I have different amount of columns in each row, and unknown amount of rows (a lot of them). The borders should be applied accordingly to the width of the longest row, like at the pic.\n\nSome of the methods I tried:\n\nThese don't even work for a single row/column (1/'A').\n\nThe result of that. The border distribution is somehow not uniform. Some rows are short, some are long, and it looks not satisfying. Besides that, some cells don't have one of the borders or don't have them at all."
    },
    {
        "link": "https://realpython.com/openpyxl-excel-spreadsheets-python",
        "document": "Excel spreadsheets are one of those things you might have to deal with at some point. Either it’s because your boss loves them or because marketing needs them, you might have to learn how to work with spreadsheets, and that’s when knowing comes in handy!\n\nSpreadsheets are a very intuitive and user-friendly way to manipulate large datasets without any prior technical background. That’s why they’re still so commonly used today.\n\nIn this article, you’ll learn how to use openpyxl to:\n• Create simple or more complex spreadsheets, including adding styles, charts, and so on\n\nThis article is written for intermediate developers who have a pretty good knowledge of Python data structures, such as dicts and lists, but also feel comfortable around OOP and more intermediate level topics.\n\nIf you ever get asked to extract some data from a database or log file into an Excel spreadsheet, or if you often have to convert an Excel spreadsheet into some more usable programmatic form, then this tutorial is perfect for you. Let’s jump into the caravan! First things first, when would you need to use a package like in a real-world scenario? You’ll see a few examples below, but really, there are hundreds of possible scenarios where this knowledge could come in handy. You are responsible for tech in an online store company, and your boss doesn’t want to pay for a cool and expensive CMS system. Every time they want to add new products to the online store, they come to you with an Excel spreadsheet with a few hundred rows and, for each of them, you have the product name, description, price, and so forth. Now, to import the data, you’ll have to iterate over each spreadsheet row and add each product to the online store. Say you have a Database table where you record all your users’ information, including name, phone number, email address, and so forth. Now, the Marketing team wants to contact all users to give them some discounted offer or promotion. However, they don’t have access to the Database, or they don’t know how to use SQL to extract that information easily. What can you do to help? Well, you can make a quick script using that iterates over every single User record and puts all the essential information into an Excel spreadsheet. That’s gonna earn you an extra slice of cake at your company’s next birthday party! You may also have to open a spreadsheet, read the information in it and, according to some business logic, append more data to it. For example, using the online store scenario again, say you get an Excel spreadsheet with a list of users and you need to append to each row the total amount they’ve spent in your store. This data is in the Database and, in order to do this, you have to read the spreadsheet, iterate through each row, fetch the total amount spent from the Database and then write back to the spreadsheet. Here’s a quick list of basic terms you’ll see when you’re working with Excel spreadsheets: A Spreadsheet is the main file you are creating or working with. A Sheet is used to split different kinds of content within the same spreadsheet. A Spreadsheet can have one or more Sheets. A Column is a vertical line, and it’s represented by an uppercase letter: A. A Row is a horizontal line, and it’s represented by a number: 1. A Cell is a combination of Column and Row, represented by both an uppercase letter and a number: A1. Now that you’re aware of the benefits of a tool like , let’s get down to it and start by installing the package. For this tutorial, you should use Python 3.7 and openpyxl 2.6.2. To install the package, you can do the following: After you install the package, you should be able to create a super simple spreadsheet with the following code: The code above should create a file called in the folder you are using to run the code. If you open that file with Excel you should see something like this:\n\nLet’s start with the most essential thing one can do with a spreadsheet: read it. You’ll go from a straightforward approach to reading a spreadsheet to more complex examples where you read the data and convert it into more useful Python structures. Before you dive deep into some code examples, you should download this sample dataset and store it somewhere as : Download Dataset: Click here to download the dataset for the openpyxl exercise you’ll be following in this tutorial. This is one of the datasets you’ll be using throughout this tutorial, and it’s a spreadsheet with a sample of real data from Amazon’s online product reviews. This dataset is only a tiny fraction of what Amazon provides, but for testing purposes, it’s more than enough. Finally, let’s start reading some spreadsheets! To begin with, open our sample spreadsheet: In the code above, you first open the spreadsheet using , and then you can use to see all the sheets you have available to work with. After that, selects the first available sheet and, in this case, you can see that it selects Sheet 1 automatically. Using these methods is the default way of opening a spreadsheet, and you’ll see it many times during this tutorial. Now, after opening a spreadsheet, you can easily retrieve data from it like this: To return the actual value of a cell, you need to do . Otherwise, you’ll get the main object. You can also use the method to retrieve a cell using index notation. Remember to add to get the actual value and not a object: You can see that the results returned are the same, no matter which way you decide to go with. However, in this tutorial, you’ll be mostly using the first approach: . Note: Even though in Python you’re used to a zero-indexed notation, with spreadsheets you’ll always use a one-indexed notation where the first row or column always has index . The above shows you the quickest way to open a spreadsheet. However, you can pass additional parameters to change the way a spreadsheet is loaded. There are a few arguments you can pass to that change the way a spreadsheet is loaded. The most important ones are the following two Booleans:\n• read_only loads a spreadsheet in read-only mode allowing you to open very large Excel files.\n• data_only ignores loading formulas and instead loads only the resulting values. Now that you’ve learned the basics about loading a spreadsheet, it’s about time you get to the fun part: the iteration and actual usage of the values within the spreadsheet. This section is where you’ll learn all the different ways you can iterate through the data, but also how to convert that data into something usable and, more importantly, how to do it in a Pythonic way. There are a few different ways you can iterate through the data depending on your needs. You can slice the data with a combination of columns and rows: You can get ranges of rows or columns: # Get all cells from column A # Get all cells for a range of columns # Get all cells from row 5 # Get all cells for a range of rows You’ll notice that all of the above examples return a . If you want to refresh your memory on how to handle in Python, check out the article on Lists and Tuples in Python. There are also multiple ways of using normal Python generators to go through the data. The main methods you can use to achieve this are: Both methods can receive the following arguments: These arguments are used to set boundaries for the iteration: You’ll notice that in the first example, when iterating through the rows using , you get one element per row selected. While when using and iterating through columns, you’ll get one per column instead. One additional argument you can pass to both methods is the Boolean . When it’s set to , the values of the cell are returned, instead of the object: If you want to iterate through the whole dataset, then you can also use the attributes or directly, which are shortcuts to using and without any arguments: These shortcuts are very useful when you’re iterating through the whole dataset. Now that you know the basics of iterating through the data in a workbook, let’s look at smart ways of converting that data into Python structures. As you saw earlier, the result from all iterations comes in the form of . However, since a is nothing more than a that’s immutable, you can easily access its data and transform it into other structures. For example, say you want to extract product information from the spreadsheet and into a dictionary where each key is a product ID. A straightforward way to do this is to iterate over all the rows, pick the columns you know are related to product information, and then store that in a dictionary. Let’s code this out! First of all, have a look at the headers and see what information you care most about: This code returns a list of all the column names you have in the spreadsheet. To start, grab the columns with names: Lucky for you, the columns you need are all next to each other so you can use the and to easily get the data you want: Nice! Now that you know how to get all the important product information you need, let’s put that data into a dictionary: # Using the values_only because you want to return the cells' values # Using json here to be able to format the output for displaying later The code above returns a JSON similar to this: Here you can see that the output is trimmed to 2 products only, but if you run the script as it is, then you should get 98 products. To finalize the reading section of this tutorial, let’s dive into Python classes and see how you could improve on the example above and better structure the data. For this, you’ll be using the new Python Data Classes that are available from Python 3.7. If you’re using an older version of Python, then you can use the default Classes instead. So, first things first, let’s look at the data you have and decide what you want to store and how you want to store it. As you saw right at the start, this data comes from Amazon, and it’s a list of product reviews. You can check the list of all the columns and their meaning on Amazon. There are two significant elements you can extract from the data available: The Review has a few more fields: You can ignore a few of the review fields to make things a bit simpler. So, a straightforward implementation of these two classes could be written in a separate file : After defining your data classes, you need to convert the data from the spreadsheet into these new structures. Before doing the conversion, it’s worth looking at our header again and creating a mapping between columns and the fields you need: Let’s create a file where you have a list of all the field names and their column location (zero-indexed) on the spreadsheet: You don’t necessarily have to do the mapping above. It’s more for readability when parsing the row data, so you don’t end up with a lot of magic numbers lying around. Finally, let’s look at the code needed to parse the spreadsheet data into a list of product and review objects: \\ \\ # Using the read_only method since you're not gonna be editing the spreadsheet # Using the values_only because you just want to return the cell value # You need to parse the date from the spreadsheet into a datetime format After you run the code above, you should get some output like this: That’s it! Now you should have the data in a very simple and digestible class format, and you can start thinking of storing this in a Database or any other type of data storage you like. Using this kind of OOP strategy to parse spreadsheets makes handling the data much simpler later on. Before you start creating very complex spreadsheets, have a quick look at an example of how to append data to an existing spreadsheet. Go back to the first example spreadsheet you created ( ) and try opening it and appending some data to it, like this: # Start by opening the spreadsheet and selecting the main sheet # Write what you want into a specific cell Et voilà, if you open the new spreadsheet, you’ll see the following change:\n\nThere are a lot of different things you can write to a spreadsheet, from simple text or number values to complex formulas, charts, or even images. Previously, you saw a very quick example of how to write “Hello world!” into a spreadsheet, so you can start with that: The highlighted lines in the code above are the most important ones for writing. In the code, you can see that:\n• Line 5 shows you how to create a new empty workbook.\n• Lines 8 and 9 show you how to add data to specific cells.\n• Line 11 shows you how to save the spreadsheet when you’re done. Even though these lines above can be straightforward, it’s still good to know them well for when things get a bit more complicated. Note: You’ll be using the spreadsheet for some of the upcoming examples, so keep it handy. One thing you can do to help with coming code examples is add the following method to your Python file or console: It makes it easier to print all of your spreadsheet values by just calling . Before you get into the more advanced topics, it’s good for you to know how to manage the most simple elements of a spreadsheet. You already learned how to add values to a spreadsheet like this: There’s another way you can do this, by first selecting a cell and then changing its value: The new value is only stored into the spreadsheet once you call . The creates a cell when adding a value, if that cell didn’t exist before: # Before, our spreadsheet has only 1 row # Try adding a value to row 10 As you can see, when trying to add a value to cell , you end up with a tuple with 10 rows, just so you can have that test value. One of the most common things you have to do when manipulating spreadsheets is adding or removing rows and columns. The package allows you to do that in a very straightforward way by using the methods: Every single one of those methods can receive two arguments: Using our basic example again, let’s see how these methods work: # Insert 5 columns between column 2 (\"B\") and 3 (\"C\") # Insert a new row in the beginning # Insert 3 new rows in the beginning The only thing you need to remember is that when inserting new data (rows or columns), the insertion happens before the parameter. So, if you do , it inserts a new row before the existing first row. It’s the same for columns: when you call , it inserts a new column right before the already existing second column ( ). However, when deleting rows or columns, deletes data starting from the index passed as an argument. For example, when doing it deletes row , and when doing it deletes the third column ( ). Sheet management is also one of those things you might need to know, even though it might be something that you don’t use that often. If you look back at the code examples from this tutorial, you’ll notice the following recurring piece of code: This is the way to select the default sheet from a spreadsheet. However, if you’re opening a spreadsheet with multiple sheets, then you can always select a specific one like this: # Let's say you have two sheets: \"Products\" and \"Company Sales\" # You can select a sheet using its title You can also change a sheet title very easily: If you want to create or delete sheets, then you can also do that with and : # You can also define the position to create the sheet at # To remove them, just pass the sheet as an argument to the .remove() One other thing you can do is make duplicates of a sheet using : If you open your spreadsheet after saving the above code, you’ll notice that the sheet Products Copy is a duplicate of the sheet Products. Something that you might want to do when working with big spreadsheets is to freeze a few rows or columns, so they remain visible when you scroll right or down. Freezing data allows you to keep an eye on important rows or columns, regardless of where you scroll in the spreadsheet. Again, also has a way to accomplish this by using the worksheet attribute. For this example, go back to our spreadsheet and try doing the following: If you open the spreadsheet in your favorite spreadsheet editor, you’ll notice that row and columns and are frozen and are always visible no matter where you navigate within the spreadsheet. This feature is handy, for example, to keep headers within sight, so you always know what each column represents. Here’s how it looks in the editor: Notice how you’re at the end of the spreadsheet, and yet, you can see both row and columns and . You can use to add filters and sorts to your spreadsheet. However, when you open the spreadsheet, the data won’t be rearranged according to these sorts and filters. At first, this might seem like a pretty useless feature, but when you’re programmatically creating a spreadsheet that is going to be sent and used by somebody else, it’s still nice to at least create the filters and allow people to use it afterward. The code below is an example of how you would add some filters to our existing spreadsheet: # Check the used spreadsheet space using the attribute \"dimensions\" You should now see the filters created when opening the spreadsheet in your editor: You don’t have to use if you know precisely which part of the spreadsheet you want to apply filters to. Formulas (or formulae) are one of the most powerful features of spreadsheets. They gives you the power to apply specific mathematical equations to a range of cells. Using formulas with is as simple as editing the value of a cell. You can see the list of formulas supported by : Let’s add some formulas to our spreadsheet. Starting with something easy, let’s check the average star rating for the 99 reviews within the spreadsheet: If you open the spreadsheet now and go to cell , you should see that its value is: 4.18181818181818. Have a look in the editor: You can use the same methodology to add any formulas to your spreadsheet. For example, let’s count the number of reviews that had helpful votes: # The helpful votes are counted on column \"I\" You should get the number on your spreadsheet cell like so: You’ll have to make sure that the strings within a formula are always in double quotes, so you either have to use single quotes around the formula like in the example above or you’ll have to escape the double quotes inside the formula: . There are a ton of other formulas you can add to your spreadsheet using the same procedure you tried above. Give it a go yourself! Even though styling a spreadsheet might not be something you would do every day, it’s still good to know how to do it. Using , you can apply multiple styling options to your spreadsheet, including fonts, borders, colors, and so on. Have a look at the documentation to learn more. You can also choose to either apply a style directly to a cell or create a template and reuse it to apply styles to multiple cells. Let’s start by having a look at simple cell styling, using our again as the base spreadsheet: If you open your spreadsheet now, you should see quite a few different styles on the first 5 cells of column :\n• A2 with the text in bold\n• A3 with the text in red and bigger font size\n• A5 with a square border around the text Note: For the colors, you can also use HEX codes instead by doing . You can also combine styles by simply adding them to the cell at the same time: # Reusing the same styles from the example above Have a look at cell here: When you want to apply multiple styles to one or several cells, you can use a class instead, which is like a style template that you can use over and over again. Have a look at the example below: # Now let's apply this to all first row (header) cells If you open the spreadsheet now, you should see that its first row is bold, the text is aligned to the center, and there’s a small bottom border! Have a look below: As you saw above, there are many options when it comes to styling, and it depends on the use case, so feel free to check documentation and see what other things you can do. This feature is one of my personal favorites when it comes to adding styles to a spreadsheet. It’s a much more powerful approach to styling because it dynamically applies styles according to how the data in the spreadsheet changes. In a nutshell, conditional formatting allows you to specify a list of styles to apply to a cell (or cell range) according to specific conditions. For example, a widespread use case is to have a balance sheet where all the negative totals are in red, and the positive ones are in green. This formatting makes it much more efficient to spot good vs bad periods. Without further ado, let’s pick our favorite spreadsheet— —and add some conditional formatting. You can start by adding a simple one that adds a red background to all reviews with less than 3 stars: Now you’ll see all the reviews with a star rating below 3 marked with a red background: Code-wise, the only things that are new here are the objects and :\n• is quite similar to , which you already saw above, and it’s used to aggregate multiple styles such as fonts, borders, alignment, and so forth.\n• is responsible for selecting the cells and applying the styles if the cells match the rule’s logic. Using a object, you can create numerous conditional formatting scenarios. However, for simplicity sake, the package offers 3 built-in formats that make it easier to create a few common conditional formatting patterns. These built-ins are: The ColorScale gives you the ability to create color gradients: # Again, let's add this gradient to the star ratings, column \"H\" Now you should see a color gradient on column , from red to green, according to the star rating: You can also add a third color and make two gradients instead: # Again, let's add this gradient to the star ratings, column \"H\" This time, you’ll notice that star ratings between 1 and 3 have a gradient from red to yellow, and star ratings between 3 and 5 have a gradient from yellow to green: The IconSet allows you to add an icon to the cell according to its value: You’ll see a colored arrow next to the star rating. This arrow is red and points down when the value of the cell is 1 and, as the rating gets better, the arrow starts pointing up and becomes green: The package has a full list of other icons you can use, besides the arrow. Finally, the DataBar allows you to create progress bars: You’ll now see a green progress bar that gets fuller the closer the star rating is to the number 5: As you can see, there are a lot of cool things you can do with conditional formatting. Here, you saw only a few examples of what you can achieve with it, but check the documentation to see a bunch of other options. Even though images are not something that you’ll often see in a spreadsheet, it’s quite cool to be able to add them. Maybe you can use it for branding purposes or to make spreadsheets more personal. To be able to load images to a spreadsheet using , you’ll have to install : Apart from that, you’ll also need an image. For this example, you can grab the Real Python logo below and convert it from to using an online converter such as cloudconvert.com, save the final file as , and copy it to the root folder where you’re running your examples: Afterward, this is the code you need to import that image into the spreadsheet: # Let's use the hello_world spreadsheet since it has less data # A bit of resizing to not fill the whole spreadsheet with the logo You have an image on your spreadsheet! Here it is: The image’s left top corner is on the cell you chose, in this case, . Another powerful thing you can do with spreadsheets is create an incredible variety of charts. Charts are a great way to visualize and understand loads of data quickly. There are a lot of different chart types: bar chart, pie chart, line chart, and so on. has support for a lot of them. Here, you’ll see only a couple of examples of charts because the theory behind it is the same for every single chart type: Note: A few of the chart types that currently doesn’t have support for are Funnel, Gantt, Pareto, Treemap, Waterfall, Map, and Sunburst. For any chart you want to build, you’ll need to define the chart type: , , and so forth, plus the data to be used for the chart, which is called . Before you can build your chart, you need to define what data you want to see represented in it. Sometimes, you can use the dataset as is, but other times you need to massage the data a bit to get additional information. Let’s start by building a new workbook with some sample data: Now you’re going to start by creating a bar chart that displays the total number of sales per product: There you have it. Below, you can see a very straightforward bar chart showing the difference between online product sales online and in-store product sales: Like with images, the top left corner of the chart is on the cell you added the chart to. In your case, it was on cell . Note: Depending on whether you’re using Microsoft Excel or an open-source alternative (LibreOffice or OpenOffice), the chart might look slightly different. Try creating a line chart instead, changing the data a bit: With the above code, you’ll be able to generate some random data regarding the sales of 3 different products across a whole year. Once that’s done, you can very easily create a line chart with the following code: Here’s the outcome of the above piece of code: One thing to keep in mind here is the fact that you’re using when adding the data. This argument makes the chart plot row by row instead of column by column. In your sample data, you see that each product has a row with 12 values (1 column per month). That’s why you use . If you don’t pass that argument, by default, the chart tries to plot by column, and you’ll get a month-by-month comparison of sales. Another difference that has to do with the above argument change is the fact that our now starts from the first column, , instead of the second one. This change is needed because the chart now expects the first column to have the titles. There are a couple of other things you can also change regarding the style of the chart. For example, you can add specific categories to the chart: Add this piece of code before saving the workbook, and you should see the month names appearing instead of numbers: Code-wise, this is a minimal change. But in terms of the readability of the spreadsheet, this makes it much easier for someone to open the spreadsheet and understand the chart straight away. Another thing you can do to improve the chart readability is to add an axis. You can do it using the attributes and : This will generate a spreadsheet like the below one: As you can see, small changes like the above make reading your chart a much easier and quicker task. There is also a way to style your chart by using Excel’s default property. In this case, you have to choose a number between 1 and 48. Depending on your choice, the colors of your chart change as well: # You can play with this by choosing any number between 1 and 48 With the style selected above, all lines have some shade of orange: There is no clear documentation on what each style number looks like, but this spreadsheet has a few examples of the styles available. Here’s the full code used to generate the line chart with categories, axis titles, and style: There are a lot more chart types and customization you can apply, so be sure to check out the package documentation on this if you need some specific formatting. You already saw how to convert an Excel spreadsheet’s data into Python classes, but now let’s do the opposite. Let’s imagine you have a database and are using some Object-Relational Mapping (ORM) to map DB objects into Python classes. Now, you want to export those same objects into a spreadsheet. Let’s assume the following data classes to represent the data coming from your database regarding product sales: Now, let’s generate some random data, assuming the above classes are stored in a file: # Ignore these for now. You'll use them in a sec ;) By running this piece of code, you should get 5 products with 5 months of sales with a random quantity of sales for each month. Now, to convert this into a spreadsheet, you need to iterate over the data and append it to the spreadsheet: That’s it. That should allow you to create a spreadsheet with some data coming from your database. However, why not use some of that cool knowledge you gained recently to add a chart as well to display that data more visually? All right, then you could probably do something like this: Now we’re talking! Here’s a spreadsheet generated from database objects and with a chart and everything: That’s a great way for you to wrap up your new knowledge of charts! Even though you can use Pandas to handle Excel files, there are few things that you either can’t accomplish with Pandas or that you’d be better off just using directly. For example, some of the advantages of using are the ability to easily customize your spreadsheet with styles, conditional formatting, and such. But guess what, you don’t have to worry about picking. In fact, has support for both converting data from a Pandas DataFrame into a workbook or the opposite, converting an workbook into a Pandas DataFrame. Note: If you’re new to Pandas, check our course on Pandas DataFrames beforehand. First things first, remember to install the package: Now that you have some data, you can use to convert it from a DataFrame into a worksheet: You should see a spreadsheet that looks like this: If you want to add the DataFrame’s index, you can change , and it adds each row’s index into your spreadsheet. On the other hand, if you want to convert a spreadsheet into a DataFrame, you can also do it in a very straightforward way like so: Alternatively, if you want to add the correct headers and use the review ID as the index, for example, then you can also do it like this instead: # Set the first row as the columns for the DataFrame # Set the field \"review_id\" as the indexes for each row Using indexes and columns allows you to access data from your DataFrame easily: # Grab review with id \"R2EQL1V1L6E0C9\", using the index There you go, whether you want to use to prettify your Pandas dataset or use Pandas to do some hardcore algebra, you now know how to switch between both packages."
    },
    {
        "link": "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html",
        "document": "Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv. If you want to pass in a path object, pandas accepts any . By file-like object, we refer to objects with a method, such as a file handle (e.g. via builtin function) or .\n\nRow number(s) containing column labels and marking the start of the data (zero-indexed). Default behavior is to infer the column names: if no are passed the behavior is identical to and column names are inferred from the first line of the file, if column names are passed explicitly to then the behavior is identical to . Explicitly pass to be able to replace existing names. The header can be a list of integers that specify row locations for a on the columns e.g. . Intervening rows that are not specified will be skipped (e.g. 2 in this example is skipped). Note that this parameter ignores commented lines and empty lines if , so denotes the first line of data rather than the first line of the file.\n\nColumn(s) to use as row label(s), denoted either by column labels or column indices. If a sequence of labels or indices is given, will be formed for the row labels. Note: can be used to force pandas to not use the first column as the index, e.g., when you have a malformed file with delimiters at the end of each line.\n\nSubset of columns to select, denoted either by column labels or column indices. If list-like, all elements must either be positional (i.e. integer indices into the document columns) or strings that correspond to column names provided either by the user in or inferred from the document header row(s). If are given, the document header row(s) are not taken into account. For example, a valid list-like parameter would be or . Element order is ignored, so is the same as . To instantiate a from with element order preserved use for columns in order or for order. If callable, the callable function will be evaluated against the column names, returning names where the callable function evaluates to . An example of a valid callable argument would be . Using this parameter results in much faster parsing time and lower memory usage.\n\nWhether or not to include the default values when parsing the data. Depending on whether is passed in, the behavior is as follows:\n• None If is , and are specified, is appended to the default values used for parsing.\n• None If is , and are not specified, only the default values are used for parsing.\n• None If is , and are specified, only the values specified are used for parsing.\n• None If is , and are not specified, no strings will be parsed as . Note that if is passed in as , the and parameters will be ignored.\n\nFunction to use for converting a sequence of string columns to an array of instances. The default uses to do the conversion. pandas will try to call in three different ways, advancing to the next if an exception occurs: 1) Pass one or more arrays (as defined by ) as arguments; 2) concatenate (row-wise) the string values from the columns defined by into a single array and pass that; and 3) call once for each row using one or more strings (corresponding to the columns defined by ) as arguments. Deprecated since version 2.0.0: Use instead, or read in as and then apply as-needed.\n\nFor on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is path-like, then detect compression from the following extensions: ‘.gz’, ‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’ (otherwise no compression). If using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in. Set to for no decompression. Can also be a dict with key set to one of { , , , , , } and other key-value pairs are forwarded to , , , , or , respectively. As an example, the following could be passed for Zstandard decompression using a custom compression dictionary: ."
    },
    {
        "link": "https://geeksforgeeks.org/python-read-csv-using-pandas-read_csv",
        "document": "CSV files are the Comma Separated Files. It allows users to load tabular data into a DataFrame, which is a powerful structure for data manipulation and analysis. To access data from the CSV file, we require a function read_csv() from Pandas that retrieves data in the form of the data frame. Here’s a quick example to get you started.\n\nSuppose you have a file named people.csv First, we must import the Pandas library. then using Pandas load this data into a DataFrame as follows:\n\nfunction in Pandas is used to read data from CSV files into a Pandas DataFrame. A DataFrame is a powerful data structure that allows you to manipulate and analyze tabular data efficiently. CSV files are plain-text files where each row represents a record, and columns are separated by commas (or other delimiters).\n\nHere is the Pandas read CSV syntax with its parameters.\n\nThe parameter allows to load only specific columns from a CSV file. This reduces memory usage and processing time by importing only the required data.\n\nThe parameter sets one or more columns as the DataFrame index, making the specified column(s) act as row labels for easier data referencing.\n\nThe parameter replaces specified strings (e.g., , ) with , enabling consistent handling of missing or incomplete data during analysis.\\\n\nWe won’t got nan values as there is no missing value in our dataset.\n\nIn this example, we will take a CSV file and then add some special characters to see how the sep parameter works.\n\nThe sample data is stored in a multi-line string for demonstration purposes.\n• Engine argument is used because the default C engine does not support regular expressions for delimiters.\n\nThe parameter limits the number of rows read from a file, enabling quick previews or partial data loading for large datasets. Here, we just display only 5 rows using nrows parameter.\n\nThe parameter skips unnecessary rows at the start of a file, which is useful for ignoring metadata or extra headers that are not part of the dataset.\n\nThe parameter converts date columns into datetime objects, simplifying operations like filtering, sorting, or time-based analysis.\n\nPandas allows you to directly read a CSV file hosted on the internet using the file’s URL. This can be incredibly useful when working with datasets shared on websites, cloud storage, or public repositories like GitHub.\n\nHow to read pandas DataFrame to csv?\n\nHow to extract data from CSV file in Python using pandas?\n\nHow to read CSV string in pandas?"
    },
    {
        "link": "https://pandas.pydata.org/docs/getting_started/intro_tutorials/02_read_write.html",
        "document": "Pclass: One out of the 3 ticket classes: Class 1 , Class 2 and Class 3 .\n\nSurvived: Indication whether passenger survived. 0 for yes and 1 for no.\n\nThis tutorial uses the Titanic data set, stored as CSV. The data consists of the following data columns:\n\nHow do I read and write tabular data?#\n• None I want to analyze the Titanic passenger data, available as a CSV file. pandas provides the function to read data stored as a csv file into a pandas . pandas supports many different file formats or data sources out of the box (csv, excel, sql, json, parquet, …), each of them with the prefix .\n\nMake sure to always have a check on the data after reading in the data. When displaying a , the first and last 5 rows will be shown by default:\n• None I want to see the first 8 rows of a pandas DataFrame. To see the first N rows of a , use the method with the required number of rows (in this case 8) as argument.\n\nA check on how pandas interpreted each of the column data types can be done by requesting the pandas attribute:\n\nFor each of the columns, the used data type is enlisted. The data types in this are integers ( ), floats ( ) and strings ( ).\n\nWhen asking for the , no brackets are used! is an attribute of a and . Attributes of a or do not need brackets. Attributes represent a characteristic of a / , whereas methods (which require brackets) do something with the / as introduced in the first tutorial.\n• None My colleague requested the Titanic data as a spreadsheet. Whereas functions are used to read data to pandas, the methods are used to store data. The method stores the data as an excel file. In the example here, the is named passengers instead of the default Sheet1. By setting the row index labels are not saved in the spreadsheet.\n\nThe equivalent read function will reload the data to a :\n• The method provides technical information about a , so let’s explain the output in more detail:\n• None It is indeed a .\n• None Each row has a row label (aka the ) with values ranging from 0 to 890.\n• None The table has 12 columns. Most columns have a value for each of the rows (all 891 values are ). Some columns do have missing values and less than 891 values.\n• None The columns , , and consists of textual data (strings, aka ). The other columns are numerical data with some of them whole numbers (aka ) and others are real numbers (aka ).\n• None The kind of data (characters, integers,…) in the different columns are summarized by listing the .\n• None The approximate amount of RAM used to hold the DataFrame is provided as well."
    },
    {
        "link": "https://datacamp.com/tutorial/pandas-read-csv",
        "document": "Learn how to effectively and efficiently join datasets in tabular format using the Python Pandas library."
    },
    {
        "link": "https://pandas.pydata.org/docs/dev/reference/api/pandas.read_csv.html",
        "document": "Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv. If you want to pass in a path object, pandas accepts any . By file-like object, we refer to objects with a method, such as a file handle (e.g. via builtin function) or .\n\nCharacter or regex pattern to treat as the delimiter. If , the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator from only the first valid row of the file by Python’s builtin sniffer tool, . In addition, separators longer than 1 character and different from will be interpreted as regular expressions and will also force the use of the Python parsing engine. Note that regex delimiters are prone to ignoring quoted data. Regex example: .\n\nRow number(s) containing column labels and marking the start of the data (zero-indexed). Default behavior is to infer the column names: if no are passed the behavior is identical to and column names are inferred from the first line of the file, if column names are passed explicitly to then the behavior is identical to . Explicitly pass to be able to replace existing names. The header can be a list of integers that specify row locations for a on the columns e.g. . Intervening rows that are not specified will be skipped (e.g. 2 in this example is skipped). Note that this parameter ignores commented lines and empty lines if , so denotes the first line of data rather than the first line of the file. When inferred from the file contents, headers are kept distinct from each other by renaming duplicate names with a numeric suffix of the form starting from 1, e.g. and . Empty headers are named or in the case of MultiIndex columns.\n\nColumn(s) to use as row label(s), denoted either by column labels or column indices. If a sequence of labels or indices is given, will be formed for the row labels. Note: can be used to force pandas to not use the first column as the index, e.g., when you have a malformed file with delimiters at the end of each line.\n\nSubset of columns to select, denoted either by column labels or column indices. If list-like, all elements must either be positional (i.e. integer indices into the document columns) or strings that correspond to column names provided either by the user in or inferred from the document header row(s). If are given, the document header row(s) are not taken into account. For example, a valid list-like parameter would be or . Element order is ignored, so is the same as . To instantiate a from with element order preserved use for columns in order or for order. If callable, the callable function will be evaluated against the column names, returning names where the callable function evaluates to . An example of a valid callable argument would be . Using this parameter results in much faster parsing time and lower memory usage.\n\nWhether or not to include the default values when parsing the data. Depending on whether is passed in, the behavior is as follows:\n• None If is , and are specified, is appended to the default values used for parsing.\n• None If is , and are not specified, only the default values are used for parsing.\n• None If is , and are specified, only the values specified are used for parsing.\n• None If is , and are not specified, no strings will be parsed as . Note that if is passed in as , the and parameters will be ignored.\n\nFor on-the-fly decompression of on-disk data. If ‘infer’ and ‘filepath_or_buffer’ is path-like, then detect compression from the following extensions: ‘.gz’, ‘.bz2’, ‘.zip’, ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’ (otherwise no compression). If using ‘zip’ or ‘tar’, the ZIP file must contain only one data file to be read in. Set to for no decompression. Can also be a dict with key set to one of { , , , , , } and other key-value pairs are forwarded to , , , , or , respectively. As an example, the following could be passed for Zstandard decompression using a custom compression dictionary: ."
    },
    {
        "link": "https://geeksforgeeks.org/python-os-makedirs-method",
        "document": "All functions in the os module raise OSError in the case of invalid or inaccessible file names and paths, or other arguments that have the correct type but are not accepted by the operating system. In this article, we will see how to create directories recursively using the os module and also about os.makedirs() method.\n\nos.makedirs() method in Python is used to create a directory recursively. That means while making leaf directory if any intermediate-level directory is missing, os.makedirs() method will create them all.\n\nFor example, consider the following path:\n\nSuppose we want to create directory ‘ihritik’ but Directory ‘GeeksForGeeks’ and ‘Authors’ are unavailable in the path. Then os.makedirs() method will create all unavailable/missing directory in the specified path. ‘GeeksForGeeks’ and ‘Authors’ will be created first then ‘ihritik’ directory will be created.\n\nBelow are some examples of os.makedirs() function by which we can see how to create directories recursively using the os module:\n\nIn this example, the method is utilized to create nested directories. The first section creates a directory named “ihritik” within the “Authors” directory path. The second section, with specified permissions, creates a directory “c” nested within “GeeksforGeeks/a/b”.\n\nIn this example, the method attempts to create a directory named “ihritik” within the “GeeksForGeeks” path. If the directory already exists, the method raises an . Upon successful creation, a confirmation message is printed.\n\nIn this example, the method is used with the parameter set to to suppress if the directory already exists. If the directory doesn’t exist, it will be created. However, other exceptions, such as an invalid path name, can still be raised and need to be handled separately."
    },
    {
        "link": "https://w3schools.com/python/ref_os_makedirs.asp",
        "document": "W3Schools offers a wide range of services and products for beginners and professionals, helping millions of people everyday to learn and master new skills."
    },
    {
        "link": "https://docs.python.org/3/library/os.html",
        "document": "This module provides a portable way of using operating system dependent functionality. If you just want to read or write a file see , if you want to manipulate paths, see the module, and if you want to read all the lines in all the files on the command line see the module. For creating temporary files and directories see the module, and for high-level file and directory handling see the module.\n\nNotes on the availability of these functions:\n• None The design of all built-in operating system dependent modules of Python is such that as long as the same functionality is available, it uses the same interface; for example, the function returns stat information about path in the same format (which happens to have originated with the POSIX interface).\n• None Extensions peculiar to a particular operating system are also available through the module, but using them is of course a threat to portability.\n• None All functions accepting path or file names accept both bytes and string objects, and result in an object of the same type, if a path or file name is returned.\n• None On VxWorks, os.popen, os.fork, os.execv and os.spawn*p* are not supported.\n• None On WebAssembly platforms, Android and iOS, large parts of the module are not available or behave differently. APIs related to processes (e.g. , ) and resources (e.g. ) are not available. Others like and are emulated or stubs. WebAssembly platforms also lack support for signals (e.g. , )."
    },
    {
        "link": "https://stackoverflow.com/questions/273192/how-do-i-create-a-directory-and-any-missing-parent-directories",
        "document": "How do I create a directory at a given path, and also create any missing parent directories along that path? For example, the Bash command mkdir -p /path/to/nested/directory does this.\n\nFor older versions of Python, I see two answers with good qualities, each with a small flaw, so I will give my take on it: Try , and consider for the creation. As noted in comments and elsewhere, there's a race condition – if the directory is created between the and the calls, the will fail with an . Unfortunately, blanket-catching and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc. One option would be to trap the and examine the embedded error code (see Is there a cross-platform way of getting information from Python’s OSError): import os, errno try: os.makedirs(directory) except OSError as e: if e.errno != errno.EEXIST: raise Alternatively, there could be a second , but suppose another created the directory after the first check, then removed it before the second one – we could still be fooled. Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation. Modern versions of Python improve this code quite a bit, both by exposing (in 3.3+)... try: os.makedirs(\"path/to/directory\") except FileExistsError: # directory already exists pass ...and by allowing a keyword argument to called (in 3.2+).\n\nas used above recursively creates the directory and does not raise an exception if the directory already exists. If you don't need or want the parents to be created, skip the argument. If you can, install the current backport named . Do not install the older unmaintained backport named . Next, refer to the Python 3.5+ section above and use it the same. If using Python 3.4, even though it comes with , it is missing the useful option. The backport is intended to offer a newer and superior implementation of which includes this missing option. as used above recursively creates the directory and does not raise an exception if the directory already exists. It has the optional argument only if using Python 3.2+, with a default value of . This argument does not exist in Python 2.x up to 2.7. As such, there is no need for manual exception handling as with Python 2.7. If you can, install the current backport named . Do not install the older unmaintained backport named . Next, refer to the Python 3.5+ section above and use it the same. import os try: os.makedirs(path) except OSError: if not os.path.isdir(path): raise While a naive solution may first use followed by , the solution above reverses the order of the two operations. In doing so, it prevents a common race condition having to do with a duplicated attempt at creating the directory, and also disambiguates files from directories. Note that capturing the exception and using is of limited usefulness because , i.e. , is raised for both files and directories. It is more reliable simply to check if the directory exists. creates the nested directory, and does nothing if the directory already exists. This works in both Python 2 and 3. Note however that has been deprecated, and is scheduled for removal in Python 3.12. Per Bug 10948, a severe limitation of this alternative is that it works only once per python process for a given path. In other words, if you use it to create a directory, then delete the directory from inside or outside Python, then use again to recreate the same directory, will simply silently use its invalid cached info of having previously created the directory, and will not actually make the directory again. In contrast, doesn't rely on any such cache. This limitation may be okay for some applications. With regard to the directory's mode, please refer to the documentation if you care about it.\n\nInsights on the specifics of this situation You give a particular file at a certain path and you pull the directory from the file path. Then after making sure you have the directory, you attempt to open a file for reading. To comment on this code: We want to avoid overwriting the builtin function, . Also, or perhaps is probably a better semantic name than so this would be better written: Your end goal is to open this file, you initially state, for writing, but you're essentially approaching this goal (based on your code) like this, which opens the file for reading: Why would you make a directory for a file that you expect to be there and be able to read? Just attempt to open the file. If the directory or file isn't there, you'll get an with an associated error number: will point to the correct error number regardless of your platform. You can catch it if you want, for example: import errno try: with open(filepath) as my_file: do_stuff(my_file) except IOError as error: if error.errno == errno.ENOENT: print 'ignoring error because directory or file is not there' else: raise This is probably what you're wanting. In this case, we probably aren't facing any race conditions. So just do as you were, but note that for writing, you need to open with the mode (or to append). It's also a Python best practice to use the context manager for opening files. import os if not os.path.exists(directory): os.makedirs(directory) with open(filepath, 'w') as my_file: do_stuff(my_file) However, say we have several Python processes that attempt to put all their data into the same directory. Then we may have contention over creation of the directory. In that case it's best to wrap the call in a try-except block. import os import errno if not os.path.exists(directory): try: os.makedirs(directory) except OSError as error: if error.errno != errno.EEXIST: raise with open(filepath, 'w') as my_file: do_stuff(my_file)\n\nCheck if a directory exists and create it if necessary? The direct answer to this is, assuming a simple situation where you don't expect other users or processes to be messing with your directory: or if making the directory is subject to race conditions (i.e. if after checking the path exists, something else may have already made it) do this: import errno try: os.makedirs(d) except OSError as exception: if exception.errno != errno.EEXIST: raise But perhaps an even better approach is to sidestep the resource contention issue, by using temporary directories via : Here's the essentials from the online doc: mkdtemp(suffix='', prefix='tmp', dir=None) User-callable function to create and return a unique temporary directory. The return value is the pathname of the directory. The directory is readable, writable, and searchable only by the creating user. Caller is responsible for deleting the directory when done with it. New in Python 3.5: with There's a new object (as of 3.4) with lots of methods one would want to use with paths - one of which is . We don't have to deal with now - just join path parts with a : Then I idempotently ensure the directory exists - the argument shows up in Python 3.5: Here's the relevant part of the documentation: If is true, exceptions will be ignored (same behavior as the command), but only if the last path component is not an existing non-directory file. Here's a little more of the script - in my case, I'm not subject to a race condition, I only have one process that expects the directory (or contained files) to be there, and I don't have anything trying to remove the directory. objects have to be coerced to before other APIs that expect paths can use them. Perhaps Pandas should be updated to accept instances of the abstract base class, .\n\nThe relevant Python documentation suggests the use of the EAFP coding style (Easier to Ask for Forgiveness than Permission). This means that the code try: os.makedirs(path) except OSError as exception: if exception.errno != errno.EEXIST: raise else: print \"\n\nBE CAREFUL! Directory %s already exists.\" % path is better than the alternative if not os.path.exists(path): os.makedirs(path) else: print \"\n\nBE CAREFUL! Directory %s already exists.\" % path The documentation suggests this exactly because of the race condition discussed in this question. In addition, as others mention here, there is a performance advantage in querying once instead of twice the OS. Finally, the argument placed forward, potentially, in favour of the second code in some cases --when the developer knows the environment the application is running-- can only be advocated in the special case that the program has set up a private environment for itself (and other instances of the same program). Even in that case, this is a bad practice and can lead to long useless debugging. For example, the fact we set the permissions for a directory should not leave us with the impression permissions are set appropriately for our purposes. A parent directory could be mounted with other permissions. In general, a program should always work correctly and the programmer should not expect one specific environment."
    },
    {
        "link": "https://note.nkmk.me/en/python-os-mkdir-makedirs",
        "document": "In Python, you can create new directories (folders) with the and functions.\n\nAll sample code in this article assumes that the module has been imported. The module is included in the standard library and does not require additional installation.\n\nSpecify a path string for the new directory. See the following article for more information on manipulating path strings.\n• Get the filename, directory, extension from a path string in Python\n\nThe path string may include or exclude a trailing delimiter, like a slash for UNIX and Mac systems, or a backslash for Windows systems.\n\nIf you specify an existing directory, an error ( ) will be raised.\n\nAn error ( ) will be raised if you attempt to create a new directory within a non-existent directory.\n\nWhen using , make sure the parent directories of the desired directory already exist. To create new directories along with their parent directories, use as explained in the next section.\n\nBy default, if you specify an existing directory, an error ( ) will be raised.\n\nThe argument (Python 3.2 or later)\n\nThe argument was added to in Python 3.2.\n\nIf you set , you can specify an existing directory without encountering an error. Note that the default value is .\n\nIn older versions without the argument, you can use to handle exceptions or to check if the target directory already exists.\n• Try, except, else, finally in Python (Exception handling)\n\nCheck for the existence of a directory with :\n• Check if a file or a directory exists in Python"
    }
]