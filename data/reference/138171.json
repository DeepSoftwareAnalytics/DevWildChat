[
    {
        "link": "https://docs.python.org/3/library/re.html",
        "document": "This module provides regular expression matching operations similar to those found in Perl.\n\nBoth patterns and strings to be searched can be Unicode strings ( ) as well as 8-bit strings ( ). However, Unicode strings and 8-bit strings cannot be mixed: that is, you cannot match a Unicode string with a bytes pattern or vice-versa; similarly, when asking for a substitution, the replacement string must be of the same type as both the pattern and the search string.\n\nRegular expressions use the backslash character ( ) to indicate special forms or to allow special characters to be used without invoking their special meaning. This collides with Python’s usage of the same character for the same purpose in string literals; for example, to match a literal backslash, one might have to write as the pattern string, because the regular expression must be , and each backslash must be expressed as inside a regular Python string literal. Also, please note that any invalid escape sequences in Python’s usage of the backslash in string literals now generate a and in the future this will become a . This behaviour will happen even if it is a valid escape sequence for a regular expression.\n\nThe solution is to use Python’s raw string notation for regular expression patterns; backslashes are not handled in any special way in a string literal prefixed with . So is a two-character string containing and , while is a one-character string containing a newline. Usually patterns will be expressed in Python code using this raw string notation.\n\nIt is important to note that most regular expression operations are available as module-level functions and methods on compiled regular expressions. The functions are shortcuts that don’t require you to compile a regex object first, but miss some fine-tuning parameters.\n\nA regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing). Regular expressions can be concatenated to form new regular expressions; if A and B are both regular expressions, then AB is also a regular expression. In general, if a string p matches A and another string q matches B, the string pq will match AB. This holds unless A or B contain low precedence operations; boundary conditions between A and B; or have numbered group references. Thus, complex expressions can easily be constructed from simpler primitive expressions like the ones described here. For details of the theory and implementation of regular expressions, consult the Friedl book [Frie09], or almost any textbook about compiler construction. A brief explanation of the format of regular expressions follows. For further information and a gentler presentation, consult the Regular Expression HOWTO. Regular expressions can contain both special and ordinary characters. Most ordinary characters, like , , or , are the simplest regular expressions; they simply match themselves. You can concatenate ordinary characters, so matches the string . (In the rest of this section, we’ll write RE’s in , usually without quotes, and strings to be matched .) Some characters, like or , are special. Special characters either stand for classes of ordinary characters, or affect how the regular expressions around them are interpreted. Repetition operators or quantifiers ( , , , , etc) cannot be directly nested. This avoids ambiguity with the non-greedy modifier suffix , and with other modifiers in other implementations. To apply a second repetition to an inner repetition, parentheses may be used. For example, the expression matches any multiple of six characters. (Dot.) In the default mode, this matches any character except a newline. If the flag has been specified, this matches any character including a newline. matches any character regardless of flags. (Caret.) Matches the start of the string, and in mode also matches immediately after each newline. Matches the end of the string or just before the newline at the end of the string, and in mode also matches before a newline. matches both ‘foo’ and ‘foobar’, while the regular expression matches only ‘foo’. More interestingly, searching for in matches ‘foo2’ normally, but ‘foo1’ in mode; searching for a single in will find two (empty) matches: one just before the newline, and one at the end of the string. Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible. will match ‘a’, ‘ab’, or ‘a’ followed by any number of ‘b’s. Causes the resulting RE to match 1 or more repetitions of the preceding RE. will match ‘a’ followed by any non-zero number of ‘b’s; it will not match just ‘a’. Causes the resulting RE to match 0 or 1 repetitions of the preceding RE. will match either ‘a’ or ‘ab’. The , , and quantifiers are all greedy; they match as much text as possible. Sometimes this behaviour isn’t desired; if the RE is matched against , it will match the entire string, and not just . Adding after the quantifier makes it perform the match in non-greedy or minimal fashion; as few characters as possible will be matched. Using the RE will match only . Like the , , and quantifiers, those where is appended also match as many times as possible. However, unlike the true greedy quantifiers, these do not allow back-tracking when the expression following it fails to match. These are known as possessive quantifiers. For example, will match because the will match all 4 s, but, when the final is encountered, the expression is backtracked so that in the end the ends up matching 3 s total, and the fourth is matched by the final . However, when is used to match , the will match all 4 , but when the final fails to find any more characters to match, the expression cannot be backtracked and will thus fail to match. , and are equivalent to , and correspondingly. Specifies that exactly m copies of the previous RE should be matched; fewer matches cause the entire RE not to match. For example, will match exactly six characters, but not five. Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible. For example, will match from 3 to 5 characters. Omitting m specifies a lower bound of zero, and omitting n specifies an infinite upper bound. As an example, will match or a thousand characters followed by a , but not . The comma may not be omitted or the modifier would be confused with the previously described form. Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as few repetitions as possible. This is the non-greedy version of the previous quantifier. For example, on the 6-character string , will match 5 characters, while will only match 3 characters. Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible without establishing any backtracking points. This is the possessive version of the quantifier above. For example, on the 6-character string , attempt to match 5 characters, then, requiring 2 more s, will need more characters than available and thus fail, while will match with capturing 5, then 4 s by backtracking and then the final 2 s are matched by the final in the pattern. is equivalent to . Either escapes special characters (permitting you to match characters like , , and so forth), or signals a special sequence; special sequences are discussed below. If you’re not using a raw string to express the pattern, remember that Python also uses the backslash as an escape sequence in string literals; if the escape sequence isn’t recognized by Python’s parser, the backslash and subsequent character are included in the resulting string. However, if Python would recognize the resulting sequence, the backslash should be repeated twice. This is complicated and hard to understand, so it’s highly recommended that you use raw strings for all but the simplest expressions. Used to indicate a set of characters. In a set:\n• None Characters can be listed individually, e.g. will match , , or .\n• None Ranges of characters can be indicated by giving two characters and separating them by a , for example will match any lowercase ASCII letter, will match all the two-digits numbers from to , and will match any hexadecimal digit. If is escaped (e.g. ) or if it’s placed as the first or last character (e.g. or ), it will match a literal .\n• None Special characters lose their special meaning inside sets. For example, will match any of the literal characters , , , or .\n• None Character classes such as or (defined below) are also accepted inside a set, although the characters they match depend on the flags used.\n• None Characters that are not within a range can be matched by complementing the set. If the first character of the set is , all the characters that are not in the set will be matched. For example, will match any character except , and will match any character except . has no special meaning if it’s not the first character in the set.\n• None To match a literal inside a set, precede it with a backslash, or place it at the beginning of the set. For example, both and will match a right bracket, as well as left bracket, braces, and parentheses.\n• None Support of nested sets and set operations as in Unicode Technical Standard #18 might be added in the future. This would change the syntax, so to facilitate this change a will be raised in ambiguous cases for the time being. That includes sets starting with a literal or containing literal character sequences , , , and . To avoid a warning escape them with a backslash. Changed in version 3.7: is raised if a character set contains constructs that will change semantically in the future. , where A and B can be arbitrary REs, creates a regular expression that will match either A or B. An arbitrary number of REs can be separated by the in this way. This can be used inside groups (see below) as well. As the target string is scanned, REs separated by are tried from left to right. When one pattern completely matches, that branch is accepted. This means that once A matches, B will not be tested further, even if it would produce a longer overall match. In other words, the operator is never greedy. To match a literal , use , or enclose it inside a character class, as in . Matches whatever regular expression is inside the parentheses, and indicates the start and end of a group; the contents of a group can be retrieved after a match has been performed, and can be matched later in the string with the special sequence, described below. To match the literals or , use or , or enclose them inside a character class: , . This is an extension notation (a following a is not meaningful otherwise). The first character after the determines what the meaning and further syntax of the construct is. Extensions usually do not create a new group; is the only exception to this rule. Following are the currently supported extensions. (One or more letters from the set , , , , , , .) The group matches the empty string; the letters set the corresponding flags for the entire regular expression: (The flags are described in Module Contents.) This is useful if you wish to include the flags as part of the regular expression, instead of passing a flag argument to the function. Flags should be used first in the expression string. Changed in version 3.11: This construction can only be used at the start of the expression. A non-capturing version of regular parentheses. Matches whatever regular expression is inside the parentheses, but the substring matched by the group cannot be retrieved after performing a match or referenced later in the pattern. (Zero or more letters from the set , , , , , , , optionally followed by followed by one or more letters from the , , , .) The letters set or remove the corresponding flags for the part of the expression: The letters , and are mutually exclusive when used as inline flags, so they can’t be combined or follow . Instead, when one of them appears in an inline group, it overrides the matching mode in the enclosing group. In Unicode patterns switches to ASCII-only matching, and switches to Unicode matching (default). In bytes patterns switches to locale dependent matching, and switches to ASCII-only matching (default). This override is only in effect for the narrow inline group, and the original matching mode is restored outside of the group. Changed in version 3.7: The letters , and also can be used in a group. Attempts to match as if it was a separate regular expression, and if successful, continues to match the rest of the pattern following it. If the subsequent pattern fails to match, the stack can only be unwound to a point before the because once exited, the expression, known as an atomic group, has thrown away all stack points within itself. Thus, would never match anything because first the would match all characters possible, then, having nothing left to match, the final would fail to match. Since there are no stack points saved in the Atomic Group, and there is no stack point before it, the entire expression would thus fail to match. Similar to regular parentheses, but the substring matched by the group is accessible via the symbolic group name name. Group names must be valid Python identifiers, and in patterns they can only contain bytes in the ASCII range. Each group name must be defined only once within a regular expression. A symbolic group is also a numbered group, just as if the group were not named. Named groups can be referenced in three contexts. If the pattern is (i.e. matching a string quoted with either single or double quotes): in the same pattern itself in a string passed to the repl argument of Changed in version 3.12: In patterns, group name can only contain bytes in the ASCII range ( - ). A backreference to a named group; it matches whatever text was matched by the earlier group named name. A comment; the contents of the parentheses are simply ignored. Matches if matches next, but doesn’t consume any of the string. This is called a lookahead assertion. For example, will match only if it’s followed by . Matches if doesn’t match next. This is a negative lookahead assertion. For example, will match only if it’s not followed by . Matches if the current position in the string is preceded by a match for that ends at the current position. This is called a positive lookbehind assertion. will find a match in , since the lookbehind will back up 3 characters and check if the contained pattern matches. The contained pattern must only match strings of some fixed length, meaning that or are allowed, but and are not. Note that patterns which start with positive lookbehind assertions will not match at the beginning of the string being searched; you will most likely want to use the function rather than the function: This example looks for a word following a hyphen: Changed in version 3.5: Added support for group references of fixed length. Matches if the current position in the string is not preceded by a match for . This is called a negative lookbehind assertion. Similar to positive lookbehind assertions, the contained pattern must only match strings of some fixed length. Patterns which start with negative lookbehind assertions may match at the beginning of the string being searched. Will try to match with if the group with given id or name exists, and with if it doesn’t. is optional and can be omitted. For example, is a poor email matching pattern, which will match with as well as , but not with nor . Changed in version 3.12: Group id can only contain ASCII digits. In patterns, group name can only contain bytes in the ASCII range ( - ). The special sequences consist of and a character from the list below. If the ordinary character is not an ASCII digit or an ASCII letter, then the resulting RE will match the second character. For example, matches the character . Matches the contents of the group of the same number. Groups are numbered starting from 1. For example, matches or , but not (note the space after the group). This special sequence can only be used to match one of the first 99 groups. If the first digit of number is 0, or number is 3 octal digits long, it will not be interpreted as a group match, but as the character with octal value number. Inside the and of a character class, all numeric escapes are treated as characters. Matches only at the start of the string. Matches the empty string, but only at the beginning or end of a word. A word is defined as a sequence of word characters. Note that formally, is defined as the boundary between a and a character (or vice versa), or between and the beginning or end of the string. This means that matches , , , and but not or . The default word characters in Unicode (str) patterns are Unicode alphanumerics and the underscore, but this can be changed by using the flag. Word boundaries are determined by the current locale if the flag is used. Inside a character range, represents the backspace character, for compatibility with Python’s string literals. Matches the empty string, but only when it is not at the beginning or end of a word. This means that matches , , , but not , , or . is the opposite of , so word characters in Unicode (str) patterns are Unicode alphanumerics or the underscore, although this can be changed by using the flag. Word boundaries are determined by the current locale if the flag is used. Note that does not match an empty string, which differs from RE implementations in other programming languages such as Perl. This behavior is kept for compatibility reasons. Matches any Unicode decimal digit (that is, any character in Unicode character category [Nd]). This includes , and also many other digit characters. Matches if the flag is used. Matches any decimal digit in the ASCII character set; this is equivalent to . Matches any character which is not a decimal digit. This is the opposite of . Matches if the flag is used. Matches Unicode whitespace characters (as defined by ). This includes , and also many other characters, for example the non-breaking spaces mandated by typography rules in many languages. Matches if the flag is used. Matches characters considered whitespace in the ASCII character set; this is equivalent to . Matches any character which is not a whitespace character. This is the opposite of . Matches if the flag is used. Matches Unicode word characters; this includes all Unicode alphanumeric characters (as defined by ), as well as the underscore ( ). Matches if the flag is used. Matches characters considered alphanumeric in the ASCII character set; this is equivalent to . If the flag is used, matches characters considered alphanumeric in the current locale and the underscore. Matches any character which is not a word character. This is the opposite of . By default, matches non-underscore ( ) characters for which returns . Matches if the flag is used. If the flag is used, matches characters which are neither alphanumeric in the current locale nor the underscore. Matches only at the end of the string. Most of the escape sequences supported by Python string literals are also accepted by the regular expression parser: , , and escape sequences are only recognized in Unicode (str) patterns. In bytes patterns they are errors. Unknown escapes of ASCII letters are reserved for future use and treated as errors. Octal escapes are included in a limited form. If the first digit is a 0, or if there are three octal digits, it is considered an octal escape. Otherwise, it is a group reference. As for string literals, octal escapes are always at most three digits in length. Changed in version 3.3: The and escape sequences have been added. Changed in version 3.6: Unknown escapes consisting of and an ASCII letter now are errors. Changed in version 3.8: The escape sequence has been added. As in string literals, it expands to the named Unicode character (e.g. ).\n\nThe module defines several functions, constants, and an exception. Some of the functions are simplified versions of the full featured methods for compiled regular expressions. Most non-trivial applications always use the compiled form. Changed in version 3.6: Flag constants are now instances of , which is a subclass of . An class containing the regex options listed below. Make , , , , , , and perform ASCII-only matching instead of full Unicode matching. This is only meaningful for Unicode (str) patterns, and is ignored for bytes patterns. The flag still exists for backward compatibility, but is redundant in Python 3 since matches are Unicode by default for patterns, and Unicode matching isn’t allowed for bytes patterns. and the inline flag are similarly redundant. Perform case-insensitive matching; expressions like will also match lowercase letters. Full Unicode matching (such as matching ) also works unless the flag is used to disable non-ASCII matches. The current locale does not change the effect of this flag unless the flag is also used. Note that when the Unicode patterns or are used in combination with the flag, they will match the 52 ASCII letters and 4 additional non-ASCII letters: ‘İ’ (U+0130, Latin capital letter I with dot above), ‘ı’ (U+0131, Latin small letter dotless i), ‘ſ’ (U+017F, Latin small letter long s) and ‘K’ (U+212A, Kelvin sign). If the flag is used, only letters ‘a’ to ‘z’ and ‘A’ to ‘Z’ are matched. Make , , , and case-insensitive matching dependent on the current locale. This flag can be used only with bytes patterns. This flag is discouraged; consider Unicode matching instead. The locale mechanism is very unreliable as it only handles one “culture” at a time and only works with 8-bit locales. Unicode matching is enabled by default for Unicode (str) patterns and it is able to handle different locales and languages. Changed in version 3.6: can be used only with bytes patterns and is not compatible with . Changed in version 3.7: Compiled regular expression objects with the flag no longer depend on the locale at compile time. Only the locale at matching time affects the result of matching. When specified, the pattern character matches at the beginning of the string and at the beginning of each line (immediately following each newline); and the pattern character matches at the end of the string and at the end of each line (immediately preceding each newline). By default, matches only at the beginning of the string, and only at the end of the string and immediately before the newline (if any) at the end of the string. Indicates no flag being applied, the value is . This flag may be used as a default value for a function keyword argument or as a base value that will be conditionally ORed with other flags. Example of use as a default value: Make the special character match any character at all, including a newline; without this flag, will match anything except a newline. In Python 3, Unicode characters are matched by default for patterns. This flag is therefore redundant with no effect and is only kept for backward compatibility. See to restrict matching to ASCII characters instead. This flag allows you to write regular expressions that look nicer and are more readable by allowing you to visually separate logical sections of the pattern and add comments. Whitespace within the pattern is ignored, except when in a character class, or when preceded by an unescaped backslash, or within tokens like , or . For example, and are not allowed. When a line contains a that is not in a character class and is not preceded by an unescaped backslash, all characters from the leftmost such through the end of the line are ignored. This means that the two following regular expression objects that match a decimal number are functionally equal: Compile a regular expression pattern into a regular expression object, which can be used for matching using its , and other methods, described below. The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables, combined using bitwise OR (the operator). but using and saving the resulting regular expression object for reuse is more efficient when the expression will be used several times in a single program. The compiled versions of the most recent patterns passed to and the module-level matching functions are cached, so programs that use only a few regular expressions at a time needn’t worry about compiling regular expressions. Scan through string looking for the first location where the regular expression pattern produces a match, and return a corresponding . Return if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string. The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables, combined using bitwise OR (the operator). If zero or more characters at the beginning of string match the regular expression pattern, return a corresponding . Return if the string does not match the pattern; note that this is different from a zero-length match. Note that even in mode, will only match at the beginning of the string and not at the beginning of each line. If you want to locate a match anywhere in string, use instead (see also search() vs. match()). The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables, combined using bitwise OR (the operator). If the whole string matches the regular expression pattern, return a corresponding . Return if the string does not match the pattern; note that this is different from a zero-length match. The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables, combined using bitwise OR (the operator). Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits occur, and the remainder of the string is returned as the final element of the list. If there are capturing groups in the separator and it matches at the start of the string, the result will start with an empty string. The same holds for the end of the string: That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables, combined using bitwise OR (the operator). Changed in version 3.7: Added support of splitting on a pattern that could match an empty string. Deprecated since version 3.13: Passing maxsplit and flags as positional arguments is deprecated. In future Python versions they will be keyword-only parameters. Return all non-overlapping matches of pattern in string, as a list of strings or tuples. The string is scanned left-to-right, and matches are returned in the order found. Empty matches are included in the result. The result depends on the number of capturing groups in the pattern. If there are no groups, return a list of strings matching the whole pattern. If there is exactly one group, return a list of strings matching that group. If multiple groups are present, return a list of tuples of strings matching the groups. Non-capturing groups do not affect the form of the result. The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables, combined using bitwise OR (the operator). Changed in version 3.7: Non-empty matches can now start just after a previous empty match. Return an iterator yielding objects over all non-overlapping matches for the RE pattern in string. The string is scanned left-to-right, and matches are returned in the order found. Empty matches are included in the result. The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables, combined using bitwise OR (the operator). Changed in version 3.7: Non-empty matches can now start just after a previous empty match. Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isn’t found, string is returned unchanged. repl can be a string or a function; if it is a string, any backslash escapes in it are processed. That is, is converted to a single newline character, is converted to a carriage return, and so forth. Unknown escapes of ASCII letters are reserved for future use and treated as errors. Other unknown escapes such as are left alone. Backreferences, such as , are replaced with the substring matched by group 6 in the pattern. For example: If repl is a function, it is called for every non-overlapping occurrence of pattern. The function takes a single argument, and returns the replacement string. For example: The pattern may be a string or a . The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a non-negative integer. If omitted or zero, all occurrences will be replaced. Empty matches for the pattern are replaced only when not adjacent to a previous empty match, so returns . In string-type repl arguments, in addition to the character escapes and backreferences described above, will use the substring matched by the group named , as defined by the syntax. uses the corresponding group number; is therefore equivalent to , but isn’t ambiguous in a replacement such as . would be interpreted as a reference to group 20, not a reference to group 2 followed by the literal character . The backreference substitutes in the entire substring matched by the RE. The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables, combined using bitwise OR (the operator). Changed in version 3.5: Unmatched groups are replaced with an empty string. Changed in version 3.6: Unknown escapes in pattern consisting of and an ASCII letter now are errors. Changed in version 3.7: Unknown escapes in repl consisting of and an ASCII letter now are errors. Empty matches for the pattern are replaced when adjacent to a previous non-empty match. Changed in version 3.12: Group id can only contain ASCII digits. In replacement strings, group name can only contain bytes in the ASCII range ( - ). Deprecated since version 3.13: Passing count and flags as positional arguments is deprecated. In future Python versions they will be keyword-only parameters. Perform the same operation as , but return a tuple . The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables, combined using bitwise OR (the operator). Escape special characters in pattern. This is useful if you want to match an arbitrary literal string that may have regular expression metacharacters in it. For example: This function must not be used for the replacement string in and , only backslashes should be escaped. For example: Changed in version 3.3: The character is no longer escaped. Changed in version 3.7: Only characters that can have special meaning in a regular expression are escaped. As a result, , , , , , , , , , , , , and are no longer escaped. Exception raised when a string passed to one of the functions here is not a valid regular expression (for example, it might contain unmatched parentheses) or when some other error occurs during compilation or matching. It is never an error if a string contains no match for a pattern. The instance has the following additional attributes: The index in pattern where compilation failed (may be ). The line corresponding to pos (may be ). The column corresponding to pos (may be ). Changed in version 3.13: was originally named ; the latter is kept as an alias for backward compatibility.\n\nMatch objects always have a boolean value of . Since and return when there is no match, you can test whether there was a match with a simple statement: Changed in version 3.9: supports to indicate a Unicode (str) or bytes match. See Generic Alias Type. Return the string obtained by doing backslash substitution on the template string template, as done by the method. Escapes such as are converted to the appropriate characters, and numeric backreferences ( , ) and named backreferences ( , ) are replaced by the contents of the corresponding group. The backreference will be replaced by the entire match. Changed in version 3.5: Unmatched groups are replaced with an empty string. Returns one or more subgroups of the match. If there is a single argument, the result is a single string; if there are multiple arguments, the result is a tuple with one item per argument. Without arguments, group1 defaults to zero (the whole match is returned). If a groupN argument is zero, the corresponding return value is the entire matching string; if it is in the inclusive range [1..99], it is the string matching the corresponding parenthesized group. If a group number is negative or larger than the number of groups defined in the pattern, an exception is raised. If a group is contained in a part of the pattern that did not match, the corresponding result is . If a group is contained in a part of the pattern that matched multiple times, the last match is returned. If the regular expression uses the syntax, the groupN arguments may also be strings identifying groups by their group name. If a string argument is not used as a group name in the pattern, an exception is raised. Named groups can also be referred to by their index: If a group matches multiple times, only the last match is accessible: # Returns only the last match. This is identical to . This allows easier access to an individual group from a match: Named groups are supported as well: Return a tuple containing all the subgroups of the match, from 1 up to however many groups are in the pattern. The default argument is used for groups that did not participate in the match; it defaults to . If we make the decimal place and everything after it optional, not all groups might participate in the match. These groups will default to unless the default argument is given: # Second group defaults to None. # Now, the second group defaults to '0'. Return a dictionary containing all the named subgroups of the match, keyed by the subgroup name. The default argument is used for groups that did not participate in the match; it defaults to . For example: Return the indices of the start and end of the substring matched by group; group defaults to zero (meaning the whole matched substring). Return if group exists but did not contribute to the match. For a match object m, and a group g that did contribute to the match, the substring matched by group g (equivalent to ) is Note that will equal if group matched a null string. For example, after , is 1, is 2, and are both 2, and raises an exception. An example that will remove remove_this from email addresses: For a match m, return the 2-tuple . Note that if group did not contribute to the match, this is . group defaults to zero, the entire match. The value of pos which was passed to the or method of a regex object. This is the index into the string at which the RE engine started looking for a match. The value of endpos which was passed to the or method of a regex object. This is the index into the string beyond which the RE engine will not go. The integer index of the last matched capturing group, or if no group was matched at all. For example, the expressions , , and will have if applied to the string , while the expression will have , if applied to the same string. The name of the last matched capturing group, or if the group didn’t have a name, or if no group was matched at all. The regular expression object whose or method produced this match instance. The string passed to or . Changed in version 3.7: Added support of and . Match objects are considered atomic.\n\nIn this example, we’ll use the following helper function to display match objects a little more gracefully: Suppose you are writing a poker program where a player’s hand is represented as a 5-character string with each character representing a card, “a” for ace, “k” for king, “q” for queen, “j” for jack, “t” for 10, and “2” through “9” representing the card with that value. To see if a given string is a valid hand, one could do the following: That last hand, , contained a pair, or two of the same valued cards. To match this with a regular expression, one could use backreferences as such: To find out what card the pair consists of, one could use the method of the match object in the following manner: # Error because re.match() returns None, which doesn't have a group() method: File , line , in : Python does not currently have an equivalent to . Regular expressions are generally more powerful, though also more verbose, than format strings. The table below offers some more-or-less equivalent mappings between format tokens and regular expressions. To extract the filename and numbers from a string like you would use a format like The equivalent regular expression would be\n• None checks for a match only at the beginning of the string\n• None checks for a match anywhere in the string (this is what Perl does by default)\n• None checks for entire string to be a match Regular expressions beginning with can be used with to restrict the match at the beginning of the string: Note however that in mode only matches at the beginning of the string, whereas using with a regular expression beginning with will match at the beginning of each line. splits a string into a list delimited by the passed pattern. The method is invaluable for converting textual data into data structures that can be easily read and modified by Python as demonstrated in the following example that creates a phonebook. First, here is the input. Normally it may come from a file, here we are using triple-quoted string syntax The entries are separated by one or more newlines. Now we convert the string into a list with each nonempty line having its own entry: Finally, split each entry into a list with first name, last name, telephone number, and address. We use the parameter of because the address has spaces, our splitting pattern, in it: The pattern matches the colon after the last name, so that it does not occur in the result list. With a of , we could separate the house number from the street name: replaces every occurrence of a pattern with a string or the result of a function. This example demonstrates using with a function to “munge” text, or randomize the order of all the characters in each word of a sentence except for the first and last characters: matches all occurrences of a pattern, not just the first one as does. For example, if a writer wanted to find all of the adverbs in some text, they might use in the following manner: \"He was carefully disguised but captured quickly by police.\" Finding all Adverbs and their Positions¶ If one wants more information about all matches of a pattern than the matched text, is useful as it provides objects instead of strings. Continuing with the previous example, if a writer wanted to find all of the adverbs and their positions in some text, they would use in the following manner: \"He was carefully disguised but captured quickly by police.\" Raw string notation ( ) keeps regular expressions sane. Without it, every backslash ( ) in a regular expression would have to be prefixed with another one to escape it. For example, the two following lines of code are functionally identical: When one wants to match a literal backslash, it must be escaped in the regular expression. With raw string notation, this means . Without raw string notation, one must use , making the following lines of code functionally identical: A tokenizer or scanner analyzes a string to categorize groups of characters. This is a useful first step in writing a compiler or interpreter. The text categories are specified with regular expressions. The technique is to combine those into a single master regular expression and to loop over successive matches: The tokenizer produces the following output: Friedl, Jeffrey. Mastering Regular Expressions. 3rd ed., O’Reilly Media, 2009. The third edition of the book no longer covers Python at all, but the first edition covered writing good regular expression patterns in great detail."
    },
    {
        "link": "https://docs.python.org/3/howto/regex.html",
        "document": "Regular expressions (called REs, or regexes, or regex patterns) are essentially a tiny, highly specialized programming language embedded inside Python and made available through the module. Using this little language, you specify the rules for the set of possible strings that you want to match; this set might contain English sentences, or e-mail addresses, or TeX commands, or anything you like. You can then ask questions such as “Does this string match the pattern?”, or “Is there a match for the pattern anywhere in this string?”. You can also use REs to modify a string or to split it apart in various ways. Regular expression patterns are compiled into a series of bytecodes which are then executed by a matching engine written in C. For advanced use, it may be necessary to pay careful attention to how the engine will execute a given RE, and write the RE in a certain way in order to produce bytecode that runs faster. Optimization isn’t covered in this document, because it requires that you have a good understanding of the matching engine’s internals. The regular expression language is relatively small and restricted, so not all possible string processing tasks can be done using regular expressions. There are also tasks that can be done with regular expressions, but the expressions turn out to be very complicated. In these cases, you may be better off writing Python code to do the processing; while Python code will be slower than an elaborate regular expression, it will also probably be more understandable.\n\nWe’ll start by learning about the simplest possible regular expressions. Since regular expressions are used to operate on strings, we’ll begin with the most common task: matching characters. For a detailed explanation of the computer science underlying regular expressions (deterministic and non-deterministic finite automata), you can refer to almost any textbook on writing compilers. Most letters and characters will simply match themselves. For example, the regular expression will match the string exactly. (You can enable a case-insensitive mode that would let this RE match or as well; more about this later.) There are exceptions to this rule; some characters are special metacharacters, and don’t match themselves. Instead, they signal that some out-of-the-ordinary thing should be matched, or they affect other portions of the RE by repeating them or changing their meaning. Much of this document is devoted to discussing various metacharacters and what they do. Here’s a complete list of the metacharacters; their meanings will be discussed in the rest of this HOWTO. The first metacharacters we’ll look at are and . They’re used for specifying a character class, which is a set of characters that you wish to match. Characters can be listed individually, or a range of characters can be indicated by giving two characters and separating them by a . For example, will match any of the characters , , or ; this is the same as , which uses a range to express the same set of characters. If you wanted to match only lowercase letters, your RE would be . Metacharacters (except ) are not active inside classes. For example, will match any of the characters , , , or ; is usually a metacharacter, but inside a character class it’s stripped of its special nature. You can match the characters not listed within the class by complementing the set. This is indicated by including a as the first character of the class. For example, will match any character except . If the caret appears elsewhere in a character class, it does not have special meaning. For example: will match either a or a . Perhaps the most important metacharacter is the backslash, . As in Python string literals, the backslash can be followed by various characters to signal various special sequences. It’s also used to escape all the metacharacters so you can still match them in patterns; for example, if you need to match a or , you can precede them with a backslash to remove their special meaning: or . Some of the special sequences beginning with represent predefined sets of characters that are often useful, such as the set of digits, the set of letters, or the set of anything that isn’t whitespace. Let’s take an example: matches any alphanumeric character. If the regex pattern is expressed in bytes, this is equivalent to the class . If the regex pattern is a string, will match all the characters marked as letters in the Unicode database provided by the module. You can use the more restricted definition of in a string pattern by supplying the flag when compiling the regular expression. The following list of special sequences isn’t complete. For a complete list of sequences and expanded class definitions for Unicode string patterns, see the last part of Regular Expression Syntax in the Standard Library reference. In general, the Unicode versions match any character that’s in the appropriate category in the Unicode database. Matches any decimal digit; this is equivalent to the class . Matches any non-digit character; this is equivalent to the class . Matches any whitespace character; this is equivalent to the class . Matches any non-whitespace character; this is equivalent to the class . Matches any alphanumeric character; this is equivalent to the class . Matches any non-alphanumeric character; this is equivalent to the class . These sequences can be included inside a character class. For example, is a character class that will match any whitespace character, or or . The final metacharacter in this section is . It matches anything except a newline character, and there’s an alternate mode ( ) where it will match even a newline. is often used where you want to match “any character”. Being able to match varying sets of characters is the first thing regular expressions can do that isn’t already possible with the methods available on strings. However, if that was the only additional capability of regexes, they wouldn’t be much of an advance. Another capability is that you can specify that portions of the RE must be repeated a certain number of times. The first metacharacter for repeating things that we’ll look at is . doesn’t match the literal character ; instead, it specifies that the previous character can be matched zero or more times, instead of exactly once. For example, will match (0 characters), (1 ), (3 characters), and so forth. Repetitions such as are greedy; when repeating a RE, the matching engine will try to repeat it as many times as possible. If later portions of the pattern don’t match, the matching engine will then back up and try again with fewer repetitions. A step-by-step example will make this more obvious. Let’s consider the expression . This matches the letter , zero or more letters from the class , and finally ends with a . Now imagine matching this RE against the string . The engine matches , going as far as it can, which is to the end of the string. The engine tries to match , but the current position is at the end of the string, so it fails. Back up, so that matches one less character. Try again, but the current position is at the last character, which is a . Back up again, so that is only matching . Try again. This time the character at the current position is , so it succeeds. The end of the RE has now been reached, and it has matched . This demonstrates how the matching engine goes as far as it can at first, and if no match is found it will then progressively back up and retry the rest of the RE again and again. It will back up until it has tried zero matches for , and if that subsequently fails, the engine will conclude that the string doesn’t match the RE at all. Another repeating metacharacter is , which matches one or more times. Pay careful attention to the difference between and ; matches zero or more times, so whatever’s being repeated may not be present at all, while requires at least one occurrence. To use a similar example, will match (1 ), (3 s), but won’t match . There are two more repeating operators or quantifiers. The question mark character, , matches either once or zero times; you can think of it as marking something as being optional. For example, matches either or . The most complicated quantifier is , where m and n are decimal integers. This quantifier means there must be at least m repetitions, and at most n. For example, will match , , and . It won’t match , which has no slashes, or , which has four. You can omit either m or n; in that case, a reasonable value is assumed for the missing value. Omitting m is interpreted as a lower limit of 0, while omitting n results in an upper bound of infinity. The simplest case matches the preceding item exactly m times. For example, will only match . Readers of a reductionist bent may notice that the three other quantifiers can all be expressed using this notation. is the same as , is equivalent to , and is the same as . It’s better to use , , or when you can, simply because they’re shorter and easier to read.\n\nNow that we’ve looked at some simple regular expressions, how do we actually use them in Python? The module provides an interface to the regular expression engine, allowing you to compile REs into objects and then perform matches with them. Regular expressions are compiled into pattern objects, which have methods for various operations such as searching for pattern matches or performing string substitutions. also accepts an optional flags argument, used to enable various special features and syntax variations. We’ll go over the available settings later, but for now a single example will do: The RE is passed to as a string. REs are handled as strings because regular expressions aren’t part of the core Python language, and no special syntax was created for expressing them. (There are applications that don’t need REs at all, so there’s no need to bloat the language specification by including them.) Instead, the module is simply a C extension module included with Python, just like the or modules. Putting REs in strings keeps the Python language simpler, but has one disadvantage which is the topic of the next section. As stated earlier, regular expressions use the backslash character ( ) to indicate special forms or to allow special characters to be used without invoking their special meaning. This conflicts with Python’s usage of the same character for the same purpose in string literals. Let’s say you want to write a RE that matches the string , which might be found in a LaTeX file. To figure out what to write in the program code, start with the desired string to be matched. Next, you must escape any backslashes and other metacharacters by preceding them with a backslash, resulting in the string . The resulting string that must be passed to must be . However, to express this as a Python string literal, both backslashes must be escaped again. In short, to match a literal backslash, one has to write as the RE string, because the regular expression must be , and each backslash must be expressed as inside a regular Python string literal. In REs that feature backslashes repeatedly, this leads to lots of repeated backslashes and makes the resulting strings difficult to understand. The solution is to use Python’s raw string notation for regular expressions; backslashes are not handled in any special way in a string literal prefixed with , so is a two-character string containing and , while is a one-character string containing a newline. Regular expressions will often be written in Python code using this raw string notation. In addition, special escape sequences that are valid in regular expressions, but not valid as Python string literals, now result in a and will eventually become a , which means the sequences will be invalid if raw string notation or escaping the backslashes isn’t used. Once you have an object representing a compiled regular expression, what do you do with it? Pattern objects have several methods and attributes. Only the most significant ones will be covered here; consult the docs for a complete listing. Determine if the RE matches at the beginning of the string. Scan through a string, looking for any location where this RE matches. Find all substrings where the RE matches, and returns them as a list. Find all substrings where the RE matches, and returns them as an iterator. and return if no match can be found. If they’re successful, a match object instance is returned, containing information about the match: where it starts and ends, the substring it matched, and more. You can learn about this by interactively experimenting with the module. This HOWTO uses the standard Python interpreter for its examples. First, run the Python interpreter, import the module, and compile a RE: Now, you can try matching various strings against the RE . An empty string shouldn’t match at all, since means ‘one or more repetitions’. should return in this case, which will cause the interpreter to print no output. You can explicitly print the result of to make this clear. Now, let’s try it on a string that it should match, such as . In this case, will return a match object, so you should store the result in a variable for later use. Now you can query the match object for information about the matching string. Match object instances also have several methods and attributes; the most important ones are: Return the string matched by the RE Return the starting position of the match Return the ending position of the match Return a tuple containing the (start, end) positions of the match Trying these methods will soon clarify their meaning: returns the substring that was matched by the RE. and return the starting and ending index of the match. returns both start and end indexes in a single tuple. Since the method only checks if the RE matches at the start of a string, will always be zero. However, the method of patterns scans through the string, so the match may not start at zero in that case. In actual programs, the most common style is to store the match object in a variable, and then check if it was . This usually looks like: Two pattern methods return all of the matches for a pattern. returns a list of matching strings: The prefix, making the literal a raw string literal, is needed in this example because escape sequences in a normal “cooked” string literal that are not recognized by Python, as opposed to regular expressions, now result in a and will eventually become a . See The Backslash Plague. has to create the entire list before it can be returned as the result. The method returns a sequence of match object instances as an iterator: You don’t have to create a pattern object and call its methods; the module also provides top-level functions called , , , , and so forth. These functions take the same arguments as the corresponding pattern method with the RE string added as the first argument, and still return either or a match object instance. Under the hood, these functions simply create a pattern object for you and call the appropriate method on it. They also store the compiled object in a cache, so future calls using the same RE won’t need to parse the pattern again and again. Should you use these module-level functions, or should you get the pattern and call its methods yourself? If you’re accessing a regex within a loop, pre-compiling it will save a few function calls. Outside of loops, there’s not much difference thanks to the internal cache. Compilation flags let you modify some aspects of how regular expressions work. Flags are available in the module under two names, a long name such as and a short, one-letter form such as . (If you’re familiar with Perl’s pattern modifiers, the one-letter forms use the same letters; the short form of is , for example.) Multiple flags can be specified by bitwise OR-ing them; sets both the and flags, for example. Here’s a table of the available flags, followed by a more detailed explanation of each one. Makes several escapes like , , and match only on ASCII characters with the respective property. Enable verbose REs, which can be organized more cleanly and understandably. Perform case-insensitive matching; character class and literal strings will match letters by ignoring case. For example, will match lowercase letters, too. Full Unicode matching also works unless the flag is used to disable non-ASCII matches. When the Unicode patterns or are used in combination with the flag, they will match the 52 ASCII letters and 4 additional non-ASCII letters: ‘İ’ (U+0130, Latin capital letter I with dot above), ‘ı’ (U+0131, Latin small letter dotless i), ‘ſ’ (U+017F, Latin small letter long s) and ‘K’ (U+212A, Kelvin sign). will match , , , or (the latter is matched only in Unicode mode). This lowercasing doesn’t take the current locale into account; it will if you also set the flag. Make , , , and case-insensitive matching dependent on the current locale instead of the Unicode database. Locales are a feature of the C library intended to help in writing programs that take account of language differences. For example, if you’re processing encoded French text, you’d want to be able to write to match words, but only matches the character class in bytes patterns; it won’t match bytes corresponding to or . If your system is configured properly and a French locale is selected, certain C functions will tell the program that the byte corresponding to should also be considered a letter. Setting the flag when compiling a regular expression will cause the resulting compiled object to use these C functions for ; this is slower, but also enables to match French words as you’d expect. The use of this flag is discouraged in Python 3 as the locale mechanism is very unreliable, it only handles one “culture” at a time, and it only works with 8-bit locales. Unicode matching is already enabled by default in Python 3 for Unicode (str) patterns, and it is able to handle different locales/languages. Usually matches only at the beginning of the string, and matches only at the end of the string and immediately before the newline (if any) at the end of the string. When this flag is specified, matches at the beginning of the string and at the beginning of each line within the string, immediately following each newline. Similarly, the metacharacter matches either at the end of the string and at the end of each line (immediately preceding each newline). Makes the special character match any character at all, including a newline; without this flag, will match anything except a newline. Make , , , , and perform ASCII-only matching instead of full Unicode matching. This is only meaningful for Unicode patterns, and is ignored for byte patterns. This flag allows you to write regular expressions that are more readable by granting you more flexibility in how you can format them. When this flag has been specified, whitespace within the RE string is ignored, except when the whitespace is in a character class or preceded by an unescaped backslash; this lets you organize and indent the RE more clearly. This flag also lets you put comments within a RE that will be ignored by the engine; comments are marked by a that’s neither in a character class or preceded by an unescaped backslash. For example, here’s a RE that uses ; see how much easier it is to read? Without the verbose setting, the RE would look like this: In the above example, Python’s automatic concatenation of string literals has been used to break up the RE into smaller pieces, but it’s still more difficult to understand than the version using .\n\nSo far we’ve only covered a part of the features of regular expressions. In this section, we’ll cover some new metacharacters, and how to use groups to retrieve portions of the text that was matched. There are some metacharacters that we haven’t covered yet. Most of them will be covered in this section. Some of the remaining metacharacters to be discussed are zero-width assertions. They don’t cause the engine to advance through the string; instead, they consume no characters at all, and simply succeed or fail. For example, is an assertion that the current position is located at a word boundary; the position isn’t changed by the at all. This means that zero-width assertions should never be repeated, because if they match once at a given location, they can obviously be matched an infinite number of times. Alternation, or the “or” operator. If A and B are regular expressions, will match any string that matches either A or B. has very low precedence in order to make it work reasonably when you’re alternating multi-character strings. will match either or , not , a or an , and . To match a literal , use , or enclose it inside a character class, as in . Matches at the beginning of lines. Unless the flag has been set, this will only match at the beginning of the string. In mode, this also matches immediately after each newline within the string. For example, if you wish to match the word only at the beginning of a line, the RE to use is . Matches at the end of a line, which is defined as either the end of the string, or any location followed by a newline character. To match a literal , use or enclose it inside a character class, as in . Matches only at the start of the string. When not in mode, and are effectively the same. In mode, they’re different: still matches only at the beginning of the string, but may match at any location inside the string that follows a newline character. Matches only at the end of the string. Word boundary. This is a zero-width assertion that matches only at the beginning or end of a word. A word is defined as a sequence of alphanumeric characters, so the end of a word is indicated by whitespace or a non-alphanumeric character. The following example matches only when it’s a complete word; it won’t match when it’s contained inside another word. There are two subtleties you should remember when using this special sequence. First, this is the worst collision between Python’s string literals and regular expression sequences. In Python’s string literals, is the backspace character, ASCII value 8. If you’re not using raw strings, then Python will convert the to a backspace, and your RE won’t match as you expect it to. The following example looks the same as our previous RE, but omits the in front of the RE string. Second, inside a character class, where there’s no use for this assertion, represents the backspace character, for compatibility with Python’s string literals. Another zero-width assertion, this is the opposite of , only matching when the current position is not at a word boundary. Frequently you need to obtain more information than just whether the RE matched or not. Regular expressions are often used to dissect strings by writing a RE divided into several subgroups which match different components of interest. For example, an RFC-822 header line is divided into a header name and a value, separated by a , like this: This can be handled by writing a regular expression which matches an entire header line, and has one group which matches the header name, and another group which matches the header’s value. Groups are marked by the , metacharacters. and have much the same meaning as they do in mathematical expressions; they group together the expressions contained inside them, and you can repeat the contents of a group with a quantifier, such as , , , or . For example, will match zero or more repetitions of . Groups indicated with , also capture the starting and ending index of the text that they match; this can be retrieved by passing an argument to , , , and . Groups are numbered starting with 0. Group 0 is always present; it’s the whole RE, so match object methods all have group 0 as their default argument. Later we’ll see how to express groups that don’t capture the span of text that they match. Subgroups are numbered from left to right, from 1 upward. Groups can be nested; to determine the number, just count the opening parenthesis characters, going from left to right. can be passed multiple group numbers at a time, in which case it will return a tuple containing the corresponding values for those groups. The method returns a tuple containing the strings for all the subgroups, from 1 up to however many there are. Backreferences in a pattern allow you to specify that the contents of an earlier capturing group must also be found at the current location in the string. For example, will succeed if the exact contents of group 1 can be found at the current position, and fails otherwise. Remember that Python’s string literals also use a backslash followed by numbers to allow including arbitrary characters in a string, so be sure to use a raw string when incorporating backreferences in a RE. For example, the following RE detects doubled words in a string. 'Paris in the the spring' Backreferences like this aren’t often useful for just searching through a string — there are few text formats which repeat data in this way — but you’ll soon find out that they’re very useful when performing string substitutions. Elaborate REs may use many groups, both to capture substrings of interest, and to group and structure the RE itself. In complex REs, it becomes difficult to keep track of the group numbers. There are two features which help with this problem. Both of them use a common syntax for regular expression extensions, so we’ll look at that first. Perl 5 is well known for its powerful additions to standard regular expressions. For these new features the Perl developers couldn’t choose new single-keystroke metacharacters or new special sequences beginning with without making Perl’s regular expressions confusingly different from standard REs. If they chose as a new metacharacter, for example, old expressions would be assuming that was a regular character and wouldn’t have escaped it by writing or . The solution chosen by the Perl developers was to use as the extension syntax. immediately after a parenthesis was a syntax error because the would have nothing to repeat, so this didn’t introduce any compatibility problems. The characters immediately after the indicate what extension is being used, so is one thing (a positive lookahead assertion) and is something else (a non-capturing group containing the subexpression ). Python supports several of Perl’s extensions and adds an extension syntax to Perl’s extension syntax. If the first character after the question mark is a , you know that it’s an extension that’s specific to Python. Now that we’ve looked at the general extension syntax, we can return to the features that simplify working with groups in complex REs. Sometimes you’ll want to use a group to denote a part of a regular expression, but aren’t interested in retrieving the group’s contents. You can make this fact explicit by using a non-capturing group: , where you can replace the with any other regular expression. Except for the fact that you can’t retrieve the contents of what the group matched, a non-capturing group behaves exactly the same as a capturing group; you can put anything inside it, repeat it with a repetition metacharacter such as , and nest it within other groups (capturing or non-capturing). is particularly useful when modifying an existing pattern, since you can add new groups without changing how all the other groups are numbered. It should be mentioned that there’s no performance difference in searching between capturing and non-capturing groups; neither form is any faster than the other. A more significant feature is named groups: instead of referring to them by numbers, groups can be referenced by a name. The syntax for a named group is one of the Python-specific extensions: . name is, obviously, the name of the group. Named groups behave exactly like capturing groups, and additionally associate a name with a group. The match object methods that deal with capturing groups all accept either integers that refer to the group by number or strings that contain the desired group’s name. Named groups are still given numbers, so you can retrieve information about a group in two ways: Additionally, you can retrieve named groups as a dictionary with : Named groups are handy because they let you use easily remembered names, instead of having to remember numbers. Here’s an example RE from the module: It’s obviously much easier to retrieve , instead of having to remember to retrieve group 9. The syntax for backreferences in an expression such as refers to the number of the group. There’s naturally a variant that uses the group name instead of the number. This is another Python extension: indicates that the contents of the group called name should again be matched at the current point. The regular expression for finding doubled words, can also be written as : 'Paris in the the spring' Another zero-width assertion is the lookahead assertion. Lookahead assertions are available in both positive and negative form, and look like this: Positive lookahead assertion. This succeeds if the contained regular expression, represented here by , successfully matches at the current location, and fails otherwise. But, once the contained expression has been tried, the matching engine doesn’t advance at all; the rest of the pattern is tried right where the assertion started. Negative lookahead assertion. This is the opposite of the positive assertion; it succeeds if the contained expression doesn’t match at the current position in the string. To make this concrete, let’s look at a case where a lookahead is useful. Consider a simple pattern to match a filename and split it apart into a base name and an extension, separated by a . For example, in , is the base name, and is the filename’s extension. The pattern to match this is quite simple: Notice that the needs to be treated specially because it’s a metacharacter, so it’s inside a character class to only match that specific character. Also notice the trailing ; this is added to ensure that all the rest of the string must be included in the extension. This regular expression matches and and and . Now, consider complicating the problem a bit; what if you want to match filenames where the extension is not ? Some incorrect attempts: The first attempt above tries to exclude by requiring that the first character of the extension is not a . This is wrong, because the pattern also doesn’t match . The expression gets messier when you try to patch up the first solution by requiring one of the following cases to match: the first character of the extension isn’t ; the second character isn’t ; or the third character isn’t . This accepts and rejects , but it requires a three-letter extension and won’t accept a filename with a two-letter extension such as . We’ll complicate the pattern again in an effort to fix it. In the third attempt, the second and third letters are all made optional in order to allow matching extensions shorter than three characters, such as . The pattern’s getting really complicated now, which makes it hard to read and understand. Worse, if the problem changes and you want to exclude both and as extensions, the pattern would get even more complicated and confusing. A negative lookahead cuts through all this confusion: The negative lookahead means: if the expression doesn’t match at this point, try the rest of the pattern; if does match, the whole pattern will fail. The trailing is required to ensure that something like , where the extension only starts with , will be allowed. The makes sure that the pattern works when there are multiple dots in the filename. Excluding another filename extension is now easy; simply add it as an alternative inside the assertion. The following pattern excludes filenames that end in either or :\n\nUp to this point, we’ve simply performed searches against a static string. Regular expressions are also commonly used to modify strings in various ways, using the following pattern methods: Split the string into a list, splitting it wherever the RE matches Find all substrings where the RE matches, and replace them with a different string Does the same thing as , but returns the new string and the number of replacements The method of a pattern splits a string apart wherever the RE matches, returning a list of the pieces. It’s similar to the method of strings but provides much more generality in the delimiters that you can split by; string only supports splitting by whitespace or by a fixed string. As you’d expect, there’s a module-level function, too. Split string by the matches of the regular expression. If capturing parentheses are used in the RE, then their contents will also be returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits are performed. You can limit the number of splits made, by passing a value for maxsplit. When maxsplit is nonzero, at most maxsplit splits will be made, and the remainder of the string is returned as the final element of the list. In the following example, the delimiter is any sequence of non-alphanumeric characters. 'This is a test, short and sweet, of split().' ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', ''] 'This is a test, short and sweet, of split().' ['This', 'is', 'a', 'test, short and sweet, of split().'] Sometimes you’re not only interested in what the text between delimiters is, but also need to know what the delimiter was. If capturing parentheses are used in the RE, then their values are also returned as part of the list. Compare the following calls: The module-level function adds the RE to be used as the first argument, but is otherwise the same. Another common task is to find all the matches for a pattern, and replace them with a different string. The method takes a replacement value, which can be either a string or a function, and the string to be processed. Returns the string obtained by replacing the leftmost non-overlapping occurrences of the RE in string by the replacement replacement. If the pattern isn’t found, string is returned unchanged. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a non-negative integer. The default value of 0 means to replace all occurrences. Here’s a simple example of using the method. It replaces colour names with the word : The method does the same work, but returns a 2-tuple containing the new string value and the number of replacements that were performed: Empty matches are replaced only when they’re not adjacent to a previous empty match. If replacement is a string, any backslash escapes in it are processed. That is, is converted to a single newline character, is converted to a carriage return, and so forth. Unknown escapes such as are left alone. Backreferences, such as , are replaced with the substring matched by the corresponding group in the RE. This lets you incorporate portions of the original text in the resulting replacement string. This example matches the word followed by a string enclosed in , , and changes to : There’s also a syntax for referring to named groups as defined by the syntax. will use the substring matched by the group named , and uses the corresponding group number. is therefore equivalent to , but isn’t ambiguous in a replacement string such as . ( would be interpreted as a reference to group 20, not a reference to group 2 followed by the literal character .) The following substitutions are all equivalent, but use all three variations of the replacement string. replacement can also be a function, which gives you even more control. If replacement is a function, the function is called for every non-overlapping occurrence of pattern. On each call, the function is passed a match object argument for the match and can use this information to compute the desired replacement string and return it. In the following example, the replacement function translates decimals into hexadecimal: When using the module-level function, the pattern is passed as the first argument. The pattern may be provided as an object or as a string; if you need to specify regular expression flags, you must either use a pattern object as the first parameter, or use embedded modifiers in the pattern string, e.g. returns .\n\nRegular expressions are a powerful tool for some applications, but in some ways their behaviour isn’t intuitive and at times they don’t behave the way you may expect them to. This section will point out some of the most common pitfalls. Sometimes using the module is a mistake. If you’re matching a fixed string, or a single character class, and you’re not using any features such as the flag, then the full power of regular expressions may not be required. Strings have several methods for performing operations with fixed strings and they’re usually much faster, because the implementation is a single small C loop that’s been optimized for the purpose, instead of the large, more generalized regular expression engine. One example might be replacing a single fixed string with another one; for example, you might replace with . seems like the function to use for this, but consider the method. Note that will also replace inside words, turning into , but the naive RE would have done that, too. (To avoid performing the substitution on parts of words, the pattern would have to be , in order to require that have a word boundary on either side. This takes the job beyond ’s abilities.) Another common task is deleting every occurrence of a single character from a string or replacing it with another single character. You might do this with something like , but is capable of doing both tasks and will be faster than any regular expression operation can be. In short, before turning to the module, consider whether your problem can be solved with a faster and simpler string method. The function only checks if the RE matches at the beginning of the string while will scan forward through the string for a match. It’s important to keep this distinction in mind. Remember, will only report a successful match which will start at 0; if the match wouldn’t start at zero, will not report it. On the other hand, will scan forward through the string, reporting the first match it finds. Sometimes you’ll be tempted to keep using , and just add to the front of your RE. Resist this temptation and use instead. The regular expression compiler does some analysis of REs in order to speed up the process of looking for a match. One such analysis figures out what the first character of a match must be; for example, a pattern starting with must match starting with a . The analysis lets the engine quickly scan through the string looking for the starting character, only trying the full match if a is found. Adding defeats this optimization, requiring scanning to the end of the string and then backtracking to find a match for the rest of the RE. Use instead. When repeating a regular expression, as in , the resulting action is to consume as much of the pattern as possible. This fact often bites you when you’re trying to match a pair of balanced delimiters, such as the angle brackets surrounding an HTML tag. The naive pattern for matching a single HTML tag doesn’t work because of the greedy nature of . The RE matches the in , and the consumes the rest of the string. There’s still more left in the RE, though, and the can’t match at the end of the string, so the regular expression engine has to backtrack character by character until it finds a match for the . The final match extends from the in to the in , which isn’t what you want. In this case, the solution is to use the non-greedy quantifiers , , , or , which match as little text as possible. In the above example, the is tried immediately after the first matches, and when it fails, the engine advances a character at a time, retrying the at every step. This produces just the right result: By now you’ve probably noticed that regular expressions are a very compact notation, but they’re not terribly readable. REs of moderate complexity can become lengthy collections of backslashes, parentheses, and metacharacters, making them difficult to read and understand. For such REs, specifying the flag when compiling the regular expression can be helpful, because it allows you to format the regular expression more clearly. The flag has several effects. Whitespace in the regular expression that isn’t inside a character class is ignored. This means that an expression such as is equivalent to the less readable , but will still match the characters , , or a space. In addition, you can also put comments inside a RE; comments extend from a character to the next newline. When used with triple-quoted strings, this enables REs to be formatted more neatly: (?P<value>.*?) # The header's value -- *? used to This is far more readable than:"
    },
    {
        "link": "https://developers.google.com/edu/python/regular-expressions",
        "document": "Regular expressions are a powerful language for matching text patterns. This page gives a basic introduction to regular expressions themselves sufficient for our Python exercises and shows how regular expressions work in Python. The Python \"re\" module provides regular expression support.\n\nIn Python a regular expression search is typically written as:\n\nThe re.search() method takes a regular expression pattern and a string and searches for that pattern within the string. If the search is successful, search() returns a match object or None otherwise. Therefore, the search is usually immediately followed by an if-statement to test if the search succeeded, as shown in the following example which searches for the pattern 'word:' followed by a 3 letter word (details below):\n\nThe code stores the search result in a variable named \"match\". Then the if-statement tests the match -- if true the search succeeded and match.group() is the matching text (e.g. 'word:cat'). Otherwise if the match is false (None to be more specific), then the search did not succeed, and there is no matching text.\n\nThe 'r' at the start of the pattern string designates a python \"raw\" string which passes through backslashes without change which is very handy for regular expressions (Java needs this feature badly!). I recommend that you always write pattern strings with the 'r' just as a habit.\n\nThe power of regular expressions is that they can specify patterns, not just fixed characters. Here are the most basic patterns which match single chars:\n• a, X, 9, < -- ordinary characters just match themselves exactly. The meta-characters which do not match themselves because they have special meanings are: . ^ $ * + ? { [ ] \\ | ( ) (details below)\n• \\w -- (lowercase w) matches a \"word\" character: a letter or digit or underbar [a-zA-Z0-9_]. Note that although \"word\" is the mnemonic for this, it only matches a single word char, not a whole word. \\W (upper case W) matches any non-word character.\n• \\d -- decimal digit [0-9] (some older regex utilities do not support \\d, but they all support \\w and \\s)\n• ^ = start, $ = end -- match the start or end of the string\n• \\ -- inhibit the \"specialness\" of a character. So, for example, use \\. to match a period or \\\\ to match a slash. If you are unsure if a character has special meaning, such as '@', you can try putting a slash in front of it, \\@. If its not a valid escape sequence, like \\c, your python program will halt with an error.\n\nJoke: what do you call a pig with three eyes? piiig!\n\nThe basic rules of regular expression search for a pattern within a string are:\n• The search proceeds through the string from start to end, stopping at the first match found\n• All of the pattern must be matched, but not all of the string\n• If is successful, match is not None and in particular match.group() is the matching text\n\nThings get more interesting when you use + and * to specify repetition in the pattern\n• + -- 1 or more occurrences of the pattern to its left, e.g. 'i+' = one or more i's\n• * -- 0 or more occurrences of the pattern to its left\n• ? -- match 0 or 1 occurrences of the pattern to its left\n\nFirst the search finds the leftmost match for the pattern, and second it tries to use up as much of the string as possible -- i.e. + and * go as far as possible (the + and * are said to be \"greedy\").\n\nSuppose you want to find the email address inside the string 'xyz alice-b@google.com purple monkey'. We'll use this as a running example to demonstrate more regular expression features. Here's an attempt using the pattern r'\\w+@\\w+':\n\nThe search does not get the whole email address in this case because the \\w does not match the '-' or '.' in the address. We'll fix this using the regular expression features below.\n\nSquare brackets can be used to indicate a set of chars, so [abc] matches 'a' or 'b' or 'c'. The codes \\w, \\s etc. work inside square brackets too with the one exception that dot (.) just means a literal dot. For the emails problem, the square brackets are an easy way to add '.' and '-' to the set of chars which can appear around the @ with the pattern r'[\\w.-]+@[\\w.-]+' to get the whole email address:\n\n(More square-bracket features) You can also use a dash to indicate a range, so [a-z] matches all lowercase letters. To use a dash without indicating a range, put the dash last, e.g. [abc-]. An up-hat (^) at the start of a square-bracket set inverts it, so [^ab] means any char except 'a' or 'b'.\n\nThe \"group\" feature of a regular expression allows you to pick out parts of the matching text. Suppose for the emails problem that we want to extract the username and host separately. To do this, add parentheses ( ) around the username and host in the pattern, like this: r'([\\w.-]+)@([\\w.-]+)'. In this case, the parentheses do not change what the pattern will match, instead they establish logical \"groups\" inside of the match text. On a successful search, match.group(1) is the match text corresponding to the 1st left parentheses, and match.group(2) is the text corresponding to the 2nd left parentheses. The plain match.group() is still the whole match text as usual.\n\nA common workflow with regular expressions is that you write a pattern for the thing you are looking for, adding parentheses groups to extract the parts you want.\n\nfindall() is probably the single most powerful function in the re module. Above we used re.search() to find the first match for a pattern. findall() finds *all* the matches and returns them as a list of strings, with each string representing one match.\n\nFor files, you may be in the habit of writing a loop to iterate over the lines of the file, and you could then call findall() on each line. Instead, let findall() do the iteration for you -- much better! Just feed the whole file text into findall() and let it return a list of all the matches in a single step (recall that f.read() returns the whole text of a file in a single string):\n\nThe parentheses ( ) group mechanism can be combined with findall(). If the pattern includes 2 or more parentheses groups, then instead of returning a list of strings, findall() returns a list of *tuples*. Each tuple represents one match of the pattern, and inside the tuple is the group(1), group(2) .. data. So if 2 parentheses groups are added to the email pattern, then findall() returns a list of tuples, each length 2 containing the username and host, e.g. ('alice', 'google.com').\n\nOnce you have the list of tuples, you can loop over it to do some computation for each tuple. If the pattern includes no parentheses, then findall() returns a list of found strings as in earlier examples. If the pattern includes a single set of parentheses, then findall() returns a list of strings corresponding to that single group. (Obscure optional feature: Sometimes you have paren ( ) groupings in the pattern, but which you do not want to extract. In that case, write the parens with a ?: at the start, e.g. (?: ) and that left paren will not count as a group result.)\n\nRegular expression patterns pack a lot of meaning into just a few characters , but they are so dense, you can spend a lot of time debugging your patterns. Set up your runtime so you can run a pattern and print what it matches easily, for example by running it on a small test text and printing the result of findall(). If the pattern matches nothing, try weakening the pattern, removing parts of it so you get too many matches. When it's matching nothing, you can't make any progress since there's nothing concrete to look at. Once it's matching too much, then you can work on tightening it up incrementally to hit just what you want.\n\nThe re functions take options to modify the behavior of the pattern match. The option flag is added as an extra argument to the search() or findall() etc., e.g. re.search(pat, str, re.IGNORECASE).\n• IGNORECASE -- ignore upper/lowercase differences for matching, so 'a' matches both 'a' and 'A'.\n• DOTALL -- allow dot (.) to match newline -- normally it matches anything but newline. This can trip you up -- you think .* matches everything, but by default it does not go past the end of a line. Note that \\s (whitespace) includes newlines, so if you want to match a run of whitespace that may include a newline, you can just use \\s*\n• MULTILINE -- Within a string made of many lines, allow ^ and $ to match the start and end of each line. Normally ^/$ would just match the start and end of the whole string.\n\nThis is optional section which shows a more advanced regular expression technique not needed for the exercises.\n\nSuppose you have text with tags in it: <b>foo</b> and <i>so on</i>\n\nSuppose you are trying to match each tag with the pattern '(<.*>)' -- what does it match first?\n\nThe result is a little surprising, but the greedy aspect of the .* causes it to match the whole '<b>foo</b> and <i>so on</i>' as one big match. The problem is that the .* goes as far as is it can, instead of stopping at the first > (aka it is \"greedy\").\n\nThere is an extension to regular expression where you add a ? at the end, such as .*? or .+?, changing them to be non-greedy. Now they stop as soon as they can. So the pattern '(<.*?>)' will get just '<b>' as the first match, and '</b>' as the second match, and so on getting each <..> pair in turn. The style is typically that you use a .*? immediately followed by some concrete marker (> in this case) to which the .*? run is forced to extend.\n\nThe *? extension originated in Perl, and regular expressions that include Perl's extensions are known as Perl Compatible Regular Expressions -- pcre. Python includes pcre support. Many command line utils etc. have a flag where they accept pcre patterns.\n\nAn older but widely used technique to code this idea of \"all of these chars except stopping at X\" uses the square-bracket style. For the above you could write the pattern, but instead of .* to get all the chars, use [^>]* which skips over all characters which are not > (the leading ^ \"inverts\" the square bracket set, so it matches any char not in the brackets).\n\nThe re.sub(pat, replacement, str) function searches for all the instances of pattern in the given string, and replaces them. The replacement string can include '\\1', '\\2' which refer to the text from group(1), group(2), and so on from the original matching text.\n\nHere's an example which searches for all the email addresses, and changes them to keep the user (\\1) but have yo-yo-dyne.com as the host.\n\nTo practice regular expressions, see the Baby Names Exercise."
    },
    {
        "link": "https://w3schools.com/python/python_regex.asp",
        "document": "A RegEx, or Regular Expression, is a sequence of characters that forms a search pattern.\n\nRegEx can be used to check if a string contains the specified search pattern.\n\nPython has a built-in package called , which can be used to work with Regular Expressions.\n\nWhen you have imported the module, you can start using regular expressions:\n\nThe module offers a set of functions that allows us to search a string for a match:\n\nA special sequence is a followed by one of the characters in the list below, and has a special meaning:\n\nA set is a set of characters inside a pair of square brackets with a special meaning:\n\nThe function returns a list containing all matches.\n\nThe list contains the matches in the order they are found.\n\nIf no matches are found, an empty list is returned:\n\nThe function searches the string for a match, and returns a Match object if there is a match.\n\nIf there is more than one match, only the first occurrence of the match will be returned:\n\nIf no matches are found, the value is returned:\n\nThe function returns a list where the string has been split at each match:\n\nYou can control the number of occurrences by specifying the parameter:\n\nThe function replaces the matches with the text of your choice:\n\nYou can control the number of replacements by specifying the parameter:\n\nA Match Object is an object containing information about the search and the result.\n\nThe Match object has properties and methods used to retrieve information about the search, and the result:\n\nreturns a tuple containing the start-, and end positions of the match.\n\n returns the string passed into the function\n\n returns the part of the string where there was a match"
    },
    {
        "link": "https://pymotw.com/2/re",
        "document": "Regular expressions are text matching patterns described with a formal syntax. The patterns are interpreted as a set of instructions, which are then executed with a string as input to produce a matching subset or modified version of the original. The term “regular expressions” is frequently shortened to as “regex” or “regexp” in conversation. Expressions can include literal text matching, repetition, pattern-composition, branching, and other sophisticated rules. A large number of parsing problems are easier to solve with a regular expression than by creating a special-purpose lexer and parser.\n\nRegular expressions are typically used in applications that involve a lot of text processing. For example, they are commonly used as search patterns in text editing programs used by developers, including vi, emacs, and modern IDEs. They are also an integral part of Unix command line utilities such as sed, grep, and awk. Many programming languages include support for regular expressions in the language syntax (Perl, Ruby, Awk, and Tcl). Other languages, such as C, C++, and Python supports regular expressions through extension libraries.\n\nThere are multiple open source implementations of regular expressions, each sharing a common core syntax but with different extensions or modifications to their advanced features. The syntax used in Python’s module is based on the syntax used for regular expressions in Perl, with a few Python-specific enhancements.\n\nRegular expressions support more powerful patterns than simple literal text strings. Patterns can repeat, can be anchored to different logical locations within the input, and can be expressed in compact forms that don’t require every literal character be present in the pattern. All of these features are used by combining literal text values with metacharacters that are part of the regular expression pattern syntax implemented by . The following examples will use this test program to explore variations in patterns. \"\"\"Given source text and a list of patterns, look for matches for each pattern within the text and print # Look for each pattern in the text and print the results \\ The output of shows the input text, including the character positions, as well as the substring range from each portion of the input that matches the pattern. There are five ways to express repetition in a pattern. A pattern followed by the metacharacter is repeated zero or more times (allowing a pattern to repeat zero times means it does not need to appear at all to match). Replace the with and the pattern must appear at least once. Using means the pattern appears zero or one time. For a specific number of occurrences, use after the pattern, where m is replaced with the number of times the pattern should repeat. And finally, to allow a variable but limited number of repetitions, use where m is the minimum number of repetitions and n is the maximum. Leaving out n ( ) means the value appears at least m times, with no maximum. # a followed by zero or more b # a followed by one or more b # a followed by zero or one b # a followed by two to three b Notice how many more matches there are for and than . The normal processing for a repetition instruction is to consume as much of the input as possible while matching the pattern. This so-called greedy behavior may result in fewer individual matches, or the matches may include more of the input text than intended. Greediness can be turned off by following the repetition instruction with . # a followed by zero or more b # a followed by one or more b # a followed by zero or one b # a followed by two to three b Disabling greedy consumption of the input for any of the patterns where zero occurences of are allowed means the matched substring does not include any characters. A character set is a group of characters, any one of which can match at that point in the pattern. For example, would match either or . # a followed by one or more a or b # a followed by one or more a or b, not greedy The greedy form of the expression, , consumes the entire string because the first letter is and every subsequent character is either or . A character set can also be used to exclude specific characters. The special marker means to look for characters not in the set following. 'This is some text -- with punctuation.' This pattern finds all of the substrings that do not contain the characters , , or a space. $ python re_charset_exclude.py 1111111111222222222233333333 01234567890123456789012345678901234567 This is some text -- with punctuation. Matching \"[^-. ]+\" 0 : 3 = \"This\" 5 : 6 = \"is\" 8 : 11 = \"some\" 13 : 16 = \"text\" 21 : 24 = \"with\" 26 : 36 = \"punctuation\" As character sets grow larger, typing every character that should (or should not) match becomes tedious. A more compact format using character ranges lets you define a character set to include all of the contiguous characters between a start and stop point. 'This is some text -- with punctuation.' # one upper case letter followed by lower case letters Here the range includes the lower case ASCII letters, and the range includes the upper case ASCII letters. The ranges can also be combined into a single character set. $ python re_charset_ranges.py 1111111111222222222233333333 01234567890123456789012345678901234567 This is some text -- with punctuation. Matching \"[a-z]+\" 1 : 3 = \"his\" 5 : 6 = \"is\" 8 : 11 = \"some\" 13 : 16 = \"text\" 21 : 24 = \"with\" 26 : 36 = \"punctuation\" Matching \"[A-Z]+\" 0 : 0 = \"T\" Matching \"[a-zA-Z]+\" 0 : 3 = \"This\" 5 : 6 = \"is\" 8 : 11 = \"some\" 13 : 16 = \"text\" 21 : 24 = \"with\" 26 : 36 = \"punctuation\" Matching \"[A-Z][a-z]+\" 0 : 3 = \"This\" As a special case of a character set the metacharacter dot, or period ( ), indicates that the pattern should match any single character in that position. # a followed by any one character # b followed by any one character # a followed by anything, ending in b # a followed by anything, ending in b Combining dot with repetition can result in very long matches, unless the non-greedy form is used. An even more compact representation uses escape codes for several pre-defined character sets. The escape codes recognized by are: Escapes are indicated by prefixing the character with a backslash ( ). Unfortunately, a backslash must itself be escaped in normal Python strings, and that results in expressions that are difficult to read. Using raw strings, created by prefixing the literal value with , for creating regular expressions eliminates this problem and maintains readability. 'This is a prime #1 example!' These sample expressions combine escape codes with repetition to find sequences of like characters in the input string. $ python re_escape_codes.py 11111111112222222 012345678901234567890123456 This is a prime #1 example! Matching \"\\d+\" 17 : 17 = \"1\" Matching \"\\D+\" 0 : 16 = \"This is a prime #\" 18 : 26 = \" example!\" Matching \"\\s+\" 4 : 4 = \" \" 7 : 7 = \" \" 9 : 9 = \" \" 15 : 15 = \" \" 18 : 18 = \" \" Matching \"\\S+\" 0 : 3 = \"This\" 5 : 6 = \"is\" 8 : 8 = \"a\" 10 : 14 = \"prime\" 16 : 17 = \"#1\" 19 : 26 = \"example!\" Matching \"\\w+\" 0 : 3 = \"This\" 5 : 6 = \"is\" 8 : 8 = \"a\" 10 : 14 = \"prime\" 17 : 17 = \"1\" 19 : 25 = \"example\" Matching \"\\W+\" 4 : 4 = \" \" 7 : 7 = \" \" 9 : 9 = \" \" 15 : 16 = \" #\" 18 : 18 = \" \" 26 : 26 = \"!\" To match the characters that are part of the regular expression syntax, escape the characters in the search pattern. These patterns escape the backslash and plus characters, since as metacharacters both have special meaning in a regular expression. In addition to describing the content of a pattern to match, you can also specify the relative location in the input text where the pattern should appear using anchoring instructions. empty string at the beginning or end of a word empty string not at the beginning or end of a word 'This is some text -- with punctuation.' # word at end of string, with optional punctuation # word at end of string, with optional punctuation # 't', not start or end of word The patterns in the example for matching words at the beginning and end of the string are different because the word at the end of the string is followed by punctuation to terminate the sentence. The pattern would not match, since is not considered an alphanumeric character. $ python re_anchoring.py 1111111111222222222233333333 01234567890123456789012345678901234567 This is some text -- with punctuation. Matching \"^\\w+\" 0 : 3 = \"This\" Matching \"\\A\\w+\" 0 : 3 = \"This\" Matching \"\\w+\\S*$\" 26 : 37 = \"punctuation.\" Matching \"\\w+\\S*\\Z\" 26 : 37 = \"punctuation.\" Matching \"\\w*t\\w*\" 13 : 16 = \"text\" 21 : 24 = \"with\" 26 : 36 = \"punctuation\" Matching \"\\bt\\w+\" 13 : 16 = \"text\" Matching \"\\w+t\\b\" 13 : 16 = \"text\" Matching \"\\Bt\\B\" 23 : 23 = \"t\" 30 : 30 = \"t\" 33 : 33 = \"t\"\n\nSearching for pattern matches is the basis of the powerful capabilities provided by regular expressions. Adding groups to a pattern lets you isolate parts of the matching text, expanding those capabilities to create a parser. Groups are defined by enclosing patterns in parentheses ( and ). # 'a' followed by 0-n 'a' and 0-n 'b' Any complete regular expression can be converted to a group and nested within a larger expression. All of the repetition modifiers can be applied to a group as a whole, requiring the entire group pattern to repeat. To access the substrings matched by the individual groups within a pattern, use the method of the object. 'This is some text -- with punctuation.' # word at end of string, with optional punctuation # word starting with 't' then another word returns a sequence of strings in the order of the group within the expression that matches the string. $ python re_groups_match.py This is some text -- with punctuation. Matching \"^(\\w+)\" ('This',) Matching \"(\\w+)\\S*$\" ('punctuation',) Matching \"(\\bt\\w+)\\W+(\\w+)\" ('text', 'with') Matching \"(\\w+t)\\b\" ('text',) If you are using grouping to find parts of the string, but you don’t need all of the parts matched by groups, you can ask for the match of only a single group with . 'This is some text -- with punctuation.' # word starting with 't' then another word Group represents the string matched by the entire expression, and sub-groups are numbered starting with in the order their left parenthesis appears in the expression. $ python re_groups_individual.py Input text : This is some text -- with punctuation. Pattern : (\\bt\\w+)\\W+(\\w+) Entire match : text -- with Word starting with \"t\": text Word after \"t\" word : with Python extends the basic grouping syntax to add named groups. Using names to refer to groups makes it easier to modify the pattern over time, without having to also modify the code using the match results. To set the name of a group, use the syntax . 'This is some text -- with punctuation.' Use to retrieve the dictionary mapping group names to substrings from the match. Named patterns are included in the ordered sequence returned by , as well. $ python re_groups_named.py This is some text -- with punctuation. Matching \"^(?P<first_word>\\w+)\" ('This',) {'first_word': 'This'} Matching \"(?P<last_word>\\w+)\\S*$\" ('punctuation',) {'last_word': 'punctuation'} Matching \"(?P<t_word>\\bt\\w+)\\W+(?P<other_word>\\w+)\" ('text', 'with') {'other_word': 'with', 't_word': 'text'} Matching \"(?P<ends_with_t>\\w+t)\\b\" ('text',) {'ends_with_t': 'text'} An updated version of that shows the numbered and named groups matched by a pattern will make the following examples easier to follow. \"\"\"Given source text and a list of patterns, look for matches for each pattern within the text and print # Look for each pattern in the text and print the results \\ Since a group is itself a complete regular expression, groups can be nested within other groups to build even more complicated expressions. # 'a' followed by 0-n 'a' and 0-n 'b' In this case, the group matches an empty string, so the return value from includes that empty string as the matched value. Groups are also useful for specifying alternative patterns. Use to indicate that one pattern or another should match. Consider the placement of the carefully, though. The first expression in this example matches a sequence of followed by a sequence consisting entirely of a single letter, or . The second pattern matches followed by a sequence that may include either or . The patterns are similar, but the resulting matches are completely different. # 'a' followed by a sequence of 'a' or sequence of 'b' # 'a' followed by a sequence of 'a' or 'b' When an alternative group is not matched, but the entire pattern does match, the return value of includes a value at the point in the sequence where the alternative group should appear. $ python re_groups_alternative.py 11111 012345678901234 abbaaabbbbaaaaa Matching \"a((a+)|(b+))\" 0 : 2 = \"abb\" Groups: ('bb', None, 'bb') 3 : 5 = \"aaa\" Groups: ('aa', 'aa', None) 10 : 14 = \"aaaaa\" Groups: ('aaaa', 'aaaa', None) Matching \"a((a|b)+)\" 0 : 14 = \"abbaaabbbbaaaaa\" Groups: ('bbaaabbbbaaaaa', 'a') Defining a group containing a sub-pattern is also useful in cases where the string matching the sub-pattern is not part of what you want to extract from the full text. These groups are called non-capturing. To create a non-capturing group, use the syntax . Compare the groups returned for the capturing and non-capturing forms of a pattern that matches the same results. $ python re_groups_non_capturing.py 11111 012345678901234 abbaaabbbbaaaaa Matching \"a((a+)|(b+))\" 0 : 2 = \"abb\" Groups: ('bb', None, 'bb') 3 : 5 = \"aaa\" Groups: ('aa', 'aa', None) 10 : 14 = \"aaaaa\" Groups: ('aaaa', 'aaaa', None) Matching \"a((?:a+)|(?:b+))\" 0 : 2 = \"abb\" Groups: ('bb',) 3 : 5 = \"aaa\" Groups: ('aa',) 10 : 14 = \"aaaaa\" Groups: ('aaaa',)\n\nYou can change the way the matching engine processes an expression using option flags. The flags can be combined using a bitwise or operation, and passed to , , , and other functions that accept a pattern for searching. causes literal characters and character ranges in the pattern to match both upper and lower case characters. 'This is some text -- with punctuation.' Since the pattern includes the literal , without setting the only match is the word . When case is ignored, also matches. $ python re_flags_ignorecase.py Text : This is some text -- with punctuation. Pattern : \\bT\\w+ Case-sensitive : ['This'] Case-insensitive: ['This', 'text'] There are two flags that effect how searching in multi-line input works. The flag controls how the pattern matching code processes anchoring instructions for text containing newline characters. When multiline mode is turned on, the anchor rules for and apply at the beginning and end of each line, in addition to the entire string. 'This is some text -- with punctuation. The pattern in the example matches the first or last word of the input. It matches at the end of the string, even though there is no newline. $ python re_flags_multiline.py Text : 'This is some text -- with punctuation.\n\nAnd a second line.' Pattern : (^\\w+)|(\\w+\\S*$) Single Line : [('This', ''), ('', 'line.')] Multline : [('This', ''), ('', 'punctuation.'), ('And', ''), ('', 'line.')] is the other flag related to multiline text. Normally the dot character matches everything in the input text except a newline character. The flag allows dot to match newlines as well. 'This is some text -- with punctuation. Without the flag, each line of the input text matches the pattern separately. Adding the flag causes the entire string to be consumed. $ python re_flags_dotall.py Text : 'This is some text -- with punctuation.\n\nAnd a second line.' Pattern : .+ No newlines : ['This is some text -- with punctuation.', 'And a second line.'] Dotall : ['This is some text -- with punctuation.\n\nAnd a second line.'] Under Python 2, objects use the ASCII character set, and regular expression processing assumes that the pattern and input text are both ASCII. The escape codes described earlier are defined in terms of ASCII by default. Those assumptions mean that the pattern will match the word “French” but not “Français”, since the is not part of the ASCII character set. To enable Unicode matching in Python 2, add the flag when compiling the pattern. The other escape sequences ( , , , , , , and ) are also processed differently for Unicode text. Instead of assuming the members of the character set identified by the escape sequence, the regular expression engine consults the Unicode database to find the properties of each character. Python 3 uses Unicode for all strings by default, so the flag is not necessary. The compact format of regular expression syntax can become a hindrance as expressions grow more complicated. As the number of groups in your expression increases, you will have trouble keeping track of why each element is needed and how exactly the parts of the expression interact. Using named groups helps mitigate these issues, but a better solution is to use verbose mode expressions, which allow you to add comments and extra whitespace. A pattern to validate email addresses will illustrate how verbose mode makes working with regular expressions easier. The first version recognizes addresses that end in one of three top-level domains, , , and . This expression is already complex. There are several character classes, groups, and repetition expressions. Converting the expression to a more verbose format will make it easier to extend. (com|org|edu) # we should support more top-level domains The expression matches the same inputs, but in this extended format it is easier to read. The comments also help identify different parts of the pattern so that it can be expanded to match more inputs. This expanded version parses inputs that include a person’s name and email address, as might appear in an email header. The name comes first and stands on its own, and the email address follows surrounded by angle brackets ( and ). # A name is made up of letters, and may include \".\" for title # but we only want one if we found a name, so keep # the start bracket in this group. )? # the entire name is optional As with other programming languages, the ability to insert comments into verbose regular expressions helps with their maintainability. This final version includes implementation notes to future maintainers and whitespace to separate the groups from each other and highlight their nesting level. $ python re_email_with_name.py Candidate: first.last@example.com Match name : None Match email: first.last@example.com Candidate: first.last+category@gmail.com Match name : None Match email: first.last+category@gmail.com Candidate: valid-address@mail.example.com Match name : None Match email: valid-address@mail.example.com Candidate: not-valid@example.foo No match Candidate: First Last <first.last@example.com> Match name : First Last Match email: first.last@example.com Candidate: No Brackets first.last@example.com Match name : None Match email: first.last@example.com Candidate: First Last No match Candidate: First Middle Last <first.last@example.com> Match name : First Middle Last Match email: first.last@example.com Candidate: First M. Last <first.last@example.com> Match name : First M. Last Match email: first.last@example.com Candidate: <first.last@example.com> Match name : None Match email: first.last@example.com In situations where you cannot add flags when compiling an expression, such as when you are passing a pattern to a library function that will compile it later, you can embed the flags inside the expression string itself. For example, to turn case-insensitive matching on, add to the beginning of the expression. 'This is some text -- with punctuation.' Because the options control the way the entire expression is evaluated or parsed, they should always come at the beginning of the expression. $ python re_flags_embedded.py Text : This is some text -- with punctuation. Pattern : (?i)\\bT\\w+ Matches : ['This', 'text'] The abbreviations for all of the flags are: Embedded flags can be combined by placing them within the same group. For example, turns on case-insensitive matching for multiline Unicode strings.\n\nThere are many cases where it is useful to match a part of a pattern only if some other part will also match. For example, in the email parsing expression the angle brackets were each marked as optional. Really, though, the brackets should be paired, and the expression should only match if both are present, or neither are. This modified version of the expression uses a positive look ahead assertion to match the pair. The look ahead assertion syntax is . # A name is made up of letters, and may include \".\" for title ) # name is no longer optional # Email addresses are wrapped in angle brackets, but we only want # the brackets if they are both there, or neither are. There are several important changes in this version of the expression. First, the name portion is no longer optional. That means stand-alone addresses do not match, but it also prevents improperly formatted name/address combinations from matching. The positive look ahead rule after the “name” group asserts that the remainder of the string is either wrapped with a pair of angle brackets, or there is not a mismatched bracket; the brackets are either both present or neither is. The look ahead is expressed as a group, but the match for a look ahead group does not consume any of the input text, so the rest of the pattern picks up from the same spot after the look ahead matches. $ python re_look_ahead.py Candidate: First Last <first.last@example.com> Match name : First Last Match email: first.last@example.com Candidate: No Brackets first.last@example.com Match name : No Brackets Match email: first.last@example.com Candidate: Open Bracket <first.last@example.com No match Candidate: Close Bracket first.last@example.com> No match A negative look ahead assertion ( ) says that the pattern does not match the text following the current point. For example, the email recognition pattern could be modified to ignore mailing addresses commonly used by automated systems. The address starting does not match the pattern, since the look ahead assertion fails. Instead of looking ahead for in the username portion of the email address, the pattern can also be written using a negative look behind assertion after the username is matched using the syntax . Looking backwards works a little differently than looking ahead, in that the expression must use a fixed length pattern. Repetitions are allowed, as long as there is a fixed number (no wildcards or ranges). A positive look behind assertion can be used to find text following a pattern using the syntax . For example, this expression finds Twitter handles. One for @ThePSF, and one for the author, @doughellmann. The pattern matches sequences of characters that can make up a Twitter handle, as long as they are preceded by an . $ python re_look_behind.py This text includes two Twitter handles. One for @ThePSF, and one for the author, @doughellmann. Handle: ThePSF Handle: doughellmann\n\nMatched values can be used in later parts of an expression. For example, the email example can be updated to match only addresses composed of the first and last name of the person by including back-references to those groups. The easiest way to achieve this is by referring to the previously matched group by id number, using . Although the syntax is simple, creating back-references by numerical id has a couple of disadvantages. From a practical standpoint, as the expression changes, you must count the groups again and possibly update every reference. The other disadvantage is that only 99 references can be made this way, because if the id number is three digits long it will be interpreted as an octal character value instead of a group reference. On the other hand, if you have more than 99 groups in your expression you will have more serious maintenance challenges than not being able to refer to some of the groups in the expression. $ python re_refer_to_group.py Candidate: First Last <first.last@example.com> Match name : First Last Match email: first.last@example.com Candidate: Different Name <first.last@example.com> No match Candidate: First Middle Last <first.last@example.com> Match name : First Last Match email: first.last@example.com Candidate: First M. Last <first.last@example.com> Match name : First Last Match email: first.last@example.com Python’s expression parser includes an extension that uses to refer to the value of a named group matched earlier in the expression. The address expression is compiled with the flag on, since proper names are normally capitalized but email addresses are not. $ python re_refer_to_named_group.py Candidate: First Last <first.last@example.com> Match name : First Last Match email: first.last@example.com Candidate: Different Name <first.last@example.com> No match Candidate: First Middle Last <first.last@example.com> Match name : First Last Match email: first.last@example.com Candidate: First M. Last <first.last@example.com> Match name : First Last Match email: first.last@example.com The other mechanism for using back-references in expressions lets you choose a different pattern based on whether or not a previous group matched. The email pattern can be corrected so that the angle brackets are required if a name is present, and not if the email address is by itself. The syntax for testing to see if a group has matched is , where id is the group name or number, yes-expression is the pattern to use if the group has a value and no-expression is the pattern to use otherwise. # A name is made up of letters, and may include \".\" for title # Email addresses are wrapped in angle brackets, but we only want # the brackets if we found a name. # remainder wrapped in angle brackets because we have a name # remainder does not include angle brackets without name # Only look for a bracket if our look ahead assertion found both # Only look for a bracket if our look ahead assertion found both This version of the email address parser uses two tests. If the group matches, then the look ahead assertion requires both angle brackets and sets up the group. If is not matched, the assertion requires the rest of the text not have angle brackets around it. Later, if the group is set, the actual pattern matching code consumes the brackets in the input using literal patterns, otherwise it consumes any blank space. $ python re_id.py Candidate: First Last <first.last@example.com> Match name : First Last Match email: first.last@example.com Candidate: No Brackets first.last@example.com No match Candidate: Open Bracket <first.last@example.com No match Candidate: Close Bracket first.last@example.com> No match Candidate: no.brackets@example.com Match name : None Match email: no.brackets@example.com\n\nis one of the most frequently used methods for breaking apart strings to parse them. It only supports using literal values as separators, though, and sometimes a regular expression is necessary if the input is not consistently formatted. For example, many plain text markup languages define paragraph separators as two or more newline ( ) characters. In this case, cannot be used because of the “or more” part of the definition. A strategy for identifying paragraphs using would use a pattern like . That pattern fails for paragraphs at the end of the input text, as illustrated by the fact that “Paragraph three.” is not part of the output. Extending the pattern to say that a paragraph ends with two or more newlines, or the end of input, fixes the problem but makes the pattern more complicated. Converting to instead of handles the boundary condition automatically and keeps the pattern simple. The pattern argument to expresses the markup specification more precisely: Two or more newline characters mark a separator point between paragraphs in the input string. $ python re_split.py With findall: 0 ('Paragraph one\n\non two lines.', '\n\n\n\n') 1 ('Paragraph two.', '\n\n\n\n\n\n') 2 ('Paragraph three.', '') With split: 0 'Paragraph one\n\non two lines.' 1 'Paragraph two.' 2 'Paragraph three.' Enclosing the expression in parentheses to define a group causes to work more like , so it returns the separator values as well as the other parts of the string. The output now includes each paragraph, as well as the sequence of newlines separating them. $ python re_split_groups.py With split: 0 'Paragraph one\n\non two lines.' 1 '\n\n\n\n' 2 'Paragraph two.' 3 '\n\n\n\n\n\n' 4 'Paragraph three.' The standard library documentation for this module. A web-based tool for testing regular expressions created by David Naffziger at BrandVerity.com. Inspired by Kodos. Use the module to set your language configuration when working with Unicode text."
    },
    {
        "link": "https://stackoverflow.com/questions/827557/how-do-you-validate-a-url-with-a-regular-expression-in-python",
        "document": "An easy way to parse (and validate) URL's is the (py2, py3) module.\n\nA regex is too much work.\n\nThere's no \"validate\" method because almost anything is a valid URL. There are some punctuation rules for splitting it up. Absent any punctuation, you still have a valid URL.\n\nCheck the RFC carefully and see if you can construct an \"invalid\" URL. The rules are very flexible.\n\nFor example is a valid URL. The path is . A pretty stupid filename, but a valid filename.\n\nAlso, is a valid URL. The netloc (\"hostname\") is . The path is . Again, stupid. Also valid. This URL normalizes to which is the equivalent.\n\nSomething like is perfectly valid. Dumb but valid.\n\nBottom Line. Parse it, and look at the pieces to see if they're displeasing in some way.\n\nDo you want the scheme to always be \"http\"? Do you want the netloc to always be \"www.somename.somedomain\"? Do you want the path to look unix-like? Or windows-like? Do you want to remove the query string? Or preserve it?\n\nThese are not RFC-specified validations. These are validations unique to your application."
    },
    {
        "link": "https://snyk.io/blog/secure-python-url-validation",
        "document": "Everything on the internet has a Uniform Resource Locator (URL) that uniquely identifies it — allowing Internet users to gain access to files and other media. For instance, this article has a unique URL that helps search engine optimization (SEO) crawlers index it for users to find.\n\nThe first definition of the URL syntax is in the 1994 Request for Comments (RFC) 1738. Since then, the structure of URLs has gone through many revisions to improve their security. However, developers often fail to use the RFC definition as intended, contributing to many malicious attacks.\n\nA recent example is the RCE 0-day exploit found in Log4j, a popular Java logging package. This attack occurred when the Java Naming and Directory Interface (JNDI) evaluated a malicious log string. The JNDI is a Java API for a directory service that allows Java software clients to discover and look up data and resources (in the form of Java objects) using a name. When it evaluates a malicious log string, it connects to a remote server and executes malicious Java code. Therefore, enterprises must continually validate the URLs provided by external agents, such as customers, partners, and so on.\n\nAnother example is the server-side request forgery attack that can compromise a server program when it accesses an insecure URL. Malicious users can leverage the provided input fields to cause damage to our web solutions — and worse, our organization’s public image.\n\nIn this article, we’ll explore the challenges of corrupted URLs, how they can damage your applications, and ways to tackle the problem. To follow along, make sure you have Python installed and set up on your machine.\n\nURLs can be risky, as they can direct users from a legitimate web page to a malicious one. They can also open multiple attack vectors — including cross-site scripting (XSS), a security vulnerability in some web applications. The XSS vulnerability enables attackers to inject client-side scripts into web pages viewed by other users.\n\nThis security risk can have serious consequences in specific industries, such as banking. An unknowing customer can open a genuine-looking page controlled by an attacker because they believe it's a login page for their banking application. This is a type of phishing attack, built on social engineering, where an attacker sends fraudulent, fake, or otherwise deceptive messages designed to trick a person into revealing sensitive information to the attacker. They could also deploy malicious software on the victim's infrastructure, including ransomware. If the attacker captures a banking user's username and password, the attacker can use this information to log in to the user's bank account and cause damage.\n\nMore advanced attacks with URLs can happen due to server-side request forgery. This attack occurs in the servers that send requests to the URLs provided by the customers. When making a request, an attacker can take over the server to perform actions that aren't allowed, such as scanning the ports and network information, requesting metadata of the infrastructure, printing, and outputting sensitive information such as passwords or tokens.\n\nThe following sections demonstrate how to validate and sanitize URLs you don’t control. For example, if we’re building a social platform where users can communicate and share data, we can control which URLs are allowed and which we can hide.\n\nHow to perform URL validation in Python\n\nPython, a programming language, is widely used to build web applications and sites for millions of customers worldwide. While Python doesn’t have a built-in URL scanner and validator, community-driven URL parsers and validators are available for Python — which can be used to validate our URLs and make them more secure. Some web application frameworks also provide URL scanners and validators for developing web applications.\n\nOne popular URL validation method in Python is the validators Python package. We can use the validators package to determine whether a URL is valid. To be valid, a URL must:\n• None Be well-formed, meaning it follows all the rules of the HTTP or HTTPS specifications\n• None Have a resource at that address, since the URL is invalid without an associated resource\n\nThe Python validators package exposes a URL method that verifies the URL, and tests if it is secure, and searches for invalid keywords and characters. If a URL is available in the public domain (meaning it’s not behind a firewall, paywall, or other barrier to access), it skips any internal IP addresses.\n\nTo use the validators package, download and set up the dependency on your local Python environment using pip. To download the validators package, run the following code in your local terminal or command-line interface:\n\nOnce this command finishes, we’ll have the validators package on our machine.\n\nNext, create a Python file named , and write the Python code to test a URL:\n\nAfter putting this code in the file, execute the code in Python interpreter using the Python command-line interface:\n\nThe code prints because there is a character missing in the URL after .\n\nThe package can also determine if a URL is publicly accessible, which is helpful when trying to validate whether the user is trying to request an internal IP address. Add the following code in the same Python file and run it to try and validate a URL.\n\nOnce again, the output states that the URL is invalid. This is because the URL isn’t available in public domains — despite the fact that there aren’t any issues with the URL itself. To learn more about the validators package’s features, consult its documentation.\n\nAnother approach we can use to validate URLs is using regular expressions. We can, for example, use regular expressions to require a URL to include HTTPS before it can be validated. The code to complete this validation looks like this:\n\nThis regular expression matches the term , but not , although both are valid URLs. You can learn more about regular expressions on this website. We can try the expression above in Python code:\n\nThe output for the code above is the matched URL. If you modify the URL string above and remove the HTTPS or make it HTTP, you get a object — indicating there was no matching URL.\n\nHowever, a regular expression is complicated and not practical for a real-world scenario. Regular expressions are hard to read and complex to debug and scale. This is why libraries are generally a better solution.\n\nFor a more advanced use case of a regular expression that parses the URL with all the conforming structures and syntax, check out this Stack Overflow thread.\n\nOne benefit of using regular expressions is that you can also find invalid URLs within input strings. This is only possible with regular expressions — and not with common libraries. The validators package doesn’t work, even if the string contains a trailing or preceding whitespace. To best use the package, you must sanitize the input string and pass it to the validator package.\n\nAnother package that parses the URL and exposes the parts of the URL is urllib. We can use it with the Python 3 interpreter.\n\nThe following code verifies if a URL is valid:\n\nWhen we set the scheme and the field for the variable, the URL is valid and can be used. Otherwise, the URL is invalid, and we should take caution.\n\nSome frameworks in Python, such as Django, provide built-in validator packages that allow us to validate URLs within that framework. However, the challenge with relying on these libraries is that, even if we’re familiar with that framework, we still have to ensure the package itself is secure. Andopen source only makes trusting the package more complex.\n\nWe can use a security tool like the Snyk Advisor to quickly review all open source packages we’re using — and new packages that we’d like to implement — for common vulnerabilities. From this review, Snyk provides us with a security report that we can use to determine whether or not the package should be included. For example, we can use the Snyk Advisor to ensure our packages, like the validators package we used in the demonstration above, are secure.\n\nWe can also use Snyk Open Source alongside Snyk Advisor to discover licensing problems, vulnerabilities, and other security-related concerns that may exist in our open source tool stack. And, we can consult the Snyk Vulnerability Database (VulnDB) to search for known URL-related vulnerabilities — like this vulnerability in the Flask framework, which redirects a user to a location without URL validation. By consulting this database, we can proactively secure our webpages and applications.\n\nIn this article, we explored the challenges that unsanitized URLs bring to a web application, and how to sanitize the URLs as needed. We started with basic validations of the URL using the validator and urllib packages. And demonstrated how to use these packages to confirm whether the URLs are all public, or if some are internal URLs used to attack the web application. Then, we used a primary regular expression to showcase how a simple one-line code can scan the URLs for basic required information, such as all URLs being HTTPS. We also discussed why regular expressions are a complex and challenging way to validate the URLs.\n\nFinally, we covered how to best select secure open-source libraries. Snyk Advisor provides a valuable source of truth when using open source packages. For more information, review the Python security best practices cheat sheet to help prepare the continuous integration and continuous development pipelines (CI/CD) to review any vulnerability added to your code."
    },
    {
        "link": "https://stackoverflow.com/questions/161738/what-is-the-best-regular-expression-to-check-if-a-string-is-a-valid-url",
        "document": "My knowledge of regular expressions is basic and doesn't allow me to choose from the hundreds of regular expressions I've already seen on the web.\n\nHow can I check if a given string is a valid URL address?\n\nI wrote my URL (actually IRI, internationalized) pattern to comply with RFC 3987 (http://www.faqs.org/rfcs/rfc3987.html). These are in PCRE syntax. To also allow relative IRIs: How they were compiled (in PHP): <?php /* Regex convenience functions (character class, non-capturing group) */ function cc($str, $suffix = '', $negate = false) { return '[' . ($negate ? '^' : '') . $str . ']' . $suffix; } function ncg($str, $suffix = '') { return '(?:' . $str . ')' . $suffix; } /* Preserved from RFC3986 */ $ALPHA = 'a-z'; $DIGIT = '0-9'; $HEXDIG = $DIGIT . 'a-f'; $sub_delims = '!\\\\$&\\'\\\\(\\\\)\\\\*\\\\+,;='; $gen_delims = ':\\\\/\\\\?\\\\#\\\\[\\\\]@'; $reserved = $gen_delims . $sub_delims; $unreserved = '-' . $ALPHA . $DIGIT . '\\\\._~'; $pct_encoded = '%' . cc($HEXDIG) . cc($HEXDIG); $dec_octet = ncg(implode('|', array( cc($DIGIT), cc('1-9') . cc($DIGIT), '1' . cc($DIGIT) . cc($DIGIT), '2' . cc('0-4') . cc($DIGIT), '25' . cc('0-5') ))); $IPv4address = $dec_octet . ncg('\\\\.' . $dec_octet, '{3}'); $h16 = cc($HEXDIG, '{1,4}'); $ls32 = ncg($h16 . ':' . $h16 . '|' . $IPv4address); $IPv6address = ncg(implode('|', array( ncg($h16 . ':', '{6}') . $ls32, '::' . ncg($h16 . ':', '{5}') . $ls32, ncg($h16, '?') . '::' . ncg($h16 . ':', '{4}') . $ls32, ncg($h16 . ':' . $h16, '?') . '::' . ncg($h16 . ':', '{3}') . $ls32, ncg(ncg($h16 . ':', '{0,2}') . $h16, '?') . '::' . ncg($h16 . ':', '{2}') . $ls32, ncg(ncg($h16 . ':', '{0,3}') . $h16, '?') . '::' . $h16 . ':' . $ls32, ncg(ncg($h16 . ':', '{0,4}') . $h16, '?') . '::' . $ls32, ncg(ncg($h16 . ':', '{0,5}') . $h16, '?') . '::' . $h16, ncg(ncg($h16 . ':', '{0,6}') . $h16, '?') . '::', ))); $IPvFuture = 'v' . cc($HEXDIG, '+') . cc($unreserved . $sub_delims . ':', '+'); $IP_literal = '\\\\[' . ncg(implode('|', array($IPv6address, $IPvFuture))) . '\\\\]'; $port = cc($DIGIT, '*'); $scheme = cc($ALPHA) . ncg(cc('-' . $ALPHA . $DIGIT . '\\\\+\\\\.'), '*'); /* New or changed in RFC3987 */ $iprivate = '\\x{E000}-\\x{F8FF}\\x{F0000}-\\x{FFFFD}\\x{100000}-\\x{10FFFD}'; $ucschar = '\\x{A0}-\\x{D7FF}\\x{F900}-\\x{FDCF}\\x{FDF0}-\\x{FFEF}' . '\\x{10000}-\\x{1FFFD}\\x{20000}-\\x{2FFFD}\\x{30000}-\\x{3FFFD}' . '\\x{40000}-\\x{4FFFD}\\x{50000}-\\x{5FFFD}\\x{60000}-\\x{6FFFD}' . '\\x{70000}-\\x{7FFFD}\\x{80000}-\\x{8FFFD}\\x{90000}-\\x{9FFFD}' . '\\x{A0000}-\\x{AFFFD}\\x{B0000}-\\x{BFFFD}\\x{C0000}-\\x{CFFFD}' . '\\x{D0000}-\\x{DFFFD}\\x{E1000}-\\x{EFFFD}'; $iunreserved = '-' . $ALPHA . $DIGIT . '\\\\._~' . $ucschar; $ipchar = ncg($pct_encoded . '|' . cc($iunreserved . $sub_delims . ':@')); $ifragment = ncg($ipchar . '|' . cc('\\\\/\\\\?'), '*'); $iquery = ncg($ipchar . '|' . cc($iprivate . '\\\\/\\\\?'), '*'); $isegment_nz_nc = ncg($pct_encoded . '|' . cc($iunreserved . $sub_delims . '@'), '+'); $isegment_nz = ncg($ipchar, '+'); $isegment = ncg($ipchar, '*'); $ipath_empty = '(?!' . $ipchar . ')'; $ipath_rootless = ncg($isegment_nz) . ncg('\\\\/' . $isegment, '*'); $ipath_noscheme = ncg($isegment_nz_nc) . ncg('\\\\/' . $isegment, '*'); $ipath_absolute = '\\\\/' . ncg($ipath_rootless, '?'); // Spec says isegment-nz *( \"/\" isegment ) $ipath_abempty = ncg('\\\\/' . $isegment, '*'); $ipath = ncg(implode('|', array( $ipath_abempty, $ipath_absolute, $ipath_noscheme, $ipath_rootless, $ipath_empty ))) . ')'; $ireg_name = ncg($pct_encoded . '|' . cc($iunreserved . $sub_delims . '@'), '*'); $ihost = ncg(implode('|', array($IP_literal, $IPv4address, $ireg_name))); $iuserinfo = ncg($pct_encoded . '|' . cc($iunreserved . $sub_delims . ':'), '*'); $iauthority = ncg($iuserinfo . '@', '?') . $ihost . ncg(':' . $port, '?'); $irelative_part = ncg(implode('|', array( '\\\\/\\\\/' . $iauthority . $ipath_abempty . '', '' . $ipath_absolute . '', '' . $ipath_noscheme . '', '' . $ipath_empty . '' ))); $irelative_ref = $irelative_part . ncg('\\\\?' . $iquery, '?') . ncg('\\\\#' . $ifragment, '?'); $ihier_part = ncg(implode('|', array( '\\\\/\\\\/' . $iauthority . $ipath_abempty . '', '' . $ipath_absolute . '', '' . $ipath_rootless . '', '' . $ipath_empty . '' ))); $absolute_IRI = $scheme . ':' . $ihier_part . ncg('\\\\?' . $iquery, '?'); $IRI = $scheme . ':' . $ihier_part . ncg('\\\\?' . $iquery, '?') . ncg('\\\\#' . $ifragment, '?'); $IRI_reference = ncg($IRI . '|' . $irelative_ref); Edit 7 March 2011: Because of the way PHP handles backslashes in quoted strings, these are unusable by default. You'll need to double-escape backslashes except where the backslash has a special meaning in regex. You can do that this way:\n\nWith regard to eyelidness' answer post that reads \"This is based on my reading of the URI specification.\": Thanks Eyelidness, yours is the perfect solution I sought, as it is based on the URI spec! Superb work. :) I had to make two amendments. The first to get the regexp to match IP address URLs correctly in PHP (v5.2.10) with the preg_match() function. I had to add one more set of parenthesis to the line above \"IP Address\" around the pipes: I have also reduced the top level domain minimum length from 3 to 2 letters to support .co.uk and similar. /^(https?|ftp):\\/\\/(?# protocol )(([a-z0-9$_\\.\\+!\\*\\'\\(\\),;\\?&=-]|%[0-9a-f]{2})+(?# username )(:([a-z0-9$_\\.\\+!\\*\\'\\(\\),;\\?&=-]|%[0-9a-f]{2})+)?(?# password )@)?(?# auth requires @ )((([a-z0-9]\\.|[a-z0-9][a-z0-9-]*[a-z0-9]\\.)*(?# domain segments AND )[a-z][a-z0-9-]*[a-z0-9](?# top level domain OR )|((\\d|[1-9]\\d|1\\d{2}|2[0-4][0-9]|25[0-5])\\.){3}(?# )(\\d|[1-9]\\d|1\\d{2}|2[0-4][0-9]|25[0-5])(?# IP address ))(:\\d+)?(?# port ))(((\\/+([a-z0-9$_\\.\\+!\\*\\'\\(\\),;:@&=-]|%[0-9a-f]{2})*)*(?# path )(\\?([a-z0-9$_\\.\\+!\\*\\'\\(\\),;:@&=-]|%[0-9a-f]{2})*)(?# query string )?)?)?(?# path and query string optional )(#([a-z0-9$_\\.\\+!\\*\\'\\(\\),;:@&=-]|%[0-9a-f]{2})*)?(?# fragment )$/i This modified version was not checked against the URI specification so I can't vouch for it's compliance, it was altered to handle URLs on local network environments and two digit TLDs as well as other kinds of Web URL, and to work better in the PHP setup I use. define('URL_FORMAT', '/^(https?):\\/\\/'. // protocol '(([a-z0-9$_\\.\\+!\\*\\'\\(\\),;\\?&=-]|%[0-9a-f]{2})+'. // username '(:([a-z0-9$_\\.\\+!\\*\\'\\(\\),;\\?&=-]|%[0-9a-f]{2})+)?'. // password '@)?(?#'. // auth requires @ ')((([a-z0-9]\\.|[a-z0-9][a-z0-9-]*[a-z0-9]\\.)*'. // domain segments AND '[a-z][a-z0-9-]*[a-z0-9]'. // top level domain OR '|((\\d|[1-9]\\d|1\\d{2}|2[0-4][0-9]|25[0-5])\\.){3}'. '(\\d|[1-9]\\d|1\\d{2}|2[0-4][0-9]|25[0-5])'. // IP address ')(:\\d+)?'. // port ')(((\\/+([a-z0-9$_\\.\\+!\\*\\'\\(\\),;:@&=-]|%[0-9a-f]{2})*)*'. // path '(\\?([a-z0-9$_\\.\\+!\\*\\'\\(\\),;:@&=-]|%[0-9a-f]{2})*)'. // query string '?)?)?'. // path and query string optional '(#([a-z0-9$_\\.\\+!\\*\\'\\(\\),;:@&=-]|%[0-9a-f]{2})*)?'. // fragment '$/i'); Here is a test program in PHP which validates a variety of URLs using the regex: <?php define('URL_FORMAT', '/^(https?):\\/\\/'. // protocol '(([a-z0-9$_\\.\\+!\\*\\'\\(\\),;\\?&=-]|%[0-9a-f]{2})+'. // username '(:([a-z0-9$_\\.\\+!\\*\\'\\(\\),;\\?&=-]|%[0-9a-f]{2})+)?'. // password '@)?(?#'. // auth requires @ ')((([a-z0-9]\\.|[a-z0-9][a-z0-9-]*[a-z0-9]\\.)*'. // domain segments AND '[a-z][a-z0-9-]*[a-z0-9]'. // top level domain OR '|((\\d|[1-9]\\d|1\\d{2}|2[0-4][0-9]|25[0-5])\\.){3}'. '(\\d|[1-9]\\d|1\\d{2}|2[0-4][0-9]|25[0-5])'. // IP address ')(:\\d+)?'. // port ')(((\\/+([a-z0-9$_\\.\\+!\\*\\'\\(\\),;:@&=-]|%[0-9a-f]{2})*)*'. // path '(\\?([a-z0-9$_\\.\\+!\\*\\'\\(\\),;:@&=-]|%[0-9a-f]{2})*)'. // query string '?)?)?'. // path and query string optional '(#([a-z0-9$_\\.\\+!\\*\\'\\(\\),;:@&=-]|%[0-9a-f]{2})*)?'. // fragment '$/i'); /** * Verify the syntax of the given URL. * * @access public * @param $url The URL to verify. * @return boolean */ function is_valid_url($url) { if (str_starts_with(strtolower($url), 'http://localhost')) { return true; } return preg_match(URL_FORMAT, $url); } /** * String starts with something * * This function will return true only if input string starts with * niddle * * @param string $string Input string * @param string $niddle Needle string * @return boolean */ function str_starts_with($string, $niddle) { return substr($string, 0, strlen($niddle)) == $niddle; } /** * Test a URL for validity and count results. * @param url url * @param expected expected result (true or false) */ $numtests = 0; $passed = 0; function test_url($url, $expected) { global $numtests, $passed; $numtests++; $valid = is_valid_url($url); echo \"URL Valid?: \" . ($valid?\"yes\":\"no\") . \" for URL: $url. Expected: \".($expected?\"yes\":\"no\").\". \"; if($valid == $expected) { echo \"PASS\n\n\"; $passed++; } else { echo \"FAIL\n\n\"; } } echo \"URL Tests:\n\n\n\n\"; test_url(\"http://localserver/projects/public/assets/javascript/widgets/UserBoxMenu/widget.css\", true); test_url(\"http://www.google.com\", true); test_url(\"http://www.google.co.uk/projects/my%20folder/test.php\", true); test_url(\"https://myserver.localdomain\", true); test_url(\"http://192.168.1.120/projects/index.php\", true); test_url(\"http://192.168.1.1/projects/index.php\", true); test_url(\"http://projectpier-server.localdomain/projects/public/assets/javascript/widgets/UserBoxMenu/widget.css\", true); test_url(\"https://2.4.168.19/project-pier?c=test&a=b\", true); test_url(\"https://localhost/a/b/c/test.php?c=controller&arg1=20&arg2=20\", true); test_url(\"http://user:password@localhost/a/b/c/test.php?c=controller&arg1=20&arg2=20\", true); echo \"\n\n$passed out of $numtests tests passed.\n\n\n\n\"; ?> Thanks again to eyelidness for the regex!\n\nI wrote a little groovy version that you can run it matches the following URLs (which is good enough for me) public static void main(args) { String url = \"go to http://www.m.abut.ly/abc its awesome\" url = url.replaceAll(/https?:\\/\\/w{0,3}\\w*?\\.(\\w*?\\.)?\\w{2,3}\\S*|www\\.(\\w*?\\.)?\\w*?\\.\\w{2,3}\\S*|(\\w*?\\.)?\\w*?\\.\\w{2,3}[\\/\\?]\\S*/ , { it -> \"woof${it}woof\" }) println url } http://google.com http://google.com/help.php http://google.com/help.php?a=5 http://www.google.com http://www.google.com/help.php http://www.google.com?a=5 google.com?a=5 google.com/help.php google.com/help.php?a=5 http://www.m.google.com/help.php?a=5 (and all its permutations) www.m.google.com/help.php?a=5 (and all its permutations) m.google.com/help.php?a=5 (and all its permutations) The important thing for any URLs that don't start with or is that they must include a or I bet this can be tweaked a little more but it does the job pretty nice for being so short and compact... because you can pretty much split it in 3: find anything that starts with : find anything that starts with : or find anything that must have a text then a dot then at least 2 letters and then a or :\n\nHere is a regex I made which extracts the different parts from an URL: (group 1): extracts the protocol\n\n (group 2): extracts the hostname\n\n (group 3): extracts the port number\n\n (groups 4 & 5): extracts the path part\n\n (group 6): extracts the query part\n\n (group 7): extracts the hash part For every part of the regex listed above, you can remove the ending to force it (or add one to make it facultative). You can also remove the at the beginning and at the end of the regex so it won't need to match the whole string. Note: this regex is not 100% safe and may accept some strings which are not necessarily valid URLs but it does indeed validate some criterias. Its main goal was to extract the different parts of an URL not to validate it.\n\nI've been working on an in-depth article discussing URI validation using regular expressions. It is based on RFC3986. Although the article is not yet complete, I have come up with a PHP function which does a pretty good job of validating HTTP and FTP URLs. Here is the current version: // function url_valid($url) { Rev:20110423_2000 // // Return associative array of valid URI components, or FALSE if $url is not // RFC-3986 compliant. If the passed URL begins with: \"www.\" or \"ftp.\", then // \"http://\" or \"ftp://\" is prepended and the corrected full-url is stored in // the return array with a key name \"url\". This value should be used by the caller. // // Return value: FALSE if $url is not valid, otherwise array of URI components: // e.g. // Given: \"http://www.jmrware.com:80/articles?height=10&width=75#fragone\" // Array( // [scheme] => http // [authority] => www.jmrware.com:80 // [userinfo] => // [host] => www.jmrware.com // [IP_literal] => // [IPV6address] => // [ls32] => // [IPvFuture] => // [IPv4address] => // [regname] => www.jmrware.com // [port] => 80 // [path_abempty] => /articles // [query] => height=10&width=75 // [fragment] => fragone // [url] => http://www.jmrware.com:80/articles?height=10&width=75#fragone // ) function url_valid($url) { if (strpos($url, 'www.') === 0) $url = 'http://'. $url; if (strpos($url, 'ftp.') === 0) $url = 'ftp://'. $url; if (!preg_match('/# Valid absolute URI having a non-empty, valid DNS host. ^ (?P<scheme>[A-Za-z][A-Za-z0-9+\\-.]*):\\/\\/ (?P<authority> (?:(?P<userinfo>(?:[A-Za-z0-9\\-._~!$&\\'()*+,;=:]|%[0-9A-Fa-f]{2})*)@)? (?P<host> (?P<IP_literal> \\[ (?: (?P<IPV6address> (?: (?:[0-9A-Fa-f]{1,4}:){6} | ::(?:[0-9A-Fa-f]{1,4}:){5} | (?: [0-9A-Fa-f]{1,4})?::(?:[0-9A-Fa-f]{1,4}:){4} | (?:(?:[0-9A-Fa-f]{1,4}:){0,1}[0-9A-Fa-f]{1,4})?::(?:[0-9A-Fa-f]{1,4}:){3} | (?:(?:[0-9A-Fa-f]{1,4}:){0,2}[0-9A-Fa-f]{1,4})?::(?:[0-9A-Fa-f]{1,4}:){2} | (?:(?:[0-9A-Fa-f]{1,4}:){0,3}[0-9A-Fa-f]{1,4})?:: [0-9A-Fa-f]{1,4}: | (?:(?:[0-9A-Fa-f]{1,4}:){0,4}[0-9A-Fa-f]{1,4})?:: ) (?P<ls32>[0-9A-Fa-f]{1,4}:[0-9A-Fa-f]{1,4} | (?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3} (?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?) ) | (?:(?:[0-9A-Fa-f]{1,4}:){0,5}[0-9A-Fa-f]{1,4})?:: [0-9A-Fa-f]{1,4} | (?:(?:[0-9A-Fa-f]{1,4}:){0,6}[0-9A-Fa-f]{1,4})?:: ) | (?P<IPvFuture>[Vv][0-9A-Fa-f]+\\.[A-Za-z0-9\\-._~!$&\\'()*+,;=:]+) ) \\] ) | (?P<IPv4address>(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3} (?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)) | (?P<regname>(?:[A-Za-z0-9\\-._~!$&\\'()*+,;=]|%[0-9A-Fa-f]{2})+) ) (?::(?P<port>[0-9]*))? ) (?P<path_abempty>(?:\\/(?:[A-Za-z0-9\\-._~!$&\\'()*+,;=:@]|%[0-9A-Fa-f]{2})*)*) (?:\\?(?P<query> (?:[A-Za-z0-9\\-._~!$&\\'()*+,;=:@\\\\/?]|%[0-9A-Fa-f]{2})*))? (?:\\#(?P<fragment> (?:[A-Za-z0-9\\-._~!$&\\'()*+,;=:@\\\\/?]|%[0-9A-Fa-f]{2})*))? $ /mx', $url, $m)) return FALSE; switch ($m['scheme']) { case 'https': case 'http': if ($m['userinfo']) return FALSE; // HTTP scheme does not allow userinfo. break; case 'ftps': case 'ftp': break; default: return FALSE; // Unrecognized URI scheme. Default to FALSE. } // Validate host name conforms to DNS \"dot-separated-parts\". if ($m['regname']) { // If host regname specified, check for DNS conformance. if (!preg_match('/# HTTP DNS host name. ^ # Anchor to beginning of string. (?!.{256}) # Overall host length is less than 256 chars. (?: # Group dot separated host part alternatives. [A-Za-z0-9]\\. # Either a single alphanum followed by dot | # or... part has more than one char (63 chars max). [A-Za-z0-9] # Part first char is alphanum (no dash). [A-Za-z0-9\\-]{0,61} # Internal chars are alphanum plus dash. [A-Za-z0-9] # Part last char is alphanum (no dash). \\. # Each part followed by literal dot. )* # Zero or more parts before top level domain. (?: # Explicitly specify top level domains. com|edu|gov|int|mil|net|org|biz| info|name|pro|aero|coop|museum| asia|cat|jobs|mobi|tel|travel| [A-Za-z]{2}) # Country codes are exactly two alpha chars. \\.? # Top level domain can end in a dot. $ # Anchor to end of string. /ix', $m['host'])) return FALSE; } $m['url'] = $url; for ($i = 0; isset($m[$i]); ++$i) unset($m[$i]); return $m; // return TRUE == array of useful named $matches plus the valid $url. } This function utilizes two regexes; one to match a subset of valid generic URIs (absolute ones having a non-empty host), and a second to validate the DNS \"dot-separated-parts\" host name. Although this function currently validates only HTTP and FTP schemes, it is structured such that it can be easily extended to handle other schemes."
    },
    {
        "link": "https://uibakery.io/regex-library/url-regex-python",
        "document": "URL regular expressions can be used to verify if a string has a valid URL format as well as to extract an URL from a string.\n\nURL regex that starts with HTTP or HTTPS HTTP and HTTPS URLs that start with protocol can be validated using the following regular expression\n\nEnter a text in the input above to see the result\n\nURL regex that doesn’t start with HTTP or HTTPS The regular expression to validate URL without protocol is very similar:\n\nEnter a text in the input above to see the result\n\nEnter a text in the input above to see the result\n\nThe above-mentioned regular expressions only cover the most commonly used types of URLs with domain names. If you have some more complex cases you might need a different solution."
    },
    {
        "link": "https://formulashq.com/the-ultimate-guide-to-using-regex-for-urls",
        "document": "Regex, short for Regular Expressions, is a powerful tool used for manipulating and searching text patterns. In the world of URLs, regex can be particularly handy for tasks like URL validation, rewriting, and redirection. Understanding the basics of regex and its syntax is crucial for effectively using it in different programming languages. In this comprehensive guide, we will dive deep into the topic of regex for URLs, exploring its significance, syntax, implementation in programming languages, URL validation techniques, and URL rewriting and redirection. So, whether you’re a beginner or an experienced developer, this guide will equip you with the knowledge you need to leverage the power of regex for URLs.\n\nRegex, short for Regular Expressions, is a sequence of characters that define a search pattern. It is a powerful and flexible tool used for pattern matching and manipulation of text. With regex, you can search for specific patterns, validate inputs, extract information, replace text, and perform various other text-related operations.\n\nRegular expressions are not specific to any single programming language or tool; they are a standardized way of defining patterns that can be used in a wide range of applications. This universality makes regex a valuable skill for developers and data analysts working with text data.\n\nURL manipulation involves modifying or extracting specific parts of a URL. Whether you want to validate a URL, rewrite its structure, or redirect it to a different location, regex can be an invaluable tool. It allows you to define patterns and apply them to URLs, enabling you to perform complex operations efficiently.\n\nOne common use case of regex in URL manipulation is extracting parameters from query strings. By defining a regex pattern that matches the desired parameter name, you can easily extract its value from a URL. This capability is particularly useful in web development when handling user inputs or processing data from external sources.\n\nIn regex, patterns are constructed using a combination of characters and metacharacters. When working with URLs, you can create patterns to match specific components like the protocol, domain, path, or query parameters. For example, to match a URL starting with “https://” and ending with “.com”, you can use the pattern .\n\nMoreover, regex provides a powerful way to extract information from URLs. You can use capturing groups to isolate different parts of a URL for further processing. For instance, to extract the domain name from a URL, you can use the pattern and capture the domain name within the second group.\n\nRegex employs special characters with reserved meanings that modify the behavior of patterns. Characters like “.”, “*”, “+”, “?”, and “[” have specific purposes in regex. Understanding these special characters and their usage is crucial for constructing accurate and effective regex patterns. For instance, the dot (.) character matches any single character, while the asterisk (*) matches zero or more occurrences of the preceding character or group.\n\nFurthermore, regex supports the use of quantifiers to specify the number of occurrences to match. Quantifiers like “{n}” (matches exactly n times), “{n,}” (matches n or more times), and “{n,m}” (matches between n and m times) provide flexibility in defining the pattern’s requirements. By utilizing quantifiers, you can create regex patterns that are more precise and tailored to your specific matching criteria.\n\nPython provides a built-in module called that makes working with regex patterns seamless. With the help of the module, you can easily compile and execute regex patterns in Python. It offers various methods and functions for matching patterns, searching, replacing, and more. Python’s regex capabilities make it an excellent choice for URL manipulation tasks.\n\nOne of the key advantages of using regex in Python is its versatility. Python’s module allows for the creation of complex regex patterns to handle a wide range of scenarios. Whether you need to extract specific data from URLs or validate user input, Python’s regex functionality can cater to your needs. Additionally, Python’s regex engine is optimized for performance, ensuring efficient pattern matching even with large datasets.\n\nIn JavaScript, regex capabilities are available through the built-in object. Similar to Python, JavaScript also offers methods like , , and that allow you to work with regex patterns in URLs. JavaScript is often used for client-side URL validation and manipulation, making regex an essential tool for web developers.\n\nWhen it comes to handling dynamic content on web pages, JavaScript’s regex support plays a crucial role. By leveraging regex patterns, developers can extract specific information from URLs, validate form inputs, and even manipulate the appearance of web elements based on certain criteria. JavaScript’s regex capabilities combined with its DOM manipulation features provide a powerful toolkit for creating interactive and dynamic web applications.\n\nURL validation is a common task in web development, ensuring that URLs entered by users are in the correct format. Regex can simplify the process by matching the pattern of a valid URL. Common URL validation patterns include checking for the presence of a valid protocol, domain, and optional query parameters. Regex patterns for URL validation provide an effective way to enforce input correctness and prevent potential errors.\n\nWhen validating URLs using regex, it is essential to consider edge cases such as internationalized domain names (IDN) and handling different protocols like HTTP, HTTPS, FTP, etc. This ensures that the validation process is robust and can accommodate a wide range of URL formats. Additionally, regex can be optimized to improve performance when dealing with large volumes of URL validation requests.\n\nWhile basic URL validation patterns can cover most scenarios, advanced techniques can handle more specific requirements. Advanced URL validation may involve checking for specific extensions in the domain or performing additional validation based on business rules. Regex provides the flexibility to create complex patterns and customize URL validation according to your specific needs.\n\nAdvanced URL validation techniques can also include verifying the existence of the domain in real-time by making DNS queries or checking SSL certificates. These additional checks enhance the security and reliability of the URL validation process, ensuring that only legitimate URLs are accepted. By combining regex with other validation methods, developers can create a comprehensive URL validation system that meets the highest standards of accuracy and security.\n\nURL rewriting involves modifying the URL structure on the server before processing a request. With regex, you can define patterns to match specific URLs and rewrite them according to your requirements. Whether you need to change parameter values, add subdomains, or adjust the URL structure, regex provides a powerful mechanism for manipulating URLs during the rewriting process.\n\nURL redirection involves forwarding incoming requests to a different URL. Regex plays a crucial role in this process by allowing you to match specific URLs and redirect them based on predefined rules. Whether you need to redirect users from old URLs to new ones or implement dynamic routing, regex enables you to redirect URLs efficiently and seamlessly.\n\nBy now, you should have a solid understanding of how regex can be used for URL manipulation. From basic syntax to implementation in different programming languages and advanced techniques, this guide has covered the essentials. With regex in your toolbox, you can navigate the complexities of URL validation, rewriting, and redirection with ease. So, go ahead and explore the possibilities of regex for URLs in your next web development project!"
    }
]