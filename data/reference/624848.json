[
    {
        "link": "https://medium.com/@python-javascript-php-html-css/tracking-mouse-movements-to-analyze-recoil-patterns-in-apex-legends-d78c806e85e1",
        "document": "In first-person shooter (FPS) games like Apex Legends, mastering recoil control can be the difference between victory and defeat. Many players rely on practice and muscle memory, but what if we could capture real-time mouse movement data to analyze and refine our aim? üéØ\n\nOne common method is using Python to track the X, Y coordinates of the mouse along with the delay between movements. This data can help players understand how their mouse behaves while controlling recoil and improve their accuracy. However, traditional libraries like pynput sometimes fall short in capturing rapid movements within a game environment.\n\nApex Legends‚Äô recoil patterns are complex, varying by weapon and fire rate. By accurately recording our mouse inputs, we can reverse-engineer these patterns, helping us train better. Imagine having a personalized dataset of your own aiming habits ‚Äî this is where advanced tracking techniques come in. üî•\n\nIn this guide, we‚Äôll explore a practical way to capture real-time recoil data while firing a weapon in Apex Legends. We‚Äôll go beyond and look at alternative solutions to track mouse movement, X/Y positions, and delay with precision.\n\nTracking mouse movement in real-time is essential for understanding recoil patterns in games like Apex Legends. The first script uses the Pynput library to capture X and Y coordinates of the mouse along with timestamps. By running a listener, the script records how the player‚Äôs mouse moves when firing a weapon. This data is stored in a text file, allowing later analysis of recoil compensation techniques. For instance, if a player struggles to control the recoil of an R-301 rifle, they can visualize their mouse movements and adjust their aim accordingly. üéØ\n\nFor higher precision, the second script employs DirectX to capture mouse movement in a lower-latency environment. This is crucial for fast-paced FPS games where every millisecond counts. Instead of using Pynput, it reads input directly from a virtual controller, making it more efficient in detecting micro-adjustments. By implementing a short sleep interval, the script ensures that data collection does not overwhelm the system while still capturing accurate recoil movements. Players can use this method to compare different weapons, such as how the recoil of a Flatline differs from a Spitfire.\n\nThe third script introduces a backend solution using Flask, allowing mouse data to be sent and retrieved via an API. This method is beneficial for players who want to store and analyze their data remotely. Imagine a player who records multiple matches and wants to track their aiming improvements over time. By sending the mouse tracking data to a server, they can later retrieve and visualize their performance using analytical tools. üî• This approach is particularly useful for esports professionals and coaches who analyze player statistics.\n\nEach of these solutions addresses different needs in capturing mouse movement for recoil analysis. While Pynput offers a simple and quick implementation, DirectX provides a more optimized method for competitive gaming. The Flask API expands functionality by enabling long-term data collection and retrieval. Combining these techniques, players can gain deeper insights into their aiming patterns, refine their recoil control strategies, and ultimately improve their performance in Apex Legends. Whether you‚Äôre a casual gamer or a competitive player, understanding and optimizing recoil compensation is key to gaining an edge in the battlefield.\n\nBeyond basic mouse tracking, capturing recoil patterns in a game like Apex Legends requires deeper analysis, such as detecting click events, tracking burst firing, and filtering noise in movement data. One of the most effective ways to refine data collection is through low-level input hooks. Libraries like PyDirectInput or Interception can help capture raw mouse movements without interference from the operating system‚Äôs smoothing algorithms. This ensures that the data reflects real, unaltered input ‚Äî crucial for precise recoil compensation.\n\nAnother key aspect is synchronizing mouse tracking with in-game events. By integrating real-time screen analysis, such as detecting muzzle flashes or ammo depletion, it‚Äôs possible to correlate firing sequences with movement data. Using OpenCV, developers can extract visual cues from the game, allowing the script to record not just mouse movements but also when shots were fired. This creates a detailed dataset that can help players develop more accurate recoil control techniques. üî•\n\nFinally, storing and visualizing the data is critical for meaningful analysis. Instead of writing to a simple text file, using a structured database like SQLite or Firebase enables better querying and long-term tracking of performance improvements. Pairing this with a frontend visualization tool, such as Matplotlib or Plotly, provides interactive graphs that allow players to study their movement patterns over time. These advanced techniques open up new possibilities for FPS enthusiasts looking to master recoil control through data-driven insights. üéØ\n\nWhy is tracking mouse movement important for recoil control?\n\nUnderstanding how your aim compensates for weapon recoil helps improve accuracy. Capturing data using mouse.Listener allows players to analyze their movements and adjust accordingly.\n\nCan I track mouse movement without interfering with my game?\n\nYes, using PyDirectInput allows capturing raw mouse data without triggering anti-cheat systems or affecting performance.\n\nHow can I synchronize mouse data with actual gunfire in Apex Legends?\n\nBy using OpenCV to detect muzzle flashes or ammo counters, you can timestamp your mouse movements accurately.\n\nWhat‚Äôs the best way to store and analyze recoil data?\n\nUsing a structured approach like SQLite or Firebase ensures efficient data management, while visualization tools like Matplotlib help in analysis.\n\nCan this method work with other FPS games?\n\nAbsolutely! The same tracking techniques can be applied to games like Call of Duty, Valorant, or CS:GO by adjusting the detection parameters.\n\nAnalyzing mouse movements for recoil control goes beyond just recording inputs ‚Äî it provides a deeper understanding of aiming behavior. By applying Python tools and structured data storage, players can visualize their movement adjustments over time. This approach transforms subjective training into a measurable, data-driven improvement method, helping both beginners and competitive players enhance their accuracy. üî•\n\nWith techniques like DirectX input tracking and Flask-based data collection, the possibilities for refining aim are vast. Whether implementing this knowledge for Apex Legends or other FPS games, leveraging technology for skill improvement is a game-changer. By combining science and gaming, players can sharpen their skills and dominate the battlefield with more controlled and precise aiming strategies.\n\nUsing DirectInput for low-latency mouse tracking in Python: Pyxinput GitHub"
    },
    {
        "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11289036",
        "document": "Numerous experiments in multiple fields have shown that the body and environment have a profound influence on mental activity (McBeath, Shaffer, & Kaiser, 1995; Thelen, Sch√∂ner, Scheier, & Smith, 2001; Hotton & Yoshimi, 2011; Silberstein & Chemero, 2012). Ongoing, continuous exchange of information between body, mind, and environment suggests that measurements of any of these subsystems will produce information about cognition. This in turn predicts that cursor data, an indirect measurement of the body‚Äôs movements, will contain information about cognition. Mouse tracking studies can capture this data, and have many additional advantages. The ‚Äúenvironment‚Äù in a computer task is highly controlled, and environmental variables can be monitored with high precision. The mouse, as a sensor for the body, can be measured with low latency. Computer tasks using mouse tracking data are relatively cheap and easy to produce, and data can be gathered from experiments run remotely over the internet. Most mouse tracking research follows a standard paradigm, a two-choice task in which a participant‚Äôs cursor begins at a predetermined start location, usually at the bottom-middle of the screen (Hehman, Stolier, & Freeman, 2015; Maldonado, Dunbar, & Chemla, 2019; Freeman, 2018). For a broad recent overview of this type of research see (Schoemann, O‚ÄôHora, Dale, & Scherbaum, 2020). The participant is then presented with a stimulus and asked to make a choice. They might be shown a picture of an animal and asked to identify that animal as a fish or a mammal by moving the mouse cursor to a text box labeled ‚Äúfish‚Äù or ‚Äúmammal‚Äù (See Fig. 1). As the participant moves their cursor towards the target, the (x, y) position of the cursor is recorded. The resulting vector of time stamped positions is a cursor trajectory. These cursor trajectories are then aggregated and analyzed (Hehman, Stolier, & Freeman, 2015; Stillman, Shen, & Ferguson, 2018). Standard mouse tracking task, based on the example in Hehman, Stolier, and Freeman (2015) In one of the most prominent examples of this type of research, participants are presented with either typical mammals such as cats, or atypical mammals such as whales. Participants‚Äô cursor trajectories are found to be more curved during trials with atypical exemplars, suggesting a ‚Äúgraded competitive process‚Äù of categorization, rather than a serial model (Dale, Kehoe, & Spivey, 2007). Other prominent examples include: evidence for multiple distinct components of inhibitory control in Stroop and flanker tasks (Erb, Moher, Sobel, & Song, 2016), evidence against a dual system of emotion and reasoning in moral reasoning (Koop, 2013), evidence that better self-control facilitates quicker resolution of self-control conflicts shown by earlier changes in curvature of mouse movement (Gillebaart, Schneider, & De Ridder, 2016), evidence for ‚Äúpartial and parallel activation of stereotypes‚Äù, implying that ‚Äúperceptual cues of the face‚Äù invoke multiple ‚Äúsimultaneously active stereotypes... and this mixture settles over time onto ultimate judgments‚Äù (Freeman & Ambady, 2009), and ‚Äúevidence that cursor motion analysis has the capacity to predict emotional experience of the computer users\" (Yamauchi & Xiao, 2018). Despite its value in the study of continuous output during binary decision tasks, this research does have limitations. First, it is limited to serial tasks with a predetermined start and end point for each mouse movement. In addition, because the data are segmented into many discrete trials, dynamic processes which might build over longer timescales are hard to analyze. Thirdly, as is normal in many psychological paradigms, participants are required to follow rigid procedures in order to obtain clean data. These constraints make it difficult to apply standard mouse tracking techniques to unconstrained mouse tracking data, which is continuous over time, not segmented into individual movements, and not necessarily constrained in terms of starting position, end position, or preferred trajectory. One way of dealing with the lack of structure in unconstrained mouse tracking data is to use machine learning techniques. Researchers in affective computing often use machine learning techniques to predict user characteristics (Kolakowska, 2013). However, though this approach addresses a particular business need, it does not usually provide results that generalize to other tasks, or provide novel scientific insights. Another option is to draw on dynamical systems and complex systems approaches to cognition. For example, some have analyzed hand movements in open ended computer tasks such as corralling artificial agents in a computer game (Nalepka, Kallen, Chemero, Saltzman, & Richardson, 2017; Dotov, Nie, & Chemero, 2010). In tasks like these, where the movements are fluid and in continuous streams of motion, it is not clear what constitutes a single movement. Because of this, researchers in these areas tend not to decompose data into individual movements or behaviors, focusing instead on whole time series of behavioral data. One type of behavior that has been found when studying cognitive systems from this standpoint is power law relationships across multiple time scales. For example, several studies have found evidence for a 1/f power law in spectra characterizing human behavior when we look at an entire time series of a behavior, where f is frequency. A time series with a 1/f power spectral density is one in which the power spectrum is inversely proportional to the frequency of the signal (for example, lots of power at low frequencies, but low power at high frequencies). The relationship is a power law and thus it forms a straight line when plotted on log-log coordinates. Time series that are characterized by 1/f power spectra have long-range correlations that are thought to indicate an underlying interaction-dominant system. It has been found that much of the variance in psychology experiments exhibits a 1/f power spectrum, which suggests that humans are interaction-dominant systems where cognitive computations emerge from interactions among components rather than from inside any of those components (Van Orden, Holden, & Turvey, 2003). 1/f noise has since been found in many different domains from motor systems (Gilden, Thornton, & Mallon, 1995; Hausdorff et al., 1996) to music (Voss, 1975) to speech (Kello, Anderson, Holden, & Van Orden, 2008a). In addition, 1/f slopes can converge within distinct subsystems (indicating that the systems are coupled), i.e. key press and timing deviation in a rhythmic tapping task converge, and heart beat and pupil dilation converge as well, but central and autonomic nervous systems do not cross-converge within participants (Rigoli, Holman, Spivey, & Kello, 2014). In this paper, we use two methods to study unconstrained mouse tracking data: singular value decomposition (SVD), and detrended fluctuation analysis (DFA). This pair of methods enables us to uncover structural and interpretable characteristics that predict performance in a task. SVD is an algorithm associated with principle components analysis (PCA), a standard method for high-dimensional data analysis and visualization used across a broad variety of domains (Eld√©n, 2007). Both SVD and PCA yield an ordered list of values (principal components, or singular values) that are associated with lower-dimensional subspaces that the data can be projected onto, in a way that reveals what the dominant characteristics of the data are. The values are ordered by how much of the variance in the data they explain, so that as one selects more of these components, they explain more of the data. The method can be applied directly to high-dimensional, complex-valued mouse trace data; is model free (it has no free parameters); reveals the most important components in a dataset in rank order; and can be used to develop interpretable diagnostics. SVD has not, to our knowledge, been applied to mouse tracking data, despite its advantages, but it has been used widely in cognitive science. For example, PCA has been used on motor movement data to show that fewer principal components are needed to explain the data when participants are engaged in a synchronized task (Riley, Richardson, Shockley, & Ramenzoni, 2011). PCA has also been used to discover that 75 percent of the variance between modalities in academic presentations (speech rate, intensity, slides changes, and gestural movement, etc) is accounted for by only 3 components (Alviar, Dale, & Galati, 2019), which correspond to different ways that presenters tend to speak. For example, the first component involved a positive relationship between speech rate, body movement, articulation rate and intensity, implying that ‚Äùspeakers who tend to speak faster also tend to speak louder and move more.‚Äù SVD is highly predictive and powerful, but it can be difficult to interpret. Thus, we also applied DFA, which has been independently applied to multi-scale data, and thus provides a baseline for comparison. With DFA a time series is broken into windows of decreasing sizes or scales, and within the windows at each scale, lines are fit to the data. The error in these lines is generally larger for the larger window sizes. The average error at each window size is plotted against window size in log-log, and a line is fitted to this data. The slope of this line is the Hurst parameter, which is a measure of fractal dimensionality in the data, which is associated multi-scale structure. It can be used to describe power law relationships and the color of noise, and is closely related to sample entropy. Researchers have used DFA to identify power law relationships between fluctuations in acceleration profiles for mouse movements at different time scales, and then shown that power laws change to reflect how well a person is ‚Äúsmoothly coping‚Äù with their mouse (Dotov et al., 2010). DFA has also been used on human inter-tap intervals when participants are attempting to tap along to a chaotic metronome to show that even though the metronome is chaotic and thus unpredictable, human inter-tap intervals will approximate the same statistical structure as the metronome (Stephen, Stepp, Dixon, & Turvey, 2008). This suggests that synchronization occurs not due to an internal tapping model with some error, but due to a more global process of coordination whereby the participant is becoming entrained with chaotic metronome.1 Several other researchers have considered techniques that might be applicable to the study of continuous mouse tracking data. For example, (Calcagn√¨, Lombardi, D‚ÄôAlessandro, & Freuli, 2019) use a state-space model to describe mouse tracking data. The method is, however, validated against standard segmented mouse traces rather than unconstrained data, for example providing better fits to standard lexical decision data than other approaches. Others have used mixture models that treat mouse movements as combinations of simpler trajectories (Yu et al., 2007). These models have been used to identify neural correlates of components of motions. Neither technique has been applied to unconstrained mouse tracking data. We suspect SVD has some advantages over these approaches, in particular in being relatively parsimonious and straightforward to apply, but it remains to be seen in future research. Summarizing: existing methods for analyzing mouse traces are focused almost entirely on segmented data (single mouse movements), while behavioral analysis techniques that can be applied to continuous movement have not, for the most part, been applied to unconstrained mouse data. A summary of these approaches to mouse tracking data, their standard use-cases, and their limitations relative to unconstrained mouse tracking data, is given in Table 1. Summary of existing methods for studying mouse traces, their typical uses, and their limitations relative to unconstrained mouse tracking data Curvature-based measures such as average deviation, AUC, and x-flips (Kieslich, Henninger, Wulff, Haslbeck, & Schulte-Mecklenbeck, 2019) Measures straightness of movements, which is sometimes associated with decision conflict Predictability of the next sample after a set of samples Associated with a variety of phenomena: attention, health, task demands, etc Derivative-based measures such as max velocity, average velocity, average acceleration, average jerk, etc. (Kieslich et al., 2019) Requires precise measurements, because taking the derivative of a time series amplifies its noise Hard to interpret or generalize from Not applied to mouse tracking data thus far Applies in principle to continuous movement and allows decomposition into constituent trajectories Not applied to unconstrained mouse tracking data thus far Provides good fits to data. Applies in principle to continuous movements Not applied to unconstrained mouse tracking data thus far In this paper we study unconstrained mouse tracking data in a simple clicking game similar to Whac-A-Mole. We used SVD and DFA to predict performance based on the mouse tracking data alone. Our results indicate that meaningful information exists at the level of an entire stream of mouse tracking data. In addition, we developed several novel approaches to analyzing mouse tracking data. First, we fit the mouse tracking coordinates to the complex plane. This allowed us to use information from both the x and y dimension simultaneously, rather than being constrained to one dimension, as is often done in mouse tracking studies. Second, we use SVD to define a diagnostic, , which says how well players fit to an accuracy space defined by the principal components of the most accurate players. The quantity is continuously varying, explains more variance than DFA does, and can be used to predict a player‚Äôs accuracy in a way that is more interpretable than DFA.\n\nWe designed a Whac-A-Mole game where several empty mole hills initially appear on the screen. Cartoon moles then appear and disappear in the mole hills in a pre-determined sequence (since this was an exploratory study, we wanted to minimize potential sources of variation). The player‚Äôs objective is to click the mole before it disappears and reappears in a different mole hill. A mole appears in a molehill for 650 ms before it disappears. If the mole is clicked, it changes to a cartoon picture of an unconscious mole for 350 ms. In both cases a mole then re-appears in another mole-hill. We pre-generated the random sequence of mole appearances so that every participant would experience the same pseudo-random sequence. The game ends after the participant has seen 120 moles (2-3 min). Upon completion of the game participants also filled out a short demographics form, and then were thanked and debriefed. The game was built in javascript and played through the browser at a website.2 During the game we continuously collected participants‚Äô cursor data, every ms (the maximum polling rate for javascript). We also collected participant‚Äôs click locations and recorded their accuracy in the game task. The experiment was deployed on Amazon Mechanical Turk (MTurk). We required that the MTurk workers have over a 95 percent approval rating, have not participated in one of our studies before, and be in the United States. We collected data from 600 participants in two samples. The first sample was collected on January 14, 2020 and had 300 participants. The second sample was collected on February 19, 2020 and had 300 participants. All participants were paid 35 cents for completing the 2-3 min study. Three additional criteria were used to filter the data. First, we focused on mouse tracking data only, and thus removed those who did not report using a mouse (a question asked them what type of device they were using: mouse, trackpad, or other). This removed 83 people from the first sample and 102 people from the second sample. We did not require that they use a mouse explicitly to prevent participants from simply lying and saying they were using one when they were not. Second, we removed people who did not register sufficient cursor movement. Since javascript only polls mouse locations when the cursor is moving, if a participant simply let the mouse idle while the game ran or only tried to move the mouse a few times, the participant would not log many datapoints. We removed 2 participants from sample 1 and no participants from sample 2 for having less than 300 cursor locations reported. This also filtered participants who reported that they were using a mouse but were in fact using a touch screen or some other input device. Third, we included two catch questions in our demographics form: ‚Äúhow many letters are in the english alphabet‚Äù and ‚Äúif you are reading this select the answer 17‚Äù. This eliminated 12 participants from sample 1 and 19 participants from sample 2. In all we removed 105 participants from sample 1 and 131 participants from sample 2 before analysis. After filtering, demographics were as follows. For sample 1: 111 male, 84 female, mean age 40.11 ( ), and approximately uniformly distributed experience with video games.3 For sample 2: 86 male, 83 female, mean age 40.22 ( ), and also approximately uniformly distributed experience with video games.4 For each participant, the cursor position was collected throughout the task every ms, producing roughly 6000-component vectors of x and y coordinates, which is the mouse trace for that participant. An example of a mouse trace is shown in Fig. 2. A sample mouse trace for one participant. Red dots correspond to mouse clicks Most methods for analyzing time series assume one-dimensional data. However, mouse tracking data is inherently two-dimensional since it is samples the and coordinates of the mouse position at discrete times. To accommodate this, researchers typically use only one dimension of their mouse trace data e.g., either the or coordinate over time. However, this restriction potentially leads to information loss, especially if one does not have insight into which dimension is likely to carry the most information. As an alternative, we introduce a complex-valued time series where with denoting the x-coordinate, denoting y-coordinate both at time level n, and denoting the imaginary constant. To isolate the coordinate, we evaluate the real part of and to isolate the coordinate, we evaluate the imaginary part of . Thus, we can retain the full information available in the mouse trace by representing the two-dimensional mouse tracking data as a function of a single complex variable. Mouse tracking through a browser has some inherent temporal variability as different computers and different browsers can poll at different speeds. To accommodate this we linearly interpolated all data using the pandas.resample method to make sure that all data points were exactly 20 ms apart and then trimmed all time series to the length of the shortest time series in the data set across both samples. (Several other resampling methods were tried to confirm that they did not impact the main results; since none did, we used the default method). Since the mouse tracking data are resampled to be uniform in sampling rate and length across participants, we are able to compute, analyze, and compare their Fourier spectra. To perform this spectral analysis, we computed the discrete Fourier transform of the complex time series using numpy.fft.fft, to produce a spectrum for each participant satisfying the relation with denoting the discrete frequencies and denoting the constant sampling rate. One possible next step would be to compute derivatives of the time series in order to analyze velocity, acceleration, jerk, etc., which is common in mouse tracking research (Kieslich & Henninger, 2017).5 However, taking derivatives of mouse tracking data is inherently problematic for several reasons. First, computing derivatives of time series amplifies noise. Additionally, mouse tracking data is driven by an inherently discontinuous sampling process, which is exacerbated in online environments due to the browser (mouse positions are polled faster by the computer than they are by the browser) and network latency. These discontinuities lead to infinite derivatives. These issues can be dealt with if the number of samples is sufficient and appropriate filters are used (Nazir et al., 2008). Regardless, we show in our results below that we are able to recover valuable insight about information contained in mouse tracking data without needing to compute derivatives.\n\nWe start with a high-level sketch of how we applied SVD and DFA to our data. First, we pre-processed the data in the following steps:\n‚Ä¢ None Import the data, which has already been filtered and converted into data frames (this is the publicly available data).\n‚Ä¢ None Linearly interpolate the (x, y) coordinates for each individual person to ensure same-length time series and points equidistant in time.\n‚Ä¢ None Perform a Fourier transform on the complex-valued time series for each person. We now have Fourier transforms for the complex-valued, interpolated time series for each participant. We then perform our SVD analysis, using the following steps:\n‚Ä¢ None Split the data into high and low performance groups for Sample 1 and Sample 2.\n‚Ä¢ None Compute the SVD of the Fourier transforms of the high performers in Sample 1.\n‚Ä¢ None Create a space from a selection of the sample singular vectors from the high performers in Sample 1, using the most important vectors, accounting for about 50% of the variability in the data.\n‚Ä¢ None Compare the high and low performing groups from Sample 2 to the space created from the singular vectors of the high performing group from Sample 1. Note that we can use the space derived from Sample 1 to separate high and low performers in Sample 2, which implies a difference in behaviors that can be generalized across samples. We then investigated multi-scale structure in the data, using the following steps:\n‚Ä¢ None Convert the spectrum to a power spectral density (PSD), and plot in log-log coordinates.\n‚Ä¢ None Observe difference in the slopes of the PSD of the high and low performers.\n‚Ä¢ None Use Hurst exponents of DFA to predict performance. Let P denote the number of participants and denote the vector of length N containing the values of the discrete Fourier spectrum for participant p. We form the matrix A of complex numbers defined according to In other words, the pth column of A corresponds to the discrete Fourier spectrum of the mouse tracking data for participant p. In what follows, we assume that since the number of participants in each study is smaller than the number of discrete Fourier frequencies. The singular value decomposition (SVD) of the matrix A (Demmel, 1997; Trefethen & Bau III, 1997; Ramsay & Silverman, 2005) is Here, the superscript denotes the complex conjugate transpose of the matrix. The columns of the matrix U form an orthonormal basis for , the space of all complex vectors of length N. The columns of the matrix V form an orthonormal basis for , the space of all complex vectors of length P. The matrix has non-negative entries along its diagonal called the singular values, which we denote by for . The non-diagonal entries of are zero identically. In fact, computing the SVD of the matrix A is the same as performing principal component analysis (PCA). We focus on the linear algebra interpretation of the SVD to study the discrete Fourier spectra of mouse tracking data. In particular we use concepts such as projections onto subspaces. By doing so we develop model-free methods that make use of any underlying algebraic structures in these data. All matrices possess a singular value decomposition and the singular values are unique. The singular values are ordered by size, Let denote the nth column of U and denote the pth column of V. We can rewrite the SVD of A as By writing A as this sum, we see that the singular values give a relative rank of the importance of the corresponding columns of U and V in the data ‚Äì the first term gives the largest contribution, the second term gives the next largest, and so on. Additionally, we can consider approximations by truncating the sum above after some specified amount of terms. This approximation corresponds to the projection onto the subspace spanned by the vectors included in it. Suppose we only use the first k singular values. Let denote the matrix formed by taking the first k columns of U and removing the rest. The columns of form an orthogonal basis for a subspace of A, which we denote by . Now consider an individual participant‚Äôs discrete Fourier spectrum, . The projection of onto is given by . The length of this resulting vector is with denoting the Euclidean norm. When we compute the value gives the fractional amount of lying in the subspace . When , lies entirely in . When , none of lies in . We explain below how we use to study performance. To analyze performance we first operationalized performance as accuracy in the game ‚Äì the higher the percentage of moles clicked, the higher the accuracy and the better the performance. To investigate performance operationalized as accuracy, we first partitioned our data into ‚Äúaccurate‚Äù and ‚Äúinaccurate‚Äù groups, where ‚Äúaccurate‚Äù participants scored above 50.5 percent, and ‚Äúinaccurate‚Äù participants scored below 12 percent. These numbers were chosen to keep the group sizes about the same across the two samples. For sample 1 this resulted in 44 in the high accuracy group and 32 in the low accuracy group. For sample 2 high accuracy had 33 and low accuracy had 36. To address the worry that demographic differences in these splits accounts for our results, we regressed the demographic variables both on performance and on our predictor of performance, . There was no meaningful relationship between any of the demographic variables and either performance or . We collect the discrete Fourier spectra of accurate players from Sample 1 and form the matrix A with them. Upon computing the SVD of A, we determine how many singular values are important in explaining the data. The singular values for are proportional to the square root of the variance accounted for by the corresponding column of U. Thus, the cumulative sum of squares of the singular values is the cumulative sum of variance explained. This cumulative sum is shown in Fig. 3 and we determine from these results that explains 50 percent of the variance. We call the resulting subspace by considering the first 9 columns of U the accuracy subspace. By computing , we determine the fractional amount a given discrete Fourier spectrum lies in the accuracy subspace. Consequently, is a measure of fitness to high performing players. The cumulative variance accounted for by each component in the accuracy space. Notice that the first 8 components account for about of the variance We consider results of Sample 2 to test how well the accuracy subspace from Sample 1 generalized to new, out-of sample participants. We identified accurate and inaccurate players in Sample 2 using the same criteria that we used to determine accurate and inaccurate players for Sample 1. To test out-of-sample performance, we computed for accurate and inaccurate players in Sample 2. The results of this computation are shown in Fig. 4. These results show that the two groups, accurate and inaccurate, are almost completely separable. They are shown to be significantly different according to a Welch‚Äôs t-test ( ). These results demonstrate the existence of structural features in the discrete Fourier spectra of accurate players that is not shared by less accurate players. The accuracy subspace contains algebraic structures inherent in accurate players that are not shared by less accurate players. Therefore, testing the extent to which a player‚Äôs discrete Fourier spectrum aligns with the accuracy subspace provides a diagnostic method for performance. Moreover, these results suggest that these structural differences persist across different samples. Projection of accurate and inaccurate participants in sample 2 to the accurate space from sample 1. Blue dots correspond to accurate players; orange dots to inaccurate players. The accurate players fit the space of accurate players from the earlier sample better with higher (which corresponds to how well a participant fits to a space). The two groups are also significantly different ( ). This shows that accurate and inaccurate players are separable using SVD Next, we computed for all players in Sample 2. In doing so, we found that there was a significant relationship ( ) between accuracy and the value of (see Fig. 5) with . Accuracy and fit both range from 0 to 1, and the unstandardized coefficient for fit regressed on accuracy was = 0.3 with standard error of .02, which means that as accuracy increases fit increases. These results show that the relationship does not just separate two groups of accurate and inaccurate players in the sample, but explains degrees of accuracy throughout the sample. Performance regressed on fit to accuracy space. The relationship between accuracy and fit to the accurate space of sample 1 for participants from sample 2. Accuracy ranges from 0 (no mole hits) to 1 (every mole was hit). We can see that accuracy is related to fit to the accuracy space. The unstandardized is 0.30 with standard error 0.02. and Representing our mouse traces using a single complex variable opens access and opportunity for novel methods of analysis. For example, we have been able to perform SVD/PCA directly on the discrete Fourier spectra of the full mouse tracking data. In doing so, we have been able to identify structural differences in the discrete Fourier spectra between accurate and less accurate players. We have found that these structural differences are statistically significant and persist in out-of-sample results. To investigate the accuracy subspace further, we consider the power spectrum of the columns of corresponding to the absolute value squared of each entry of a column of . We then examine the shape of the power spectrum on a log-log scale. We have performed this analysis on the first 8 columns of . Figure 6 shows the power spectrum for the first column of plotted in log-log scale. Over the first 8 columns of , we observe a consistent linear structure to the power spectra. A linear trend for frequencies plotted in log-log can indicate a power law, which can in turn imply long-range correlations in a complex system. To investigate possible long-range correlations, we use DFA (Peng, Havlin, Stanley, & Goldberger, 1995). The most important component used for creating the accurate player space, plotted in log-log scale DFA is a measure of the relationship between variance within windows of a time series and the size of those windows which, in turn, provides a measure of the amount of long-range correlation in time series (Stergiou & Decker, 2011). DFA has been applied in several areas of cognitive science (and extensively in other fields) as a tool to measure complexity in a time series. For example, Dotov et al use DFA to identify a change in the complexity of motor movements corresponding to a change from smoothly using an interface to cases of ‚Äúbreakdown‚Äù, where the user interface is perturbed so that it no longer behaves as the user expects it to Dotov et al., (2010). To compute DFA we start with our complex time series: We center the data by subtracting the mean and then compute the cumulative sum, We then partition the time series into windows of size . Using the smallest possible value, , is often not advised (Bryce & Sprague, 2012), so we set as the minimum window size. For a fixed window of width s starting at n, we compute a least-squares regression model satisfying, and then calculate the residuals, Here denotes the fitted polynomial of degree d (Shao, Gu, Jiang, Zhou, & Sornette, 2012). Linear fits are usually used so that in most applications (including ours), . We compute the root mean square of the residual for each window size s, to obtain the fluctuation value (Shao et al., 2012), Note that we are squaring the absolute values of the residuals, rather than the residuals themselves, since we are working with complex-valued time series. We then fit a line to the relationship between the log-scaled and the log-scaled s (Shao et al., 2012). The slope of this line is , which is taken to approximate the Hurst parameter H. The Hurst parameter is a measure of fractal dimension in a time series. If the process is considered to be anti-correlated in time such that high values tend to be followed by low values and vice versa. If the process is not correlated in time, and if then the process is said to be positively correlated in time (Ihlen, 2012; Nolds module ‚Äî 0.5.2 Documentation, n.d.). However, if the process is non-stationary and can be modeled as fractional Brownian motion where the Hurst parameter of the systems is approximated by instead of (Hardstone et al., 2012; Nolds module ‚Äî 0.5.2 Documentation, n.d.). That is, for a non-stationary process, when the process is anti-correlated in time, if the process is not correlated in time, and if then the process is positively correlated in time. DFA is a frequently used to analyze complex systems to determine the amount of long-range correlation in the data, which some contend is indicative of the degree of fractal structure in the system. The Hurst parameters provided by DFA were significantly predictive of accuracy ( ), as shown in Fig. 7. However, it was a much less powerful model with (vs. for SVD). Virtually all participants‚Äô Hurst Parameters indicated some degree of nonstationairity in their fractal structure, as all participants were . The negative relationship = implies that lower performing participants actually have more long range positive correlation in time than high performing participants, and high performers‚Äô mouse movements are somewhat anti-correlated in time. This might seem strange at first, given that previous literature suggests that long-range correlations are positively related to performance. However, given that the moles‚Äô next position is pseudorandom, it could also mean that participants whose Hurst parameters are below 1.5 are actually better approximating the target. In a similar fashion, expert Tetris players have been shown to rely heavily on the rotate button, allowing them to offload some of their cognition (Kirsh & Maglio, 1994). High-performing participants in this task appear to develop a pattern of interfacing with their environment that is substantially different from how the low-performing participants are interfacing with their environment. By exhibiting a lower fractal dimensionality in their time series, these high-performing participants are using up less of the ‚Äúreal estate‚Äù in the two-dimensional playing field and generating more efficient mouse traces that can be characterized in fewer fractal dimensions. The parameter regressed on performance. The negative slope = implies that the fractal dimension of the time series is decreasing as performance goes up. This in turn suggests that the time series are more likely to be anti-correlated as performance improves\n\nWe designed a simple Whac-A-Mole like video game which participants played for a few minutes, during which mouse position data were captured. We did not know what might predict performance in this data, but were able to systematically explore it and find quantitative structures that were highly predictive of performance. Our results show that accurate players play differently than inaccurate players and that this difference is detectable in the mouse tracking data. Overall our efforts provide a good case study of how to explore and analyze unconstrained mouse tracking data. Even if a performance measure like accuracy were not available for a computer mouse task, these results show that those metrics could nicely be approximated by the mouse movements alone using principal components from known experts. The SVD was substantially more predictive of accuracy than DFA ( vs. ), suggesting it is more powerful as a means of predicting accuracy and other features of behavior. However, the DFA analysis is important because it has an interpretation in terms of cognitive science. DFA indicates the presence of multi-scale structure. In fact, the degree to which SVD outperforms DFA suggests that there is more going on for accuracy than just multi-scale structure. Unconstrained mouse traces are difficult to analyze using standard technique such as reaction times (Table 1) because they lack well-defined beginnings and ends relative to individual mouse movements. This is representative of many real tasks outside of scripted psychology experiments. For example, in our data, mouse clicks can‚Äôt be interpreted as reactions to particular stimuli because we don‚Äôt know which stimulus participants are attending to. In some cases they may be attending to the currently visible mole when clicking, which is a straightforward reaction time. However, in other cases they might be predicting where a mole will appear next, adopting a strategy like ‚Äúclick in one place repeatedly to guarantee some hits‚Äù, or reacting to (and missing) a mole that is replaced by a new mole before clicking. In these cases the time interval between a mole‚Äôs initial appearance and the next mouse click is something other than a reaction time. These methods and results provide two contributions to mouse tracking research and in particular to the analysis of unconstrained mouse traces. First, to our knowledge the only methods that have been used to analyze unconstrained mouse tracking data are machine learning techniques (Kolakowska, 2013; Liu, Fernando, & Rajapakse, 2018), which do not, however, provide interpretable results or generalizable insight into the mouse movements of the participants. As summarized in Table 1, other techniques could in principle be applied to this data, but this has not yet been done, to our knowledge. We have provided an initial guide to analyzing uninterrupted streams of mouse movements, in contexts where there are no clearly demarcated individual movements with determinate beginnings or endings. We have shown how to study unconstrained mouse tracking data in a way that is systematic, and can produce interpretable results. To be clear, the method we describe is not intended as a replacement for existing mouse tracking methods, which work well for single-movement data. Existing approaches to analyzing segmented mouse traces are clear, easy to interpret, and have an established track record. Second, mouse tracking data naturally lies on a two-dimensional plane, but most time series analyses require a one-dimensional time series. The problem is usually solved by taking a time series of one dimension, such as the x dimension (Schulte-Mecklenbeck, Kuehberger, & Johnson, 2019). This solution works for binary forced choice tasks, where participants are making single movements and most of the information exists along one axis. However, even in these situations the one-dimensional analysis ends up neglecting potentially meaningful information in the other dimension, or in the combination of the dimensions. To address this we instead embed the data in the complex plane, which allows us to take two-dimensional coordinates and express them using a single complex variable. We are then able to convert our time series directly into the frequency domain. To our knowledge converting mouse coordinates to the complex plane has not been done before. Outside of advancing methods in mouse tracking, we believe that our results help to characterize how high performers use their mouse. Our results indicate that behaviors associated with accurate game play produce long-range anti-correlations in the mouse movements. This result contrasts with some existing literature, which has found examples where long-range correlations are indicative of health or performance in human systems (Voytek et al., 2015; Hausdorff, 2007; Diniz et al., 2011). However, we could interpret accurate play in our task as attempting to synchronize spatially with a pseudo-random target, which does not have these long-range correlations. This is similar to the way participants attempting to synchronize with a chaotic metronome approximate its global multi-scale structure (Stephen et al., 2008). In the current experiment, rather than produce the long-range correlations they normally would in a repetitive task like walking or saying the same word repeatedly (Kello, Anderson, Holden, & Van Orden, 2008b), participants adapt themselves to the structure of the task. Additional hypothesis testing is needed to confirm this. We believe this analysis could serve as a foundation for future research. In most natural settings user data cannot be precisely segmented into individual movements, and so traditional approaches to studying mouse movements cannot be applied. But there is often a desire to be able to gather data about such phenomena as affective states or engagement. These phenomena typically unfold at temporal scales much longer than individual mouse movements. For example, consider an immersive video game such as a first person shooter in a three-dimensional environment, which involves extended periods of play during which players provide continuous input to the game. Developers often want to know if changes they make to the game improve the experience of players, which is difficult to obtain via direct reporting. Methods like these could be used to study how players‚Äô dynamics change in response to changes in the game, which could be indicative of player performance, engagement, team compatibility, ease of use, sentiment, etc. Any sufficiently large subset of mouse tracking data with some known characteristic could be used to define a space analogous to the accuracy space we used here. For example, data from players who report strong vs. weak team compatibility could be used to define a team compatibility space, which could then be used to identify new players for a team. An example where this type of approach is applied to measuring task engagement is Meyer (2022). Future work extending this approach could also involve the development of an AI simulation that plays the Whac-A-Mole game. Different parameters and strategies could be programmed into the simulation and our approach could be tested for its ability to detect the presence or absence of those particular parameter settings and strategies. This research could also provide insight into other components of cognition, such as response conflict, uncertainty, the time course of perception vs. cognition in tasks, etc., which have traditionally been a focus of mouse tracking research in cognitive science and psychology. To some extent, there is a paradigm difference between these approaches and ours. From our ‚Äúembodied mind‚Äù and dynamical systems perspective (Dotov & Chemero, 2014; Kelso, 1995; Schmidt, Carello, & Turvey, 1990), we are revealing how spatiotemporal structures in behavior can be related to performance, based on complex profiles of long-term and short-term correlations. We are not looking for specific components of cognition in the data or ‚Äúcomponent-dominant dynamics‚Äù (Van Orden et al., 2003). Rather, we are looking at dynamic interactive patterns in the movement space, and making minimal assumptions about cognitive modules that may or may not be involved (Spivey, 2023). We are not ideologically opposed to componential studies, and could see future work integrating insights from both approaches. Our SVD approach allows an arbitrary data stream to be studied for its general characteristics, but this could then be used alongside more traditional studies, in the spirit of pluralism in cognitive science (Dale, Dietrich, & Chemero, 2009; Yoshimi, 2023). Broadly speaking, the approach is more data driven than task or theory driven. The method is meant to identify complex patterns in a data set, and then to use these structures for analysis and prediction. The details will vary from task to task, and the results might not correspond directly to any existing theoretical constructs. But even if the approach is data driven, the methods are generalizable. The analysis pipeline we developed can be applied to any unconstrained behavioral task, and used to identify and interpret behaviors even when they are difficult to put into words. Consider soccer, basketball, or any team sport. Many features of these behaviors are the result of extremely complex interactions that have no pre-existing name or designation. Yet there is consensus among good players about best practices. As a result, a soccer teacher might just say ‚Äúkick like this.‚Äù These methods can be used to identify such behaviors in time series data and to associate them with a space describing to what degree a person performs the behavior. Especially in online settings where such behaviors are common and the data relatively easy to gather, we expect these methods to be valuable."
    },
    {
        "link": "https://link.springer.com/article/10.3758/s13428-023-02210-5",
        "document": "Mouse tracking is an important source of data in cognitive science. Most contemporary mouse tracking studies use binary-choice tasks and analyze the curvature or velocity of an individual mouse movement during an experimental trial as participants select from one of the two options. However, there are many types of mouse tracking data available beyond what is produced in a binary-choice task, including naturalistic data from web users. In order to utilize these data, cognitive scientists need tools that are robust to the lack of trial-by-trial structure in most normal computer tasks. We use singular value decomposition (SVD) and detrended fluctuation analysis (DFA) to analyze whole time series of unstructured mouse movement data. We also introduce a new technique for describing two-dimensional mouse traces as complex-valued time series, which allows SVD and DFA to be applied in a straightforward way without losing important spatial information. We find that there is useful information at the level of whole time series, and we use this information to predict performance in an online task. We also discuss how the implications of these results can advance the use of mouse tracking research in cognitive science.\n\nNumerous experiments in multiple fields have shown that the body and environment have a profound influence on mental activity (McBeath, Shaffer, & Kaiser, 1995; Thelen, Sch√∂ner, Scheier, & Smith, 2001; Hotton & Yoshimi, 2011; Silberstein & Chemero, 2012). Ongoing, continuous exchange of information between body, mind, and environment suggests that measurements of any of these subsystems will produce information about cognition. This in turn predicts that cursor data, an indirect measurement of the body‚Äôs movements, will contain information about cognition. Mouse tracking studies can capture this data, and have many additional advantages. The ‚Äúenvironment‚Äù in a computer task is highly controlled, and environmental variables can be monitored with high precision. The mouse, as a sensor for the body, can be measured with low latency. Computer tasks using mouse tracking data are relatively cheap and easy to produce, and data can be gathered from experiments run remotely over the internet. Most mouse tracking research follows a standard paradigm, a two-choice task in which a participant‚Äôs cursor begins at a predetermined start location, usually at the bottom-middle of the screen (Hehman, Stolier, & Freeman, 2015; Maldonado, Dunbar, & Chemla, 2019; Freeman, 2018). For a broad recent overview of this type of research see (Schoemann, O‚ÄôHora, Dale, & Scherbaum, 2020). The participant is then presented with a stimulus and asked to make a choice. They might be shown a picture of an animal and asked to identify that animal as a fish or a mammal by moving the mouse cursor to a text box labeled ‚Äúfish‚Äù or ‚Äúmammal‚Äù (See Fig. 1). As the participant moves their cursor towards the target, the (x, y) position of the cursor is recorded. The resulting vector of time stamped positions is a cursor trajectory. These cursor trajectories are then aggregated and analyzed (Hehman, Stolier, & Freeman, 2015; Stillman, Shen, & Ferguson, 2018). Standard mouse tracking task, based on the example in Hehman, Stolier, and Freeman (2015) In one of the most prominent examples of this type of research, participants are presented with either typical mammals such as cats, or atypical mammals such as whales. Participants‚Äô cursor trajectories are found to be more curved during trials with atypical exemplars, suggesting a ‚Äúgraded competitive process‚Äù of categorization, rather than a serial model (Dale, Kehoe, & Spivey, 2007). Other prominent examples include: evidence for multiple distinct components of inhibitory control in Stroop and flanker tasks (Erb, Moher, Sobel, & Song, 2016), evidence against a dual system of emotion and reasoning in moral reasoning (Koop, 2013), evidence that better self-control facilitates quicker resolution of self-control conflicts shown by earlier changes in curvature of mouse movement (Gillebaart, Schneider, & De Ridder, 2016), evidence for ‚Äúpartial and parallel activation of stereotypes‚Äù, implying that ‚Äúperceptual cues of the face‚Äù invoke multiple ‚Äúsimultaneously active stereotypes... and this mixture settles over time onto ultimate judgments‚Äù (Freeman & Ambady, 2009), and ‚Äúevidence that cursor motion analysis has the capacity to predict emotional experience of the computer users\" (Yamauchi & Xiao, 2018). Despite its value in the study of continuous output during binary decision tasks, this research does have limitations. First, it is limited to serial tasks with a predetermined start and end point for each mouse movement. In addition, because the data are segmented into many discrete trials, dynamic processes which might build over longer timescales are hard to analyze. Thirdly, as is normal in many psychological paradigms, participants are required to follow rigid procedures in order to obtain clean data. These constraints make it difficult to apply standard mouse tracking techniques to unconstrained mouse tracking data, which is continuous over time, not segmented into individual movements, and not necessarily constrained in terms of starting position, end position, or preferred trajectory. One way of dealing with the lack of structure in unconstrained mouse tracking data is to use machine learning techniques. Researchers in affective computing often use machine learning techniques to predict user characteristics (Kolakowska, 2013). However, though this approach addresses a particular business need, it does not usually provide results that generalize to other tasks, or provide novel scientific insights. Another option is to draw on dynamical systems and complex systems approaches to cognition. For example, some have analyzed hand movements in open ended computer tasks such as corralling artificial agents in a computer game (Nalepka, Kallen, Chemero, Saltzman, & Richardson, 2017; Dotov, Nie, & Chemero, 2010). In tasks like these, where the movements are fluid and in continuous streams of motion, it is not clear what constitutes a single movement. Because of this, researchers in these areas tend not to decompose data into individual movements or behaviors, focusing instead on whole time series of behavioral data. One type of behavior that has been found when studying cognitive systems from this standpoint is power law relationships across multiple time scales. For example, several studies have found evidence for a 1/f power law in spectra characterizing human behavior when we look at an entire time series of a behavior, where f is frequency. A time series with a 1/f power spectral density is one in which the power spectrum is inversely proportional to the frequency of the signal (for example, lots of power at low frequencies, but low power at high frequencies). The relationship is a power law and thus it forms a straight line when plotted on log-log coordinates. Time series that are characterized by 1/f power spectra have long-range correlations that are thought to indicate an underlying interaction-dominant system. It has been found that much of the variance in psychology experiments exhibits a 1/f power spectrum, which suggests that humans are interaction-dominant systems where cognitive computations emerge from interactions among components rather than from inside any of those components (Van Orden, Holden, & Turvey, 2003). 1/f noise has since been found in many different domains from motor systems (Gilden, Thornton, & Mallon, 1995; Hausdorff et al., 1996) to music (Voss, 1975) to speech (Kello, Anderson, Holden, & Van Orden, 2008a). In addition, 1/f slopes can converge within distinct subsystems (indicating that the systems are coupled), i.e. key press and timing deviation in a rhythmic tapping task converge, and heart beat and pupil dilation converge as well, but central and autonomic nervous systems do not cross-converge within participants (Rigoli, Holman, Spivey, & Kello, 2014). In this paper, we use two methods to study unconstrained mouse tracking data: singular value decomposition (SVD), and detrended fluctuation analysis (DFA). This pair of methods enables us to uncover structural and interpretable characteristics that predict performance in a task. SVD is an algorithm associated with principle components analysis (PCA), a standard method for high-dimensional data analysis and visualization used across a broad variety of domains (Eld√©n, 2007). Both SVD and PCA yield an ordered list of values (principal components, or singular values) that are associated with lower-dimensional subspaces that the data can be projected onto, in a way that reveals what the dominant characteristics of the data are. The values are ordered by how much of the variance in the data they explain, so that as one selects more of these components, they explain more of the data. The method can be applied directly to high-dimensional, complex-valued mouse trace data; is model free (it has no free parameters); reveals the most important components in a dataset in rank order; and can be used to develop interpretable diagnostics. SVD has not, to our knowledge, been applied to mouse tracking data, despite its advantages, but it has been used widely in cognitive science. For example, PCA has been used on motor movement data to show that fewer principal components are needed to explain the data when participants are engaged in a synchronized task (Riley, Richardson, Shockley, & Ramenzoni, 2011). PCA has also been used to discover that 75 percent of the variance between modalities in academic presentations (speech rate, intensity, slides changes, and gestural movement, etc) is accounted for by only 3 components (Alviar, Dale, & Galati, 2019), which correspond to different ways that presenters tend to speak. For example, the first component involved a positive relationship between speech rate, body movement, articulation rate and intensity, implying that ‚Äùspeakers who tend to speak faster also tend to speak louder and move more.‚Äù SVD is highly predictive and powerful, but it can be difficult to interpret. Thus, we also applied DFA, which has been independently applied to multi-scale data, and thus provides a baseline for comparison. With DFA a time series is broken into windows of decreasing sizes or scales, and within the windows at each scale, lines are fit to the data. The error in these lines is generally larger for the larger window sizes. The average error at each window size is plotted against window size in log-log, and a line is fitted to this data. The slope of this line is the Hurst parameter, which is a measure of fractal dimensionality in the data, which is associated multi-scale structure. It can be used to describe power law relationships and the color of noise, and is closely related to sample entropy. Researchers have used DFA to identify power law relationships between fluctuations in acceleration profiles for mouse movements at different time scales, and then shown that power laws change to reflect how well a person is ‚Äúsmoothly coping‚Äù with their mouse (Dotov et al., 2010). DFA has also been used on human inter-tap intervals when participants are attempting to tap along to a chaotic metronome to show that even though the metronome is chaotic and thus unpredictable, human inter-tap intervals will approximate the same statistical structure as the metronome (Stephen, Stepp, Dixon, & Turvey, 2008). This suggests that synchronization occurs not due to an internal tapping model with some error, but due to a more global process of coordination whereby the participant is becoming entrained with chaotic metronome.Footnote 1 Several other researchers have considered techniques that might be applicable to the study of continuous mouse tracking data. For example, (Calcagn√¨, Lombardi, D‚ÄôAlessandro, & Freuli, 2019) use a state-space model to describe mouse tracking data. The method is, however, validated against standard segmented mouse traces rather than unconstrained data, for example providing better fits to standard lexical decision data than other approaches. Others have used mixture models that treat mouse movements as combinations of simpler trajectories (Yu et al., 2007). These models have been used to identify neural correlates of components of motions. Neither technique has been applied to unconstrained mouse tracking data. We suspect SVD has some advantages over these approaches, in particular in being relatively parsimonious and straightforward to apply, but it remains to be seen in future research. Summarizing: existing methods for analyzing mouse traces are focused almost entirely on segmented data (single mouse movements), while behavioral analysis techniques that can be applied to continuous movement have not, for the most part, been applied to unconstrained mouse data. A summary of these approaches to mouse tracking data, their standard use-cases, and their limitations relative to unconstrained mouse tracking data, is given in Table 1. Table 1 Summary of existing methods for studying mouse traces, their typical uses, and their limitations relative to unconstrained mouse tracking data In this paper we study unconstrained mouse tracking data in a simple clicking game similar to Whac-A-Mole. We used SVD and DFA to predict performance based on the mouse tracking data alone. Our results indicate that meaningful information exists at the level of an entire stream of mouse tracking data. In addition, we developed several novel approaches to analyzing mouse tracking data. First, we fit the mouse tracking coordinates to the complex plane. This allowed us to use information from both the x and y dimension simultaneously, rather than being constrained to one dimension, as is often done in mouse tracking studies. Second, we use SVD to define a diagnostic, \\(\\eta \\), which says how well players fit to an accuracy space defined by the principal components of the most accurate players. The quantity \\(\\eta \\) is continuously varying, explains more variance than DFA does, and can be used to predict a player‚Äôs accuracy in a way that is more interpretable than DFA.\n\nWe designed a Whac-A-Mole game where several empty mole hills initially appear on the screen. Cartoon moles then appear and disappear in the mole hills in a pre-determined sequence (since this was an exploratory study, we wanted to minimize potential sources of variation). The player‚Äôs objective is to click the mole before it disappears and reappears in a different mole hill. A mole appears in a molehill for 650 ms before it disappears. If the mole is clicked, it changes to a cartoon picture of an unconscious mole for 350 ms. In both cases a mole then re-appears in another mole-hill. We pre-generated the random sequence of mole appearances so that every participant would experience the same pseudo-random sequence. The game ends after the participant has seen 120 moles (2-3 min). Upon completion of the game participants also filled out a short demographics form, and then were thanked and debriefed. The game was built in javascript and played through the browser at a website.Footnote 2 During the game we continuously collected participants‚Äô cursor data, every \\(8-12\\) ms (the maximum polling rate for javascript). We also collected participant‚Äôs click locations and recorded their accuracy in the game task. The experiment was deployed on Amazon Mechanical Turk (MTurk). We required that the MTurk workers have over a 95 percent approval rating, have not participated in one of our studies before, and be in the United States. We collected data from 600 participants in two samples. The first sample was collected on January 14, 2020 and had 300 participants. The second sample was collected on February 19, 2020 and had 300 participants. All participants were paid 35 cents for completing the 2-3 min study. Three additional criteria were used to filter the data. First, we focused on mouse tracking data only, and thus removed those who did not report using a mouse (a question asked them what type of device they were using: mouse, trackpad, or other). This removed 83 people from the first sample and 102 people from the second sample. We did not require that they use a mouse explicitly to prevent participants from simply lying and saying they were using one when they were not. Second, we removed people who did not register sufficient cursor movement. Since javascript only polls mouse locations when the cursor is moving, if a participant simply let the mouse idle while the game ran or only tried to move the mouse a few times, the participant would not log many datapoints. We removed 2 participants from sample 1 and no participants from sample 2 for having less than 300 cursor locations reported. This also filtered participants who reported that they were using a mouse but were in fact using a touch screen or some other input device. Third, we included two catch questions in our demographics form: ‚Äúhow many letters are in the english alphabet‚Äù and ‚Äúif you are reading this select the answer 17‚Äù. This eliminated 12 participants from sample 1 and 19 participants from sample 2. In all we removed 105 participants from sample 1 and 131 participants from sample 2 before analysis. After filtering, demographics were as follows. For sample 1: 111 male, 84 female, mean age 40.11 (\\(\\sigma = 21.35\\)), and approximately uniformly distributed experience with video games.Footnote 3 For sample 2: 86 male, 83 female, mean age 40.22 (\\(\\sigma = 13.17\\)), and also approximately uniformly distributed experience with video games.Footnote 4 For each participant, the cursor position was collected throughout the task every \\(8-12\\) ms, producing roughly 6000-component vectors of x and y coordinates, which is the mouse trace for that participant. An example of a mouse trace is shown in Fig. 2. Most methods for analyzing time series assume one-dimensional data. However, mouse tracking data is inherently two-dimensional since it is samples the \\(x-\\) and \\(y-\\)coordinates of the mouse position at discrete times. To accommodate this, researchers typically use only one dimension of their mouse trace data e.g., either the \\(x-\\) or \\(y-\\)coordinate over time. However, this restriction potentially leads to information loss, especially if one does not have insight into which dimension is likely to carry the most information. As an alternative, we introduce a complex-valued time series \\(z_{n}\\) where with \\(x_{n}\\) denoting the x-coordinate, \\(y_{n}\\) denoting y-coordinate both at time level n, and \\(\\textrm{i} = \\sqrt{-1}\\) denoting the imaginary constant. To isolate the \\(x-\\)coordinate, we evaluate the real part of \\(z_{n}\\) and to isolate the \\(y-\\)coordinate, we evaluate the imaginary part of \\(z_{n}\\). Thus, we can retain the full information available in the mouse trace by representing the two-dimensional mouse tracking data as a function of a single complex variable. Mouse tracking through a browser has some inherent temporal variability as different computers and different browsers can poll at different speeds. To accommodate this we linearly interpolated all data using the pandas.resample method to make sure that all data points were exactly 20 ms apart and then trimmed all time series to the length of the shortest time series in the data set across both samples. (Several other resampling methods were tried to confirm that they did not impact the main results; since none did, we used the default method). A sample mouse trace for one participant. Red dots correspond to mouse clicks Since the mouse tracking data are resampled to be uniform in sampling rate and length across participants, we are able to compute, analyze, and compare their Fourier spectra. To perform this spectral analysis, we computed the discrete Fourier transform of the complex time series using numpy.fft.fft, to produce a spectrum \\(Z_{n}\\) for each participant satisfying the relation with \\(f_{n} = n/(N \\Delta t)\\) denoting the discrete frequencies and \\(\\Delta t\\) denoting the constant sampling rate. One possible next step would be to compute derivatives of the time series in order to analyze velocity, acceleration, jerk, etc., which is common in mouse tracking research (Kieslich & Henninger, 2017).Footnote 5 However, taking derivatives of mouse tracking data is inherently problematic for several reasons. First, computing derivatives of time series amplifies noise. Additionally, mouse tracking data is driven by an inherently discontinuous sampling process, which is exacerbated in online environments due to the browser (mouse positions are polled faster by the computer than they are by the browser) and network latency. These discontinuities lead to infinite derivatives. These issues can be dealt with if the number of samples is sufficient and appropriate filters are used (Nazir et al., 2008). Regardless, we show in our results below that we are able to recover valuable insight about information contained in mouse tracking data without needing to compute derivatives.\n\nWe start with a high-level sketch of how we applied SVD and DFA to our data. First, we pre-processed the data in the following steps:\n‚Ä¢ Import the data, which has already been filtered and converted into data frames (this is the publicly available data).\n‚Ä¢ Linearly interpolate the (x, y) coordinates for each individual person to ensure same-length time series and points equidistant in time.\n‚Ä¢ Perform a Fourier transform on the complex-valued time series for each person. We now have Fourier transforms for the complex-valued, interpolated time series for each participant. We then perform our SVD analysis, using the following steps:\n‚Ä¢ Split the data into high and low performance groups for Sample 1 and Sample 2.\n‚Ä¢ Compute the SVD of the Fourier transforms of the high performers in Sample 1.\n‚Ä¢ Create a space from a selection of the sample singular vectors from the high performers in Sample 1, using the most important vectors, accounting for about 50% of the variability in the data.\n‚Ä¢ Compare the high and low performing groups from Sample 2 to the space created from the singular vectors of the high performing group from Sample 1. Note that we can use the space derived from Sample 1 to separate high and low performers in Sample 2, which implies a difference in behaviors that can be generalized across samples. We then investigated multi-scale structure in the data, using the following steps:\n‚Ä¢ Convert the spectrum to a power spectral density (PSD), and plot in log-log coordinates.\n‚Ä¢ Observe difference in the slopes of the PSD of the high and low performers.\n‚Ä¢ Use Hurst exponents of DFA to predict performance. Let P denote the number of participants and \\(\\textbf{Z}_{p}\\) denote the vector of length N containing the values of the discrete Fourier spectrum for participant p. We form the \\(N \\times P\\) matrix A of complex numbers defined according to In other words, the pth column of A corresponds to the discrete Fourier spectrum of the mouse tracking data for participant p. In what follows, we assume that \\(P < N\\) since the number of participants in each study is smaller than the number of discrete Fourier frequencies. The singular value decomposition (SVD) of the matrix A (Demmel, 1997; Trefethen & Bau III, 1997; Ramsay & Silverman, 2005) is Here, the superscript \\(*\\) denotes the complex conjugate transpose of the matrix. The columns of the \\(N \\times N\\) matrix U form an orthonormal basis for \\(\\mathbb {C}^{N}\\), the space of all complex vectors of length N. The columns of the \\(P \\times P\\) matrix V form an orthonormal basis for \\(\\mathbb {C}^{P}\\), the space of all complex vectors of length P. The \\(N \\times P\\) matrix \\(\\Sigma \\) has non-negative entries along its diagonal called the singular values, which we denote by \\(\\sigma _{p}\\) for \\(p = 1, \\cdots , P\\). The non-diagonal entries of \\(\\Sigma \\) are zero identically. In fact, computing the SVD of the matrix A is the same as performing principal component analysis (PCA). We focus on the linear algebra interpretation of the SVD to study the discrete Fourier spectra of mouse tracking data. In particular we use concepts such as projections onto subspaces. By doing so we develop model-free methods that make use of any underlying algebraic structures in these data. All matrices possess a singular value decomposition and the singular values are unique. The singular values are ordered by size, Let \\(\\textbf{u}_{n}\\) denote the nth column of U and \\(\\textbf{v}_{p}\\) denote the pth column of V. We can rewrite the SVD of A as By writing A as this sum, we see that the singular values give a relative rank of the importance of the corresponding columns of U and V in the data ‚Äì the first term gives the largest contribution, the second term gives the next largest, and so on. Additionally, we can consider approximations by truncating the sum above after some specified amount of terms. This approximation corresponds to the projection onto the subspace spanned by the vectors included in it. Suppose we only use the first k singular values. Let \\(\\tilde{U}\\) denote the \\(N \\times k\\) matrix formed by taking the first k columns of U and removing the rest. The columns of \\(\\tilde{U}\\) form an orthogonal basis for a subspace of A, which we denote by \\(\\tilde{\\mathbb {U}}\\). Now consider an individual participant‚Äôs discrete Fourier spectrum, \\(\\textbf{Z}_p\\). The projection of \\(\\textbf{Z}_p\\) onto \\(\\tilde{\\mathbb {U}}\\) is given by \\(\\tilde{U} \\tilde{U}^{*} \\textbf{Z}_p\\). The length of this resulting vector is \\(\\Vert \\tilde{U} \\tilde{U}^{*} \\textbf{Z}_p \\Vert \\) with \\(\\Vert \\cdot \\Vert \\) denoting the Euclidean norm. When we compute the value \\(0 \\le \\eta \\le 1\\) gives the fractional amount of \\(\\textbf{Z}_p\\) lying in the subspace \\(\\tilde{\\mathbb {U}}\\). When \\(\\eta = 1\\), \\(\\textbf{Z}_p\\) lies entirely in \\(\\tilde{\\mathbb {U}}\\). When \\(\\eta = 0\\), none of \\(\\textbf{Z}_p\\) lies in \\(\\tilde{\\mathbb {U}}\\). We explain below how we use \\(\\eta \\) to study performance. To analyze performance we first operationalized performance as accuracy in the game ‚Äì the higher the percentage of moles clicked, the higher the accuracy and the better the performance. To investigate performance operationalized as accuracy, we first partitioned our data into ‚Äúaccurate‚Äù and ‚Äúinaccurate‚Äù groups, where ‚Äúaccurate‚Äù participants scored above 50.5 percent, and ‚Äúinaccurate‚Äù participants scored below 12 percent. These numbers were chosen to keep the group sizes about the same across the two samples. For sample 1 this resulted in 44 in the high accuracy group and 32 in the low accuracy group. For sample 2 high accuracy had 33 and low accuracy had 36. To address the worry that demographic differences in these splits accounts for our results, we regressed the demographic variables both on performance and on our predictor of performance, \\(\\eta \\). There was no meaningful relationship between any of the demographic variables and either performance or \\(\\eta \\). We collect the discrete Fourier spectra of accurate players from Sample 1 and form the matrix A with them. Upon computing the SVD of A, we determine how many singular values are important in explaining the data. The singular values \\(\\sigma _{p}\\) for \\(p = 1, \\cdots , P\\) are proportional to the square root of the variance accounted for by the corresponding column of U. Thus, the cumulative sum of squares of the singular values is the cumulative sum of variance explained. This cumulative sum is shown in Fig. 3 and we determine from these results that \\(k = 9\\) explains 50 percent of the variance. We call the resulting subspace \\(\\tilde{\\mathbb {U}}\\) by considering the first 9 columns of U the accuracy subspace. By computing \\(\\eta \\), we determine the fractional amount a given discrete Fourier spectrum lies in the accuracy subspace. Consequently, \\(\\eta \\) is a measure of fitness to high performing players. The cumulative variance accounted for by each component in the accuracy space. Notice that the first 8 components account for about \\(50 \\%\\) of the variance We consider results of Sample 2 to test how well the accuracy subspace from Sample 1 generalized to new, out-of sample participants. We identified accurate and inaccurate players in Sample 2 using the same criteria that we used to determine accurate and inaccurate players for Sample 1. To test out-of-sample performance, we computed \\(\\eta \\) for accurate and inaccurate players in Sample 2. The results of this computation are shown in Fig. 4. These results show that the two groups, accurate and inaccurate, are almost completely separable. They are shown to be significantly different according to a Welch‚Äôs t-test (\\(p<0.0001\\)). These results demonstrate the existence of structural features in the discrete Fourier spectra of accurate players that is not shared by less accurate players. The accuracy subspace contains algebraic structures inherent in accurate players that are not shared by less accurate players. Therefore, testing the extent to which a player‚Äôs discrete Fourier spectrum aligns with the accuracy subspace provides a diagnostic method for performance. Moreover, these results suggest that these structural differences persist across different samples. Projection of accurate and inaccurate participants in sample 2 to the accurate space from sample 1. Blue dots correspond to accurate players; orange dots to inaccurate players. The accurate players fit the space of accurate players from the earlier sample better with higher \\(\\eta \\) (which corresponds to how well a participant fits to a space). The two groups are also significantly different (\\(p<0.0001\\)). This shows that accurate and inaccurate players are separable using SVD Next, we computed \\(\\eta \\) for all players in Sample 2. In doing so, we found that there was a significant relationship (\\(p<0.01\\)) between accuracy and the value of \\(\\eta \\) (see Fig. 5) with \\(R^2 = 0.61\\). Accuracy and fit both range from 0 to 1, and the unstandardized \\(\\beta \\) coefficient for fit regressed on accuracy was \\(\\beta \\) = 0.3 with standard error of .02, which means that as accuracy increases fit increases. These results show that the relationship does not just separate two groups of accurate and inaccurate players in the sample, but explains degrees of accuracy throughout the sample. Performance regressed on fit to accuracy space. The relationship between accuracy and fit to the accurate space of sample 1 for participants from sample 2. Accuracy ranges from 0 (no mole hits) to 1 (every mole was hit). We can see that accuracy is related to fit to the accuracy space. The unstandardized \\(\\beta \\) is 0.30 with standard error 0.02. \\(R^2 = 0.61\\) and \\(p<0.01\\) Representing our mouse traces using a single complex variable opens access and opportunity for novel methods of analysis. For example, we have been able to perform SVD/PCA directly on the discrete Fourier spectra of the full mouse tracking data. In doing so, we have been able to identify structural differences in the discrete Fourier spectra between accurate and less accurate players. We have found that these structural differences are statistically significant and persist in out-of-sample results. The most important component used for creating the accurate player space, plotted in log-log scale To investigate the accuracy subspace \\(\\tilde{\\mathbb {U}}\\) further, we consider the power spectrum of the columns of \\(\\tilde{U}\\) corresponding to the absolute value squared of each entry of a column of \\(\\tilde{U}\\). We then examine the shape of the power spectrum on a log-log scale. We have performed this analysis on the first 8 columns of \\(\\tilde{U}\\). Figure 6 shows the power spectrum for the first column of \\(\\tilde{U}\\) plotted in log-log scale. Over the first 8 columns of \\(\\tilde{U}\\), we observe a consistent linear structure to the power spectra. A linear trend for frequencies plotted in log-log can indicate a power law, which can in turn imply long-range correlations in a complex system. To investigate possible long-range correlations, we use DFA (Peng, Havlin, Stanley, & Goldberger, 1995). DFA is a measure of the relationship between variance within windows of a time series and the size of those windows which, in turn, provides a measure of the amount of long-range correlation in time series (Stergiou & Decker, 2011). DFA has been applied in several areas of cognitive science (and extensively in other fields) as a tool to measure complexity in a time series. For example, Dotov et al use DFA to identify a change in the complexity of motor movements corresponding to a change from smoothly using an interface to cases of ‚Äúbreakdown‚Äù, where the user interface is perturbed so that it no longer behaves as the user expects it to Dotov et al., (2010). To compute DFA we start with our complex time series: We center the data by subtracting the mean and then compute the cumulative sum, We then partition the time series \\(C_{n}\\) into windows of size \\(4 \\le s \\le N\\). Using the smallest possible value, \\(s = 2\\), is often not advised (Bryce & Sprague, 2012), so we set \\(s = 4\\) as the minimum window size. For a fixed window of width s starting at n, we compute a least-squares regression model satisfying, and then calculate the residuals, Here \\(P_{d}(z)\\) denotes the fitted polynomial of degree d (Shao, Gu, Jiang, Zhou, & Sornette, 2012). Linear fits are usually used so that in most applications (including ours), \\(d=1\\). We compute the root mean square of the residual for each window size s, to obtain the fluctuation value (Shao et al., 2012), Note that we are squaring the absolute values of the residuals, \\(| r_{n} |\\) rather than the residuals themselves, since we are working with complex-valued time series. We then fit a line to the relationship between the log-scaled \\(F_s\\) and the log-scaled s (Shao et al., 2012). The slope of this line is \\(\\alpha \\), which is taken to approximate the Hurst parameter H. The Hurst parameter is a measure of fractal dimension in a time series. If \\(H < 0.5\\) the process is considered to be anti-correlated in time such that high values tend to be followed by low values and vice versa. If \\(H = 0.5\\) the process is not correlated in time, and if \\(1> H > 0.5\\) then the process is said to be positively correlated in time (Ihlen, 2012; Nolds module ‚Äî 0.5.2 Documentation, n.d.). However, if \\(\\alpha > 1\\) the process is non-stationary and can be modeled as fractional Brownian motion where the Hurst parameter of the systems is approximated by \\(H = \\alpha - 1\\) instead of \\(H = \\alpha \\) (Hardstone et al., 2012; Nolds module ‚Äî 0.5.2 Documentation, n.d.). That is, for a non-stationary process, when \\(1> \\alpha > 1.5\\) the process is anti-correlated in time, if \\(\\alpha = 1.5\\) the process is not correlated in time, and if \\(2> \\alpha > 1\\) then the process is positively correlated in time. DFA is a frequently used to analyze complex systems to determine the amount of long-range correlation in the data, which some contend is indicative of the degree of fractal structure in the system. The Hurst parameters provided by DFA were significantly predictive of accuracy (\\(p<.01\\)), as shown in Fig. 7. However, it was a much less powerful model with \\(R^2 =.08\\) (vs. \\(R^2 = 0.61\\) for SVD). Virtually all participants‚Äô Hurst Parameters indicated some degree of nonstationairity in their fractal structure, as all participants were \\(\\alpha > 1\\). The negative relationship \\(\\beta \\) = \\(-.75\\) implies that lower performing participants actually have more long range positive correlation in time than high performing participants, and high performers‚Äô mouse movements are somewhat anti-correlated in time. This might seem strange at first, given that previous literature suggests that long-range correlations are positively related to performance. However, given that the moles‚Äô next position is pseudorandom, it could also mean that participants whose Hurst parameters are below 1.5 are actually better approximating the target. In a similar fashion, expert Tetris players have been shown to rely heavily on the rotate button, allowing them to offload some of their cognition (Kirsh & Maglio, 1994). High-performing participants in this task appear to develop a pattern of interfacing with their environment that is substantially different from how the low-performing participants are interfacing with their environment. By exhibiting a lower fractal dimensionality in their time series, these high-performing participants are using up less of the ‚Äúreal estate‚Äù in the two-dimensional playing field and generating more efficient mouse traces that can be characterized in fewer fractal dimensions. The parameter \\(\\alpha \\) regressed on performance. The negative slope \\(\\beta \\) = \\(-.75\\) implies that the fractal dimension of the time series is decreasing as performance goes up. This in turn suggests that the time series are more likely to be anti-correlated as performance improves\n\nWe designed a simple Whac-A-Mole like video game which participants played for a few minutes, during which mouse position data were captured. We did not know what might predict performance in this data, but were able to systematically explore it and find quantitative structures that were highly predictive of performance. Our results show that accurate players play differently than inaccurate players and that this difference is detectable in the mouse tracking data. Overall our efforts provide a good case study of how to explore and analyze unconstrained mouse tracking data. Even if a performance measure like accuracy were not available for a computer mouse task, these results show that those metrics could nicely be approximated by the mouse movements alone using principal components from known experts. The SVD was substantially more predictive of accuracy than DFA (\\(R^2 = 0.61\\) vs. \\(R^2 =.08\\)), suggesting it is more powerful as a means of predicting accuracy and other features of behavior. However, the DFA analysis is important because it has an interpretation in terms of cognitive science. DFA indicates the presence of multi-scale structure. In fact, the degree to which SVD outperforms DFA suggests that there is more going on for accuracy than just multi-scale structure. Unconstrained mouse traces are difficult to analyze using standard technique such as reaction times (Table 1) because they lack well-defined beginnings and ends relative to individual mouse movements. This is representative of many real tasks outside of scripted psychology experiments. For example, in our data, mouse clicks can‚Äôt be interpreted as reactions to particular stimuli because we don‚Äôt know which stimulus participants are attending to. In some cases they may be attending to the currently visible mole when clicking, which is a straightforward reaction time. However, in other cases they might be predicting where a mole will appear next, adopting a strategy like ‚Äúclick in one place repeatedly to guarantee some hits‚Äù, or reacting to (and missing) a mole that is replaced by a new mole before clicking. In these cases the time interval between a mole‚Äôs initial appearance and the next mouse click is something other than a reaction time. These methods and results provide two contributions to mouse tracking research and in particular to the analysis of unconstrained mouse traces. First, to our knowledge the only methods that have been used to analyze unconstrained mouse tracking data are machine learning techniques (Kolakowska, 2013; Liu, Fernando, & Rajapakse, 2018), which do not, however, provide interpretable results or generalizable insight into the mouse movements of the participants. As summarized in Table 1, other techniques could in principle be applied to this data, but this has not yet been done, to our knowledge. We have provided an initial guide to analyzing uninterrupted streams of mouse movements, in contexts where there are no clearly demarcated individual movements with determinate beginnings or endings. We have shown how to study unconstrained mouse tracking data in a way that is systematic, and can produce interpretable results. To be clear, the method we describe is not intended as a replacement for existing mouse tracking methods, which work well for single-movement data. Existing approaches to analyzing segmented mouse traces are clear, easy to interpret, and have an established track record. Second, mouse tracking data naturally lies on a two-dimensional plane, but most time series analyses require a one-dimensional time series. The problem is usually solved by taking a time series of one dimension, such as the x dimension (Schulte-Mecklenbeck, Kuehberger, & Johnson, 2019). This solution works for binary forced choice tasks, where participants are making single movements and most of the information exists along one axis. However, even in these situations the one-dimensional analysis ends up neglecting potentially meaningful information in the other dimension, or in the combination of the dimensions. To address this we instead embed the data in the complex plane, which allows us to take two-dimensional coordinates and express them using a single complex variable. We are then able to convert our time series directly into the frequency domain. To our knowledge converting mouse coordinates to the complex plane has not been done before. Outside of advancing methods in mouse tracking, we believe that our results help to characterize how high performers use their mouse. Our results indicate that behaviors associated with accurate game play produce long-range anti-correlations in the mouse movements. This result contrasts with some existing literature, which has found examples where long-range correlations are indicative of health or performance in human systems (Voytek et al., 2015; Hausdorff, 2007; Diniz et al., 2011). However, we could interpret accurate play in our task as attempting to synchronize spatially with a pseudo-random target, which does not have these long-range correlations. This is similar to the way participants attempting to synchronize with a chaotic metronome approximate its global multi-scale structure (Stephen et al., 2008). In the current experiment, rather than produce the long-range correlations they normally would in a repetitive task like walking or saying the same word repeatedly (Kello, Anderson, Holden, & Van Orden, 2008b), participants adapt themselves to the structure of the task. Additional hypothesis testing is needed to confirm this. We believe this analysis could serve as a foundation for future research. In most natural settings user data cannot be precisely segmented into individual movements, and so traditional approaches to studying mouse movements cannot be applied. But there is often a desire to be able to gather data about such phenomena as affective states or engagement. These phenomena typically unfold at temporal scales much longer than individual mouse movements. For example, consider an immersive video game such as a first person shooter in a three-dimensional environment, which involves extended periods of play during which players provide continuous input to the game. Developers often want to know if changes they make to the game improve the experience of players, which is difficult to obtain via direct reporting. Methods like these could be used to study how players‚Äô dynamics change in response to changes in the game, which could be indicative of player performance, engagement, team compatibility, ease of use, sentiment, etc. Any sufficiently large subset of mouse tracking data with some known characteristic could be used to define a space analogous to the accuracy space we used here. For example, data from players who report strong vs. weak team compatibility could be used to define a team compatibility space, which could then be used to identify new players for a team. An example where this type of approach is applied to measuring task engagement is Meyer (2022). Future work extending this approach could also involve the development of an AI simulation that plays the Whac-A-Mole game. Different parameters and strategies could be programmed into the simulation and our approach could be tested for its ability to detect the presence or absence of those particular parameter settings and strategies. This research could also provide insight into other components of cognition, such as response conflict, uncertainty, the time course of perception vs. cognition in tasks, etc., which have traditionally been a focus of mouse tracking research in cognitive science and psychology. To some extent, there is a paradigm difference between these approaches and ours. From our ‚Äúembodied mind‚Äù and dynamical systems perspective (Dotov & Chemero, 2014; Kelso, 1995; Schmidt, Carello, & Turvey, 1990), we are revealing how spatiotemporal structures in behavior can be related to performance, based on complex profiles of long-term and short-term correlations. We are not looking for specific components of cognition in the data or ‚Äúcomponent-dominant dynamics‚Äù (Van Orden et al., 2003). Rather, we are looking at dynamic interactive patterns in the movement space, and making minimal assumptions about cognitive modules that may or may not be involved (Spivey, 2023). We are not ideologically opposed to componential studies, and could see future work integrating insights from both approaches. Our SVD approach allows an arbitrary data stream to be studied for its general characteristics, but this could then be used alongside more traditional studies, in the spirit of pluralism in cognitive science (Dale, Dietrich, & Chemero, 2009; Yoshimi, 2023). Broadly speaking, the approach is more data driven than task or theory driven. The method is meant to identify complex patterns in a data set, and then to use these structures for analysis and prediction. The details will vary from task to task, and the results might not correspond directly to any existing theoretical constructs. But even if the approach is data driven, the methods are generalizable. The analysis pipeline we developed can be applied to any unconstrained behavioral task, and used to identify and interpret behaviors even when they are difficult to put into words. Consider soccer, basketball, or any team sport. Many features of these behaviors are the result of extremely complex interactions that have no pre-existing name or designation. Yet there is consensus among good players about best practices. As a result, a soccer teacher might just say ‚Äúkick like this.‚Äù These methods can be used to identify such behaviors in time series data and to associate them with a space describing to what degree a person performs the behavior. Especially in online settings where such behaviors are common and the data relatively easy to gather, we expect these methods to be valuable."
    },
    {
        "link": "https://allion.com/ss_syst_gaming_mouse_latency_testing",
        "document": "The e-sports industry has rapidly developed in recent years, and ‚Äúmouse latency‚Äù has become a critical factor in determining the gaming experience and competition results. From a technical perspective, traditional mice have a latency of about 20 milliseconds, entry-level gaming mice typically have a latency of 5 milliseconds, while high-end gaming mice can reduce latency to just 2 milliseconds. These differences may seem small, but in highly competitive games, especially in scenarios where reaction time and speed are critical, every millisecond of optimization can provide a competitive advantage.\n\nThe popularity of e-sports competitions has led players to desire lower mouse latency to improve their performance. They aim to conduct precise tests to understand the specific impact of different operating systems and settings on latency and seek the optimal configuration to gain a competitive edge. This demand has driven the market to urgently seek testing solutions that can provide detailed performance analysis and optimization recommendations.\n\nHigh-end gaming mice are often equipped with advanced features such as Dots Per Inch (DPI) switching, polling rate adjustments, lift-off distance (LOD) settings, debounce time settings, customizable buttons, and RGB lighting effects. These features provide a richer gaming experience for players but also increase the complexity of mouse performance optimization. Mouse manufacturers require a comprehensive and effective testing solution to thoroughly analyze the actual impact of each function setting on latency.\n\nThe case involves a well-known gaming mouse brand facing increased market competition and growing demands from gamers for higher performance. The customer is under dual pressure and realizes that only by reducing the latency of their mouse products can they maintain their market leadership. However, the variables and scope of influence involved in the product design are complex, making it difficult to comprehensively assess the factors affecting mouse latency. Therefore, they reached out to Allion for assistance.\n‚Ä¢ Changeperformance requirements for various user scenarios into quantifiable performance indicators.\n‚Ä¢ Analyze the impact of different DPI and polling rate settings on latency.\n‚Ä¢ Measure mouse performance across various hardware and software environments.\n‚Ä¢ Lack of professional testing equipment and methods to accurately measure millisecond-level latency differences.\n\nTo address the challenges in optimizing mouse performance, Allion provided a comprehensive and efficient mouse latency testing and optimization solution, successfully resolving the issues they encountered:\n\nMeasurement tools with end-to-end capability, combined with high-speed photography at up to 1000 fps, and Allion‚Äôs custom-developed automation fixtures, achieving millisecond-level precision in measuring mouse click latency.\n\nWe have established an automated testing platform that provides multiple measurements and precise verification of mouse movement latency, as well as data collection and analysis to ensure the accuracy of the test results.\n\nWe simulate various user scenarios under different hardware configurations, game environments, and mouse settings to evaluate the mouse‚Äôs performance.\n\nWe conducted in-depth analysis of a large volume of test data and established correlation models between latency and various factors, providing the customer with a data-driven foundation for optimization.\n\nBased on the measurement results, we provided customized adjustment recommendations for mouse latency under different DPI and polling rate settings. Specifically, we identified settings that could cause abnormal increases in latency in different hardware environments.\n\nWith years of industry experience, Allion‚Äôs gaming mouse testing and solutions provide three core advantages for customers:\n‚Ä¢ Efficient Testing Process: Our automated testing platform allows for fast mouse performance testing, integrating detailed data analysis, significantly reducing the time required for traditional testing.\n‚Ä¢ Real-Time Data Feedback: Using high-precision testing equipment, we can immediately collect and analyze performance data, enabling mouse manufacturers to quickly identify performance bottlenecks and make immediate adjustments.\n‚Ä¢ Shortened Development Cycle: By accelerating the testing and validation process, we help manufacturers quickly address issues, shortening product development and validation cycles, speeding up time to market, and enhancing market responsiveness.\n‚Ä¢ Rapid Iterative Optimization: Based on testing data, customers can quickly iterate on products and continuously improve performance.\n‚Ä¢ Automated Testing Equipment to Optimize Testing Process: We use advanced automated equipment for testing, automatically recording and analyzing data, greatly simplifying the tedious process of manual testing.\n‚Ä¢ Easy-to-Understand Reports: Test results are presented in clear, easy-to-understand reports, offering detailed performance analysis and optimization recommendations, allowing customers to easily understand the results and quickly adjust their products.\n‚Ä¢ One-Stop Service: We provide a complete one-stop testing and analysis service, from test design and data collection to analysis reports and final product modification suggestions, improving the quality of customer products.\n‚Ä¢ High-Quality and Consistent Data: Through our automated platform and self-developed software, we provide high-precision test data and in-depth performance evaluation, ensuring the accuracy and reliability of the data and helping customers understand their products‚Äô actual performance in various environments.\n‚Ä¢ Comprehensive Performance Validation: Testing covers both the basic performance and long-term stability of the mouse, ensuring the product‚Äôs durability and stability under high-intensity use, avoiding potential performance issues.\n‚Ä¢ Enhanced User Experience: Through precise performance optimization, we help customers improve the overall quality of their products, enhancing consumer experience and satisfaction, and boosting the competitiveness of the product in the market.\n\nOur professional testing and analysis services effectively address customer issues related to gaming mouse latency. By providing fast, efficient, simple, and high-quality solutions, we help customers improve product performance, shorten development cycles, streamline the testing process, and ultimately increase market competitiveness and customer satisfaction. Our services not only help customers achieve business goals but also provide strong support in the fierce market competition.\n\nIf you are looking for a reliable accessory product testing and problem-solving consultancy, please contact Allion."
    },
    {
        "link": "https://researchgate.net/publication/356589184_The_Analysis_of_Mouse_Tracking_Data_in_a_Game_for_Detection_of_Dyslexia_Risk_A_Pilot_Study",
        "document": "The Analysis of Mouse Tracking Data in a Game for Detection of Dyslexia is the disorder aÓÄùecting reading and learning language. Children with dyslexia cannot spell words or acquire reading. Screening is a necessary process to distinguish dyslexia children to treat and help them appropriately. If detection can be done since they are in pre-readers age, it can lessen the undesirable outcomes for children such as lower educational attainment, negative feelings toward learning, and loss of self-conÓÄõdence and self-respect. Many sign is a signiÓÄõcant part to achieve the goal. One of the challenges in creating a game for children is designing the game that maintains children‚Äôs attention until they ÓÄõnish the game. In addition, the level of diÓÄúculties must be suitable for the participants‚Äô skill. Thus, this paper presents a pilot study that used a picture rotation game to study children behavior in attempt to distinguish them. The game was designed mainly to study behavior of children with dyslexia but not the game design principles. This study found that game playing behavior of the two groups of children was diÓÄùerent. The diÓÄúculty levels of the game were found to have inÓÄûuence on their gameplay. The ÓÄõndings are used as the guidelines to improve the design of the game to better assess the risk of dyslexia children. wong. 2021. The Analysis of Mouse Tracking Data in a Game for De- Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proÓÄõt or commercial advantage and that copies bear this notice and the full citation on the ÓÄõrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciÓÄõc permission and/or a Dyslexia is a learning disorder associated with diÓÄúculty in reading, and writing. Children with dyslexia have problems with language acquisition. Early detection of dyslexia risk leads to appropriate treatment and, thus, prevents developmental delays. Detection of risks done earlier could minimize the undesirable outcomes for programs or games with young children for screening purpose [ of children while playing the games instead of feeling that they are being tested. Recently, several serious games were developed based on dyslexia features on short-term memory, visual perception, or ][2][3][4][5]. Among them, MusVis and GC are The challenges in designing computer games for children, espe- cially for pre-readers include maintaining their attentions through- out the game and choosing suitable level of diÓÄúculties to match indicators. As a result, require players to spend time with a number of mini games. That could inÓÄûuence loss of excitement and atten- tion of children and, eventually, stop them fr om playing the game ][2][4]. The games for diagnosis of dyslexia risk should be made to promote attention as well as providing suitable diÓÄúculty levels. This paper presents the behavioral analysis of a simple game, which dyslexia children usually have problem with. The analysis of mouse tracking data recorded while the risk and non-risk children playing the game gives insights to attention and diÓÄúculty issues. The indicators were chosen based on the behavior of children with The paper is organized as follows. Section 2 describes dyslexia and reviews games developed to detect the risk of having dyslexia. the paper concludes with summary, discussion, and future study . Dyslexia is a reading disorder which is a type of Learning Disabili- ties. Three possible causes are 1) genetic alteration 2) premature birth and 3) brain infection or injured or epilepsy [ Children with Dyslexia are discovered that their left side of in phonological processing skill which is the basic part of spelling and 2) left occipito, the temporal region which relates to ability\n\nin whole word recognition without identifying speech sounds and work hard to support other two parts that work less than normal With the increasing use of computers, serious games have re- ceived much attention in dyslexia risk detection because of its sults are not yet proven to be adequate for detection of the risk, it provides valuable insights to initial or early diagnosis [6]. 2.1 Games for prediction of dyslexia risk in the story-based game about a dog robot that ÓÄõghts criminal cats. The game was designed to motivate preschoolers for a longer atten- tion span to achieve a more accurate measurement. Results from performance measurements were used to predict the risk. Another work published in 2017 by Gaggi and coworkers [ six serious games. Performance outcomes of each game were used to identify children at risk. Three games were able to distinguish the children. Others were not. They were either too diÓÄúcult, too game called MusVis in German, Spanish, and English languages for pre-readers. Their results are 74% and 69% accuracy for German and Spanish respectively. The predictive model using machine learn- ing with standard classiÓÄõers such as Random Forest, Extra Trees, Gradient Boosting, and the Dummy ClassiÓÄõer was employed. Two indicators which were musical and visual were used as language independent indicators. They found that the musical indicator was not suitable for screening as it is a cultural dependent variable. The other issue involved game design is that it allowed children to randomly choose answers without listening to the sound. This could result in inaccurate prediction results. Rauschenberger and to screen pre-readers for dyslexia risk by measuring motor skills while they were using the language independent game contents. The main concern of the game was to avoid players struggling during game and encourage players to succeed even in the ÓÄõrst time of playing. That resulted in a range of puzzle pictures and numbers to suit players‚Äô skills or age. However , the children found diÓÄúculty in choosing the suitable levels for themselves. As a result, the parents had to choose. The game-based approaches described above used collections of performance data which were analyzed using basic statistics on Such analysis does not facilitate an inference about the population. Research on inferential analytics can assist researchers in drawing expert system for training long jump athletes. It used the method agement theory. The expert was able to analyze and coach based Boosting Machines, and Neural Networks to forecast the crime type in a speciÓÄõc location. Factors such as crime characteristics, demographic, economic and ethnic information as well as patterns of previous crimes were considered. Chuang and Fan [ a YOLOv2-based deep learning method with joint iris and sclera for identity identiÓÄõcation. The precision up to 99% was reached. Farid replaces contradictory example‚Äôs class value to improve quality of It can be seen that a number of issues should be addressed when First, the game should be designed to handle attention and diÓÄúculty issues, especially the game for pre-readers. So that more complete and meaningful data can be acquired for further analysis [ Second, detection of dyslexia risk can be seen as a classiÓÄõcation problem. Therefore, they can beneÓÄõt from existing classiÓÄõcation algorithms. Inference analytics should be done to allow for gener- alization of the sample data. This paper focuses on the study of the design of the game in order to ÓÄõnd the ground for the next stage of This paper presents a study to observe 12 Thai children playing the game called picture rotation. Half of them is dyslexic children. Data were collected for the analysis of dependent measures suitable to be used in detection of dyslexia risk. There were 12 participants, 6 children with dyslexia risk and the rest of them were non-dyslexia. They studied in Prathom (primary level) 2 and 3. The participant were 9 boys (6 dyslexia, 3 non-dyslexia) in the pilot study aimed to investigate participants‚Äô behavior for the design of a game to detect dyslexia risk. The results will be used to improve the game design for a larger group of participants. The children with dyslexia risk were studying at W at Suan Dok School in Chiang Mai. They were primarily screened by the spe- with dyslexia risk. The non-dyslexia participants were studying at the Demonstration School of Lampang Rajabhat University in Lampang. The average age of children with dyslexia risk was 9.50 with a standard deviation at 0.50, age between 9-10 years old. The non-dyslexia children‚Äôs age were between 8-9 years old. The age average was 8.16, with a standard deviation of 0.37. All participants problems which could aÓÄùect future research. The test revealed minor usability problems. Users could still ÓÄõnish the game after The participants played the game one by one and played at least one game round. Each spent around 5 minutes. The participants\n\nThe Analysis of Mouse Tracking Data in a Game for Detection of Dyslexia Risk: A Pilot Study ICICM 2021, August 12‚Äì14, 2021, Tokyo , Japan Time to ÓÄõrst click Time until the ÓÄõrst mouse click. Number of click The total number of clicks in a round. Accuracy The number of hits /The number of clicks. Number of ÓÄõxations The total number of ÓÄõxations in a round. Fixations duration The average of ÓÄõxations duration in a round. Second try correct The number of correct answers on the second try. Third try correct The number of correct answers on the third try. were observed and guided by one of the researchers the whole time. When one was playing, the rest of participants had snacks. Therefore, they didn‚Äôt experience stress during waiting time. After ÓÄõnishing the game, a few comments were made by some partici- pants such as ‚Äúthe game were easy‚Äù and ‚Äúwould like to play again‚Äù. Overall, most participants thought the game was easy and they ] was used to record mouse tracking data of children during the test. The mouse-tracking param- eters are divided into four categories as follow: 1) Mouse ÓÄõxation, 2) Mouse saccade, 3) Mouse clicks, and 4) Mouse path. Two of the parameters were found to be signiÓÄõcant for this study: mouse ÓÄõxa- tions and mouse click. The right click variable was removed from this study, since the game was not designed to use with right click. The data collected were analyzed to determine the signiÓÄõcance of the variables between the participants with signiÓÄõcant at p < 0.05. The pilot study to observe behavior of 12 Thai children, half of them is risk of dyslexic children, was administered through a game called picture rotation. The purpose was to focus on the analysis of the behavior and the participants‚Äô thinking process to ÓÄõnd out which variables should be used to assess the risk of dyslexia. A game pro- totype was created and tested with a sample group, including both normal children and children with risk of dyslexia. The times spent to perform tasks in the game of both groups showed signiÓÄõcant The game was designed based on the directional separation indi- cator which dyslexia children usually have problem [ game was named as picture rotation. It comes from an exercise children are familiar with. In this picture rotation game, children could choose freely which item to place in any of the spaces pro- vided. Children were required to click on the correct images and drop them in the correct positions. Data on choices selected, cor- rect order of choices, duration of actions, number of decisions and The game contains three minigames: Practice, Easy, and Hard. The practice game was designed to be used before the actual test because they need time to learn and understand the game. Each minigame corresponds to a distinct level of diÓÄúculty: easy, and hard. In each level, participants were presented with an object to be rotated as shown in Figure 1. As children with dyslexia tends to have problems with separation of symmetrical nature, this game was designed to indicate the risk via this task. The game was designed to be easy to play for every child. Thus, a few options were provided. At the beginning of the game, the introduction screen was displayed to describe the instructions via text and sounds. After that, the ÓÄõrst game was displayed to the children. Once the children were success in placing correct images, they were shown with the next game. In each minigame, the chil- dren had to click on one of the remaining choices and drag it to the right position. At the beginning of a minigame, children were shown with one original object in the right place and the other ob- jects were at the bottom waiting to be dragged and dropped to the correct spots located on the right-hand side of the original object. The objects appeared in each minigame were the same but were rotated in diÓÄùerent directions as shown in Figure 1. The objects are accepted as the correct answer if the object is placed on 80% of the correct region. The children kept playing until they complete all three minigames. Then, the ÓÄõnish round screen was appeared. Children could choose to play again or end the game. The ÓÄûow diagram of the game is shown in Figure 2 The objects as shown in Figure 1 were designed to be big enough for children to distinguish the diÓÄùerences in direction and easily select. The objects familiar to all children, such as fruits and animals, were chosen. The visual elements were designed to look friendly. Colors are based on real-life objects. The game is web-based with a familiar Mouse-tracking data were recorded via an external software while the children were playing the game. Based on the data collected, ten variables were found, as in Table 1. This study aims to examine the\n\nvariables that can describe the behavior in game playing of children and identify the variables that can be used to detect children with Overall, the participants could play the game without guidance. The analysis results demonstrated the diÓÄùerences between two groups of children (risk and non-risk). SigniÓÄõcant diÓÄùerences between groups were identiÓÄõed using, F-test two sample for variances and using the standard value of p < 0.05 as threshold for signiÓÄõcant results. Table 2 and T able 3 show the results for all variables. 5.1.1 Game flow. Most participants understood the ÓÄûow of the game and were able to play in the correct sequences while two participants were not. One of them was in the risk group. There were two games he could not play in the correct sequences. The participant from the non-risk group could not play in sequence for the practice game only. He could play the other games correctly . The participant from the risk group, although missed the chance to play the practice game correctly, could still play the easy game. However , when he played the harder game, he failed to apply what he learned from the practice and easy games to the harder game. Therefore, unable to play the harder game correctly . 5.1.2 Game diÓÄõiculty. For the two participants who did not play the game in the correct sequence, one of them did in the practice game. The other did in the practice game and the hard game. As expected, that later one was from the risk group. The rest of the non-risk group could play the hard game whereas the other three participants from the risk group could not. A harder game requires children to concentrate more in order to understand and come up with the correct answer. More than half of the risk gr oup‚Äôs partici- pants could not play the hard game correctly. The children from the non-risk group had no problem with the hard game. Being unable to concentrate was likely to be a result of having dyslexia conditions. Based on this, a harder game can, thus, be used to distinguish the children. However , a game that is too hard for participants may discourage them from putting eÓÄùort into playing. 5.1.3 Time to first click. Table 2 shows the results of the easy game. Table 3 shows the results for the hard game . The risk group spent longer time until the ÓÄõrst click than the non-risk group. It was 0.039). This could be because of the diÓÄùerence in ability to process information. For the hard game, the risk group did have signiÓÄõcantly shorter time than the non-risk risk group, p < 0.0001). The cause could be inability to concentrate 5.1.4 Fixation duration. The risk group did have signiÓÄõcant shorter 0.017). This is contrary to a common belief that non-risk children performs faster than at\n\nThe Analysis of Mouse Tracking Data in a Game for Detection of Dyslexia Risk: A Pilot Study ICICM 2021, August 12‚Äì14, 2021, Tokyo , Japan Table 2: The results of dependent measures extracted via mouse tracking in easy game Table 3: The results of dependent measures extracted via mouse tracking in hard game risk children. The cause might be that the non-risk group tried to analyze before playing. For the hard game, the risk group‚Äôs time is merely less than the non-risk group. This value is in the same direction with . Inability to concentrate or attend to the problem longer results in a shorter ÓÄõxation time. 5.1.5 Mistakes. The risk group made more mistake than the non- risk group, shown in Figure 3. Although, the values of Hits, Misses, Second try correct Third tr y correct group are less than non-risk group but they are not statistically signiÓÄõcant. If number of participants is increased, the results could In this paper, the results of easy and hard games are pr esented. Table 4 shows the behavioral sequences (paths) of both games. 5.2.1 Easy game. The task path for the easy game is modeled as three pairs of image and position. The three pairs when connected form a task path. For example, i2-p1-i1-p2-i3-p3 (read as image #2 to position p1, image #1 to position p2 and image #3 to position p3). In this game, two participants from of the risk group and three participants from of the non-risk group made mistakes. The behavioral paths of the two participants from the risk group who made mistakes are longer than the paths of participants from the non-risk group who also made mistakes. Both paths of the risk group contain 5 pairs, while the three paths of the non-risk group contain 4 pairs. All paths are longer than the game‚Äôs task path. The analysis of the paths shows that p1 was the position children made the most mistakes. When looking at p2 and p3, the non-risk group was able to play p2 and p3. In contrast, the risk group could not play in p2 while p3 is forced to be right. 5.2.2 Hard game. For the hard game, more participants fr om the risk group made mistakes. There were four participants of the risk group and three participants of the non-risk group. The risk group could not play in p1, p2, and p3. Surprisingly, ev ery one of them made mistakes at p1 for 3 times. The average length of the behavioral paths of the non-risk group is less than the risk group for both easy and hard game. The behavioral paths are demonstrated to be useful in visualizing eÓÄùorts spent by both groups. Similarity and diÓÄùerence can be straightforwardly compared and analyzed. Table 4 presents the analysis of children‚Äôs behavior while playing easy number and the resulted behavioral paths are shown. Nearly every child in the risk group made more than eight steps (or 4 pairs) in the hard game. The results demonstrated inability to play the game. Thus, the paths can be used to distinguish the children with risk.\n\nThe Analysis of Mouse Tracking Data in a Game for Detection of Dyslexia Risk: A Pilot Study ICICM 2021, August 12‚Äì14, 2021, Tokyo , Japan Figure 4: The proposed design of the Dynamic DiÓÄúculty Ad- Accuracy is the ratio of hits and clicks to identify how well children play according to the correct ÓÄûow and obtain the correct answer. The variables in Accuracy gr oup are 1) Hits, This game provided a limited number of choices to participants. That means every choice would be a correct answer. Adding mor e choices allows an incorrect answer to be presented. Thus, providing participants an obstacle and adding a layer to diÓÄúculty. Similarly , the number of subtasks in a game could be increased. These varia- Figure 4 proposes the use of the dynamic diÓÄúculty adjustment variables obtained from the analysis of mouse tracking data. The algorithm computes for the appropriate level of diÓÄúculty with the details of diÓÄúculty attributes. The user interface is then updated This paper presented a game called picture rotation which was designed to study children behavior in order to detect the risk. The pilot study was administrated with 12 Thai children. The study focused on examining their behavior, ÓÄõnd similarity and diÓÄùerences between two groups. The behavioral paths were found to be use- ful in separating the risk and non-risk groups. The results reveal interesting insights that can be used toward the improvement of module to provide a more accurate detection of dyslexia risk. Recommendations were made to improve the game. First, the possibility of children getting the correct answer by chance should be limited. The number of alternatives in each game should be increased. Second, more minigames or stages should be added. So, more data can be collected. Third, a module to dynamically adjust diÓÄúculty should be added to provide suitable gameplay experience and encourage them to play longer. detection of dyslexia in preschoolers, ‚Äù in Games for Health, 2013, pp. 257‚Äì266. independent detection of dyslexia with a web-based game, ‚Äù Proceedings of the 15th Web for All Conference: Internet of Accessible Things, W4A 2018, 2018, doi: ing a new puzzle app to target dyslexia screening in pre-readers, ‚Äù in ACM J. Stein, ‚ÄúDyslexia: the Role of Vision and Visual Attention, ‚Äù 2014, doi: M. J. Snowling, ‚ÄúFrom language to reading and dyslexia, ‚Äù Dyslexia, vol. 7, no. 1, for dyslexic children‚Äôs reading application, ‚Äù in Lecture Notes in Engineering and through a web-game using language-independent content and machine learning, ‚Äù Proceedings of the 17th International Web for All Conference, W4A 2020, 2020, Long Jump Athletes Using Action Recognition, ‚Äù Journal of Advances in Informa- with Inadequate Data for Crime Prediction, ‚Äù Journal of Advances in Information C. W. Chuang and C. P . Fan, ‚ÄúDeep-learning based joint iris and sclera recognition with yolo network for identity identiÓÄõcation, ‚Äù Journal of Advances in Information tion, Attribute Selection and ClassiÓÄõcation, ‚Äù Journal of Advances in Information [16] ‚ÄúWhy You Only Need to T est with 5 Users. ‚Äù https://www.nngroup.com/articles/ Gaze and Mouse Analyzer): Open-source software designed to analyze eye and"
    },
    {
        "link": "https://sciencedirect.com/science/article/abs/pii/S0747563218300700",
        "document": ""
    },
    {
        "link": "https://dl.acm.org/doi/10.1007/978-3-319-99740-7_3",
        "document": ""
    },
    {
        "link": "https://researchgate.net/publication/334385231_User_Experience_Evaluation_Using_Mouse_Tracking_and_Artificial_Intelligence",
        "document": "Received May 6, 2019, accepted July 2, 2019, date of publication July 10, 2019, date of current version August 5, 2019. 1 Post-Graduate Program in Anthropic Studies in the Amazon, Federal University of Para, Castanhal 68740-222, Brazil 2 Post-Graduate Program in Anthropic Studies in the Amazon, Federal University of Para, Belem 66075-110, Brazil This work was supported in part by the Coordena√ß√£o de Aperfei√ßoamento de Pessoal de N√≠vel Superior - Brasil (CAPES) - Finance Code 001, in part by the University of Para (UFP A), in part by the National Council of Technological and ScientiÔ¨Åc Development (CNPq), and in part by the Carlos Chagas Filho Research Support Foundation (FAPERJ). ABSTRACT Business platform models frequently require continuous adaptation and agility to allow new experiences to be created and delivered to customers. T o understand user behavior in online systems, researchers have taken advantage of a combination of traditional and recently de veloped analysis techniques. Earlier studies have shown that user behavior monitoring data, as obtained by mouse tracking, can be utilized to improve user experience (UX). Many mouse-tracking solutions exist; ho wever, the vast majority is proprietary, and open-source packages do not pro vide the resources and data needed to support UX research. Thus, this paper presents: 1) the development of an interaction monitoring application titled of the tool in a case study conducted on the W ebsite of the Brazilian Federal Revenue Service (BFR); 3) the deÔ¨Ånition of a new relationship pattern of variables that determine user behavior; 4) the construction of a fuzzy inference system for measuring user performance using the deÔ¨Åned variables and the data captured in the case study; and 5) the application of a clustering algorithm to complement the analysis. A comparison of the results of the applied quantitative methodologies indicates that the dev eloped framework was able to infer UX scores similar to those reported by users in questionnaires. includes all the users‚Äô emotions, beliefs, preferences, per- ceptions, physical, and psychological responses, as well as behaviors and achievements, that occur before, during, and after use of a product or service. UX is, therefore, the direct representation of the human factor in the context of the development of products and services on digital platforms. UX has become an increasingly prominent aspect of systems development, following the e volution of business and process (through techniques such as eye tracking and mouse tracking, The associate editor coordinating the review of this manuscript and approving it for publication was Sudhakar Babu Thanikanti. for example) have become critical for the success of a W eb service. Evaluation and monitoring systems are capable of providing statistical descriptions that allow usage patterns to be identiÔ¨Åed, so that they can be used as a reference for the development of systems, ranging from use recommendations, at the network management level. Allied with these tech- niques, computational intelligence can be used to correlate The analysis of user interaction in W eb systems is an may even support modiÔ¨Åcations to increase the UX lev el. In the present article, a systematic method of evaluating UX by using metrics obtained from mouse tracking in combina- Traditional methods for performing such assessments are 96506 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/\n\nbased on the analysis of the responses of a group of users to items on a satisfaction questionnaire. In the methodology proposed in the present article, an evaluation score consists of the performance parameters of users for task completion, which are directly correlated with the UX perception. The results obtained in this research were compared with those of a classic UX evaluation method to verify the rela- tionship between the UX that the user reports and the UX as measured using data collection and correlation tools. The main contribution is the development of a structure based on computational intelligence techniques that allows the UX to be inferred from user performance parameters. This structure is called the ArtiÔ¨Åcial Intelligence and Mouse Tracking-based tions include the development and application of a tool for the W ebsite of the Federal Revenue Service of Brazil (FRSB), and a comparison of the scores of the methodologies used in This article is organized as follows. Section presents In section , a case study and the analysis of the obtained results are presented. In section , the conclusion is This section presents the main research studies in the litera- ture that support the development of the methods described in this article. The gaps that were found in UX evaluation methods in the literature review and that are considered in Several means for ev aluating UX for computer systems and eye tracking, Ô¨Åxation of attention, etc. may be applied. The application of eye and mouse tracking has been investigated In their study reported in [2], the authors identiÔ¨Åed a strong relationship between the position of the user‚Äôs gaze and the position of the user‚Äôs cursor on a computer screen during W eb browsing. These results attest to the possibility of ev aluating posed, which can record eye movements, the operational data of a user, and the screen image of the pages visited through the use of eye and mouse tracking techniques, and can also the Ô¨Åndings reported in [2], the paper presents optimized techniques for capturing and transmitting data in terms of In the study in [4], a tool was developed for recording all mouse movements on a W eb page and used to analyze and The research reported in [5] showed the identiÔ¨Åcation of user behaviors for UX prediction resulting from the analysis of mouse usage patterns. The presented results allow user frustration and attempt to read a text to be inferred with high In a similar cognitive approach for improving UX, in the to understand the manner in which the user interacts with the design of sites. They concluded that differences in the content that users search on a site can result in large differences in the number of times users move the mouse. As an additional approach for UX evaluation using the mouse-tracking technique, in [7] a solution for capturing the mouse movements of users on W eb pages to identify areas of interest was proposed. The application was developed to In the literature review , it was found that the most recent and CrazyEgg. However , in addition to service fees, such tools include an internal implementation method, that is, they require laborious adaptations for integration with the systems being studied. Furthermore, they do not allow access to the source code, a feature that restricts the depth of investigations. advantages that include limitations on the types of navigation data that can be tracked, the recording and playback of test sessions per user, and the number of sites and pages that can be tested. Some, such as MetricBuzz, third-party sites, which can cause security issues and conÔ¨Çicts with secure sockets layer (SSL) certiÔ¨Åcates. Thus, the char- acteristic of these non-proprietary systems that deÔ¨Ånitively made it impossible to use them in our study is the fact that they Although dozens of visual analysis tools exist, such as those mentioned above, many monitor only user session data. Our study included the development of our own solution with an effective focus on UX and user behavior on a site. of activities based on mouse tracking, which can be easily exported and subsequently served as a basis for the applica- in the UX evaluation. Although it is possible to identify in the literature a few studies in which fuzzy systems were used to measure UX [8]‚Äì[13], in none of these was a framework such as the present one developed and in only a few were the results compared with those of other methodologies.\n\nIn the literature review , references to UX evaluation methods based on questionnaires and applied in several areas were In [15], the authors presented a comparison of the fol- to be adaptable to evaluations for W ebsites: the System in [15], named Our Questionnaire. The comparison showed that, among the models tested, the SUS method achieved the highest accuracy level with the smallest number of In addition, the authors of [20] concluded that the SUS method is reliable and capable of jointly measuring learning and usability, which are directly correlated with the user‚Äô s performance. In the study presented in [21], based on the analysis of approximately 1,000 results obtained with the SUS method, the authors determined the reliability and effec- tiveness of this method in terms of measuring the usability of In the study reported in [22], data were collected from 262 users of applications for comparison with evaluations previously registered using the SUS method. The results showed that the previous application UX is reÔ¨Çected posi- tively in the ev aluation ascribed by the data collection tool. From the conclusions presented in the mentioned papers, it can be understood that the SUS method is a classical reference metric for UX evaluation. This moti vated us to compare the results obtained by our UX framework with those obtained by the SUS method. tain relationships and implicit characteristics that can be dis- covered by applying artiÔ¨Åcial intelligence algorithms. In the last six years, such techniques, most frequently fuzzy logic models, have been applied in UX problems. graphical interfaces was proposed to predict Ô¨Åve lev els of usability in applications. This model used three input vari- ables, but the authors did not explain their measurement method and the results were not compared with those of other UX evaluation techniques. The authors of [24] adopted the same Ô¨Åve levels to e valuate W ebsites and proposed a fuzzy from three different sources, including questionnaires. The opment process, the authors of [13], [25], [26] also utilized usability by means of a Mamdani fuzzy system for selecting a Also using the Mamdani method, the authors of [26] quan- tiÔ¨Åed the conÔ¨Çicts among usability attributes, because the can lead to critical ambiguities for the development of more appropriate and usable software systems. However , in the literature survey presented in [25] the Ô¨Åve key f actors that affect the development of e-commerce W ebsites were identiÔ¨Åed. The W ebsites‚Äô usability was measured by using the neuro-fuzzy inference system (ANFIS) together with SpeciÔ¨Åcally for enhancing the quality of mobile appli- cations, in [27] 12 usability factors that were extracted including the SUS, were examined. In this study , fuzzy asso- ciation rules were generated from the results of the usability survey questionnaires and the patterns were used to obtain the knowledge from the users‚Äô experience to improve usability . Adopting other datamining techniques, the authors of [28] proposed the use of a biclustering algorithm to extract infor- mation from the daily online activities of virtual campus users. The results showed that the knowledge extracted from ter usability and adaption to user preferences. For improv- ing UX, in the study in [29] user context information was also extracted, but for mobile applications. The data extracted by Google Services API were applied to a non-informed and allowing the application to be adapted to the context of applied in UX classiÔ¨Åcation tasks. In particular, in the study in [30] the concept of W ebsite similarity as perceived by users was explored with the goal of facilitating the reuse of with user impression-related inputs had a greater effect on user-assessed similarity of W ebsites than those with user interface intrinsic inputs. In [31], software that was developed to collect selected metrics related to the visual complexity of W eb pages was described. These metrics were used in training an ANN user behavior model to predict the users‚Äô subjective perception of the W ebpages orderliness and com- plexity . In the authors‚Äô opinion, this approach can aid W eb designers to produce W ebsites that attain higher levels of the Although, as mentioned above, many different UX e val- uation methodologies have been developed, the application of artiÔ¨Åcial intelligence techniques is still incipient. Gaps exist that we sought to resolve in the present study . Thus, the goal of this study was to provide a comprehensive UX on mouse tracking, AIMT -UXT, that captures the user perfor- mance parameters and uses them in a fuzzy model to infer a score for each user. Then, an additional intelligent technique, a clustering algorithm, is applied to identify users with sim- ilar characteristics. This methodology allows the inference of the fuzzy system to be conÔ¨Årmed. Finally, the results\n\nwere compared to those of a classic user evaluation method, the SUS questionnaire. An innovativ e framework was used to The AIMT -UXT tool was developed to obtain the user‚Äôs interactions with the mouse and subsequently to analyze them using computational intelligence techniques. The tool is composed of three modules: single-view , heatmap, and and processing of data through the architecture presented in This technology arrangement allows the Ô¨Çexibility obtained through the use of PHP and JavaScript, which allows data capture and storage modules to operate on a multi- platform basis, to be balanced with the capability of the data resources with high performance through C#. As shown in Figure , the architecture is divided into three application. In general, the interaction data are captured by the browser module, which groups the data and sends them to the storage server, responsible for transcribing, org anizing, and storing the collected data. This data is used by the analysis to generate information about system usage and user behav- ior. The modules are described in detail in the follo wing The browser module is an extension of the W eb browser that allows interaction data to be captured while the user performs a certain task. Then, user interactions with the mouse act as a trigger for recording the data of the accessed page, the movement of the mouse itself, and the page object with which the user is interacting. The recordings are performed at a minimum interval of 500 ms, deÔ¨Åned empirically to allow bandwidth savings for data transmission and still preserve the in which the data collection procedure performed by AIMT -UXT consists of three steps. The browser engine i) receives the data of the W eb page to be accessed, ii) renders the interface, and iii) shows to the user the front end. After the completion of this process, the browser engine injects into the JavaScript code from the front end the functions necessary to capture user interaction with the interface. The data collected in the front end are sent to the data grouping system, where the data grouping and user unique identiÔ¨Åcation and encoding in JSON are performed, for subsequent transmission through For intercommunication between the stages and modules, JSON is used, because it is a standard that provides high-level data structuring, which allows at the same time interoperabil- ity between different languages and easy coding and decod- ing, even when performed manually . The HTTP protocol is used because of its easy implementation and use. The data sent by the browser module are received by the stor - age server. Through an application written in PHP , the data are decoded, transcribed to PHP objects, separated by single user IDs, encoded in XML, and stored in separate directories by the calibrated W eb application domain for subsequent use The analysis application, as indicated in Figure , includes three modules that, using the DirectX graphical API, can generate from the data decoded by the XML loader compo- nent different representations of data received from the stor - age server. These are the single-vie w module, which builds individual views of interactions, the heatmap module, which is responsible for grouping data and generating compiled views of multiple samples, and the datafuzzy module, which articulates an action strategy based on a set of linguistic The operation of the single-view module is divided into two stages, starting with the reception of the data of each sample, encoded in XML. Stage one is responsible for sorting the data into Scroll, Click, and W ait, preparing for the next component view . Then, these are represented graphically in stage two, by means of coordinate points on the screens The heatmap module is also divided in two stages. After receipt of the XML data of multiple samples for decoding and transcription for C# objects by the XML loader, the data stored in the memory pass to the Ô¨Årst stage, responsible for identifying agglomerations of coordinated points and assigning them scores accordingly. After the y have been\n\nappropriately processed, the objects pass to the second stage, in which, through the coordinates, they are positioned on the captured screens of the calibrated system and deÔ¨Åned with colors according to the score assigned in the previous stage. The result of this processing is a heatmap cluster. The datafuzzy module, as well as the previous modules, depends on the receipt of the data of multiple samples that are decoded by the XML loader. In the Ô¨Årst stage, the obtained data are submitted to a process of identiÔ¨Åcation and quantiÔ¨Å- cation of user behaviors based on their chronological order. The processed information is sent to the second stage, which organizes it in preparation for export and submission to the intelligence system external to AIMT -UXT, which is dis- cussed in the next section. The W ebsite of the Federal Revenue Service of Brazil was used in our case study. Dozens of tax services are pro vided by the W ebsite, including the income declarations of individ- uals and legal entities, the main sources of the tax collected Users were selected based on the random sampling Each user was chosen entirely randomly, ensuring that a user had the same probability of being selected at any time during the sampling period. A total of 21 users participated in the All the users in the experiments were university exact sciences and humanities students. The age range of the stu- dents was 20 to 25 years-old. A brief interview (pre-test) was conducted to identify their previous knowledge about the subject of the test. Therefore, it was considered that the knowledge base of the sample space was not discrepant. The tests were conducted on three computers with Ubuntu 16 and the Google Chrome browser . The AIMT -UXT browser module, which was responsible for capturing interaction data, was installed. Each execution of the test occurred without any interference from other users or researchers involved in the study, aiming to leav e the interface as the only entity to guide the user to the completion of the set tasks. Each task execution was considered Ô¨Ånished only at the moment of its completion or when the user declared he/she was withdrawing. T o infer the UX, it was necessary to deÔ¨Åne variables that can evaluate the performance of the user in ex ecuting the tasks. T able shows the variables considered rele vant for this case The interaction record can be analyzed using the trace analyzer component of the datafuzzy module. The values for the input variables that allow the user‚Äô s performance in a task to be measured and the corresponding UX to be evaluated are User tasks were deÔ¨Åned that allowed the UX to be evalu- ated in this case study. The tasks were selected using the criterion of relevance to the population. Therefore, consid- through mobile devices [33], the notable expansion of the for anticipation of statement analysis for taxpayers who are retained in the audit, but still weren‚Äôt summoned [35], and the requirement of registration for use of most FRSB services, we selected four activities, described in T able . Each task was initially performed by one of the authors of this study to obtain reference values for the variables used in the study, presented in T able seconds; px T able presents the values of variables considered ideal for performing the deÔ¨Åned tasks, which served as a basis for comparison with the users‚Äô registered values for the same After the tests, a self-assessment questionnaire was adminis- tered to understand the user‚Äôs perception when performing the tasks. As a result of the literature review in section , the SUS questionnaire was selected as the comparative ev aluation\n\nTABLE 3. Reference values for the four tasks. The respondents of the SUS questionnaire indicate their agree‚Äô‚Äô to ‚Äò ‚ÄòStrongly Agree.‚Äô ‚Äô The SUS questionnaire contains The SUS questionnaire was administered after the comple- tion of each of the four tasks. The results of each user were calculated using the method deÔ¨Åned in [16], resulting in a score between 0 and 100, where 0 corresponds to a poor usage experience and 100 to a good user experience. The grades resulting from the application of the SUS method were com- pared with the evaluations obtained from the fuzzy inference of the AIMT -UXT, described in the following subsection. imprecise, and uncertain problems, has been used as a mod- eling tool for complex systems that can be controlled by humans but are difÔ¨Åcult to deÔ¨Åne precisely . Because of these characteristics, fuzzy logic can be con- veniently applied for UX evaluation. It initially in volves the construction of the fuzziÔ¨Åcation interface in which the inputs are mapped to the fuzzy sets, represented by the membership functions. In this case study, we used trape- zoidal and triangular functions, where the minimum and maximum intervals of the records observed for each variable ables with the corresponding degrees of input membership After the fuzziÔ¨Åcation of each input, the process of infer- ence of the UX evaluation was initiated. T o achieve this, the relationship between the input variables presented in The hierarchy of variables presented in Figure facilitate the formulation of the rules that describe the UX used for fuzzy reasoning and the center of area defuzziÔ¨Åca- From a set of 90 rules that were formulated, a fuzzy sys- tem was obtained (a fuzzy score), considering the measured values of the eight input variables and one output variable. Clustering methods can be used to separate records in a dataset into subsets or clusters so that elements of a cluster share common properties that distinguish them from elements in other clusters. Clustering algorithms can help identify natural groups in a dataset, using a certain similarity measure. In this case study, the v alues of the fuzzy score were input to a grouping method. Thus, using the TensorFlo w alization in a low dimensional space. It models each high- dimensional object by two or three-dimensional points such that similar objects are modeled by nearby points and dis- similar objects are modeled by distant points with high Thus, the interaction logs of all users in the four tasks captured by the AIMT -UXT were loaded into TensorFlow . Then, the t-SNE algorithm performed the reduction of the\n\neight input variables to two, distributing the users according to the planes shown in Figure . Each quadrant represents the result of the algorithm for each of the four tasks, respectively , in Figures a), b), c), and d). In Figures b), c), and d), it can be observed that the users, represented by indexes 1 to 21, are associated with a colored circle that indicates the resulting fuzzy score value. It can be observed that, although users present different distributions in each task, it is possible to identify , in general, the formation of two large groups, deÔ¨Åned as the users with The interaction data captured by the AIMT -UXT and pro- cessed to produce evaluation scores in the fuzzy system, together with the clusters visualized by applying the t-SNE algorithm, were compared to the results of the SUS method, ing to T asks 1, 2, 3, and 4, respectively , allow a comparison of the results of the different methodologies. Next to each table, the columns of which identify the grades assigned by the SUS and the fuzzy score and the colors of the clusters that belong to each user, we present the graph- ical representation of these results. These representations consist of frames with a color scale, composed of a gradient from red to green, representing the values of the fuzzy score, from 0 to 1 in ascending order. Additional important elements of this representation are as follows.\n‚Ä¢ The numbered circles arranged in each frame identify\n‚Ä¢ The positions of the circles on the horizontal axis indi-\n‚Ä¢ The color of each circle is deÔ¨Åned by the result obtained using the SUS method, by means of a chromatic rep- resentation similar to that used for the fuzzy score; however , it varies between 0 and 100;\n‚Ä¢ The delimitations around the user representations indi- cate the existence of a cluster; i.e., the users contained Figure presents, at the bottom, the legend of this repre- sentation, with the indications of the SUS, fuzzy score, and An analysis of all the Ô¨Ågures veriÔ¨Åed that certain users pre- sented more consistent evaluations; for example, Users 8, 17, and 21 belonged to the same groups in all tasks. In addition, the results of the corresponding fuzzy score and SUS are consistent with the groups to which the users were allocated; i.e., the value assigned by the user in the SUS method is in tune with the value measured by the proposed fuzzy model. It is also noted that, despite the ‚Äò‚Äòhorizontal dispersion‚Äô ‚Äô in the\n\nevaluation of some users, such as Users 3, 7, and 10, these methodologies. This indicates that, in fact, the performances, and consequently the UX, were close in different tasks. It is also noted that, in the case of a minority of users, such as Users 4 and 18, who presented close evaluations in terms of the SUS result and fuzzy score values (except in T ask 1), the clustering algorithm failed to identify the correct level of In general, it was established that the fuzzy-based duce a subjective assessment of users‚Äô UX from their perfor- mance records on tasks. The identiÔ¨Åcation of groups of users with similar performances was, for the most part, successfully In addition, the reliability of AIMT -UXT is evidenced by a comparison of its results with those of the classical method of UX evaluation: in most cases, the scores ascribed by the SUS methodology are consistent with the fuzzy score. It was also noted that users were gathered in well-deÔ¨Åned groups, which indicates that those who reported good UX via SUS also had clusters that were in general well deÔ¨Åned. This indicates that users who reported a good UX, also had positive ev aluation results through the fuzzy system. Similarly, users with a poor UX, for the most part, had a poor evaluation via the fuzzy system. Thus, the proposed tool provides a graphic resource for visualizing results in different methodologies, making it possible to identify the behavior of UX easily and It should be noted that in the reported case study the sam- ple was small-scale, consisting of only 21 users. However , AIMT -UXT is generic and Ô¨Çexible and can be extended to any number of users, providing UX by means of its compu- tions. In addition, it should be noted that the AIMT -UXT tool is free and open source, and its integration is simple, which allows the ev aluation of diverse online systems without the restrictions present in similar solutions in the market. In this paper, a quantitativ e UX evaluation methodology was proposed and a case study of its application in the Brazilian were obtained by monitoring the interactions of users on gation parameters, using a tool developed for this purpose, AIMT -UXT. The evaluation was obtained by applying artiÔ¨Å- are integrated in the tool. T o validate the data capture and analysis capabilities of the AIMT -UXT tool, the evaluations assessed by this tool were compared with those of a traditional and subjective UX The values returned by the fuzzy inference system on the interaction records of a set of users were congruent with the values obtained with the SUS method. In addition, in most cases, the evaluations were consistent with the clusters iden- tiÔ¨Åed by the t-SNE algorithm. This result shows that the AIMT -UXT is a promising tool for UX measurement from As contributions of this study , we highlight the following. The development and application of a free, open-source tool for monitoring user interactions in W eb systems without the restrictions pertaining to similar market solutions, the use of artiÔ¨Åcial intelligence techniques integrated in the tool to mea- sure the UX from user performance parameters, the validation of the methodology with tasks performed on the W ebsite of the Federal Revenue Service of Brazil, and an easy and In future work, we intend to investigate additional f ac- tors that may inÔ¨Çuence UX and implement additional com- Additionally, we intend to de velop a new version of the tool, with features that allow the data of users belonging to the poor UX group to be processed to adapt the system interface automatically, to realize an impro vement in the UX perceived [2] M. C. Chen, J. R. Anderson, and M. H. Sohn, ‚Äò‚ÄòWhat can a mouse cursor tell us more?: Correlation of eye/mouse movements on W eb browsing,‚Äô‚Äô on Websites, a tool for user modeling, ‚Äô‚Äô in [9] C. B. Cakir and B. Oztaysi, ‚Äò‚Äò A model proposal for usability scoring of\n\nmethods of smartphone based on fuzzy theory, ‚Äô‚Äô in logic system for the user interface usability measurement,‚Äô ‚Äô in [15] T. S. T ullis and J. N. Stetson, ‚Äò‚Äò A comparison of questionnaires for assess- [17] J. P . Chin, V . A. Diehl, and K. L. Norman, ‚Äò‚ÄòDevelopment of an instrument measuring user satisfaction of the human-computer interface,‚Äô ‚Äô in metric evaluation and instructions for use, ‚Äô‚Äô , [22] S. McLellan, A. Muddimer, and S. C. Peres, ‚Äò ‚ÄòThe effect of expe- for GUI based application using fuzzy logic,‚Äô ‚Äô in ‚Äò‚ÄòImproving the user e xperience on mobile apps through data mining,‚Äô ‚Äô prediction of university websites perceptions by different user groups, ‚Äô‚Äô of new Juaben municipality in Ghana,‚Äô ‚Äô in , [36] R. Likert, ‚Äò‚Äò A technique for the measurement of attitudes,‚Äô‚Äô [39] E. H. Mamdani, ‚Äò ‚ÄòApplication of fuzzy algorithms for control of in 2019, where he is currently pursuing the mas- ter‚Äôs degree in anthropic studies in the Amazon. From 2016 to 2018, he, while an undergrad- tory (LADES). He is currently a master‚Äôs degree Mr. Souza is an Associate Member of the Brazilian Computer nology‚Äôs degree in data processing from the Uni- versity Center of the State of Para (CESUP A), in 2004, and the master‚Äôs degree in computer sci- ence from the Federal University of Para, in 2008, where he also received the Ph.D. degree in elec- trical engineering with an emphasis in applied He is currently an Associate Professor (level IV) of the Federal University of Para (UFP A). He is also permanent Professor of Postgraduate Program in Anthropic Studies in the Amazon (PPGEAA), a Collaborator Professor of the Postgraduate Program in Electrical Engineering (PPGEE), and a Collaborator Professor of the Postgraduate Program in Computer Science (PPGCC). He is a Researcher He is the author of more than 80 scientiÔ¨Åc papers. His research interests Dr. Seruffo is an Associate Member of the Brazilian Computer"
    },
    {
        "link": "https://sciencedirect.com/science/article/pii/S0920548924000187",
        "document": ""
    },
    {
        "link": "https://inria.hal.science/hal-02060040/document",
        "document": ""
    }
]