[
    {
        "link": "https://esa.github.io/pygmo2",
        "document": ""
    },
    {
        "link": "https://esa.github.io/pygmo",
        "document": "PyGMO (the Python Parallel Global Multiobjective Optimizer) is a scientific library providing a large number of optimisation problems and algorithms under the same powerful parallelization abstraction built around the generalized island-model paradigm. What this means to the user is that the available algorithms are all automatically parallelized (asynchronously, coarse-grained approach) thus making efficient use of the underlying multicore architecture. The user can also program his own solvers ... they also will be parallelized by PyGMO!! PyGMO’s implementation of the generalized migration operator allows the user to easily define “migration paths” (topologies) between a large number of “islands” (CPU cores).\n\nEfficient implementantions of state-of-the-art bio-inspired algorithms are sided to state-of the art optimization algorithms (Simplex Methods, SQP methods ....) and can be easily mixed (also with your newly invented algorithms) to build a super-algorithm exploiting cooperation via the asynchronous, generalized island model.\n\nMany complex-networks topologies (Hypercube, Ring, Barabasi-Albert, Watts-Strogatz, Erdos-Renyi, etc.) are built-in and may be used to define the migration pathways of good solutions among islands. Custom topologies are also possible.\n\nPyGMO can be used to solve constrained, unconstrained, single objective, multiple objective, continuous, mixed int optimization problem, or to perform research on novel algorithms and paradigms and easily compare them to state of the art implementations of established ones.\n\nPyGMO is interfaced with SciPy optimization algorithms, NLOPT algorithms, GSL algorithms, SNOPT, IPOPT and, hopefully .... more to come. Packages such as networkx and vpython enhance functionalities allowing advanced visualization options.\n\nPlease send your comments via the pagmo/PyGMO mailing list and submit any bugs via our pagmo/PyGMO bug-tracker\n\nON THE ANIMATION ABOVE: One animation is worth a lot of words!!! So here are the ‘words’ explaining what you see in the animation. This is a visualization of an optimization (evolution) in a PyGMO archipelago containing 490 islands. Particle Swarm optimization is used in all islands each containing 20 individuals. The interpanetary trajectory problem Cassini is being solved. This is a problem from the GTOP database (all of which included in PyGMO). Red dots are islands containing the worst solution so far, white dots are islands containing the best solution so far. All other islands colors are scaled from white to red according to their champion’s fitness. The islands are connected using a Barabasi-Albert ageing clustered topology. The code below reproduces the optimization and shows how to create figures. The animation can then be made by putting together all figures produced.\n\n# We need networkx installed and PyGMO compiled with the keplerian_toolbox option activated # Also start this in ipython with the --pylab option #We instantiate the algorithm Differential Evolution fixing 10 generations for each call #Here we instantiate the archipelago with 490 islands an 20 individuals per island ..... #We can draw an archipelago like this #And we start the evolution loops (each evolve will advance each island 10 generation) #this opens 490 threads ..... each one evolving its population using algo!!!"
    },
    {
        "link": "https://pymoo.org",
        "document": "Our framework offers state of the art single- and multi-objective optimization algorithms and many more features related to multi-objective optimization such as visualization and decision making. pymoo is available on PyPi and can be installed by:\n\nPlease note that some modules can be compiled to speed up computations (optional). The command above attempts is made to compile the modules; however, if unsuccessful, the pure python version is installed. More information are available in our Installation Guide.\n\nJuly 11, 2022: It just happened. The new pymoo (version 0.6.0) version has been released. Many things happened under the hood; however, the code base has changed quite a bit. The individual class has been reimplemented, and the meta algorithms can now be constructed much simpler. New algorithms have been added (G3PXC, RVEA, SMS-EMOA), and dynamic optimization problems and a simple implementation of D-NSGA-II are available. For more details, please have a look at the changelogs. (Release Notes) September 12, 2021: After quite some time, a bigger release of pymoo (version 0.5.0) is available. The project has made significant progress regarding its structure and has an entirely new module organization. Even though there might be some breaking changes for users, it shall improve the clarity and readability of code in the long term. The documentation has gotten a completely new design and become responsive. In addition, some more algorithms have been improved (PSO, DE) and added (AGEMOEA, ES, SRES, ISRES). For more details, please have a look at the changelogs. (Release Notes) September 4, 2020: We are more than happy to announce that a new version of pymoo (version 0.4.2) is available. This version has some new features and evolutionary operators, as well as an improved getting, started guide. For more details, please have a look at the release notes. (Release Notes)\n\nThis framework is powered by anyoptimization, a Python research community. It is developed and maintained by Julian Blank who is affiliated to the Computational Optimization and Innovation Laboratory (COIN) supervised by Kalyanmoy Deb at the Michigan State University in East Lansing, Michigan, USA. We have developed the framework for research purposes and hope to contribute to the research area by delivering tools for solving and analyzing multi-objective problems. Each algorithm is developed as close as possible to the proposed version to the best of our knowledge. NSGA-II and NSGA-III have been developed collaboratively with one of the authors and, therefore, we recommend using them for official benchmarks. If you intend to use our framework for any profit-making purposes, please contact us. Also, be aware that even state-of-the-art algorithms are just the starting point for many optimization problems. The full potential of genetic algorithms requires customization and the incorporation of domain knowledge. We have experience for more than 20 years in the optimization field and are eager to tackle challenging problems. Let us know if you are interested in working with experienced collaborators in optimization. Please keep in mind that only through such projects can we keep developing and improving our framework and making sure it meets the industry’s current needs. Moreover, any kind of contribution is more than welcome: (i) Give us a on GitHub. This makes not only our framework but, in general, multi-objective optimization more accessible by being listed with a higher rank regarding specific keywords. (ii) To offer more and more new algorithms and features, we are more than happy if somebody wants to contribute by developing code. You can see it as a win-win situation because your development will be linked to your publication(s), which can significantly increase your work awareness. Please note that we aim to keep a high level of code quality, and some refactoring might be suggested. (iii) You like our framework, and you would like to use it for profit-making purposes? We are always searching for industrial collaborations because they help direct research to meet the industry’s needs. Our laboratory solving practical problems have a high priority for every student and can help you benefit from the research experience we have gained over the last years. If you find a bug or you have any kind of concern regarding the correctness, please use our Issue Tracker Nobody is perfect Moreover, only if we are aware of the issues we can start to investigate them."
    },
    {
        "link": "https://stackoverflow.com/questions/77411477/pygmo-multi-objective-optimization-with-constraints",
        "document": "I want to solve a multi-objective optimization problem with constraints using pygmo and obtain the resulting Pareto front. However, even though my program only contains linear constraints, I obtain an error:\n\nI implemented a more simple program to recreate the error:\n\nwhich results in the same error. If I remove the constraint it works fine.\n\nTo my understanding, fitness should return a vector containing the objectives followed by the constraints, as shown in the example \"Coding a User Defined Problem with constraints\" of the pygmo2 documentation. They however do not list an example with multiple objectives that contains other constraints except the decision variable bounds. Do I need to handle the fitness function differently in this case?"
    },
    {
        "link": "https://stackoverflow.com/questions/38141923/multi-objective-optimisation-using-pygmo",
        "document": "I am using the PyGMO package for Python, for multi-objective optimisation. I am unable to fix the dimension of the fitness function in the constructor, and the documentation is not very descriptive either. I am wondering if anyone here has had experience with PyGMO in the past: this could be fairly simple.\n\nI try to construct a minimum example below:\n\nabove is a failed attempt to set the fitness dimension. The code fails with the following error:\n\nI'd be grateful if someone can help figure this out. Thanks!"
    },
    {
        "link": "https://stackoverflow.com/questions/77411477/pygmo-multi-objective-optimization-with-constraints",
        "document": "I want to solve a multi-objective optimization problem with constraints using pygmo and obtain the resulting Pareto front. However, even though my program only contains linear constraints, I obtain an error:\n\nI implemented a more simple program to recreate the error:\n\nwhich results in the same error. If I remove the constraint it works fine.\n\nTo my understanding, fitness should return a vector containing the objectives followed by the constraints, as shown in the example \"Coding a User Defined Problem with constraints\" of the pygmo2 documentation. They however do not list an example with multiple objectives that contains other constraints except the decision variable bounds. Do I need to handle the fitness function differently in this case?"
    },
    {
        "link": "https://stackoverflow.com/questions/38141923/multi-objective-optimisation-using-pygmo",
        "document": "I am using the PyGMO package for Python, for multi-objective optimisation. I am unable to fix the dimension of the fitness function in the constructor, and the documentation is not very descriptive either. I am wondering if anyone here has had experience with PyGMO in the past: this could be fairly simple.\n\nI try to construct a minimum example below:\n\nabove is a failed attempt to set the fitness dimension. The code fails with the following error:\n\nI'd be grateful if someone can help figure this out. Thanks!"
    },
    {
        "link": "https://esa.github.io/pygmo2/tutorials/moo.html",
        "document": ""
    },
    {
        "link": "https://esa.github.io/pygmo/tutorials/adding_a_new_optimization_problem.html",
        "document": "In this Tutorial we will learn how to code simple optimization problems (continuous, single objective, unconstrained), so that PyGMO can then apply all of its algorithmic power to solve it. In a nutshell, we will write a class deriving from PyGMO.problem.base and reimplement some of its ‘virtual’ methods.\n\nLet us start with defining one of the classic textbook examples of an optimization problem. # First we call the constructor of the base class telling PyGMO # what kind of problem to expect ('dim' dimensions, 1 objective, 0 contraints etc.) # We set the problem bounds (in this case equal for all components) # Reimplement the virtual method that defines the objective function. # Note that we return a tuple with one element only. In PyGMO the objective functions # return tuples so that multi-objective optimization is also possible. # Finally we also reimplement a virtual method that adds some output to the __repr__ method Note that by default PyGMO will assume one wants to minimize the objective function. In the second part of this tutorial we will also see how it is possible to change this default behaviour. To solve our problem we will use Artificial Bee Colony algorithm with 20 individuals. And we are done! Objective value in the order of \\(10^{-25}\\), no big deal for a sphere problem.\n\nLet’s consider now a maximization problem. To solve such a problem, two possibilities are available to the PaGMO/PyGMO user. The first one is to code the original problem as a minimization problem by premultiplying the objective function by \\(-1\\) (a technique wich is often used and requires no particular effort). If such a method is used, the final fitness value obtained with PyGMO has to be multiplied by \\(-1\\) to get back to the correct value. A second method, more elegant and most of all serving the purpose to show the use of another virtual method which can be reimplemented in python objects deriving from base, is to override the function that compares two fitness vectors. This function is used by all pagmo algorithms to compare performances of individuals. By default, this function compares the fitness \\(f_1\\) to a fitness \\(f_2\\) and returns true if \\(f_1\\) dominates \\(f_2\\) (which is single objective optimization correspond to minimization). Let us see how... # We provide a list of the best known solutions to the problem # Reimplement the virtual method that defines the objective function Additionally in the constructor we provide a list of all known global minima (we will use those later for testing). The list of corresponding objective function values will be then computed and accessible through best_f of the problem’s instance. As before, we use our favorite optimization algorithm: \"Comparison of the best found fitness with the best known fitness:\" \"L2 distance to the best decision vector:\" Best individual: Decision vector: [1.0000035381312899, -1.000007979785372] Constraints vector: [] Fitness vector: [-1.0000000000941514] Comparison of the best found fitness with the best known fitness: 9.41513533803e-11 L2 distance to the best decision vector: 8.72899465051e-06 Note here that we used the best_f and best_x methods which return the best known fitness and decision vectors. The best_f vector is automatically available as we defined best_x in the problem. With these vectors, we can have an idea of the optimizer performances. The result of this optimization should be in order of \\(10^{-11}\\) for the comparison with the best fitness and \\(10^{-6}\\) for the distance to the best decision vector.\n\nAs hinted before, users can also define their own multi-objective problem. In that case we need to overload the the base constructor with third argument stating the desired objective function dimension and return a tuple or a list with more than one element in the objective function implementation (both dimensions must agree). # We call the base constructor as 'dim' dimensional problem, with 0 integer parts and 2 objectives. # Reimplement the virtual method that defines the objective function We instantiate our problem as before, but this time we use one of the multi-objective algorithms available in PaGMO: # 2000 generations of SMS-EMOA should solve it Since in the Multi-Objective world the idea of a single ‘champion’ solution is not very well defined, we plot the Pareto front of the whole population, i.e., the two objectives \\(f_i^{(1)}\\) and \\(f_i^{(2)}\\) of each individual \\(i \\in 1,\\ldots,30\\). %matplotlib inline import matplotlib.pyplot as plt import numpy as np # Fold each objectives into vectors and print the Pareto front F = np.array([ind.cur_f for ind in pop]).T plt.scatter(F[0], F[1]) plt.xlabel(\"$f^{(1)}$\") plt.ylabel(\"$f^{(2)}$\") plt.show() NOTE1: This problems of tutorial are implemented in PyGMO under the name PyGMO.problem.py_example and PyGMO.problem.py_example_max NOTE2: When evolve is called from an island, the process is forked and transferred to another python or ipython instance. As a consequence, when writing your *obj*fun_impl you cannot use stuff like matplotlib to make interactive plots and alike. If you need, during development, to have this kind of support, use the algorithm evolve method (see the optimization of the Multi-Objective problemabove) NOTE3: If performance is your goal, you should implement your problem in C++, and then expose it into Python."
    },
    {
        "link": "https://github.com/esa/pagmo2/issues/149",
        "document": "I have read the complete python tutorials and have successfully tested my installation with some simple mono-objective examples.\n\nSince I intend to use it for multi-objective optimization, I have been looking for some examples on how to do this. In the mono-objective UDP example tutorial is says that the number of objectives can be defined similarly to the number of constraints (eqs/iqs) but \" Since we do not define, in this case, any other method pygmo will assume a single objective, no constraints, no gradients etc…\" and in the MOO tutorial a pre-defined standard problem is chosen.\n\nAre there any tutorials or code examples that show how to set up multi-objective customized UDPs such as in the simple UDP tutorial?\n\nYour packages seems really promising but I got stuck here.."
    }
]