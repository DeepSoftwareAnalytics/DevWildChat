[
    {
        "link": "https://geeksforgeeks.org/use-posix-semaphores-c",
        "document": "How to use POSIX semaphores in C language\n\nSemaphores are very useful in process synchronization and multithreading. But how to use one in real life, for example say in C Language?\n\nWell, we have the POSIX semaphore library in Linux systems. Let’s learn how to use it.\n\nThe basic code of a semaphore is simple as presented here. But this code cannot be written directly, as the functions require to be atomic and writing code directly would lead to a context switch without function completion and would result in a mess.\n\nThe POSIX system in Linux presents its own built-in semaphore library. To use it, we have to :\n• None Compile the code by linking with -lpthread -lrt\n• None To lock a semaphore or wait we can use the sem_wait\n\nTo release or signal a semaphore, we use the sem_post function:\n\nA semaphore is initialised by using sem_init(for processes or threads) or sem_open (for IPC).\n• sem : Specifies the semaphore to be initialized.\n• pshared : This argument specifies whether or not the newly initialized semaphore is shared between processes or between threads. A non-zero value means the semaphore is shared between processes and a value of zero means it is shared between threads.\n• value : Specifies the value to assign to the newly initialized semaphore.\n\nTo destroy a semaphore, we can use sem_destroy.\n\nTo declare a semaphore, the data type is sem_t.\n\nCompilation should be done with gcc a.c -lpthread -lrt\n\n2 threads are being created, one 2 seconds after the first one.\n\nBut the first thread will sleep for 4 seconds after acquiring the lock.\n\nThus the second thread will not enter immediately after it is called, it will enter 4 – 2 = 2 secs after it is called. So the output is:"
    },
    {
        "link": "https://stackoverflow.com/questions/79156346/thread-synchronization-with-semaphore-in-c",
        "document": "I am working on an assignment which requires me to simulate a bus travelling from Stop A to Stop B over and over again while students can get on and get out of it.\n\nI coded the whole routine of the bus and the students but I can't seem to get them synchronized properly.\n\nAs an example of what is working and what is not, here's a sample run of a single cycle of the program with 4 students/threads (plus the bus thread):\n\nAs you can see, the bus is initialized at Stop A, the students are created and getting into the bus correctly (student 3 can't get into the bus because of the department rule that says: N / 4 students of the same department can be in the bus at a given time, here N = 4). When the bus arrives at Stop B, all students in the bus should get off it and go to the university. Here, only Student 1 is getting off the bus.\n\nI understand that the semaphore is not working properly. What can I do to fix it? Any answers would be appreciated."
    },
    {
        "link": "https://cs.cmu.edu/afs/cs/academic/class/15492-f07/www/pthreads.html",
        "document": "\n• A thread does not maintain a list of created threads, nor does it know the thread that created it.\n• All threads within a process share the same address space.\n• Threads in the same process share:\n• In this example the same function is used in each thread. The arguments are different. The functions need not be the same.\n• Threads terminate by explicitly calling , by letting the function return, or by a call to the function which will terminate the process including any threads.\n• Function call: Arguments:\n• - Set to NULL if default thread attributes are used. (else define members of the struct defined in bits/pthreadtypes.h) Attributes include:\n• scope (Kernel threads: PTHREAD_SCOPE_SYSTEM User threads: PTHREAD_SCOPE_PROCESS Pick one or the other not both.)\n• - pointer to the function to be threaded. Function has a single argument: pointer to void.\n• - pointer to argument of function. To pass multiple arguments, send a pointer to a structure.\n• Function call: Arguments: This routine kills the thread. The function never returns. If the thread is not detached, the thread id and return value may be examined from another thread by using pthread_join. \n\n Note: the return pointer , must not be of local scope otherwise it would cease to exist once the thread terminates.\n• : The above sample program will compile with the GNU C and C++ compiler . The following function pointer representation below will work for C but not C++. Note the subtle differences and avoid the pitfall below:\n\nThe threads library provides three synchronization mechanisms:\n• mutexes - Mutual exclusion lock: Block access to variables by other threads. This enforces exclusive access by a thread to a variable or set of variables.\n\nIf register load and store operations for the incrementing of variable occurs with unfortunate timing, it is theoretically possible to have each thread increment and overwrite the same variable with the same value. Another possibility is that thread two would first increment locking out thread one until complete and then thread one would increment it to 2. \n\n\n\nWhen a mutex lock is attempted against a mutex which is held by another thread, the thread is blocked until the mutex is unlocked. When a thread terminates, the mutex does not unless explicitly unlocked. Nothing happens by default.\n\nA condition variable is a variable of type and is used with the appropriate functions for waiting and later, process continuation. The condition variable mechanism allows threads to suspend execution and relinquish the processor until some condition is true. A condition variable must always be associated with a mutex to avoid a race condition created by one thread preparing to wait and another thread which may signal the condition before the first thread actually waits on it resulting in a deadlock. The thread will be perpetually waiting for a signal that is never sent. Any mutex can be used, there is no explicit link between the mutex and the condition variable.\n\nFunctions used in conjunction with the condition variable:\n• Waiting on condition:\n• pthread_cond_timedwait - place limit on how long it will block.\n• Waking thread based on condition:\n• pthread_cond_broadcast - wake up all threads blocked by the specified condition variable.\n\nNote that was halted while count was between the values COUNT_HALT1 and COUNT_HALT2. The only thing that has been ensures is that will increment the count between the values COUNT_HALT1 and COUNT_HALT2. Everything else is random.\n\nThe logic conditions (the \"if\" and \"while\" statements) must be chosen to insure that the \"signal\" is executed if the \"wait\" is ever processed. Poor software logic can also lead to a deadlock condition.\n\nNote: Race conditions abound with this example because count is used as the condition and can't be locked in the while statement without causing deadlock. I'll work on a cleaner example but it is an example of a condition variable.\n\nWhen this option is enabled, each thread may have its own scheduling properties. Scheduling attributes may be specified:\n• by dynamically by changing the attributes of a thread already created\n• by defining the effect of a mutex on the thread's scheduling when creating a mutex\n• by dynamically changing the scheduling of a thread during synchronization operations.\n• Race conditions: While the code may appear on the screen in the order you wish the code to execute, threads are scheduled by the operating system and are executed at random. It cannot be assumed that threads are executed in the order they are created. They may also execute at different speeds. When threads are executing (racing to complete) they may give unexpected results (race condition). Mutexes and joins must be utilized to achieve a predictable execution order and outcome.\n• Thread safe code: The threaded routines must call functions which are \"thread safe\". This means that there are no static or global variables which other threads may clobber or read assuming single threaded operation. If static or global variables are used then mutexes must be applied or the functions must be re-written to avoid the use of these variables. In C, local variables are dynamically allocated on the stack. Therefore, any function that does not use static data or other shared resources is thread-safe. Thread-unsafe functions may be used by only one thread at a time in a program and the uniqueness of the thread must be ensured. Many non-reentrant functions return a pointer to static data. This can be avoided by returning dynamically allocated data or using caller-provided storage. An example of a non-thread safe function is which is also not re-entrant. The \"thread safe\" version is the re-entrant version .\n• Mutex Deadlock: This condition occurs when a mutex is applied but then not \"unlocked\". This causes program execution to halt indefinitely. It can also be caused by poor application of mutexes or joins. Be careful when applying two or more mutexes to a section of code. If the first pthread_mutex_lock is applied and the second pthread_mutex_lock fails due to another thread applying a mutex, the first mutex may eventually lock all other threads from accessing data including the thread which holds the second mutex. The threads may wait indefinitely for the resource to become free causing a deadlock. It is best to test and if failure occurs, free the resources and stall before retrying. ...\n\n pthread_mutex_lock(&mutex_1);\n\n while ( pthread_mutex_trylock(&mutex_2) ) /* Test if already locked */\n\n {\n\n pthread_mutex_unlock(&mutex_1); /* Free resource to avoid deadlock */\n\n ...\n\n /* stall here */\n\n ...\n\n pthread_mutex_lock(&mutex_1);\n\n }\n\n count++;\n\n pthread_mutex_unlock(&mutex_1);\n\n pthread_mutex_unlock(&mutex_2);\n\n ...\n\n The order of applying the mutex is also important. The following code segment illustrates a potential for deadlock: If acquires the first mutex and acquires the second, all resources are tied up and locked.\n• Condition Variable Deadlock: The logic conditions (the \"if\" and \"while\" statements) must be chosen to insure that the \"signal\" is executed if the \"wait\" is ever processed.\n• pthread_atfork - register handlers to be called at fork(2) time\n• pthread_join - wait for termination of another thread\n• pthread_kill_other_threads_np - terminate all threads in program except calling thread\n• Introduction of threads for Solaris, Linux, and Windows\n• Pthreads tutorial and examples of thread problems - by Andrae Muys\n• Linux-mag.com: The Fibers of Threads - Discussion of how Linux threads work\n• C++ Thread classes:\n• GNU: Common C++ - support for threading, sockets, file access, daemons, persistence, serial I/O, XML parsing and system services"
    },
    {
        "link": "https://stackoverflow.com/questions/2350544/in-what-situation-do-you-use-a-semaphore-over-a-mutex-in-c",
        "document": "The typical use case for a mutex (allowing only one thread access to a resource at any time) is far more common than the typical uses if a semaphore. But a semaphore is actually the more general concept: A mutex is (almost) a special case of a semaphore.\n\nTypical applications would be: You don't want to create more than (e.g.) 5 database connections. No matter how many worker threads there are, they have to share these 5 connections. Or, if you run on a N-core machine, you might want to make sure that certain CPU/memory-intensive tasks don't run in more than N threads at the same time (because that would only reduce throughput due to context switches and cache thrashing effects). You might even want to limit the number of parallel CPU/memory intensive tasks to N-1, so the rest of the system doesn't starve. Or imagine a certain task needs a lot of memory, so running more than N instances of that task at the same time would lead to paging. You could use a semaphore here, to make sure that no more than N instances of this particular task run at the same time.\n\nEDIT/PS: From your question \"This is only possible if those threads are only reading the resource but not writing. Is this correct?\" and your comment, it seems to me as if you're thinking of a resource as a variable or a stream, that can be read or written and that can only be written to by one thread at a time. Don't. This is misleading in this context.\n\nThink of resources like \"water\". You can use water to wash your dishes. I can use water to wash my dishes at the same time. We don't need any kind of synchronization for that, because there is enough water for both of us. We don't necessarily use the same water. (And you can't \"read\" or \"write\" water.) But the total amount of water is finite. So it's not possible for any number of parties to wash their dishes at the same time. This kind of synchronization is done with a semaphore. Only usually not with water but with other finite resources like memory, disk space, IO throughput or CPU cores."
    },
    {
        "link": "https://geeksforgeeks.org/mutex-vs-semaphore",
        "document": "In the Operating System, Mutex and Semaphores are kernel resources that provide synchronization services (also known as synchronization primitives). Synchronization is required when multiple processes are executing concurrently, to avoid conflicts between processes using shared resources. In this article we will see differences between Mutex and Semaphore, their advantages and disadvantages.\n\nA mutex is different from a binary semaphore, which provides a locking mechanism. It stands for Mutual Exclusion Object. Mutex is mainly used to provide mutual exclusion to a specific portion of the code so that the process can execute and work with a particular section of the code at a particular time. A mutex enforces strict ownership. Only the thread that locks the mutex can unlock it. It is specifically used for locking a resource to ensure that only one thread accesses it at a time. Due to this strict ownership, a mutex is not only typically used for signaling between threads, but it is used for mutual exclusion also to ensuring that a resource is accessed by only one thread at a time.\n\nMutex uses a priority inheritance mechanism to avoid priority inversion issues. The priority inheritance mechanism keeps higher-priority processes in the blocked state for the minimum possible time. However, this cannot avoid the priority inversion problem, but it can reduce its effect up to an extent.\n• None No race condition arises, as only one process is in the\n• None Data remains consistent and it helps in maintaining integrity.\n• None It is a simple locking mechanism that into a critical section and is released while leaving the critical section.\n• None If after entering into the critical section, the thread sleeps or gets preempted by a high-priority process, no other thread can enter into the critical section. This can lead to\n• None When the previous thread leaves the critical section, then only other processes can enter into it, there is no other mechanism to lock or unlock the critical section.\n• None Implementation of mutex can lead to busy waiting, which leads to the wastage of the CPU cycle.\n\nThe producer-consumer problem: Consider the standard producer-consumer problem. Assume, we have a buffer of 4096-byte length. A producer thread collects the data and writes it to the buffer. A consumer thread processes the collected data from the buffer. The objective is, that both the threads should not run at the same time.\n\nSolution: A mutex provides mutual exclusion, either producer or consumer can have the key (mutex) and proceed with their work. As long as the buffer is filled by the producer, the consumer needs to wait, and vice versa. At any point in time, only one thread can work with the entire buffer. The concept can be generalized using semaphore.\n\nA semaphore is a non-negative integer variable that is shared between various threads. Semaphore works upon signaling mechanism, in this a thread can be signaled by another thread. It provides a less restrictive control mechanism. Any thread can invoke (also known as or ), and any other thread can invoke (also known as or ). There is no strict ownership in semaphores, meaning the thread that signals doesn’t necessarily have to be the same one that waited. Semaphores are often used for coordinating signaling between threads. Semaphore uses two atomic operations for process synchronisation:\n• None Multiple threads can access the critical section at the same time.\n• None Only one process will access the critical section at a time, however, multiple threads are allowed.\n• None Semaphores are machine-independent, so they should be run over\n• None Semaphore operations (Wait, Signal) must be implemented in the correct manner to avoid deadlock.\n• None It leads to a loss of modularity, so semaphores can’t be used for large-scale systems.\n• None Semaphore is prone to programming error and this can lead to deadlock or violation of mutual exclusion property.\n• None Operating System has to track all the calls to wait and signal operations.\n\nThe producer-consumer problem: Consider the standard producer-consumer problem. Assume, we have a buffer of 4096-byte length. A producer thread collects the data and writes it to the buffer. A consumer thread processes the collected data from the buffer. The objective is, both the threads should not run at the same time.\n\nSolution: A semaphore is a generalized mutex. instead a single buffer, we can split the 4 KB buffer into four 1 KB buffers (identical resources). A semaphore can be associated with these four buffers. The consumer and producer can work on different buffers at the same time.\n\nThere is an ambiguity between binary semaphore and mutex. We might have come across that a mutex is a binary semaphore. But it is not! The purposes of mutex and semaphore are different. Maybe, due to similarity in their implementation of a mutex would be referred to as a binary semaphore. A mutex is a locking mechanism used to synchronize access to a resource. Only one task (can be a thread or process based on OS abstraction) can acquire the mutex. It means there is ownership associated with a mutex, and only the owner can release the lock (mutex).\n\nA semaphore is a signaling mechanism used to control access to shared resources in an operating system. For example, imagine you are downloading a large file on your computer (Task A) while simultaneously trying to print a document (Task B). When the print job is initiated, it triggers a semaphore that checks if the download is complete.\n\nIf the download is still in progress, the semaphore prevents the print task from proceeding, effectively saying, “Wait until the download finishes.” Once the download completes, the semaphore signals that Task B can start printing. This ensures that both tasks do not interfere with each other and helps manage system resources efficiently, allowing tasks to run smoothly without conflict.\n\nMutexes and semaphores are synchronization tools used to manage concurrent access to shared resources. Mutexes ensure mutual exclusion by allowing only one thread to lock a resource at a time. Semaphores use signaling to coordinate access, enabling multiple threads to share resources. While mutexes prevent race conditions, semaphores offer more flexibility. Choosing the right tool depends on the specific synchronization needs.\n\nCan a thread acquire more than one lock (Mutex)?\n\nWhat happens if a non-recursive mutex is locked more than once?\n\nCan we acquire mutex/semaphore in an Interrupt Service Routine?\n\nWhat do we mean by “thread blocking on mutex/semaphore” when they are not available?"
    },
    {
        "link": "https://learn.microsoft.com/en-us/windows/win32/api/synchapi/nf-synchapi-createmutexa",
        "document": "To specify an access mask for the object, use the CreateMutexEx function.\n\nA pointer to a SECURITY_ATTRIBUTES structure. If this parameter is NULL, the handle cannot be inherited by child processes.\n\nThe lpSecurityDescriptor member of the structure specifies a security descriptor for the new mutex. If lpMutexAttributes is NULL, the mutex gets a default security descriptor. The ACLs in the default security descriptor for a mutex come from the primary or impersonation token of the creator. For more information, see Synchronization Object Security and Access Rights.\n\nIf this value is TRUE and the caller created the mutex, the calling thread obtains initial ownership of the mutex object. Otherwise, the calling thread does not obtain ownership of the mutex. To determine if the caller created the mutex, see the Return Values section.\n\nThe name of the mutex object. The name is limited to MAX_PATH characters. Name comparison is case sensitive.\n\nIf lpName matches the name of an existing named mutex object, this function requests the MUTEX_ALL_ACCESS access right. In this case, the bInitialOwner parameter is ignored because it has already been set by the creating process. If the lpMutexAttributes parameter is not NULL, it determines whether the handle can be inherited, but its security-descriptor member is ignored.\n\nIf lpName is NULL, the mutex object is created without a name.\n\nIf lpName matches the name of an existing event, semaphore, waitable timer, job, or file-mapping object, the function fails and the GetLastError function returns ERROR_INVALID_HANDLE. This occurs because these objects share the same namespace.\n\nThe name can have a \"Global\" or \"Local\" prefix to explicitly create the object in the global or session namespace. The remainder of the name can contain any character except the backslash character (\\). For more information, see Kernel Object Namespaces. Fast user switching is implemented using Terminal Services sessions. Kernel object names must follow the guidelines outlined for Terminal Services so that applications can support multiple users.\n\nThe object can be created in a private namespace. For more information, see Object Namespaces.\n\nIf the function succeeds, the return value is a handle to the newly created mutex object.\n\nIf the function fails, the return value is NULL. To get extended error information, call GetLastError.\n\nIf the mutex is a named mutex and the object existed before this function call, the return value is a handle to the existing object, and the GetLastError function returns ERROR_ALREADY_EXISTS.\n\nThe handle returned by CreateMutex has the MUTEX_ALL_ACCESS access right; it can be used in any function that requires a handle to a mutex object, provided that the caller has been granted access. If a mutex is created from a service or a thread that is impersonating a different user, you can either apply a security descriptor to the mutex when you create it, or change the default security descriptor for the creating process by changing its default DACL. For more information, see Synchronization Object Security and Access Rights.\n\nIf you are using a named mutex to limit your application to a single instance, a malicious user can create this mutex before you do and prevent your application from starting. To prevent this situation, create a randomly named mutex and store the name so that it can only be obtained by an authorized user. Alternatively, you can use a file for this purpose. To limit your application to one instance per user, create a locked file in the user's profile directory.\n\nAny thread of the calling process can specify the mutex-object handle in a call to one of the wait functions. The single-object wait functions return when the state of the specified object is signaled. The multiple-object wait functions can be instructed to return either when any one or when all of the specified objects are signaled. When a wait function returns, the waiting thread is released to continue its execution.\n\nThe state of a mutex object is signaled when it is not owned by any thread. The creating thread can use the bInitialOwner flag to request immediate ownership of the mutex. Otherwise, a thread must use one of the wait functions to request ownership. When the mutex's state is signaled, one waiting thread is granted ownership, the mutex's state changes to nonsignaled, and the wait function returns. Only one thread can own a mutex at any given time. The owning thread uses the ReleaseMutex function to release its ownership.\n\nThe thread that owns a mutex can specify the same mutex in repeated wait function calls without blocking its execution. Typically, you would not wait repeatedly for the same mutex, but this mechanism prevents a thread from deadlocking itself while waiting for a mutex that it already owns. However, to release its ownership, the thread must call ReleaseMutex once for each time that the mutex satisfied a wait.\n\nTwo or more processes can call CreateMutex to create the same named mutex. The first process actually creates the mutex, and subsequent processes with sufficient access rights simply open a handle to the existing mutex. This enables multiple processes to get handles of the same mutex, while relieving the user of the responsibility of ensuring that the creating process is started first. When using this technique, you should set the bInitialOwner flag to FALSE; otherwise, it can be difficult to be certain which process has initial ownership.\n\nMultiple processes can have handles of the same mutex object, enabling use of the object for interprocess synchronization. The following object-sharing mechanisms are available:\n• A child process created by the CreateProcess function can inherit a handle to a mutex object if the lpMutexAttributes parameter of CreateMutex enabled inheritance. This mechanism works for both named and unnamed mutexes.\n• A process can specify the handle to a mutex object in a call to the DuplicateHandle function to create a duplicate handle that can be used by another process. This mechanism works for both named and unnamed mutexes.\n• A process can specify a named mutex in a call to [OpenMutex](./nf-synchapi-openmutexw.md) or CreateMutex to retrieve a handle to the mutex object.\n\nUse the CloseHandle function to close the handle. The system closes the handle automatically when the process terminates. The mutex object is destroyed when its last handle has been closed.\n\nSee Using Mutex Objects for an example of CreateMutex."
    },
    {
        "link": "https://learn.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-createsemaphorea",
        "document": "To specify an access mask for the object, use the CreateSemaphoreEx function.\n\nA pointer to a SECURITY_ATTRIBUTES structure. If this parameter is NULL, the handle cannot be inherited by child processes.\n\nThe lpSecurityDescriptor member of the structure specifies a security descriptor for the new semaphore. If this parameter is NULL, the semaphore gets a default security descriptor. The ACLs in the default security descriptor for a semaphore come from the primary or impersonation token of the creator.\n\nThe initial count for the semaphore object. This value must be greater than or equal to zero and less than or equal to lMaximumCount. The state of a semaphore is signaled when its count is greater than zero and nonsignaled when it is zero. The count is decreased by one whenever a wait function releases a thread that was waiting for the semaphore. The count is increased by a specified amount by calling the ReleaseSemaphore function.\n\nThe maximum count for the semaphore object. This value must be greater than zero.\n\nThe name of the semaphore object. The name is limited to MAX_PATH characters. Name comparison is case sensitive.\n\nIf lpName matches the name of an existing named semaphore object, this function requests the SEMAPHORE_ALL_ACCESS access right. In this case, the lInitialCount and lMaximumCount parameters are ignored because they have already been set by the creating process. If the lpSemaphoreAttributes parameter is not NULL, it determines whether the handle can be inherited, but its security-descriptor member is ignored.\n\nIf lpName is NULL, the semaphore object is created without a name.\n\nIf lpName matches the name of an existing event, mutex, waitable timer, job, or file-mapping object, the function fails and the GetLastError function returns ERROR_INVALID_HANDLE. This occurs because these objects share the same namespace.\n\nThe name can have a \"Global\" or \"Local\" prefix to explicitly create the object in the global or session namespace. The remainder of the name can contain any character except the backslash character (\\). For more information, see Kernel Object Namespaces. Fast user switching is implemented using Terminal Services sessions. Kernel object names must follow the guidelines outlined for Terminal Services so that applications can support multiple users.\n\nThe object can be created in a private namespace. For more information, see Object Namespaces.\n\nIf the function succeeds, the return value is a handle to the semaphore object. If the named semaphore object existed before the function call, the function returns a handle to the existing object and GetLastError returns ERROR_ALREADY_EXISTS.\n\nIf the function fails, the return value is NULL. To get extended error information, call GetLastError.\n\nThe handle returned by CreateSemaphore has the SEMAPHORE_ALL_ACCESS access right; it can be used in any function that requires a handle to a semaphore object, provided that the caller has been granted access. If a semaphore is created from a service or a thread that is impersonating a different user, you can either apply a security descriptor to the semaphore when you create it, or change the default security descriptor for the creating process by changing its default DACL. For more information, see Synchronization Object Security and Access Rights.\n\nThe state of a semaphore object is signaled when its count is greater than zero, and nonsignaled when its count is equal to zero. The lInitialCount parameter specifies the initial count. The count can never be less than zero or greater than the value specified in the lMaximumCount parameter.\n\nAny thread of the calling process can specify the semaphore-object handle in a call to one of the wait functions. The single-object wait functions return when the state of the specified object is signaled. The multiple-object wait functions can be instructed to return either when any one or when all of the specified objects are signaled. When a wait function returns, the waiting thread is released to continue its execution. Each time a thread completes a wait for a semaphore object, the count of the semaphore object is decremented by one. When the thread has finished, it calls the ReleaseSemaphore function, which increments the count of the semaphore object.\n\nMultiple processes can have handles of the same semaphore object, enabling use of the object for interprocess synchronization. The following object-sharing mechanisms are available:\n• A child process created by the CreateProcess function can inherit a handle to a semaphore object if the lpSemaphoreAttributes parameter of CreateSemaphore enabled inheritance.\n• A process can specify the semaphore-object handle in a call to the DuplicateHandle function to create a duplicate handle that can be used by another process.\n• A process can specify the name of a semaphore object in a call to the [OpenSemaphore](/windows/win32/api/synchapi/nf-synchapi-opensemaphorew) or CreateSemaphore function.\n\nUse the CloseHandle function to close the handle. The system closes the handle automatically when the process terminates. The semaphore object is destroyed when its last handle has been closed.\n\nFor an example that uses CreateSemaphore, see Using Semaphore Objects."
    },
    {
        "link": "https://microfocus.com/documentation/silk-performer/205/en/silkperformer-205-webhelp-en/SILKPERF-48C5E4C9-CREATEMUTEXFUNCTION-REF.html",
        "document": "Uses the Win32 CreateMutexEx function to create a named mutex object. Mutex objects are used to serialize access to critical sections inside transactions for multiple concurrent users."
    },
    {
        "link": "https://scorpiosoftware.net/tag/internals",
        "document": "In Part 1 we’ve seen how to create a new kernel object type. The natural next step is to implement some functionality associated with the new object type. Before we dive into that, let’s take a broader view of what we’re trying to do. For comparison purposes, we can take an existing kernel object type, such as a Semaphore or a Section, or any other object type, look at how it’s “invoked” to get an idea of what we need to do.\n\nA word of warning: this is a code-heavy post, and assumes the reader is fairly familiar with Win32 and native API conventions, and has basic understanding of device driver writing.\n\nThe following diagram shows the call flow when creating a semaphore from user mode starting with the ( ) API:\n\nA process calls the officially documented , implemented in . This calls the native (undocumented) API , converting arguments as needed from Win32 conventions to native conventions. has no “real” implementation in user mode, as the kernel is the only one which can create a semaphore (or any other kernel object for that matter). NtDll has code to transition the CPU to kernel mode by using the machine instruction on x64. Before issuing a , the code places a number into the CPU register. This number – system service index, indicates what operation is being requested.\n\nOn the kernel side of things, the System Service Dispatcher uses the value in as an index into the System Service Descriptor Table (SSDT) to locate the actual function to call, pointing to the real implementation. Semaphores are relatively simple objects, so creation is a matter of allocating memory for a structure (and a header), done with , initializing the structure, and then inserting the object into the system ( ).\n\nMore complex objects are created similarly, although the actual creation code in the kernel may be more elaborate. Here is a similar diagram for creating a Section object:\n\nAs can be seen in the diagram, creating a section involves a private function ( ), but the overall process is the same.\n\nWe’ll try to mimic creating a DataStack object in a similar way. However, extending NtDll for our purposes is not an option. Even using to make the transition to the kernel is problematic for the following reasons:\n• There is no entry in the SSDT for something like , and we can’t just add an entry because PatchGuard does not like when the SSDT changes.\n• Even if we could add an entry to the SSDT safely, the entry itself is tricky. On x64, it’s not a 64-bit address. Instead, it’s a 28-bit offset from the beginning of the SSDT (the lower 4 bits store the number of parameters passed on the stack), which means the function cannot be too far from the SSDT’s address. Our driver can be loaded to any address, so the offset to anything mapped may be too large to be stored in an SSDT entry.\n• We could fix that problem perhaps by adding code in spare bytes at the end of the kernel mapped PE image, and add a trampoline call to our real function…\n\nNot easy, and we still have the PatchGuard issue. Instead, we’ll go about it in a simpler way – use (or the native ) to pass the parameters to our driver. The following diagram illustrates this:\n\nWe’ll keep the “Win32 API” functions and “Native APIs” implemented in the same DLL for convenience. Let’s from the top, moving from user space to kernel space. Implementing involves converting Win32 style arguments to native-style arguments before calling . Here is the beginning:\n\nNotice the similarity to functions like , , , etc. An optional name is accepted, as DataStack objects can be named.\n\nNative APIs work with s and , so we need to do some work to be able to call the native API:\n\nWe start by building an :\n\nIf a name exists, we wrap it in a . The security attributes are used, if provided. The most interesting part is the actual name (if provided). When calling a function like the following:\n\nThe object name is not going to be just “MySemaphore”. Instead, it’s going to be something like “\\Sessions\\1\\BaseNamedObjects\\MySemaphore”. This is because the Windows API uses “local” session-relative names by default. Our DataStack API should provide the same semantics, which means the base directory in the Object Manager’s namespace for the current session must be used. This is the job of . Here is one way to implement it:\n\nWe just need to do that once, since the resulting directory handle can be stored in a global/static variable for the lifetime of the process; we won’t even bother closing the handle. The native is used to open a handle to the correct directory and return it. Notice that for session 0, there is a special rule: its directory is simply “\\BaseNamedObjects”.\n\nThere is a snag in the above handling, as it’s incomplete. UWP processes have their own object directory based on their AppContainer SID, which looks like “\\Sessions\\1\\AppContainerNamedObjects\\{AppContainerSid}”, which the code above is not dealing with. I’ll leave that as an exercise for the interested coder.\n\nBack in – the session-relative directory handle is stored in the member. Now we can call the native API:\n\nIf we get a failed status, we convert it to a Win32 error with and call to make it available to the caller via the usual . Here is the full function for easier reference:\n\nNext, we need to handle the native implementation. Since we just call our driver, we package the arguments in a helper structure and send it to the driver via :\n\nWhere is coming from? When our DataStack.Dll is loaded into a process, we can open a handle to the device exposed by the driver (which we have yet to implement). In fact, if we can’t obtain a handle, the DLL should fail to load:\n\nuses the native to open a handle, as the driver does not provide a symbolic link to make it slightly harder to reach it directly from user mode. If returns false, the DLL will unload.\n\nNow we move to the kernel side of things. Our driver must create a device object and expose IOCTLs for calls made from user mode. The additions to are pretty standard:\n\nThe driver creates a single device object with the name “\\Device\\DataStack” that was used in to open a handle to that device. and are supported to make the driver usable. Finally, handling is set up ( ).\n\nThe job of is to propagate the data provided by helper structures to the real implementation of the native APIs. Here is the code that covers :\n\nis called with the unpacked arguments. The only trick here is the use of to check if the calling process is 32-bit. If so, 4 bytes should be copied back as the handle instead of 8 bytes.\n\nThe real work of creating a DataStack object (finally), falls on . First, we need to have a structure that manages DataStack objects. Here it is:\n\nThe details are not important now, since we’re dealing with object creation only. But we should initialize the structure properly when the object is created. The first major step is telling the kernel to create a new object of DataStack type:\n\nlooks like this:\n\nreturns the caller’s mode ( or enum values), and based off of that we ask to make the relevant probing and security checks. is our DataStack type object, is , our data structure. The last parameter is where the object pointer is returned.\n\nIf this succeeds, we need to initialize the structure appropriately, and then add the object to the system “officially”, where the object header would be built as well:\n\nis a helper function to initialize an empty DataStack:\n\nThis is it for and its chain of called functions. Handling is similar, and simpler, as the heavy lifting is done by the kernel.\n\nattempts to open a handle to an existing DataStack object by name:\n\nAgain, from a high-level perspective it looks similar to APIs like or . will make a call to the driver via , packing the arguments:\n\nFinally, the implementation of in the kernel is surprisingly simple:\n\nThe simplicity is thanks to the generic kernel API, which is not documented, but is exported, that attempts to open a handle to any named object:\n\nThat’s it for creating and opening a DataStack object. Let’s test it!\n\nAfter deploying the driver to a test machine, we can write simple code to create a DataStack object (named or unnamed), and see if it works. Then, we’ll close the handle:\n\nHere is what Process Explorer shows when the handle is open, but not yet closed:\n\nAfter opening the second handle (by name), the debugger reports two handles (different run):\n\nThe source code can be found here."
    },
    {
        "link": "https://github.com/7etsuo/windows-api-function-cheatsheets",
        "document": "\n• Allocate memory in the target process with\n• Write the DLL path to the allocated memory with\n• Get the address of using\n• Create a remote thread in the target process with , pointing to pass the address of as the parameter.\n• (Optional) Use or for alternative thread creation methods\n• Use application whitelisting to prevent unauthorized DLLs from loading\n• Use tools like Microsoft's Process Monitor to detect DLL injection attempts\n\nThis technique involves writing and executing malicious code in a remote process or the same process (self-injection).\n• Allocate memory in the target process with\n• Write the malicious code to the allocated memory with\n• Modify the thread context to point to the injected code with\n• Resume the thread with or\n• Use Endpoint Detection and Response (EDR) solutions to detect suspicious memory modifications\n\nSimilar to PE Injection but avoids using and . Involves writing a custom loader that can load a DLL from memory without using the standard Windows loader.\n• Create a file mapping of the DLL with\n• Map a view of the file with\n• Allocate memory in the target process with\n• Copy the DLL contents to the allocated memory with\n• Perform manual loading and relocation of the DLL in the target process\n• Process the relocation table:\n• Apply relocations based on the new base address\n• Resolve imports:\n• For each imported function, resolve its address using GetProcAddress\n• Write the resolved addresses to the IAT\n• Execute the DLL's entry point using one of the thread creation methods\n\nThis technique allows code execution in a specific thread by attaching to an Asynchronous Procedure Call (APC) queue. Works best with alertable threads (those that call alertable wait functions).\n• Create a snapshot of the system processes with\n• Enumerate processes and threads using , , , and\n• Allocate memory in the target process with\n• Write the malicious code to the allocated memory with\n• Queue an APC to the target thread with , pointing to the injected code\n• Use EDR solutions with capabilities to detect APC abuse\n\nThis technique \"drains out\" the entire content of a process and inserts malicious content into it.\n• Create a new process in a suspended state using with flag\n• Get the process information using\n• Unmap the original executable from the process using after unmapping the original executable, adjust the image base address in the PEB (Process Environment Block) to point to the new allocated memory.\n• Adjust the image base address in the PEB:\n• Use to read the PEB\n• Use to update it with the address of the newly allocated memory\n• Allocate memory in the target process with\n• Write the malicious executable to the allocated memory with\n• Update the thread context to point to the new entry point using and\n• Resume the main thread of the process with\n• Monitor for suspicious process creation patterns, especially with the flag\n• Use memory forensics tools to identify signs of process hollowing\n\nA variant of APC injection that works by splitting the malicious payload into separate strings and using atoms. this technique relies on the fact that atoms are shared across processes.\n• For each chunk, use to create a global atom\n• Queue an APC to the target thread with or\n• In the APC routine, use to retrieve the payload chunks\n• Assemble the payload in the target process memory\n• Execute the payload using or by queuing another APC\n• Monitor for unusual patterns of atom creation and retrieval\n• Use EDR solutions with capabilities to detect AtomBombing techniques\n• Employ runtime analysis to identify suspicious APC usage in combination with atom manipulation\n\nAn evolution of Process Hollowing that replaces the image before the process is created. this technique leverages the Windows Transactional NTFS (TxF) to temporarily replace a legitimate file with a malicious one during process creation.\n• Write the malicious payload to the transacted file\n• Create a section for the transacted file using\n• Create a process from the section using\n• Create a thread in the new process with\n• Rollback the transaction with to remove traces of the malicious file\n\nSimilar to Process Doppelgänging, but exploits the order of process creation and security checks. this technique exploits the fact that Windows performs security checks on the executable file before it starts executing the process.\n• Write the malicious payload to the file\n• Create a section for the file using\n• Create a process from the section using\n• Create a thread in the new process with\n• Implement file integrity monitoring to detect rapid changes in executable files\n• Use behavior-based detection to identify processes with mismatched file contents\n• Monitor for suspicious patterns of file creation, modification, and process creation\n\nThis technique uses hooking-related functions to inject a malicious DLL. this technique can also be used for API hooking, not just for injection.\n• Use to set a hook in the target process\n• Trigger the hook by sending a message with\n• Monitor for suspicious usage of , especially with global hooks\n• Use EDR solutions with capabilities to detect abnormal hook installations\n\nThis technique injects code into a process by using the Extra Windows Memory (EWM), which is appended to the instance of a class during window class registration. less common and might be detected by some security solutions.\n• Get the process ID of the window with\n• Allocate memory in the target process with\n• Write the malicious code to the allocated memory with\n• Use to modify the window's extra memory\n• Use EDR solutions with capabilities to detect EWM manipulation\n• Employ behavior-based detection to identify processes with unexpected changes in window properties\n\nThis technique is used to inject malicious code into processes with medium integrity level, such as explorer.exe. It works by enumerating windows and subclassing them. can be particularly effective for privilege escalation.\n• For each window, check for subclassed windows using and\n• Allocate memory in the target process with\n• Write the malicious code to the allocated memory with\n• Set a new property with to store the payload\n• Monitor for suspicious patterns of window enumeration and subclassing\n• Use EDR solutions with capabilities to detect propagate injection techniques\n• Employ behavior-based detection to identify processes with unexpected changes in window subclassing\n\nWhile not strictly an injection technique, heap spraying is often used in conjunction with other injection methods to facilitate exploit payload delivery. modern browsers and operating systems have implemented mitigations against this.\n• Fill these blocks with a combination of NOP sleds and the payload\n• Repeat this process to cover a large portion of the process's address space\n\nThis technique involves suspending a legitimate thread in a target process, modifying its execution context to point to malicious code, and then resuming the thread. saving and restoring the original thread context required to maintain process stability.\n• Get the thread context with\n• Allocate memory in the target process with\n• Write the malicious code to the allocated memory with\n• Modify the thread context to point to the injected code with\n• Monitor for suspicious patterns of thread suspension and resumption\n• Implement thread execution monitoring to detect unexpected changes in execution flow\n• Use EDR solutions with capabilities to detect thread hijacking techniques\n\nThis technique overwrites the memory of a legitimate module in the target process with malicious code, potentially bypassing some security checks. detected by integrity checks on loaded modules.\n• Get information about the target module using\n• Change the memory protection of the module to writable using\n• Overwrite the module's code section with malicious code using\n• Use EDR solutions with capabilities to detect module stomping techniques\n\nThis technique modifies the Import Address Table (IAT) of a process to redirect function calls to malicious code. detected by comparing the IAT entries with the actual function addresses in the target DLLs.\n• Locate the IAT of the target process\n• Identify the function to be hooked\n• Change the memory protection of the IAT to writable using\n• Replace the original function address with the address of the malicious function\n• Calculate the address of the IAT entry for the target function\n• Read the original function address from the IAT entry\n• Replace the original function address with the address of the malicious function\n• Use EDR solutions with capabilities to detect IAT hooking\n\nThis technique modifies the first few instructions of a function to redirect execution to malicious code. requires careful handling of multi-byte instructions and relative jumps.\n• Change the memory protection to writable using\n• Save the original instructions (usually 5 or more bytes)\n• Overwrite the beginning of the function with a jump to the malicious code\n• In the malicious code, execute the saved original instructions and then jump back to the original function\n• Use EDR solutions with capabilities to detect inline hooking\n• Employ runtime analysis to identify unexpected changes in function execution flow\n\nThis technique uses debugging APIs to inject code into a target process. can be detected by anti-debugging checks in the target process.\n• Attach to the target process as a debugger using\n• When a suitable event occurs, inject the malicious code using\n• Modify the thread context to execute the injected code\n• Monitor for suspicious use of debugging APIs\n• Use EDR solutions with capabilities to detect debugger-based injection\n\nThis technique involves replacing legitimate COM objects with malicious ones to execute code when the COM object is instantiated. used for persistence, not just for injection.\n• Modify the registry to replace the CLSID of a legitimate COM object with the malicious one\n• When the application calls , the malicious object will be instantiated instead\n• Monitor for suspicious registry modifications related to COM objects\n• Use application whitelisting to prevent unauthorized COM objects from loading\n\nThis technique involves creating a new section in a legitimate DLL and injecting code into it.\n• Copy the malicious code to the new section\n• Modify the DLL's PE headers to include the new section\n• Change the memory protection of the new section using\n• Monitor for suspicious patterns of DLL loading and memory allocation\n• Use EDR solutions with capabilities to detect phantom DLL hollowing\n\nThis technique abuses the SetProp/GetProp Windows API functions to achieve code execution.\n• Allocate memory for the payload using\n• Write the payload to the allocated memory using\n• Use to set a property on the window, with the payload address as the property value\n• Use to replace the original window procedure with the custom one\n• Trigger the execution by causing the window to enumerate its properties (e.g., by sending a message that causes a redraw)\n• Use EDR solutions with capabilities to detect PROPagate techniques\n• Employ behavior-based detection to identify processes with unexpected changes in window properties\n\nThis technique injects code into a process during its initialization, before the main thread starts executing.\n• Create a new process in suspended state using with flag\n• Allocate memory in the new process using\n• Write the payload to the allocated memory using\n• Queue an APC to the main thread using , pointing to the payload\n• Monitor for process creation with the flag\n• Use EDR solutions with capabilities to detect Early Bird injection techniques\n\nThis technique leverages the Windows Application Compatibility framework to inject code.\n• Write shim data to the database, including the payload and target application\n• The payload will be executed when the target application is launched\n• Use EDR solutions with capabilities to detect shim-based injection techniques\n\nThis technique uses memory-mapped files to inject code into a remote process.\n• Map a view of the file into the current process using\n• Write the payload to the mapped view\n• Use to map the view into the target process\n• Execute the payload in the target process\n• Monitor for suspicious patterns of file mapping and view creation\n• Use EDR solutions with capabilities to detect mapping injection techniques\n\nThis technique involves replacing a legitimate DLL in the KnownDlls cache with a malicious one.\n• Create a malicious DLL with the same name as a legitimate KnownDlls entry\n• Create a Section object for the malicious DLL:\n• Map a view of the section into memory\n• Write the malicious DLL content to the mapped view\n• Use with to add the malicious DLL to the KnownDlls cache\n• The malicious DLL will be loaded instead of the legitimate one by processes\n• Monitor for modifications to the KnownDlls cache\n• Use EDR solutions with capabilities to detect KnownDlls cache poisoning\n• Employ whitelisting and code signing verification for DLLs in the KnownDlls cache\n• Implement a robust Application Whitelisting strategy to prevent unauthorized executables and DLLs from running.\n• Use Windows Defender Exploit Guard or similar technologies to enable Attack Surface Reduction (ASR) rules.\n• Keep systems and software up-to-date with the latest security patches.\n• Utilize User Account Control (UAC) and principle of least privilege to limit the impact of successful injections.\n• Implement Network Segmentation to limit lateral movement in case of a successful attack.\n• Use Runtime Application Self-Protection (RASP) technologies to detect and prevent injection attempts in real-time.\n• Regularly perform threat hunting activities to proactively search for signs of injection techniques.\n• Implement and maintain a robust Security Information and Event Management (SIEM) system to correlate and analyze security events.\n• Conduct regular security awareness training for users to recognize and report suspicious activities.\n• Perform regular penetration testing and red team exercises to identify vulnerabilities and improve defenses against injection techniques."
    }
]