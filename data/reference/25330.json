[
    {
        "link": "https://socket.io/docs/v4",
        "document": "Socket.IO is a library that enables low-latency, bidirectional and event-based communication between a client and a server.\n\nThe Socket.IO connection can be established with different low-level transports:\n\nSocket.IO will automatically pick the best available option, depending on:\n• the capabilities of the browser (see here and here)\n\nYou can find more detail about that in the \"How it works\" section.\n\nAlthough Socket.IO indeed uses WebSocket for transport when possible, it adds additional metadata to each packet. That is why a WebSocket client will not be able to successfully connect to a Socket.IO server, and a Socket.IO client will not be able to connect to a plain WebSocket server either.\n\nIf you are looking for a plain WebSocket server, please take a look at ws or µWebSockets.js.\n\nThere are also discussions for including a WebSocket server in the Node.js core.\n\nOn the client-side, you might be interested in the robust-websocket package.\n\nThe Socket.IO library keeps an open TCP connection to the server, which may result in a high battery drain for your users. Please use a dedicated messaging platform like FCM for this use case.\n\nHere are the features provided by Socket.IO over plain WebSockets:\n\nThe connection will fall back to HTTP long-polling in case the WebSocket connection cannot be established.\n\nThis feature was the #1 reason people used Socket.IO when the project was created more than ten years ago (!), as the browser support for WebSockets was still in its infancy.\n\nEven if most browsers now support WebSockets (more than 97%), it is still a great feature as we still receive reports from users that cannot establish a WebSocket connection because they are behind some misconfigured proxy.\n\nUnder some particular conditions, the WebSocket connection between the server and the client can be interrupted with both sides being unaware of the broken state of the link.\n\nThat's why Socket.IO includes a heartbeat mechanism, which periodically checks the status of the connection.\n\nAnd when the client eventually gets disconnected, it automatically reconnects with an exponential back-off delay, in order not to overwhelm the server.\n\nThe packets are automatically buffered when the client is disconnected, and will be sent upon reconnection.\n\nSocket.IO provides a convenient way to send an event and receive a response:\n\nYou can also add a timeout:\n\nOn the server-side, you can send an event to all connected clients or to a subset of clients:\n\nThis also works when scaling to multiple nodes.\n\nNamespaces allow you to split the logic of your application over a single shared connection. This can be useful for example if you want to create an \"admin\" channel that only authorized users can join.\n\nMore on that here.\n\nThat's a fair question, since WebSockets are supported almost everywhere now.\n\nThat being said, we believe that, if you use plain WebSockets for your application, you will eventually need to implement most of the features that are already included (and battle-tested) in Socket.IO, like reconnection, acknowledgements or broadcasting.\n\nwill be sent as a single WebSocket frame containing with:\n• being the -ed version of the arguments array\n\nSo, a few additional bytes for each message, which can be further reduced by the usage of a custom parser.\n\nYou can find the details of the Socket.IO protocol here."
    },
    {
        "link": "https://stackoverflow.com/questions/9762528/documentation-for-socket-io",
        "document": "I'm trying to make a real time canvas kinda thing with simply Node and Socket.io, but I'm having considerable trouble.\n\nI don't know what anything means!\n\nEssentially, I'm coding it completely blind without any idea what in the heck I'm doing. Do you guys know where some good documentation of socket.io is?\n\nThanks for your answer."
    },
    {
        "link": "https://m.php.cn/faq/620280.html",
        "document": ""
    },
    {
        "link": "https://socket.io/docs/v2",
        "document": "Socket.IO is a library that enables real-time, bidirectional and event-based communication between the browser and the server. It consists of:\n• a Javascript client library for the browser (which can be also run from Node.js): Source | API\n\nThere are also several client implementation in other languages, which are maintained by the community:\n\nThe client will try to establish a WebSocket connection if possible, and will fall back on HTTP long polling if not.\n\nWebSocket is a communication protocol which provides a full-duplex and low-latency channel between the server and the browser. More information can be found here.\n\nSo, in the best-case scenario, provided that:\n• the browser supports WebSocket (97% of all browsers in 2020)\n• there is no element (proxy, firewall, ...) preventing WebSocket connections between the client and the server\n\nyou can consider the Socket.IO client as a \"slight\" wrapper around the WebSocket API. Instead of writing:\n\nYou will have, on the client-side:\n\nThe API on the server-side is similar, you also get an object which extends the Node.js EventEmitter class:\n\nSocket.IO provides additional features over a plain WebSocket object, which are listed below.\n\nBut first, let's detail what the Socket.IO library is not.\n\nSocket.IO is NOT a WebSocket implementation. Although Socket.IO indeed uses WebSocket as a transport when possible, it adds additional metadata to each packet. That is why a WebSocket client will not be able to successfully connect to a Socket.IO server, and a Socket.IO client will not be able to connect to a plain WebSocket server either.\n\nIf you are looking for a plain WebSocket server, please take a look at ws or uWebSockets.js.\n\nThere are also talks to include a WebSocket server in the Node.js core.\n\nOn the client-side, you might be interested by the robust-websocket package.\n\nIf you are new to the Node.js ecosystem, please take a look at the Get Started guide, which is ideal for beginners.\n\nElse, let's start right away! The server library can be installed from NPM:\n\nMore information about the installation can be found in the Server installation page.\n\nThen, let's create an file, with the following content:\n\nHere, a classic Node.js HTTP server is started to serve the file, and the Socket.IO server is attached to it. Please see the Server initialization page for the various ways to create a server.\n\nLet's create the file next to it:\n\nThe object on both sides extends the EventEmitter class, so:\n• sending an event is done with:\n• receiving an event is done by registering a listener:\n\nNow, let's detail the features provided by Socket.IO.\n\nConnections are established even in the presence of:\n\nFor this purpose, it relies on Engine.IO, which first establishes a long-polling connection, then tries to upgrade to better transports that are \"tested\" on the side, like WebSocket. Please see the Goals section for more information.\n\nUnless instructed otherwise a disconnected client will try to reconnect forever, until the server is available again. Please see the available reconnection options here.\n\nA heartbeat mechanism is implemented at the Engine.IO level, allowing both the server and the client to know when the other one is not responding anymore.\n\nThat functionality is achieved with timers set on both the server and the client, with timeout values (the pingInterval and pingTimeout parameters) shared during the connection handshake. Those timers require any subsequent client calls to be directed to the same server, hence the sticky-session requirement when using multiples nodes.\n\nAny serializable data structures can be emitted, including:\n• ArrayBuffer and Blob in the browser\n\nIn order to create separation of concerns within your application (for example per module, or based on permissions), Socket.IO allows you to create several Namespaces, which will act as separate communication channels but will share the same underlying connection."
    },
    {
        "link": "https://github.com/guyue88/hyoga-uni-socket.io",
        "document": "真机运行 TypeError: undefined is not an object (evaluating 'document.createElement')？\n\n 示例代码中："
    },
    {
        "link": "https://ably.com/topic/websocket-architecture-best-practices",
        "document": "If you’re building realtime application, you’re likely already familiar with the benefits of WebSockets—persistent, bidirectional, low-overhead communication, and near-universal availability.\n\nBut even if WebSocket is already on your radar, you might not yet have looked into WebSocket architecture best practices. Particularly if you’re more used to building request-response based applications with HTTP, then working with WebSocket requires some changes in your assumptions and the tools you use.\n\nThe good news is that this change is fairly straightforward. In this guide, we’ll explore the key considerations for designing an application architecture with WebSocket. We’ll cover both architectural and operational best practices to ensure scalability and long-term reliability. And, crucially, we’ll look at how WebSocket’s architectural needs differ from system design for HTTP.\n\nA brief overview of WebSocket vs HTTP HTTP’s stateless, request-response model is effectively the default pattern for client-server and intra-application communication. And so much of the tooling we use to build applications is designed around those assumptions. So, before we get into WebSocket architecture best practices, let’s put WebSocket and HTTP side by side to underscore how they differ. Higher latency due to need for constant connection setup Less resource-intensive as connections are short-lived In summary, the key difference with WebSocket is that it provides persistent, stateful connections, allowing both the client and server to send messages at any time. This is what makes it great for realtime communication, but it also means we face new challenges.\n\nEvery protocol and design pattern comes with its own set of pros and cons. For instance, HTTP’s statelessness makes it easy to scale horizontally, but it also requires workarounds—such as —to support the needs of web applications. Similarly, WebSocket system design is all about understanding the protocol’s characteristics well enough to know both the challenges it presents and how to account for them in your application architecture. Let’s look at three of the main challenges that WebSocket presents. Horizontal scaling (adding more servers) is necessary as user numbers grow Each connection maintains state between client and server Harder to load balance, as connections must persist to the same server, unlike stateless connections where clients can connect to any server Requires more resources to track and maintain connection state Requires manual reconnection management, such as heartbeats and pings Need to manage potential data loss during disconnections and pay attention to factors such as message ordering \n\nNone of these makes WebSocket any less suitable for building realtime application architectures. In fact, they’re the very thing that makes them so well suited. But the trade-off is that you need to work them into your application architectures. And that’s especially true as your application scales.\n\nHow these challenges evolve with scale As an industry, we have well-practiced ways of scaling HTTP connections. That’s because each HTTP request is independent. You can simply add more servers and use a load balancer to distribute incoming traffic. WebSocket’s long-lived, stateful connections require more intentional planning. That’s not to say it’s impossible or even especially hard. But you do need to cater to the specifics of WebSocket’s architecture to scale as your system grows. Here’s why scaling WebSocket requires a different type of planning than scaling HTTP traffic:\n• None State: Each client must stay connected to the same server to maintain session state, which complicates load balancing. Unlike stateless HTTP, WebSocket connections can’t be freely distributed across servers. As your system scales, this can translate challenges around:\n• None Hot spots: Too much load may get directed to a few instances, leading to uneven resource usage and potential bottlenecks.\n• None State synchronization: Redistributing the load when clients reconnect can ease hot spots, but it introduces the need to synchronize state across servers, adding complexity to your architecture.\n• None Failover difficulties: One key benefit of distributed systems, redundancy, becomes harder to achieve with WebSocket. If a server fails, switching clients to a new server without losing session data requires inter-server data synchronization, further complicating your architecture.\n• None Message integrity and ordering: As more servers and redundancy are introduced, keeping messages in the right order and ensuring they’re delivered without duplication becomes a challenge, especially for critical realtime applications. Many WebSocket-based systems accept that duplication will happen and handle it with deduplication. Others, such as Ably, implement strict processes to guarantee exactly-once delivery.\n• None Backpressure management: With thousands or millions of connected clients, the flow of data around your WebSocket system can scale to billions or trillions of messages. To avoid overload, you’ll need to implement flow control systems such as queues and rate limits.\n• None N-Squared problem: As the number of connections increases, the potential interactions between clients grow exponentially. For example, in a realtime chat system, if each user can message any other user, the number of potential message paths scales quadratically. With 100 users, you have 10,000 possible interactions. With 1,000 users, that number jumps to 1,000,000. Now, consider that each message could trigger multiple responses or reactions, each of which creates additional traffic. These interactions don’t just increase linearly. They grow dramatically. That creates significant strain on server resources and network bandwidth if left to grow without optimization. There are WebSocket implementations handling billions of messages between millions of clients. So, how do they do it?\n\nSharding is an idea borrowed from databases, where it enables scaling by splitting large datasets into smaller pieces (or shards) and assigning each piece to a different server. For WebSocket, the idea is similar: sharding breaks the client namespace into smaller segments, with each server managing a portion of that namespace. For example, you might assign all clients whose username starts with ‘A’ to one server, those starting with ‘B’ to another, and so on. However, this can lead to hot spots since certain letters are more common in some languages and regions than others. So, how does sharding WebSocket shape-up in practice?\n• None Horizontal scalability: It’s easy to add and remove shards as needs change.\n• None Fault isolation: Failures in one shard shouldn’t impact others.\n• None Hot shards: Some shards may become overloaded and need rebalancing.\n• None Shard redistribution: When you need to add or remove shards, the system needs to update the sharding scheme on the client-side and then redistribute sessions across shards.\n• None Siloed state: Harder for clients connected to different servers to communicate. Also harder to move clients between shards without losing state. \n\nSharding’s biggest issue is the risk of creating silos within your system. For example, in a chat application, if users from the US all connect to shard 1 and users from Japan connect to shard 2, what happens when someone from Tokyo wants to chat with someone in Chicago? In effect, the sharded system means that you have two or more entirely separate chat servers and there’s no way for those two people to chat with each other. The solution is to share state updates between shards. That way, users shouldn’t ever notice that the sharding exists. But it introduces additional complexity. Sharing state across shards can lead to data integrity and ordering issues. And, of course, some part of each shard’s resources will be dedicated to backend synchronization, meaning you’ll need more shards than otherwise. Any time you introduce more than one WebSocket server, you’ll need to consider state synchronization between those servers. But issues like hot shards and resharding are more likely to occur in sharded systems. Using a load balancer, instead of a sharding scheme, is one way to address that.\n\nIf traditional HTTP load balancing isn’t well-suited to WebSocket because it’s designed for short-lived, stateless connections, is there a way to adapt the approach to suit WebSocket’s persistent connections? One way is to make sure that specific clients connect to the same server every time they reconnect. These are sticky sessions. Sticky sessions are different to shards because the stickiness lasts only so long. Usually for the duration of a session. That way, the client doesn’t need to know the sharding scheme but just where to find the load balancer. Here’s how it works: once a client establishes a connection with a server, any subsequent reconnections are directed to the same server. This avoids the need to synchronize session state across multiple servers. While this helps maintain session continuity, it also introduces some challenges. The load balancer needs to track which client belongs to which server, which adds complexity and can make that load balancer into a single point of failure. And if the assigned “sticky” server goes down, there’s a chance of some data loss depending on how robust the inter-server data sharing is. So, what are the pros and cons of sticky sessions?\n• None Session affinity: Clients reconnect to the same server, keeping session state intact.\n• None Greater flexibility: There’s no need to maintain a sharding scheme or to reshard when scaling.\n• None Session persistence overhead: Managing sticky sessions requires an additional tool in the form of the load balancer.\n• None State sharing: Like sharded systems, there’s an additional resource overhead to share data between server instances.\n• None Single point of failure: If the load balancer fails then that shouldn’t affect open connections but could prevent clients from reconnecting. You can add more load balancers to reduce this risk. Sticky sessions have a lot in common with sharding. However, the load balancer simplifies the architecture and makes it easier to scale up or down by shielding the clients from the precise make-up of the back-end.\n\nhelps scale WebSocket architectures by taking the problem of inter-server communication and making it the hero of the story. Rather than thinking of keeping servers in sync as a complication of scaling, pub/sub makes it a feature. In this approach, instead of each server needing to constantly share state with others, messages are published to a central system and then distributed to subscribers. This way, WebSocket servers focus on managing connections, while the pub/sub system takes care of ensuring that messages get to the right clients. For example, in a realtime chat app, rather than having every WebSocket server manage both connections and message routing, the servers handle the connections and leave the pub/sub system to broadcast messages to all clients subscribed to a chat room or channel. By offloading this responsibility, pub/sub allows your architecture to scale without requiring every server to stay perfectly synchronized.\n• None Decouples connections from messaging: Only handles connections, leaving messaging to the pub/sub system.\n• None Increased complexity: Adds an extra layer of infrastructure to manage.\n• None Latency overhead: Pub/sub adds extra latency, especially if not optimized.\n• None Bottlenecks: The pub/sub system itself can become a bottleneck if not well managed. Pub/sub offers a scalable way to handle message distribution by turning inter-server communication into a strength rather than a complication. By decoupling message handling from connection management, it allows your WebSocket servers to focus on what they do best—managing connections—while the pub/sub layer ensures messages reach the right clients. But architecture is only a part of the solution to scaling WebSocket-based systems. There are also several operational best practices to consider.\n\nShould you build or buy the functionality to scale WebSocket? Creating and maintaining an application architecture that relies on real-time communication requires more planning and engineering effort than a traditional request-response model. As we’ve seen, maintaining state across multiple clients and servers consumes significant computing resources and places greater demands on your engineering team. As you scale, these challenges don’t just increase—they grow non-linearly. It’s not just the potential for a quadratic explosion in traffic due to the n-squared problem, but also the need to maintain a responsive, fault-tolerant backend across multiple servers. So the question becomes whether or not you should build your own solution in-house or, instead, take advantage of a ready-made platform that solves both the problems you have today and that you might have as your application grows.\n• None Realtime communication is time consuming: Building and maintaining a distributed, realtime system will suck-up engineering resources and money that you could otherwise put into delivering the features your users need. shows that projects like this rarely come in on time or under budget.\n• None It’s also hard: Without extensive prior experience, even the best engineering teams can find it hard to build realtime communications platforms that scale. As we saw above, this isn’t just about implementing WebSocket but it could be a case of building a pub/sub messaging system.\n• None Control is an illusion: One reason for developing a system in-house might be to build precisely what you need. But time and resource constraints mean that teams often end-up compromising and building a lesser solution. Using a realtime platform-as-a-service (PaaS) you can have the best of both worlds, in that you build the solution you need with building blocks created and maintained by specialists."
    },
    {
        "link": "https://medium.com/voodoo-engineering/websockets-on-production-with-node-js-bdc82d07bb9f",
        "document": "In this article, we will use the ”ws” module to illustrate some points but the principles remain the same regardless of the library used. I wrote this article to create a kind of checklist about what to keep in mind before release a project using Websocket and Node.js.\n\nMost of the time you will find a lot of great articles to learn how to implement and use Websockets. It shows you examples of very basic applications using real-time communication.\n\nBut what happens in real life? When you release an API on your production you must take into account more than just if your code works. You monitor your production, you use CI, a logging system (I really hope you do!), etc.\n\nThis is the same thing for Websockets. You should be careful about some important points.\n\nJWT is a powerful tool to manage security on API but it works for Websocket based system too. It’s as simple as :\n• Server-side: before each connection, check the token inside headers.\n\nLike HTTP, WS protocol has its secure version, called WSS. On your server, you should configure SSL and a different port as you do for HTTPS. On the client-side just use wss:// instead of ws://.\n\nMost of the time, a WS connection will stay idle after the connection is established. Except when you use it for business logic, and for the keep-alive protocol (ping/pong requests), a Websocket doesn’t use a lot of resources.\n\nSetting up an autoscaling system based on memory and/or CPU is not always the best idea and this is why automatically scaling a WebSocket application is not really easy.\n\nEven the number of requests per server is not a good indicator because your connections are stateful, and every user will not reconnect very often. The best way to do it is to scale on open connections per server. You can have access to this value with CloudWatch if you use AWS for example.\n\nAnother thing to keep in mind is the tuning of your instances. The best way to handle a lot of persistent connections is to increase some values of your operating system and/or your application. For Node.js under a Linux based OS, you can refer to this great article: https://blog.jayway.com/2015/04/13/600k-concurrent-websocket-connections-on-aws-using-node-js/\n\nWhen working with Websockets, you build an event-based system. The best solution to scale your backend with such a system is to use a message broker. It will allow you to work with a powerful messaging pattern called Pub/Sub. A lot of technologies support this kind of pattern like Redis, RabbitMQ or Kafka. The good news is most of them are managed by Cloud providers and can scale automatically.\n\nA common issue when you work with WebSocket is broken connections. It appears when one of the endpoints (client or server) does not respond, or when it’s not reachable anymore. To manage this we need a logic on both server-side and client-side to gracefully close the connection. The idea is very simple: create a kind of heartbeat function to check periodically if a connection is still alive. Otherwise, close the connection.\n\nSome libraries, like WS, do not always provide a mechanism to automatically reconnect to the server. You will probably need this feature if your backend unexpectedly restarts (which can happen after each deployment ;)). Here we just need to automatically reconnect the client after it catches a close event.\n\nIf your connections have a long life, which is probably the case if you use Websocket, then you should refresh them (basically close them and open a new one). This is useful when you do some stuff when the connection is established and if you want the client to be up to date with the server. Or if you want to use another token if it expires soon.\n\nThere is no advice here on how to do it because it highly depends on your business logic. Anyway, a good recommendation is to refresh the connection every hour then you can change this interval if necessary.\n\nMost APM solutions don’t support WebSocket monitoring, they are mainly focused on classical request/response through HTTP protocol. They are well designed for API and web servers.\n\nAnyway, even if your APM doesn’t support Websocket instrumentation, you can use custom transactions and/or custom attributes to do it.\n\nSee how with elastic APM or with NewRelic agent.\n\nNow you can see your events in Kibana:"
    },
    {
        "link": "https://community.sanicframework.org/t/websockets-documentation-and-best-practices/972",
        "document": "So I’m writing a real-life chat app as part of a bigger app, and I’d love to help make Sanic’s WebSockets documentation better (IMHO it can be significantly improved, eg there’s this gist by Adam https://gist.github.com/ahopkins/5b6d380560d8e9d49e25281ff964ed81 and a small section in the documentation- but this info might be not quite enough for a commercial product).\n\n I read through the documentation and discussion, and here are two issues for which I am confused:\n• While I understand that Adam said that Sanic is not opinionated(Overrride websocket events like Open, error, message,close using sanic - #5 by fyndpurav) in the context of WebSockets, I’m still not sure if my current approach is viable/principled.\n\nIn particular, since Websocket is bi-directional,\n\n For my app I want to send messages to the client and get “acks” from the client, eg acknowledge receiving a particular message.\n\n So for every message, there’s a unique ack id attached, and the client sends the server back an ack with the message’s specific ack if received.\n\n For simplicity (see my confusion regarding pub/sub in my second question) and although it’s ugly, for now, let’s just use a single worker and a dict of connected_websockets.\n\nThis is how i register a websocket from the client:\n\nFrom my understanding of Websockets documentation, when the register_websocket handler finishes, the WebSocket closes automatically. This is the reason I have this line:\n\n await websocket.keepalive_ping()\n\nAlso notice that I’m calling the task get_acks so that someone will handle the incoming acks from the client. Here’s what it looks like:\n\nI’m not sure if my approach is principled. Something feels off - and there’s no real-life example or tutorial on this matter (I’d love to write it with you guys).\n\nAs I read through Adam’s gist example, I realized that I don’t fully understand what will happen when using pub/sub.\n\n-To my understanding, each worker process may get any client (in the gist example by Adam, a few workers might have the same channel with different clients for example, right?)\n\nFor simplicity let’s look at a private chat app, eg assume channel_name = <user_id> and each such “channel” may have a single user in it or no users in it.\n\n You recommend using pub/sub, in that paradigm a publisher might not know if there are any subs. So it seems like the only way for me to know if the client got the message through a Websocket (otherwise I send the message via a different push mechanism, in my case FCM) is to use some kind of acks mechanism, where I’ll have to handle Redis synchronization(since one worker might remove some ack from the same key[user_id] while another adds some ack to the same key). And yet, this feels wrong. Your advice?"
    },
    {
        "link": "https://medium.com/@rameshkannanyt0078/understanding-event-stream-types-and-best-practices-for-websocket-mechanisms-with-code-examples-a07c3c5aa9ba",
        "document": "WebSockets are the backbone of real-time communication in modern applications. From live chat and real-time updates to collaborative tools, they help deliver seamless experiences to users. However, to take full advantage of WebSockets, it’s essential to understand event stream types and follow best practices to optimize performance. Let’s dive deeper, explore different event stream types, and learn how to apply WebSocket mechanisms with code examples.\n\nEvent streams are continuous data flows between the server and the client. Depending on the use case, these streams can be categorized into several types. Let’s explore each type with a brief example:\n• Characteristics: Data flows at regular intervals or whenever there’s a change.\n• Challenge: Ensuring efficient handling of regular updates without overwhelming the client.\n• Example: Notifications for new messages, alerts, or events.\n• Characteristics: Data is transmitted when a specific event or condition…"
    },
    {
        "link": "https://stackoverflow.com/questions/21496114/websocket-best-practice",
        "document": "Since there is a single 'onmessage' event fired, it would seem cleanest to have a single handler for this. Otherwise things can get messy very quickly, since there is no central place where it's apparent what happens once the event fires.\n\nAdditionally, with a multitude of handlers, that's potentially a lot of code which all gets called on each message. This may be uncritical for a lot of use cases, but with high message frequencies and/or time-critical handling, having a single function seems the more efficient solution.\n\nIncidentially, a single handler function is what Mozilla has in its WebSocket tutorial"
    }
]