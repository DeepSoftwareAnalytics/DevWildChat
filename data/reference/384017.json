[
    {
        "link": "https://numpy.org/doc/2.1/reference/generated/numpy.linalg.norm.html",
        "document": "This function is able to return one of eight different matrix norms, or one of an infinite number of vector norms (described below), depending on the value of the parameter.\n\nInput array. If axis is None, x must be 1-D or 2-D, unless ord is None. If both axis and ord are None, the 2-norm of will be returned. Order of the norm (see table under ). inf means numpy’s object. The default is None. If axis is an integer, it specifies the axis of x along which to compute the vector norms. If axis is a 2-tuple, it specifies the axes that hold 2-D matrices, and the matrix norms of these matrices are computed. If axis is None then either a vector norm (when x is 1-D) or a matrix norm (when x is 2-D) is returned. The default is None. If this is set to True, the axes which are normed over are left in the result as dimensions with size one. With this option the result will broadcast correctly against the original x. Norm of the matrix or vector(s).\n\nFor values of , the result is, strictly speaking, not a mathematical ‘norm’, but it may still be useful for various numerical purposes.\n\nThe following norms can be calculated:\n\nThe Frobenius norm is given by [1]:\n\nThe nuclear norm is the sum of the singular values.\n\nBoth the Frobenius and nuclear norm orders are only defined for matrices and raise a ValueError when .\n\nUsing the axis argument to compute vector norms:\n\nUsing the axis argument to compute matrix norms:"
    },
    {
        "link": "https://numpy.org/devdocs/reference/generated/numpy.linalg.norm.html",
        "document": "This function is able to return one of eight different matrix norms, or one of an infinite number of vector norms (described below), depending on the value of the parameter.\n\nInput array. If axis is None, x must be 1-D or 2-D, unless ord is None. If both axis and ord are None, the 2-norm of will be returned. Order of the norm (see table under for what values are supported for matrices and vectors respectively). inf means numpy’s object. The default is None. If axis is an integer, it specifies the axis of x along which to compute the vector norms. If axis is a 2-tuple, it specifies the axes that hold 2-D matrices, and the matrix norms of these matrices are computed. If axis is None then either a vector norm (when x is 1-D) or a matrix norm (when x is 2-D) is returned. The default is None. If this is set to True, the axes which are normed over are left in the result as dimensions with size one. With this option the result will broadcast correctly against the original x. Norm of the matrix or vector(s).\n\nFor values of , the result is, strictly speaking, not a mathematical ‘norm’, but it may still be useful for various numerical purposes.\n\nThe following norms can be calculated:\n\nThe Frobenius norm is given by [1]:\n\nThe nuclear norm is the sum of the singular values.\n\nBoth the Frobenius and nuclear norm orders are only defined for matrices and raise a ValueError when ."
    },
    {
        "link": "https://numpy.org/doc/stable/reference/routines.linalg.html",
        "document": "The NumPy linear algebra functions rely on BLAS and LAPACK to provide efficient low level implementations of standard linear algebra algorithms. Those libraries may be provided by NumPy itself using C versions of a subset of their reference implementations but, when possible, highly optimized libraries that take advantage of specialized processor functionality are preferred. Examples of such libraries are OpenBLAS, MKL (TM), and ATLAS. Because those libraries are multithreaded and processor dependent, environmental variables and external packages such as threadpoolctl may be needed to control the number of threads or specify the processor architecture.\n\nThe SciPy library also contains a submodule, and there is overlap in the functionality provided by the SciPy and NumPy submodules. SciPy contains functions not found in , such as functions related to LU decomposition and the Schur decomposition, multiple ways of calculating the pseudoinverse, and matrix transcendentals such as the matrix logarithm. Some functions that exist in both have augmented functionality in . For example, can take a second matrix argument for solving generalized eigenvalue problems. Some functions in NumPy, however, have more flexible broadcasting options. For example, can handle “stacked” arrays, while accepts only a single square array as its first argument.\n\nThe term matrix as it is used on this page indicates a 2d object, and not a object. The latter is no longer recommended, even for linear algebra. See the matrix object documentation for more information.\n\nLinear algebra on several matrices at once# Several of the linear algebra routines listed above are able to compute results for several matrices at once, if they are stacked into the same array. This is indicated in the documentation via input parameter specifications such as . This means that if for instance given an input array , it is interpreted as a “stack” of N matrices, each of size M-by-M. Similar specification applies to return values, for instance the determinant has and will in this case return an array of shape . This generalizes to linear algebra operations on higher-dimensional arrays: the last 1 or 2 dimensions of a multidimensional array are interpreted as vectors or matrices, as appropriate for each operation."
    },
    {
        "link": "https://numpy.org/doc/2.2/reference/routines.linalg.html",
        "document": "The NumPy linear algebra functions rely on BLAS and LAPACK to provide efficient low level implementations of standard linear algebra algorithms. Those libraries may be provided by NumPy itself using C versions of a subset of their reference implementations but, when possible, highly optimized libraries that take advantage of specialized processor functionality are preferred. Examples of such libraries are OpenBLAS, MKL (TM), and ATLAS. Because those libraries are multithreaded and processor dependent, environmental variables and external packages such as threadpoolctl may be needed to control the number of threads or specify the processor architecture.\n\nThe SciPy library also contains a submodule, and there is overlap in the functionality provided by the SciPy and NumPy submodules. SciPy contains functions not found in , such as functions related to LU decomposition and the Schur decomposition, multiple ways of calculating the pseudoinverse, and matrix transcendentals such as the matrix logarithm. Some functions that exist in both have augmented functionality in . For example, can take a second matrix argument for solving generalized eigenvalue problems. Some functions in NumPy, however, have more flexible broadcasting options. For example, can handle “stacked” arrays, while accepts only a single square array as its first argument.\n\nThe term matrix as it is used on this page indicates a 2d object, and not a object. The latter is no longer recommended, even for linear algebra. See the matrix object documentation for more information.\n\nLinear algebra on several matrices at once# Several of the linear algebra routines listed above are able to compute results for several matrices at once, if they are stacked into the same array. This is indicated in the documentation via input parameter specifications such as . This means that if for instance given an input array , it is interpreted as a “stack” of N matrices, each of size M-by-M. Similar specification applies to return values, for instance the determinant has and will in this case return an array of shape . This generalizes to linear algebra operations on higher-dimensional arrays: the last 1 or 2 dimensions of a multidimensional array are interpreted as vectors or matrices, as appropriate for each operation."
    },
    {
        "link": "https://docs.vultr.com/python/third-party/numpy/linalg/norm",
        "document": "The function in Python is a powerful tool provided by the NumPy library, primarily used to calculate the norm of a vector or matrix. This method supports various norms, making it extremely versatile for scientific computing. Norm calculations are fundamental in numerous mathematical and engineering computations, particularly in operations involving vectors and matrices.\n\nIn this article, you will learn how to leverage the function to compute vector norms. Discover how to apply this function in different scenarios and understand the impact of various norm types on the computation.\n• None Define a vector for which the norm is to be calculated.\n• None Use the function to compute the Euclidean norm. This code snippet calculates the Euclidean norm (also known as L2 norm) for the vector . The result is , which is the straight-line distance from the origin to the point represented by the vector.\n• None Set up a vector whose Manhattan norm you wish to find.\n• None Using , specify the parameter to calculate the L1 norm. Here, the Manhattan norm (or L1 norm) for the vector is calculated. The L1 norm sums the absolute values of the components, resulting in .\n• None Specify within the function to execute this computation. For the vector , the infinity norm calculates the maximum absolute value among the vector's components, which is in this case.\n\nThe function from the module is essential for calculating various types of norms for vectors and matrices. Whether it's the straightforward Euclidean norm, the summative Manhattan norm, or the maximum-seeking infinity norm, this function is equipped to handle them efficiently. By mastering the function, streamline complex mathematical tasks involving vector and matrix operations, ultimately refining analytical capabilities and computational accuracy in Python projects."
    },
    {
        "link": "https://dev.to/sajal2692/coding-k-means-clustering-using-python-and-numpy-fg1",
        "document": "For the day-to-day work of a Machine Learning Engineer or Data Scientist, it is common to use popular ML frameworks like Scikit-learn, Pytorch, etc. These frameworks provide us with highly optimized implementations of most ML algorithms to use out of the box.\n\nDespite this, it's a good exercise to try and code some of the basic algorithms from scratch, or using just NumPy. Writing code helps solidify our conceptual understanding of the algorithms, and improves our coding ability. Implementing ML algorithms without using frameworks is also a popular interview exercise. Thus, it's best to be able to code algorithms such as K-Means, K Nearest Neighbours, Linear Regression and Logistic Regression.\n\nIn this post, we'll implement the K-means clustering algorithm. The code is adapted from multiple sources listed in the references at the bottom, but presented in a way to\n\n represent the block-by-block process of coding something relatively complex.\n\nK-means clustering is an unsupervised learning algorithm, which groups an unlabeled dataset into different clusters. The \"K\" refers to the number of pre-defined clusters the dataset is grouped into.\n\nWe'll implement the algorithm using Python and NumPy to understand the concepts more clearly.\n• max_iterations = max number of iterations to run the algorithm for\n\nPlainly, the algorithm entails the following steps:\n• Randomly initialize K cluster centroids i.e. the center of the clusters.\n• Repeat till convergence or end of max number of iterations:\n• For samples i=1 to m in the dataset:\n• For cluster k=1 to K:\n• Find new cluster centroids by calculating the mean of the points assigned to cluster k.\n\nWe will define the needed functions as and when we require them.\n\nAs a starting point, we'll initialize the K cluster centoids by picking K samples at random from the dataset X.\n\nNote that this method of initialization can result in different clusters being found in different runs of the algorithm. The clusters will also depend on the location of the initial centroids.\n\nA smarter initialization mehtod, which produces more stable clusters, while maximizing the distance between a centroid to other centroids is the k-means++ algorithm. We won't be covering it here, but feel free to read up on it. K-means++ is the initialization algorithm used in Scikit-learn's implementation.\n\nIn order to find the closest centroid for a given sample x, we can use Euclidean Distance between a given centroid and x.\n\nThe euclidean distance between two points, p and q in Euclidean n-space is given by the formula:\n\nThis can be adapted by thinking in terms of two vectors x1 and x2:\n\nWe can also use the calculate the same by taking the L2 norm of the difference between the two vectors. This can be accomplished using NumPy:\n\n3. Finding the closest centroid to a given data point\n\nWe can find the closest centriod for a given data point by iterating through the centroids and picking the one with the minimum distance.\n\nAssign the samples to closest centroids to create the clusters:\n\nCompute the means of cluster to find new centroids.\n\nNumPy axes can be tricky if you're just starting out. This article is an excellent refresher.\n\nLet's build a function that can run the K-means algorithm for the required number of iterations, or till convergence.\n\nTo test our implementation, we can use Scikit-learn's function.\n\nTo plot the clusters in 2D, we can use the plotting function from ML-From-Scratch Github repository. We'll plot the clusters calculated by our implementation,\n\n and the ones returned by Scikit-learn.\n\nAgain, the clusters can depend on the initialization points of centroids, but this time it looks like our implementation was able to find the correct clusters.\n\nIn this post, we saw how we can implement K-means clustering algorithm from scratch using Python and NumPy. Be sure to brush up other concepts and implementation before giving your next ML interview!\n\nPlease check out my website for more machine learning projects: https://sajalsharma.com\n• ML From Scratch - An excellent Github repository containing implementations of many machine learning models and algorithms. Easy to understand and highly recommended.\n• Code ML Algorithms from Scracth - A good blog post similar to this one, echoing the sentiment that this type of exercise is common in ML interviews."
    },
    {
        "link": "https://medium.com/@juanc.olamendy/back-to-basics-mastering-k-means-clustering-with-numpy-ae7e6f1cb9a3",
        "document": "Imagine you’re standing in front of a massive, chaotic pile of colorful marbles.\n\nYour task? Organize them into distinct groups based on their similarities.\n\nNow, picture an intelligent algorithm that can do this for you, not just with marbles, but with complex, multi-dimensional data points.\n\nWelcome to the world of K-Means Clustering, a powerful unsupervised machine learning technique that’s revolutionizing data analysis across industries.\n\nIn this article, we’ll delve deep into the mechanics of K-Means Clustering, explore its implementation using NumPy, and provide you with the knowledge to apply it effectively in real-world scenarios.\n\nK-Means Clustering is an unsupervised machine learning algorithm used to partition a dataset into K distinct, non-overlapping clusters.\n\nIt’s like having a smart assistant that can look at your data and say, “I see K different groups here.”\n\nThe algorithm’s goal is simple yet powerful: minimize the variance within each cluster.\n\nIt achieves this by iteratively assigning data points to clusters based on the nearest mean (centroid) and updating these centroids based on the current cluster memberships.\n\nAt its heart, K-Means operates on a straightforward principle:\n• Assign each data point to the nearest centroid.\n\nLet’s dive into the key mathematical components that make this algorithm tick.\n\nThe cornerstone of K-Means is the distance metric used to determine similarity between points.\n\nFor two points in n-dimensional space, p = (p1, p2, …, pn) and q = (q1, q2, …, qn), the Euclidean distance is given by:\n\nThis formula quantifies how “far apart” two points are in the feature space.\n\nNow that we understand the theory, let’s roll up our sleeves and implement K-Means using NumPy.\n\nThis implementation will give you a deep, hands-on understanding of how the algorithm works.\n\nThis implementation encapsulates the core K-Means algorithm in a class.\n\nThe method sets up the basic parameters:\n\nThe method is where the magic happens:\n• It iteratively assigns points to clusters and updates centroids.\n• It checks for convergence or stops after .\n\nThe method computes the Euclidean distances between points and centroids.\n\nThis is a critical part of the algorithm, determining which cluster each point belongs to.\n\nThe method allows us to assign new data points to clusters based on the trained model.\n\nWhile our initial implementation is functional, there’s always room for improvement.\n\nLet’s explore some optimizations that can significantly boost the performance of our K-Means algorithm.\n\nOne of the most computationally intensive parts of K-Means is calculating distances.\n\nWe can leverage NumPy’s broadcasting capabilities to perform this calculation more efficiently:\n\nX[:, np.newaxis, :] reshapes the data points to have an extra dimension, resulting in shape (n_samples, 1, n_features).\n\nThe subtraction X[:, np.newaxis, :] — centroids[np.newaxis, :, :] leverages broadcasting to compute differences between each data point and each centroid, resulting in a shape (n_samples, n_clusters, n_features).\n\nSquaring the differences ** 2 prepares the data for Euclidean distance calculation. And .sum(axis=2) aggregates the squared differences across features, yielding squared distances with shape (n_samples, n_clusters).\n• Vectorization: Eliminates the need for explicit Python loops, enhancing speed.\n• Readability: Provides a concise and clear implementation of distance calculations.\n\nIn order to integrate the Optimized Distance Function into our KMeans class, we can modify the code as follows:\n\nMarketers use K-Means to group customers based on purchasing behavior, demographics, and other attributes.\n\nThis segmentation allows for targeted marketing strategies and personalized customer experiences.\n\nK-Means can be used for lossy image compression by reducing the number of colors in an image:\n• Treat each pixel as a point in 3D space (RGB values).\n• Replace each pixel’s color with its cluster centroid.\n\nThis technique can significantly reduce file size while maintaining visual quality.\n\nK-Means can help identify unusual patterns in network traffic:\n• Flag data points that are far from all cluster centroids as potential anomalies.\n\nThis approach can detect novel cyber threats that signature-based systems might miss.\n\nWhile K-Means is powerful, it’s not a one-size-fits-all solution. Understanding its limitations is crucial for effective application.\n\nThe algorithm’s results can vary depending on the initial centroid placement. To mitigate this:\n• Run the algorithm multiple times with different initializations.\n• Use techniques like K-Means++ for smarter centroid initialization.\n\nK-Means assumes that clusters are spherical and equally sized. This can lead to poor results when:\n• Clusters have significantly different sizes or densities\n\nIn such cases, consider alternatives like DBSCAN or Gaussian Mixture Models.\n• Use techniques like one-hot encoding to convert categories to numerical values.\n• Consider specialized algorithms for categorical data, like K-Modes.\n\nK-Means is sensitive to the scale of features.\n\nAlways normalize your data before applying K-Means to ensure all features contribute equally to the distance calculations.\n• Use techniques like Min-Max scaling or Z-score normalization.\n• For high-dimensional data, consider PCA or t-SNE before clustering.\n• This can improve performance and visualization.\n• Choose the result with the lowest inertia.\n• Use this advanced initialization method for better starting centroids.\n• It spreads out initial centroids, often leading to better results.\n\nAs we’ve explored, K-Means clustering is a powerful, versatile algorithm with applications across numerous domains.\n\nIts simplicity belies its effectiveness in uncovering hidden patterns and structures in data.\n\nFrom customer segmentation to image compression, from anomaly detection to data preprocessing, K-Means continues to be a fundamental tool in the data scientist’s toolkit.\n\nHowever, like any tool, its effectiveness depends on proper understanding and application.\n\nBy being aware of its strengths, limitations, and best practices, we can leverage K-Means to its full potential.\n\nAs data continues to grow in volume and complexity, K-Means is evolving, with innovations like Mini-Batch K-Means and GPU acceleration pushing the boundaries of what’s possible.\n\nWhether you’re a seasoned data scientist or just beginning your journey, mastering K-Means clustering is a valuable step towards becoming a more effective and insightful data analyst.\n\nSo, the next time you’re faced with a mountain of unstructured data, remember: within that chaos, K-Means might just help you find the order you’re looking for.\n\nPS: If you like this article, share it with others ♻️\n\nAnd feel free to follow me for articles more like this."
    },
    {
        "link": "https://flothesof.github.io/k-means-numpy.html",
        "document": "A word of caution before going on: in this post, we will write pure numpy based functions, based on the numpy array object. This has advantages but also disadvantages. In particular:\n• the code becomes efficient and fast, due to the fact that numpy supports vector operations that are coded in C\n• at the expense of being readable, which is usually what Python code is\n\nTo follow along, a working knowledge of numpy is therefore necessary.\n\nTo implement the algorithm, we will start by defining a dataset to work with. We choose a dataset containing three clusters, with a little bit of variance around each cluster center. We construct the point cloud by stacking shifted random numbers:"
    },
    {
        "link": "https://realpython.com/k-means-clustering-python",
        "document": "The k-means clustering method is an unsupervised machine learning technique used to identify clusters of data objects in a dataset. There are many different types of clustering methods, but k-means is one of the oldest and most approachable. These traits make implementing k-means clustering in Python reasonably straightforward, even for novice programmers and data scientists.\n\nIf you’re interested in learning how and when to implement k-means clustering in Python, then this is the right place. You’ll walk through an end-to-end example of k-means clustering using Python, from preprocessing the data to evaluating results.\n• When to use k-means clustering to analyze your data\n• How to implement k-means clustering in Python with scikit-learn\n• How to select a meaningful number of clusters\n\nClick the link below to download the code you’ll use to follow along with the examples in this tutorial and implement your own k-means clustering pipeline:\n\nClustering is a set of techniques used to partition data into groups, or clusters. Clusters are loosely defined as groups of data objects that are more similar to other objects in their cluster than they are to data objects in other clusters. In practice, clustering helps identify two qualities of data: Meaningful clusters expand domain knowledge. For example, in the medical field, researchers applied clustering to gene expression experiments. The clustering results identified groups of patients who respond differently to medical treatments. Useful clusters, on the other hand, serve as an intermediate step in a data pipeline. For example, businesses use clustering for customer segmentation. The clustering results segment customers into groups with similar purchase histories, which businesses can then use to create targeted advertising campaigns. Note: You’ll learn about unsupervised machine learning techniques in this tutorial. If you’re interested in learning more about supervised machine learning techniques, then check out Logistic Regression in Python. There are many other applications of clustering, such as document clustering and social network analysis. These applications are relevant in nearly every industry, making clustering a valuable skill for professionals working with data in any field. You can perform clustering using many different approaches—so many, in fact, that there are entire categories of clustering algorithms. Each of these categories has its own unique strengths and weaknesses. This means that certain clustering algorithms will result in more natural cluster assignments depending on the input data. Note: If you’re interested in learning about clustering algorithms not mentioned in this section, then check out A Comprehensive Survey of Clustering Algorithms for an excellent review of popular techniques. Selecting an appropriate clustering algorithm for your dataset is often difficult due to the number of choices available. Some important factors that affect this decision include the characteristics of the clusters, the features of the dataset, the number of outliers, and the number of data objects. You’ll explore how these factors help determine which approach is most appropriate by looking at three popular categories of clustering algorithms: It’s worth reviewing these categories at a high level before jumping right into k-means. You’ll learn the strengths and weaknesses of each category to provide context for how k-means fits into the landscape of clustering algorithms. Partitional clustering divides data objects into nonoverlapping groups. In other words, no object can be a member of more than one cluster, and every cluster must have at least one object. These techniques require the user to specify the number of clusters, indicated by the variable k. Many partitional clustering algorithms work through an iterative process to assign subsets of data points into k clusters. Two examples of partitional clustering algorithms are k-means and k-medoids. These algorithms are both nondeterministic, meaning they could produce different results from two separate runs even if the runs were based on the same input.\n• They work well when clusters have a spherical shape. They also have several weaknesses:\n• They’re not well suited for clusters with complex shapes and different sizes.\n• They break down when used with clusters of different densities. Hierarchical clustering determines cluster assignments by building a hierarchy. This is implemented by either a bottom-up or a top-down approach:\n• Agglomerative clustering is the bottom-up approach. It merges the two points that are the most similar until all points have been merged into a single cluster.\n• Divisive clustering is the top-down approach. It starts with all points as one cluster and splits the least similar clusters at each step until only single data points remain. These methods produce a tree-based hierarchy of points called a dendrogram. Similar to partitional clustering, in hierarchical clustering the number of clusters (k) is often predetermined by the user. Clusters are assigned by cutting the dendrogram at a specified depth that results in k groups of smaller dendrograms. Unlike many partitional clustering techniques, hierarchical clustering is a deterministic process, meaning cluster assignments won’t change when you run an algorithm twice on the same input data. The strengths of hierarchical clustering methods include the following:\n• They often reveal the finer details about the relationships between data objects. The weaknesses of hierarchical clustering methods include the following: Density-based clustering determines cluster assignments based on the density of data points in a region. Clusters are assigned where there are high densities of data points separated by low-density regions. Unlike the other clustering categories, this approach doesn’t require the user to specify the number of clusters. Instead, there is a distance-based parameter that acts as a tunable threshold. This threshold determines how close points must be to be considered a cluster member. Examples of density-based clustering algorithms include Density-Based Spatial Clustering of Applications with Noise, or DBSCAN, and Ordering Points To Identify the Clustering Structure, or OPTICS. The strengths of density-based clustering methods include the following:\n• They excel at identifying clusters of nonspherical shapes. The weaknesses of density-based clustering methods include the following:\n• They aren’t well suited for clustering in high-dimensional spaces.\n• They have trouble identifying clusters of varying densities.\n\nHow to Perform K-Means Clustering in Python In this section, you’ll take a step-by-step tour of the conventional version of the k-means algorithm. Understanding the details of the algorithm is a fundamental step in the process of writing your k-means clustering pipeline in Python. What you learn in this section will help you decide if k-means is the right choice to solve your clustering problem. Conventional k-means requires only a few steps. The first step is to randomly select k centroids, where k is equal to the number of clusters you choose. Centroids are data points representing the center of a cluster. The main element of the algorithm works by a two-step process called expectation-maximization. The expectation step assigns each data point to its nearest centroid. Then, the maximization step computes the mean of all the points for each cluster and sets the new centroid. Here’s what the conventional version of the k-means algorithm looks like: The quality of the cluster assignments is determined by computing the sum of the squared error (SSE) after the centroids converge, or match the previous iteration’s assignment. The SSE is defined as the sum of the squared Euclidean distances of each point to its closest centroid. Since this is a measure of error, the objective of k-means is to try to minimize this value. The figure below shows the centroids and SSE updating through the first five iterations from two different runs of the k-means algorithm on the same dataset: The purpose of this figure is to show that the initialization of the centroids is an important step. It also highlights the use of SSE as a measure of clustering performance. After choosing a number of clusters and the initial centroids, the expectation-maximization step is repeated until the centroid positions reach convergence and are unchanged. The random initialization step causes the k-means algorithm to be nondeterministic, meaning that cluster assignments will vary if you run the same algorithm twice on the same dataset. Researchers commonly run several initializations of the entire k-means algorithm and choose the cluster assignments from the initialization with the lowest SSE. Writing Your First K-Means Clustering Code in Python Thankfully, there’s a robust implementation of k-means clustering in Python from the popular machine learning package scikit-learn. You’ll learn how to write a practical implementation of the k-means algorithm using the scikit-learn version of the algorithm. Note: If you’re interested in gaining a deeper understanding of how to write your own k-means algorithm in Python, then check out the Python Data Science Handbook. The code in this tutorial requires some popular external Python packages and assumes that you’ve installed Python with Anaconda. For more information on setting up your Python environment for machine learning in Windows, read through Setting Up Python for Machine Learning on Windows. Otherwise, you can begin by installing the required packages: The code is presented so that you can follow along in an console or Jupyter Notebook. Click the prompt ( ) at the top right of each code block to see the code formatted for copy-paste. You can also download the source code used in this article by clicking on the link below: Download the sample code: Click here to get the code you’ll use to learn how to write a k-means clustering pipeline in this tutorial. This step will import the modules needed for all the code in this section: You can generate the data from the above GIF using , a convenience function in scikit-learn used to generate synthetic clusters. uses these parameters:\n• is the total number of samples to generate.\n• is the number of centers to generate.\n• A two-dimensional NumPy array with the x- and y-values for each of the samples\n• A one-dimensional NumPy array containing the cluster labels for each sample Note: Many scikit-learn algorithms rely heavily on NumPy in their implementations. If you want to learn more about NumPy arrays, check out Look Ma, No Loops: Array Programming With NumPy. Nondeterministic machine learning algorithms like k-means are difficult to reproduce. The parameter is set to an integer value so you can follow the data presented in the tutorial. In practice, it’s best to leave as the default value, . Here’s a look at the first five elements for each of the variables returned by : Data sets usually contain numerical features that have been measured in different units, such as height (in inches) and weight (in pounds). A machine learning algorithm would consider weight more important than height only because the values for weight are larger and have higher variability from person to person. Machine learning algorithms need to consider all features on an even playing field. That means the values for all features must be transformed to the same scale. The process of transforming numerical features to use the same scale is known as feature scaling. It’s an important data preprocessing step for most distance-based machine learning algorithms because it can have a significant impact on the performance of your algorithm. There are several approaches to implementing feature scaling. A great way to determine which technique is appropriate for your dataset is to read scikit-learn’s preprocessing documentation. In this example, you’ll use the class. This class implements a type of feature scaling called standardization. Standardization scales, or shifts, the values for each numerical feature in your dataset so that the features have a mean of 0 and standard deviation of 1: Take a look at how the values have been scaled in : Now the data are ready to be clustered. The estimator class in scikit-learn is where you set the algorithm parameters before fitting the estimator to the data. The scikit-learn implementation is flexible, providing several parameters that can be tuned. Here are the parameters used in this example:\n• controls the initialization technique. The standard version of the k-means algorithm is implemented by setting to . Setting this to employs an advanced trick to speed up convergence, which you’ll use later.\n• sets k for the clustering step. This is the most important parameter for k-means.\n• sets the number of initializations to perform. This is important because two runs can converge on different cluster assignments. The default behavior for the scikit-learn algorithm is to perform ten k-means runs and return the results of the one with the lowest SSE.\n• sets the number of maximum iterations for each initialization of the k-means algorithm. Instantiate the class with the following arguments: The parameter names match the language that was used to describe the k-means algorithm earlier in the tutorial. Now that the k-means class is ready, the next step is to fit it to the data in . This will perform ten runs of the k-means algorithm on your data with a maximum of iterations per run: Statistics from the initialization run with the lowest SSE are available as attributes of after calling : # The number of iterations required to converge Finally, the cluster assignments are stored as a one-dimensional NumPy array in . Here’s a look at the first five predicted labels: Note that the order of the cluster labels for the first two data objects was flipped. The order was in but in even though those data objects are still members of their original clusters in . This behavior is normal, as the ordering of cluster labels is dependent on the initialization. Cluster 0 from the first run could be labeled cluster 1 in the second run and vice versa. This doesn’t affect clustering evaluation metrics. Choosing the Appropriate Number of Clusters In this section, you’ll look at two methods that are commonly used to evaluate the appropriate number of clusters: These are often used as complementary evaluation techniques rather than one being preferred over the other. To perform the elbow method, run several k-means, increment with each iteration, and record the SSE: # A list holds the SSE values for each k The previous code block made use of Python’s dictionary unpacking operator ( ). To learn more about this powerful Python operator, check out How to Iterate Through a Dictionary in Python. When you plot SSE as a function of the number of clusters, notice that SSE continues to decrease as you increase . As more centroids are added, the distance from each point to its closest centroid will decrease. There’s a sweet spot where the SSE curve starts to bend known as the elbow point. The x-value of this point is thought to be a reasonable trade-off between error and number of clusters. In this example, the elbow is located at : The above code produces the following plot: Determining the elbow point in the SSE curve isn’t always straightforward. If you’re having trouble choosing the elbow point of the curve, then you could use a Python package, kneed, to identify the elbow point programmatically: The silhouette coefficient is a measure of cluster cohesion and separation. It quantifies how well a data point fits into its assigned cluster based on two factors:\n• How close the data point is to other points in the cluster\n• How far away the data point is from points in other clusters Silhouette coefficient values range between and . Larger numbers indicate that samples are closer to their clusters than they are to other clusters. In the scikit-learn implementation of the silhouette coefficient, the average silhouette coefficient of all the samples is summarized into one score. The function needs a minimum of two clusters, or it will raise an exception. Loop through values of again. This time, instead of computing SSE, compute the silhouette coefficient: # A list holds the silhouette coefficients for each k # Notice you start at 2 clusters for silhouette coefficient Plotting the average silhouette scores for each shows that the best choice for is since it has the maximum score: The above code produces the following plot: Ultimately, your decision on the number of clusters to use should be guided by a combination of domain knowledge and clustering evaluation metrics. The elbow method and silhouette coefficient evaluate clustering performance without the use of ground truth labels. Ground truth labels categorize data points into groups based on assignment by a human or an existing algorithm. These types of metrics do their best to suggest the correct number of clusters but can be deceiving when used without context. Note: In practice, it’s rare to encounter datasets that have ground truth labels. When comparing k-means against a density-based approach on nonspherical clusters, the results from the elbow method and silhouette coefficient rarely match human intuition. This scenario highlights why advanced clustering evaluation techniques are necessary. To visualize an example, import these additional modules: This time, use to generate synthetic data in the shape of crescents: Fit both a k-means and a DBSCAN algorithm to the new data and visually assess the performance by plotting the cluster assignments with Matplotlib: # Fit the algorithms to the features # Compute the silhouette scores for each algorithm Print the silhouette coefficient for each of the two algorithms and compare them. A higher silhouette coefficient suggests better clusters, which is misleading in this scenario: The silhouette coefficient is higher for the k-means algorithm. The DBSCAN algorithm appears to find more natural clusters according to the shape of the data: This suggests that you need a better method to compare the performance of these two clustering algorithms. If you’re interested, you can find the code for the above plot by expanding the box below. To learn more about plotting with Matplotlib and Python, check out Python Plotting with Matplotlib (Guide). Here’s how you can plot the comparison of the two algorithms in the crescent moons example: Since the ground truth labels are known, it’s possible to use a clustering metric that considers labels in its evaluation. You can use the scikit-learn implementation of a common metric called the adjusted rand index (ARI). Unlike the silhouette coefficient, the ARI uses true cluster assignments to measure the similarity between true and predicted labels. Compare the clustering results of DBSCAN and k-means using ARI as the performance metric: The ARI output values range between and . A score close to indicates random assignments, and a score close to indicates perfectly labeled clusters. Based on the above output, you can see that the silhouette coefficient was misleading. ARI shows that DBSCAN is the best choice for the synthetic crescents example as compared to k-means. There are several metrics that evaluate the quality of clustering algorithms. Reading through the implementations in scikit-learn will help you select an appropriate clustering evaluation metric.\n\nHow to Build a K-Means Clustering Pipeline in Python Now that you have a basic understanding of k-means clustering in Python, it’s time to perform k-means clustering on a real-world dataset. These data contain gene expression values from a manuscript authored by The Cancer Genome Atlas (TCGA) Pan-Cancer analysis project investigators. There are samples (rows) representing five distinct cancer subtypes. Each sample has gene expression values for genes (columns). The dataset is available from the UC Irvine Machine Learning Repository, but you can use the Python code below to obtain the data programmatically. To follow along with the examples below, you can download the source code by clicking on the following link: Download the sample code: Click here to get the code you’ll use to learn how to write a k-means clustering pipeline in this tutorial. In this section, you’ll build a robust k-means clustering pipeline. Since you’ll perform multiple transformations of the original input data, your pipeline will also serve as a practical clustering framework. Assuming you want to start with a fresh namespace, import all the modules needed to build and evaluate the pipeline, including pandas and seaborn for more advanced visualizations: Download and extract the TCGA dataset from UCI: # Extract the data from the archive After the download and extraction is completed, you should have a directory that looks like this: The class in scikit-learn requires a NumPy array as an argument. The NumPy package has a helper function to load the data from the text file into memory as NumPy arrays: Check out the first three columns of data for the first five samples as well as the labels for the first five samples: The variable contains all the gene expression values from genes. The are the cancer types for each of the samples. The first record in corresponds with the first label in . The labels are strings containing abbreviations of cancer types: To use these labels in the evaluation methods, you first need to convert the abbreviations to integers with : Since the has been fitted to the data, you can see the unique classes represented using . Store the length of the array to the variable for later use: In practical machine learning pipelines, it’s common for the data to undergo multiple sequences of transformations before it feeds into a clustering algorithm. You learned about the importance of one of these transformation steps, feature scaling, earlier in this tutorial. An equally important data transformation technique is dimensionality reduction, which reduces the number of features in the dataset by either removing or combining them. Dimensionality reduction techniques help to address a problem with machine learning algorithms known as the curse of dimensionality. In short, as the number of features increases, the feature space becomes sparse. This sparsity makes it difficult for algorithms to find data objects near one another in higher-dimensional space. Since the gene expression dataset has over features, it qualifies as a great candidate for dimensionality reduction. Principal Component Analysis (PCA) is one of many dimensionality reduction techniques. PCA transforms the input data by projecting it into a lower number of dimensions called components. The components capture the variability of the input data through a linear combination of the input data’s features. Note: A full description of PCA is out of scope for this tutorial, but you can learn more about it in the scikit-learn user guide. The next code block introduces you to the concept of scikit-learn pipelines. The scikit-learn class is a concrete implementation of the abstract idea of a machine learning pipeline. Your gene expression data aren’t in the optimal format for the class, so you’ll need to build a preprocessing pipeline. The pipeline will implement an alternative to the class called for feature scaling. You use when you do not assume that the shape of all your features follows a normal distribution. The next step in your preprocessing pipeline will implement the class to perform dimensionality reduction: Now that you’ve built a pipeline to process the data, you’ll build a separate pipeline to perform k-means clustering. You’ll override the following default arguments of the class:\n• init: You’ll use instead of to ensure centroids are initialized with some distance between them. In most cases, this will be an improvement over .\n• n_init: You’ll increase the number of initializations to ensure you find a stable solution.\n• max_iter: You’ll increase the number of iterations per initialization to ensure that k-means will converge. Build the k-means clustering pipeline with user-defined arguments in the constructor: The class can be chained to form a larger pipeline. Build an end-to-end k-means clustering pipeline by passing the and pipelines to : Calling with as the argument performs all the pipeline steps on the : The pipeline performs all the necessary steps to execute k-means clustering on the gene expression data! Depending on your Python REPL, may print a summary of the pipeline. Objects defined inside pipelines are accessible using their step name. Evaluate the performance by calculating the silhouette coefficient: Calculate ARI, too, since the ground truth cluster labels are available: As mentioned earlier, the scale for each of these clustering performance metrics ranges from -1 to 1. A silhouette coefficient of 0 indicates that clusters are significantly overlapping one another, and a silhouette coefficient of 1 indicates clusters are well-separated. An ARI score of 0 indicates that cluster labels are randomly assigned, and an ARI score of 1 means that the true labels and predicted labels form identical clusters. Since you specified in the PCA step of the k-means clustering pipeline, you can also visualize the data in the context of the true labels and predicted labels. Plot the results using a pandas DataFrame and the seaborn plotting library: Here’s what the plot looks like: The visual representation of the clusters confirms the results of the two clustering evaluation metrics. The performance of your pipeline was pretty good. The clusters only slightly overlapped, and cluster assignments were much better than random. Your first k-means clustering pipeline performed well, but there’s still room to improve. That’s why you went through the trouble of building the pipeline: you can tune the parameters to get the most desirable clustering results. The process of parameter tuning consists of sequentially altering one of the input values of the algorithm’s parameters and recording the results. At the end of the parameter tuning process, you’ll have a set of performance scores, one for each new value of a given parameter. Parameter tuning is a powerful method to maximize performance from your clustering pipeline. By setting the parameter , you squished all the features into two components, or dimensions. This value was convenient for visualization on a two-dimensional plot. But using only two components means that the PCA step won’t capture all of the explained variance of the input data. Explained variance measures the discrepancy between the PCA-transformed data and the actual input data. The relationship between and explained variance can be visualized in a plot to show you how many components you need in your PCA to capture a certain percentage of the variance in the input data. You can also use clustering performance metrics to evaluate how many components are necessary to achieve satisfactory clustering results. In this example, you’ll use clustering performance metrics to identify the appropriate number of components in the PCA step. The class is powerful in this situation. It allows you to perform basic parameter tuning using a loop. Iterate over a range of and record evaluation metrics for each iteration: # This set the number of components for pca, Plot the evaluation metrics as a function of to visualize the relationship between adding components and the performance of the k-means clustering results: The above code generates the a plot showing performance metrics as a function of : There are two takeaways from this figure:\n• The silhouette coefficient decreases linearly. The silhouette coefficient depends on the distance between points, so as the number of dimensions increases, the sparsity increases.\n• The ARI improves significantly as you add components. It appears to start tapering off after , so that would be the value to use for presenting the best clustering results from this pipeline. Like most machine learning decisions, you must balance optimizing clustering evaluation metrics with the goal of the clustering task. In situations when cluster labels are available, as is the case with the cancer dataset used in this tutorial, ARI is a reasonable choice. ARI quantifies how accurately your pipeline was able to reassign the cluster labels. The silhouette coefficient, on the other hand, is a good choice for exploratory clustering because it helps to identify subclusters. These subclusters warrant additional investigation, which can lead to new and important insights.\n\nYou now know how to perform k-means clustering in Python. Your final k-means clustering pipeline was able to cluster patients with different cancer types using real-world gene expression data. You can use the techniques you learned here to cluster your own data, understand how to get the best clustering results, and share insights with others. In this tutorial, you learned:\n• What the popular clustering techniques are and when to use them\n• What the k-means algorithm is\n• How to implement k-means clustering in Python\n• How to evaluate the performance of clustering algorithms\n• How to build and tune a robust k-means clustering pipeline in Python\n• How to analyze and present clustering results from the k-means algorithm You also took a whirlwind tour of scikit-learn, an accessible and extensible tool for implementing k-means clustering in Python. If you’d like to reproduce the examples you saw above, then be sure to download the source code by clicking on the following link: Download the sample code: Click here to get the code you’ll use to learn how to write a k-means clustering pipeline in this tutorial. You’re now ready to perform k-means clustering on datasets you find interesting. Be sure to share your results in the comments below! Note: The dataset used in this tutorial was obtained from the UCI Machine Learning Repository. Dua, D. and Graff, C. (2019). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science. The original dataset is maintained by The Cancer Genome Atlas Pan-Cancer analysis project."
    },
    {
        "link": "https://blog.paperspace.com/speed-up-kmeans-numpy-vectorization-broadcasting-profiling",
        "document": "In this part we'll see how to speed up an implementation of the k-means clustering algorithm by 70x using NumPy. We cover how to use cProfile to find bottlenecks in the code, and how to address them using vectorization.\n\nIn Part 1 of our series on how to write efficient code using NumPy, we covered the important topics of vectorization and broadcasting. In this part we will put these concepts into practice by implementing an efficient version of the K-Means clustering algorithm using NumPy. We will benchmark it against a naive version implemented entirely using looping in Python. In the end we'll see that the NumPy version is about 70 times faster than the simple loop version.\n\nTo be exact, in this post we will cover:\n• Using cProfile to find bottlenecks in the code\n\nIn this post we will be optimizing an implementation of the k-means clustering algorithm. It is therefore imperative that we at least have a basic understanding of how the algorithm works. Of course, a detailed discussion would also be beyond the scope of this post; if you want to dig deeper into k-means you can find several recommended links below.\n\nWhat Does the K-Means Clustering Algorithm Do?\n\nIn a nutshell, k-means is an unsupervised learning algorithm which separates data into groups based on similarity. As it's an unsupervised algorithm, this means we have no labels for the data.\n\nThe most important hyperparameter for the k-means algorithm is the number of clusters, or k. Once we have decided upon our value for k, the algorithm works as follows.\n• Initialize k points (corresponding to k clusters) randomly from the data. We call these points centroids.\n• For each data point, measure the L2 distance from the centroid. Assign each data point to the centroid for which it has the shortest distance. In other words, assign the closest centroid to each data point.\n• Now each data point assigned to a centroid forms an individual cluster. For k centroids, we will have k clusters. Update the value of the centroid of each cluster by the mean of all the data points present in that particular cluster.\n• Repeat steps 1-3 until the maximum change in centroids for each iteration falls below a threshold value, or the clustering error converges.\n\nHere's the pseudo-code for the algorithm.\n\nI'm going to leave K-Means at that. This is enough to help us code the algorithm. However, there is much more to it, such as how to choose a good value of k, how to evaluate the performance, which distance metrics can be used, preprocessing steps, and theory. In case you wish to dig deeper, here are a few links for you to study it further.\n\nNow, let's proceed with the implementation of the algorithm.\n\nIn this section we will be implementing the K-Means algorithm using Python and loops. We will not be using NumPy for this. This code will be used as a benchmark for our optimized version.\n\nTo perform clustering, we first need our data. While we can choose from multiple datasets online, let's keep things rather simple and intuitive. We are going to synthesize a dataset by sampling from multiple Gaussian distributions, so that visualizing clusters is easy for us.\n\nIn case you don't know what a Gaussian distribution is, check it out!\n\nWe will create data from four Gaussian's with different means and distributions.\n\nIn order to aid our visualization, let's plot this data in a 3-D space.\n\nIt's very easy to see the four clusters of data in the plot above. This, for one, makes it easy for us to pick up a suitable value of k for our implementation. This goes in spirit of keeping the algorithmic details as simple as possible, so that we can focus on the implementation.\n\nWe begin by initialising our centroids, as well as a list to keep track of which centroid each data point is assigned to.\n\nBefore we implement our loop, we will first implement a few helper functions.\n\ntakes two points (say and ) and computes the L2 distance between them, according to the following formula.\n\nThe other helper function we implement is called , the name being pretty self-explanatory. The function takes an input and a list, , and returns the index of the list corresponding to the centroid closest to .\n\nThen we implement the function , which computes the SSE or Sum of Squared Errors. This metric is used to guide how many iterations we have to do. Once this value converges, we can stop training.\n\nNow, let's write the main loop. Refer to the pseudo-code mentioned above for reference. Instead of looping until convergence, we merely loop for 50 iterations.\n\nThe entire code can be viewed below.\n\nOnce we let the code run, let's check how we have performed according to the SSE through the iterations.\n\nIf we visualize the clusters, this is what we get.\n\nWe see that k-means is able to discover all the clusters on its own. We will be using this code as our benchmark.\n\nLet us now time our code. We can use the module as we did in the last post. You could also use the module, although in our last post I advocated against it because measuring the running time for only a single run can lead to unstable estimates due to processes running in the background, especially when it comes to short snippets (often, one-liners).\n\nHowever, it's important to note that the code for K-Means doesn't correspond to a short snippet. In fact, the body of code being considered here has a lot of short snippets being repeated multiple times in loops. This is exactly what we were doing with ; running short snippets time and time again. Therefore, even the module works fine for our example.\n\nIn fact, this is what we are going to use here, as shown below.\n\nWhen used for our code, the time taken for the loop version is about 0.053 seconds per loop. (Estimates may vary to the tune of 0.001 seconds).\n\nWe use a couple of methods to identify bottlenecks: inspection of the loop structure, and the use of to measure the running time of various functions in our code.\n\nFirst, I want to focus on the body of the loop. Here's a rough outline of how loops are structured in the code.\n\nWe use to iterate over the number of iterations, to iterate over the dataset, to iterate over the number of clusters, and to iterate over the dimensions of the data.\n\nHere, the loops that will benefit the most from optimization are those that go over the data ( corresponds to the size of our dataset, which could be very large) and dimensions ( , in case we have very high-dimensional data, like images). In comparison, the loops that go over the number of clusters, , and the number of iterations, , may require only a small amount of iterations and may not benefit as much from optimization. Nonetheless, we will try to optimize those as well.\n\nAlso notice that the loop that is responsible for calculating the centroids for each data point is a triply nested loop, with individual loops going over the dataset size, number of clusters, and dimensions of the data, respectively. As we've discovered in the previous post, nested loops can be one of the biggest bottlenecks.\n\nUsing cProfile to Identify the Bottlenecks\n\nWhile we could draw an outline detailing loop structure for our code, as it was still somewhat small, doing the same for large bodies of code can be pretty tedious.\n\nTherefore, I am now going to introduce a tool called that helps you profile your code and get running times for various elements in your code. In order to use cProfile, put your code inside a python script and run the following command from the terminal.\n\nHere, flag denotes the name of the log file that will be created. In our case, this file is named as . In order to read this file, we will be needing another utility called which can be installed with .\n\nOnce you have installed it, we can use it to view our log file.\n\nThis will result in a message that reads something like:\n\nGo to the address in the browser. You will see something like this.\n\nHere, you see column heading on the top regarding each function call in your code.\n• : Total time taken by a function call including time taken by other function it calls.\n• : Total time taken by the function alone not including time taken by function it calls.\n• : File name and Line number of the function call.\n\nHere, we are most interesting in the time a function call takes by itself, i.e. . We click on the column label to sort the entries by\n\nOnce, we have done that we see exactly which functions are taking the most time.\n\nHere, we see that that the function and take the maximum individual times. Notice that both of these function include loops which can be vectorized. The is called 1 million times, while is called 200,000 times.\n\nWe also see that the (list comprehension function) and the functions also feature in the top time-taking functions. These functions are used in the lines which includes loops for computing data points belonging to a particular cluster, computing the closest centroid and computing the new centroids respectively. We shall also attempt to vectorize these loops.\n\nIn this section, we are going to take the implementation and optimize it using vectorization and Broadcasting.\n\nWe first begin by vectorizing the function . We modify it to accept inputs , an array of shape (d = 3 in our example) and to be of shape (k = 4 in our example).\n\nSince is of shape and of shape , the array will be broadcasted over the first dimension and we would have the resulting array of shape with each row representing the distance of array with each centroid. This vectorizes the loop over the number of centroids.\n\nWe then sum the resulting array along it's first dimensions ( ) so that we have an array of size which contains the distance of from 3 centroids.\n\nNow, we turn our attention to the function. Again, the inputs to this function would be , an array of shape (d = 3 in our example) and to be of shape (k = 4 in our example).\n\nWe replace the line with . Note that this call featured in one of top time-taking functions.\n\nConsequently, we can also vectorize the loop in function by invoking the on the entire and array.\n\nNote that the array is of shape ( = 4000). The array helps us get a list of assigned centroids which earlier had to be computed using a loop with the line .\n\nIn order to make the loop work with our modifications, we have to make some modifications to our code.\n\nFirst, is now a array of shape (as compared to a list seen earlier). So we have to change its initialization from:\n\nWe also have to ensure our data is now in form of not . To do this , we add the line after reading our data .\n\nWe also modify the loop that computes the mean of the assigned centroids ( to compute new centroids) to much easier code from\n\nOnce this is done, our new code for K-Means looks like:\n\nWhen we time the vectorized code, we get a time of about 0.031 seconds (+/- 0.001 sec). Well, it's a speed up, but isn't it disappointing? To be honest, A speed up of just 1.7x seems to be a big let off given what we saw in Part 1 of one. It seems that maybe vectorization doesn't work that well at all?\n\nLet's use the profiler to see what the time taking functions are.\n\nAgain, the functions that take most time (excluding internal functions) are and . While we vectorized them, a more problematic aspect is them being called a huge number of times. While the is now called 200,000 times (instead of 1M due to vectorizing loop over centroids), the number of calls made to remains the same.\n\nThese large number of calls are because we are still using a loop to go over our entire dataset, which has many many ( = 4000) iterations. In contrast, The loops we have vectorized mostly go over the dimensions (= 3) or centroids (=4) and have comparatively lesser iterations. If we can vectorize the loop over data, we can gain considerable speed ups.\n\nIn order to think about vectorizing the loop over data, we revisit our visualizing loops as arrays logic from part 1. In our code, the bottleneck basically comes from measure distance between a given data point with all the centroids, for each data point in the dataset.\n\nLet us visualize a 3-D array of dimensions . It's element represent the distance between $k_{th}$ dimension of the $i^{th}$ data point and the $j_{th}$ centroid.\n\nOperating on this array enables us to perform one iteration of K-Means without a loop, enabling us to get rid of the loop over data.\n\nSuch an array can be easily created using broadcasting. We have our data as a array and a centroids as a array. To broadcast them, we can reshape and to and respectively. Passing these resized arrays to results in the formation of the array we talked about above, with the shape .\n\nThis can be done simply as:\n\nNow that we are dealing with 3-D and arrays, we must make minor modifications to the helper functions (the along which and has to be computed).\n\nOnce this is done, we can write our main code without the loop going over dataset.\n\nThe full entire code can be found here:\n\nLet's time the code now. Using the module, we get an estimated running time of 0.00073 seconds (+/- 0.00002 seconds) per iteration! Now that's a speed up of 72x for the optimized code!\n\nLooking the profiler log of the code:\n\nWe see that is now only called 100 times, and hence the decreases considerably. is only called 50 times and is further down the list.\n\nThat brings us to the end of this post! If you were to take anything from this post, it is that merely vectorizing code is not enough; we must also look at which loops have the largest number of iterations. This reminds me of the famous line from George Orwell's Animal Farm:\n\nFor loops that have a small number of iterations, you can even leave them be to improve code readability. Of course, there is a trade-off in this case between optimization and readability. That is something I plan to discuss in the future parts of this series, along with concepts like in-place ops, reshaping, transposing, and other options beyond NumPy. Until then, I'll leave you with this key take away message from this post."
    }
]