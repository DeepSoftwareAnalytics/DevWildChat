[
    {
        "link": "https://docs.python.org/3/library/typing.html",
        "document": "This module provides runtime support for type hints.\n\nConsider the function below:\n\nThe function takes an argument expected to be an instance of , as indicated by the type hint . The function is expected to return an instance of , as indicated by the hint.\n\nWhile type hints can be simple classes like or , they can also be more complex. The module provides a vocabulary of more advanced type hints.\n\nNew features are frequently added to the module. The typing_extensions package provides backports of these new features to older versions of Python.\n\nUse the helper to create distinct types: The static type checker will treat the new type as if it were a subclass of the original type. This is useful in helping catch logical errors: # fails type checking; an int is not a UserId You may still perform all operations on a variable of type , but the result will always be of type . This lets you pass in a wherever an might be expected, but will prevent you from accidentally creating a in an invalid way: # 'output' is of type 'int', not 'UserId' Note that these checks are enforced only by the static type checker. At runtime, the statement will make a callable that immediately returns whatever parameter you pass it. That means the expression does not create a new class or introduce much overhead beyond that of a regular function call. More precisely, the expression is always true at runtime. It is invalid to create a subtype of : # Fails at runtime and does not pass type checking However, it is possible to create a based on a ‘derived’ : and typechecking for will work as expected. See PEP 484 for more details. Recall that the use of a type alias declares two types to be equivalent to one another. Doing will make the static type checker treat as being exactly equivalent to in all cases. This is useful when you want to simplify complex type signatures. In contrast, declares one type to be a subtype of another. Doing will make the static type checker treat as a subclass of , which means a value of type cannot be used in places where a value of type is expected. This is useful when you want to prevent logic errors with minimal runtime cost. Changed in version 3.10: is now a class rather than a function. As a result, there is some additional runtime cost when calling over a regular function. Changed in version 3.11: The performance of calling has been restored to its level in Python 3.9.\n\nFor most containers in Python, the typing system assumes that all elements in the container will be of the same type. For example: # Type checker will infer that all elements in ``x`` are meant to be ints # Type checker will infer that all keys in ``z`` are meant to be strings, # and that all values in ``z`` are meant to be either strings or ints only accepts one type argument, so a type checker would emit an error on the assignment above. Similarly, only accepts two type arguments: the first indicates the type of the keys, and the second indicates the type of the values. Unlike most other Python containers, however, it is common in idiomatic Python code for tuples to have elements which are not all of the same type. For this reason, tuples are special-cased in Python’s typing system. accepts any number of type arguments: # OK: ``x`` is assigned to a tuple of length 1 where the sole element is an int # OK: ``y`` is assigned to a tuple of length 2; # element 1 is an int, element 2 is a str # Error: the type annotation indicates a tuple of length 1, # but ``z`` has been assigned to a tuple of length 3 To denote a tuple which could be of any length, and in which all elements are of the same type , use . To denote an empty tuple, use . Using plain as an annotation is equivalent to using : # These reassignments are OK: ``tuple[int, ...]`` indicates x can be of any length # This reassignment is an error: all elements in ``x`` must be ints # ``y`` can only ever be assigned to an empty tuple # These reassignments are OK: plain ``tuple`` is equivalent to ``tuple[Any, ...]``\n\nA user-defined class can be defined as a generic class. This syntax indicates that the class is parameterised around a single type variable . This also makes valid as a type within the class body. Generic classes implicitly inherit from . For compatibility with Python 3.11 and lower, it is also possible to inherit explicitly from to indicate a generic class: Generic classes have methods, meaning they can be parameterised at runtime (e.g. below): A generic type can have any number of type variables. All varieties of are permissible as parameters for a generic type: Each type variable argument to must be distinct. This is thus invalid: Generic classes can also inherit from other classes: When inheriting from generic classes, some type parameters could be fixed: In this case has a single parameter, . Using a generic class without specifying type parameters assumes for each position. In the following example, is not generic but implicitly inherits from : # Return type here is same as Iterable[str] | int For backward compatibility, generic type aliases can also be created through a simple assignment: Changed in version 3.7: no longer has a custom metaclass. Changed in version 3.12: Syntactic support for generics and type aliases is new in version 3.12. Previously, generic classes had to explicitly inherit from or contain a type variable in one of their bases. User-defined generics for parameter expressions are also supported via parameter specification variables in the form . The behavior is consistent with type variables’ described above as parameter specification variables are treated by the typing module as a specialized type variable. The one exception to this is that a list of types can be used to substitute a : Classes generic over a can also be created using explicit inheritance from . In this case, is not used: Another difference between and is that a generic with only one parameter specification variable will accept parameter lists in the forms and also for aesthetic reasons. Internally, the latter is converted to the former, so the following are equivalent: Note that generics with may not have correct after substitution in some cases because they are intended primarily for static type checking. Changed in version 3.10: can now be parameterized over parameter expressions. See and PEP 612 for more details. A user-defined generic class can have ABCs as base classes without a metaclass conflict. Generic metaclasses are not supported. The outcome of parameterizing generics is cached, and most types in the typing module are hashable and comparable for equality.\n\nA special kind of type is . A static type checker will treat every type as being compatible with and as being compatible with every type. This means that it is possible to perform any operation or method call on a value of type and assign it to any variable: # Passes type checking; 'item' could be any type, # and that type might have a 'bar' method Notice that no type checking is performed when assigning a value of type to a more precise type. For example, the static type checker did not report an error when assigning to even though was declared to be of type and receives an value at runtime! Furthermore, all functions without a return type or parameter types will implicitly default to using : # A static type checker will treat the above # as having the same signature as: This behavior allows to be used as an escape hatch when you need to mix dynamically and statically typed code. Contrast the behavior of with the behavior of . Similar to , every type is a subtype of . However, unlike , the reverse is not true: is not a subtype of every other type. That means when the type of a value is , a type checker will reject almost all operations on it, and assigning it to a variable (or using it as a return value) of a more specialized type is a type error. For example: # Fails type checking; an object does not have a 'magic' method. # Passes type checking, since ints and strs are subclasses of object # Passes type checking, since Any is compatible with all types Use to indicate that a value could be any type in a typesafe manner. Use to indicate that a value is dynamically typed."
    },
    {
        "link": "https://docs.python.org/3/tutorial/datastructures.html",
        "document": "This chapter describes some things you’ve learned about already in more detail, and adds some new things as well.\n\nThe list data type has some more methods. Here are all of the methods of list objects: Add an item to the end of the list. Similar to . Extend the list by appending all the items from the iterable. Similar to . Insert an item at a given position. The first argument is the index of the element before which to insert, so inserts at the front of the list, and is equivalent to . Remove the first item from the list whose value is equal to x. It raises a if there is no such item. Remove the item at the given position in the list, and return it. If no index is specified, removes and returns the last item in the list. It raises an if the list is empty or the index is outside the list range. Remove all items from the list. Similar to . Return zero-based index in the list of the first item whose value is equal to x. Raises a if there is no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument. Return the number of times x appears in the list. Sort the items of the list in place (the arguments can be used for sort customization, see for their explanation). Reverse the elements of the list in place. Return a shallow copy of the list. Similar to . An example that uses most of the list methods: You might have noticed that methods like , or that only modify the list have no return value printed – they return the default . This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, doesn’t sort because integers can’t be compared to strings and can’t be compared to other types. Also, there are some types that don’t have a defined ordering relation. For example, isn’t a valid comparison. The list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved (“last-in, first-out”). To add an item to the top of the stack, use . To retrieve an item from the top of the stack, use without an explicit index. For example: It is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-out”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing inserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use which was designed to have fast appends and pops from both ends. For example: # The first to arrive now leaves # The second to arrive now leaves List comprehensions provide a concise way to create lists. Common applications are to make new lists where each element is the result of some operations applied to each member of another sequence or iterable, or to create a subsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like: Note that this creates (or overwrites) a variable named that still exists after the loop completes. We can calculate the list of squares without any side effects using: which is more concise and readable. A list comprehension consists of brackets containing an expression followed by a clause, then zero or more or clauses. The result will be a new list resulting from evaluating the expression in the context of the and clauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal: Note how the order of the and statements is the same in both these snippets. If the expression is a tuple (e.g. the in the previous example), it must be parenthesized. # create a new list with the values doubled # apply a function to all the elements # the tuple must be parenthesized, otherwise an error is raised File , line : did you forget parentheses around the comprehension target? # flatten a list using a listcomp with two 'for' List comprehensions can contain complex expressions and nested functions: The initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4: The following list comprehension will transpose rows and columns: As we saw in the previous section, the inner list comprehension is evaluated in the context of the that follows it, so this example is equivalent to: which, in turn, is the same as: # the following 3 lines implement the nested listcomp In the real world, you should prefer built-in functions to complex flow statements. The function would do a great job for this use case: See Unpacking Argument Lists for details on the asterisk in this line.\n\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two examples of sequence data types (see Sequence Types — list, tuple, range). Since Python is an evolving language, other sequence data types may be added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance: File , line , in : # but they can contain mutable objects: As you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they may be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple is part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to create tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples are immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later in this section) or indexing (or even by attribute in the case of ). Lists are mutable, and their elements are usually homogeneous and are accessed by iterating over the list. A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accommodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed by following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example: The statement is an example of tuple packing: the values , and are packed together in a tuple. The reverse operation is also possible: This is called, appropriately enough, sequence unpacking and works for any sequence on the right-hand side. Sequence unpacking requires that there are as many variables on the left side of the equals sign as there are elements in the sequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking.\n\nPython also includes a data type for sets. A set is an unordered collection with no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. Set objects also support mathematical operations like union, intersection, difference, and symmetric difference. Curly braces or the function can be used to create sets. Note: to create an empty set you have to use , not ; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration: # show that duplicates have been removed # Demonstrate set operations on unique letters from two words # letters in a but not in b # letters in a or b or both # letters in both a and b # letters in a or b but not both Similarly to list comprehensions, set comprehensions are also supported:\n\nAnother useful data type built into Python is the dictionary (see Mapping Types — dict). Dictionaries are sometimes found in other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range of numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be keys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable object either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified in place using index assignments, slice assignments, or methods like and . It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within one dictionary). A pair of braces creates an empty dictionary: . Placing a comma-separated list of key:value pairs within the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also possible to delete a key:value pair with . If you store using a key that is already in use, the old value associated with that key is forgotten. It is an error to extract a value using a non-existent key. Performing on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you want it sorted, just use instead). To check whether a single key is in the dictionary, use the keyword. Here is a small example using a dictionary: The constructor builds dictionaries directly from sequences of key-value pairs: In addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions: When the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the method. When looping through a sequence, the position index and corresponding value can be retrieved at the same time using the function. To loop over two or more sequences at the same time, the entries can be paired with the function. What is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the function. To loop over a sequence in sorted order, use the function which returns a new sorted list while leaving the source unaltered. Using on a sequence eliminates duplicate elements. The use of in combination with over a sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. It is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create a new list instead.\n\nThe conditions used in and statements can contain any operators, not just comparisons. The comparison operators and are membership tests that determine whether a value is in (or not in) a container. The operators and compare whether two objects are really the same object. All comparison operators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, tests whether is less than and moreover equals . Comparisons may be combined using the Boolean operators and , and the outcome of a comparison (or of any other Boolean expression) may be negated with . These have lower priorities than comparison operators; between them, has the highest priority and the lowest, so that A and not B or C is equivalent to (A and (not B)) or C . As always, parentheses can be used to express the desired composition. The Boolean operators and are so-called short-circuit operators: their arguments are evaluated from left to right, and evaluation stops as soon as the outcome is determined. For example, if and are true but is false, A and B and C does not evaluate the expression . When used as a general value and not as a Boolean, the return value of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example, Note that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator . This avoids a common class of problems encountered in C programs: typing in an expression when was intended.\n\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses lexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of the comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried out recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence is an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one. Lexicographical ordering for strings uses the Unicode code point number to order individual characters. Some examples of comparisons between sequences of the same type: Note that comparing objects of different types with or is legal provided that the objects have appropriate comparison methods. For example, mixed numeric types are compared according to their numeric value, so 0 equals 0.0, etc. Otherwise, rather than providing an arbitrary ordering, the interpreter will raise a exception."
    },
    {
        "link": "https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html",
        "document": "This document is a quick cheat sheet showing how to use type annotations for various common types in Python.\n\nTechnically many of the type annotations shown below are redundant, since mypy can usually infer the type of a variable from its value. See Type inference and type annotations for more details. # This is how you declare the type of a variable # You don't need to initialize a variable to annotate it # Ok (no value at runtime until assigned) # Doing so can be useful in conditional branches\n\n# For most types, just use the name of the type in the annotation # Note that mypy can usually infer the type of a variable from its value, # so technically these annotations are redundant # For collections on Python 3.9+, the type of the collection item is in brackets # For mappings, we need the types of both keys and values # For tuples of fixed size, we specify the types of all the elements # For tuples of variable size, we use one type and ellipsis # On Python 3.8 and earlier, the name of the collection type is # capitalized, and the type is imported from the 'typing' module # On Python 3.10+, use the | operator when something could be one of a few types # Use X | None for a value that could be None on Python 3.10+ # Use Optional[X] on 3.9 and earlier; Optional[X] is the same as 'X | None' # Mypy understands x won't be None here because of the if-statement # If you know a value can never be None due to some logic that mypy doesn't\n\n# This is how you annotate a function definition # And here's how you specify multiple arguments # If a function does not return a value, use None as the return type # Default value for an argument goes after the type annotation # Note that arguments without a type are dynamically typed (treated as Any) # and that functions without any annotations are not checked # This is how you annotate a callable (function) value # A generator function that yields ints is secretly just a function that # returns an iterator of ints, so that's how we annotate it # You can of course split a function annotation over multiple lines # Positional-only arguments can also be marked by using a name starting with # error: Too many positional arguments for \"quux\" # This says each positional arg and each keyword arg is a \"str\"\n\n# The \"__init__\" method doesn't return anything, so it gets return # type \"None\" just like any other method that doesn't return anything # mypy will infer the correct types for these instance variables # based on the types of the parameters. # For instance methods, omit type for \"self\" # User-defined classes are valid as types in annotations # Functions that accept BankAccount also accept any subclass of BankAccount! # You can optionally declare instance variables in the class body # You can use the ClassVar annotation to declare a class variable # If you want dynamic attributes on your class, have it # This will allow assignment to any A.x, if x is the same type as \"value\" # (use \"value: Any\" to allow arbitrary types) # This will allow access to any A.x, if x is compatible with the return type\n\nWhen you’re puzzled or when things are complicated¶ # To find out what type mypy infers for an expression anywhere in # your program, wrap it in reveal_type(). Mypy will print an error # message with the type; remove it again before running the code. # If you initialize a variable with an empty container or \"None\" # you may have to help mypy a bit by providing an explicit type annotation # Use Any if you don't know the type of something or it's too # Mypy will let you do anything with x! # Use a \"type: ignore\" comment to suppress errors on a given line, # when your code confuses mypy or runs into an outright bug in mypy. # Good practice is to add a comment explaining the issue. # type: ignore # confusing_function won't return None here because ... # \"cast\" is a helper function that lets you override the inferred # type of an expression. It's only for mypy -- there's no runtime check. # Passes fine despite being a lie (no runtime check) # Still prints [4] ... the object is not changed or casted at runtime # Use \"TYPE_CHECKING\" if you want to have code that mypy can see but will not # be executed at runtime (or to have code that mypy can't see) # mypy is unaware of this In some cases type annotations can cause issues at runtime, see Annotation issues at runtime for dealing with this. See Silencing type errors for details on how to silence errors.\n\nIn typical Python code, many functions that can take a list or a dict as an argument only need their argument to be somehow “list-like” or “dict-like”. A specific meaning of “list-like” or “dict-like” (or something-else-like) is called a “duck type”, and several duck types that are common in idiomatic Python are standardized. # or 'from typing import ...' (required in Python 3.8) # Use Iterable for generic iterables (anything usable in \"for\"), # and Sequence where a sequence (supporting \"len\" and \"__getitem__\") is # Mapping describes a dict-like object (with \"__getitem__\") that we won't # mutate, and MutableMapping one (with \"__setitem__\") that we might # mypy will complain about this line... # ...but mypy is OK with this. # Use IO[str] or IO[bytes] for functions that should accept or return # objects that come from an open() call (note that IO does not # distinguish between reading, writing or other modes) You can even make your own duck types using Protocols and structural subtyping."
    },
    {
        "link": "https://docs.python.org/3/library/stdtypes.html",
        "document": "The following sections describe the standard types that are built into the interpreter.\n\nThe principal built-in types are numerics, sequences, mappings, classes, instances and exceptions.\n\nSome collection classes are mutable. The methods that add, subtract, or rearrange their members in place, and don’t return a specific item, never return the collection instance itself but .\n\nSome operations are supported by several object types; in particular, practically all objects can be compared for equality, tested for truth value, and converted to a string (with the function or the slightly different function). The latter function is implicitly used when an object is written by the function.\n\nThere are three distinct numeric types: integers, floating-point numbers, and complex numbers. In addition, Booleans are a subtype of integers. Integers have unlimited precision. Floating-point numbers are usually implemented using double in C; information about the precision and internal representation of floating-point numbers for the machine on which your program is running is available in . Complex numbers have a real and imaginary part, which are each a floating-point number. To extract these parts from a complex number z, use and . (The standard library includes the additional numeric types , for rationals, and , for floating-point numbers with user-definable precision.) Numbers are created by numeric literals or as the result of built-in functions and operators. Unadorned integer literals (including hex, octal and binary numbers) yield integers. Numeric literals containing a decimal point or an exponent sign yield floating-point numbers. Appending or to a numeric literal yields an imaginary number (a complex number with a zero real part) which you can add to an integer or float to get a complex number with real and imaginary parts. Python fully supports mixed arithmetic: when a binary arithmetic operator has operands of different numeric types, the operand with the “narrower” type is widened to that of the other, where integer is narrower than floating point, which is narrower than complex. A comparison between numbers of different types behaves as though the exact values of those numbers were being compared. The constructors , , and can be used to produce numbers of a specific type. All numeric types (except complex) support the following operations (for priorities of the operations, see Operator precedence): absolute value or magnitude of x a complex number with real part re, imaginary part im. im defaults to zero. conjugate of the complex number c\n• None Also referred to as integer division. For operands of type , the result has type . For operands of type , the result has type . In general, the result is a whole integer, though the result’s type is not necessarily . The result is always rounded towards minus infinity: is , is , is , and is .\n• None Not for complex numbers. Instead convert to floats using if appropriate.\n• None Conversion from to truncates, discarding the fractional part. See functions and for alternative conversions.\n• None float also accepts the strings “nan” and “inf” with an optional prefix “+” or “-” for Not a Number (NaN) and positive or negative infinity.\n• None Python defines and to be , as is common for programming languages.\n• None The numeric literals accepted include the digits to or any Unicode equivalent (code points with the property). See the Unicode Standard for a complete list of code points with the property. All types ( and ) also include the following operations: x rounded to n digits, rounding half to even. If n is omitted, it defaults to 0. For additional numeric operations see the and modules. Bitwise operations only make sense for integers. The result of bitwise operations is calculated as though carried out in two’s complement with an infinite number of sign bits. The priorities of the binary bitwise operations are all lower than the numeric operations and higher than the comparisons; the unary operation has the same priority as the other unary numeric operations ( and ). This table lists the bitwise operations sorted in ascending priority: bitwise exclusive or of x and y\n• None Negative shift counts are illegal and cause a to be raised.\n• None A left shift by n bits is equivalent to multiplication by .\n• None A right shift by n bits is equivalent to floor division by .\n• None Performing these calculations with at least one extra sign extension bit in a finite two’s complement representation (a working bit-width of or more) is sufficient to get the same result as if there were an infinite number of sign bits. The int type implements the abstract base class. In addition, it provides a few more methods: Return the number of bits necessary to represent an integer in binary, excluding the sign and leading zeros: More precisely, if is nonzero, then is the unique positive integer such that . Equivalently, when is small enough to have a correctly rounded logarithm, then . If is zero, then returns . Return the number of ones in the binary representation of the absolute value of the integer. This is also known as the population count. Example: Return an array of bytes representing an integer. The integer is represented using length bytes, and defaults to 1. An is raised if the integer is not representable with the given number of bytes. The byteorder argument determines the byte order used to represent the integer, and defaults to . If byteorder is , the most significant byte is at the beginning of the byte array. If byteorder is , the most significant byte is at the end of the byte array. The signed argument determines whether two’s complement is used to represent the integer. If signed is and a negative integer is given, an is raised. The default value for signed is . The default values can be used to conveniently turn an integer into a single byte object: However, when using the default arguments, don’t try to convert a value greater than 255 or you’ll get an . \"byteorder must be either 'little' or 'big'\" Changed in version 3.11: Added default argument values for and . Return the integer represented by the given array of bytes. The argument bytes must either be a bytes-like object or an iterable producing bytes. The byteorder argument determines the byte order used to represent the integer, and defaults to . If byteorder is , the most significant byte is at the beginning of the byte array. If byteorder is , the most significant byte is at the end of the byte array. To request the native byte order of the host system, use as the byte order value. The signed argument indicates whether two’s complement is used to represent the integer. \"byteorder must be either 'little' or 'big'\" Changed in version 3.11: Added default argument value for . Return a pair of integers whose ratio is equal to the original integer and has a positive denominator. The integer ratio of integers (whole numbers) is always the integer as the numerator and as the denominator. The float type implements the abstract base class. float also has the following additional methods. Return a pair of integers whose ratio is exactly equal to the original float. The ratio is in lowest terms and has a positive denominator. Raises on infinities and a on NaNs. Return if the float instance is finite with integral value, and otherwise: Two methods support conversion to and from hexadecimal strings. Since Python’s floats are stored internally as binary numbers, converting a float to or from a decimal string usually involves a small rounding error. In contrast, hexadecimal strings allow exact representation and specification of floating-point numbers. This can be useful when debugging, and in numerical work. Return a representation of a floating-point number as a hexadecimal string. For finite floating-point numbers, this representation will always include a leading and a trailing and exponent. Class method to return the float represented by a hexadecimal string s. The string s may have leading and trailing whitespace. Note that is an instance method, while is a class method. where the optional may by either or , and are strings of hexadecimal digits, and is a decimal integer with an optional leading sign. Case is not significant, and there must be at least one hexadecimal digit in either the integer or the fraction. This syntax is similar to the syntax specified in section 6.4.4.2 of the C99 standard, and also to the syntax used in Java 1.5 onwards. In particular, the output of is usable as a hexadecimal floating-point literal in C or Java code, and hexadecimal strings produced by C’s format character or Java’s are accepted by . Note that the exponent is written in decimal rather than hexadecimal, and that it gives the power of 2 by which to multiply the coefficient. For example, the hexadecimal string represents the floating-point number , or : Applying the reverse conversion to gives a different hexadecimal string representing the same number: For numbers and , possibly of different types, it’s a requirement that whenever (see the method documentation for more details). For ease of implementation and efficiency across a variety of numeric types (including , , and ) Python’s hash for numeric types is based on a single mathematical function that’s defined for any rational number, and hence applies to all instances of and , and all finite instances of and . Essentially, this function is given by reduction modulo for a fixed prime . The value of is made available to Python as the attribute of . CPython implementation detail: Currently, the prime used is on machines with 32-bit C longs and on machines with 64-bit C longs. Here are the rules in detail:\n• None If is a nonnegative rational number and is not divisible by , define as , where gives the inverse of modulo .\n• None If is a nonnegative rational number and is divisible by (but is not) then has no inverse modulo and the rule above doesn’t apply; in this case define to be the constant value .\n• None If is a negative rational number define as . If the resulting hash is , replace it with .\n• None The particular values and are used as hash values for positive infinity or negative infinity (respectively).\n• None For a number , the hash values of the real and imaginary parts are combined by computing , reduced modulo so that it lies in . Again, if the result is , it’s replaced with . To clarify the above rules, here’s some example Python code, equivalent to the built-in hash, for computing the hash of a rational number, , or : Assumes m and n are integers, with n positive. # Remove common factors of P. (Unnecessary if m and n already coprime.) # Fermat's Little Theorem: pow(n, P-1, P) is 1, so # pow(n, P-2, P) gives the inverse of n modulo P.\n\nThere are three basic sequence types: lists, tuples, and range objects. Additional sequence types tailored for processing of binary data and text strings are described in dedicated sections. The operations in the following table are supported by most sequence types, both mutable and immutable. The ABC is provided to make it easier to correctly implement these operations on custom sequence types. This table lists the sequence operations sorted in ascending priority. In the table, s and t are sequences of the same type, n, i, j and k are integers and x is an arbitrary object that meets any type and value restrictions imposed by s. The and operations have the same priorities as the comparison operations. The (concatenation) and (repetition) operations have the same priority as the corresponding numeric operations. if an item of s is equal to x, else if an item of s is equal to x, else the concatenation of s and t equivalent to adding s to itself n times slice of s from i to j with step k index of the first occurrence of x in s (at or after index i and before index j) total number of occurrences of x in s Sequences of the same type also support comparisons. In particular, tuples and lists are compared lexicographically by comparing corresponding elements. This means that to compare equal, every element must compare equal and the two sequences must be of the same type and have the same length. (For full details see Comparisons in the language reference.) Forward and reversed iterators over mutable sequences access values using an index. That index will continue to march forward (or backward) even if the underlying sequence is mutated. The iterator terminates only when an or a is encountered (or when the index drops below zero).\n• None While the and operations are used only for simple containment testing in the general case, some specialised sequences (such as , and ) also use them for subsequence testing:\n• None Values of n less than are treated as (which yields an empty sequence of the same type as s). Note that items in the sequence s are not copied; they are referenced multiple times. This often haunts new Python programmers; consider: What has happened is that is a one-element list containing an empty list, so all three elements of are references to this single empty list. Modifying any of the elements of modifies this single list. You can create a list of different lists this way: Further explanation is available in the FAQ entry How do I create a multidimensional list?.\n• None If i or j is negative, the index is relative to the end of sequence s: or is substituted. But note that is still .\n• None The slice of s from i to j is defined as the sequence of items with index k such that . If i or j is greater than , use . If i is omitted or , use . If j is omitted or , use . If i is greater than or equal to j, the slice is empty.\n• None The slice of s from i to j with step k is defined as the sequence of items with index such that . In other words, the indices are , , , and so on, stopping when j is reached (but never including j). When k is positive, i and j are reduced to if they are greater. When k is negative, i and j are reduced to if they are greater. If i or j are omitted or , they become “end” values (which end depends on the sign of k). Note, k cannot be zero. If k is , it is treated like .\n• None Concatenating immutable sequences always results in a new object. This means that building up a sequence by repeated concatenation will have a quadratic runtime cost in the total sequence length. To get a linear runtime cost, you must switch to one of the alternatives below:\n• None if concatenating objects, you can build a list and use at the end or else write to an instance and retrieve its value when complete\n• None if concatenating objects, you can similarly use or , or you can do in-place concatenation with a object. objects are mutable and have an efficient overallocation mechanism\n• None for other types, investigate the relevant class documentation\n• None Some sequence types (such as ) only support item sequences that follow specific patterns, and hence don’t support sequence concatenation or repetition.\n• None raises when x is not found in s. Not all implementations support passing the additional arguments i and j. These arguments allow efficient searching of subsections of the sequence. Passing the extra arguments is roughly equivalent to using , only without copying any data and with the returned index being relative to the start of the sequence rather than the start of the slice. The only operation that immutable sequence types generally implement that is not also implemented by mutable sequence types is support for the built-in. This support allows immutable sequences, such as instances, to be used as keys and stored in and instances. Attempting to hash an immutable sequence that contains unhashable values will result in . The operations in the following table are defined on mutable sequence types. The ABC is provided to make it easier to correctly implement these operations on custom sequence types. In the table s is an instance of a mutable sequence type, t is any iterable object and x is an arbitrary object that meets any type and value restrictions imposed by s (for example, only accepts integers that meet the value restriction ). item i of s is replaced by x slice of s from i to j is replaced by the contents of the iterable t the elements of are replaced by those of t removes the elements of from the list appends x to the end of the sequence (same as ) removes all items from s (same as ) creates a shallow copy of s (same as ) extends s with the contents of t (for the most part the same as ) inserts x into s at the index given by i (same as ) retrieves the item at i and also removes it from s removes the first item from s where is equal to x reverses the items of s in place\n• None If k is not equal to , t must have the same length as the slice it is replacing.\n• None The optional argument i defaults to , so that by default the last item is removed and returned.\n• None raises when x is not found in s.\n• None The method modifies the sequence in place for economy of space when reversing a large sequence. To remind users that it operates by side effect, it does not return the reversed sequence.\n• None and are included for consistency with the interfaces of mutable containers that don’t support slicing operations (such as and ). is not part of the ABC, but most concrete mutable sequence classes provide it.\n• None The value n is an integer, or an object implementing . Zero and negative values of n clear the sequence. Items in the sequence are not copied; they are referenced multiple times, as explained for under Common Sequence Operations. Lists are mutable sequences, typically used to store collections of homogeneous items (where the precise degree of similarity will vary by application). Lists may be constructed in several ways:\n• None Using a pair of square brackets to denote the empty list:\n• None Using the type constructor: or The constructor builds a list whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a list, a copy is made and returned, similar to . For example, returns and returns . If no argument is given, the constructor creates a new empty list, . Many other operations also produce lists, including the built-in. Lists implement all of the common and mutable sequence operations. Lists also provide the following additional method: This method sorts the list in place, using only comparisons between items. Exceptions are not suppressed - if any comparison operations fail, the entire sort operation will fail (and the list will likely be left in a partially modified state). accepts two arguments that can only be passed by keyword (keyword-only arguments): key specifies a function of one argument that is used to extract a comparison key from each list element (for example, ). The key corresponding to each item in the list is calculated once and then used for the entire sorting process. The default value of means that list items are sorted directly without calculating a separate key value. The utility is available to convert a 2.x style cmp function to a key function. reverse is a boolean value. If set to , then the list elements are sorted as if each comparison were reversed. This method modifies the sequence in place for economy of space when sorting a large sequence. To remind users that it operates by side effect, it does not return the sorted sequence (use to explicitly request a new sorted list instance). The method is guaranteed to be stable. A sort is stable if it guarantees not to change the relative order of elements that compare equal — this is helpful for sorting in multiple passes (for example, sort by department, then by salary grade). For sorting examples and a brief sorting tutorial, see Sorting Techniques. CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even inspect, the list is undefined. The C implementation of Python makes the list appear empty for the duration, and raises if it can detect that the list has been mutated during a sort. Tuples are immutable sequences, typically used to store collections of heterogeneous data (such as the 2-tuples produced by the built-in). Tuples are also used for cases where an immutable sequence of homogeneous data is needed (such as allowing storage in a or instance). Tuples may be constructed in a number of ways:\n• None Using a pair of parentheses to denote the empty tuple:\n• None Using a trailing comma for a singleton tuple: or\n• None Using the built-in: or The constructor builds a tuple whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a tuple, it is returned unchanged. For example, returns and returns . If no argument is given, the constructor creates a new empty tuple, . Note that it is actually the comma which makes a tuple, not the parentheses. The parentheses are optional, except in the empty tuple case, or when they are needed to avoid syntactic ambiguity. For example, is a function call with three arguments, while is a function call with a 3-tuple as the sole argument. Tuples implement all of the common sequence operations. For heterogeneous collections of data where access by name is clearer than access by index, may be a more appropriate choice than a simple tuple object. The type represents an immutable sequence of numbers and is commonly used for looping a specific number of times in loops. The arguments to the range constructor must be integers (either built-in or any object that implements the special method). If the step argument is omitted, it defaults to . If the start argument is omitted, it defaults to . If step is zero, is raised. For a positive step, the contents of a range are determined by the formula where and . For a negative step, the contents of the range are still determined by the formula , but the constraints are and . A range object will be empty if does not meet the value constraint. Ranges do support negative indices, but these are interpreted as indexing from the end of the sequence determined by the positive indices. Ranges containing absolute values larger than are permitted but some features (such as ) may raise . Ranges implement all of the common sequence operations except concatenation and repetition (due to the fact that range objects can only represent sequences that follow a strict pattern and repetition and concatenation will usually violate that pattern). The value of the start parameter (or if the parameter was not supplied) The value of the stop parameter The value of the step parameter (or if the parameter was not supplied) The advantage of the type over a regular or is that a object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the , and values, calculating individual items and subranges as needed). Range objects implement the ABC, and provide features such as containment tests, element index lookup, slicing and support for negative indices (see Sequence Types — list, tuple, range): Testing range objects for equality with and compares them as sequences. That is, two range objects are considered equal if they represent the same sequence of values. (Note that two range objects that compare equal might have different , and attributes, for example or .) Changed in version 3.2: Implement the Sequence ABC. Support slicing and negative indices. Test objects for membership in constant time instead of iterating through all items. Changed in version 3.3: Define ‘==’ and ‘!=’ to compare range objects based on the sequence of values they define (instead of comparing based on object identity).\n• None The linspace recipe shows how to implement a lazy version of range suitable for floating-point applications."
    },
    {
        "link": "https://fastapi.tiangolo.com/python-types",
        "document": "Python has support for optional \"type hints\" (also called \"type annotations\").\n\nThese \"type hints\" or annotations are a special syntax that allow declaring the of a variable.\n\nBy declaring types for your variables, editors and tools can give you better support.\n\nThis is just a quick tutorial / refresher about Python type hints. It covers only the minimum necessary to use them with FastAPI... which is actually very little.\n\nFastAPI is all based on these type hints, they give it many advantages and benefits.\n\nBut even if you never use FastAPI, you would benefit from learning a bit about them.\n\nThe function does the following:\n• Converts the first letter of each one to upper case with .\n• them with a space in the middle.\n\nBut now imagine that you were writing it from scratch.\n\nAt some point you would have started the definition of the function, you had the parameters ready...\n\nBut then you have to call \"that method that converts the first letter to upper case\".\n\nWas it ? Was it ? ? ?\n\nThen, you try with the old programmer's friend, editor autocompletion.\n\nYou type the first parameter of the function, , then a dot ( ) and then hit to trigger the completion.\n\nBut, sadly, you get nothing useful:\n\nWe will change exactly this fragment, the parameters of the function, from:\n\nThose are the \"type hints\":\n\nThat is not the same as declaring default values like would be with:\n\nWe are using colons ( ), not equals ( ).\n\nAnd adding type hints normally doesn't change what happens from what would happen without them.\n\nBut now, imagine you are again in the middle of creating that function, but with type hints.\n\nAt the same point, you try to trigger the autocomplete with and you see:\n\nWith that, you can scroll, seeing the options, until you find the one that \"rings a bell\":\n\nCheck this function, it already has type hints:\n\nBecause the editor knows the types of the variables, you don't only get completion, you also get error checks:\n\nNow you know that you have to fix it, convert to a string with :\n\nYou just saw the main place to declare type hints. As function parameters.\n\nThis is also the main place you would use them with FastAPI.\n\nYou can declare all the standard Python types, not only .\n\nYou can use, for example:\n\nThere are some data structures that can contain other values, like , , and . And the internal values can have their own type too.\n\nThese types that have internal types are called \"generic\" types. And it's possible to declare them, even with their internal types.\n\nTo declare those types and the internal types, you can use the standard Python module . It exists specifically to support these type hints.\n\nThe syntax using is compatible with all versions, from Python 3.6 to the latest ones, including Python 3.9, Python 3.10, etc.\n\nAs Python advances, newer versions come with improved support for these type annotations and in many cases you won't even need to import and use the module to declare the type annotations.\n\nIf you can choose a more recent version of Python for your project, you will be able to take advantage of that extra simplicity.\n\nIn all the docs there are examples compatible with each version of Python (when there's a difference).\n\nFor example \"Python 3.6+\" means it's compatible with Python 3.6 or above (including 3.7, 3.8, 3.9, 3.10, etc). And \"Python 3.9+\" means it's compatible with Python 3.9 or above (including 3.10, etc).\n\nIf you can use the latest versions of Python, use the examples for the latest version, those will have the best and simplest syntax, for example, \"Python 3.10+\".\n\nFor example, let's define a variable to be a of .\n\nThat means: \"the variable is a , and each of the items in this list is a \".\n\nBy doing that, your editor can provide support even while processing items from the list:\n\nWithout types, that's almost impossible to achieve.\n\nNotice that the variable is one of the elements in the list .\n\nAnd still, the editor knows it is a , and provides support for that.\n\nYou would do the same to declare s and s:\n• The variable is a with 3 items, an , another , and a .\n• The variable is a , and each of its items is of type .\n\nTo define a , you pass 2 type parameters, separated by commas.\n\nThe first type parameter is for the keys of the .\n\nThe second type parameter is for the values of the :\n• The variable is a :\n• The keys of this are of type (let's say, the name of each item).\n• The values of this are of type (let's say, the price of each item).\n\nYou can declare that a variable can be any of several types, for example, an or a .\n\nIn Python 3.6 and above (including Python 3.10) you can use the type from and put inside the square brackets the possible types to accept.\n\nIn Python 3.10 there's also a new syntax where you can put the possible types separated by a .\n\nIn both cases this means that could be an or a .\n\nYou can declare that a value could have a type, like , but that it could also be .\n\nIn Python 3.6 and above (including Python 3.10) you can declare it by importing and using from the module.\n\nUsing instead of just will let the editor help you detect errors where you could be assuming that a value is always a , when it could actually be too.\n\nis actually a shortcut for , they are equivalent.\n\nThis also means that in Python 3.10, you can use :\n\nIf you are using a Python version below 3.10, here's a tip from my very subjective point of view:\n\nBoth are equivalent and underneath they are the same, but I would recommend instead of because the word \"optional\" would seem to imply that the value is optional, and it actually means \"it can be \", even if it's not optional and is still required.\n\nI think is more explicit about what it means.\n\nIt's just about the words and names. But those words can affect how you and your teammates think about the code.\n\nAs an example, let's take this function:\n\nThe parameter is defined as , but it is not optional, you cannot call the function without the parameter:\n\nThe parameter is still required (not optional) because it doesn't have a default value. Still, accepts as the value:\n\nThe good news is, once you are on Python 3.10 you won't have to worry about that, as you will be able to simply use to define unions of types:\n\nAnd then you won't have to worry about names like and . 😎\n\nThese types that take type parameters in square brackets are called Generic types or Generics, for example:\n\nYou can also declare a class as the type of a variable.\n\nLet's say you have a class , with a name:\n\nThen you can declare a variable to be of type :\n\nAnd then, again, you get all the editor support:\n\nNotice that this means \" is an instance of the class \".\n\nIt doesn't mean \" is the class called \".\n\nYou declare the \"shape\" of the data as classes with attributes.\n\nAnd each attribute has a type.\n\nThen you create an instance of that class with some values and it will validate the values, convert them to the appropriate type (if that's the case) and give you an object with all the data.\n\nAnd you get all the editor support with that resulting object.\n\nAn example from the official Pydantic docs:\n\nFastAPI is all based on Pydantic.\n\nYou will see a lot more of all this in practice in the Tutorial - User Guide.\n\nPython also has a feature that allows putting additional in these type hints using .\n\nPython itself doesn't do anything with this . And for editors and other tools, the type is still .\n\nBut you can use this space in to provide FastAPI with additional metadata about how you want your application to behave.\n\nThe important thing to remember is that the first type parameter you pass to is the actual type. The rest, is just metadata for other tools.\n\nFor now, you just need to know that exists, and that it's standard Python. 😎\n\nLater you will see how powerful it can be.\n\nFastAPI takes advantage of these type hints to do several things.\n\nWith FastAPI you declare parameters with type hints and you get:\n\n...and FastAPI uses the same declarations to:\n• Convert data: from the request to the required type.\n• Validate data: coming from each request:\n• Generating automatic errors returned to the client when the data is invalid.\n• Document the API using OpenAPI:\n• which is then used by the automatic interactive documentation user interfaces.\n\nThis might all sound abstract. Don't worry. You'll see all this in action in the Tutorial - User Guide.\n\nThe important thing is that by using standard Python types, in a single place (instead of adding more classes, decorators, etc), FastAPI will do a lot of the work for you."
    },
    {
        "link": "https://fastapi.tiangolo.com/python-types",
        "document": "Python has support for optional \"type hints\" (also called \"type annotations\").\n\nThese \"type hints\" or annotations are a special syntax that allow declaring the of a variable.\n\nBy declaring types for your variables, editors and tools can give you better support.\n\nThis is just a quick tutorial / refresher about Python type hints. It covers only the minimum necessary to use them with FastAPI... which is actually very little.\n\nFastAPI is all based on these type hints, they give it many advantages and benefits.\n\nBut even if you never use FastAPI, you would benefit from learning a bit about them.\n\nThe function does the following:\n• Converts the first letter of each one to upper case with .\n• them with a space in the middle.\n\nBut now imagine that you were writing it from scratch.\n\nAt some point you would have started the definition of the function, you had the parameters ready...\n\nBut then you have to call \"that method that converts the first letter to upper case\".\n\nWas it ? Was it ? ? ?\n\nThen, you try with the old programmer's friend, editor autocompletion.\n\nYou type the first parameter of the function, , then a dot ( ) and then hit to trigger the completion.\n\nBut, sadly, you get nothing useful:\n\nWe will change exactly this fragment, the parameters of the function, from:\n\nThose are the \"type hints\":\n\nThat is not the same as declaring default values like would be with:\n\nWe are using colons ( ), not equals ( ).\n\nAnd adding type hints normally doesn't change what happens from what would happen without them.\n\nBut now, imagine you are again in the middle of creating that function, but with type hints.\n\nAt the same point, you try to trigger the autocomplete with and you see:\n\nWith that, you can scroll, seeing the options, until you find the one that \"rings a bell\":\n\nCheck this function, it already has type hints:\n\nBecause the editor knows the types of the variables, you don't only get completion, you also get error checks:\n\nNow you know that you have to fix it, convert to a string with :\n\nYou just saw the main place to declare type hints. As function parameters.\n\nThis is also the main place you would use them with FastAPI.\n\nYou can declare all the standard Python types, not only .\n\nYou can use, for example:\n\nThere are some data structures that can contain other values, like , , and . And the internal values can have their own type too.\n\nThese types that have internal types are called \"generic\" types. And it's possible to declare them, even with their internal types.\n\nTo declare those types and the internal types, you can use the standard Python module . It exists specifically to support these type hints.\n\nThe syntax using is compatible with all versions, from Python 3.6 to the latest ones, including Python 3.9, Python 3.10, etc.\n\nAs Python advances, newer versions come with improved support for these type annotations and in many cases you won't even need to import and use the module to declare the type annotations.\n\nIf you can choose a more recent version of Python for your project, you will be able to take advantage of that extra simplicity.\n\nIn all the docs there are examples compatible with each version of Python (when there's a difference).\n\nFor example \"Python 3.6+\" means it's compatible with Python 3.6 or above (including 3.7, 3.8, 3.9, 3.10, etc). And \"Python 3.9+\" means it's compatible with Python 3.9 or above (including 3.10, etc).\n\nIf you can use the latest versions of Python, use the examples for the latest version, those will have the best and simplest syntax, for example, \"Python 3.10+\".\n\nFor example, let's define a variable to be a of .\n\nThat means: \"the variable is a , and each of the items in this list is a \".\n\nBy doing that, your editor can provide support even while processing items from the list:\n\nWithout types, that's almost impossible to achieve.\n\nNotice that the variable is one of the elements in the list .\n\nAnd still, the editor knows it is a , and provides support for that.\n\nYou would do the same to declare s and s:\n• The variable is a with 3 items, an , another , and a .\n• The variable is a , and each of its items is of type .\n\nTo define a , you pass 2 type parameters, separated by commas.\n\nThe first type parameter is for the keys of the .\n\nThe second type parameter is for the values of the :\n• The variable is a :\n• The keys of this are of type (let's say, the name of each item).\n• The values of this are of type (let's say, the price of each item).\n\nYou can declare that a variable can be any of several types, for example, an or a .\n\nIn Python 3.6 and above (including Python 3.10) you can use the type from and put inside the square brackets the possible types to accept.\n\nIn Python 3.10 there's also a new syntax where you can put the possible types separated by a .\n\nIn both cases this means that could be an or a .\n\nYou can declare that a value could have a type, like , but that it could also be .\n\nIn Python 3.6 and above (including Python 3.10) you can declare it by importing and using from the module.\n\nUsing instead of just will let the editor help you detect errors where you could be assuming that a value is always a , when it could actually be too.\n\nis actually a shortcut for , they are equivalent.\n\nThis also means that in Python 3.10, you can use :\n\nIf you are using a Python version below 3.10, here's a tip from my very subjective point of view:\n\nBoth are equivalent and underneath they are the same, but I would recommend instead of because the word \"optional\" would seem to imply that the value is optional, and it actually means \"it can be \", even if it's not optional and is still required.\n\nI think is more explicit about what it means.\n\nIt's just about the words and names. But those words can affect how you and your teammates think about the code.\n\nAs an example, let's take this function:\n\nThe parameter is defined as , but it is not optional, you cannot call the function without the parameter:\n\nThe parameter is still required (not optional) because it doesn't have a default value. Still, accepts as the value:\n\nThe good news is, once you are on Python 3.10 you won't have to worry about that, as you will be able to simply use to define unions of types:\n\nAnd then you won't have to worry about names like and . 😎\n\nThese types that take type parameters in square brackets are called Generic types or Generics, for example:\n\nYou can also declare a class as the type of a variable.\n\nLet's say you have a class , with a name:\n\nThen you can declare a variable to be of type :\n\nAnd then, again, you get all the editor support:\n\nNotice that this means \" is an instance of the class \".\n\nIt doesn't mean \" is the class called \".\n\nYou declare the \"shape\" of the data as classes with attributes.\n\nAnd each attribute has a type.\n\nThen you create an instance of that class with some values and it will validate the values, convert them to the appropriate type (if that's the case) and give you an object with all the data.\n\nAnd you get all the editor support with that resulting object.\n\nAn example from the official Pydantic docs:\n\nFastAPI is all based on Pydantic.\n\nYou will see a lot more of all this in practice in the Tutorial - User Guide.\n\nPython also has a feature that allows putting additional in these type hints using .\n\nPython itself doesn't do anything with this . And for editors and other tools, the type is still .\n\nBut you can use this space in to provide FastAPI with additional metadata about how you want your application to behave.\n\nThe important thing to remember is that the first type parameter you pass to is the actual type. The rest, is just metadata for other tools.\n\nFor now, you just need to know that exists, and that it's standard Python. 😎\n\nLater you will see how powerful it can be.\n\nFastAPI takes advantage of these type hints to do several things.\n\nWith FastAPI you declare parameters with type hints and you get:\n\n...and FastAPI uses the same declarations to:\n• Convert data: from the request to the required type.\n• Validate data: coming from each request:\n• Generating automatic errors returned to the client when the data is invalid.\n• Document the API using OpenAPI:\n• which is then used by the automatic interactive documentation user interfaces.\n\nThis might all sound abstract. Don't worry. You'll see all this in action in the Tutorial - User Guide.\n\nThe important thing is that by using standard Python types, in a single place (instead of adding more classes, decorators, etc), FastAPI will do a lot of the work for you."
    },
    {
        "link": "https://stackoverflow.com/questions/68154122/how-do-i-type-annotate-json-data-in-python",
        "document": "Json objects are usually like a bag of items. It can have numbers, string, floats, list and nested json objects. If you wish to deep dive into JSON body actual structure then following Option1 & 2 can assist you or you can do the 3 rd step.\n\nFirst Option: Please check this Python3 docs links.\n\nIf you can clearly define your json body then you can use following example.\n\nSecond Option: you can also define you own custom type classes to work with, unlike above where you create lots of global items.\n\nThird Option: Like the above suggested answers, using a is simple approach. Treat you json body as string and using json modules to convert it to string & viceversa\n\nFourth Option: Using a Library to define your classes - https://marshmallow.readthedocs.io/en/stable/\n\nIf you are working on Apache Spark then https://github.com/ketgo/marshmallow-pyspark is worth knowing about."
    },
    {
        "link": "https://mypy.readthedocs.io/en/latest/cheat_sheet_py3.html",
        "document": "This document is a quick cheat sheet showing how to use type annotations for various common types in Python.\n\nTechnically many of the type annotations shown below are redundant, since mypy can usually infer the type of a variable from its value. See Type inference and type annotations for more details. # This is how you declare the type of a variable # You don't need to initialize a variable to annotate it # Ok (no value at runtime until assigned) # Doing so can be useful in conditional branches\n\n# For most types, just use the name of the type in the annotation # Note that mypy can usually infer the type of a variable from its value, # so technically these annotations are redundant # For collections on Python 3.9+, the type of the collection item is in brackets # For mappings, we need the types of both keys and values # For tuples of fixed size, we specify the types of all the elements # For tuples of variable size, we use one type and ellipsis # On Python 3.8 and earlier, the name of the collection type is # capitalized, and the type is imported from the 'typing' module # On Python 3.10+, use the | operator when something could be one of a few types # Use X | None for a value that could be None on Python 3.10+ # Use Optional[X] on 3.9 and earlier; Optional[X] is the same as 'X | None' # Mypy understands x won't be None here because of the if-statement # If you know a value can never be None due to some logic that mypy doesn't\n\n# This is how you annotate a function definition # And here's how you specify multiple arguments # If a function does not return a value, use None as the return type # Default value for an argument goes after the type annotation # Note that arguments without a type are dynamically typed (treated as Any) # and that functions without any annotations are not checked # This is how you annotate a callable (function) value # A generator function that yields ints is secretly just a function that # returns an iterator of ints, so that's how we annotate it # You can of course split a function annotation over multiple lines # Positional-only arguments can also be marked by using a name starting with # error: Too many positional arguments for \"quux\" # This says each positional arg and each keyword arg is a \"str\"\n\n# The \"__init__\" method doesn't return anything, so it gets return # type \"None\" just like any other method that doesn't return anything # mypy will infer the correct types for these instance variables # based on the types of the parameters. # For instance methods, omit type for \"self\" # User-defined classes are valid as types in annotations # Functions that accept BankAccount also accept any subclass of BankAccount! # You can optionally declare instance variables in the class body # You can use the ClassVar annotation to declare a class variable # If you want dynamic attributes on your class, have it # This will allow assignment to any A.x, if x is the same type as \"value\" # (use \"value: Any\" to allow arbitrary types) # This will allow access to any A.x, if x is compatible with the return type\n\nWhen you’re puzzled or when things are complicated¶ # To find out what type mypy infers for an expression anywhere in # your program, wrap it in reveal_type(). Mypy will print an error # message with the type; remove it again before running the code. # If you initialize a variable with an empty container or \"None\" # you may have to help mypy a bit by providing an explicit type annotation # Use Any if you don't know the type of something or it's too # Mypy will let you do anything with x! # Use a \"type: ignore\" comment to suppress errors on a given line, # when your code confuses mypy or runs into an outright bug in mypy. # Good practice is to add a comment explaining the issue. # type: ignore # confusing_function won't return None here because ... # \"cast\" is a helper function that lets you override the inferred # type of an expression. It's only for mypy -- there's no runtime check. # Passes fine despite being a lie (no runtime check) # Still prints [4] ... the object is not changed or casted at runtime # Use \"TYPE_CHECKING\" if you want to have code that mypy can see but will not # be executed at runtime (or to have code that mypy can't see) # mypy is unaware of this In some cases type annotations can cause issues at runtime, see Annotation issues at runtime for dealing with this. See Silencing type errors for details on how to silence errors.\n\nIn typical Python code, many functions that can take a list or a dict as an argument only need their argument to be somehow “list-like” or “dict-like”. A specific meaning of “list-like” or “dict-like” (or something-else-like) is called a “duck type”, and several duck types that are common in idiomatic Python are standardized. # or 'from typing import ...' (required in Python 3.8) # Use Iterable for generic iterables (anything usable in \"for\"), # and Sequence where a sequence (supporting \"len\" and \"__getitem__\") is # Mapping describes a dict-like object (with \"__getitem__\") that we won't # mutate, and MutableMapping one (with \"__setitem__\") that we might # mypy will complain about this line... # ...but mypy is OK with this. # Use IO[str] or IO[bytes] for functions that should accept or return # objects that come from an open() call (note that IO does not # distinguish between reading, writing or other modes) You can even make your own duck types using Protocols and structural subtyping."
    },
    {
        "link": "https://fastapi.tiangolo.com/pl/python-types",
        "document": "Now you know that you have to fix it, convert to a string with :\n\nFor example, let's define a variable to be a of .\n\nTo define a , you pass 2 type parameters, separated by commas.\n\nIn Python 3.10 there's also a new syntax where you can put the possible types separated by a .\n\nIf you are using a Python version below 3.10, here's a tip from my very subjective point of view:\n\nThe good news is, once you are on Python 3.10 you won't have to worry about that, as you will be able to simply use to define unions of types:\n\nThe important thing is that by using standard Python types, in a single place (instead of adding more classes, decorators, etc), FastAPI will do a lot of the work for you."
    },
    {
        "link": "https://docs.pydantic.dev/latest/concepts/types",
        "document": "Where possible Pydantic uses standard library types to define fields, thus smoothing the learning curve. For many useful applications, however, no standard library type exists, so Pydantic implements many commonly used types.\n\nThere are also more complex types that can be found in the Pydantic Extra Types package.\n\nIf no existing type suits your purpose you can also implement your own Pydantic-compatible types with custom properties and validation.\n\nThe following sections describe the types supported by Pydantic.\n• Strict Types — types that enable you to prevent coercion from compatible types.\n• Field Type Conversions — strict and lax conversion between different field types.\n\nDuring validation, Pydantic can coerce data into expected types.\n\nThere are two modes of coercion: strict and lax. See Conversion Table for more details on how Pydantic converts data in both strict and lax modes.\n\nSee Strict mode and Strict Types for details on enabling strict coercion.\n\nPydantic provides the following strict types:\n\nThese types will only pass validation when the validated value is of the respective type or is a subtype of that type.\n\nThis behavior is also exposed via the field of the constrained types and can be combined with a multitude of complex validation rules. See the individual type signatures for supported arguments.\n• (and the option of ) will accept both , and types.\n• (and the option of ) will not accept types, even though is a subclass of in Python. Other subclasses will work.\n• (and the option of ) will not accept .\n\nBesides the above, you can also have a type that will only accept finite values (i.e. not , or ).\n\nYou can also define your own custom data types. There are several ways to achieve it.\n\nPEP 593 introduced as a way to attach runtime metadata to types without changing how type checkers interpret them. Pydantic takes advantage of this to allow you to create types that are identical to the original type as far as type checkers are concerned, but add validation, serialize differently, etc.\n\nFor example, to create a type representing a positive int:\n\nNote that you can also use constraints from annotated-types to make this Pydantic-agnostic:\n\nYou can add or override validation, serialization, and JSON schemas to an arbitrary type using the markers that Pydantic exports:\n\nYou can use type variables within to make reusable modifications to types:\n\nThe above examples make use of implicit type aliases. This means that they will not be able to have a in JSON schemas and their schema will be copied between fields. You can use PEP 695's via its typing-extensions backport to make named aliases, allowing you to define a new type without creating subclasses. This new type can be as simple as a name or have complex validation logic attached to it:\n\nThese named type aliases can also be generic:\n\nYou can also use to create recursive types:\n\nTo do more extensive customization of how Pydantic handles custom classes, and in particular when you have access to the class or can subclass it, you can implement a special to tell Pydantic how to generate the schema.\n\nWhile uses internally to handle validation and serialization, it is a new API for Pydantic V2, thus it is one of the areas most likely to be tweaked in the future and you should try to stick to the built-in constructs like those provided by , , or and so on.\n\nYou can implement both on a custom type and on metadata intended to be put in . In both cases the API is middleware-like and similar to that of \"wrap\" validators: you get a (which isn't necessarily the same as the class, in particular for generics) and a that you can call with a type to either call the next metadata in or call into Pydantic's internal schema generation.\n\nThe simplest no-op implementation calls the handler with the type you are given, then returns that as the result. You can also choose to modify the type before calling the handler, modify the core schema returned by the handler, or not call the handler at all.\n\nThe following is an example of a type that uses to customize how it gets validated. This is equivalent to implementing in Pydantic V1.\n\nSee JSON Schema for more details on how to customize JSON schemas for custom types.\n\nOften you'll want to parametrize your custom type by more than just generic type parameters (which you can do via the type system and will be discussed later). Or you may not actually care (or want to) make an instance of your subclass; you actually want the original type, just with some extra validation done.\n\nFor example, if you were to implement (see Adding validation and serialization) yourself, you'd do something similar to the following:\n\nAnother use case for the pattern in the previous section is to handle third party types.\n\nThis is meant to represent a type from a third-party library that wasn't designed with Pydantic integration in mind, and so doesn't have a `pydantic_core.CoreSchema` or anything. We return a pydantic_core.CoreSchema that behaves in the following ways: * ints will be parsed as `ThirdPartyType` instances with the int as the x attribute * `ThirdPartyType` instances will be parsed as `ThirdPartyType` instances without any changes * Nothing else will pass validation * Serialization will always return just an int # check if it's an instance first before doing any further work # Use the same schema that would be used for `int` # We now create an `Annotated` wrapper that we'll use as the annotation for fields on `BaseModel`s, etc. # Create a model class that uses this annotation as a field # Demonstrate that this field is handled correctly, that ints are parsed into `ThirdPartyType`, and that # these instances are also \"dumped\" directly into ints as expected. # Do the same thing where an instance of ThirdPartyType is passed in # Demonstrate that validation errors are raised as expected for invalid inputs Input should be an instance of ThirdPartyType [type=is_instance_of, input_value='a', input_type=str] Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str] This is meant to represent a type from a third-party library that wasn't designed with Pydantic integration in mind, and so doesn't have a `pydantic_core.CoreSchema` or anything. We return a pydantic_core.CoreSchema that behaves in the following ways: * ints will be parsed as `ThirdPartyType` instances with the int as the x attribute * `ThirdPartyType` instances will be parsed as `ThirdPartyType` instances without any changes * Nothing else will pass validation * Serialization will always return just an int # check if it's an instance first before doing any further work # Use the same schema that would be used for `int` # We now create an `Annotated` wrapper that we'll use as the annotation for fields on `BaseModel`s, etc. # Create a model class that uses this annotation as a field # Demonstrate that this field is handled correctly, that ints are parsed into `ThirdPartyType`, and that # these instances are also \"dumped\" directly into ints as expected. # Do the same thing where an instance of ThirdPartyType is passed in # Demonstrate that validation errors are raised as expected for invalid inputs Input should be an instance of ThirdPartyType [type=is_instance_of, input_value='a', input_type=str] Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n\nYou can use this approach to e.g. define behavior for Pandas or Numpy types.\n\nYou may notice that the above examples where we create a marker class require a good amount of boilerplate. For many simple cases you can greatly minimize this by using :\n• Pydantic provides high level hooks to customize types via like and . Use these when possible.\n• Under the hood these use to customize validation, and you can hook into that directly using or a marker class with .\n• If you really want a custom type you can implement on the type itself.\n\nYou can use Generic Classes as field types and perform custom validation based on the \"type parameters\" (or sub-types) with .\n\nIf the Generic class that you are using as a sub-type has a classmethod , you don't need to use for it to work.\n\nBecause the parameter is not the same as the parameter, you can use (or ) to extract the generic parameters. Then you can use the to generate a schema for them by calling . Note that we do not do something like because we want to generate an unrelated schema for that generic parameter, not one that is influenced by the current context of metadata and such. This is less important for custom types, but crucial for annotated metadata that modifies schema building.\n\nThe same idea can be applied to create generic container types, like a custom type:\n\nAs of Pydantic V2.4, you can access the field name via the within and thereby set the field name which will be available from .\n\nYou can also access from the markers used with , like ."
    },
    {
        "link": "https://stackoverflow.com/questions/68154122/how-do-i-type-annotate-json-data-in-python",
        "document": "Json objects are usually like a bag of items. It can have numbers, string, floats, list and nested json objects. If you wish to deep dive into JSON body actual structure then following Option1 & 2 can assist you or you can do the 3 rd step.\n\nFirst Option: Please check this Python3 docs links.\n\nIf you can clearly define your json body then you can use following example.\n\nSecond Option: you can also define you own custom type classes to work with, unlike above where you create lots of global items.\n\nThird Option: Like the above suggested answers, using a is simple approach. Treat you json body as string and using json modules to convert it to string & viceversa\n\nFourth Option: Using a Library to define your classes - https://marshmallow.readthedocs.io/en/stable/\n\nIf you are working on Apache Spark then https://github.com/ketgo/marshmallow-pyspark is worth knowing about."
    },
    {
        "link": "https://stackoverflow.com/questions/76345697/type-hinting-json-object-rigorously",
        "document": "I think you should avoid as much as possible (see these recommendations also). It is too often used as a cop-out of actually thinking about your data types. I also don't think your type hint is a convoluted mess. It is just formatted and structured sub-optimally in my opinion.\n\nAt the minimum, you could use line breaks and indentation for improved readability:\n\nAside from that, you should definitely remove redundancies in your type unions. An example is using a union of types , when is a subtype of . In that case just use .\n\nis a subtype of (check it with ), so you can drop the from the unions:\n\nThen you might want to use (explicit) type aliases to abstract some of the details a bit and reduce repetition. I would also suggest to always place last in a type union, but this may just be my preference:\n\nAnd at best, those nested types actually get some semantic names/aliases. Here you did not yet provide enough information, so the best I can do is provide some generic names like this:\n\nBut if you can name those appropriately, not only will this be more concise in the actual function signature, but it will also be much clearer to anyone reading the code, what those types actually mean. Which leads into your second question.\n\nThe better you name things in your code, the less comments and documentation you will need. Obviously documentation is necessary, but you will be able to leverage the names you already defined to make it much more concise and precise.\n\nIn this case, you will be able to refer to some of your type aliases directly, writing things like this:\n\nshould be a list of \"items\"; an item is a dictionary with string-keys, where each value is a \"value\"; a value can be either a string, an integer, a dictionary of strings or integers or .\n\nI am again deliberately using generic terms like \"item\" and \"value\", for which you can substitute something with actual meaning in your specific context.\n\nLastly, I would advise not calling that parameter in the first place because that is a confusing and frankly incorrect name for what that object will contain. JSON as you know is just a specific text format. It would make sense to call that parameter this way, if you expected the argument to be a of actual JSON.\n\nBut you don't expect that. Your function expects built-in Python types that you can lay out very precisely (as above). And your function is (and should be) agnostic about where those objects come from - a parsed JSON file or anywhere else. It would work the same, regardless of where that list of dictionaries etc. came from. Therefore the \"JSON\" in the parameter name is simply misleading and unnecessary. \"Response\" may be sensible in terms of meaning, again I don't know the context.\n\nAnd yes, I would suggest always fully documenting your parameters (and their more complex types if necessary) in the function's docstring. This does not mean you should avoid mentioning that somewhere else as well, but the docstring should explain everything one needs to know to use that function.\n\nIn summary, I would probably write it something like this:\n\nI have omitted a lot of \"in general\", \"typically\", and \"my advice would be\" clauses in my answer here. But I think it goes without saying that most of this is at least somewhat subjective or conventional.\n\nAll that being said, I am a big fan of Pydantic and agree completely with Roland in the comments that it seems like yours is a prime use case for it. Especially if the objects involved mostly follow a certain schema, you could define models for what I called and instead to encapsulate their meaning even better.\n\nNot to mention it offers validation and provides much better type safety overall.\n\nBut I think most of what I wrote above still applies regardless of whether you use Pydantic models or built-in types."
    },
    {
        "link": "https://medium.com/@erick.peirson/type-checking-with-json-schema-in-python-3244f3917329",
        "document": "Occasionally (usually while Little Human #1 is down for a nap) I get a few minutes to play around with something not on the critical path for work projects. On one such occasion, I started to wonder about the not-uncommon case in which an API resource (described with JSON Schema) is very similar if not identical in structure to the data we’re passing around inside an app (described with type annotations). This kind of thing might look familiar: The example above is not terribly interesting, but you get the idea: we have a JSON Schema for API tests (and our poor API consumers), and we have a (thanks to PEP 589 and mypy_extensions) for our static type checks. Is it really always necessary to maintain two descriptions of what are essentially the same data structure? Of course, there is not a perfect 1:1 mapping between concepts in JSON Schema and Python’s type annotations. Most notably, JSON Schema tends toward open-ended-ness, asserting constraints on data rather than providing a complete description. Unless specifically prohibited, a document may go beyond the specific properties enumerated in its schema. Type annotations in Python come down across the spectrum, ranging from permissive approaches like structural duck typing with Protocols (PEP 544) on one end to approaches like that provide a complete and total description. At a more basic level, there isn’t a direct mapping between primitive data types. For example, JSON inherits JavaScript’s ambivalence about integers and floating point numbers, so the JSON struct would satisfy the schema ; however, that JSON could plausibly be deserialized to the Python struct which would not satisfy in a declaration. Nevertheless, I suspect that there is enough of an isomorphism between JSON Schema and Python typing to warrant some exploration of the possibilities. Since a JSON document is generally represented as a in Python programs, I started looking specifically at interpreting JSON schema as definitions.\n\nThe driving intuition is that we shouldn’t have to write and maintain the (nearly) same type constraints for what are essentially two views on the same data. Not all applications that work with JSON resources are structured this way. But for those that are, eliminating duplicated information may reduce errors and will certainly reduce effort. To be clear, this isn’t about validating JSON. JSON Schema validation (e.g. as implemented in jsonschema) is about the correctness/conformity of an instance of the schema, a JSON document. What I’m interested in here is translating a JSON Schema into a set of Python type constraints that can be leveraged in static type checking. What this means in practical terms is that we need a way to refer to a JSON Schema document in a Python program, load that document during static analysis (i.e. not in the program runtime), and integrate type information from the schema into the type checking process. Something like:"
    },
    {
        "link": "https://rob-blackbourn.medium.com/enhancing-json-serialization-in-python-with-typing-a481017934c5",
        "document": "Maintaining valid types when deserializing JSON with Python is hard. This article discusses an approach using typing. You can find the package on GitHub.\n\nHere we have a python with a mix of data types.\n\nBecause the dict contains and this won’t serialize without some extra work:\n\nTo support the serialization of these types we need to provide an encoder.\n\nThis is quite nice. We simply check to see if the object is of a particular type and return a JSON compatible object. For the date this is a string (although we’d prefer it to be in proper ISO 8601 format), and the Decimal becomes a float. Now our serialization works:\n\nObviously we haven’t provided any information about the dates and decimals, so we just get back the standard JSON types. To do this we need to provide an function. The object hook takes in any dictionary the JSON parser finds and changes it in any way it sees fit.\n\nDetecting the desired type is obviously a problem. Here I “detected” the type by trying to convert every entry. I could used a regular expression to check first, but I still have to check everything.\n\nHowever my main problem is that there is no way of telling between a float and a decimal. Rob sad :(\n\nThe deserialization now looks like this.\n\nWe could put in some business logic to use the key names, but this would require a custom decoder for each data set. We could put some type information in the JSON, but we may not be in control of its generation, and anyway that looks ugly.\n\nWith type annotations we should be able to solve this problem. The data structure we are streaming can be “typed” by using a . in Python 3.7 this can be found in the package, while in 3.8 it is standard.\n\nUsing the package we can use these type annotations. It relies heavily on the package.\n\nLets see what happens when we serialize our data.\n\nFirst it’s camel-cased the keys! The takes a key serializer and deserializer (using the stringcase package). We can see the date got formatted nicely (the config option also allows for value serializers).\n\nNow lets see how the JSON is deserialized.\n\nThe keys are now snake-case and the types have been correctly identified, even the decimals. A quick check shows a successful round trip.\n\nAnd just for fun, we can serialize into XML.\n\nAs XML requires a tag to wrap the object we needed to put in some extra information which was achieved with the tag available through the typing extensions package and described in PEP 593.\n\nI’ve been using this with a REST framework which uses typing to automatically bind variables to reduce the effort to produce the API. You can find that code here."
    },
    {
        "link": "https://zyte.com/blog/json-parsing-with-python",
        "document": "JSON (JavaScript Object Notation) is a text-based data format used for exchanging and storing data between web applications. It simplifies the data transmission process between different programming languages and platforms.\n\nThe has become increasingly popular in recent years. It’s a simple and flexible way of representing data that can be easily understood and parsed by both humans and machines. JSON consists of key-value pairs enclosed in curly braces, separated by a colon.\n\nPython provides various and manipulating JSON data, making it a popular choice for data analysts, web developers, and data scientists.\n\nIn this guide, we’ll explore the syntax and data types of JSON, as well as the Python libraries and methods used for parsing JSON data, including more advanced options like JMESPath and ChompJS, which are very useful for web scraping data."
    }
]