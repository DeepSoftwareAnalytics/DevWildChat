[
    {
        "link": "https://mathworks.com/help/signal/time-frequency-analysis.html",
        "document": ""
    },
    {
        "link": "https://mathworks.com/help/signal/ref/fsst.html",
        "document": ""
    },
    {
        "link": "https://mathworks.com/help/matlab/ref/fft.html",
        "document": ""
    },
    {
        "link": "https://mathworks.com/help/signal/ug/time-frequency-gallery.html",
        "document": ""
    },
    {
        "link": "https://mathworks.com/help/wavelet/ug/time-frequency-gallery.html",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/fileexchange/67889-detrended-fluctuation-analysis-dfa",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/answers/1728615-anybody-here-familiar-with-detrended-fluctuation-analysis-dfa",
        "document": ""
    },
    {
        "link": "https://researchgate.net/publication/225276433_Introduction_to_Multifractal_Detrended_Fluctuation_Analysis_in_Matlab",
        "document": "Department of Neuroscience, Norwegian University of Science and T echnology,Trondheim, Norway Fractal struct ures are found in biomedical time series from a wide range of physiological phenomena. The multifractal spectrum identiﬁes the deviations in fractal structure within time periods with large and small ﬂuctuations. The present tutorial is an introduction to trum of biomedical time series. The tutorial presents MFDF A step-by-step in an interactive Matlab session. All Matlab tools needed are available in where the reader can employ pieces of, or the entire MFDF A to example time series. Af ter introducing MFDF A, the tutorial discusses the best practice of MFDF A in biomedical signal processing. The main aim of the tutorial is to give the reader a simple self-sustained guide to the implementation of MFDFA and interpretation of the resulting multifractal spectra. The structural characteristics of biomedical signals are often visu- ally apparent, but not captured by con ventional measures like the average amplitude of the signal. Biomedical signals from a wide ture. A biomedical signal has a scale invariant structure when the structure repeats itself on subintervals of the signal. Formally, the the particular kind of scale invariant structure of the biomed- signal processing to deﬁne the scale invariant structure in ECG, human respiration, and inter-beat int ervals of the human heart has differentiated between healthy and pathological conditions Hausdorff, 2007 ), and between different types of pathological con- ditions (e.g., ). Scale in variant structures are also found in spatial phenomena like the branching of the nervous sys- son and Fazzalari, 1994 ), and are able t o differentiate between during the last decade suggest that changes in the scale invariant structure of biomedical signals reﬂect changes in the adaptability of physiological processes and successful treatment of pathologi- therefore promising prognostic and diagnostic tools in biomedical Monofractal and multifractal structures of the biomedical sig- nal are particular kind of scale invariant structures. Most com- by a single power law exponent and assumes that the scale invari- ance is independent on time and space. However , spatial and temporal variation in scale invariant structure of the biomedical signal often appears. These spatial and temporal variations indi- cate a multifractal structure of the biomedical signal that is deﬁned by a multifractal spectrum of power law exponents. As an exam- ple, age related changes in the scale in variant structure of heart r ate variability are indicated by changes of the multifractal spectrum 2011 ). The width and shape of the multifractal spectrum can also differentiate between the heart rate variability from patients with 2007 ). The multifractal structure of heart rate variability is there- fore suggested to reﬂect important properties of the autonomic and response times is more sensitive to the inﬂuence of age and more, the multifractal structure of EEG and series of inter-spike intervals have been able to differentiate between the neural activi- therefore be important as a computer aided tool to increase the precision of neurosurgeries. The main aim of the present tutorial is to introduce a robust analysis called the ﬂuctuation analysis (MFDFA) that can estimate the multifractal ( ). Those r eaders not familiar with analysis\n\nof monofractal ﬂuctuations in biomedical signals are referred to The tutorial is intended to be a self-sustained guide to the implementation of MFDFA to time series and interpretation of the resulting multifractal spec tra to the readers that are unfa- miliar to fractal analysis. In order to be a self-sustained guide, the tutorial decomposes MFDFA into a series of simple Matlab codes that are introduced in a step-wise manner to the reader . The tutorial is meant to be interactive where the reader can employ the Matlab codes while reading the text to enhanc e the understanding of MFDFA. The reader is therefore advised to www.ntnu.edu/inm/geri/software where all Matlab c odes used in the tutorial are available. The reader should set the folder as the current directory folder in Matlab before reading the fol- lowing sections of the tutorial. The folder can be set as current directory folder by pasting it into the current directory window and are written in the Matlab command font and a red color to separate them from the rest of the text. The reader can type the red commands in the Matlab command window wherever they appear in the text to access parameters or plot them with Matlab’ s translation of the Matlab codes of MFDFA to the mathemati- readers interested in the mathematical details of the MFDFA. The rest of the tutorial is divided into two sections: the imple- mentation of MFDFA in Matlab is introduced step-by-st ep in where the interpretation of the re emphasized. Important issues for the best practice of MFDFA are discussed in Section “ The Best Pr actice of Multifractal Detrended The construction of MFDFA is divided into eight steps: Section “ Noise and Random W alk Like Variation in a T ime Series duces a method to convert a noise like time series into a random walk like time series that is a preliminary step for MFDFA. Section introduces root-mean-square (RMS) that is the basic computa- tion within MFDFA and a typical way to compute the average of local ﬂuctuation in the time series as RMS of the time ser ies the Time Series, ” the same local RMS is co mputed around trends that are often encountered in biomedical time series. In Section the local RMS are summarized into an overall RMS. The ove r- all RMS of the segments with small sample sizes is dominated by the fast ﬂuctuations in the time series. In contrast, the over - all RMS for segments with large sample sizes is dominated by slow ﬂuctuations. The power law relation between the o verall by a monofractal detrended ﬂuctuation analysis (DFA) and is Fluctuation Analysis of Time Series, ” MFDFA is obtained by the q -order extension of the overall RMS. The q distinguish between segments with small and large ﬂuctuations. The power law relation between the tra are computed from the version of MFDFA is introduced that comput e the multifractal Before starting the introduction of MFDFA, the reader can type multifractal . These time series will be used as test series in struction of the Matlab code for MFDFA is represented as M atlab code boxes within the text. The main intention of these Matlab code boxes is that the reader should past e the Matlab code into the Matlab command window while reading the tutorial. Figures are accessed by typing the plot command at the end of the Matlab code boxes. The reader can acc ess all Matlab code boxes b y opening the NOISE AND RANDOM WALK LIKE VARIA TION IN A TIME SERIES of these random walks is reﬂected by their picture-in-picture similarity as illustrated in the upper panel of “hills” and “valleys” with similar structure appear when you zoom on the large “hills” and “valleys” of the random walk. The DFA is employed t o time series with a random walk like series have ﬂuctuations that are more similar to the increments of the random walks (see the blue traces in biomedical time series has the noise like structure of the blue traces in , it should be conv erted to a random walk like time series before employing DFA. N oises can be converted to random walks by subtracting the mean value and integrate and are all noise like time series and are converted to random walk like time series by Matlab c ode 1 Typ e in the command window to access A conventional analysis of variation in biomedical time series is to compute the average variation as a RMS. The reader can use Matlab\n\nThe -order Hurst exponent can now be deﬁned as the slopes The relationship between Matlab code 9 are given below in the mathematical notation Figure 8 shows that the slopes of the regression lines are The difference between the q ’s are more visual apparent at the small segment sizes c ompared to the large segment sizes (see able to distinguish between the local periods with large and small the small segments are embedded within these periods. In con- trast, the large segments cross several local periods with both small and large ﬂuctuations and will therefore average out their differ- ences in magnitude. Thus, the relationship between the RMS of the time series becomes similar to the monofractal time series at the largest segment sizes (com- time series have no periods with small and large ﬂuctuations and, consequently , the same difference between the irrespective of the segment sample sizes (see ments with small ﬂuctuations have a random walk like structure whereas segments with large ﬂuctuations have a noise like struc- ture (see the continuum of Hurst exponents in Figure 8D ). Thus, the monofractal DF A in Matlab code 5 and 6 will not distinguish between the structure of the The -order Hurst exponent is only one of several types of scaling exponents used to parameterize the multifractal structure of time series. The typical procedure in the literature of MFDFA is plot of versu s is referred to as the multifractal spectrum from by the Matlab code 10 below (see The mass exponent is used to compute the by Matlab code 11 below (see upper right Typ e in the Matlab command window to access of leads to a constant of these time series because is the tangent slope of (see the ﬁrst command line in Matlab code spectrum is a large arc where the difference between the maximum The reader should notice that the 2010 ). Furthermore, the singularity dimension can be confused with the generalized dimension and the box counting dimension that is other ways to parameterize the multifractal structure of The Hurst exponent deﬁned by the monofractal DF A repre- sents the average fractal structure of the time series as illustrated in and is closely related to the central tendency of mul- for segments with large and small ﬂuctuations is represented by ture in the continuum of Hurst exponents (see new continuum of multifractal spectrum widths that represents\n\nTyp e or in the Matlab command window to access the deﬁnition of the input and output variables. The help functions provide examples for the employment of The main aim of Section “The Best Practice of Multifrac- tal Detrended Fluctuation Analysis” is to guide the application ers has gained insight into the construction of MFDFA2 and this insight will help them to avoid potential pitfalls in the application of of and has several steps. First, the structure of biomedical time series must be similar to noise before employ- to make the biomedical time series similar to a noise like time series. Secondly, the local ﬂuctuations within the biomedical time series cannot be close to zero. Section “ to zero and possible solutions to this problem. Thirdly , the bio- medical time series must be scale invariant within the predeﬁned cusses the general assumption of a scale invariant time series as the Input Parameters Scale, q, and m in MFDFA1 and MFDF A2 ses where results can be compared to results fr om MFDFA1 MFDFA2 have the best performance when signal are a noise like time series. However , it can be difﬁcult according to Figure 6 to visually differentiate between random walk and noise like time series. A possible solution suggested by is to run a monofractal DFA (i.e., M atlab code 5 and 6) before running and . The time series are noise like if Hurst exponent is between 0.2 and 0.8. In this case, and MFDFA2 can be employed directly without transformation of the time series. However , the time series are random walk like when is between 1.2 and 1.8. In these cases, the time series should either be differentiated before entering the conversion to random walk in the ﬁrst line of Matlab code 8 and 12 should be eliminated. If the time series are random walk like 1 should be added to the output variables the categories of the Hurst exponent estimated by a monofractal DFA with corresponding con version of the biomedical time series that should be performed before entering it into T able 1 | Conversions of the biomedical time series and adjustment The local ﬂuctuation in the time series is deﬁned as a local multifractal spectrum when is close to zero because both log2(Fq) for negative ’s in Matlab c ode 8 and lab). Extreme large will be present for negative to zero will lead to large right tails for the multifractal spectrum. The problem of segments with close to zero can be solved by eps can be set to the precision of the measurement device that is recording the biomedical time series. As an example, the measure- ment of the inter-beat intervals of the human heart is measured as the time interval between R-peaks in ECG and has a typical be eliminated from further analysis when are employed to series of inter-beat intervals. Elimination of local ﬂuctuations below the measurement error is possible in There are two main reasons why the local ﬂuctuation becomes zero in segments with small sample sizes. First, the poly- nomial trend of the time series can be overﬁtted in segments with small sample sizes (i.e., small scale). An overﬁtt ed trend will be similar to the time series and cause the residual ﬂuctuations, RMS , to be close to zero . The sample size of the smallest segment (i.e., scale) should therefore be much larger than the polynomial order to prevent an overﬁtted tr end. Secondly, the biomedical time series might be smooth with little apparent variation and therefore similar to the polynomial trend even for low order these cases, the value of the smallest scales should be raised and The application of both Matlab function and assumes that the biomedical time series are scale invariant. be estimated by a linear regression if the relationship between\n\nrelation in this plot might arise from several reasons. First, an insufﬁcient order for the polynomial detrending will yield a non- scale invariant time series with a trend. The solution is to run ﬂuctuations close to zero for small scales would yield a non- This dip can be prevented by elimination of the phenomenon recorded in the biomedical time series. As an example, respiratory frequency creates distinct oscillations in the 1999 ) and cause the scale invariance to break down at the small- est scales. Another example is postural sway in humans where the variation of the center of pressure has two distinct scaling regions thought to represent two distinct modes for human bal- the sub-regions with scale invariance is to look for periods with stant indicates the segment sizes above and below which the local ﬂuctuations (i.e., RMS) are no longer scale invariant. These points will in many cases have phenomenological explanations and should not be ignored. HOW TO SET THE INPUT PARAMETERS scale, q, AND m IN MFDFA1 ters , and . The estimation of the multifractal spec- tra is dependent on these parameter settings. The rest of this section gives guidelines to the parameter settings in The input parameters is the multiple segment sizes for 12. A minimum and maximum sample size of the segments [i.e., min(scale) max(scale) in Matlab] has to be chosen to construct the set of scales used in Both statistical and phenomenological arguments exist on how to choose the minimum and maximum segment size. The sta- tistical argument is to choose minimum and maximum segment in Matlab code 8 and 12. The minimum segment sample size should be large enough to prevent error in the computation of samples is a “ rule of tumb” for the computation of thermore, the minimum sample size must be considerably larger minimum segment size of 10 samples might be too small for maximum segment size should be small enough to provide a suf- ﬁcient number of segments in the computation of code 8. A maximum segment size below 1/10 of the sample size of the time series will provide at least 10 segments in the com- putation of in Matlab code 8. Furthermore, it’ s favorable to have a equal spacing between scales when they are represented in formance of the linear regression that estimates and the total number of segment sizes, order to provide a stable estimation of the probability distribu- tion and, consequently , the multifractal spect rum et al., 2003 ). The local Hurst exponent for large scale will have a smooth and slow varying dynamics that are not well described scale [7,9,11,13,15,17] used in Matlab code 12 are preferable in . However , the reader should notice that the of a less precise estimation of the local ﬂuctuation imprecise estimation of can be seen as measurement noise Phenomenological argumentations are important for the choice of minimum and maximum segment sizes within the example, it is unlikely that the mov ement of the center of mass is faster than 10 Hz during postural sway . If ground reaction force is sampled at 200 Hz by a force plate then the minimum segment size should be larger than 200/10 Hz ple is to exclude the smallest segment sizes in heart rate variability known to be dominated by oscillations due to the respiratory fre- quency. Furthermore, heart rate variability operates with several to be inﬂuenced by different mechanisms (e.g., r espiratory fre- Kleiger, 1999 ). Three scale invariant sub-bands are also found in EEG signal where the Hurst exponent are able to separate between MFDFA1 can be employed to sub-bands of the scaling range in\n\nconsist of both positive and negative ’ s in order to weight the peri- ods with large and small variation in a time series. The precision of the computation of the are explained by the result in the smallest and largest variation will tower up as a single sky- q -order RMS in Matlab code 7). The domination of the single seg- ments with the smallest and largest variation destabilizes and leads to an increasing spread around the regression lines of avoid large negative and positiv e values because they inﬂict larger numerical errors in the tails of the multifractal spectrum. The stability of the computation of the multifractal spectrum is also dependent on the differences between the segments of largest and trum width will have large differences between the segments with the smallest and largest variation and, consequently , destabilize the and 5 for most biomedical time series ( also dependent on the sample size of the time series. Time series with large sample size will have multiple segments with extremely large and small variation whereas time series with moderate sam- ple size will only have a single segment. Multiple segments of large and small variation would stabilize the computation of large negative and positive -orders. There e xists no consensus for the deﬁnition of a “too small” sample sizes for multifractal analy- ses, but the reader should interpret the result with caution when MFDFA1 MFDFA2 are employed to time series with less than In both and is com- puted around a polynomial trend where its shape is deﬁned by the order . A higher order yield a more complex shape of the trend, but might lead to overﬁtting for time series within small when the smallest segment sizes contains 10–20 samples. Most studies that employ DFA to biomedical time series do not report the details of the polynomial detrending. Still, the multifractal spectrum for multiple orders should be compare to ensure that the multifractal spectrum are not inﬂuenced by non-stationary trends in the time series. The trends present in biomedical sig- nals do not have to be of a polynomial shape but might have be extended to include more adaptive detrending pr ocedures like ( ). Furthermore, an adaptiv e fractal analysis is shown to perform better than the DFA with polynomial detrend- ing when employed to biomedical time series with strong trends ( ). Extensions and modiﬁcation of the detrend- are employed to biomedical time series with strong trends. Mat- lab functions for MFDFA with other detrending procedur es are The basic component of both used to deﬁne the local ﬂuctuation in a time series. In multifractal analyses based on wavelet transformations, the local ﬂuctuation is deﬁned as the convolution product between the time series and a waveform ﬁtted within local segments of the time series (cf. 2006 ) can therefore be directly compared with the results from MFDFA1 MFDFA2 . In an entropy-based estimation of the multifractal spectrum, the local ﬂuc tuation is deﬁned as the sum of the time series within the local segment relative to the total and estimates and , directly , as the regression slope of the q- order entropy functions. The MFDFA has been sho wn to perform as well as or better than these multifractal analyses ( in and should be considered when the biomed- The multifractal spectrum reﬂects the variation in the fractal struc- ture of the biomedical time series. The multifractal structure of the inter-beat intervals can identify pathological conditions of the multifractal structure in neural activity can separate the activity of different brain areas and thereby guide more precise neuro- 2002 ). MFDFA is simply based on the computation of local RMS for multiple segment sizes as illustrated in Section “ in Section “ The Best Practice of Multifractal Detrended Fluctuation Analysis ” for the best practice of MFDFA are of paramount impor- tance when MFDFA are emplo yed to biomedical time series. First, a monofractal DFA should be employed to ensur e that the biomed- to should be made if the time series has not a noise like structure. Secondly, local ﬂuctuation close to zero should be elim- inated within MFDFA. Thirdly , the presence of scale invariance should be checked by ﬁrst running in Matlab] and then plot"
    },
    {
        "link": "https://mathworks.com/help/matlab/ref/detrend.html",
        "document": ""
    },
    {
        "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC3366552",
        "document": "The structural characteristics of biomedical signals are often visually apparent, but not captured by conventional measures like the average amplitude of the signal. Biomedical signals from a wide range of physiological phenomena posses a scale invariant structure. A biomedical signal has a scale invariant structure when the structure repeats itself on subintervals of the signal. Formally, the biomedical signal X(t) are scale invariant when X(ct) = cHX(t). Fractal analyses estimates the power law exponent, H, that defines the particular kind of scale invariant structure of the biomedical signal. Fractal analyses are frequently employed in biomedical signal processing to define the scale invariant structure in ECG, EEG, MR, and X-ray pictures (cf. Lopes and Betrouni, 2009). The scale invariant structures of inter-spike-interval of neuron firing, inter-stride-interval of human walking, inter-breath-interval of human respiration, and inter-beat intervals of the human heart has differentiated between healthy and pathological conditions (e.g., Ivanov et al., 1999; Peng et al., 2002; Zheng et al., 2005; Hausdorff, 2007), and between different types of pathological conditions (e.g., Wang et al., 2007). Scale invariant structures are also found in spatial phenomena like the branching of the nervous system and lungs (e.g., Bassingthwaighte et al., 1990; Abbound et al., 1991; Weibel, 1991; Krenz et al., 1992), bone structure (Parkinson and Fazzalari, 1994), and are able to differentiate between healthy and cancer tissues (Atupelage et al., 2012). Several reports during the last decade suggest that changes in the scale invariant structure of biomedical signals reflect changes in the adaptability of physiological processes and successful treatment of pathological conditions might change fractal structure and improve health (Goldberger, 1996; Goldberger et al., 2002). Fractal analyses are therefore promising prognostic and diagnostic tools in biomedical signal processing. Monofractal and multifractal structures of the biomedical signal are particular kind of scale invariant structures. Most commonly, the monofractal structure of biomedical signals are defined by a single power law exponent and assumes that the scale invariance is independent on time and space. However, spatial and temporal variation in scale invariant structure of the biomedical signal often appears. These spatial and temporal variations indicate a multifractal structure of the biomedical signal that is defined by a multifractal spectrum of power law exponents. As an example, age related changes in the scale invariant structure of heart rate variability are indicated by changes of the multifractal spectrum rather than a single power law exponent (e.g., Makowiec et al., 2011). The width and shape of the multifractal spectrum can also differentiate between the heart rate variability from patients with heart diseases like ventricular tachycardia, ventricular fibrillation and congestive heart failure (e.g., Ivanov et al., 1999; Wang et al., 2007). The multifractal structure of heart rate variability is therefore suggested to reflect important properties of the autonomic regulation of the heart rate (Goldberger et al., 2002). Furthermore, the multifractal spectrum of endogenous brain dynamics and response times is more sensitive to the influence of age and cognitive performance compared to a single power law exponent alone (Suckling et al., 2008; Ihlen and Vereijken, 2010). Furthermore, the multifractal structure of EEG and series of inter-spike intervals have been able to differentiate between the neural activities of brain areas (Zheng et al., 2005). Multifractal analyses might therefore be important as a computer aided tool to increase the precision of neurosurgeries. The main aim of the present tutorial is to introduce a robust analysis called the multifractal detrended fluctuation analysis (MFDFA) that can estimate the multifractal spectrum of power law exponents from a biomedical time series (Kantelhardt et al., 2002). Those readers not familiar with analysis of monofractal fluctuations in biomedical signals are referred to Eke et al. (2000). The tutorial is intended to be a self-sustained guide to the implementation of MFDFA to time series and interpretation of the resulting multifractal spectra to the readers that are unfamiliar to fractal analysis. In order to be a self-sustained guide, the tutorial decomposes MFDFA into a series of simple Matlab codes that are introduced in a step-wise manner to the reader. The tutorial is meant to be interactive where the reader can employ the Matlab codes while reading the text to enhance the understanding of MFDFA. The reader is therefore advised to download the folder “Introduction to MFDFA” at the web site www.ntnu.edu/inm/geri/software where all Matlab codes used in the tutorial are available. The reader should set the folder as the current directory folder in Matlab before reading the following sections of the tutorial. The folder can be set as current directory folder by pasting it into the current directory window after opening Matlab. Matlab and are written in the Matlab command font and a red color to separate them from the rest of the text. The reader can type the red commands in the Matlab command window wherever they appear in the text to access and or plot them with Matlab’s function. A translation of the Matlab codes of MFDFA to the mathematical notations used by Kantelhardt et al. (2002) are given for the readers interested in the mathematical details of the MFDFA. The rest of the tutorial is divided into two sections: the implementation of MFDFA in Matlab is introduced step-by-step in Section “Multifractal Detrended Fluctuation Analysis in Matlab” where the interpretation of the resulting multifractal spectrum is emphasized. Important issues for the best practice of MFDFA are discussed in Section “The Best Practice of Multifractal Detrended Fluctuation Analysis.”"
    },
    {
        "link": "https://mathworks.com/help/images/ref/imnlmfilt.html",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/fileexchange/27395-fast-non-local-means-1d-2d-color-and-3d",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/fileexchange/13176-non-local-means-filter",
        "document": ""
    },
    {
        "link": "https://mathworks.com/matlabcentral/fileexchange/52018-simple-non-local-means-nlm-filter",
        "document": ""
    },
    {
        "link": "https://researchgate.net/publication/236272489_Image_denoising_based_on_non-local_means_filter_and_its_method_noise_thresholding",
        "document": "Non local-means filter uses all the possible se lf-predictions and self-similarities the image can provide to determine the pixel weights for filtering the noisy image, with the assumption that the image contains an extensive amount of self-similarity. As the pixel s are highly correlated and the noi se is typically independently and identically distributed, averaging of the se pixels results in noise suppression thereby yielding a pix el that is similar to i ts original value. The non lo cal-means f ilter remove s the nois e and cleans the edges without losing too many fine structure and deta ils. But as the noise increases, the performance of non l ocal-means filter deteriorates and the denoised image suffers from bl urring and l oss of im age details . This is because, the similar local patc hes used to find the pixel wei ghts contains noisy pixels. In this paper, t he blend of non local-means filter and its method noise thresholding using w avelets is proposed fo r be tter image denoising. The perf ormance of the proposed method i s com pared filter. It is found that, performance of proposed method is superior to wavelet thresholding, bilateral filter and non local-means filter and superior/akin to multi-res olution bi lateral filter in terms of method noise, visual quality, PSNR and Image Quality Index. Many scientific data sets are contaminated by noise be cause of data acquisition process and/or transmission, which can degrade the signal of interest. A first pre-proce ssing step in analyzing such data sets is denoising, that is, estimating the signal of interest from the a vailable noisy Eventhough denoising has long been a focus of research, there always remains room for improvement, especially in image denoising. For images, noise suppression/reduction is a delicate and a difficult task because, there is a trade-off between noise reduction and preservation of actual image features. If hig h frequency noise is to be removed from the corrupted image, the simple spatial filtering m ay be sufficient, but a t the cost of computat ional complexity involved in performi ng the convolution. This can be reduced by Frequency-domain methods where convolution is transfor med into multipl ication of the spectra due to Fourier convolution property. As the noise is spread across all fre quencies, the frequency-based Department of Electrical and C omputer Engineering,\n\ndenoising methods adopt low-pass f iltering to suppress most of high-frequency components in order to denoise t he image. Howe ver, this is general ly not ef fective as it suppresses both noise as well as other high-frequency features of the image resulting in an overly smoothed denoised Many of the denoising methodologies and strategies [2-13] devise a mo del for the noise and/or for the original signal in a suitable subspace where the differences be tween them are accentuated based on the following observations: (i) the noise and clean signal show di fferent behaviors in multiresolution representation, (ii) significant geometrical com ponents of an especially at low resolutions [14]. Hence, in last two decades, a flurry of research has involved the use of the wavelet transform for denoising because of its multiresolution and energy compaction properties [15, 16] . The motivation is that the small wavelet coefficients in high- frequency bands that are more likely due to noise are thresholded, leaving t he large wavelet coefficients which are more likely due to signal features [10,11]. The in fluential w orks on signal denoising via wavelet thresholding or shri nkage of Donoho and Johnstone [10, 11] in the additive white Gaussian nois e set ting ha ve shown that various thresholding schemes for denoising have near-optimal properties in the minmax sens e a nd perform well in simulation studies of one-dimensional c urve estimation. The main assumption in wavelet thresholding is the signal magnitudes increasingly dominate the magnitudes of the noise in a wavelet representation w ith increasing level, so that wavelet coefficients can be set to zero if their magnitudes are less than a predetermined threshold. Hard-thresholding and soft-thresholding are the most popul ar th resholding schem es used for denoising, where the former leaves the magnitudes of coefficients unc hanged if th ey are larger than a given threshold, while the latter just shrinks them to zero by the threshold value otherwise it is set to zero in both cases. Further, the performances of these methods are close to that of an ideal coefficient selection method if the coefficients of the underlying signal are known in advance [10, 11]. Even though sof t-thresholding introduces more e rror or bias than hard-thresholding, it is more efficient in denoising. But for some classes of im ages hard- thresholding performs better [3]. However, the choice of a suitable threshold value is the major problem with both of these methods and most of their variants. Initially, Donoho and Johns tone have given a mechanism for finding a universal threshold value known as VisuShrink, which depends on the noise power and the signal size (number of samples in the image). This was derived by proving an a symptotically optimal upper bound on the approximation error in t he limit of an arbitrary large signal size [10, 11, 17]. VisuShrink is a global thresholding scheme where a si ngle value of threshold is applied globally to all the wavelet coefficients. As the given noisy signal may con sist of some parts where the ma gnitudes of the signal are below the threshold and other parts where the noise magnitudes a re above the given thres hold, thresholding by VisuShrink will cut off pa rts of the signal on one hand and leave som e noise untouched on the other hand. This observation ha s led to the idea of a non-uniform or adaptive threshold depend ing on the relationship between the energy distribution of the observed signal and that of the noise. The use of di fferent thresholds for different decomposition levels and subbands seems more reasonable as the adaptive thresh old accounts for variation of the local An adaptive method of selecting a threshold that adapts to the data a s well as minimizing the Stein Unbiased Risk Estimator (SURE) is developed by Donoho and Johnston e, which is called as SureShrink wavelet thresholding technique [10, 17] . This is achieved by choosing di stinct thresholds for each subband of each decomposition level of t he wavelet tree using a n efficie nt\n\nrecursive process [2]. E venthough the SureShrink thresholding method cl early provides an adaptive thresholding strategy; its pe rformance depends on the estimated statistics of the wavelet coefficients of the original image from that of the noisy i mage. Among the literatu re available on threshold value selection for image denoising, BayesShrink proposed by Chang et al. [3] has a better Mean Squared Error (MSE) performance than SureShrink. This has been derived in a Bayesian framework assuming a generalized Gaussian distribution for the wavelet An alternative t o the wavelet-based denoising methods is the Bilateral Filter (BF) introduced by Tomasi and Manduchi [18] which considers both the spatial an d the intensity inform ation between a point and its neighboring points unlike the conventional linear filtering where only spatial information is considered. The concept of the BF was earlier presented in [19] as t he SUSAN filter a nd in [20] as the neighborhood filter. The BF takes a weighted sum of pixels in a local neighborhood; the weights depend on both the spatial dista nce and the intensity distance. This preserves the edges/sharp boundaries very well while noise is averaged out as it average pixels belonging to the s ame region a s the reference pixel. But it fails when the standard deviation of the noise exceeds the edge contrast. Recently, a rel ation between BF and anisotropic diffusion has been established in [21]. Also, Elad [22] proved that the BF is identical to a single Jacobi iteration of a weighted least squares minimization. In the last decade, the classical BF algorithm [23-27] has been modified and improved by m any researchers. In [28, 29], the authors give an empirical study of the o ptimal BF parameter selection in image denoising applications and proposed the Multi-Resolution Bilateral Filter (MRBF). The application of BF on the approximation subband results in los s of some image details, whereas that aft er eac h le vel of wavele t reconstructi on flattens the gray levels thereby resulting in a cartoon-like appearance. Further, the variants of MRBF proposed in [30] for denoising of ma gnetic resonance images and in [31] for astronomi cal, ul trasound and x-ray images a lso suffers from loss of some i mage de tails as well as flattening o f gray levels due to BF. This is bec ause, the application of BF removes noise a s w ell as some image details by spatial filtering without loss of edge information (range fi ltering). The problem of cartoon-like appearance due to flattening of gray levels i s mini mized by applying BF only once duri ng the process of denoising, thereby avoiding loss of too many image details consequently improving systematically uses all the possible self-predictions the image can provide and similarity of local patches t o determine the pixel weights. As the pa tch size reduces to one pixel, the NL- means filter becomes equivalent to the BF. The former better cleans t he edges without losing too many fine structures and details while the later loses details a nd creates irregularities on the edges. Further, Ker vrann et al. [ 34] extended the work of [ 33] by controlling t he neighborhood of each pixel adaptively. All these denoising methods works well with l ess noise (high SNR) but fails to do so with more noise (low SNR). As both the target pixel and the similar local patches which are us ed to find the pixel weights are noisy, the estimate of NL-means filter becomes biased [35]. To cater for this problem of noisy target pixel , adaption of central kernel weight (AKW) to the degree of noise is proposed in [35]. But t his does not take ca re of the similar noisy loc al patches a nd hence, es pecially at higher noise, the bia sed estimate degrades/blurs the image by removing much of the image details. In order to resolve these issues, an amalgamation of NL-means Filtering and its method noise thresholding us ing wavelets has been proposed for image denoising.\n\nThe paper is organized as follows: section 2 discusses the NL-means Filter, section 3 proposes the NL-means Filter and its method noise thresholding using wavelets for image denoising, The goal of image d enoising is to remove the noise while r etaining the important image features like edges, details as much as possible. Linear filter convolves the image with a constant matrix to obtain a linear c ombination of ne ighborhood values and has been widely used for noise elimination in the presence of additive noise. This produces a blurred and the spatial neighborhood [20] and is given by  is the normalization factor and controls the pixel sim ilarity. The Ya roslavsky filter is less known than more recent versions, namely the SUSAN filter [19] a nd the BF [ 18]. Both algorithms, instead of con sidering a fixed spatial neighborhood weigh the distance to the reference pixel ,  is the normalization factor and filtering parameter. These filters maintain sharp boundaries since they ave rage pixels belonging to the same region as the reference p ixel. The problem with these filters is that comparing only grey level values around a given pixel is not s o robust when these values are noisy. Further, the Neighborhood filters also create artificial shocks. In last decade, Buades et al. have extended the Neighborhood filters to a wider class which they called it as Non Local- means (NL-means) [33, 36]. This is with the assumption that the image contains an e xtensive amount of self-similarity and is used to find the pixel weights for filte ring the noisy image. The most similar pixels to a given pixe l have no reason to be close to it. Think of the periodic patterns, or the elongated edges whi ch appear in m ost images. It is therefore l icit to scan a vast portion of the image in sea rch of a ll the pixels that really resemble the pixel to be denoised. The resemblance is evaluated by comparing a whole window around each pixel, not just the pixel value. Denoising is then done by computing the average gray value of these most resembling pixe ls. Since the image pixels a re highly correlated while noise i s typically independently and identically distributed (i.i.d.), averaging of these pixels results in noise cancellation and yields a pixel that is similar to its original value. Given a discrete noisy image , the estimated value for a pixel , is computed as a weighted average of all the pixel intensities in the image , where is the weight assigned to value for restoring the pi xel . Eventhough the traditional definitio n of the NL-means filte r considers the intensity of each pixel can be linked to pi xel intensities of the whole image, for practical and computational considerations, the number of pixels taken into account in the weighted average is restricted to a neighborhood search window centered at the pixel . More precisely, the weight evaluates the similarity between the intensitie s of the local neighborhoods (patches)\n\ncentered on pixels an d , suc h that and square neighborhood of fixed size centered at a pixel and is within the search window centered at the pixel . This similarity is mea sured as a decreasing functi on of the weighted   wh ere is the standard deviation of the Gaussian kernel. This distance is the traditional -norm convolved with a Gaussian kernel of standard d eviation . Indeed in digital image s, c loser pixels are more dependent and therefore closer pixels to the central one should have more importance in the window comparison. Hence, the Gaussian kernel is used to assign spatial weights to the pixels in the window such that the central pixel in the window contribute more to the distance than the pixels located at the periphery. The weights are computed as follows:    and is the smoothing kernel width whi ch controls the decay of the ex ponential functio n and therefore the decay of the weights as a function of the Euclidean distances. From Eq. (5), it can be seen that a small shrinks the area of averaging and thus noise is not likely to be s uppressed e nough. Conversely, if is too large, the weights at the boundary of are also very large, which results in blurry ou tput. Further, due to the fast decay of the exponential kernel, large Euclidean distances lead to nearly zero weights acting as an automatic threshold. Since the NL-means filter not only compa res the g rey level in a single point but al so the geometrical configuration in a whole neighborhood, it allows a m ore robust The application of the Euclidean distance to the noisy neighborhoods raises the following where denotes the or iginal (unknown) i mage and the noisy image obtained by adding a white noise. This equality shows the robustness of the algorithm since in expectation the Euclidean d istance conserves the order of similarity between pi xels. Thus, using a threshold function and setting this hard threshold to  leads to take an average of pixels which originally had an almost identical window around them. The image denoising framework us ing the blend of NL-means Filter and its Method noise Thresholding using wavelets (NLFMT) is shown in Fig. 1. A difference between the original image and its denoised image shows the noise removed by the algorithm, which is called as method noise. In principle, the meth od noise should look like a noise. Since even good quality images have some noise, it m akes sense to e valuate any denoisin g method in tha t way, without the traditional “add noise and then remove it” trick. Mathematicall y, it is given by where, is the original image (not necessarily noisy) and is the output of denoisi ng operator\n\nThe application of NL-means filter on the noisy image remo ves the noi se and cleans the edges without losi ng too many fine structures and details. Eventhough the NL-mea ns filter is very effective in removing t he nois e at high SNR (with le ss noise ) but as the noise increases, it s performance deteriorates. This is beca use; the similar local patches which are used to find t he pixel weights are also noisy. To capture w hat is removed from the noisy image by the NL- means filter, the definition o f the method noise is redefined as the difference be tween the noisy image and its denoised image. Hence, Eqn. (7) is rewritten as where, is a noisy image obtained by corrupting the original image by a white Gaussian noise and is the output of NL-means filter for a input image . At l ow SNR, the NL-means filter not only removes the noise but a t the same time it blurs the image thereby removing much of the image details. Consequently, the method noise will consists of noise as well as image details along wit h some edges. Hence, the method noise can be c onsidered as a combination of i mage details and a white Gaussian noise a nd is Now the problem is to estimate the detail image , which has only the or iginal image features and edges/sharp boundaries that are removed by NL-means filter, a s accurately as possible according to some criteria and is added with the NL-means filtered image denoised image with details. In wavelet domain, Eqn. (9) can be represented a s where is the noisy wavelet coefficient (method noise), is the true wavelet coefficient In wavelet domai n, the goal is to estima te the true wavelet coefficient from by thresholding with a proper value of threshold which minimizes MSE so that it can retain the original image features and edges/sha rp boundaries very we ll in the f inal denoised image. The estimate of the true wavelet coefficient is represented a s gives an estimate of detail image . The summation of this detail i mage   , certainly have more image details and edges as The wavelet thresholding adds power to the proposed method as noise components can be eliminated better in detail subbands of method noise. The adaptive method of selecting a threshold developed by Donoho and Johnstone, minimizes the Stein Unbiased Risk Estimator (SURE) [37] , which has been known as the SureShrink wavelet thresholding technique [10, 17]. The a daptivity of SureShrink is achieved by c hoosing distinct thresholds for each subband of each level of the wavelet tree using an efficient recursive process [ 2, 3] . This thresholding\n\nscheme attempts to se lect thresholds that adapt to the data as well as minimize an estimation of the MSE or risk. Further, it uses a hybrid approach while selecting th e SURE threshold or local universal threshold depending on the energy of a particular subband. That is, it uses SURE threshold in high activity subbands and localized uni versal threshold in sparse subbands. Although the SureShrink threshol ding method cl early provides a n adaptive thresholding strategy, its perform ance is dependent on estimating the statistics of the wavelet coefficients of the original image from that of the noisy image. In last decade, there has been a fair amount of research on threshold value selection for image denoising. Among them, Chang et al. have a generalized G aussian distribution f or the wavelet coefficients [3]. This met hod has a better MSE performance than SureShrink and hence , it is used in the proposed method to threshold BayesShrink is also an adaptive, data-driven thresholding s trategy via soft-thres holding which This method is adaptive to each sub-ba nd because it depends on data-driven esti mates of the parameters. The threshold for a given subband derived by minimizing Bayesian risk, given by  is the noise variance estimated from subband  is the variance of wavelet coe fficients in that subband, whose estimate is computed Experiments were carried out on various sta ndard grayscale images of size 512 x 512 which are shown in Fig. 2. The i nput images are c orrupted by a simulated Gauss ian white noise wi th zero mean and five different standard de viations . The denoising process has been perf ormed on these five noisy realizations. To validate the superiority of the proposed method NLFMT, its p erformance is compared in terms of method noise, visual quality, PSNR and Image Qual ity Index (IQI) of t he denoised images using the various methods available in literature su ch as Wavelet based Thresholding (WT), BF, MRBF, NL- means filte r and BM3D [38]. For BM 3D, the parameter values suggested by the authors are used. In all the cases, db8 is used for wavelet decomposition and BayesShrink s oft thresholding is used to threshold these wavelet coefficients. In W T based thresholding and NLFMT, three levels of decomposition is used whereas in MRBF only one decomposition level is used. The other parameters used are given against the methods consider ed. The me thod noise of a very good image denoising method should look li ke a noi se even for a noise free image. That is, any denoising algorith m should not a lter the noise free images, so\n\nIn Fig. 10, (a) shows the noisy image of Barbara wi th and its denoised images by NLFMT using sym8, db16, coif5, bior6.8, DCHWT f or method noise decomposition are shown in (b-f) re spectively. It is observed from Fig. 10 that , there is a reduction of noise in all the denoised images except for a few arti facts, which are more prominent in Fig . 10 (e) (bior6.8). Further, the denoised images by sym8 (Fig. 10 (b)), coif5 (Fig. 10 (d)) and DCHWT (Fig. 10 (f )) have sim ilar performance, and be tter than that of bior6.8 (Fig. 10 (e)) and db16 (Fig. 10 (c)). For Barbara image with , it is observed from Tables 4 and 5 that, the NLFMT using DCHWT provides highest PSNR whereas NLFMT usin g coif3 provides highest IQI. Eventhough the IQI of bior6.8 is same as DCHWT; the visual quality of the denoised image using bior6.8 is not a s good as that of DCHWT because o f the artifacts present in that denoised image. From Fig. 10, it is observed that the denoised images by NLFMT u sing sym8, In thi s pa per, the amalgamation of NL-means filter and its method noise thresholding using wavelet has been propose d. The performance of the proposed methods is c ompared with WT based approach, BF, MRBF and NL-means filter. Through experiments c onducted on standard images it was found that, the proposed met hod has improved the results of WT approach, BF, NL-means filter and MRBF with slight increase in performance in terms of method noise, visual quality, PSNR and IQI. Only in few cases MRBF has shown improved performance when compared to the proposed method. The performance of the proposed method c an be improved by us ing adaptive kerne l based NL- means f ilter and collaborative filtering used in BM3D. Further, it is possible to improve the denoised images by N LFMT using (b) sym8, (c) db16,"
    }
]