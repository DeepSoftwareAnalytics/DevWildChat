[
    {
        "link": "https://medium.com/design-bootcamp/3-key-principles-for-creating-an-intuitive-user-interface-6189a6165134",
        "document": "In the world of digital design, there’s nothing more gratifying than an interface that just “feels right.” A seamless interaction where we intuitively know where to click, swipe, or touch without the need for lengthy explanations or a steep learning curve. That intuitive feeling isn’t by accident; it’s the result of careful design decisions based on a few foundational principles. Today, we’ll dive into three of these essential principles to guide you in creating a user interface (UI) that’s not only attractive but also user-friendly.\n\n1. Keep it Simple and Minimize Complexity\n\nThe adage “less is more” holds true, especially in UI design. A cluttered interface can overwhelm users, making it difficult for them to find what they need or complete their intended actions.\n• Eliminate unnecessary elements: Before adding any component, ask yourself if it truly adds value to the user’s experience. If it doesn’t, reconsider its inclusion.\n• Group related items: Grouping similar functions or information can make an interface feel organized and intuitive. For example, placing all communication-related functions (like messaging, calling, and video chat) in one section can make them easier to locate.\n• Prioritize key actions: Identify the most important actions a user will take on your platform and ensure they are prominently displayed, easily accessible, and not buried beneath less essential elements.\n\nImagine entering a new city without a map, road signs, or any indications of where you’re going. That’s how users feel in a poorly navigated UI. Clear navigation ensures users can easily move around and achieve their goals without frustration.\n• Utilize familiar patterns: Stick to navigation patterns that users are already familiar with. Whether it’s the hamburger menu on mobile apps or the tab-based navigation in web browsers, using recognizable patterns reduces the learning curve.\n• Use clear and descriptive labels: Ensure that every navigation item or button is labeled in a way that immediately tells users what it does. Ambiguous or clever labels can confuse users and lead to avoidable mistakes.\n• Offer feedback: When users take action, provide feedback. For instance, when a button is clicked, it can change color or animate to confirm the action.\n\nConsistency is the glue that binds the entire experience. It ensures that once a user learns how one part works, they can predict how other parts will function, resulting in a smoother experience.\n• Stick to a design system: Create or adopt a design system that defines the visual and interaction patterns. This system can include typography, color schemes, button designs, and more.\n• Use consistent terminology: If you refer to an action as “Delete” in one part of your interface, don’t call it “Remove” in another.\n• Keep interactions uniform: If swiping left on one screen results in a particular action, the same gesture should produce a similar outcome elsewhere.\n\nIn conclusion, crafting an intuitive UI is akin to designing a silent guide that walks users through an experience without them ever realizing they’re being led. By keeping things simple, providing clear navigation, and ensuring consistent design and interactions, you can create a UI that users will love to use and recommend. Always remember, in the world of user interfaces, a smooth journey leads to happy users."
    },
    {
        "link": "https://uxdesigninstitute.com/blog/design-intuitive-user-interfaces",
        "document": "Build your UX career with a globally-recognised, industry-approved certification. Get the mindset, the skills and the confidence of UX designers."
    },
    {
        "link": "https://geeksforgeeks.org/software-engineering-user-interface-design",
        "document": "The user interface is the front-end application view to which the user interacts to use the software. The software becomes more popular if its user interface is:\n• Command Line Interface: The Command Line Interface provides a command prompt, where the user types the command and feeds it to the system. The user needs to remember the syntax of the command and its use.\n• Graphical User Interface: Graphical User Interface provides a simple interactive interface to interact with the system. GUI can be a combination of both hardware and software. Using GUI, the user interprets the software.\n\nThe analysis and design process of a user interface is iterative and can be represented by a spiral model. The analysis and design process of user interface consists of four framework activities.\n\nInitially, the focus is based on the profile of users who will interact with the system, i.e., understanding, skill and knowledge, type of user, etc., based on the user’s profile users are made into categories. From each category requirements are gathered. Based on the requirement’s developer understand how to develop the interface. Once all the requirements are gathered a detailed analysis is conducted. In the analysis part, the tasks that the user performs to establish the goals of the system are identified, described and elaborated. The analysis of the user environment focuses on the physical work environment. Among the questions to be asked are:\n• None Where will the interface be located physically?\n• None Will the user be sitting, standing, or performing other tasks unrelated to the interface?\n• None Does the interface hardware accommodate space, light, or noise constraints?\n• None Are there special human factors considerations driven by environmental factors?\n\nThe goal of this phase is to define the set of interface objects and actions i.e., control mechanisms that enable the user to perform desired tasks. Indicate how these control mechanisms affect the system. Specify the action sequence of tasks and subtasks, also called a user scenario. Indicate the state of the system when the user performs a particular task. Always follow the three golden rules stated by Theo Mandel. Design issues such as response time, command and action structure, error handling, and help facilities are considered as the design model is refined. This phase serves as the foundation for the implementation phase.\n\nThe implementation activity begins with the creation of a prototype (model) that enables usage scenarios to be evaluated. As iterative design process continues a User Interface toolkit that allows the creation of windows, menus, device interaction, error messages, commands, and many other elements of an interactive environment can be used for completing the construction of an interface.\n\nThis phase focuses on testing the interface. The interface should be in such a way that it should be able to perform tasks correctly, and it should be able to handle a variety of tasks. It should achieve all the user’s requirements. It should be easy to use and easy to learn. Users should accept the interface as a useful one in their work.\n\nThe following are the golden rules stated by Theo Mandel that must be followed during the design of the interface. Place the user in control:\n• Define the interaction modes in such a way that does not force the user into unnecessary or undesired actions: The user should be able to easily enter and exit the mode with little or no effort.\n• Provide for flexible interaction: Different people will use different interaction mechanisms, some might use keyboard commands, some might use mouse, some might use touch screen, etc., Hence all interaction mechanisms should be provided.\n• Allow user interaction to be interruptible and undoable: When a user is doing a sequence of actions the user must be able to interrupt the sequence to do some other work without losing the work that had been done. The user should also be able to do undo operation.\n• Streamline interaction as skill level advances and allow the interaction to be customized: Advanced or highly skilled user should be provided a chance to customize the interface as user wants which allows different interaction mechanisms so that user doesn’t feel bored while using the same interaction mechanism.\n• Hide technical internals from casual users: The user should not be aware of the internal technical details of the system. He should interact with the interface just to do his work.\n• Design for direct interaction with objects that appear on-screen: The user should be able to use the objects and manipulate the objects that are present on the screen to perform a necessary task. By this, the user feels easy to control over the screen.\n• Reduce demand on short-term memory: When users are involved in some complex tasks the demand on short-term memory is significant. So the interface should be designed in such a way to reduce the remembering of previously done actions, given inputs and results.\n• Establish meaningful defaults: Always an initial set of defaults should be provided to the average user, if a user needs to add some new features then he should be able to add the required features.\n• Define shortcuts that are intuitive: Mnemonics should be used by the user. Mnemonics means the keyboard shortcuts to do some action on the screen.\n• The visual layout of the interface should be based on a real-world metaphor: Anything you represent on a screen if it is a metaphor for a real-world entity then users would easily understand.\n• Disclose information in a progressive fashion: The interface should be organized hierarchically i.e., on the main screen the information about the task, an object or some behavior should be presented first at a high level of abstraction. More detail should be presented after the user indicates interest with a mouse pick.\n• Allow the user to put the current task into a meaningful context: Many interfaces have dozens of screens. So it is important to provide indicators consistently so that the user know about the doing work. The user should also know from which page has navigated to the current page and from the current page where it can navigate.\n• Maintain consistency across a family of applications: in The development of some set of applications all should follow and implement the same design, rules so that consistency is maintained among applications.\n• None If past interactive models have created user expectations do not make changes unless there is a compelling reason.\n\nUser interface design is a crucial aspect of software engineering, as it is the means by which users interact with software applications. A well-designed user interface can improve the usability and user experience of an application, making it easier to use and more effective.\n• User-centered design: User interface design should be focused on the needs and preferences of the user. This involves understanding the user’s goals, tasks, and context of use, and designing interfaces that meet their needs and expectations.\n• Consistency: Consistency is important in user interface design, as it helps users to understand and learn how to use an application. Consistent design elements such as icons, color schemes, and navigation menus should be used throughout the application.\n• Simplicity: User interfaces should be designed to be simple and easy to use, with clear and concise language and intuitive navigation. Users should be able to accomplish their tasks without being overwhelmed by unnecessary complexity.\n• Feedback: Feedback is significant in user interface design, as it helps users to understand the results of their actions and confirms that they are making progress towards their goals. Feedback can take the form of visual cues, messages, or sounds.\n• Accessibility: User interfaces should be designed to be accessible to all users, regardless of their abilities. This involves considering factors such as color contrast, font size, and assistive technologies such as screen readers.\n• Flexibility: User interfaces should be designed to be flexible and customizable, allowing users to tailor the interface to their own preferences and needs.\n\nOverall, user interface design is a key component of software engineering, as it can have a significant impact on the usability, effectiveness, and user experience of an application. Software engineers should follow best practices and design principles to create interfaces that are user-centered, consistent, simple, and accessible."
    },
    {
        "link": "https://dev.to/citrux-digital/creating-intuitive-user-interfaces-3igm",
        "document": "In a digital world filled with complex applications and platforms, creating intuitive user interfaces (UI) is essential. Have you ever wondered why some applications are easy to navigate while others are frustrating? The secret lies in well-designed user experience. This article explores the principles and techniques behind intuitive interfaces, ensuring a seamless experience for users.\n\nUser interface design is the process of building interfaces in software or computerized devices, focusing on appearance or style. Its goal is to make the user's interaction as simple and efficient as possible to achieve their goals. An intuitive interface means that when a user sees it, they can easily understand how to use it without needing a manual.\n• User-Centered Design: Placing the user at the center of the design process ensures that the final product meets their needs and expectations.\n• Consistency: Consistent use of colors, typography, and layout helps users predict and better understand the interface.\n• Simplicity: A simple design reduces the cognitive load on users, making navigation straightforward and stress-free.\n• Usability Testing: Conducting usability tests helps identify issues and areas for improvement, ensuring the interface is user-friendly.\n• Creating Wireframes and Prototypes: Creating wireframes and prototypes allows designers to visualize and improve their designs before final implementation.\n• Feedback Mechanisms: Incorporating feedback mechanisms, such as tooltips or error messages, guides users and enhances their experience.\n• Gestalt Principles: Applying Gestalt principles, such as proximity, similarity, and closure, helps in creating organized and visually appealing interfaces. These principles help users perceive patterns and make sense of complex interfaces quickly.\n• Increased Efficiency: Users can complete tasks more quickly and easily.\n• Reduced Training Costs: Minimal training is required as users can navigate the interface effortlessly.\n• Design Thinking: An iterative process that seeks to understand the user, challenge assumptions, and redefine problems to create innovative solutions.\n• Agile Methodology: Involves iterative design and development, allowing for continuous improvement and adaptation.\n\nIntuitive interface design is relevant in various contexts:\n• Keeping Up with Trends: Staying updated with design trends and user expectations can be challenging.\n• Balancing Aesthetics and Functionality: Ensuring the interface is both visually appealing and functional.\n• Accessibility: Designing for users with disabilities to ensure inclusion.\n\nCreating intuitive user interfaces is a combination of art and science, requiring a deep understanding of user needs and behaviors. By adhering to key principles and employing effective techniques, designers can create interfaces that not only look good but also provide a smooth and enjoyable user experience.\n\nReady to improve your UI design skills? Subscribe to our newsletter for more insights, tips, and updates on the latest in UI/UX design. Follow us on social media and join the conversation.\n• Nielsen Norman Group. (n.d.). User Experience and Usability. Retrieved from Nielsen Norman Group\n• Krug, S. (2014). Don't Make Me Think: A Common Sense Approach to Web Usability. New Riders. Retrieved from Amazon\n• Interaction Design Foundation. (n.d.). Interaction Design and Usability. Retrieved from Interaction Design Foundation\n• Norman, D. (2013). The Design of Everyday Things: Revised and Expanded Edition. Basic Books. Retrieved from Amazon"
    },
    {
        "link": "https://upstackstudio.com/blog/user-interface-design-principles",
        "document": "First, give yourself a pat on the back for your interest in user interface design principles!\n\nPWC recently found 32% of customers polled would switch brands they previously loved after experiencing just one negative encounter.\n\nRegardless of what app you’re building, the user interface is the market’s first impression. Humans are fussy by nature – we expect something not only functional but pleasing to look at and easily understood. Unsurprisingly,\n\nCase in point: While all men know how to walk, it sure wouldn’t hurt to look like Brad Pitt while doing it!\n\nClear Definition Of What Is User Interface\n\nYou probably already know, but for the sake of clarity, let’s define what a mobile app user interface is.\n\nThe user interface, or UI as it’s commonly referred to, is the point where users interact with your mobile app.\n\nThis includes buttons, swipe actions, input fields to visual design elements. The user interface is the bridge that connects users with the backend functions of your app.\n\nIts design should therefore make that interaction as simple, efficient and enjoyable as possible.\n\nYou may have heard the term ‘User Experience’ thrown around in the same sentence as User Interface. While closely related, they are more like Siamese twins that each rely on the other. Let’s set the record straight.\n\nThe User Interface, or UI, is all about how your app looks and feels to your users.\n\nIt’s the arrangement of buttons, icons, and sliders; the choice of colors and fonts; the layout of each screen.\n\nIn other words, it’s all the visual elements that your users interact with.\n\nThe User Experience, or UX, is about how your users experience your app.\n\nIt’s not just about how your app looks, but also how it works.\n\nThink about how your users navigate from one screen to another, how they input data, how they recover from errors, and so on.\n\nUX is concerned with the entire process of acquiring and integrating a product, including aspects of branding, design, usability, and function.\n\nRemember these main points about UI and UX:\n• UI is about the visual design of your app, while UX is about the overall experience of using it.\n• Good UI is visually pleasing and intuitive, while good UX is seamless and enjoyable.\n• Both UI and UX are crucial to the success of your app—they both influence whether users will keep using your app or switch to a competitor.\n\nUI and UX are both crucial to making a good first impression\n\nEvery successful mobile app has one key factor in common – a well-planned and implemented user interface (UI) combined with a strong user experience (UX).\n\nThese factors in combination are essential in providing a positive first impression to your users.\n\nNow that we’ve got that clear, let’s move on to the principles of design for mobile app user interfaces!\n\nUI design principles are collectively every designer’s bible when it comes to building user-centric interfaces. You’ll come across other lists and terms, but it all boils down to the following nine items:\n\nThe first principle of design is simplicity.\n\nThis means your user interface (UI) should be straightforward and intuitive.\n\nMake sure users can quickly grasp how to navigate your app without lengthy explanations.\n\nEliminate features, steps, or processes that don’t contribute directly to the user’s main tasks.\n\nNever grow attached to parts of your app – your users won’t care how beautiful the interface looks if it makes navigation difficult for the sake of it.\n\nYou know how supermarkets put important items at the very back so shoppers are forced to navigate through a bunch of tempting but unnecessary crap?\n\nDon’t do that with your app – the most-used functions should be at the forefront.\n\nThis principle ensures users get what they want quickly, contributing to a superior user experience.\n\nPredict and pre-empt is the second principle of design.\n\nYour app should anticipate user needs and offer functionalities before they might need them.\n\nFor example, a weather app might automatically show the forecast for the user’s location.\n\n5. Let Users Take Charge (If They Want)\n\nThe next user interface design principle is letting the user control their experience.\n\nAllow them to customize settings, choose preferences, and have a hand in shaping their journey within your app.\n\nJust remember to include a reset option so they can return to default settings!\n\n6. Be Consistent Across the App\n\nEnsure your buttons, icons, typography, and color schemes remain uniform across your platform.\n\nThis predictability makes for a more immersive user experience and completes a user’s onboarding much faster.\n\nKeep your users well informed of their location within your app.\n\nThis is achieved through:\n\nAlso, make it easy for users to return to a previous screen or undo an action in the event they make mistakes.\n\nIf you can preempt it, you can even set popups to verify they would like to take a certain action.\n\nEver tried to submit a form, only for it to reject your submission with no explanation why?\n\nNow compare that to a situation where a clear explanation is provided, such as password conventions not being followed.\n\nPositive acknowledgement of successful actions and clear, informative responses to any errors, will maintain user confidence and satisfaction.\n\nDesigning with accessibility in mind ensures your app is usable by as many people as possible, regardless of any physical, sensory, or cognitive limitations.\n\nFor example, you might want to include a theme that is easier to see for those suffering from colour blindness.\n\nAdditionally, you might want to make sure your media content is neutral and inoffensive, unless\n\nTo adhere to the ten design principles in the previous section, developers and designers look to elements that can be manipulated to create a user interface that is intuitive and attractive.\n\nHere are the seven UI elements we consider:\n\nEmphasis is the principle of design that is used to create focus on specific areas in your app. Using this principle correctly will guide your user’s eye to the most important information or features first.\n\nThe key to creating an aesthetically pleasing interface is to maintain balance and alignment. This principle is all about making sure your elements do not appear as if they are about to topple over or are drawn haphazardly.\n\nContrast is another key design principle. It emphasizes the differences between screen elements. Good contrast helps different elements stand out which can lead to an improved user experience.\n\nRepetition is all about consistency and brand identity. Things like your colors, fonts and logos should be the same across all of your platforms. It is not only comforting to users, but it gives a polished and professional look to your app.\n\nThe principle of Proportion addresses the size and visual weight of elements in a design, to ensure they are placed accurately as per their importance. Larger elements are more noticeable than smaller ones and hence draw more attention.\n\nThe shape of your elements, animations and transitions are key underlying utilities for leading the viewer’s eye movement around the screen. Movement is about the visual path the eye follows in a design.\n\nLastly, White Space, also known as negative space, is a crucial principle of design that offers the other elements on screen some breathing room. It can help call attention to important content and improve readability.\n\nCommon design mistakes in user interface (UI) have a way of creeping into your mobile app, potentially affecting its usability and overall experience.\n\nLet’s delve into some of these mistakes:\n\nInconsistency in a mobile app’s UI can confuse your users and make your app appear unprofessional. It’s like building a house with mismatched bricks – the overall structure won’t hold up aesthetically or functionally.\n• Common examples: Using different typography styles or sizes in similar contexts, inconsistent colour schemes, or mismatching element styles.\n• Solution: Establish a style guide that defines your typography, colour scheme, button styles, etc., and adhere to it throughout the app.\n\nNo Contrast Between Primary and Secondary Buttons\n\nWhen primary and secondary buttons lack enough contrast, users can easily mistake one for the other, leading to unintended actions.\n• Common examples: Both buttons are in the same colour or size.\n• Solution: Make your primary button more prominent. It can be bigger in size or in a more vibrant colour.\n\nA poorly structured text hierarchy can make important information difficult to find, thereby increasing user frustration.\n• Common examples: Using the same font size for headings and body text or mixing up heading styles.\n• Solution: Develop a clear typographic hierarchy. This can be done by differentiating the font size, weight and colour.\n\nIcons should be clear and intuitive. When icons are vague or unfamiliar, they can confuse users, making navigation more difficult.\n• Common examples: Using non-standard icons or deploying icon-only navigation without text labels.\n• Solution: Stick to established icon conventions and consider pairing icons with text labels for clarity.\n\nPoor alignment negatively impacts the aesthetic appeal of your app and can make your interface seem disorderly and harder to use.\n• Common examples: Irregular spacing between various elements or asymmetrical layouts.\n\nTouch targets that are too small or too close together can lead to accidental taps, causing user frustration.\n• Common examples: Small buttons or controls that don’t fit an average fingertip.\n• Solution: Ensure touch targets are adequately sized and sufficiently spaced to accommodate a fingertip.\n\nWith a proper understanding of these pitfalls, you can craft a more effective, engaging, and user-friendly interface without learning the hard way!\n\nThe Value of A/B Testing to Evaluate UI Design\n\nEvery app founder, regardless of their technical background, should be invested in their app’s user interface design.\n\nAn app’s user interface, or UI, is vital to the experience your users will have, and can drastically impact the app’s popularity and retention rates.\n\nOne of the best ways to ensure your UI design is meeting user needs is through A/B testing.\n\nWhat is A/B Testing and how does it work?\n\nA/B testing, also known as split testing, is a method of comparing two versions of a webpage or app to see which one performs better. It involves showing the two variants, A and B, to similar visitors at the same time.\n\nThis provides empirical data that enables you to make sound decisions on design factors that directly impact the user experience.\n\nThe process involves creating two different versions of your app’s UI. This could mean changing:\n• anything that could affect UX\n\nThese versions are then shown to a segment of your user base, with the rest shown the current design. User engagement metrics, like session length and click rates, are then compared.\n\nWhy use A/B Testing in UI Design?\n\nOne of the main principles of design is user-centricity. The goal of any UI design should be to make the user experience seamless and enjoyable.\n\nBy applying web design principles through A/B testing, you can validate changes to user interface design before wide-scale implementation, saving resources and avoiding potential negative impacts on user engagement.\n• Better Conversion Rates: Convert more visitors into users or customers.\n• Informed Decisions: Base your decision-making process on data, not intuition.\n\nRemember, it’s not about what we think will work, it’s about what actually works.\n\nUsing A/B testing for your mobile app user interface design helps to highlight what’s effective, reduce guesswork, and ultimately lead to a better user experience.\n\nUltimately, if what your users enjoy goes against every UI design principle in this post, who should you listen to?\n• Always remember your mobile app is for users and they are your focus when designing UI.\n• Use different colors, sizes, and placements to highlight the most important elements.\n• Stick to a consistent set of colours, fonts, symbols, or layout styles throughout the app.\n• Keep it simple (like this sentence).\n• Provide users with instant feedback via sensory cues showing if actions are successful (or not).\n• Design an interface that aligns with how users already expect to use an app.\n• Don’t forget to do A/B testing with actual users!\n\nHey there stranger, thanks for reading all the way to the end. Consider joining our mailing list for a one-stop resource on everything from micro SaaS validation all the way to execution and promotion. Get a nifty list of questions to ask app developers when you sign up!"
    },
    {
        "link": "https://smart-interface-design-patterns.com/articles/drag-and-drop-ux",
        "document": "Guidelines for designing a better drag-and-drop UX. With practical guidelines on accessibility and design states.\n\nDrag-and-drop is not a trivial user interaction. It’s messy, inaccurate and comes in plenty of flavors — from design states to interaction modes. Yet when we think of drag-and-drop, we typically think of a simple drag’n’drop file upload — which is only one of the many contexts where drag-and-drop appears.\n\nYet every time we need to re-order a list, or move around cards, or reshuffle columns in a fancy enterprise table, we’ll probably be dealing with drag-and-drop interactions. And too often, they will feel too sluggish, too difficult to use and absolutely inaccessible. Let’s fix it.\n\nYou can find more details on navigation and interaction design in usability chapters in the video library, with a new UX training coming in September 2023.\n\nIt’s not surprising that many users expect drag-and-drop to feel very much like the offline experience of moving physical objects from one place to another. With it come expectations around everything from lifting an item and moving it to spotting available “drop zone” and eventually dropping an item there.\n\nIn fact, there are plenty of states to consider:\n• states for components: resting, lifted/grabbed, in transit, dropped, erroneous and successful.\n• states for the drop zone: empty, hidden, revealed, disabled, ready and contentful.\n• other states: changes in drag handle and grab cursor, but also adjustments of drop shadows and drop targets.\n\nEach of these states must be designed with affordance in mind, and provide instant feedback for the changes made — whether they are possible or not.\n\n2. Use The Right Cursors and Grab Handles #\n\nIf a UI component doesn’t provide any clues about its support of drag-and-drop, we shouldn’t really expect users to discover it on their own. This is similar to right-click interactions which, without any clues, often have a very low discovery rate. With drag-and-drop, the cursor should change on hover to indicate that tapping or clicking will initiate a grab.\n\nThis isn’t enough though. Hover alone assumes that users will discover it on their own, which will not be the case for keyboard users. The component must also be focusable and include a focused state — along with controls to move the component. To be on the safe side, we can clearly indicate for each item that it can be dragged by adding a “grab” or “move” handle on it.\n\nThe mouse cursor could change to indicate that an item is being dragged — from the “move” or “grab” cursor (which indicates something can or is to be moved) to the “grabbing” cursor (which indicates that something is being moved).\n\nUsually there is no need to reinvent the cursor and design an entirely new set of drag-and-drop icons.\n\nWhenever we are moving an item from one place to another, we almost instinctively follow a pattern that we are used to in physical spaces, too. We lift an item, move it, make space for it, drop it to its new spot. Each of these movements is familiar and obvious — and on the web, we can imitate it, too.\n\nIn UI terms, that means “lifting up” an item towards a user once it has been grabbed, in the z-dimension. Not only does the item then stand out from the others; the elevation also indicates that the item’s state has now changed. In fact, it could be achieved in a few different ways:\n• Add an outline around the component,\n• Leave a “ghost” image where the component used to be.\n\nWhatever options you choose to use, consider also using indentation with some horizontal and vertical offset, so the item appears quite different from the items that are currently in place. This will help avoid confusion when you need it the least.\n\nAnd here comes the never-ending question: as the item is being dragged, when do we actually remove it from its original position? This seems like a question with an obvious answer, but there are 5 important considerations which every drag-and-drop experience might need to consider:\n• Always leave a ghost image of the component to indicate where it used to be.\n• As the item is being moved, make sure it stands out from the rest of the list.\n• For large items, collapse them into a summary of the contents.\n• Remove the ghost image on drop, but support undo.\n\nThe summary pattern seems to work best when we are moving large columns, rows, files or large chunks of data as otherwise they would pollute the entire screen. For smaller items, such as relatively small cards or list item, we don’t need to collapse into summaries, and can move the item directly across the screen.\n\nAs items are travelling across the screen, eventually we also need to either “capture” them in a drop zone, or move other content out of the way to make room for them. Usually we change the drop zone to a \"ready” state to indicate that it’s ready to capture the dropped content.\n\nWith other components, we usually push items out of the way and use a visual indicator to cue the change (with a horizontal line or a temporary empty card). Both give users a preview about where the item will land once it’s dropped.\n\nThe most complex question, however, is when exactly we should start pushing out components to make space for a new one?\n\nMany implementations start moving items out when their edges meet, but it might be a little premature. An alternative option is to move an item out of the way once the center of the dragged component overlaps the edge of the other component — this might be a slightly stronger intent that the user has made up their mind.\n\n6. Use Magnetism To Snap Objects Into Place #\n\nDrag-and-drop is inherently inaccurate, so whenever an item can be comfortably dropped, we might want to make it obvious to users. We could do so with a slightly different outline of a dropzone that the target area is ready for the drop.\n\nEven better if we can animate the drop with a short transition (100ms) into its new home position, so it feels like it snaps an object into place.\n\nTypically a dotted or dashed area indicate that an item will be safely captured once it’s dropped. Notice how on Dropbox (pictured below), a file is collapsed into a summary, indicating just how many files there are and they type of the file as well.\n\nMistakes are inevitable, and eventually items will end up in wrong places. To help users recover from these mistakes, we might want to support an option to “Undo” the last action and restore the initial position of the item. It could be as simple as an “Undo” button that remains visible until the user moves on to the next operation. It could also be a stack of last changes that users could revert back to.\n\nBecause drag-and-drop is inaccurate, an alternative way to prevent errors or mistakes is by providing an option to select one or multiple items and move them by using a dedicated “Move to” button, as it’s used in some mobile applications (see below). That’s a simple way to make drag-and-drop more accessible in general, but it is extremely useful especially on narrow mobile screens.\n\nThere is a common assumption that drag-and-drop can’t be accessible. But there are some implementations that make the interaction fully accessible without a mouse. On mobile, sometimes interface use a subtle haptic “bump” to indicate that an object has been grabbed.\n\nKeyboard users need to be able to focus on handle icons and receive screen reader messages about the changes they are about to make, implemented with ARIA live regions. The actual drag-and-drop experience need to be implemented with keyboard keys.\n\nThe Salesforce implementation allows users to use Tab/Shift+Tab to navigate to an item, press Space to enter into drag mode, then use Down/Right, Up/Left arrow keys to select a new position and then press Space to drop item in new position. For each of them, we also need to design a separate state.\n\nIndeed, drag-and-drop is not a trivial interaction. Hopefully the pointers listed above will help you design slightly better and more accessible drag-and-drop UX without making users confused about just how painful and slow the experience is.\n\nHere’s a quick summary of the pointers mentioned above:\n• Users should feel like they are moving physical objects.\n• Dragged items should move towards users in the z-dimension.\n• Animate the drop of an item (100ms) into its new home position.\n• Reshuffle when a center of a dragged item overlaps an edge.\n• Support Spacebar to pick up, Arrow keys to move, Space to drop.\n• Use a haptic “bump” to indicate grabbing on mobile.\n\nOf course, the techniques listed above barely scratch the surface. Here are some fantastic resources all around drag-and-drop, from design considerations to technical implementations and ready-to-use libraries:\n• Drag and Drop UX Best Practices, by Ceara Crawshaw\n• Drag and Drop UX for Design Systems, by Grace N.\n• Drag–and–Drop: How to Design for Ease of Use, by Page Laubheimer\n• Major Interaction Patterns for Accessible Drag and Drop, by Jesse Hausler"
    },
    {
        "link": "https://pencilandpaper.io/articles/ux-pattern-drag-and-drop",
        "document": "This, my friends, is one of THE most involved and spiciest interaction challenges in the mix. What are we dealing with? Basically every consideration in interaction design happens for a drag and drop interaction. Not only do we have to effectively convey the interaction exists in the first place, the object needs to physically move, the live feedback second to second matters, and there are lots of decisions to make throughout to make it ‘feel’ the right way. Indicating state takes on more nuance than we usually deal with.\n\nThings can get weird and go wrong over different devices, and working out the kinks invariably needs some meaningful collaboration between design and devs.\n\nAny way you slice it 🍕, it’s no joke.\n\nThings to consider when designing drag and drop experiences\n\nWhen entering into designing a drag and drop interaction, you and your team have a lot of things to consider.\n• What are the ways we could solve this problem (in general)?\n• Do users need or want a drag and drop interaction?\n• What devices and use cases will be involved?\n• Is drag and drop an appropriate solution for our interaction problem to solve? Does this match up with familiar patterns out there? Or is it new?\n• Is there a JS framework we need to stick to? Or is there freedom to design it in a more specific way? How much control might we have?\n• Do we have enough bandwidth to implement this kind of interaction?\n• Is this interaction needed on mobile?\n• Can we test a framework with people with some dumby data, could we run this as a ‘spike’ type of task?\n\nFor the interaction itself\n• Are any restrictions necessary here? Restrict movement into any directions\n• Do we want a totally flexible or incremental behaviour\n• Is there any key logic to convey about what’s allowed and not allowed to be dragged? If so, what’s the logic?\n• How precise or sensitive should this be?\n\nThe number of components or UI pieces involved in a drag and drop interaction is quite simple, the complexity comes in dealing with the states, feedback and logic of your interaction.\n\nThis is the thing being dragged, this is usually a list item, a card or another object (for simplicity, we’ll just call them the item or list item for the remainder of this article).\n\nThe container that houses the items you’re going to drag.\n\nThis may be static (there all the time) or it may be a dynamic thing – the purpose of it is to give you real time feedback on the items being dragged – empty state of sorts, and it deserves some time and attention, especially if there is logic that needs to be expressed within the area.\n\nDrag and drop UI/UX is quite a varied out there in the world and it’s used (for better or worse), in a lot of contexts. They all have slightly different interaction needs and requirements — as such they have a variety of drag and drop UX patterns. This is especially in enterprise software context, where the use cases can get quite involved, so the UX patterns can get more and more complex. Generally speaking, use cases in drag and drop are moving items, reordering a list, resizing containers and power user drag and drop interactions.\n\nThis use case is the ‘classic’ drag and drop example, where we assume there’s a static and distinct dropzone – much of this article will reference this classic example as it’s the most complex and involved.\n\nA file upload pattern depicted on the Mac desktop, a stack of files mid-drag en route to a enterprise software hosted in the browser.\n\nA folder full of excellent ideas being dragged into the trash can on mac.\n\nThis use case is very common across OS’ and platforms – this is the act of reordering items in a list or card format. Here the drag target is dynamic on the screen and will show the precise position the item will end up in once the drag is released.\n\nExamples of common drag and drop to reorder patterns:\n\nReordering elements on Evernote dashboard uses drag and drop.\n\nReordering sentences in a word processor, such as on Google Docs.\n\nResizing is when users can drag containers within a screen within a range of space available (usually it’s limited in most SaaS products). There are a couple of unique aspects to this interaction.\n• There’s less of a distinct drop target here – the drop target is not really a thing, but the act of ‘releasing’ the selection is still present\n• Confirmation feedback is less pronounced because the size of the object changing itself is the feedback\n\nExample of resize on drag interaction:\n\nResizing a container within a software product to optimize space – a drag handle is active and a cursor change is present in this Google Docs example.\n\nThis use case is specific to enterprise products which allow for deeply involved drag and drop interactions, where users can manipulate items in the UI in an almost unlimited way. Take for example, drawing a rectangle in a product like Figma (or any in-depth design product). Users, depending on their ‘level’ of selection into the object can resize it while keeping the same ratio (ex. Hold down shift). They can change the height and width, and even drag an anchor point (double click in a few times) to change the object from a rectangle to any other shape.\n\nThis level of manipulation is a whole next level of advanced interaction which we’d love to deep dive on, mostly this article doesn’t touch on this complexity level (but we would love to deep dive into this complexity level, so make a request if you’re dying to dive deep).\n\nIn many a design software, you can create or manipulate an object by dragging. Let's check out these examples of what happens in Figma:\n\nObjects are created in design software, like this rectangle\n\nDrawing applications have a ‘deeper level’ of manipulation, in this state the user can ‘click in’ deeply into the anchor points\n\nA single anchor point can be selected, changing the shape of the item completely.\n\nTo illustrate each step in the drag and drop interaction, we’re going to use the example of a screen of an app that allows items in a list (either single or multi-select) to be dragged into a specific drop-zone target on the screen itself. This example lets us show each moment in drag and drop as distinct.\n\nIn the default state, the list items (and their container) are static and the drop target is visible.\n\nIn this example we see that the drop target is visible on the upper right by default\n\nUX microcopy is extremely important for drag targets, so make sure you put in effort here. There are two main opportunities for microcopy, the main text and the supplementary text. The main text tells you the most important information: what to do. In many enterprise or SaaS use cases, there is additional logic that can be explained upfront in the supplementary text.\n\n💡 Bonus UX moment:\n\nIf this logic is complex or has upstream/downstream implications, pop a link in there to your knowledge base which will help people understand their actions more deeply. 🤌\n\n\n\nWhenever possible, we urge people to communicate things upfront rather than throw an error after the fact, this is kind of a big deal heuristic for usability (error prevention and communicating system status are explained in our UX Heuristics article if you’re curious).\n\nTrigger: Mouse is over the drag affordance area\n\nThe hover state communicates that an element can be interacted with.—The mouse indicator as well as the element design can change.\n\nIn this state, the drag area is ‘grabbed’ or gripped. Now it's time to start moving it! Let’s go!🏃🏻♀️\n\n\n\nThe act of ‘grabbing’ is successful, now the item(s) are moving in space alongside the cursor – this is the step before the drag target starts to activate.\n\n\n\nIf multiple items are selected: there is another transition possible which confirms to users that the initiation of the drag was successful WITH the amount of desired items (totals) shown.\n\nTrigger: The drop-zone is within range of the mouse\n\nThe drop-zone indicates that the items are within range – the visual feedback might intensify as the items get closer and closer to the core of the drop-zone.\n\nThis is a good opportunity to give both visual feedback AND use UX microcopy to ensure that the details of the operation to be completed is ‘foreshadowed’.\n\nMore nuanced visual feedback may be necessary when say, there are multiple drop zones so people are differentiating between them, so movement will be more precise. There may be staged feedback within the outer edges of the dropzone – initial feedback to assure users that they are on the right track.\n\nDrop zones might be dynamic and based on their x and y coordinates: take this example of a table hierarchy UI where you’re building parent-child relationships.\n\n\n\nWarnings may also be triggered as the object enters the range of the drop-zone. We always suggest that you warn people rather than throw errors after the fact whenever possible (see our errors article for more info here!)\n\n🎤 Great success! Or, maybe not. The ‘dropped’ state isn’t necessarily as simple as you might think. In fact, there can be a variety of results, ex: loading states, requiring the user to make another decision, success, or even failure.\n\nLet’s build up our understanding with these other states and top it off with success.\n\nFor use cases where files are uploaded for example, you may opt for a very literal UI response, where files are shown going ‘into’ the target. In cases where this drop event has more to it, make sure each item is described properly.\n\nThere are lots of cases in enterprise where dragging and dropping actually requires another decision to be made in order to complete the operation. Using the drop target can be a nice place to locate a simple dialog because you know the user is looking there in that precise moment 👀.\n\nThis is an opportunity to show people the operation worked and confirm exactly *what* happened. In this example, success feedback is supported with the statement that 4 items were added. Then users know that everything they just tried to do worked for sure. (Success feedback is often forgotten and deserves its moment, we did a pattern article on success feedback to help).\n\nAnd finally, the error state – this may happen for many reasons, such as:\n• List items aren’t allowed to be dropped there\n• The operation wasn’t registered on the front end\n• The operation ‘tried’ but the backend failed to perform the task\n• The item wasn’t actually draggable in the first place, the UI was misleading\n\nDrag and drop is definitely a culprit for ‘passive aggressive’ errors, that is: subtle/non-existent) or even misleading behaviour in the UI when an error happens. Check out our error pattern article if you want to explore more.\n\nThis wraps up the phases of your drag and drop operation. Now let’s explore more nuances of drag and drop to become total professionals on the topic.🤜💥🤛\n\nIf you’re feeling like: Whoa that was a lot of states and interactions, you might enjoy our article on creating high quality interactions which gives a nice overview of #allthethings. Cheers 🥂\n\nReordering is special and the perfect place to address a couple of the UX patterns and logic you might want to apply to your drag and drop situation. Let’s take a moment to zoom in on it, so that we can discuss both the drop indicator and the behaviour of the container of the list items.\n\nYou know what’s hard? Showing on a flat screen that you can ‘physically’ pick something up (you can’t actually because it’s 0’s and 1’s) and ‘move’ it (you’re actually changing values of 0’s and 1’s in the database that surrounds the product). Showing that drag and drop is available is a difficult challenge for designers. We’ve got issues people.\n\nIf the interaction was physical, you could easily create a handle which is obviously designed for a hand to fit around it. That handle would be there, out in the open. Our challenge with drag and drop is that the ‘hand’ is either our pointer/cursor on desktop and a finger on mobile (where you can’t detect if it’s close by to the item at all because people don’t ‘look’ around on their mobile screen using their finger). On top of that, drag and drop may be a very occasional action people do, screen real estate and attention is limited, and screens get cluttered very quickly. Always showing the ability to drag and drop makes it more discoverable, but does it pull focus and make other things less discoverable? It’s a balance we’re always trying to come to when we create UIs.\n\nSo how do we make things look like you can pick them up and drag? One technique (the most common one) is the use of icons. Iconography, as we know from many other moments (like in navigation, or buttons for example), can be very tricky to get right.\n\n\n\nOnce upon a time we tested some drag and drop affordances, and let’s just say, it was confusing 🫠 (this was quite a few years ago), but we wanted to provide a specific affordance that told users precisely what they could do. This is a summary of how it went:\n\nAnother visual indicator that a drag is possible happens with the cursor on desktop, specifically upon hovering over a draggable item. We typically see a pointer appear initially, then a grabbing hand once the mouse is being pressed. For move and the re-size cursors, they typically stay the same on hover and while they are active.\n\n🔥 Hot Tip: grabbing something to drag it isn’t exactly the same thing as selecting something. Account for the possibility of multi-selection and drag and drop.\n\nAffordances of drag and drop aren’t only localized to the list item itself. The drop target (AKA drop-zone) is also used to communicate the possibilities – that plus the fact that the technique is used across so many platforms can help people put the pieces together. 🤞\n\nDiscoverability will be likely to continue to be a challenge in the UX design world for a while. With enterprise products, we have the context of users being trained and perhaps more motivated to discover things that might make their workflow easier than consumer products. But, as we always say, test early and test often. Also utilize your usage analytics when you can to understand more about user behaviour in reality.\n\nDark mode to UI is what drag and drop is to interaction. It really does illicit strong reactions, either FOR and AGAINST it. For us, we feel that your design rationale and logic is key to justifying your efforts in creating new interactions and functionality overall. There are lots of good reasons and rationale to create a drag and drop interaction.\n\nIn cases where the specific view is highly visual, allowing users to directly manipulate the object they are working with is a strong approach to building interactions that are intuitive. Some enterprise examples include a data model visualization, a drawing application, or an org chart visualization tool\n\nReordering lists using the non drag and drop patterns out there, can be quite onerous and difficult to QA (ex. Adding numeric fields to order them or using a container system with an ‘input’ on the left and ‘output’ on the right) – our crew isn’t convinced these approaches are easier to develop nor are they less confusing than drag and drop.\n\nEnterprise software shoutout here. We actually do a good chunk of UIs which display complex logic in a visual way. There are a ton of use cases around boolean logic (and other logic) out there. To understand them, visualizations are the most efficient way to understand at a glance, the way these systems work. By extension, direct manipulation of the object through drag and drop can be the most intuitive.\n\nDisadvantages or reasons to avoid drag and drop\n\nDrag and drop is a very ‘demo-able’ feature, it certainly brings the razzle dazzle and presents as very easy in that kind of context. When thinking about solving a problem with drag and drop, consider some of the possible disadvantages of using this interaction mechanism.\n\nIf there is priority for these interactions to be created/improved, the non-drag and drop version is key to have as well. Accessibility is a big murky question here that could be an issue throughout discovery all the way to execution. When we’re working on enterprise products, we typically start by building the alternative, then build drag and drop as a supporting interaction or ‘power user’ version of the feature.\n\nAs mentioned when we started this article, drag and drop can be pretty complicated in terms of the interaction design, there are lots of cases and considerations to make. If implementing drag and drop as a solution, it needs to be tested across platforms and devices rigorously. If you don’t have the bandwidth to do this, you risk blockers in your software. Drag and drop really needs to be implemented well to work well.\n\nIf you are required to scroll and drag at the same time, this may be way too onerous and frustrating for your users. This long distance scrolling might pop up when you have screens which may be very long (and this isn’t predictable because it’s user generated data) like screens with infinite scroll.\n\nDrag and drop is slick and cool, but sometimes there isn’t a good enough justification to build with drag and drop, or perhaps the action is quite high stakes, so lowering the barrier of entry and making it super efficient isn’t ideal.\n\nIn enterprise, we typically always design alternatives to drag and drop, even when the drag and drop interaction is definitely making it to production. Having only drag and drop in place to achieve a goal is fragile, because if it isn’t usable by someone, that’s a blocker. (Other than accessibility, there are other ways drag and drop can fail, including latency of the system (ex. secure systems you have to use a virtual machine or VPN to access, browser updates causing bugs, outdated front end frameworks, even just someone having a wonky mouse — you need contingency.)\n\nFor moving things, it’s possible that some of the most basic UI mechanisms can do the job for you, perhaps in a more expedient way.\n\nThe example above shows two methods, the action bar (this can be contextual or persistent), it offers a way to apply not JUST a move action, but could house a myriad of batch actions at the same time. The menu dropdown is another method you can use, where you can manipulate the item directly, without moving things visually.\n\nSteps of this mobile drag and drop alternative flow are quite simple. This is something worth considering for reordering on mobile.\n• Tap to select → Each selected chip shows a number to help the user keep track of how many of the 5 they've already selected. They can reset their options or un-select a chip to remove it from their total count.‍\n• Click 'Next' → Once more than 1 chip is selected, the 'next' link becomes clickable\n\nWant more alternatives to drag and drop? Shoot us a request on Twitter, we’re full of ideas!\n\nThere’s probably a few articles to write on this topic, as a thorough usability test of drag and drop should ideally involve a mix of user profiles, system states and devices/hardware.\n\nOn the practical front, user testing drag and drop is quite difficult on a high fidelity design software, especially if you’ve got some complexity in your drag targets or there are multiple states and scenarios you’d like to test.\n\nHere’s where the design and dev crew can shine together as a team. Since so many frameworks are typically used with drag and drop, we suggest that you create a live code prototype that’s realistic enough to give you some nice usability insights. If you’re able to use something that’s relatively fast to build, you’ll be able to nuance and iterate on the behaviour together in a super productive way.\n\nIf you want to dig into more topics on collaboration, check out some of our stuff on team collaboration.\n\nWell, we hope your 🧠 is activated by all these drag and drop best practices and UX patterns…and downright nerdy energy we’re servin’ up. Drag and drop is a very rich and interesting interaction pattern that can extend your functionality and give amazing power to your SaaS or enterprise software application. When this functionality is combined with complex operations, workflows and use cases, this can be an excellent tool to give to your power users. Proceed with intention, user data and creativity! 🪐"
    },
    {
        "link": "https://nngroup.com/articles/drag-drop",
        "document": "Clear signifiers and clear feedback at all stages of the interaction make drag–and–drop discoverable and easy to use.\n\nDrag–and–drop has been around since the dawn of GUIs and is familiar to most users. It is a type of direct manipulation, particularly useful for grouping, reordering, moving, or resizing objects. It works as follows:\n• As with all direct-manipulation interactions, items of interest need to be visible on the screen — for example, icons, thumbnails, or explicit interface elements, such as column dividers in a table or spreadsheet. (In principle, we can drag invisible objects, but usability would surely suffer.)\n• To initiate the interaction, users acquire an object — using a mouse or touch gesture (such as a mouse click or, respectively, a long press). Other selection techniques are possible, but not as common — for example, speech (“select the red car”) or “grabbing” an object in a VR or AR environment.\n• While keeping the object selected (e.g., by continuous pressure on the mouse button), the user then moves the pointing device (mouse, finger, etc.) to some desired target. This is the “drag” part of the operation.\n• Finally, the user deselects the object — for example, by letting go of the mouse button. This is the “drop” step.\n\nThe outcome of all these steps may simply be that the object has been relocated. For example, moving a column divider to the right makes that table column wider. Or, moving a circle in a drawing program changes the look of the picture being drawn. But the movement may also trigger a full command. The classic example is dragging a file icon to the trash icon and dropping it there, causing the corresponding file to be deleted. For many operations, drag–and–drop makes the actions visible and immediate and can thus improve usability.\n\nThe downsides to drag–and–drop are that it can be inefficient, imprecise, and even physically challenging, especially over long distances: if they run out of room, users might need to reposition their mouse or adjust their finger on a touchscreen. Thus, it often results in errors — the user drops an item in the wrong spot, and has to start all over again.\n\nBecause it is inherently a tricky physical interaction, understand your users’ mental model for the action that it will implement to make sure that they expect to use it. During usability testing, observe if users attempt to drag–and–drop objects (but don’t ask them about it directly).\n\nIn many cases, the downsides of drag–and–drop can be addressed by an accompanying more-precise interaction; for example, dragging a shape in Photoshop can get it to the general desired area, and then arrow keys can be used to precisely position it. In some situations, alternative interactions can replace drag-and-drop completely; on mobile, for example, using menus to move a file to a different folder can be less error-prone than drag-and-drop.\n\nWhen appropriate, drag–and–drop is well understood, and quickly adopted by users. All the interactions that drag–and–drop is used for can be grouped in two main types: resizing objects and moving objects. These two capabilities need different microinteraction design to succeed as intuitive, responsive interfaces.\n\nCreating an obvious signifier for drag–and–drop is challenging. While a button can have a subtle drop shadow to indicate that it is raised and clickable, a drag–and–drop signifier has to signal two functions — (1) that the item is “grabbable” and (2) what dragging it somewhere will accomplish (moving or resizing).\n\nThere are two types of visual signifiers for grabbability: grab-handle icons and cursor changes.\n\nGrab handle icons communicate that drag–and–drop is available and provide a safe target to click and drag without activating other nearby controls. (In some applications the user need not click exactly on the grab handle icon, but its purpose remains the same.)\n\nUnfortunately, icons in use for this purpose are not nearly as universal as designers may think and they are often a poor visual metaphor. There are several common drag–and–drop icons in use and the lack of a universal convention reduces their efficacy and recognizability.\n\nSome of the handle icons used to signal movement are confusing also because they resemble familiar icons conventionally used for other functionalities, such as a hamburger icon or the kebab icon.\n\nSome of these icons also attempt to indicate the direction of movement: either in one dimension (e.g. reordering a list) or two dimensions (e.g. moving a window around on a screen), but their lack of external consistency fails to communicate the purpose clearly.\n\nFor resizing, such as expanding column headers in a table or changing an object’s size on a canvas, the grab-handle icon is often pretty subtle: a single vertical line between columns, for example, or a pair of diagonal lines in the bottom right corner.\n\nIn mouse-driven interfaces, cursor changes can also be used to signal that drag–and–drop is available: as the user hovers upon an object that can be dragged–and–dropped, the cursor changes shape to indicate that clicking it will initiate a grab.\n\nIf you decide to change the cursor icon, avoid creating new, custom icons. Use the platform’s standard cursor for moving or resizing. On Macs, the standard arrow cursor will change to an open, white-gloved “Mickey Mouse” hand; this icon will further change to look like a closed hand grasping when the object is grabbed. Windows uses a white crossbar icon for drag–and–drop (typically for objects within an app or website, not for windows). For websites, CSS has a variety of classes that use the native platform icons.\n\nWhen the grab is followed by resizing, a slightly different crossbar cursor icon is available. The icon shows the arrows along one axis. A diagonal icon pointing out of a window in the corner indicates that an object can be resized along two dimensions at once (both width and height).\n\nFeedback that an Object Has Been Grabbed\n\nOnce the user has “grabbed” the object that will be dragged–and–dropped, two types of feedback are needed: (1) feedback that the object was “grabbed”, and (2) feedback previewing what will happen before the user “drops” the object.\n\nFeedback that the object is grabbed usually makes the object look different than other similar objects on the screen; it can include the following:\n• A visual presentation that makes it appear “above” other items, such as a drop shadow\n• Visual offsetting of the object, such as indenting it or angling it\n• A small, translucent “ghost” image of the object (for file uploading or moving between folders)\n\nWhen dragging a file (e.g., to upload it or moving it to a different location), the cursor will typically stay unchanged, but a small, translucent “ghost” preview image of the file will be displayed. This image communicates that the file is being dragged and, when the ghost image is clear enough, helps prevent slips where a user drags the wrong file accidentally.\n\nEspecially when drag–and–drop is used to reorder a list of items, it’s important to show the background objects moving out of the way before the user releases the item. This short animation gives a preview of what will happen when the cursor is released and makes the motion feel natural. Rather than instantly redrawing the other objects in their new place, use a quick animation (roughly 100 ms) to show them moving towards their new location, in order to give the user a sense of physical manipulation of the objects. As with other types of UX motion, use easing to make the motion look natural.\n\nOne of the most complex aspects of the animated preview is deciding when to trigger the motion: should an object start moving out of the way when the edge of the grabbed object overlaps it or when the position of the mouse cursor overlaps the other object? The most natural version of this interaction uses neither — instead, it begins the reshuffling animation once the center of the dragged object overlaps the edge of the other object. This solution prevents both a “mushy”-feeling interaction (where it is slow and unresponsive), or a “twitchy”-feeling interaction (where items begin to move unexpectedly and too quickly).\n\nAs described by Fitts’s Law, moving the cursor to a precise location on screen is challenging, which makes drag–and–drop inherently inefficient for precise adjustments. One way to mitigate this challenge is by simulating a magnetic effect that snaps objects into place, even if the user hasn’t yet fully acquired the target. For example, a file-upload drop zone can be active slightly outside its borders, allowing users to release the mouse before they’ve gotten all the way there.\n\nTo use magnetism, you need to clearly indicate to the user when the drop zone is active, by showing a visual signifier when the dragged object is within the active drop zone (especially if the droppable area extends outside the visible border). Several common signifiers that are used for magnetism include a dotted border around the drop zone (especially common in file uploads) a highlight appearing over the drop zone when the cursor goes nearby, or an animation showing where it will snap into place before the user releases their cursor.\n\nDrag–and–drop is traditionally a mouse or touchscreen-only interaction, but making it accessible for people that use assistive technologies is both completely possible and necessary. First, make sure that your handle icon is keyboard accessible with the Tab key; this enables “grabbing” the draggable item via the spacebar. Second, make sure the handle icon offers a message to screen readers that indicates what actions are available (typically using arrow keys to move or resize the object), whether it is currently “grabbed”, and its current position or size.\n\nDrag–and–drop can be hard to implement on touchscreens because they lack hover states, which are often used to signal the availability of drag–and–drop. Furthermore, due to the fat-finger problem, you need to ensure that draggable objects have at least 1cm x 1cm of unused space for dragging and that fingers don’t cover any important feedback (such as a highlighted “grab” state). Another important consideration is that you must distinguish among a tap, a swiping gesture (such as scrolling), and an intentional “grab” by using a timing delay of a few milliseconds, and providing clear feedback that the object has been grabbed.\n\nOne way to provide feedback on mobile for drag–and–drop is to use haptics; a subtle haptic “bump” can indicate that an object has been grabbed, and another one can indicate that an object has been dragged over a drop zone.\n\nSince hover signifiers for drag–and–drop (such as a cursor change) are not available on touchscreens, it is recommended to use drag–and–drop only when:\n• You have clear evidence (from research such as usability testing) that your users expect drag–and–drop to be available, and\n• There is no reasonable alternative with lower interaction cost (such as cut–and–paste or a menu-driven interaction).\n\nDrag–and–drop is not always the best choice, but when users expect it, the familiarity of the metaphor can make the interaction relatively simple and straightforward. To make drag–and–drop as effective as possible, use appropriate signifiers, such as handle icons and hover-state cursor changes, provide clear feedback throughout the interaction, and ensure that it is accessible."
    },
    {
        "link": "https://blog.prototypr.io/building-a-responsive-drag-and-drop-ui-5761fd5281d5",
        "document": "Drag and drop, in the context of a web app, gives people a visual way to pick up and move elements just like we would in the real world. This bit of skeuomorphism makes User Interfaces with drag and drop interactions intuitive to use. Skeuomorphism is where an object in software mimics its real world counterpart. — IDF Whilst there may not be an obvious real-world counterpart to dragging digital cards around an interactive Kanban list, such as that of Trello, the action itself is familiar to humans, so it’s easy to learn. Modern skeuomorphism is the bridge at the intersection of digital and industrial design. It is about facilitating non-traditional device interaction without sacrificing usability. It is about enriching and enlivening real world objects in the context of our human physiology. ~ Justin Baker Despite these interactions becoming a common feature in a wide range of tools on the web — from Kanban boards like Trello, to actual email inboxes like Gmail, they’re pretty hard to actually build. I found this out when making my own, even with the use of open source libraries. Here’s what it looks like at the moment:\n• Making it responsive: Drag and drop on mobile\n\nBefore looking into different libraries, and the technical side of implementing a drag and drop, I’d recommend starting with the design considerations. What makes a good drag and drop? Here’s a few things: Accessibility can be challenging for a drag and drop, with traditional drag and drop libraries skipping past it: Traditionally drag and drop interactions have been exclusively a mouse or touch interaction. ~ Alex Reardon If a user can’t physically drag and drop using their method of interaction, how can you make it easier? Keyboard interactions are a good option, e.g.:\n• Use arrow keys to move the selected element\n• Use space again to drop Without prior knowledge, this area can sound like something daunting to implement. A good place to start exploring is ARIA Live Regions, which help you communicate operation, identity, and state during a drag and drop interaction. Jesse Hausler (Principal Accessibility Specialist at Salesforce) covers this his article article, ‘4 Major Patterns for Accessible Drag and Drop’. The drag handle is the area of the draggable element that you click or touch to pick up and move an item. It also can be called the draggable area: The example above shows small handle, which can work for somebody on a desktop device with a mouse cursor, but may be tricky for a chubby finger on a small touch screen. In that case you may want to make some changes. You can also question using a drag handle at all. Whilst helpful in some contexts, in others, it might not actually be necessary: For components that don’t typically involve drag and drop, a drag handle helps users discover drag and drop as an available action. But in cases where drag and drop is always an expected behavior, it isn’t necessary. ~ Grace Noh, on Marvel blog This is evident in Notion. For their regular list views, a really small drag handle is present, but not for the Kanban view. In that situation, the entire card becomes the draggable surface:"
    },
    {
        "link": "https://saasframe.io/blog/mastering-drag-and-drop-a-comprehensive-guide",
        "document": "Few interactions are as versatile and intuitive as drag and drop. From organizing tasks in productivity apps to rearranging elements on a website, drag and drop interfaces empower users to interact with digital content in a fluid and natural manner. In this guide, we'll explore everything UX designers need to know about harnessing the power of drag and drop to create seamless and engaging user experiences.\n\nAt its core, drag and drop is a user interface gesture that allows users to select an object (or multiple objects) by clicking and holding on it, dragging it to a new location, and releasing the mouse button to drop it into place. This interaction pattern is widely used across various digital platforms and applications, offering users a tactile way to manipulate and interact with content.\n\nBenefits of Drag and Drop in UX Design\n• Intuitiveness: Drag and drop interfaces mimic real-world interactions, making them intuitive and easy to learn for users of all skill levels.\n• Efficiency: Drag and drop interactions streamline complex tasks, such as organizing files or rearranging elements, by allowing users to directly manipulate content with minimal effort.\n• Flexibility: Drag and drop interfaces offer users the freedom to customize their experiences by arranging elements according to their preferences, fostering a sense of ownership and control.\n• Engagement: Interactive drag and drop experiences can enhance user engagement and satisfaction, providing immediate visual feedback and a sense of accomplishment.\n\nBest Practices for Designing Drag and Drop Interfaces\n• Visual Feedback: Provide clear visual cues to indicate draggable elements and drop targets, such as highlighting or animation effects, to guide users throughout the interaction.\n• Accessibility: Ensure that drag and drop interactions are accessible to users with disabilities by providing alternative input methods, such as keyboard shortcuts or assistive technologies.\n• Consistency: Maintain consistency in drag and drop behavior across different parts of the interface and platforms to avoid confusion and enhance learnability.\n• Undo Functionality: Implement an undo feature to allow users to revert changes made through drag and drop interactions, reducing the risk of accidental actions and preserving user control.\n• Performance Optimization: Optimize the performance of drag and drop interactions to ensure smooth and responsive user experiences, particularly in applications with large datasets or complex layouts\n\nCommon Use Cases for Drag and Drop in UX Design\n• Task Management: Drag and drop can facilitate task organization in productivity apps, allowing users to prioritize, categorize, and schedule tasks with ease.\n• Content Management: Content management systems (CMS) often leverage drag and drop interfaces for arranging and editing website content, such as articles, images, and multimedia elements.\n• Data Visualization: Drag and drop can be used to create interactive data visualization tools, enabling users to customize charts, graphs, and dashboards according to their data analysis needs.\n• File Management: File management applications utilize drag and drop interfaces for organizing files and folders, enabling users to move, copy, and delete files effortlessly.\n• Layout Customization: Drag and drop interfaces empower users to customize the layout and design of digital interfaces, such as website builders or email template editors, by rearranging and resizing elements.\n\nWhile drag and drop interactions offer numerous benefits, they also present challenges and considerations for UX designers, including:\n• Touchscreen Optimization: Designing for touch-based devices requires special consideration for touch gestures and screen real estate to ensure a seamless drag and drop experience.\n• Complexity: Complex drag and drop interactions with multiple draggable elements and drop targets can be challenging to implement and may require careful planning and testing.\n• Error Handling: Designing robust error handling mechanisms is crucial to address issues such as invalid drop locations or conflicts between draggable elements.\n• Performance: Performance optimization is essential to maintain responsiveness and fluidity in drag and drop interactions, particularly in applications with large datasets or dynamic content.\n\nDrag and drop interfaces are a powerful tool in the UX designer's toolkit, offering intuitive, efficient, and engaging user experiences across a wide range of applications and platforms. By understanding the principles, best practices, and common use cases of drag and drop, UX designers can create seamless and delightful experiences that empower users to interact with digital content with ease and confidence.\n\nReady to elevate your UX design with drag and drop interactions? Incorporate these best practices and considerations into your design process to unlock the full potential of this versatile interaction pattern.\n\nStay tuned for more insights and tips on UX design from SaaSFrame!"
    }
]