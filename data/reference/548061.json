[
    {
        "link": "https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html",
        "document": "Converts an image from one color space to another.\n\nThe function converts an input image from one color space to another. In case of a transformation to-from RGB color space, the order of the channels should be specified explicitly (RGB or BGR). Note that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the bytes are reversed). So the first byte in a standard (24-bit) color image will be an 8-bit Blue component, the second byte will be Green, and the third byte will be Red. The fourth, fifth, and sixth bytes would then be the second pixel (Blue, then Green, then Red), and so on.\n\nThe conventional ranges for R, G, and B channel values are:\n\nIn case of linear transformations, the range does not matter. But in case of a non-linear transformation, an input RGB image should be normalized to the proper value range to get the correct results, for example, for RGB \\(\\rightarrow\\) L*u*v* transformation. For example, if you have a 32-bit floating-point image directly converted from an 8-bit image without any scaling, then it will have the 0..255 value range instead of 0..1 assumed by the function. So, before calling cvtColor , you need first to scale the image down:\n\nIf you use cvtColor with 8-bit images, the conversion will have some information lost. For many applications, this will not be noticeable but it is recommended to use 32-bit images in applications that need the full range of colors or that convert an image before an operation and then convert back.\n\nIf conversion adds the alpha channel, its value will set to the maximum of corresponding channel range: 255 for CV_8U, 65535 for CV_16U, 1 for CV_32F."
    },
    {
        "link": "https://blog.roboflow.com/opencv-color-spaces",
        "document": "Color spaces are fundamental to image processing and computer vision. They define how colors are represented in an image. OpenCV, a popular library for computer vision, supports multiple color spaces, each with its own unique properties and use cases.\n\nIn this blog post, we’ll explore some of the most commonly used color spaces in OpenCV: BGR, RGB, HSV, and more. We’ll also provide Python code examples and visual outputs to help you understand these concepts better.\n\nOpenCV, by default, reads images in the BGR (Blue, Green, Red) color space. This is different from the more commonly known RGB (Red, Green, Blue) color space. The difference lies in the order of the channels.\n\nYou may be wondering: why is BGR the default colour space?\n\nHistorically, OpenCV adopted BGR as its default because of how some camera manufacturers and software libraries stored color information. However, most other libraries (like Matplotlib) use RGB, so you’ll often need to convert between the two.\n\n\n\nNote: Make sure you have OpenCV and Matplotlib installed to run the code examples:\n\nYou can convert BGR data to RGB using the method:\n\nHere is an example showing the data before and after conversion:\n\nHSV stands for Hue, Saturation, and Value. It is often used in tasks like object tracking and color segmentation because it separates color information (hue) from brightness (value) and saturation.\n• Saturation: Represents the intensity or purity of the color (0% to 100%).\n• Value: Represents the brightness of the color (0% to 100%).\n\nYou can convert data from BGR to HSV with the method:\n\nHere is an example showing the data before and after conversion:\n\nGrayscale is a single-channel representation of an image, where each pixel represents only the intensity of light (brightness). It is often used to augment data for use in training computer vision models.\n\nYou can convert data from RGB to Grayscale using the method:\n\nHere is an example of an image converted using the code above:\n\nThe LAB color space separates color information into three channels:\n\nLAB is designed to approximate human vision and is useful for tasks like color correction and image enhancement.\n\nYou can convert data from BGR to LAB with the method:\n\nHere is an example of an image converted with this method:\n\nYCrCb is a color space commonly used in video and image compression. It separates luminance (Y) from chrominance (Cr and Cb):\n\nYou can convert data from BGR to YCrCb with the method:\n\nHere is an example of an image converted with this method:\n\nUnderstanding color spaces is crucial for effective image processing and computer vision. OpenCV provides a wide range of color space conversions, each suited for specific tasks.\n\nWhether you’re working with BGR, RGB, HSV, or any other color space, knowing how to manipulate and convert between them will help you achieve better results in your projects."
    },
    {
        "link": "https://stackoverflow.com/questions/23396501/how-to-convert-an-rgb-image-to-ycrcb-colour-space-in-opencv-python",
        "document": "using open cv python i am trying to convert an rgb image to ycbcr using cv2.cvtclor.\n\nthe error is name 'CV_BGR2YCrCb' is not defined\n\nCan anyone suggest few ideas."
    },
    {
        "link": "https://docs.opencv.org/4.x/df/d9d/tutorial_py_colorspaces.html",
        "document": "\n• In this tutorial, you will learn how to convert images from one color-space to another, like BGR \\(\\leftrightarrow\\) Gray, BGR \\(\\leftrightarrow\\) HSV, etc.\n• In addition to that, we will create an application to extract a colored object in a video\n• You will learn the following functions: cv.cvtColor(), cv.inRange(), etc.\n\nThere are more than 150 color-space conversion methods available in OpenCV. But we will look into only two, which are most widely used ones: BGR \\(\\leftrightarrow\\) Gray and BGR \\(\\leftrightarrow\\) HSV.\n\nFor color conversion, we use the function cv.cvtColor(input_image, flag) where flag determines the type of conversion.\n\nFor BGR \\(\\rightarrow\\) Gray conversion, we use the flag cv.COLOR_BGR2GRAY. Similarly for BGR \\(\\rightarrow\\) HSV, we use the flag cv.COLOR_BGR2HSV. To get other flags, just run following commands in your Python terminal:\n\nNow that we know how to convert a BGR image to HSV, we can use this to extract a colored object. In HSV, it is easier to represent a color than in BGR color-space. In our application, we will try to extract a blue colored object. So here is the method:\n• Take each frame of the video\n• We threshold the HSV image for a range of blue color\n• Now extract the blue object alone, we can do whatever we want on that image.\n\nBelow is the code which is commented in detail:\n\nBelow image shows tracking of the blue object:\n\nHow to find HSV values to track?\n\nThis is a common question found in stackoverflow.com. It is very simple and you can use the same function, cv.cvtColor(). Instead of passing an image, you just pass the BGR values you want. For example, to find the HSV value of Green, try the following commands in a Python terminal:\n\nNow you take [H-10, 100,100] and [H+10, 255, 255] as the lower bound and upper bound respectively. Apart from this method, you can use any image editing tools like GIMP or any online converters to find these values, but don't forget to adjust the HSV ranges.\n• Try to find a way to extract more than one colored object, for example, extract red, blue, and green objects simultaneously."
    },
    {
        "link": "https://learnopencv.com/color-spaces-in-opencv-cpp-python",
        "document": "In this tutorial, we will learn about popular colorspaces used in Computer Vision and use it for color based segmentation. We will also share demo code in C++ and Python.\n\nIn 1975, the Hungarian Patent HU170062 introduced a puzzle with just one right solution out of 43,252,003,274,489,856,000 (43 quintillion) possibilities. This invention now known as the Rubik’s Cube took the world by storm selling more than 350 million by January 2009.\n\nSo, when a few days back my friend, Mark, told me about his idea of building a computer vision based automated Rubik’s cube solver, I was intrigued. He was trying to use color segmentation to find the current state of the cube. While his color segmentation code worked pretty well during evenings in his room, it fell apart during daytime outside his room!\n\nHe asked me for help and I immediately understood where he was going wrong. Like many other amateur computer vision enthusiasts, he was not taking into account the effect of different lighting conditions while doing color segmentation. We face this problem in many computer vision applications involving color based segmentation like skin tone detection, traffic light recognition etc. Let’s see how we can help him build a robust color detection system for his robot.\n\nThe article is organized as follows:\n• First we will see how to read an image in OpenCV and convert it into different color spaces and see what new information do the different channels of each color space provide us.\n• We will apply a simple color segmentation algorithm as done by Mark and ponder over its weaknesses.\n• Then we will jump into some analytics and use a systematic way to choose:\n• The right threshold values for segmentation.\n\nIn this section, we will cover some important color spaces used in computer vision. We will not describe the theory behind them as it can be found on Wikipedia. Instead, we will develop a basic intuition and learn some important properties which will be useful in making decisions later on.\n\nLet us load 2 images of the same cube. It will get loaded in BGR format by default. We can convert between different colorspaces using the OpenCV function cvtColor() as will be shown later.\n\nThe first image is taken under outdoor conditions with bright sunlight, while the second is taken indoor with normal lighting conditions.\n\nThe RGB colorspace has the following properties\n• It is an additive colorspace where colors are obtained by a linear combination of Red, Green, and Blue values.\n• The three channels are correlated by the amount of light hitting the surface.\n\nLet us split the two images into their R, G and B components and observe them to gain more insight into the color space.\n\nIf you look at the blue channel, it can be seen that the blue and white pieces look similar in the second image under indoor lighting conditions but there is a clear difference in the first image. This kind of non-uniformity makes color based segmentation very difficult in this color space. Further, there is an overall difference between the values of the two images. Below we have summarized the inherent problems associated with the RGB Color space:\n\nThe Lab color space has three components.\n\nThe Lab color space is quite different from the RGB color space. In RGB color space the color information is separated into three channels but the same three channels also encode brightness information. On the other hand, in Lab color space, the L channel is independent of color information and encodes brightness only. The other two channels encode color.\n\nIt has the following properties.\n• Perceptually uniform color space which approximates how we perceive color.\n• Is related to the RGB color space by a complex transformation equation.\n\nLet us see the two images in the Lab color space separated into three channels.\n• It is pretty clear from the figure that the change in illumination has mostly affected the L component.\n• The A and B components which contain the color information did not undergo massive changes.\n• The respective values of Green, Orange and Red ( which are the extremes of the A Component ) has not changed in the B Component and similarly the respective values of Blue and Yellow ( which are the extremes of the B Component ) has not changed in the A component.\n\nThe YCrCb color space is derived from the RGB color space and has the following three compoenents.\n• Y – Luminance or Luma component obtained from RGB after gamma correction.\n• Cr = R – Y ( how far is the red component from Luma ).\n• Cb = B – Y ( how far is the blue component from Luma ).\n\nThis color space has the following properties.\n• Separates the luminance and chrominance components into different channels.\n• Mostly used in compression ( of Cr and Cb components ) for TV Transmission.\n\nThe two images in YCrCb color space separated into its channels are shown below\n• Similar observations as LAB can be made for Intensity and color components with regard to Illumination changes.\n• Perceptual difference between Red and Orange is less even in the outdoor image as compared to LAB.\n• White has undergone change in all 3 components.\n\nThe HSV color space has the following three components\n\nLet’s enumerate some of its properties.\n• Best thing is that it uses only one channel to describe color (H), making it very intuitive to specify color.\n\nThe H, S and V components of the two images are shown below.\n• The H Component is very similar in both the images which indicates the color information is intact even under illumination changes.\n• The S component is also very similar in both images.\n• The V Component captures the amount of light falling on it thus it changes due to illumination changes.\n• There is drastic difference between the values of the red piece of outdoor and Indoor image. This is because Hue is represented as a circle and red is at the starting angle. So, it may take values between [300, 360] and again [0, 60].\n\nHow to use these color spaces for segmentation\n\nNow that we have got some idea about the different color spaces, lets first try to use them to detect the Green color from the cube.\n\nStep 1 : Get the color values for a particular color\n\nFind the approximate range of values of green color for each color space. For doing this, I’ve made an interactive GUI where you can check the values of all the color spaces for each pixel just by hovering the mouse on the image as shown below :\n\nExtract all pixels from the image which have values close to that of the green pixel. We can take a range of +/- 40 for each color space and check how the results look like. We will use the opencv function inRange for finding the mask of green pixels and then use bitwise_and operation to get the green pixels from the image using the mask.\n\nAlso note that for converting one pixel to another color space, we first need to convert 1D array to a 3D array.\n\nSo, it seems that the RGB and LAB are enough to detect the color and we dont need to think much. Lets see some more results.\n\nSo, the same threshold doesn’t work on the dark image. Doing the same experiment to detect the yellow color gives the following results.\n\nBut why is it that the results are so bad? This is because we had taken a wild guess of 40 for the threshold. I made another interactive demo where you can play with the values and try to find one that works for all the images. Check out the screenshot. But then there will be cases where another image comes and it doesn’t work again. We cannot just take some threshold by trial and error blindly. We are not using the power of the color spaces by doing so.\n\nWe need to have some methodical way to find the correct threshold values.\n\nSome Data Analysis for a Better Solution\n\nI have collected 10 images of the cube under varying illumination conditions and separately cropped every color to get 6 datasets for the 6 different colors. You can see how much change the colors undergo visually.\n\nCheck the distribution of a particular color say, blue or yellow in different color spaces. The density plot or the 2D Histogram gives an idea about the variations in values for a given color. For example, Ideally the blue channel of a blue colored image should always have the value of 255. But practically, it is distributed between 0 to 255.\n\nI am showing the code only for BGR color space. You need to do it for all the color spaces.\n• We will first load all images of blue or yellow pieces.\n• Separate the channels and create and array for each channel by appending the values from each image.\n• Use histogram plot from matplotlib to plot the 2D histogram\n\nIt can be seen that under similar lighting conditions all the plots are very compact. Some points to be noted are :\n• YCrCb and LAB are much more compact than others\n• In HSV, there is variation in S direction ( color purity ) but very little variation in H direction.\n\nAs the Illumination changes by a large amount, we can see that :\n• Ideally, we want to work with a color space with the most compact / concentrated density plot for color channels.\n• The density plots for RGB blow up drastically. This means that the variation in the values of the channels is very high and fixing a threshold is a big problem. Fixing a higher range will detect colors which are similar to the desired color ( False Positives ) and lower range will not detect the desired color in different lighting ( False Negatives ).\n• In HSV, since only the H component contains information about the absolute color. Thus, it becomes my first choice of color space since I can tweak just one knob ( H ) to specify a color as compared to 2 knobs in YCrCb ( Cr and Cb ) and LAB ( A and B ).\n• Comparing the plots of YCrCb and LAB shows a higher level of compactness in case of LAB. So, next best choice for me becomes the LAB color space.\n\nIn this last section, I will show the results for detecting the blue and yellow piece by taking the threshold values from the density plots and applying it to the respective color spaces in the same way we did in the second section. We don’t have to worry about the Intensity component when we are working in HSV, YCrCb and LAB color space. We just need to specify the thresholds for the color components. The values I’ve taken for generating the results are shown in the figures.\n\nIn the above results I have taken the values directly from the density plot. We can also chose to take the values which belong to to most dense region in the density plot which will help in getting tighter control of the color range. That will leave some holes and stray pixels which can be cleaned using Erosion and Dilation followed by Filtering.\n\nOther Useful Applications of Color spaces\n• Histogram equalization is generally done on grayscale images. However, you can perform equalization of color images by converting the RGB image to YCbCr and doing histogram equalization of only the Y channel.\n• Color Transfer between two images by converting the images to Lab color space.\n• Many filters in smartphone camera applications like Google camera or Instagram make use of these Color space transforms to create those cool effects!\n\nP.S : If you’re interested in solving a Rubik’s cube, you can refer to this step-by-step guide."
    },
    {
        "link": "https://stackoverflow.com/questions/40878731/the-convert-between-ycbcr-and-rgb-on-python",
        "document": "I want to write some image processing code on python.\n\nHowever , when I try to do the same thing on python the psnr is lower then the result of matlab.\n\nThere is no any problem of the psnr function on both python/matlab , I am sure that they are the same, beacuse i have tried to output the image and measure them on both python/matlab.\n\nThe problem is , why a got a lower psnr when i do convert on Python ?"
    },
    {
        "link": "https://stackoverflow.com/questions/47700042/why-we-use-a-complex-equation-when-do-convert-rgb-to-ycbcr-instead-of-a-simple-o",
        "document": "When I do implement RGB2YCBCR on verilog. I saw several ways to convert RGB to YCBCR. Some of it are very simple. But others are quite complex.\n\nFor example, if we use\n\nit is very easy to implement to hardware\n\nBut some people say that\n\nI don't know why they have this equation and why a complex equation better than a simple equation. And WHY THEY USE IT instead of that simple equation.\n\nP/S: I saw that OpenCV also uses that complex one. Thank a lot!"
    },
    {
        "link": "https://github.com/opencv/opencv/issues/17370",
        "document": "I have a problem when I convert the color space from RGB to YCrCb. Accroding to RGB ↔ YCrCb JPEG (or YCC), I write a function named .\n\nI use a picture named to test this function. The code works as follows:\n\nBut the output is:\n\nYou can see the output of is much different with the . Are there some mistakes in my function ?\n\nI checked the problem with documentation, FAQ, open issues, answers.opencv.org, Stack Overflow, etc and have not found solution."
    },
    {
        "link": "https://github.com/ghanashyamprabhu/RGB2YCbCr_py",
        "document": ""
    },
    {
        "link": "https://xilinx.com/products/intellectual-property/rgb_to_ycrcb.html",
        "document": "The AMD RGB to YCrCb Color Space Conversion LogiCORE™ is an optimized hardware block for converting RGB video data to the YCrCb color space.\n\nVideo system designers frequently need to convert video data between various color spaces. The AMD RGB to YCrCb Color-space Converter LogiCORE has built-in support for 5 formats and 3 range standards. The implementation is a simplified 3x3 constant coefficient matrix multiplier, which uses only 4 multipliers exploiting the inter-relations of RGB to YCrCb coefficients. The module is optimized to take advantage of multiply-add capabilities of XtremeDSP slices."
    }
]