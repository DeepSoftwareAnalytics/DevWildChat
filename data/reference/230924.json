[
    {
        "link": "https://tutorialspoint.com/pascal/pascal_memory.htm",
        "document": "This chapter explains dynamic memory management in Pascal. Pascal programming language provides several functions for memory allocation and management.\n\nWhile doing programming, if you are aware about the size of an array, then it is easy and you can define it as an array. For example, to store a name of any person, it can go max 100 characters so you can define something as follows −\n\nBut now, let us consider a situation, where you have no idea about the length of the text you need to store, for example, you want to store a detailed description about a topic. Here, we need to define a pointer to string without defining how much memory is required.\n\nWhen the above code is compiled and executed, it produces the following result −\n\nNow, if you need to define a pointer with specific number of bytes to be referred by it later, you should use the getmem function or the getmem procedure, which has the following syntax −\n\nIn the previous example, we declared a pointer to a string. A string has a maximum value of 255 bytes. If you really don't need that much space, or a larger space, in terms of bytes, getmem subprogram allows specifying that. Let us rewrite the previous example, using getmem −\n\nWhen the above code is compiled and executed, it produces the following result −\n\nSo, you have complete control and you can pass any size value while allocating memory unlike arrays, where once you defined the size cannot be changed.\n\nWhen your program comes out, operating system automatically releases all the memory allocated by your program, but as a good practice when you are not in need of memory anymore, then you should release that memory.\n\nPascal provides the procedure dispose to free a dynamically created variable using the procedure new. If you have allocated memory using the getmem subprogram, then you need to use the subprogram freemem to free this memory. The freemem subprograms have the following syntax −\n\nAlternatively, you can increase or decrease the size of an allocated memory block by calling the function ReAllocMem. Let us check the above program once again and make use of ReAllocMem and freemem subprograms. Following is the syntax for ReAllocMem −\n\nFollowing is an example which makes use of ReAllocMem and freemem subprograms −\n\nWhen the above code is compiled and executed, it produces the following result −\n\nPascal provides a hoard of memory management functions that is used in implementing various data structures and implementing low-level programming in Pascal. Many of these functions are implementation dependent. Free Pascal provides the following functions and procedures for memory management −"
    },
    {
        "link": "https://freepascal.org/docs-html/rtl/system/memoryfunctions.html",
        "document": "Move data from one location in memory to another"
    },
    {
        "link": "https://pilotlogic.com/sitejoom/index.php/107-wiki/pascal-basics/chapter-4/154-pascal-memory-management.html",
        "document": "This chapter explains dynamic memory management in Pascal. Pascal programming language provides several functions for memory allocation and management.\n\nWhile doing programming, if you are aware about the size of an array, then it is easy and you can define it as an array. For example to store a name of any person, it can go max 100 characters so you can define something as follows:\n\nBut now let us consider a situation where you have no idea about the length of the text you need to store, for example you want to store a detailed description about a topic. Here we need to define a pointer to string without defining how much memory is required.\n\nPascal provides a procedure new to create pointer variables.\n\nWhen the above code is compiled and executed, it produces following result:\n\nNow, if you need to define a pointer with specific number of bytes to be referred by it later, you should use the getmem function or the getmem procedure, which has the following syntax:\n\nIn the previous example, we declared a pointer to a string. A string has a maximum value of 255 bytes. If you really don't need that much space, or a larger space, in terms of bytes, getmem subprogram allows specifying that. Let us rewrite the previous example, using getmem:\n\nWhen the above code is compiled and executed, it produces following result:\n\nSo you have complete control and you can pass any size value while allocating memory unlike arrays where once you defined the size cannot be changed.\n\nWhen your program comes out, operating system automatically release all the memory allocated by your program but as a good practice when you are not in need of memory anymore then you should release that memory.\n\nPascal provides the procedure dispose to free a dynamically created variable using the procedure new. If you have allocated memory using the getmemsubprogram, then you need to use the subprogram freemem to free this memory. The freemem subprograms have the following syntax:\n\nAlternatively, you can increase or decrease the size of an allocated memory block by calling the function ReAllocMem. Let us check the above program once again and make use of ReAllocMem and freemem subprograms. Following is the syntax for ReAllocMem:\n\nFollowing is an example which makes use of ReAllocMem and freemem subprograms:\n\nWhen the above code is compiled and executed, it produces following result:\n\nPascal provides a hoard of memory management functions that is used in implementing various data structures and implementing low level programming in Pascal. Many of these functions are implementation dependent. Free Pascal provides the following functions and procedure for memory management:"
    },
    {
        "link": "https://wiki.freepascal.org/Memory_Management",
        "document": "Pascal, by default, provides three kinds of memory management mechanisms for different datatypes and in different contexts: Local Lifetime, Manual Memory Management and Reference Counting.\n\nIn the following these mechanisms will be explained in detail, as well as outlining some best practices for their use.\n\nLocal lifetime is the first form of memory management most programmers come into contact with. This is the default way on how variables and function parameters are handled. Here the compiler fully takes over the management of the lifetime of the variable. Take for example this simple function:\n\nThe compiler will create the memory for both the parameter i and the variable x when the function is called. Once the function ends, the memory will be freed. For functions this is ususally done through the local program stack. When calling the function, the compiler generates code that will push the memory for all local variables and parameters on the stack. This is called a stack frame. Once the function returns, the whole stack frame will be poped from the stack, and thereby freeing the allocated memory.\n\nGlobal variables are created on program startup and will be freed when the program is closed.\n\nHere GlobalX, as a global variable is not bound by the lifetime of the function PrintTenth and will be available as long as the program is running.\n\nLastly there are thread local variables. Those are global variables, whose lifetime is bound to a thread. The memory will be newly allocated for every thread started within the program, and will be freed when it's corresponding thread is finished or killed.\n\nSo when PrintTenth would be called from two different threads, they would use a different memory for their thread local ThreadedX, while when called twice from the same thread, it would be the same memory.\n\nLocal lifetime is a very easy and also very efficient way of memory management. This allows for usually quite care-free usage of that memory, as the compiler will take care of all of it.\n\nThat said, there is a big limitation here, any data can only live as long as it's context. This is not an issue for global variables, because by definition, they live as long as any code that could access them. But specifically when using local variables, it can happen that there may still be references to that variable after the function containing it has ended. This is called a dangling pointer.\n\nTake the following program:\n\nThe function Dangling returns a pointer to a local variable. The problem here is, that as soon as the function ends, x doesn't exist anymore, so the Pointer returned (and stored in p) will point to already freed memory. Those kinds of bugs can be hard to find, because of the nature of the stack, the memory is still around and may not have been reused at this point. In the example above, will still print 42, as nothing happend to override this newly freed memory yet. But if another function is called:\n\nNow the function has it's own stack frame, and it will be overlapping with the memory previously used by and pointed to by .\n\nThis makes finding such bugs quite hard, as the code might work as expected initially, but later, when another function was called, suddenly the results are completely different.\n\nGenerally usage of local lifetime managed variables is very easy and mostly safe. Due to the implementation through the stack it is also very efficient. It is therefore recommended to always use local variables whenever possible, and therefore preferable over the other methods outlined in this article.\n\nThat said, the programmer should take a few precautions to avoid having dangling pointers:\n• Never return the pointer to a local variable:\n\nOne big issue with global variables is the (lack of) scoping. A global variable is, as the name suggests, globally accessible. In order to avoid bugs through misuse, you may want to restrict access to a variable within a context, the so called scope, but without restring the lifetime to that scope. This can be achived with writable consts. Those are local variables with a global lifetime, meaning they will be created when the program first calls the encapsulating function, but they won't be freed until the program ends.\n\nThis function declares CurrentID as writable const, meaning it has a global lifetime, even though it is locally defined in NextID. Therefore every call to the function NextID uses the same memory for CurrentID, so NextID can \"remember\" the CurrentID from the last call. This allows this function to return a new ID, always being one more than the last time, in each consecutive call.\n\nUnlike local variables, because the lifetime of writable consts is the one of a global variable, pointers can be taken and passed without creating the dangling pointer problems outlined above.\n\nFor most types the local lifetime will just manage the memory. Often a programmer wants to associate code with the construction or destruction of the memory. For example, when a TFileStream is created, not only the memory is allocated, but also a file is opend. Similarly when a TFileStream is freed, not only the memory will be freed, but also that file will be closed.\n\nPreviously this was only possible for classes, which had constructors and destructors tied to their memory lifetime. But those classes can only be used with manual memory management, or reference counting (through COM interfaces, see below), and therefore was not available for local lifetime managed variables. This has changed in FPC 3.2.0 with the use of management operators. These allow to write code that will be automatically called by the compiler when the memory is allocated (through the operator), and when it is freed (through the operator). See the wiki article for further information.\n\nWhile local lifetime based memory management is extremely efficient and very safe, it requires the compiler to know exactly what data is required at which point in time. Also it explicetly binds the lifetime of the memory to the lifetime of the scope it is in.\n\nWhile this works great for local variables, this can be a problem for dynamic data, i.e. where the size is not known at compiletime (like for Lists or Arrays), in cases where the type of data may vary (Polymorphism), or where the lifetime is not directly tied to the scope where it is created.\n\nTake for example a linked list, whenever a new item is added to the list, its memory must be allocated and then used by the list. As you may want to use functions for adding, removing or searching the list, the lifetime of each list element cannot be bound to the function that created it, otherwise it would be gone as soon as the add function returns.\n\nFor this dynamic memory allocation, also often called heap allocation, is used. When you allocate memory on the heap, the memory usually (with the exception of the reference counted types outlined below), must be manually freed. Therefore both the creation of the memory as well as the freeing must be done manually.\n\nWhile the reasons for requiring dynamic allocation outlined above seem quite niche, there is a more practical reason why this is required. The major Object-Oriented Programming (OOP) implementation in Pascal, Classes are by design always dynamic and unlike other types like records or Integers, cannot be used as local lifetime variables. So a programmer will often find themselves in the situation where it is theoretically not be necessary to do dynamic (and manual) memory management, but due to the design of classes is practically forced to do so anyway.\n\nThere are 3 kinds of memory allocation:\n\nThis is the rawest form of memory allocation, and is done with the functions GetMem, ReallocMem and FreeMem.\n\nThese functions allocate untyped blocks of memory, where all the initialization and finalization must be performed by the user. This can be utilized for some optimizations, such as Pre Allocation of large chunks of memory, to avoid many smaller allocations and potetnial copying of data in the future.\n\nAs such they are rather rarely used, instead programmers will most often use one of the allocation methods outlined below.\n\nTyped memory allocation allows the programmer to dynamically allocate memory for a specific type. This is done with the New and Dispose functions.\n\nCompared to the untyped memory allocation described above, and have knowledge about the datatype for which memory is allocated and can therefore do the required initialization and size computations.\n\nTherefore the following code:\n\nIs equivalent to the following code using raw memory allocation:\n\nThis initialization and finalization is necessary because Composite Types such as Records or Objects contain member fields, whose lifetime is bound to the lifetime of the owning record. It will therefore call the and operators implicetly (see management operators).\n\nTherefore and are basically just a bit of syntactic sugar to clean up the code and not have all that additional size computation and initialization/finalization code that is required when using raw allocation.\n\nWhile and are the usualy way of implementing dynamic allocation for all base types, as well as Records and Objects, when Classes where introduced, they got their own mechanism for memory allocation, which ties directly with the constructor and destructor functions of the class.\n\nThe constructor, usually named (but can have other names, such as for Exceptions), operates in three steps:\n• Allocation of the memory for the class\n• Initialization of the allocated memory (equivalent to the call that is performed by as described above)\n\nThe complement to the Constructor is the Destructor, which should be a virtual/overriden function named Destroy. The destructor performs similar function to the constructor just in opposite order:\n• Cleanup of the allocated memory (equivalent to the finalize call that is performed by as outlined above)\n• Freeing of the memory used by the class\n\nIn practice the usage of a class looks like this:\n\nNote that usually the destructor is not called directly, but rather , which first checks for nil before calling Destroy. How sensical it is to call instead of directly is debatable, but it's a common convention that can be seen in most code and will also be used here.\n\nNo matter what form of allocation is used, every allocation requires a correspopnding free. So for each , there should be one call to to clean up the allocated memory afterwards. For each call to there should be a corresponding . And for every class created through it's constructor there should be a call to or the Destructor directly.\n\nBecause Programs can get very complex, it can sometimes be quite hard to make sure that all allocated memory is correctly freed. If there is memory which is allocated but never freed, this is called a \"Memory Leak\". Memory leaks can be sole occurances, in which case they are not very harmful. But often memory leaks occur within a piece of code that is called multiple times. Over these calls the memory leaks add up, and could result in major waste of memory, which can result in performance loss and potentially even to the computer running out of memory and having to forcefully kill processes or crash completely.\n\nEven worse than memory leaks are so called use-after-free bugs, which is when the memory was freed to early, while there is still code that has a reference to that memory and wants to access it later in the programs execution. The dangling pointers described above are a form of use-after-free.\n\nUse-After-Free bugs are considered worse than memory leaks, because while memory leaks can result in performance loss and in the worst case crashes, they do not result in any misbehavior. Also memory leaks are usually quite easy to find. Use-After-Free on the other hand can result in unpredicted behavior, and may even result in exploitable vulnerabilities through which an attacker could trick your program into executing malicious code, or circumventing other security mechanisms such as access control.\n\nThe reason for this is, that memory as a limited resource, does not go away after it has been freed, but will be reused eventually, resulting in access to other data than was originally intended. An example for this behavior is:\n\nBecause memory is re-used, in this example sl2 will get the same memory allocated as sl1 previously held. Therefore when accessing sl1 after it has been freed, it will unknowingly access sl2 and print .\n\nThis means in a sufficiently complex program, a use-after-free could potentially access any memory at any time, making the resulting errors hard to predict and hard to catch. Note that in the example above the use-after-free does not throw any exception/error, and produces a completely valid result. This is what makes finding these bugs so difficult, while giving them also the potential to completely alter the behavior of the program, by writing data to memory that the code shouldn't be able to touch.\n\nIn order to avoid both memory leaks, and use-after-free, it is helpful to structure your memory management around an \"ownership model\". The core idea is, similar to the compiler managed local memory described above, that the lifetime of any memory is tied to the one of the logical owner of that piece of memory. Everytime memory is allocated there must be an \"owner\", some piece of code that is responsible for that memory. This onwer then must make sure that to always free the memory, eventually (potentially when itself is finished it frees all the objects it owns). Also important is that whenever the owner \"dies\" no one else has access to that memory anymore.\n\nThis ownership model is already provided by many classes in the RTL, FCL and LCL, e.g. in the Component Model, or in the container libraries like Generics.Collections.\n\nNote, in the following we will always use classes as an example, but the same holds true for memory allocated with new/dispose or GetMem/FreeMem.\n\nThe easiest case is for temporary and local objects, those are essentially equivalent to the local variables whose lifetime is bound to their scope and that are managed by the compiler. E.g. a TStringList to read a config file:\n\nIn this case the owner of that SL is the function ReadConfigFile. It is created by that function, and in the end freed by that function. The Try-Finally ensures that this will always happen, no matter if it has an early break, exception or any other form of jump.\n\nTo avoid use-after-free, sl cannot leave this function. After the finally block sl should not be used anymore. This also includes passing sl to some other object, this is fine as long as this other object can only use SL while the function is still active:\n\nHere this function owns two objects, the enc and ss. Again both are ensured to be freed through try-finally. But enc uses ss, so basically enc is \"borrowing\" the ss, which is owned by the function. It is important to ensure that enc is not using ss after it is freed. The only way to ensure this is by having enc be freed before ss was.\n\nSo when an another piece of code \"borrows\" memory owned by a different piece of code, the borrower must \"give up\" the borrowed memory before it can be freed. When writing object oriented code, most of the time this means either freeing the object that borrows the memory before freeing the borrowed memory. In other cases this may mean to revoke access to said object, or to stretch the borrowing metapher further, for the borrower to return the borrowed memory:\n\nHere the global variable , which is used by anohter function, is the borrower. So before the FileStream can be freed by it's owner (the function), the owner first must make sure that the borrowing is revoked, and does this by resetting the global variable to .\n\nThe examples above describe the easy case, where the creator of the memory is also the owner. In some scenarios this may not be the case. For example, when adding data to the list, the function that creates the data, may be just called to create that piece of data, but the real owner is the list where that data will be stored in even after the creating function is finished.\n\nThe easiest example for this is the use of , because this class already provides functionality for ownership handling:\n\nBy setting the AOwnsObjects parameter of the Constructor of TObjectList to true, we tell the TObjectList that it is the owner of all objects we pass to it. This means, when adding a new object to the list, the list will automatically ensure that the object is going to be freed when the item is deleted, or the list is freed. Because ownership is handed over to the list, the function that creates the object does not need to care about freeing it's memory afterwards.\n\ncan not just claim ownership through the function, but also provides the method to give up ownership of an element:\n\nThe ownership model is an easy way to structure the code in a way to make it clear when memory can be used, and when it can be freed. By always making sure that every manually allocated memory has exactly one owner, this owner can make sure that the data will be freed. It also can help preventing use-after-free bugs, as every piece of memory can live at most as long as it's owner, so by tracking the lifetime of the owner, it can be ensured that the memory is still valid.\n\nThe ownership model is already implemented in many libraries that are provided by the RTL, FCL or RTL, it forms the basis for the whole Component Model, on which the LCL is based:\n\nBy setting the owner of the button to Self, this Button is owned by the Form, and when the Form is destroyed, it will also destroy the button.\n\nThe ownership model can be summarized by a few rules of thumb:\n• Always ensure there is one and only one owner\n• When used only locally use try-finally to enforce ownership\n• Borrows are not allower to live longer than the owner\n• When borrowing a local object, the borrow must be finished within the same try-finally block\n• When borrowing between objects, the borrowing object cannot be destroyed before the borrow ended\n• When transferring ownership ensure that the new owner satisfies all the previous rules\n\nThe only way to truely ensure that there are no use-after-free bugs or memory leaks is through testing. There are multiple levels of testing, but for finding these sorts of bugs, Unit Tests are usually the best approach. These are very small programs, that only test a very small subset of the functionality, e.g. a single class or function. FPC provides the fpcunit framework, which allows to easiely create and manage these test cases.\n\nIn order to detect such memory errors, fpc provides the heaptrc unit. This unit checks if for every allocation there is a free, and then reports any memory leaks, including where the memory was allocated. Despite this, heaptrc also taints memory after it is freed, this helps with finding use-after-free bugs.\n\nThrough the use of the it also prevents memory being reused. While this would in a real application result in massive memory consumption, for small test cases, such as unit tests, this can be used to ensure that use-after-free will always result in access to this taineted memory.\n\nTaking the example from above, simply adding heaptrc and keepreleased:\n\nNow because sl1 has been tainted and is not re-used by sl2, the call to sl1.Text will throw an error, making it easy to find and fix.\n\nAnother tool to detect memory errors is Valgrind. Unlike heaptrc, which simply adds some additional checks to the GetMem and FreeMem functions, valgrind is a complete emulator. When executing your code in Valgrind, it will check at every single instruction if some memory errors are present.\n\nThis makes valgrind by far the most powerful tool for finding memory errors, but this comes at a price. Valgrinds emulation is around a factor 1000 slower than native execution, making it potentially infeasable to test larger programs. So also here this must be used in combination with very small and very specialized unit tests.\n\nThere is this quote, which I could not figure out whom to attribute:\n\nAs outlined above, use-after-free errors are much worse than memory leaks. Infact, when your program is not going to use that much memory in the first place, memory leaks will have nearly no impact on the user at all.\n\nOne strategy can therefore be to simply ignore the memory leaks and never free the memory. This strategy is often employed by extremely security critical software, which have quite a limited memory consumption. For example when creating a CGI module for a webservice, which will be started just to serve a single request, as soon as the request is over, the process is killed and all the memory will be released by the OS anyhow. Therefore memory leaks will not matter. But if it is an external facing webservice, security vulnerabilities that may be introduced by use-after-free could be devastating. Therefore not freeing the memory could be a completely valid strategy in order to avoid any use-after-free errors.\n\nThe problem with this is that classes who need their destructor called (e.g. Streams to flush their buffered content), cannot call the destructor without calling Free. So in order to not use Free, either no classes need to be used, or a memory manager must be installed that does not actually free the memory. While HeapTrc.KeepReleased does exactly that, HeapTrc other functionality may impact the performance to much to make it a viable alternative.\n\nEven when following the ownership model strictly, and doing a lot of tests, memory management errors are unavoidable. Manual memory management is hard, and errors can be very hard to find due to their subtlety.\n\nWhen Mozilla rewrote their CSS engine in Rust, they analyzed the security related bugs that where previously found in that code and published the results in their blog. Of all the bugs they've got reported, nearly half where memory management bugs, i.e. where use-after-free or memory leaks.\n\nBecause memory management is so hard, the most simple solution is often to simply avoid manual memory management whenever possible. Because Classes are designed to require manual memory management most of the time, it may sometimes not be avoidable, but there are a few ways reliance on manual memory management can be reduced:\n• Use (advanced) Records and Objects instead of classes\n• Use Dynamic arrays instead of Class based Datastructures\n• Use COM interfaces to your classes\n\nWhile the ownership principle can help to easiely identify when an and where any memory needs to be freed, it is not applicable in all cases. Sometimes the architecture requires a piece of memory to be shared by multiple peers, where there is no clear owner, or multiple owners.\n\nConsidering an expression tree for the expression . This could be represented as either a strict tree:\n\nThis can be simply put into code, whith each node being it's own object and having exactly one parent. When the parent node is freed, it would free all of it's children.\n\nBut, as an optimization, the representation in code is changed such that equal subtrees are replaced with just a reference to the same object:\n\nBut now there is a problem, because now the \"+\" node has two parents, and thereby no clear owner.\n\nThere are multiple solutions to this. For example, all those nodes could be put into one list, which will be the owner of all the nodes, and all the nodes just borrow each other from that list. But a more flexible solution is to simply allow multiple owners.\n\nThis can be achieved with so called reference counting. For this each allocated object will have a counter embedded. When a new owner gets access to the object, it notifies the counter and the count will be incremented. Then when an owner does not need the object anymore, it just tells the counter that it's reference will not be used anymore, and the counter is decreased. When the counter hits 0, the memory will be freed.\n\nIn the example expression tree above, the reference count of '*' would be 1, '+' is owned two times by '*' so its reference count is 2, '5' and '3' are owned exactly once, so their reference count is 1. When '*' reference is lost reducing the counter to 0, it will reduce the reference counter of it's first child, '+' to 1, and then when freeing the second child, it is reduced again to 0. '+' then reduces both it's childrens reference counter from 1 to 0, freeing them, before freeing itself, and finally '*' get's freed.\n\nThis results in no memory leaks, and when used consequently, no use-after-free, because it can only be used when there are references, but then the counter would not be 0.\n\nThe major problem is, implementing this manually is extremely error prone, as it is easy to simply forget to decrease or increase the counter. But the FPC already implements reference counting, at least for some types, on a language level. Dynamic arrays, Strings and COM Interfaces are already reference counted. This means, whenever such an object is created, it's reference count is set to 1. When it is assigned to a new variable, it's reference count will increment, if a variable pointing to that object is finalized, the reference counter will be decremented:\n\nThis is why, even though Arrays are dynamically allocated, there is no need to manually free them.\n\nWhile the usage of arrays and strings is straight forward, Interfaces are often underutilized for this.\n\nTo use Interfaces to solve the original problem of representing the expression tree of (5+3)*(5+3), we can simply implement the expressions as classes implementing a common interface, and use this:\n\nThis will be able to evalute the expression tree to 64, without any memory leaks, or risk of running into use-after-free.\n\nAnother interesting use of COM interfaces to facilitate reference counting is the GMP unit provided by the FPC. Because one issue with manual memory management is that the usage of any temporary object would create a memory leak.\n\nTake the following expression: . First (a + b) is computed, which gives a temporary object that then is used to be multiplied with c. If the object requires dynamic allocation, because of it's temporary nature, (a + b) could not be freed, resulting in a memory leak, therefore operator overloading is not possible with classes. So in classical, manually managed GMP this computation would be written like this:\n\nThis is alot of boiler plate code distracting from the actually quite simple computation. Here is how it looks like using the reference counted interfaces\n\nSo while normal classes cannot use operators, because the creation of temporary objects would result in memory leaks, through the use of COM interfaces this is possible, which can result in much cleaner code\n\nOne issue with reference counting are circular references. Assuming two objects, A and B, if A has a reference to B and B holds a reference to A, then their respective reference counters can not drop below 1, because they always reference each other. Especially when representing cyclic graphs, this can acutally lead to memory leaks, if not resolved properly.\n\nTherefore, while the usage of interfaces can help massively with writing clean and memory safe code, it is not a \"silver bullet\". The programmer must still always be aware if circular references can occur, and if so, they must be resolved manually."
    },
    {
        "link": "http://pascal.hansotten.com/uploads/standardpascal/Programming%20standard%20Pascal.pdf",
        "document": ""
    },
    {
        "link": "https://geeksforgeeks.org/implement-a-stack-using-singly-linked-list",
        "document": "To implement a stack using a singly linked list, we need to ensure that all operations follow the LIFO (Last In, First Out) principle. This means that the most recently added element is always the first one to be removed. In this approach, we use a singly linked list, where each node contains data and a reference (or link) to the next node.\n\nTo manage the stack, we maintain a pointer that always points to the most recent (topmost) node in the stack. The key stack operations—push, pop, and peek can be performed using this pointer.\n\nIn the stack Implementation, a stack contains a top pointer. which is the “head” of the stack where pushing and popping items happens at the head of the list. The first node has a null in the link field and second node-link has the first node address in the link field and so on and the last node address is in the “top” pointer.\n\nThe main advantage of using a linked list over arrays is that it is possible to implement a stack that can shrink or grow as much as needed. Using an array will put a restriction on the maximum capacity of the array which can lead to stack overflow. Here each new node will be dynamically allocated. so overflow is not possible.\n• push(): Insert a new element into the stack (i.e just insert a new element at the beginning of the linked list.)\n• pop(): Return the top element of the Stack (i.e simply delete the first element from the linked list.)\n\n// C program to implement a stack using singly linked list // Function to check if the stack is empty // If head is NULL, the stack is empty // Function to push an element onto the stack // Create a new node with given data // Check if memory allocation for the new node failed // Link the new node to the current top node // Update the top to the new node // Function to remove the top element from the stack // Update the top to the next node // Deallocate the memory of the old top node // Function to return the top element of the stack // If stack is not empty, return the top element // removing two elemements from the top // Function to check if the stack is empty // If head is null, the stack is empty // Function to push an element onto the stack // Create a new node with given data // Check if memory allocation for the new node // Link the new node to the current top node // Update the top to the new node // Function to remove the top element from the stack // Update the top to the next node // Deallocate the memory of the old top node // Function to return the top element of the stack // If stack is not empty, return the top element // removing two elemements from the top # Function to check if the stack is empty # If head is None, the stack is empty # Function to push an element onto the stack # Create a new node with given data # Check if memory allocation for the new node failed # Link the new node to the current top node # Update the top to the new node # Function to remove the top element from the stack # Update the top to the next node # Deallocate the memory of the old top node # Function to return the top element of the stack # If stack is not empty, return the top element # removing two elemements from the top // C# program to implement a stack using singly linked list // Function to check if the stack is empty // If head is null, the stack is empty // Function to push an element onto the stack // Create a new node with given data // Check if memory allocation for the new node // Link the new node to the current top node // Update the top to the new node // Function to remove the top element from the stack // Update the top to the next node /* No need to manually free the memory of the // Function to return the top element of the stack // If stack is not empty, return the top element // removing two elemements from the top // Function to check if the stack is empty // If head is null, the stack is empty // Function to push an element onto the stack // Create a new node with given data // Check if memory allocation for the new node // Link the new node to the current top node // Update the top to the new node // Function to remove the top element from the stack // Update the top to the next node // Deallocate the memory of the old top node // Function to return the top element of the stack // If stack is not empty, return the top element // removing two elemements from the top\n\nTime Complexity: O(1), for all push(), pop(), and peek(), as we are not performing any kind of traversal over the list. \n\nAuxiliary Space: O(n), where n is the size of the stack\n• Dynamic memory allocation : The size of the stack can be increased or decreased dynamically by adding or removing nodes from the linked list, without the need to allocate a fixed amount of memory for the stack upfront.\n• Efficient memory usage: Since nodes in a singly linked list only have a next pointer and not a prev pointer, they use less memory than nodes in a doubly linked list.\n• Easy implementation : Implementing a stack using a singly linked list is straightforward and can be done using just a few lines of code.\n• Versatile : Singly linked lists can be used to implement other data structures such as queues, linked lists, and trees.\n\nStacks are used in various real-world scenarios where a last-in, first-out (LIFO) data structure is required. Here are some examples of real-time applications of stacks:\n• Function Call Stack: When a function is called, its return address and parameters are pushed onto the stack. The stack ensures functions execute and return in reverse order..\n• Undo/Redo Operations: In apps like text or image editors, actions are pushed onto a stack. Undo removes the last action, while redo restores it.\n• Browser History: Browsers use stacks to track visited pages. Visiting a page pushes its URL onto the stack, and the “Back” button pops the last URL to go to the previous page.\n• Expression Evaluation: In compilers, expressions are converted to postfix notation and evaluated using a stack.\n• Call Stack in Recursion: Recursive function calls are pushed onto the stack. Once recursion ends, the stack is popped to return to the previous function call."
    },
    {
        "link": "https://simplilearn.com/tutorials/data-structure-tutorial/stack-implementation-using-linked-list",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/20087309/inserting-element-in-a-linked-list-with-pascal",
        "document": "Here's a very simple program which will do what you want. Maintaining a 'tail' pointer means that you don't have to traverse the list every time that you want to add a value. If this were your code, then you would be missing the 'tail:= tmp' line in Insert: without this, Display prints the first and last entries, but not those in the middle.\n\nJudging by your comments, some further explanation is required. [Professorial mode on] When I started programming some thirty years ago (OMSI Pascal on a PDP 11/70), linked lists and pointers appeared in every self-respecting program, but since the rise of Delphi in 1990, such complexities have been hidden and most programmers now never see a naked pointer.\n\nLinked lists come in different formats: the simple and the complex. The simple types differ at the points of insertion and deletion: a stack inserts and deletes at the same end, a queue inserts at one end and deletes at the other, a list allows insertion and deletion at any place. More complex types are trees and graphs. Your question is asking about the implementation of a queue - insertion is always at the rear, deletion is at the front.\n\nIn order to implement this properly, we need two variables: 'head' points to the head of the queue and 'tail' points to the end of the queue. These variables are normal global variables; memory is allocated for them in the data segment of the program. A pointer is a simple variable whose value is the memory address of another variable. Initially, 'head' does not point to anything so its value is nil (think of this as 0).\n\nNormally in textbooks, the construction of a queue is accompanied by little boxes showing how memory is allocated, but I don't know how to do that here and so the explanation will be a little wordy.\n\nWhen the first insertion occurs, the memory manager in the run time system allocates 12 bytes from the heap and sets the value of the local variable 'tmp' to be the address of the first of those 12 bytes (this is 'new (tmp)'). Of those 12 bytes, the 'value' part is set to 5 and the 'next' part is set to nil. Then the program checks what the value of 'head' is: if it is nil, then the value (ie address of the memory block allocated above) is copied from 'tmp' to 'head'. If 'head' already points to something, then the value of 'tmp' is copied to 'tail^.next' (which previously would have been nil). Then the value of 'tmp' is copied to the tail variable. Thus 'head' always points to the beginning of the queue and does not change whereas 'tail' points to the end of the queue and changes every time a new node is inserted.\n\nIf your program has more than one queue, then you will need two variables for each queue, and 'Insert' will have to be changed in order to accept two parameters (which will be the head and tail of the given queue).\n\nThere is no need to write 'new (head)' and 'new (tail)' - doing so will cause the original pointers to the beginning and end of the queue to be lost.\n\n[Professorial mode off] I hope that this explanation helps."
    },
    {
        "link": "https://cslab.pepperdine.edu/warford/ComputingFundamentals/PboxCh21.pdf",
        "document": ""
    },
    {
        "link": "https://fiveable.me/key-terms/data-structures/linked-list-based-stack-implementation",
        "document": ""
    }
]