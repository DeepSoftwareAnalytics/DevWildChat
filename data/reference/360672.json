[
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/json/json-data-sql-server?view=sql-server-ver16",
        "document": "Applies to: SQL Server 2016 (13.x) and later versions Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics SQL database in Microsoft Fabric\n\nJSON is a popular textual data format that's used for exchanging data in modern web and mobile applications. JSON is also used for storing unstructured data in log files or NoSQL databases such as Microsoft Azure Cosmos DB. Many REST web services return results that are formatted as JSON text or accept data that's formatted as JSON. For example, most Azure services, such as Azure Search, Azure Storage, and Azure Cosmos DB, have REST endpoints that return or consume JSON. JSON is also the main format for exchanging data between webpages and web servers by using AJAX calls.\n\nJSON functions, first introduced in SQL Server 2016 (13.x), enable you to combine NoSQL and relational concepts in the same database. You can combine classic relational columns with columns that contain documents formatted as JSON text in the same table, parse and import JSON documents in relational structures, or format relational data to JSON text.\n\nHere's an example of JSON text:\n\nBy using SQL Server built-in functions and operators, you can do the following things with JSON text:\n• Run any Transact-SQL query on the converted JSON objects.\n• Format the results of Transact-SQL queries in JSON format.\n\nThe next sections discuss the key capabilities that SQL Server provides with its built-in JSON support.\n\nThe new json data type that stores JSON documents in a native binary format that provides the following benefits over storing JSON data in varchar/nvarchar:\n• More efficient reads, as the document is already parsed\n• More efficient writes, as the query can update individual values without accessing the entire document\n• No change in compatibility with existing code\n\nUsing the JSON same functions described in this article remain the most efficient way to query the json data type. For more information on the native json data type, see JSON data type.\n\nExtract values from JSON text and use them in queries\n\nIf you have JSON text that's stored in database tables, you can read or modify values in the JSON text by using the following built-in functions:\n• JSON_QUERY (Transact-SQL) extracts an object or an array from a JSON string.\n• JSON_MODIFY (Transact-SQL) changes a value in a JSON string.\n\nIn the following example, the query uses both relational and JSON data (stored in a column named ) from a table called :\n\nApplications and tools see no difference between the values taken from scalar table columns and the values taken from JSON columns. You can use values from JSON text in any part of a Transact-SQL query (including WHERE, ORDER BY, or GROUP BY clauses, window aggregates, and so on). JSON functions use JavaScript-like syntax for referencing values inside JSON text.\n\nFor more information, see Validate, Query, and Change JSON Data with Built-in Functions (SQL Server), JSON_VALUE (Transact-SQL), and JSON_QUERY (Transact-SQL).\n\nIf you must modify parts of JSON text, you can use the JSON_MODIFY (Transact-SQL) function to update the value of a property in a JSON string and return the updated JSON string. The following example updates the value of a property in a variable that contains JSON:\n\nYou don't need a custom query language to query JSON in SQL Server. To query JSON data, you can use standard T-SQL. If you must create a query or report on JSON data, you can easily convert JSON data to rows and columns by calling the rowset function. For more information, see Parse and Transform JSON Data with OPENJSON.\n\nThe following example calls and transforms the array of objects that is stored in the variable to a rowset that can be queried with a standard Transact-SQL statement:\n\ntransforms the array of JSON objects into a table in which each object is represented as one row, and key/value pairs are returned as cells. The output observes the following rules:\n• converts JSON values to the types that are specified in the clause.\n• can handle both flat key/value pairs and nested, hierarchically organized objects.\n• You don't have to return all the fields that are contained in the JSON text.\n• You can optionally specify a path after the type specification to reference a nested property or to reference a property by a different name.\n• The optional prefix in the path specifies that values for the specified properties must exist in the JSON text.\n\nFor more information, see Parse and Transform JSON Data with OPENJSON and OPENJSON (Transact-SQL).\n\nJSON documents might have sub-elements and hierarchical data that can't be directly mapped into the standard relational columns. In this case, you can flatten JSON hierarchy by joining parent entity with sub-arrays.\n\nIn the following example, the second object in the array has sub-array representing person skills. Every sub-object can be parsed using additional function call:\n\nThe array is returned in the first as original JSON text fragment and passed to another function using operator. The second function parses JSON array and return string values as single column rowset that will be joined with the result of the first .\n\njoins first-level entity with sub-array and return flatten resultset. Due to JOIN, the second row is repeated for every skill.\n\nFormat SQL Server data or the results of SQL queries as JSON by adding the clause to a statement. Use to delegate the formatting of JSON output from your client applications to SQL Server. For more information, see Format query results as JSON with FOR JSON.\n\nThe following example uses PATH mode with the clause:\n\nThe clause formats SQL results as JSON text that can be provided to any app that understands JSON. The PATH option uses dot-separated aliases in the SELECT clause to nest objects in the query results.\n\nFor more information, see Format query results as JSON with FOR JSON and FOR Clause (Transact-SQL).\n\nJSON aggregate functions enable construction of JSON objects or arrays based on an aggregate from SQL data.\n• JSON_OBJECTAGG constructs a JSON object from an aggregation of SQL data or columns.\n• JSON_ARRAYAGG constructs a JSON array from an aggregation of SQL data or columns.\n\nUse cases for JSON data in SQL Server\n\nJSON support in SQL Server and Azure SQL Database lets you combine relational and NoSQL concepts. You can easily transform relational to semi-structured data and vice-versa. JSON isn't a replacement for existing relational models, however. Here are some specific use cases that benefit from the JSON support in SQL Server and in SQL Database.\n\nConsider denormalizing your data model with JSON fields in place of multiple child tables.\n\nStore info about products with a wide range of variable attributes in a denormalized model for flexibility.\n\nLoad, query, and analyze log data stored as JSON files with all the power of the Transact-SQL language.\n\nWhen you need real-time analysis of IoT data, load the incoming data directly into the database instead of staging it in a storage location.\n\nTransform relational data from your database easily into the JSON format used by the REST APIs that support your web site.\n\nSQL Server provides a hybrid model for storing and processing both relational and JSON data by using standard Transact-SQL language. You can organize collections of your JSON documents in tables, establish relationships between them, combine strongly typed scalar columns stored in tables with flexible key/value pairs stored in JSON columns, and query both scalar and JSON values in one or more tables by using full Transact-SQL.\n\nJSON text is stored in or columns and is indexed as plain text. Any SQL Server feature or component that supports text supports JSON, so there are almost no constraints on interaction between JSON and other SQL Server features. You can store JSON in In-memory or Temporal tables, apply Row-Level Security predicates on JSON text, and so on.\n\nHere are some use cases that show how you can use the built-in JSON support in SQL Server.\n\nJSON is a textual format so the JSON documents can be stored in columns in a SQL Database. Since type is supported in all SQL Server subsystems you can put JSON documents in tables with clustered columnstore indexes, memory optimized tables, or external files that can be read using OPENROWSET or PolyBase.\n\nTo learn more about your options for storing, indexing, and optimizing JSON data in SQL Server, see the following articles:\n\nYou can format information that's stored in files as standard JSON or line-delimited JSON. SQL Server can import the contents of JSON files, parse it by using the or functions, and load it into tables.\n• None If your JSON documents are stored in local files, on shared network drives, or in Azure Files locations that can be accessed by SQL Server, you can use bulk import to load your JSON data into SQL Server.\n• None If your line-delimited JSON files are stored in Azure Blob storage or the Hadoop file system, you can use PolyBase to load JSON text, parse it in Transact-SQL code, and load it into tables.\n\nIf you must load JSON data from an external service into SQL Server, you can use to import the data into SQL Server instead of parsing the data in the application layer.\n\nIn supported platforms, use the native json data type instead of nvarchar(max) for improved performance and more efficient storage.\n\nYou can provide the content of the JSON variable by an external REST service, send it as a parameter from a client-side JavaScript framework, or load it from external files. You can easily insert, update, or merge results from JSON text into a SQL Server table.\n\nIf you must filter or aggregate JSON data for reporting purposes, you can use to transform JSON to relational format. You can then use standard Transact-SQL and built-in functions to prepare the reports.\n\nYou can use both standard table columns and values from JSON text in the same query. You can add indexes on the expression to improve the performance of the query. For more information, see Index JSON data.\n\nIf you have a web service that takes data from the database layer and returns it in JSON format, or if you have JavaScript frameworks or libraries that accept data formatted as JSON, you can format JSON output directly in a SQL query. Instead of writing code or including a library to convert tabular query results and then serialize objects to JSON format, you can use to delegate the JSON formatting to SQL Server.\n\nFor example, you might want to generate JSON output that's compliant with the OData specification. The web service expects a request and response in the following format:\n\nThis OData URL represents a request for the ProductID and ProductName columns for the product with 1. You can use to format the output as expected in SQL Server.\n\nThe output of this query is JSON text that's fully compliant with the OData spec. Formatting and escaping are handled by SQL Server. SQL Server can also format query results in any format, such as OData JSON or GeoJSON.\n\nTo get the AdventureWorks sample database, download at least the database file and the samples and scripts file from GitHub.\n\nAfter you restore the sample database to an instance of SQL Server, extract the samples file, and then open the file from the JSON folder. Run the scripts in this file to reformat some existing data as JSON data, test sample queries and reports over the JSON data, index the JSON data, and import and export JSON.\n\nHere's what you can do with the scripts that are included in the file:\n• None Denormalize the existing schema to create columns of JSON data.\n• None Store information from , , , , and other tables that contain information related to sales order into JSON columns in the table.\n• None Store information from and tables in the table as arrays of JSON objects.\n• None Import and export JSON. Create and run procedures that export the content of the and the tables as JSON results, and import and update the and the tables by using JSON input.\n• None Run query examples. Run some queries that call the stored procedures and views that you created in steps 2 and 4.\n• None Clean up scripts. Don't run this part if you want to keep the stored procedures and views that you created in steps 2 and 4."
    },
    {
        "link": "https://stackoverflow.com/questions/4720494/javascript-libraries-that-allow-for-sql-like-queries-on-json-data",
        "document": "Say our JSON data comes from a single MySQL table:\n\nAnd say the pseudo-code is:\n\n\"Get all the person objects of all of > 60000`\".\n\nAre there any javascript libraries that would allow one to code such queries on this JSON data using a SQL or SQL-like syntax.\n\nIn case you are curious, some context:\n\nI am making the front-end of a data analysis web service for my organization without knowing what the future backend will be. In the future they will migrate their data from MS Access tables to some-sort of MySQL-type database. Until then I am using static JSON files to start development and was thinking it may be helpful for them in the future to have my javascript queries appear as MySQL queries. (The current MS Access database is unreachable from the web.)"
    },
    {
        "link": "https://geeksforgeeks.org/working-with-json-in-sql",
        "document": "JSON stands for Javascript Object Notation. It is mainly used in storing and transporting data. Mostly all NoSQL databases like MongoDB, CouchDB, etc., use JSON format data. Whenever your data from one server has to be transferred to a web page, JSON format is the preferred format for front-end applications like Android, iOS, React, Angular, etc.\n\nIn this article, we will learn how to store, retrieve, and manipulate JSON data in SQL Server using various SQL functions. We will learn how JSON fits into SQL, demonstrate how to store JSON data in SQL tables and cover the most common JSON functions like ISJSON(), JSON_VALUE(), JSON_MODIFY(), and more.\n\nWhat is JSON in SQL Server?\n\nJSON is a lightweight data-interchange format that is easy for humans to read and write. SQL Server introduced native support for JSON handling starting from SQL Server 2016. This allows you to store JSON data in NVARCHAR columns and use SQL functions to parse, query, and modify JSON data.\n\nIn SQL Server, you can store JSON data as a string in an NVARCHAR column. SQL Server treats JSON data as a string, allowing you to parse it when necessary.\n\nNow let us create a table named “Authors” and let us insert some data into it as shown below:\n\nJSON is a beautiful option for bridging NoSQL and relational worlds. Hence, in case if you have the data got exported from MongoDB and need to import them in SQL Server, we can follow below approaches\n\nJSON documents can be stored as-is in NVARCHAR columns either in LOB storage format or Relational storage format. Raw JSON documents have to be parsed, and they may contain Non-English text. By using nvarchar(max) data type, we can store JSON documents with a max capacity of 2 GB in size. If the JSON data is not huge, we can go for NVARCHAR(4000), or else we can go for NVARCHAR(max) for performance reasons.\n\nThe main reason for keeping the JSON document in NVARCHAR format is for Cross feature compatibility. NVARCHAR works with X feature i.e. all the SQL server components such as Hekaton(OLTP), temporal, or column store tables, etc. As JSON behavior is also in that way, it is represented as NVARCHAR datatype.\n\nBefore SQL Server 2016, JSON was stored in the database as text. Hence, there was a need to change the database schema and migration occurred as JSON type in NVarchar format\n\nJSON is just treated as an Object in JavaScript and hence called as Javascript Object Notation. There is no specific standardized JSON object type on client-side available similar to XmlDom object.\n\nLet us see the important functionalities available in SQL Server which can be used with JSON data.\n\nThis function is used to check whether the given input json string is in JSON format or not. If it is in JSON format, it returns 1 as output or else 0. i.e. it returns either 1 or 0 in INT format.\n\nThe output will be a scalar value from the given JSON string. Parsing of JSON string is done and there are some specific formats are there for providing the path. For example\n\nUsed to extract an array of data or objects from the JSON string.\n\nThere is an option called “JSON_MODIFY” in (Transact-SQL) function is available to update the value of a property in a JSON string and return the updated JSON string. Whenever there is a requirement to change JSON text, we can do that\n\nThis function is used for Exporting SQL Server data as JSON format. This is a useful function to export SQL data into JSON format. There are two options available with FOR JSON\n• AUTO: As it is nested JSON sub-array is created based on the table hierarchy.\n• PATH: By using this we can define the structure of JSON in a customized way.\n\nThis function is used for importing JSON as String data. We can import JSON as a text file by using OPENROWSET function and in that the BULK option should be enabled. It returns a single string field with BulkColumn as its column name.\n\nNote: Even large data also can be placed. As a sample, we showed only a single row.\n\nSINGLE_BLOB, which reads a file as varbinary(max). SINGLE_NCLOB, which reads a file as nvarchar(max) — If the contents are in Non-English text like Japanese or Chinese etc., data, we need to go in this pattern. We used SINGLE_CLOB, which reads a file as varchar(max).\n\nIt will generate a relational table with its contents from the JSON string. Each row is created which can be got by iterating through JSON object elements, OPENJSON can be used to parse the JSON as a text. Let us have a JSON placed in an external file and its contents are\n\nWe can see that for “Strings” key like “authorname” and “skills” got type as 1 and “int” key like “id” and “age” got type as 2. Similarly, for boolean, the type is 3. For arrays, it is 4 and for object, it is 5. OPENJSON parses only the root level of the JSON.\n\nIn case if the JSON is nested, we need to use Path variables\n\nWe can even make the skillsets as columns of data as\n\nSaving the rowset into Table: Here the number of columns should match the count that is present inside with:\n\nThere is an option called “JSON_MODIFY” in (Transact-SQL) function is available to update the value of a property in a JSON string and return the updated JSON string. Whenever there is a requirement to change JSON text, we can do that\n\nHandling JSON in SQL Server enables seamless interaction with modern web applications and NoSQL databases. The ability to store, query, and manipulate JSON data directly in SQL Server enhances the flexibility and efficiency of your data management system. SQL Server’s native JSON functions—such as ISJSON(), JSON_VALUE(), JSON_QUERY(), and JSON_MODIFY()—make it easier to integrate and work with JSON data without needing a separate NoSQL system."
    },
    {
        "link": "https://stackoverflow.com/questions/777455/is-there-a-query-language-for-json",
        "document": "Closed. This question is seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. It does not meet This question is seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. It does not meet Stack Overflow guidelines . It is not currently accepting answers. We don’t allow questions seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. You can edit the question so it can be answered with facts and citations. The community is reviewing whether to reopen this question as of 20 days ago. Is there a (roughly) SQL or XQuery-like language for querying JSON? I'm thinking of very small datasets that map nicely to JSON where it would be nice to easily answer queries such as \"what are all the values of X where Y > 3\" or to do the usual SUM / COUNT type operations. As completely made-up example, something like this: [{\"x\": 2, \"y\": 0}}, {\"x\": 3, \"y\": 1}, {\"x\": 4, \"y\": 1}] SUM(X) WHERE Y > 0 (would equate to 7) LIST(X) WHERE Y > 0 (would equate to [3,4]) I'm thinking this would work both client-side and server-side with results being converted to the appropriate language-specific data structure (or perhaps kept as JSON) A quick Googling suggests that people have thought about it and implemented a few things (JAQL), but it doesn't seem like a standard usage or set of libraries has emerged yet. While each function is fairly trivial to implement on its own, if someone has already done it right I don't want to re-invent the wheel. Edit: This may indeed be a bad idea or JSON may be too generic a format for what I'm thinking.. The reason for wanting a query language instead of just doing the summing/etc functions directly as needed is that I hope to build the queries dynamically based on user-input. Kinda like the argument that \"we don't need SQL, we can just write the functions we need\". Eventually that either gets out of hand or you end up writing your own version of SQL as you push it further and further. (Okay, I know that is a bit of a silly argument, but you get the idea..)"
    },
    {
        "link": "https://olibr.com/blog/json-vs-sql-whats-the-difference",
        "document": "JSON uses JSONPath and JMESPath for query languages. JSONPath is a query language that can help you parse data and is similar to query languages like SQL.\n\nLet’s say we have a table of data. We can use a query to extract fields like the color and price of a bus using this query .bus. The dot notation in the query helps you select a field. And if you want to select a specific field, we can use .bus.color.\n\nIn the above code example, the bus is encapsulated within a dictionary named automobile. Therefore, the automobile becomes the parent dictionary, the bus is a child dictionary, and then color and price are properties of the current path. To denote a root element, we use $; this way, we can form the JSONPath query in the right way.\n\nLikewise, we use $[0] to get the first element in the list. And a question mark (?) to specify a criteria. And last, to replace any item, we need to use the @ symbol.\n\nJAMESPath: It is an intuitive way of writing a query. With a few lines of code, you can extract the elements from a JSON document. Let’s look at some expressions used to retrieve and filter and retrieve multiple values and make a new JSON.\n• None By using the . operator field.sub_field we use to specify a key.\n• None This [*] is used to extract all elements in an array \n\n [field[index], field[another_index]] to extract specific indices of an array\n• None Index, it selects the value at the specified index in a JSON array.\n\nAlthough JSON is primarily used to interchange and transmit data, it doesn’t have in-built query capabilities like SQL. This is where JSONPath and JAMESPath enable you to retrieve data from the RESTful API and extract specific data from a JSON document. By using this query language, it can improve functionality as well as promote flexibility."
    },
    {
        "link": "https://discuss.jsonapi.org/t/document-best-practices-and-tools/1985",
        "document": "It’s all about the API clients. If your clients are expected to know about JSON:API, then you can just document the resources and the standard JSON:API operations on those resources (as well as all relevant semantics).\n\nHere is an example of recent API documentation I have created for our company (part of a larger ecosystem). Make sure to also take into consideration the common specs it is based on (linked to at the top). For a free-standing API spec, I would inline those common specs.\n\nHere is an example for another API I have created. It’s a bit older, so there are some inconsistencies compared to how things are done in first spec that I would fix if I had the time (or had created it now), but there are two things to look out for here:\n• It’s a free-standing API (not part of a larger ecosystem), so some of the common specs mentioned above are inlined here\n• API clients for this API do not necessarily know anything about JSON:API right off the bat, so the request and response bodies are documented. It’s a bit more work (OpenAPI is not as expressive as I’d like regarding re-using definitions), but possible.\n\nBoth of the specifications allow you to download the OpenAPI file if you want to have a look at it (see download button at the top)."
    },
    {
        "link": "https://swagger.io/resources/articles/best-practices-in-api-design",
        "document": "Good API design is a topic that comes up a lot for teams that are trying to perfect their API strategy. In a previous blog post, I briefly discussed the importance of API design. The benefits of a well-designed API include: improved developer experience, faster documentation, and higher adoption for your API . But what exactly goes into good API design? In this blog post, I will detail a few best practices for designing RESTful APIs.\n\nIn general, an effective API design will have the following characteristics:\n• Easy to read and work with : A well designed API will be easy to work with, and its resources and associated operations can quickly be memorized by developers who work with it constantly.\n• Hard to misuse: Implementing and integrating with an API with good design will be a straightforward process, and writing incorrect code will be a less likely outcome. It has informative feedback, and doesn’t enforce strict guidelines on the API’s end consumer.\n• Complete and concise: Finally, a complete API will make it possible for developers to make full- fledged applications against the data you expose. Completeness happens over time usually, and most API designers and developers incrementally build on top of existing APIs. It is an ideal which every engineer or company with an API must strive towards.\n\nFor the purpose of illustrating the concepts listed below, I’ll be taking the example of a photosharing app. The app allows users to upload photos, characterizing them with the location where these photos were taken and hashtags that describe the emotions associated with them.\n\nResources are fundamental to the concept of REST. A resource is an object that’s important enough to be referenced in itself. A resource has data, relationships to other resources, and methods that operate against it to allow for accessing and manipulating the associated information. A group of resources is called a collection. The contents of collections and resources depend on your organizational and consumer requirements. If, for example, you believe the market will benefit from obtaining basic information about your product’s user base, then you could expose this as a collection or resource. A Uniform Resource Locator (URL) identifies the online location of a resource. This URL points to the location where your API’s resources exist. The base URL is the consistent part of this location. In the case of the photosharing app, we could expose data about the users who use the app through collections and resources, accessed by the appropriate URL.\n\nThe base URL should be neat, elegant, and simple so that developers using your product can easily use them in their web applications. A long and difficult-to-read base URL is not just bad to look at, but can also be prone to mistakes when trying to recode it. Nouns should always be trusted. There’s no rule on keeping the resource nouns singular or plural, though it is advisable to keep collections plural. Having the same plurality across all resources and collections respectively for consistency is good practice. Keeping these nouns self explanatory helps developers understand the kind of resource described from the URL, which can eventually enable them to become self sufficient while working with your API . Coming back to the photosharing app, say it has a public API with /users and /photos as collections. Notice how they’re all plural nouns?They’re also self explanatory and we can infer that /users and /photos gives information about the product’s registered userbase, and shared photos respectively.\n\nAll resources have a set of methods that can be operated against them to work with the data being exposed by the API. REStful APIs comprise majorly of HTTP methods which have well defined and unique actions against any resource. Here’s a list of commonly used HTTP methods that define the CRUD operations for any resource or collection in a RESTful API.\n\n(If you want to know the difference between PUT and PATCH, check out this feed on StackOverflow.) Keeping verbs out of your URLs is also a good idea. The operations GET, PUT, POST and DELETE are already used to operate on your resource described by the URL, so having verbs instead of nouns in the URL can make working with your resources confusing. In the photosharing app, with /users and /photos as end points, an end consumer of your API can easily work with them intuitively using the RESTful CRUD operations described above.\n\nProviding good feedback to developers on how well they are using your product goes a long way in improving adoption and retention. Every client request and server side response is a message and, in an ideal RESTful ecosystem, these messages must be self descriptive. Good feedback involves positive validation on correct implementation, and an informative error on incorrect implementation that can help users debug and correct the way they use the product. For an API, errors are a great way to provide context to using an API. Align your errors around the standard HTTP codes. Incorrect, client side calls should have 400-type errors associated with them. If there are any server side errors, then a suitable 500 response must be associated with them. A successful method used against your resource should return a 200-type response. There are a lot of response codes. For additional information, check out this REST API tutorial. In general, there are three possible outcomes when using your API: -\n\nHand holding your end consumer to success whenever they hit a road block working with your API will go a long way in improving developer experience and preventing API misuse. Describe these error responses well, but keep them concise and neat. Provide enough information in the error codes for an end user to start work on fixing the cause, and, if you feel there’s more information needed, provide links to additional documentation.\n\nGive examples for all your GET responses\n\nA well- designed API also has an example of the kind of response one can expect on successful call against a URL. This example response should be simple, plain, and quick to comprehend. A good rule of thumb is to help developers understand exactly what a successful response would give them in under five seconds. Coming back to our photosharing app, we’ve defined a /users and a /photos URL. The /users collection would give the username and date of joining of all the users who have registered with the app in an array. You can use an API design tool to define your API in the Swagger (OpenAPI) specification as follows:\n\nNotice the data types and an example described in each response item an end user can expect from a successful GET call. The successful response an end user would receive in JSON would look as follows.\n\nIf the end user successfully calls the end point with a GET method, the user should obtain the above data along with a 200 response code to validate the correct usage. Likewise, an incorrect call should produce an appropriate 400 or 500 response code with relevant information to help user better operate against the collection.\n\nThe data you’re trying to expose can be characterized by a lot of properties which could be beneficial for the end consumer working with your API. These properties describe the base resource and isolate specific assets of information that can be manipulated with the appropriate method. An API should strive towards completion, and provide all the required information, data and resources to help developers integrate with them in a seamless manner. But completion means taking into account common use cases for your API. There could be numerous such relationships and properties, and it’s not good practice to define resources for each of them. The amount of data the resource exposes should also be taken into account. If you’re trying to expose a lot, there can be negative implications on the server, especially with regards to load and performance. The above cases and relationships are important considerations in the design of the API, and can be handled using the appropriate parameters. You can sweep properties and limit responses behind the ‘?’ in a query parameter, or isolate specific component of the data the client is working with using a path parameter. Let's take the example of our photosharing app. It could be of use to developers to get information on all the photos shared in a particular location and a specific hashtag. You also want to limit the number of results to 10 per API call to prevent server load. If the end user wants to find all photos in Boston with a hashtag #winter, the call would be:\n\nNotice how the complexities have now been reduced to a simple association with a query parameter. If you want to provide information about a specific user depending on the client’s request, the call would be:\n\nWhere kesh92 is the username of a specific user in the users collection, and will return the location and date of joining for kesh92. These are just some of the ways you could design parameters that strive towards API completion and help your end developers use your API intuitively. Finally, when in doubt, leave it out. If you’re having second thoughts about a specific resource or collection’s functionality, then leave it for the next iteration. Developing and maintaining APIs is a continuous process, and waiting for the feedback from the right users can go a long way in building a robust API that enables users to integrate and develop applications in creative ways.\n\nThere isn’t a single approach to API design that will work for every organization. The above suggestions are just that — advice and recommendations which can be used or discarded depending on your user case and requirement. One of the main reasons why API design is crucial is to help the end consumer use your API. Their needs should be the guiding light towards designing and building a great API.\n\nInterested in getting started with API design for REST APIs? Find out how Swagger API design tools can help."
    },
    {
        "link": "https://blog.dreamfactory.com/7-tips-to-write-great-api-documentation",
        "document": "Developers build REST APIs so people can use their applications, and they write great API documentation so people can use their APIs. But for some reason, writing API documentation that is both pleasurable to read and easy to work with is a skill that many developers lack, so let’s get this clear:\n\nYour API is only as great as your API documentation.\n\nBelow, we explore seven tips for writing great API documentation. These tips will help you understand why it’s important to write great API documentation, the best strategies for going about it, and we’ll also show you how to dramatically speed up your API documentation process with DreamFactory – which can automatically generate fully-documented REST APIs in minutes!\n• Write API Documentation That Decision-Makers and Developers Can Understand\n\nTo write great documentation, you need to start with an API that’s consistent with naming conventions and follows common standards for behavior. Stick to what an experienced developer expects. For example, your API should use conventional HTTP status code definitions and verbs – i.e., 404 (not found), 400 (bad request), 500 (internal Server Error), DELETE (delete), POST (create), etc. An exception to this is PUT and PATCH, which may vary depending on the needs of your app.\n\nConsider reviewing the REST Resource Naming Guide for more information about creating APIs that are intuitive and easy to use. According to thiguide:\n\n“REST APIs use Uniform Resource Identifiers (URIs) to address resources. REST API designers should create URIs that convey a REST API’s resource model to its potential client developers. When resources are named well, an API is intuitive and easy to use. If done poorly, that same API can feel difficult to use and understand. The constraint of a uniform interface is partially addressed by the combination of URIs and HTTP verbs and using them in line with the standards and conventions.”\n\n2. Write API Documentation That Decision-Makers and Developers Can Understand\n\nBefore companies use your API, they’ll evaluate whether it solves their pain-points. This involves a close review of your app, API, and documentation by company decision-makers. These decision-makers won’t use your API directly, but they need to understand it. By keeping decisionmakers in mind while writing your docs – like CIOs, CTOs, and tech product managers – you’ll develop API documentation that “sells” your solution to the widest audience possible. An important way to do this is to avoid jargon, offer explanations for nuanced topics, and make the utility of the API clear.\n\nThe other important audience for your API documentation is the developers who will be calling and interacting with the API. Many of these developers struggle with bad API documentation on a daily basis. For example, these quotes from Reddit show you what they go through:\n• “After 12 years, I still struggle with new APIs. Sometimes the APIs are complex (PayPal and Stripe, for instance) have multiple integrations and multiple APIs, so it takes time to understand which calls should be used with which integration. Even when the documentation is clear, and example code is provided, it is sometimes written for a platform I am not using, a dependency that doesn't exist or is not compatible with my build, or some other technical roadblock. At that point, there is no choice but to Google for code samples specific to your set-up. Of course, you will run across incorrect and outdated samples, but you will try them anyway just to get things to work (source).”\n• “I've done my fair share of integrations with external systems. I'm not sure what is worse, a clear but undocumented API. Or one that's documented so badly that nothing that actually makes any sense (source).”\n\nTo ensure that your API documentation “makes sense” to the developer audience, make sure your API documentation provides the following:\n• A quick sense for what the API can do.\n• Instructions, examples, and code samples for calling each service that the API makes available.\n\nWhen your documentation satisfies these requirements, developers are more likely to sing your praises – and that’s when your solutions become popular in the developer community.\n\nThe organization of API documentation depends a lot on the industry, but there are certain sections that developers have come to expect. Make sure to organize your API documentation into the following sections at a minimum:\n• Authentication: This section tells API consumers how to use your API’s authentication schemes. Carefully walk developers through each step of the authentication process in a way that there’s no chance of confusion. Here’s an example authentication guide from Twilio.\n• Error messages: It’s important to clearly define all error messages and error codes. Describe the parameters that trigger each error notice, and suggest fixes to resolve errors when they occur.\n• Resources: Resources are the services and components that your API offers to clients and users. This section should (1) serve as a catalog for all available resources; (2) clearly explain how clients/users integrate with each resource; and (3) provide information and examples about requests/responses related to the resources.\n• Terms of use: This section defines the legal terms of use that your organization and API users have agreed to. It should provide usage guidelines, legal terms and conditions, and spell out API limits and constraints. Here are the API terms of use for LinkedIn.\n• Changelog: The changelog lists each API version and any implemented updates. It tells developers if they need to adjust the way they make API calls in different versions. It also shows decision-makers how often your organization is updating the API. Here’s an API change log example from StackExchange.\n\nThink back to the days when you were first learning about your industry. Your head was spinning with tech jargon that you didn’t understand. Some decision-makers and users could feel this way while exploring your API documentation, so do your best to support them by avoiding unnecessary tech jargon when possible.\n\nWhen uncommon terms and industry-specific jargon are necessary, offer links and support material so readers can learn about these concepts. This will help everyone to understand the “why, what, and how” behind the API calls and resources associated with your product.\n\nWhen it comes to request/response cycles, give detailed explanations by keeping these principals in mind:\n• Document all of your calls and provide contextual information: Document each possible call and its available parameters. Give contextual information, example scenarios, and practical details that help the reader understand.\n• Explain responses and error messages for all formats: Describe all responses and error messages and don’t leave out descriptions for any of the formats that your API is compatible with (JSON, XML, BSON, form-urlencoded, etc.). Also include the following: definitions for HTTP headers, messages, and error codes; examples in the objects that the API returns; and examples for the different parameters developers can implement in their calls.\n\nAdding additional resources to your API documentation is not required, but including any of the following will offer a world of difference to developers:\n• Educational guides: API documentation that strives to educate users with informative resources helps new users understand how to work with your API. Twilio’s API documentation starts from the ground up with educational materials that teach users about APIs.\n• Quick-start tutorial: A quick start guide illustrates each step required to quickly integrate with your API. Here’s a quick start guide from Spotify as an example.\n• Code libraries: Whether you’re a new developer or not, there’s nothing like a code library to save time. Code libraries offer pluggable snippets of code for different actions in the widest variety of languages. Here’s a great library example from Stripe.\n• Create a full SDK: Consider putting together a full SDK or devkit for your API. An SDK serves as a complete workshop for building apps/products that use your API. It includes documentation, libraries, tools, code samples, and guides. Swagger Codegen is an awesome resource to help you quickly create an SDK.\n• Offer a free test environment: An API sandbox or testing environment lets developers try out your API before fully committing to the solution. For potential new customers, it’s a zero-risk opportunity to test drive your API.\n\nThis final tip will make your “great API documentation” journey faster and easier to complete. It involves DreamFactory, which can automatically generate Swagger documentation for your API projects. Swagger has become the gold standard format for API documentation for several reasons:\n• It’s interactive: Swagger documentation is interactive. You can point-and-click through various fields to explore different types of requests and the parameters available for the requests. These features let you generate an API call and see the result directly from the Swagger UI.\n• Excellent user experience: Swagger’s interactive documentation is nice on the eyes and a joy to navigate.\n• Open-source: Swagger is free for anyone to use.\n• Big tech loves it: As a machine-readable solution for documenting REST APIs, Swagger has become the darling of big technology firms like Microsoft, Google, and IBM.\n• Stellar reputation among developers: Developers frequently praise Swagger documentation, like this Reddit user: “Swagger documentation is fantastic. In-line \"try it now\" boxes, example input and output json/xml, full model specification... mmm, love me some swagger documentation.”\n\nIf you’re using the DreamFactory API gateway, there’s another reason you’ll like Swagger. DreamFactory includes automatic API generation tools that create REST API’s for any database in minutes. These APIs also come with full Swagger documentation. Here’s a screenshot of Swagger documentation that DreamFactory automatically generated for a SQL Server database. It’s an abbreviated list of REST API endpoints that you can explore by pointing and clicking:\n\nWhen you click the second “GET” row labeled “Retrieve one or more records,” it displays a list of supported API parameters. Then, you can click on different parameters to identify the target table and the fields you want to retrieve. Finally, you can specify other functions like FILTER, LIMIT, JOIN, ORDER, etc.:\n\nAfter choosing the parameters, you can see the actual results of the request:\n\nHere are some of the benefits you’ll receive by incorporating DreamFactory and Swagger into your API and API documentation strategy:\n• The Swagger part of your API documentation will always be up-to-date. As soon as you update the API, you’ll update the Swagger documentation too.\n• Because DreamFactory offers role-based access control, you can control how deeply users can interact with the docs. This allows certain users to have a surface-level view while permitting others to make edits and changes.\n• DreamFactory lets you import OpenAPI specifications for remote and scripted APIs.\n\nBy keeping the above tips in mind, you should be able to write the kind of API documentation that encourages decision-makers to adopt your technology, and helps developers quickly integrate your solutions after that decision has been made. Ultimately, when you write great API documentation, developers will love you for it – and that’s how your API becomes legendary!\n\nIf you want to speed up your API documentation process with automatically generated REST APIs that come with full Swagger documentation, contact the DreamFactory team for a free, hosted trial now!"
    },
    {
        "link": "https://stackoverflow.blog/2020/03/02/best-practices-for-rest-api-design",
        "document": "REST APIs are one of the most common kinds of web interfaces available today. They allow various clients including browser apps to communicate with services via the REST API. Therefore, it's very important to design REST APIs properly so that we won't run into problems down the road. We have to take into account security, performance, and ease of use for API consumers.\n\nOtherwise, we create problems for clients that use our APIs, which isn’t pleasant and detracts people from using our API. If we don’t follow commonly accepted conventions, then we confuse the maintainers of the API and the clients that use them since it’s different from what everyone expects.\n\nIn this article, we'll look at how to design REST APIs to be easy to understand for anyone consuming them, future-proof, and secure and fast since they serve data to clients that may be confidential.\n• Use nouns instead of verbs in endpoint paths\n\nA REST API is an application programming interface architecture style that conforms to specific architectural constraints, like stateless communication and cacheable data. It is not a protocol or standard. While REST APIs can be accessed through a number of communication protocols, most commonly, they are called over HTTPS, so the guidelines below apply to REST API endpoints that will be called over the internet.\n\nNote: For REST APIs called over the internet, you'll like want to follow the best practices for REST API authentication.\n\nEven though some people think REST should only return hypertext (including Roy Fielding who created the term) REST APIs should accept JSON for request payload and also send responses to JSON. JSON is the standard for transferring data. Almost every networked technology can use it: JavaScript has built-in methods to encode and decode JSON either through the Fetch API or another HTTP client. Server-side technologies have libraries that can decode JSON without doing much work.\n\nThere are other ways to transfer data. XML isn’t widely supported by frameworks without transforming the data ourselves to something that can be used, and that’s usually JSON. We can’t manipulate this data as easily on the client-side, especially in browsers. It ends up being a lot of extra work just to do normal data transfer.\n\nForm data is good for sending data, especially if we want to send files. But for text and numbers, we don’t need form data to transfer those since—with most frameworks—we can transfer JSON by just getting the data from it directly on the client side. It’s by far the most straightforward to do so.\n\nTo make sure that when our REST API app responds with JSON that clients interpret it as such, we should set Content-Type in the response header to application/json after the request is made. Many server-side app frameworks set the response header automatically. Some HTTP clients look at the Content-Type response header and parse the data according to that format.\n\nThe only exception is if we’re trying to send and receive files between client and server. Then we need to handle file responses and send form data from client to server. But that is a topic for another time.\n\nWe should also make sure that our endpoints return JSON as a response. Many server-side frameworks have this as a built-in feature.\n\nLet’s take a look at an example API that accepts JSON payloads. This example will use the Express back end framework for Node.js. We can use the body-parser middleware to parse the JSON request body, and then we can call the res.json method with the object that we want to return as the JSON response as follows:\n\nbodyParser.json() parses the JSON request body string into a JavaScript object and then assigns it to the req.body object.\n\nSet the Content-Type header in the response to application/json; charset=utf-8 without any changes. The method above applies to most other back end frameworks.\n\nUse nouns instead of verbs in endpoint paths\n\nWe shouldn't use verbs in our endpoint paths. Instead, we should use the nouns which represent the entity that the endpoint that we're retrieving or manipulating as the pathname.\n\nThis is because our HTTP request method already has the verb. Having verbs in our API endpoint paths isn’t useful and it makes it unnecessarily long since it doesn’t convey any new information. The chosen verbs could vary by the developer’s whim. For instance, some like ‘get’ and some like ‘retrieve’, so it’s just better to let the HTTP GET verb tell us what and endpoint does.\n\nThe action should be indicated by the HTTP request method that we're making. The most common methods include GET, POST, PUT, and DELETE.\n• POST submits new data to the server.\n\nWith the two principles we discussed above in mind, we should create routes like GET /articles/ for getting news articles. Likewise, POST /articles/ is for adding a new article , PUT /articles/:id is for updating the article with the given id. DELETE /articles/:id is for deleting an existing article with the given ID.\n\n/articles represents a REST API resource. For instance, we can use Express to add the following endpoints for manipulate articles as follows:\n\nIn the code above, we defined the endpoints to manipulate articles. As we can see, the path names do not have any verbs in them. All we have are nouns. The verbs are in the HTTP verbs.\n\nThe POST, PUT, and DELETE endpoints all take JSON as the request body, and they all return JSON as the response, including the GET endpoint.\n\nWhen designing endpoints, it makes sense to group those that contain associated information. That is, if one object can contain another object, you should design the endpoint to reflect that. This is good practice regardless of whether your data is structured like this in your database. In fact, it may be advisable to avoid mirroring your database structure in your endpoints to avoid giving attackers unnecessary information.\n\nFor example, if we want an endpoint to get the comments for a news article, we should append the /comments path to the end of the /articles path. We can do that with the following code in Express:\n\nIn the code above, we can use the GET method on the path '/articles/:articleId/comments'. We get comments on the article identified by articleId and then return it in the response. We add 'comments' after the '/articles/:articleId' path segment to indicate that it's a child resource of /articles.\n\nThis makes sense since comments are the children objects of the articles, assuming each article has its own comments. Otherwise, it’s confusing to the user since this structure is generally accepted to be for accessing child objects. The same principle also applies to the POST, PUT, and DELETE endpoints. They can all use the same kind of nesting structure for the path names.\n\nHowever, nesting can go too far. After about the second or third level, nested endpoints can get unwieldy. Consider, instead, returning the URL to those resources instead, especially if that data is not necessarily contained within the top level object.\n\nFor example, suppose you wanted to return the author of particular comments. You could use /articles/:articleId/comments/:commentId/author. But that's getting out of hand. Instead, return the URI for that particular user within the JSON response instead:\n\nTo eliminate confusion for API users when an error occurs, we should handle errors gracefully and return HTTP response codes that indicate what kind of error occurred. This gives maintainers of the API enough information to understand the problem that’s occurred. We don’t want errors to bring down our system, so we can leave them unhandled, which means that the API consumer has to handle them.\n• 401 Unauthorized - This means the user isn't not authorized to access a resource. It usually returns when the user isn't authenticated.\n• 403 Forbidden - This means the user is authenticated, but it's not allowed to access a resource.\n• 404 Not Found - This indicates that a resource is not found.\n• 500 Internal server error - This is a generic server error. It probably shouldn't be thrown explicitly.\n• 502 Bad Gateway - This indicates an invalid response from an upstream server.\n• 503 Service Unavailable - This indicates that something unexpected happened on server side (It can be anything like server overload, some parts of the system failed, etc.).\n\nWe should be throwing errors that correspond to the problem that our app has encountered. For example, if we want to reject the data from the request payload, then we should return a 400 response as follows in an Express API:\n\nIn the code above, we have a list of existing users in the users array with the given email.\n\nThen if we try to submit the payload with the email value that already exists in users, we'll get a 400 response status code with a 'User already exists' message to let users know that the user already exists. With that information, the user can correct the action by changing the email to something that doesn't exist.\n\nError codes need to have messages accompanied with them so that the maintainers have enough information to troubleshoot the issue, but attackers can’t use the error content to carry our attacks like stealing information or bringing down the system.\n\nWhenever our API does not successfully complete, we should fail gracefully by sending an error with information to help users make corrective action.\n\nThe databases behind a REST API can get very large. Sometimes, there's so much data that it shouldn’t be returned all at once because it’s way too slow or will bring down our systems. Therefore, we need ways to filter items.\n\nWe also need ways to paginate data so that we only return a few results at a time. We don't want to tie up resources for too long by trying to get all the requested data at once.\n\nFiltering and pagination both increase performance by reducing the usage of server resources. As more data accumulates in the database, the more important these features become.\n\nHere’s a small example where an API can accept a query string with various query parameters to let us filter out items by their fields:\n\nIn the code above, we have the req.query variable to get the query parameters. We then extract the property values by destructuring the individual query parameters into variables using the JavaScript destructuring syntax. Finally, we run filter on with each query parameter value to locate the items that we want to return.\n\nOnce we have done that, we return the results as the response. Therefore, when we make a GET request to the following path with the query string:\n\nas the returned response since we filtered by lastName and age.\n\nLikewise, we can accept the page query parameter and return a group of entries in the position from (page - 1) * 20 to page * 20.\n\nWe can also specify the fields to sort by in the query string. For instance, we can get the parameter from a query string with the fields we want to sort the data for. Then we can sort them by those individual fields.\n\nFor instance, we may want to extract the query string from a URL like:\n\nWhere + means ascending and - means descending. So we sort by author’s name in alphabetical order and datepublished from most recent to least recent.\n\nMost communication between client and server should be private since we often send and receive private information. Therefore, using SSL/TLS for security is a must.\n\nA SSL certificate isn't too difficult to load onto a server and the cost is free or very low. There's no reason not to make our REST APIs communicate over secure channels instead of in the open.\n\nPeople shouldn't be able to access more information that they requested. For example, a normal user shouldn't be able to access information of another user. They also shouldn't be able to access data of admins.\n\nTo enforce the principle of least privilege, we need to add role checks either for a single role, or have more granular roles for each user.\n\nIf we choose to group users into a few roles, then the roles should have the permissions that cover all they need and no more. If we have more granular permissions for each feature that users have access to, then we have to make sure that admins can add and remove those features from each user accordingly. Also, we need to add some preset roles that can be applied to a group users so that we don’t have to do that for every user manually.\n\nWe can add caching to return data from the local memory cache instead of querying the database to get the data every time we want to retrieve some data that users request. The good thing about caching is that users can get data faster. However, the data that users get may be outdated. This may also lead to issues when debugging in production environments when something goes wrong as we keep seeing old data.\n\nThere are many kinds of caching solutions like Redis, in-memory caching, and more. We can change the way data is cached as our needs change.\n\nFor instance, Express has the apicache middleware to add caching to our app without much configuration. We can add a simple in-memory cache into our server like so:\n\nThe code above just references the apicache middleware with apicache.middleware and then we have:\n\nto apply the caching to the whole app. We cache the results for five minutes, for example. We can adjust this for our needs.\n\nIf you are using caching, you should also include Cache-Control information in your headers. This will help users effectively use your caching system.\n\nWe should have different versions of API if we're making any changes to them that may break clients. The versioning can be done according to semantic version (for example, 2.0.6 to indicate major version 2 and the sixth patch) like most apps do nowadays.\n\nThis way, we can gradually phase out old endpoints instead of forcing everyone to move to the new API at the same time. The v1 endpoint can stay active for people who don’t want to change, while the v2, with its shiny new features, can serve those who are ready to upgrade. This is especially important if our API is public. We should version them so that we won't break third party apps that use our APIs.\n\nVersioning is usually done with /v1/, /v2/, etc. added at the start of the API path.\n\nFor example, we can do that with Express as follows:\n\nWe just add the version number to the start of the endpoint URL path to version them.\n\nThe most important takeaways for designing high-quality REST APIs is to have consistency by following web standards and conventions. JSON, SSL/TLS, and HTTP status codes are all standard building blocks of the modern web.\n\nPerformance is also an important consideration. We can increase it by not returning too much data at once. Also, we can use caching so that we don't have to query for data all the time.\n\nPaths of endpoints should be consistent, we use nouns only since the HTTP methods indicate the action we want to take. Paths of nested resources should come after the path of the parent resource. They should tell us what we’re getting or manipulating without the need to read extra documentation to understand what it’s doing."
    },
    {
        "link": "https://learn.microsoft.com/en-us/azure/architecture/best-practices/api-design",
        "document": "Most modern web applications expose APIs that clients can use to interact with the application. A well-designed web API should aim to support:\n• None Platform independence. Any client should be able to call the API, regardless of how the API is implemented internally. This requires using standard protocols, and having a mechanism whereby the client and the web service can agree on the format of the data to exchange.\n• None Service evolution. The web API should be able to evolve and add functionality independently from client applications. As the API evolves, existing client applications should continue to function without modification. All functionality should be discoverable so that client applications can fully use it.\n\nThis guidance describes issues that you should consider when designing a web API.\n\nIn 2000, Roy Fielding proposed Representational State Transfer (REST) as an architectural approach to designing web services. REST is an architectural style for building distributed systems based on hypermedia. REST is independent of any underlying protocol and is not necessarily tied to HTTP. However, most common REST API implementations use HTTP as the application protocol, and this guide focuses on designing REST APIs for HTTP.\n\nA primary advantage of REST over HTTP is that it uses open standards, and does not bind the implementation of the API or the client applications to any specific implementation. For example, a REST web service could be written in ASP.NET, and client applications can use any language or toolset that can generate HTTP requests and parse HTTP responses.\n\nHere are some of the main design principles of RESTful APIs using HTTP:\n• None REST APIs are designed around resources, which are any kind of object, data, or service that can be accessed by the client.\n• None A resource has an identifier, which is a URI that uniquely identifies that resource. For example, the URI for a particular customer order might be:\n• None Clients interact with a service by exchanging representations of resources. Many web APIs use JSON as the exchange format. For example, a GET request to the URI listed above might return this response body:\n• None REST APIs use a uniform interface, which helps to decouple the client and service implementations. For REST APIs built on HTTP, the uniform interface includes using standard HTTP verbs to perform operations on resources. The most common operations are GET, POST, PUT, PATCH, and DELETE.\n• None REST APIs use a stateless request model. HTTP requests should be independent and might occur in any order, so keeping transient state information between requests is not feasible. The only place where information is stored is in the resources themselves, and each request should be an atomic operation. This constraint enables web services to be highly scalable, because there is no need to retain any affinity between clients and specific servers. Any server can handle any request from any client. That said, other factors can limit scalability. For example, many web services write to a backend data store, which might be hard to scale out. For more information about strategies to scale out a data store, see Horizontal, vertical, and functional data partitioning.\n• None REST APIs are driven by hypermedia links that are contained in the representation. For example, the following shows a JSON representation of an order. It contains links to get or update the customer associated with the order.\n\nIn 2008, Leonard Richardson proposed the following maturity model for web APIs:\n• Level 0: Define one URI, and all operations are POST requests to this URI.\n• Level 2: Use HTTP methods to define operations on resources.\n• Level 3: Use hypermedia (HATEOAS, described below).\n\nLevel 3 corresponds to a truly RESTful API according to Fielding's definition. In practice, many published web APIs fall somewhere around level 2.\n\nFocus on the business entities that the web API exposes. For example, in an e-commerce system, the primary entities might be customers and orders. Creating an order can be achieved by sending an HTTP POST request that contains the order information. The HTTP response indicates whether the order was placed successfully or not. When possible, resource URIs should be based on nouns (the resource) and not verbs (the operations on the resource).\n\nA resource doesn't have to be based on a single physical data item. For example, an order resource might be implemented internally as several tables in a relational database, but presented to the client as a single entity. Avoid creating APIs that simply mirror the internal structure of a database. The purpose of REST is to model entities and the operations that an application can perform on those entities. A client should not be exposed to the internal implementation.\n\nEntities are often grouped together into collections (orders, customers). A collection is a separate resource from the item within the collection, and should have its own URI. For example, the following URI might represent the collection of orders:\n\nSending an HTTP GET request to the collection URI retrieves a list of items in the collection. Each item in the collection also has its own unique URI. An HTTP GET request to the item's URI returns the details of that item.\n\nAdopt a consistent naming convention in URIs. In general, it helps to use plural nouns for URIs that reference collections. It's a good practice to organize URIs for collections and items into a hierarchy. For example, is the path to the customers collection, and is the path to the customer with ID equal to 5. This approach helps to keep the web API intuitive. Also, many web API frameworks can route requests based on parameterized URI paths, so you could define a route for the path .\n\nAlso consider the relationships between different types of resources and how you might expose these associations. For example, the might represent all of the orders for customer 5. You could also go in the other direction, and represent the association from an order back to a customer with a URI such as . However, extending this model too far can become cumbersome to implement. A better solution is to provide navigable links to associated resources in the body of the HTTP response message. This mechanism is described in more detail in the section Use HATEOAS to enable navigation to related resources.\n\nIn more complex systems, it can be tempting to provide URIs that enable a client to navigate through several levels of relationships, such as . However, this level of complexity can be difficult to maintain and is inflexible if the relationships between resources change in the future. Instead, try to keep URIs relatively simple. Once an application has a reference to a resource, it should be possible to use this reference to find items related to that resource. The preceding query can be replaced with the URI to find all the orders for customer 1, and then to find the products in this order.\n\nAnother factor is that all web requests impose a load on the web server. The more requests, the bigger the load. Therefore, try to avoid \"chatty\" web APIs that expose a large number of small resources. Such an API might require a client application to send multiple requests to find all of the data that it requires. Instead, you might want to denormalize the data and combine related information into bigger resources that can be retrieved with a single request. However, you need to balance this approach against the overhead of fetching data that the client doesn't need. Retrieving large objects can increase the latency of a request and incur additional bandwidth costs. For more information about these performance antipatterns, see Chatty I/O and Extraneous Fetching.\n\nAvoid introducing dependencies between the web API and the underlying data sources. For example, if your data is stored in a relational database, the web API doesn't need to expose each table as a collection of resources. In fact, that's probably a poor design. Instead, think of the web API as an abstraction of the database. If necessary, introduce a mapping layer between the database and the web API. That way, client applications are isolated from changes to the underlying database scheme.\n\nFinally, it might not be possible to map every operation implemented by a web API to a specific resource. You can handle such non-resource scenarios through HTTP requests that invoke a function and return the results as an HTTP response message. For example, a web API that implements simple calculator operations such as add and subtract could provide URIs that expose these operations as pseudo resources and use the query string to specify the parameters required. For example, a GET request to the URI /add?operand1=99&operand2=1 would return a response message with the body containing the value 100. However, only use these forms of URIs sparingly.\n\nThe HTTP protocol defines a number of methods that assign semantic meaning to a request. The common HTTP methods used by most RESTful web APIs are:\n• GET retrieves a representation of the resource at the specified URI. The body of the response message contains the details of the requested resource.\n• POST creates a new resource at the specified URI. The body of the request message provides the details of the new resource. Note that POST can also be used to trigger operations that don't actually create resources.\n• PUT either creates or replaces the resource at the specified URI. The body of the request message specifies the resource to be created or updated.\n• PATCH performs a partial update of a resource. The request body specifies the set of changes to apply to the resource.\n• DELETE removes the resource at the specified URI.\n\nThe effect of a specific request should depend on whether the resource is a collection or an individual item. The following table summarizes the common conventions adopted by most RESTful implementations using the e-commerce example. Not all of these requests might be implemented—it depends on the specific scenario.\n\nThe differences between POST, PUT, and PATCH can be confusing.\n• None A POST request creates a resource. The server assigns a URI for the new resource, and returns that URI to the client. In the REST model, you frequently apply POST requests to collections. The new resource is added to the collection. A POST request can also be used to submit data for processing to an existing resource, without any new resource being created.\n• None A PUT request creates a resource or updates an existing resource. The client specifies the URI for the resource. The request body contains a complete representation of the resource. If a resource with this URI already exists, it is replaced. Otherwise a new resource is created, if the server supports doing so. PUT requests are most frequently applied to resources that are individual items, such as a specific customer, rather than collections. A server might support updates but not creation via PUT. Whether to support creation via PUT depends on whether the client can meaningfully assign a URI to a resource before it exists. If not, then use POST to create resources and PUT or PATCH to update.\n• None A PATCH request performs a partial update to an existing resource. The client specifies the URI for the resource. The request body specifies a set of changes to apply to the resource. This can be more efficient than using PUT, because the client only sends the changes, not the entire representation of the resource. Technically PATCH can also create a new resource (by specifying a set of updates to a \"null\" resource), if the server supports this.\n\nPUT requests must be idempotent. If a client submits the same PUT request multiple times, the results should always be the same (the same resource will be modified with the same values). POST and PATCH requests are not guaranteed to be idempotent.\n\nThis section describes some typical considerations for designing an API that conforms to the HTTP specification. However, it doesn't cover every possible detail or scenario. When in doubt, consult the HTTP specifications.\n\nAs mentioned earlier, clients and servers exchange representations of resources. For example, in a POST request, the request body contains a representation of the resource to create. In a GET request, the response body contains a representation of the fetched resource.\n\nIn the HTTP protocol, formats are specified through the use of media types, also called MIME types. For non-binary data, most web APIs support JSON (media type = ) and possibly XML (media type = ).\n\nThe Content-Type header in a request or response specifies the format of the representation. Here is an example of a POST request that includes JSON data:\n\nIf the server doesn't support the media type, it should return HTTP status code 415 (Unsupported Media Type).\n\nA client request can include an Accept header that contains a list of media types the client will accept from the server in the response message. For example:\n\nIf the server cannot match any of the media types listed, it should return HTTP status code 406 (Not Acceptable).\n\nA successful GET method typically returns HTTP status code 200 (OK). If the resource cannot be found, the method should return 404 (Not Found).\n\nIf the request was fulfilled but there is no response body included in the HTTP response, then it should return HTTP status code 204 (No Content); for example, a search operation yielding no matches might be implemented with this behavior.\n\nIf a POST method creates a new resource, it returns HTTP status code 201 (Created). The URI of the new resource is included in the Location header of the response. The response body contains a representation of the resource.\n\nIf the method does some processing but does not create a new resource, the method can return HTTP status code 200 and include the result of the operation in the response body. Alternatively, if there is no result to return, the method can return HTTP status code 204 (No Content) with no response body.\n\nIf the client puts invalid data into the request, the server should return HTTP status code 400 (Bad Request). The response body can contain additional information about the error or a link to a URI that provides more details.\n\nIf a PUT method creates a new resource, it returns HTTP status code 201 (Created), as with a POST method. If the method updates an existing resource, it returns either 200 (OK) or 204 (No Content). In some cases, it might not be possible to update an existing resource. In that case, consider returning HTTP status code 409 (Conflict).\n\nConsider implementing bulk HTTP PUT operations that can batch updates to multiple resources in a collection. The PUT request should specify the URI of the collection, and the request body should specify the details of the resources to be modified. This approach can help to reduce chattiness and improve performance.\n\nWith a PATCH request, the client sends a set of updates to an existing resource, in the form of a patch document. The server processes the patch document to perform the update. The patch document doesn't describe the whole resource, only a set of changes to apply. The specification for the PATCH method (RFC 5789) doesn't define a particular format for patch documents. The format must be inferred from the media type in the request.\n\nJSON is probably the most common data format for web APIs. There are two main JSON-based patch formats, called JSON patch and JSON merge patch.\n\nJSON merge patch is somewhat simpler. The patch document has the same structure as the original JSON resource, but includes just the subset of fields that should be changed or added. In addition, a field can be deleted by specifying for the field value in the patch document. (That means merge patch is not suitable if the original resource can have explicit null values.)\n\nFor example, suppose the original resource has the following JSON representation:\n\nHere is a possible JSON merge patch for this resource:\n\nThis tells the server to update , delete , and add , while and are not modified. For the exact details of JSON merge patch, see RFC 7396. The media type for JSON merge patch is .\n\nMerge patch is not suitable if the original resource can contain explicit null values, due to the special meaning of in the patch document. Also, the patch document doesn't specify the order that the server should apply the updates. That may or may not matter, depending on the data and the domain. JSON patch, defined in RFC 6902, is more flexible. It specifies the changes as a sequence of operations to apply. Operations include add, remove, replace, copy, and test (to validate values). The media type for JSON patch is .\n\nHere are some typical error conditions that might be encountered when processing a PATCH request, along with the appropriate HTTP status code.\n\nIf the delete operation is successful, the web server should respond with HTTP status code 204 (No Content), indicating that the process has been successfully handled, but that the response body contains no further information. If the resource doesn't exist, the web server can return HTTP 404 (Not Found).\n\nSometimes a POST, PUT, PATCH, or DELETE operation might require processing that takes a while to complete. If you wait for completion before sending a response to the client, it might cause unacceptable latency. If so, consider making the operation asynchronous. Return HTTP status code 202 (Accepted) to indicate the request was accepted for processing but is not completed.\n\nYou should expose an endpoint that returns the status of an asynchronous request, so the client can monitor the status by polling the status endpoint. Include the URI of the status endpoint in the Location header of the 202 response. For example:\n\nIf the client sends a GET request to this endpoint, the response should contain the current status of the request. Optionally, it could also include an estimated time to completion or a link to cancel the operation.\n\nIf the asynchronous operation creates a new resource, the status endpoint should return status code 303 (See Other) after the operation completes. In the 303 response, include a Location header that gives the URI of the new resource:\n\nFor more information on how to implement this approach, see Providing asynchronous support for long-running requests and the Asynchronous Request-Reply pattern.\n\nAny time the body of a successful response is empty, the status code should be 204 (No Content). For empty sets, such as a response to a filtered request with no items, the status code should still be 204 (No Content), not 200 (OK).\n\nExposing a collection of resources through a single URI can lead to applications fetching large amounts of data when only a subset of the information is required. For example, suppose a client application needs to find all orders with a cost over a specific value. It might retrieve all orders from the /orders URI and then filter these orders on the client side. Clearly this process is highly inefficient. It wastes network bandwidth and processing power on the server hosting the web API.\n\nInstead, the API can allow passing a filter in the query string of the URI, such as /orders?minCost=n. The web API is then responsible for parsing and handling the parameter in the query string and returning the filtered results on the server side.\n\nGET requests over collection resources can potentially return a large number of items. You should design a web API to limit the amount of data returned by any single request. Consider supporting query strings that specify the maximum number of items to retrieve and a starting offset into the collection. For example:\n\nAlso consider imposing an upper limit on the number of items returned, to help prevent Denial of Service attacks. To assist client applications, GET requests that return paginated data should also include some form of metadata that indicate the total number of resources available in the collection.\n\nYou can use a similar strategy to sort data as it is fetched, by providing a sort parameter that takes a field name as the value, such as /orders?sort=ProductID. However, this approach can have a negative effect on caching, because query string parameters form part of the resource identifier used by many cache implementations as the key to cached data.\n\nYou can extend this approach to limit the fields returned for each item, if each item contains a large amount of data. For example, you could use a query string parameter that accepts a comma-delimited list of fields, such as /orders?fields=ProductID,Quantity.\n\nGive all optional parameters in query strings meaningful defaults. For example, set the parameter to 10 and the parameter to 0 if you implement pagination, set the sort parameter to the key of the resource if you implement ordering, and set the parameter to all fields in the resource if you support projections.\n\nA resource may contain large binary fields, such as files or images. To overcome problems caused by unreliable and intermittent connections and to improve response times, consider enabling such resources to be retrieved in chunks. To do this, the web API should support the Accept-Ranges header for GET requests for large resources. This header indicates that the GET operation supports partial requests. The client application can submit GET requests that return a subset of a resource, specified as a range of bytes.\n\nAlso, consider implementing HTTP HEAD requests for these resources. A HEAD request is similar to a GET request, except that it only returns the HTTP headers that describe the resource, with an empty message body. A client application can issue a HEAD request to determine whether to fetch a resource by using partial GET requests. For example:\n\nHere is an example response message:\n\nThe Content-Length header gives the total size of the resource, and the Accept-Ranges header indicates that the corresponding GET operation supports partial results. The client application can use this information to retrieve the image in smaller chunks. The first request fetches the first 2500 bytes by using the Range header:\n\nThe response message indicates that this is a partial response by returning HTTP status code 206. The Content-Length header specifies the actual number of bytes returned in the message body (not the size of the resource), and the Content-Range header indicates which part of the resource this is (bytes 0-2499 out of 4580):\n\nA subsequent request from the client application can retrieve the remainder of the resource.\n\nUse HATEOAS to enable navigation to related resources\n\nOne of the primary motivations behind REST is that it should be possible to navigate the entire set of resources without requiring prior knowledge of the URI scheme. Each HTTP GET request should return the information necessary to find the resources related directly to the requested object through hyperlinks included in the response, and it should also be provided with information that describes the operations available on each of these resources. This principle is known as HATEOAS, or Hypertext as the Engine of Application State. The system is effectively a finite state machine, and the response to each request contains the information necessary to move from one state to another; no other information should be necessary.\n\nFor example, to handle the relationship between an order and a customer, the representation of an order could include links that identify the available operations for the customer of the order. Here is a possible representation:\n\nIn this example, the array has a set of links. Each link represents an operation on a related entity. The data for each link includes the relationship (\"customer\"), the URI ( ), the HTTP method, and the supported MIME types. This is all the information that a client application needs to be able to invoke the operation.\n\nThe array also includes self-referencing information about the resource itself that has been retrieved. These have the relationship self.\n\nThe set of links that are returned may change, depending on the state of the resource. This is what is meant by hypertext being the \"engine of application state.\"\n\nIt is highly unlikely that a web API will remain static. As business requirements change new collections of resources may be added, the relationships between resources might change, and the structure of the data in resources might be amended. While updating a web API to handle new or differing requirements is a relatively straightforward process, you must consider the effects that such changes will have on client applications consuming the web API. The issue is that although the developer designing and implementing a web API has full control over that API, the developer does not have the same degree of control over client applications, which may be built by third-party organizations operating remotely. The primary imperative is to enable existing client applications to continue functioning unchanged while allowing new client applications to take advantage of new features and resources.\n\nVersioning enables a web API to indicate the features and resources that it exposes, and a client application can submit requests that are directed to a specific version of a feature or resource. The following sections describe several different approaches, each of which has its own benefits and trade-offs.\n\nThis is the simplest approach, and may be acceptable for some internal APIs. Significant changes could be represented as new resources or new links. Adding content to existing resources might not present a breaking change as client applications that are not expecting to see this content will ignore it.\n\nFor example, a request to the URI should return the details of a single customer containing , , and fields expected by the client application:\n\nIf the field is added to the schema of the customer resource, then the response would look like this:\n\nExisting client applications might continue functioning correctly if they are capable of ignoring unrecognized fields, while new client applications can be designed to handle this new field. However, if more radical changes to the schema of resources occur (such as removing or renaming fields) or the relationships between resources change then these may constitute breaking changes that prevent existing client applications from functioning correctly. In these situations, you should consider one of the following approaches.\n\nEach time you modify the web API or change the schema of resources, you add a version number to the URI for each resource. The previously existing URIs should continue to operate as before, returning resources that conform to their original schema.\n\nExtending the previous example, if the field is restructured into subfields containing each constituent part of the address (such as , , , and ), this version of the resource could be exposed through a URI containing a version number, such as :\n\nThis versioning mechanism is very simple but depends on the server routing the request to the appropriate endpoint. However, it can become unwieldy as the web API matures through several iterations and the server has to support a number of different versions. Also, from a purist's point of view, in all cases the client applications are fetching the same data (customer 3), so the URI should not really be different depending on the version. This scheme also complicates implementation of HATEOAS as all links will need to include the version number in their URIs.\n\nRather than providing multiple URIs, you can specify the version of the resource by using a parameter within the query string appended to the HTTP request, such as . The version parameter should default to a meaningful value such as 1 if it is omitted by older client applications.\n\nThis approach has the semantic advantage that the same resource is always retrieved from the same URI, but it depends on the code that handles the request to parse the query string and send back the appropriate HTTP response. This approach also suffers from the same complications for implementing HATEOAS as the URI versioning mechanism.\n\nRather than appending the version number as a query string parameter, you could implement a custom header that indicates the version of the resource. This approach requires that the client application adds the appropriate header to any requests, although the code handling the client request could use a default value (version 1) if the version header is omitted. The following examples use a custom header named Custom-Header. The value of this header indicates the version of web API.\n\nAs with the previous two approaches, implementing HATEOAS requires including the appropriate custom header in any links.\n\nWhen a client application sends an HTTP GET request to a web server it should stipulate the format of the content that it can handle by using an Accept header, as described earlier in this guidance. Frequently the purpose of the Accept header is to allow the client application to specify whether the body of the response should be XML, JSON, or some other common format that the client can parse. However, it is possible to define custom media types that include information enabling the client application to indicate which version of a resource it is expecting.\n\nThe following example shows a request that specifies an Accept header with the value application/vnd.adventure-works.v1+json. The vnd.adventure-works.v1 element indicates to the web server that it should return version 1 of the resource, while the json element specifies that the format of the response body should be JSON:\n\nThe code handling the request is responsible for processing the Accept header and honoring it as far as possible (the client application may specify multiple formats in the Accept header, in which case the web server can choose the most appropriate format for the response body). The web server confirms the format of the data in the response body by using the Content-Type header:\n\nIf the Accept header does not specify any known media types, the web server could generate an HTTP 406 (Not Acceptable) response message or return a message with a default media type.\n\nThis approach is arguably the purest of the versioning mechanisms and lends itself naturally to HATEOAS, which can include the MIME type of related data in resource links.\n\nThe Open API Initiative was created by an industry consortium to standardize REST API descriptions across vendors. As part of this initiative, the Swagger 2.0 specification was renamed the OpenAPI Specification (OAS) and brought under the Open API Initiative.\n\nYou might want to adopt OpenAPI for your web APIs. Some points to consider:\n• None The OpenAPI Specification comes with a set of opinionated guidelines on how a REST API should be designed. That has advantages for interoperability, but requires more care when designing your API to conform to the specification.\n• None OpenAPI promotes a contract-first approach, rather than an implementation-first approach. Contract-first means you design the API contract (the interface) first and then write code that implements the contract.\n• None Tools like Swagger can generate client libraries or documentation from API contracts. For example, see ASP.NET Web API help pages using Swagger.\n• None Web API checklist. A useful list of items to consider when designing and implementing a web API."
    }
]