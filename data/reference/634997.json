[
    {
        "link": "https://learn.microsoft.com/en-us/azure/devops/pipelines/process/set-variables-scripts?view=azure-devops",
        "document": "When you use PowerShell and Bash scripts in your pipelines, it's often useful to be able to set variables that you can then use in future tasks. Newly set variables aren't available in the same task.\n\nScripts are great for when you want to do something not supported by a task. For example, you can use a script to call a custom REST API and parse the response.\n\nYou use the logging command to set variables in PowerShell and Bash scripts.\n\nTo use a variable with a condition in a pipeline, see Specify conditions.\n\nWhen you add a variable with , the following tasks can use the variable using macro syntax . The variable is only available to tasks in the same job by default. If you add the parameter , the syntax to call your variable changes. For more information, see Set an output variable for use in the same job.\n\nThe command includes properties for setting a variable as secret, as an output variable, and as read only. The available properties include:\n\nTo use the variable in the next stage, set the property to . To reference a variable with the set to true, you include the task name. For example, .\n\nWhen you set a variable as read only, downstream tasks can't overwrite it. Set to . Setting a variable as read only enhances security by making that variable immutable.\n\nWhen is set to true, the value of the variable will be saved as secret and masked out from logs.\n\nThere are four different types of output variables with distinct syntaxes:\n• Output variables set in the same job without the parameter. To reference these variables, you use macro syntax. Example: .\n• Output variables set in the same job with the parameter. To reference these variables, you include the task name. Example: .\n• Output variables set in a future job. To reference these variables, you reference the variable in the section with syntax.\n• Output variables set in future stages. To reference these variables, you reference the variable in the section with syntax.\n\nThe name of an output variable may change if your pipeline uses an execution strategy like a matrix job. For those cases, output your variable for testing first to verify its name. You can also print out all available variables in a pipeline with the script .\n\nSet an output variable for use in the same job\n\nWhen you use an output variable in the same job, you don't have to use the property. By default, the variable is available to downstream steps within the same job. However, if you do add the property, you need to reference the variable with the task name.\n\nSet an output variable for use in future jobs\n\nWhen you use output variables across jobs, you reference them with . The syntax for accessing an output variable in a future job or stage varies based on the relationship between the setter and consumer of the variable. Learn about each case in dependencies.\n\nSet an output variable for use in future stages\n\nOutput variables can be used across stages in pipelines. You can use output variables to pass useful information, such as the ID of a generated output, from one stage to the next.\n\nWhen you set a variable with the property, you can reference that variable in later stages with the task name and the syntax. Learn more about dependencies.\n\nOutput variables are only available in the next downstream stage. If multiple stages consume the same output variable, use the condition.\n\nIn case your value contains newlines, you can escape them and the agent automatically unescapes it:\n\nMy output variable isn't rendering. What is going wrong?\n\nThere are a few reasons why your output variable might not appear.\n• Output variables set with aren't available in the same job and instead are only available in downstream jobs.\n• Depending on what variable syntax you use, a variable that sets an output variable's value might not be available at runtime. For example, variables with macro syntax ( ) get processed before a task runs. In contrast, variables with template syntax are processed at runtime ( ). You usually want to use runtime syntax when setting output variables. For more information on variable syntax, see Define variables.\n• There might be extra spaces within your expression. If your variable isn't rendering, check for extra spaces surrounding .\n\nYou can troubleshoot the output for a pipeline job or stage by adding a variable for the dependencies and then printing that variable. For example, in this pipeline job sets the output variable . The second job ( ) depends on job . A new variable, holds the JSON representation of the job dependencies. The second step in Job uses PowerShell to print so that you can see the job dependencies."
    },
    {
        "link": "https://learn.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops",
        "document": "Variables give you a convenient way to get key bits of data into various parts of the pipeline. The most common use of variables is to define a value that you can then use in your pipeline. All variables are strings and are mutable. The value of a variable can change from run to run or job to job of your pipeline.\n\nWhen you define the same variable in multiple places with the same name, the most locally scoped variable takes precedence. So, a variable defined at the job level can override a variable set at the stage level. A variable defined at the stage level overrides a variable set at the pipeline root level. A variable set in the pipeline root level overrides a variable set in the Pipeline settings UI. To learn more how to work with variables defined at the job, stage, and root level, see Variable scope.\n\nYou can use variables with expressions to conditionally assign values and further customize pipelines.\n\nWhen you define a variable, you can use different syntaxes (macro, template expression, or runtime) and what syntax you use determines where in the pipeline your variable renders.\n\nIn YAML pipelines, you can set variables at the root, stage, and job level. You can also specify variables outside of a YAML pipeline in the UI. When you set a variable in the UI, that variable can be encrypted and set as secret.\n\nUser-defined variables can be set as read-only. There are naming restrictions for variables (example: you can't use at the start of a variable name).\n\nYou can use a variable group to make variables available across multiple pipelines.\n\nUse templates to define variables in one file that are used in multiple pipelines.\n\nAzure DevOps supports multi-line variables but there are a few limitations.\n\nDownstream components such as pipeline tasks might not handle the variable values correctly.\n\nAzure DevOps won't alter user-defined variable values. Variable values need to be formatted correctly before being passed as multi-line variables. When formatting your variable, avoid special characters, don't use restricted names, and make sure you use a line ending format that works for the operating system of your agent.\n\nMulti-line variables behave differently depending on the operating system. To avoid this, make sure that you format multi-line variables correctly for the target operating system.\n\nAzure DevOps never alters variable values, even if you provide unsupported formatting.\n\nIn addition to user-defined variables, Azure Pipelines has system variables with predefined values. For example, the predefined variable Build.BuildId gives the ID of each build and can be used to identify different pipeline runs. You can use the variable in scripts or tasks when you need to a unique value.\n\nIf you're using YAML or classic build pipelines, see predefined variables for a comprehensive list of system variables.\n\nIf you're using classic release pipelines, see release variables.\n\nSystem variables get set with their current value when you run the pipeline. Some variables are set automatically. As a pipeline author or end user, you change the value of a system variable before the pipeline runs.\n\nEnvironment variables are specific to the operating system you're using. They're injected into a pipeline in platform-specific ways. The format corresponds to how environment variables get formatted for your specific scripting platform.\n\nOn UNIX systems (macOS and Linux), environment variables have the format . On Windows, the format is for batch and in PowerShell.\n\nSystem and user-defined variables also get injected as environment variables for your platform. When variables convert into environment variables, variable names become uppercase, and periods turn into underscores. For example, the variable name becomes the variable name .\n\nThere are variable naming restrictions for environment variables (example: you can't use at the start of a variable name).\n\nUser-defined and environment variables can consist of letters, numbers, , and characters. Don't use variable prefixes reserved by the system. These are: , , , , and . Any variable that begins with one of these strings (regardless of capitalization) won't be available to your tasks and scripts.\n\nAzure Pipelines supports three different ways to reference variables: macro, template expression, and runtime expression. You can use each syntax for a different purpose and each have some limitations.\n\nIn a pipeline, template expression variables ( ) get processed at compile time, before runtime starts. Macro syntax variables ( ) get processed during runtime before a task runs. Runtime expressions ( ) also get processed during runtime but are intended to be used with conditions and expressions. When you use a runtime expression, it must take up the entire right side of a definition.\n\nIn this example, you can see that the template expression still has the initial value of the variable after the variable is updated. The value of the macro syntax variable updates. The template expression value doesn't change because all template expression variables get processed at compile time before tasks run. In contrast, macro syntax variables evaluate before each task runs.\n\nMost documentation examples use macro syntax ( ). Macro syntax is designed to interpolate variable values into task inputs and into other variables.\n\nVariables with macro syntax get processed before a task executes during runtime. Runtime happens after template expansion. When the system encounters a macro expression, it replaces the expression with the contents of the variable. If there's no variable by that name, then the macro expression doesn't change. For example, if can't be replaced, won't be replaced by anything.\n\nMacro syntax variables remain unchanged with no value because an empty value like might mean something to the task you're running and the agent shouldn't assume you want that value replaced. For example, if you use to reference variable in a Bash task, replacing all expressions in the input to the task could break your Bash scripts.\n\nMacro variables are only expanded when they're used for a value, not as a keyword. Values appear on the right side of a pipeline definition. The following is valid: . The following isn't valid: . Macro variables aren't expanded when used to display a job name inline. Instead, you must use the property.\n\nThis example uses macro syntax with Bash, PowerShell, and a script task. The syntax for calling a variable with macro syntax is the same for all three.\n\nYou can use template expression syntax to expand both template parameters and variables ( ). Template variables process at compile time, and get replaced before runtime starts. Template expressions are designed for reusing parts of YAML as templates.\n\nTemplate variables silently coalesce to empty strings when a replacement value isn't found. Template expressions, unlike macro and runtime expressions, can appear as either keys (left side) or values (right side). The following is valid: .\n\nYou can use runtime expression syntax for variables that are expanded at runtime ( ). Runtime expression variables silently coalesce to empty strings when a replacement value isn't found. Use runtime expressions in job conditions, to support conditional execution of jobs, or whole stages.\n\nRuntime expression variables are only expanded when they're used for a value, not as a keyword. Values appear on the right side of a pipeline definition. The following is valid: . The following isn't valid: . The runtime expression must take up the entire right side of a key-value pair. For example, is valid but isn't.\n\nWhat syntax should I use?\n\nUse macro syntax if you're providing a secure string or a predefined variable input for a task.\n\nChoose a runtime expression if you're working with conditions and expressions. However, don't use a runtime expression if you don't want your empty variable to print (example: ). For example, if you have conditional logic that relies on a variable having a specific value or no value. In that case, you should use a macro expression.\n\nTypically a template variable is the standard to use. By leveraging template variables, your pipeline will fully inject the variable value into your pipeline at pipeline compilation. This is helpful when attempting to debug pipelines. You can download the log files and evaluate the fully expanded value that is being substituted in. Since the variable is substituted in, you shouldn't leverage template syntax for sensitive values.\n\nIn the most common case, you set the variables and use them within the YAML file. This allows you to track changes to the variable in your version control system. You can also define variables in the pipeline settings UI (see the Classic tab) and reference them in your YAML. Here's an example that shows how to set two variables, and , and use them later in steps. To use a variable in a YAML statement, wrap it in . Variables can't be used to define a in a YAML statement. # Set variables once variables: configuration: debug platform: x64 steps: # Use them once - task: MSBuild@1 inputs: solution: solution1.sln configuration: $(configuration) # Use the variable platform: $(platform) # Use them again - task: MSBuild@1 inputs: solution: solution2.sln configuration: $(configuration) # Use the variable platform: $(platform) In the YAML file, you can set a variable at various scopes:\n• At the root level, to make it available to all jobs in the pipeline.\n• At the stage level, to make it available only to a specific stage.\n• At the job level, to make it available only to a specific job. When you define a variable at the top of a YAML, the variable is available to all jobs and stages in the pipeline and is a global variable. Global variables defined in a YAML aren't visible in the pipeline settings UI. Variables at the job level override variables at the root and stage level. Variables at the stage level override variables at the root level. variables: global_variable: value # this is available to all jobs jobs: - job: job1 pool: vmImage: 'ubuntu-latest' variables: job_variable1: value1 # this is only available in job1 steps: - bash: echo $(global_variable) - bash: echo $(job_variable1) - bash: echo $JOB_VARIABLE1 # variables are available in the script environment too - job: job2 pool: vmImage: 'ubuntu-latest' variables: job_variable2: value2 # this is only available in job2 steps: - bash: echo $(global_variable) - bash: echo $(job_variable2) - bash: echo $GLOBAL_VARIABLE The output from both jobs looks like this: # job1 value value1 value1 # job2 value value2 value In the preceding examples, the keyword is followed by a list of key-value pairs. The keys are the variable names and the values are the variable values. There's another syntax, useful when you want to use templates for variables or variable groups. With templates, variables can be defined in one YAML and included in another YAML file. Variable groups are a set of variables that you can use across multiple pipelines. They allow you to manage and organize variables that are common to various stages in one place. Use this syntax for variable templates and variable groups at the root level of a pipeline. In this alternate syntax, the keyword takes a list of variable specifiers. The variable specifiers are for a regular variable, for a variable group, and to include a variable template. The following example demonstrates all three. variables: # a regular variable - name: myvariable value: myvalue # a variable group - group: myvariablegroup # a reference to a variable template - template: myvariabletemplate.yml Learn more about variable reuse with templates. Notice that variables are also made available to scripts through environment variables. The syntax for using these environment variables depends on the scripting language. The name is upper-cased, and the is replaced with the . This is automatically inserted into the process environment. Here are some examples: Predefined variables that contain file paths are translated to the appropriate styling (Windows style C:\\foo\\ versus Unix style /foo/) based on agent host type and shell type. If you are running bash script tasks on Windows, you should use the environment variable method for accessing these variables rather than the pipeline variable method to ensure you have the correct file path styling. You can set a variable for a build pipeline by following these steps:\n• Go to the Pipelines page, select the appropriate pipeline, and then select Edit.\n• Locate the Variables for this pipeline.\n• To mark the variable as secret, select Keep this value secret. After setting the variable, you can use it as an input to a task or within the scripts in your pipeline. To use a variable as an input to a task, wrap it in . Notice that variables are also made available to scripts through environment variables. The syntax for using these environment variables depends on the scripting language. The name is upper-cased, and the is replaced with the . This is automatically inserted into the process environment. Here are some examples: Predefined variables that contain file paths are translated to the appropriate styling (Windows style C:\\foo\\ versus Unix style /foo/) based on agent host type and shell type. If you are running bash script tasks on Windows, you should use the environment variable method for accessing these variables rather than the pipeline variable method to ensure you have the correct file path styling. Using the Azure DevOps CLI, you can create and update variables for the pipeline runs in your project. You can also delete the variables if you no longer need them.\n• You've installed the Azure DevOps CLI extension as described in Get started with Azure DevOps CLI.\n• For the examples in this article, set the default organization using . You can create variables in your pipeline with the az pipelines variable create command. To get started, see Get started with Azure DevOps CLI.\n• name: Required. Name of the variable.\n• allow-override: Optional. Indicates whether the value can be set at queue time. Accepted values are false and true.\n• org: Azure DevOps organization URL. You can configure the default organization using . Required if not configured as default or picked up using . Example: .\n• pipeline-id: Required if pipeline-name isn't supplied. ID of the pipeline.\n• pipeline-name: Required if pipeline-id isn't supplied, but ignored if pipeline-id is supplied. Name of the pipeline.\n• project: Name or ID of the project. You can configure the default project using . Required if not configured as default or picked up using .\n• secret: Optional. Indicates whether the variable's value is a secret. Accepted values are false and true.\n• value: Required for non-secret variable. Value of the variable. For secret variables, if value parameter isn't provided, it's picked from environment variable prefixed with or user is prompted to enter it via standard input. For example, a variable named MySecret can be input using the environment variable . The following command creates a variable in MyFirstProject named Configuration with the value platform in the pipeline with ID 12. It shows the result in table format. az pipelines variable create --name Configuration --pipeline-id 12 --value platform --project MyFirstProject --output table Name Allow Override Is Secret Value ---------- ---------------- ----------- -------- Configuration False False platform You can update variables in your pipeline with the az pipelines variable update command. To get started, see Get started with Azure DevOps CLI.\n• name: Required. Original name of the variable.\n• allow-override: Optional. Indicates whether the value can be set at queue time. Accepted values are false and true.\n• new-name: Optional. Specify to change the name of the variable.\n• org: Azure DevOps organization URL. You can configure the default organization using . Required if not configured as default or picked up using . Example: .\n• pipeline-id: Required if pipeline-name isn't supplied. ID of the pipeline.\n• pipeline-name: Required if pipeline-id isn't supplied, but ignored if pipeline-id is supplied. Name of the pipeline.\n• project: Name or ID of the project. You can configure the default project using . Required if not configured as default or picked up using .\n• prompt-value: Set to true to update the value of a secret variable using environment variable or prompt via standard input. Accepted values are false and true.\n• secret: Indicates whether the variable's value is a secret. Accepted values are false and true.\n• value: Updates the value of the variable. For secret variables, use the prompt-value parameter to be prompted to enter it via standard input. For non-interactive consoles, it can be picked from environment variable prefixed with . For example, a variable named MySecret can be input using the environment variable . The following command updates the Configuration variable with the new value config.debug in the pipeline with ID 12. It specifies that the variable isn't a secret and shows the result in table format. az pipelines variable update --name Configuration --pipeline-id 12 --secret false --value config.debug --output table Name Allow Override Is Secret Value ------------- ---------------- ----------- ------------ Configuration False False config.debug You can delete variables in your pipeline with the az pipelines variable delete command. To get started, see Get started with Azure DevOps CLI.\n• name: Required. Name of the variable you want to delete.\n• org: Azure DevOps organization URL. You can configure the default organization using . Required if not configured as default or picked up using . Example: .\n• pipeline-id: Required if pipeline-name isn't supplied. ID of the pipeline.\n• pipeline-name: Required if pipeline-id isn't supplied, but ignored if pipeline-id is supplied. Name of the pipeline.\n• project: Name or ID of the project. You can configure the default project using . Required if not configured as default or picked up using . The following command deletes the Configuration variable from the pipeline with ID 12 and doesn't prompt for confirmation.\n\nDon't set secret variables in your YAML file. Operating systems often log commands for the processes that they run, and you wouldn't want the log to include a secret that you passed in as an input. Use the script's environment or map the variable within the block to pass secrets to your pipeline. Azure Pipelines makes an effort to mask secrets when emitting data to pipeline logs, so you may see additional variables and data masked in output and logs that are not set as secrets. You need to set secret variables in the pipeline settings UI for your pipeline. These variables are scoped to the pipeline where they're set. You can also set secret variables in variable groups. To set secrets in the web interface, follow these steps:\n• Go to the Pipelines page, select the appropriate pipeline, and then select Edit.\n• Locate the Variables for this pipeline.\n• Select the option to Keep this value secret to store the variable in an encrypted manner. Secret variables are encrypted at rest with a 2048-bit RSA key. Secrets are available on the agent for tasks and scripts to use. Be careful about who has access to alter your pipeline. We make an effort to mask secrets from appearing in Azure Pipelines output, but you still need to take precautions. Never echo secrets as output. Some operating systems log command line arguments. Never pass secrets on the command line. Instead, we suggest that you map your secrets into environment variables. We never mask substrings of secrets. If, for example, \"abc123\" is set as a secret, \"abc\" isn't masked from the logs. This is to avoid masking secrets at too granular of a level, making the logs unreadable. For this reason, secrets should not contain structured data. If, for example, \"{ \"foo\": \"bar\" }\" is set as a secret, \"bar\" isn't masked from the logs. Unlike a normal variable, they are not automatically decrypted into environment variables for scripts. You need to explicitly map secret variables. The following example shows how to map and use a secret variable called in PowerShell and Bash scripts. Two global variables are defined. is assigned the value of a secret variable , and is assigned the value of a non-secret variable . Unlike a normal pipeline variable, there's no environment variable called . The PowerShell task runs a script to print the variables.\n• : This is a direct reference to the secret variable and works.\n• : This attempts to access the secret variable as an environment variable, which does not work because secret variables are not automatically mapped to environment variables.\n• : This attempts to access the secret variable through a global variable, which also does not work because secret variables cannot be mapped this way.\n• : This accesses the non-secret variable through a global variable, which works.\n• : This accesses the secret variable through a task-specific environment variable, which is the recommended way to map secret variables to environment variables. variables: GLOBAL_MYSECRET: $(mySecret) # this will not work because the secret variable needs to be mapped as env GLOBAL_MY_MAPPED_ENV_VAR: $(nonSecretVariable) # this works because it's not a secret. steps: - powershell: | Write-Host \"Using an input-macro works: $(mySecret)\" Write-Host \"Using the env var directly does not work: $env:MYSECRET\" Write-Host \"Using a global secret var mapped in the pipeline does not work either: $env:GLOBAL_MYSECRET\" Write-Host \"Using a global non-secret var mapped in the pipeline works: $env:GLOBAL_MY_MAPPED_ENV_VAR\" Write-Host \"Using the mapped env var for this task works and is recommended: $env:MY_MAPPED_ENV_VAR\" env: MY_MAPPED_ENV_VAR: $(mySecret) # the recommended way to map to an env variable - bash: | echo \"Using an input-macro works: $(mySecret)\" echo \"Using the env var directly does not work: $MYSECRET\" echo \"Using a global secret var mapped in the pipeline does not work either: $GLOBAL_MYSECRET\" echo \"Using a global non-secret var mapped in the pipeline works: $GLOBAL_MY_MAPPED_ENV_VAR\" echo \"Using the mapped env var for this task works and is recommended: $MY_MAPPED_ENV_VAR\" env: MY_MAPPED_ENV_VAR: $(mySecret) # the recommended way to map to an env variable The output from both tasks in the preceding script would look like this: Using an input-macro works: *** Using the env var directly does not work: Using a global secret var mapped in the pipeline does not work either: Using a global non-secret var mapped in the pipeline works: foo Using the mapped env var for this task works and is recommended: *** You can also use secret variables outside of scripts. For example, you can map secret variables to tasks using the definition. This example shows how to use secret variables and in an Azure file copy task. This example shows how to reference a variable group in your YAML file, and also how to add variables within the YAML. There are two variables used from the variable group: and . The variable is secret, and is mapped to the environment variable so that it can be referenced in the YAML. This YAML makes a REST call to retrieve a list of releases, and outputs the result. variables: - group: 'my-var-group' # variable group - name: 'devopsAccount' # new variable defined in YAML value: 'contoso' - name: 'projectName' # new variable defined in YAML value: 'contosoads' steps: - task: PowerShell@2 inputs: targetType: 'inline' script: | # Encode the Personal Access Token (PAT) # $env:USER is a normal variable in the variable group # $env:MY_MAPPED_TOKEN is a mapped secret variable $base64AuthInfo = [Convert]::ToBase64String([Text.Encoding]::ASCII.GetBytes((\"{0}:{1}\" -f $env:USER,$env:MY_MAPPED_TOKEN))) # Get a list of releases $uri = \"https://vsrm.dev.azure.com/$(devopsAccount)/$(projectName)/_apis/release/releases?api-version=5.1\" # Invoke the REST call $result = Invoke-RestMethod -Uri $uri -Method Get -ContentType \"application/json\" -Headers @{Authorization=(\"Basic {0}\" -f $base64AuthInfo)} # Output releases in JSON Write-Host $result.value env: MY_MAPPED_TOKEN: $(token) # Maps the secret variable $(token) from my-var-group By default with GitHub repositories, secret variables associated with your pipeline aren't made available to pull request builds of forks. For more information, see Contributions from forks. To set secrets in the web interface, follow these steps:\n• Go to the Pipelines page, select the appropriate pipeline, and then select Edit.\n• Locate the Variables for this pipeline.\n• Select the option to Keep this value secret to store the variable in an encrypted manner. Secret variables are encrypted at rest with a 2048-bit RSA key. Secrets are available on the agent for tasks and scripts to use. Be careful about who has access to alter your pipeline. We make an effort to mask secrets from appearing in Azure Pipelines output, but you still need to take precautions. Never echo secrets as output. Some operating systems log command line arguments. Never pass secrets on the command line. Instead, we suggest that you map your secrets into environment variables. We never mask substrings of secrets. If, for example, \"abc123\" is set as a secret, \"abc\" isn't masked from the logs. This is to avoid masking secrets at too granular of a level, making the logs unreadable. For this reason, secrets should not contain structured data. If, for example, \"{ \"foo\": \"bar\" }\" is set as a secret, \"bar\" isn't masked from the logs. Unlike a normal variable, they are not automatically decrypted into environment variables for scripts. You need to explicitly map secret variables. Each task that needs to use the secret as an environment variable does remapping. If you want to use a secret variable called from a script, use the section of the scripting task's input variables. Set the environment variable name to , and set the value to . By default with GitHub repositories, secret variables associated with your pipeline aren't made available to pull request builds of forks. For more information, see Contributions from forks. To set secret variables using the Azure DevOps CLI, see Create a variable or Update a variable.\n\nTo share variables across multiple pipelines in your project, use the web interface. Under Library, use variable groups.\n• To reference a variable from a different task within the same job, use .\n• To reference a variable from a task from a different job, use .\n\nScripts can define variables that are later consumed in subsequent steps in the pipeline. All variables set by this method are treated as strings. To set a variable from a script, you use a command syntax and print to stdout.\n\nTo set a variable from a script, you use the logging command. This updates the environment variables for subsequent jobs. Subsequent jobs have access to the new variable with macro syntax and in tasks as environment variables. When is true, the value of the variable will be saved as secret and masked from the log. For more information on secret variables, see logging commands. steps: # Create a variable - bash: | echo \"##vso[task.setvariable variable=sauce]crushed tomatoes\" # remember to use double quotes # Use the variable # \"$(sauce)\" is replaced by the contents of the `sauce` variable by Azure Pipelines # before handing the body of the script to the shell. - bash: | echo my pipeline variable is $(sauce) Subsequent steps will also have the pipeline variable added to their environment. You can't use the variable in the step that it's defined. steps: # Create a variable # Note that this does not update the environment of the current script. - bash: | echo \"##vso[task.setvariable variable=sauce]crushed tomatoes\" # An environment variable called `SAUCE` has been added to all downstream steps - bash: | echo \"my environment variable is $SAUCE\" - pwsh: | Write-Host \"my environment variable is $env:SAUCE\" The output from the preceding pipeline. my environment variable is crushed tomatoes my environment variable is crushed tomatoes If you want to make a variable available to future jobs, you must mark it as an output variable by using . Then you can map it into future jobs by using the syntax and including the step name that set the variable. Multi-job output variables only work for jobs in the same stage. To pass variables to jobs in different stages, use the stage dependencies syntax. By default, each stage in a pipeline depends on the one just before it in the YAML file. Therefore, each stage can use output variables from the prior stage. To access further stages, you will need to alter the dependency graph, for instance, if stage 3 requires a variable from stage 1, you will need to declare an explicit dependency on stage 1. When you create a multi-job output variable, you should assign the expression to a variable. In this YAML, is assigned to the variable . jobs: # Set an output variable from job A - job: A pool: vmImage: 'windows-latest' steps: - powershell: echo \"##vso[task.setvariable variable=myOutputVar;isOutput=true]this is the value\" name: setvarStep - script: echo $(setvarStep.myOutputVar) name: echovar # Map the variable into job B - job: B dependsOn: A pool: vmImage: 'ubuntu-latest' variables: myVarFromJobA: $[ dependencies.A.outputs['setvarStep.myOutputVar'] ] # map in the variable # remember, expressions require single quotes steps: - script: echo $(myVarFromJobA) name: echovar The output from the preceding pipeline. this is the value this is the value If you're setting a variable from one stage to another, use . If you're setting a variable from a matrix or slice, then to reference the variable when you access it from a downstream job, you must include:\n• The name of the job. jobs: # Set an output variable from a job with a matrix - job: A pool: vmImage: 'ubuntu-latest' strategy: maxParallel: 2 matrix: debugJob: configuration: debug platform: x64 releaseJob: configuration: release platform: x64 steps: - bash: echo \"##vso[task.setvariable variable=myOutputVar;isOutput=true]this is the $(configuration) value\" name: setvarStep - bash: echo $(setvarStep.myOutputVar) name: echovar # Map the variable from the debug job - job: B dependsOn: A pool: vmImage: 'ubuntu-latest' variables: myVarFromJobADebug: $[ dependencies.A.outputs['debugJob.setvarStep.myOutputVar'] ] steps: - script: echo $(myVarFromJobADebug) name: echovar jobs: # Set an output variable from a job with slicing - job: A pool: vmImage: 'ubuntu-latest' parallel: 2 # Two slices steps: - bash: echo \"##vso[task.setvariable variable=myOutputVar;isOutput=true]this is the slice $(system.jobPositionInPhase) value\" name: setvarStep - script: echo $(setvarStep.myOutputVar) name: echovar # Map the variable from the job for the first slice - job: B dependsOn: A pool: vmImage: 'ubuntu-latest' variables: myVarFromJobsA1: $[ dependencies.A.outputs['job1.setvarStep.myOutputVar'] ] steps: - script: \"echo $(myVarFromJobsA1)\" name: echovar Be sure to prefix the job name to the output variables of a deployment job. In this case, the job name is : jobs: # Set an output variable from a deployment - deployment: A pool: vmImage: 'ubuntu-latest' environment: staging strategy: runOnce: deploy: steps: - bash: echo \"##vso[task.setvariable variable=myOutputVar;isOutput=true]this is the deployment variable value\" name: setvarStep - bash: echo $(setvarStep.myOutputVar) name: echovar # Map the variable from the job for the first slice - job: B dependsOn: A pool: vmImage: 'ubuntu-latest' variables: myVarFromDeploymentJob: $[ dependencies.A.outputs['A.setvarStep.myOutputVar'] ] steps: - bash: \"echo $(myVarFromDeploymentJob)\" name: echovar To set a variable from a script, use the logging command. This doesn't update the environment variables, but it does make the new variable available to downstream steps within the same job. You can run a script on a:\n• Windows agent using either a Batch script task or PowerShell script task. @echo off set sauceArgument=%~1 set secretSauceArgument=%~2 @echo No problem reading %sauceArgument% or %SAUCE% @echo But I cannot read %SECRET_SAUCE% @echo But I can read %secretSauceArgument% (but the log is redacted so I do not spoil the secret) Param( [string]$sauceArgument, [string]$secretSauceArgument ) Write-Host No problem reading $env:SAUCE or $sauceArgument Write-Host But I cannot read $env:SECRET_SAUCE Write-Host But I can read $secretSauceArgument \"(but the log is redacted so I do not spoil the secret)\" #!/bin/bash echo \"No problem reading $1 or $SAUCE\" echo \"But I cannot read $SECRET_SAUCE\" echo \"But I can read $2 (but the log is redacted so I do not spoil the secret)\" No problem reading crushed tomatoes or crushed tomatoes But I cannot read But I can read ******** (but the log is redacted so I do not spoil the secret) In order to use a variable as a task input, you must make the variable an output variable, and you must give the producing task a reference name. You can set a task's reference name on the Output Variables section of the task editor. For instance, a script task whose output variable reference name is might have the following contents: The output variable can be referenced in the input of a downstream task as . You can't pass a variable from one job to another job of a build pipeline, unless you use YAML. There's no az pipelines command that applies to setting variables in scripts."
    },
    {
        "link": "https://stackoverflow.com/questions/52333871/azure-devops-setting-and-using-variables-in-powershell-scripts",
        "document": "I have an Azure DevOps build pipeline that has two separate PowerShell scripts. In the first script, I am getting a value from an XML file and setting that value in an environment variable. In my second script, I want to use the value in the environment variable. Unfortunately, I don't see the environment variable getting set. At this time, I have:\n\nNotice: 1) The value is not printing in the \"Set environment variable\" statement and 2) The value is NOT listed in the environment variable list. My intention is to use in the second script, which looks like this:\n\nAt this time, the script just shows:\n\nI've seen the other related SO questions and reviewed the docs. However, this simply isn't working. I don't understand what I'm doing wrong. Can someone please show me how to fix this and explain what I'm doing wrong? Thank you!"
    },
    {
        "link": "https://learn.microsoft.com/en-us/azure/devops/pipelines/scripts/powershell?view=azure-devops",
        "document": "This article explains how you can move beyond compiling and testing code and use PowerShell scripts to add business logic to pipelines. The Azure Pipelines PowerShell task runs PowerShell scripts in your pipelines. You can use PowerShell to access the Azure DevOps REST API, work with Azure DevOps work items and test management, or call other services as needed.\n\nYou can use variables in your PowerShell scripts, including user-defined variables that you set yourself. You can also use predefined variables that are available in all Azure Pipelines, and set multi-job output variables to make variables available to future jobs. For more information, see Define variables.\n\nYou can use named parameters in your PowerShell scripts. Other kinds of parameters, such as switch parameters, aren't supported and cause errors if you try to use them. For more information, see How to declare cmdlet parameters.\n\nThe build uses the active branch of your code. If your pipeline run uses the branch, your script also uses the branch.\n\nYou can run Windows PowerShell on a Windows build agent, or run PowerShell Core on any platform. The syntax for including PowerShell Core is slightly different than for Windows PowerShell. After you push your PowerShell script to your repo, add a or step to your pipeline. The keyword and keywords are both shortcuts to run the PowerShell task. Add the PowerShell Script task to your pipeline, and add your script file to the Script Path. The same PowerShell task works for both PowerShell Core and Windows PowerShell.\n\nExample script to apply version to assemblies\n\nThe example script in this section applies a version to assembly property files. For the script to run successfully, the defined build number format must have four periods, for example .\n\nThe following PowerShell example script applies a version to assemblies. For example, if your defined build number format produces build number , the script applies version to your assemblies.\n\nExample script to access the REST API\n\nThis example uses the variable to access the Azure Pipelines REST API."
    },
    {
        "link": "https://medium.com/microsoftazure/how-to-pass-variables-in-azure-pipelines-yaml-tasks-5c81c5d31763",
        "document": "How to pass variables in Azure Pipelines YAML tasks\n\nThis is a quick reference on passing variables between multiple tasks in Azure Pipelines, a popular CI/CD platform. They have recently enabled support for multi-stage pipelines defined in YAML documents, allowing the creation of both build and release (CI and CD) pipelines, in a single file. This is very powerful, as it lets developers define their pipelines to continuously build and deploy apps, using a declarative syntax, and storing the YAML document in the same repo as their code, versioned.\n\nOne recurrent question is: how do you pass variables around tasks? While passing variables from a step to another within the same job is relatively easy, sharing state and variables with tasks in other jobs or even stages isn’t immediate.\n\nThe examples below are about using multi-stage pipelines within YAML documents. I’ll focus on pipelines running on Linux, and all examples show bash scripts. The same concepts would apply to developers working with PowerShell or Batch scripts, although the syntax of the commands will be slightly different. The work below is based on the official documentation, adding some examples and explaining how to pass variables between stages.\n\nPassing variables between tasks in the same job\n\nThis is the easiest one. In a script task, you need to print a special value to STDOUT that will be captured by Azure Pipelines to set the variable.\n\nFor example, to pass the variable between scripts:\n• Set the value with the command\n• In subsequent tasks, you can use the syntax to have Azure Pipelines replace the variable with\n• Alternatively, in the following scripts tasks, is also set as environmental variable and can be accessed as\n\nYou can also use the syntax inside task definitions. For example, these steps copy files to a folder whose name is defined as variable:\n\nPassing variables between jobs in the same stage is a bit more complex, as it requires working with output variables.\n\nSimilarly to the example above, to pass the variable:\n• Make sure you give a name to the job, for example\n• Likewise, make sure you give a name to the step as well, for example:\n• Set the variable with the same command as before, but adding , like:\n• In the second job, define a variable at the job level, giving it the value (remember to use single quotes for expressions)\n\nAt this time, it’s not possible to pass variables between different stages. There is, however, a workaround that involves writing the variable to disk and then passing it as a file, leveraging pipeline artifacts.\n\nTo pass the variable from a job to another one in a different stage:\n• Create a folder that will contain all variables you want to pass; any folder could work, but something like might be a good idea.\n• Write the contents of the variable to a file, for example . Even though the name could be anything you'd like, giving the file the same name as the variable might be a good idea.\n• In the second stage, download the pipeline artifact\n• Read each file into a variable, for example\n• Expose the variable in the current job, just like we did in the first example:\n• You can then access the variable by expanding it within Azure Pipelines ( ) or use it as an environmental variable inside a bash script ( ).\n\nstages:\n\n\n\n - stage: firststage\n\n jobs:\n\n\n\n - job: firstjob\n\n pool:\n\n vmImage: 'Ubuntu-16.04'\n\n steps:\n\n\n\n # To pass the variable FOO, write it to a file\n\n # While the file name doesn't matter, naming it like the variable and putting it inside the $(Pipeline.Workspace)/variables folder could be a good pattern\n\n - bash: |\n\n FOO=\"some value\"\n\n mkdir -p $(Pipeline.Workspace)/variables\n\n echo \"$FOO\" > $(Pipeline.Workspace)/variables/FOO\n\n\n\n # Publish the folder as pipeline artifact\n\n - publish: $(Pipeline.Workspace)/variables\n\n artifact: variables\n\n \n\n - stage: secondstage\n\n jobs:\n\n\n\n - job: secondjob\n\n pool:\n\n vmImage: 'Ubuntu-16.04'\n\n steps:\n\n\n\n # Download the artifacts\n\n - download: current\n\n artifact: variables\n\n\n\n # Read the variable from the file, then expose it in the job\n\n - bash: |\n\n FOO=$(cat $(Pipeline.Workspace)/variables/FOO)\n\n echo \"##vso[task.setvariable variable=FOO]$FOO\"\n\n\n\n # Just like in the first example, we can expand the variable within Azure Pipelines itself\n\n - bash: |\n\n echo \"$(FOO)\"\n\n\n\n # Or we can expand it within bash, reading it as environmental variable\n\n - bash: |\n\n echo \"$FOO\"\n\nHere’s the pipeline running. Note in the second stage how line #14 shows in both bash scripts. However, take a look at the script being executed on line #11: in the first case, the variable was expanded inside Azure Pipelines (so the script became ), while in the second one bash is reading an environmental variable (the script remains ).\n\nIf you want to pass more than one variable, you can create multiple files within the (e.g. for a variable named , write it inside ), then read all the variables in the second stage."
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/maui/deployment/visual-studio-properties?view=net-maui-9.0",
        "document": ".NET MAUI uses a single-project system to manage the configuration of your cross-platform app. Project configuration in .NET MAUI is similar to other projects in Visual Studio, right-click on the project in the Solution Explorer, and select Properties.\n\nThe Application section describes some settings related to which platforms your app targets, as well as the output file and default namespace.\n• Describes some basic settings about your app. Specifies the name of the output file that will hold the assembly manifest. Specifies the base namespace for files added to your project. This generally defaults to the name of your project or a value you specified when you created the project.\n• If you're going to target iOS and macOS (using Mac Catalyst), these settings describe the target iOS version. Specifies that this project will target the iOS platform. The Target Framework Moniker used to target iOS. The minimum version of iOS your app targets.\n• If you're going to target Android, these settings describe the target Android version. When checked, the .NET MAUI project will target and build an Android version of your app. Uncheck to disable the Android target. The Target Framework Moniker used to target Android. The minimum version of Android your app targets.\n• If you're going to target Windows, these settings describe the target Windows version. When checked, the .NET MAUI project will target and build a Windows version of your app. Uncheck to disable the Windows target. The Target Framework Moniker used to target Windows. The minimum version of Windows your app targets.\n\nThe Build section describes settings related to compiling your app.\n• Specifies symbols on which to perform conditional compilation. Separate symbols with a semicolon . Symbols can be broken up into target platforms. For more information, see Conditional compilation.\n• Specifies the processor to be targeted by the output file. Choose to specify that any processor is acceptable, allowing the application to run on the broadest range of hardware. Typically this is set to and the runtime identifier setting is used to target a CPU platform. (Default) Compiles your assembly to run on any platform. Your application runs as a 64-bit process whenever possible and falls back to 32-bit when only that mode is available. Compiles your assembly to be run by the 32-bit, x86-compatible runtime. Compiles your assembly to be run by the 64-bit runtime on a computer that supports the AMD64 or EM64T instruction set. Compiles your assembly to run on a computer that has an Advanced RISC Machine (ARM) processor. Compiles your assembly to run by the 64-bit runtime on a computer that has an Advanced RISC Machine (ARM) processor that supports the A64 instruction set.\n• Specifies the project-wide C# nullable context. For more information, see Nullable References. (Default) If this setting isn't set, the default is . Nullable warnings are disabled. All reference type variables are nullable reference types. The compiler enables all null reference analysis and all language features. The compiler performs all null analysis and emits warnings when code might dereference null. The compiler doesn't perform null analysis or emit warnings when code might dereference null.\n• Enables implicit global usings to be declared by the project SDK. This is enabled by default and imports many of the .NET MAUI namespaces automatically to all code files. Code files don't need to add statements for common .NET MAUI namespaces. For more information, see MSBuild properties - ImplicitUsings.\n• Allow code that uses the keyword to compile. This is disabled by default.\n• Enable compiler optimizations for smaller, faster, and more efficient output. There is an option for each target platform, in Debug or Release mode. Generally, this is enabled for Release mode, as the code is optimized for speed at the expense of helpful debugging information.\n• Specifies the kind of debug symbols produced during build.\n\nSettings related to how errors and warnings are treated and reported during compilation.\n• Specifies the level to display for compiler warnings.\n• Blocks the compiler from generating the specified warnings. Separate multiple warning numbers with a comma or a semicolon .\n• When enabled, instructs the compiler to treat warnings as errors. This is disabled by default.\n• Specifies which warnings are treated as errors. Separate multiple warning numbers with a comma or a semicolon .\n• Specifies the base location for the project's output during build. Subfolders will be appended to this path to differentiate project configuration.\n• Specifies the base location for the project's intermediate output during build. Subfolders will be appended to the path to differentiate project configuration.\n• When enabled, produces a reference assembly containing the public API of the project. This is disabled by default.\n• When enabled, generates a file containing API documentation. This is disabled by default.\n\nIn this section you can add commands that run during the build.\n• Specifies commands that run before the build starts. Does not run if the project is up-to-date. A non-zero exit code will fail the build before it runs.\n• Specifies commands that run before the build starts. Does not run if the project is up-to-date. A non-zero exit code will fail the build before it runs.\n• None When to run the post-build event Specifies under which condition the post-build even will be run.\n• When enabled, signs the output assembly to give it a strong name.\n• The version of the language available to the code in the project. Defaults to .\n• Throw exceptions when integer arithmetic produces out of range values. This setting is available for each platform. The default is disabled for each platform.\n• Produce identical compilation output for identical inputs. This setting is available for each platform. The default is enabled for each platform.\n• Specifies, in bytes, where to align the sections of the output file. This setting is available for each platform. The default is for each platform.\n• When enabled, produces a NuGet package file during build operations. This is disabled by default.\n• The case-insensitive package identifier, which must be unique across the NuGet package gallery, such as nuget.org. IDs may not contain spaces or characters that aren't valid for a URL, and generally follow .NET namespace rules. Defaults to the MSBuild value of .\n• A human-friendly title of the package, typically used in UI displays as on nuget.org and the Package Manager in Visual Studio.\n• The version of the package, following the pattern. Version numbers may include a pre-release suffix. Defaults to the MSBuild value of .\n• A comma-separated list of authors, matching the profile names on nuget.org. These are displayed in the NuGet Gallery on nuget.org and are used to cross-reference packages by the same authors. Defaults to the MSBuild value of .\n• The name of the company associated with the NuGet package. Defaults to the MSBuild value of .\n• The name of the product associated with the NuGet package. Defaults to the MSBuild value of .\n• A description of the package for UI display.\n• A URL for the package's home page, often shown in UI displays as well as nuget.org.\n• The icon image for the package. Image file size is limited to 1 MB. Supported file formats include JPEG and PNG. An image resolution of 128x128 is recommended.\n• The README document for the package. Must be a Markdown (.md) file.\n• Specifies the URL for the repository where the source code for the package resides and/or from which it's being built. For linking to the project page, use the 'Project URL' field, instead.\n• Specifies the type of the repository. Default is 'git'.\n• A semicolon-delimited list of tags and keywords that describe the package and aid discoverability of the packages through search and filtering.\n• A description of the changes made in the release of the package, often used in UI like the Updates tab of the Visual Studio Package Manager in place of the package description.\n• When enabled, packs the project as a special package that contains a console application that may be installed via the \"dotnet tool\" command. This is disabled by default.\n• Determines the output path in which the package will be dropped. Defaults to the MSBuild value of .\n• Which language code is considered the neutral language. Defaults to unset.\n• The version of the assembly, defaults to if not set.\n• The version associated with the file, defaults to if not set.\n• Specify a license fo the project's package. Defaults to .\n• \n• When enabled, creates an additional symbol package when the project is packaged. This is disabled by default.\n• When enabled, runs code analysis on build. Defaults to enabled.\n• When enabled, runs code analysis live in the editor as you type. Defaults to enabled.\n• When enabled, produces diagnostics about code style on build. This is disabled by default.\n• When enabled, runs .NET analyzers to help with API usage. Defaults to enabled.\n• The set of analyzers that should be run in the project. Defaults to . For more information, see MSBuild: AnalysisLevel.\n\nThese are project settings for .NET MAUI that are shared across all target platforms.\n• The display name of the application.\n• The identifier of the application in reverse domain name format, for example: .\n• The identifier of the application in GUID format.\n• The display version of the application. This should be at most a three part version number such as 1.0.0.\n• The version of the application. This should be a single digit integer such as 1.\n• The string that's displayed as the name of the application. This is the name that's shown in the app's title bar. If not set, the label of the app's MainActivity is used as the application name. The default setting is , which refers to the string resource location in .\n• A string that's used to uniquely identify the application. Typically, the package name is based on a reversed internet domain name convention, such as .\n• Specifies the application icon resource that will be displayed for the app. The setting refers to the image file located in the folder.\n• Sets the UI style that's applied to the entire app. Every view in the app applies to the style attributes that are defined in the selected theme.\n• An integer value greater than zero that defines the version number of the app. Higher numbers indicate more recent versions. This value is evaluated programmatically by Android and by other apps, it isn't shown to users.\n• A string that specifies the version of the app to users. The version name can be a raw string or a reference to a string resource.\n• Indicates a preference as to where the app should be stored, whether in internal or external storage. (Default) Specifies that the app can't be installed or moved to external storage. Specifies that the app should be installed in external storage, if possible. Specifies that the app should be installed in internal storage, if possible.\n• The oldest API level of an Android device that can install and run the app. Also referred to as .\n• The target API level of the Android device where the app expects to run. This API level is used at run-time, unlike Target Framework, which is used at build time. Android uses this version as a way to provide forward compatibility. Also referred to as , this should match Target Framework .\n• Either or , which packages the Android application as an APK file or Android App Bundle, respectively. This can be set individually for both Debug and Release modes. App Bundles are the latest format for Android release builds that are intended for submission on Google Play. The default value is . When is selected, other MSBuild properties are set:\n• When enabled, deploys the app faster than normal to the target device. This process speeds up the build/deploy/debug cycle because the package isn't reinstalled when only assemblies are changed. Only the updated assemblies are resynchronized to the target device. This is enabled by default.\n• When enabled, generates one Android package (apk) per selected Application Binary Interface (ABI). This is disabled by default.\n• When enabled, uses the incremental Android packaging system (aapt2). This is enabled by default.\n• When enabled, allows the Android build system to use multidex. The default is disabled.\n• Selects the code shrinker to use.\n• is the next-generation tool which converts Java byte code to optimized dex code.\n• Leaves the specified resource extensions uncompressed. Separate extensions with a semicolon . For example: .\n• When enabled, developer instrumentation is provided for debugging and profiling. This can be set for individually for both Debug and Release modes. The default is enabled for Debug builds.\n• Selects which debugger to use. The default is , which is used for managed code. The C++ debugger can be selected to debug native libraries used by the app.\n• Enables Ahead-of-Time (AOT) compilation. This can be set for individually for both Debug and Release modes. The default is enabled for Release builds.\n• Enables the LLVM optimizing compiler. The default is disabled.\n• Enables startup tracing. This can be set for individually for both Debug and Release modes. The default is enabled for Release builds.\n• When enabled, uses the concurrent garbage collector. Defaults to enabled.\n• When enabled, trims the application during publishing. This can be set for individually for both Debug and Release modes. For more information, see Trim self-contained deployments and executables and Trim options. The default is enabled for Release builds.\n• Controls how aggressively IL is discarded. There are two modes to select from:\n• (default) enableds assembly-level trimming, which keeps an entire assembly if any part of it is used.\n• Set this value to increase the size of memory that an app can use. For example, a value of increases the heap size to 2 gigabytes. Note that there isn't a guarantee of how large the heap will be, and requesting too much heap memory may force other apps to terminate prematurely.\n• Specifies additional command-line options to pass to the Java compiler when building a .dex file. From the command line, you can type to see the available options.\n\nWhen enabled, signs the .APK file using the keystore details. This is disabled by default.\n• The linker can strip out unused methods, properties, fields, events, structs, and even classes in order to reduce the overall size of the application. You can add a attribute to any of these in order to prevent the linker from stripping it out if it's needed for serialization or reflection. Enabling this feature may hinder debugging, as it may strip out property accessors that would allow you to inspect the state of your objects.\n• When enabled, uses the LLVM optimized compiler. This can be set for individually for both Debug and Release modes. The default is enabled for Release builds.\n• When enabled, strips native debugging symbols from the output. This is enabled by default.\n• When enabled, uses the concurrent garbage collector. This is disabled by default.\n• Additional command line arguments to be passed to the application bundling code.\n• When enabled, optimizes .PNG images. This is enabled by default.\n\nThese settings are related to generating and signing the app bundle.\n• Configures the signing scheme for the bundle. It can be set to one of the following values:\n• : With this value, you'll be responsible for setting provisioning profiles and signing certificates yourself.\n• : (default) With this value, Visual Studio will set provisioning profiles and signing certificates for you, which simplifies app deployment when testing on a device.\n• A signing identity is the certificate and private key pair that's used for code-signing app bundle using Apple's codesign utility.\n• Provisioning profiles are a way of tying together a team of developers with an App ID and, potentially, a list of test devices. The provisioning profiles list is filtered to only show provisioning profiles that match both the chosen identity and the App ID (aka bundle identifier) set in the Info.plist. If the provisioning profile that you're looking for isn't in the list, make sure that you've chosen a compatible identity and double-check that the bundle identifier set in your Info.plist is correct.\n• The plist file to use for entitlements. For more information, see Entitlements.\n• The plist file containing custom rules used by Apple's codesign utility. As of Mac OSX 10.10, Apple has deprecated the use of custom resource rules. So, this setting should be avoided unless absolutely necessary.\n• Additional command line arguments to be passed to Apple's codesign utility during the code-signing phase of the build.\n\nThese are settings related to debugging.\n• When enabled, turns on debugging. The default is based on the current profile. Debug profiles enable debugging, while Release profiles disable debugging.\n\nSettings related to on-demand resources. For more information, see Apple Developer Documentation - On-Demand Resources Essentials.\n• The tags of the on-demand resources that are downloaded at the same time the app is downloaded from the app store. Separate tags with a semicolon .\n• The tags of the on-demand resources that are downloaded after the app is installed. Separate tags with a semicolon .\n• When enabled, embeds on-demand resources in the app bundle. This is enabled by default. Disable this setting to use the Web server.\n• The URI of a web server that hosts on-demand resources.\n\nOptions related to running the app on an iOS or macOS device.\n• This setting determines how the app is run on the target device.\n• Additional command line arguments to be passed to the app when it's started on the device.\n• Additional command line arguments to be passed to mlaunch.\n• Name-value pairs of environment variables to set when the app is run on the device."
    },
    {
        "link": "https://stackoverflow.com/questions/78805812/xamarin-build-download-net-maui-build-process-hanging-at-file-extraction-gappm",
        "document": "Description: I am encountering an issue during the build process for an iOS application. The build seems to hang during the extraction of a specific file. The relevant portion of the build output is as follows:\n\nThe process gets stuck at this point and does not progress further. I have attempted to manually extract the file GAppM-10.24.0.tgz, and although this succeeds, the build still fails at the same extraction step.\n\nCould anyone provide insights or solutions to bypass this issue? Any tips on further diagnostics or configurations that might help resolve this would be greatly appreciated.\n\nThank you in advance for your assistance!"
    },
    {
        "link": "https://github.com/xamarin/xamarin-macios/issues/17722",
        "document": ""
    },
    {
        "link": "https://learn.microsoft.com/en-us/answers/questions/1313675/mtoucharch-to-runtimeidentifier-in-maui-ios",
        "document": "I am migrating xamarin forms project to .net maui.as part of migration i am changing the iOS .csproj.\n\nI have changed the MtouchArch to RuntimeIdentifiers as mentioned in the below link.\n\ni have replaced i386, x86_64 to iossimulator-x86,iossimulator-x64 as mentioned in the above link.\n\nafter doing changes i am getting below error while restoring nuget pacakges after deleting bin and obj.\n\n/usr/local/share/dotnet/sdk/7.0.304/Sdks/Microsoft.NET.Sdk/targets/Microsoft.NET.Sdk.FrameworkReferenceResolution.targets(90,5) : error NETSDK1083: The specified RuntimeIdentifier 'iossimulator-x64,iossimulator-x86' is not recognized.\n\nbelow is my configuration in iOS .csproj in xamarin :\n\nbelow is my configuration in iOS .csproj in MAUI :"
    },
    {
        "link": "https://github.com/xamarin/xamarin-macios/issues/18510",
        "document": ""
    }
]