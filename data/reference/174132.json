[
    {
        "link": "https://give.globaluniversity.edu/99609981/hcampaignsj/khousesc/rintroducesa/solution+manual+computer+science+an+overview+brookshear.pdf",
        "document": ""
    },
    {
        "link": "https://bbb.edouniversity.edu.ng/+y/chap/file?EPDF=solution+manual+computer+science+an+overview+brookshear.pdf",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/24599876/how-to-optimize-simple-stack-machine-code",
        "document": "I've been playing around with a simple stack-based language, and one of the things that I've found myself doing repeatedly is manually optimizing chunks of code.\n\nI figured \"hey, this looks very much like something that a computer can do! Repetitive work with a clear goal and semantics.\". But looking around, I can't find much of anything on optimizing stack machine code. Register machines, yes. But not stack-based languages. It seems like the general response to \"how do you optimize stack machine code?\" is \"don't.\"\n\nSo: how does one go about optimizing stack machine code? Are there any general methods beyond simple peephole optimizations? Are there any methods of generating peephole optimizations automatically?"
    },
    {
        "link": "https://jhzhang.cn/resources/A050113G/Computer%20Science-%20An%20Overview%20(12th%20Global%20Edition).pdf",
        "document": ""
    },
    {
        "link": "https://slideshare.net/FALLEE31188/brookshear-06",
        "document": ""
    },
    {
        "link": "https://studocu.com/en-gb/messages/question/2938057/can-anyone-please-explain-the-brookshear-machine-and-its-instructions",
        "document": "Can anyone please explain the Brookshear Machine and it's instructions?"
    },
    {
        "link": "https://cgi.cse.unsw.edu.au/~cs1917/15s2/lect/18_Machine4.pdf",
        "document": ""
    },
    {
        "link": "https://chegg.com/homework-help/questions-and-answers/kindly-solve-big-upvote-low-level-programming-following-questions-brookshear-machine-code--q101159225",
        "document": "The following questions are about the Brookshear machine code language.\n\na) Describe the following machine code instructions in words:\n\nb) Write the machine code instructions for the following:\n\nii) Copy the bit pattern found in register A to the memory cell whose address is F0\n\niii) EXCLUSIVE OR the bit patterns in registers A and B and place the result in register C.\n\niv) ADD the floating-point numbers in registers 6 and 7 and store the result in register 1\n\nc) Explain why the following instructions are not valid in the language provided:\n\nd) Here is a machine code program that adds the two’s complement numbers in memory locations A1 and A2, and places the result in A3.\n\nShow how this program can be written in a more efficient way.\n\ne) The machine code language provided does not include an instruction for multiplication. One way to multiply integers is by repeated addition in a loop.\n\nFor example, instead of doing 5 × 20, the processor does 5 + 5 + 5 + 5... twenty times.\n• Register C contains the two’s complement number 0\n\nShow how the machine language can be used to multiply contents of register A and B, putting the result in register C.\n\nIn a bracket)or a machine code program, or a mixture of explanation and machine code)."
    },
    {
        "link": "https://en.wikipedia.org/wiki/Machine_code",
        "document": "In computer programming, machine code is computer code consisting of machine language instructions, which are used to control a computer's central processing unit (CPU). For conventional binary computers, machine code is the binary representation of a computer program which is actually read and interpreted by the computer. A program in machine code consists of a sequence of machine instructions (possibly interspersed with data).[1]\n\nEach machine code instruction causes the CPU to perform a specific task. Examples of such tasks include:\n• Execute an arithmetic logic unit (ALU) operation on one or more registers or memory locations\n• Jump or skip to an instruction that is not the next one\n\nIn general, each architecture family (e.g., x86, ARM) has its own instruction set architecture (ISA), and hence its own specific machine code language. There are exceptions, such as the VAX architecture, which includes optional support of the PDP-11 instruction set; the IA-64 architecture, which includes optional support of the IA-32 instruction set; and the PowerPC 615 microprocessor, which can natively process both PowerPC and x86 instruction sets.\n\nMachine code is a strictly numerical language, and it is the lowest-level interface to the CPU intended for a programmer. Assembly language provides a direct map between the numerical machine code and a human-readable mnemonic. In assembly, numerical opcodes and operands are replaced with mnemonics and labels. For example, the x86 architecture has available the 0x90 opcode; it is represented as NOP in the assembly source code. While it is possible to write programs directly in machine code, managing individual bits and calculating numerical addresses is tedious and error-prone. Therefore, programs are rarely written directly in machine code. However, an existing machine code program may be edited if the assembly source code is not available.\n\nThe majority of programs today are written in a high-level language. A high-level program may be translated into machine code by a compiler.\n\nEvery processor or processor family has its own instruction set. Machine instructions are patterns of bits[nb 1] that specify some particular action.[2] An instruction set is described by its instruction format. Some ways in which instruction formats may differ:[2]\n• all instructions may have the same length or instructions may have different lengths;\n• the number of instructions may be small or large;\n• instructions may or may not align with the architecture's word length.\n\nA processor's instruction set needs to execute the circuits of a computer's digital logic level. At the digital level, the program needs to control the computer's registers, bus, memory, ALU, and other hardware components.[3] To control a computer's architectural features, machine instructions are created. Examples of features that are controlled using machine instructions:\n• Instructions most commonly used should be shorter than instructions rarely used. 2\n• The memory transfer rate of the underlying hardware determines the flexibility of the memory fetch instructions.\n• The number of bits in the address field requires special consideration. 7\n\nDetermining the size of the address field is a choice between space and speed.[7] On some computers, the number of bits in the address field may be too small to access all of the physical memory. Also, virtual address space needs to be considered. Another constraint may be a limitation on the size of registers used to construct the address. Whereas a shorter address field allows the instructions to execute more quickly, other physical properties need to be considered when designing the instruction format.\n\nInstructions can be separated into two types: general-purpose and special-purpose. Special-purpose instructions exploit architectural features that are unique to a computer. General-purpose instructions control architectural features common to all computers.[8]\n• Data movement from one place to another\n• Monadic operations that have one operand to produce a result\n• Dyadic operations that have two operands to produce a result\n\nA much more human-friendly rendition of machine language, named assembly language, uses mnemonic codes to refer to machine code instructions, rather than using the instructions' numeric values directly, and uses symbolic names to refer to storage locations and sometimes registers.[9] For example, on the Zilog Z80 processor, the machine code , which causes the CPU to decrement the general-purpose register, would be represented in assembly language as .[10]\n\nThe IBM 704, 709, 704x and 709x store one instruction in each instruction word; IBM numbers the bit from the left as S, 1, ..., 35. Most instructions have one of two formats:\n\nFor all but the IBM 7094 and 7094 II, there are three index registers designated A, B and C; indexing with multiple 1 bits in the tag subtracts the logical or of the selected index registers and loading with multiple 1 bits in the tag loads all of the selected index registers. The 7094 and 7094 II have seven index registers, but when they are powered on they are in multiple tag mode, in which they use only the three of the index registers in a fashion compatible with earlier machines, and require a Leave Multiple Tag Mode (LMTM) instruction in order to access the other four index registers.\n\nThe effective address is normally Y-C(T), where C(T) is either 0 for a tag of 0, the logical or of the selected index registers in multiple tag mode or the selected index register if not in multiple tag mode. However, the effective address for index register control instructions is just Y.\n\nA flag with both bits 1 selects indirect addressing; the indirect address word has both a tag and a Y field.\n\nIn addition to transfer (branch) instructions, these machines have skip instruction that conditionally skip one or two words, e.g., Compare Accumulator with Storage (CAS) does a three way compare and conditionally skips to NSI, NSI+1 or NSI+2, depending on the result.\n\nThe MIPS architecture provides a specific example for a machine code whose instructions are always 32 bits long.[11]: 299 The general type of instruction is given by the op (operation) field, the highest 6 bits. J-type (jump) and I-type (immediate) instructions are fully specified by op. R-type (register) instructions include an additional field funct to determine the exact operation. The fields used in these types are:\n\nrs, rt, and rd indicate register operands; shamt gives a shift amount; and the address or immediate fields contain an operand directly.[11]: 299–301\n\nFor example, adding the registers 1 and 2 and placing the result in register 6 is encoded:[11]: 554\n\nLoad a value into register 8, taken from the memory cell 68 cells after the location listed in register 3:[11]: 552\n\nOn processor architectures with variable-length instruction sets[12] (such as Intel's x86 processor family) it is, within the limits of the control-flow resynchronizing phenomenon known as the Kruskal count,[13][12][14][15][16] sometimes possible through opcode-level programming to deliberately arrange the resulting code so that two code paths share a common fragment of opcode sequences.[nb 2] These are called overlapping instructions, overlapping opcodes, overlapping code, overlapped code, instruction scission, or jump into the middle of an instruction.[17][18][19]\n\nIn the 1970s and 1980s, overlapping instructions were sometimes used to preserve memory space. One example were in the implementation of error tables in Microsoft's Altair BASIC, where interleaved instructions mutually shared their instruction bytes.[20][12][17] The technique is rarely used today, but might still be necessary to resort to in areas where extreme optimization for size is necessary on byte-level such as in the implementation of boot loaders which have to fit into boot sectors.[nb 3]\n\nIt is also sometimes used as a code obfuscation technique as a measure against disassembly and tampering.[12][15]\n\nThe principle is also used in shared code sequences of fat binaries which must run on multiple instruction-set-incompatible processor platforms.[nb 2]\n\nThis property is also used to find unintended instructions called gadgets in existing code repositories and is used in return-oriented programming as alternative to code injection for exploits such as return-to-libc attacks.[21][12]\n\nIn some computers, the machine code of the architecture is implemented by an even more fundamental underlying layer called microcode, providing a common machine language interface across a line or family of different models of computer with widely different underlying dataflows. This is done to facilitate porting of machine language programs between different models. An example of this use is the IBM System/360 family of computers and their successors.\n\nMachine code is generally different from bytecode (also known as p-code), which is either executed by an interpreter or itself compiled into machine code for faster (direct) execution. An exception is when a processor is designed to use a particular bytecode directly as its machine code, such as is the case with Java processors.\n\nMachine code and assembly code are sometimes called native code when referring to platform-dependent parts of language features or libraries.[22]\n\nFrom the point of view of the CPU, machine code is stored in RAM, but is typically also kept in a set of caches for performance reasons. There may be different caches for instructions and data, depending on the architecture.\n\nThe CPU knows what machine code to execute, based on its internal program counter. The program counter points to a memory address and is changed based on special instructions which may cause programmatic branches. The program counter is typically set to a hard coded value when the CPU is first powered on, and will hence execute whatever machine code happens to be at this address.\n\nSimilarly, the program counter can be set to execute whatever machine code is at some arbitrary address, even if this is not valid machine code. This will typically trigger an architecture specific protection fault.\n\nThe CPU is oftentimes told, by page permissions in a paging based system, if the current page actually holds machine code by an execute bit — pages have multiple such permission bits (readable, writable, etc.) for various housekeeping functionality. E.g. on Unix-like systems memory pages can be toggled to be executable with the system call, and on Windows, can be used to achieve a similar result. If an attempt is made to execute machine code on a non-executable page, an architecture specific fault will typically occur. Treating data as machine code, or finding new ways to use existing machine code, by various techniques, is the basis of some security vulnerabilities.\n\nSimilarly, in a segment based system, segment descriptors can indicate whether a segment can contain executable code and in what rings that code can run.\n\nFrom the point of view of a process, the code space is the part of its address space where the code in execution is stored. In multitasking systems this comprises the program's code segment and usually shared libraries. In multi-threading environment, different threads of one process share code space along with data space, which reduces the overhead of context switching considerably as compared to process switching.\n\nMachine code can be seen as a set of electrical pulses that make the instructions readable to the computer; it is not readable by humans, with Douglas Hofstadter comparing it to examining the atoms of a DNA molecule. However, various tools and methods exist to decode machine code to human-readable source code. One such method is disassembly, which easily decodes it back to its corresponding assembly language source code because assembly language forms a one-to-one mapping to machine code.\n\nMachine code may also be decoded to high-level language under two conditions. The first condition is to accept an obfuscated reading of the source code. An obfuscated version of source code is displayed if the machine code is sent to a decompiler of the source language. The second condition requires the machine code to have information about the source code encoded within. The information includes a symbol table that contains debug symbols. The symbol table may be stored within the executable, or it may exist in separate files. A debugger can then read the symbol table to help the programmer interactively debug the machine code in execution.\n• The SHARE Operating System (1959) for the IBM 709, IBM 7090, and IBM 7094 computers allowed for an loadable code format named SQUOZE. SQUOZE was a compressed binary form of assembly language code and included a symbol table.\n• Modern IBM mainframe operating systems, such as z/OS, have available a symbol table named Associated data (ADATA). The table is stored in a file that can be produced by the IBM High-Level Assembler (HLASM), 26 27 IBM's COBOL compiler, 28 and IBM's PL/I compiler, 29 either as a separate SYSADATA file or as ADATA records in a Generalized object output file (GOFF). 30\n• Microsoft Windows has available a symbol table 31 that is stored in a program database ( ) file. 32\n• Most Unix-like operating systems have available symbol table formats named stabs and DWARF. In macOS and other Darwin-based operating systems, the debug symbols are stored in DWARF format in a separate file.\n• None Samuelson, Pamela (1984). \"CONTU Revisited: The Case Against Copyright Protection for Computer Programs in Machine-Readable Form\". Duke Law Journal. 33 (4): 769. hdl:hein.journals/duklr1984 ."
    },
    {
        "link": "https://studocu.com/en-gb/document/university-of-sussex/introduction-to-computer-systems/brookshear-machine-instruction-set-and-machine-code-11-03-2019/14812840",
        "document": "-However, instructi on set shows main characteristics of RISC architecture\n\n-Has 16 registers ( modern Intel C PUs also do), nu mber 0 to F (hex)\n\n-1 byte (8 bits) can be represented by two hex dig its\n\n-Uses 16-bit instructi ons, so each is 2 by tes long and occupies two mem ory locations\n\n- Operands: take up remaining 12 bits;they are para meters, specifying what data t he instruction"
    }
]