[
    {
        "link": "https://reddit.com/r/Python/comments/sekrzq/how_to_optimize_python_code",
        "document": "I'm interested in learning what optimization techniques you know for python code. I know its a general statement, but I'm interested in really pushing execution to the maximum.\n\nI use the following -\n• I use builtins when possible\n• I use set lookups wherever possible\n\nEdit: I am using a profiler, and benchmarks. I'm working on a library - an ASGI Api framework. The code is async. Its not darascience. Its neither compatible with pypy, nor with numba.."
    },
    {
        "link": "https://theserverside.com/tip/Tips-to-improve-Python-performance",
        "document": ""
    },
    {
        "link": "https://softformance.com/blog/how-to-speed-up-python-code",
        "document": "We at SoftFormance adore Python. Actually, it is our favorite programming language, as both startups and established enterprises can benefit from Python software development. With its remarkable diversity of libraries and frameworks, Python provides excellent solutions for mobile and web application development.\n\nOver 10+ years in the market, the SoftFormance team has developed and released more than 100 applications using Python and our favorite framework, Django.\n\nWe certainly know how to take the maximum out of Python, and we are eager to share our expertise in Python code optimization with you.\n\nKeep reading if you want a development team that knows how to speed up Python code and save your time, money, and effort.\n\nTo begin with, let’s outline some Python essentials.\n\nOne of the main distinctions and selling points of Python is that it is an interpreted language. Python code can be executed directly, eliminating the need for pre-compilation into machine code. This significantly boosts the speed of Python development.\n\nHowever, Python code needs to undergo interpretation each time it is executed on the processor. To prevent the necessity of recompiling the code with each run, Python employs compiled .pyc files. These files enable the storage of bytecode produced from the original Python code, facilitating caching. Later on, we will dwell on some useful tips on Python code compiling.\n\nFinally, Python code is dynamically typed. This means that you aren’t required to specify a data type every time you create a variable. This dynamic approach significantly boosts the speed of coding with Python, but it can also negatively impact Python’s performance if not managed properly.\n\nFortunately, this article will give you useful tips on how to speed up Python code and the overall performance of this programming language.\n\nWith Python code optimization tips mentioned in this article, you will have great ideas on how to:\n• Boost the performance of apps built with Python\n\nAs a team that has an impressive track record of successful Python application development projects, we certainly have some advice to offer to Python developers.\n\nMany tips on this list are rather simple yet often overlooked. And, most probably, you will find, at least, some useful ideas here.\n\nHere’s a more general suggestion that will help you embrace the complete potential of Python.\n\nFrom our experience, there’s no better Python framework than Django.\n\nIt is fast, efficient, popular, and rich with Python development tools.\n\nAs a result, writing Python code with Django may become a clear highway to success.\n\nBut, surely, there are more specific ideas on optimizing Python code to come.\n\n2. Use PyPy Instead of CPython\n\nPyPy is an implementation of Python that uses just-in-time compilation instead of ahead-of-time compilation, peculiar to this language.\n\nAs a result, PyPy allows our developers to speed up code execution.\n\nSometimes, code execution with PyPy can be seven times faster than with CPython.\n\n3. Use NumPy Arrays Instead of Lists\n\nThe NumPy library has a great implementation in scientific computing. When dealing with substantial data and mathematical operations, NumPy arrays can significantly outpace common Python lists.\n\nNumPy arrays are tailored for numerical tasks, enhancing efficiency with sizable datasets and consuming less memory than lists. This, in turn, means improved performance.\n\nThe “timeit” module is a special feature that allows you to control Python, improve performance, and track its efficiency much better.\n\nIt allows the developer to measure how long it takes to execute a piece of code.\n\nAs a result, there appears a great space for testing the efficiency of different coding approaches.\n\nGenerator expressions offer a memory-efficient approach to crafting lists by generating values on-the-fly instead of storing the entire list at once.\n\nUnlike list comprehensions, generator expressions rely on parentheses, yielding a generator object rather than a list, which helps users enhance code performance while minimizing memory consumption.\n\nMultiprocessing allows you to partition your code into multiple processes.\n\nAs a result, you can harness the additional processing capability offered by multicore processors, thereby enhancing your code’s performance.\n\nMind that your technical team may need to show a lot of skill in order to handle multiprocessing properly.\n\nThe Python profiling feature is a perfect way for you to track memory usage, measure the number of function calls, and analyze the time needed for the execution of those calls.\n\nVarious continuous profilers provided by the vibrant community of Python developers can come in handy.\n\nOr you may aim for a more custom profiler, which will allow you to ensure an always-on approach.\n\nLoops are very common in coding, and Python provides inherent mechanisms to facilitate them. The point is that such loops often slow down Python programs.\n\nFortunately, code mapping is here to optimize time utilization and accelerate the execution of such loops.\n\nCode maps are native structure elements that simplify intricate code, making it more shareable and comprehensible. The more efficient and consolidated the code, the better your Python code speed up.\n\nWhile writing Python code, the developers should review it regularly. The point is to remove unnecessary code parts and save memory.\n\nThere are multiple ways for removing dead code. These include multiprocessing, using content managers, and relying on preload managers.\n\nDon’t forget to monitor the performance of your Python apps because this allows you to properly evaluate the efficiency of your work.\n\nAPM tools, such as New Relic, will come in handy. They benchmark a program, identify performance bottlenecks, and provide optimization solutions to these issues.\n\nPeephole optimization is a Python coding technique that boosts code performance during the compilation.\n\nIts main tasks are pre-computing constant expressions and employing membership tests.\n\nFor example, a developer can improve code readability by writing “a = 606024” to represent the number of seconds in a day. However, the language interpreter automatically calculates this and replaces repetitive instances, which, in turn, boosts software performance.\n\nIf you are using Peephole optimization, Python precomputes constant expressions like 606024 and replaces them with the result, such as 86400. This allows you to avoid performance decrease.\n\nPython string objects are sequences of Unicode characters, referred to as “text” sequences in the documentation.\n\nIf different character sizes are appended to a string, the overall size and weight of the string grow exponentially. In addition, Python allocates additional information for storing these strings. As a result, too much space is consumed.\n\nThat’s when string interning comes into action. It is based on caching of specific strings in memory upon creation.\n\nAs a result, only a single instance of each unique string remains active at any point. This, in turn, means more efficient memory allocation.\n\ncProfile offers functionality for advanced profiling, which is part of the Python package since Python 2.5.\n\nYou can connect it to the Python code in the following ways:\n• Encapsulate a function within its “run” method to measure its performance.;\n• Run the command line script, activate cProfile as an argument, and use Python’s “-m” option.\n\n14. Use Generators and Keys for Sorting\n\nUsing generators is one more way to optimize memory consumption.\n\nThese generators can yield items one by one instead of yielding them all at once. When you are sorting items in a list afterwards, we advise you to employ keys and the default <sort()> method.\n\nThe developers can employ this technique to sort both lists and strings based on a chosen index specified within the key argument.\n\nPython offers a wide array of built-in operators and libraries. We don’t know all of them, but we do know for sure that there are thousands in existence.\n\nUse these built-ins whenever feasible to make your code more efficient. As long as such built-in operators are pre-compiled, they bring you truly swift performance.\n\nThe “C” counterparts of certain Python libraries can bring you the same or even more advanced functionality than the original versions of these libraries. Unsurprisingly, their usage can help you with Python performance optimization.\n\nFor example, you may consider substituting Pickle with cPickle to observe the performance disparity.\n\nThe developers can also boost Python coding efficiency with the above-mentioned PyPy and <Cython>.\n\nBoth these solutions serve as means to optimize a static compiler.\n\nGlobal variables have their benefits, but they can also bring unexpected side effects, such as excessively complex code structures.\n\nPython performance may drop when you are accessing external variables. So, we advise you to minimize their usage or avoid applying such variables at all.\n\nIf there is no way to avoid using globals, consider the following suggestions:\n• Apply the ‘global’ keyword to explicitly declare an external variable.\n• Before applying globals within loops, generate local copies to boost efficiency.\n\nPython offers list, tuple, set, and dictionary as the built-in data structures.\n\nAnd most developers rely on a list of all cases.\n\nHowever, if you want a truly good performance, check how different data structures fit different cases. And, as a result of your research, choose data structures depending on your needs\n\nThis approach optimizes and speeds up the code execution.\n\nThe key point is to reject variables like this:\n\nAnd to assign variables like this:\n\nIn Python, you have the option to concatenate strings using the + operator. For example:\n\nWe recommend you try the join () method because it is faster.\n\nIn this case, your optimization code in Python will look the following way:\n\nInstead of using the “while True” construct in your code, rely on the “while 1” construct. Unless quite simple, this modification can reduce your code’s runtime.\n\nThe point is that “while 1” offers a more straightforward depiction of an infinite loop condition. This can enhance performance compared to “while True” construct, which is slightly more abstract.\n\nC/C++ outperforms Python in terms of speed. And there are numerous packages and modules developed in C/C++ that can be integrated into your Python programs.\n\nNotably, Numpy, Scipy, and Pandas are three prominent examples, known for their effectiveness in handling large datasets.\n\nTake a look at an example. What you see is a code to list all the numbers between 1 and 1000 that is the multiplier of 3:\n\nWith list comprehension, this code will look as follows:\n\nThe main benefit of list comprehension is that it can help you improve Python performance.\n\nDo not write a function that already exists in the library manually.\n\nLibrary functions prove to be very efficient. Actually, replicating their level of efficiency in your own code can be quite challenging.\n\nAnd, surely, their use helps you save a lot of time.\n\n25. Do Not Use .dot Operation\n\nTry to avoid dot operations, as it may be time-consuming. Take a look at the example below:\n\nYou may write the same operation in the following style:\n\nThe point is that the function with a .(dot) first calls __getattribute()__ or __getattr()__, which then uses a dictionary operation. This means that your operation takes more time. We recommend you use the module import function for optimizing Python code for speed.\n\nSo, these 25 tips will help you or your developers optimize the Python code.\n\nAs a result, you will develop apps that show excellent performance a few times faster.\n\nBut it is always better to rely on specialists who have already mastered these tips long before and know how to improve Python performance.\n\nIf you have issues with performance of your Python/Django app, SoftFormance, a perfect Python development team, is ready to help you.\n\nWe will thoroughly analyze your code and tune it up with the best Python code optimization techniques.\n\nContact us to get your Python apps running faster and more efficiently than ever!"
    },
    {
        "link": "https://geeksforgeeks.org/optimization-tips-python-code",
        "document": "Optimization Tips for Python Code focuses on improving the performance of Python programs by refining common coding patterns. It covers strategies such as using built-in functions, minimizing redundant operations, Using local variables and choosing the right data structures to speed up execution and enhance efficiency.\n\nThis code compares the performance of two approaches for converting a string to uppercase: using a loop and . It measures and compares the execution time of each method to highlight the efficiency of the built-in function\n• None loop explicitly iterates and appends, making it slower, while\n• None returns an iterator, so its execution isn’t timed properly. Using\n\nWe should use the key argument to the built-in sort instead which is a faster way to sort.\n• None returns a new list of sorted characters without changing the original string.\n• None is sorted numerically whereas string is sorted lexicographically producing a list of characters in alphabetical order.\n\nOptimizing loops involves minimizing redundant calculations, using built-in functions like and , and leveraging list comprehensions for efficiency. Avoiding excessive memory operations and using generators can further enhance performance.\n• None First method uses explicit looping with while the second is more concise and efficient.\n\nUse local variable if possible\n\nUsing local variables improves performance by reducing the overhead of global lookups. It also makes the code more readable and minimizes potential bugs from modifying global states.\n• None reduces the time spent searching for the method in the object, improving execution speed."
    },
    {
        "link": "https://wiki.python.org/moin/PythonSpeed/PerformanceTips",
        "document": "This page is devoted to various tips and tricks that help improve the performance of your Python programs. Wherever the information comes from someone else, I've tried to identify the source.\n\nPython has changed in some significant ways since I first wrote my \"fast python\" page in about 1996, which means that some of the orderings will have changed. I migrated it to the Python wiki in hopes others will help maintain it.\n\nYou should always test these tips with your application and the specific version of the Python implementation you intend to use and not just blindly accept that one method is faster than another. See the profiling section for more details.\n\nAlso new since this was originally written are packages like Cython, Pyrex, Psyco, Weave, Shed Skin and PyInline, which can dramatically improve your application's performance by making it easier to push performance-critical code into C or machine language.\n\nYou can only know what makes your program slow after first getting the program to give correct results, then running it to see if the correct program is slow. When found to be slow, profiling can show what parts of the program are consuming most of the time. A comprehensive but quick-to-run test suite can then ensure that future optimizations don't change the correctness of your program. In short:\n• Get it right.\n\nCertain optimizations amount to good programming style and so should be learned as you learn the language. An example would be moving the calculation of values that don't change within a loop, outside of the loop.\n\nSorting lists of basic Python objects is generally pretty efficient. The sort method for lists takes an optional comparison function as an argument that can be used to change the sorting behavior. This is quite convenient, though it can significantly slow down your sorts, as the comparison function will be called many times. In Python 2.4, you should use the key argument to the built-in sort instead, which should be the fastest way to sort.\n\nOnly if you are using older versions of Python (before 2.4) does the following advice from Guido van Rossum apply:\n\nAn alternative way to speed up sorts is to construct a list of tuples whose first element is a sort key that will sort properly using the default comparison, and whose second element is the original list element. This is the so-called Schwartzian Transform, also known as DecorateSortUndecorate (DSU).\n\nSuppose, for example, you have a list of tuples that you want to sort by the n-th field of each tuple. The following function will do that.\n\nMatching the behavior of the current list sort method (sorting in place) is easily achieved as well:\n\nHere's an example use:\n\nFrom Python 2.3 sort is guaranteed to be stable.\n\nPython 2.4 adds an optional key parameter which makes the transform a lot easier to use:\n\nNote that the original item is never used for sorting, only the returned key - this is equivalent to doing:\n\nThe accuracy of this section is disputed with respect to later versions of Python. In CPython 2.5, string concatenation is fairly fast, although this may not apply likewise to other Python implementations. See ConcatenationTestCode for a discussion.\n\nStrings in Python are immutable. This fact frequently sneaks up and bites novice Python programmers on the rump. Immutability confers some advantages and disadvantages. In the plus column, strings can be used as keys in dictionaries and individual copies can be shared among multiple variable bindings. (Python automatically shares one- and two-character strings.) In the minus column, you can't say something like, \"change all the 'a's to 'b's\" in any given string. Instead, you have to create a new string with the desired properties. This continual copying can lead to significant inefficiencies in Python programs.\n\nUse instead. The former is a very common and catastrophic mistake when building large strings. Similarly, if you are generating bits of a string sequentially instead of:\n\nEven better, for readability (this has nothing to do with efficiency other than yours as a programmer), use dictionary substitution:\n\nThis last two are going to be much faster, especially when piled up over many CGI script executions, and easier to modify to boot. In addition, the slow way of doing things got slower in Python 2.0 with the addition of rich comparisons to the language. It now takes the Python virtual machine a lot longer to figure out how to concatenate two strings. (Don't forget that Python does all method lookup at runtime.)\n\nPython supports a couple of looping constructs. The statement is most commonly used. It loops over the elements of a sequence, assigning each to the loop variable. If the body of your loop is simple, the interpreter overhead of the loop itself can be a substantial amount of the overhead. This is where the map function is handy. You can think of as a moved into C code. The only restriction is that the \"loop body\" of must be a function call. Besides the syntactic benefit of list comprehensions, they are often as fast or faster than equivalent use of .\n\nHere's a straightforward example. Instead of looping over a list of words and converting them to upper case:\n\nyou can use to push the loop from the interpreter into compiled C code:\n\nList comprehensions were added to Python in version 2.0 as well. They provide a syntactically more compact and more efficient way of writing the above for loop:\n\nGenerator expressions were added to Python in version 2.4. They function more-or-less like list comprehensions or but avoid the overhead of generating the entire list at once. Instead, they return a generator object which can be iterated over bit-by-bit:\n\nWhich method is appropriate will depend on what version of Python you're using and the characteristics of the data you are manipulating.\n\nGuido van Rossum wrote a much more detailed (and succinct) examination of loop optimization that is definitely worth reading.\n\nSuppose you can't use or a list comprehension? You may be stuck with the for loop. The for loop example has another inefficiency. Both and are function references that are reevaluated each time through the loop. The original loop can be replaced with:\n\nThis technique should be used with caution. It gets more difficult to maintain if the loop is large. Unless you are intimately familiar with that piece of code you will find yourself scanning up to check the definitions of and .\n\nThe final speedup available to us for the non- version of the loop is to use local variables wherever possible. If the above loop is cast as a function, and become local variables. Python accesses local variables much more efficiently than global variables.\n\nAt the time I originally wrote this I was using a 100MHz Pentium running BSDI. I got the following times for converting the list of words in (38,470 words at that time) to upper case:\n\nSuppose you are building a dictionary of word frequencies and you've already broken your text up into a list of words. You might execute something like:\n\nExcept for the first time, each time a word is seen the statement's test fails. If you are counting a large number of words, many will probably occur multiple times. In a situation where the initialization of a value is only going to occur once and the augmentation of that value will occur many times it is cheaper to use a statement:\n\nIt's important to catch the expected KeyError exception, and not have a default clause to avoid trying to recover from an exception you really can't handle by the statement(s) in the clause.\n\nA third alternative became available with the release of Python 2.x. Dictionaries now have a get() method which will return a default value if the desired key isn't found in the dictionary. This simplifies the loop:\n\nWhen I originally wrote this section, there were clear situations where one of the first two approaches was faster. It seems that all three approaches now exhibit similar performance (within about 10% of each other), more or less independent of the properties of the list of words.\n\nOther options are defaultdict and (since python 3.1) Counter:\n\nAll the options presented so far involve a double lookup: the dictionary is searched once to see if the item is present, then inserting the new value requires another search to find where to store that value. Since python 3.3 the method avoids double lookup. Applying it to the word counting example requires storing a mutable counter, for example a one-element list.\n\nA drawback to is that a default value is constructed for each call whether it is used or not. Also, since dictionary lookup is fast, it seems difficult even to contrive an example where the double lookup is the bottleneck. As always it is wise to measure these costs before settling on an implementation.\n\nstatements can be executed just about anywhere. It's often useful to place them inside functions to restrict their visibility and/or reduce initial startup time. Although Python's interpreter is optimized to not import the same module multiple times, repeatedly executing an import statement can seriously affect performance in some circumstances.\n\nConsider the following two snippets of code (originally from Greg McFarlane, I believe - I found it unattributed in a comp.lang.python python-list@python.org posting and later attributed to him in another source):\n\nwill run much faster than , even though the reference to the string module is global in . Here's a Python interpreter session run using Python 2.3 and the new module, which shows how much faster the second is than the first:\n\nString methods were introduced to the language in Python 2.0. These provide a version that avoids the import completely and runs even faster:\n\nThe above example is obviously a bit contrived, but the general principle holds.\n\nNote that putting an import in a function can speed up the initial loading of the module, especially if the imported module might not be required. This is generally a case of a \"lazy\" optimization -- avoiding work (importing a module, which can be very expensive) until you are sure it is required.\n\nThis is only a significant saving in cases where the module wouldn't have been imported at all (from any module) -- if the module is already loaded (as will be the case for many standard modules, like or ), avoiding an import doesn't save you anything. To see what modules are loaded in the system look in .\n\nA good way to do lazy imports is:\n\nThis way the module will only be imported once, on the first invocation of .\n\nFunction call overhead in Python is relatively high, especially compared with the execution speed of a builtin function. This strongly suggests that where appropriate, functions should handle data aggregates. Here's a contrived example written in Python.\n\nHere's the proof in the pudding using an interactive session:\n\nEven written in Python, the second example runs about four times faster than the first. Had been written in C the difference would likely have been even greater (exchanging a Python loop for a C loop as well as removing most of the function calls).\n\nDoing Stuff Less Often\n\nThe Python interpreter performs some periodic checks. In particular, it decides whether or not to let another thread run and whether or not to run a pending call (typically a call established by a signal handler). Most of the time there's nothing to do, so performing these checks each pass around the interpreter loop can slow things down. There is a function in the module, , which you can call to tell the interpreter how often to perform these periodic checks. Prior to the release of Python 2.3 it defaulted to 10. In 2.3 this was raised to 100. If you aren't running with threads and you don't expect to be catching many signals, setting this to a larger value can improve the interpreter's performance, sometimes substantially.\n\nPython is not C\n\nIt is also not Perl, Java, C++ or Haskell. Be careful when transferring your knowledge of how other languages perform to Python. A simple example serves to demonstrate:\n\nNow consider the similar C programs (only the add version is shown):\n\nNote that there is a significant advantage in Python to adding a number to itself instead of multiplying it by two or shifting it left by one bit. In C on all modern computer architectures, each of the three arithmetic operations are translated into a single machine instruction which executes in one cycle, so it doesn't really matter which one you choose.\n\nA common \"test\" new Python programmers often perform is to translate the common Perl idiom\n\ninto Python code that looks something like\n\nand use it to conclude that Python must be much slower than Perl. As others have pointed out numerous times, Python is slower than Perl for some things and faster for others. Relative performance also often depends on your experience with the two languages.\n\nUse xrange instead of range\n\nThis section no longer applies if you're using Python 3, where now provides an iterator over ranges of arbitrary size, and where no longer exists.\n\nPython has two ways to get a range of numbers: and . Most people know about , because of its obvious name. , being way down near the end of the alphabet, is much less well-known.\n\nis a generator object, basically equivalent to the following Python 2.3 code:\n\nExcept that it is implemented in pure C.\n\ndoes have limitations. Specifically, it only works with s; you cannot use s or s (they will be converted to s, as shown above).\n\nIt does, however, save gobs of memory, and unless you store the yielded objects somewhere, only one yielded object will exist at a time. The difference is thus: When you call , it creates a containing so many number ( , , or ) objects. All of those objects are created at once, and all of them exist at the same time. This can be a pain when the number of numbers is large.\n\n, on the other hand, creates no numbers immediately - only the range object itself. Number objects are created only when you pull on the generator, e.g. by looping through it. For example:\n\nAnd for this reason, the code runs instantly. If you substitute there, Python will lock up; it will be too busy allocating number objects (about 2.1 billion on the typical PC) to do anything else. Eventually, it will run out of memory and exit.\n\nIn Python versions before 2.2, objects also supported optimizations such as fast membership testing ( ). These features were removed in 2.2 due to lack of use.\n\nSay you have a function\n\nAnd suppose this function gets called from somewhere else many times.\n\nWell, your check will have an if statement slowing you down all the time except the first time, so you can do this:\n\nWell, this example is fairly inadequate, but if the 'if' statement is a pretty complicated expression (or something with lots of dots), you can save yourself evaluating it, if you know it will only be true the first time.\n\nThe first step to speeding up your program is learning where the bottlenecks lie. It hardly makes sense to optimize code that is never executed or that already runs fast. I use two modules to help locate the hotspots in my code, profile and trace. In later examples I also use the module, which is new in Python 2.3.\n\nThe advice in this section is out of date. See the separate profiling document for alternatives to the approaches given below.\n\nThere are a number of profiling modules included in the Python distribution. Using one of these to profile the execution of a set of functions is quite easy. Suppose your main function is called , takes no arguments and you want to execute it under the control of the module. In its simplest form you just execute\n\nWhen returns, the module will print a table of function calls and execution times. The output can be tweaked using the class included with the module. From Python 2.4, has permitted the time consumed by Python builtins and functions in extension modules to be profiled as well.\n\nA slightly longer description of profiling using the and modules can be found here (archived version):\n\nThe `cProfile` module is an alternative to written in C that generally runs much faster. It uses the same interface.\n\nThe trace module is a spin-off of the profile module I wrote originally to perform some crude statement level test coverage. It's been heavily modified by several other people since I released my initial crude effort. As of Python 2.0 you should find trace.py in the Tools/scripts directory of the Python distribution. Starting with Python 2.3 it's in the standard library (the Lib directory). You can copy it to your local bin directory and set the execute permission, then execute it directly. It's easy to run from the command line to trace execution of whole scripts:\n\nIn Python 2.4 it's even easier to run. Just execute .\n\nThere's no separate documentation, but you can execute \"pydoc trace\" to view the inline documentation.\n\nRunSnakeRun is a GUI tool by Mike Fletcher which visualizes profile dumps from cProfile using square maps. Function/method calls may be sorted according to various criteria, and source code may be displayed alongside the visualization and call statistics. Currently (April 2016) RunSnakeRun supports Python 2.x only - thus it cannot load profile data generated by Python 3 programs.\n\nGprof2Dot is a python based tool that can transform profiling results output into a graph that can be converted into a PNG image or SVG.\n\nA typical profiling session with python 2.5 looks like this (on older platforms you will need to use actual script instead of the -m option):\n\nPyCallGraph pycallgraph is a Python module that creates call graphs for Python programs. It generates a PNG file showing an modules's function calls and their link to other function calls, the amount of times a function was called and the time spent in that function.\n\nPyProf2CallTree is a script to help visualize profiling data collected with the cProfile python module with the kcachegrind graphical calltree analyser.\n\nProfileEye is a browser-based frontend to gprof2dot using d3.js for decluttering visual information."
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Learn_web_development/Extensions/Performance/JavaScript",
        "document": "It is very important to consider how you are using JavaScript on your websites and think about how to mitigate any performance issues that it might be causing. While images and video account for over 70% of the bytes downloaded for the average website, byte per byte, JavaScript has a greater potential for negative performance impact — it can significantly impact download times, rendering performance, and CPU and battery usage. This article introduces tips and techniques for optimizing JavaScript to enhance the performance of your website. To learn about the effects of JavaScript on web performance and how to mitigate or fix related issues.\n\nTo optimize or not to optimize The first question you should answer before starting to optimize your code is \"what do I need to optimize?\". Some of the tips and techniques discussed below are good practices that will benefit just about any web project, whereas some are only needed in certain situations. Trying to apply all these techniques everywhere is probably unnecessary, and may be a waste of your time. You should figure out what performance optimizations are actually needed in each project. To do this, you need to measure the performance of your site. As the previous link shows, there are several different ways to measure performance, some involving sophisticated performance APIs. The best way to get started however, is to learn how to use tools such as built-in browser network and performance tools, to see what parts of the page load are taking a long time and need optimizing.\n\nThe most performant, least blocking JavaScript you can use is JavaScript that you don't use at all. You should use as little JavaScript as possible. Some tips to bear in mind:\n• You don't always need a framework: You might be familiar with using a JavaScript framework. If you are experienced and confident with using this framework, and like all of the tooling it provides, then it might be your go-to tool for building most projects. However, frameworks are JavaScript-heavy. If you are creating a fairly static experience with few JavaScript requirements, you probably don't need that framework. You might be able to implement what you need using a few lines of standard JavaScript.\n• Consider a simpler solution: You might have a flashy, interesting solution to implement, but consider whether your users will appreciate it. Would they prefer something simpler?\n• Remove unused code: This may sound obvious, but it is surprising how many developers forget to clean up unused functionality that was added during the development process. You need to be careful and deliberate about what is added and removed. All script gets parsed, whether it is used or not; therefore, a quick win to speed up downloads would be to get rid of any functionality not being used. Consider also that often you will only use a small amount of the functionality available in a framework. Is it possible to create a custom build of the framework that only contains the part that you need?\n• Consider built-in browser features: It might be that you can use a feature the browser already has, rather than creating your own via JavaScript. For example:\n• Use the browser's own player.\n• Use CSS animations instead of a JavaScript animation library (see also Handling animations). You should also split your JavaScript into multiple files representing critical and non-critical parts. JavaScript modules allow you to do this more efficiently than just using separate external JavaScript files. Then you can optimize these smaller files. Minification reduces the number of characters in your file, thereby reducing the number of bytes or weight of your JavaScript. Gzipping compresses the file further and should be used even if you don't minify your code. Brotli is similar to Gzip, but generally outperforms Gzip compression. You can split and optimize your code manually, but often a module bundler like webpack will do a better job of this.\n\nBefore looking at the tips contained in this section, it is important to talk about where in the process of browser page rendering JavaScript is handled. When a web page is loaded:\n• The HTML is generally parsed first, in the order in which it appears on the page.\n• Whenever CSS is encountered, it is parsed to understand the styles that need to be applied to the page. During this time, linked assets such as images and web fonts start to be fetched.\n• Whenever JavaScript is encountered, the browser parses, evaluates, and runs it against the page.\n• Slightly later on, the browser works out how each HTML element should be styled, given the CSS applied to it.\n• The styled result is then painted to the screen. Note: This is a very simplified account of what happens, but it does give you an idea. The key step here is Step 3. By default, JavaScript parsing and execution are render-blocking. This means that the browser blocks the parsing of any HTML that appears after the JavaScript is encountered, until the script has been handled. As a result, styling and painting are blocked too. This means that you need to think carefully not only about what you are downloading, but also about when and how that code is being executed. The next few sections provide useful techniques for optimizing the parsing and execution of your JavaScript.\n\nLoading critical assets as soon as possible If a script is really important and you are concerned that it is affecting performance by not being loaded quickly enough, you can load it inside the of the document: This works OK, but is render-blocking. A better strategy is to use to create a preloader for critical JavaScript: The preload fetches the JavaScript as soon as possible, without blocking rendering. You can then use it wherever you want in your page: or inside your script, in the case of a JavaScript module: Note: Preloading does not guarantee that the script will be loaded by the time you include it, but it does mean that it will start being downloaded sooner. Render-blocking time will still be shortened, even if it is not completely removed.\n\nOn the other hand, you should aim to defer parsing and execution of non-critical JavaScript to later on, when it is needed. Loading it all up-front blocks rendering unnecessarily. First of all, you can add the attribute to your elements: This causes the script to be fetched in parallel with the DOM parsing, so it will be ready at the same time and won't block rendering. Note: There is another attribute, , which causes the script to be executed after the document has been parsed, but before firing the event. This has a similar effect to . You could also just not load the JavaScript at all until an event occurs when it is needed. This could be done via DOM scripting, for example: const scriptElem = document.createElement(\"script\"); scriptElem.src = \"index.js\"; scriptElem.addEventListener(\"load\", () => { // Run a function contained within index.js once it has definitely loaded init(); }); document.head.append(scriptElem); JavaScript modules can be dynamically loaded using the function: import(\"./modules/myModule.js\").then((module) => { // Do something with the module });\n\nWhen the browser runs your JavaScript, it will organize the script into tasks that are run sequentially, such as making fetch requests, driving user interactions and input through event handlers, running JavaScript-driven animation, and so on. Most of this happens on the main thread, with exceptions including JavaScript that runs in Web Workers. The main thread can run only one task at a time. When a single task takes longer than 50 ms to run, it is classified as a long task. If the user attempts to interact with the page or an important UI update is requested while a long task is running, their experience will be affected. An expected response or visual update will be delayed, resulting in the UI appearing sluggish or unresponsive. To mitigate this issue, you need to break down long tasks into smaller tasks. This gives the browser more chances to perform vital user interaction handling or UI rendering updates — the browser can potentially do them between each smaller task, rather than only before or after the long task. In your JavaScript, you might do this by breaking your code into separate functions. This also makes sense for several other reasons, such as easier maintenance, debugging, and writing tests. However, this kind of structure doesn't help with main thread blocking. Since all the five functions are being run inside one main function, the browser runs them all as a single long task. To handle this, we tend to run a \"yield\" function periodically to get the code to yield to the main thread. This means that our code is split into multiple tasks, between the execution of which the browser is given the opportunity to handle high-priority tasks such as updating the UI. A common pattern for this function uses to postpone execution into a separate task: This can be used inside a task runner pattern like so, to yield to the main thread after each task has been run: async function main() { // Create an array of functions to run const tasks = [a, b, c, d, e]; // Loop over the tasks while (tasks.length > 0) { // Shift the first task off the tasks array const task = tasks.shift(); // Run the task task(); // Yield to the main thread await yield(); } } To improve this further, we can use where available to allow this code to continue executing ahead of other less critical tasks in the queue: function yield() { // Use scheduler.yield() if available if (\"scheduler\" in window && \"yield\" in scheduler) { return scheduler.yield(); } // Fall back to setTimeout: return new Promise((resolve) => { setTimeout(resolve, 0); }); }\n\nAnimations can improve perceived performance, making interfaces feel snappier and making users feel like progress is being made when they are waiting for a page to load (loading spinners, for example). However, larger animations and a higher number of animations will naturally require more processing power to handle, which can degrade performance. The most obvious piece of animation advice is to use less animations — cut out any non-essential animations, or consider giving your users a preference they can set to turn off animations, for example if they are using a low-powered device or a mobile device with limited battery power. For essential DOM animations, you are advised to use CSS animations where possible, rather than JavaScript animations (the Web Animations API provides a way to directly hook into CSS animations using JavaScript). Using the browser to directly perform DOM animations rather than manipulating inline styles using JavaScript is much faster and more efficient. See also CSS performance optimization > Handling animations. For animations that can't be handled in JavaScript, for example, animating an HTML , you are advised to use rather than older options such as . The method is specially designed for handling animation frames efficiently and consistently, for a smooth user experience. The basic pattern looks like this: function loop() { // Clear the canvas before drawing the next frame of the animation ctx.fillStyle = \"rgb(0 0 0 / 25%)\"; ctx.fillRect(0, 0, width, height); // Draw objects on the canvas and update their positioning data // ready for the next frame for (const ball of balls) { ball.draw(); ball.update(); } // Call requestAnimationFrame to run the loop() function again // at the right time to keep the animation smooth requestAnimationFrame(loop); } // Call the loop() function once to set the animation running loop(); You can find a nice introduction to canvas animations at Drawing graphics > Animations, and a more in-depth example at Object building practice. You can also find a full set of canvas tutorials at Canvas tutorial.\n\nEvents can be expensive for the browser to track and handle, especially when you are running an event continuously. For example, you might be tracking the position of the mouse using the event to check whether it is still inside a certain area of the page: function handleMouseMove() { // Do stuff while mouse pointer is inside elem } elem.addEventListener(\"mousemove\", handleMouseMove); You might be running a game in your page. While the mouse is inside the canvas, you will want to constantly check for mouse movement and cursor position and update the game state — including the score, the time, the position of all the sprites, collision detection information, etc. Once the game is over, you will no longer need to do all that, and in fact, it will be a waste of processing power to keeping listening for that event. It is, therefore, a good idea to remove event listeners that are no longer needed. This can be done using : Another tip is to use event delegation wherever possible. When you have some code to run in response to a user interacting with any one of a large number of child elements, you can set an event listener on their parent. Events fired on any child element will bubble up to their parent, so you don't need to set the event listener on each child individually. Less event listeners to keep track of means better performance. See Event delegation for more details and a useful example.\n\nThere are several general best practices that will make your code run more efficiently.\n• Reduce DOM manipulation: Accessing and updating the DOM is computationally expensive, so you should minimize the amount that your JavaScript does, especially when performing constant DOM animation (see Handling JavaScript animations above).\n• Batch DOM changes: For essential DOM changes, you should batch them into groups that get done together, rather than just firing off each individual change as it occurs. This can reduce the amount of work the browser is doing in real terms, but also improve perceived performance. It can make the UI look smoother to get several updates out of the way in one go, rather than constantly making small updates. A useful tip here is — when you have a large chunk of HTML to add to the page, build the entire fragment first (typically inside a ) and then append it all to the DOM in one go, rather than appending each item separately.\n• Simplify your HTML: The simpler your DOM tree is, the faster it can be accessed and manipulated with JavaScript. Think carefully about what your UI needs, and remove unnecessary cruft.\n• Reduce the amount of looped code: Loops are expensive, so reduce the amount of loop usage in your code wherever possible. In cases where loops are unavoidable:\n• Avoid running the full loop when it is unnecessary, using or statements as appropriate. For example, if you are searching arrays for a specific name, you should break out of the loop once the name is found; there is no need to run further loop iterations: function processGroup(array) { const toFind = \"Bob\"; for (let i = 0; i < array.length - 1; i++) { if (array[i] === toFind) { processMatchingArray(array); break; } } }\n• Do work that is only needed once outside the loop. This may sound a bit obvious, but it is easy to overlook. Take the following snippet, which fetches a JSON object containing data to be processed in some way. In this case the operation is being done on every iteration of the loop, which is a waste of computing power. The fetching, which does not depend on , could be moved outside the loop, so it is only done once.\n• Run computation off the main thread: Earlier on we talked about how JavaScript generally runs tasks on the main thread, and how long operations can block the main thread, potentially leading to bad UI performance. We also showed how to break long tasks up into smaller tasks, mitigating this problem. Another way to handle such problems is to move tasks off the main thread altogether. There are a few ways to achieve this:\n• Use asynchronous code: Asynchronous JavaScript is basically JavaScript that does not block the main thread. Asynchronous APIs tend to handle operations such as fetching resources from the network, accessing a file on the local file system, or opening a stream to a user's web cam. Because those operations could take a long time, it would be bad to just block the main thread while we wait for them to complete. Instead, the browser executes those functions, keeps the main thread running subsequent code, and those functions will return results once they are available at some point in the future. Modern asynchronous APIs are -based, which is a JavaScript language feature designed for handling asynchronous operations. It is possible to write your own Promise-based functions if you have functionality that would benefit from being run asynchronously.\n• Run computation in web workers: Web Workers are a mechanism allowing you to open a separate thread to run a chunk of JavaScript in, so that it won't block the main thread. Workers do have some major restrictions, the biggest being that you can't do any DOM scripting inside a worker. You can do most other things, and workers can send and receive messages to and from the main thread. The main use case for workers is if you have a lot of computation to do, and you don't want it to block the main thread. Do that computation in a worker, wait for the result, and send it back to the main thread when it is ready.\n• Use WebGPU: WebGPU is a browser API that allows web developers to use the underlying system's GPU (Graphics Processing Unit) to carry out high-performance computations and draw complex images that can be rendered in the browser. It is fairly complex, but it can provide even better performance benefits than web workers."
    },
    {
        "link": "https://bitskingdom.com/blog/optimizing-javascript-speed-strategies",
        "document": "Ever felt like your website’s as sluggish as a Monday morning without coffee? You’re not alone. The digital universe is loaded with websites struggling to hit the right notes of performance, often bogged down by clunky JavaScript files.\n\nBut worry not, fellow web maestros! If you enjoyed our Day.js JavaScript Date Management Guide, you’re in for another treat. We’re here to guide you through the process of JavaScript optimization, ensuring your website performs like a well-rehearsed orchestra.\n\nWe’ve all been there – those endless nights where coding feels like a hamster wheel. Loops, if not fine-tuned, can indeed feel like running in circles without a destination. Instead of the old-school loop, it’s high time you dance to the tunes of , , and . They don’t just offer a clearer path but boost your code’s tempo.\n\nNew Rhythm: Using for clarity and speed.\n\nEver thought of using the statement? It’s like hitting the pause button during a song, skipping needless repetitions. If you’re scratching your head, don’t just rely on hearsay. Check into developer forums and see these strategies in action.\n\nImagine a music band where every instrument wants to be the soloist. Chaos, right? Debouncing and throttling ensure your code’s components play in rhythm, not letting any function overshadow the others.\n\n3. The Backbone Beats: Set and Map for Data Efficiency\n\nES6 wasn’t just another update; it was like introducing a brand-new instrument to an orchestra. Data structures like and are those new beats that can redefine your coding rhythm. If your code was a sandwich, think of it as that special ingredient making it stand out!\n\nFor example, you can use for unique values. It’s that special ingredient to make your code stand out!\n\nChanging from to isn’t about being whimsical; it’s about choosing the faster horse in the race. It’s like preferring acoustic to electric when you know the former fits the song better.\n\nWho invited errors to this concert, anyway? But like that unexpected instrument going out of tune, errors happen. With , , and , you ensure the show goes on, and the audience (read: users) remains engrossed.\n\nIt’s like being a maestro, knowing where each note (event) fits. Rather than bombarding every section of the orchestra with cues, be selective. Choose a common anchor point and let the symphony flow organically.\n\nThink of JavaScript optimization as composing a piece of music. Each tweak, every adjustment, harmonizes the output, making web interactions melodious for your audience. But remember, the world of web development is a vast ocean, and there’s always more to explore."
    },
    {
        "link": "https://dev.to/hkp22/writing-clean-and-efficient-javascript-10-best-practices-every-developer-should-know-20be",
        "document": "Writing Clean and Efficient JavaScript: 10 Best Practices Every Developer Should Know\n\nJavaScript Shallow Copy vs Deep Copy: Examples and Best Practices\n\nMastering Arrow Functions in JavaScript: Simplify Your Code with Concise Syntax and Lexical `this` Binding\n\nJavaScript is an essential tool in modern web development, but as applications grow in complexity, messy or inefficient code can lead to bugs, performance bottlenecks, and maintainability issues. Writing clean, efficient, and maintainable JavaScript is key to creating scalable applications.\n\nThis post will cover 10 essential best practices to help you streamline your code, optimize performance, and ensure maintainability. These practices include leveraging modern ES6+ features, optimizing workflows, and building scalable architectures. Many of these techniques and tools are discussed in the eBook JavaScript: From ES2015 to ES2023, your go-to resource for mastering modern JavaScript features.\n\nThe introduction of ES6 (ECMAScript 2015) and subsequent updates have revolutionized JavaScript, making code more concise, readable, and powerful. Features such as destructuring, arrow functions, template literals, and nullish coalescing are must-haves in your toolkit.\n\nFor example, nullish coalescing ( ) ensures cleaner handling of null or undefined values:\n\n\n\nFor a detailed exploration of these and other features, refer to JavaScript: From ES2015 to ES2023.\n\nModular programming makes codebases more organized, maintainable, and scalable. ES6 module syntax allows you to encapsulate functionality and share it across your application.\n\n\n\nConsistent coding style is critical for readability and maintainability. Tools like ESLint help enforce coding standards by catching errors early, while Prettier automatically formats your code for a uniform appearance.\n\n\n\nIntegrating ESLint and Prettier tools into your workflow reduces errors, saves time during reviews, and ensures clean, professional code.\n\nFor event-heavy applications, such as those using or , unoptimized event handling can degrade performance. Debouncing and throttling control the rate at which functions execute, improving responsiveness.\n• Debouncing: Delays execution until after a specified inactivity period.\n• Throttling: Ensures execution occurs at most once in a given timeframe.\n\nMemoization is an optimization technique that stores the results of expensive function calls to prevent redundant calculations.\n\n\n\nMemoization is particularly effective for computationally intensive tasks.\n\nDynamic imports enable you to load JavaScript modules on demand, improving initial load times for large applications.\n\n\n\nThis technique is especially valuable in single-page applications (SPAs) to manage performance.\n\nReadable code reduces the need for excessive comments and makes maintenance easier. Use descriptive variable and function names to convey intent clearly.\n\n\n\nFor complex logic or larger projects, supplement your code with tools like JSDoc to generate professional documentation.\n\nTesting ensures your code works as intended and reduces the risk of bugs. Use unit tests for individual functions and integration tests for interactions between components.\n\n\n\nFrameworks like Jest and Mocha simplify the testing process, allowing you to refactor with confidence.\n\nProactive error handling ensures your application remains functional, even when something goes wrong. Use blocks for runtime errors and validate inputs to prevent unexpected behavior.\n\n\n\nJavaScript evolves rapidly, with new features and best practices emerging regularly. Stay informed by reading resources like JavaScript: From ES2015 to ES2023, engaging with the developer community, and following blogs or forums.\n\nAdopting these 10 best practices will transform your JavaScript development. From leveraging modern ES6+ features to optimizing performance with memoization and dynamic imports, these techniques ensure your code is clean, maintainable, and efficient.\n\nFor an in-depth understanding of the latest JavaScript features and trends, don’t miss the eBook JavaScript: From ES2015 to ES2023. Start implementing these tips today and elevate your JavaScript skills to the next level!"
    },
    {
        "link": "https://upwork.com/resources/javascript-optimization-tips",
        "document": "Check out our latest products, partners, and enhancements.\n\nNews and stories from the world’s work marketplace.\n\nInsights and tools for business leaders navigating a new world of work."
    },
    {
        "link": "https://najm-eddine-zaga.medium.com/top-javascript-best-practices-cf897022b6fd",
        "document": "In JavaScript, using new Object is a bit risky, while using primitives always better for several reasons. Let’s dig deeper into this. The for example, creates a string primitive as we all know, on the other hand… creates a string object. As they are more complex and have methods, string object can bring unexpected behavior, precisely when it comes to comparisons and type coercion. Primitives are simpler in usage and more straightforward, as their usage avoids unnecessary complexity, and the code become easy to read and maintain. Primitives are more efficient in terms of memory and performance. While creating an object involves additional overhead. Since JavaScript treats objects and primitives differently, using can lead to confusing situations where you’re unintentionally dealing with an object instead of a primitive, which might take you to a nest of bugs. In most cases, it’s better to use primitives instead. // ❌ Avoid\n\nconst str = new String();\n\nconst num = new Number();\n\nconst bool = new Boolean();\n\nconst obj = new Object();\n\nconst arr = new Array();\n\nconst regEx = new RegExp();\n\nconst func = new Function();\n\n\n\n// ✅ Use\n\nconst str = \"JavaScript\";\n\nconst num = 10;\n\nconst bool = true;\n\nconst obj = {};\n\nconst arr = [];\n\nconst regEx = /()/;\n\nconst func = function() {};\n\n2 — Avoid using let with arrays and objects First of all, let’s be clear… Using with arrays and objects is not inherently problematic at all. But there are some specific considerations that might lead you to avoid it in certain cases: As we all know, allows us to reassign the variable itself, which can lead to confusion or data loss. An object / array can be reassigned by accident with an entire new set of data (new object / new array). Using instead makes it safer and clear that the reference to the object / array won’t change, but you can still modify it’s content. Using , you signal to other developers you work with that the variable should not be reassigned, enhancing code readability and maintainability. While has a block scope, it can lead to unexpected behavior in loops or conditional statements. By using , the variable remains in scope without the risk of unintentional reassignment. Many coding standards and best practices encourage using for variables that don’t need reassignment, promoting cleaner and more predictable code. // ❌ Avoid\n\nlet book = { title: \"Inferno\", author: \"Dan Brown\" };\n\n\n\n// The book object will be overrode with string\n\nbook = \"Hello world\"; // ✅ Use\n\nconst book = { title: \"Inferno\", author: \"Dan Brown\" };\n\n\n\n// The book object cannot be overrode\n\nbook = \"Hello world\";\n\nand are comparison operators used to compare values, but they behave differently. When using , JavaScript converts the values to a common type before making the comparison console.log(5 == '5'); // true (number is converted to string)\n\nconsole.log(null == undefined); // true (considered equal)\n\nconsole.log(0 == false); // true (0 is converted to boolean as it's falsy value) With , the comparison checks both the value and the type. If types are different, it returns console.log(5 === '5'); // false (different types)\n\nconsole.log(null === undefined); // false (different types)\n\nconsole.log(0 === false); // false (different types) When to Use ? Use when you want to ensure both value and type are the same, which is generally a good practice to avoid unexpected results. Use if you specifically need to compare values without considering their types, but this can lead to bugs and usually discouraged. In general, consider using for more predictable and clear comparisons. Note: Same thing goes with and\n\nIn JavaScript, using destructuring technique with Objects and Arrays gives you several benefits. The destructuring assignment syntax is a JavaScript expression that makes it possible to unpack values from arrays, or properties from objects, into distinct variables. As MDN web docs says. It allows you to extract multiple properties from an object or elements from an array in a single statement, reducing the amount of code you need to write. const book = { name: 'The Lost Symbol', author: 'Dan Brown' };\n\nconst { name, price } = book; // concise extraction Destructuring can make your code more readable by clearly showing which properties or elements you are working with. You can easily assign default values if the property or element doesn’t exist. const { height = 180 } = person; // uses default value if height is undefined You can destructure nested objects or arrays, which can simplify accessing deeply nested data. const user = { profile: { name: 'Eren Yeager', age: 20 } };\n\nconst { profile: { name } } = user; // easy access to nested properties It can be useful for function parameters, allowing you to unpack values directly. Destructuring helps streamline your code, making it cleaner and easier to maintain.\n\nThe DRY (Don’t Repeat Yourself) principle is a key concept in software development aimed at reducing repetition in code. By ensuring that every piece of knowledge or logic is represented in a single place, you make your code easier to maintain, understand, and refactor. Encapsulate repetitive logic in functions. This way, you can reuse the same code without duplication. function calculateArea(width, height) {\n\n return width * height;\n\n}\n\n\n\n// Use the function instead of repeating the code\n\nconst area1 = calculateArea(5, 10);\n\nconst area2 = calculateArea(7, 3); Use modules to organize your code. This helps keep related functions and variables together, making them reusable across different parts of your application. Utilize classes or objects to group related data and behaviors. This encapsulation helps avoid repetition when working with similar data structures. Note: If you’re adopting the “Functional Programming” paradigm in your daily coding, consider using any other tip but this one “Classes and Objects”. In web development, use templates or components (in frameworks like React, Vue, etc.) to encapsulate UI logic and styles that are reused. Use arrays or objects to store related data rather than creating separate variables for each piece of data. const members = [\n\n { name: 'Feitan Portor', nen: \"Transmutation\" },\n\n { name: 'Nobonaga Hazama', nen: \"Enhancement\"},\n\n];\n\n\n\n// Iterate over users without repeating code\n\nmembers.forEach(member => console.log(member.name)); Use configuration objects to pass parameters to functions or classes instead of having multiple parameters. function addMember({ name, nen }) {\n\n return { name, nen };\n\n}\n\n\n\nconst member = addMember({ name: 'Illumi Zoldyck', nen: \"Manipulation\" }); Applying the DRY principle leads to cleaner, more maintainable code. It helps minimize the risk of bugs since changes need to be made in only one place, and it enhances readability by reducing clutter. Remember that while it’s important to avoid repetition, there’s a balance to strike; over-abstracting can lead to complexity, so use your judgment when applying these principles.\n\nUsing meaningful variable and function names is crucial for writing clear, maintainable, and understandable code. Choose names that clearly describe the purpose or value of the variable or function. // ❌ Bad\n\nlet x = 10; // What does x represent?\n\n\n\n// ✅ Good\n\nlet itemCount = 10; // Clearly indicates it's a count of items. Start functions with a verb that describes the action being performed. While short names might seem convenient, they can lead to confusion. Avoid abbreviations unless they are widely understood. // ❌ Bad\n\nlet amt = 50; // What does amt mean?\n\n\n\n// ✅ Good\n\nlet amount = 50; // Clear and understandable. Stick to a consistent naming convention throughout your codebase, such as camelCase for variables and functions, and PascalCase for classes. Indicate Data Type or Purpose in Names If a variable holds a specific type of data or serves a particular purpose, include that in the name. // ❌ Bad\n\nlet data = []; // What kind of data?\n\n\n\n// ✅ Good\n\nlet userProfiles = []; // Indicates it's an array of user profiles. Consider the context in which the variable or function will be used to make names more meaningful. // ❌ Bad\n\nlet list = []; // Vague\n\n\n\n// ✅ Good\n\nlet todoList = []; // Clearly indicates it's for to-do items. Keep It Concise but Clear While names should be descriptive, they shouldn’t be excessively long. Aim for a balance between clarity and brevity. If you’re working in a specific domain (like finance, healthcare, etc.), use terms that are familiar to that domain. let interestRate = 5.5; // Clear in a financial context. If you find that a name is no longer suitable as the code evolves, don’t hesitate to refactor it for better clarity. let temp = 30; // After some time, this name may become unclear.\n\nlet roomTemperature = 30; // After refactor... More descriptive. Meaningful variable and function names significantly enhance code readability and maintainability. They help others (and yourself) understand the purpose and function of your code at a glance, making collaboration and debugging much easier. Always strive for clarity in your naming conventions.\n\nAvoiding global variables is a key practice in JavaScript (and programming in general) to maintain clean, modular, and maintainable code. Global variables can lead to unexpected behavior, naming conflicts, and difficulty in debugging. Declare variables within functions to limit their scope and prevent them from being accessible globally. Use Block Scope with and Utilize and to declare variables within blocks (like loops or conditionals), ensuring they are not accessible outside that block. for (let i = 0; i < 10; i++) {\n\n let square = i * i; // `square` is block-scoped\n\n console.log(square);\n\n}\n\n// console.log(square); // ReferenceError: square is not defined Organize your code into modules. Use ES6 modules or IIFE (Immediately Invoked Function Expressions) to encapsulate variables. Group related variables and functions within an object to avoid polluting the global scope. If you need to persist data, consider using local storage, session storage, or indexedDB instead of global variables. Limit the Use of Globals If you must use global variables, limit their use to configuration constants or application-wide settings. Name them clearly to indicate their global nature. const APP_VERSION = \"1.0.0\"; // A constant that might be needed globally When designing functions, avoid modifying global variables. This keeps functions predictable and easier to test. let counter = 0;\n\n\n\nfunction incrementCounter() {\n\n return ++counter; // Avoid this! Instead, return a new value.\n\n} In object-oriented programming, use to manage state within instances instead of relying on global variables. By avoiding global variables, you enhance the modularity and maintainability of your code. It helps prevent naming conflicts and unintended side effects, making your code more predictable and easier to work with. Following these best practices will lead to cleaner and more manageable codebases.\n\nDocumenting your code is essential for maintaining clarity, aiding collaboration, and ensuring long-term maintainability.\n• Explain “Why,” Not “What”: Focus on explaining why you did something rather than what the code does. The code itself should be readable enough to convey what it does. // ❌ Bad: This doesn't provide much context\n\nlet x = 10; // Assigns 10 to x\n\n\n\n// ✅ Good: Explains the purpose\n\nlet maxRetries = 10; // Maximum number of attempts for the API call\n• Comment Complex Logic: For complex or non-obvious sections of code, provide detailed explanations. // Check if user has the necessary permissions to access the resource\n\nif (user.role === 'admin' || user.permissions.includes('access_resource')) {\n\n // Proceed with the operation\n\n} In JavaScript, especially when using JSDoc, you can document functions, classes, and methods using structured comments. /**\n\n * Calculates the total price including tax.\n\n * @param {number} price - The original price of the item.\n\n * @param {number} tax - The tax rate as a decimal.\n\n * @returns {number} The total price after tax.\n\n */\n\nfunction calculateTotal(price, tax) {\n\n return price + (price * tax);\n\n} For libraries or modules, provide clear documentation for public APIs, including parameters, return values, and usage examples. /**\n\n * Fetches user data from the server.\n\n * @async\n\n * @param {string} userId - The ID of the user to fetch.\n\n * @returns {Promise<Object>} A promise that resolves to the user data.\n\n * @throws {Error} Throws an error if the fetch fails.\n\n */\n\nasync function fetchUserData(userId) {\n\n const response = await fetch(`/api/users/${userId}`);\n\n if (!response.ok) {\n\n throw new Error('Failed to fetch user data');\n\n }\n\n return response.json();\n\n} For projects, maintain a file that provides an overview, installation instructions, usage examples, and contribution guidelines. Effective documentation makes your code more understandable and maintainable, helping both current and future developers (including yourself) work efficiently. By incorporating these practices into your development workflow, you’ll foster better collaboration and reduce the learning curve for anyone interacting with your code."
    }
]