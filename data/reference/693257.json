[
    {
        "link": "https://geeksforgeeks.org/vector-in-cpp-stl",
        "document": "In C++, vector is a dynamic array that stores collection of elements same type in contiguous memory. It has the ability to resize itself automatically when an element is inserted or deleted.\n\nVector is defined as the std::vector class template inside the <vector> header file.\n\nwhere T is the type of elements and v is the name assigned to the vector.\n\nCreating a vector involves creating an instance of std::vector class. This requires us to provide the type of elements as template parameter.\n\nWe can also provide the values to be stored in the vector inside {} curly braces. This process is called initialization.\n\nIn the above example,\n• vector<int> v2(5, 9) creates a vector of size 5 where each element initialized to 9.\n\nMore ways to declare and initialize vectors are discussed in this article – 8 Ways to Initialize Vector in C++\n\nAn element can be inserted into a vector using vector insert() method which takes linear time. But for the insertion at the end, the vector push_back() method can be used. It is much faster, taking only constant time.\n\nMore ways to insert an element in the vector are discussed in the article – Different Ways to Add Elements in a Vector\n\nJust like arrays, vector elements can be accessed using their index inside the [] subscript operator. This method is fast but doesn’t check whether the given index exists in the vector or not. So, there is another member method vector at() for safely accessing elements.\n\nTo know more about accessing vector elements, refer to the article – Different Ways to Access Elements in Vector\n\nUpdating elements is very similar to the accessing except that we use an assignment operator to assign a new value. It uses the same methods: [] subscript operator and vector at().\n\nMore methods to update vector elements are discussed in this article – Different Ways to Update Vector Elements\n\nOne of the common problems with arrays was to keep a separate variable to store the size information. Vector provides the solution to this problem by providing size() method.\n\nVector in C++ can be traversed using indexes in a loop. The indexes start from 0 and go up to vector size – 1. To iterate through this range, we can use a loop and determine the size of the vector using the vector size()method.\n\nWe can also use a range-based loop for simple traversal. More ways to traverse vectors are discussed in this article – Different Ways to Iterate Through Vector\n\nAn element can be deleted from a vector using vector erase() but this method needs iterator to the element to be deleted. If only the value of the element is known, then find() function is used to find the position of this element.\n\nFor the deletion at the end, the vector pop_back() method can be used, and it is much faster, taking only constant time.\n\nTo know more about the deletion of an element in the vector, refer to this article – Different Ways to Remove Elements from Vector\n\nVector is one of the most frequently used containers in C++. It is used in many situations for different purposes. The following examples aim to help you master vector operations beyond the basics.\n\nThe below table lists the time complexity of the above operations on a vector:\n\nVectors can be passed to a function as arguments just like any other variable in C++. But it is recommended to pass the vector by reference so as to avoid the copying of all elements which can be expensive if the vector is large. Refer to this article to know more – Passing Vector to a Function\n\nVector internal working is very interesting and useful to select and optimize its usage. Understanding the internal memory management also helps in modifying the default mechanism of vector to suits our needs. Refer to this article to know more – Internal Working of Vector\n\nJust like arrays, we can also create multidimensional vectors in C++. Each element of multidimensional vector can be visualized as the collection of vectors with dimension one less that the current vector. For example, 2D vectors are the collection of 1D vectors, while 3D vectors are the collection of 2D vectors and so on.\n\nWith the addition of each dimension, the complexity of operations on the vectors also increases.\n\nRefer to this article to know more – Multidimensional Vectors in C++\n\nFollowing is the list of all member functions of std::vector class in C++:\n\nAdds an element to the end of the vector. Removes the last element of the vector. Returns the number of elements in the vector. Returns the maximum number of elements that the vector can hold. Changes the size of the vector. Checks if the vector is empty. Accesses the element at a specific position, with bounds checking. Accesses the first element of the vector. Accesses the last element of the vector. Returns an iterator pointing to the first element of the vector. Returns an iterator pointing to the past-the-end element of the vector. Returns a reverse iterator pointing to the last element of the vector. Returns a reverse iterator pointing to the element preceding the first element of the vector. Inserts elements at a specific position in the vector. Removes elements from a specific position or range in the vector. Swaps the contents of the vector with those of another vector. Removes all elements from the vector. Constructs and inserts an element in the vector. Constructs and inserts an element at the end of the vector. Assigns new values to the vector elements by replacing old ones. Returns the size of the storage space currently allocated to the vector. Requests that the vector capacity be at least enough to contain a specified number of elements. Returns a direct pointer to the memory array used internally by the vector to store its owned elements. Returns a copy of the allocator object associated with the vector."
    },
    {
        "link": "https://studyplan.dev/intro-to-programming/std-vector",
        "document": "Inevitably, we will want to store a group of related objects. That might be a collection of characters in a party, a collection of buttons on a UI, or countless other use cases.\n\nLet's imagine we have these objects, which we want to store and manage as a single collection:\n\nProgrammers have invented a huge range of options for storing collections of objects. These containers are broadly called data structures, and which data structure we should use depends on our specific requirements. We’ll cover a much wider range of data structures in the next course. Here, we’ll introduce the most common choice - the dynamic array.\n\nUnder the hood, arrays are contiguous blocks of memory, big enough to store multiple objects in sequence.\n\nThere are hundreds of implementations of arrays in C++ that we can use, and we can even create our own once we learn more advanced topics. In this lesson, we’re using the standard library’s implementation of dynamic arrays, which is called .\n\nThe C++ standard library using the \"vector\" name for their implementation of dynamic arrays is unfortunate. When we’re working on projects that involve maths and physics, such as a video games, the constructs we use to represent things like positions, movement and forces are also called vectors.\n\nThese vectors are not related to arrays at all - the confusing naming conflict is just something we need to adapt to.\n\nTo use , we need to . We can then declare a by giving it a name, and specifying the type of objects it will contain within angled brackets: and . The following example shows how we can declare a called that stores objects:\n\nWhen we see chevrons - and - in our code, we’re typically using an advanced C++ feature called templates. Templates allow classes and functions to be written without specifying all of the data types that the class or function will be using. In this case, the standard library authors created a container called that can store a collection of any type of object. As developers using , we just need to provide the type we want to store between the chevrons. This type we provide is referred to as a template argument. When we pass as the template argument - that is, - we create an array for storing values. But we can replace with any type: Templates are particularly powerful as they allow classes and functions to be compatible with types that aren’t known or don’t exist at the time the template was written. For example, the authors of couldn’t know we would want to store a collection of objects, but their code supports it anyway: We cover templates in much more detail, including how to create our own, in the advanced course.\n\nWe can provide a with some initial values:\n\nWhen we are initializing the values at the same time we declare the array, we can optionally remove the template argument. The compiler can infer what type the vector will be storing, based on the type of objects we provided for its initial values:\n\nTo do this, the compiler is using Class Template Argument Deduction (CTAD), which we’ll cover more in our advanced course.\n\nWe can access the members of our array with the subscript operator, which uses syntax. For example, to access an object within , we’d use , where is the index of the element we want to access.\n\nThe index of an element within an array is simply its position within the array. However, in most programming contexts, indexing is zero-based, meaning we start counting from . This means the first element of the vector is at index , the second element is at index , and so on.\n\nFor example, to access the elements of our array, we would do this:\n\nAs with all values, the index can be derived from any expression that evaluates to an integer:\n\nThis code logs out elements at indices , , and in order:\n\nThe size of an array refers to the number of elements it currently contains. This is also sometimes called the length of the array.\n\nThe function returns the current size of our :\n\nNote that because indexing is zero-based, the last element of a vector is at an index of one less than its . For an array of size , the last element is at index .\n\nWe can get the last element by applying this arithmetic within the subscript operator, or by using the function:\n\nOnce our array is created, we’ll often want to add more items to it. Typically, we want to add items to the end of arrays, as this has performance benefits over adding them to the start. We’ll cover the performance characteristics of containers in more detail in the next course.\n\nand many other data structures provide two ways of adding objects:\n• Pushing an object involves moving or copying an existing object into the container\n• Emplacing an object involves creating a new object directly within the container\n\nCreating an object in place has performance benefits over creating it elsewhere and then moving it. Therefore, where possible, we should prefer emplacing over pushing.\n\nWith , we’re adding items to the back of the container, so the respective functions are called and\n\nIf an object has already been constructed, and we want to add it to the back of our array, we can use :\n\nIf the object we want to add does not already exist, we can construct it right inside of the array, using .\n\nThe arguments we call with will be passed to the constructor of the object type the vector stores:\n\nThe type also offers an method to remove objects from our array. The erase method requires we provide an iterator, which is slightly more advanced than a simple index.\n\nWe cover iterators in detail in the advanced course, but for now, note that we can get an iterator corresponding to a index using , where is the index we’re interested in.\n\nSo, for example, to erase the second item (the item at index ) from our array we’d use:\n\nThe of our array will be reduced by , and all of the objects that were after the element we erased get moved by one position to the left to fill in the gap:\n\nWe can modify objects in a in the usual ways. We can replace the object at a given index using the assignment operator, :\n\nWe can also call functions (including operators) on our objects as needed:\n\nOur above example uses vectors with values, but we can store pointers and references in arrays too:\n\nArrays can also store other arrays. This creates \"multidimensional arrays\". For example, a 3x3 grid could be represented as an array of 3 rows, each row being an array of 3 items:\n\nWe can treat a collection of objects like any other value. Below, we pass a collection to a function:\n\nAs with any other parameter, arrays are passed by value by default. The performance implications are particularly important here, as copying a collection of objects is inherently more expensive than copying a single object.\n\nWe can pass by reference in the usual way, with or without :\n\nWe can also generate and use pointers in the normal way. The following code replicates the previous example, using pointers instead of references:\n\nA common task we have when working with arrays is to perform some action on every object in the collection. We can do this with a loop:\n\nThere is an issue with using values as the index of vectors: modern computers have enough memory to store a lot of objects in an array. This means that the of the array, or the index used to reference a specific position, can be a larger number than the maximum value storable in an .\n\nTo deal with this problem, we have the data type. is guaranteed to be large enough to match the largest possible size of the array.\n\nBecause of this, it is the recommended way of storing array sizes and indices:\n\nOften, we usually don’t need to work with indices at all - we just want to iterate over everything in the array. For those scenarios, we can use this syntax:\n\nThis is known as a range-based for loop. We cover these in more detail in the next course, including how to make our custom types compatible with this syntax.\n\nSimilar to functions, range-based for loops can receive their parameters by reference or value, with value being the default. This means each item in the collection is copied into the body of the loop. We should consider passing by reference instead, particularly if the type we’re using is expensive to copy:\n\nJust like when we’re passing by reference into a function if the loop body isn’t going to modify that reference, we should consider marking it as :\n\nand other arrays keep our objects in contiguous blocks of memory on our system. As we push or emplace objects into our array, it may run out of space at its current memory location.\n\nWe can see how much of our capacity we’re currently using by comparing what is returned from the and methods:\n• returns the number of elements currently in the array.\n• returns the number of elements the array can hold in its current memory location.\n\nBelow, we see the initially has a capacity of , with all spaces being taken. When we add a 6th item, the increases to , whilst the is now :\n\nWhen we add elements beyond the current capacity, the will do some work behind the scenes to let our array grow. It will:\n• Allocate a new block of memory with a larger capacity.\n• Move all existing elements to the new location.\n\nIn our previous example, this new location has enough space to store objects. We’re currently only storing , so we have room to add one more before everything needs to be moved to a larger memory block again.\n\nMoving an array to a new location has a performance cost, so if we’re able to reduce unnecessary movements, we should consider it.\n\nIf we know approximately how many objects our is likely to need to store, we can directly enough capacity for them. Below, we ask our to move to a location with room for objects:\n\nNow, it has plenty of room to grow before it needs to move again:\n\nNaturally, a with a capacity for objects will consume more system memory than one with a capacity of only .\n\nBut if we think it’s eventually going to grow to objects anyway, we may as well just reserve that space from the start and eliminate all the expensive moving.\n• Reallocation can be expensive, especially for large vectors or complex objects.\n• Using can help avoid unnecessary reallocations.\n• However, over-reserving can waste memory if the extra capacity isn't used.\n\nIn this lesson, we've explored the essentials of dynamic arrays, with a particular focus on . You've learned how to create, access, modify, and efficiently manage collections of objects, laying a strong foundation for more advanced programming concepts.\n• Understanding the difference between static and dynamic arrays, and the flexibility of .\n• Creating, initializing, and accessing elements in a , including using and methods.\n• Techniques for modifying elements within a , and the implications of passing vectors to functions.\n• Effective looping through vectors using both traditional and range-based for loops, and the importance of in managing vector sizes.\n• How manages its capacity, and how we can interact with that mechanism using and .\n\nIn the next lesson, we introduce the main design pattern used to manage memory in complex applications. We also introduce smart pointers, the main mechanism used to implement this pattern. We cover:\n• Memory Management Simplified: We explore how smart pointers automate memory management, thereby reducing the chances of memory-related errors.\n• Understanding Memory Ownership: What smart pointers are and how they implement an ownership model for objects in dynamically allocated memory\n• Creating Unique Pointers using : How to create unique pointers using ,\n• Access and Ownership Transfer: How to give other functions access to our resources, and whether we want to maintain or transfer ownership at the same time."
    },
    {
        "link": "https://stackoverflow.com/questions/11189198/dynamic-arrays-vs-stl-vectors-exact-difference",
        "document": "A great deal here depends on what he means by a \"dynamic array\". Most people mean something where the memory is allocated with array-new and freed with array-delete. If that's the intent here, then having qualities on a par with simply isn't possible.\n\nThe reason is fairly simple: routinely allocates a chunk of memory larger than necessary to hold the number of elements currently being stored. It then constructs objects in that memory as needed to expand. With array-new, however, you have no choice -- you're allocating an array of objects, so if you allocate space for (say) 100 objects, you end up with 100 objects being created in that space (immediately). It simply has no provision for having a buffer some part of which contains real objects, and another part of which is just plain memory, containing nothing.\n\nI suppose if yo want to stretch a point, it's possible to imitate and still allocate the space with array-new. To do it, you just have to allocate an array of , and then use placement to create objects in that raw memory space. This allows pretty much the same things as , because it is nearly the same thing as . We're still missing a (potential) level of indirection though -- actually allocates memory via an Allocator object so you can change exactly how it allocates its raw memory (by default it uses , which uses , but if you wanted to, you could actually write an allocator that would use , though I can't quite imagine why you would).\n\nYou could, of course, write your dynamic array to use an allocator object as well. At that point, for all practical purposes you've just reinvented under a (presumably) new name. In that case, @sbi is still right: the mere fact that it's not standardized means it's still missing one of the chief qualities of -- the quality of being standardized and already known by everybody who knows C++. Even without that, though, we have to stretch the phrase \"dynamic array\" to (and I'd posit, beyond) the breaking point to get the same qualities as , even if we ignore standardization."
    },
    {
        "link": "https://cplusplus.com/reference/vector/vector",
        "document": "an unsigned integral type that can represent any non-negative value of\n\nusually the same as size_t"
    },
    {
        "link": "https://stackoverflow.com/questions/1071674/dynamically-allocated-arrays-or-stdvector",
        "document": "I'm trying to optimize my C++ code. I've searched the internet on using dynamically allocated C++ arrays vs using std::vector and have generally seen a recommendation in favor of std::vector and that the difference in performance between the two is negligible. For instance here - Using arrays or std::vectors in C++, what's the performance gap?.\n\nHowever, I wrote some code to test the performance of iterating through an array/vector and assigning values to the elements and I generally found that using dynamically allocated arrays was nearly 3 times faster than using vectors (I did specify a size for the vectors beforehand). I used g++-4.3.2.\n\nHowever I feel that my test may have ignored issues I don't know about so I would appreciate any advice on this issue."
    },
    {
        "link": "https://cplusplus.com/doc/tutorial/files",
        "document": "std; main () { ofstream myfile ( ); (myfile.is_open()) { myfile << ; myfile << \"This is another line.\n\n\" ; myfile.close(); } cout << ; 0; }\n\n[file example.txt] This is a line. This is another line."
    },
    {
        "link": "https://w3schools.com/cpp/cpp_files.asp",
        "document": "The library allows us to work with files.\n\nTo use the library, include both the standard AND the header file:\n\nThere are three classes included in the library, which are used to create, write or read files:\n\nTo create a file, use either the or class, and specify the name of the file.\n\nTo write to the file, use the insertion operator ( ).\n\n#include <iostream>\n\n#include <fstream>\n\nusing namespace std;\n\n\n\n int main() {\n\n // Create and open a text file\n\n ofstream MyFile(\"filename.txt\");\n\n\n\n // Write to the file\n\n MyFile << \"Files can be tricky, but it is fun enough!\";\n\n\n\n // Close the file\n\n MyFile.close();\n\n}\n\nTo read from a file, use either the or class, and the name of the file.\n\nNote that we also use a loop together with the function (which belongs to the class) to read the file line by line, and to print the content of the file:\n\nFor a complete reference of <fstream> classes and functions, go to our C++ fstream Reference."
    },
    {
        "link": "https://stackoverflow.com/questions/32435991/how-to-read-and-write-in-file-with-fstream-simultaneously-in-c",
        "document": "fstream has two positions : input and output. In your case they both are set to the beginning of the file when you open it.\n\nSo you have 4 methods:\n\nin your case you can use the following line to set output position to the end of the file\n\nPS i missed ios::app flag. mea culpa. comment of @Nawaz gives the right answer: after reading the whole file it is necessary to call"
    },
    {
        "link": "https://geeksforgeeks.org/std-fstream-close-in-cpp",
        "document": "Files play an important role in programming. It allows storage of data permanently. The C++ language provides a mechanism to store the output of a program in a file and browse from a file on the disk. This mechanism is termed file handling. In order to perform file handling, some general functions which are used are as follows:\n• open(): This function helps to create a file and open the file in different modes, like input operations, output operations, binary mode, etc.\n• close(): This function helps to close an existing file.\n• get(): This function helps to read a single character from the file.\n• put() : This function helps to write a single character in the file.\n• read(): This function helps to read data from a file.\n• write(): This function helps us to write data into a file.\n\nA stream is an abstraction that represents a tool on which operations of input and output are performed. A stream is often represented as a source or destination of characters of indefinite length, counting on its usage. So far, the header file which provides functions cin and cout is used to require input from the console and write output to a console respectively. In C++ there is a group of file handling methods. These include ifstream, ofstream, and fstream. These classes are obtained from fstreambase and from the corresponding iostream class. These classes are designed such that they are able to manage the disk files, declared in fstream, and thus this file must be included in any program that uses files.\n\nfstream Library: Fstream is a library that consists of both, ofstream and ifstream which means it can create files, write information to files, and read information from files. This header file is generally used as a data type that represents the file stream. Which is used while describing the syntax to open, read, take input and close the file, etc.\n\nHow To Close File? In order to use a disk file for storing data, the following parameters need to be decided about the file and its intended use. The parameters that are to be noted are as follows:\n• None A name for the file.\n• None Data type and structure of the file.\n• None Closing the file after use.\n\nThis article focuses on closing the file. In a case, if a C++ program terminates, then it automatically flushes out all the streams, releases all the allocated memory, and closes all the opened files. Therefore, it is a good alternative to use the close() function to close the file-related streams, and it is a member of ifsream, ofstream, and fstream objects.\n• Return value: The close() function provides no which means that if the operation fails, including if no file was open before the call, the failbit state flag is set for the stream (which may throw ios_base::failure if that state flag was registered using member exceptions.\n• Exception handling: When the function is provided with an exception and the stream is in a valid state, then any exception thrown by an internal operation is caught by the function and rethrown after closing the file. It throws an exception to member type failure only if the function fails (setting the failbit state flag) and member exceptions are set to throw for that state.\n• fstream object. Concurrent access to an equivalent stream may introduce data races.\n\nBelow is the C++ program to implement the close() function:"
    },
    {
        "link": "https://studyplan.dev/pro-cpp/file-streams",
        "document": "Working with files typically forms a big part of our C++ projects. We often need to read data from and write data to locations on the user's file system.\n\nTo do this, we use file streams. As the name suggests, these are streams, so we'll be leaning heavily on what we learned in our previous chapter. File streams are direct children of and , so often we'll be using the exact same methods.\n\nThe standard library's implementation of file streams is available within the header:\n\nWe have three main options for creating file streams:\n• - An input stream, used for reading data from a file. This inherits from .\n• - An output stream, used for writing data to a file. This inherits from .\n• - A bidirectional stream, which allows us to both read and write data to the same file. This inherits from , which in turn inherits from both and\n\nIn this lesson, we’ll work mostly with the bidirectional object. We can construct it without any arguments:\n\nWe do not need to provide a path to a specific file during construction. Instead, we can connect our stream to a file in the underlying file system at any time using the method, and we close that connection using\n\nA file stream does not necessarily have a one-to-one mapping to a file. We can reuse the file stream for different files:\n\nBuilding on what we covered in the previous lesson, we can pass a object to :\n\nOr, we can pass a :\n\nWe can check if a file is open using the method:\n\nGenerally, we should not open a file until we need it. However, we do have the option to open the file at the same time we create the file stream. We can do this by passing a path to the constructor:\n\nIn addition to passing the path to the function or the file stream constructor, we can pass a second argument, specifying the open mode. Open modes define what we can do with our file, and how some of our operations behave.\n• - Allow input to be read from the file. This is enabled by default for input and bidirectional file streams\n• - Allows output to be written to the file. This is enabled by default for output and bidirectional file streams\n• (\"at end\") - move the input and output positions to the end of the file upon opening\n• (\"append\") - write operations are done at the end of the file, regardless of where the output position is\n• - open the file in binary mode. We cover binary streams in more detail later in the chapter\n• (\"truncate\") - when the file is opened, its existing contents are deleted\n• - if the file we’re opening already exists, throw an exception. In other systems, this sometimes is referred to as opening the file in \"exclusive mode\".\n\nThe flag was added in C++23 and is not yet supported on all compilers, but can be replicated in other ways. For example, we can check whether a file exists using the function, or the method on an .\n\nOpen modes are provided as the second argument to or as the second argument to the file stream constructor:\n\nOpen modes are a bitmask, so we can combine multiple modes using the operator:\n\nWe can combine open modes in dozens of different ways. Unfortunately, how these combinations interact is not always obvious. For example, if the file we’re trying to open doesn’t exist, it might get created, or it might not. It depends on the open modes we set.\n\nThe file will be created in the following scenarios:\n• Output mode ( ) is set, and input mode ( ) is not set. This is the default behavior of an output file stream. Therefore, if we a without passing any flags, will be set in isolation, and the file will be created if it doesn’t already exist.\n• Append mode ( ) or truncate mode ( ) is set, regardless of any other flags.\n\nAside from this, there are many more unintuitive behaviors and interactions between open modes. Some combinations will throw errors. Some combinations will work but behave in ways we weren't expecting. This is a common source of confusion and bugs.\n\nIn general, if your code is compiling but your file is not being written to or updated in the way we expect, the issue is almost always the combination of open modes we’ve selected.\n\nIt’s much too complex to memorize all the interactions - we can just look them up when needed. A full table of the interactions is available on a standard library reference, such as cppreference.com.\n\nFile streams have the same error-handling mechanisms as any other stream. We covered those in the previous chapter, and will talk about them in more detail a little later in this lesson,\n\nHowever, file streams have unique error scenarios we need to consider, caused by their interactions with the underlying filesystem.\n\nUsually, the first error we’ll want to check for when working with files is whether the file is open when we expect it to be.\n\nWe can do that with the method. In the following examples, we’re creating an error by trying to open a file that already exists, using the open mode.\n\nAs we covered in our lesson on output streams, we can use the method to cause our stream to throw exceptions when it encounters errors. The exception type will be a :\n\nThis exception has a and method, but they’re not especially useful in this scenario. When we want to find out what went wrong when accessing the file system, we usually need to talk to the operating system, and each system handles and reports errors differently.\n\nWe generally focus on portable code (ie, things that work across as many systems as possible), but we’ll briefly introduce some ways of working with system-specific issues here. For this example, we’ll assume our code is being built for Windows.\n\nBy including the header, we get access to some additional functions.\n\nThe function returns the error code of the last issue that occurred on the thread that called it:\n\nAll the Windows error codes are listed on the official Microsoft site.\n\nIn this example, the error code relates to a file already existing. We can use these error codes to have our code react appropriately to specific problems we anticipate might happen.\n\nThe standard library also provides access to an object that can help us with system errors. This can be accessed through the function from .\n\nThis object has a few useful utilities, including the ability to generate an error message from an operator-system-specific error code:\n\nOnce we’ve opened our file stream, we just use it like we would any other input and output stream. We covered input and output streams in detail here:\n\nThe rest of this lesson covers no new topics - it just shows examples of how the concepts covered in those lessons also work as we’d expect with file streams.\n\nWe write to files using the same methods we write to other output streams, such as the operator, the function, and the function:\n\nAfter running this code, we should have the file defined within containing the \"Hello World\" content.\n\nWe read from files in the same way we read from other input streams, using the operator, and methods such as and .\n\nThis program should print out the first line of the file we specified within our call:\n\nLike any other stream, file streams can have input and output positions. We use and to access and change the output position, whilst and work with the input position.\n\nWhen we call , the input and output positions are reset:\n\nAs with the streams we covered in previous lessons, file streams have internal states that we can use to check for errors.\n\nThey set , , and in the usual way, which we can check for directly using , or shorthand methods like and . Below, we read characters until our stream runs out of content:\n\nWe can also use the method, to cause our streams to once something goes wrong. In the following example, we’re trying to read from a file that has no content:\n\nTypically, the error codes and messages are not very descriptive:\n\nIf we need to understand the error, we must rely on OS-specific methods, as described in the previous section.\n\nFor example, on Windows, this specific scenario would generate a error code from .\n\nPassing this to the method of the object returned from yields the string: \"An attempt was made to move the file pointer before the beginning of the file.\"\n\nThe message is a little cryptic, but it means we tried to read content from our stream (using ) when the output position was outside the bounds of the file.\n\nThe following example shows how we can use file streams to create a rudimentary save/load feature.\n\nThe following class gives its objects the ability to save and load their state from a stream. Remember, file streams inherit from the basic stream types, so:\n• an is an\n• an is an\n• an is an , which is both an and an .\n\nOur functions accept references by the base type, as they do not need to be restricted to just working with file streams.\n\nOver in our main function, we check if a save file exists. If it does, we load our previous state; otherwise, we start from a clean slate.\n\nThe first time we run the program, we get this output:\n\nOn subsequent runs, we get this:\n\nThis process of converting our objects into forms that we can store on disk, or send across the internet, is called serialization.\n\nWe expand this concept to more complex use cases in the rest of this chapter.\n\nIn this lesson, we explored the fundamental aspects of file streams in C++, covering how to open, read, write, and handle files. We also delved into understanding the various file stream open modes, error handling techniques, and practical applications, enhancing your proficiency in managing file operations.\n• Learned the basics of file streams in C++ using , , and , and their inheritance from and .\n• Explored how to open and close file streams, and the versatility of file streams in handling multiple files.\n• Understood the different open modes ( , , , etc.) and their implications in file operations.\n• Gained insights into error handling in file streams, including the use of , , and system-specific error handling methods.\n• Discussed the concept of serialization and its application in saving and loading object states from files."
    },
    {
        "link": "https://cp-algorithms.com/algebra/sieve-of-eratosthenes.html",
        "document": "Sieve of Eratosthenes is an algorithm for finding all the prime numbers in a segment $[1;n]$ using $O(n \\log \\log n)$ operations.\n\nThe algorithm is very simple: at the beginning we write down all numbers between 2 and $n$. We mark all proper multiples of 2 (since 2 is the smallest prime number) as composite. A proper multiple of a number $x$, is a number greater than $x$ and divisible by $x$. Then we find the next number that hasn't been marked as composite, in this case it is 3. Which means 3 is prime, and we mark all proper multiples of 3 as composite. The next unmarked number is 5, which is the next prime number, and we mark all proper multiples of it. And we continue this procedure until we have processed all numbers in the row.\n\nIn the following image you can see a visualization of the algorithm for computing all prime numbers in the range $[1; 16]$. It can be seen, that quite often we mark numbers as composite multiple times.\n\nThe idea behind is this: A number is prime, if none of the smaller prime numbers divides it. Since we iterate over the prime numbers in order, we already marked all numbers, which are divisible by at least one of the prime numbers, as divisible. Hence if we reach a cell and it is not marked, then it isn't divisible by any smaller prime number and therefore has to be prime.\n\nThis code first marks all numbers except zero and one as potential prime numbers, then it begins the process of sifting composite numbers. For this it iterates over all numbers from $2$ to $n$. If the current number $i$ is a prime number, it marks all numbers that are multiples of $i$ as composite numbers, starting from $i^2$. This is already an optimization over naive way of implementing it, and is allowed as all smaller numbers that are multiples of $i$ necessary also have a prime factor which is less than $i$, so all of them were already sifted earlier. Since $i^2$ can easily overflow the type , the additional verification is done using type before the second nested loop.\n\nUsing such implementation the algorithm consumes $O(n)$ of the memory (obviously) and performs $O(n \\log \\log n)$ (see next section).\n\nIt's simple to prove a running time of $O(n \\log n)$ without knowing anything about the distribution of primes - ignoring the check, the inner loop runs (at most) $n/i$ times for $i = 2, 3, 4, \\dots$, leading the total number of operations in the inner loop to be a harmonic sum like $n(1/2 + 1/3 + 1/4 + \\cdots)$, which is bounded by $O(n \\log n)$.\n\nLet's prove that algorithm's running time is $O(n \\log \\log n)$. The algorithm will perform $\\frac{n}{p}$ operations for every prime $p \\le n$ in the inner loop. Hence, we need to evaluate the next expression:\n• The number of prime numbers less than or equal to is approximately .\n• The -th prime number approximately equals (this follows from the previous fact).\n\nThus we can write down the sum in the following way:\n\nHere we extracted the first prime number 2 from the sum, because $k = 1$ in approximation $k \\ln k$ is $0$ and causes a division by zero.\n\nNow, let's evaluate this sum using the integral of a same function over $k$ from $2$ to $\\frac n {\\ln n}$ (we can make such approximation because, in fact, the sum is related to the integral as its approximation using the rectangle method):\n\nThe antiderivative for the integrand is $\\ln \\ln k$. Using a substitution and removing terms of lower order, we'll get the result:\n\nNow, returning to the original sum, we'll get its approximate evaluation:\n\nYou can find a more strict proof (that gives more precise evaluation which is accurate within constant multipliers) in the book authored by Hardy & Wright \"An Introduction to the Theory of Numbers\" (p. 349).\n\nDifferent optimizations of the Sieve of Eratosthenes¶\n\nThe biggest weakness of the algorithm is, that it \"walks\" along the memory multiple times, only manipulating single elements. This is not very cache friendly. And because of that, the constant which is concealed in $O(n \\log \\log n)$ is comparably big.\n\nBesides, the consumed memory is a bottleneck for big $n$.\n\nThe methods presented below allow us to reduce the quantity of the performed operations, as well as to shorten the consumed memory noticeably.\n\nObviously, to find all the prime numbers until $n$, it will be enough just to perform the sifting only by the prime numbers, which do not exceed the root of $n$.\n\nSuch optimization doesn't affect the complexity (indeed, by repeating the proof presented above we'll get the evaluation $n \\ln \\ln \\sqrt n + o(n)$, which is asymptotically the same according to the properties of logarithms), though the number of operations will reduce noticeably.\n\nSince all even numbers (except $2$) are composite, we can stop checking even numbers at all. Instead, we need to operate with odd numbers only.\n\nFirst, it will allow us to halve the needed memory. Second, it will reduce the number of operations performed by algorithm approximately in half.\n\nWe should notice, that these two implementations of the Sieve of Eratosthenes use $n$ bits of memory by using the data structure . is not a regular container that stores a series of (as in most computer architectures a takes one byte of memory). It's a memory-optimization specialization of , that only consumes $\\frac{N}{8}$ bytes of memory.\n\nModern processors architectures work much more efficiently with bytes than with bits as they usually cannot access bits directly. So underneath the stores the bits in a large continuous memory, accesses the memory in blocks of a few bytes, and extracts/sets the bits with bit operations like bit masking and bit shifting.\n\nBecause of that there is a certain overhead when you read or write bits with a , and quite often using a (which uses 1 byte for each entry, so 8x the amount of memory) is faster.\n\nHowever, for the simple implementations of the Sieve of Eratosthenes using a is faster. You are limited by how fast you can load the data into the cache, and therefore using less memory gives a big advantage. A benchmark (link) shows, that using a is between 1.4x and 1.7x faster than using a .\n\nThe same considerations also apply to . It's also an efficient way of storing bits, similar to , so it takes only $\\frac{N}{8}$ bytes of memory, but is a bit slower in accessing the elements. In the benchmark above performs a bit worse than . Another drawback from is that you need to know the size at compile time.\n\nIt follows from the optimization \"sieving till root\" that there is no need to keep the whole array at all times. For sieving it is enough to just keep the prime numbers until the root of $n$, i.e. , split the complete range into blocks, and sieve each block separately.\n\nLet $s$ be a constant which determines the size of the block, then we have $\\lceil {\\frac n s} \\rceil$ blocks altogether, and the block $k$ ($k = 0 ... \\lfloor {\\frac n s} \\rfloor$) contains the numbers in a segment $[ks; ks + s - 1]$. We can work on blocks by turns, i.e. for every block $k$ we will go through all the prime numbers (from $1$ to $\\sqrt n$) and perform sieving using them. It is worth noting, that we have to modify the strategy a little bit when handling the first numbers: first, all the prime numbers from $[1; \\sqrt n]$ shouldn't remove themselves; and second, the numbers $0$ and $1$ should be marked as non-prime numbers. While working on the last block it should not be forgotten that the last needed number $n$ is not necessarily located at the end of the block.\n\nAs discussed previously, the typical implementation of the Sieve of Eratosthenes is limited by the speed how fast you can load data into the CPU caches. By splitting the range of potential prime numbers $[1; n]$ into smaller blocks, we never have to keep multiple blocks in memory at the same time, and all operations are much more cache-friendlier. As we are now no longer limited by the cache speeds, we can replace the with a , and gain some additional performance as the processors can handle read and writes with bytes directly and don't need to rely on bit operations for extracting individual bits. The benchmark (link) shows, that using a is about 3x faster in this situation than using a . A word of caution: those numbers might differ depending on architecture, compiler, and optimization levels.\n\nHere we have an implementation that counts the number of primes smaller than or equal to $n$ using block sieving.\n\nThe running time of block sieving is the same as for regular sieve of Eratosthenes (unless the size of the blocks is very small), but the needed memory will shorten to $O(\\sqrt{n} + S)$ and we have better caching results. On the other hand, there will be a division for each pair of a block and prime number from $[1; \\sqrt{n}]$, and that will be far worse for smaller block sizes. Hence, it is necessary to keep balance when selecting the constant $S$. We achieved the best results for block sizes between $10^4$ and $10^5$.\n\nSometimes we need to find all prime numbers in a range $[L,R]$ of small size (e.g. $R - L + 1 \\approx 1e7$), where $R$ can be very large (e.g. $1e12$).\n\nTo solve such a problem, we can use the idea of the Segmented sieve. We pre-generate all prime numbers up to $\\sqrt R$, and use those primes to mark all composite numbers in the segment $[L, R]$.\n\nIt's also possible that we don't pre-generate all prime numbers:\n\nObviously, the complexity is worse, which is $O((R - L + 1) \\log (R) + \\sqrt R)$. However, it still runs very fast in practice.\n\nWe can modify the algorithm in a such a way, that it only has linear time complexity. This approach is described in the article Linear Sieve. However, this algorithm also has its own weaknesses."
    },
    {
        "link": "https://geeksforgeeks.org/sieve-of-eratosthenes",
        "document": "Given a number n, print all primes smaller than or equal to n. It is also given that n is a small number.\n\nInput: n = 10\n\nOutput: 2 3 5 7\n\nExplanation: The prime numbers up to 10 obtained by Sieve of Eratosthenes are 2 3 5 7 . Input: n = 20\n\nOutput: 2 3 5 7 11 13 17 19\n\nExplanation: The prime numbers up to 20 obtained by Sieve of Eratosthenes are 2 3 5 7 11 13 17 19 . Input: n = 30\n\nOutput: 2 3 5 7 11 13 17 19 23 29\n\nExplanation: The prime numbers up to 30 obtained by Sieve of Eratosthenes are 2 3 5 7 11 13 17 19 23 29 .\n\nA Naive Approach is to one by one do prime check for all numbers from 1 to n\n\nSieve of Eratosthenes – O(N*log(log(N))) Time and O(n) Space\n\nThe Sieve of Eratosthenes works by iteratively marking the multiples of each prime starting from 2, marking them as non-prime, and continuing this process up to sqrt(n), leaving only the prime numbers unmarked. \n\nThe sieve of Eratosthenes is one of the most efficient ways to find all prime numbers smaller than n when n is smaller than 10 million or so.\n\n// all entries it as true. A value in prime[i] will // finally be false if i is Not a prime, else true. // Update all multiples of p greater than or // equal to the square of it numbers which are // multiple of p and are less than p^2 are // all entries it as true. A value in prime[i] will // finally be false if i is Not a prime, else true. // If prime[p] is not changed, then it is a prime // Update all multiples of p greater than or // equal to the square of it numbers which are // multiple of p and are less than p^2 are // initialize all entries it as true. A value in // prime[i] will finally be false if i is Not a // If prime[p] is not changed, then it is a // Update all multiples of p greater than or // equal to the square of it numbers which // are multiple of p and are less than p^2 // are already been marked. \"Following are the prime numbers \" \"smaller than or equal to \" # all entries it as true. # A value in prime[i] will # finally be false if i is # changed, then it is a prime // it as true. A value in // If prime[p] is not changed, // it as true. A value in // If prime[p] is not changed, then it is a\n\nTime Complexity: O(N*log(log(N))) : The time complexity of the Sieve of Eratosthenes is O(nlog⁡log⁡n)O(n \\log \\log n)O(nloglogn) because for each prime ppp, it marks its multiples up to nnn, and the marking process grows logarithmically. \n\nAuxiliary Space: O(N) : Because an array of n size is used to keep track of the primes.\n• None How is the time complexity of Sieve of Eratosthenes is n*log(log(n))?\n• None Sieve of Eratosthenes in O(n) time complexity"
    },
    {
        "link": "https://stackoverflow.com/questions/69349764/sieve-of-eratosthenes-not-sure-how-to-implement-it-exactly",
        "document": "I would not recommend blindly following instructions. As you can see, you have trouble translating them into code, so just don't. Try to understand the algorithm first, then iterate through it on paper and only then write it in code. It should be easier to do based on the iteration you have done.\n\nSince you can find the implementation anywhere, it won't be much of a spoiler if I provide it to you.\n\nThe goal is to find all prime numbers, the crucial thing is to realize that all non-prime numbers (non-prime) multiples of some prime number. That follow from its unique factorization. If you reverse it, for each prime , none of , , ... are primes. So if you start from , you can rule out all those non-primes. You can then do , ... for all primes and will be left with only prime numbers. Well that's it.\n\nSo about the implementation:\n• None We need to have a table of numbers for marking, at the end only unmarked( ) numbers are the found primes. Also make a type for the returned primes.\n• None Let's say we want to find all primes between and , this is how the function might look like:\n• None It will be handy to have a separate function for obtaining the primes from the table:\n• None Now, let's implement the smallest unit of work: marking all multiples of a given number.\n• None Another piece of the puzzle is finding the smallest unmarked element in the table from a given offset\n• None Now we need to repeat all of the above in a, thus the full looks like:\n\nNote that the function can almost be read like the instructions from Wikipedia. I find this bottom-to-top approach easier than trying to write it all in one big function.\n\nI am sure that my implementation might raise some more questions for you, especially the iterators. That's good, run it through a debugger to see what each function accepts, does, and returns. Go to cppreference and see what each symbol means."
    },
    {
        "link": "https://geeksforgeeks.org/c-program-for-sieve-of-eratosthenes",
        "document": "Given a number n, print all primes smaller than or equal to n. It is also given that n is a small number. For example, if n is 10, the output should be “2, 3, 5, 7”. If n is 20, the output should be “2, 3, 5, 7, 11, 13, 17, 19”.\n\n// C++ program to print all primes smaller than or equal to // all entries it as true. A value in prime[i] will // finally be false if i is Not a prime, else true. // If prime[p] is not changed, then it is a prime \"Following are the prime numbers smaller \"\n\nPlease refer complete article on Sieve of Eratosthenes for more details!"
    },
    {
        "link": "https://stackoverflow.com/questions/33828681/fixing-my-implementation-of-sieve-of-eratosthenes-in-c",
        "document": "I'm absolutely amazed the program runs at all. It has an absolute truckload of undefined behaviour!.\n\nUnless I'm very much mistaken (in which case please reward the serenity of my Friday afternoon with downvotes), is creating a vector of size , with the elements initialised to .\n\nYou have the constructor arguments the wrong way round. This is effectively reversing the sieve for most of the values.\n\nHave you absolutely clobbered your compiler's warning level?"
    }
]