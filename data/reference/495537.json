[
    {
        "link": "https://man7.org/linux/man-pages/man3/wcswidth.3.html",
        "document": "Pages that refer to this page: wcwidth(3), utf-8(7)"
    },
    {
        "link": "https://ibm.com/docs/en/zos/3.1.0?topic=functions-wcswidth-determine-display-width-wide-character-string",
        "document": "C or C++\n\nDetermines the number of printing positions that a graphic representation of n wide characters (or fewer than n wide characters, if a NULL wide character is encountered before n wide characters have been exhausted), in the wide-character string pointed to by wcs, occupies on a display device. The number of printing positions is independent of its location on the device.\n\nIf successful, wcswidth() returns the number of printing positions occupied by the wide-character string pointed to by wcs.\n\nIf any wide character in the wide-character string pointed to by wcs is not a printing wide character, wcswidth() returns -1.\n\nThe behavior of wcswidth() is affected by the LC_CTYPE category.\n\nUnder applications, the width returned will be 1 for each single-byte character and 2 for each double-byte character."
    },
    {
        "link": "https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/man3/wcswidth.3.html",
        "document": "This document is a Mac OS X manual page. Manual pages are a command-line technology for providing documentation. You can view these manual pages locally using the man(1) command. These manual pages come from many different sources, and thus, have a variety of writing styles.\n\nFor more information about the manual page format, see the manual page for manpages(5)."
    },
    {
        "link": "https://ocaml.org/p/wcwidth/1.0.1/doc/index.html",
        "document": "is a small library for calculating the terminal display width of a string. This is often the same as , but differs when 'wide' characters (such as CJK characters or emoji) are used.\n\nThe and C functions are actually defined as part of the POSIX standard (see , for example). This library, however, uses a very minimal reimplementation of the wcwidth Python package.\n\nIn principle, this should be a standalone library, not bundled as part of . However, I (Jon) am not yet confident enough in the correctness of the code to publish it on OPAM.\n\nThe API is very simple: it consists of three functions, and is documented at ."
    },
    {
        "link": "https://ibm.com/docs/en/i/7.5?topic=extensions-standard-c-library-functions-table-by-name",
        "document": "1 This function is not supported for files opened with type=record. 2 This function is not supported for files opened with type=record and mode=ab+, rb+, or wb+. 3 The ILE C compiler only supports fully buffered and line-buffered streams. Since a block and a line are equal to the record length of the opened file, fully buffered and line-buffered streams are supported in the same way. The and functions have no effect. 4 This function is not available when LOCALETYPE(*CLD) is specified on the compilation command. 5 This function is available only when SYSIFCOPT(*IFSIO) is specified on the CRTCMOD or CRTBNDC command. 6 This function is not available when either LOCALETYPE(*CLD) or SYSIFCOPT(*NOIFSIO) is specified on the compilation command."
    },
    {
        "link": "https://stackoverflow.com/questions/2259544/is-wchar-t-needed-for-unicode-support",
        "document": "As has already been noted, wchar_t is absolutely not necessary for unicode support. Not only that, it is also utterly useless for that purpose, since the standard provides no fixed-size guarantee for wchar_t (in other words, you don't know ahead of time what sizeof( wchar_t ) will be on a particular system), whereas sizeof( char ) will always be 1.\n\nIn a UTF-8 encoding, any actual UNICODE character is mapped to a sequence of one or more (up to four, I believe) octets. In a UTF-16 encoding, any actual UNICODE character is mapped to a sequence of one or more (up to two, I believe) 16-bit words. In a UTF-32 encoding, any actual UNICODE character is mapped to exactly one 32-bit-word.\n\nAs you can see, wchar_t could be of some use for implementing UTF-16 support IF the standard was nice enough to guarantee that wchar_t is always 16 bits wide. Unfortunately it does not, so you'd have to revert to a fixed-width integer type from (such as std::uint16_t) anyway.\n\nWhat's more infuriating is the additional confusion caused by Microsoft's Visual Studio UNICODE and MBCS (multi-byte character set) build configurations. Both of these are\n\nbecause neither does a \"UNICODE\" configuration in Visual Studio do anything to buy the programmer actual Unicode support, nor does the difference implied by these 2 build configurations make any sense. To explain, Microsoft recommends using TCHAR instead of using char or wchar_t directly. In an MBCS configuration, TCHAR expands to char, meaning you could potentially use this to implement UTF-8 support. In a UNICODE configuration, it expands to wchar_t, which in Visual Studio happens to be 16 bits wide and could potentially be used to implement UTF-16 support (which, as far as I'm aware, is the native encoding used by Windows). However, both of these encodings are multi-byte character sets, since both UTF-8 and UTF-16 allow for the possibility that a particular Unicode character may be encoded as more than a one char/wchar_t respectively, so the term multi-byte character set (as opposed to single-byte character set?) makes little sense.\n\nTo add insult to injury, merely using the Unicode configuration does not actually give you one iota of Unicode support. To actually get that, you have to use an actual Unicode library like ICU ( http://site.icu-project.org/ ). In short, the wchar_t type and Microsoft's MBCS and UNICODE configurations add nothing of any use and cause unnecessary confusion, and the world would be a significantly better place if none of them had ever been invented."
    },
    {
        "link": "https://stackoverflow.com/questions/13509733/what-is-the-use-of-wchar-t-in-general-programming",
        "document": "is intended for representing text in fixed-width, multi-byte encodings; since is usually 2 bytes in size it can be used to represent text in any 2-byte encoding. It can also be used for representing text in variable-width multi-byte encodings of which the most common is UTF-16.\n\nOn platforms where is 4 bytes in size it can be used to represent any text using UCS-4 (Unicode), but since on most platforms it's only 2 bytes it can only represent Unicode in a variable-width encoding (usually UTF-16). It's more common to use with a variable-width encoding e.g. UTF-8 or GB 18030.\n\nAbout the only modern operating system to use extensively is Windows; this is because Windows adopted Unicode before it was extended past U+FFFF and so a fixed-width 2-byte encoding (UCS-2) appeared sensible. Now UCS-2 is insufficient to represent the whole of Unicode and so Windows uses UTF-16, still with 2-byte code units."
    },
    {
        "link": "https://unicode-org.github.io/icu/userguide/strings",
        "document": "This section explains how to handle Unicode strings with ICU in C and C++.\n\nSample code is available in the ICU source code library at icu/source/samples/ustring/ustring.cpp .\n\nStrings are the most common and fundamental form of handling text in software. Logically, and often physically, they contain contiguous arrays (vectors) of basic units. Most of the ICU API functions work directly with simple strings, and where possible, this is preferred.\n\nSometimes, text needs to be accessed via more powerful and complicated methods. For example, text may be stored in discontiguous chunks in order to deal with frequent modification (like typing) and large amounts, or it may not be stored in the internal encoding, or it may have associated attributes like bold or italic styles.\n\nICU provides multiple text access interfaces which were added over time. If simple strings cannot be used, then consider the following:\n• UText: Intended to be the strategic text access API for use with ICU. C API, high performance, writable, supports native indexes for efficient non-UTF-16 text storage.\n• Replaceable (Java & C++) and UReplaceable (C): Writable, designed for use with Transliterator.\n• CharacterIterator (Java JDK & C++): Read-only, used in many APIs. Large differences between the JDK and C++ versions.\n• UCharacterIterator (Java): Back-port of the C++ CharacterIterator to ICU4J for support of supplementary code points and post-increment iteration.\n• UCharIterator (C): Read-only, C interface used mostly in incremental normalization and collation.\n\nThe following provides some historical perspective and comparison between the interfaces.\n\nICU has long provided the CharacterIterator interface for some services. It allows for abstract text access, but has limitations:\n• Originally, it was designed for UCS-2 operation and did not support direct handling of supplementary Unicode code points. Such support was later added.\n• Its pre-increment iteration semantics are uncommon, and are inefficient when used with a variable-width encoding form (UTF-16). Functions for post-increment iteration were added later.\n• The C++ version added iteration start/limit boundaries only because the C++ UnicodeString copies string contents during substringing; the Java CharacterIterator does not have these extra boundaries – substringing is more efficient in Java.\n• CharacterIterator is not available for use in C.\n• It uses UTF-16 indexes into the text, which is not efficient for other encoding forms.\n• With the additions to the API over time, the number of methods that have to be overridden by subclasses has become rather large.\n\nThe core Java adopted an early version of CharacterIterator; later functionality, like support for supplementary code points, was back-ported from ICU4C to ICU4J to form the UCharacterIterator class.\n\nThe UCharIterator C interface was added to allow for incremental normalization and collation in C. It is entirely code unit (UChar)-oriented, uses only post-increment iteration and has a smaller number of overridable methods.\n\nThe Replaceable (Java & C++) and UReplaceable (C) interfaces are designed for, and used in, Transliterator. They are random-access interfaces, not iterators.\n\nThe UText text access interface was designed as a possible replacement for all previous interfaces listed above, with additional functionality. It allows for high-performance operation through the use of storage-native indexes (for efficient use of non-UTF-16 text) and through accessing multiple characters per function call. Code point iteration is available with functions as well as with C macros, for maximum performance. UText is also writable, mostly patterned after Replaceable. For details see the UText chaper.\n\nIn Java, ICU uses the standard String and StringBuffer classes, , etc. See the Java documentation for details.\n\nStrings in C and C++ are, at the lowest level, arrays of some particular base type. In most cases, the base type is a char, which is an 8-bit byte in modern compilers. Some APIs use a “wide character” type wchar_t that is typically 8, 16, or 32 bits wide and upwards compatible with char. C code passes or wchar_t pointers to the first element of an array. C++ enables you to create a class for encapsulating these kinds of character arrays in handy and safe objects.\n\nThe interpretation of the byte or wchar_t values depends on the platform, the compiler, the signed state of both char and wchar_t, and the width of wchar_t. These characteristics are not specified in the language standards. When using internationalized text, the encoding often uses multiple chars for most characters and a wchar_t that is wide enough to hold exactly one character code point value each. Some APIs, especially in the standard library (stdlib), assume that wchar_t strings use a fixed-width encoding with exactly one character code point per wchar_t.\n\nIn order to take advantage of Unicode with its large character repertoire and its well-defined properties, there must be types with consistent definitions and semantics. The Unicode standard defines a default encoding based on 16-bit code units. This is supported in ICU by the definition of the UChar to be an unsigned 16-bit integer type. This is the base type for character arrays for strings in ICU.\n\nWith the UTF-16 encoding form, a single Unicode code point is encoded with either one or two 16-bit UChar code units (unambiguously). “Supplementary” code points, which are encoded with pairs of code units, are rare in most texts. The two code units are called “surrogates”, and their unit value ranges are distinct from each other and from single-unit value ranges. Code should be generally optimized for the common, single-unit case.\n\n16-bit Unicode strings in internal processing contain sequences of 16-bit code units that may not always be well-formed UTF-16. ICU treats single, unpaired surrogates as surrogate code points, i.e., they are returned in per-code point iteration, they are included in the number of code points of a string, and they are generally treated much like normal, unassigned code points in most APIs. Surrogate code points have Unicode properties although they cannot be assigned an actual character.\n\nICU string handling functions (including append, substring, etc.) do not automatically protect against producing malformed UTF-16 strings. Most of the time, indexes into strings are naturally at code point boundaries because they result from other functions that always produce such indexes. If necessary, the user can test for proper boundaries by checking the code unit values, or adjust arbitrary indexes to code point boundaries by using the C macros U16_SET_CP_START() and U16_SET_CP_LIMIT() (see utf.h) and the UnicodeString functions getChar32Start() and getChar32Limit().\n\nUTF-8 and UTF-32 are supported with converters (ucnv.h), macros (utf.h), and convenience functions (ustring.h), but only a subset of APIs works with UTF-8 directly as string encoding form.\n\nSee the UTF-8 subpage for details about working with UTF-8. Some of the following sections apply to UTF-8 APIs as well; for example sections about handling lengths and overflows.\n\nA Unicode code point is an integer with a value from 0 to 0x10FFFF. ICU 2.4 and later defines the UChar32 type for single code point values as a 32 bits wide signed integer (int32_t). This allows the use of easily testable negative values as sentinels, to indicate errors, exceptions or “done” conditions. All negative values and positive values greater than 0x10FFFF are illegal as Unicode code points.\n\nICU 2.2 and earlier defined UChar32 depending on the platform: If the compiler’s wchar_t was 32 bits wide, then UChar32 was defined to be the same as wchar_t. Otherwise, it was defined to be an unsigned 32-bit integer. This means that UChar32 was either a signed or unsigned integer type depending on the compiler. This was meant for better interoperability with existing libraries, but was of little use because ICU does not process 32-bit strings — UChar32 is only used for single code points. The platform dependence of UChar32 could cause problems with C++ function overloading.\n\nThe compiler’s and the runtime character set’s codepage encodings are not specified by the C/C++ language standards and are usually not a Unicode encoding form. They typically depend on the settings of the individual system, process, or thread. Therefore, it is not possible to instantiate a Unicode character or string variable directly with C/C++ character or string literals. The only safe way is to use numeric values. It is not an issue for User Interface (UI) strings that are translated. These UI strings are loaded from a resource bundle, which is generated from a text file that can be in Unicode or in any other ICU-provided codepage. The binary form of the genrb tool generates UTF-16 strings that are ready for direct use.\n\nThere is a useful exception to this for program-internal strings and test strings. Within each “family” of character encodings, there is a set of characters that have the same numeric code values. Such characters include Latin letters, the basic digits, the space, and some punctuation. Most of the ASCII graphic characters are invariant characters. The same set, with different but again consistent numeric values, is invariant among almost all EBCDIC codepages. For details, see icu4c/source/common/unicode/utypes.h . With strings that contain only these invariant characters, it is possible to use efficient ICU constructs to write a C/C++ string literal and use it to initialize Unicode strings.\n\nIn some APIs, ICU uses strings. This is either for file system paths or for strings that contain invariant characters only (such as locale identifiers). These strings are in the platform-specific encoding of either ASCII or EBCDIC. All other codepage differences do not matter for invariant characters and are manipulated by the C stdlib functions like strcpy().\n\nIn some APIs where identifiers are used, ICU uses strings with invariant characters. Such strings do not require the full Unicode repertoire and are easier to handle in C and C++ with string literals and standard C library functions. Their useful character repertoire is actually smaller than the set of graphic ASCII characters; for details, see utypes.h . Examples of identifier uses are converter names, locale IDs, and resource bundle table keys.\n\nThere is another, less efficient way to have human-readable Unicode string literals in C and C++ code. ICU provides a small number of functions that allow any Unicode characters to be inserted into a string with escape sequences similar to the one that is used in the C and C++ language. In addition to the familiar \n\n and \\xhh etc., ICU also provides the \\uhhhh syntax with four hex digits and the \\Uhhhhhhhh syntax with eight hex digits for hexadecimal Unicode code point values. This is very similar to the newer escape sequences used in Java and defined in the latest C and C++ standards. Since ICU is not a compiler extension, the “unescaping” is done at runtime and the backslash itself must be escaped (duplicated) so that the compiler does not attempt to “unescape” the sequence itself.\n\nThe length of a string and all indexes and offsets related to the string are always counted in terms of UChar code units, not in terms of UChar32 code points. (This is the same as in common C library functions that use strings with multi-byte encodings.)\n\nOften, a user thinks of a “character” as a complete unit in a language, like an ‘Ä’, while it may be represented with multiple Unicode code points including a base character and combining marks. (See the Unicode standard for details.) This often requires users to index and pass strings (UnicodeString or ) with multiple code units or code points. It cannot be done with single-integer character types. Indexing of such “characters” is done with the BreakIterator class (in C: ubrk_ functions).\n\nEven with such “higher-level” indexing functions, the actual index values will be expressed in terms of UChar code units. When more than one code unit is used at a time, the index value changes by more than one at a time.\n\nICU uses signed 32-bit integers (int32_t) for lengths and offsets. Because of internal computations, strings (and arrays in general) are limited to 1G base units or 2G bytes, whichever is smaller.\n\nUsing C Strings: NUL-Terminated vs. Length Parameters\n\nStrings are either terminated with a NUL character (code point 0, U+0000) or their length is specified. In the latter case, it is possible to have one or more NUL characters inside the string.\n\nInput string arguments are typically passed with two parameters: The (const) pointer and an int32_t length argument. If the length is -1 then the string must be NUL-terminated and the ICU function will call the u_strlen() method or treat it equivalently. If the input string contains embedded NUL characters, then the length must be specified.\n\nOutput string arguments are typically passed with a destination pointer and an int32_t capacity argument and the function returns the length of the output as an int32_t. There is also almost always a UErrorCode argument. Essentially, a array is passed in with its start and the number of available UChars. The array is filled with the output and if space permits the output will be NUL-terminated. The length of the output string is returned. In all cases the length of the output string does not include the terminating NUL. This is the same behavior found in most ICU and non-ICU string APIs, for example u_strlen(). The output string may contain NUL characters as part of its actual contents, depending on the input and the operation. Note that the UErrorCode parameter is used to indicate both errors and warnings (non-errors). The following describes some of the situations in which the UErrorCode will be set to a non-zero value:\n• If the output length is greater than the output array capacity, then the UErrorCode will be set to U_BUFFER_OVERFLOW_ERROR and the contents of the output array is undefined.\n• If the output length is equal to the capacity, then the output has been completely written minus the terminating NUL. This is also indicated by setting the UErrorCode to U_STRING_NOT_TERMINATED_WARNING. Note that U_STRING_NOT_TERMINATED_WARNING does not indicate failure (it passes the U_SUCCESS() macro). Note also that it is more reliable to check the output length against the capacity, rather than checking for the warning code, because warning codes do not cause the early termination of a function and may subsequently be overwritten.\n• If neither of these two conditions apply, the error code will indicate success and not a U_STRING_NOT_TERMINATED_WARNING. (If a U_STRING_NOT_TERMINATED_WARNING code had been set in the UErrorCode parameter before the function call, then it is reset to a U_ZERO_ERROR.)\n\nPreflighting: The returned length is always the full output length even if the output buffer is too small. It is possible to pass in a capacity of 0 (and an output array pointer of NUL) for “pure preflighting” to determine the necessary output buffer size. Add one to make the output string NUL-terminated.\n\nNote that — whether the caller intends to “preflight” or not — if the output length is equal to or greater than the capacity, then the UErrorCode is set to U_STRING_NOT_TERMINATED_WARNING or U_BUFFER_OVERFLOW_ERROR respectively, as described above.\n\nHowever, “pure preflighting” is very expensive because the operation has to be processed twice — once for calculating the output length, and a second time to actually generate the output. It is much more efficient to always provide an output buffer that is expected to be large enough for most cases, and to reallocate and repeat the operation only when an overflow occurred. (Remember to reset the UErrorCode to U_ZERO_ERROR before calling the function again.) In C/C++, the initial output buffer can be a stack buffer. In case of a reallocation, it may be possible and useful to cache and reuse the new, larger buffer.\n\nUsing Unicode Strings in C\n\nIn C, Unicode strings are similar to standard strings. Unicode strings are arrays of UChar and most APIs take a pointer to the first element and an input length and/or output capacity, see above. ICU has a number of functions that provide the Unicode equivalent of the stdlib functions such as strcpy(), strstr(), etc. Compared with their C standard counterparts, their function names begin with u_. Otherwise, their semantics are equivalent. These functions are defined in icu/source/common/unicode/ustring.h.\n\nSometimes, Unicode code points need to be accessed in C for iteration, movement forward, or movement backward in a string. A string might also need to be written from code points values. ICU provides a number of macros that are defined in the icu/source/common/unicode/utf.h and utf8.h/utf16.h headers that it includes (utf.h is in turn included with utypes.h).\n\nMacros for 16-bit Unicode strings have a U16_ prefix. For example:\n\nThere are also macros with a U_ prefix for code point range checks (e.g., test for non-character code point), and U8_ macros for 8-bit (UTF-8) strings. See the header files and the API References for more details.\n\nIn ICU 2.4, the utf*.h macros have been revamped, improved, simplified, and renamed. The old macros continue to be available. They are in utf_old.h, together with an explanation of the change. utf.h, utf8.h and utf16.h contain the new macros instead. The new macros are intended to be more consistent, more useful, and less confusing. Some macros were simply renamed for consistency with a new naming scheme.\n\nThe documentation of the old macros has been removed. If you need it, see a User Guide version from ICU 4.2 or earlier (see the download page).\n\nThere is a pair of macros that together enable users to instantiate a Unicode string in C — a array — from a C string literal:\n\nWith invariant characters, it is also possible to efficiently convert strings to and from UChar \\ strings:\n\nIt is sometimes useful to test if a 16-bit Unicode string is well-formed UTF-16, that is, that it does not contain unpaired surrogate code units. For a boolean test, call a function like u_strToUTF8() which sets an error code if the input string is malformed. (Provide a zero-capacity destination buffer and treat the buffer overflow error as “is well-formed”.) If you need to know the position of the unpaired surrogate, you can iterate through the string with U16_NEXT() and U_IS_SURROGATE().\n\nUsing Unicode Strings in C++\n\nUnicodeString is a C++ string class that wraps a UChar array and associated bookkeeping. It provides a rich set of string handling functions.\n\nUnicodeString combines elements of both the Java String and StringBuffer classes. Many UnicodeString functions are named and work similar to Java String methods but modify the object (UnicodeString is “mutable”).\n\nUnicodeString provides functions for random access and use (insert/append/find etc.) of both code units and code points. For each non-iterative string/code point macro in utf.h there is at least one UnicodeString member function. The names of most of these functions contain “32” to indicate the use of a UChar32.\n\nCode point and code unit iteration is provided by the CharacterIterator abstract class and its subclasses. There are concrete iterator implementations for UnicodeString objects and plain arrays.\n\nMost UnicodeString constructors and functions do not have a UErrorCode parameter. Instead, if the construction of a UnicodeString fails, for example when it is constructed from a NULL pointer, then the UnicodeString object becomes “bogus”. This can be tested with the isBogus() function. A UnicodeString can be put into the “bogus” state explicitly with the setToBogus() function. This is different from an empty string (although a “bogus” string also returns true from isEmpty()) and may be used equivalently to NULL in C APIs (or null references in Java, or NULL values in SQL). A string remains “bogus” until a non-bogus string value is assigned to it. For complete details of the behavior of “bogus” strings see the description of the setToBogus() function.\n\nSome APIs work with the Replaceable abstract class. It defines a simple interface for random access and text modification and is useful for operations on text that may have associated meta-data (e.g., styled text), especially in the Transliterator API. UnicodeString implements Replaceable.\n\nUnicodeString can be used together with standard library algorithms and containers:\n\nSee the Collation API for how to use a collator to sort strings in natural language ordering for humans.\n\nLike in C, there are macros that enable users to instantiate a UnicodeString from a C string literal. One macro requires the length of the string as in the C macros, the other one implies a strlen().\n\nIt is possible to efficiently convert between invariant-character strings and UnicodeStrings by using constructor, setTo() or extract() overloads that take codepage data ( ) and specifying an empty string (“”) as the codepage name.\n\nUsing C++ Strings in C APIs\n\nThe internal buffer of UnicodeString objects is available for direct handling in C (or C-style) APIs that take arguments. It is possible but usually not necessary to copy the string contents with one of the extract functions. The following describes several direct buffer access methods.\n\nThe UnicodeString function getBuffer() const returns a readonly const . The length of the string is indicated by UnicodeString’s length() function. Generally, UnicodeString does not NUL-terminate the contents of its internal buffer. However, it is possible to check for a NUL character if the length of the string is less than the capacity of the buffer. The following code is an example of how to check the capacity of the buffer:\n\nAn easier way to NUL-terminate the buffer and get a pointer to it is the getTerminatedBuffer() function. Unlike getBuffer() const, getTerminatedBuffer() is not a const function because it may have to (reallocate and) modify the buffer to append a terminating NUL. Therefore, use getBuffer() const if you do not need a NUL-terminated buffer.\n\nThere is also a pair of functions that allow controlled write access to the buffer of a UnicodeString: and . provides a writeable buffer of at least the requested capacity and returns a pointer to it. The actual capacity of the buffer after the call may be larger than the requested capacity and can be determined with .\n\nOnce the buffer contents are modified, the buffer must be released with the function, which sets the new length of the UnicodeString (newLength=-1 can be passed to determine the length of NUL-terminated contents like ).\n\nBetween the and function calls, the contents of the UnicodeString is unknown and the object behaves like it contains an empty string. A nested , or will fail (return NULL) and modifications of the string via UnicodeString member functions will have no effect. Copying a string with an “open buffer” yields an empty copy. The move constructor, move assignment operator and Return Value Optimization (RVO) transfer the state, including the open buffer.\n\nSee the UnicodeString API documentation for more information.\n\nUsing C Strings in C++ APIs\n\nThere are efficient ways to wrap C-style strings in C++ UnicodeString objects without copying the string contents. In order to use C strings in C++ APIs, the pointer and length need to be wrapped into a UnicodeString. This can be done efficiently in two ways: With a readonly alias and a writable alias. The UnicodeString object that is constructed actually uses the pointer as its internal buffer pointer instead of allocating a new buffer and copying the string contents.\n\nIf the original string is a readonly , then the UnicodeString must be constructed with a read only alias. If the original string is a writable (non-const) and is to be modified (e.g., if the buffer is an output buffer) then the UnicodeString should be constructed with a writeable alias. For more details see the section “Maximizing Performance with the UnicodeString Storage Model” and search the unistr.h header file for “alias”.\n\nUnicodeString uses four storage methods to maximize performance and minimize memory consumption:\n• Short strings are normally stored inside the UnicodeString object. The object has fields for the “bookkeeping” and a small UChar array. When the object is copied, the internal characters are copied into the destination object.\n• Longer strings are normally stored in allocated memory. The allocated UChar array is preceded by a reference counter. When the string object is copied, the allocated buffer is shared by incrementing the reference counter. If any of the objects that share the same string buffer are modified, they receive their own copy of the buffer and decrement the reference counter of the previously co-used buffer.\n• A UnicodeString can be constructed (or set with a setTo() function) so that it aliases a readonly buffer instead of copying the characters. In this case, the string object uses this aliased buffer for as long as the object is not modified and it will never attempt to modify or release the buffer. This model has copy-on-write semantics. For example, when the string object is modified, the buffer contents are first copied into writable memory (inside the object for short strings or the allocated buffer for longer strings). When a UnicodeString with a readonly setting is copied to another UnicodeString using the fastCopyFrom() function, then both string objects share the same readonly setting and point to the same storage. Copying a string with the normal assignment operator or copy constructor will copy the buffer. This prevents accidental misuse of readonly-aliased strings. (This is new in ICU 2.4; earlier, the assignment operator and copy constructor behaved like the new fastCopyFrom() does now.) Important:\n• The aliased buffer must remain valid for as long as any UnicodeString object aliases it. This includes unmodified fastCopyFrom()and copies of the object (including moves via the move constructor and move assignment operator), and when the compiler uses Return Value Optimization (RVO) where a function returns a UnicodeString by value.\n• Be prepared that return-by-value may either make a copy (which does not preserve aliasing), or moves the value or uses RVO (which do preserve aliasing).\n• It is an error to readonly-alias temporary buffers and then pass the resulting UnicodeString objects (or references/pointers to them) to APIs that store them for longer than the buffers are valid.\n• If it is necessary to make sure that a string is not a readonly alias, then use any modifying function without actually changing the contents (for example, s.setCharAt(0, s.charAt(0))).\n• In ICU 2.4 and later, a simple assignment or copy construction will also copy the buffer.\n• A UnicodeString can be constructed (or set with a setTo() function) so that it aliases a writable buffer instead of copying the characters. The difference from the above is that the string object writes through to this aliased buffer for write operations. A new buffer is allocated and the contents are copied only when the capacity of the buffer is not sufficient. An efficient way to get the string contents into the original buffer is to use the function. The function copies the string contents only if the dst buffer is different from the buffer of the string object itself. If a string grows and shrinks during a sequence of operations, then it will not use the same buffer, even if the string would fit. When a UnicodeString with a writeable alias is assigned to another UnicodeString, the contents are always copied. The destination string will not point to the buffer that the source string aliases point to. However, a move constructor, move assignment operator, and Return Value Optimization (RVO) do preserve aliasing.\n\nIn general, UnicodeString objects have “copy-on-write” semantics. Several objects may share the same string buffer, but a modification only affects the object that is modified itself. This is achieved by copying the string contents if it is not owned exclusively by this one object. Only after that is the object modified.\n\nEven though it is fairly efficient to copy UnicodeString objects, it is even more efficient, if possible, to work with references or pointers. Functions that output strings can be faster by appending their results to a UnicodeString that is passed in by reference, compared with returning a UnicodeString object or just setting the local results alone into a string reference.\n\nAs mentioned in the overview of this chapter, ICU and most other Unicode-supporting software uses 16-bit Unicode for internal processing. However, there are circumstances where UTF-8 is used instead. This is usually the case for software that does little or no processing of non-ASCII characters, and/or for APIs that predate Unicode, use byte-based strings, and cannot be changed or replaced for various reasons.\n\nA common perception is that UTF-8 has an advantage because it was designed for compatibility with byte-based, ASCII-based systems, although it was designed for string storage (of Unicode characters in Unix file names) rather than for processing performance.\n\nWhile ICU mostly does not natively use UTF-8 strings, there are many ways to work with UTF-8 strings and ICU. For more information see the newer UTF-8 subpage.\n\nIt is even rarer to use UTF-32 for string processing than UTF-8. While 32-bit Unicode is convenient because it is the only fixed-width UTF, there are few or no legacy systems with 32-bit string processing that would benefit from a compatible format, and the memory bandwidth requirements of UTF-32 diminish the performance and handling advantage of the fixed-width format.\n\nOver time, the wchar_t type of some C/C++ compilers became a 32-bit integer, and some C libraries do use it for Unicode processing. However, application software with good Unicode support tends to have little use for the rudimentary Unicode and Internationalization support of the standard C/C++ libraries and often uses custom types (like ICU’s) and UTF-16 or UTF-8.\n\nFor those systems where 32-bit Unicode strings are used, ICU offers some convenience functions.\n• Conversion of whole strings: u_strFromUTF32() and u_strFromUTF32() in ustring.h.\n• Access to code points is trivial and does not require any macros.\n• Using a UTF-32 converter with all of the ICU conversion APIs in ucnv.h, including ones with an “Algorithmic” suffix.\n• For conversion directly between UTF-32 and another charset use ucnv_convertEx(). However, since ICU converters work with byte streams in external charsets on the non-“Unicode” side, the UTF-32 string will be treated as a byte stream (UTF-32 Character Encoding Scheme) rather than a sequence of 32-bit code units (UTF-32 Character Encoding Form). The correct converter must be used: UTF-32BE or UTF-32LE according to the platform endianness (U_IS_BIG_ENDIAN). Treating the string like a byte stream also makes a difference in data types ( ), lengths and indexes (counting bytes), and NUL-termination handling (input NUL-termination not possible, output writes only a NUL byte, not a NUL 32-bit code unit). For the difference between internal encoding forms and external encoding schemes see the Unicode Standard.\n• Some ICU APIs work with a CharacterIterator, a UText or a UCharIterator instead of directly with a C/C++ string parameter. There is currently no ICU instance of any of these interfaces that reads UTF-32, although an application could provide one.\n\nBeginning with ICU release 2.0, there are a few changes to the ICU string facilities compared with earlier ICU releases.\n\nSome of the NUL-termination behavior was inconsistent across the ICU API functions. In particular, the following functions used to count the terminating NUL character in their output length (counted one more before ICU 2.0 than now): ucnv_toUChars, ucnv_fromUChars, uloc_getLanguage, uloc_getCountry, uloc_getVariant, uloc_getName, uloc_getDisplayLanguage, uloc_getDisplayCountry, uloc_getDisplayVariant, uloc_getDisplayName\n\nSome functions used to set an overflow error code even when only the terminating NUL did not fit into the output buffer. These functions now set UErrorCode to U_STRING_NOT_TERMINATED_WARNING rather than to U_BUFFER_OVERFLOW_ERROR.\n\nThe aliasing UnicodeString constructors and most extract functions have existed for several releases prior to ICU 2.0. There is now an additional extract function with a UErrorCode parameter. Also, the getBuffer, releaseBuffer and getCapacity functions are new to ICU 2.0.\n\nFor more information about these changes, please consult the old and new API documentation."
    },
    {
        "link": "https://thecodingforums.com/threads/wchar_t-is-useless.806149",
        "document": "That is a very strange way of putting it. Certainly wchar_t has _an_encoding, that is, a mapping between abstract characters and integervalues. (In Unicode terminology, it's a \"coded character set\".)The euc.c module is a bit of a complex example, since it isparameterized (as there are many variants of EUC):Even the man page explicitly says that the encoding of wchar_t isdependent on the precise definition of the locale. For instance,character for love (U+611B), which is encoded in EUC-JP as \"\\xb0\\xa6\"is represented by the wchar_t value 0xb0a6.No _single_ encoding is wrong, the problem is that these differentlocales have different encodings for wchar_t. In the utf-8 locale, thecharacter for love is represented by the wchar_t value 0x611b. So nowif I want my library to input and output wchar_t values, _I need toknow which locale they were produced on_ in order to know how tointerpret them.The standard library functions, and wide string literals, are whatimbue wchar_t values with an indended interpretation as characters.Without the intended interpretation, wchar_t would just be a plaininteger type that wouldn't fulfill any function that other integertypes wouldn't already.I'm not concerned with external encodings (other than UTF-8, which isused by a certain file format I process). I can let the user of mylibrary worry about those. I'm concerned with the API, and the choiceof representation for strings. It's not only a question of choosing atype, there must also be an interpretation for values of that type.And for wchar_t, it seems, the interpretation can be quite volatile.I'm writing a _library_. As I explained earlier, a library cannotcontrol, or constrain, the current locale. Perhaps someone would liketo plug the library into a legacy application that needs to be runin a certain locale. As a library writer, it's my job to make surethat this is possible without pain.I indeed do not need to use those, but the user of the librarypresumably might. Now suppose someone calls a function in my library,and I wish to return the character for love as a wchar_t. Now how canI know which wchar_t value I should return?It's curious that you find this particular limitation of Windows to besignificant. It's a nuisance, sure, but I don't see why it would be soimportant to have a single wchar_t value represent a whole code point.The only important operations on individual wchar_t's are those in , but if you need to classify code points at all, you are soonlikely to need more detailed access to Unicode character propertiesthat goes beyond what provides.And if you need to split a piece of text into discrete units, I don'tsee why code points, especially of unnormalized or NFC-normalizedtext, would be any more important units than, say, grapheme clusters.You mean, rewriting all those locale modules so that wchar_t alwayshas a consistent value (the unicode code point) for a given character,regardless of the way it is encoded in the current module?That's effectively what I was saying: those platforms, as theycurrently stand, cannot have locale-independent unicode literals, sothey have to be modified.But actually, I'm not quite sure if C1X really requires unicodeliterals to be locale-independent. The text on character constants,string literals and universal character names is really confusing, andthere's talk about \"an implementation-dependent current locale\", so itmight be that even C1X allows the meaning of wide string literals tovary between locales. It'd be a shame if this is true.Lauri"
    },
    {
        "link": "https://cplusplus.com/forum/general/7142",
        "document": "/* * Copyright (c) 2009, Helios (helios.vmg@gmail.com) * All rights reserved. * * Redistribution and use in source and binary forms, with or without * modification, are permitted provided that the following conditions are met: * * Redistributions of source code must retain the above copyright notice, * this list of conditions and the following disclaimer. * * Redistributions in binary form must reproduce the above copyright * notice, this list of conditions and the following disclaimer in the * documentation and/or other materials provided with the distribution. * * THIS SOFTWARE IS PROVIDED BY HELIOS \"AS IS\" AND ANY EXPRESS OR IMPLIED * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO * EVENT SHALL HELIOS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED * OF THE POSSIBILITY OF SUCH DAMAGE. */ uchar; /* string: a UTF-8-encoded C string (nul terminated) Return value: a wchar_t C string. The function handles memory allocation on its own. Limitations: Only handles the range [U+0000;U+FFFF], higher code points are changed to '?'. Assumptions: sizeof(wchar_t)>=2 */ *UTF8_to_WChar( *string){ b=0, c=0; ((uchar)string[0]==BOM8A && (uchar)string[1]==BOM8B && (uchar)string[2]==BOM8C) string+=3; ( *a=string;*a;a++) (((uchar)*a)<128 || (*a&192)==192) c++; *res= [c+1]; res[c]=0; (uchar *a=(uchar*)string;*a;a++){ (!(*a&128)) //Byte represents an ASCII character. Direct copy will do. res[b]=*a; ((*a&192)==128) //Byte is the middle of an encoded character. Ignore. ; ((*a&224)==192) //Byte represents the start of an encoded character in the range res[b]=((*a&31)<<6)|a[1]&63; ((*a&240)==224) //Byte represents the start of an encoded character in the range res[b]=((*a&15)<<12)|((a[1]&63)<<6)|a[2]&63; ((*a&248)==240){ //Byte represents the start of an encoded character beyond the res[b]= ; } b++; } res; } //Do not call me. getUTF8size( *string){ (!string) 0; res=0; (;*string;string++){ (*string<0x80) res++; (*string<0x800) res+=2; res+=3; } res; } /* string: a wchar_t C string (nul terminated) Return value: a UTF-8-encoded C string. The function handles memory allocation on its own. Limitations: Only handles the range [U+0000;U+FFFF], higher code points are changed to '?'. Assumptions: sizeof(wchar_t)>=2 */ *WChar_to_UTF8( *string){ fSize=getUTF8size(string); *res= [fSize+1]; res[fSize]=0; (!string) res; b=0; (;*string;string++,b++){ (*string<0x80) res[b]=( )*string; (*string<0x800){ res[b++]=(*string>>6)|192; res[b]=*string&63|128; } { res[b++]=(*string>>12)|224; res[b++]=((*string&4095)>>6)|128; res[b]=*string&63|128; } } res; }"
    }
]