[
    {
        "link": "https://grafana.com/grafana/dashboards/15877-kubernetes-cost-report",
        "document": "Monitor your Kubernetes deployment with prebuilt visualizations that allow you to drill down from a high-level cluster overview to pod-specific details in minutes."
    },
    {
        "link": "https://grafana.com/grafana/dashboards/18283-kubernetes-dashboard",
        "document": "Monitor your Kubernetes deployment with prebuilt visualizations that allow you to drill down from a high-level cluster overview to pod-specific details in minutes."
    },
    {
        "link": "https://grafana.com/grafana/dashboards/8670-cluster-cost-utilization-metrics",
        "document": "Opinionated solutions that help you get there easier and faster\n\nInstantly connect all your data sources to Grafana"
    },
    {
        "link": "https://grafana.com/grafana/dashboards/6417-kubernetes-cluster-prometheus",
        "document": "Monitor your Kubernetes deployment with prebuilt visualizations that allow you to drill down from a high-level cluster overview to pod-specific details in minutes."
    },
    {
        "link": "https://grafana.com/pricing",
        "document": "Fully managed log aggregation system powered by Grafana Loki that allows you to store and query logs from all your applications and infrastructure. Use logs volume explorer, logs filtering, and logs to metrics to optimize cost. Understand which log streams are generating the most volume to better attribute logs ingest across an organization and identify areas where logs ingest can be optimized via logs filtering and logs to metrics. Run faster queries at scale with massive parallelization and query splitting techniques. Native support for out-of-order ingestion and bursts of logs, so no more lost logs. Leverage Promtail, Fluentbit, Fluentd, Vector, Logstash, the OpenTelemetry Collector, and the Grafana Agent, as well as a host of unofficial clients for shipping logs. For long-term retention needs, export logs to your own storage bucket (e.g., s3) in a format that is still queryable without needing to ingest logs back into Grafana. Contact us for volume discounts and expert support\n• None 50 GB logs ingested per month, then pay for what you use. No usage limits.\n• None 100 GB logs ingested per month, then pay for what you use. No usage limits. Do you offer retention greater than 30 days? Yes, we have additional retention options available. Contact us for more details. Default retention is 30 days, and you can also use logs export to retain logs in your own storage bucket. Do you provide discounts for higher usage volumes? Yes, we provide volume discounts for enterprise-scale usage. Contact us for more details.\n\nQuery, visualize, alert on, and understand your data no matter where it’s stored. Ease of use and flexibility: Visualize data from a Kubernetes cluster, Raspberry Pi, different cloud services, or even Google Sheets in a single dashboard to gain full stack visibility, track real-time SLI/SLO metrics, and more. Security and governance: Create and manage user permissions, instances, access policies, and tokens via UI and/or API. Leverage SSO, RBAC, SAML, audit logs, reporting, etc. at scale. Generative AI for panels: Automatically generate titles and descriptions and change summaries for your Grafana dashboards to streamline your workflow. Private Data Source Connect: Leverage the Private Data Source Connect feature to query any network-secured data source, regardless of whether it is hosted on an AWS/GCP/Azure VPC, an on-prem network, or even your local computer.\n• None 3 monthly active users, then pay for what you use. Paid add-on: Enterprise plugins. No usage limits.\n• None 5 monthly active users, then pay for what you use. Enterprise plugins included. No usage limits. Any user that logs into Grafana during the billing month is considered an active user. Does the Cloud Pro Pay As You Go plan include Enterprise plugins? Enterprise plugins are a paid add-on for the Cloud Pro Pay As You Go Plan that is priced at $55 per active user per month. By default, your account will have Grafana without Enterprise plugins, which is priced at $8 per active user per month. Do you provide discounts for higher usage volumes? Yes, we provide volume discounts for enterprise-scale usage. Contact us for more details.\n\nGain application performance insights and reduce MTTR out of the box, all based on OpenTelemetry and Prometheus. Accelerate time to insights with guided onboarding, Service Inventory, Service Overview, Service Map, and seamless metrics/logs/traces exploration. Correlate metrics, logs, and traces across frontend, application & infrastructure layers, preserving context during troubleshooting. Combine OpenTelemetry and Prometheus instrumentation as you want. No more expensive, proprietary instrumentation. Contact us for volume discounts and expert support\n• None 2,232 app o11y host hours per month, then pay for what you use. No usage limits.\n• None 3,720 app o11y host hours per month, then pay for what you use. No usage limits. An Host is a physical or virtual operating system instance that is sending observability signals including traces and span metrics - a host is considered active if it has sent observability signals in the last 15 minutes. Billable host hours is the total number of host hours measured during the month. Note: By billing based on host hours, customers don’t have to pay for their peak (i.e. 99th percentile) host usage but rather the actual host hours consumed during the billing month. Host Hours based pricing is only applicable for customers that are using the Application Observability product offering in Grafana Cloud. For customers not using the Application Observability product offering in Grafana Cloud and instead building their own dashboards, alerts, and workflows to monitor applications, standard pricing for Grafana Cloud Metrics, Logs, Traces, Profiles and Visualization applies and there are no charges based on Host Hours. Do you provide discounts for higher usage volumes? Yes, we provide volume discounts for Enterprise scale usage. Contact us for more details.\n\nConnect your infrastructure by a simple helm chart installation powered by Grafana Alloy. Pre-filter to only ingest the data that is actually useful. Designed for diverse use cases, Kubernetes Monitoring works with a broad spectrum of Kubernetes distributions, cloud service providers, and industry standards for metric capturing and exportation. Identify Kubernetes efficiencies and cost savings with OpenCost-based features and visualizations. Analyze, categorize, and visualize expenses and trends by cloud provider and resource type. Access correlated Kubernetes metrics,logs and events, Prometheus and Grafana Loki’s shared metadata keeps the exact same labels for your Kubernetes infrastructure. Start quickly monitoring your fleet with pre-configured dashboards, alerts, and scraping rules to effectively monitor prevalent Kubernetes services. Forecast Kubernetes object consumption, from cluster to container, including CPU & memory needs. Contact us for volume discounts and expert support\n• None 2,232 host hours & 37,944 container hours per month, then pay for what you use. No usage limits.\n• None 3,720 host hours & 52,824 container hours per month, then pay for what you use. No usage limits. An Host is a physical or virtual operating system instance that is sending observability signals including k8s metrics - a host is considered active if it has sent observability signals in the last 15 minutes. Billable host hours is the total number of host hours measured during the month. Note: By billing based on host hours, customers don’t have to pay for their peak (i.e. 99th percentile) host usage but rather the actual host hours consumed during the billing month. Host Hours based pricing is only applicable for customers that are using the Kubernetes Monitoring product offering in Grafana Cloud. Do you provide discounts for higher usage volumes? Yes, we provide volume discounts for enterprise-scale usage. Contact us for more details.\n\nProactively monitors your APIs and web applications globally and throughout the application lifecycle, with out-of-the-box debugging insights. Proactively monitor the performance and uptime of your websites and APIs at various network levels from around the globe, helping you track SLOs and SLAs. Streamline your workflow with automated Synthetic Monitoring. Use the same k6 scripts from pre-prod to production to improve collaboration and efficiency. Combine the user-friendly pre-built dashboards with Grafana’s flexible dashboarding for effortless triage, diagnosis, and issue resolution. Contact us for volume discounts and expert support\n• None 100k test executions per month, then pay for what you use. No usage limits.\n• None 200k test executions per month, then pay for what you use. No usage limits. A test execution is a Synthetic test running in a probe location per minute of run time. Example: A synthetic test running in 5 locations that takes 1.5 minutes to complete will consume 10 executions each time it runs. How do I estimate the number of test executions? To estimate the number of test executions per month, you will need the following inputs:\n• Duration of Test (rounded to the nearest minute) Using the above info, you can calculate the number of test executions per month by applying this formula (where 43,200 is the total minutes in a month): Using the above info, you can calculate the number of test executions per month by applying this formula (where 43,200 is the total minutes in a month): Do you provide discounts for higher usage volumes? Yes, we provide volume discounts for enterprise-scale usage. Contact us for more details.\n\nFully managed performance testing platform to prevent system failures and consistently deliver fast and reliable applications. Run load tests in the cloud for up to 1 million concurrent virtual users or 5 million requests/second. Launch tests from 21 geographic locations to ensure a great experience no matter where your users are. Ease of use and flexibility Onboard users quickly and lower the barrier to entry for writing test scripts with the GUI test builder and browser recorder. Schedule and automate testing from the web app, CLI, and CI pipelines and use SLOs as the pass/fail criteria. The integration generates useful aggregations, correlations, and actionable insights from users’ tracing data to help understand your performance tests and prevent reliability problems from impacting end users. Contact us for volume discounts and expert support\n• None 500 virtual user hours (VUh) per month, then pay for what you use. No usage limits.\n• None 1000 virtual user hours (VUh) per month, then pay for what you use. No usage limits. VUh is calculated by using the following formula: If your test ramps up to a maximum of 100 VUs and runs for 10 minutes, the test run will use 16.67 VUh ((100 VUs x 10 minutes)/60 = 16.67 VUh). Note that VU hours are calculated based on the period that the test run executes, not the preconfigured test duration. If the test duration is 2 or more hours but runs for only 30.01 minutes, then the subscription will be charged for the test-execution period rounded up to the next minute (in this case, 31 minutes). The minimum for a test is 1 VUh. Find additional details here. Do you provide discounts for higher usage volumes? Yes, we provide volume discounts for enterprise-scale usage. Contact us for more details."
    },
    {
        "link": "https://grafana.com/docs/grafana/latest/datasources",
        "document": "Grafana comes with built-in support for many data sources. If you need other data sources, you can also install one of the many data source plugins. If the plugin you need doesn’t exist, you can develop a custom plugin.\n\nEach data source comes with a query editor, which formulates custom queries according to the source’s structure. After you add and configure a data source, you can use it as an input for many operations, including:\n\nThis documentation describes how to manage data sources in general, and how to configure or query the built-in data sources. For other data sources, refer to the list of datasource plugins.\n\nOnly users with the organization administrator role can add or remove data sources. To access data source management tools in Grafana as an administrator, navigate to Configuration > Data Sources in the Grafana sidebar.\n\nFor details on data source management, including instructions on how configure user permissions for queries, refer to the administration documentation.\n\nBefore you can create your first dashboard, you need to add your data source.\n• Enter the name of a specific data source in the search dialog. You can filter by Data source to only see data sources.\n• Click the data source you want to add.\n• Configure the data source following instructions specific to that data source.\n\nEach data source’s query editor provides a customized user interface that helps you write queries that take advantage of its unique capabilities. You use a data source’s query editor when you create queries in dashboard panels or Explore.\n\nBecause of the differences between query languages, each data source query editor looks and functions differently. Depending on your data source, the query editor might provide auto-completion features, metric names, variable suggestions, or a visual query-building interface.\n\nFor example, this video demonstrates the visual Prometheus query builder:\n\nFor general information about querying in Grafana, and common options and user interface elements across all query editors, refer to Query and transform data.\n\nA built-in data source that generates random walk data and can poll the Testdata data source. Additionally, it can list files and get other data from a Grafana installation. This can be helpful for testing visualizations and running experiments.\n\nAn abstraction that lets you query multiple data sources in the same panel. When you select Mixed, you can then select a different data source for each new query that you add.\n• The first query uses the data source that was selected before you selected Mixed.\n• You can’t change an existing query to use the Mixed data source.\n\nA data source that uses the result set from another panel in the same dashboard. The dashboard data source can use data either directly from the selected panel or from annotations attached to the selected panel.\n\nThese built-in core data sources are also included in the Grafana documentation:\n\nYou can add additional data sources as plugins (that are not available in core Grafana), which you can install or create yourself.\n\nTo view available data source plugins, go to the plugin catalog and select the “Data sources” filter. For details about the plugin catalog, refer to Plugin management.\n\nYou can further filter the plugin catalog’s results for data sources provided by the Grafana community, Grafana Labs, and partners. If you use Grafana Enterprise, you can also filter by Enterprise-supported plugins.\n\nFor more documentation on a specific data source plugin’s features, including its query language and editor, refer to its plugin catalog page.\n\nTo build your own data source plugin, refer to the Build a data source plugin tutorial and Plugin tools."
    },
    {
        "link": "https://grafana.com/docs/grafana/latest/setup-grafana/installation/kubernetes",
        "document": "On this page, you will find instructions for installing and running Grafana on Kubernetes using Kubernetes manifests for the setup. If Helm is your preferred option, refer to Grafana Helm community charts.\n\nWatch this video to learn more about installing Grafana on Kubernetes:\n• None You need the latest version of Kubernetes running either locally or remotely on a public or private cloud.\n• None If you plan to use it in a local environment, you can use various Kubernetes options such as minikube, kind, Docker Desktop, and others.\n• None If you plan to use Kubernetes in a production setting, it’s recommended to utilize managed cloud services like Google Kubernetes Engine (GKE), Amazon Elastic Kubernetes Service (EKS), or Azure Kubernetes Service (AKS).\n\nThis section provides minimum hardware and software requirements.\n\nFor a list of supported databases, refer to supported databases.\n\nFor a list of support web browsers, refer to supported web browsers.\n\nThis section explains how to install Grafana OSS using Kubernetes.\n\nIf you deploy an application in Kubernetes, it will use the default namespace which may already have other applications running. This can result in conflicts and other issues.\n\nIt is recommended to create a new namespace in Kubernetes to better manage, organize, allocate, and manage cluster resources. For more information about Namespaces, refer to the official Kubernetes documentation.\n• None To create a namespace, run the following command: In this example, the namespace is\n• None To verify and view the newly created namespace, run the following command: The output of the command provides more information about the newly created namespace.\n• None Create a YAML manifest file named . This file will contain the necessary code for deployment. In the next step you define the following three objects in the YAML file. This object provides network access to the Pod defined in the deployment. This object is responsible for creating the pods, ensuring they stay up to date, and managing Replicaset and Rolling updates.\n• None Copy and paste the following contents and save it in the file. --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: grafana-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: labels: app: grafana name: grafana spec: selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: securityContext: fsGroup: 472 supplementalGroups: - 0 containers: - name: grafana image: grafana/grafana:latest imagePullPolicy: IfNotPresent ports: - containerPort: 3000 name: http-grafana protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /robots.txt port: 3000 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 30 successThreshold: 1 timeoutSeconds: 2 livenessProbe: failureThreshold: 3 initialDelaySeconds: 30 periodSeconds: 10 successThreshold: 1 tcpSocket: port: 3000 timeoutSeconds: 1 resources: requests: cpu: 250m memory: 750Mi volumeMounts: - mountPath: /var/lib/grafana name: grafana-pv volumes: - name: grafana-pv persistentVolumeClaim: claimName: grafana-pvc --- apiVersion: v1 kind: Service metadata: name: grafana spec: ports: - port: 3000 protocol: TCP targetPort: http-grafana selector: app: grafana sessionAffinity: None type: LoadBalancer\n• None Run the following command to send the manifest to the Kubernetes API server: This command creates the PVC, Deployment, and Service objects.\n• None Complete the following steps to verify the deployment status of each object. a. For PVC, run the following command: b. For Deployment, run the following command: c. For Service, run the following command:\n\nIn this task, you access Grafana deployed on a Managed Kubernetes provider using a web browser. Accessing Grafana via a web browser is straightforward if it is deployed on a Managed Kubernetes Provider as it uses the cloud provider’s LoadBalancer to which the external load balancer routes are automatically created.\n• None Run the following command to obtain the deployment information: The output returned should look similar to the following: NAME READY STATUS RESTARTS AGE pod/grafana-69946c9bd6-kwjb6 1/1 Running 0 7m27s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/grafana LoadBalancer 10.5.243.226 1.120.130.330 3000:31171/TCP 7m27s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/grafana 1/1 1 1 7m29s NAME DESIRED CURRENT READY AGE replicaset.apps/grafana-69946c9bd6 1 1 1 7m30s\n• None Identify the EXTERNAL-IP value in the output and type it into your browser.\n• None To sign in, enter for both the username and password.\n• None If you do not see the EXTERNAL-IP, complete the following steps: a. Run the following command to do a port-forwarding of the Grafana service on port . For more information about port-forwarding, refer to Use Port Forwarding to Access Applications in a Cluster. b. Navigate to in your browser. c. To sign in, enter for both the username and password.\n\nThere are multiple ways to access the Grafana UI on a web browser when using minikube. For more information about minikube, refer to How to access applications running within minikube.\n\nThis section lists the two most common options for accessing an application running in minikube.\n\nThis option uses the in the service manifest, which makes the service accessible through the command. For more information, refer to minikube Service command usage.\n• None Run the following command to obtain the Grafana service IP: The output returns the Kubernetes URL for service in your local cluster.\n• None Run a command to verify whether a given connection should work in a browser under ideal circumstances. The following example output shows that an endpoint has been located:\n• None Access the Grafana UI in the browser using the provided IP:Port from the command above. For example\n• None To sign in to Grafana, enter for both the username and password.\n\nIf Option 1 does not work in your minikube environment (this mostly depends on the network), then as an alternative you can use the port forwarding option for the Grafana service on port .\n\nFor more information about port forwarding, refer to Use Port Forwarding to Access Applications in a Cluster.\n• None To find the minikube IP address, run the following command: The output contains the IP address that you use to access the Grafana Pod during port forwarding. A Pod is the smallest deployment unit in Kubernetes and is the core building block for running applications in a Kubernetes cluster. For more information about Pods, refer to Pods.\n• None To obtain the Grafana Pod information, run the following command: The output should look similar to the following: The output shows the Grafana POD name in the column, that you use for port forwarding.\n• None Run the following command for enabling the port forwarding on the POD:\n• None To access the Grafana UI on the web browser, type the minikube IP along with the forwarded port. For example\n• None To sign in to Grafana, enter for both the username and password.\n\nRolling updates enable deployment updates to take place with no downtime by incrementally updating Pods instances with new ones. The new Pods will be scheduled on nodes with available resources. For more information about rolling updates, refer to Performing a Rolling Update.\n\nThe following steps use the command to add the metadata and keep track of the deployment. For more information about , refer to kubectl annotate documentation.\n• None To view the current status of the rollout, run the following command: The output will look similar to this: The output shows that nothing has been updated or changed after applying the file.\n• None To add metadata to keep record of the initial deployment, run the following command:\n• None To review the rollout history and verify the changes, run the following command: You should see the updated information that you added in the earlier.\n• None To change the deployed Grafana version, run the following command:\n• None In the editor, change the container image under the section.\n• None Once you save the file, you receive a message similar to the following: This means that the changes have been applied.\n• None To verify that the rollout on the cluster is successful, run the following command: A successful deployment rollout means that the Grafana Dev cluster is now available.\n• None To check the statuses of all deployed objects, run the following command and include the flag to get more detailed output: You should see the newly deployed image.\n• None To verify it, access the Grafana UI in the browser using the provided IP:Port from the command above.\n• None To sign in to Grafana, enter for both the username and password.\n• None In the top-right corner, click the help icon.\n• None Add the metadata to keep track of things using the commands:\n• None You will see an output similar to this: deployment.apps/grafana REVISION CHANGE-CAUSE 1 deploying the default yaml 2 using grafana-oss-dev:10.1.0-124419pre for testing\n\nThis means that is the current version.\n\nWhen the Grafana deployment becomes unstable due to crash looping, bugs, and so on, you can roll back a deployment to an earlier version (a ).\n\nBy default, Kubernetes deployment rollout history remains in the system so that you can roll back at any time. For more information, refer to Rolling Back to a Previous Revision.\n• None To list all possible values, run the following command:\n• None To roll back to a previous version, run the command and provide a revision number. Example: To roll back to a previous version, specify the number, which appears after you run the command, in the parameter.\n• None To verify that the rollback on the cluster is successful, run the following command:\n• None Access the Grafana UI in the browser using the provided IP:Port from the command above.\n• None To sign in to Grafana, enter for both the username and password.\n• None In the top-right corner, click the help icon to display the version number.\n• None To see the new rollout history, run the following command:\n\nIf you need to go back to any other , just repeat the steps above and use the correct revision number in the parameter.\n\nProvisioning can add, update, or delete resources specified in your configuration files when Grafana starts. For detailed information, refer to Grafana Provisioning.\n\nThis section outlines general instructions for provisioning Grafana resources within Kubernetes, using a persistent volume to supply the configuration files to the Grafana pod.\n• None Add a new to the file.\n• None In the file, mount the persistent volume into as follows.\n• None Find or create the provision resources you want to add. For instance, create a file adding a mute timing (alerting resource).\n• None By default, configuration files for alerting resources need to be placed in the directory. Save the file in a directory named , as we will next supply this directory to the folder of the Grafana pod.\n• None Verify first the content of the provisioning directory in the running Grafana pod. Because the folder is not available yet, the last command should output a No such file or directory error.\n• None Copy the local directory to in the Grafana pod. You can follow the same process to provision additional Grafana resources by supplying the following folders:\n• None Verify the directory in the running Grafana pod includes the file.\n• None Restart the Grafana pod to provision the resources. Note that kills the previous pod and scales a new pod. When the old pod terminates, you may have to enable port-forwarding in the new pod. For instructions, refer to the previous sections about port forwarding in this guide.\n• None Verify the Grafana resources are properly provisioned within the Grafana instance.\n\nThis section includes troubleshooting tips you might find helpful when deploying Grafana on Kubernetes.\n\nIt is important to view the Grafana server logs while troubleshooting any issues.\n• None To check the Grafana logs, run the following command:\n• None If you have multiple containers running in the deployment, run the following command to obtain the logs only for the Grafana deployment:\n\nFor more information about accessing Kubernetes application logs, refer to Pods and Deployments.\n\nBy default, the Grafana log level is set to , but you can increase it to mode to fetch information needed to diagnose and troubleshoot a problem. For more information about Grafana log levels, refer to Configuring logs.\n\nThe following example uses the Kubernetes ConfigMap which is an API object that stores non-confidential data in key-value pairs. For more information, refer to Kubernetes ConfigMap Concept.\n• None Create a empty file and name it and add the following: [log] ; # Either \"debug\", \"info\", \"warn\", \"error\", \"critical\", default is \"info\" ; # we change from info to debug level level = debug This example adds the portion of the log section from the configuration file. You can refer to the Configure Grafana documentation to view all the default configuration settings.\n• None To add the configuration file into the Kubernetes cluster via the ConfigMap object, run the following command:\n• None To verify the ConfigMap object creation, run the following command:\n• None Open the file and In the Deployment section, provide the mount path to the custom configuration ( ) and reference the newly created ConfigMap for it. --- apiVersion: apps/v1 kind: Deployment metadata: labels: app: grafana name: grafana # the rest of the code remains the same. ... .... ... requests: cpu: 250m memory: 750Mi volumeMounts: - mountPath: /var/lib/grafana name: grafana-pv # This is to mount the volume for the custom configuration - mountPath: /etc/grafana name: ge-config volumes: - name: grafana-pv persistentVolumeClaim: claimName: grafana-pvc # This is to provide the reference to the ConfigMap for the volume - name: ge-config configMap: name: ge-config\n• None Deploy the manifest using the following kubectl apply command:\n• None To verify the status, run the following commands: # first check the rollout status kubectl rollout status deployment grafana --namespace=my-grafana # then check the deployment and configMap information kubectl get all --namespace=my-grafana\n• None To verify it, access the Grafana UI in the browser using the provided IP:Port\n• None To sign in to Grafana, enter for both the username and password.\n• None Navigate to Server Admin > Settings and then search for log. You should see the level to debug mode.\n\nYou can use the Kubernetes command to send requests to modifying endpoints and determine if the request would have succeeded.\n\nPerforming a dry run can be useful for catching errors or unintended consequences before they occur. For more information, refer to Kubernetes Dry-run.\n\nThe following example shows how to perform a dry run when you make changes to the such as using a new image version, or adding new labels and you want to determine if there are syntax errors or conflicts.\n\nTo perform a dry run, run the following command:\n\nIf there are no errors, then the output will look similar to this:\n\nIf there are errors or warnings, you will see them in the terminal.\n\nIf you want to remove any of the Grafana deployment objects, use the .\n• None If you want to remove the complete Grafana deployment, run the following command: This command deletes the deployment, persistentvolumeclaim, and service objects.\n• None To delete the ConfigMap, run the following command:\n\nThe process for deploying Grafana Enterprise is almost identical to the preceding process, except for additional steps that are required for adding your license file.\n\nTo run Grafana Enterprise, you need a valid license. To obtain a license, contact a Grafana Labs representative. This topic assumes that you have a valid license in a file. Associate your license with a URL that you can use later in the topic.\n\nCreate a Kubernetes secret from your license file using the following command:\n• None Create a Grafana configuration file with the name\n• None Paste the following YAML contents into the file you created:\n• None Update the field to the url associated with the license provided to you.\n\nCreate a Kubernetes Configmap from your file with the following command:\n• None Create a file, and copy-and-paste the following content into it. The following YAML is identical to the one for a Grafana installation, except for the additional references to the Configmap that contains your Grafana configuration file and the secret that has your license. --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: grafana-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: labels: app: grafana name: grafana spec: selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: securityContext: fsGroup: 472 supplementalGroups: - 0 containers: - image: grafana/grafana-enterprise:latest imagePullPolicy: IfNotPresent name: grafana ports: - containerPort: 3000 name: http-grafana protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /robots.txt port: 3000 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 30 successThreshold: 1 timeoutSeconds: 2 resources: limits: memory: 4Gi requests: cpu: 100m memory: 2Gi volumeMounts: - mountPath: /var/lib/grafana name: grafana-pv - mountPath: /etc/grafana name: ge-config - mountPath: /etc/grafana/license name: ge-license volumes: - name: grafana-pv persistentVolumeClaim: claimName: grafana-pvc - name: ge-config configMap: name: ge-config - name: ge-license secret: secretName: ge-license --- apiVersion: v1 kind: Service metadata: name: grafana spec: ports: - port: 3000 protocol: TCP targetPort: http-grafana selector: app: grafana sessionAffinity: None type: LoadBalancer If you use in the Service and depending on your cloud platform and network configuration, doing so might expose your Grafana instance to the Internet. To eliminate this risk, use to restrict access from within the cluster Grafana is deployed to.\n• None To send the manifest to Kubernetes API Server, run the following command:\n• None To verify the manifest was sent, run the following command:\n• None Navigate to in your browser. You should see the Grafana login page.\n• None Use for both the username and password to login.\n• None To verify you are working with an enterprise license, scroll to the bottom of the page where you should see ."
    },
    {
        "link": "https://grafana.com/docs/grafana/latest/getting-started/build-first-dashboard",
        "document": "This topic helps you get started with Grafana and build your first dashboard using the built-in data source. To learn more about Grafana, refer to Introduction to Grafana.\n\nGrafana can be installed on many different operating systems. For a list of the minimum hardware and software requirements, as well as instructions on installing Grafana, refer to Install Grafana.\n\nTo sign in to Grafana for the first time:\n• None Open your web browser and go to http://localhost:3000/. The default HTTP port that Grafana listens to is unless you have configured a different port.\n• None On the sign-in page, enter for both the username and password.\n• None If successful, you’ll see a prompt to change the password.\n• None Click OK on the prompt and change your password.\n\nIf you’ve already set up a data source that you know how to query, refer to Create a dashboard instead.\n\nTo create your first dashboard using the built-in data source:\n• None On the Dashboards page, click New and select New Dashboard from the drop-down menu.\n• None In the dialog box that opens, click : This configures your query and generates the Random Walk dashboard.\n• None Alternatively, click Back to dashboard if you want to see your changes applied to the dashboard first. Then click Save dashboard when you’re ready.\n• None Add a descriptive title for the dashboard, or have Grafana create one using generative AI features, and then click Save.\n• None Click Back to dashboard and then Exit edit.\n\nCongratulations, you have created your first dashboard and it’s displaying results.\n\nContinue to experiment with what you have built, try the explore workflow or another visualization feature. Refer to Data sources for a list of supported data sources and instructions on how to add a data source. The following topics will be of interest to you:\n\nThe following topics are of interest to Grafana server admin users:"
    },
    {
        "link": "https://github.com/dotdc/grafana-dashboards-kubernetes",
        "document": "\n• Known issue(s)\n• Broken panels on k8s-views-nodes when a node changes its IP address\n• Broken panels on k8s-views-nodes due to the nodename label\n\nThis repository contains a modern set of Grafana dashboards for Kubernetes.\n\n They are inspired by many other dashboards from and .\n\nMore information about them in my article: A set of modern Grafana dashboards for Kubernetes\n\nYou can also download them on Grafana.com.\n\nThis repository follows semantic versioning for releases.\n\n It relies on conventional commits to automate releases using semantic-release.\n\nThese dashboards are made and tested for the kube-prometheus-stack chart, but they should work well with others as soon as you have kube-state-metrics and prometheus-node-exporter installed on your Kubernetes cluster.\n\nThey are not backward compatible with older Grafana versions because they try to take advantage of Grafana's newest features like:\n\nThey also have a variable so they will work on a federated Grafana instance.\n\nAs an example, here's how the dashboard looks like:\n\nIn most cases, you will need to clone this repository (or your fork):\n\nIf you plan to deploy these dashboards using ArgoCD, ConfigMaps or Terraform, you will also need to enable and configure the on the Grafana Helm chart to get the dashboards loaded in your Grafana instance:\n\nOn the WebUI of your Grafana instance, put your mouse over the sign on the left menu, then click on .\n\n Once you are on the Import page, you can upload the JSON files one by one from your local copy using the button.\n\nOn the WebUI of your Grafana instance, put your mouse over the sign on the left menu, then click on .\n\n Once you are on the Import page, you can put the grafana.com dashboard ID (see table below) under then click on the button. Repeat for each dashboard.\n\nIf you are using ArgoCD, this will deploy the dashboards in the default project of ArgoCD:\n\nYou will also need to enable and configure the Grafana as described in Installation.\n\nIf you use the official Grafana helm chart or kube-prometheus-stack, you can install the dashboards directly using the & helm chart values.\n\nDepending on your setup, add or merge the following block example to your helm chart values.\n\n The example is for kube-prometheus-stack, for the official Grafana helm chart, remove the first line ( ), and reduce the indentation level of the entire block.\n\nGrafana dashboards can be provisioned as Kubernetes ConfigMaps if you configure the dashboard sidecar available on the official Grafana Helm Chart.\n\nTo build the ConfigMaps and output them on STDOUT :\n\nNote: no namespace is set by default, you can change that in the file.\n\nTo build and deploy them directly on your Kubernetes cluster :\n\nYou will also need to enable and configure the Grafana as described in Installation.\n\nNote: you can change the namespace if needed.\n\nIf you use Terraform to provision your Kubernetes resources, you can convert the generated ConfigMaps to Terraform code using tfk8s.\n\nTo build and convert ConfigMaps to Terraform code :\n\nYou will also need to enable and configure the Grafana as described in Installation.\n\nNote: no namespace is set by default, you can change that in the file.\n\nA user reported in #50 that some panels were broken because the default value of the variable was too low. The root cause hasn't been identified precisely, but he was using Grafana Agent & Grafana Mimir. Changing the variable to a higher value (a lower resolution) will likely solve the issue. To make the fix permanent, you can configure the in your Grafana Datasource to a working value for your setup.\n\nTo make this dashboard more convenient, there's a small variable hack to display instead of . Because of that, some panels could lack data when a node changes its IP address as reported in #102.\n\nNo easy fix for this scenario yet, but it should be a corner case for most people. Feel free to reopen the issue if you have ideas to fix this.\n\nThe dashboard will have many broken panels if the label from doesn't match the label from .\n\nThis situation can happen on certain deployments of the node exporter running inside Kubernetes(e.g. via a ), where takes a different value than the node name as understood by the Kubernetes API.\n\nBelow are some ways to relabel the metric to force the label to the appropriate value, depending on the way the collection agent is deployed:\n\nAssuming the node exporter job is defined through , you can take advantage of the internal discovery labels and fix this by adding the following relabeling rule to the job:\n\nIf using the Prometheus operator or the Grafana agent in operator mode, the scrape job should instead be configured via a that will dynamically edit the Prometheus configuration file. In that case, the relabeling has a slightly different syntax:\n\nAs a convenience, if using the kube-prometheus-stack helm chart, this added rule can be directly specified in your values.yaml:\n\nThe Grafana Agent can bundle its own node_exporter. In that case, relabeling can be done this way:\n\nThe environment variable is injected by default by the Grafana Agent helm chart\n\nFeel free to contribute to this project:\n• Give a GitHub ⭐ if you like it\n• Create an Issue to make a feature request, report a bug or share an idea.\n• Create a Pull Request if you want to share code or anything useful to this project."
    },
    {
        "link": "https://grafana.com/tutorials/provision-dashboards-and-data-sources",
        "document": "Learn how you can reuse dashboards and data sources across multiple teams by provisioning Grafana from version-controlled configuration files.\n\nConfiguration as code is the practice of storing the configuration of your system as a set of version controlled, human-readable configuration files, rather than in a database. These configuration files can be reused across environments to avoid duplicated resources.\n\nAs the number of dashboards and data sources grows within your organization, manually managing changes can become tedious and error-prone. Encouraging reuse becomes important to avoid multiple teams redesigning the same dashboards.\n\nGrafana supports configuration as code through provisioning. The resources that currently supports provisioning are:\n\nBefore you can start provisioning resources, Grafana needs to know where to find the provisioning directory. The provisioning directory contains configuration files that are applied whenever Grafana starts and continuously updated while running.\n\nBy default, Grafana looks for a provisioning directory in the configuration directory (grafana > conf) on the system where Grafana is installed. However, if you are a Grafana Administrator, then you might want to place the config files in a shared resource like a network folder, so you would need to change the path to the provisioning directory.\n\nYou can set a different path by setting the property in the main config file:\n\nFor more information about configuration files, refer to Configuration in the Grafana documentation.\n\nThe provisioning directory assumes the following structure:\n\nNext, we’ll look at how to provision a data source.\n\nEach data source provisioning config file contains a manifest that specifies the desired state of a set of provisioned data sources.\n\nAt startup, Grafana loads the configuration files and provisions the data sources listed in the manifests.\n\nLet’s configure a TestData data source that you can use for your dashboards.\n• None In the directory, create a file called with the following content:\n• None Restart Grafana to load the new changes.\n• None In the sidebar, hover the cursor over the Configuration (gear) icon and click Data Sources. TestData appears in the list of data sources.\n\nEach dashboard config file contains a manifest that specifies the desired state of a set of dashboard providers.\n\nA dashboard provider tells Grafana where to find the dashboard definitions and where to put them.\n\nGrafana regularly checks for changes to the dashboard definitions (by default every 10 seconds).\n\nLet’s define a dashboard provider so that Grafana knows where to find the dashboards we want to provision.\n\nIn the directory, create a file called with the following content:\n\nFor more information on how to configure dashboard providers, refer to Dashboards.\n• None In the dashboard definitions directory you specified in the dashboard provider, i.e. , create a file called with the following content: { \"__inputs\": [], \"__requires\": [], \"annotations\": { \"list\": [] }, \"editable\": false, \"gnetId\": null, \"graphTooltip\": 0, \"hideControls\": false, \"id\": null, \"links\": [], \"panels\": [ { \"aliasColors\": {}, \"bars\": false, \"dashLength\": 10, \"dashes\": false, \"datasource\": \"TestData\", \"fill\": 1, \"gridPos\": { \"h\": 8, \"w\": 24, \"x\": 0, \"y\": 0 }, \"id\": 2, \"legend\": { \"alignAsTable\": false, \"avg\": false, \"current\": false, \"max\": false, \"min\": false, \"rightSide\": false, \"show\": true, \"total\": false, \"values\": false }, \"lines\": true, \"linewidth\": 1, \"links\": [], \"nullPointMode\": \"null\", \"percentage\": false, \"pointradius\": 5, \"points\": false, \"renderer\": \"flot\", \"repeat\": null, \"seriesOverrides\": [], \"spaceLength\": 10, \"stack\": false, \"steppedLine\": false, \"targets\": [], \"thresholds\": [], \"timeFrom\": null, \"timeShift\": null, \"title\": \"CPU Usage\", \"tooltip\": { \"shared\": true, \"sort\": 0, \"value_type\": \"individual\" }, \"type\": \"graph\", \"xaxis\": { \"buckets\": null, \"mode\": \"time\", \"name\": null, \"show\": true, \"values\": [] }, \"yaxes\": [ { \"format\": \"short\", \"label\": null, \"logBase\": 1, \"max\": null, \"min\": null, \"show\": true }, { \"format\": \"short\", \"label\": null, \"logBase\": 1, \"max\": null, \"min\": null, \"show\": true } ] } ], \"refresh\": \"\", \"rows\": [], \"schemaVersion\": 16, \"tags\": [\"kubernetes\"], \"templating\": { \"list\": [] }, \"time\": { \"from\": \"now-6h\", \"to\": \"now\" }, \"timepicker\": {}, \"timezone\": \"browser\", \"title\": \"Cluster\", \"version\": 0 }\n• None Restart Grafana to provision the new dashboard or wait 10 seconds for Grafana to automatically create the dashboard.\n• None In the sidebar, hover the cursor over Dashboards (squares) icon, and then click Manage. The dashboard appears in a Services folder.\n\nIf you don’t specify an in the dashboard definition, then Grafana assigns one during provisioning. You can set the yourself if you want to reference the dashboard from other dashboards. Be careful to not use the same for multiple dashboards, as this will cause a conflict.\n\nIn this tutorial you learned how you to reuse dashboards and data sources across multiple teams by provisioning Grafana from version-controlled configuration files.\n\nDashboard definitions can get unwieldy as more panels and configurations are added to them. There are a number of open source tools available to make it easier to manage dashboard definitions:"
    }
]