[
    {
        "link": "https://f5.com/company/blog/nginx/avoiding-top-10-nginx-configuration-mistakes",
        "document": ""
    },
    {
        "link": "https://baeldung.com/linux/nginx-timeouts",
        "document": "NGINX is a common cross-platform multipurpose server. As such, it can link many parts of an internal or external network, transferring and providing access to files and dynamic data. In fact, it can also serve as a load balancer, ensuring availability. To that end, we may need to configure delay times to avoid errors like 504 Gateway Time-out and 408 Request Time-out.\n\nIn this tutorial, we explore timeouts and ways to set and disable different timeouts in NGINX. First, we explain how to add options in the NGINX configuration. After that, we enumerate and describe NGINX timeout types and settings. Finally, we show a snippet to effectively disable common timeouts.\n\nWe tested the code in this tutorial on Debian 11 (Bullseye) with GNU Bash 5.1.4. It should work in most POSIX-compliant environments.\n\nA timeout is a period of time after which a given process is terminated. While this can be an actual Linux process ID (PID), timeouts are a general concept.\n\nSince NGINX can serve in many different capacities, the timeout we may want to set might depend on the function we aim for. Here, all timeouts are in seconds, but we can also use the NGINX time units:\n\nCritically, for some settings, using 0 forces immediate timeouts, so setting an unlikely high value like 9999999 or simply 1y is usually the way to disable them.\n\nTo set options, we modify NGINX configuration files. Best practices dictate we shouldn’t change nginx.conf directly, and instead should create .conf files in conf.d, which is usually in /etc/nginx:\n\nAlmost all options we discuss can be set in any of three blocks:\n\nTo do that, we just add the appropriate name with its parameter values after whitespace, finishing with a ; semicolon:\n\nAfter any modifications, we can check the configuration file syntax:\n\nIn this case, the -t flag of nginx tests the file specified by -c (usual default /etc/nginx/nginx.conf).\n\nSeveral of the NGINX timeouts are basic and fairly universal:\n• client_body_timeout – maximum time (between successive reads) for reading the body of a client request (defaults 60, may result in 408 Request Time-out)\n• client_header_timeout – maximum time for reading the header of a client request (default 60, may result in 408 Request Time-out)\n• keepalive_timeout – maximum time for a client connection to be kept on the server (mandatory first parameter, default 75, 0 disables), as well as value for the Keep-Alive: timeout=time (optional second parameter, default 60)\n• lingering_timeout – if lingering_close is on, sets the maximum time for more client data to arrive (default 5), which it reads and ignores, repeating the cycle for a maximum time of lingering_time (default 30)\n• send_timeout – maximum time (between successive writes) when sending a response back to a client (default 60)\n\nIn addition, name resolution may be the culprit for many issues. By setting resolver_timeout, we can limit or increase the maximum time for resolving a name when using NGINX (default 30).\n\nAlso, ssl_session_timeout is the maximum time for a client to reuse SSL session parameters (default 5m).\n\nAll of the above affect most connections. Now, let’s move on to some specifics.\n\nOn a lower level, the listen directive has a so_keepalive parameter to configure the TCP listening socket. In other words, by setting it to on or off, we enable the keepalive mechanism SO_KEEPALIVE.\n\nFor supported operating systems, we can also supply a colon-separated list of options:\n\nOn the other hand, skipping any of these parameters leaves the system default.\n\nThe server directive has its own parameters provided by the upstream module.\n\nOne of them is the fail_timeout, which sets the maximum time to attempt max_fails (default 1, 0 disables) server contact before considering the server unavailable (default 10). This state remains for the same period before any retries.\n\nHowever, if we only have a single server, these options are ignored.\n\nThere are three common proxy server timeout values for NGINX:\n• proxy_connect_timeout – maximum time to connect to a proxied server (default 60, usually under 75)\n\nIn addition, there is the proxy_cache_lock_timeout that defines the maximum time to prevent simultaneous cache requests (default 5) if proxy_cache_lock (default off) is on. Stale caching can also depend on this timeout value.\n\nOf course, NGINX also provides FastCGI server transmission constraint settings:\n• fastcgi_connect_timeout – maximum time to connect with FastCGI server (default 60, usually under 75)\n\nAgain, fastcgi_cache_lock_timeout defines the maximum time to prevent simultaneous cache requests (default 5) if fastcgi_cache_lock (default off) is on. Further, similar to the proxy_* settings, stale caching can depend on this timeout value.\n\nFor Memcached, NGINX offers similar options to those for proxy and FastCGI:\n• memcached_connect_timeout – maximum time to connect with memcached server (default 60, usually under 75)\n\nOf course, we don’t have a cache lock in this case.\n\nWhile similar settings exist for other modules as well, in general, to effectively disable the effect of common timeout options, we can use a list of settings in an http or server block:\n\nIn all cases, we set the period to one day. Consequently, using these settings may heavily reduce performance.\n\nIn this article, we discussed timeouts and the NGINX timeout settings.\n\nIn conclusion, while NGINX provides many options to change different timeouts, changing the correct one is imperative for optimizing performance."
    },
    {
        "link": "https://stackoverflow.com/questions/24453388/nginx-reverse-proxy-causing-504-gateway-timeout",
        "document": "I am using Nginx as a reverse proxy that takes requests then does a proxy_pass to get the actual web application from the upstream server running on port 8001.\n\nIf I go to or do a wget, I get a 504 Gateway Timeout after 60 seconds... However, if I load , the application loads as expected!\n\nSo something is preventing Nginx from communicating with the upstream server.\n\nAll this started after my hosting company reset the machine my stuff was running on, prior to that no issues whatsoever.\n\nAnd the output from my Nginx error log:"
    },
    {
        "link": "https://serverfault.com/questions/875025/setting-timeouts-in-nginx-conf",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    },
    {
        "link": "https://serverfault.com/questions/287102/nginx-proxy-read-timeout-vs-proxy-connect-timeout",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    },
    {
        "link": "https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy",
        "document": "This article describes the basic configuration of a proxy server. You will learn how to pass a request from NGINX to proxied servers over different protocols, modify client request headers that are sent to the proxied server, and configure buffering of responses coming from the proxied servers.\n\nProxying is typically used to distribute the load among several servers, seamlessly show content from different websites, or pass requests for processing to application servers over protocols other than HTTP.\n\nWhen NGINX proxies a request, it sends the request to a specified proxied server, fetches the response, and sends it back to the client. It is possible to proxy requests to an HTTP server (another NGINX server or any other server) or a non-HTTP server (which can run an application developed with a specific framework, such as PHP or Python) using a specified protocol. Supported protocols include FastCGI, uwsgi, SCGI, and memcached.\n\nTo pass a request to an HTTP proxied server, the proxy_pass directive is specified inside a location. For example:\n\nThis example configuration results in passing all requests processed in this location to the proxied server at the specified address. This address can be specified as a domain name or an IP address. The address may also include a port:\n\nNote that in the first example above, the address of the proxied server is followed by a URI, . If the URI is specified along with the address, it replaces the part of the request URI that matches the location parameter. For example, here the request with the URI will be proxied to . If the address is specified without a URI, or it is not possible to determine the part of URI to be replaced, the full request URI is passed (possibly, modified).\n\nTo pass a request to a non-HTTP proxied server, the appropriate directive should be used:\n\nNote that in these cases, the rules for specifying addresses may be different. You may also need to pass additional parameters to the server (see the reference documentation for more detail).\n\nThe proxy_pass directive can also point to a named group of servers. In this case, requests are distributed among the servers in the group according to the specified method.\n\nBy default, NGINX redefines two header fields in proxied requests, “Host” and “Connection”, and eliminates the header fields whose values are empty strings. “Host” is set to the variable, and “Connection” is set to .\n\nTo change these setting, as well as modify other header fields, use the proxy_set_header directive. This directive can be specified in a location or higher. It can also be specified in a particular server context or in the http block. For example:\n\nIn this configuration the “Host” field is set to the $host variable.\n\nTo prevent a header field from being passed to the proxied server, set it to an empty string as follows:\n\nBy default NGINX buffers responses from proxied servers. A response is stored in the internal buffers and is not sent to the client until the whole response is received. Buffering helps to optimize performance with slow clients, which can waste proxied server time if the response is passed from NGINX to the client synchronously. However, when buffering is enabled NGINX allows the proxied server to process responses quickly, while NGINX stores the responses for as much time as the clients need to download them.\n\nThe directive that is responsible for enabling and disabling buffering is proxy_buffering. By default it is set to and buffering is enabled.\n\nThe proxy_buffers directive controls the size and the number of buffers allocated for a request. The first part of the response from a proxied server is stored in a separate buffer, the size of which is set with the proxy_buffer_size directive. This part usually contains a comparatively small response header and can be made smaller than the buffers for the rest of the response.\n\nIn the following example, the default number of buffers is increased and the size of the buffer for the first portion of the response is made smaller than the default.\n\nIf buffering is disabled, the response is sent to the client synchronously while it is receiving it from the proxied server. This behavior may be desirable for fast interactive clients that need to start receiving the response as soon as possible.\n\nTo disable buffering in a specific location, place the proxy_buffering directive in the location with the parameter, as follows:\n\nIn this case NGINX uses only the buffer configured by proxy_buffer_size to store the current part of a response.\n\nA common use of a reverse proxy is to provide load balancing. Learn how to improve power, performance, and focus on your apps with rapid deployment in the free Five Reasons to Choose a Software Load Balancer ebook.\n\nIf your proxy server has several network interfaces, sometimes you might need to choose a particular source IP address for connecting to a proxied server or an upstream. This may be useful if a proxied server behind NGINX is configured to accept connections from particular IP networks or IP address ranges.\n\nSpecify the proxy_bind directive and the IP address of the necessary network interface:\n\nThe IP address can be also specified with a variable. For example, the variable passes the IP address of the network interface that accepted the request:"
    },
    {
        "link": "http://nginx.org/en/docs/beginners_guide.html",
        "document": "This guide gives a basic introduction to nginx and describes some simple tasks that can be done with it. It is supposed that nginx is already installed on the reader’s machine. If it is not, see the Installing nginx page. This guide describes how to start and stop nginx, and reload its configuration, explains the structure of the configuration file and describes how to set up nginx to serve out static content, how to configure nginx as a proxy server, and how to connect it with a FastCGI application.\n\nnginx has one master process and several worker processes. The main purpose of the master process is to read and evaluate configuration, and maintain worker processes. Worker processes do actual processing of requests. nginx employs event-based model and OS-dependent mechanisms to efficiently distribute requests among worker processes. The number of worker processes is defined in the configuration file and may be fixed for a given configuration or automatically adjusted to the number of available CPU cores (see worker_processes).\n\nThe way nginx and its modules work is determined in the configuration file. By default, the configuration file is named and placed in the directory , , or .\n\nChanges made in the configuration file will not be applied until the command to reload configuration is sent to nginx or it is restarted. To reload configuration, execute:\n\nOnce the master process receives the signal to reload configuration, it checks the syntax validity of the new configuration file and tries to apply the configuration provided in it. If this is a success, the master process starts new worker processes and sends messages to old worker processes, requesting them to shut down. Otherwise, the master process rolls back the changes and continues to work with the old configuration. Old worker processes, receiving a command to shut down, stop accepting new connections and continue to service current requests until all such requests are serviced. After that, the old worker processes exit.\n\nA signal may also be sent to nginx processes with the help of Unix tools such as the utility. In this case a signal is sent directly to a process with a given process ID. The process ID of the nginx master process is written, by default, to the in the directory or . For example, if the master process ID is 1628, to send the QUIT signal resulting in nginx’s graceful shutdown, execute:\n\nnginx consists of modules which are controlled by directives specified in the configuration file. Directives are divided into simple directives and block directives. A simple directive consists of the name and parameters separated by spaces and ends with a semicolon ( ). A block directive has the same structure as a simple directive, but instead of the semicolon it ends with a set of additional instructions surrounded by braces ( and ). If a block directive can have other directives inside braces, it is called a context (examples: events, http, server, and location).\n\nDirectives placed in the configuration file outside of any contexts are considered to be in the main context. The and directives reside in the context, in , and in .\n\nAn important web server task is serving out files (such as images or static HTML pages). You will implement an example where, depending on the request, files will be served from different local directories: (which may contain HTML files) and (containing images). This will require editing of the configuration file and setting up of a server block inside the http block with two location blocks.\n\nThis block specifies the “ ” prefix compared with the URI from the request. For matching requests, the URI will be added to the path specified in the root directive, that is, to , to form the path to the requested file on the local file system. If there are several matching blocks nginx selects the one with the longest prefix. The block above provides the shortest prefix, of length one, and so only if all other blocks fail to provide a match, this block will be used.\n\nThis is already a working configuration of a server that listens on the standard port 80 and is accessible on the local machine at . In response to requests with URIs starting with , the server will send files from the directory. For example, in response to the request nginx will send the file. If such file does not exist, nginx will send a response indicating the 404 error. Requests with URIs not starting with will be mapped onto the directory. For example, in response to the request nginx will send the file.\n\nOne of the frequent uses of nginx is setting it up as a proxy server, which means a server that receives requests, passes them to the proxied servers, retrieves responses from them, and sends them to the clients.\n\nWe will configure a basic proxy server, which serves requests of images with files from the local directory and sends all other requests to a proxied server. In this example, both servers will be defined on a single nginx instance.\n\nThis will be a simple server that listens on the port 8080 (previously, the directive has not been specified since the standard port 80 was used) and maps all requests to the directory on the local file system. Create this directory and put the file into it. Note that the directive is placed in the context. Such directive is used when the block selected for serving a request does not include its own directive.\n\nNext, use the server configuration from the previous section and modify it to make it a proxy server configuration. In the first block, put the proxy_pass directive with the protocol, name and port of the proxied server specified in the parameter (in our case, it is ):\n\nThe most basic nginx configuration to work with a FastCGI server includes using the fastcgi_pass directive instead of the directive, and fastcgi_param directives to set parameters passed to a FastCGI server. Suppose the FastCGI server is accessible on . Taking the proxy configuration from the previous section as a basis, replace the directive with the directive and change the parameter to . In PHP, the parameter is used for determining the script name, and the parameter is used to pass request parameters. The resulting configuration would be:"
    },
    {
        "link": "http://nginx.org/en/docs/http/ngx_http_core_module.html",
        "document": ""
    },
    {
        "link": "https://digitalocean.com/community/tutorials/understanding-nginx-server-and-location-block-selection-algorithms",
        "document": "Nginx is one of the most popular web servers in the world. It can successfully handle high loads with many concurrent client connections, and can function as a web server, a mail server, or a reverse proxy server.\n\nIn this guide, we will discuss some of the behind-the-scenes details that determine how Nginx processes client requests. Understanding these ideas can help take the guesswork out of designing server and location blocks and can make the request handling seem less unpredictable.\n\nNginx logically divides the configurations meant to serve different content into blocks, which live in a hierarchical structure. Each time a client request is made, Nginx begins a process of determining which configuration blocks should be used to handle the request. This decision process is what we will be discussing in this guide.\n\nThe main blocks that we will be discussing are the server block and the location block.\n\nA server block is a subset of Nginx’s configuration that defines a virtual server used to handle requests of a defined type. Administrators often configure multiple server blocks and decide which block should handle which connection based on the requested domain name, port, and IP address.\n\nA location block lives within a server block and is used to define how Nginx should handle requests for different resources and URIs for the parent server. The URI space can be subdivided in whatever way the administrator likes using these blocks. It is an extremely flexible model.\n\nHow Nginx Decides Which Server Block Will Handle a Request\n\nSince Nginx allows the administrator to define multiple server blocks that function as separate virtual web server instances, it needs a procedure for determining which of these server blocks will be used to satisfy a request.\n\nIt does this through a defined system of checks that are used to find the best possible match. The main server block directives that Nginx is concerned with during this process are the directive, and the directive.\n\nParsing the Directive to Find Possible Matches\n\nFirst, Nginx looks at the IP address and the port of the request. It matches this against the directive of each server to build a list of the server blocks that can possibly resolve the request.\n\nThe directive typically defines which IP address and port that the server block will respond to. By default, any server block that does not include a directive is given the listen parameters of (or if Nginx is being run by a normal, non-root user). This allows these blocks to respond to requests on any interface on port 80, but this default value does not hold much weight within the server selection process.\n\nThe directive can be set to:\n• A lone IP address which will then listen on the default port 80.\n• A lone port which will listen to every interface on that port.\n\nThe last option will generally only have implications when passing requests between different servers.\n\nWhen trying to determine which server block to send a request to, Nginx will first try to decide based on the specificity of the directive using the following rules:\n• Nginx translates all “incomplete” directives by substituting missing values with their default values so that each block can be evaluated by its IP address and port. Some examples of these translations are:\n• A block with no directive uses the value .\n• A block set to an IP address with no port becomes\n• A block set to port with no IP address becomes\n• Nginx then attempts to collect a list of the server blocks that match the request most specifically based on the IP address and port. This means that any block that is functionally using as its IP address (to match any interface), will not be selected if there are matching blocks that list a specific IP address. In any case, the port must be matched exactly.\n• If there is only one most specific match, that server block will be used to serve the request. If there are multiple server blocks with the same level of specificity matching, Nginx then begins to evaluate the directive of each server block.\n\nIt is important to understand that Nginx will only evaluate the directive when it needs to distinguish between server blocks that match to the same level of specificity in the directive. For instance, if is hosted on port of , a request for will always be served by the first block in this example, despite the directive in the second block.\n\nIn the event that more than one server block matches with equal specificity, the next step is to check the directive.\n\nNext, to further evaluate requests that have equally specific directives, Nginx checks the request’s header. This value holds the domain or IP address that the client was actually trying to reach.\n\nNginx attempts to find the best match for the value it finds by looking at the directive within each of the server blocks that are still selection candidates. Nginx evaluates these by using the following formula:\n• Nginx will first try to find a server block with a that matches the value in the header of the request exactly. If this is found, the associated block will be used to serve the request. If multiple exact matches are found, the first one is used.\n• If no exact match is found, Nginx will then try to find a server block with a that matches using a leading wildcard (indicated by a at the beginning of the name in the config). If one is found, that block will be used to serve the request. If multiple matches are found, the longest match will be used to serve the request.\n• If no match is found using a leading wildcard, Nginx then looks for a server block with a that matches using a trailing wildcard (indicated by a server name ending with a in the config). If one is found, that block is used to serve the request. If multiple matches are found, the longest match will be used to serve the request.\n• If no match is found using a trailing wildcard, Nginx then evaluates server blocks that define the using regular expressions (indicated by a before the name). The first with a regular expression that matches the “Host” header will be used to serve the request.\n• If no regular expression match is found, Nginx then selects the default server block for that IP address and port.\n\nEach IP address/port combo has a default server block that will be used when a course of action can not be determined with the above methods. For an IP address/port combo, this will either be the first block in the configuration or the block that contains the option as part of the directive (which would override the first-found algorithm). There can be only one declaration per each IP address/port combination.\n\nIf there is a defined that exactly matches the header value, that server block is selected to process the request.\n\nIn this example, if the header of the request was set to , the second server would be selected:\n\nIf no exact match is found, Nginx then checks to see if there is a with a starting wildcard that fits. The longest match beginning with a wildcard will be selected to fulfill the request.\n\nIn this example, if the request had a header of , the second server block would be selected:\n\nIf no match is found with a starting wildcard, Nginx will then see if a match exists using a wildcard at the end of the expression. At this point, the longest match ending with a wildcard will be selected to serve the request.\n\nFor instance, if the request has a header set to , the third server block will be selected:\n\nIf no wildcard matches can be found, Nginx will then move on to attempting to match directives that use regular expressions. The first matching regular expression will be selected to respond to the request.\n\nFor example, if the header of the request is set to , then the second server block will be selected to satisfy the request:\n\nIf none of the above steps are able to satisfy the request, then the request will be passed to the default server for the matching IP address and port.\n\nSimilar to the process that Nginx uses to select the server block that will process a request, Nginx also has an established algorithm for deciding which location block within the server to use for handling requests.\n\nBefore we cover how Nginx decides which location block to use to handle requests, let’s go over some of the syntax you might see in location block definitions. Location blocks live within server blocks (or other location blocks) and are used to decide how to process the request URI (the part of the request that comes after the domain name or IP address/port).\n\nLocation blocks generally take the following form:\n\nThe in the above defines what Nginx should check the request URI against. The existence or nonexistence of the modifier in the above example affects the way that the Nginx attempts to match the location block. The modifiers below will cause the associated location block to be interpreted as follows:\n• (none): If no modifiers are present, the location is interpreted as a prefix match. This means that the location given will be matched against the beginning of the request URI to determine a match.\n• : If an equal sign is used, this block will be considered a match if the request URI exactly matches the location given.\n• : If a tilde modifier is present, this location will be interpreted as a case-sensitive regular expression match.\n• : If a tilde and asterisk modifier is used, the location block will be interpreted as a case-insensitive regular expression match.\n• : If a carat and tilde modifier is present, and if this block is selected as the best non-regular expression match, regular expression matching will not take place.\n\nAs an example of prefix matching, the following location block may be selected to respond for request URIs that look like , , or :\n\nFor a demonstration of exact request URI matching, this block will always be used to respond to a request URI that looks like . It will not be used to respond to a request URI. Keep in mind that if this block is selected and the request is fulfilled using an index page, an internal redirect will take place to another location that will be the actual handler of the request:\n\nAs an example of a location that should be interpreted as a case-sensitive regular expression, this block could be used to handle requests for , but not for :\n\nA block that would allow for case-insensitive matching similar to the above is shown below. Here, both and could be handled by this block:\n\nFinally, this block would prevent regular expression matching from occurring if it is determined to be the best non-regular expression match. It could handle requests for :\n\nAs you see, the modifiers indicate how the location block should be interpreted. However, this does not tell us the algorithm that Nginx uses to decide which location block to send the request to. We will go over that next.\n\nHow Nginx Chooses Which Location to Use to Handle Requests\n\nNginx chooses the location that will be used to serve a request in a similar fashion to how it selects a server block. It runs through a process that determines the best location block for any given request. Understanding this process is a crucial requirement in being able to configure Nginx reliably and accurately.\n\nKeeping in mind the types of location declarations we described above, Nginx evaluates the possible location contexts by comparing the request URI to each of the locations. It does this using the following algorithm:\n• Nginx begins by checking all prefix-based location matches (all location types not involving a regular expression). It checks each location against the complete request URI.\n• First, Nginx looks for an exact match. If a location block using the modifier is found to match the request URI exactly, this location block is immediately selected to serve the request.\n• If no exact (with the modifier) location block matches are found, Nginx then moves on to evaluating non-exact prefixes. It discovers the longest matching prefix location for the given request URI, which it then evaluates as follows:\n• If the longest matching prefix location has the modifier, then Nginx will immediately end its search and select this location to serve the request.\n• If the longest matching prefix location does not use the modifier, the match is stored by Nginx for the moment so that the focus of the search can be shifted.\n• After the longest matching prefix location is determined and stored, Nginx moves on to evaluating the regular expression locations (both case sensitive and insensitive). If there are any regular expression locations within the longest matching prefix location, Nginx will move those to the top of its list of regex locations to check. Nginx then tries to match against the regular expression locations sequentially. The first regular expression location that matches the request URI is immediately selected to serve the request.\n• If no regular expression locations are found that match the request URI, the previously stored prefix location is selected to serve the request.\n\nIt is important to understand that, by default, Nginx will serve regular expression matches in preference to prefix matches. However, it evaluates prefix locations first, allowing for the administer to override this tendency by specifying locations using the and modifiers.\n\nIt is also important to note that, while prefix locations generally select based on the longest, most specific match, regular expression evaluation is stopped when the first matching location is found. This means that positioning within the configuration has vast implications for regular expression locations.\n\nFinally, it it is important to understand that regular expression matches within the longest prefix match will “jump the line” when Nginx evaluates regex locations. These will be evaluated, in order, before any of the other regular expression matches are considered. Maxim Dounin, an incredibly helpful Nginx developer, explains in this post this portion of the selection algorithm.\n\nWhen Does Location Block Evaluation Jump to Other Locations?\n\nGenerally speaking, when a location block is selected to serve a request, the request is handled entirely within that context from that point onward. Only the selected location and the inherited directives determine how the request is processed, without interference from sibling location blocks.\n\nAlthough this is a general rule that will allow you to design your location blocks in a predictable way, it is important to realize that there are times when a new location search is triggered by certain directives within the selected location. The exceptions to the “only one location block” rule may have implications on how the request is actually served and may not align with the expectations you had when designing your location blocks.\n\nSome directives that can lead to this type of internal redirect are:\n\nLet’s go over these briefly.\n\nThe directive always leads to an internal redirect if it is used to handle the request. Exact location matches are often used to speed up the selection process by immediately ending the execution of the algorithm. However, if you make an exact location match that is a directory, there is a good chance that the request will be redirected to a different location for actual processing.\n\nIn this example, the first location is matched by a request URI of , but in order to handle the request, the directive inherited by the block initiates an internal redirect to the second block:\n\nIn the case above, if you really need the execution to stay in the first block, you will have to come up with a different method of satisfying the request to the directory. For instance, you could set an invalid for that block and turn on :\n\nThis is one way of preventing an from switching contexts, but it’s probably not useful for most configurations. Mostly an exact match on directories can be helpful for things like rewriting the request (which also results in a new location search).\n\nAnother instance where the processing location may be reevaluated is with the directive. This directive tells Nginx to check for the existence of a named set of files or directories. The last parameter can be a URI that Nginx will make an internal redirect to.\n\nConsider the following configuration:\n\nIn the above example, if a request is made for , the first location will initially get the request. It will try to find a file called in directory. If it cannot find one, it will follow up by searching for a file called . It will then try to see if there is a directory called within the directory. Failing all of these attempts, it will redirect to . This will trigger another location search that will be caught by the second location block. This will serve the file .\n\nAnother directive that can lead to a location block pass off is the directive. When using the parameter with the directive, or when using no parameter at all, Nginx will search for a new matching location based on the results of the rewrite.\n\nFor example, if we modify the last example to include a rewrite, we can see that the request is sometimes passed directly to the second location without relying on the directive:\n\nIn the above example, a request for will be handled initially by the first location block. It will be rewritten to and a location will be searched. In this case, it will match the first location again and be processed by the as usual, maybe kicking back to if nothing is found (using the internal redirect we discussed above).\n\nHowever, if a request is made for , the first block again will match. The rewrite be applied again, this time resulting in . The request will then be served out of the second location block.\n\nA related situation happens with the directive when sending the or status codes. The difference in this case is that it results in an entirely new request in the form of an externally visible redirect. This same situation can occur with the directive when using the or flags. However, these location searches shouldn’t be unexpected, since externally visible redirects always result in a new request.\n\nThe directive can lead to an internal redirect similar to that created by . This directive is used to define what should happen when certain status codes are encountered. This will likely never be executed if is set, since that directive handles the entire life cycle of a request.\n\nConsider this example:\n\nEvery request (other than those starting with ) will be handled by the first block, which will serve files out of . However, if a file is not found (a 404 status), an internal redirect to will occur, leading to a new location search that will eventually land on the second block. This file will be served out of .\n\nAs you can see, understanding the circumstances in which Nginx triggers a new location search can help to predict the behavior you will see when making requests.\n\nUnderstanding the ways that Nginx processes client requests can make your job as an administrator much easier. You will be able to know which server block Nginx will select based on each client request. You will also be able to tell how the location block will be selected based on the request URI. Overall, knowing the way that Nginx selects different blocks will give you the ability to trace the contexts that Nginx will apply in order to serve each request."
    },
    {
        "link": "https://docs.nginx.com/nginx/admin-guide/web-server/web-server",
        "document": "Configuring NGINX and NGINX Plus as a Web Server\n\nThis article explains how to configure NGINX Open Source and F5 NGINX Plus as a web server.\n\nNote: The information in this article applies to both NGINX Open Source and NGINX Plus. For ease of reading, the remainder of the article refers to NGINX Plus only.\n\nAt a high level, configuring NGINX Plus as a web server is a matter of defining which URLs it handles and how it processes HTTP requests for resources at those URLs. At a lower level, the configuration defines a set of virtual servers that control the processing of requests for particular domains or IP addresses. For more information about configuration files, refer to Creating NGINX and NGINX Plus Configuration Files.\n\nEach virtual server for HTTP traffic defines special configuration instances called locations that control processing of specific sets of URIs. Each location defines its own scenario of what happens to requests that are mapped to this location. NGINX Plus provides full control over this process. Each location can proxy the request or return a file. In addition, the URI can be modified, so that the request is redirected to another location or virtual server. Also, a specific error code can be returned and you can configure a specific page to correspond to each error code.\n\nThe NGINX Plus configuration file must include at least one server directive to define a virtual server. When NGINX Plus processes a request, it first selects the virtual server that will serve the request.\n\nA virtual server is defined by a directive in the context, for example:\n\nIt is possible to add multiple directives into the context to define multiple virtual servers.\n\nThe configuration block usually includes a listen directive to specify the IP address and port (or Unix domain socket and path) on which the server listens for requests. Both IPv4 and IPv6 addresses are accepted; enclose IPv6 addresses in square brackets.\n\nThe example below shows configuration of a server that listens on IP address 127.0.0.1 and port 8080:\n\nIf a port is omitted, the standard port is used. Likewise, if an address is omitted, the server listens on all addresses. If the directive is not included at all, the “standard” port is and the “default” port is , depending on superuser privileges.\n\nIf there are several servers that match the IP address and port of the request, NGINX Plus tests the request’s header field against the server_name directives in the blocks. The parameter to can be a full (exact) name, a wildcard, or a regular expression. A wildcard is a character string that includes the asterisk ( ) at its beginning, end, or both; the asterisk matches any sequence of characters. NGINX Plus uses the Perl syntax for regular expressions; precede them with the tilde ( ). This example illustrates an exact name.\n\nIf several names match the header, NGINX Plus selects one by searching for names in the following order and using the first match it finds:\n• Longest wildcard starting with an asterisk, such as\n• Longest wildcard ending with an asterisk, such as\n• First matching regular expression (in order of appearance in the configuration file)\n\nIf the header field does not match a server name, NGINX Plus routes the request to the default server for the port on which the request arrived. The default server is the first one listed in the nginx.conf file, unless you include the parameter to the directive to explicitly designate a server as the default.\n\nNGINX Plus can send traffic to different proxies or serve different files based on the request URIs. These blocks are defined using the location directive placed within a directive.\n\nFor example, you can define three blocks to instruct the virtual server to send some requests to one proxied server, send other requests to a different proxied server, and serve the rest of the requests by delivering files from the local file system.\n\nNGINX Plus tests request URIs against the parameters of all directives and applies the directives defined in the matching location. Inside each block, it is usually possible (with a few exceptions) to place even more directives to further refine the processing for specific groups of requests.\n\nNote: In this guide, the word location refers to a single location context.\n\nThere are two types of parameter to the directive: prefix strings (pathnames) and regular expressions. For a request URI to match a prefix string, it must start with the prefix string.\n\nThe following sample location with a pathname parameter matches request URIs that begin with /some/path/, such as /some/path/document.html. (It does not match /my-site/some/path because /some/path does not occur at the start of that URI.)\n\nA regular expression is preceded with the tilde ( ) for case-sensitive matching, or the tilde-asterisk ( ) for case-insensitive matching. The following example matches URIs that include the string .html or .htm in any position.\n\nTo find the location that best matches a URI, NGINX Plus first compares the URI to the locations with a prefix string. It then searches the locations with a regular expression.\n\nHigher priority is given to regular expressions, unless the modifier is used. Among the prefix strings NGINX Plus selects the most specific one (that is, the longest and most complete string). The exact logic for selecting a location to process a request is given below:\n• Test the URI against all prefix strings.\n• The (equals sign) modifier defines an exact match of the URI and a prefix string. If the exact match is found, the search stops.\n• If the (caret-tilde) modifier prepends the longest matching prefix string, the regular expressions are not checked.\n• Stop processing when the first matching regular expression is found and use the corresponding location.\n• If no regular expression matches, use the location corresponding to the stored prefix string.\n\nA typical use case for the modifier is requests for / (forward slash). If requests for / are frequent, specifying as the parameter to the directive speeds up processing, because the search for matches stops after the first comparison.\n\nA context can contain directives that define how to resolve a request – either serve a static file or pass the request to a proxied server. In the following example, requests that match the first context are served files from the /data directory and the requests that match the second are passed to the proxied server that hosts content for the <www.example.com> domain.\n\nThe root directive specifies the file system path in which to search for the static files to serve. The request URI associated with the location is appended to the path to obtain the full name of the static file to serve. In the example above, in response to a request for /images/example.png, NGINX Plus delivers the file /data/images/example.png.\n\nThe proxy_pass directive passes the request to the proxied server accessed with the configured URL. The response from the proxied server is then passed back to the client. In the example above, all requests with URIs that do not start with /images/ are be passed to the proxied server.\n\nYou can use variables in the configuration file to have NGINX Plus process requests differently depending on defined circumstances. Variables are named values that are calculated at runtime and are used as parameters to directives. A variable is denoted by the (dollar) sign at the beginning of its name. Variables define information based upon NGINX’s state, such as the properties of the request being currently processed.\n\nThere are a number of predefined variables, such as the core HTTP variables, and you can define custom variables using the set, map, and geo directives. Most variables are computed at runtime and contain information related to a specific request. For example, contains the client IP address and holds the current URI value.\n\nSome website URIs require immediate return of a response with a specific error or redirect code, for example when a page has been moved temporarily or permanently. The easiest way to do this is to use the return directive. For example:\n\nThe first parameter of is a response code. The optional second parameter can be the URL of a redirect (for codes , , , and ) or the text to return in the response body. For example:\n\nThe directive can be included in both the and contexts.\n\nA request URI can be modified multiple times during request processing through the use of the rewrite directive, which has one optional and two required parameters. The first (required) parameter is the regular expression that the request URI must match. The second parameter is the URI to substitute for the matching URI. The optional third parameter is a flag that can halt processing of further directives or send a redirect (code or ). For example:\n\nAs this example shows, the second parameter captures though matching of regular expressions.\n\nYou can include multiple directives in both the and contexts. NGINX Plus executes the directives one-by-one in the order they occur. The directives in a context are executed once when that context is selected.\n\nAfter NGINX processes a set of rewriting instructions, it selects a context according to the new URI. If the selected location contains directives, they are executed in turn. If the URI matches any of those, a search for the new location starts after all defined directives are processed.\n\nThe following example shows directives in combination with a directive.\n\nThis example configuration distinguishes between two sets of URIs. URIs such as /download/some/media/file are changed to /download/some/mp3/file.mp3. Because of the flag, the subsequent directives (the second and the directive) are skipped but NGINX Plus continues processing the request, which now has a different URI. Similarly, URIs such as /download/some/audio/file are replaced with /download/some/mp3/file.ra. If a URI doesn’t match either directive, NGINX Plus returns the error code to the client.\n\nThere are two parameters that interrupt processing of directives:\n• – Stops execution of the directives in the current or context, but NGINX Plus searches for locations that match the rewritten URI, and any directives in the new location are applied (meaning the URI can be changed again).\n• – Like the break directive, stops processing of directives in the current context and cancels the search for locations that match the new URI. The directives in the new location are not executed.\n\nSometimes you need to rewrite or change the content in an HTTP response, substituting one string for another. You can use the sub_filter directive to define the rewrite to apply. The directive supports variables and chains of substitutions, making more complex changes possible.\n\nFor example, you can change absolute links that refer to a server other than the proxy:\n\nAnother example changes the scheme from to and replaces the address with the hostname from the request header field. The sub_filter_once directive tells NGINX to apply sub_filter directives consecutively within a location:\n\nNote that the part of the response already modified with the is not replaced again if another match occurs.\n\nWith the error_page directive, you can configure NGINX Plus to return a custom page along with an error code, substitute a different error code in the response, or redirect the browser to a different URI. In the following example, the directive specifies the page (/404.html) to return with the error code.\n\nNote that this directive does not mean that the error is returned immediately (the directive does that), but simply specifies how to treat errors when they occur. The error code can come from a proxied server or occur during processing by NGINX Plus (for example, the results when NGINX Plus can’t find the file requested by the client).\n\nIn the following example, when NGINX Plus cannot find a page, it substitutes code for code , and redirects the client to http:/example.com/new/path.html. This configuration is useful when clients are still trying to access a page at its old URI. The code informs the browser that the page has moved permanently, and it needs to replace the old address with the new one automatically upon return.\n\nThe following configuration is an example of passing a request to the back end when a file is not found. Because there is no status code specified after the equals sign in the directive, the response to the client has the status code returned by the proxied server (not necessarily ).\n\nThe directive instructs NGINX Plus to make an internal redirect when a file is not found. The variable in the final parameter to the directive holds the URI of the current request, which gets passed in the redirect.\n\nFor example, if /images/some/file is not found, it is replaced with /fetch/images/some/file and a new search for a location starts. As a result, the request ends up in the second context and is proxied to “http://backend/”.\n\nThe open_file_cache_errors directive prevents writing an error message if a file is not found. This is not necessary here since missing files are correctly handled."
    }
]