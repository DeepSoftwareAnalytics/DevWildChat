[
    {
        "link": "https://registry.terraform.io/providers/digitalocean/digitalocean/latest/docs/resources/firewall",
        "document": "Please enable Javascript to use this application"
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-deploy-load-balanced-web-applications-on-digitalocean-with-cdk-for-terraform-and-typescript",
        "document": "The author selected the Wikimedia Foundation to receive a donation as part of the Write for DOnations program.\n\nInfrastructure as Code (IaC) is a practice of automating infrastructure deployment and modifications by defining the resource states and their relationships in code. Executing that code then creates or modifies the actual resources in the cloud. IaC allows engineers to use an IaC tool like Terraform (by HashiCorp) for provisioning infrastructure.\n\nWith IaC, changes to your infrastructure can go through the same code review process as your application code. You can store the code in version control (like Git) to keep a history of the state of your infrastructure, and you can automate the deployment process further with higher-level tools such as a self-service internal developer platform (IDP).\n\nTerraform is a popular platform-agnostic IaC tool due to its broad support for many platforms, including GitHub, Cloudflare, and DigitalOcean. Most Terraform configurations are written using a declarative language called the HashiCorp Configuration Language (HCL).\n\nThe Cloud Development Kit for Terraform (CDKTF) is a tool built on top of Terraform that allows you to define infrastructure using a familiar programming language (such as TypeScript, Python, or Go) instead of HCL. This tool can provide a shallower learning curve for developers unfamiliar with HCL, while allowing developers to use native programming features like loops, variables, and functions.\n\nIn this tutorial, you will start by installing the command-line interface (CLI) tool. Then, you will author a CDKTF project in TypeScript and define the project with two NGINX servers that are load-balanced by a load balancer. You will then use to deploy the infrastructure. At the end of this tutorial, you will have a CDKTF project from which you can build to expand your infrastructure.\n\nTo complete this tutorial, you will need:\n• A good understanding of Infrastructure-as-Code (IaC). You can learn about IaC in Infrastructure as Code Explained.\n• A DigitalOcean account. If you do not have one, sign up for a new account.\n• A DigitalOcean Personal Access Token, which you can create via the DigitalOcean console. Instructions on how to do that can be found at How to Generate a Personal Access Token.\n• A password-less SSH key added to your DigitalOcean account. You can add that by following How To Use SSH Keys with DigitalOcean Droplets. When you add the key to your account, remember the name you give it, as you will need it in this tutorial. For CDKTF to accept the name of your key, it must start with a letter or underscore and may contain only letters, digits, underscores, and dashes.\n• Terraform installed on your local machine, which you can set up with “Step 1 - Installing Terraform” in How To Use Terraform with DigitalOcean.\n• Node.js installed on your local machine. You can find instructions for this in the How to Install Node.js and Create a Local Development Environment series.\n• To be comfortable programming with JavaScript. To build your skills, check out the How To Code in JavaScript series.\n• To be comfortable using the basic features of TypeScript. If you are not comfortable with TypeScript, the How To Code in TypeScript tutorial series is a good resource to get you up to speed.\n• A code editor or integrated development environment (IDE) that supports TypeScript. If you are not currently using one, try Visual Studio Code. You can also read up on How To Work With TypeScript in Visual Studio Code.\n\nTo begin, you will install the command-line tool.\n\nThe CLI is available as an NPM package. If you search for on npmjs.com, you will find two similarly-named packages: and .\n\nConceptually, CDKTF is an abstraction layer on top of Terraform. It consists of two parts:\n• a library containing a set of language-native constructs (such as functions and classes) for defining infrastructure. This part is encapsulated within the npm package. For example, you can see the use of the and classes from the package in the following sample CDKTF project:\n• an adapter that parses the constructs within the CDKTF project and reduces them to a set of JSON documents, which are then ingested into Terraform in the same way HCL is ingested. This adaptor is encapsulated into a CLI tool called , provided by the package.\n\nTo install the CLI tool, you need the package. You can install this package globally using , , or a package manager of your choosing.\n\nTo install with , run the following:\n\nAlternatively, you can use Homebrew on macOS or Linux to install the CLI as the formula:\n\nTo verify the installation is successful, run the command with no arguments:\n\nYou will see output similar to the following:\n\nThe output shows you the available commands. In the rest of this tutorial, you will gain experience using , , , and .\n\nNow that you have installed the CLI, you can define infrastructure by writing some TypeScript code.\n\nIn this step, you will use the CLI you just installed to create a boilerplate CDKTF project, which you will build on in subsequent steps.\n\nCreate a directory that will house the CDKTF project by running the following command:\n\nThen, navigate into the newly-created directory:\n\nUse the command to create a CDKTF project scaffold that you will build on:\n\nCDKTF allows developers to define infrastructure using TypeScript, Python, Java, C#, or Go. The option tells to scaffold this CDKTF project using TypeScript.\n\nTerraform (and thus CDKTF) keeps track of the resources it is managing by recording their definitions and states in files called Terraform state files. The option tells CDKTF to keep these state files locally on the machine running (each file follows the naming structure ).\n\nAfter running the command, the CLI may ask you for permission to send crash reports to the CDKTF team to help them improve the product:\n\nType if you’d like to consent or if you disagree, then press .\n\nwill then create the project scaffold and install the packages. When the project is scaffolded, you will see an output similar to the following:\n\nYou will also see some new files added to the directory. The most important files are and .\n\nis the configuration file for the CDKTF project. If you open the file, it will display something like the following:\n\nThe property defines the command that will be run to synthesize the TypeScript code to Terraform-compatible JSON. This property indicates that is the entry point to the CDKTF project.\n\nIf you open the file, you will see something similar to the following:\n\nIn the language of CDKTF, a collection of related infrastructure resources can be grouped into a stack. For example, the resources making up an API application, such as Droplets, load balancers, and DNS records, can be grouped into a single stack named . Each stack keeps its own state and can be deployed, modified, or destroyed independently from other stacks. A common use of stacks is to have one stack for production and a separate stack for development.\n\nAn application is a container for multiple stacks. For example, an application can group the stacks of various microservices.\n\nThe CDKTF project scaffold generated in contains a single stack class called , currently defining no resources. An instance of is created with the name , contained within an application called . In subsequent steps, you will define infrastructure resources within the constructor.\n\nAfter creating the project, the next step is configuring the CDKTF project with providers.\n\nIn this step, you will install the DigitalOcean Provider into the CDKTF project.\n\nProviders are libraries that provide instructions to Terraform (which is used by under the hood) on how to create, update, and delete resources on cloud providers, SaaS providers, and other platforms exposing application programming interfaces (APIs). Providers encapsulate the logic of calling these upstream APIs into standard functions that Terraform can call.\n\nFor example, if you were to create a new DigitalOcean Droplet without Terraform, you’d have to send a request to the endpoint of the DigitalOcean API. With Terraform, you would instead install the DigitalOcean provider and define a resource, similar to the following sample snippet:\n\nYou can then use the CLI tool to translate this TypeScript code into Terraform-compatible JSON and pass it to the provider, who will make the appropriate API calls to create the Droplet on your behalf.\n\nNow that you understand what a provider is, you can set up the DigitalOcean provider for your CDKTF project.\n\nOpen the file and add the string to the array:\n\nis the identifier for the DigitalOcean provider on the Terraform Registry.\n\nNext, run to download and install the provider.\n\nwill download the provider, extract the schema, generate the corresponding TypeScript classes, and add it as a TypeScript module under . This auto-code generation enables you to use any Terraform providers and HCL modules with CDKTF, and it is how CDKTF can provide code completion in editors that support it.\n\nOnce finishes running, you will see output similar to the following:\n\nYou will also see a new directory called containing the generated code of the provider.\n\nIn this step, you installed the provider into the project. In the next step, you will configure the DigitalOcean provider with the credentials required to authenticate the provider with the DigitalOcean API.\n\nIn this step, you will configure the DigitalOcean provider with your DigitalOcean Personal Access Token, which allows the provider to call the DigitalOcean API on your behalf.\n\nDifferent providers require and support different credentials for authenticating with the upstream API. For the DigitalOcean provider, you need to provide your DigitalOcean Personal Access Token. You can specify the token to the provider by setting it as the or environment variables.\n\nRun the following command in your terminal to set the environment variable for that terminal session.\n\nNext, you will specify the provider within the class, which will allow you to define resources provided by the provider within your stack. Update the file to the following:\n\nThe module for the provider is located at , which was automatically generated when you ran .\n\nYou configured the provider with credentials in this step. Next, you will start defining the infrastructure that forms part of the goal of this tutorial.\n\nIn this step, you will define two NGINX servers, each serving different files, deployed on two identical Ubuntu 20.04 Droplets.\n\nYou start with the definition of the two Droplets. Modify with the highlighted changes:\n\nYou use a JavaScript-native loop ( ) to avoid duplication in the code.\n\nJust as if you were creating the Droplet through the console, there are several parameters to specify:\n• - the Linux distribution and version your Droplet will run.\n• - the data center the Droplet will run in.\n• - the amount of CPU and memory resources to reserve to the Droplet.\n• - a unique name used to refer to the Droplet.\n\nThe values for , , and must be things that DigitalOcean supports. You can find the valid values (called slugs) for all supported Linux distribution images, Droplet sizes, and regions on the DigitalOcean API Slugs page. You can find a complete list of required and optional attributes on the documentation page.\n\nAs part of the prerequisites, you uploaded a password-less SSH public key to your DigitalOcean account and noted its name. You will now use that name to retrieve the SSH key’s ID and pass it into the definition of your Droplet.\n\nSince the SSH key was manually added to your DigitalOcean account, it is not a resource managed by your current Terraform configuration. If you tried to define a new resource, it will create a new SSH key instead of using the existing one.\n\nInstead, you will define a new data source. In Terraform, data sources are used to retrieve information about infrastructure that are not managed by the current Terraform configuration. In other words, they provide a read-only view into the state of pre-existing, external infrastructure. Once a data source is defined, you can use the data elsewhere in your Terraform configuration.\n\nStill in and within the constructor of , define a new data source, and pass in the name you assigned to your SSH key (here, the name is ):\n\nThen, update the Droplet’s definition to include the SSH key:\n\nWhen provisioned, you can access the Droplet using a private SSH key instead of a password.\n\nYou have now defined two identical Droplets running Ubuntu, configured with SSH access. The next task is to install NGINX on each Droplet.\n\nWhen a Droplet is being created, a tool called CloudInit will bootstrap the server. CloudInit can accept a file called user data, which can modify how the server is bootstrapped. The user data can be any files or scripts the server can interpret, such as Bash scripts.\n\nIn the remainder of this step, you will create a Bash script and specify it as the Droplet’s user data. The script will install NGINX as part of the bootstrapping process. In addition, the script will also replace the contents of the file (the default file served by NGINX) with the hostname and IP address of the Droplet, which will cause the two NGINX servers to serve different files. In the next step, you will put both of these NGINX servers behind a load balancer; by serving different files, it will make it apparent whether the load balancer is distributing requests correctly or not.\n\nStill in , add a new property to the Droplet’s configuration object:\n\nWhen the Droplet is first provisioned, the script will be run as the user. It will use Ubuntu’s package manager, APT, to install the package. It will then use DigitalOcean’s Metadata Service to retrieve information about itself, and write the hostname and IP address into , which is served by NGINX.\n\nIn this step, you defined the two Droplets running Ubuntu, configured each one with SSH access, and installed NGINX using the user data feature. In the next step, you will define a load balancer that will sit in front of these NGINX servers and configure it to load balance in a round-robin fashion.\n\nIn this step, you will define a DigitalOcean Load Balancer by defining an instance of the resource.\n\nStill in , add the following definition for a load balancer at the end of the constructor:\n\nThe argument tells the load balancer to listen for HTTP requests on port and forward them to each of the Droplets on port .\n\nThe specify the Droplets to which the load balancer will pass requests. It takes a number, but the value of is a string. Therefore, you have used the Terraform function to convert the string Droplet ID value to a number.\n\nYou have now defined two Droplets and a load balancer that sits in front of them. Your should look similar to this:\n\nIn the next step, you will use the CLI tool to actualize your entire CDKTF project.\n\nIn this step, you will use the CLI tool to provision the Droplets and load balancers you defined in the previous steps.\n\nMake sure that you are in the directory and have set the environment variable for your terminal session, then run the command:\n\nYou should see output similar to the following:\n\nThis display lists all the resources and properties that plans to create, update, and destroy. Some values, such as a Droplet’s ID, are only known after the resource is provisioned. For those, you will see as the property value in the output.\n\nReview the list of resources to make sure it is what you expect. Then, use the arrow keys to select the Approve option and press .\n\nYou will see an output similar to the following:\n\nThis output tells you that is communicating with the DigitalOcean API to create the Droplet. is creating the Droplets first because the load balancer depends on the Droplet’s ID, which is unknown until the Droplets are provisioned.\n\nDroplet creation usually takes less than a minute. Once the Droplets are provisioned, moves on to creating the load balancer.\n\nThe load balancer may take longer. After the load balancer is created, you will see a summary that shows the stack has been deployed successfully.\n\nYou can now visit the DigitalOcean console, where you can see one load balancer named and two healthy Droplets named and , each serving as a target for the load balancer.\n\nYou can test that NGINX is running and serving content correctly by visiting the IP address of each Droplet. You should see text similar to the following:\n\nIf you don’t see that string of text or the server is not responding, check that the user data you specified is correct and that no characters (including new lines) preceed the shebang ( ). You can also SSH into the Droplet using your SSH private key and review the output logs generated by CloudInit at :\n\nOnce you have confirmed the Droplets are up and serving content, you can begin testing the load balancer. You do this by sending a few requests.\n\nRun the following command from your terminal to send ten requests to the load balancer:\n\nYou should see output similar to the following, although the IP addresses shown will be different:\n\nIt shows that requests to the load balancer were forwarded to each Droplet five times, indicating that the load balancer is working.\n\nIn this step, you used to provision your resources, and then you used the DigitalOcean console to discover the IP addresses of your Droplets and load balancer. You then sent requests to each Droplet and load balancer to confirm they work.\n\nIn the next step, you will obtain the IP addresses of the Droplets and load balancer without logging into the DigitalOcean console.\n\nIn the previous step, you had to log in to the DigitalOcean Console to obtain the IP addresses of your Droplet and load balancer. In this step, you will modify your code slightly so that this information is printed in the output of the command, saving you a trip to the console.\n\nTerraform records the configuration and state of its managed resources in state files. For your stack, the state file can be found at . You will be able to find the IP addresses of the Droplets and load balancer inside this state file.\n\nHowever, sorting through a large file can be inconvenient. CDKTF provides the construct, which you can use to output variables and make them available outside of the stack. Any outputs are printed in after is run. Running can also print outputs at any time.\n\nUpdate the file to include outputs of the IP addresses of the load balancer and Droplets:\n\nWithin the output, you should see something similar to the following:\n\nThis output tells you that no infrastructure changes will be made, only what is output from the stack.\n\nUse the arrow keys to select Approve, and then press . At the end of the terminal output, you should see something similar to:\n\nNow, each time you run or , the IP address of the Droplets and the load balancers are printed in the terminal output, removing the need to access that information from the DigitalOcean console.\n\nYou have now provisioned two Droplets and a load balancer and confirmed they are working. You can use the CDKTF project you have developed as a base to define more sophisticated infrastructure (you can find a reference implementation at ).\n\nThe resources provisioned in this tutorial will incur a charge. If you do not intend to use the infrastructure created, you should destroy it. In the next and final step, you will clean up the project by destroying the resources created in this tutorial.\n\nIn this step, you will remove all the resources created in this tutorial.\n\nStill within the directory, run :\n\nYou should see output similar to the following:\n\nThis time, instead of showing next to each resource, it shows , indicating CDKTF plans to destroy the resource. Review the changes proposed, then use the arrow keys to select Approve and press . The DigitalOcean provider will now communicate with the DigitalOcean API to destroy the resources.\n\nThe load balancer was deleted first because it has no dependencies (no other resources reference the load balancer in their inputs). Because the load balancer references the Droplets, they can only be destroyed after the load balancer is destroyed.\n\nAfter the resources have been destroyed, you will see the following line printed in the output:\n\nIn this tutorial, you used CDKTF to provision and destroy a load-balanced web page, consisting of two DigitalOcean Droplets running NGINX servers, served behind a load balancer. You also output information about the resources on the terminal.\n\nCDKTF is an abstraction layer above Terraform. A good understanding of Terraform is helpful in understanding CDKTF. If you’d like to learn more about Terraform, you can read the How To Manage Infrastructure with Terraform series, which covers Terraform in depth.\n\nYou can also check out the official CDK for Terraform documentation and tutorials to learn more about CDKTF."
    },
    {
        "link": "https://docs.digitalocean.com/reference/terraform/reference/resources/firewall",
        "document": "Provides a DigitalOcean Cloud Firewall resource. This can be used to create, modify, and delete Firewalls.\n\nThe following arguments are supported:\n• (Optional) - The list of the IDs of the Droplets assigned to the Firewall (max. 10). If you want to assign more droplets to the Firewall, add Tags to them and use the argument below.\n• (Optional) - The names of the Tags assigned to the Firewall (max. 5).\n• - (Optional) The inbound access rule block for the Firewall. The block is documented below.\n• - (Optional) The outbound access rule block for the Firewall. The block is documented below.\n• - (Required) The type of traffic to be allowed. This may be one of “tcp”, “udp”, or “icmp”.\n• - (Optional) The ports on which traffic will be allowed specified as a string containing a single port, a range (e.g. “8000-9000”), or “1-65535” to open all ports for a protocol. Required for when protocol is or .\n• - (Optional) An array of strings containing the IPv4 addresses, IPv6 addresses, IPv4 CIDRs, and/or IPv6 CIDRs from which the inbound traffic will be accepted.\n• - (Optional) An array containing the IDs of the Droplets from which the inbound traffic will be accepted.\n• - (Optional) An array containing the names of Tags corresponding to groups of Droplets from which the inbound traffic will be accepted.\n• - (Optional) An array containing the IDs of the Load Balancers from which the inbound traffic will be accepted.\n• - (Optional) An array containing the IDs of the Kubernetes clusters from which the inbound traffic will be accepted.\n• - (Required) The type of traffic to be allowed. This may be one of “tcp”, “udp”, or “icmp”.\n• - (Optional) The ports on which traffic will be allowed specified as a string containing a single port, a range (e.g. “8000-9000”), or “1-65535” to open all ports for a protocol. Required for when protocol is or .\n• - (Optional) An array of strings containing the IPv4 addresses, IPv6 addresses, IPv4 CIDRs, and/or IPv6 CIDRs to which the outbound traffic will be allowed.\n• - (Optional) An array containing the IDs of the Droplets to which the outbound traffic will be allowed.\n• - (Optional) An array containing the IDs of the Kubernetes clusters to which the outbound traffic will be allowed.\n• - (Optional) An array containing the names of Tags corresponding to groups of Droplets to which the outbound traffic will be allowed.\n• - (Optional) An array containing the IDs of the Load Balancers to which the outbound traffic will be allowed.\n\nThe following attributes are exported:\n• - A unique ID that can be used to identify and reference a Firewall.\n• - A status string indicating the current state of the Firewall. This can be “waiting”, “succeeded”, or “failed”.\n• - A time value given in ISO8601 combined date and time format that represents when the Firewall was created.\n• - An list of object containing the fields, “droplet_id”, “removing”, and “status”. It is provided to detail exactly which Droplets are having their security policies updated. When empty, all changes have been successfully applied.\n• - The name of the Firewall.\n• - The list of the IDs of the Droplets assigned to the Firewall.\n• - The names of the Tags assigned to the Firewall.\n• - The inbound access rule block for the Firewall.\n• - The outbound access rule block for the Firewall.\n\nFirewalls can be imported using the firewall , e.g."
    },
    {
        "link": "https://github.com/digitalocean/terraform-provider-digitalocean/issues/1162",
        "document": "I have created the following digitalocean terraform config for a firewall to allow all traffic over http/https, ssh etc.\n\n I was asked by Digital Ocean to add a firewall as after a port scan they closed the port that my Redis instance was running on as they mentioned this is a security risk.\n\nThis is my configuration -\n\nThis is the droplet\n\nThis is the firewall\n\nI have a docker-compose stack that runs inside the droplet, it works until i add the firewall.\n\n one of the containers in the stack is an nginx image, with the following config -\n\nAfter adding this firewall & i try to see the website in a browser with for example - http://www.nottoboard.com/\n\n Please note: I have currently turned the firewall off for this website until i can resolve this issue, so if you check this url it will seem like it works.\n\nWith the firewal turned on I get a .\n\nThe website should be available over port 80 so that i can access the website from a browser."
    },
    {
        "link": "https://developer.hashicorp.com/terraform/cdktf/concepts/resources",
        "document": "Resources are the most important element when defining infrastructure in CDKTF applications. Each resource describes one or more infrastructure objects, such as virtual networks, compute instances, or higher-level components such as DNS records.\n\nIn your CDK for Terraform (CDKTF) application, you will use your preferred programming language to define the resources you want Terraform to manage on one or more providers. This page explains how to use resources in your application and how to use escape hatches to change resource behavior when necessary.\n\nResource definitions and properties vary depending on the type of resource and the provider. Consult your provider's documentation for a full list of available resources and their configuration options.\n\nThe following example defines a DynamoDB table resource on the AWS provider.\n\nThe examples page contains multiple example projects for every supported programming language.\n\nYou can instantiate the same resource multiple times throughout your infrastructure. For example, you may want to create multiple S3 Buckets with different configurations. Instances that share the same parent element are considered to be part of the same scope. You must set a different property for each instance to avoid naming conflicts.\n\nRefer to the constructs documentation for more details and an example.\n\nYou can reference resource properties throughout your configuration. For example, you may want to use the name of a parent resource when assigning names to related child resources. Refer to your provider's documentation for a full list of available properties for each resource type.\n\nTo create references, call on the resource instance. For example, you could use to retrieve the property from . Terraform does not support passing an entire block (e.g. ) into a resource or data source, so you must create a reference for each individual property.\n\nReferences are also useful when you need to track logical dependencies. For example, Kubernetes resources live in a namespace, so a namespace must exist before Terraform can provision the associated resources. The following example uses a reference for the namespace property in the the deployment. This reference tells Terraform that it needs to create the namespace before creating the resources.\n\nWhen working with your infrastructure definitions and the need arises to refactor or rename resources without destroying and recreating them, you can leverage the function like so:\n\nRefer to our Refactoring Guide for more information\n\nProvisioners can be used to model specific actions on the local machine or on a remote machine in order to prepare servers or other infrastructure objects for service. You can find more information on the concept of provisioners in the Terraform docs. You can pass the key to define a list of provisioners, connections can be configured with the key. A working example can be found at examples/typescript/provisioner.\n\nIf you need to use the special object that can only be used in and blocks to refer to the parent resource you can use the class like this: .\n\nIf you need to ensure a condition is met either before or after a resource was created you can specify conditions. To add one configure the key on your resource with an object containing a and / or a . These keys take a list of conditions with a key containing a Terraform Expression to be evaluated and an key containing a string to be displayed if the condition is not met.\n\nIf you have existing resources that you want to manage with CDKTF, you can import them into your CDKTF application. The best way to do this is using the block feature of Terraform >= 1.5. You can do this in CDKTF either with a specified configuration or without.\n\nTo import a resource, first instantiate an instance of the resource type you wish to import – in our case we'll be using an S3Bucket. No configuration is explicitly needed. You then call the method on the resource object. This method takes the ID of the resource to be imported as the first argument and the provider as an optional second. The provider is only required if you have multiple providers of the same type in your configuration.\n\nWhen running plan / apply you will get the information that your resource is going to be imported. Once you have ran apply, you can remove the call and the resource will become managed by CDKTF.\n\nPlease note that Terraform is going to update existing fields on the imported resource to match your configuration as it puts it under management. In our case we did not define any specific properties on the which causes Terraform e.g. to remove the tags currently defined on the resource (as can be seen on the plan below). If you want to keep existing settings, you can run a plan first, add everything that Terraform would change to your resource config, and only then apply the changes.\n\nYour output might look as follows:\n\nIf you don't want to specify the configuration of your imported resource yourself you can use the static method on the class of the resource you want to import. This method takes the scope as the first argument, the construct id of the resource to import to (as will be given in the generated config returned), the resource id of the resource to be imported, and the provider as an optional fourth. The provider is only required if you have multiple providers of the same type in your configuration.\n\nWhen running Terraform will generate code for the resource you are importing and CDKTF will convert it to the language you are using.\n\nYour output might look as follows:\n\n- Reusing previous version of hashicorp/aws from the dependency lock file You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. ts-import-with-configuration Terraform will perform the following actions: Plan: 1 to import, 0 to add, 0 to change, 0 to destroy. │ Generating configuration during import is currently experimental, and the Terraform has generated configuration and written it to generated_resources.tf. Please review the configuration and edit it as necessary before adding it to version control. To perform exactly these actions, run the following command to apply: ts-import-with-configuration Import without configuration detected. Terraform has created configuration for it: # Please review these resources and move them into your main configuration files. CDKTF has translated the code to the following: * Provider bindings are generated by running `cdktf get`. * See https://cdk.tf/provider-generation for more details. Please review the code and make any necessary changes before adding it to your codebase. Make sure to only copy the code within the construct's constructor. NOTE: Your resource has not yet become managed by CDKTF. To finish the import remove the call \"generateConfigForImport\", add the above code within the construct's constructor, and then append the call importFrom(<resource_id_to_import_from>) to the generated code:\n\nThough at this point, your resource has not been imported. To import, first add the new generated configuration to your project, then remove the initial call of . Finally, follow the steps outlined in the section \"How To Import\" above. On apply, your resource will be imported, then becoming managed by CDKTF.\n\nTerraform provides meta-arguments to change resource behavior. For example, the meta-argument creates multiple resource instances according to a map, or set of strings. The escape hatch allows you to use these meta-arguments to your CDKTF application and to override attributes that CDKTF cannot yet fully express.\n\nThe following example defines a provisioner for a resource using the method.\n\nWhen you run , CDKTF generates a Terraform configuration with the provisioner added to the JSON object.\n\nTo override an attribute, include the resource attribute key in . The attribute in the escape hatch is in snake case because the Terraform JSON configuration uses snake case instead of camel case.\n\nWhen you run , CDKTF generates a Terraform configuration with the value overwritten.\n\nUse a dot notation to access elements in arrays: .\n\nTerraform configurations sometimes use blocks to create related resources based on dynamic data, or data that is only known after Terraform provisions the infrastructure. For example, you could create a series of nested blocks for a series of Virtual Private Cloud (VPC) ingress ports. A block loops over a complex value and generates a nested resource block for each element of that complex value.\n\nIn CDKTF applications, you must use an escape hatch when you want to loop through a dynamic value like a or a resource output.\n\nTo use an escape hatch to loop over dynamic data, you must:\n• Set the first argument of to be .\n• Create a value for the second argument and set it to the list you want to iterate over.\n• Take the attribute as base for the reference when you reference values from the list. For example, use .\n\nThe following example adds ingress values by looping through the ports passed as .\n\nYou should only use escape hatches when you need to work with dynamic values that are unknown until after Terraform provisions your infrastructure. If you are working with static values, we recommend using the functionality available in your preferred programming language to iterate through the array.\n\nThe following example loops through the ports without using an escape hatch.\n\nThe resource implements the standard resource lifecycle but does not directly perform any other actions. In CDKTF, the resource is exposed as the class and you can import it directly from the package.\n\nA few individual Terraform Resources have very deeply nested schemas with a lot of attributes. This blows up the config classes and slows down the code generation for languages besides Typescript. To work around this we sometimes limit the depth of the config classes and use on deeper level, some attributes we directly expose as on the top level config class.\n• Provider:\n• , , and are set to\n• related resources have a lot of deeply nested attributes that might be skipped"
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-deploy-load-balanced-web-applications-on-digitalocean-with-cdk-for-terraform-and-typescript",
        "document": "The author selected the Wikimedia Foundation to receive a donation as part of the Write for DOnations program.\n\nInfrastructure as Code (IaC) is a practice of automating infrastructure deployment and modifications by defining the resource states and their relationships in code. Executing that code then creates or modifies the actual resources in the cloud. IaC allows engineers to use an IaC tool like Terraform (by HashiCorp) for provisioning infrastructure.\n\nWith IaC, changes to your infrastructure can go through the same code review process as your application code. You can store the code in version control (like Git) to keep a history of the state of your infrastructure, and you can automate the deployment process further with higher-level tools such as a self-service internal developer platform (IDP).\n\nTerraform is a popular platform-agnostic IaC tool due to its broad support for many platforms, including GitHub, Cloudflare, and DigitalOcean. Most Terraform configurations are written using a declarative language called the HashiCorp Configuration Language (HCL).\n\nThe Cloud Development Kit for Terraform (CDKTF) is a tool built on top of Terraform that allows you to define infrastructure using a familiar programming language (such as TypeScript, Python, or Go) instead of HCL. This tool can provide a shallower learning curve for developers unfamiliar with HCL, while allowing developers to use native programming features like loops, variables, and functions.\n\nIn this tutorial, you will start by installing the command-line interface (CLI) tool. Then, you will author a CDKTF project in TypeScript and define the project with two NGINX servers that are load-balanced by a load balancer. You will then use to deploy the infrastructure. At the end of this tutorial, you will have a CDKTF project from which you can build to expand your infrastructure.\n\nTo complete this tutorial, you will need:\n• A good understanding of Infrastructure-as-Code (IaC). You can learn about IaC in Infrastructure as Code Explained.\n• A DigitalOcean account. If you do not have one, sign up for a new account.\n• A DigitalOcean Personal Access Token, which you can create via the DigitalOcean console. Instructions on how to do that can be found at How to Generate a Personal Access Token.\n• A password-less SSH key added to your DigitalOcean account. You can add that by following How To Use SSH Keys with DigitalOcean Droplets. When you add the key to your account, remember the name you give it, as you will need it in this tutorial. For CDKTF to accept the name of your key, it must start with a letter or underscore and may contain only letters, digits, underscores, and dashes.\n• Terraform installed on your local machine, which you can set up with “Step 1 - Installing Terraform” in How To Use Terraform with DigitalOcean.\n• Node.js installed on your local machine. You can find instructions for this in the How to Install Node.js and Create a Local Development Environment series.\n• To be comfortable programming with JavaScript. To build your skills, check out the How To Code in JavaScript series.\n• To be comfortable using the basic features of TypeScript. If you are not comfortable with TypeScript, the How To Code in TypeScript tutorial series is a good resource to get you up to speed.\n• A code editor or integrated development environment (IDE) that supports TypeScript. If you are not currently using one, try Visual Studio Code. You can also read up on How To Work With TypeScript in Visual Studio Code.\n\nTo begin, you will install the command-line tool.\n\nThe CLI is available as an NPM package. If you search for on npmjs.com, you will find two similarly-named packages: and .\n\nConceptually, CDKTF is an abstraction layer on top of Terraform. It consists of two parts:\n• a library containing a set of language-native constructs (such as functions and classes) for defining infrastructure. This part is encapsulated within the npm package. For example, you can see the use of the and classes from the package in the following sample CDKTF project:\n• an adapter that parses the constructs within the CDKTF project and reduces them to a set of JSON documents, which are then ingested into Terraform in the same way HCL is ingested. This adaptor is encapsulated into a CLI tool called , provided by the package.\n\nTo install the CLI tool, you need the package. You can install this package globally using , , or a package manager of your choosing.\n\nTo install with , run the following:\n\nAlternatively, you can use Homebrew on macOS or Linux to install the CLI as the formula:\n\nTo verify the installation is successful, run the command with no arguments:\n\nYou will see output similar to the following:\n\nThe output shows you the available commands. In the rest of this tutorial, you will gain experience using , , , and .\n\nNow that you have installed the CLI, you can define infrastructure by writing some TypeScript code.\n\nIn this step, you will use the CLI you just installed to create a boilerplate CDKTF project, which you will build on in subsequent steps.\n\nCreate a directory that will house the CDKTF project by running the following command:\n\nThen, navigate into the newly-created directory:\n\nUse the command to create a CDKTF project scaffold that you will build on:\n\nCDKTF allows developers to define infrastructure using TypeScript, Python, Java, C#, or Go. The option tells to scaffold this CDKTF project using TypeScript.\n\nTerraform (and thus CDKTF) keeps track of the resources it is managing by recording their definitions and states in files called Terraform state files. The option tells CDKTF to keep these state files locally on the machine running (each file follows the naming structure ).\n\nAfter running the command, the CLI may ask you for permission to send crash reports to the CDKTF team to help them improve the product:\n\nType if you’d like to consent or if you disagree, then press .\n\nwill then create the project scaffold and install the packages. When the project is scaffolded, you will see an output similar to the following:\n\nYou will also see some new files added to the directory. The most important files are and .\n\nis the configuration file for the CDKTF project. If you open the file, it will display something like the following:\n\nThe property defines the command that will be run to synthesize the TypeScript code to Terraform-compatible JSON. This property indicates that is the entry point to the CDKTF project.\n\nIf you open the file, you will see something similar to the following:\n\nIn the language of CDKTF, a collection of related infrastructure resources can be grouped into a stack. For example, the resources making up an API application, such as Droplets, load balancers, and DNS records, can be grouped into a single stack named . Each stack keeps its own state and can be deployed, modified, or destroyed independently from other stacks. A common use of stacks is to have one stack for production and a separate stack for development.\n\nAn application is a container for multiple stacks. For example, an application can group the stacks of various microservices.\n\nThe CDKTF project scaffold generated in contains a single stack class called , currently defining no resources. An instance of is created with the name , contained within an application called . In subsequent steps, you will define infrastructure resources within the constructor.\n\nAfter creating the project, the next step is configuring the CDKTF project with providers.\n\nIn this step, you will install the DigitalOcean Provider into the CDKTF project.\n\nProviders are libraries that provide instructions to Terraform (which is used by under the hood) on how to create, update, and delete resources on cloud providers, SaaS providers, and other platforms exposing application programming interfaces (APIs). Providers encapsulate the logic of calling these upstream APIs into standard functions that Terraform can call.\n\nFor example, if you were to create a new DigitalOcean Droplet without Terraform, you’d have to send a request to the endpoint of the DigitalOcean API. With Terraform, you would instead install the DigitalOcean provider and define a resource, similar to the following sample snippet:\n\nYou can then use the CLI tool to translate this TypeScript code into Terraform-compatible JSON and pass it to the provider, who will make the appropriate API calls to create the Droplet on your behalf.\n\nNow that you understand what a provider is, you can set up the DigitalOcean provider for your CDKTF project.\n\nOpen the file and add the string to the array:\n\nis the identifier for the DigitalOcean provider on the Terraform Registry.\n\nNext, run to download and install the provider.\n\nwill download the provider, extract the schema, generate the corresponding TypeScript classes, and add it as a TypeScript module under . This auto-code generation enables you to use any Terraform providers and HCL modules with CDKTF, and it is how CDKTF can provide code completion in editors that support it.\n\nOnce finishes running, you will see output similar to the following:\n\nYou will also see a new directory called containing the generated code of the provider.\n\nIn this step, you installed the provider into the project. In the next step, you will configure the DigitalOcean provider with the credentials required to authenticate the provider with the DigitalOcean API.\n\nIn this step, you will configure the DigitalOcean provider with your DigitalOcean Personal Access Token, which allows the provider to call the DigitalOcean API on your behalf.\n\nDifferent providers require and support different credentials for authenticating with the upstream API. For the DigitalOcean provider, you need to provide your DigitalOcean Personal Access Token. You can specify the token to the provider by setting it as the or environment variables.\n\nRun the following command in your terminal to set the environment variable for that terminal session.\n\nNext, you will specify the provider within the class, which will allow you to define resources provided by the provider within your stack. Update the file to the following:\n\nThe module for the provider is located at , which was automatically generated when you ran .\n\nYou configured the provider with credentials in this step. Next, you will start defining the infrastructure that forms part of the goal of this tutorial.\n\nIn this step, you will define two NGINX servers, each serving different files, deployed on two identical Ubuntu 20.04 Droplets.\n\nYou start with the definition of the two Droplets. Modify with the highlighted changes:\n\nYou use a JavaScript-native loop ( ) to avoid duplication in the code.\n\nJust as if you were creating the Droplet through the console, there are several parameters to specify:\n• - the Linux distribution and version your Droplet will run.\n• - the data center the Droplet will run in.\n• - the amount of CPU and memory resources to reserve to the Droplet.\n• - a unique name used to refer to the Droplet.\n\nThe values for , , and must be things that DigitalOcean supports. You can find the valid values (called slugs) for all supported Linux distribution images, Droplet sizes, and regions on the DigitalOcean API Slugs page. You can find a complete list of required and optional attributes on the documentation page.\n\nAs part of the prerequisites, you uploaded a password-less SSH public key to your DigitalOcean account and noted its name. You will now use that name to retrieve the SSH key’s ID and pass it into the definition of your Droplet.\n\nSince the SSH key was manually added to your DigitalOcean account, it is not a resource managed by your current Terraform configuration. If you tried to define a new resource, it will create a new SSH key instead of using the existing one.\n\nInstead, you will define a new data source. In Terraform, data sources are used to retrieve information about infrastructure that are not managed by the current Terraform configuration. In other words, they provide a read-only view into the state of pre-existing, external infrastructure. Once a data source is defined, you can use the data elsewhere in your Terraform configuration.\n\nStill in and within the constructor of , define a new data source, and pass in the name you assigned to your SSH key (here, the name is ):\n\nThen, update the Droplet’s definition to include the SSH key:\n\nWhen provisioned, you can access the Droplet using a private SSH key instead of a password.\n\nYou have now defined two identical Droplets running Ubuntu, configured with SSH access. The next task is to install NGINX on each Droplet.\n\nWhen a Droplet is being created, a tool called CloudInit will bootstrap the server. CloudInit can accept a file called user data, which can modify how the server is bootstrapped. The user data can be any files or scripts the server can interpret, such as Bash scripts.\n\nIn the remainder of this step, you will create a Bash script and specify it as the Droplet’s user data. The script will install NGINX as part of the bootstrapping process. In addition, the script will also replace the contents of the file (the default file served by NGINX) with the hostname and IP address of the Droplet, which will cause the two NGINX servers to serve different files. In the next step, you will put both of these NGINX servers behind a load balancer; by serving different files, it will make it apparent whether the load balancer is distributing requests correctly or not.\n\nStill in , add a new property to the Droplet’s configuration object:\n\nWhen the Droplet is first provisioned, the script will be run as the user. It will use Ubuntu’s package manager, APT, to install the package. It will then use DigitalOcean’s Metadata Service to retrieve information about itself, and write the hostname and IP address into , which is served by NGINX.\n\nIn this step, you defined the two Droplets running Ubuntu, configured each one with SSH access, and installed NGINX using the user data feature. In the next step, you will define a load balancer that will sit in front of these NGINX servers and configure it to load balance in a round-robin fashion.\n\nIn this step, you will define a DigitalOcean Load Balancer by defining an instance of the resource.\n\nStill in , add the following definition for a load balancer at the end of the constructor:\n\nThe argument tells the load balancer to listen for HTTP requests on port and forward them to each of the Droplets on port .\n\nThe specify the Droplets to which the load balancer will pass requests. It takes a number, but the value of is a string. Therefore, you have used the Terraform function to convert the string Droplet ID value to a number.\n\nYou have now defined two Droplets and a load balancer that sits in front of them. Your should look similar to this:\n\nIn the next step, you will use the CLI tool to actualize your entire CDKTF project.\n\nIn this step, you will use the CLI tool to provision the Droplets and load balancers you defined in the previous steps.\n\nMake sure that you are in the directory and have set the environment variable for your terminal session, then run the command:\n\nYou should see output similar to the following:\n\nThis display lists all the resources and properties that plans to create, update, and destroy. Some values, such as a Droplet’s ID, are only known after the resource is provisioned. For those, you will see as the property value in the output.\n\nReview the list of resources to make sure it is what you expect. Then, use the arrow keys to select the Approve option and press .\n\nYou will see an output similar to the following:\n\nThis output tells you that is communicating with the DigitalOcean API to create the Droplet. is creating the Droplets first because the load balancer depends on the Droplet’s ID, which is unknown until the Droplets are provisioned.\n\nDroplet creation usually takes less than a minute. Once the Droplets are provisioned, moves on to creating the load balancer.\n\nThe load balancer may take longer. After the load balancer is created, you will see a summary that shows the stack has been deployed successfully.\n\nYou can now visit the DigitalOcean console, where you can see one load balancer named and two healthy Droplets named and , each serving as a target for the load balancer.\n\nYou can test that NGINX is running and serving content correctly by visiting the IP address of each Droplet. You should see text similar to the following:\n\nIf you don’t see that string of text or the server is not responding, check that the user data you specified is correct and that no characters (including new lines) preceed the shebang ( ). You can also SSH into the Droplet using your SSH private key and review the output logs generated by CloudInit at :\n\nOnce you have confirmed the Droplets are up and serving content, you can begin testing the load balancer. You do this by sending a few requests.\n\nRun the following command from your terminal to send ten requests to the load balancer:\n\nYou should see output similar to the following, although the IP addresses shown will be different:\n\nIt shows that requests to the load balancer were forwarded to each Droplet five times, indicating that the load balancer is working.\n\nIn this step, you used to provision your resources, and then you used the DigitalOcean console to discover the IP addresses of your Droplets and load balancer. You then sent requests to each Droplet and load balancer to confirm they work.\n\nIn the next step, you will obtain the IP addresses of the Droplets and load balancer without logging into the DigitalOcean console.\n\nIn the previous step, you had to log in to the DigitalOcean Console to obtain the IP addresses of your Droplet and load balancer. In this step, you will modify your code slightly so that this information is printed in the output of the command, saving you a trip to the console.\n\nTerraform records the configuration and state of its managed resources in state files. For your stack, the state file can be found at . You will be able to find the IP addresses of the Droplets and load balancer inside this state file.\n\nHowever, sorting through a large file can be inconvenient. CDKTF provides the construct, which you can use to output variables and make them available outside of the stack. Any outputs are printed in after is run. Running can also print outputs at any time.\n\nUpdate the file to include outputs of the IP addresses of the load balancer and Droplets:\n\nWithin the output, you should see something similar to the following:\n\nThis output tells you that no infrastructure changes will be made, only what is output from the stack.\n\nUse the arrow keys to select Approve, and then press . At the end of the terminal output, you should see something similar to:\n\nNow, each time you run or , the IP address of the Droplets and the load balancers are printed in the terminal output, removing the need to access that information from the DigitalOcean console.\n\nYou have now provisioned two Droplets and a load balancer and confirmed they are working. You can use the CDKTF project you have developed as a base to define more sophisticated infrastructure (you can find a reference implementation at ).\n\nThe resources provisioned in this tutorial will incur a charge. If you do not intend to use the infrastructure created, you should destroy it. In the next and final step, you will clean up the project by destroying the resources created in this tutorial.\n\nIn this step, you will remove all the resources created in this tutorial.\n\nStill within the directory, run :\n\nYou should see output similar to the following:\n\nThis time, instead of showing next to each resource, it shows , indicating CDKTF plans to destroy the resource. Review the changes proposed, then use the arrow keys to select Approve and press . The DigitalOcean provider will now communicate with the DigitalOcean API to destroy the resources.\n\nThe load balancer was deleted first because it has no dependencies (no other resources reference the load balancer in their inputs). Because the load balancer references the Droplets, they can only be destroyed after the load balancer is destroyed.\n\nAfter the resources have been destroyed, you will see the following line printed in the output:\n\nIn this tutorial, you used CDKTF to provision and destroy a load-balanced web page, consisting of two DigitalOcean Droplets running NGINX servers, served behind a load balancer. You also output information about the resources on the terminal.\n\nCDKTF is an abstraction layer above Terraform. A good understanding of Terraform is helpful in understanding CDKTF. If you’d like to learn more about Terraform, you can read the How To Manage Infrastructure with Terraform series, which covers Terraform in depth.\n\nYou can also check out the official CDK for Terraform documentation and tutorials to learn more about CDKTF."
    },
    {
        "link": "https://github.com/cdktf/cdktf-provider-digitalocean",
        "document": "This repo builds and publishes the Terraform digitalocean provider bindings for CDK for Terraform.\n\nThe npm package is available at https://www.npmjs.com/package/@cdktf/provider-digitalocean.\n\nThe PyPI package is available at https://pypi.org/project/cdktf-cdktf-provider-digitalocean.\n\nThe Nuget package is available at https://www.nuget.org/packages/HashiCorp.Cdktf.Providers.Digitalocean.\n\nThe Maven package is available at https://mvnrepository.com/artifact/com.hashicorp/cdktf-provider-digitalocean.\n\nThe go package is generated into the package.\n\nWhere is the version of the prebuilt provider you would like to use e.g. . The full module name can be found within the go.mod file.\n\nFind auto-generated docs for this provider here:\n\nYou can also visit a hosted version of the documentation on constructs.dev.\n\nThis project is explicitly not tracking the Terraform digitalocean provider version 1:1. In fact, it always tracks of with every release. If there are scenarios where you explicitly have to pin your provider version, you can do so by generating the provider constructs manually.\n\nThese are the upstream dependencies:\n\nIf there are breaking changes (backward incompatible) in any of the above, the major version of this project will be bumped.\n\nPlease report bugs and issues to the CDK for Terraform project:\n\nThis is mostly based on Projen, which takes care of generating the entire repository.\n\nThere's a custom project builder which encapsulate the common settings for all prebuilt providers.\n\nThe provider version can be adjusted in ./.projenrc.js.\n\nThe repository is managed by CDKTF Repository Manager."
    },
    {
        "link": "https://github.com/cdktf/cdktf-provider-digitalocean/blob/main/docs/API.typescript.md",
        "document": "The following submodules are available:"
    },
    {
        "link": "https://developer.hashicorp.com/terraform/cdktf/examples-and-guides/examples",
        "document": "This page contains links to tutorials, example projects in every supported language, explanatory videos, and other resources to help you learn to create and manage CDK for Terraform (CDKTF) applications.\n\nEach CDK for Terraform project can specify a backend that defines where and how Terraform operations are performed, where Terraform state snapshots are stored, etc.\n• Our official playlist contains a set of videos from community office hours to deep dives into technical topics\n• CDK Day 2022 - Hybrid Constructs: How to build CDKTF abstractions that cooperate with your HCL\n• The CDKTF engineering team builds a simple end to end serverless application in an end to end livestream\n• Getting Started with CDK for Terraform and Python, by Charles McLaughlin of ShopStyle\n• Extending constructs of the CDK for Terraform\n• None 0.4: Go support, Asset construct, Terraform Cloud (now HCP Terraform) integration. This includes a Google Kubernetes Engine demo.\n• None If you are interested in extending the command, you may also be interested in the convert deep dive. You do not need to watch this video to use the command successfully.\n\nMozilla Pocket is a widely used application for managing reading lists that is built into the Firefox browser. Like many Mozilla projects, Pocket is open source, and the CDK for Terraform codebase that Pocket uses to manage infrastructure for the recommendation API is also public and open source. Pocket's codebase provides a great example of how to lay out a CDK for Terraform project.\n\nIn order to re-use components, Pocket's codebase is separated out into a set of reusable modules. These are then used from CDK for Terraform code in the recommendation-api codebase. The recommended reading order is to:\n• Look at the constructs used that are defined in the repository, such as .\n• Look at the \"base\" constructs, which are are used in the higher-level constructs in the previous step."
    },
    {
        "link": "https://hint.io/blog/deploy-infrastructure-cdktf",
        "document": "CDK or Cloud Development Kit came out of AWS in 2018 as a way to write Infrastructure as Code in software languages used day-to-day by developers (JavaScript/TypeScript, Python, Java, C#, and soon Go). Since its release, a community has built up around it, and new flavors have arrived. AWS CDK, CDKTF, and CDK8s are all based on the same core, but compile to different formats. AWS CDK compiles to CloudFormation, while CDKTF compiles to Terraform compatible JSON, and CDK8s compiles to Kubernetes config.\n\nIn this post, we will walk through how to use CDKTF with DigitalOcean's Terraform provider. A Terraform provider is a \"plugin\" for Terraform to interact with remote systems. In this case, the provider is created and maintained by DigitalOcean. We will share a few examples of creating a Digital Ocean Project, a VPC, a Postgres Database, and a Droplet.\n\nTo use cdktf you will need the following packages installed:\n\nTo install cdktf, we will use\n\nYou will also need to create a personal access token on Digital Ocean if you would like to deploy this config.\n\nCreate and Initialize the example project\n\nFirst let's make a directory and change into it.\n\nInitialize the project with the command. In general, I use the flag, so all state is stored locally.\n\nYou will be prompted for Project Name and Description but defaults are fine.\n\nThe last step of setting up the project is to add Terraform providers to the . Open the project in your editor and let's add the DigitalOcean provider to it as follows.\n\nRun to download the dependencies for using DigitalOcean with Typescript.\n\nOpen in your editor and let's start by creating a DO Project.\n\nYou will create a new and pass in the environment variable assigned to your DO personal access token. Next, we create the , which has a required key of .\n\nOptionally, as a test of the code above, run to deploy your CDKTF project. The cli will ask if you want to make the changes listed under Resources. Type 'yes', then once it finishes, you will see a green check next to the Resources it successfully created.\n\nNow we will add a VPC, a Postgres Database, and a Droplet. Once those examples are in, we will tie it all together before deploying it again.\n\n* Note: If you do not have VPC in your account already this will become the default VPC which will not be deleted when cleaning up the CDKTF Project.\n\nNotice we assigned the to a variable . We then use the variable to create the and on that cluster.\n\nLet's Put It All Together\n\nIf you run now, it would create everything, but nothing created would be put into the Digital Ocean project or the VPC we create. Let's do that now.\n\nWe start by assigning the project, VPC, and droplet to variables. In the definition, we add to place the database in our newly created VPC. Similarly, on the definition, we place it in the VPC, by adding .\n\nLastly, create a new to assign other resources to the Digital Ocean project. In this small example, we will assign the database and droplet to the project using the for each resource. We will wait to assign those until both are created using a Terraform helper .\n\nWith all of that in place you can deploy again. The database and droplet creation take a bit, so be patient. 🙂 Once it has finished, check your Digital Ocean Dashboard to see everything created and ready for use.\n\n* Make sure you run to remove these resources from your account or you will be charged by Digital Ocean. *\n\nCDKTF is still a young project, so it is changing fast, has limited documentation, and you can run into unclear errors.\n\nThere are few things that help with the limited documentation. You can read the provider documentation on the Terraform registry site and use it as a guide. Also, using a language like Typescript with VSCode there are a lot of code hints, hover info, and signature information. The gif below is an example of what is shown in VSCode when you hover on the problem. Note the missing properties for .\n\nWhen you run into unclear errors, prepend to the deploy and/or destroy commands to get very verbose output.\n\nIn this post, we used CDKTF to create some basic example resources on Digital Ocean which gives you a good primer to build more complex infrastructure in a language of your choice. You can find the code from this post in this repo. If you would like to chat more about CDK or infrastructure as code you can ping me on Twitter @natron99."
    }
]