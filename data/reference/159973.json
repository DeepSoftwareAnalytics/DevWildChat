[
    {
        "link": "https://docs.python.org/3/tutorial/datastructures.html",
        "document": "This chapter describes some things you’ve learned about already in more detail, and adds some new things as well.\n\nThe list data type has some more methods. Here are all of the methods of list objects: Add an item to the end of the list. Similar to . Extend the list by appending all the items from the iterable. Similar to . Insert an item at a given position. The first argument is the index of the element before which to insert, so inserts at the front of the list, and is equivalent to . Remove the first item from the list whose value is equal to x. It raises a if there is no such item. Remove the item at the given position in the list, and return it. If no index is specified, removes and returns the last item in the list. It raises an if the list is empty or the index is outside the list range. Remove all items from the list. Similar to . Return zero-based index in the list of the first item whose value is equal to x. Raises a if there is no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument. Return the number of times x appears in the list. Sort the items of the list in place (the arguments can be used for sort customization, see for their explanation). Reverse the elements of the list in place. Return a shallow copy of the list. Similar to . An example that uses most of the list methods: You might have noticed that methods like , or that only modify the list have no return value printed – they return the default . This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, doesn’t sort because integers can’t be compared to strings and can’t be compared to other types. Also, there are some types that don’t have a defined ordering relation. For example, isn’t a valid comparison. The list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved (“last-in, first-out”). To add an item to the top of the stack, use . To retrieve an item from the top of the stack, use without an explicit index. For example: It is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-out”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing inserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use which was designed to have fast appends and pops from both ends. For example: # The first to arrive now leaves # The second to arrive now leaves List comprehensions provide a concise way to create lists. Common applications are to make new lists where each element is the result of some operations applied to each member of another sequence or iterable, or to create a subsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like: Note that this creates (or overwrites) a variable named that still exists after the loop completes. We can calculate the list of squares without any side effects using: which is more concise and readable. A list comprehension consists of brackets containing an expression followed by a clause, then zero or more or clauses. The result will be a new list resulting from evaluating the expression in the context of the and clauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal: Note how the order of the and statements is the same in both these snippets. If the expression is a tuple (e.g. the in the previous example), it must be parenthesized. # create a new list with the values doubled # apply a function to all the elements # the tuple must be parenthesized, otherwise an error is raised File , line : did you forget parentheses around the comprehension target? # flatten a list using a listcomp with two 'for' List comprehensions can contain complex expressions and nested functions: The initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4: The following list comprehension will transpose rows and columns: As we saw in the previous section, the inner list comprehension is evaluated in the context of the that follows it, so this example is equivalent to: which, in turn, is the same as: # the following 3 lines implement the nested listcomp In the real world, you should prefer built-in functions to complex flow statements. The function would do a great job for this use case: See Unpacking Argument Lists for details on the asterisk in this line.\n\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two examples of sequence data types (see Sequence Types — list, tuple, range). Since Python is an evolving language, other sequence data types may be added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance: File , line , in : # but they can contain mutable objects: As you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they may be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple is part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to create tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples are immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later in this section) or indexing (or even by attribute in the case of ). Lists are mutable, and their elements are usually homogeneous and are accessed by iterating over the list. A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accommodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed by following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example: The statement is an example of tuple packing: the values , and are packed together in a tuple. The reverse operation is also possible: This is called, appropriately enough, sequence unpacking and works for any sequence on the right-hand side. Sequence unpacking requires that there are as many variables on the left side of the equals sign as there are elements in the sequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking.\n\nPython also includes a data type for sets. A set is an unordered collection with no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. Set objects also support mathematical operations like union, intersection, difference, and symmetric difference. Curly braces or the function can be used to create sets. Note: to create an empty set you have to use , not ; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration: # show that duplicates have been removed # Demonstrate set operations on unique letters from two words # letters in a but not in b # letters in a or b or both # letters in both a and b # letters in a or b but not both Similarly to list comprehensions, set comprehensions are also supported:\n\nAnother useful data type built into Python is the dictionary (see Mapping Types — dict). Dictionaries are sometimes found in other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range of numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be keys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable object either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified in place using index assignments, slice assignments, or methods like and . It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within one dictionary). A pair of braces creates an empty dictionary: . Placing a comma-separated list of key:value pairs within the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also possible to delete a key:value pair with . If you store using a key that is already in use, the old value associated with that key is forgotten. It is an error to extract a value using a non-existent key. Performing on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you want it sorted, just use instead). To check whether a single key is in the dictionary, use the keyword. Here is a small example using a dictionary: The constructor builds dictionaries directly from sequences of key-value pairs: In addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions: When the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the method. When looping through a sequence, the position index and corresponding value can be retrieved at the same time using the function. To loop over two or more sequences at the same time, the entries can be paired with the function. What is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the function. To loop over a sequence in sorted order, use the function which returns a new sorted list while leaving the source unaltered. Using on a sequence eliminates duplicate elements. The use of in combination with over a sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. It is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create a new list instead.\n\nThe conditions used in and statements can contain any operators, not just comparisons. The comparison operators and are membership tests that determine whether a value is in (or not in) a container. The operators and compare whether two objects are really the same object. All comparison operators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, tests whether is less than and moreover equals . Comparisons may be combined using the Boolean operators and , and the outcome of a comparison (or of any other Boolean expression) may be negated with . These have lower priorities than comparison operators; between them, has the highest priority and the lowest, so that A and not B or C is equivalent to (A and (not B)) or C . As always, parentheses can be used to express the desired composition. The Boolean operators and are so-called short-circuit operators: their arguments are evaluated from left to right, and evaluation stops as soon as the outcome is determined. For example, if and are true but is false, A and B and C does not evaluate the expression . When used as a general value and not as a Boolean, the return value of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example, Note that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator . This avoids a common class of problems encountered in C programs: typing in an expression when was intended.\n\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses lexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of the comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried out recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence is an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one. Lexicographical ordering for strings uses the Unicode code point number to order individual characters. Some examples of comparisons between sequences of the same type: Note that comparing objects of different types with or is legal provided that the objects have appropriate comparison methods. For example, mixed numeric types are compared according to their numeric value, so 0 equals 0.0, etc. Otherwise, rather than providing an arbitrary ordering, the interpreter will raise a exception."
    },
    {
        "link": "https://docs.python.org/3/reference/datamodel.html",
        "document": "Objects are Python’s abstraction for data. All data in a Python program is represented by objects or by relations between objects. (In a sense, and in conformance to Von Neumann’s model of a “stored program computer”, code is also represented by objects.) Every object has an identity, a type and a value. An object’s identity never changes once it has been created; you may think of it as the object’s address in memory. The operator compares the identity of two objects; the function returns an integer representing its identity. CPython implementation detail: For CPython, is the memory address where is stored. An object’s type determines the operations that the object supports (e.g., “does it have a length?”) and also defines the possible values for objects of that type. The function returns an object’s type (which is an object itself). Like its identity, an object’s type is also unchangeable. The value of some objects can change. Objects whose value can change are said to be mutable; objects whose value is unchangeable once they are created are called immutable. (The value of an immutable container object that contains a reference to a mutable object can change when the latter’s value is changed; however the container is still considered immutable, because the collection of objects it contains cannot be changed. So, immutability is not strictly the same as having an unchangeable value, it is more subtle.) An object’s mutability is determined by its type; for instance, numbers, strings and tuples are immutable, while dictionaries and lists are mutable. Objects are never explicitly destroyed; however, when they become unreachable they may be garbage-collected. An implementation is allowed to postpone garbage collection or omit it altogether — it is a matter of implementation quality how garbage collection is implemented, as long as no objects are collected that are still reachable. CPython implementation detail: CPython currently uses a reference-counting scheme with (optional) delayed detection of cyclically linked garbage, which collects most objects as soon as they become unreachable, but is not guaranteed to collect garbage containing circular references. See the documentation of the module for information on controlling the collection of cyclic garbage. Other implementations act differently and CPython may change. Do not depend on immediate finalization of objects when they become unreachable (so you should always close files explicitly). Note that the use of the implementation’s tracing or debugging facilities may keep objects alive that would normally be collectable. Also note that catching an exception with a … statement may keep objects alive. Some objects contain references to “external” resources such as open files or windows. It is understood that these resources are freed when the object is garbage-collected, but since garbage collection is not guaranteed to happen, such objects also provide an explicit way to release the external resource, usually a method. Programs are strongly recommended to explicitly close such objects. The … statement and the statement provide convenient ways to do this. Some objects contain references to other objects; these are called containers. Examples of containers are tuples, lists and dictionaries. The references are part of a container’s value. In most cases, when we talk about the value of a container, we imply the values, not the identities of the contained objects; however, when we talk about the mutability of a container, only the identities of the immediately contained objects are implied. So, if an immutable container (like a tuple) contains a reference to a mutable object, its value changes if that mutable object is changed. Types affect almost all aspects of object behavior. Even the importance of object identity is affected in some sense: for immutable types, operations that compute new values may actually return a reference to any existing object with the same type and value, while for mutable objects this is not allowed. For example, after , a and b may or may not refer to the same object with the value one, depending on the implementation. This is because is an immutable type, so the reference to can be reused. This behaviour depends on the implementation used, so should not be relied upon, but is something to be aware of when making use of object identity tests. However, after , c and d are guaranteed to refer to two different, unique, newly created empty lists. (Note that assigns the same object to both e and f.)"
    },
    {
        "link": "https://docs.python.org/3/library/functions.html",
        "document": "The Python interpreter has a number of functions and types built into it that are always available. They are listed here in alphabetical order.\n\nOpen file and return a corresponding file object. If the file cannot be opened, an is raised. See Reading and Writing Files for more examples of how to use this function. file is a path-like object giving the pathname (absolute or relative to the current working directory) of the file to be opened or an integer file descriptor of the file to be wrapped. (If a file descriptor is given, it is closed when the returned I/O object is closed unless closefd is set to .) mode is an optional string that specifies the mode in which the file is opened. It defaults to which means open for reading in text mode. Other common values are for writing (truncating the file if it already exists), for exclusive creation, and for appending (which on some Unix systems, means that all writes append to the end of the file regardless of the current seek position). In text mode, if encoding is not specified the encoding used is platform-dependent: is called to get the current locale encoding. (For reading and writing raw bytes use binary mode and leave encoding unspecified.) The available modes are: open for writing, truncating the file first open for exclusive creation, failing if the file already exists open for writing, appending to the end of file if it exists The default mode is (open for reading text, a synonym of ). Modes and open and truncate the file. Modes and open the file with no truncation. As mentioned in the Overview, Python distinguishes between binary and text I/O. Files opened in binary mode (including in the mode argument) return contents as objects without any decoding. In text mode (the default, or when is included in the mode argument), the contents of the file are returned as , the bytes having been first decoded using a platform-dependent encoding or using the specified encoding if given. Python doesn’t depend on the underlying operating system’s notion of text files; all the processing is done by Python itself, and is therefore platform-independent. buffering is an optional integer used to set the buffering policy. Pass 0 to switch buffering off (only allowed in binary mode), 1 to select line buffering (only usable when writing in text mode), and an integer > 1 to indicate the size in bytes of a fixed-size chunk buffer. Note that specifying a buffer size this way applies for binary buffered I/O, but (i.e., files opened with ) would have another buffering. To disable buffering in , consider using the flag for . When no buffering argument is given, the default buffering policy works as follows:\n• None Binary files are buffered in fixed-size chunks; the size of the buffer is chosen using a heuristic trying to determine the underlying device’s “block size” and falling back on . On many systems, the buffer will typically be 4096 or 8192 bytes long.\n• None “Interactive” text files (files for which returns ) use line buffering. Other text files use the policy described above for binary files. encoding is the name of the encoding used to decode or encode the file. This should only be used in text mode. The default encoding is platform dependent (whatever returns), but any text encoding supported by Python can be used. See the module for the list of supported encodings. errors is an optional string that specifies how encoding and decoding errors are to be handled—this cannot be used in binary mode. A variety of standard error handlers are available (listed under Error Handlers), though any error handling name that has been registered with is also valid. The standard names include:\n• None to raise a exception if there is an encoding error. The default value of has the same effect.\n• None ignores errors. Note that ignoring encoding errors can lead to data loss.\n• None causes a replacement marker (such as ) to be inserted where there is malformed data.\n• None will represent any incorrect bytes as low surrogate code units ranging from U+DC80 to U+DCFF. These surrogate code units will then be turned back into the same bytes when the error handler is used when writing data. This is useful for processing files in an unknown encoding.\n• None is only supported when writing to a file. Characters not supported by the encoding are replaced with the appropriate XML character reference .\n• None (also only supported when writing) replaces unsupported characters with escape sequences. newline determines how to parse newline characters from the stream. It can be , , , , and . It works as follows:\n• None When reading input from the stream, if newline is , universal newlines mode is enabled. Lines in the input can end in , , or , and these are translated into before being returned to the caller. If it is , universal newlines mode is enabled, but line endings are returned to the caller untranslated. If it has any of the other legal values, input lines are only terminated by the given string, and the line ending is returned to the caller untranslated.\n• None When writing output to the stream, if newline is , any characters written are translated to the system default line separator, . If newline is or , no translation takes place. If newline is any of the other legal values, any characters written are translated to the given string. If closefd is and a file descriptor rather than a filename was given, the underlying file descriptor will be kept open when the file is closed. If a filename is given closefd must be (the default); otherwise, an error will be raised. A custom opener can be used by passing a callable as opener. The underlying file descriptor for the file object is then obtained by calling opener with (file, flags). opener must return an open file descriptor (passing as opener results in functionality similar to passing ). The following example uses the dir_fd parameter of the function to open a file relative to a given directory: 'This will be written to somedir/spamspam.txt' The type of file object returned by the function depends on the mode. When is used to open a file in a text mode ( , , , , etc.), it returns a subclass of (specifically ). When used to open a file in a binary mode with buffering, the returned class is a subclass of . The exact class varies: in read binary mode, it returns an ; in write binary and append binary modes, it returns an , and in read/write mode, it returns an . When buffering is disabled, the raw stream, a subclass of , , is returned. See also the file handling modules, such as , (where is declared), , , , and . The and arguments may have been modified or inferred from the original call.\n• None used to be raised, it is now an alias of .\n• None is now raised if the file opened in exclusive creation mode ( ) already exists.\n• None The file is now non-inheritable.\n• None If the system call is interrupted and the signal handler does not raise an exception, the function now retries the system call instead of raising an exception (see PEP 475 for the rationale).\n• None On Windows, opening a console buffer may return a subclass of other than . Changed in version 3.11: The mode has been removed.\n\nReturn a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing inherited methods that have been overridden in a class. The object_or_type determines the method resolution order to be searched. The search starts from the class right after the type. For example, if of object_or_type is and the value of type is , then searches . The attribute of the class corresponding to object_or_type lists the method resolution search order used by both and . The attribute is dynamic and can change whenever the inheritance hierarchy is updated. If the second argument is omitted, the super object returned is unbound. If the second argument is an object, must be true. If the second argument is a type, must be true (this is useful for classmethods). When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument ”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately enclosing function (typically ). (This means that zero-argument will not work as expected within nested functions, including generator expressions, which implicitly create nested functions.) There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer to parent classes without naming them explicitly, thus making the code more maintainable. This use closely parallels the use of super in other programming languages. The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This use case is unique to Python and is not found in statically compiled languages or languages that only support single inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes implement the same method. Good design dictates that such implementations have the same calling signature in every case (because the order of calls is determined at runtime, because that order adapts to changes in the class hierarchy, and because that order can include sibling classes that are unknown prior to runtime). For both use cases, a typical superclass call looks like this: # This does the same thing as: In addition to method lookups, also works for attribute lookups. One possible use case for this is calling descriptors in a parent or sibling class. Note that is implemented as part of the binding process for explicit dotted attribute lookups such as . It does so by implementing its own method for searching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, is undefined for implicit lookups using statements or operators such as . Also note that, aside from the zero argument form, is not limited to use inside methods. The two argument form specifies the arguments exactly and makes the appropriate references. The zero argument form only works inside a class definition, as the compiler fills in the necessary details to correctly retrieve the class being defined, as well as accessing the current instance for ordinary methods. For practical suggestions on how to design cooperative classes using , see guide to using super()."
    },
    {
        "link": "https://docs.python.org/3/library/stdtypes.html",
        "document": "The following sections describe the standard types that are built into the interpreter.\n\nThe principal built-in types are numerics, sequences, mappings, classes, instances and exceptions.\n\nSome collection classes are mutable. The methods that add, subtract, or rearrange their members in place, and don’t return a specific item, never return the collection instance itself but .\n\nSome operations are supported by several object types; in particular, practically all objects can be compared for equality, tested for truth value, and converted to a string (with the function or the slightly different function). The latter function is implicitly used when an object is written by the function.\n\nThere are three distinct numeric types: integers, floating-point numbers, and complex numbers. In addition, Booleans are a subtype of integers. Integers have unlimited precision. Floating-point numbers are usually implemented using double in C; information about the precision and internal representation of floating-point numbers for the machine on which your program is running is available in . Complex numbers have a real and imaginary part, which are each a floating-point number. To extract these parts from a complex number z, use and . (The standard library includes the additional numeric types , for rationals, and , for floating-point numbers with user-definable precision.) Numbers are created by numeric literals or as the result of built-in functions and operators. Unadorned integer literals (including hex, octal and binary numbers) yield integers. Numeric literals containing a decimal point or an exponent sign yield floating-point numbers. Appending or to a numeric literal yields an imaginary number (a complex number with a zero real part) which you can add to an integer or float to get a complex number with real and imaginary parts. Python fully supports mixed arithmetic: when a binary arithmetic operator has operands of different numeric types, the operand with the “narrower” type is widened to that of the other, where integer is narrower than floating point, which is narrower than complex. A comparison between numbers of different types behaves as though the exact values of those numbers were being compared. The constructors , , and can be used to produce numbers of a specific type. All numeric types (except complex) support the following operations (for priorities of the operations, see Operator precedence): absolute value or magnitude of x a complex number with real part re, imaginary part im. im defaults to zero. conjugate of the complex number c\n• None Also referred to as integer division. For operands of type , the result has type . For operands of type , the result has type . In general, the result is a whole integer, though the result’s type is not necessarily . The result is always rounded towards minus infinity: is , is , is , and is .\n• None Not for complex numbers. Instead convert to floats using if appropriate.\n• None Conversion from to truncates, discarding the fractional part. See functions and for alternative conversions.\n• None float also accepts the strings “nan” and “inf” with an optional prefix “+” or “-” for Not a Number (NaN) and positive or negative infinity.\n• None Python defines and to be , as is common for programming languages.\n• None The numeric literals accepted include the digits to or any Unicode equivalent (code points with the property). See the Unicode Standard for a complete list of code points with the property. All types ( and ) also include the following operations: x rounded to n digits, rounding half to even. If n is omitted, it defaults to 0. For additional numeric operations see the and modules. Bitwise operations only make sense for integers. The result of bitwise operations is calculated as though carried out in two’s complement with an infinite number of sign bits. The priorities of the binary bitwise operations are all lower than the numeric operations and higher than the comparisons; the unary operation has the same priority as the other unary numeric operations ( and ). This table lists the bitwise operations sorted in ascending priority: bitwise exclusive or of x and y\n• None Negative shift counts are illegal and cause a to be raised.\n• None A left shift by n bits is equivalent to multiplication by .\n• None A right shift by n bits is equivalent to floor division by .\n• None Performing these calculations with at least one extra sign extension bit in a finite two’s complement representation (a working bit-width of or more) is sufficient to get the same result as if there were an infinite number of sign bits. The int type implements the abstract base class. In addition, it provides a few more methods: Return the number of bits necessary to represent an integer in binary, excluding the sign and leading zeros: More precisely, if is nonzero, then is the unique positive integer such that . Equivalently, when is small enough to have a correctly rounded logarithm, then . If is zero, then returns . Return the number of ones in the binary representation of the absolute value of the integer. This is also known as the population count. Example: Return an array of bytes representing an integer. The integer is represented using length bytes, and defaults to 1. An is raised if the integer is not representable with the given number of bytes. The byteorder argument determines the byte order used to represent the integer, and defaults to . If byteorder is , the most significant byte is at the beginning of the byte array. If byteorder is , the most significant byte is at the end of the byte array. The signed argument determines whether two’s complement is used to represent the integer. If signed is and a negative integer is given, an is raised. The default value for signed is . The default values can be used to conveniently turn an integer into a single byte object: However, when using the default arguments, don’t try to convert a value greater than 255 or you’ll get an . \"byteorder must be either 'little' or 'big'\" Changed in version 3.11: Added default argument values for and . Return the integer represented by the given array of bytes. The argument bytes must either be a bytes-like object or an iterable producing bytes. The byteorder argument determines the byte order used to represent the integer, and defaults to . If byteorder is , the most significant byte is at the beginning of the byte array. If byteorder is , the most significant byte is at the end of the byte array. To request the native byte order of the host system, use as the byte order value. The signed argument indicates whether two’s complement is used to represent the integer. \"byteorder must be either 'little' or 'big'\" Changed in version 3.11: Added default argument value for . Return a pair of integers whose ratio is equal to the original integer and has a positive denominator. The integer ratio of integers (whole numbers) is always the integer as the numerator and as the denominator. The float type implements the abstract base class. float also has the following additional methods. Return a pair of integers whose ratio is exactly equal to the original float. The ratio is in lowest terms and has a positive denominator. Raises on infinities and a on NaNs. Return if the float instance is finite with integral value, and otherwise: Two methods support conversion to and from hexadecimal strings. Since Python’s floats are stored internally as binary numbers, converting a float to or from a decimal string usually involves a small rounding error. In contrast, hexadecimal strings allow exact representation and specification of floating-point numbers. This can be useful when debugging, and in numerical work. Return a representation of a floating-point number as a hexadecimal string. For finite floating-point numbers, this representation will always include a leading and a trailing and exponent. Class method to return the float represented by a hexadecimal string s. The string s may have leading and trailing whitespace. Note that is an instance method, while is a class method. where the optional may by either or , and are strings of hexadecimal digits, and is a decimal integer with an optional leading sign. Case is not significant, and there must be at least one hexadecimal digit in either the integer or the fraction. This syntax is similar to the syntax specified in section 6.4.4.2 of the C99 standard, and also to the syntax used in Java 1.5 onwards. In particular, the output of is usable as a hexadecimal floating-point literal in C or Java code, and hexadecimal strings produced by C’s format character or Java’s are accepted by . Note that the exponent is written in decimal rather than hexadecimal, and that it gives the power of 2 by which to multiply the coefficient. For example, the hexadecimal string represents the floating-point number , or : Applying the reverse conversion to gives a different hexadecimal string representing the same number: For numbers and , possibly of different types, it’s a requirement that whenever (see the method documentation for more details). For ease of implementation and efficiency across a variety of numeric types (including , , and ) Python’s hash for numeric types is based on a single mathematical function that’s defined for any rational number, and hence applies to all instances of and , and all finite instances of and . Essentially, this function is given by reduction modulo for a fixed prime . The value of is made available to Python as the attribute of . CPython implementation detail: Currently, the prime used is on machines with 32-bit C longs and on machines with 64-bit C longs. Here are the rules in detail:\n• None If is a nonnegative rational number and is not divisible by , define as , where gives the inverse of modulo .\n• None If is a nonnegative rational number and is divisible by (but is not) then has no inverse modulo and the rule above doesn’t apply; in this case define to be the constant value .\n• None If is a negative rational number define as . If the resulting hash is , replace it with .\n• None The particular values and are used as hash values for positive infinity or negative infinity (respectively).\n• None For a number , the hash values of the real and imaginary parts are combined by computing , reduced modulo so that it lies in . Again, if the result is , it’s replaced with . To clarify the above rules, here’s some example Python code, equivalent to the built-in hash, for computing the hash of a rational number, , or : Assumes m and n are integers, with n positive. # Remove common factors of P. (Unnecessary if m and n already coprime.) # Fermat's Little Theorem: pow(n, P-1, P) is 1, so # pow(n, P-2, P) gives the inverse of n modulo P.\n\nThere are three basic sequence types: lists, tuples, and range objects. Additional sequence types tailored for processing of binary data and text strings are described in dedicated sections. The operations in the following table are supported by most sequence types, both mutable and immutable. The ABC is provided to make it easier to correctly implement these operations on custom sequence types. This table lists the sequence operations sorted in ascending priority. In the table, s and t are sequences of the same type, n, i, j and k are integers and x is an arbitrary object that meets any type and value restrictions imposed by s. The and operations have the same priorities as the comparison operations. The (concatenation) and (repetition) operations have the same priority as the corresponding numeric operations. if an item of s is equal to x, else if an item of s is equal to x, else the concatenation of s and t equivalent to adding s to itself n times slice of s from i to j with step k index of the first occurrence of x in s (at or after index i and before index j) total number of occurrences of x in s Sequences of the same type also support comparisons. In particular, tuples and lists are compared lexicographically by comparing corresponding elements. This means that to compare equal, every element must compare equal and the two sequences must be of the same type and have the same length. (For full details see Comparisons in the language reference.) Forward and reversed iterators over mutable sequences access values using an index. That index will continue to march forward (or backward) even if the underlying sequence is mutated. The iterator terminates only when an or a is encountered (or when the index drops below zero).\n• None While the and operations are used only for simple containment testing in the general case, some specialised sequences (such as , and ) also use them for subsequence testing:\n• None Values of n less than are treated as (which yields an empty sequence of the same type as s). Note that items in the sequence s are not copied; they are referenced multiple times. This often haunts new Python programmers; consider: What has happened is that is a one-element list containing an empty list, so all three elements of are references to this single empty list. Modifying any of the elements of modifies this single list. You can create a list of different lists this way: Further explanation is available in the FAQ entry How do I create a multidimensional list?.\n• None If i or j is negative, the index is relative to the end of sequence s: or is substituted. But note that is still .\n• None The slice of s from i to j is defined as the sequence of items with index k such that . If i or j is greater than , use . If i is omitted or , use . If j is omitted or , use . If i is greater than or equal to j, the slice is empty.\n• None The slice of s from i to j with step k is defined as the sequence of items with index such that . In other words, the indices are , , , and so on, stopping when j is reached (but never including j). When k is positive, i and j are reduced to if they are greater. When k is negative, i and j are reduced to if they are greater. If i or j are omitted or , they become “end” values (which end depends on the sign of k). Note, k cannot be zero. If k is , it is treated like .\n• None Concatenating immutable sequences always results in a new object. This means that building up a sequence by repeated concatenation will have a quadratic runtime cost in the total sequence length. To get a linear runtime cost, you must switch to one of the alternatives below:\n• None if concatenating objects, you can build a list and use at the end or else write to an instance and retrieve its value when complete\n• None if concatenating objects, you can similarly use or , or you can do in-place concatenation with a object. objects are mutable and have an efficient overallocation mechanism\n• None for other types, investigate the relevant class documentation\n• None Some sequence types (such as ) only support item sequences that follow specific patterns, and hence don’t support sequence concatenation or repetition.\n• None raises when x is not found in s. Not all implementations support passing the additional arguments i and j. These arguments allow efficient searching of subsections of the sequence. Passing the extra arguments is roughly equivalent to using , only without copying any data and with the returned index being relative to the start of the sequence rather than the start of the slice. The only operation that immutable sequence types generally implement that is not also implemented by mutable sequence types is support for the built-in. This support allows immutable sequences, such as instances, to be used as keys and stored in and instances. Attempting to hash an immutable sequence that contains unhashable values will result in . The operations in the following table are defined on mutable sequence types. The ABC is provided to make it easier to correctly implement these operations on custom sequence types. In the table s is an instance of a mutable sequence type, t is any iterable object and x is an arbitrary object that meets any type and value restrictions imposed by s (for example, only accepts integers that meet the value restriction ). item i of s is replaced by x slice of s from i to j is replaced by the contents of the iterable t the elements of are replaced by those of t removes the elements of from the list appends x to the end of the sequence (same as ) removes all items from s (same as ) creates a shallow copy of s (same as ) extends s with the contents of t (for the most part the same as ) inserts x into s at the index given by i (same as ) retrieves the item at i and also removes it from s removes the first item from s where is equal to x reverses the items of s in place\n• None If k is not equal to , t must have the same length as the slice it is replacing.\n• None The optional argument i defaults to , so that by default the last item is removed and returned.\n• None raises when x is not found in s.\n• None The method modifies the sequence in place for economy of space when reversing a large sequence. To remind users that it operates by side effect, it does not return the reversed sequence.\n• None and are included for consistency with the interfaces of mutable containers that don’t support slicing operations (such as and ). is not part of the ABC, but most concrete mutable sequence classes provide it.\n• None The value n is an integer, or an object implementing . Zero and negative values of n clear the sequence. Items in the sequence are not copied; they are referenced multiple times, as explained for under Common Sequence Operations. Lists are mutable sequences, typically used to store collections of homogeneous items (where the precise degree of similarity will vary by application). Lists may be constructed in several ways:\n• None Using a pair of square brackets to denote the empty list:\n• None Using the type constructor: or The constructor builds a list whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a list, a copy is made and returned, similar to . For example, returns and returns . If no argument is given, the constructor creates a new empty list, . Many other operations also produce lists, including the built-in. Lists implement all of the common and mutable sequence operations. Lists also provide the following additional method: This method sorts the list in place, using only comparisons between items. Exceptions are not suppressed - if any comparison operations fail, the entire sort operation will fail (and the list will likely be left in a partially modified state). accepts two arguments that can only be passed by keyword (keyword-only arguments): key specifies a function of one argument that is used to extract a comparison key from each list element (for example, ). The key corresponding to each item in the list is calculated once and then used for the entire sorting process. The default value of means that list items are sorted directly without calculating a separate key value. The utility is available to convert a 2.x style cmp function to a key function. reverse is a boolean value. If set to , then the list elements are sorted as if each comparison were reversed. This method modifies the sequence in place for economy of space when sorting a large sequence. To remind users that it operates by side effect, it does not return the sorted sequence (use to explicitly request a new sorted list instance). The method is guaranteed to be stable. A sort is stable if it guarantees not to change the relative order of elements that compare equal — this is helpful for sorting in multiple passes (for example, sort by department, then by salary grade). For sorting examples and a brief sorting tutorial, see Sorting Techniques. CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even inspect, the list is undefined. The C implementation of Python makes the list appear empty for the duration, and raises if it can detect that the list has been mutated during a sort. Tuples are immutable sequences, typically used to store collections of heterogeneous data (such as the 2-tuples produced by the built-in). Tuples are also used for cases where an immutable sequence of homogeneous data is needed (such as allowing storage in a or instance). Tuples may be constructed in a number of ways:\n• None Using a pair of parentheses to denote the empty tuple:\n• None Using a trailing comma for a singleton tuple: or\n• None Using the built-in: or The constructor builds a tuple whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a tuple, it is returned unchanged. For example, returns and returns . If no argument is given, the constructor creates a new empty tuple, . Note that it is actually the comma which makes a tuple, not the parentheses. The parentheses are optional, except in the empty tuple case, or when they are needed to avoid syntactic ambiguity. For example, is a function call with three arguments, while is a function call with a 3-tuple as the sole argument. Tuples implement all of the common sequence operations. For heterogeneous collections of data where access by name is clearer than access by index, may be a more appropriate choice than a simple tuple object. The type represents an immutable sequence of numbers and is commonly used for looping a specific number of times in loops. The arguments to the range constructor must be integers (either built-in or any object that implements the special method). If the step argument is omitted, it defaults to . If the start argument is omitted, it defaults to . If step is zero, is raised. For a positive step, the contents of a range are determined by the formula where and . For a negative step, the contents of the range are still determined by the formula , but the constraints are and . A range object will be empty if does not meet the value constraint. Ranges do support negative indices, but these are interpreted as indexing from the end of the sequence determined by the positive indices. Ranges containing absolute values larger than are permitted but some features (such as ) may raise . Ranges implement all of the common sequence operations except concatenation and repetition (due to the fact that range objects can only represent sequences that follow a strict pattern and repetition and concatenation will usually violate that pattern). The value of the start parameter (or if the parameter was not supplied) The value of the stop parameter The value of the step parameter (or if the parameter was not supplied) The advantage of the type over a regular or is that a object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the , and values, calculating individual items and subranges as needed). Range objects implement the ABC, and provide features such as containment tests, element index lookup, slicing and support for negative indices (see Sequence Types — list, tuple, range): Testing range objects for equality with and compares them as sequences. That is, two range objects are considered equal if they represent the same sequence of values. (Note that two range objects that compare equal might have different , and attributes, for example or .) Changed in version 3.2: Implement the Sequence ABC. Support slicing and negative indices. Test objects for membership in constant time instead of iterating through all items. Changed in version 3.3: Define ‘==’ and ‘!=’ to compare range objects based on the sequence of values they define (instead of comparing based on object identity).\n• None The linspace recipe shows how to implement a lazy version of range suitable for floating-point applications."
    },
    {
        "link": "https://realpython.com/python-data-structures",
        "document": "Data structures are the fundamental constructs around which you build your programs. Each data structure provides a particular way of organizing data so it can be accessed efficiently, depending on your use case. Python ships with an extensive set of data structures in its standard library.\n\nHowever, Python’s naming convention doesn’t provide the same level of clarity that you’ll find in other languages. In Java, a list isn’t just a —it’s either a or an . Not so in Python. Even experienced Python developers sometimes wonder whether the built-in type is implemented as a linked list or a dynamic array.\n• Which common abstract data types are built into the Python standard library\n• How the most common abstract data types map to Python’s naming scheme\n• How to put abstract data types to practical use in various algorithms\n\nIn Python, dictionaries (or dicts for short) are a central data structure. Dicts store an arbitrary number of objects, each identified by a unique dictionary key. Dictionaries are also often called maps, hashmaps, lookup tables, or associative arrays. They allow for the efficient lookup, insertion, and deletion of any object associated with a given key. Phone books make a decent real-world analog for dictionary objects. They allow you to quickly retrieve the information (phone number) associated with a given key (a person’s name). Instead of having to read a phone book front to back to find someone’s number, you can jump more or less directly to a name and look up the associated information. This analogy breaks down somewhat when it comes to how the information is organized to allow for fast lookups. But the fundamental performance characteristics hold. Dictionaries allow you to quickly find the information associated with a given key. Dictionaries are one of the most important and frequently used data structures in computer science. So, how does Python handle dictionaries? Let’s take a tour of the dictionary implementations available in core Python and the Python standard library. Because dictionaries are so important, Python features a robust dictionary implementation that’s built directly into the core language: the data type. Python also provides some useful syntactic sugar for working with dictionaries in your programs. For example, the curly-brace ({ }) dictionary expression syntax and dictionary comprehensions allow you to conveniently define new dictionary objects: There are some restrictions on which objects can be used as valid keys. Python’s dictionaries are indexed by keys that can be of any hashable type. A hashable object has a hash value that never changes during its lifetime (see ), and it can be compared to other objects (see ). Hashable objects that compare as equal must have the same hash value. Immutable types like strings and numbers are hashable and work well as dictionary keys. You can also use objects as dictionary keys as long as they contain only hashable types themselves. For most use cases, Python’s built-in dictionary implementation will do everything you need. Dictionaries are highly optimized and underlie many parts of the language. For example, class attributes and variables in a stack frame are both stored internally in dictionaries. Python dictionaries are based on a well-tested and finely tuned hash table implementation that provides the performance characteristics you’d expect: O(1) time complexity for lookup, insert, update, and delete operations in the average case. There’s little reason not to use the standard implementation included with Python. However, specialized third-party dictionary implementations exist, such as skip lists or B-tree–based dictionaries. Besides plain objects, Python’s standard library also includes a number of specialized dictionary implementations. These specialized dictionaries are all based on the built-in dictionary class (and share its performance characteristics) but also include some additional convenience features. Let’s take a look at them. Python includes a specialized subclass that remembers the insertion order of keys added to it: . Note: is not a built-in part of the core language and must be imported from the module in the standard library. While standard instances preserve the insertion order of keys in CPython 3.6 and above, this was simply a side effect of the CPython implementation and was not defined in the language spec until Python 3.7. So, if key order is important for your algorithm to work, then it’s best to communicate this clearly by explicitly using the class: odict_keys(['one', 'two', 'three', 'four']) Until Python 3.8, you couldn’t iterate over dictionary items in reverse order using . Only instances offered that functionality. Even in Python 3.8, and objects aren’t exactly the same. instances have a method that is unavailable on plain instance, as well as a more customizable method than the one plain instances. The class is another dictionary subclass that accepts a callable in its constructor whose return value will be used if a requested key cannot be found. This can save you some typing and make your intentions clearer as compared to using or catching a exception in regular dictionaries: # initializes it using the default factory, # i.e. list() in this example: The data structure groups multiple dictionaries into a single mapping. Lookups search the underlying mappings one by one until a key is found. Insertions, updates, and deletions only affect the first mapping added to the chain: ChainMap({'one': 1, 'two': 2}, {'three': 3, 'four': 4}) # ChainMap searches each collection in the chain # from left to right until it finds the key (or fails): File , line , in : is a wrapper around a standard dictionary that provides a read-only view into the wrapped dictionary’s data. This class was added in Python 3.3 and can be used to create immutable proxy versions of dictionaries. can be helpful if, for example, you’d like to return a dictionary carrying internal state from a class or module while discouraging write access to this object. Using allows you to put these restrictions in place without first having to create a full copy of the dictionary: File , line , in : # Updates to the original are reflected in the proxy: All the Python dictionary implementations listed in this tutorial are valid implementations that are built into the Python standard library. If you’re looking for a general recommendation on which mapping type to use in your programs, I’d point you to the built-in data type. It’s a versatile and optimized hash table implementation that’s built directly into the core language. I would recommend that you use one of the other data types listed here only if you have special requirements that go beyond what’s provided by . All the implementations are valid options, but your code will be clearer and easier to maintain if it relies on standard Python dictionaries most of the time.\n\nAn array is a fundamental data structure available in most programming languages, and it has a wide range of uses across different algorithms. In this section, you’ll take a look at array implementations in Python that use only core language features or functionality that’s included in the Python standard library. You’ll see the strengths and weaknesses of each approach so you can decide which implementation is right for your use case. But before we jump in, let’s cover some of the basics first. How do arrays work, and what are they used for? Arrays consist of fixed-size data records that allow each element to be efficiently located based on its index: Because arrays store information in adjoining blocks of memory, they’re considered contiguous data structures (as opposed to linked data structures like linked lists, for example). A real-world analogy for an array data structure is a parking lot. You can look at the parking lot as a whole and treat it as a single object, but inside the lot there are parking spots indexed by a unique number. Parking spots are containers for vehicles—each parking spot can either be empty or have a car, a motorbike, or some other vehicle parked on it. But not all parking lots are the same. Some parking lots may be restricted to only one type of vehicle. For example, a motor home parking lot wouldn’t allow bikes to be parked on it. A restricted parking lot corresponds to a typed array data structure that allows only elements that have the same data type stored in them. Performance-wise, it’s very fast to look up an element contained in an array given the element’s index. A proper array implementation guarantees a constant O(1) access time for this case. Python includes several array-like data structures in its standard library that each have slightly different characteristics. Let’s take a look. Lists are a part of the core Python language. Despite their name, Python’s lists are implemented as dynamic arrays behind the scenes. This means a list allows elements to be added or removed, and the list will automatically adjust the backing store that holds these elements by allocating or releasing memory. Python lists can hold arbitrary elements—everything is an object in Python, including functions. Therefore, you can mix and match different kinds of data types and store them all in a single list. This can be a powerful feature, but the downside is that supporting multiple data types at the same time means that data is generally less tightly packed. As a result, the whole structure takes up more space: ['one', 'hello', 'three'] Just like lists, tuples are part of the Python core language. Unlike lists, however, Python’s objects are immutable. This means elements can’t be added or removed dynamically—all elements in a tuple must be defined at creation time. Tuples are another data structure that can hold elements of arbitrary data types. Having this flexibility is powerful, but again, it also means that data is less tightly packed than it would be in a typed array: Python’s module provides space-efficient storage of basic C-style data types like bytes, 32-bit integers, floating-point numbers, and so on. Arrays created with the class are mutable and behave similarly to lists except for one important difference: they’re typed arrays constrained to a single data type. Because of this constraint, objects with many elements are more space efficient than lists and tuples. The elements stored in them are tightly packed, and this can be useful if you need to store many elements of the same type. Also, arrays support many of the same methods as regular lists, and you might be able to use them as a drop-in replacement without requiring other changes to your application code: File , line , in : must be real number, not str Python 3.x uses objects to store textual data as immutable sequences of Unicode characters. Practically speaking, that means a is an immutable array of characters. Oddly enough, it’s also a recursive data structure—each character in a string is itself a object of length 1. String objects are space efficient because they’re tightly packed and they specialize in a single data type. If you’re storing Unicode text, then you should use a string. Because strings are immutable in Python, modifying a string requires creating a modified copy. The closest equivalent to a mutable string is storing individual characters inside a list: File , line , in : File , line , in : # Strings can be unpacked into a list to objects are immutable sequences of single bytes, or integers in the range 0 ≤ x ≤ 255. Conceptually, objects are similar to objects, and you can also think of them as immutable arrays of bytes. Like strings, have their own literal syntax for creating objects and are space efficient. objects are immutable, but unlike strings, there’s a dedicated mutable byte array data type called that they can be unpacked into: # Bytes literals have their own syntax: File , line , in : bytes must be in range(0, 256) File , line , in : File , line , in : The type is a mutable sequence of integers in the range 0 ≤ x ≤ 255. The object is closely related to the object, with the main difference being that a can be modified freely—you can overwrite elements, remove existing elements, or add new ones. The object will grow and shrink accordingly. A can be converted back into immutable objects, but this involves copying the stored data in full—a slow operation taking O(n) time: # Bytearrays can grow and shrink in size: File , line , in : 'str' object cannot be interpreted as an integer File , line , in : byte must be in range(0, 256) # Bytearrays can be converted back into bytes objects: # (This will copy the data) There are a number of built-in data structures you can choose from when it comes to implementing arrays in Python. In this section, you’ve focused on core language features and data structures included in the standard library. If you’re willing to go beyond the Python standard library, then third-party packages like NumPy and pandas offer a wide range of fast array implementations for scientific computing and data science. If you want to restrict yourself to the array data structures included with Python, then here are a few guidelines:\n• If you need to store arbitrary objects, potentially with mixed data types, then use a or a , depending on whether or not you want an immutable data structure.\n• If you have numeric (integer or floating-point) data and tight packing and performance is important, then try out .\n• If you have textual data represented as Unicode characters, then use Python’s built-in . If you need a mutable string-like data structure, then use a of characters.\n• If you want to store a contiguous block of bytes, then use the immutable type or a if you need a mutable data structure. In most cases, I like to start out with a simple . I’ll only specialize later on if performance or storage space becomes an issue. Most of the time, using a general-purpose array data structure like gives you the fastest development speed and the most programming convenience. I’ve found that this is usually much more important in the beginning than trying to squeeze out every last drop of performance right from the start.\n\nCompared to arrays, record data structures provide a fixed number of fields. Each field can have a name and may also have a different type. In this section, you’ll see how to implement records, structs, and plain old data objects in Python using only built-in data types and classes from the standard library. Note: I’m using the definition of a record loosely here. For example, I’m also going to discuss types like Python’s built-in that may or may not be considered records in a strict sense because they don’t provide named fields. Python offers several data types that you can use to implement records, structs, and data transfer objects. In this section, you’ll get a quick look at each implementation and its unique characteristics. At the end, you’ll find a summary and a decision-making guide that will help you make your own picks. Note: This tutorial is adapted from the chapter “Common Data Structures in Python” in Python Tricks: The Book. If you enjoy what you’re reading, then be sure to check out the rest of the book. As mentioned previously, Python dictionaries store an arbitrary number of objects, each identified by a unique key. Dictionaries are also often called maps or associative arrays and allow for efficient lookup, insertion, and deletion of any object associated with a given key. Using dictionaries as a record data type or data object in Python is possible. Dictionaries are easy to create in Python as they have their own syntactic sugar built into the language in the form of dictionary literals. The dictionary syntax is concise and quite convenient to type. Data objects created using dictionaries are mutable, and there’s little protection against misspelled field names as fields can be added and removed freely at any time. Both of these properties can introduce surprising bugs, and there’s always a trade-off to be made between convenience and error resilience: Python’s tuples are a straightforward data structure for grouping arbitrary objects. Tuples are immutable—they can’t be modified once they’ve been created. Performance-wise, tuples take up slightly less memory than lists in CPython, and they’re also faster to construct. As you can see in the bytecode disassembly below, constructing a tuple constant takes a single opcode, while constructing a list object with the same contents requires several more operations: However, you shouldn’t place too much emphasis on these differences. In practice, the performance difference will often be negligible, and trying to squeeze extra performance out of a program by switching from lists to tuples will likely be the wrong approach. A potential downside of plain tuples is that the data you store in them can only be pulled out by accessing it through integer indexes. You can’t give names to individual properties stored in a tuple. This can impact code readability. Also, a tuple is always an ad-hoc structure: it’s difficult to ensure that two tuples have the same number of fields and the same properties stored in them. This makes it easy to introduce slip-of-the-mind bugs, such as mixing up the field order. Therefore, I would recommend that you keep the number of fields stored in a tuple as low as possible: File , line , in : # No protection against missing or extra fields Classes allow you to define reusable blueprints for data objects to ensure each object provides the same set of fields. Using regular Python classes as record data types is feasible, but it also takes manual work to get the convenience features of other implementations. For example, adding new fields to the constructor is verbose and takes time. Also, the default string representation for objects instantiated from custom classes isn’t very helpful. To fix that, you may have to add your own method, which again is usually quite verbose and must be updated each time you add a new field. Fields stored on classes are mutable, and new fields can be added freely, which you may or may not like. It’s possible to provide more access control and to create read-only fields using the decorator, but once again, this requires writing more glue code. Writing a custom class is a great option whenever you’d like to add business logic and behavior to your record objects using methods. However, this means that these objects are technically no longer plain data objects: # String representation is not very useful Data classes are available in Python 3.7 and above. They provide an excellent alternative to defining your own data storage classes from scratch. By writing a data class instead of a plain Python class, your object instances get a few useful features out of the box that will save you some typing and manual implementation work:\n• The syntax for defining instance variables is shorter, since you don’t need to implement the method.\n• Instances of your data class automatically get nice-looking string representation via an auto-generated method.\n• Instance variables accept type annotations, making your data class self-documenting to a degree. Keep in mind that type annotations are just hints that are not enforced without a separate type-checking tool. Data classes are typically created using the decorator, as you’ll see in the code example below: # Type annotations are not enforced without To learn more about Python data classes, check out the The Ultimate Guide to Data Classes in Python 3.7. The class available in Python 2.6+ provides an extension of the built-in data type. Similar to defining a custom class, using allows you to define reusable blueprints for your records that ensure the correct field names are used. objects are immutable, just like regular tuples. This means you can’t add new fields or modify existing fields after the instance is created. Besides that, objects are, well . . . named tuples. Each object stored in them can be accessed through a unique identifier. This frees you from having to remember integer indexes or resort to workarounds like defining integer constants as mnemonics for your indexes. objects are implemented as regular Python classes internally. When it comes to memory usage, they’re also better than regular classes and just as memory efficient as regular tuples: objects can be an easy way to clean up your code and make it more readable by enforcing a better structure for your data. I find that going from ad-hoc data types like dictionaries with a fixed format to objects helps me to express the intent of my code more clearly. Often when I apply this refactoring, I magically come up with a better solution for the problem I’m facing. Using objects over regular (unstructured) tuples and dicts can also make your coworkers’ lives easier by making the data that’s being passed around self-documenting, at least to a degree: Added in Python 3.6, is the younger sibling of the class in the module. It’s very similar to , with the main difference being an updated syntax for defining new record types and added support for type hints. Please note that type annotations are not enforced without a separate type-checking tool like mypy. But even without tool support, they can provide useful hints for other programmers (or be terribly confusing if the type hints become out of date): File , line , in : File , line , in : # Type annotations are not enforced without The class converts between Python values and C structs serialized into Python objects. For example, it can be used to handle binary data stored in files or coming in from network connections. Structs are defined using a mini language based on format strings that allows you to define the arrangement of various C data types like , , and as well as their variants. Serialized structs are seldom used to represent data objects meant to be handled purely inside Python code. They’re intended primarily as a data exchange format rather than as a way of holding data in memory that’s only used by Python code. In some cases, packing primitive data into structs may use less memory than keeping it in other data types. However, in most cases that would be quite an advanced (and probably unnecessary) optimization: # All you get is a blob of data: # Data blobs can be unpacked again: Here’s one more slightly obscure choice for implementing data objects in Python: . This class was added in Python 3.3 and provides attribute access to its namespace. This means instances expose all of their keys as class attributes. You can use dotted attribute access instead of the square-bracket indexing syntax that’s used by regular dicts. All instances also include a meaningful by default. As its name proclaims, is simple! It’s basically a dictionary that allows attribute access and prints nicely. Attributes can be added, modified, and deleted freely: As you’ve seen, there’s quite a number of different options for implementing records or data objects. Which type should you use for data objects in Python? Generally your decision will depend on your use case:\n• If you have only a few fields, then using a plain tuple object may be okay if the field order is easy to remember or field names are superfluous. For example, think of an point in three-dimensional space.\n• If you need immutable fields, then plain tuples, , and are all good options.\n• If you need to lock down field names to avoid typos, then and are your friends.\n• If you want to keep things simple, then a plain dictionary object might be a good choice due to the convenient syntax that closely resembles JSON.\n• If you need full control over your data structure, then it’s time to write a custom class with setters and getters.\n• If you need to add behavior (methods) to the object, then you should write a custom class, either from scratch, or using the decorator, or by extending or .\n• If you need to pack data tightly to serialize it to disk or to send it over the network, then it’s time to read up on because this is a great use case for it! If you’re looking for a safe default choice, then my general recommendation for implementing a plain record, struct, or data object in Python would be to use in Python 2.x and its younger sibling, in Python 3.\n\nIn this section, you’ll see how to implement mutable and immutable set and multiset (bag) data structures in Python using built-in data types and classes from the standard library. A set is an unordered collection of objects that doesn’t allow duplicate elements. Typically, sets are used to quickly test a value for membership in the set, to insert or delete new values from a set, and to compute the union or intersection of two sets. In a proper set implementation, membership tests are expected to run in fast O(1) time. Union, intersection, difference, and subset operations should take O(n) time on average. The set implementations included in Python’s standard library follow these performance characteristics. Just like dictionaries, sets get special treatment in Python and have some syntactic sugar that makes them easy to create. For example, the curly-brace set expression syntax and set comprehensions allow you to conveniently define new set instances: But be careful: To create an empty set you’ll need to call the constructor. Using empty curly-braces ( ) is ambiguous and will create an empty dictionary instead. Python and its standard library provide several set implementations. Let’s have a look at them. The type is the built-in set implementation in Python. It’s mutable and allows for the dynamic insertion and deletion of elements. Python’s sets are backed by the data type and share the same performance characteristics. Any hashable object can be stored in a set: The class implements an immutable version of that can’t be changed after it’s been constructed. objects are static and allow only query operations on their elements, not inserts or deletions. Because objects are static and hashable, they can be used as dictionary keys or as elements of another set, something that isn’t possible with regular (mutable) objects: File , line , in : # Frozensets are hashable and can # be used as dictionary keys: The class in the Python standard library implements a multiset, or bag, type that allows elements in the set to have more than one occurrence. This is useful if you need to keep track of not only if an element is part of a set, but also how many times it’s included in the set: One caveat for the class is that you’ll want to be careful when counting the number of elements in a object. Calling returns the number of unique elements in the multiset, whereas the total number of elements can be retrieved using : Sets are another useful and commonly used data structure included with Python and its standard library. Here are a few guidelines for deciding which one to use:\n• If you need a mutable set, then use the built-in type.\n• If you need hashable objects that can be used as dictionary or set keys, then use a .\n• If you need a multiset, or bag, data structure, then use .\n\nA stack is a collection of objects that supports fast Last-In/First-Out (LIFO) semantics for inserts and deletes. Unlike lists or arrays, stacks typically don’t allow for random access to the objects they contain. The insert and delete operations are also often called push and pop. A useful real-world analogy for a stack data structure is a stack of plates. New plates are added to the top of the stack, and because the plates are precious and heavy, only the topmost plate can be moved. In other words, the last plate on the stack must be the first one removed (LIFO). To reach the plates that are lower down in the stack, the topmost plates must be removed one by one. Performance-wise, a proper stack implementation is expected to take O(1) time for insert and delete operations. Stacks have a wide range of uses in algorithms. For example, they’re used in language parsing as well as runtime memory management, which relies on a call stack. A short and beautiful algorithm using a stack is depth-first search (DFS) on a tree or graph data structure. Python ships with several stack implementations that each have slightly different characteristics. Let’s take a look at them and compare their characteristics. Python’s built-in type makes a decent stack data structure as it supports push and pop operations in amortized O(1) time. Python’s lists are implemented as dynamic arrays internally, which means they occasionally need to resize the storage space for elements stored in them when elements are added or removed. The list over-allocates its backing storage so that not every push or pop requires resizing. As a result, you get an amortized O(1) time complexity for these operations. The downside is that this makes their performance less consistent than the stable O(1) inserts and deletes provided by a linked list–based implementation (as you’ll see below with ). On the other hand, lists do provide fast O(1) time random access to elements on the stack, and this can be an added benefit. There’s an important performance caveat that you should be aware of when using lists as stacks: To get the amortized O(1) performance for inserts and deletes, new items must be added to the end of the list with the method and removed again from the end using . For optimum performance, stacks based on Python lists should grow towards higher indexes and shrink towards lower ones. Adding and removing from the front is much slower and takes O(n) time, as the existing elements must be shifted around to make room for the new element. This is a performance antipattern that you should avoid as much as possible: The class implements a double-ended queue that supports adding and removing elements from either end in O(1) time (non-amortized). Because deques support adding and removing elements from either end equally well, they can serve both as queues and as stacks. Python’s objects are implemented as doubly-linked lists, which gives them excellent and consistent performance for inserting and deleting elements but poor O(n) performance for randomly accessing elements in the middle of a stack. Overall, is a great choice if you’re looking for a stack data structure in Python’s standard library that has the performance characteristics of a linked-list implementation: The stack implementation in the Python standard library is synchronized and provides locking semantics to support multiple concurrent producers and consumers. Besides , the module contains several other classes that implement multi-producer, multi-consumer queues that are useful for parallel computing. Depending on your use case, the locking semantics might be helpful, or they might just incur unneeded overhead. In this case, you’d be better off using a or a as a general-purpose stack: As you’ve seen, Python ships with several implementations for a stack data structure. All of them have slightly different characteristics as well as performance and usage trade-offs. If you’re not looking for parallel processing support (or if you don’t want to handle locking and unlocking manually), then your choice comes down to the built-in type or . The difference lies in the data structure used behind the scenes and overall ease of use. is backed by a dynamic array, which makes it great for fast random access but requires occasional resizing when elements are added or removed. The list over-allocates its backing storage so that not every push or pop requires resizing, and you get an amortized O(1) time complexity for these operations. But you do need to be careful to only insert and remove items using and . Otherwise, performance slows down to O(n). is backed by a doubly-linked list, which optimizes appends and deletes at both ends and provides consistent O(1) performance for these operations. Not only is its performance more stable, the class is also easier to use because you don’t have to worry about adding or removing items from the wrong end. In summary, is an excellent choice for implementing a stack (LIFO queue) in Python.\n\nIn this section, you’ll see how to implement a First-In/First-Out (FIFO) queue data structure using only built-in data types and classes from the Python standard library. A queue is a collection of objects that supports fast FIFO semantics for inserts and deletes. The insert and delete operations are sometimes called enqueue and dequeue. Unlike lists or arrays, queues typically don’t allow for random access to the objects they contain. Imagine a line of Pythonistas waiting to pick up their conference badges on day one of PyCon registration. As new people enter the conference venue and queue up to receive their badges, they join the line (enqueue) at the back of the queue. Developers receive their badges and conference swag bags and then exit the line (dequeue) at the front of the queue. Another way to memorize the characteristics of a queue data structure is to think of it as a pipe. You add ping-pong balls to one end, and they travel to the other end, where you remove them. While the balls are in the queue (a solid metal pipe) you can’t get at them. The only way to interact with the balls in the queue is to add new ones at the back of the pipe (enqueue) or to remove them at the front (dequeue). Queues are similar to stacks. The difference between them lies in how items are removed. With a queue, you remove the item least recently added (FIFO) but with a stack, you remove the item most recently added (LIFO). Performance-wise, a proper queue implementation is expected to take O(1) time for insert and delete operations. These are the two main operations performed on a queue, and in a correct implementation, they should be fast. Queues have a wide range of applications in algorithms and often help solve scheduling and parallel programming problems. A short and beautiful algorithm using a queue is breadth-first search (BFS) on a tree or graph data structure. Scheduling algorithms often use priority queues internally. These are specialized queues. Instead of retrieving the next element by insertion time, a priority queue retrieves the highest-priority element. The priority of individual elements is decided by the queue based on the ordering applied to their keys. A regular queue, however, won’t reorder the items it carries. Just like in the pipe example, you get out what you put in, and in exactly that order. Python ships with several queue implementations that each have slightly different characteristics. Let’s review them. It’s possible to use a regular as a queue, but this is not ideal from a performance perspective. Lists are quite slow for this purpose because inserting or deleting an element at the beginning requires shifting all the other elements by one, requiring O(n) time. Therefore, I would not recommend using a as a makeshift queue in Python unless you’re dealing with only a small number of elements: The class implements a double-ended queue that supports adding and removing elements from either end in O(1) time (non-amortized). Because deques support adding and removing elements from either end equally well, they can serve both as queues and as stacks. Python’s objects are implemented as doubly-linked lists. This gives them excellent and consistent performance for inserting and deleting elements, but poor O(n) performance for randomly accessing elements in the middle of the stack. As a result, is a great default choice if you’re looking for a queue data structure in Python’s standard library: The implementation in the Python standard library is synchronized and provides locking semantics to support multiple concurrent producers and consumers. The module contains several other classes implementing multi-producer, multi-consumer queues that are useful for parallel computing. Depending on your use case, the locking semantics might be helpful or just incur unneeded overhead. In this case, you’d be better off using as a general-purpose queue: is a shared job queue implementation that allows queued items to be processed in parallel by multiple concurrent workers. Process-based parallelization is popular in CPython due to the global interpreter lock (GIL) that prevents some forms of parallel execution on a single interpreter process. As a specialized queue implementation meant for sharing data between processes, makes it easy to distribute work across multiple processes in order to work around the GIL limitations. This type of queue can store and transfer any pickleable object across process boundaries: Python includes several queue implementations as part of the core language and its standard library. objects can be used as queues, but this is generally not recommended due to slow performance. If you’re not looking for parallel processing support, then the implementation offered by is an excellent default choice for implementing a FIFO queue data structure in Python. It provides the performance characteristics you’d expect from a good queue implementation and can also be used as a stack (LIFO queue).\n\nA priority queue is a container data structure that manages a set of records with totally-ordered keys to provide quick access to the record with the smallest or largest key in the set. You can think of a priority queue as a modified queue. Instead of retrieving the next element by insertion time, it retrieves the highest-priority element. The priority of individual elements is decided by the order applied to their keys. Priority queues are commonly used for dealing with scheduling problems. For example, you might use them to give precedence to tasks with higher urgency. Think about the job of an operating system task scheduler: Ideally, higher-priority tasks on the system (such as playing a real-time game) should take precedence over lower-priority tasks (such as downloading updates in the background). By organizing pending tasks in a priority queue that uses task urgency as the key, the task scheduler can quickly select the highest-priority tasks and allow them to run first. In this section, you’ll see a few options for how you can implement priority queues in Python using built-in data structures or data structures included in Python’s standard library. Each implementation will have its own upsides and downsides, but in my mind there’s a clear winner for most common scenarios. Let’s find out which one it is. You can use a sorted to quickly identify and delete the smallest or largest element. The downside is that inserting new elements into a list is a slow O(n) operation. While the insertion point can be found in O(log n) time using in the standard library, this is always dominated by the slow insertion step. Maintaining the order by appending to the list and re-sorting also takes at least O(n log n) time. Another downside is that you must manually take care of re-sorting the list when new elements are inserted. It’s easy to introduce bugs by missing this step, and the burden is always on you, the developer. This means sorted lists are only suitable as priority queues when there will be few insertions: # Remember to re-sort every time a new element is inserted, is a binary heap implementation usually backed by a plain , and it supports insertion and extraction of the smallest element in O(log n) time. This module is a good choice for implementing priority queues in Python. Since technically provides only a min-heap implementation, extra steps must be taken to ensure sort stability and other features typically expected from a practical priority queue: uses internally and shares the same time and space complexities. The difference is that is synchronized and provides locking semantics to support multiple concurrent producers and consumers. Depending on your use case, this might be helpful, or it might just slow your program down slightly. In any case, you might prefer the class-based interface provided by over the function-based interface provided by : Python includes several priority queue implementations ready for you to use. stands out from the pack with a nice object-oriented interface and a name that clearly states its intent. It should be your preferred choice. If you’d like to avoid the locking overhead of , then using the module directly is also a good option."
    },
    {
        "link": "https://stackoverflow.com/questions/55738301/how-can-i-optimize-loops-through-a-multidimensional-array",
        "document": "The logic looks sound, but we can optimize it a bit further using generators and comprehensions.\n\nLet's isolate the inner logic into a function called .\n\nForgive me if I am reading this wrong, but it looks like you are trying to find the index of the value closest to 3000? If so first we will make a generator that returns a tuple containing the index and the absolute value of \"variable - variable - 3000\":\n\nIn order to get the value we want, we wrap the whole thing in a function (with the key saying we want it sorted by the second value) and specify we want to get the index (i.e. the first value in the tuple returned by ):\n\nFor the value put into \"newd\" it looks like you are taking the root of the sum of the squares (i.e. its normalization or magnitude). Luckily numpy (which is what I assume \"np\" is) has a built-in-method for finding the magnitude/normalization of an array: np.linalg.norm. All we have to do is put the other values into an np.array and then call it on them:\n\nNow we can put the entire loop into a nested comprehension:\n\nUsing generators and comprehensions should speed things up over using for loops. But if you really want to crank things up we can use \"multiprocessing\". Specifically, a multiprocessing pool. In order to do so we will need to create a second function to handle each vector (this is due to restrictions on how multiprocessing pools work):\n\nYou can alter the number of \"processes\" created for the pool to see what gives you the best results."
    },
    {
        "link": "https://stackoverflow.com/questions/47876828/how-to-optimize-a-nested-for-loop-in-python",
        "document": "If you are not memory constrained, the first step to optimize nested loops in is to use broadcasting and perform operations in a vectorized way:\n\nBut while in this case looping occurs in C instead of Python it involves allocation of a size (N, N) array.\n\nBroadcasting is not a panacea, try to unroll the inner loop\n\nAs it was noted above broadcasting implies huge memory overhead. So it should be used with care and it is not always the right way. While you may have first impression to use it everywhere - do not. Not so long ago I was also confused by this fact, see my question Numpy ufuncs speed vs for loop speed. Not to be too verbose, I will show this on yours example:\n\nAs you can see for small-sized arrays broadcast version is 20x faster than unrolled, for medium-sized arrays they are rather equal, but for large-sized arrays it is 4x slower because memory overhead is paying its own costly price.\n\nAnother approach is to use and its magic powerful function-decorator. In this case, only slight modification of your initial code is necessary. Also to make loops parallel you should change to and provide keyword argument. In the snippet below I use the decorator which is the same as the :\n\nYou didn't provide function, but to run the code in mode you must also decorate function, or if it is a number pass it as an argument to the jitted function.\n\nPython scientific ecosystem is huge, I just mention some other equivalent options to speed up: , , , and many others. Perhaps you are interested in , but this is actually another story.\n\nOn my computer, unfortunately the old one, the timings are:\n\nIt can be seen that approach is 730x faster then your initial solution, and also 24.5x faster than solution (maybe you need Intel's Vector Math Library to accelerate it). Also simple approach with the inner loop unrolling gives you 60x speed up compared to your initial version. My specs are:\n\nI was surprised by your phrase \"I have heard (haven't yet tested) that indexing a numpy array using a python for loop is very slow.\" So I test:\n\nand it turns out that you are right. It is 2-5x faster to iterate over the list. Of course, these results must be taken with a certain amount of irony :)"
    },
    {
        "link": "https://geeksforgeeks.org/python-nested-loops",
        "document": "In Python programming language there are two types of loops which are for loop and while loop. Using these loops we can create nested loops in Python. Nested loops mean loops inside a loop. For example, while loop inside the for loop, for loop inside the for loop, etc.\n\nExample 1: Basic Example of Python Nested Loops\n\nExample 2: Printing multiplication table using Python nested for loops\n\nIn the above example what we do is take an outer for loop running from 2 to 3 for multiplication table of 2 and 3 and then inside that loop we are taking an inner for loop that will run from 1 to 10 inside that we are printing multiplication table by multiplying each iteration value of inner loop with the iteration value of outer loop as we see in the below output.\n\nExample 3: Printing using different inner and outer nested loops\n\nIn this example, we are initializing two lists with some strings. Store the size of list2 in ‘list2_Size’ using len() function and using it in the while loop as a counter. After that run an outer for loop to iterate over list1 and inside that loop run an inner while loop to iterate over list2 using list indexing inside that we are printing each value of list2 for every value of list1.\n\nIt is a type of loop control statement. In a loop, we can use the break statement to exit from the loop. When we use a break statement in a loop it skips the rest of the iteration and terminates the loop. let’s understand it using an example.\n\nThe above code is the same as in Example 2 In this code we are using a break statement inside the inner loop by using the if statement. Inside the inner loop if ‘i’ becomes equals to ‘j’ then the inner loop will be terminated and not executed the rest of the iteration as we can see in the output table of 3 is printed up to two iterations because in the next iteration ‘i’ becomes equal to ‘j’ and the loop breaks.\n\nA continue statement is also a type of loop control statement. It is just the opposite of the break statement. The continue statement forces the loop to jump to the next iteration of the loop whereas the break statement terminates the loop. Let’s understand it by using code.\n\nIn the above code instead of using a break statement, we are using a continue statement. Here when ‘i’ becomes equal to ‘j’ in the inner loop it skips the rest of the code in the inner loop and jumps on the next iteration as we see in the output “2 * 2 = 4” and “3 * 3 = 9” is not printed because at that point ‘i’ becomes equal to ‘j’.\n\nTo convert the multiline nested loops into a single line, we are going to use list comprehension in Python. List comprehension includes brackets consisting of expression, which is executed for each element, and the for loop to iterate over each element in the list.\n\nIn the above code, we are storing a list inside the list using list comprehension in the inner loop of list comprehension [j for j in range(3)] to make a list [0, 1, 2] for every iteration of the outer loop “for i in range(5)”.\n\nTime Complexity: O(n2) It is faster than nested loops\n\nWhat is a Nested Loop in Python?\n\nA nested loop in Python refers to a loop within another loop. The “inner loop” will be executed one time for each iteration of the “outer loop”. This structure is commonly used when you need to perform operations on multi-dimensional data structures like lists of lists, or when processing tasks that require multiple levels of looping. \n\n for j in range(1, 4): # Inner loop \n\n This will print pairs of and values, where is from the outer loop and from the inner.\n\nWhat are the 2 Main Types of Loops in Python?\n\nWhat are the 3 Types of Loops?\n\nHow Many Nested Loops are There?\n\nWhat is Nested Class in Python?"
    },
    {
        "link": "https://quora.com/What-are-some-ways-to-optimize-nested-loops-if-they-are-causing-slow-performance",
        "document": "Something went wrong. Wait a moment and try again."
    },
    {
        "link": "https://algocademy.com/link?problem=nested-loops&lang=py&solution=1",
        "document": "Binary Strings With At Most K Consecutive Ones in Python\n\nBinary Strings With At Most K Consecutive Ones in Python\n\nBinary Strings With K Ones On Even Positions in Python\n\nBinary Strings With K Ones On Even Positions in Python\n\nLongest Subarray With At Most K Distinct Integers in Python\n\nLongest Subarray With At Most K Distinct Integers in Python\n\nLongest Subarray With Sum At Most S in Python\n\nLongest Subarray With Sum At Most S in Python\n\nLongest Subarray With At Most K Distinct Integers in Python\n\nLongest Subarray With At Most K Distinct Integers in Python\n\nLongest Subarray With Sum At Most S in Python\n\nLongest Subarray With Sum At Most S in Python\n\nMinimum Value Of Three in Python\n\nMinimum Value Of Three in Python\n\nReducing If Else To Boolean Expression in Python\n\nReducing If Else To Boolean Expression in Python\n\nA nested loop has one loop inside of another. These are typically used for working with two dimensions such as printing stars in rows and columns as shown below. When a loop is nested inside another loop, the inner loop runs many times inside the outer loop. In each iteration of the outer loop, the inner loop will be re-started. The inner loop must finish all of its iterations before the outer loop can continue to its next iteration. for row in range(3): for col in range(5): print(\"*\", end='') print() # This code prints a rectangle with 3 rows and 5 columns, filled with '*' # We use print(\"*\", end='') because print() prints with a trailing newline by default Nested loops are also helpful when we want to iterate through a multi dimensional array, for example: arr = [[1, 2], [3, 4], [5, 6]] for i in range(len(arr)): for j in range(len(arr[i])): print(arr[i][j]) This outputs each sub-element in one at a time. Note that for the inner loop, we are using , since is itself an array. In a nested loop, a statement only stops the loop it is placed in. Therefore, if a is placed in the inner loop, the outer loop still continues. For example: arr = [[1, 2], [3, 4], [5, 6]] for i in range(len(arr)): for j in range(len(arr[i])): if arr[i][j] == 3: break print(arr[i][j]) # prints the numbers 1, 2, 5 and 6 on different lines When is and is , we execute the . This means we stop the inner loop and go back to the outer loop to continue from the next iteration, which is . And as you can see, we print all the elements of row 2. However, if the is placed in the outer loop, all of the looping stops. For example: arr = [[1, 2], [3, 4], [5, 6]] for i in range(len(arr)): if arr[i][0] == 3: break for j in range(len(arr[i])): print(arr[i][j]) # prints the numbers 1 and 2 on different lines Assignment\n\nFollow the Coding Tutorial and let's write some nested loops. Hint\n\n Look at the examples above if you get stuck.\n\nNested loops are a fundamental concept in programming, especially when dealing with multi-dimensional data structures or performing repetitive tasks within repetitive tasks. They are crucial for tasks such as matrix operations, image processing, and more. Understanding nested loops is essential for solving complex problems efficiently.\n\nAt its core, a nested loop is simply a loop inside another loop. The outer loop controls the number of complete iterations, while the inner loop runs through its entire cycle for each iteration of the outer loop. This structure is particularly useful for working with grids, tables, or any two-dimensional data.\n\nConsider the following simple example:\n\nIn this example, the inner loop runs twice for each iteration of the outer loop, resulting in a total of 6 print statements.\n\nLet's break down the key concepts and techniques involved in nested loops:\n• Outer Loop: Controls the number of iterations for the entire nested structure.\n• Inner Loop: Runs its full cycle for each iteration of the outer loop.\n• Loop Control Variables: Variables that control the number of iterations for each loop.\n\nHere's a more detailed example that prints a 3x3 grid of numbers:\n\nNested loops are particularly useful in scenarios such as:\n\nConsider the following example of iterating through a 2D list (matrix):\n\nThis code will output each element of the matrix in a grid format.\n\nWhen working with nested loops, it's important to avoid common mistakes such as:\n• Infinite Loops: Ensure that your loop control variables are correctly updated to avoid infinite loops.\n• Off-by-One Errors: Pay attention to the range of your loops to avoid missing elements or accessing out-of-bounds indices.\n• Clear Variable Names: Use descriptive names for loop control variables to improve code readability.\n• Limit Nesting Depth: Avoid deeply nested loops when possible, as they can be difficult to read and maintain.\n• Using Break and Continue: Control the flow of nested loops with break and continue statements.\n• Combining with Other Constructs: Use nested loops in combination with other control structures like if-else statements for more complex logic.\n\nFor example, using break in a nested loop:\n\nHere's a comprehensive example that demonstrates the use of nested loops to print a multiplication table:\n\nWhen debugging nested loops, consider the following tips:\n• Print Statements: Use print statements to track the values of loop control variables.\n• Step-by-Step Execution: Use a debugger to step through each iteration and observe the behavior.\n\nFor testing, write test cases that cover different scenarios, such as edge cases and typical use cases. For example:\n• Break Down the Problem: Divide the problem into smaller parts and solve each part individually.\n• Visualize the Process: Draw diagrams or use visual aids to understand the flow of nested loops.\n• Practice: Solve various problems and exercises to strengthen your understanding of nested loops.\n\nMastering nested loops is essential for tackling complex problems in programming. By understanding the basics, avoiding common pitfalls, and practicing regularly, you can become proficient in using nested loops effectively. Keep exploring and applying these concepts to real-world scenarios to enhance your problem-solving skills.\n\nFor further reading and practice, consider the following resources:\n• Python Official Documentation on For Statements"
    }
]