[
    {
        "link": "https://gstreamer.freedesktop.org/documentation/installing/on-linux.html",
        "document": "GStreamer is included in all Linux distributions. We recommend using the latest version of a fast moving distribution such as Fedora, Ubuntu (non-LTS), Debian sid or OpenSuse to get a recent GStreamer release.\n\nAll the commands given in this section are intended to be typed in from a terminal.\n\nThe only other “development environment” that is required is the compiler and a text editor. In order to compile code that requires GStreamer and uses the GStreamer core library, remember to add this string to your command:\n\nIf you're using other GStreamer libraries, e.g. the video library, you have to add additional packages after gstreamer-1.0 in the above string (gstreamer-video-1.0 for the video library, for example).\n\nIf your application is built with the help of libtool, e.g. when using automake/autoconf as a build system, you have to run the script from inside the environment.\n\nThe source code for the tutorials can be copied and pasted from the tutorial pages into a text file, but, for convenience, it is also available in a GIT repository in the subdirectory.\n\nThe GIT repository can be cloned with:\n\nAnd then compile it with:\n\nUsing the file name of the tutorial you are interested in ( in this example).\n\nDepending on the GStreamer libraries you need to use, you will have to add more packages to the command, besides At the bottom of each tutorial's source code you will find the command for that specific tutorial, including the required libraries, in the required order. When developing your own applications, the GStreamer documentation will tell you what library a function belongs to.\n\nTo run the tutorials, simply execute the desired tutorial:"
    },
    {
        "link": "https://linuxfromscratch.org/blfs/view/7.7/multimedia/gstreamer.html",
        "document": ""
    },
    {
        "link": "https://gstreamer.freedesktop.org/documentation/installing/index.html",
        "document": "Building from source using Cerbero – Setting up a development environment the modern way\n\nBuilding from source using Meson – Setting up a development environment the modern way"
    },
    {
        "link": "https://bbs.archlinux.org/viewtopic.php?id=93248",
        "document": "Thanks for your reply. Could not find any plugins. Pl. see below\n\n[san2ban@SANJAY ~]$ sudo pacman -Sy gstreamer0.10 plug-ins\n\nPassword: \n\n:: Synchronizing package databases...\n\n core 36.2K 10.6K/s 00:00:03 [##################################] 100%\n\n extra 445.9K 15.7K/s 00:00:28 [##################################] 100%\n\n community 368.4K 15.3K/s 00:00:24 [##################################] 100%\n\nwarning: gstreamer0.10-0.10.28-1 is up to date -- reinstalling\n\nplug-ins package not found, searching for group...\n\nerror: 'plug-ins': not found in sync db\n\n[san2ban@SANJAY ~]$ sudo pacman -Sy gstreamer0.10 plugins\n\n:: Synchronizing package databases...\n\n core is up to date\n\n extra is up to date\n\n community is up to date\n\nwarning: gstreamer0.10-0.10.28-1 is up to date -- reinstalling\n\nplugins package not found, searching for group...\n\nerror: 'plugins': not found in sync db\n\n[san2ban@SANJAY ~]$ sudo pacman -Sy gstreamer plugins\n\n:: Synchronizing package databases...\n\n core is up to date\n\n extra is up to date\n\n community is up to date\n\ngstreamer package not found, searching for group...\n\nerror: 'gstreamer': not found in sync db\n\n[san2ban@SANJAY ~]$"
    },
    {
        "link": "https://linuxfromscratch.org/blfs/view/7.4/multimedia/gstreamer.html",
        "document": ""
    },
    {
        "link": "https://doc.qt.io/qt-5/qaudiooutput.html",
        "document": "The QAudioOutput class provides an interface for sending audio data to an audio output device. More...\n\nYou can construct an audio output with the system's default audio output device. It is also possible to create QAudioOutput with a specific QAudioDeviceInfo. When you create the audio output, you should also send in the QAudioFormat to be used for the playback (see the QAudioFormat class description for details). Starting to play an audio stream is simply a matter of calling start() with a QIODevice. QAudioOutput will then fetch the data it needs from the io device. So playing back an audio file is as simple as: sourceFile; audio; { sourceFile setFileName( ); sourceFile open( ReadOnly); format; format setSampleRate( ); format setChannelCount( ); format setSampleSize( ); format setCodec( ); format setByteOrder( LittleEndian); format setSampleType( UnSignedInt); info( defaultOutputDevice()); ( info isFormatSupported(format)) { qWarning() \"Raw audio format not supported by backend, cannot play audio.\" ; ; } audio (format ); connect(audio SIGNAL(stateChanged( State)) SLOT(handleStateChanged( State))); audio start( sourceFile); } The file will start playing assuming that the audio system and output device support it. If you run out of luck, check what's up with the error() function. After the file has finished playing, we need to stop the device: At any given time, the QAudioOutput will be in one of four states: active, suspended, stopped, or idle. These states are described by the QAudio::State enum. State changes are reported through the stateChanged() signal. You can use this signal to, for instance, update the GUI of the application; the mundane example here being changing the state of a button. You request a state change directly with suspend(), stop(), reset(), resume(), and start(). While the stream is playing, you can set a notify interval in milliseconds with setNotifyInterval(). This interval specifies the time between two emissions of the notify() signal. This is relative to the position in the stream, i.e., if the QAudioOutput is in the SuspendedState or the IdleState, the notify() signal is not emitted. A typical use-case would be to update a slider that allows seeking in the stream. If you want the time since playback started regardless of which states the audio output has been in, elapsedUSecs() is the function for you. If an error occurs, you can fetch the error type with the error() function. Please see the QAudio::Error enum for a description of the possible errors that are reported. When an error is encountered, the state changes to QAudio::StoppedState. You can check for errors by connecting to the stateChanged() signal:\n\nSee also QAudioInput and QAudioDeviceInfo.\n\nConstruct a new audio output and attach it to parent. The device referenced by audioDevice is used with the output format parameters. Construct a new audio output and attach it to parent. The default audio output device is used with the output format parameters. This signal is emitted when a certain interval of milliseconds of audio data has been processed. The interval is set by setNotifyInterval(). This signal is emitted when the device state has changed. This is the current state of the audio output. This will release any system resources used and free any buffers. If called before start(), returns platform default value. If called before start() but setBufferSize() was called prior, returns value set by setBufferSize(). If called after start(), returns the actual buffer size being used. This may not be what was set previously by setBufferSize(). Returns the number of free bytes available in the audio buffer. Note: The returned value is only valid while in QAudio::ActiveState or QAudio::IdleState state, otherwise returns zero. Returns the audio category of this audio stream. Some platforms can group audio streams into categories and manage their volumes independently, or display them in a system mixer control. You can set this property to allow the platform to distinguish the purpose of your streams. Returns the microseconds since start() was called, including time in Idle and Suspend states. Returns the QAudioFormat being used. Returns the period size in bytes. This is the amount of data required each period to prevent buffer underrun, and to ensure uninterrupted playback. Note: It is recommended to provide at least enough data for a full period with each write operation. Returns the amount of audio data processed since start() was called (in microseconds). Drops all audio data in the buffers, resets buffers to zero. Sets error() to QAudio::NoError. Sets state() to QAudio::ActiveState if you previously called start(QIODevice*). Sets state() to QAudio::IdleState if you previously called start(). emits stateChanged() signal. Sets the audio buffer size to value in bytes. Note: This function can be called anytime before start(). Calls to this are ignored after start(). It should not be assumed that the buffer size set is the actual buffer size used - call bufferSize() anytime after start() to return the actual buffer size being used. Sets the audio category of this audio stream to category. Some platforms can group audio streams into categories and manage their volumes independently, or display them in a system mixer control. You can set this property to allow the platform to distinguish the purpose of your streams. Not all platforms support audio stream categorization. In this case, the function call will be ignored. Changing an audio output stream's category while it is opened will not take effect until it is reopened. Sets the interval for notify() signal to be emitted. This is based on the ms of audio data processed, not on wall clock time. The minimum resolution of the timer is platform specific and values should be checked with notifyInterval() to confirm the actual value being used. The volume is scaled linearly from (silence) to (full volume). Values outside this range will be clamped. Note: Adjustments to the volume will change the volume of this audio stream, not the global volume. UI volume controls should usually be scaled nonlinearly. For example, using a logarithmic scale will produce linear changes in perceived loudness, which is what a user would normally expect from a volume control. See QAudio::convertVolume() for more details. Starts transferring audio data from the device to the system's audio output. The device must have been opened in the ReadOnly or ReadWrite modes. If the QAudioOutput is able to successfully output audio data, state() returns QAudio::ActiveState, error() returns QAudio::NoError and the stateChanged() signal is emitted. If a problem occurs during this process, error() returns QAudio::OpenError, state() returns QAudio::StoppedState and the stateChanged() signal is emitted. Returns a pointer to the internal QIODevice being used to transfer data to the system's audio output. The device will already be open and write() can write data directly to it. Note: The pointer will become invalid after the stream is stopped or if you start another stream. If the QAudioOutput is able to access the system's audio device, state() returns QAudio::IdleState, error() returns QAudio::NoError and the stateChanged() signal is emitted. If a problem occurs during this process, error() returns QAudio::OpenError, state() returns QAudio::StoppedState and the stateChanged() signal is emitted. Stops the audio output, detaching from the system resource. Sets error() to QAudio::NoError, state() to QAudio::StoppedState and emit stateChanged() signal. Sets error() to QAudio::NoError, state() to QAudio::SuspendedState and emits stateChanged() signal. Returns the volume between 0.0 and 1.0 inclusive."
    },
    {
        "link": "https://doc.qt.io/qt-5/qtmultimedia-index.html",
        "document": "Qt Multimedia is an essential module that provides a rich set of QML types and C++ classes to handle multimedia content. It also provides necessary APIs to access the camera and radio functionality. The included Qt Audio Engine provides types for 3D positional audio playback and content management.\n\nThe functionality of this module is divided into the following submodules:\n\nThe QML types can be imported into your applciation using the following import statement in your file.\n\nIf you intend to use the C++ classes in your application, include the C++ definitions using the following directive:\n\nTo link against the corresponding C++ libraries, add the following to your project file:\n\nThe following is a list of important QML types and C++ classes provided by this module:\n\nThe Qt Quick Multimedia module is available under commercial licenses from The Qt Company. In addition, it is available under free software licenses. Since Qt 5.4, these free software licenses are GNU Lesser General Public License, version 3, or the GNU General Public License, version 2. See Qt Licensing for further details.\n\nThe Qt Multimedia Backends wiki provides a summary of features supported by each platform plugin made available by this module. The following topics provide more platform-specific information."
    },
    {
        "link": "https://felgo.com/doc/qt5/qtmultimedia-multimedia-audiooutput-example",
        "document": "Audio Output demonstrates the basic use cases of QAudioOutput.\n\nThis example provides a tone generator to supply continuous audio playback. The first button allows pause and resume of the playback, and the second button allows toggling between push and pull modes of operation.\n\nTo run the example from Qt Creator, open the Welcome mode and select the example from Examples. For more information, visit Building and Running an Example."
    },
    {
        "link": "https://felgo.com/doc/qt/audiooverview",
        "document": "Qt Multimedia offers a range of audio classes that cover both low and high level approaches to: audio input, output and processing.\n\nFor playing media or audio files that are not simple, uncompressed audio, you can use the QMediaPlayer C++ class, or the MediaPlayer QML type. The QMediaPlayer class and associated QML types are also capable of playing video, if required.\n\nSee Supported Media Formats for more detail.\n\nThe media player needs to be connected to a QAudioOutput object (or the QML AudioOutput element) to play back audio.\n\nHere is how you play a local file using C++:\n\nThe same functionality in QML:\n\nTo record audio to a file, you need to create a capture session and connect to it an audio input and a recorder. These elements are implemented with the QMediaCaptureSession, QAudioInput, and QMediaRecorder classes. The default constructed QAudioInput selects the system default audio input. The recorder controls the recording process with a simple record() and stop() functions. Additionally, you can use it to select the output location, audio encoder, or file container format.\n\nA session recording audio from the default microphone would look as follows in C++:\n\nIn QML, the same can be achieved by:\n\nQMediaCaptureSession also provides support for more complex use cases such as image capturing or video recording.\n\nIn addition to raw access to sound devices, the QSoundEffect class (and SoundEffect QML type) offers a more abstract way to play sounds. This class allows you to specify a WAV format file, which can then be played with low latency when necessary.\n\nYou can adjust the:\n• Number of loops in which a sound effect is played.\n\nThe C++ API of Qt Multimedia offers classes for raw access to audio input and output facilities, allowing applications to receive raw data from devices like microphones, and to write raw data to speakers or other devices. Generally these classes do not do any audio decoding, or other processing, but they can support different types of raw audio data.\n\nThe QAudioSink class offers raw audio data output, while QAudioSource offers raw audio data input. The available hardware determines what audio outputs and inputs are available.\n\nThe low level audio classes can operate in two modes - and . In mode, the audio device is started by giving it a QIODevice. For an output device, the QAudioSink class will pull data from the QIODevice (using QIODevice::read()) when more audio data is required. Conversely, for mode with QAudioSource, when audio data is available then the data will be written directly to the QIODevice.\n\nIn mode, the audio device provides a QIODevice instance that can be written or read to as needed. Typically, this results in simpler code but more buffering, which may affect latency.\n\nIn some cases you may want to decode a compressed audio file and do further processing yourself. For example, mixing multiple samples or using custom digital signal processing algorithms. QAudioDecoder supports decoding local files or data streams from QIODevice instances.\n\nHere's an example of decoding a local file:\n\nThe Qt Spatial Audio module provides an API for implementation sound fields in 3D space."
    },
    {
        "link": "https://stackoverflow.com/questions/45426930/play-sound-file-with-c-and-qt-5",
        "document": "How can I play a sound file using Qt 5 and C++? I have tried but I am told it does not workin Ubuntu (my current Operating System) and I have heard of but the library does not seem to be available in my Qt Package."
    }
]