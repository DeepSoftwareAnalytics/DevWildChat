[
    {
        "link": "https://pillow.readthedocs.io",
        "document": "Pillow is the friendly PIL fork by Jeffrey A. Clark and contributors. PIL is the Python Imaging Library by Fredrik Lundh and contributors.\n\nPillow for enterprise is available via the Tidelift Subscription. Learn more."
    },
    {
        "link": "https://pillow.readthedocs.io/en/stable/reference/Image.html",
        "document": "The module provides a class with the same name which is used to represent a PIL image. The module also provides a number of factory functions, including functions to load images from files, and to create new images.\n\nInstances of the class have the following attributes: The filename or path of the source file. Only images created with the factory function have a filename attribute. If the input is a file like object, the filename attribute is set to an empty string. The file format of the source file. For images created by the library itself (via a factory function, or by running a method on an existing image), this attribute is set to . Image mode. This is a string specifying the pixel format used by the image. Typical values are “1”, “L”, “RGB”, or “CMYK.” See Modes for a full list. Image size, in pixels. The size is given as a 2-tuple (width, height). Colour palette table, if any. If mode is “P” or “PA”, this should be an instance of the class. Otherwise, it should be set to . A dictionary holding data associated with the image. This dictionary is used by file handlers to pass on various non-image information read from the file. See documentation for the various file handlers for details. Most methods ignore the dictionary when returning new images; since the keys are not standardized, it’s not possible for a method to know if the operation affects the dictionary. If you need the information later on, keep a reference to the info dictionary returned from the open method. Unless noted elsewhere, this dictionary does not affect saving files. if this image has more than one frame, or otherwise. This attribute is only defined by image plugins that support animated images. Plugins may leave this attribute undefined if they don’t support loading animated images, even if the given format supports animated images. Given that this attribute is not present for all images use to check if Pillow is aware of multiple frames in an image regardless of its format. The number of frames in this image. This attribute is only defined by image plugins that support animated images. Plugins may leave this attribute undefined if they don’t support loading animated images, even if the given format supports animated images. Given that this attribute is not present for all images use to check the number of frames that Pillow is aware of in an image regardless of its format. Determine if an image has transparency data, whether in the form of an alpha channel, a palette with an alpha channel, or a “transparency” key in the info dictionary. Note the image might still appear solid, if all of the values shown within are opaque."
    },
    {
        "link": "https://realpython.com/image-processing-with-the-python-pillow-library",
        "document": "Python Pillow allows you to manipulate images and perform basic image processing tasks. As a fork of the Python Imaging Library (PIL), Pillow supports image formats like JPEG, PNG, and more, enabling you to read, edit, and save images. With Python Pillow, you can crop, resize, rotate, and apply filters to images, making it a versatile tool for image manipulation.\n\nPillow is often used for high-level image processing tasks and exploratory work. While not the fastest library, it offers a gentle learning curve and a comprehensive set of features for basic to intermediate image processing needs. You can enhance its capabilities by integrating it with NumPy for pixel-level manipulations and creating animations.\n\nBy the end of this tutorial, you’ll understand that:\n• Python Pillow is used for image manipulation and basic image processing.\n• Pillow offers reasonable speed for its intended use cases.\n• PIL is the original library, while Pillow is its actively maintained fork.\n• You read an image in Python Pillow using from the PIL module.\n• Pillow is used for its ease of use, versatility, and integration with NumPy.\n\nWith these insights, you’re ready to dive into the world of image processing with Python Pillow. You’ll use several images in this tutorial, which you can download from the tutorial’s image repository:\n\nWith these images in hand, you’re now ready to get started with Pillow.\n\nThe Python Pillow library is a fork of an older library called PIL. PIL stands for Python Imaging Library, and it’s the original library that enabled Python to deal with images. PIL was discontinued in 2011 and only supports Python 2. To use its developers’ own description, Pillow is the friendly PIL fork that kept the library alive and includes support for Python 3. There’s more than one module in Python to deal with images and perform image processing. If you want to deal with images directly by manipulating their pixels, then you can use NumPy and SciPy. Other popular libraries for image processing are OpenCV, scikit-image, and Mahotas. Some of these libraries are faster and more powerful than Pillow. However, Pillow remains an important tool for dealing with images. It provides image processing features that are similar to ones found in image processing software such as Photoshop. Pillow is often the preferred option for high-level image processing tasks that don’t require more advanced image processing expertise. It’s also often used for exploratory work when dealing with images. Pillow also has the advantage of being widely used by the Python community, and it doesn’t have the same steep learning curve as some of the other image processing libraries. You’ll need to install the library before you can use it. You can install Pillow using within a virtual environment: Now that you’ve installed the package, you’re ready to start familiarizing yourself with the Python Pillow library and perform basic manipulations of images. The Module and Class in Pillow The main class defined in Pillow is the class. When you read an image using Pillow, the image is stored in an object of type . For the code in this section, you’ll need the image file named (image credit), which you can find in the image repository for this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. You can place this image file in the project folder that you’re working in. When exploring images with Pillow, it’s best to use an interactive REPL environment. You’ll start by opening the image that you just downloaded: You might expect to import from Pillow instead of from PIL. You did install , after all, not . However, Pillow is a fork of the PIL library. Therefore, you’ll still need to use when importing into your code. You call the function to read the image from the file and to read the image into memory so that the file can now be closed. You use a statement to create a context manager to ensure the file is closed as soon as it’s no longer needed. In this example, the object is a JPEG image-specific type that’s a subclass of the class, as you confirm with the call to . Note that both the class and the module where the class is defined share the same name, . You can display the image using : The method saves the image as a temporary file and displays it using your operating system’s native software for dealing with images. When you run the code above, you’ll see the following image displayed: On some systems, calling will block the REPL until you close the image. This depends on the operating system and the default image viewing software that you’re using. You’ll need to be familiar with three key properties when dealing with images in the Python Pillow library. You can explore these using the class attributes , , and : The format of an image shows what type of image you’re dealing with. In this case, the format of the image is . The size shows the width and height of the image in pixels. The mode of this image is . You’ll learn more about modes shortly. Often, you may need to crop and resize images. The class has two methods that you can use to perform these operations, and : The argument to must be a 4-tuple that defines the left, upper, right, and bottom edges of the region that you wish to crop. The coordinate system used in Pillow assigns the coordinates (0, 0) to the pixel in the upper-left corner. This is the same coordinate system that’s usually used for two-dimensional arrays. The 4-tuple represents the following section of the image: The new image that returns in the code above has a size of pixels. The cropped image shows only one of the buildings from the original picture: In the code above, you also change the resolution of the cropped image using , which needs a tuple as a required argument. The tuple that you use as an argument defines the new width and height of the image in pixels. In the example above, you’re setting the new width and height to a quarter of their original values using the floor division operator ( ) and the attributes and . The final call to displays the cropped and resized image: There are additional optional parameters that you can use with to control how the image is resampled. Alternatively, you can achieve similar scaling using : The argument determines the factor by which you scale the image down. If you prefer to set a maximum size rather than a scaling factor, then you can use . The size of the thumbnail will be smaller than or equal to the size that you set. Note: The method changes the object in place and doesn’t return a new object. However, , , and all return a new object. Not all methods in the Pillow library behave in the same way. Once you’re happy with your returned image, you can save any of the objects to file using : Once you call the method, it creates the image files in your project folder. In this example, one of the images is a JPEG image and the other is a PNG image. The extension that you use as a filname automatically determines the file format, or you can specify the format as an additional optional argument. You can manipulate the image beyond cropping and resizing. Another common requirement is to rotate or flip the image. You can use the method for some transformations. Go ahead and carry on with the same REPL session that you started in the previous section: This code displays the following image: There are seven options that you can pass as arguments to :\n• : Flips the image left to right, resulting in a mirror image\n• : Rotates the image by 270 degrees counterclockwise, which is the same as 90 degrees clockwise\n• : Transposes the rows and columns using the top-left pixel as the origin, with the top-left pixel being the same in the transposed image as in the original image\n• : Transposes the rows and columns using the bottom-left pixel as the origin, with the bottom-left pixel being the one that remains fixed between the original and modified versions All the rotation options above define rotations in steps of 90 degrees. If you need to rotate an image by another angle, then you can use : This method call rotates the image by 45 degrees counterclockwise, giving the following image: The object returned is the same size as the original . Therefore, the corners of the image are missing in this display. You can change this behavior using the named parameter: This method returns a larger image that fully contains the rotated image: You can customize the rotation further with additional optional parameters. You can now change the size and orientation of an image. In the next section, you’ll learn about different types of images in the Python Pillow library. Bands and Modes of an Image in the Python Pillow Library An image is a two-dimensional array of pixels, where each pixel corresponds to a color. Each pixel can be represented by one or more values. For example, in an RGB image, each pixel is represented by three values corresponding to the red, green, and blue values for that pixel. Therefore, the object for an RBG image contains three bands, one for each color. An RGB image of size pixels is represented by a array of values. RGBA images also include the alpha value, which contains information about the transparency for each pixel. An RGBA image has four bands, one for each of the colors and a fourth one containing the alpha values. Each band has the same dimensions as the image dimensions. Therefore, an RGBA image of size pixels is represented by a array of values. The mode of an image describes what type of image you’re working with. Pillow supports most standard modes, including black-and-white (binary), grayscale, RGB, RGBA, and CMYK. You can see the full list of supported modes in the Pillow documentation on modes. You can find out how many bands are in an object using the method, and you can convert between modes using . Now you’ll use the image named (image credit) from the image repository for this tutorial: This image’s mode is also RGB. You can convert this image into other modes. This code uses the same REPL session that you started in the previous sections: You call twice to convert the RGB image into a CMYK and a grayscale version. The CMYK image looks similar to the original image but is encoded using the mode that’s common for printed material rather than digital displays. The conversion to grayscale gives the following output: The outputs from the calls to confirm that there are three bands in the RGB image, four bands in the CMYK image, and one band in the grayscale image. You can separate an image into its bands using and combine separate bands back into an object using . When you use , the method returns all the bands as separate objects. You can confirm this by displaying the string representation of one of the objects returned: The mode of the object that returns is , indicating this is a grayscale image, or an image that only displays the luminance values of each pixel. Now, you can create three new RGB images showing the red, green, and blue channels separately using , which is a function in the module: The first argument in determines the mode of the image that you want to create. The second argument contains the individual bands that you want to merge into a single image. The red band alone, stored in the variable , is a grayscale image with mode L. To create the image showing only the red channel, you merge the red band from the original image with green and blue bands that only contain zeros. To create a band containing zeros everywhere, you use the method. This method needs a function as an argument. The function that you use determines how each point transforms. In this case, you use a function to map each point to . When you merge the red band with green and blue bands containing zeros, you get an RGB image called . Therefore, the RGB image that you create only has non-zero values in the red channel, but because it’s still an RGB image, it’ll display in color. You also repeat a similar process to obtain and , which contain RGB images with the green and blue channels from the original image. The code displays the following three images: The red image contains a strong signal in the pixels that represent the strawberry, because these pixels are mostly red. The green and blue channels show these pixels as dark because they have small values. The exceptions are those pixels that represent the reflection of the light on the surface of the strawberry as these pixels are nearly white. Creating the side-by-side displays shown in this tutorialShow/Hide In this tutorial, when there are several images output in the code that need to be displayed next to one another to make comparisons easier, the images are displayed side by side rather than as separate images. These side-by-side displays were created using Pillow itself. You can use the function , shown below, to merge several images into a single display: The first parameter in uses the unpacking operator ( ) so that any number of objects of type can be used as input arguments. The keyword parameter can be set to if you want to tile the images vertically rather than horizontally. This function assumes that all images have the same size. The overall size of the display is calculated from the size of the images and the number of images used. You then create a new object with the same mode as the original images and with the size of the overal display. The loop pastes the images that you input when you call the function into the final display. The function returns the final object containing all the images side by side. The image in the main article showing the three color channels for the strawberry image was obtained by calling the function as follows: This function was used to generate all the displays that show more than one image in this tutorial.\n\nYou’ve learned how to crop and rotate images, resize them, and extract color bands from color images. However, none of the actions that you’ve taken so far have made any changes to the content of the image. In this section, you’ll learn about image processing features in the Python Pillow library. You’ll use the module in Pillow. One of the methods that’s used in image processing is image convolution using kernels. The aim of this tutorial is not to give a detailed explanation of image processing theory. If you’re interested in the science of image processing, one of the best resources that you can use is Digital Image Processing by Gonzalez and Woods. In this section, you’ll learn the basics of how you can use convolution kernels to perform image processing. But what’s a convolution kernel? A kernel is a matrix: You can consider a simple image to understand the process of convolution using kernels. The image has a size of pixels and contains a vertical line and a dot. The line is four pixels wide, and the dot consists of a pixel square. The image below is enlarged for display purposes: You can place the kernel anywhere on the image and use the location of the kernel’s central cell as a reference. The diagram below is a representation of the top-left portion of the image: The elements in this diagram represent different aspects of the image and the kernel:\n• The white squares represent pixels in the image that have a value of .\n• The red squares represent pixels in the image that have a value of . These make up the dot in the image shown above.\n• Each purple region represents the kernel. This kernel consists of a region, and each cell in the kernel has a value of . The diagram shows the kernel in three different positions labeled 1, 2, and 3. A new image can be created as a result of the convolution of the image with the kernel. You can understand the convolution process through the following steps:\n• Locate kernel: Consider one of the kernel locations and look at the image pixels covered by the kernel’s nine cells.\n• Multiply kernel and pixel values: Multiply the values in each of the kernel’s cells with the corresponding pixel values in the image. You’ll have nine values from the nine multiplications.\n• Sum results of multiplications: Add those nine values together. The result will be the value of the pixel in the new image that has the same coordinates as the kernel’s center pixel.\n• Repeat for all pixels: Repeat the process for every pixel in the image, moving the kernel each time so that the kernel’s central cell corresponds to a different image pixel each time. You can see this process with the three kernel positions labeled 1, 2, and 3 in diagram above. Consider the kernel position labeled 1. The position of this kernel is , which is the position of its central cell because it’s in the fourth row (index = ) and the third column (index = ). Each image pixel in the region covered by the kernel has a value of zero. Therefore, all the multiplications from step 2 will be zero, and their addition will also be zero. The new image will have a value of zero at pixel . The scenario is different for the other kernel positions shown. Next, consider the kernel labeled 2, located at . One of the image pixels overlapping this is not zero. The multiplication of this pixel value with the kernel value will give . The eight remaining multiplications are still zero because the image pixels are zero. Therefore, the value of the pixel at position in the new image will be . The third kernel position illustrated above is at . There are four non-zero image pixels overlapping with this kernel. Each one has a value of , so the multiplication result will again be for each of those pixel positions. The overall result for this kernel position is . The new image will have this value at . The diagram and the discussion above only consider three kernel positions. The convolution process repeats this process for every possible kernel position in the image. This gives a value for each pixel position in the new image. The result of the convolution is shown on the right in the following image, with the original image on the left: The kernel that you used is a box blur kernel. The factor of is there so that the overall weighting of the kernel is . The result of the convolution is a blurred version of the original image. There are other kernels that perform different functions, including different blurring methods, edge detection, sharpening, and more. The Python Pillow library has several built-in kernels and functions that’ll perform the convolution described above. You don’t need to understand the math of filtering through convolution to use these filters, but it always helps to know what’s happening behind the scenes when using these tools. The next sections will look at the kernels and image filtering capabilities available in the module in Pillow. You’ll return to using the image of the buildings that you used at the beginning of this tutorial. You can start a new REPL session for this section: In addition to , you also import the module from Pillow. You can use the method to apply filtering to the image. This method needs a convolution kernel as its argument, and you can use one of the several kernels available in the module in Pillow. The first set of filters that you’ll learn about deal with blurring, sharpening, and smoothing an image. You can blur the image using the predefined filter: The displayed image is a blurred version of the original one. You can zoom in to observe the difference in more detail using and then display the images again using : The two cropped images show the difference between the two versions: You can customize the type and amount of blurring that you need using or : You can see the three blurred images below, shown in the same order as in the code above: The filter is similar to the one described in the previous section introducing convolution kernels. The argument is the radius of the box blur filter. In the earlier section discussing kernels, the box blur filter that you used was a filter. This means that it had a radius of , because the filter extends by one pixel from the center. The blurred images show that the box blur filter with a radius of produces an image that’s more blurred than the image generated by the box blur filter with radius . You can also use the filter, which uses a Gaussian blur kernel. The Gaussian kernel puts more weight on the pixels at the center of the kernel than those at the edges, and this leads to smoother blurring than what’s obtained with the box blur. For this reason, Gaussian blurring can give better results in many cases. What if you want to sharpen an image? In that case, you can use the filter and compare the result with the original image: You’re comparing a cropped version of both images showing a small portion of the building. The sharpened image is on the right: Perhaps instead of sharpening an image, you need to smooth it. You can achieve this by passing as an argument for : Below, you can see the original image on the left and the smoothed image on the right: You’ll see an application of the smooth filter in the next section, in which you’ll learn about more filters in the module. These filters act on the edges of objects in the image. When you look at an image, it’s relatively easy to determine the edges of objects within that image. It’s also possible for an algorithm to detect edges automatically using edge detection kernels. The module in Pillow has a predefined kernel to achieve this. In this section, you’ll use the image of the buildings again and convert it to grayscale before you apply the edge detection filter. You can carry on with the REPL session from the previous section: The result is an image showing the edges from the original image: This filter identifies the edges in the image. You can obtain a better outcome by applying the filter before finding the edges: You can see a comparison of the original grayscale image and the two edge detection results below. The version with smoothing before edge detection is shown at the bottom: You can also enhance the edges of the original image with the filter: You used the smoothed version of the grayscale image to enhance the edges. A portion of the original grayscale image and the image with the edges enhanced are shown side by side below. The image with edge enhancement is on the right: Another predefined filter in that deals with object edges is . You can pass it as an argument to as you did with the other filters in this section: You’re using the smoothed, grayscale version as a starting point for this filter. You can see the embossed image below, which shows a different effect using the edges in the image: In this section, you’ve learned about several filters available in the module that you can apply to images. There are other filters that you can use to process images. You can see a list of all the filters available in the documentation.\n\nImage Segmentation and Superimposition: An Example In this section, you’ll use the image files named (image credit) and (image credit), which you can find in the image repository for this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. You can use the Python Pillow library to extract the cat from the first image and place it on the floor of the monastery courtyard. You’ll use a number of image processing techniques to achieve this. You’ll start by working on . You’ll need to remove the picture of the cat from the background using image segmentation techniques. In this example, you’ll segment the image using thresholding techniques. First, you can crop the image to a smaller one to remove some of the background. You can start a new REPL session for this project: The cropped image contains the cat and some of the background that’s too close to the cat for you to crop it: Each pixel in a color image is represented digitally by three numbers corresponding to the red, green, and blue values of that pixel. Thresholding is the process of converting all the pixels to either the maximum or minimum value depending on whether they’re higher or lower than a certain number. It’s easier to do this on a grayscale image: You achieve thresholding by calling to convert each pixel in the grayscale image into either or . The conversion depends on whether the value in the grayscale image is greater or smaller than the threshold value. The threshold value in this example is . The figure below shows the grayscale image and the result from the thresholding process: In this example, all the points in the grayscale image that had a pixel value greater than are converted to white, and all other pixels are changed to black. You can change the sensitivity of the thresholding process by varying the threshold value. Thresholding can be used to segment images when the object to segment is distinct from the background. You can achieve better results with versions of the original image that have higher contrast. In this example, you can achieve higher contrast by thresholding the blue channel of the original image rather than the grayscale image, because the dominant colors in the background are brown and green colors, which have a weak blue component. You can extract the red, green, and blue channels from the color image as you did earlier: The red, green, and blue channels are shown below, from left to right. All three are displayed as grayscale images: The blue channel has a higher contrast between the pixels representing the cat and those representing the background. You can use the blue channel image to threshold: You use a threshold value of in this example. You also convert the image into a binary mode using as an argument to . The pixels in a binary image can only have the values of or . Note: When dealing with certain image formats, such as JPEG, that rely on lossy compression, the images may vary slightly depending on which JPEG decoders you’re using. Different operating systems often come with different default JPEG decoders. Therefore, the results that you get when processing images may vary depending on the operating system and JPEG decoder that you’re using. You may need to slightly adjust the threshold value if your results do not match the ones shown in this tutorial. The result of thresholding is the following: You can identify the cat in this black-and-white image. However, you’d like to have an image in which all the pixels that correspond to the cat are white and all other pixels are black. In this image, you still have black regions in the area which corresponds to the cat, such as where the eyes, nose and mouth are, and you also still have white pixels elsewhere in the image. You can use the image processing techniques called erosion and dilation to create a better mask that represents the cat. You’ll learn about these two techniques in the next section. You can look at the image file called , which you can download from the repository linked to this tutorial: The left-hand side of this binary image shows a white dot on a black background, while the right-hand side shows a black hole in a solid white section. Erosion is the process of removing white pixels from the boundaries in an image. You can achieve this in a binary image by using as an argument for the method. This filter replaces the value of a pixel with the minimum value of the nine pixels in the array centered around the pixel. In a binary image, this means that a pixel will have the value of zero if any of its neighboring pixels are zero. You can see the effect of erosion by applying several times to the image. You should continue with the same REPL session as in the previous section: You’ve applied the filter three times using a loop. This code gives the following output: The dot has shrunk but the hole has grown as a result of erosion. Dilation is the opposite process to erosion. White pixels are added to the boundaries in a binary image. You can achieve dilation by using , which converts a pixel to white if any of its neighbors are white. You can apply dilation to the same image containing a dot and a hole, which you can open and load again: The dot has now grown bigger, and the hole has shrunk: You can use erosion and dilation together to fill in holes and remove small objects from a binary image. Using the image with a dot and hole, you can perform ten erosion cycles to remove the dot, followed by ten dilation cycles to restore the hole to its original size: You perform ten erosion cycles with the first loop. The image at this stage is the following: The dot has disappeared, and the hole is larger than it was in the original image. The second loop performs ten dilation cycles, which return the hole to its original size: However, the dot is no longer present in the image. The erosions and dilations have modified the image to keep the hole but remove the dot. The number of erosions and dilations needed depends on the image and what you want to achieve. Often, you’ll need to find the right combination through trial and error. You can define functions to perform several cycles of erosion and dilation: These functions make it easier to experiment with erosion and dilation for an image. You’ll use these functions in the next section as you continue working on placing the cat into the monastery. You can use a sequence of erosions and dilations on the threshold image that you obtained earlier to remove parts of the mask that don’t represent the cat and to fill in any gaps in the region containing the cat. Once you’ve experimented with erosion and dilation, you’ll be able to use educated guesses in a trial-and-error process to find the best combination of erosions and dilations to achieve the ideal mask. Starting with the image , which you obtained earlier, you can start with a series of erosions to remove the white pixels that represent the background in the original image. You should continue working in the same REPL session as in the previous sections: The eroded threshold image no longer contains white pixels representing the background of the image: However, the remaining mask is smaller than the overall outline of the cat and has holes and gaps within it. You can perform dilations to fill the gaps: The fifty-eight cycles of dilation filled all the holes in the mask to give the following image: However, this mask is too big. You can therefore finish the process with a series of erosions: The result is a mask that you can use to segment the image of the cat: You can avoid the sharp edges of a binary mask by blurring this mask. You’ll have to convert it from a binary image into a grayscale image first: The filter returns the following mask: The mask now looks like a cat! Now you’re ready to extract the image of the cat from its background: First, you create a blank image with the same size as . You create a new object from by using and setting all values to zero. Next, you use the function in to create an image made up from both and using to determine which parts of each image are used. The composite image is shown below: You’ve segmented the image of the cat and extracted the cat from its background. You can go a step further and paste the segmented image of the cat into the image of the monastery courtyard from the image repository for this tutorial: You’ve used to paste an image onto another one. This method can be used with three arguments:\n• The first argument is the image that you want to paste in. You’re resizing the image to one-fifth of its size using the integer division operator ( ).\n• The second argument is the location in the main image where you want to paste the second picture. The tuple includes the coordinates within the main image where you want to place the top-left corner of the image that you’re pasting in.\n• The third argument provides the mask that you wish to use if you don’t want to paste the entire image. You’ve used the mask that you obtained from the process of thresholding, erosion, and dilation to paste the cat without its background. The output is the following image: You’ve segmented the cat from one image and placed it into another image to show the cat sitting quietly in the monastery courtyard rather than in the field where it was sitting in the original image. Your final task in this example is to add the Real Python logo as a watermark to the image. You can get the image file with the Real Python logo from the repository accompanying this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. You should continue working in the same REPL session: This is the full-size logo in color: You can change the image to grayscale and threshold it using to transform it into a black-and-white image. You also reduce its size and transform it into a contour image: The output shows the contour from the Real Python logo. The contour is ideal for using as a watermark on your image: To use this as a watermark, you’ll need to reverse the colors so that the background is black and only the outline that you want to keep is white. You can achieve this using again: You’ve converted the pixels that had a value of and assigned them the value , converting them from white to black pixels. You set the remaining pixels to white. The reversed outline logo is shown below: Your final step is to paste this outline onto the image of the cat sitting in the monastery courtyard. You can use again: The first argument in indicates the image that you wish to paste in, and the third argument represents the mask. In this case, you’re using the same image as a mask because the image is a binary image. The second argument provides the top-left coordinates of the region where you want to paste the image. The watermark has a rectangular outline, which is a result of the contour filter that you used earlier. If you prefer to remove this outline, you can crop the image using . This is an exercise that you can try on your own.\n\nPillow has an extensive selection of built-in functions and filters. However, there are times when you need to go further and manipulate images beyond the features that are already available in Pillow. You can manipulate the image further with the help of NumPy. NumPy is a very popular Python library for dealing with numeric arrays, and it’s an ideal tool to use with Pillow. You can learn more about NumPy in NumPy Tutorial: Your First Steps Into Data Science in Python. When you convert an image into a NumPy array, you can perform any transformations that you require directly on the pixels in the array. Once you’ve completed your processing in NumPy, you can convert the array back into an object using Pillow. You need to install NumPy for this section: Now that you’ve installed NumPy, you’re ready to use Pillow and NumPy to spot the difference between two images. Using NumPy to Subtract Images From Each Other See if you can spot the differences between the following two images: This isn’t a hard one! However, you decide to cheat and write a Python program to solve the puzzle for you. You can download the image files and (image credit) from the repository accompanying this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. Your first step is to read the images using Pillow and convert them to NumPy arrays: Since and are objects of type , you can manipulate them using all the tools that you have available in NumPy. You can subtract one array from the other to show the pixels that differ between the two images: When you subtract an array from another one of the same size, the result is another array with the same shape as the original arrays. You can convert this array into an image using in Pillow: The result of subtracting one NumPy array from another and converting into a Pillow is the difference image shown below: The difference image only shows three regions from the original image. These regions highlight the differences between the two images. You can also see some noise surrounding the cloud and the fence, which is due to small changes in the original JPEG compression in the region surrounding these items. You can go further and create images from scratch using NumPy and Pillow. You can start by creating a grayscale image. In this example, you’ll create a simple image containing a square, but you can create more elaborate images in the same way: You create an array of size containing zeros everywhere. Next, you set the value of a set of pixels at the center of the array to . You can index NumPy arrays using both rows and columns. In this example, the first slice, , represents the rows to . The second slice, , which follows the comma, represents the columns to . You can use to convert the NumPy array into an object of type . The output from the code above is shown below: You’ve created a grayscale image containing a square. The mode of the image is inferred automatically when you use . In this case, mode is used, which corresponds to an image with 32-bit floating-point pixels. You can convert this to a simpler grayscale image with 8-bit pixels if you wish: You can also go further and create a color image. You can repeat the process above to create three images, one corresponding to the red channel, another to the green, and a final one corresponding to the blue channel: You create an object from each NumPy array and convert the images to mode , which represents grayscale. Now, you can combine these three separate images into one RGB image using : The first argument in is the mode of the image output. The second argument is a sequence with the individual single-band images. This code creates the following image: You’ve combined the separate bands into an RGB color image. In the next section, you’ll go a step further and create a GIF animation using NumPy and Pillow. In the previous section, you created a color image containing three overlapping squares of different colors. In this section, you’ll create an animation showing those three squares merging into a single white square. You’ll create several versions of the images containing three squares, and the location of the squares will vary slightly between successive images: You create an empty list called , which you’ll use to store the various images that you generate. Within the loop, you create NumPy arrays for the red, green, and blue channels, as you did in the previous section. The array containing the green layer is always the same and represents a square in the center of the image. The red square starts in a position displaced to the top-left of the center. In each successive frame, the red square moves closer to the center until it reaches the center in the final iteration of the loop. The blue square is initially shifted toward the bottom-right then moves towards the center with each iteration. Note that in this example, you’re iterating over , which means that the variable increases in steps of two. You learned earlier that you can save an object to file using . You can use the same function to save to a GIF file that includes a sequence of images. You call on the first image in the sequence, which is the first image that you stored in the list : The first argument in is the filename for the file that you want to save. The extension in the filename tells what file format it needs to output. You also include two keyword arguments in :\n• ensures that all the images in the sequence are saved, and not just the first one.\n• allows you to append the remaining images in the sequence to the GIF file. This code saves to file, and you can then open the GIF file with any image software. The GIF should loop by default, but on some systems you’ll need to add the keyword argument to to make sure the GIF loops. The animation that you get is the following one: The three squares with different colors merge into a single white square. Can you create your own animation using different shapes and different colors?"
    },
    {
        "link": "https://geeksforgeeks.org/python-pillow-tutorial",
        "document": "sinceDigital Image processing means processing the image digitally with the help of a computer. Using image processing we can perform operations like enhancing the image, blurring the image, extracting text from images, and many more operations. There are various ways to process images digitally. Here we will discuss the Pillow module of Python. Python Pillow is built on the top of PIL (Python Image Library) and is considered as the fork for the same as PIL has been discontinued since 2011. Pillow supports many image file formats including BMP, PNG, JPEG, and TIFF. The library encourages adding support for newer formats in the library by creating new file decoders.\n\nThis article aims at providing information about Python Pillow from basics to advance with the help of well-explained concepts and examples. So, let’s not waste any of the time and dive deep into the Pillow.\n\nPython Pillow does not come in-built with Python. To install it type the below command in the terminal.\n\nAfter installation let’s get started using the pillow module.\n\nThe Pillow module provides the open() and show() function to read and display the image respectively. For displaying the image Pillow first converts the image to a .png format (on Windows OS) and stores it in a temporary buffer and then displays it. Therefore, due to the conversion of the image format to .png some properties of the original image file format might be lost (like animation). Therefore, it is advised to use this method only for test purposes.\n\nImage Used for all the below Examples:\n\nRefer to the below articles to get detailed information about opening and displaying images.\n\nGetting information about the opened image\n\nGetting the Size, and format of the Image\n• size attribute provides the size of the image. It returns a tuple that contains width and height.\n• format attribute returns the format of the image file.\n\nRefer to the below article to get detailed information about Getting the Size, and format of the Image\n• None Finding the Size Resolution of Image in Python\n• None How to find width and height of an image using Python?\n\nGetting Color mode of the image\n\nThe mode attribute of the image tells the type and depth of the pixel in the image. A 1-bit pixel has a range of 0-1, and an 8-bit pixel has a range of 0-255. There are different modes provided by this module. A few of them are:\n\nrotate() method of the Image class is used to rotate the image by a particular angle counterclockwise around its center. After rotating the image, the sections of the image having no pixel values are filled with black (for non-alpha images) and with completely transparent pixels (for images supporting transparency).\n\nRefer to the below articles to get detailed information about rotating the image.\n• None How to rotate an image using Python?\n\nImage.transpose() is used to transpose the image (flip or rotate in 90 degree steps).\n\nKeywords FLIP_TOP_BOTTOM and FLIP_LEFT_RIGHT will be passed to transpose method to flip it.\n\nRefer to the below articles to get detailed information about flipping images.\n• None How to flip an image horizontally or vertically in Python?\n\nImage.resize() returns a resized copy of the image. Interpolation happens during the resize process, due to which the quality of image changes whether it is being upscaled (resized to a higher dimension than original) or downscaled (resized to a lower Image then original). Therefore resize() should be used cautiously and while providing suitable value for resampling argument.\n\nRefer to the below article to get detailed information about resizing images.\n• None Change the ratio between width and height of an image using Python – Pillow\n\nImage.save() saves the image under the given filename. If no format is specified, the format to use is determined from the filename extension, if possible. You can use a file object instead of a filename. In this case, you must always specify the format. The file object must implement the seek, tell, and write methods, and be opened in binary mode.\n\nTill now, we have learned the basics of pillow now let’s start with some complex operations like blurring the image of merging two images or even creating a thumbnail. So let’s get started by merging images.\n\nImage.merge() is used to merge a set of single band images into a new multiband image.\n\nNote: We will be using Image.split() method to split the image into individual bands.\n\nMerging Two or More Images\n\nUsing the merge() method we can also merge two or more images. We have to select two images of the same size or we can resize the image. Then using the new() function we will create a new image and will paste all the images there. See the below example for a better understanding.\n\nRefer to the below articles to get detailed information about merging images.\n• None How to merge images with same size using the Python 3 module pillow?\n• None Python | Copy and Paste Images onto other Image using Pillow\n• None How to merge a transparent PNG image with another image using PIL?\n\nImage.thumbnail() convert the image into a thumbnail. This method modifies the image to contain a thumbnail version of itself, no larger than the given size. This method calculates an appropriate thumbnail size to preserve the aspect of the image, calls the draft() method to configure the file reader (where applicable), and finally resizes the image.\n\nNote: This function modifies the Image object in place. If you need to use the full resolution image as well, apply this method to a copy() of the original image.\n\nRefer to the below articles to get detailed information about creating thumbnails.\n\nCropping is the process of selecting only a part of the image. The crop() method is used to crop a rectangular portion of any image.\n\nRefer to the below articles to get detailed information about Cropping images.\n• None Cropping an Image in a circular way\n\nIf a blurred image is observed carefully then a common thing to notice is that image is smooth meaning edges are not observed. A filter used for blurring is also called a low pass filter because it allows the low frequency to enter and stop high frequency. The ImageFilter class in the pillow library provides various filters that can be applied using the filter() method. Let’s see some of the blurring filters provided by the pillow.\n\nThis method blurs the image using the kernel matrix or through the convolution matrix. It can be applied using the BLUR parameter.\n\nNote: For more information refer, What is Image Blurring\n\nThe Gaussian filter is implemented as an Odd sized Symmetric Kernel (DIP version of a Matrix) which is passed through each pixel of the Region of Interest to get the desired effect. The kernel is not hard towards drastic color changed (edges) due to the pixels towards the center of the kernel having more weightage towards the final value than the periphery. A Gaussian filter could be considered as an approximation of the Gaussian Function (mathematics). The Pillow module provides the predefined gaussianblur kernel that does the underlying maths for us.\n\nBox blur is also known as box linear filter. Box blurs are frequently used to approximate Gaussian blur. A box blur is generally implemented as an image effect that affects the whole screen. The blurred color of the current pixel is the average of the current pixel’s color and its 8 neighboring pixels. Pillow provides the BoxBlur() method to do the same.\n\nRefer to the below articles to get detailed information about blurring images.\n• None Apply a Gauss filter to an image with Python\n\nPillow provides the ImageDraw module that provides simple 2D graphics for Image objects. You can use this module to create new images, annotate or retouch existing images, and generate graphics on the fly for web use. Let’s see various figures or texts that we can draw on the image.\n\nAdding text to an image can sometimes be very necessary as it can be used to provide some useful information to the image or can also be used to add a digital signature to the image. With pillow, we can easily add a text to any image. Let’s see the below example.\n• ImageFont to specify font and font size. This step is optional. It is for those who want their text to look cool or stylish because someone won’t select any font style then the system takes the default font style.\n• ImageFont truetype() as it needs two parameters that are (“font type”, size)\n• text() function of draw object and pass the four-parameters (Point of starting for text, “sample text”, Color, ImageFont object).\n\nRefer to the below articles to get detailed information about adding texts to the image.\n\nImageDraw.Draw.multiline_text() is used to draws the string at the given position.\n\nImageDraw.Draw.line() is used to draws a line between the coordinates in the xy list.\n\nImageDraw.Draw.rectangle() is used to draw a rectangle.\n\nImageDraw.Draw.polygon() is used to draw a polygon. The polygon outline consists of straight lines between the given coordinates, plus a straight line between the last and the first coordinate.\n\nPython Pillow provides the ImageEnhance module to adjust the color, brightness, contrast, and sharpness of the image.\n\nImageEnhance.Color() and ImageEnhance.Contrast() methods are used to adjust the color and contrast of the image respectively.\n• ImageEnhance.Color() is used to adjust the color balance of an image, in a manner similar to the controls on a color TV set. An enhancement factor of 0.0 gives a black and white image. A factor of 1.0 gives the original image.\n• ImageEnhance.Contrast() is used to control the contrast of an image, similar to the contrast control on a TV set. An enhancement factor of 0.0 gives a solid grey image. A factor of 1.0 gives the original image.\n\nRefer to the below articles to get detailed information about enhancing color and contrast.\n\nImageEnhance.Brightness() and ImageEnhance.Sharpness() methods are used to adjust the brightness and sharpness of the image.\n• ImageEnhance.Brightness() is used to control the brightness of an image. An enhancement factor of 0.0 gives a black image. A factor of 1.0 gives the original image.\n• ImageEnhance.Sharpness() is used to adjust the sharpness of an image. An enhancement factor of 0.0 gives a blurred image, a factor of 1.0 gives the original image, and a factor of 2.0 gives a sharpened image.\n\nRefer to the below articles to get detailed information about enhancing the brightness and sharpness of the image.\n• None Convert the .GIF to .BMP and it’s vice-versa in Python\n• None Convert an image into jpg format using Pillow in Python\n• None Convert files from jpg to png and vice versa using Python\n• None Convert the .PNG to .GIF and it’s vice-versa in Python\n• None Convert files from jpg to gif and vice versa using Python\n• None Add padding to the image with Python – Pillow\n• None Find most used colors in image using Python\n• None Overlay an image on another image in Python\n• None Spot the difference between two images using Python\n• None How to Extract Text from Images with Python?\n• None How to compress images using Python and PIL?\n• None Python | OCR on All the Images present in a Folder Simultaneously\n• None Apply changes to all the images in given folder – Using Python PIL"
    },
    {
        "link": "https://pypi.org/project/pillow",
        "document": "A required part of this site couldn’t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser."
    },
    {
        "link": "https://blog.pythonlibrary.org/2021/02/23/drawing-shapes-on-images-with-python-and-pillow",
        "document": "Pillow provides a drawing module called that you can use to create simple 2D graphics on your objects. According to Pillow’s documentation, “you can use this module to create new images, annotate or retouch existing images, and to generate graphics on the fly for web use.”\n\nIf you need more advanced drawing capabilities than what is included in Pillow, you can get a separate package called aggdraw.\n\nYou will focus on what comes with Pillow in this article. Specifically, you will learn about the following:\n\nWhen drawing with Pillow, it uses the same coordinate system that you have been using with the rest of Pillow. The upper left corner is still (0,0), for example. If you draw outside of the image bounds, those pixels will be discarded.\n\nIf you want to specify a color, you can use a series of numbers or tuples as you would when using . For “1”, “L”, and “I” images, use integers. For “RGB” images, use a 3-tuple containing integer values. You may also use the color names that are supported by Pillow that you learned about in chapter 2.\n\nWhen you go to use the various drawing methods, you will discover that they have a lot of common parameters that they share. Rather than explain the same parameters in every section, you will learn about them up-front!\n\nMost of the drawing methods have an parameter that sets a rectangular area in which to draw a figure. This can be defined in the following two ways:\n\nWhen it comes to drawing a line, polygon, or point, multiple coordinates are specified in either of these ways:\n\nThe method will draw a straight line, connecting each point. The will draw a polygon where each point is connected. Finally, the will draw a point of 1-pixel at each point.\n\nThe parameter, , is used to set the color that will fill the shape. The way you set the is determined by the mode of the image:\n• : Set each color value (0-255) using (R, G, B) or a color name\n• (grayscale): Set a value (0-255) as an integer\n\nThe default is or no fill.\n\nThe sets the border color of your drawing. Its specification is the same as the one you use for .\n\nThe default is , which means no border.\n\nNow that you know about the common parameters, you can move on and learn how to start drawing!\n\nThe first type of drawing you will learn about is how to draw lines in Pillow. All shapes are made up of lines. In Pillow’s case, a line is drawn by telling Pillow the beginning and ending coordinates to draw the line between. Alternatively, you can pass in a series of XY coordinates and Pillow will draw lines to connect the points.\n\nFollowing is the method definition:\n\nYou can see that it accepts several different parameters. You learned what some of these parameters mean in the previous section. The parameter is used to control the width of the lines.\n\nBefore you learn how to use , you should learn how to draw lines without it. But first, you will need an image to draw on. You will use this image of one of the Madison County bridges:\n\nNow go open up your Python editor and create a new file named and add this code to it:\n\nHere you open up the image in Pillow and then pass the object to , which returns an object. Now you can draw lines on your image. In this case, you use a loop to draw five lines on the image. The beginning image starts at (0,0) in the first loop. Then the X position changes in each iteration. The endpoint is the size of the image.\n\nYou use the module to choose a random color from a list of colors. When you run this code, the output will look something like this:\n\nNow you can try creating a series of points and drawing lines that way. Create a new file named and put this code in your file:\n\nThis time you create an image using Pillow rather than drawing on one of your own. Then you create a list of points. To make the line connections look nicer, you can set the parameter to “curve”. If you look at the source code for the method, you will find that “curve” is the only valid value to give it other than . This may change in a future version of Pillow.\n\nWhen you run this code, your image will look like this:\n\nNow try removing the parameter from your code and re-run the example. Your output will now look like this:\n\nBy setting to “curve”, the output will be slightly more pleasing to the eye.\n\nNow you’re ready to learn about drawing arcs with Pillow!\n\nAn arc is a curved line. You can draw arcs with Pillow too. Here is the method specification:\n\nAn can also be made using points. The parameter defines the starting angle, in degrees. The parameter tells Pillow what the ending angle is, which is also in degrees. The other two parameters are ones that have already been introduced.\n\nTo see how you might draw an arc, create a new file named and add this code to it:\n\nIn this code, you create a new image with a white background. Then you create your object. Next, you create two different arcs. The first arc will be filled with green. The second arc will be filled in yellow, but its line width will be 5. When you draw an arc, the fill is referring to the arc’s line color. You aren’t filling the arc itself.\n\nWhen you run this code, your output image will look like this:\n\nTry changing some of the parameters and re-running the code to see how you can change the arcs yourself.\n\nNow let’s move on and learn about drawing chords!\n\nPillow also supports the concept of chords. A chord is the same as an arc except that the endpoints are connected with a straight line.\n\nHere is the method definition of :\n\nThe only difference here is that you can also add an color. This color can be specified in any of the ways that you can specify a color.\n\nCreate a new file and name it . Then add this code so you can see how you make chords yourself:\n\nThis example will draw two chords on a green image. The first chord is filled in with a red color. The second chord is filled in with yellow but is outlined in blue. The blue outline has a width of 5.\n\nWhen you run this code, you will create the following image:\n\nThat looks pretty good. Go ahead and play around with this example too. You’ll soon master chord making with Pillow with a little practice.\n\nNow let’s continue and learn about drawing ellipses!\n\nAn ellipse, or oval, is drawn in Pillow by giving it a bounding box (xy). You have seen this several other times in previous sections.\n\nHere is the method definition:\n\nThe lets you fill it with a color, add a colored border ( ) and change the of that .\n\nTo see how you can create an , make a new file named and add this code to it:\n\nIn this code, you create a nice white image via the method. Then you draw a red ellipse on top of it. Finally, you draw a second ellipse that is filled with yellow and outlined in black where the outline width is set to 5.\n\nWhen you run this code, the image it creates will look like this:\n\nYou can create ovals and circles using . Give it a try and see what you can do with it.\n\nNow let’s find out how to create pie slices!\n\nA pie slice is the same as , but also draws straight lines between the endpoints and the center of the bounding box.\n\nHere is how the method is defined:\n\nYou have used all of these parameters in other drawings. To review, adds color to the inside of the while adds a colored border to the figure.\n\nTo start practicing this shape, create a new file named and add this code to your file:\n\nIn this code, you generate a grey image to draw on. Then you create two pie slices. The first is filled in with green. The second one is not filled in, but it does have a yellow . Note that each has a different starting and ending degree.\n\nWhen you run this code, you will get the following image:\n\nWith a little work, you could create a pie graph using Pillow! You should play around with your code a bit and change some values. You will quickly learn how to make some nice pie slices of your own.\n\nNow let’s find out how to draw polygons with Pillow!\n\nA polygon is a geometric shape that has a number of points (vertices) and an equal number of line segments or sides. A square, triangle, and hexagon are all types of polygons. Pillow lets you create your own polygons. Pillow’s documentation defines a polygon like this: The polygon outline consists of straight lines between the given coordinates, plus a straight line between the last and the first coordinate.\n\nHere is the code definition of the method:\n\nAll of these parameters should be familiar to you now. Go ahead and create a new Python file and name it . Then add this code:\n\nThis code will create a grey image like the last example in the previous section. It will then create a polygon that is filled with the color green. Then it will create a second polygon and outline it in yellow without filling it.\n\nIn both of the drawings, you are supplying three points. That will create two triangles.\n\nWhen you run this code, you will get this output:\n\nTry changing the code by adding additional points to one or more of the polygons in the code above. With a little practice, you’ll be able to create complex polygons quickly with Pillow.\n\nThe method allows you to draw a rectangle or square using Pillow. Here is how is defined:\n\nYou can pass in two tuples that define the beginning and ending coordinates to draw the rectangle. Or you can supply the four coordinates as a box tuple (4-item tuple). Then you can add an , it with a color, and change the outline’s .\n\nCreate a new file and name it . Then fill it in with this code so you can start drawing rectangles:\n\nThis code will create a blue image that is 400×400 pixels. Then it will draw two rectangles. The first rectangle will be filled with red. The second will be filled with green and outlined with yellow.\n\nWhen you run this code, you will get this image as output:\n\nAren’t those lovely rectangles? You can modify the rectangle’s points to create thinner or wider rectangles. You could also modify the outline width that you add to the rectangles.\n\nYou can use Pillow to add shapes to your images. This can be helpful for adding outlines to your images, highlighting one or more portions of your image, and more.\n\nIn this article, you learned about the following topics:\n\nYou can do a lot with the shapes that are provided by Pillow. You should take these examples and modify them to test them out with your own photos. Give it a try and see what you can come up with!\n• Drawing Text on Images with Python and Pillow"
    },
    {
        "link": "https://holypython.com/python-pil-tutorial/how-to-draw-shapes-on-images-python-ultimate-guide",
        "document": "For instance, most mobile phones, desks, beds, screens, laptops, buttons, books and windows have rectangular shapes while pizza is almost always circular (except Sicilian pizza) and its slices resemble triangles. Signs and flags concerning nautical, aviation, road and rail transportation can have circular, hexagonal or octagonal as well as triangular shapes. Particularly for niche sub-domains under engineering, online businesses, digital image manipulation, architecture and e-learning geometric shapes are irreplaceable. Some example fields would be: Geometric shapes get plenty of utilization in both digital and physical applications and the list above is a tiny representation of where we might see utilization of geometric shapes. In this tutorial, we will use Python to draw geometric shapes, combine geometric shapes with images and demonstrate several use cases of geometric shapes through Python examples.\n\nSquare is a geometric shape with 4 equal sides and 4 right angles (90 degrees) between them. Using Python’s module we can draw square shapes on any image and any coordinate on that image. We can also specify a fill color or outline color and we can even adjust transparency of the square by using more advanced Python image editing techniques. We can use 2 methods from ImageDraw to achieve a square shape. In the next section, you can see a rectangle example drawn using the rectangle method. If you make sure the first argument has equal x and y values you will end up with a square instead of a rectangle. The first attribute defines the coordinates of the square (or rectangle) as following. If you check out the example below you will see that both x1 – x0 and y1 – y0 are equal which results in a square drawing. By increasing x1 or y1 you could create a rectangle as well. We get a cool rectangle with orange fill and teal outline with 25 pixel thickness.\n\nHow to draw polygons like pentagon, hexagon, septagon or octagon? A is a 2D shape that has multiple straight sides which form a closed plane figure. A is a equiangular and equilateral shape polygon shape. This means all regular polygons must have equal angles and equal sides. Technically, many geometric shapes qualify as polygons. Some categorization examples are as following. All regular polygons are also simple polygons. We can conveniently draw polygons such as pentagon, hexagon, septagon, octagon nanogon (enneagon) or decagon etc.. using Python and the PIL (pillow library). Using Python’s module we can initiate the draw object’s handle on an existing or new image. Then we can use and define the bounding circle and number of sides as well as some other attributes such as fill color. Let’s draw a pentagon using the ImageDraw module from Python’s Pillow library. Firstly, we can import the libraries we need and create a new image in RGBA mode. Check out our tutorial regarding RGBA color modes but RGBA allows us to have transparency layer (alpha layer) in case transparency is needed. 500×500 pixels should be a fine image dimension for the sake of this demonstration. Next, we will need a draw object which we can use as a drawing handle. Draw object can be created on the image we just created. Then we can draw a pentagon which is nothing but a polygon with 5 sides. As the filling color let’s use “lightslategray”. That’s it. It’s that easy drawing a sophisticated geometric shape on an image with Python. We can now show the image and check out how it came out.\n\nIf you are working with geometric shapes you might eventually encounter a situation where law is also part of the equation. Established artists, developers and businesses usually aim to protect their brand and/or work by registering trademarks or copyrights of their intellectual properties (IPs). While both trademark and copyright are intellectual properties, they are easily distinguishable due to a significant difference. Trademark can be applied to an item concerning the brand of a company or an individual such as logo, name, product name, coloring etc that represents the company while copyright is usually applied for the content of a specific work. It can be said that trademark is registered concerning the source of the work (brand name, logo etc.) while copyright applies to the work (product, art, text, drawing, design etc.) itself. For example, design of a logo representing can be registered as a trademark for a company (given that it satisfies all the necessary requirements), while design work created for a project might be registered for copyright to eliminate IP theft. While both trademarks and copyrights protect intellectual property, they serve different purposes and have different legal requirements for protection. Trademarks are used to prevent consumer confusion and protect the reputation and goodwill of a company or brand, while copyrights are used to protect the creative expression of an individual or group. Additionally, the duration of protection for trademarks and copyrights also differs. Trademarks can be renewed indefinitely as long as they are in use, while copyrights typically last for the life of the creator plus a certain number of years after their death. In most cases, it is not possible to copyright a geometric shape. Copyright law protects original works of authorship, such as literary, artistic, or musical works. A geometric shape, by itself, is not considered a work of authorship and is not eligible for copyright protection. However, there are some exceptions to this general rule. If a geometric shape is used as part of a logo, for example, the logo as a whole may be eligible for copyright protection. In this case, the geometric shape would be protected as part of the overall design of the logo. Additionally, if a geometric shape is used as part of a sculpture or other artistic work, the sculpture or artwork as a whole may be eligible for copyright protection. In this case, the geometric shape would be protected as part of the overall creative expression of the work. In general, however, a geometric shape by itself is not eligible for copyright protection. If you have specific questions about copyright and geometric shapes, it is best to consult with an attorney who specializes in copyright law. Similar to the copyright of geometric shapes it’s quite difficult to register a geometric shape as a trademark. A company named IGT tried to register geometric shapes used in their game machines and expectedly they were refused to do that. Later when they appealed a similar outcome occurred after the previous refusal decision was reconfirmed by Trademark Trial and Appeal Board (TTAB) of United States Patent and Trademark Office (USPTO). Accross the pond UK Government also has a very clear and informative guideline regarding untrademarkable items where it is stated that: Trade marks are acceptable if they are:\n• distinctive for the goods and services you provide In other words they can be recognised as signs that differentiates your goods or service as different from someone else’s. Since geometric shapes are most likely not distinctive for a single company, it is usually quite difficult to trademark them. Having said that there might be cases where a brand reaches enough distinction to actually be able to register some form of a geometric shape as their trademark. Please discuss with your attorney for professional advise. You can search existing trademark databases from relevant links:"
    },
    {
        "link": "https://realpython.com/image-processing-with-the-python-pillow-library",
        "document": "Python Pillow allows you to manipulate images and perform basic image processing tasks. As a fork of the Python Imaging Library (PIL), Pillow supports image formats like JPEG, PNG, and more, enabling you to read, edit, and save images. With Python Pillow, you can crop, resize, rotate, and apply filters to images, making it a versatile tool for image manipulation.\n\nPillow is often used for high-level image processing tasks and exploratory work. While not the fastest library, it offers a gentle learning curve and a comprehensive set of features for basic to intermediate image processing needs. You can enhance its capabilities by integrating it with NumPy for pixel-level manipulations and creating animations.\n\nBy the end of this tutorial, you’ll understand that:\n• Python Pillow is used for image manipulation and basic image processing.\n• Pillow offers reasonable speed for its intended use cases.\n• PIL is the original library, while Pillow is its actively maintained fork.\n• You read an image in Python Pillow using from the PIL module.\n• Pillow is used for its ease of use, versatility, and integration with NumPy.\n\nWith these insights, you’re ready to dive into the world of image processing with Python Pillow. You’ll use several images in this tutorial, which you can download from the tutorial’s image repository:\n\nWith these images in hand, you’re now ready to get started with Pillow.\n\nThe Python Pillow library is a fork of an older library called PIL. PIL stands for Python Imaging Library, and it’s the original library that enabled Python to deal with images. PIL was discontinued in 2011 and only supports Python 2. To use its developers’ own description, Pillow is the friendly PIL fork that kept the library alive and includes support for Python 3. There’s more than one module in Python to deal with images and perform image processing. If you want to deal with images directly by manipulating their pixels, then you can use NumPy and SciPy. Other popular libraries for image processing are OpenCV, scikit-image, and Mahotas. Some of these libraries are faster and more powerful than Pillow. However, Pillow remains an important tool for dealing with images. It provides image processing features that are similar to ones found in image processing software such as Photoshop. Pillow is often the preferred option for high-level image processing tasks that don’t require more advanced image processing expertise. It’s also often used for exploratory work when dealing with images. Pillow also has the advantage of being widely used by the Python community, and it doesn’t have the same steep learning curve as some of the other image processing libraries. You’ll need to install the library before you can use it. You can install Pillow using within a virtual environment: Now that you’ve installed the package, you’re ready to start familiarizing yourself with the Python Pillow library and perform basic manipulations of images. The Module and Class in Pillow The main class defined in Pillow is the class. When you read an image using Pillow, the image is stored in an object of type . For the code in this section, you’ll need the image file named (image credit), which you can find in the image repository for this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. You can place this image file in the project folder that you’re working in. When exploring images with Pillow, it’s best to use an interactive REPL environment. You’ll start by opening the image that you just downloaded: You might expect to import from Pillow instead of from PIL. You did install , after all, not . However, Pillow is a fork of the PIL library. Therefore, you’ll still need to use when importing into your code. You call the function to read the image from the file and to read the image into memory so that the file can now be closed. You use a statement to create a context manager to ensure the file is closed as soon as it’s no longer needed. In this example, the object is a JPEG image-specific type that’s a subclass of the class, as you confirm with the call to . Note that both the class and the module where the class is defined share the same name, . You can display the image using : The method saves the image as a temporary file and displays it using your operating system’s native software for dealing with images. When you run the code above, you’ll see the following image displayed: On some systems, calling will block the REPL until you close the image. This depends on the operating system and the default image viewing software that you’re using. You’ll need to be familiar with three key properties when dealing with images in the Python Pillow library. You can explore these using the class attributes , , and : The format of an image shows what type of image you’re dealing with. In this case, the format of the image is . The size shows the width and height of the image in pixels. The mode of this image is . You’ll learn more about modes shortly. Often, you may need to crop and resize images. The class has two methods that you can use to perform these operations, and : The argument to must be a 4-tuple that defines the left, upper, right, and bottom edges of the region that you wish to crop. The coordinate system used in Pillow assigns the coordinates (0, 0) to the pixel in the upper-left corner. This is the same coordinate system that’s usually used for two-dimensional arrays. The 4-tuple represents the following section of the image: The new image that returns in the code above has a size of pixels. The cropped image shows only one of the buildings from the original picture: In the code above, you also change the resolution of the cropped image using , which needs a tuple as a required argument. The tuple that you use as an argument defines the new width and height of the image in pixels. In the example above, you’re setting the new width and height to a quarter of their original values using the floor division operator ( ) and the attributes and . The final call to displays the cropped and resized image: There are additional optional parameters that you can use with to control how the image is resampled. Alternatively, you can achieve similar scaling using : The argument determines the factor by which you scale the image down. If you prefer to set a maximum size rather than a scaling factor, then you can use . The size of the thumbnail will be smaller than or equal to the size that you set. Note: The method changes the object in place and doesn’t return a new object. However, , , and all return a new object. Not all methods in the Pillow library behave in the same way. Once you’re happy with your returned image, you can save any of the objects to file using : Once you call the method, it creates the image files in your project folder. In this example, one of the images is a JPEG image and the other is a PNG image. The extension that you use as a filname automatically determines the file format, or you can specify the format as an additional optional argument. You can manipulate the image beyond cropping and resizing. Another common requirement is to rotate or flip the image. You can use the method for some transformations. Go ahead and carry on with the same REPL session that you started in the previous section: This code displays the following image: There are seven options that you can pass as arguments to :\n• : Flips the image left to right, resulting in a mirror image\n• : Rotates the image by 270 degrees counterclockwise, which is the same as 90 degrees clockwise\n• : Transposes the rows and columns using the top-left pixel as the origin, with the top-left pixel being the same in the transposed image as in the original image\n• : Transposes the rows and columns using the bottom-left pixel as the origin, with the bottom-left pixel being the one that remains fixed between the original and modified versions All the rotation options above define rotations in steps of 90 degrees. If you need to rotate an image by another angle, then you can use : This method call rotates the image by 45 degrees counterclockwise, giving the following image: The object returned is the same size as the original . Therefore, the corners of the image are missing in this display. You can change this behavior using the named parameter: This method returns a larger image that fully contains the rotated image: You can customize the rotation further with additional optional parameters. You can now change the size and orientation of an image. In the next section, you’ll learn about different types of images in the Python Pillow library. Bands and Modes of an Image in the Python Pillow Library An image is a two-dimensional array of pixels, where each pixel corresponds to a color. Each pixel can be represented by one or more values. For example, in an RGB image, each pixel is represented by three values corresponding to the red, green, and blue values for that pixel. Therefore, the object for an RBG image contains three bands, one for each color. An RGB image of size pixels is represented by a array of values. RGBA images also include the alpha value, which contains information about the transparency for each pixel. An RGBA image has four bands, one for each of the colors and a fourth one containing the alpha values. Each band has the same dimensions as the image dimensions. Therefore, an RGBA image of size pixels is represented by a array of values. The mode of an image describes what type of image you’re working with. Pillow supports most standard modes, including black-and-white (binary), grayscale, RGB, RGBA, and CMYK. You can see the full list of supported modes in the Pillow documentation on modes. You can find out how many bands are in an object using the method, and you can convert between modes using . Now you’ll use the image named (image credit) from the image repository for this tutorial: This image’s mode is also RGB. You can convert this image into other modes. This code uses the same REPL session that you started in the previous sections: You call twice to convert the RGB image into a CMYK and a grayscale version. The CMYK image looks similar to the original image but is encoded using the mode that’s common for printed material rather than digital displays. The conversion to grayscale gives the following output: The outputs from the calls to confirm that there are three bands in the RGB image, four bands in the CMYK image, and one band in the grayscale image. You can separate an image into its bands using and combine separate bands back into an object using . When you use , the method returns all the bands as separate objects. You can confirm this by displaying the string representation of one of the objects returned: The mode of the object that returns is , indicating this is a grayscale image, or an image that only displays the luminance values of each pixel. Now, you can create three new RGB images showing the red, green, and blue channels separately using , which is a function in the module: The first argument in determines the mode of the image that you want to create. The second argument contains the individual bands that you want to merge into a single image. The red band alone, stored in the variable , is a grayscale image with mode L. To create the image showing only the red channel, you merge the red band from the original image with green and blue bands that only contain zeros. To create a band containing zeros everywhere, you use the method. This method needs a function as an argument. The function that you use determines how each point transforms. In this case, you use a function to map each point to . When you merge the red band with green and blue bands containing zeros, you get an RGB image called . Therefore, the RGB image that you create only has non-zero values in the red channel, but because it’s still an RGB image, it’ll display in color. You also repeat a similar process to obtain and , which contain RGB images with the green and blue channels from the original image. The code displays the following three images: The red image contains a strong signal in the pixels that represent the strawberry, because these pixels are mostly red. The green and blue channels show these pixels as dark because they have small values. The exceptions are those pixels that represent the reflection of the light on the surface of the strawberry as these pixels are nearly white. Creating the side-by-side displays shown in this tutorialShow/Hide In this tutorial, when there are several images output in the code that need to be displayed next to one another to make comparisons easier, the images are displayed side by side rather than as separate images. These side-by-side displays were created using Pillow itself. You can use the function , shown below, to merge several images into a single display: The first parameter in uses the unpacking operator ( ) so that any number of objects of type can be used as input arguments. The keyword parameter can be set to if you want to tile the images vertically rather than horizontally. This function assumes that all images have the same size. The overall size of the display is calculated from the size of the images and the number of images used. You then create a new object with the same mode as the original images and with the size of the overal display. The loop pastes the images that you input when you call the function into the final display. The function returns the final object containing all the images side by side. The image in the main article showing the three color channels for the strawberry image was obtained by calling the function as follows: This function was used to generate all the displays that show more than one image in this tutorial.\n\nYou’ve learned how to crop and rotate images, resize them, and extract color bands from color images. However, none of the actions that you’ve taken so far have made any changes to the content of the image. In this section, you’ll learn about image processing features in the Python Pillow library. You’ll use the module in Pillow. One of the methods that’s used in image processing is image convolution using kernels. The aim of this tutorial is not to give a detailed explanation of image processing theory. If you’re interested in the science of image processing, one of the best resources that you can use is Digital Image Processing by Gonzalez and Woods. In this section, you’ll learn the basics of how you can use convolution kernels to perform image processing. But what’s a convolution kernel? A kernel is a matrix: You can consider a simple image to understand the process of convolution using kernels. The image has a size of pixels and contains a vertical line and a dot. The line is four pixels wide, and the dot consists of a pixel square. The image below is enlarged for display purposes: You can place the kernel anywhere on the image and use the location of the kernel’s central cell as a reference. The diagram below is a representation of the top-left portion of the image: The elements in this diagram represent different aspects of the image and the kernel:\n• The white squares represent pixels in the image that have a value of .\n• The red squares represent pixels in the image that have a value of . These make up the dot in the image shown above.\n• Each purple region represents the kernel. This kernel consists of a region, and each cell in the kernel has a value of . The diagram shows the kernel in three different positions labeled 1, 2, and 3. A new image can be created as a result of the convolution of the image with the kernel. You can understand the convolution process through the following steps:\n• Locate kernel: Consider one of the kernel locations and look at the image pixels covered by the kernel’s nine cells.\n• Multiply kernel and pixel values: Multiply the values in each of the kernel’s cells with the corresponding pixel values in the image. You’ll have nine values from the nine multiplications.\n• Sum results of multiplications: Add those nine values together. The result will be the value of the pixel in the new image that has the same coordinates as the kernel’s center pixel.\n• Repeat for all pixels: Repeat the process for every pixel in the image, moving the kernel each time so that the kernel’s central cell corresponds to a different image pixel each time. You can see this process with the three kernel positions labeled 1, 2, and 3 in diagram above. Consider the kernel position labeled 1. The position of this kernel is , which is the position of its central cell because it’s in the fourth row (index = ) and the third column (index = ). Each image pixel in the region covered by the kernel has a value of zero. Therefore, all the multiplications from step 2 will be zero, and their addition will also be zero. The new image will have a value of zero at pixel . The scenario is different for the other kernel positions shown. Next, consider the kernel labeled 2, located at . One of the image pixels overlapping this is not zero. The multiplication of this pixel value with the kernel value will give . The eight remaining multiplications are still zero because the image pixels are zero. Therefore, the value of the pixel at position in the new image will be . The third kernel position illustrated above is at . There are four non-zero image pixels overlapping with this kernel. Each one has a value of , so the multiplication result will again be for each of those pixel positions. The overall result for this kernel position is . The new image will have this value at . The diagram and the discussion above only consider three kernel positions. The convolution process repeats this process for every possible kernel position in the image. This gives a value for each pixel position in the new image. The result of the convolution is shown on the right in the following image, with the original image on the left: The kernel that you used is a box blur kernel. The factor of is there so that the overall weighting of the kernel is . The result of the convolution is a blurred version of the original image. There are other kernels that perform different functions, including different blurring methods, edge detection, sharpening, and more. The Python Pillow library has several built-in kernels and functions that’ll perform the convolution described above. You don’t need to understand the math of filtering through convolution to use these filters, but it always helps to know what’s happening behind the scenes when using these tools. The next sections will look at the kernels and image filtering capabilities available in the module in Pillow. You’ll return to using the image of the buildings that you used at the beginning of this tutorial. You can start a new REPL session for this section: In addition to , you also import the module from Pillow. You can use the method to apply filtering to the image. This method needs a convolution kernel as its argument, and you can use one of the several kernels available in the module in Pillow. The first set of filters that you’ll learn about deal with blurring, sharpening, and smoothing an image. You can blur the image using the predefined filter: The displayed image is a blurred version of the original one. You can zoom in to observe the difference in more detail using and then display the images again using : The two cropped images show the difference between the two versions: You can customize the type and amount of blurring that you need using or : You can see the three blurred images below, shown in the same order as in the code above: The filter is similar to the one described in the previous section introducing convolution kernels. The argument is the radius of the box blur filter. In the earlier section discussing kernels, the box blur filter that you used was a filter. This means that it had a radius of , because the filter extends by one pixel from the center. The blurred images show that the box blur filter with a radius of produces an image that’s more blurred than the image generated by the box blur filter with radius . You can also use the filter, which uses a Gaussian blur kernel. The Gaussian kernel puts more weight on the pixels at the center of the kernel than those at the edges, and this leads to smoother blurring than what’s obtained with the box blur. For this reason, Gaussian blurring can give better results in many cases. What if you want to sharpen an image? In that case, you can use the filter and compare the result with the original image: You’re comparing a cropped version of both images showing a small portion of the building. The sharpened image is on the right: Perhaps instead of sharpening an image, you need to smooth it. You can achieve this by passing as an argument for : Below, you can see the original image on the left and the smoothed image on the right: You’ll see an application of the smooth filter in the next section, in which you’ll learn about more filters in the module. These filters act on the edges of objects in the image. When you look at an image, it’s relatively easy to determine the edges of objects within that image. It’s also possible for an algorithm to detect edges automatically using edge detection kernels. The module in Pillow has a predefined kernel to achieve this. In this section, you’ll use the image of the buildings again and convert it to grayscale before you apply the edge detection filter. You can carry on with the REPL session from the previous section: The result is an image showing the edges from the original image: This filter identifies the edges in the image. You can obtain a better outcome by applying the filter before finding the edges: You can see a comparison of the original grayscale image and the two edge detection results below. The version with smoothing before edge detection is shown at the bottom: You can also enhance the edges of the original image with the filter: You used the smoothed version of the grayscale image to enhance the edges. A portion of the original grayscale image and the image with the edges enhanced are shown side by side below. The image with edge enhancement is on the right: Another predefined filter in that deals with object edges is . You can pass it as an argument to as you did with the other filters in this section: You’re using the smoothed, grayscale version as a starting point for this filter. You can see the embossed image below, which shows a different effect using the edges in the image: In this section, you’ve learned about several filters available in the module that you can apply to images. There are other filters that you can use to process images. You can see a list of all the filters available in the documentation.\n\nImage Segmentation and Superimposition: An Example In this section, you’ll use the image files named (image credit) and (image credit), which you can find in the image repository for this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. You can use the Python Pillow library to extract the cat from the first image and place it on the floor of the monastery courtyard. You’ll use a number of image processing techniques to achieve this. You’ll start by working on . You’ll need to remove the picture of the cat from the background using image segmentation techniques. In this example, you’ll segment the image using thresholding techniques. First, you can crop the image to a smaller one to remove some of the background. You can start a new REPL session for this project: The cropped image contains the cat and some of the background that’s too close to the cat for you to crop it: Each pixel in a color image is represented digitally by three numbers corresponding to the red, green, and blue values of that pixel. Thresholding is the process of converting all the pixels to either the maximum or minimum value depending on whether they’re higher or lower than a certain number. It’s easier to do this on a grayscale image: You achieve thresholding by calling to convert each pixel in the grayscale image into either or . The conversion depends on whether the value in the grayscale image is greater or smaller than the threshold value. The threshold value in this example is . The figure below shows the grayscale image and the result from the thresholding process: In this example, all the points in the grayscale image that had a pixel value greater than are converted to white, and all other pixels are changed to black. You can change the sensitivity of the thresholding process by varying the threshold value. Thresholding can be used to segment images when the object to segment is distinct from the background. You can achieve better results with versions of the original image that have higher contrast. In this example, you can achieve higher contrast by thresholding the blue channel of the original image rather than the grayscale image, because the dominant colors in the background are brown and green colors, which have a weak blue component. You can extract the red, green, and blue channels from the color image as you did earlier: The red, green, and blue channels are shown below, from left to right. All three are displayed as grayscale images: The blue channel has a higher contrast between the pixels representing the cat and those representing the background. You can use the blue channel image to threshold: You use a threshold value of in this example. You also convert the image into a binary mode using as an argument to . The pixels in a binary image can only have the values of or . Note: When dealing with certain image formats, such as JPEG, that rely on lossy compression, the images may vary slightly depending on which JPEG decoders you’re using. Different operating systems often come with different default JPEG decoders. Therefore, the results that you get when processing images may vary depending on the operating system and JPEG decoder that you’re using. You may need to slightly adjust the threshold value if your results do not match the ones shown in this tutorial. The result of thresholding is the following: You can identify the cat in this black-and-white image. However, you’d like to have an image in which all the pixels that correspond to the cat are white and all other pixels are black. In this image, you still have black regions in the area which corresponds to the cat, such as where the eyes, nose and mouth are, and you also still have white pixels elsewhere in the image. You can use the image processing techniques called erosion and dilation to create a better mask that represents the cat. You’ll learn about these two techniques in the next section. You can look at the image file called , which you can download from the repository linked to this tutorial: The left-hand side of this binary image shows a white dot on a black background, while the right-hand side shows a black hole in a solid white section. Erosion is the process of removing white pixels from the boundaries in an image. You can achieve this in a binary image by using as an argument for the method. This filter replaces the value of a pixel with the minimum value of the nine pixels in the array centered around the pixel. In a binary image, this means that a pixel will have the value of zero if any of its neighboring pixels are zero. You can see the effect of erosion by applying several times to the image. You should continue with the same REPL session as in the previous section: You’ve applied the filter three times using a loop. This code gives the following output: The dot has shrunk but the hole has grown as a result of erosion. Dilation is the opposite process to erosion. White pixels are added to the boundaries in a binary image. You can achieve dilation by using , which converts a pixel to white if any of its neighbors are white. You can apply dilation to the same image containing a dot and a hole, which you can open and load again: The dot has now grown bigger, and the hole has shrunk: You can use erosion and dilation together to fill in holes and remove small objects from a binary image. Using the image with a dot and hole, you can perform ten erosion cycles to remove the dot, followed by ten dilation cycles to restore the hole to its original size: You perform ten erosion cycles with the first loop. The image at this stage is the following: The dot has disappeared, and the hole is larger than it was in the original image. The second loop performs ten dilation cycles, which return the hole to its original size: However, the dot is no longer present in the image. The erosions and dilations have modified the image to keep the hole but remove the dot. The number of erosions and dilations needed depends on the image and what you want to achieve. Often, you’ll need to find the right combination through trial and error. You can define functions to perform several cycles of erosion and dilation: These functions make it easier to experiment with erosion and dilation for an image. You’ll use these functions in the next section as you continue working on placing the cat into the monastery. You can use a sequence of erosions and dilations on the threshold image that you obtained earlier to remove parts of the mask that don’t represent the cat and to fill in any gaps in the region containing the cat. Once you’ve experimented with erosion and dilation, you’ll be able to use educated guesses in a trial-and-error process to find the best combination of erosions and dilations to achieve the ideal mask. Starting with the image , which you obtained earlier, you can start with a series of erosions to remove the white pixels that represent the background in the original image. You should continue working in the same REPL session as in the previous sections: The eroded threshold image no longer contains white pixels representing the background of the image: However, the remaining mask is smaller than the overall outline of the cat and has holes and gaps within it. You can perform dilations to fill the gaps: The fifty-eight cycles of dilation filled all the holes in the mask to give the following image: However, this mask is too big. You can therefore finish the process with a series of erosions: The result is a mask that you can use to segment the image of the cat: You can avoid the sharp edges of a binary mask by blurring this mask. You’ll have to convert it from a binary image into a grayscale image first: The filter returns the following mask: The mask now looks like a cat! Now you’re ready to extract the image of the cat from its background: First, you create a blank image with the same size as . You create a new object from by using and setting all values to zero. Next, you use the function in to create an image made up from both and using to determine which parts of each image are used. The composite image is shown below: You’ve segmented the image of the cat and extracted the cat from its background. You can go a step further and paste the segmented image of the cat into the image of the monastery courtyard from the image repository for this tutorial: You’ve used to paste an image onto another one. This method can be used with three arguments:\n• The first argument is the image that you want to paste in. You’re resizing the image to one-fifth of its size using the integer division operator ( ).\n• The second argument is the location in the main image where you want to paste the second picture. The tuple includes the coordinates within the main image where you want to place the top-left corner of the image that you’re pasting in.\n• The third argument provides the mask that you wish to use if you don’t want to paste the entire image. You’ve used the mask that you obtained from the process of thresholding, erosion, and dilation to paste the cat without its background. The output is the following image: You’ve segmented the cat from one image and placed it into another image to show the cat sitting quietly in the monastery courtyard rather than in the field where it was sitting in the original image. Your final task in this example is to add the Real Python logo as a watermark to the image. You can get the image file with the Real Python logo from the repository accompanying this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. You should continue working in the same REPL session: This is the full-size logo in color: You can change the image to grayscale and threshold it using to transform it into a black-and-white image. You also reduce its size and transform it into a contour image: The output shows the contour from the Real Python logo. The contour is ideal for using as a watermark on your image: To use this as a watermark, you’ll need to reverse the colors so that the background is black and only the outline that you want to keep is white. You can achieve this using again: You’ve converted the pixels that had a value of and assigned them the value , converting them from white to black pixels. You set the remaining pixels to white. The reversed outline logo is shown below: Your final step is to paste this outline onto the image of the cat sitting in the monastery courtyard. You can use again: The first argument in indicates the image that you wish to paste in, and the third argument represents the mask. In this case, you’re using the same image as a mask because the image is a binary image. The second argument provides the top-left coordinates of the region where you want to paste the image. The watermark has a rectangular outline, which is a result of the contour filter that you used earlier. If you prefer to remove this outline, you can crop the image using . This is an exercise that you can try on your own.\n\nPillow has an extensive selection of built-in functions and filters. However, there are times when you need to go further and manipulate images beyond the features that are already available in Pillow. You can manipulate the image further with the help of NumPy. NumPy is a very popular Python library for dealing with numeric arrays, and it’s an ideal tool to use with Pillow. You can learn more about NumPy in NumPy Tutorial: Your First Steps Into Data Science in Python. When you convert an image into a NumPy array, you can perform any transformations that you require directly on the pixels in the array. Once you’ve completed your processing in NumPy, you can convert the array back into an object using Pillow. You need to install NumPy for this section: Now that you’ve installed NumPy, you’re ready to use Pillow and NumPy to spot the difference between two images. Using NumPy to Subtract Images From Each Other See if you can spot the differences between the following two images: This isn’t a hard one! However, you decide to cheat and write a Python program to solve the puzzle for you. You can download the image files and (image credit) from the repository accompanying this tutorial: Get Images: Click here to get access to the images that you’ll manipulate and process with Pillow. Your first step is to read the images using Pillow and convert them to NumPy arrays: Since and are objects of type , you can manipulate them using all the tools that you have available in NumPy. You can subtract one array from the other to show the pixels that differ between the two images: When you subtract an array from another one of the same size, the result is another array with the same shape as the original arrays. You can convert this array into an image using in Pillow: The result of subtracting one NumPy array from another and converting into a Pillow is the difference image shown below: The difference image only shows three regions from the original image. These regions highlight the differences between the two images. You can also see some noise surrounding the cloud and the fence, which is due to small changes in the original JPEG compression in the region surrounding these items. You can go further and create images from scratch using NumPy and Pillow. You can start by creating a grayscale image. In this example, you’ll create a simple image containing a square, but you can create more elaborate images in the same way: You create an array of size containing zeros everywhere. Next, you set the value of a set of pixels at the center of the array to . You can index NumPy arrays using both rows and columns. In this example, the first slice, , represents the rows to . The second slice, , which follows the comma, represents the columns to . You can use to convert the NumPy array into an object of type . The output from the code above is shown below: You’ve created a grayscale image containing a square. The mode of the image is inferred automatically when you use . In this case, mode is used, which corresponds to an image with 32-bit floating-point pixels. You can convert this to a simpler grayscale image with 8-bit pixels if you wish: You can also go further and create a color image. You can repeat the process above to create three images, one corresponding to the red channel, another to the green, and a final one corresponding to the blue channel: You create an object from each NumPy array and convert the images to mode , which represents grayscale. Now, you can combine these three separate images into one RGB image using : The first argument in is the mode of the image output. The second argument is a sequence with the individual single-band images. This code creates the following image: You’ve combined the separate bands into an RGB color image. In the next section, you’ll go a step further and create a GIF animation using NumPy and Pillow. In the previous section, you created a color image containing three overlapping squares of different colors. In this section, you’ll create an animation showing those three squares merging into a single white square. You’ll create several versions of the images containing three squares, and the location of the squares will vary slightly between successive images: You create an empty list called , which you’ll use to store the various images that you generate. Within the loop, you create NumPy arrays for the red, green, and blue channels, as you did in the previous section. The array containing the green layer is always the same and represents a square in the center of the image. The red square starts in a position displaced to the top-left of the center. In each successive frame, the red square moves closer to the center until it reaches the center in the final iteration of the loop. The blue square is initially shifted toward the bottom-right then moves towards the center with each iteration. Note that in this example, you’re iterating over , which means that the variable increases in steps of two. You learned earlier that you can save an object to file using . You can use the same function to save to a GIF file that includes a sequence of images. You call on the first image in the sequence, which is the first image that you stored in the list : The first argument in is the filename for the file that you want to save. The extension in the filename tells what file format it needs to output. You also include two keyword arguments in :\n• ensures that all the images in the sequence are saved, and not just the first one.\n• allows you to append the remaining images in the sequence to the GIF file. This code saves to file, and you can then open the GIF file with any image software. The GIF should loop by default, but on some systems you’ll need to add the keyword argument to to make sure the GIF loops. The animation that you get is the following one: The three squares with different colors merge into a single white square. Can you create your own animation using different shapes and different colors?"
    },
    {
        "link": "https://tutorialspoint.com/python_pillow/python_pillow_imagedraw_module.htm",
        "document": "Drawing on images in Pillow involves using the Pillow library (Python Imaging Library) to add various visual elements such as lines, shapes, text and more to an existing image. This is a common image processing task used for tasks like image annotation, creating visualizations, adding labels or captions highlighting areas of interest and more.\n\nWe can use the ImageDraw module in Pillow to create a drawing object and then use various methods of this object to draw on the image. We can use the line(), rectangle(), ellipse(), text() and other methods to draw various elements on the image.\n\nTo draw or write text on an image we can use the ImageDraw.Draw() function in the Pillow library, this method creates a drawing object that allows us to perform drawing operations on images.\n\nThe following is the syntax and parameters of the Draw() method −\n• None image − This parameter represents the image on which we want to perform drawing operations. It's an instance of a Pillow Image object.\n• None mode (optional) − This parameter specifies the mode in which drawing will occur. The available modes are −\n\nInput image to be used for the below two examples.\n\nIn this example we are using the Draw() method of the ImageDraw module to add text on the image.\n\nHere this is another example using the Draw() method for adding text at the middle of the image.\n\nIn the Pillow library (PIL) the PIL.ImageDraw.Draw.rectangle() method is used to draw a rectangle on an image using a specified outline and fill color. This method is part of the ImageDraw module and is typically called on an ImageDraw object created using PIL.ImageDraw.Draw().\n\nThe following is the syntax and parameters of the PIL.ImageDraw.Draw.rectangle() method −\n• None xy − This parameter specifies the coordinates of the rectangle as a tuple of two points. Each point is represented as (x1, y1) and (x2, y2) in which (x1, y1) is the upper-left corner and (x2, y2) is the lower-right corner of the rectangle.\n• None outline − This parameter is optional and specifies the color of the outline of the rectangle. We can provide a color as a string e.g., \"red\" or \"#FF0000\" or as a tuple representing an RGB color (e.g., (255, 0, 0)). If set to None no outline will be drawn.\n• None fill − This parameter is optional and specifies the color to fill the rectangle. Like the outline parameter we can specify the fill color as a string or an RGB tuple. If set to None the rectangle will not be filled.\n• None width − This is an optional parameter to specify the width of the outline of the rectangle. By default it is 0 which means the rectangle will be filled without an outline.\n\nInput image to be used for the below two examples.\n\nIn this example we are drawing a rectangle on the given input image by using the PIL.ImageDraw.Draw.rectangle() method.\n\nHere this is another example of drawing the rectangle with the specifying the outline as Blue and fill parameter as None.\n\nPIL.ImageDraw.Draw.line() is a method provided by the Python Imaging Library (PIL) or the Pillow library. Pillow is a more modern and actively maintained fork of PIL that is used to draw a line on an image. This method is part of the ImageDraw module within PIL/Pillow which is used for drawing shapes, text, and other graphics on images.\n\nHere the below is the syntax of the PIL.ImageDraw.Draw.line() method −\n• None xy − A sequence of (x, y) coordinates specifying the endpoints of the line.\n• None fill − This parameter is optional and specifies the color of the line. It can be a string specifying a color name a (R, G, B) tuple or an integer value. If not specified, the line will be black.\n• None width − This parameter is optional and specifies the line's width in pixels. The default value is 0 which means the line will be 1 pixel wide.\n• None joint − This parameter is optional and can be used to specify the joint style for the line. It can be one of the following values −\n• None None (default) − The line has regular joints.\n\nInput image to be used for the below two examples.\n\nIn this example we are drawing a line on the input image by using PIL.ImageDraw.Draw.line() method.\n\nThis is another example of the PIL.ImageDraw.Draw.line() method by specifying the joint parameter as curve.\n\nPIL.ImageDraw.Draw.polygon() is a method provided by the ImageDraw object in the Pillow library. It allows us to draw a polygon on an image. A polygon is a closed shape with multiple sides so we can specify the coordinates of the vertices to define the shape of the polygon.\n\nThis method is part of the ImageDraw.Draw object and is used to create and fill a polygon shape with a specified color.\n\nThe following is the syntax of the PIL.ImageDraw.Draw.polygon() method −\n• None xy − This is a list of tuples or a flat list of coordinates specifying the vertices of the polygon. Each tuple or pair of coordinates represents a vertex of the polygon.\n• None fill − This parameter is optional and specifies the fill color for the interior of the polygon. If we want the polygon to have no fill and we can set this to None.\n• None outline − This parameter is optional and specifies the color of the outline or border of the polygon. If we don't want an outline then we can set this to None.\n\nInput image to be used for the below two examples.\n\nIn this example we are drawing a polygon on the image by using the PIL.ImageDraw.Draw.polygon() method and specifying the parameters xy, fill and outline.\n\nHere this is another example in which we are passing the fill parameter of PIL.ImageDraw.Draw.polygon() method as None to avoid filling the polygon.\n\nIn addition to the above methods, This module offers many other specific methods that can be used for specific conditions. Let's explore and understand the basic fuctionality of each method −"
    },
    {
        "link": "https://geeksforgeeks.org/python-pillow-tutorial",
        "document": "sinceDigital Image processing means processing the image digitally with the help of a computer. Using image processing we can perform operations like enhancing the image, blurring the image, extracting text from images, and many more operations. There are various ways to process images digitally. Here we will discuss the Pillow module of Python. Python Pillow is built on the top of PIL (Python Image Library) and is considered as the fork for the same as PIL has been discontinued since 2011. Pillow supports many image file formats including BMP, PNG, JPEG, and TIFF. The library encourages adding support for newer formats in the library by creating new file decoders.\n\nThis article aims at providing information about Python Pillow from basics to advance with the help of well-explained concepts and examples. So, let’s not waste any of the time and dive deep into the Pillow.\n\nPython Pillow does not come in-built with Python. To install it type the below command in the terminal.\n\nAfter installation let’s get started using the pillow module.\n\nThe Pillow module provides the open() and show() function to read and display the image respectively. For displaying the image Pillow first converts the image to a .png format (on Windows OS) and stores it in a temporary buffer and then displays it. Therefore, due to the conversion of the image format to .png some properties of the original image file format might be lost (like animation). Therefore, it is advised to use this method only for test purposes.\n\nImage Used for all the below Examples:\n\nRefer to the below articles to get detailed information about opening and displaying images.\n\nGetting information about the opened image\n\nGetting the Size, and format of the Image\n• size attribute provides the size of the image. It returns a tuple that contains width and height.\n• format attribute returns the format of the image file.\n\nRefer to the below article to get detailed information about Getting the Size, and format of the Image\n• None Finding the Size Resolution of Image in Python\n• None How to find width and height of an image using Python?\n\nGetting Color mode of the image\n\nThe mode attribute of the image tells the type and depth of the pixel in the image. A 1-bit pixel has a range of 0-1, and an 8-bit pixel has a range of 0-255. There are different modes provided by this module. A few of them are:\n\nrotate() method of the Image class is used to rotate the image by a particular angle counterclockwise around its center. After rotating the image, the sections of the image having no pixel values are filled with black (for non-alpha images) and with completely transparent pixels (for images supporting transparency).\n\nRefer to the below articles to get detailed information about rotating the image.\n• None How to rotate an image using Python?\n\nImage.transpose() is used to transpose the image (flip or rotate in 90 degree steps).\n\nKeywords FLIP_TOP_BOTTOM and FLIP_LEFT_RIGHT will be passed to transpose method to flip it.\n\nRefer to the below articles to get detailed information about flipping images.\n• None How to flip an image horizontally or vertically in Python?\n\nImage.resize() returns a resized copy of the image. Interpolation happens during the resize process, due to which the quality of image changes whether it is being upscaled (resized to a higher dimension than original) or downscaled (resized to a lower Image then original). Therefore resize() should be used cautiously and while providing suitable value for resampling argument.\n\nRefer to the below article to get detailed information about resizing images.\n• None Change the ratio between width and height of an image using Python – Pillow\n\nImage.save() saves the image under the given filename. If no format is specified, the format to use is determined from the filename extension, if possible. You can use a file object instead of a filename. In this case, you must always specify the format. The file object must implement the seek, tell, and write methods, and be opened in binary mode.\n\nTill now, we have learned the basics of pillow now let’s start with some complex operations like blurring the image of merging two images or even creating a thumbnail. So let’s get started by merging images.\n\nImage.merge() is used to merge a set of single band images into a new multiband image.\n\nNote: We will be using Image.split() method to split the image into individual bands.\n\nMerging Two or More Images\n\nUsing the merge() method we can also merge two or more images. We have to select two images of the same size or we can resize the image. Then using the new() function we will create a new image and will paste all the images there. See the below example for a better understanding.\n\nRefer to the below articles to get detailed information about merging images.\n• None How to merge images with same size using the Python 3 module pillow?\n• None Python | Copy and Paste Images onto other Image using Pillow\n• None How to merge a transparent PNG image with another image using PIL?\n\nImage.thumbnail() convert the image into a thumbnail. This method modifies the image to contain a thumbnail version of itself, no larger than the given size. This method calculates an appropriate thumbnail size to preserve the aspect of the image, calls the draft() method to configure the file reader (where applicable), and finally resizes the image.\n\nNote: This function modifies the Image object in place. If you need to use the full resolution image as well, apply this method to a copy() of the original image.\n\nRefer to the below articles to get detailed information about creating thumbnails.\n\nCropping is the process of selecting only a part of the image. The crop() method is used to crop a rectangular portion of any image.\n\nRefer to the below articles to get detailed information about Cropping images.\n• None Cropping an Image in a circular way\n\nIf a blurred image is observed carefully then a common thing to notice is that image is smooth meaning edges are not observed. A filter used for blurring is also called a low pass filter because it allows the low frequency to enter and stop high frequency. The ImageFilter class in the pillow library provides various filters that can be applied using the filter() method. Let’s see some of the blurring filters provided by the pillow.\n\nThis method blurs the image using the kernel matrix or through the convolution matrix. It can be applied using the BLUR parameter.\n\nNote: For more information refer, What is Image Blurring\n\nThe Gaussian filter is implemented as an Odd sized Symmetric Kernel (DIP version of a Matrix) which is passed through each pixel of the Region of Interest to get the desired effect. The kernel is not hard towards drastic color changed (edges) due to the pixels towards the center of the kernel having more weightage towards the final value than the periphery. A Gaussian filter could be considered as an approximation of the Gaussian Function (mathematics). The Pillow module provides the predefined gaussianblur kernel that does the underlying maths for us.\n\nBox blur is also known as box linear filter. Box blurs are frequently used to approximate Gaussian blur. A box blur is generally implemented as an image effect that affects the whole screen. The blurred color of the current pixel is the average of the current pixel’s color and its 8 neighboring pixels. Pillow provides the BoxBlur() method to do the same.\n\nRefer to the below articles to get detailed information about blurring images.\n• None Apply a Gauss filter to an image with Python\n\nPillow provides the ImageDraw module that provides simple 2D graphics for Image objects. You can use this module to create new images, annotate or retouch existing images, and generate graphics on the fly for web use. Let’s see various figures or texts that we can draw on the image.\n\nAdding text to an image can sometimes be very necessary as it can be used to provide some useful information to the image or can also be used to add a digital signature to the image. With pillow, we can easily add a text to any image. Let’s see the below example.\n• ImageFont to specify font and font size. This step is optional. It is for those who want their text to look cool or stylish because someone won’t select any font style then the system takes the default font style.\n• ImageFont truetype() as it needs two parameters that are (“font type”, size)\n• text() function of draw object and pass the four-parameters (Point of starting for text, “sample text”, Color, ImageFont object).\n\nRefer to the below articles to get detailed information about adding texts to the image.\n\nImageDraw.Draw.multiline_text() is used to draws the string at the given position.\n\nImageDraw.Draw.line() is used to draws a line between the coordinates in the xy list.\n\nImageDraw.Draw.rectangle() is used to draw a rectangle.\n\nImageDraw.Draw.polygon() is used to draw a polygon. The polygon outline consists of straight lines between the given coordinates, plus a straight line between the last and the first coordinate.\n\nPython Pillow provides the ImageEnhance module to adjust the color, brightness, contrast, and sharpness of the image.\n\nImageEnhance.Color() and ImageEnhance.Contrast() methods are used to adjust the color and contrast of the image respectively.\n• ImageEnhance.Color() is used to adjust the color balance of an image, in a manner similar to the controls on a color TV set. An enhancement factor of 0.0 gives a black and white image. A factor of 1.0 gives the original image.\n• ImageEnhance.Contrast() is used to control the contrast of an image, similar to the contrast control on a TV set. An enhancement factor of 0.0 gives a solid grey image. A factor of 1.0 gives the original image.\n\nRefer to the below articles to get detailed information about enhancing color and contrast.\n\nImageEnhance.Brightness() and ImageEnhance.Sharpness() methods are used to adjust the brightness and sharpness of the image.\n• ImageEnhance.Brightness() is used to control the brightness of an image. An enhancement factor of 0.0 gives a black image. A factor of 1.0 gives the original image.\n• ImageEnhance.Sharpness() is used to adjust the sharpness of an image. An enhancement factor of 0.0 gives a blurred image, a factor of 1.0 gives the original image, and a factor of 2.0 gives a sharpened image.\n\nRefer to the below articles to get detailed information about enhancing the brightness and sharpness of the image.\n• None Convert the .GIF to .BMP and it’s vice-versa in Python\n• None Convert an image into jpg format using Pillow in Python\n• None Convert files from jpg to png and vice versa using Python\n• None Convert the .PNG to .GIF and it’s vice-versa in Python\n• None Convert files from jpg to gif and vice versa using Python\n• None Add padding to the image with Python – Pillow\n• None Find most used colors in image using Python\n• None Overlay an image on another image in Python\n• None Spot the difference between two images using Python\n• None How to Extract Text from Images with Python?\n• None How to compress images using Python and PIL?\n• None Python | OCR on All the Images present in a Folder Simultaneously\n• None Apply changes to all the images in given folder – Using Python PIL"
    }
]