[
    {
        "link": "https://datacamp.com/tutorial/dijkstra-algorithm-in-python",
        "document": "This course will equip you with the skills to analyze, visualize, and make sense of networks using the NetworkX library."
    },
    {
        "link": "https://udacity.com/blog/2021/10/implementing-dijkstras-algorithm-in-python.html",
        "document": "What do GPS navigation devices and websites for booking flights have in common? As it turns out, a lot! For one, both technologies employ Dijkstra’s shortest path algorithm.\n\nIn this article, we’ll give an overview of Dijkstra’s algorithm and provide an easy-to-follow implementation in Python. After we lay out the explanation in plain English, you’ll see that the Python implementation is not that much different.\n\nIn 1956, Dutch programmer Edsger W. Dijkstra had a practical question. He wanted to figure out the shortest way to travel from Rotterdam to Groningen. But he did not simply consult a map to calculate the distances of the roads he would need to take. Instead, Dijkstra took a computer scientist’s approach: he abstracted from the problem by filtering out the specifics such as traveling from city A to city B. This allowed him to discover the more general problem of graph search. Thus, Dijkstra’s algorithm was born.\n\nDijkstra’s algorithm is a popular search algorithm used to determine the shortest path between two nodes in a graph. In the original scenario, the graph represented the Netherlands, the graph’s nodes represented different Dutch cities, and the edges represented the roads between the cities.\n\nYou can apply Dijkstra’s algorithm to any problem that can be represented as a graph. Friend suggestions on social media, routing packets over the internet, or finding a way through a maze—the algorithm can do it all. But how does it actually work?\n\nRecall that Dijkstra’s algorithm operates on graphs, meaning that it can address a problem only if it can be represented in a graph-like structure. The example we’ll use throughout this tutorial is perhaps the most intuitive: the shortest path between two cities.\n\n\n\nWe’ll be working with the map below to figure out the best route between the two European cities of Reykjavik and Belgrade. For the sake of simplicity, let’s imagine that all cities are connected by roads (a real-life route would involve at least one ferry).\n• Each city is represented as a node.\n• Each road is represented as an edge.\n• Each road has an associated value. A value could be the distance between cities, a highway toll, or the amount of traffic. Generally, we’ll favor edges with lower values. In our specific case, the associated value is defined by the distance between two cities.\n\nYou also may have noticed that we cannot reach Belgrade from Reykjavik directly; that would render our exercise pointless. But there are several paths from Reykjavik to Belgrade that go through other cities:\n\n\n\nEach of these paths end in Belgrade, but they all have different values. We can use Dijkstra’s algorithm to find the path with the lowest total value.\n\nBefore diving into the code, let’s start with a high-level illustration of Dijkstra’s algorithm.\n\nFirst, we initialize the algorithm as follows:\n• We set Reykjavik as the starting node.\n• We set the distances between Reykjavik and all other cities to infinity, except for the distance between Reykjavik and itself, which we set to 0.\n\nAfter that, we iteratively execute the following steps:\n• We choose the node with the smallest value as the “current node” and visit all of its neighboring nodes. As we visit each neighbor, we update their tentative distance from the starting node.\n• Once we visit all of the current node’s neighbors and update their distances, we mark the current node as “visited.” Marking a node as “visited” means that we’ve arrived at its final cost.\n• We go back to step one. The algorithm loops until it visits all the nodes in the graph.\n\nIn our example, we start by marking Reykjavik as the “current node” since its value is 0. We proceed by visiting Reykjavik’s two neighboring nodes: London and Oslo. At the beginning of the algorithm, their values are set to infinity, but as we visit the nodes, we update the value for London to 4, and Oslo to 5.\n\nWe then mark Reykjavik as “visited.” We know that its final cost is zero, and we don’t need to visit it again. We continue with the next node with the lowest value, which is London.\n\nWe visit all of London’s neighboring nodes which we haven’t marked as “visited.” London’s neighbors are Reykjavik and Berlin, but we ignore Reykjavik because we’ve already visited it. Instead, we update Berlin’s value by adding the value of the edge connecting London and Berlin (3) to the value of London (4), which gives us a value of 7.\n\nWe mark London as visited and choose the next node: Oslo. We visit Oslo’s neighbors and update their values. It turns out that we can better reach Berlin through Oslo (with a value of 6) than through London, so we update its value accordingly. We also update the current value of Moscow from infinity to 8.\n\nWe mark Oslo as “visited” and update its final value to 5. Between Berlin and Moscow, we choose Berlin as the next node because its value (6) is lower than Moscow’s (8). We proceed as before: We visit Rome and Belgrade and update their tentative values, before marking Berlin as “visited” and moving on to the next city.\n\nNote that we’ve already found a path from Reykjavik to Belgrade with a value of 15! But is it the best one?\n\n\n\nUltimately, it’s not. We’ll skip the rest of the steps, but you get the drill. The best path turns out to be Reykjavik –> Oslo –> Berlin –> Rome –> Athens –> Belgrade, with a value of 11.\n\nNow, let’s see how we would implement this in Python code.\n\nFirst, we’ll create the Graph class. This class does not cover any of the Dijkstra algorithm’s logic, but it will make the implementation of the algorithm more succinct.\n\nWe’ll implement the graph as a Python dictionary. The dictionary’s keys will correspond to the cities and its values will correspond to dictionaries that record the distances to other cities in the graph.\n\nNext, we’ll implement the Dijkstra algorithm. We’ll start by defining the function.\n\nThe function takes two arguments: and is an instance of the Graph class that we created in the previous step, whereas is the node from which we’ll start the calculations. We’ll call the method to initialize the list of unvisited nodes:\n\nNext, we’ll create two dicts, and :\n• will store the best-known cost of visiting each city in the graph starting from the . In the beginning, the cost starts at infinity, but we’ll update the values as we move along the graph.\n• will store the trajectory of the current best known path for each node. For example, if we know the best way to Berlin to be via Oslo, will return “Oslo”, and will return “Reykjavik.” We’ll use this dictionary to backtrace the shortest path.\n\n\n\nNow we can start the algorithm. Remember that Dijkstra’s algorithm executes until it visits all the nodes in a graph, so we’ll represent this as a condition for exiting the while-loop.\n\n\n\nNow, the algorithm can start visiting the nodes. The code block below first instructs the algorithm to find the node with the lowest value.\n\nOnce that’s done, the algorithm visits all node’s neighbors that are still unvisited. If the new path to the neighbor is better than the current best path, the algorithm makes adjustments in the and dictionaries.\n\n\n\n\n\nAfter visiting all of its neighbors, we can mark the current node as “visited”:\n\n\n\n\n\nAt last, we can return the two dictionaries:\n\nLastly, we need to create a function that prints out the results. This function will take the two dictionaries returned by the dijskstra_algorithm function, as well as the names of the beginning and target nodes. It’ll use the two dictionaries to find the best path and calculate the path’s score.\n\nNow, let’s see the algorithm in action. We’ll manually initialize the nodes and their edges.\n\nWe’ll use these values to create an object of the Graph class.\n\nWith our graph fully constructed, we can pass it to the dijkstra_algorithm() function.\n\nAnd now let’s print out the results:\n\nAnd that’s it! Feel free to play around with the code. For example, you could add more nodes to the graph, tweak the edges’ values, or choose different starting and ending cities.\n\nIn this article, we provided a hands-on explanation of Dijkstra’s algorithm before showing an implementation in Python. Although Dijkstra’s algorithm is conceptually simple, it’s powerful enough to be employed in many interesting applications.\n\nLooking to continue learning Python?\n\n\n\nCheck out our Introduction to Programming Nanodegree program. You’ll learn the foundations and work towards a career in fields like software development, machine learning, or data science!"
    },
    {
        "link": "https://geeksforgeeks.org/python-program-for-dijkstras-shortest-path-algorithm-greedy-algo-7",
        "document": "Given a graph and a source vertex in the graph, find the shortest paths from source to all vertices in the given graph. Dijkstra’s algorithm is a popular algorithm for solving many single-source shortest path problems having non-negative edge weight in the graphs i.e., it is to find the shortest distance between two vertices on a graph. It was conceived by Dutch computer scientist Edsger W. Dijkstra in 1956.\n\nDijkstra’s algorithm is very similar to Prim’s algorithm for minimum spanning tree. Like Prim’s MST, we generate an SPT (shortest path tree) with a given source as root. We maintain two sets, one set contains vertices included in the shortest-path tree, another set includes vertices not yet included in the shortest-path tree. At every step of the algorithm, we find a vertex that is in the other set (set of not yet included) and has a minimum distance from the source. Below are the detailed steps used in Dijkstra’s algorithm to find the shortest path from a single source vertex to all other vertices in the given graph.\n\n1) Create a set sptSet (shortest path tree set) that keeps track of vertices included in shortest path tree, i.e., whose minimum distance from source is calculated and finalized. Initially, this set is empty. \n\n2) Assign a distance value to all vertices in the input graph. Initialize all distance values as INFINITE. Assign distance value as 0 for the source vertex so that it is picked first. \n\n3) While sptSet doesn’t include all vertices:\n• None Pick a vertex u which is not there in sptSet and has minimum distance value.\n• None Update distance value of all adjacent vertices of u. To update the distance values, iterate through all adjacent vertices. For every adjacent vertex v, if the sum of a distance value of u (from source) and weight of edge u-v, is less than the distance value of v, then update the distance value of v.\n\nBelow is the Python Implementation of the above discussed algorithm:\n\n# A utility function to find the vertex with # minimum distance value, from the set of vertices # not yet included in shortest path tree # Search not nearest vertex not in the # the set of vertices not yet processed. # u is always equal to src in first iteration # Put the minimum distance vertex in the # Update dist value of the adjacent vertices # of the picked vertex only if the current # distance is greater than new distance and # the vertex in not in the shortest path tree\n\nTime Complexity: The time complexity of Dijkstra’s algorithm is O(V^2). This is because the algorithm uses two nested loops to traverse the graph and find the shortest path from the source node to all other nodes.\n\nSpace Complexity: The space complexity of Dijkstra’s algorithm is O(V), where V is the number of vertices in the graph. This is because the algorithm uses an array of size V to store the distances from the source node to all other nodes."
    },
    {
        "link": "https://w3schools.com/dsa/dsa_algo_graphs_dijkstra.php",
        "document": "Dijkstra's algorithm finds the shortest path from one vertex to all other vertices.\n\nIt does so by repeatedly selecting the nearest unvisited vertex and calculating the distance to all the unvisited neighboring vertices.\n\nDijkstra's algorithm is often considered to be the most straightforward algorithm for solving the shortest path problem.\n\nDijkstra's algorithm is used for solving single-source shortest path problems for directed or undirected paths. Single-source means that one vertex is chosen to be the start, and the algorithm will find the shortest path from that vertex to all other vertices.\n\nDijkstra's algorithm does not work for graphs with negative edges. For graphs with negative edges, the Bellman-Ford algorithm that is described on the next page, can be used instead.\n\nTo find the shortest path, Dijkstra's algorithm needs to know which vertex is the source, it needs a way to mark vertices as visited, and it needs an overview of the current shortest distance to each vertex as it works its way through the graph, updating these distances when a shorter distance is found.\n\nIn the animation above, when a vertex is marked as visited, the vertex and its edges become faded to indicate that Dijkstra's algorithm is now done with that vertex, and will not visit it again.\n\nRun the simulation below to get a more detailed understanding of how Dijkstra's algorithm runs on a specific graph, finding the shortest distances from vertex D.\n\nThis simulation shows how distances are calculated from vertex D to all other vertices, by always choosing the next vertex to be the closest unvisited vertex from the starting point.\n\nFollow the step-by-step description below to get all the details of how Dijkstra's algorithm calculates the shortest distances.\n\nConsider the Graph below.\n\nWe want to find the shortest path from the source vertex D to all other vertices, so that for example the shortest path to C is D->E->C, with path weight 2+4=6.\n\nTo find the shortest path, Dijkstra's algorithm uses an array with the distances to all other vertices, and initially sets these distances to infinite, or a very big number. And the distance to the vertex we start from (the source) is set to 0.\n\nThe image below shows the initial infinite distances to other vertices from the starting vertex D. The distance value for vertex D is 0 because that is the starting point.\n\nDijkstra's algorithm then sets vertex D as the current vertex, and looks at the distance to the adjacent vertices. Since the initial distance to vertices A and E is infinite, the new distance to these are updated with the edge weights. So vertex A gets the distance changed from inf to 4, and vertex E gets the distance changed to 2. As mentioned on the previous page, updating the distance values in this way is called 'relaxing'.\n\nAfter relaxing vertices A and E, vertex D is considered visited, and will not be visited again.\n\nThe next vertex to be chosen as the current vertex must the vertex with the shortest distance to the source vertex (vertex D), among the previously unvisited vertices. Vertex E is therefore chosen as the current vertex after vertex D.\n\nThe distance to all adjacent and not previously visited vertices from vertex E must now be calculated, and updated if needed.\n\nThe calculated distance from D to vertex A, via E, is 2+4=6. But the current distance to vertex A is already 4, which is lower, so the distance to vertex A is not updated.\n\nThe distance to vertex C is calculated to be 2+4=6, which is less than infinity, so the distance to vertex C is updated.\n\nSimilarly, the distance to node G is calculated and updated to be 2+5=7.\n\nThe next vertex to be visited is vertex A because it has the shortest distance from D of all the unvisited vertices.\n\nThe calculated distance to vertex C, via A, is 4+3=7, which is higher than the already set distance to vertex C, so the distance to vertex C is not updated.\n\nVertex A is now marked as visited, and the next current vertex is vertex C because that has the lowest distance from vertex D between the remaining unvisited vertices.\n\nVertex F gets updated distance 6+5=11, and vertex B gets updated distance 6+2=8.\n\nCalculated distance to vertex G via vertex C is 6+5=11 which is higher than the already set distance of 7, so distance to vertex G is not updated.\n\nVertex C is marked as visited, and the next vertex to be visited is G because is has the lowest distance between the remaining unvisited vertices.\n\nVertex F already has a distance of 11. This is lower than the calculated distance from G, which is 7+5=12, so the distance to vertex F is not updated.\n\nVertex G is marked as visited, and B becomes the current vertex because it has the lowest distance of the remaining unvisited vertices.\n\nThe new distance to F via B is 8+2=10, because it is lower than F's existing distance of 11.\n\nVertex B is marked as visited, and there is nothing to check for the last unvisited vertex F, so Dijkstra's algorithm is finished.\n\nEvery vertex has been visited only once, and the result is the lowest distance from the source vertex D to every other vertex in the graph.\n\nTo implement Dijkstra's algorithm, we create a class. The represents the graph with its vertices and edges:\n\nLine 3: We create the to hold all the edges and edge weights. Initial values are set to .\n\nLine 4: is the number of vertices in the graph.\n\nLine 5: The holds the names of all the vertices.\n\nLine 7-10: The method is used to add an edge from vertex to vertex , with edge weight .\n\nLine 12-14: The method is used to add a vertex to the graph. The index where the vertex should belong is given with the argument, and is the name of the vertex.\n\nThe class also contains the method that runs Dijkstra's algorithm:\n\nLine 18-19: The initial distance is set to infinity for all vertices in the array, except for the start vertex, where the distance is 0.\n\nLine 20: All vertices are initially set to to mark them as not visited in the array.\n\nLine 23-28: The next current vertex is found. Outgoing edges from this vertex will be checked to see if shorter distances can be found. It is the unvisited vertex with the lowest distance from the start.\n\nLine 30-31: If the next current vertex has not been found, the algorithm is finished. This means that all vertices that are reachable from the source have been visited.\n\nLine 33: The current vertex is set as visited before relaxing adjacent vertices. This is more effective because we avoid checking the distance to the current vertex itself.\n\nLine 35-39: Distances are calculated for not visited adjacent vertices, and updated if the new calculated distance is lower.\n\nAfter defining the class, the vertices and edges must be defined to initialize the specific graph, and the complete code for this Dijkstra's algorithm example looks like this:\n\nTo run Dijkstra's algorithm on directed graphs, very few changes are needed.\n\nSimilarly to the change we needed for cycle detection for directed graphs, we just need to remove one line of code so that the adjacency matrix is not symmetric anymore.\n\nLet's implement this directed graph and run Dijkstra's algorithm from vertex D.\n\nHere is the implementation of Dijkstra's algorithm on the directed graph, with D as the source vertex:\n\nThe image below shows us the shortest distances from vertex D as calculated by Dijkstra's algorithm.\n\nThis result is similar to the previous example using Dijkstra's algorithm on the undirected graph. However, there's a key difference: in this case, vertex B cannot be visited from D, and this means that the shortest distance from D to F is now 11, not 10, because the path can no longer go through vertex B.\n\nWith a few adjustments, the actual shortest paths can also be returned by Dijkstra's algorithm, in addition to the shortest path values. So for example, instead of just returning that the shortest path value is 10 from vertex D to F, the algorithm can also return that the shortest path is \"D->E->C->B->F\".\n\nTo return the path, we create a array to keep the previous vertex in the shortest path for each vertex. The array can be used to backtrack to find the shortest path for every vertex.\n\nLine 7 and 29: The array is first initialized with values, then it is updated with the correct predecessor for each vertex as the shortest path values are updated.\n\nLine 33-42: The method uses the array and returns a string with the shortest path from start to end vertex.\n\nLet's say we are only interested in finding the shortest path between two vertices, like finding the shortest distance between vertex D and vertex F in the graph below.\n\nDijkstra's algorithm is normally used for finding the shortest path from one source vertex to all other vertices in the graph, but it can also be modified to only find the shortest path from the source to a single destination vertex, by just stopping the algorithm when the destination is reached (visited).\n\nThis means that for the specific graph in the image above, Dijkstra's algorithm will stop after visiting F (the destination vertex), before visiting vertices H, I and J because they are farther away from D than F is.\n\nBelow we can see the status of the calculated distances when Dijkstra's algorithm has found the shortest distance from D to F, and stops running.\n\nIn the image above, vertex F has just got updated with distance 10 from vertex B. Since F is the unvisited vertex with the lowest distance from D, it would normally be the next current vertex, but since it is the destination, the algorithm stops. If the algorithm did not stop, J would be the next vertex to get an updated distance 11+2=13, from vertex I.\n\nThe code below is Dijkstra's algorithm implemented to find the shortest path to a single destination vertex:\n\nLine 20-23: If we are about to choose the destination vertex as the current vertex and mark it as visited, it means we have already calculated the shortest distance to the destination vertex, and Dijkstra's algorithm can be stopped in this single destination case.\n\nWith \\(V\\) as the number of vertices in our graph, the time complexity for Dijkstra's algorithm is\n\nThe reason why we get this time complexity is that the vertex with the lowest distance must to be search for to choose the next current vertex, and that takes \\(O(V)\\) time. And since this must to be done for every vertex connected to the source, we need to factor that in, and so we get time complexity \\(O(V^2)\\) for Dijkstra's algorithm.\n\nBy using a Min-heap or Fibonacci-heap data structure for the distances instead (not yet explained in this tutorial), the time needed to search for the minimum distance vertex is reduced from \\(O(V)\\) to \\(O( \\log{V})\\), which results in an improved time complexity for Dijkstra's algorithm\n\nWhere \\(V\\) is the number of vertices in the graph, and \\(E\\) is the number of edges.\n\nThe improvement we get from using a Min-heap data structure for Dijkstra's algorithm is especially good if we have a large and sparse graph, which means a graph with a large number of vertices, but not as many edges.\n\nThe implementation of Dijkstra's algorithm with the Fibonacci-heap data structure is better for dense graphs, where each vertex has an edge to almost every other vertex."
    },
    {
        "link": "https://analyticsvidhya.com/blog/2024/10/dijkstra-algorithm",
        "document": "Suppose you are over a map of roads, and you want to know how to get from one city to another using the fewest possible roads. When delivering products through city roads or searching for the most effective route in a network or other systems, the shortest route is crucial. However, one of the best algorithms used in solving them is the Dijkstra’s Algorithm. Also originally thought by Edsger W. Dijkstra in year 1956, this algorithm effectively finds all shortest paths in a weighted graph in which each arc comes with a non negative weight. Here in this tutorial, we will show you how to implement Dijkstra’s Algorithm in steps and for practical use in Python.\n• Be able to implement Dijkstra’s Algorithm in Python.\n• Learn how to handle weighted graphs and calculate the shortest paths between nodes.\n• Know how to optimize and tweak the algorithm for performance in Python.\n\nThe algorithm is a greedy algorithm that helps identify the shortest path on a graph that starts with one node. Specifically, in the case of the non-negative weight of edges, the algorithm demonstrates a low complexity. A key idea is to have a pool of nodes for which there exists a best known distance from the source and the expansion to the set of nodes is done by choosing a node with the least known distance. This process continues until and all nodes have been processed.\n• Assign a tentative distance value to every node: set it to 0 for the initial node and to infinity for all others.\n• Set the initial node as current and mark all other nodes as unvisited.\n• For the current node, check all its unvisited neighbors and calculate their tentative distances through the current node. If this distance is less than the previously recorded tentative distance, update the distance.\n• Once done with the neighbors, mark the current node as visited. A visited node will not be checked again.\n• Select the unvisited node with the smallest tentative distance as the new current node and repeat steps 3-4.\n• Continue the process until all nodes are visited or the shortest distance to the target node is found.\n\nBefore diving into the implementation, it’s essential to understand some key concepts:\n• Graph Representation: The algorithm expects the graph to be done using nodes and edges. Every edge comes with weight – the meaning of which is the distance or cost estimated between two nodes.\n• Priority Queue: The ground algorithm that Dijkstra’s Algorithm can employ is the priority queue that determines the next node in the shortest distance.\n• Greedy Approach: The algorithm enlarges the shortest known space by yielding the nearest neutral node with respect to a focused node.\n\nWe will now implement the Dijkstra algorithm step by step using Python. We’ll represent the graph as a dictionary where keys are nodes and values are lists of tuples representing the adjacent nodes and their corresponding weights.\n\nWe need to represent the graph we are working with. We’ll use a dictionary where the keys are the nodes, and the values are lists of tuples representing the adjacent nodes and their corresponding weights.\n• Node A connects to B with weight 1 and to C with weight 4.\n• Node B connects to A, C, and D, and so on.\n\nNext, we will define the Dijkstra algorithm itself. This function will take the graph and a starting node as input and return the shortest distances from the start node to every other node in the graph. We will use Python’s to implement a priority queue to always explore the node with the smallest known distance first.\n\nWith the algorithm defined, we can now run it on our graph. Here, we’ll specify a starting node (in this case, ‘A’) and call the function to find the shortest paths from ‘A’ to all other nodes.\n\nThe output would show the shortest path from node A to all other nodes.\n\nAfter running the code, the output will display the shortest paths from the start node (A) to all other nodes in the graph.\n\nIf we run the code above, the output will be:\n\nThis result tells us that:\n• The shortest path from A to B is 1.\n• The shortest path from A to C is 3.\n• The shortest path from A to D is 4.\n\nBelow we will see the example of Dijkstra’s Algorithm in detail:\n• The algorithm starts at the source node A and calculates the shortest path to all other nodes by evaluating the edge weights between connected nodes.\n• Visited and unvisited nodes: Dijkstra’s Algorithm uses two sets of nodes – visited and unvisited. Initially, only the source node (A) is marked as visited, and the rest are considered unvisited. As the algorithm progresses, it visits nodes in order of increasing shortest distance.\n• Shortest Distances: The shortest distances are continually updated as the algorithm evaluates all possible paths. Each node is assigned a distance value, starting with 0 for the source node and infinity for the others. As better paths are found, the distances are updated.\n• Starting from node A, the algorithm checks its neighbors and calculates the tentative distances to them. The neighbors are B and C, with distances of 7 and 5, respectively.\n• The algorithm chooses node C (distance 5) as the next node to visit since it has the smallest distance.\n• From node C, the algorithm evaluates the neighboring nodes D and E, updating their distances.\n• The shortest path to node D is found, so the algorithm moves to node D.\n• From node D, it evaluates the path to the final node, F.\n• After visiting all relevant nodes, the shortest path to node F is determined to be 10.\n\nThe shortest path from A to F is A → C → D → F, with a total distance of 10.\n\nThe shortest distance to each node from the source node A is:\n\nThe algorithm efficiently calculated the shortest path using the principle of visiting the nearest unvisited node and updating distances based on the edges connecting them.\n\nDijkstra’s Algorithm can be enhanced in various ways to improve its performance, especially for large or specific applications. Below are some key optimizations:\n\nIf what you want is simply the shortest path from the source node to the destination node then you can employ early stopping. After reaching the target node it can be stopped because then extra nodes can be overlooked and have less play in this particular algorithm.\n\nBy running Dijkstra’s Algorithm from both the start and target nodes simultaneously, bidirectional Dijkstra reduces the search space. The two searches meet in the middle, significantly speeding up the process in large graphs.\n\nFor sparse graphs, using an adjacency list saves memory and speeds up the algorithm. In dense graphs, an adjacency matrix can be more efficient for edge lookups. Choosing the right graph representation can have a significant impact on performance.\n\nA Fibonacci heap improves the time complexity of Dijkstra’s Algorithm from to by making priority queue operations faster. Though more complex to implement, it’s beneficial for very large graphs with many nodes and edges.\n\nFor large, sparse graphs, consider lazy loading parts of the graph or compressing the graph to reduce memory usage. This is useful in applications like road networks or social graphs where memory can become a limiting factor.\n\nDijkstra’s Algorithm has numerous applications across various industries due to its efficiency in solving shortest path problems. Below are some key real-world use cases:\n\nOther GPS such as Google Map and Waze, also apply Dijkstra’s Algorithm to determine the shortest path between two destinations. It assists users in finding the best routes depending on roads shared to assist in real-time by providing traffic patterns or congestion, road blockage, or spillage. These systems are further improved by feature enhancements such as early stopping and bidirectional search to find the shortest possible link between two given points.\n\nOther protocols such as OSPF (Open Shortest Path First) in Computer networking application Dijkstra’s algorithm for analyzing the best possible path for data packet to travel in a network. Data is therefore transmitted with much ease, hence reducing congestion on the linked networks in the system and hence making the overall speed of the system very efficient.\n\nMany telecommunication companies apply Dijkstra’s Algorithm in the manner in which the communication’s signal is laid to suit the cables, routers and servers it will pass through. This allows information to be relayed through the shortest and best channels possible and reduce chances of delays and breaks of the channels.\n\nIn robotics and artificial intelligence conferences, conventions, and applications, Dijkstra’s Algorithm is employed in path-searching techniques which are environments with barriers for robotic or autonomous systems. Since it helps the robots move in the shortest distance while at the same time avoiding object and other obstacles, the algorithm is very essential for applications such as warehousing and automotive where robotic vehicles are now used.\n\nProbably the most popular use of Dijkstra’s Algorithm is used in the development of games for path finding in games. Characters as NPCs in games have to move through virtual environment and paths are often optimized and for this Dijkstra helps in giving shortest path among two points and avoids hindrances during game play.\n\nCommon Pitfalls and How to Avoid Them\n\nThere are some mistakes that are typical for this algorithm and we should beware of them. Below are a few, along with tips on how to avoid them:\n\nPitfall: The limitation to this type of algorithm is that it does not recognize negative weights for edges, therefore produces wrong results.\n\nSolution: If your graph contains negative weights then, it is preferable to use algorithms such as Bellman-Ford to solve it, otherwise, normalize all the weights of the graph to be non-negative before using Dijkstra each case.\n\nPitfall: Using an inefficient data structure for the priority queue (like a simple list) can drastically slow down the algorithm, especially for large graphs.\n\nSolution: Always implement the priority queue using a binary heap (e.g., Python’s ), or even better, a Fibonacci heap for faster decrease-key operations in large graphs.\n\nPitfall: Storing large graphs entirely in memory, especially dense graphs, can lead to excessive memory usage, causing performance bottlenecks or crashes.\n\nSolution: Optimize your graph representation based on the type of graph (sparse or dense). For sparse graphs, use an adjacency list; for dense graphs, an adjacency matrix may be more efficient. In very large graphs, consider lazy loading or graph compression techniques.\n\nPitfall: Continuing the algorithm after the shortest path to the target node has been found can waste computational resources.\n\nSolution: Implement early stopping by terminating the algorithm as soon as the shortest path to the target node is determined. This is especially important for large graphs or point-to-point searches.\n\nFailing to Choose the Right Algorithm for the Job\n\nPitfall: Using Dijkstra’s Algorithm in scenarios where a different algorithm might be more suitable, such as graphs with negative weights or cases requiring faster heuristic-based solutions.\n\nSolution: Analyze your graph and the problem context. If negative weights are present, opt for the Bellman-Ford Algorithm. For large graphs where an approximate solution is acceptable, consider using A search* or Greedy algorithms.\n\nDijkstra’s Algorithm can be described as an effective technique in addressing shortest path problems in cases where weights are non-negative. It is applicable to different areas which include development of networks to games. Following this tutorial, you are now able to perform Dijkstra’s Algorithm in Python by creating and modifying the given code. Altogether this implementation is good to have if one deals with routing problems or would like simply to learn about graph algorithms."
    },
    {
        "link": "https://geeksforgeeks.org/sys-maxsize-in-python",
        "document": "maxsize attribute of the sys module fetches the largest value a variable of data type Py_ssize_t can store. It is the Python platform’s pointer that dictates the maximum size of lists and strings in Python. The size value returned by maxsize depends on the platform architecture:\n• 32-bit: the value will be 2^31 – 1, i.e. 2147483647\n• 64-bit: the value will be 2^63 – 1, i.e. 9223372036854775807\n\nExample 1: Let us fetch the maximum Py_ssize_t value on a 64-bit system.\n\nExample 2: Creating a list with the maximum size.\n\nExample 3: Trying to create a list with a size greater than the maximum size."
    },
    {
        "link": "https://stackoverflow.com/questions/48138632/in-python-what-is-sys-maxsize",
        "document": "I assumed that this number ( ) was the maximum value python could handle, or store as a variable. But these commands seem to be working fine:\n\nSo is there any significance at all? Can Python handle arbitrarily large numbers, if computation resoruces permitt?\n\nNote, here's the print-out of my version is:"
    },
    {
        "link": "https://stackoverflow.com/questions/7604966/maximum-and-minimum-values-for-ints",
        "document": "See also: What is the maximum float in Python? .\n\nHow do I represent minimum and maximum values for integers in Python? In Java, we have Integer.MIN_VALUE and Integer.MAX_VALUE .\n\nIn Python 3, this question doesn't apply. The plain type is unbounded. However, you might actually be looking for information about the current interpreter's word size, which will be the same as the machine's word size in most cases. That information is still available in Python 3 as , which is the maximum value representable by a signed word. Equivalently, it's the size of the largest possible list or in-memory sequence. Generally, the maximum value representable by an unsigned word will be , and the number of bits in a word will be . See this answer for more information. In Python 2, the maximum value for plain values is available as : You can calculate the minimum value with as shown in the docs. Python seamlessly switches from plain to long integers once you exceed this value. So most of the time, you won't need to know it.\n\nIn Python 2, integers will automatically switch from a fixed-size representation into a variable width representation once you pass the value , which is either 231 - 1 or 263 - 1 depending on your platform. Notice the that gets appended here: Numbers are created by numeric literals or as the result of built-in functions and operators. Unadorned integer literals (including binary, hex, and octal numbers) yield plain integers unless the value they denote is too large to be represented as a plain integer, in which case they yield a long integer. Integer literals with an or suffix yield long integers ( is preferred because looks too much like eleven!). Python tries very hard to pretend its integers are mathematical integers and are unbounded. It can, for instance, calculate a googol with ease:\n\nIf you want the max for array or list indices (equivalent to in C/C++), you can use numpy: This is same as however advantage is that you don't need import sys just for this. If you want max for native int on the machine: You can look at other available types in doc. For floats you can also use .\n\nOn CPython 3.11 on a 64-bit system, the maximum and minimal integers are You will need 40 exabytes of memory to create one, which would cost $70 billion at today's (July 2023) prices of $57 per 32GB on NewEgg, so in practice Python's maximum integer is limited by how much memory you have in your computer. CPython 3.11 stores integers like this (I simplified the actual code by taking out all the macros): struct PyLongObject { Py_ssize_t ob_refcnt; /* Metadata for garbage collection */ PyTypeObject* ob_type; /* Metadata for type() */ Py_ssize_t ob_size; /* Number of items in ob_digit */ uint32_t ob_digit[1]; /* Array of 32-bit integers */ }; So on a 64-bit system, Python integers are implemented as an array of 32-bit integers storing the absolute value of the integer (but 2 of the bits of each integer aren't used) and a 64-bit signed two's complement integer stores the length of that array as well as the sign of the Python integer, so a negative integer has a negative \"size\".\n\nis not the actually the maximum integer value which is supported. You can double maxsize and multiply it by itself and it stays a valid and correct value. However, if you try , it will hang your machine for a significant amount of time. As many have pointed out, the byte and bit size does not seem to be relevant because it practically doesn't exist. I guess python just happily expands it's integers when it needs more memory space. So in general there is no limit. Now, if you're talking about packing or storing integers in a safe way where they can later be retrieved with integrity then of course that is relevant. I'm really not sure about packing but I know python's module handles those things well. String representations obviously have no practical limit. So really, the bottom line is: what is your applications limit? What does it require for numeric data? Use that limit instead of python's fairly nonexistent integer limit."
    },
    {
        "link": "https://datacamp.com/tutorial/everything-you-need-to-know-about-pythons-maximum-integer-value",
        "document": "Master the basics of data analysis with Python in just four hours. This online course will introduce the Python interface and explore popular packages."
    },
    {
        "link": "https://freecodecamp.org/news/maximum-integer-size-in-python",
        "document": "You can check the maximum integer size in Python using the property of the module.\n\nIn this article, you'll learn about the maximum integer size in Python. You'll also see the differences in Python 2 and Python 3.\n\nThe maximum value of an integer shouldn't bother you. With the current version of Python, the data type has the capacity to hold very large integer values.\n\nWhat Is the Maximum Integer Size in Python?\n\nIn Python 2, you can check the max integer size using the module's property.\n\nPython 2 has a built-in data type called which stores integer values larger than what can handle.\n\nYou can do the same thing for Python 3 using :\n\nNote that the value in the code above is not the maximum capacity of the data type in the current version of Python.\n\nIf you multiply that number (9223372036854775807) by a very large number in Python 2, will be returned.\n\nOn the other hand, Python 3 can handle the operation:\n\nYou can perform operation with large integers values in Python without worrying about reaching the max value.\n\nThe only limitation to using these large values is the available memory in the systems where they're being used.\n\nIn this article, you have learned about the max integer size in Python. You have also seen some code examples that showed the maximum integer size in Python 2 and Python 3.\n\nWith modern Python, you don't have to worry about reaching a maximum integer size. Just make sure you have enough memory to handle the computation of very large integer operations, and you're good to go."
    }
]