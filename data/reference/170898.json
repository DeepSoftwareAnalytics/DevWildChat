[
    {
        "link": "https://learn.microsoft.com/en-us/sql/t-sql/functions/hashbytes-transact-sql?view=sql-server-ver16",
        "document": "Applies to: SQL Server Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics Analytics Platform System (PDW) SQL analytics endpoint in Microsoft Fabric Warehouse in Microsoft Fabric\n\nReturns the MD2, MD4, MD5, SHA, SHA1, or SHA2 hash of its input in SQL Server.\n\n\n\n Identifies the hashing algorithm to be used to hash the input. This is a required argument with no default. The single quotation marks are required. Beginning with SQL Server 2016 (13.x), all algorithms other than SHA2_256, and SHA2_512 are deprecated.\n\n\n\n Specifies a variable containing the data to be hashed. is varchar, nvarchar, or varbinary.\n\n'input'\n\n Specifies an expression that evaluates to a character or binary string to be hashed.\n\nThe output conforms to the algorithm standard: 128 bits (16 bytes) for MD2, MD4, and MD5; 160 bits (20 bytes) for SHA and SHA1; 256 bits (32 bytes) for SHA2_256, and 512 bits (64 bytes) for SHA2_512.\n\nApplies to: SQL Server 2012 (11.x) and later\n\nFor SQL Server 2014 (12.x) and earlier, allowed input values are limited to 8000 bytes.\n\nConsider using or as alternatives to compute a hash value.\n\nThe MD2, MD4, MD5, SHA, and SHA1 algorithms are deprecated starting with SQL Server 2016 (13.x). Use SHA2_256 or SHA2_512 instead. Older algorithms will continue working, but they will raise a deprecation event.\n\nThe following example returns the hash of the nvarchar data stored in variable .\n\nThe following example returns the SHA2_256 hash of the values in column in the table ."
    },
    {
        "link": "https://sqlshack.com/the-hashbytes-function-in-t-sql",
        "document": "One of the paramount ways to guard data within a database is to utilize database encryption. However, no one encryption solution is perfect for all databases. Which encryption solution you select totally depends on the requirements of your application. Note that more powerful encryption for larger amounts of data requires a healthy amount of CPU. So, be prepared in the event that that introduction of encryption increases the system load.\n\nThis article will start with the divergence of hashing and encryption, and give all the details of the HashBytes function used in T-SQL\n• Details about the function with syntaxes and clear examples\n• How to store and check passwords with hashbytes function\n• How to deal with the restriction of the return value 8000 bytes limit\n• Some restrictions such as Collation difference, or data type with Unicode data\n\nThere are two main methodologies to safeguard your data: hashing and encryption. Encryption is accomplished via one of several different algorithms that return a value that can be decrypted through the correct decryption key. Each of the different encryption options provides you with a different strength of encryption. As I have mentioned earlier, the stronger level of encryption you use, the greater the CPU load on the Microsoft SQL Server.\n\nHowever, if we can talk about hashing values, we are mainly referring to hashing algorithms. Hashing algorithms provide us a one-way technique that has been used to mask data, in which we have a minimal chance that someone could reverse the hashed value back to the original value. And with hashed techniques, every time you hash the original value you get the same hashed value.\n\nMicrosoft SQL Server has supported the same hashing values from Microsoft SQL Server 2005 to Microsoft SQL Server 2008 R2. You can use MD2, MD4, MD5, SHA, or SHA1 to create hashes of your data. These algorithms are limited up to 20 bytes only.\n\nIn SQL Server 2012, we have an enhancement in this function and now it supports SHA2_256, SHA2_512 algorithms that can generate 32 and 64 bytes hash codes for the respective input.\n\nBeginning with SQL Server 2016, all algorithms other than SHA2_256, and SHA2_512 are deprecated. Older algorithms (not recommended) will continue working, but they will raise a deprecation event.\n\nHashing can be created, regardless of the algorithm used, via the HashBytes system function. A hash is an essential calculation based on the values of the input, and two inputs that are the same ought to produce the same hash.\n\nIf we talk about the syntax for SQL Server, Azure SQL Database, Azure SQL Data Warehouse, and Parallel Data Warehouse the below images describe the syntax in detail.\n\n‘<algorithm>’ \n\n In this, we have to initiate the hashing algorithm to be used to hash the input. This is a mandatory field with no default. And its also requires a single quotation mark. Starting with SQL Server 2016, all algorithms other than SHA2_256, and SHA2_512 are deprecated. Older algorithms (not recommended) will continue working, but they will raise a deprecation event.\n\n@input \n\n In this, we have to specify a variable that contains the data to be hashed. @input is varchar, nvarchar, or varbinary.\n\n‘input’ \n\n this specifies an expression that evaluates to a character or binary string to be hashed.\n\nThe output conforms to the algorithm standard: 128 bits (16 bytes) for MD2, MD4, and MD5; 160 bits (20 bytes) for SHA and SHA1; 256 bits (32 bytes) for SHA2_256 and 512 bits (64 bytes) for SHA2_512.\n\nThe below image depicts all supported algorithms with their respective lengths\n\nThe HashBytes function accepts two values: the algorithm to use and the value to get the hash for.\n\nThe HashBytes system function does not support all data types that Microsoft SQL Server supports before SQL server 2016. The biggest problem with this lack of support is that the HashBytes function doesn’t support character strings longer than 8000 bytes (For SQL Server 2014 and earlier, allowed input values are limited to 8000 bytes.)\n\nTo be more specific, when using ASCII strings with the CHAR or VARCHAR data types, the HashBytes system function will accept up to 8000 characters. When using Unicode strings with the NCHAR or NVARCHAR data types, the HashBytes system function will accept up to 4000 characters. We will provide a solution how to come up with this particular restriction.\n\nI will now explain the HashBytes function as it existed before 2014, not allowing large string in SQL Server and its solution.\n\nLet’s quickly look at the example.\n\nThe above code will throw the exception “String or binary data would be truncated.” as shown below:\n\nTo overcome the limitation, I have come up with a solution, a SQL function, to break down the string into multiple sub-parts and apply the hashing separately and later re-constitute them back into a single string\n\nThe script is as below:\n\nNow we execute scripts and the error has vanished.\n\nI hope this will help you whenever you may need to generate hashes for larger strings in SQL Server versions prior to 2014\n\nFirst of all, we have to make sure that the field or column we have used to preserve password for store the hash code is of data type varbinary. Then, use the HashBytes function in the insert statement to generate the hash for the password and store it in the column. Below is the salient example of storing a password in hash code with SHA2 512 algorithm and comparing the hash-coded password in a select statement.\n\nWe should review some gray areas before uses it.\n\nFirst, we have to take care of the collation; if the collation is different, the output will be different.\n\nSecond, the column definition, if we used same data type but the length is different, then there should be the same result. To elaborate in depth, review below example of VARCHAR(50) and VARCHAR(100), we can test the output:\n\nBoth SELECT statements return the similar hashes value such as below:\n\nHowever, although, it has a similar data type, one should be aware that VARCHAR and NVARCHAR will not produce the same HashBytes value, even with the same string. To illustrate, review the following select statements.\n\nIt can be noted that collations are only reviewed when we compare values between two files. The reason why the n[var]char produces a different result because it’s two bytes per character whilst the[var]char is a single byte per character.\n\nFor further understating, HashBytes, as the name implies, hashes a set of bytes, and so the two inputs return different results.\n\nAfter reviewing all the points elaborated above it can be said that, there should be another hash for the similar values by using different algorithms.\n\nFurthermore, it can be easily seen if something has changed while comparing the same string to itself if hashes algorithm is different than it is the exception. Especially, I prefer to use it for password protection, so, one can hash a password in the database table and then have the user enter their own version, hash it, and compare the results. In this way, the system end (front end) never knows the value. Just make sure to double check you have used same the same algorithm"
    },
    {
        "link": "https://stackoverflow.com/questions/52485862/how-to-use-hashbytes-function-in-sql-server-for-multiple-columns",
        "document": "I have a requirement wherein I have to create hashvalue which consist of all columns of a table. With this can be done easily, but is not recommended as per Microsoft:\n\nIf at least one of the values in the expression list changes, the list checksum will probably change. However, this is not guaranteed. Therefore, to detect whether values have changed, we recommend the use of CHECKSUM only if your application can tolerate an occasional missed change. Otherwise, consider using HashBytes instead. With a specified MD5 hash algorithm, the probability that HashBytes will return the same result, for two different inputs, is much lower compared to CHECKSUM.\n\nNow the problem is even though is more reliable compared to checksum but there doesn't seem to be an easy way to create it on multiple columns.\n\nAn example in the checksum,\n\nHow can we do the above using instead of checksum?"
    },
    {
        "link": "https://learn.microsoft.com/lt-lt/sql/t-sql/functions/hashbytes-transact-sql?view=sql-server-ver16",
        "document": "Applies to: SQL Server Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics Analytics Platform System (PDW) SQL analytics endpoint in Microsoft Fabric Warehouse in Microsoft Fabric\n\nReturns the MD2, MD4, MD5, SHA, SHA1, or SHA2 hash of its input in SQL Server.\n\n\n\n Identifies the hashing algorithm to be used to hash the input. This is a required argument with no default. The single quotation marks are required. Beginning with SQL Server 2016 (13.x), all algorithms other than SHA2_256, and SHA2_512 are deprecated.\n\n\n\n Specifies a variable containing the data to be hashed. is varchar, nvarchar, or varbinary.\n\n'input'\n\n Specifies an expression that evaluates to a character or binary string to be hashed.\n\nThe output conforms to the algorithm standard: 128 bits (16 bytes) for MD2, MD4, and MD5; 160 bits (20 bytes) for SHA and SHA1; 256 bits (32 bytes) for SHA2_256, and 512 bits (64 bytes) for SHA2_512.\n\nApplies to: SQL Server 2012 (11.x) and later\n\nFor SQL Server 2014 (12.x) and earlier, allowed input values are limited to 8000 bytes.\n\nConsider using or as alternatives to compute a hash value.\n\nThe MD2, MD4, MD5, SHA, and SHA1 algorithms are deprecated starting with SQL Server 2016 (13.x). Use SHA2_256 or SHA2_512 instead. Older algorithms will continue working, but they will raise a deprecation event.\n\nThe following example returns the hash of the nvarchar data stored in variable .\n\nThe following example returns the SHA2_256 hash of the values in column in the table ."
    },
    {
        "link": "https://stackoverflow.com/questions/10952213/generate-unique-hash-for-a-field-in-sql-server",
        "document": "I'm in the process of writing a Membership Provider for use with our existing membership base. I use EF4.1 for all of my database access and one of the issued that I'm running into is when the DB was originally setup the relationships were done programmatically instead of in the db. One if the relationships needs to be made on a column that isn't required for all of our users, but in order to make the relationships does need to be unique (from my understanding).\n\nMy solution that I believe will work is to do an MD5 hash on the userid field (which is unique ...which would/should guarantee a unique value in that field). The part that I'm having issues with on sql server is the query that would do this WITHOUT replacing the existing values stored in the employeeNum field (the one in question).\n\nSo in a nutshell my question is. What is the best way to get a unique value in the field (possibly based on an md5 hash of the field) on all the rows in which a value isn't already present. Also, to a minor/major extent...does this sound like a good plan?"
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/system-stored-procedures/sp-executesql-transact-sql?view=sql-server-ver16",
        "document": "Applies to: SQL Server Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics Analytics Platform System (PDW) SQL analytics endpoint in Microsoft Fabric Warehouse in Microsoft Fabric\n\nExecutes a Transact-SQL statement or batch that can be reused many times, or one that is built dynamically. The Transact-SQL statement or batch can contain embedded parameters.\n\nThe code samples in this article use the or sample database, which you can download from the Microsoft SQL Server Samples and Community Projects home page.\n\nA Unicode string that contains a Transact-SQL statement or batch. @stmt must be either a Unicode constant or a Unicode variable. More complex Unicode expressions, such as concatenating two strings with the operator, aren't allowed. Character constants aren't allowed. Unicode constants must be prefixed with an . For example, the Unicode constant is valid, but the character constant isn't. The size of the string is limited only by available database server memory. On 64-bit servers, the size of the string is limited to 2 GB, the maximum size of nvarchar(max).\n\n@stmt can contain parameters having the same form as a variable name. For example:\n\nEach parameter included in @stmt must have a corresponding entry in both the @params parameter definition list and the parameter values list.\n\nA string that contains the definitions of all parameters that are embedded in @stmt. The string must be either a Unicode constant or a Unicode variable. Each parameter definition consists of a parameter name and a data type. n is a placeholder that indicates more parameter definitions. Every parameter specified in @stmt must be defined in @params. If the Transact-SQL statement or batch in @stmt doesn't contain parameters, @params isn't required. The default value for this parameter is .\n\nA value for the first parameter that is defined in the parameter string. The value can be a Unicode constant or a Unicode variable. There must be a parameter value supplied for every parameter included in @stmt. The values aren't required when the Transact-SQL statement or batch in @stmt has no parameters.\n\nIndicates that the parameter is an output parameter. text, ntext, and image parameters can be used as parameters, unless the procedure is a common language runtime (CLR) procedure. An output parameter that uses the keyword can be a cursor placeholder, unless the procedure is a CLR procedure.\n\nA placeholder for the values of extra parameters. Values can only be constants or variables. Values can't be more complex expressions such as functions, or expressions built by using operators.\n\nReturns the result sets from all the SQL statements built into the SQL string.\n\nparameters must be entered in the specific order as described in the Syntax section earlier in this article. If the parameters are entered out of order, an error message occurs.\n\nhas the same behavior as regarding batches, the scope of names, and database context. The Transact-SQL statement or batch in the @stmt parameter isn't compiled until the statement is executed. The contents of @stmt are then compiled and executed as an execution plan separate from the execution plan of the batch that called . The batch can't reference variables declared in the batch that calls . Local cursors or variables in the batch aren't visible to the batch that calls . Changes in database context last only to the end of the statement.\n\ncan be used instead of stored procedures to execute a Transact-SQL statement many times when the change in parameter values to the statement is the only variation. Because the Transact-SQL statement itself remains constant and only the parameter values change, the SQL Server query optimizer is likely to reuse the execution plan it generates for the first execution. In this scenario, performance is equivalent to that of a stored procedure.\n\nsupports the setting of parameter values separately from the Transact-SQL string, as shown in the following example.\n\nOutput parameters can also be used with . The following example retrieves a job title from the table in the sample database, and returns it in the output parameter .\n\nBeing able to substitute parameters in offers the following advantages over using the statement to execute a string:\n• None Because the actual text of the Transact-SQL statement in the string doesn't change between executions, the query optimizer probably matches the Transact-SQL statement in the second execution with the execution plan generated for the first execution. Therefore, SQL Server doesn't have to compile the second statement.\n• None The Transact-SQL string is built only once.\n• None The integer parameter is specified in its native format. Casting to Unicode isn't required.\n\nWhen the OPTIMIZED_SP_EXECUTESQL database scoped configuration is enabled, the compilation behavior of batches submitted using becomes identical to the serialized compilation behavior that objects such as stored procedures and triggers currently employ.\n\nWhen batches are identical (excluding any parameter differences), the option tries to obtain a compile lock as an enforcement mechanism to guarantee that the compilation process is serialized. This lock ensures that if multiple sessions invoke simultaneously, those sessions will wait while trying to obtain an exclusive compile lock after the first session starts the compilation process. The first execution of compiles and inserts its compiled plan into the plan cache. Other sessions abort waiting on the compile lock and reuse the plan once it becomes available.\n\nWithout the option, multiple invocations of identical batches executed via compile in parallel and place their own copies of a compiled plan into the plan cache, which replace or duplicate plan cache entries in some cases.\n\nis off by default. To enable at the database level, use the following Transact-SQL statement:\n\nThe following example creates and executes a statement that contains an embedded parameter named .\n\nThe following example shows using to execute a dynamically built string. The example stored procedure is used to insert data into a set of tables that are used to partition sales data for a year. There's one table for each month of the year that has the following format:\n\nThis sample stored procedure dynamically builds and executes an statement to insert new orders into the correct table. The example uses the order date to build the name of the table that should contain the data, and then incorporates that name into an statement.\n\nUsing in this procedure is more efficient than using to execute the dynamically built string, because it allows for the use of parameter markers. Parameter markers make it more likely that the Database Engine reuses the generated query plan, which helps to avoid additional query compilations. With , each string is unique because the parameter values are different, and would be appended to the end of the dynamically generated string. When executed, the query wouldn't be parameterized in a way that encourages plan reuse, and would have to be compiled before each statement is executed, which would add a separate cached entry of the query in the plan cache.\n\nC. Use the OUTPUT parameter\n\nThe following example uses an parameter to store the result set generated by the statement in the parameter. Two statements are then executed that use the value of the parameter.\n\nThe following example creates and executes a statement that contains an embedded parameter named ."
    },
    {
        "link": "https://sqlshack.com/introduction-to-sp_executesql-stored-procedure-with-examples",
        "document": "The sp_executesql is a built-in stored procedure in SQL Server that enables to execute of the dynamically constructed SQL statements or batches. Executing the dynamically constructed SQL batches is a technique used to overcome different issues in SQL programming sometimes. For example, when we want to determine the displayed columns in our reports, this procedure might be a solution option for us. In the simplest sense, this procedure takes a dynamically constructed SQL batch and other parameters, then execute it in the runtime and, finally, it returns the result.\n• Note: In this article’s examples, the sample AdventureWorks database will be used.\n\nThe following code describes the syntax:\n\n@stmt parameter is used to specify dynamically generated SQL statement or batch. The data type of this parameter must be Unicode strings, for this reason, we have to add N prefix for the direct text usage or have to use nvarchar or nchar data typed variables.\n\n@parameternameN_datatype defines the parameter’s name and data type that has been used in the dynamically constructed SQL statements.\n\nWith the help of the @parameternameN=’ValueN’ expression, we can assign a value to the defined parameters which are placed in the SQL statement. In the following sections of the article, we will explore the usage details with examples from easy to difficult.\n\nThe purpose of this example is, retrieving data from the Person table which is taking part under the same schema on the AdventureWorks database:\n\nThe dynamically constructed SQL statement will be assigned to the @SqlStatment variable. The @ColName variable is used to specify the column names, that we want to display in the result set of the query. As a last, we will filter the Person table data with the @PerType parameter. This parameter data type will be nchar(2) and filter the data whose Persontype column expressions equal to “EM”. As the last step, we will execute the query and achieve the result:\n\nThe result set of the query shows only FirstName, MiddleName and LastName columns because of the assigned value of the @ColNames variable. At the same time, we can adjust the displaying column names with this parameter. For example, the following example will be displayed only FirstName column:\n\nsp_executesql provides to return execution result of the dynamically constructed SQL statement or batch. The OUTPUT parameter plays a key role to resolve this case. In this example, we will count the row number of the PersonPhone table and then we will set the return value to a variable with the OUTPUT parameter. The trick of this usage is to indicate the @RowNumber parameter as an OUTPUT parameter and then we assigned this internal parameter value to the @Result parameter:\n\nThe EXEC statement is another option to execute the dynamic SQL statements. For example, we can execute the following dynamically constructed SQL statement through the EXEC statement:\n\nIn the previous example, we executed the dynamically constructed query with the EXEC statement but we need to take account one point about it. We could not parametrize the EXEC statement and this is the main drawback of it.\n\nsp_executesql has some advantages comparing to the EXEC statement. Now, let’s take a glance at these:\n• sp_executesql has the ability to reuse the cached query plans\n\nEach query executed in SQL Server is compiled before it is executed. This query compilation process generates an output that is called the query plan. However, this query compilation process might be very expensive sometimes. For this reason, SQL Server wishes to reuse the cached query plans as possible as for the same queries in order to degrade the query compilation costs. Now, we will prove this idea.\n\nAt first, we will clear all the cached plans with FREEPROCCACHE. However, do not execute this command in the production environment because it could be damage to the performance of the SQL Server:\n\nIn this step, we will execute the following query 3 times with the random parameters.\n\nNow we will check out the generated query plans in the sys.dm_exec_cached_plans:\n\nNow, we will repeat a similar test scenario for the EXEC statement:\n\nIn this step, we will execute the dynamically constructed query 3 times for the random parameters with the EXEC statement:\n\nNow, we will re-check sys.dm_exec_cached_plans view to see how many query plans were created:\n\nAs a result, sp_executesql generated a one query plan in the first execution of the query and then it used the same query plan again and again. In spite of that, the EXEC statement created new query plans for each query execution. This type of usage could consume SQL Server resources and could be caused by performance issues.\n• Note: sp_executesql allows for generating parameterized dynamic queries. So that it is more secure to SQL injection attacks. EXEC statement is more vulnerable in terms of SQL injections.\n\nIn this article, we explored the sp_executesql procedure details and learned the usage methods. This procedure is very useful to resolve the dynamic query issues however, we have to consider the SQL injection issues when we decide to use dynamic queries in SQL Server."
    },
    {
        "link": "https://stackoverflow.com/questions/68531204/executing-dynamic-sql-code-with-sp-executesql-with-return-value",
        "document": "I'm looking for a way to execute the @batchSQL dynamic SQL through sp_executesql. I'm working on synchronizing tables between two databases and due to poor performance trying to see if synchronizing data in batches could help solve the performance issues.\n\nThe batching part is just an excerpt, but it would execute all stored procedures that synchronize data by starting with the first record in a table and calculating the next batch size based on how many records it can synchronize within one minute.\n\nThere is a default set for the first run: 10 for @batchSize and 0 for @batchRow. The calculations are not really relevant to the issue so I've left that part out and just kept the important bits. In the @batchSQL variable the @batchProcess contains the name of the next stored procedure to run.\n\nIn order to run the second batching process after the first 'default' run, the @cursRows variable gets the number of rows in the cursor with @@CURSOR_ROWS. This way the second batch process will start from the first record not yet synchronized. However after the sp_executesql line runs, the value returned is null in the BatchSize column of the BatchTable table.\n\nWhen I'm not executing it as dynamic sql but hardcoding the @batchSQL line with the same values as used in the default run, it returns the value from @cursRows correctly.\n\nHere is the procedure that I'm testing with called by the previous code snippet.\n\nDoes anyone have an idea how to get @cursRows back from this query?\n\nAll help is greatly appreciated!"
    },
    {
        "link": "https://sqlshack.com/dynamic-sql-in-sql-server",
        "document": "In this article, we will review how to construct and execute dynamic SQL statements in SQL Server with different examples.\n\nDynamic SQL is the SQL statement that is constructed and executed at runtime based on input parameters passed. Let us go through some examples using the EXEC command and sp_executesql extended stored procedure.\n\nEXEC command executes a stored procedure or string passed to it. Please refer to EXEC SQL overview and examples for more details and examples on the EXEC command.\n\nThe following example demonstrates constructing the SQL statement using the input variable and executing the SQL statement using the EXEC command.\n\nThere is a possibility of SQL injection when you construct the SQL statement by concatenating strings from user input values. I hope to cover the SQL injection and some methods to prevent SQL Injection in my future articles.\n\nWe should take care of null values when concatenating strings from parameters using ‘+’ operator. In the below example, I commented out the statement that sets a value to variable “@pid”.\n\nBy default, the variable “@pid” is NULL as we did not set any value. The final statement constructed after concatenation is blank as ‘+’ operator does not handle null values. Please refer to the below image that shows the final value of “@SQL” variable is blank.\n\nIn this case, use the ISNULL function to construct a proper SQL statement while concatenating strings using ‘+’ operator.\n\nEXEC command does not re-use the compiled plan stored in the plan cache. Execute the following query and check for the cached plans.\n\nPlease refer to the below image that shows two separate plans created when the above query is executed for two different parameters.\n\nsp_executesql is an extended stored procedure that can be used to execute dynamic SQL statements in SQL Server. we need to pass the SQL statement and definition of the parameters used in the SQL statement and finally set the values to the parameters used in the query.\n\nFollowing is the syntax of executing dynamic SQL statements using sp_executesql extended stored procedure.\n\nBelow example demonstrates executing dynamic SQL statement by passing parameters to sp_executesql extended stored procedure.\n\nsp_executesql reuses the compiled plan when the statement is executed for different parameters. Execute the following query and check for the cached plan.\n\nPlease refer to the below image that shows the same plan is being used when the statement is executed with different parameters.\n\nFollowing is the example of using dynamic SQL inside a stored procedure. For demo purpose, I used the Product table from the AdventureWorksLT database. This stored procedure is used to search for products based on different columns like name, color, productid, and the product number. The dynamic SQL statement is constructed based on the input parameters passed to the stored procedure and is executed by the EXEC command.\n\nWhen we execute the stored procedure with input parameter productid only, the SQL statement is constructed as shown in the below image.\n\nPlease refer to the below image that shows a different SQL statement constructed when productid and product number are passed as input parameters to the stored procedure.\n\nLet us re-write the stored procedure to form dynamic SQL and execute it using sp_executesql extended stored procedure. Please refer to the below sample script.\n\nLet us execute below sample thread that will retrieve all the products that are red.\n\nsp_executesql extended stored procedure supports the output parameter to store the value returned by the select query and use the output variable in another statement.\n\nFollowing is the example script which shows the usage of the output variable in sp_executesql.\n\nThe local temp table created by executing dynamic SQL cannot be accessed outside the execution of dynamic SQL. It throws invalid object error as shown in the below image.\n\nA workaround for this is to create the local temp table outside and use it in the dynamic SQL. Following is the example that demonstrates this scenario.\n\nPlease refer to the below image. we can see that the data is inserted in the temp table and can be accessed again.\n\nIn this article, we explored how to construct and execute dynamic SQL in SQL Server using the EXEC command and sp_executesql extended stored procedure with different examples. In case you have any questions, please feel free to ask in the comment section below."
    },
    {
        "link": "https://forums.sqlteam.com/t/how-to-use-sp-executesql-for-dynamic-sql-which-is-stored-in-sql-table/15667",
        "document": "Here is an example of how you would do it. That said, don't do it. It is very vulnerable to SQL injection attacks. If you can describe your end goal, people on this forum might be able to suggest safer/better alternatives. CREATE TABLE #tmp (QueryString NVARCHAR(4000)); INSERT INTO #tmp VALUES ('SELECT * FROM sys.tables') DECLARE @x NVARCHAR(4000); SELECT TOP (1) @x = QueryString FROM #tmp; EXEC sys.sp_executesql @x;\n\nThe return code from sp_executesql is zero if the job was successful, and non-zero on failure. So @i being zero simply means the query ran successfully. If you want to get the output from the result of the query, you have to use an OUT parameter. There is a very specific way for doing this. Look at this page, and in particular the example code that I have copied below from that page. Here, @max_titleOUT is the parameter that returns the desired result. Notice how the OUTPUT keyword is specified both in @ParmDefinition and in sp_executesql call for that parameter.\n\n----STEP1 EXECUTE STATAMENT FROM DIRECT QUERY IS UPATING THE SALESDETAIL AMOUNT\n\n DECLARE @SQLCODE NVARCHAR(1000)\n\n DECLARE @statement NVARCHAR(400)\n\n DECLARE @parameterDefinition NVARCHAR(400)\n\n DECLARE @BID INT=1\n\n DECLARE @i int\n\n SET @SQLCODE='UPDATE SALESDETAIL SET AMOUNT=50 WHERE Batchid=@batchid'\n\n SET @statement =@SQLCODE\n\n SET @parameterDefinition = N'@batchid int'\n\n execute @i= sp_executesql @statement, @parameterDefinition, @BatchID=@BID (3 rows affected)\n\n 0\n\n ---ABOVE STEP IS WORKING\n\n ----STEP2 EXECUTE STATAMENT FROM SQL TABLE IS NOT UPATING THE SALESDETAIL AMOUNT --IN THE MESSAGE WINDOW\n\n 0\n\n STEP2 NOT UPDATING THE AMOUNT THIS IS THE PROBLEM\n\nThere is no reason why storing sql code in a table, pulling it out and executing it shouldn't work; whether that is a good idea (as per JamesK & yosiasz) is a different conversation Looking at your \"demo\" code the one thing missing is any actual data in the SQLCODE table to execute use tempdb; DROP TABLE IF EXISTS #wibble DROP TABLE IF EXISTS #code -- table to hold \"code\" create table #code ( code varchar(100) ) -- dummy table with some data CREATE TABLE #wibble ( wobble VARCHAR(10) ) INSERT INTO #wibble SELECT * FROM (VALUES ('some'), ('data')) as v(v) -- set up variables requried DECLARE @SQL NVARCHAR(100) = 'SELECT * FROM #WIBBLE' DECLARE @RC INTEGER -- SQL parameters DECLARE @parameterDefinition NVARCHAR(400) = N'@batchid int' DECLARE @BID INT=1 -- run sp_execute sql with just variables -- OUTPUT, 2 rows EXEC @RC = SP_EXECUTESQL @SQL SELECT @RC -- prove #code is empty -- OUTPUT, 0 rows SELECT * FROM #code -- get NON existent code from #code and execute -- OUTPUT 0 rows SELECT @SQL = (SELECT code from #code) -- prove @sql is blank SELECT @SQL AS '@sql is empty' -- EXECUTE EXEC @RC = SP_EXECUTESQL @SQL SELECT @RC -- same again but with (spurious) parameters attached, same 0 row output EXEC @RC = SP_EXECUTESQL @SQL, @parameterDefinition, @BatchID=@BID SELECT @RC -- actually populate #code INSERT INTO #code SELECT 'SELECT * FROM #WIBBLE' -- PROVE #code has ... er ... code SELECT * FROM #code -- now get code from #code and execute -- OUTPUT, 2 rows SELECT @SQL = (SELECT code from #code) -- prove @SQL has \"code\" SELECT @SQL AS '@sql is not empty' -- execute EXEC @RC = SP_EXECUTESQL @SQL SELECT @RC -- and again, with parameters, 2 rows EXEC @RC = SP_EXECUTESQL @SQL, @parameterDefinition, @BatchID=@BID SELECT @RC"
    }
]