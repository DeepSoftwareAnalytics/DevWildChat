[
    {
        "link": "https://geeksforgeeks.org/python-program-for-dijkstras-shortest-path-algorithm-greedy-algo-7",
        "document": "Given a graph and a source vertex in the graph, find the shortest paths from source to all vertices in the given graph. Dijkstra’s algorithm is a popular algorithm for solving many single-source shortest path problems having non-negative edge weight in the graphs i.e., it is to find the shortest distance between two vertices on a graph. It was conceived by Dutch computer scientist Edsger W. Dijkstra in 1956.\n\nDijkstra’s algorithm is very similar to Prim’s algorithm for minimum spanning tree. Like Prim’s MST, we generate an SPT (shortest path tree) with a given source as root. We maintain two sets, one set contains vertices included in the shortest-path tree, another set includes vertices not yet included in the shortest-path tree. At every step of the algorithm, we find a vertex that is in the other set (set of not yet included) and has a minimum distance from the source. Below are the detailed steps used in Dijkstra’s algorithm to find the shortest path from a single source vertex to all other vertices in the given graph.\n\n1) Create a set sptSet (shortest path tree set) that keeps track of vertices included in shortest path tree, i.e., whose minimum distance from source is calculated and finalized. Initially, this set is empty. \n\n2) Assign a distance value to all vertices in the input graph. Initialize all distance values as INFINITE. Assign distance value as 0 for the source vertex so that it is picked first. \n\n3) While sptSet doesn’t include all vertices:\n• None Pick a vertex u which is not there in sptSet and has minimum distance value.\n• None Update distance value of all adjacent vertices of u. To update the distance values, iterate through all adjacent vertices. For every adjacent vertex v, if the sum of a distance value of u (from source) and weight of edge u-v, is less than the distance value of v, then update the distance value of v.\n\nBelow is the Python Implementation of the above discussed algorithm:\n\n# A utility function to find the vertex with # minimum distance value, from the set of vertices # not yet included in shortest path tree # Search not nearest vertex not in the # the set of vertices not yet processed. # u is always equal to src in first iteration # Put the minimum distance vertex in the # Update dist value of the adjacent vertices # of the picked vertex only if the current # distance is greater than new distance and # the vertex in not in the shortest path tree\n\nTime Complexity: The time complexity of Dijkstra’s algorithm is O(V^2). This is because the algorithm uses two nested loops to traverse the graph and find the shortest path from the source node to all other nodes.\n\nSpace Complexity: The space complexity of Dijkstra’s algorithm is O(V), where V is the number of vertices in the graph. This is because the algorithm uses an array of size V to store the distances from the source node to all other nodes."
    },
    {
        "link": "https://udacity.com/blog/2021/10/implementing-dijkstras-algorithm-in-python.html",
        "document": "What do GPS navigation devices and websites for booking flights have in common? As it turns out, a lot! For one, both technologies employ Dijkstra’s shortest path algorithm.\n\nIn this article, we’ll give an overview of Dijkstra’s algorithm and provide an easy-to-follow implementation in Python. After we lay out the explanation in plain English, you’ll see that the Python implementation is not that much different.\n\nIn 1956, Dutch programmer Edsger W. Dijkstra had a practical question. He wanted to figure out the shortest way to travel from Rotterdam to Groningen. But he did not simply consult a map to calculate the distances of the roads he would need to take. Instead, Dijkstra took a computer scientist’s approach: he abstracted from the problem by filtering out the specifics such as traveling from city A to city B. This allowed him to discover the more general problem of graph search. Thus, Dijkstra’s algorithm was born.\n\nDijkstra’s algorithm is a popular search algorithm used to determine the shortest path between two nodes in a graph. In the original scenario, the graph represented the Netherlands, the graph’s nodes represented different Dutch cities, and the edges represented the roads between the cities.\n\nYou can apply Dijkstra’s algorithm to any problem that can be represented as a graph. Friend suggestions on social media, routing packets over the internet, or finding a way through a maze—the algorithm can do it all. But how does it actually work?\n\nRecall that Dijkstra’s algorithm operates on graphs, meaning that it can address a problem only if it can be represented in a graph-like structure. The example we’ll use throughout this tutorial is perhaps the most intuitive: the shortest path between two cities.\n\n\n\nWe’ll be working with the map below to figure out the best route between the two European cities of Reykjavik and Belgrade. For the sake of simplicity, let’s imagine that all cities are connected by roads (a real-life route would involve at least one ferry).\n• Each city is represented as a node.\n• Each road is represented as an edge.\n• Each road has an associated value. A value could be the distance between cities, a highway toll, or the amount of traffic. Generally, we’ll favor edges with lower values. In our specific case, the associated value is defined by the distance between two cities.\n\nYou also may have noticed that we cannot reach Belgrade from Reykjavik directly; that would render our exercise pointless. But there are several paths from Reykjavik to Belgrade that go through other cities:\n\n\n\nEach of these paths end in Belgrade, but they all have different values. We can use Dijkstra’s algorithm to find the path with the lowest total value.\n\nBefore diving into the code, let’s start with a high-level illustration of Dijkstra’s algorithm.\n\nFirst, we initialize the algorithm as follows:\n• We set Reykjavik as the starting node.\n• We set the distances between Reykjavik and all other cities to infinity, except for the distance between Reykjavik and itself, which we set to 0.\n\nAfter that, we iteratively execute the following steps:\n• We choose the node with the smallest value as the “current node” and visit all of its neighboring nodes. As we visit each neighbor, we update their tentative distance from the starting node.\n• Once we visit all of the current node’s neighbors and update their distances, we mark the current node as “visited.” Marking a node as “visited” means that we’ve arrived at its final cost.\n• We go back to step one. The algorithm loops until it visits all the nodes in the graph.\n\nIn our example, we start by marking Reykjavik as the “current node” since its value is 0. We proceed by visiting Reykjavik’s two neighboring nodes: London and Oslo. At the beginning of the algorithm, their values are set to infinity, but as we visit the nodes, we update the value for London to 4, and Oslo to 5.\n\nWe then mark Reykjavik as “visited.” We know that its final cost is zero, and we don’t need to visit it again. We continue with the next node with the lowest value, which is London.\n\nWe visit all of London’s neighboring nodes which we haven’t marked as “visited.” London’s neighbors are Reykjavik and Berlin, but we ignore Reykjavik because we’ve already visited it. Instead, we update Berlin’s value by adding the value of the edge connecting London and Berlin (3) to the value of London (4), which gives us a value of 7.\n\nWe mark London as visited and choose the next node: Oslo. We visit Oslo’s neighbors and update their values. It turns out that we can better reach Berlin through Oslo (with a value of 6) than through London, so we update its value accordingly. We also update the current value of Moscow from infinity to 8.\n\nWe mark Oslo as “visited” and update its final value to 5. Between Berlin and Moscow, we choose Berlin as the next node because its value (6) is lower than Moscow’s (8). We proceed as before: We visit Rome and Belgrade and update their tentative values, before marking Berlin as “visited” and moving on to the next city.\n\nNote that we’ve already found a path from Reykjavik to Belgrade with a value of 15! But is it the best one?\n\n\n\nUltimately, it’s not. We’ll skip the rest of the steps, but you get the drill. The best path turns out to be Reykjavik –> Oslo –> Berlin –> Rome –> Athens –> Belgrade, with a value of 11.\n\nNow, let’s see how we would implement this in Python code.\n\nFirst, we’ll create the Graph class. This class does not cover any of the Dijkstra algorithm’s logic, but it will make the implementation of the algorithm more succinct.\n\nWe’ll implement the graph as a Python dictionary. The dictionary’s keys will correspond to the cities and its values will correspond to dictionaries that record the distances to other cities in the graph.\n\nNext, we’ll implement the Dijkstra algorithm. We’ll start by defining the function.\n\nThe function takes two arguments: and is an instance of the Graph class that we created in the previous step, whereas is the node from which we’ll start the calculations. We’ll call the method to initialize the list of unvisited nodes:\n\nNext, we’ll create two dicts, and :\n• will store the best-known cost of visiting each city in the graph starting from the . In the beginning, the cost starts at infinity, but we’ll update the values as we move along the graph.\n• will store the trajectory of the current best known path for each node. For example, if we know the best way to Berlin to be via Oslo, will return “Oslo”, and will return “Reykjavik.” We’ll use this dictionary to backtrace the shortest path.\n\n\n\nNow we can start the algorithm. Remember that Dijkstra’s algorithm executes until it visits all the nodes in a graph, so we’ll represent this as a condition for exiting the while-loop.\n\n\n\nNow, the algorithm can start visiting the nodes. The code block below first instructs the algorithm to find the node with the lowest value.\n\nOnce that’s done, the algorithm visits all node’s neighbors that are still unvisited. If the new path to the neighbor is better than the current best path, the algorithm makes adjustments in the and dictionaries.\n\n\n\n\n\nAfter visiting all of its neighbors, we can mark the current node as “visited”:\n\n\n\n\n\nAt last, we can return the two dictionaries:\n\nLastly, we need to create a function that prints out the results. This function will take the two dictionaries returned by the dijskstra_algorithm function, as well as the names of the beginning and target nodes. It’ll use the two dictionaries to find the best path and calculate the path’s score.\n\nNow, let’s see the algorithm in action. We’ll manually initialize the nodes and their edges.\n\nWe’ll use these values to create an object of the Graph class.\n\nWith our graph fully constructed, we can pass it to the dijkstra_algorithm() function.\n\nAnd now let’s print out the results:\n\nAnd that’s it! Feel free to play around with the code. For example, you could add more nodes to the graph, tweak the edges’ values, or choose different starting and ending cities.\n\nIn this article, we provided a hands-on explanation of Dijkstra’s algorithm before showing an implementation in Python. Although Dijkstra’s algorithm is conceptually simple, it’s powerful enough to be employed in many interesting applications.\n\nLooking to continue learning Python?\n\n\n\nCheck out our Introduction to Programming Nanodegree program. You’ll learn the foundations and work towards a career in fields like software development, machine learning, or data science!"
    },
    {
        "link": "https://w3schools.com/dsa/dsa_algo_graphs_dijkstra.php",
        "document": "Dijkstra's algorithm finds the shortest path from one vertex to all other vertices.\n\nIt does so by repeatedly selecting the nearest unvisited vertex and calculating the distance to all the unvisited neighboring vertices.\n\nDijkstra's algorithm is often considered to be the most straightforward algorithm for solving the shortest path problem.\n\nDijkstra's algorithm is used for solving single-source shortest path problems for directed or undirected paths. Single-source means that one vertex is chosen to be the start, and the algorithm will find the shortest path from that vertex to all other vertices.\n\nDijkstra's algorithm does not work for graphs with negative edges. For graphs with negative edges, the Bellman-Ford algorithm that is described on the next page, can be used instead.\n\nTo find the shortest path, Dijkstra's algorithm needs to know which vertex is the source, it needs a way to mark vertices as visited, and it needs an overview of the current shortest distance to each vertex as it works its way through the graph, updating these distances when a shorter distance is found.\n\nIn the animation above, when a vertex is marked as visited, the vertex and its edges become faded to indicate that Dijkstra's algorithm is now done with that vertex, and will not visit it again.\n\nRun the simulation below to get a more detailed understanding of how Dijkstra's algorithm runs on a specific graph, finding the shortest distances from vertex D.\n\nThis simulation shows how distances are calculated from vertex D to all other vertices, by always choosing the next vertex to be the closest unvisited vertex from the starting point.\n\nFollow the step-by-step description below to get all the details of how Dijkstra's algorithm calculates the shortest distances.\n\nConsider the Graph below.\n\nWe want to find the shortest path from the source vertex D to all other vertices, so that for example the shortest path to C is D->E->C, with path weight 2+4=6.\n\nTo find the shortest path, Dijkstra's algorithm uses an array with the distances to all other vertices, and initially sets these distances to infinite, or a very big number. And the distance to the vertex we start from (the source) is set to 0.\n\nThe image below shows the initial infinite distances to other vertices from the starting vertex D. The distance value for vertex D is 0 because that is the starting point.\n\nDijkstra's algorithm then sets vertex D as the current vertex, and looks at the distance to the adjacent vertices. Since the initial distance to vertices A and E is infinite, the new distance to these are updated with the edge weights. So vertex A gets the distance changed from inf to 4, and vertex E gets the distance changed to 2. As mentioned on the previous page, updating the distance values in this way is called 'relaxing'.\n\nAfter relaxing vertices A and E, vertex D is considered visited, and will not be visited again.\n\nThe next vertex to be chosen as the current vertex must the vertex with the shortest distance to the source vertex (vertex D), among the previously unvisited vertices. Vertex E is therefore chosen as the current vertex after vertex D.\n\nThe distance to all adjacent and not previously visited vertices from vertex E must now be calculated, and updated if needed.\n\nThe calculated distance from D to vertex A, via E, is 2+4=6. But the current distance to vertex A is already 4, which is lower, so the distance to vertex A is not updated.\n\nThe distance to vertex C is calculated to be 2+4=6, which is less than infinity, so the distance to vertex C is updated.\n\nSimilarly, the distance to node G is calculated and updated to be 2+5=7.\n\nThe next vertex to be visited is vertex A because it has the shortest distance from D of all the unvisited vertices.\n\nThe calculated distance to vertex C, via A, is 4+3=7, which is higher than the already set distance to vertex C, so the distance to vertex C is not updated.\n\nVertex A is now marked as visited, and the next current vertex is vertex C because that has the lowest distance from vertex D between the remaining unvisited vertices.\n\nVertex F gets updated distance 6+5=11, and vertex B gets updated distance 6+2=8.\n\nCalculated distance to vertex G via vertex C is 6+5=11 which is higher than the already set distance of 7, so distance to vertex G is not updated.\n\nVertex C is marked as visited, and the next vertex to be visited is G because is has the lowest distance between the remaining unvisited vertices.\n\nVertex F already has a distance of 11. This is lower than the calculated distance from G, which is 7+5=12, so the distance to vertex F is not updated.\n\nVertex G is marked as visited, and B becomes the current vertex because it has the lowest distance of the remaining unvisited vertices.\n\nThe new distance to F via B is 8+2=10, because it is lower than F's existing distance of 11.\n\nVertex B is marked as visited, and there is nothing to check for the last unvisited vertex F, so Dijkstra's algorithm is finished.\n\nEvery vertex has been visited only once, and the result is the lowest distance from the source vertex D to every other vertex in the graph.\n\nTo implement Dijkstra's algorithm, we create a class. The represents the graph with its vertices and edges:\n\nLine 3: We create the to hold all the edges and edge weights. Initial values are set to .\n\nLine 4: is the number of vertices in the graph.\n\nLine 5: The holds the names of all the vertices.\n\nLine 7-10: The method is used to add an edge from vertex to vertex , with edge weight .\n\nLine 12-14: The method is used to add a vertex to the graph. The index where the vertex should belong is given with the argument, and is the name of the vertex.\n\nThe class also contains the method that runs Dijkstra's algorithm:\n\nLine 18-19: The initial distance is set to infinity for all vertices in the array, except for the start vertex, where the distance is 0.\n\nLine 20: All vertices are initially set to to mark them as not visited in the array.\n\nLine 23-28: The next current vertex is found. Outgoing edges from this vertex will be checked to see if shorter distances can be found. It is the unvisited vertex with the lowest distance from the start.\n\nLine 30-31: If the next current vertex has not been found, the algorithm is finished. This means that all vertices that are reachable from the source have been visited.\n\nLine 33: The current vertex is set as visited before relaxing adjacent vertices. This is more effective because we avoid checking the distance to the current vertex itself.\n\nLine 35-39: Distances are calculated for not visited adjacent vertices, and updated if the new calculated distance is lower.\n\nAfter defining the class, the vertices and edges must be defined to initialize the specific graph, and the complete code for this Dijkstra's algorithm example looks like this:\n\nTo run Dijkstra's algorithm on directed graphs, very few changes are needed.\n\nSimilarly to the change we needed for cycle detection for directed graphs, we just need to remove one line of code so that the adjacency matrix is not symmetric anymore.\n\nLet's implement this directed graph and run Dijkstra's algorithm from vertex D.\n\nHere is the implementation of Dijkstra's algorithm on the directed graph, with D as the source vertex:\n\nThe image below shows us the shortest distances from vertex D as calculated by Dijkstra's algorithm.\n\nThis result is similar to the previous example using Dijkstra's algorithm on the undirected graph. However, there's a key difference: in this case, vertex B cannot be visited from D, and this means that the shortest distance from D to F is now 11, not 10, because the path can no longer go through vertex B.\n\nWith a few adjustments, the actual shortest paths can also be returned by Dijkstra's algorithm, in addition to the shortest path values. So for example, instead of just returning that the shortest path value is 10 from vertex D to F, the algorithm can also return that the shortest path is \"D->E->C->B->F\".\n\nTo return the path, we create a array to keep the previous vertex in the shortest path for each vertex. The array can be used to backtrack to find the shortest path for every vertex.\n\nLine 7 and 29: The array is first initialized with values, then it is updated with the correct predecessor for each vertex as the shortest path values are updated.\n\nLine 33-42: The method uses the array and returns a string with the shortest path from start to end vertex.\n\nLet's say we are only interested in finding the shortest path between two vertices, like finding the shortest distance between vertex D and vertex F in the graph below.\n\nDijkstra's algorithm is normally used for finding the shortest path from one source vertex to all other vertices in the graph, but it can also be modified to only find the shortest path from the source to a single destination vertex, by just stopping the algorithm when the destination is reached (visited).\n\nThis means that for the specific graph in the image above, Dijkstra's algorithm will stop after visiting F (the destination vertex), before visiting vertices H, I and J because they are farther away from D than F is.\n\nBelow we can see the status of the calculated distances when Dijkstra's algorithm has found the shortest distance from D to F, and stops running.\n\nIn the image above, vertex F has just got updated with distance 10 from vertex B. Since F is the unvisited vertex with the lowest distance from D, it would normally be the next current vertex, but since it is the destination, the algorithm stops. If the algorithm did not stop, J would be the next vertex to get an updated distance 11+2=13, from vertex I.\n\nThe code below is Dijkstra's algorithm implemented to find the shortest path to a single destination vertex:\n\nLine 20-23: If we are about to choose the destination vertex as the current vertex and mark it as visited, it means we have already calculated the shortest distance to the destination vertex, and Dijkstra's algorithm can be stopped in this single destination case.\n\nWith \\(V\\) as the number of vertices in our graph, the time complexity for Dijkstra's algorithm is\n\nThe reason why we get this time complexity is that the vertex with the lowest distance must to be search for to choose the next current vertex, and that takes \\(O(V)\\) time. And since this must to be done for every vertex connected to the source, we need to factor that in, and so we get time complexity \\(O(V^2)\\) for Dijkstra's algorithm.\n\nBy using a Min-heap or Fibonacci-heap data structure for the distances instead (not yet explained in this tutorial), the time needed to search for the minimum distance vertex is reduced from \\(O(V)\\) to \\(O( \\log{V})\\), which results in an improved time complexity for Dijkstra's algorithm\n\nWhere \\(V\\) is the number of vertices in the graph, and \\(E\\) is the number of edges.\n\nThe improvement we get from using a Min-heap data structure for Dijkstra's algorithm is especially good if we have a large and sparse graph, which means a graph with a large number of vertices, but not as many edges.\n\nThe implementation of Dijkstra's algorithm with the Fibonacci-heap data structure is better for dense graphs, where each vertex has an edge to almost every other vertex."
    },
    {
        "link": "https://builtin.com/software-engineering-perspectives/dijkstras-algorithm",
        "document": "Dijkstra’s algorithm is a well-known algorithm in computer science that is used to find the shortest path between one vertex (source node) and all other vertices in a weighted graph. The algorithm uses a priority queue to explore the graph, assigning each vertex a tentative distance from a source vertex and then iteratively updating this value as it visits neighboring vertices.\n\nWe will go over how Dijkstra’s algorithm works, provide an example on a small graph, demonstrate its implementation in Python and touch on some of its practical applications.\n\nDijkstra’s algorithm commonly works on directed graphs, where nodes are connected with weighted non-negative edges. In a directed graph, edges have specific, one-way directions for travel. The algorithm finds the distance from a single source node to all other nodes in the graph, where the sum of the edge weights on the paths is minimized. If we only care about the shortest distance to a single target node, we can simply stop the algorithm after that particular path has been found.\n\nThe time complexity of Dijkstra’s algorithm can be when using an array, or when using a min-priority queue. In these equations, represents the number of vertices and represents the number of edges in the given graph. The space complexity of Dijkstra’s algorithm is typically .\n\nTo initialize our graph, we first assign values to every node, which represents the node’s distance from the source. The source node receives a value of 0, the rest receive an initial (tentative) value of infinity ∞.\n\nWe will use this example graph where the source node is s, and there are four target nodes: a, b, c, and d.\n\nIn the next step, we take the smallest-value unprocessed node (shaded gray). We then assign its value as the minimum of the current value, or any of the neighboring values plus the edge distance connecting them. In this first step, we assign s to min(0, ∞+4, ∞+8). So we keep the value as 0, then mark the node as completed (shaded with black).\n\nNext, we take all our neighboring nodes and assign them again to the minimum of their current value, or their neighboring values plus the corresponding edge distances.\n\nWe take the smallest-valued node (b in this case) and treat it as our new node of interest.\n\nWe then repeat the process with the next node: update its neighbors’ values, mark it as completed and find the next minimum-valued node.\n\nNote that once a node is marked as completed, its value is definitively the shortest path from the target. If this is the only node we care about, we can stop here. Or we can continue to find the shortest paths to all other nodes by repeating the process:\n\nIn summary, the steps are:\n• Initialize the source node to take value 0 and all other nodes to ∞. Start with node 0 as the “current node.”\n• Find all neighboring nodes and update their values to either the minimum of their value or the value of the current node plus its distance. Mark the node as finished.\n• Assign the minimum-valued unfinished node as the current node.\n• Repeat steps 2 and 3 until all nodes (or a specific node of interest) are finished.\n\nImplementing Dijkstra’s algorithm in Python is a good exercise for understanding how it works. We will cover the important components of a Python implementation.\n\nFirst, we can represent a directed graph using a dictionary adjacency list:\n\nThere are a couple of important notes for this implementation. First, we keep the unfinished nodes in queue, using the built-in Python library to push and pop nodes based on their distance value. Additionally, the returned value is a dictionary of nodes, where we can use the node’s parent, e.g. nodes[ ].parent to traverse the shortest path back to the source node.\n\nDijkstra’s algorithm can be used to find the shortest route between two points on a map, taking into account traffic conditions and other obstacles. In network routing, it can be used to find the shortest path between two computers on a network, while in computer networks, it can be used to find the fastest route between two nodes in a distributed system.\n\nIt is also used in geographic information system (GIS) applications to find the shortest paths between geographic points. Generally, Dijkstra’s algorithm is a tool that has many real-world applications in various fields, particularly those that require efficient pathfinding in graph structures.\n\nDijkstra’s algorithm is one of several algorithms used to solve shortest path problems in graphs. In particular, Dijkstra’s algorithm is used to find a single-source shortest path in a weighted graph, where node edges are positive. Here are other shortest path algorithms to know and how they compare to Dijkstra’s algorithm:\n• Bellman-Ford algorithm: Solves single-source shortest path problems in a weighted graph, where edges can be positive or negative (with no negative cycles).\n• A* search algorithm: Solves single-pair shortest path problems in a weighted graph, where edges are positive.\n• Floyd-Warshall algorithm: Solves all-pairs shortest path problems in a weighted graph, where edges can be positive or negative (with no negative cycles); effective for dense graphs (many edges).\n• Johnson’s algorithm: Solves all-pairs shortest path problems in a weighted graph, where edges can be positive or negative (with no negative cycles); effective for sparse graphs (few edges)."
    },
    {
        "link": "https://geeksforgeeks.org/dijkstras-shortest-path-algorithm-greedy-algo-7",
        "document": "How to find Shortest Paths from Source to all Vertices using Dijkstra’s Algorithm\n\nGiven a weighted graph and a source vertex in the graph, find the shortest paths from the source to all the other vertices in the given graph.\n\nNote: The given graph does not contain any negative edge.\n\nThe idea is to generate a SPT (shortest path tree) with a given source as a root. Maintain an Adjacency Matrix with two sets,\n• None One set contains vertices included in the shortest-path tree,\n• None The other set includes vertices not yet included in the shortest-path tree.\n\nAt every step of the algorithm, find a vertex that is in the other set (set not yet included) and has a minimum distance from the source.\n\nBelow is the implementation of the above approach:\n\nWe use a boolean array sptSet[] to represent the set of vertices included in SPT. If a value sptSet[v] is true, then vertex v is included in SPT, otherwise not. Array dist[] is used to store the shortest distance values of all vertices.\n\n// A utility function to find the vertex with the minimum // distance value, from the set of vertices not yet included // the shortest distance from src to i // sptSet[i] will be true if vertex i // Distance of source vertex from itself is always 0 // Pick the minimum distance vertex from the set of // If no valid vertex is found, stop. // Update dist value of the adjacent vertices // Update dist[v] only if it is not in sptSet, // there is an edge from u to v, and total weight // of path from src to v through u is smaller // than current value of dist[v] // Number of vertices in the graph // A utility function to find the vertex with minimum // distance value, from the set of vertices not yet included // The output array. dist[i] will hold the // sptSet[i] will be true if vertex i is // path tree or shortest distance from src to i is // Initialize all distances as INFINITE and stpSet[] as // Distance of source vertex from itself is always 0 // Pick the minimum distance vertex from the set of // vertices not yet processed. u is always equal to // src in the first iteration. // Update dist value of the adjacent vertices of the // Update dist[v] only if is not in sptSet, // there is an edge from u to v, and total // weight of path from src to v through u is // smaller than current value of dist[v] /* Let us create the example graph discussed above */ // A utility function to find the vertex with minimum // distance value, from the set of vertices not yet // the shortest distance from src to i // sptSet[i] will true if vertex i is included in // Initialize all distances as INFINITE and stpSet[] // Distance of source vertex from itself is always 0 // Pick the minimum distance vertex from the set // of vertices not yet processed. u is always // equal to src in first iteration. // Update dist value of the adjacent vertices of // Update dist[v] only if is not in sptSet, // there is an edge from u to v, and total // weight of path from src to v through u is // smaller than current value of dist[v] /* Let us create the example graph discussed above // This code is contributed by Aakash Hasija # A utility function to find the vertex with # minimum distance value, from the set of vertices # not yet included in shortest path tree # Search not nearest vertex not in the # the set of vertices not yet processed. # x is always equal to src in first iteration # Put the minimum distance vertex in the # Update dist value of the adjacent vertices # of the picked vertex only if the current # distance is greater than new distance and # the vertex in not in the shortest path tree \\ # This code is contributed by Divyanshu Mehta and Updated by Pranav Singh Sambyal // value, from the set of vertices // not yet included in shortest // from itself is always 0 // from the set of vertices not yet // processed. u is always equal to // Update dist value of the adjacent // Update dist[v] only if is not in // sptSet, there is an edge from u // to v, and total weight of path // from src to v through u is smaller // than current value of dist[v] /* Let us create the example // This code is contributed by ChitraNayal // value, from the set of vertices // not yet included in shortest // from itself is always 0 // from the set of vertices not yet // processed. u is always equal to // Update dist value of the adjacent // Update dist[v] only if is not in // sptSet, there is an edge from u // to v, and total weight of path // from src to v through u is smaller // than current value of dist[v] // This code is contributed by rag2127\n• None The code calculates the shortest distance but doesn’t calculate the path information. Create a parent array, update the parent array when distance is updated and use it to show the shortest path from source to different vertices.\n• None The time Complexity of the implementation is O(V2) , it can be reduced to O(E*log V) with the help of a binary heap.\n\nWhy Dijkstra’s Algorithms fails for the Graphs having Negative Edges ?\n\nThe problem with negative weights arises from the fact that Dijkstra’s algorithm assumes that once a node is added to the set of visited nodes, its distance is finalized and will not change. However, in the presence of negative weights, this assumption can lead to incorrect results.\n\nConsider the following graph for the example:\n\nIn the above graph, A is the source node, among the edges A to B and A to C , A to B is the smaller weight and Dijkstra assigns the shortest distance of B as 2, but because of existence of a negative edge from C to B , the actual shortest distance reduces to 1 which Dijkstra fails to detect.\n\nNote: We use Bellman Ford’s Shortest path algorithm in case we have negative edges in the graph.\n\nDijkstra’s Algorithm using Adjacency List and Heap in O(E*logV):\n\n// Prints shortest paths from src to all other vertices // Create a vector for distances and initialize all // Insert source itself in priority queue and initialize /* Looping till priority queue becomes empty (or all // The first vertex in pair is the minimum distance // Get all adjacent of u. // Get vertex label and weight of current // If there is shorted path to v through u. // Java program for the above approach // Prints shortest paths from src to all other vertices // Create a list for distances and initialize all // Insert source itself in priority queue and /* Looping till priority queue becomes empty (or all // The first vertex in pair is the minimum // Get all adjacent of u. // Get vertex label and weight of current // If there is a shorter path to v through # Function to add an edge to the adjacency list # Function to find the shortest paths from source to all other vertices # Create a priority queue to store vertices that are being preprocessed # Create an array for distances and initialize all distances as infinite (INF) # Insert source itself in the priority queue and initialize its distance as 0 # Loop until the priority queue becomes empty # Extract the vertex with minimum distance from the priority queue # Get all adjacent vertices of u # If there is a shorter path to v through u // Function to add an edge to the adjacency list // Function to find the shortest paths from source to all // Create a priority queue to store vertices that are // Create an array for distances and initialize all // Insert source itself in the priority queue and // Loop until the priority queue becomes empty // Extract the vertex with minimum distance from the // Get all adjacent vertices of u // If there is a shorter path to v through u\n\nTime Complexity: O(E*logV), Where E is the number of edges and V is the number of vertices. \n\n Auxiliary Space: O(V), Where V is the number of vertices.\n• Google maps uses Dijkstra algorithm to show shortest distance between source and destination.\n• computer networking , Dijkstra’s algorithm forms the basis for various routing protocols, such as OSPF (Open Shortest Path First) and IS-IS (Intermediate System to Intermediate System).\n• None Transportation and traffic management systems use Dijkstra’s algorithm to optimize traffic flow, minimize congestion, and plan the most efficient routes for vehicles.\n• None Airlines use Dijkstra’s algorithm to plan flight paths that minimize fuel consumption, reduce travel time.\n• None Dijkstra’s algorithm is applied in electronic design automation for routing connections on integrated circuits and very-large-scale integration (VLSI) chips.\n• None Shortest path with one curved edge in an undirected Graph\n• None 1st to Kth shortest path lengths in given Graph\n• None Number of ways to reach at destination in shortest time"
    },
    {
        "link": "https://docs.python.org/3/tutorial/datastructures.html",
        "document": "This chapter describes some things you’ve learned about already in more detail, and adds some new things as well.\n\nThe list data type has some more methods. Here are all of the methods of list objects: Add an item to the end of the list. Similar to . Extend the list by appending all the items from the iterable. Similar to . Insert an item at a given position. The first argument is the index of the element before which to insert, so inserts at the front of the list, and is equivalent to . Remove the first item from the list whose value is equal to x. It raises a if there is no such item. Remove the item at the given position in the list, and return it. If no index is specified, removes and returns the last item in the list. It raises an if the list is empty or the index is outside the list range. Remove all items from the list. Similar to . Return zero-based index in the list of the first item whose value is equal to x. Raises a if there is no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument. Return the number of times x appears in the list. Sort the items of the list in place (the arguments can be used for sort customization, see for their explanation). Reverse the elements of the list in place. Return a shallow copy of the list. Similar to . An example that uses most of the list methods: You might have noticed that methods like , or that only modify the list have no return value printed – they return the default . This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, doesn’t sort because integers can’t be compared to strings and can’t be compared to other types. Also, there are some types that don’t have a defined ordering relation. For example, isn’t a valid comparison. The list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved (“last-in, first-out”). To add an item to the top of the stack, use . To retrieve an item from the top of the stack, use without an explicit index. For example: It is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-out”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing inserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use which was designed to have fast appends and pops from both ends. For example: # The first to arrive now leaves # The second to arrive now leaves List comprehensions provide a concise way to create lists. Common applications are to make new lists where each element is the result of some operations applied to each member of another sequence or iterable, or to create a subsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like: Note that this creates (or overwrites) a variable named that still exists after the loop completes. We can calculate the list of squares without any side effects using: which is more concise and readable. A list comprehension consists of brackets containing an expression followed by a clause, then zero or more or clauses. The result will be a new list resulting from evaluating the expression in the context of the and clauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal: Note how the order of the and statements is the same in both these snippets. If the expression is a tuple (e.g. the in the previous example), it must be parenthesized. # create a new list with the values doubled # apply a function to all the elements # the tuple must be parenthesized, otherwise an error is raised File , line : did you forget parentheses around the comprehension target? # flatten a list using a listcomp with two 'for' List comprehensions can contain complex expressions and nested functions: The initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4: The following list comprehension will transpose rows and columns: As we saw in the previous section, the inner list comprehension is evaluated in the context of the that follows it, so this example is equivalent to: which, in turn, is the same as: # the following 3 lines implement the nested listcomp In the real world, you should prefer built-in functions to complex flow statements. The function would do a great job for this use case: See Unpacking Argument Lists for details on the asterisk in this line.\n\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two examples of sequence data types (see Sequence Types — list, tuple, range). Since Python is an evolving language, other sequence data types may be added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance: File , line , in : # but they can contain mutable objects: As you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they may be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple is part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to create tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples are immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later in this section) or indexing (or even by attribute in the case of ). Lists are mutable, and their elements are usually homogeneous and are accessed by iterating over the list. A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accommodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed by following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example: The statement is an example of tuple packing: the values , and are packed together in a tuple. The reverse operation is also possible: This is called, appropriately enough, sequence unpacking and works for any sequence on the right-hand side. Sequence unpacking requires that there are as many variables on the left side of the equals sign as there are elements in the sequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking.\n\nPython also includes a data type for sets. A set is an unordered collection with no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. Set objects also support mathematical operations like union, intersection, difference, and symmetric difference. Curly braces or the function can be used to create sets. Note: to create an empty set you have to use , not ; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration: # show that duplicates have been removed # Demonstrate set operations on unique letters from two words # letters in a but not in b # letters in a or b or both # letters in both a and b # letters in a or b but not both Similarly to list comprehensions, set comprehensions are also supported:\n\nAnother useful data type built into Python is the dictionary (see Mapping Types — dict). Dictionaries are sometimes found in other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range of numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be keys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable object either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified in place using index assignments, slice assignments, or methods like and . It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within one dictionary). A pair of braces creates an empty dictionary: . Placing a comma-separated list of key:value pairs within the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also possible to delete a key:value pair with . If you store using a key that is already in use, the old value associated with that key is forgotten. It is an error to extract a value using a non-existent key. Performing on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you want it sorted, just use instead). To check whether a single key is in the dictionary, use the keyword. Here is a small example using a dictionary: The constructor builds dictionaries directly from sequences of key-value pairs: In addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions: When the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the method. When looping through a sequence, the position index and corresponding value can be retrieved at the same time using the function. To loop over two or more sequences at the same time, the entries can be paired with the function. What is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the function. To loop over a sequence in sorted order, use the function which returns a new sorted list while leaving the source unaltered. Using on a sequence eliminates duplicate elements. The use of in combination with over a sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. It is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create a new list instead.\n\nThe conditions used in and statements can contain any operators, not just comparisons. The comparison operators and are membership tests that determine whether a value is in (or not in) a container. The operators and compare whether two objects are really the same object. All comparison operators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, tests whether is less than and moreover equals . Comparisons may be combined using the Boolean operators and , and the outcome of a comparison (or of any other Boolean expression) may be negated with . These have lower priorities than comparison operators; between them, has the highest priority and the lowest, so that A and not B or C is equivalent to (A and (not B)) or C . As always, parentheses can be used to express the desired composition. The Boolean operators and are so-called short-circuit operators: their arguments are evaluated from left to right, and evaluation stops as soon as the outcome is determined. For example, if and are true but is false, A and B and C does not evaluate the expression . When used as a general value and not as a Boolean, the return value of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example, Note that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator . This avoids a common class of problems encountered in C programs: typing in an expression when was intended.\n\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses lexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of the comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried out recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence is an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one. Lexicographical ordering for strings uses the Unicode code point number to order individual characters. Some examples of comparisons between sequences of the same type: Note that comparing objects of different types with or is legal provided that the objects have appropriate comparison methods. For example, mixed numeric types are compared according to their numeric value, so 0 equals 0.0, etc. Otherwise, rather than providing an arbitrary ordering, the interpreter will raise a exception."
    },
    {
        "link": "https://docs.python.org/2/tutorial/datastructures.html",
        "document": "This chapter describes some things you’ve learned about already in more detail, and adds some new things as well.\n\nThe list data type has some more methods. Here are all of the methods of list objects: Add an item to the end of the list; equivalent to . Extend the list by appending all the items in the given list; equivalent to . Insert an item at a given position. The first argument is the index of the element before which to insert, so inserts at the front of the list, and is equivalent to . Remove the first item from the list whose value is x. It is an error if there is no such item. Remove the item at the given position in the list, and return it. If no index is specified, removes and returns the last item in the list. (The square brackets around the i in the method signature denote that the parameter is optional, not that you should type square brackets at that position. You will see this notation frequently in the Python Library Reference.) Return the index in the list of the first item whose value is x. It is an error if there is no such item. Return the number of times x appears in the list. Sort the items of the list in place (the arguments can be used for sort customization, see for their explanation). Reverse the elements of the list, in place. An example that uses most of the list methods: You might have noticed that methods like , or that only modify the list have no return value printed – they return the default . This is a design principle for all mutable data structures in Python. The list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved (“last-in, first-out”). To add an item to the top of the stack, use . To retrieve an item from the top of the stack, use without an explicit index. For example: It is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-out”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing inserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use which was designed to have fast appends and pops from both ends. For example: # The first to arrive now leaves # The second to arrive now leaves List comprehensions provide a concise way to create lists. Common applications are to make new lists where each element is the result of some operations applied to each member of another sequence or iterable, or to create a subsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like: We can obtain the same result with: This is also equivalent to , but it’s more concise and readable. A list comprehension consists of brackets containing an expression followed by a clause, then zero or more or clauses. The result will be a new list resulting from evaluating the expression in the context of the and clauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal: Note how the order of the and statements is the same in both these snippets. If the expression is a tuple (e.g. the in the previous example), it must be parenthesized. # create a new list with the values doubled # apply a function to all the elements # the tuple must be parenthesized, otherwise an error is raised # flatten a list using a listcomp with two 'for' List comprehensions can contain complex expressions and nested functions: The initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4: The following list comprehension will transpose rows and columns: As we saw in the previous section, the nested listcomp is evaluated in the context of the that follows it, so this example is equivalent to: which, in turn, is the same as: # the following 3 lines implement the nested listcomp In the real world, you should prefer built-in functions to complex flow statements. The function would do a great job for this use case: See Unpacking Argument Lists for details on the asterisk in this line.\n\nThere is a way to remove an item from a list given its index instead of its value: the statement. This differs from the method which returns a value. The statement can also be used to remove slices from a list or clear the entire list (which we did earlier by assignment of an empty list to the slice). For example: can also be used to delete entire variables: Referencing the name hereafter is an error (at least until another value is assigned to it). We’ll find other uses for later.\n\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two examples of sequence data types (see Sequence Types — str, unicode, list, tuple, bytearray, buffer, xrange). Since Python is an evolving language, other sequence data types may be added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance: File , line , in : # but they can contain mutable objects: As you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they may be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple is part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to create tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples are immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later in this section) or indexing (or even by attribute in the case of ). Lists are mutable, and their elements are usually homogeneous and are accessed by iterating over the list. A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accommodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed by following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example: The statement is an example of tuple packing: the values , and are packed together in a tuple. The reverse operation is also possible: This is called, appropriately enough, sequence unpacking and works for any sequence on the right-hand side. Sequence unpacking requires the list of variables on the left to have the same number of elements as the length of the sequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking.\n\nPython also includes a data type for sets. A set is an unordered collection with no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. Set objects also support mathematical operations like union, intersection, difference, and symmetric difference. Curly braces or the function can be used to create sets. Note: to create an empty set you have to use , not ; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration: # Demonstrate set operations on unique letters from two words # letters in a but not in b # letters in either a or b # letters in both a and b # letters in a or b but not both Similarly to list comprehensions, set comprehensions are also supported:\n\nAnother useful data type built into Python is the dictionary (see Mapping Types — dict). Dictionaries are sometimes found in other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range of numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be keys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable object either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified in place using index assignments, slice assignments, or methods like and . It is best to think of a dictionary as an unordered set of key: value pairs, with the requirement that the keys are unique (within one dictionary). A pair of braces creates an empty dictionary: . Placing a comma-separated list of key:value pairs within the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also possible to delete a key:value pair with . If you store using a key that is already in use, the old value associated with that key is forgotten. It is an error to extract a value using a non-existent key. The method of a dictionary object returns a list of all the keys used in the dictionary, in arbitrary order (if you want it sorted, just apply the function to it). To check whether a single key is in the dictionary, use the keyword. Here is a small example using a dictionary: The constructor builds dictionaries directly from sequences of key-value pairs: In addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions: When the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using the function. To loop over two or more sequences at the same time, the entries can be paired with the function. What is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the function. To loop over a sequence in sorted order, use the function which returns a new sorted list while leaving the source unaltered. When looping through dictionaries, the key and corresponding value can be retrieved at the same time using the method. It is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create a new list instead.\n\nThe conditions used in and statements can contain any operators, not just comparisons. The comparison operators and check whether a value occurs (does not occur) in a sequence. The operators and compare whether two objects are really the same object; this only matters for mutable objects like lists. All comparison operators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, tests whether is less than and moreover equals . Comparisons may be combined using the Boolean operators and , and the outcome of a comparison (or of any other Boolean expression) may be negated with . These have lower priorities than comparison operators; between them, has the highest priority and the lowest, so that A and not B or C is equivalent to (A and (not B)) or C . As always, parentheses can be used to express the desired composition. The Boolean operators and are so-called short-circuit operators: their arguments are evaluated from left to right, and evaluation stops as soon as the outcome is determined. For example, if and are true but is false, A and B and C does not evaluate the expression . When used as a general value and not as a Boolean, the return value of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example, Note that in Python, unlike C, assignment cannot occur inside expressions. C programmers may grumble about this, but it avoids a common class of problems encountered in C programs: typing in an expression when was intended.\n\nSequence objects may be compared to other objects with the same sequence type. The comparison uses lexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of the comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried out recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence is an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one. Lexicographical ordering for strings uses the ASCII ordering for individual characters. Some examples of comparisons between sequences of the same type: Note that comparing objects of different types is legal. The outcome is deterministic but arbitrary: the types are ordered by their name. Thus, a list is always smaller than a string, a string is always smaller than a tuple, etc. Mixed numeric types are compared according to their numeric value, so 0 equals 0.0, etc."
    },
    {
        "link": "https://python101.pythonlibrary.org/chapter6_comprehensions.html",
        "document": "The Python language has a couple of methods for creating lists and dictionaries that are known as comprehensions. There is also a third type of comprehension for creating a Python set. In this chapter we will learn how to use each type of comprehension. You will find that the comprehension constructs build on the knowledge you have acquired from the previous chapters as they contain loops and conditionals themselves.\n\nList comprehensions in Python are very handy. They can also be a little hard to understand when and why you would use them. List comprehensions tend to be harder to read than just using a simple for loop as well. You may want to review the looping chapter before you continue. If you are ready, then we’ll spend some time looking at how to construct list comprehensions and learn how they can be used. A list comprehension is basically a one line for loop that produces a Python list data structure. Here’s a simple example: Let’s break this down a bit. Python comes with a range function that can return a list of numbers. By default, it returns integers starting at 0 and going up to but not including the number you pass it. So in this case, it returns a list containing the integers 0-4. This can be useful if you need to create a list very quickly. For example, say you’re parsing a file and looking for something in particular. You could use a list comprehension as a kind of filter: I have used code similar to this to look through a file quickly to parse out specific lines or sections of the file. When you throw functions into the mix, you can start doing some really cool stuff. Say you want to apply a function to every element in a list, such as when you need to cast a bunch of strings into integers: This sort of thing comes up more often than you’d think. I have also had to loop over a list of strings and call a string method, such as strip on them because they had all kinds of leading or ending white space: There are also occasions where one needs to create a nested list comprehension. One reason to do that is to flatten multiple lists into one. This example comes from the Python documentation: The documentation shows several other interesting examples for nested list comprehensions as well. I highly recommend taking a look at it! At this point, you should now be capable of using list comprehensions in your own code and use them well. Just use your imagination and you’ll start seeing lots of good places where you too can use them. Now we’re ready to move on to Python’s dictionary comprehensions!\n\nDictionary comprehensions started life in Python 3.0, but were backported to Python 2.7. They were originally proposed in the Python Enhancement Proposal 274 (PEP 274) back in 2001. They are pretty similar to a list comprehension in the way that they are organized. The best way to understand is to just do one! This is a pretty straightforward comprehension. Basically it is creating an integer key and string value for each item in the range. Now you may be wondering how you could use a dictionary comprehension in real life. Mark Pilgrim mentioned that you could use a dictionary comprehension for swapping the dictionary’s keys and values. Here’s how you would do that: This will only work if the dictionary values are of a non-mutable type, such as a string. Otherwise you will end up causing an exception to be raised. I could also see a dictionary comprehension being useful for creating a table out of class variables and their values. However, we haven’t covered classes at this point, so I won’t confuse you with that here.\n\nSet comprehensions are created in much the same way as dictionary comprehensions. Now a Python set is much like a mathematical set in that it doesn’t have any repeated elements. You can create a normal set like this: As you can see from the example above, the call to set has removed the duplicates from the list. Now let’s rewrite this code to use a set comprehension: You will notice that to create a set comprehension, we basically changed the square brackets that a list comprehension uses to the curly braces that the dictionary comprehension has.\n\nNow you know how to use the various Python comprehensions. You will probably find the list comprehension the most useful at first and also the most popular. If you start using your imagination, I am sure you will be able to find uses for all three types of comprehensions. Now we’re ready to move on and learn about exception handling!"
    },
    {
        "link": "https://w3schools.com/python/python_lists_comprehension.asp",
        "document": "List comprehension offers a shorter syntax when you want to create a new list based on the values of an existing list.\n\nBased on a list of fruits, you want a new list, containing only the fruits with the letter \"a\" in the name.\n\nWithout list comprehension you will have to write a statement with a conditional test inside:\n\nWith list comprehension you can do all that with only one line of code:\n\nnewlist = [expression for item in iterable if condition == True]\n\nThe return value is a new list, leaving the old list unchanged.\n\nThe condition is like a filter that only accepts the items that evaluate to .\n\nThe condition if x != \"apple\" will return for all elements other than \"apple\", making the new list contain all fruits except \"apple\".\n\nThe condition is optional and can be omitted:\n\nThe iterable can be any iterable object, like a list, tuple, set etc.\n\nSame example, but with a condition:\n\nThe expression is the current item in the iteration, but it is also the outcome, which you can manipulate before it ends up like a list item in the new list:\n\nYou can set the outcome to whatever you like:\n\nThe expression can also contain conditions, not like a filter, but as a way to manipulate the outcome:\n\nThe expression in the example above says:\n\n\"Return the item if it is not banana, if it is banana return orange\"."
    },
    {
        "link": "https://realpython.com/list-comprehension-python",
        "document": "List comprehensions in Python provide a concise way to create lists by embedding a loop and optional conditional logic in a single line. You use a list comprehension to transform and filter elements from an iterable efficiently. It allows you to replace complex loops and functions with more readable and often faster expressions. By understanding list comprehensions, you can optimize your code for better performance and clarity.\n\nBy the end of this tutorial, you’ll understand that:\n• A list comprehension in Python is a tool for creating lists by iterating over an iterable and optionally applying a condition.\n• You should use list comprehensions instead of loops when you want concise, readable code that performs transformations or filtering.\n• You add conditional logic to a list comprehension by including an statement within the comprehension.\n• A list comprehension can be faster than a loop because it’s optimized for performance by Python’s internal mechanisms.\n• A Python list comprehension is not lazy—it generates and stores the entire list in memory eagerly.\n• The difference between list comprehensions and is that the former creates a list, while the latter returns a object, which is iterable.\n\nIn this tutorial, you’ll explore how to leverage list comprehensions to simplify your code. You’ll also gain an understanding of the trade-offs that come with using them so that you can determine when other approaches are preferable.\n\nThere are a few different ways to create and add items to a lists in Python. In this section, you’ll explore loops and the function to perform these tasks. Then, you’ll move on to learn about how to use list comprehensions and when list comprehensions can benefit your Python program. The most common type of loop is the loop. You can use a loop to create a list of elements in three steps:\n• Loop over an iterable or range of elements.\n• Append each element to the end of the list. If you want to create a list containing the first ten perfect squares, then you can complete these steps in three lines of code: Here, you instantiate an empty list, . Then, you use a loop to iterate over . Finally, you multiply each number by itself and append the result to the end of the list. For an alternative approach that’s based in functional programming, you can use . You pass in a function and an iterable, and will create an object. This object contains the result that you’d get from running each iterable element through the supplied function. As an example, consider a situation in which you need to calculate the price after tax for a list of transactions: Here, you have an iterable, , and a function, . You pass both of these arguments to and store the resulting object in . Finally, you convert into a list using . List comprehensions are a third way of making or transforming lists. With this elegant approach, you could rewrite the loop from the first example in just a single line of code: Rather than creating an empty list and adding each element to the end, you simply define the list and its contents at the same time by following this format: Every list comprehension in Python includes three elements:\n• is the member itself, a call to a method, or any other valid expression that returns a value. In the example above, the expression is the square of the member value.\n• is the object or value in the list or iterable. In the example above, the member value is .\n• is a list, set, sequence, generator, or any other object that can return its elements one at a time. In the example above, the iterable is . Because the expression requirement is so flexible, a list comprehension in Python works well in many places where you would use . You can rewrite the pricing example with its own list comprehension: The only distinction between this implementation and is that the list comprehension in Python returns a list, not a map object.\n\nOne benefit of using a list comprehension in Python is that it’s a single tool that you can use in many different situations. In addition to standard list creation, list comprehensions can also be used for mapping and filtering. In this section, you’ll find advanced techniques to work with list comprehensions in Python. The most common way to add conditional logic to a list comprehension is to add a conditional to the end of the expression. Earlier, you saw this formula for how to create list comprehensions: While this formula is accurate, it’s also a bit incomplete. A more complete description of the comprehension formula adds support for optional conditionals. Here, your conditional statement comes just before the closing bracket: Conditionals are important because they allow list comprehensions to filter out unwanted values, which would normally require a call to : \"the rocket came back from mars\" In this code block, the conditional statement filters out any characters in that aren’t vowels. The conditional can test any valid expression. If you need a more complex filter, then you can even move the conditional logic to a separate function: \"The rocket, who was named Ted, came back \" \"from Mars because he missed his friends.\" Here, you create a complex filter, , and pass this function as the conditional statement for your list comprehension. Note that you also pass the member value as an argument to your function. You can place the conditional at the end of the statement for basic filtering, but what if you want to change a member value instead of filtering it out? In this case, it’s useful to place the conditional near the beginning of the expression. You can do so by taking advantage of the conditional expression: By placing the conditional logic at the beginning of a list comprehension, you can use conditional logic to select from multiple possible output options. For example, if you have a list of prices, then you may want to replace negative prices with and leave the positive values unchanged: Here, your expression is a conditional expression, . This tells Python to output the value of if the number is positive, but to use if the number is negative. If this seems overwhelming, then it may be helpful to view the conditional logic as its own function: Now, your conditional expression is contained within , and you can use it as part of your list comprehension. While the list comprehension in Python is a common tool, you can also create set and dictionary comprehensions. A set comprehension is almost exactly the same as a list comprehension in Python. The difference is that set comprehensions make sure the output contains no duplicates. You can create a set comprehension by using curly braces instead of brackets: Your set comprehension outputs all the unique vowels that it found in . Unlike lists, sets don’t guarantee that items will be saved in any particular order. This is why the first member of the set is , even though the first vowel in is . Dictionary comprehensions are similar, with the additional requirement of defining a key: To create the dictionary, you use curly braces ( ) as well as a key-value pair ( ) in your expression. Python 3.8 introduced the assignment expression, also known as the walrus operator. To understand how you can use it, consider the following example. Say you need to make ten requests to an API that will return temperature data. You only want to return results that are greater than 100 degrees Fahrenheit. Assume that each request will return different data. In this case, the formula expression for member in iterable if conditional provides no way for the conditional to assign data to a variable that the expression can access. You need the temperature in both the expression and the conditional so this is a challenge. The walrus operator ( ) solves this problem. It allows you to run an expression while simultaneously assigning the output value to a variable. The following example shows how this is possible, using to generate fake weather data: Note that the walrus operator needs to be in the conditional part of your comprehension. You won’t often need to use the assignment expression inside of a list comprehension in Python, but it’s a useful tool to have at your disposal when necessary.\n\nDeciding When Not to Use a List Comprehension List comprehensions are useful and can help you write elegant code that’s easy to read and debug, but they’re not the right choice for all circumstances. They might make your code run more slowly or use more memory. If your code is less performant or harder to understand, then it’s probably better to choose an alternative. You can nest comprehensions to create combinations of lists, dictionaries, and sets within a collection. For example, say a climate laboratory is tracking the high temperature in five different cities for the first week of June. The perfect data structure for storing this data could be a Python list nested within a dictionary. You can create the data using nested comprehensions: You create the outer dictionary with a dictionary comprehension. The expression is a key-value pair that contains yet another comprehension. This code will quickly generate a list of data for each city in . Nested lists are a common way to create matrices, which you’ll often use for mathematical purposes. Take a look at the code block below: The outer list comprehension creates six rows, while the inner list comprehension fills each of these rows with values. So far, the purpose of each nested comprehension is pretty intuitive. However, there are other situations, such as flattening lists, where the logic arguably makes your code more confusing. Take this example, which uses a nested list comprehension to flatten a matrix: The code to flatten the matrix is concise, but it may not be so intuitive to understand how it works. On the other hand, if you used loops to flatten the same matrix, then your code would be much more straightforward to understand: Now you can see that the code traverses one row of the matrix at a time, pulling out all the elements in that row before moving on to the next one. A list comprehension in Python works by loading the entire output list into memory. For small or even medium-sized lists, this is generally fine. If you want to sum the squares of the first one-thousand integers, then a list comprehension will solve this problem admirably: But what if you wanted to sum the squares of the first billion integers? If you tried that on your machine, then your computer might become unresponsive. That’s because Python is trying to create a list with one billion integers, which consumes more memory than your computer would like. If you tried to do it anyway, then your machine could slow down or even crash. When the size of a list becomes problematic, it’s often helpful to use a generator instead of a list comprehension in Python. A generator doesn’t create a single, large data structure in memory, but instead returns an iterable. Your code can ask for the next value from the iterable as many times as necessary or until you’ve reached the end of your sequence, while only storing a single value at a time. If you sum the first billion squares with a generator, then your program will likely run for a while, but it shouldn’t cause your computer to freeze. In the example below, you use a generator: You can tell this is a generator because the expression isn’t inside brackets or curly braces. Optionally, generators can be inside parentheses. The example above still requires a lot of work, but it performs the operations lazily. Because of lazy evaluation, your code only calculates values when they’re explicitly requested. After the generator yields a value, it can add that value to the running sum, then discard that value and generate the next value. When the function requests the next value, the cycle starts over. This process keeps the memory footprint small. The function also operates lazily, meaning memory won’t be an issue if you choose to use it in this case: It’s up to you whether you prefer the generator expression or . So, which approach is faster? Should you use list comprehensions or one of their alternatives? Rather than adhere to a single rule that’s true in all cases, it’s more useful to ask yourself whether or not performance matters in your specific circumstance. If not, then it’s usually best to choose whatever approach leads to the cleanest code! If you’re in a scenario where performance is important, then it’s typically best to profile different approaches and listen to the data. The library is useful for timing how long it takes chunks of code to run. You can use to compare the runtime of , loops, and list comprehensions: Here, you define three methods that each use a different approach for creating a list. Then, you tell to run each of those functions 100 times each, and returns the total time it took to run those 100 executions. As your code demonstrates, the biggest difference is between the loop-based approach and , with the loop taking 50 percent longer to execute. Whether or not this matters depends on the needs of your application.\n\nIn this tutorial, you learned how to use a list comprehension in Python to accomplish complex tasks without making your code overly complicated. Whenever you have to choose a list creation method, try multiple implementations and consider what’s most convenient to read and understand in your specific scenario. If performance is important, then you can use profiling tools to give you actionable data instead of relying on hunches or guesses about what works the best.\n• Determine when code clarity or performance dictates an alternative approach Remember that while Python list comprehensions get a lot of attention, your intuition and ability to use data when it counts will help you write clean code that serves the task at hand. This, ultimately, is the key to making your code Pythonic! Get Your Code: Click here to download the free code that shows you how and when to use list comprehensions in Python.\n\nNow that you have some experience with list comprehensions in Python, you can use the questions and answers below to check your understanding and recap what you’ve learned. These FAQs are related to the most important concepts you’ve covered in this tutorial. Click the Show/Hide toggle beside each question to reveal the answer. What is a list comprehension in Python?Show/Hide A list comprehension is a Python construct that lets you create a new list by applying an expression to each item in an existing iterable, all in a single line of code. When should you use a list comprehension instead of a loop in Python?Show/Hide You should use a list comprehension when you want to create a list in a concise, readable manner, especially when transforming or filtering elements from an existing iterable. How can you add conditional logic to a list comprehension in Python?Show/Hide You can add conditional logic by including an statement at the end of the comprehension to filter elements, or you can use a conditional expression within the comprehension to modify elements. Is a list comprehension faster than a loop in Python?Show/Hide In general, list comprehensions are faster than loops because they’re optimized for performance, but you should profile your specific use case to confirm this. How do you optimize performance with list comprehensions in Python?Show/Hide You can optimize performance by using list comprehensions for operations that fit within memory constraints, and by using profiling tools like to compare different approaches in your specific context. Test your knowledge with our interactive “When to Use a List Comprehension in Python” quiz. You’ll receive a score upon completion to help you track your learning progress: When to Use a List Comprehension in Python In this quiz, you'll test your understanding of Python list comprehensions. You'll revisit how to rewrite loops as list comprehensions, how to choose between comprehensions and loops, and how to use conditional logic in your comprehensions."
    },
    {
        "link": "https://geeksforgeeks.org/time-and-space-complexity-of-dijkstras-algorithm",
        "document": "The time complexity of Dijkstra's Algorithm is typically O(V2) when using a simple array implementation or O((V + E) log V) with a priority queue, where V represents the number of vertices and E represents the number of edges in the graph. The space complexity of the algorithm is O(V) for storing the distances and predecessors for each node, along with additional space for data structures like priority queues or arrays.\n\nLet's explore the detailed time and space complexity of the Dijkstra’s Algorithm:\n• None This best-case scenario occurs when using an optimized data structure like a Fibonacci heap for implementing the priority queue.\n• None The time complexity is determined by the graph's number of vertices (V) and edges (E).\n• None In this scenario, the algorithm efficiently finds the shortest paths, with the priority queue operations optimized, leading to the overall time complexity of O((V + E) log V).\n• None This scenario is typically encountered when the graph is sparse, meaning it has relatively few edges compared to vertices.\n• None The average-case time complexity of Dijkstra's algorithm is typically the same as the best-case scenario, O((V + E) log V).\n• None This is because Dijkstra's algorithm performs well on most real-world graphs, which are often neither extremely sparse nor fully connected.\n• None The algorithm efficiently finds shortest paths in graphs with varying densities, finding a balance between the quantity of edges and vertices.\n• None In practice, this average complexity is encountered in a wide range of scenarios, making Dijkstra's algorithm a reliable choice for many shortest path problems.\n• None In the worst-case scenario, Dijkstra's algorithm operates less efficiently, typically when using a simple priority queue or an array-based implementation.\n• None This occurs when the graph is dense, with many edges, and the priority queue operations become less efficient due to the lack of optimization.\n• None The time complexity in this case is determined by the number of vertices squared (V2) and logarithmic factors related to priority queue operations, resulting in O((V2) log V).\n• None The worst-case scenario often arises in fully connected graphs or graphs with many edges between each pair of vertices.\n\nThe auxiliary space complexity of Dijkstra's algorithm is typically O(V) to O(E + V), where V is the number of vertices and E is the number of edges in the graph, depending on the implementation and data structures used.\n\nThe auxiliary space complexity of Dijkstra's algorithm primarily depends on the data structures used for implementation, particularly the priority queue for managing vertices with their associated distances."
    },
    {
        "link": "https://stackoverflow.com/questions/26547816/understanding-time-complexity-calculation-for-dijkstra-algorithm",
        "document": "let n be the number of vertices and m be the number of edges.\n\nSince with Dijkstra's algorithm you have O(n) delete-mins and O(m) decrease_keys, each costing O(logn), the total run time using binary heaps will be O(log(n)(m + n)). It is totally possible to amortize the cost of decrease_key down to O(1) using Fibonacci heaps resulting in a total run time of O(nlogn+m) but in practice this is often not done since the constant factor penalties of FHs are pretty big and on random graphs the amount of decrease_keys is way lower than its respective upper bound (more in the range of O(n*log(m/n), which is way better on sparse graphs where m = O(n)). So always be aware of the fact that the total run time is both dependent on your data structures and the input class."
    },
    {
        "link": "https://geeksforgeeks.org/python-program-for-dijkstras-shortest-path-algorithm-greedy-algo-7",
        "document": "Given a graph and a source vertex in the graph, find the shortest paths from source to all vertices in the given graph. Dijkstra’s algorithm is a popular algorithm for solving many single-source shortest path problems having non-negative edge weight in the graphs i.e., it is to find the shortest distance between two vertices on a graph. It was conceived by Dutch computer scientist Edsger W. Dijkstra in 1956.\n\nDijkstra’s algorithm is very similar to Prim’s algorithm for minimum spanning tree. Like Prim’s MST, we generate an SPT (shortest path tree) with a given source as root. We maintain two sets, one set contains vertices included in the shortest-path tree, another set includes vertices not yet included in the shortest-path tree. At every step of the algorithm, we find a vertex that is in the other set (set of not yet included) and has a minimum distance from the source. Below are the detailed steps used in Dijkstra’s algorithm to find the shortest path from a single source vertex to all other vertices in the given graph.\n\n1) Create a set sptSet (shortest path tree set) that keeps track of vertices included in shortest path tree, i.e., whose minimum distance from source is calculated and finalized. Initially, this set is empty. \n\n2) Assign a distance value to all vertices in the input graph. Initialize all distance values as INFINITE. Assign distance value as 0 for the source vertex so that it is picked first. \n\n3) While sptSet doesn’t include all vertices:\n• None Pick a vertex u which is not there in sptSet and has minimum distance value.\n• None Update distance value of all adjacent vertices of u. To update the distance values, iterate through all adjacent vertices. For every adjacent vertex v, if the sum of a distance value of u (from source) and weight of edge u-v, is less than the distance value of v, then update the distance value of v.\n\nBelow is the Python Implementation of the above discussed algorithm:\n\n# A utility function to find the vertex with # minimum distance value, from the set of vertices # not yet included in shortest path tree # Search not nearest vertex not in the # the set of vertices not yet processed. # u is always equal to src in first iteration # Put the minimum distance vertex in the # Update dist value of the adjacent vertices # of the picked vertex only if the current # distance is greater than new distance and # the vertex in not in the shortest path tree\n\nTime Complexity: The time complexity of Dijkstra’s algorithm is O(V^2). This is because the algorithm uses two nested loops to traverse the graph and find the shortest path from the source node to all other nodes.\n\nSpace Complexity: The space complexity of Dijkstra’s algorithm is O(V), where V is the number of vertices in the graph. This is because the algorithm uses an array of size V to store the distances from the source node to all other nodes."
    },
    {
        "link": "https://programiz.pro/resources/dsa-python-dijkstra-algorithm-complexity",
        "document": "Dijkstra's algorithm is a widely used algorithm for finding the shortest path between nodes in a weighted graph.\n\nIn this article, we will delve into the time complexity of Dijkstra's algorithm.\n• Selects the node with the minimum distance that has not been visited yet.\n• Updates the distances of its neighbors.\n• Repeats this process until all nodes have been visited, finding the shortest path to each node from the source node.\n\nThe above implementation is not the optimal solution.\n\nThe time complexity of the above program can be divided into following components:\n\nThe main loop iterates over all unvisited vertices, finding the vertex with the smallest distance. For vertices, a single iteration takes time.\n\nSince each of the vertices needs to be visited in the worst case, the loop runs for times.\n\nThus, by themselves, the loop takes time complexity.\n\nAdditionally, the algorithm updates the shortest distances of its neighbors, which takes time on average (where is the number of edges). We get this particular complexity because each edge is visited once.\n\nTherefore, the total time complexity of the main loop is .\n\nThe algorithm reconstructs the shortest path by tracing back the predecessors from the end vertex to the start vertex, which takes time for vertices.\n\nThus, the time complexity of the given Dijkstra's algorithm implementation is because the main loop dominates the total computing cost.\n\n \n\n Note: Dijkstra's algorithm is used for graphs without cycles. So, the number of edges is very small. Therefore, the impact of E is generally ignored for time complexity and is often written as .\n\nFortunately, our implementation can be optimized by using a priority queue to store the unvisited vertices.\n\nThe time complexity of the above program can be divided into following components:\n\nThe initialization of the and dictionaries takes time.\n\nThe priority queue operations, including insertion and deletion, take time per operation. Since we perform these operations times for each vertex and times for each edge, the total time complexity is .\n\nThe edge updates take time, where is the number of edges. This is because we iterate over all edges in the graph and update the distances and predecessors of the vertices.\n\nWhen you sum up all the components, you get:\n\nThus, the total time complexity of Dijkstra's algorithm is:\n\nSince dominates and for large graphs (particularly when is large), the overall time complexity is usually simplified to ."
    },
    {
        "link": "https://w3schools.com/dsa/dsa_algo_graphs_dijkstra.php",
        "document": "Dijkstra's algorithm finds the shortest path from one vertex to all other vertices.\n\nIt does so by repeatedly selecting the nearest unvisited vertex and calculating the distance to all the unvisited neighboring vertices.\n\nDijkstra's algorithm is often considered to be the most straightforward algorithm for solving the shortest path problem.\n\nDijkstra's algorithm is used for solving single-source shortest path problems for directed or undirected paths. Single-source means that one vertex is chosen to be the start, and the algorithm will find the shortest path from that vertex to all other vertices.\n\nDijkstra's algorithm does not work for graphs with negative edges. For graphs with negative edges, the Bellman-Ford algorithm that is described on the next page, can be used instead.\n\nTo find the shortest path, Dijkstra's algorithm needs to know which vertex is the source, it needs a way to mark vertices as visited, and it needs an overview of the current shortest distance to each vertex as it works its way through the graph, updating these distances when a shorter distance is found.\n\nIn the animation above, when a vertex is marked as visited, the vertex and its edges become faded to indicate that Dijkstra's algorithm is now done with that vertex, and will not visit it again.\n\nRun the simulation below to get a more detailed understanding of how Dijkstra's algorithm runs on a specific graph, finding the shortest distances from vertex D.\n\nThis simulation shows how distances are calculated from vertex D to all other vertices, by always choosing the next vertex to be the closest unvisited vertex from the starting point.\n\nFollow the step-by-step description below to get all the details of how Dijkstra's algorithm calculates the shortest distances.\n\nConsider the Graph below.\n\nWe want to find the shortest path from the source vertex D to all other vertices, so that for example the shortest path to C is D->E->C, with path weight 2+4=6.\n\nTo find the shortest path, Dijkstra's algorithm uses an array with the distances to all other vertices, and initially sets these distances to infinite, or a very big number. And the distance to the vertex we start from (the source) is set to 0.\n\nThe image below shows the initial infinite distances to other vertices from the starting vertex D. The distance value for vertex D is 0 because that is the starting point.\n\nDijkstra's algorithm then sets vertex D as the current vertex, and looks at the distance to the adjacent vertices. Since the initial distance to vertices A and E is infinite, the new distance to these are updated with the edge weights. So vertex A gets the distance changed from inf to 4, and vertex E gets the distance changed to 2. As mentioned on the previous page, updating the distance values in this way is called 'relaxing'.\n\nAfter relaxing vertices A and E, vertex D is considered visited, and will not be visited again.\n\nThe next vertex to be chosen as the current vertex must the vertex with the shortest distance to the source vertex (vertex D), among the previously unvisited vertices. Vertex E is therefore chosen as the current vertex after vertex D.\n\nThe distance to all adjacent and not previously visited vertices from vertex E must now be calculated, and updated if needed.\n\nThe calculated distance from D to vertex A, via E, is 2+4=6. But the current distance to vertex A is already 4, which is lower, so the distance to vertex A is not updated.\n\nThe distance to vertex C is calculated to be 2+4=6, which is less than infinity, so the distance to vertex C is updated.\n\nSimilarly, the distance to node G is calculated and updated to be 2+5=7.\n\nThe next vertex to be visited is vertex A because it has the shortest distance from D of all the unvisited vertices.\n\nThe calculated distance to vertex C, via A, is 4+3=7, which is higher than the already set distance to vertex C, so the distance to vertex C is not updated.\n\nVertex A is now marked as visited, and the next current vertex is vertex C because that has the lowest distance from vertex D between the remaining unvisited vertices.\n\nVertex F gets updated distance 6+5=11, and vertex B gets updated distance 6+2=8.\n\nCalculated distance to vertex G via vertex C is 6+5=11 which is higher than the already set distance of 7, so distance to vertex G is not updated.\n\nVertex C is marked as visited, and the next vertex to be visited is G because is has the lowest distance between the remaining unvisited vertices.\n\nVertex F already has a distance of 11. This is lower than the calculated distance from G, which is 7+5=12, so the distance to vertex F is not updated.\n\nVertex G is marked as visited, and B becomes the current vertex because it has the lowest distance of the remaining unvisited vertices.\n\nThe new distance to F via B is 8+2=10, because it is lower than F's existing distance of 11.\n\nVertex B is marked as visited, and there is nothing to check for the last unvisited vertex F, so Dijkstra's algorithm is finished.\n\nEvery vertex has been visited only once, and the result is the lowest distance from the source vertex D to every other vertex in the graph.\n\nTo implement Dijkstra's algorithm, we create a class. The represents the graph with its vertices and edges:\n\nLine 3: We create the to hold all the edges and edge weights. Initial values are set to .\n\nLine 4: is the number of vertices in the graph.\n\nLine 5: The holds the names of all the vertices.\n\nLine 7-10: The method is used to add an edge from vertex to vertex , with edge weight .\n\nLine 12-14: The method is used to add a vertex to the graph. The index where the vertex should belong is given with the argument, and is the name of the vertex.\n\nThe class also contains the method that runs Dijkstra's algorithm:\n\nLine 18-19: The initial distance is set to infinity for all vertices in the array, except for the start vertex, where the distance is 0.\n\nLine 20: All vertices are initially set to to mark them as not visited in the array.\n\nLine 23-28: The next current vertex is found. Outgoing edges from this vertex will be checked to see if shorter distances can be found. It is the unvisited vertex with the lowest distance from the start.\n\nLine 30-31: If the next current vertex has not been found, the algorithm is finished. This means that all vertices that are reachable from the source have been visited.\n\nLine 33: The current vertex is set as visited before relaxing adjacent vertices. This is more effective because we avoid checking the distance to the current vertex itself.\n\nLine 35-39: Distances are calculated for not visited adjacent vertices, and updated if the new calculated distance is lower.\n\nAfter defining the class, the vertices and edges must be defined to initialize the specific graph, and the complete code for this Dijkstra's algorithm example looks like this:\n\nTo run Dijkstra's algorithm on directed graphs, very few changes are needed.\n\nSimilarly to the change we needed for cycle detection for directed graphs, we just need to remove one line of code so that the adjacency matrix is not symmetric anymore.\n\nLet's implement this directed graph and run Dijkstra's algorithm from vertex D.\n\nHere is the implementation of Dijkstra's algorithm on the directed graph, with D as the source vertex:\n\nThe image below shows us the shortest distances from vertex D as calculated by Dijkstra's algorithm.\n\nThis result is similar to the previous example using Dijkstra's algorithm on the undirected graph. However, there's a key difference: in this case, vertex B cannot be visited from D, and this means that the shortest distance from D to F is now 11, not 10, because the path can no longer go through vertex B.\n\nWith a few adjustments, the actual shortest paths can also be returned by Dijkstra's algorithm, in addition to the shortest path values. So for example, instead of just returning that the shortest path value is 10 from vertex D to F, the algorithm can also return that the shortest path is \"D->E->C->B->F\".\n\nTo return the path, we create a array to keep the previous vertex in the shortest path for each vertex. The array can be used to backtrack to find the shortest path for every vertex.\n\nLine 7 and 29: The array is first initialized with values, then it is updated with the correct predecessor for each vertex as the shortest path values are updated.\n\nLine 33-42: The method uses the array and returns a string with the shortest path from start to end vertex.\n\nLet's say we are only interested in finding the shortest path between two vertices, like finding the shortest distance between vertex D and vertex F in the graph below.\n\nDijkstra's algorithm is normally used for finding the shortest path from one source vertex to all other vertices in the graph, but it can also be modified to only find the shortest path from the source to a single destination vertex, by just stopping the algorithm when the destination is reached (visited).\n\nThis means that for the specific graph in the image above, Dijkstra's algorithm will stop after visiting F (the destination vertex), before visiting vertices H, I and J because they are farther away from D than F is.\n\nBelow we can see the status of the calculated distances when Dijkstra's algorithm has found the shortest distance from D to F, and stops running.\n\nIn the image above, vertex F has just got updated with distance 10 from vertex B. Since F is the unvisited vertex with the lowest distance from D, it would normally be the next current vertex, but since it is the destination, the algorithm stops. If the algorithm did not stop, J would be the next vertex to get an updated distance 11+2=13, from vertex I.\n\nThe code below is Dijkstra's algorithm implemented to find the shortest path to a single destination vertex:\n\nLine 20-23: If we are about to choose the destination vertex as the current vertex and mark it as visited, it means we have already calculated the shortest distance to the destination vertex, and Dijkstra's algorithm can be stopped in this single destination case.\n\nWith \\(V\\) as the number of vertices in our graph, the time complexity for Dijkstra's algorithm is\n\nThe reason why we get this time complexity is that the vertex with the lowest distance must to be search for to choose the next current vertex, and that takes \\(O(V)\\) time. And since this must to be done for every vertex connected to the source, we need to factor that in, and so we get time complexity \\(O(V^2)\\) for Dijkstra's algorithm.\n\nBy using a Min-heap or Fibonacci-heap data structure for the distances instead (not yet explained in this tutorial), the time needed to search for the minimum distance vertex is reduced from \\(O(V)\\) to \\(O( \\log{V})\\), which results in an improved time complexity for Dijkstra's algorithm\n\nWhere \\(V\\) is the number of vertices in the graph, and \\(E\\) is the number of edges.\n\nThe improvement we get from using a Min-heap data structure for Dijkstra's algorithm is especially good if we have a large and sparse graph, which means a graph with a large number of vertices, but not as many edges.\n\nThe implementation of Dijkstra's algorithm with the Fibonacci-heap data structure is better for dense graphs, where each vertex has an edge to almost every other vertex."
    }
]