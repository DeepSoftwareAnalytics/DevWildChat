[
    {
        "link": "https://w3schools.com/mysql/mysql_like.asp",
        "document": "The operator is used in a clause to search for a specified pattern in a column.\n\nThere are two wildcards often used in conjunction with the operator:\n• The percent sign (%) represents zero, one, or multiple characters\n\nThe percent sign and the underscore can also be used in combinations!\n\nHere are some examples showing different operators with '%' and '_' wildcards:\n\nThe table below shows the complete \"Customers\" table from the Northwind sample database:\n\nThe following SQL statement selects all customers with a CustomerName starting with \"a\":\n\nThe following SQL statement selects all customers with a CustomerName ending with \"a\":\n\nThe following SQL statement selects all customers with a CustomerName that have \"or\" in any position:\n\nThe following SQL statement selects all customers with a CustomerName that have \"r\" in the second position:\n\nThe following SQL statement selects all customers with a CustomerName that starts with \"a\" and are at least 3 characters in length:\n\nThe following SQL statement selects all customers with a ContactName that starts with \"a\" and ends with \"o\":\n\nThe following SQL statement selects all customers with a CustomerName that does NOT start with \"a\":"
    },
    {
        "link": "https://stackoverflow.com/questions/15657317/mysql-like-statement-in-select-column-name",
        "document": "I am trying to select the column names from a specific table, where the table name is like '98673'\n\nSo I am using this:\n\nHowever this will not result in any data. Though I do have column names with '98673Blah' in there.\n\nI know I must be doing something wrong, but what??"
    },
    {
        "link": "https://stackoverflow.com/questions/18415820/mysql-is-it-possible-to-use-like-on-all-columns-in-a-table",
        "document": "I'm trying to make a simple search bar that searches through my database for certain words. It is possible to use the LIKE attribute without using WHERE? I want it to search all columns for the keywords, not just one. Currently I have this:\n\nWhich obviously only searches for names with the search input. I tried both of these:\n\nand neither worked. Is this something that is possible or is there another way to go about it?"
    },
    {
        "link": "https://dev.mysql.com/doc/en/select.html",
        "document": "is used to retrieve rows selected from one or more tables, and can include operations and subqueries. and operations are also supported. The , , and operators are described in more detail later in this section. See also Section 15.2.15, “Subqueries”.\n\nA statement can start with a clause to define common table expressions accessible within the . See Section 15.2.20, “WITH (Common Table Expressions)”.\n\nThe most commonly used clauses of statements are these:\n\ncan also be used to retrieve rows computed without reference to any table.\n\nYou are permitted to specify as a dummy table name in situations where no tables are referenced:\n\nis purely for the convenience of people who require that all statements should have and possibly other clauses. MySQL may ignore the clauses. MySQL does not require if no tables are referenced.\n\nIn general, clauses used must be given in exactly the order shown in the syntax description. For example, a clause must come after any clause and before any clause. The clause, if present, can appear in any position indicated by the syntax description, but within a given statement can appear only once, not in multiple positions. For more information about , see Section 15.2.13.1, “SELECT ... INTO Statement”.\n\nThe list of terms comprises the select list that indicates which columns to retrieve. Terms specify a column or expression or can use -shorthand:\n\nThe following list provides additional information about other clauses:\n• None A can be given an alias using . The alias is used as the expression's column name and can be used in , , or clauses. For example: SELECT CONCAT(last_name,', ',first_name) AS full_name FROM mytable ORDER BY full_name; The keyword is optional when aliasing a with an identifier. The preceding example could have been written like this: However, because the is optional, a subtle problem can occur if you forget the comma between two expressions: MySQL interprets the second as an alias name. For example, in the following statement, is treated as an alias name: For this reason, it is good practice to be in the habit of using explicitly when specifying column aliases. It is not permissible to refer to a column alias in a clause, because the column value might not yet be determined when the clause is executed. See Section B.3.4.4, “Problems with Column Aliases”.\n• None The clause indicates the table or tables from which to retrieve rows. If you name more than one table, you are performing a join. For information on join syntax, see Section 15.2.13.2, “JOIN Clause”. For each table specified, you can optionally specify an alias. The use of index hints provides the optimizer with information about how to choose indexes during query processing. For a description of the syntax for specifying these hints, see Section 10.9.4, “Index Hints”. You can use as an alternative way to force MySQL to prefer key scans instead of table scans. See Section 7.1.8, “Server System Variables”.\n• None You can refer to a table within the default database as , or as . to specify a database explicitly. You can refer to a column as , . , or . . . You need not specify a or . prefix for a column reference unless the reference would be ambiguous. See Section 11.2.2, “Identifier Qualifiers”, for examples of ambiguity that require the more explicit column reference forms.\n• None A table reference can be aliased using or . These statements are equivalent: SELECT t1.name, t2.salary FROM employee AS t1, info AS t2 WHERE t1.name = t2.name; SELECT t1.name, t2.salary FROM employee t1, info t2 WHERE t1.name = t2.name;\n• None Columns selected for output can be referred to in and clauses using column names, column aliases, or column positions. Column positions are integers and begin with 1: SELECT college, region, seed FROM tournament ORDER BY region, seed; SELECT college, region AS r, seed AS s FROM tournament ORDER BY r, s; SELECT college, region, seed FROM tournament ORDER BY 2, 3; To sort in reverse order, add the (descending) keyword to the name of the column in the clause that you are sorting by. The default is ascending order; this can be specified explicitly using the keyword. If occurs within a parenthesized query expression and also is applied in the outer query, the results are undefined and may change in a future version of MySQL. Use of column positions is deprecated because the syntax has been removed from the SQL standard.\n• None When you use or to sort a column in a , the server sorts values using only the initial number of bytes indicated by the system variable.\n• None MySQL extends the use of to permit selecting fields that are not mentioned in the clause. If you are not getting the results that you expect from your query, please read the description of found in Section 14.19, “Aggregate Functions”.\n• None The clause, like the clause, specifies selection conditions. The clause specifies conditions on columns in the select list, but cannot refer to aggregate functions. The clause specifies conditions on groups, typically formed by the clause. The query result includes only groups satisfying the conditions. (If no is present, all rows implicitly form a single aggregate group.) The clause is applied nearly last, just before items are sent to the client, with no optimization. ( is applied after .) The SQL standard requires that must reference only columns in the clause or columns used in aggregate functions. However, MySQL supports an extension to this behavior, and permits to refer to columns in the list and columns in outer subqueries as well. If the clause refers to a column that is ambiguous, a warning occurs. In the following statement, is ambiguous because it is used as both an alias and a column name: SELECT COUNT(col1) AS col2 FROM t GROUP BY col2 HAVING col2 = 2; Preference is given to standard SQL behavior, so if a column name is used both in and as an aliased column in the select column list, preference is given to the column in the column.\n• None Do not use for items that should be in the clause. For example, do not write the following:\n• None The clause can refer to aggregate functions, which the clause cannot: SELECT user, MAX(salary) FROM users GROUP BY user HAVING MAX(salary) > 10;\n• None MySQL permits duplicate column names. That is, there can be more than one with the same name. This is an extension to standard SQL. Because MySQL also permits and to refer to values, this can result in an ambiguity: SELECT 12 AS a, a FROM t GROUP BY a; In that statement, both columns have the name . To ensure that the correct column is used for grouping, use different names for each .\n• None The clause, if present, defines named windows that can be referred to by window functions. For details, see Section 14.20.4, “Named Windows”.\n• None MySQL resolves unqualified column or alias references in clauses by searching in the values, then in the columns of the tables in the clause. For or clauses, it searches the clause before searching in the values. (For and , this differs from the pre-MySQL 5.0 behavior that used the same rules as for .)\n• None The clause can be used to constrain the number of rows returned by the statement. takes one or two numeric arguments, which must both be nonnegative integer constants, with these exceptions:\n• None Within prepared statements, parameters can be specified using placeholder markers.\n• None Within stored programs, parameters can be specified using integer-valued routine parameters or local variables. With two arguments, the first argument specifies the offset of the first row to return, and the second specifies the maximum number of rows to return. The offset of the initial row is 0 (not 1): To retrieve all rows from a certain offset up to the end of the result set, you can use some large number for the second parameter. This statement retrieves all rows from the 96th row to the last: With one argument, the value specifies the number of rows to return from the beginning of the result set: In other words, is equivalent to . For prepared statements, you can use placeholders. The following statements return one row from the table: SET @a=1; PREPARE STMT FROM 'SELECT * FROM tbl LIMIT ?'; EXECUTE STMT USING @a; The following statements return the second to sixth rows from the table: SET @skip=1; SET @numrows=5; PREPARE STMT FROM 'SELECT * FROM tbl LIMIT ?, ?'; EXECUTE STMT USING @skip, @numrows; For compatibility with PostgreSQL, MySQL also supports the syntax. If occurs within a parenthesized query expression and also is applied in the outer query, the results are undefined and may change in a future version of MySQL.\n• None The form of enables the query result to be written to a file or stored in variables. For more information, see Section 15.2.13.1, “SELECT ... INTO Statement”.\n• None If you use with a storage engine that uses page or row locks, rows examined by the query are write-locked until the end of the current transaction. You cannot use as part of the in a statement such as . (If you attempt to do so, the statement is rejected with the error Can't update table ' ' while ' ' is being created.) and set shared locks that permit other transactions to read the examined rows but not to update or delete them. and are equivalent. However, , like , supports , , and options. is a replacement for , but remains available for backward compatibility. causes a or query to execute immediately, returning an error if a row lock cannot be obtained due to a lock held by another transaction. causes a or query to execute immediately, excluding rows from the result set that are locked by another transaction. and options are unsafe for statement-based replication. Queries that skip locked rows return an inconsistent view of the data. is therefore not suitable for general transactional work. However, it may be used to avoid lock contention when multiple sessions access the same queue-like table. applies and queries to named tables. For example: SELECT * FROM t1, t2 FOR SHARE OF t1 FOR UPDATE OF t2; All tables referenced by the query block are locked when is omitted. Consequently, using a locking clause without in combination with another locking clause returns an error. Specifying the same table in multiple locking clauses returns an error. If an alias is specified as the table name in the statement, a locking clause may only use the alias. If the statement does not specify an alias explicitly, the locking clause may only specify the actual table name. For more information about and , see Section 17.7.2.4, “Locking Reads”. For additional information about and options, see Locking Read Concurrency with NOWAIT and SKIP LOCKED.\n\nFollowing the keyword, you can use a number of modifiers that affect the operation of the statement. , , and modifiers beginning with are MySQL extensions to standard SQL.\n• None The and modifiers specify whether duplicate rows should be returned. (the default) specifies that all matching rows should be returned, including duplicates. specifies removal of duplicate rows from the result set. It is an error to specify both modifiers. is a synonym for . can be used with a query that also uses .\n• None gives the higher priority than a statement that updates a table. You should use this only for queries that are very fast and must be done at once. A query that is issued while the table is locked for reading runs even if there is an update statement waiting for the table to be free. This affects only storage engines that use only table-level locking (such as , , and ). cannot be used with statements that are part of a .\n• None forces the optimizer to join the tables in the order in which they are listed in the clause. You can use this to speed up a query if the optimizer joins the tables in nonoptimal order. also can be used in the list. See Section 15.2.13.2, “JOIN Clause”. does not apply to any table that the optimizer treats as a or table. Such a table produces a single row, is read during the optimization phase of query execution, and references to its columns are replaced with the appropriate column values before query execution proceeds. These tables appear first in the query plan displayed by . See Section 10.8.1, “Optimizing Queries with EXPLAIN”. This exception may not apply to or tables that are used on the -complemented side of an outer join (that is, the right-side table of a or the left-side table of a .\n• None or can be used with or to tell the optimizer that the result set has many rows or is small, respectively. For , MySQL directly uses disk-based temporary tables if they are created, and prefers sorting to using a temporary table with a key on the elements. For , MySQL uses in-memory temporary tables to store the resulting table instead of using sorting. This should not normally be needed.\n• None forces the result to be put into a temporary table. This helps MySQL free the table locks early and helps in cases where it takes a long time to send the result set to the client. This modifier can be used only for top-level statements, not for subqueries or following .\n• None tells MySQL to calculate how many rows there would be in the result set, disregarding any clause. The number of rows can then be retrieved with . See Section 14.15, “Information Functions”. The query modifier and accompanying function are deprecated; expect them to be removed in a future version of MySQL. See the description of for information about an alternative strategy.\n• None The and modifiers were used with the query cache prior to MySQL 8.4. The query cache was removed in MySQL 8.4. The modifier was removed as well. is deprecated, and has no effect; expect it to be removed in a future MySQL release."
    },
    {
        "link": "https://w3schools.com/sql/sql_like.asp",
        "document": "The operator is used in a clause to search for a specified pattern in a column.\n\nThere are two wildcards often used in conjunction with the operator:\n• The percent sign represents zero, one, or multiple characters\n\nYou will learn more about wildcards in the next chapter.\n\nBelow is a selection from the Customers table used in the examples:\n\nIt can be any character or number, but each represents one, and only one, character.\n\nReturn all customers from a city that starts with 'L' followed by one wildcard character, then 'nd' and then two wildcard characters: SELECT * FROM Customers\n\n WHERE city LIKE 'L_nd__'; Try it Yourself »\n\nThe wildcard represents any number of characters, even zero characters.\n\nTo return records that starts with a specific letter or phrase, add the at the end of the letter or phrase.\n\nTo return records that ends with a specific letter or phrase, add the at the beginning of the letter or phrase.\n\nTo return records that contains a specific letter or phrase, add the both before and after the letter or phrase.\n\nAny wildcard, like and , can be used in combination with other wildcards.\n\nReturn all customers that starts with \"a\" and are at least 3 characters in length: SELECT * FROM Customers\n\n WHERE CustomerName LIKE 'a__%'; Try it Yourself »\n\nIf no wildcard is specified, the phrase has to have an exact match to return a result."
    },
    {
        "link": "https://expressjs.com/en/resources/middleware/session.html",
        "document": "This is a Node.js module available through the npm registry. Installation is done using the command:\n\nCreate a session middleware with the given .\n\nNote Session data is not saved in the cookie itself, just the session ID. Session data is stored server-side.\n\nNote Since version 1.5.0, the middleware no longer needs to be used for this module to work. This module now directly reads and writes cookies on / . Using may result in issues if the is not the same between this module and .\n\nWarning The default server-side session storage, , is purposely not designed for a production environment. It will leak memory under most conditions, does not scale past a single process, and is meant for debugging and developing.\n\nFor a list of stores, see compatible session stores.\n\naccepts these properties in the options object.\n\nSettings object for the session ID cookie. The default value is .\n\nThe following are options that can be set in this object.\n\nSpecifies the value for the attribute. By default, no domain is set, and most clients will consider the cookie to apply to only the current domain.\n\nSpecifies the object to be the value for the attribute. By default, no expiration is set, and most clients will consider this a “non-persistent cookie” and will delete it on a condition like exiting a web browser application.\n\nNote If both and are set in the options, then the last one defined in the object is what is used.\n\nNote The option should not be set directly; instead only use the option.\n\nSpecifies the value for the attribute. When truthy, the attribute is set, otherwise it is not. By default, the attribute is set.\n\nNote be careful when setting this to , as compliant clients will not allow client-side JavaScript to see the cookie in .\n\nSpecifies the (in milliseconds) to use when calculating the attribute. This is done by taking the current server time and adding milliseconds to the value to calculate an datetime. By default, no maximum age is set.\n\nNote If both and are set in the options, then the last one defined in the object is what is used.\n\nSpecifies the value for the attribute. When truthy, the attribute is set, otherwise it is not. By default, the attribute is not set.\n\nNote This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it.\n\nMore information about can be found in the proposal.\n\nSpecifies the value for the . By default, this is set to , which is the root path of the domain.\n\nSpecifies the to be the value for the attribute.\n• will set the attribute to .\n• will set the attribute to , the default priority when not set.\n• will set the attribute to .\n\nMore information about the different priority levels can be found in the specification.\n\nNote This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it.\n\nSpecifies the or to be the value for the attribute. By default, this is .\n• will set the attribute to for strict same site enforcement.\n• will not set the attribute.\n• will set the attribute to for lax same site enforcement.\n• will set the attribute to for an explicit cross-site cookie.\n• will set the attribute to for strict same site enforcement.\n\nMore information about the different enforcement levels can be found in the specification.\n\nNote This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it.\n\nNote There is a draft spec that requires that the attribute be set to when the attribute has been set to . Some web browsers or other clients may be adopting this specification.\n\nSpecifies the value for the attribute. When truthy, the attribute is set, otherwise it is not. By default, the attribute is not set.\n\nNote be careful when setting this to , as compliant clients will not send the cookie back to the server in the future if the browser does not have an HTTPS connection.\n\nPlease note that is a recommended option. However, it requires an https-enabled website, i.e., HTTPS is necessary for secure cookies. If is set, and you access your site over HTTP, the cookie will not be set. If you have your node.js behind a proxy and are using , you need to set “trust proxy” in express:\n\nFor using secure cookies in production, but allowing for testing in development, the following is an example of enabling this setup based on in express:\n\nThe option can also be set to the special value to have this setting automatically match the determined security of the connection. Be careful when using this setting if the site is available both as HTTP and HTTPS, as once the cookie is set on HTTPS, it will no longer be visible over HTTP. This is useful when the Express setting is properly setup to simplify development vs production configuration.\n\nFunction to call to generate a new session ID. Provide a function that returns a string that will be used as a session ID. The function is given as the first argument if you want to use some value attached to when generating the ID.\n\nThe default value is a function which uses the library to generate IDs.\n\nNOTE be careful to generate unique IDs so your sessions do not conflict.\n\nThe name of the session ID cookie to set in the response (and read from in the request).\n\nThe default value is .\n\nNote if you have multiple apps running on the same hostname (this is just the name, i.e. or ; different schemes and ports do not name a different hostname), then you need to separate the session cookies from each other. The simplest method is to simply set different s per app.\n\nTrust the reverse proxy when setting secure cookies (via the “X-Forwarded-Proto” header).\n\nThe default value is .\n• The “X-Forwarded-Proto” header will be used.\n• All headers are ignored and the connection is considered secure only if there is a direct TLS/SSL connection.\n• Uses the “trust proxy” setting from express\n\nForces the session to be saved back to the session store, even if the session was never modified during the request. Depending on your store this may be necessary, but it can also create race conditions where a client makes two parallel requests to your server and changes made to the session in one request may get overwritten when the other request ends, even if it made no changes (this behavior also depends on what store you’re using).\n\nThe default value is , but using the default has been deprecated, as the default will change in the future. Please research into this setting and choose what is appropriate to your use-case. Typically, you’ll want .\n\nHow do I know if this is necessary for my store? The best way to know is to check with your store if it implements the method. If it does, then you can safely set . If it does not implement the method and your store sets an expiration date on stored sessions, then you likely need .\n\nForce the session identifier cookie to be set on every response. The expiration is reset to the original , resetting the expiration countdown.\n\nThe default value is .\n\nWith this enabled, the session identifier cookie will expire in since the last response was sent instead of in since the session was last modified by the server.\n\nThis is typically used in conjuction with short, non-session-length values to provide a quick timeout of the session data with reduced potential of it occurring during on going server interactions.\n\nNote When this option is set to but the option is set to , the cookie will not be set on a response with an uninitialized session. This option only modifies the behavior when an existing session was loaded for the request.\n\nForces a session that is “uninitialized” to be saved to the store. A session is uninitialized when it is new but not modified. Choosing is useful for implementing login sessions, reducing server storage usage, or complying with laws that require permission before setting a cookie. Choosing will also help with race conditions where a client makes multiple parallel requests without a session.\n\nThe default value is , but using the default has been deprecated, as the default will change in the future. Please research into this setting and choose what is appropriate to your use-case.\n\nNote if you are using Session in conjunction with PassportJS, Passport will add an empty Passport object to the session for use after a user is authenticated, which will be treated as a modification to the session, causing it to be saved. This has been fixed in PassportJS 0.3.0\n\nThis is the secret used to sign the session ID cookie. The secret can be any type of value that is supported by Node.js (like a string or a ). This can be either a single secret, or an array of multiple secrets. If an array of secrets is provided, only the first element will be used to sign the session ID cookie, while all the elements will be considered when verifying the signature in requests. The secret itself should be not easily parsed by a human and would best be a random set of characters. A best practice may include:\n• The use of environment variables to store the secret, ensuring the secret itself does not exist in your repository.\n• Periodic updates of the secret, while ensuring the previous secret is in the array.\n\nUsing a secret that cannot be guessed will reduce the ability to hijack a session to only guessing the session ID (as determined by the option).\n\nChanging the secret value will invalidate all existing sessions. In order to rotate the secret without invalidating sessions, provide an array of secrets, with the new secret as first element of the array, and including previous secrets as the later elements.\n\nNote HMAC-256 is used to sign the session ID. For this reason, the secret should contain at least 32 bytes of entropy.\n\nThe session store instance, defaults to a new instance.\n\nControl the result of unsetting (through , setting to , etc.).\n\nThe default value is .\n• The session will be destroyed (deleted) when the response ends.\n• The session in the store will be kept, but modifications made during the request are ignored and not saved.\n\nTo store or access session data, simply use the request property , which is (generally) serialized as JSON by the store, so nested objects are typically fine. For example below is a user-specific view counter:\n\nTo regenerate the session simply invoke the method. Once complete, a new SID and instance will be initialized at and the will be invoked.\n\nDestroys the session and will unset the property. Once complete, the will be invoked.\n\nReloads the session data from the store and re-populates the object. Once complete, the will be invoked.\n\nSave the session back to the store, replacing the contents on the store with the contents in memory (though a store may do something else–consult the store’s documentation for exact behavior).\n\nThis method is automatically called at the end of the HTTP response if the session data has been altered (though this behavior can be altered with various options in the middleware constructor). Because of this, typically this method does not need to be called.\n\nThere are some cases where it is useful to call this method, for example, redirects, long-lived requests or in WebSockets.\n\nUpdates the property. Typically this is not necessary to call, as the session middleware does this for you.\n\nEach session has a unique ID associated with it. This property is an alias of and cannot be modified. It has been added to make the session ID accessible from the object.\n\nEach session has a unique cookie object accompany it. This allows you to alter the session cookie per visitor. For example we can set to to enable the cookie to remain for only the duration of the user-agent.\n\nAlternatively will return the time remaining in milliseconds, which we may also re-assign a new value to adjust the property appropriately. The following are essentially equivalent\n\nFor example when is set to (one minute), and 30 seconds has elapsed it will return until the current request has completed, at which time is called to reset to its original value.\n\nThe property returns the original (time-to-live), in milliseconds, of the session cookie.\n\nTo get the ID of the loaded session, access the request property . This is simply a read-only value set when a session is loaded/created.\n\nEvery session store must be an and implement specific methods. The following methods are the list of required, recommended, and optional.\n• Required methods are ones that this module will always call on the store.\n• Recommended methods are ones that this module will call on the store if available.\n• Optional methods are ones this module does not call at all, but helps present uniform stores to users.\n\nFor an example implementation view the connect-redis repo.\n\nThis optional method is used to get all sessions in the store as an array. The should be called as .\n\nThis required method is used to destroy/delete a session from the store given a session ID ( ). The should be called as once the session is destroyed.\n\nThis optional method is used to delete all sessions from the store. The should be called as once the store is cleared.\n\nThis optional method is used to get the count of all sessions in the store. The should be called as .\n\nThis required method is used to get a session from the store given a session ID ( ). The should be called as .\n\nThe argument should be a session if found, otherwise or if the session was not found (and there was no error). A special case is made when to act like .\n\nThis required method is used to upsert a session into the store given a session ID ( ) and session ( ) object. The callback should be called as once the session has been set in the store.\n\nThis recommended method is used to “touch” a given session given a session ID ( ) and session ( ) object. The should be called as once the session has been touched.\n\nThis is primarily used when the store will automatically delete idle sessions and this method is used to signal to the store the given session is active, potentially resetting the idle timer.\n\nThe following modules implement a session store that is compatible with this module. Please make a PR to add additional modules :)\n\ncluster-store A wrapper for using in-process / embedded stores - such as SQLite (via knex), leveldb, files, or memory - with node cluster (desirable for Raspberry Pi 2 and other multi-core embedded devices).\n\nconnect-memjs A memcached-based session store using memjs as the memcached client.\n\nconnect-session-knex A session store using Knex.js, which is a SQL query builder for PostgreSQL, MySQL, MariaDB, SQLite3, and Oracle.\n\nconnect-session-sequelize A session store using Sequelize.js, which is a Node.js / io.js ORM for PostgreSQL, MySQL, SQLite and MSSQL.\n\ndynamodb-store-v3 Implementation of a session store using DynamoDB backed by the AWS SDK for JavaScript v3.\n\nexpress-mysql-session A session store using native MySQL via the node-mysql module.\n\nexpress-oracle-session A session store using native oracle via the node-oracledb module.\n\nexpress-session-cache-manager A store that implements cache-manager, which supports a variety of storage types.\n\nexpress-session-rsdb Session store based on Rocket-Store: A very simple, super fast and yet powerfull, flat file database.\n\nnedb-session-store An alternate NeDB-based (either in-memory or file-persisted) session store.\n\nsession-pouchdb-store Session store for PouchDB / CouchDB. Accepts embedded, custom, or remote PouchDB instance and realtime synchronization.\n\nsessionstore A session store that works with various databases.\n\nA simple example using to store page views for a user.\n\nA simple example using to keep a user log in session.\n\nThis module uses the debug module internally to log information about session operations.\n\nTo see all the internal logs, set the environment variable to when launching your app ( , in this example):\n\nOn Windows, use the corresponding command;"
    },
    {
        "link": "https://jonathan-holloway.medium.com/node-and-express-session-a23eb36a052",
        "document": "Session handling for simple server-side apps can be provided in Node.js and Express by making use of the express-session module. Let’s look at a concrete example of setting this up with the various configuration options. Hurrah!\n\nIn order to setup express-session you need to do the following:\n• Enable express-session in your app.js file or main entry point\n• Create middleware that is injected into each route that checks for the presence of a piece of information in the session\n• Choose your Store correctly, by default express-session uses MemoryStore as the chosen solution. This isn’t intended to be used in production, you’re better off using Firestore (if using Firebase) or Redis or something else.\n\nTo enable express-session you just need the following:\n\nThere are a few key pieces of information here to be aware of with express:\n• name: ‘nameofthesession’ — the name of the session id cookie\n• secret: ‘something’ — used to sign the session cookie, use something secure!\n• resave: false — Forces the session to be resaved back to the session store if not modified (if set to true);\n• saveUnInitialized: false — This forces a new session to be saved when it is created new, before being modified;\n• secure: false — If this is set to ‘true’ during development then you need to ensure you have https enabled, otherwise a new session id will be generated each time;\n• maxAge: 60000 — This is the max-age of the cookie in ms, so make sure you set it appropriately, in my case about 60s/1min.\n\nBy creating a small piece of middleware for Express Session you can check for the presence of the session and handle login/logout accordingly.\n\nIn the following example we look for the profile (created when the user logs in successfully). If we don’t find that profile we redirect to the login page for the user to authenticate with their credentials. Easy!\n\nFinally, we need to inject the middleware into our routes. Make sure you don’t inject this into the login, logout routes however!\n\nJust to be clear, here’s our login route with an example of setting the item in the session:\n\nFinally when we logout we can clear the session by destroying it as follows:\n\nThere’s a full list of the various session store on the express-session Github page here (at the bottom):\n\nIf you’re using Axios to talk to an API, there’s a bit of a gotcha here, make sure you set the following to have Axios send cookies through in requests:"
    },
    {
        "link": "https://codecademy.com/learn/fscp-22-user-authentication-authorization/modules/wdcp-22-session-authentication-in-express/cheatsheet",
        "document": "A session is a storage strategy that consists of information server-side. A session id, as well as other session variables, are stored client-side in cookies or and allow the browser to make an HTTP request to get the persistent session information from the server. Sessions are terminated when a user exits the browser or after client storage is cleared.\n\nA cookie is a text file that stores stateful client data in a key-pair format. It is stored by the web browser, aka client-side. Cookies are first defined by the server, then stored by the browser. The cookie may be sent in requests to the server. Session cookies keep track of the session ID and expire automatically if there’s a time provided or when the browser closes. One cookie for a domain can store 4kb.\n\nand are client-side browser storage introduced with HTML5 that stores data in a key-pair format. It does not interact with the server and is only changeable through JavaScript, with simple syntax. persists after a user exits the browser, while sessionStorage clears when the browser is exited. Per domain, can store 10mb while can store 5mb.\n\nA JSON Web Token (JWT) is a self-contained JSON object that compactly and securely transmits information between two parties. It is digitally signed using a secret or a public/private key pair. It is often sent in the Authorization header using the Bearer schema, as shown in the code example.\n\nThe header and payload will be Base64UrL encoded, and then each part is separated by a , which looks like: . A fully created JWT is shown in the code example.\n\nThe express-session module can be used as a middleware to implement sessions in Express.js. A full configuration looks something like this: where the session secret is used to encrypt the session data stored in the browser, the cookie expiration and options are set, and the , booleans are set.\n\nIn express-session, is used to access the session associated with a request. Session data is serialized as JSON and can be stored in memory, in database, or in a memory cache. The syntax for finding something in a session object looks something like this: .\n\nThe Strict-Transportation-Security HTTP security header enforces the use of HTTPS when a browser accesses a website. Here’s an example of the Strict-Transport-Security header: The value tells the browser that the current site, including all of its sub-domains, is HTTPS-only. The field tells the browser to remember this for the next year (31536000 seconds = 1 year), reducing redirect responses to the HTTPS version of the site in the future.\n\nThe HTTP security header restricts where content-like scripts can load from, which helps prevent Cross-Site-Scripting (XSS) attacks. Options for the header include: only loading from the same domain ( ), specifying for a type of content, and more. Here’s an example of the header: The option restricts which resources JavaScript can be loaded from. The value indicates that the browser should only run scripts from the current domain."
    },
    {
        "link": "https://geeksforgeeks.org/how-to-handle-sessions-in-express",
        "document": "How to handle sessions in Express ?\n\n﻿ExpressJS is a small framework that works on top of Node web server functionality to simplify its APIs and add helpful new features. It makes it easier to organize your application’s functionality with middleware and routing. It adds helpful utilities to Node HTTP objects and facilitates the rendering of dynamic HTTP objects.\n• Use Session Middleware : Start by installing and configuring a session middleware for ExpressJS, such as\n• Require the Middleware : In your ExpressJS application, require the session middleware and initialize it by passing a configuration object.\n• Session Configuration : Set up the session configuration, including options like secret key, session expiration, and cookie settings.\n• Middleware Integration : Add the session middleware to your method. This ensures that session functionality is available throughout your application.\n• Session Data Access : Access session data within your routes and middleware using the object. You can store and retrieve user-specific data in the session object, such as user authentication status or preferences.\n• Session Management : Implement logic to manage session data, such as creating a session upon user login, updating session data during user interactions, and destroying the session upon user logout or inactivity.\n• Security Considerations : Ensure that session-related data, such as session IDs and sensitive user information, are handled securely to prevent and other security vulnerabilities. Use secure , HTTPS, and other best practices to protect session data.\n• Testing : Test your session handling functionality thoroughly to ensure it works as expected. Use tools like or browser testing to simulate user interactions and verify session behavior.\n• None middleware in your ExpressJS application. This middleware creates a session object on the request ) object, which you can use to store session data:\n• None Once the session middleware is set up, you can access and modify session data in your route handlers:\n• None By default, sessions are stored in memory, which is not suitable for production use. You can use session stores like\n• None uses cookies to store session IDs. Ensure that your application properly handles session cookies and sets appropriate security options, such as , to prevent common security vulnerabilities like session hijacking and\n\nBy following these steps, you can effectively handle sessions in your ExpressJS application, allowing you to maintain user state and provide personalized experiences for your users.\n\nExample: Below is the example to handle session in ExpressJS.\n\n// used to sign the session ID cookie // do not save the session if it's not modified // do not save new sessions that have not been modified"
    },
    {
        "link": "https://github.com/expressjs/session",
        "document": "This is a Node.js module available through the npm registry. Installation is done using the command:\n\nCreate a session middleware with the given .\n\nNote Session data is not saved in the cookie itself, just the session ID. Session data is stored server-side.\n\nNote Since version 1.5.0, the middleware no longer needs to be used for this module to work. This module now directly reads and writes cookies on / . Using may result in issues if the is not the same between this module and .\n\nWarning The default server-side session storage, , is purposely not designed for a production environment. It will leak memory under most conditions, does not scale past a single process, and is meant for debugging and developing.\n\nFor a list of stores, see compatible session stores.\n\naccepts these properties in the options object.\n\nSettings object for the session ID cookie. The default value is .\n\nThe following are options that can be set in this object.\n\nSpecifies the value for the attribute. By default, no domain is set, and most clients will consider the cookie to apply to only the current domain.\n\nSpecifies the object to be the value for the attribute. By default, no expiration is set, and most clients will consider this a \"non-persistent cookie\" and will delete it on a condition like exiting a web browser application.\n\nNote If both and are set in the options, then the last one defined in the object is what is used.\n\nNote The option should not be set directly; instead only use the option.\n\nSpecifies the value for the attribute. When truthy, the attribute is set, otherwise it is not. By default, the attribute is set.\n\nNote be careful when setting this to , as compliant clients will not allow client-side JavaScript to see the cookie in .\n\nSpecifies the (in milliseconds) to use when calculating the attribute. This is done by taking the current server time and adding milliseconds to the value to calculate an datetime. By default, no maximum age is set.\n\nNote If both and are set in the options, then the last one defined in the object is what is used.\n\nSpecifies the value for the attribute. When truthy, the attribute is set, otherwise it is not. By default, the attribute is not set.\n\nNote This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it.\n\nMore information about can be found in the proposal.\n\nSpecifies the value for the . By default, this is set to , which is the root path of the domain.\n\nSpecifies the to be the value for the attribute.\n• will set the attribute to .\n• will set the attribute to , the default priority when not set.\n• will set the attribute to .\n\nMore information about the different priority levels can be found in the specification.\n\nNote This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it.\n\nSpecifies the or to be the value for the attribute. By default, this is .\n• will set the attribute to for strict same site enforcement.\n• will not set the attribute.\n• will set the attribute to for lax same site enforcement.\n• will set the attribute to for an explicit cross-site cookie.\n• will set the attribute to for strict same site enforcement.\n\nMore information about the different enforcement levels can be found in the specification.\n\nNote This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it.\n\nNote There is a draft spec that requires that the attribute be set to when the attribute has been set to . Some web browsers or other clients may be adopting this specification.\n\nSpecifies the value for the attribute. When truthy, the attribute is set, otherwise it is not. By default, the attribute is not set.\n\nNote be careful when setting this to , as compliant clients will not send the cookie back to the server in the future if the browser does not have an HTTPS connection.\n\nPlease note that is a recommended option. However, it requires an https-enabled website, i.e., HTTPS is necessary for secure cookies. If is set, and you access your site over HTTP, the cookie will not be set. If you have your node.js behind a proxy and are using , you need to set \"trust proxy\" in express:\n\nFor using secure cookies in production, but allowing for testing in development, the following is an example of enabling this setup based on in express:\n\nThe option can also be set to the special value to have this setting automatically match the determined security of the connection. Be careful when using this setting if the site is available both as HTTP and HTTPS, as once the cookie is set on HTTPS, it will no longer be visible over HTTP. This is useful when the Express setting is properly setup to simplify development vs production configuration.\n\nFunction to call to generate a new session ID. Provide a function that returns a string that will be used as a session ID. The function is given as the first argument if you want to use some value attached to when generating the ID.\n\nThe default value is a function which uses the library to generate IDs.\n\nNOTE be careful to generate unique IDs so your sessions do not conflict.\n\nThe name of the session ID cookie to set in the response (and read from in the request).\n\nThe default value is .\n\nNote if you have multiple apps running on the same hostname (this is just the name, i.e. or ; different schemes and ports do not name a different hostname), then you need to separate the session cookies from each other. The simplest method is to simply set different s per app.\n\nTrust the reverse proxy when setting secure cookies (via the \"X-Forwarded-Proto\" header).\n\nThe default value is .\n• The \"X-Forwarded-Proto\" header will be used.\n• All headers are ignored and the connection is considered secure only if there is a direct TLS/SSL connection.\n• Uses the \"trust proxy\" setting from express\n\nForces the session to be saved back to the session store, even if the session was never modified during the request. Depending on your store this may be necessary, but it can also create race conditions where a client makes two parallel requests to your server and changes made to the session in one request may get overwritten when the other request ends, even if it made no changes (this behavior also depends on what store you're using).\n\nThe default value is , but using the default has been deprecated, as the default will change in the future. Please research into this setting and choose what is appropriate to your use-case. Typically, you'll want .\n\nHow do I know if this is necessary for my store? The best way to know is to check with your store if it implements the method. If it does, then you can safely set . If it does not implement the method and your store sets an expiration date on stored sessions, then you likely need .\n\nForce the session identifier cookie to be set on every response. The expiration is reset to the original , resetting the expiration countdown.\n\nThe default value is .\n\nWith this enabled, the session identifier cookie will expire in since the last response was sent instead of in since the session was last modified by the server.\n\nThis is typically used in conjuction with short, non-session-length values to provide a quick timeout of the session data with reduced potential of it occurring during on going server interactions.\n\nNote When this option is set to but the option is set to , the cookie will not be set on a response with an uninitialized session. This option only modifies the behavior when an existing session was loaded for the request.\n\nForces a session that is \"uninitialized\" to be saved to the store. A session is uninitialized when it is new but not modified. Choosing is useful for implementing login sessions, reducing server storage usage, or complying with laws that require permission before setting a cookie. Choosing will also help with race conditions where a client makes multiple parallel requests without a session.\n\nThe default value is , but using the default has been deprecated, as the default will change in the future. Please research into this setting and choose what is appropriate to your use-case.\n\nNote if you are using Session in conjunction with PassportJS, Passport will add an empty Passport object to the session for use after a user is authenticated, which will be treated as a modification to the session, causing it to be saved. This has been fixed in PassportJS 0.3.0\n\nThis is the secret used to sign the session ID cookie. The secret can be any type of value that is supported by Node.js (like a string or a ). This can be either a single secret, or an array of multiple secrets. If an array of secrets is provided, only the first element will be used to sign the session ID cookie, while all the elements will be considered when verifying the signature in requests. The secret itself should be not easily parsed by a human and would best be a random set of characters. A best practice may include:\n• The use of environment variables to store the secret, ensuring the secret itself does not exist in your repository.\n• Periodic updates of the secret, while ensuring the previous secret is in the array.\n\nUsing a secret that cannot be guessed will reduce the ability to hijack a session to only guessing the session ID (as determined by the option).\n\nChanging the secret value will invalidate all existing sessions. In order to rotate the secret without invalidating sessions, provide an array of secrets, with the new secret as first element of the array, and including previous secrets as the later elements.\n\nNote HMAC-256 is used to sign the session ID. For this reason, the secret should contain at least 32 bytes of entropy.\n\nThe session store instance, defaults to a new instance.\n\nControl the result of unsetting (through , setting to , etc.).\n\nThe default value is .\n• The session will be destroyed (deleted) when the response ends.\n• The session in the store will be kept, but modifications made during the request are ignored and not saved.\n\nTo store or access session data, simply use the request property , which is (generally) serialized as JSON by the store, so nested objects are typically fine. For example below is a user-specific view counter:\n\nTo regenerate the session simply invoke the method. Once complete, a new SID and instance will be initialized at and the will be invoked.\n\nDestroys the session and will unset the property. Once complete, the will be invoked.\n\nReloads the session data from the store and re-populates the object. Once complete, the will be invoked.\n\nSave the session back to the store, replacing the contents on the store with the contents in memory (though a store may do something else--consult the store's documentation for exact behavior).\n\nThis method is automatically called at the end of the HTTP response if the session data has been altered (though this behavior can be altered with various options in the middleware constructor). Because of this, typically this method does not need to be called.\n\nThere are some cases where it is useful to call this method, for example, redirects, long-lived requests or in WebSockets.\n\nUpdates the property. Typically this is not necessary to call, as the session middleware does this for you.\n\nEach session has a unique ID associated with it. This property is an alias of and cannot be modified. It has been added to make the session ID accessible from the object.\n\nEach session has a unique cookie object accompany it. This allows you to alter the session cookie per visitor. For example we can set to to enable the cookie to remain for only the duration of the user-agent.\n\nAlternatively will return the time remaining in milliseconds, which we may also re-assign a new value to adjust the property appropriately. The following are essentially equivalent\n\nFor example when is set to (one minute), and 30 seconds has elapsed it will return until the current request has completed, at which time is called to reset to its original value.\n\nThe property returns the original (time-to-live), in milliseconds, of the session cookie.\n\nTo get the ID of the loaded session, access the request property . This is simply a read-only value set when a session is loaded/created.\n\nEvery session store must be an and implement specific methods. The following methods are the list of required, recommended, and optional.\n• Required methods are ones that this module will always call on the store.\n• Recommended methods are ones that this module will call on the store if available.\n• Optional methods are ones this module does not call at all, but helps present uniform stores to users.\n\nFor an example implementation view the connect-redis repo.\n\nThis optional method is used to get all sessions in the store as an array. The should be called as .\n\nThis required method is used to destroy/delete a session from the store given a session ID ( ). The should be called as once the session is destroyed.\n\nThis optional method is used to delete all sessions from the store. The should be called as once the store is cleared.\n\nThis optional method is used to get the count of all sessions in the store. The should be called as .\n\nThis required method is used to get a session from the store given a session ID ( ). The should be called as .\n\nThe argument should be a session if found, otherwise or if the session was not found (and there was no error). A special case is made when to act like .\n\nThis required method is used to upsert a session into the store given a session ID ( ) and session ( ) object. The callback should be called as once the session has been set in the store.\n\nThis recommended method is used to \"touch\" a given session given a session ID ( ) and session ( ) object. The should be called as once the session has been touched.\n\nThis is primarily used when the store will automatically delete idle sessions and this method is used to signal to the store the given session is active, potentially resetting the idle timer.\n\nThe following modules implement a session store that is compatible with this module. Please make a PR to add additional modules :)\n\ncluster-store A wrapper for using in-process / embedded stores - such as SQLite (via knex), leveldb, files, or memory - with node cluster (desirable for Raspberry Pi 2 and other multi-core embedded devices).\n\nconnect-memjs A memcached-based session store using memjs as the memcached client.\n\nconnect-session-knex A session store using Knex.js, which is a SQL query builder for PostgreSQL, MySQL, MariaDB, SQLite3, and Oracle.\n\nconnect-session-sequelize A session store using Sequelize.js, which is a Node.js / io.js ORM for PostgreSQL, MySQL, SQLite and MSSQL.\n\ndynamodb-store-v3 Implementation of a session store using DynamoDB backed by the AWS SDK for JavaScript v3.\n\nexpress-mysql-session A session store using native MySQL via the node-mysql module.\n\nexpress-oracle-session A session store using native oracle via the node-oracledb module.\n\nexpress-session-cache-manager A store that implements cache-manager, which supports a variety of storage types.\n\nexpress-session-rsdb Session store based on Rocket-Store: A very simple, super fast and yet powerfull, flat file database.\n\nnedb-session-store An alternate NeDB-based (either in-memory or file-persisted) session store.\n\nsession-pouchdb-store Session store for PouchDB / CouchDB. Accepts embedded, custom, or remote PouchDB instance and realtime synchronization.\n\nsessionstore A session store that works with various databases.\n\nA simple example using to store page views for a user.\n\nA simple example using to keep a user log in session.\n\nThis module uses the debug module internally to log information about session operations.\n\nTo see all the internal logs, set the environment variable to when launching your app ( , in this example):\n\nOn Windows, use the corresponding command;"
    },
    {
        "link": "https://nodejs.org/api/fs.html",
        "document": "The module enables interacting with the file system in a way modeled on standard POSIX functions.\n\nTo use the promise-based APIs:\n\nTo use the callback and sync APIs:\n\nAll file system operations have synchronous, callback, and promise-based forms, and are accessible using both CommonJS syntax and ES6 Modules (ESM).\n\nThe common objects are shared by all of the file system API variants (promise, callback, and synchronous). When using the async iterator, the <fs.Dir> object will be automatically closed after the iterator exits. Asynchronously close the directory's underlying resource handle. Subsequent reads will result in errors. A promise is returned that will be fulfilled after the resource has been closed. Passing an invalid callback to the argument now throws instead of . Asynchronously close the directory's underlying resource handle. Subsequent reads will result in errors. The will be called after the resource handle has been closed. Synchronously close the directory's underlying resource handle. Subsequent reads will result in errors. The read-only path of this directory as was provided to , , or . Asynchronously read the next directory entry via as an <fs.Dirent>. A promise is returned that will be fulfilled with an <fs.Dirent>, or if there are no more directory entries to read. Directory entries returned by this function are in no particular order as provided by the operating system's underlying directory mechanisms. Entries added or removed while iterating over the directory might not be included in the iteration results. Asynchronously read the next directory entry via as an <fs.Dirent>. After the read is completed, the will be called with an <fs.Dirent>, or if there are no more directory entries to read. Directory entries returned by this function are in no particular order as provided by the operating system's underlying directory mechanisms. Entries added or removed while iterating over the directory might not be included in the iteration results. Synchronously read the next directory entry as an <fs.Dirent>. See the POSIX documentation for more detail. If there are no more directory entries to read, will be returned. Directory entries returned by this function are in no particular order as provided by the operating system's underlying directory mechanisms. Entries added or removed while iterating over the directory might not be included in the iteration results. Asynchronously iterates over the directory until all entries have been read. Refer to the POSIX documentation for more detail. Entries returned by the async iterator are always an <fs.Dirent>. The case from is handled internally. See <fs.Dir> for an example. Directory entries returned by this iterator are in no particular order as provided by the operating system's underlying directory mechanisms. Entries added or removed while iterating over the directory might not be included in the iteration results. A representation of a directory entry, which can be a file or a subdirectory within the directory, as returned by reading from an <fs.Dir>. The directory entry is a combination of the file name and file type pairs. Additionally, when or is called with the option set to , the resulting array is filled with <fs.Dirent> objects, rather than strings or <Buffer>s. The file name that this <fs.Dirent> object refers to. The type of this value is determined by the passed to or . The path to the parent directory of the file this <fs.Dirent> object refers to. The property is no longer read-only. Accessing this property emits a warning. It is now read-only. A successful call to method will return a new <fs.FSWatcher> object. All <fs.FSWatcher> objects emit a event whenever a specific watched file is modified.\n• <string> The type of change event that has occurred\n• <string> | <Buffer> The filename that changed (if relevant/available) Emitted when something changes in a watched directory or file. See more details in . The argument may not be provided depending on operating system support. If is provided, it will be provided as a <Buffer> if is called with its option set to , otherwise will be a UTF-8 string. Emitted when the watcher stops watching for changes. The closed <fs.FSWatcher> object is no longer usable in the event handler. Emitted when an error occurs while watching the file. The errored <fs.FSWatcher> object is no longer usable in the event handler. Stop watching for changes on the given <fs.FSWatcher>. Once stopped, the <fs.FSWatcher> object is no longer usable. When called, requests that the Node.js event loop not exit so long as the <fs.FSWatcher> is active. Calling multiple times will have no effect. By default, all <fs.FSWatcher> objects are \"ref'ed\", making it normally unnecessary to call unless had been called previously. When called, the active <fs.FSWatcher> object will not require the Node.js event loop to remain active. If there is no other activity keeping the event loop running, the process may exit before the <fs.FSWatcher> object's callback is invoked. Calling multiple times will have no effect. A successful call to method will return a new <fs.StatWatcher> object. When called, requests that the Node.js event loop not exit so long as the <fs.StatWatcher> is active. Calling multiple times will have no effect. By default, all <fs.StatWatcher> objects are \"ref'ed\", making it normally unnecessary to call unless had been called previously. When called, the active <fs.StatWatcher> object will not require the Node.js event loop to remain active. If there is no other activity keeping the event loop running, the process may exit before the <fs.StatWatcher> object's callback is invoked. Calling multiple times will have no effect. Instances of <fs.ReadStream> are created and returned using the function. Emitted when the <fs.ReadStream>'s underlying file descriptor has been closed.\n• <integer> Integer file descriptor used by the <fs.ReadStream>. Emitted when the <fs.ReadStream>'s file descriptor has been opened. Emitted when the <fs.ReadStream> is ready to be used. The number of bytes that have been read so far. The path to the file the stream is reading from as specified in the first argument to . If is passed as a string, then will be a string. If is passed as a <Buffer>, then will be a <Buffer>. If is specified, then will be . This property is if the underlying file has not been opened yet, i.e. before the event is emitted. Objects returned from , , , and their synchronous counterparts are of this type. If in the passed to those methods is true, the numeric values will be instead of , and the object will contain additional nanosecond-precision properties suffixed with . objects are not to be created directly using the keyword. If the <fs.Stats> object was obtained from calling on a symbolic link which resolves to a directory, this method will return . This is because returns information about a symbolic link itself and not the path it resolves to. This method is only valid when using . The numeric identifier of the device containing the file. The file system specific \"Inode\" number for the file. The number of hard-links that exist for the file. The numeric user identifier of the user that owns the file (POSIX). The numeric group identifier of the group that owns the file (POSIX). The size of the file in bytes. If the underlying file system does not support getting the size of the file, this will be . The number of blocks allocated for this file. The timestamp indicating the last time this file was accessed expressed in milliseconds since the POSIX Epoch. The timestamp indicating the last time this file was modified expressed in milliseconds since the POSIX Epoch. The timestamp indicating the last time the file status was changed expressed in milliseconds since the POSIX Epoch. The timestamp indicating the creation time of this file expressed in milliseconds since the POSIX Epoch. Only present when is passed into the method that generates the object. The timestamp indicating the last time this file was accessed expressed in nanoseconds since the POSIX Epoch. Only present when is passed into the method that generates the object. The timestamp indicating the last time this file was modified expressed in nanoseconds since the POSIX Epoch. Only present when is passed into the method that generates the object. The timestamp indicating the last time the file status was changed expressed in nanoseconds since the POSIX Epoch. Only present when is passed into the method that generates the object. The timestamp indicating the creation time of this file expressed in nanoseconds since the POSIX Epoch. The timestamp indicating the last time this file was accessed. The timestamp indicating the last time this file was modified. The timestamp indicating the last time the file status was changed. The timestamp indicating the creation time of this file. The , , , properties are numeric values that hold the corresponding times in milliseconds. Their precision is platform specific. When is passed into the method that generates the object, the properties will be bigints, otherwise they will be numbers. The , , , properties are bigints that hold the corresponding times in nanoseconds. They are only present when is passed into the method that generates the object. Their precision is platform specific. , , , and are object alternate representations of the various times. The and number values are not connected. Assigning a new number value, or mutating the value, will not be reflected in the corresponding alternate representation. The times in the stat object have the following semantics:\n• \"Access Time\": Time when file data last accessed. Changed by the , , and system calls.\n• \"Modified Time\": Time when file data last modified. Changed by the , , and system calls.\n• \"Change Time\": Time when file status was last changed (inode data modification). Changed by the , , , , , , , , and system calls.\n• \"Birth Time\": Time of file creation. Set once when the file is created. On file systems where birthtime is not available, this field may instead hold either the or (ie, Unix epoch timestamp ). This value may be greater than or in this case. On Darwin and other FreeBSD variants, also set if the is explicitly set to an earlier value than the current using the system call. Prior to Node.js 0.12, the held the on Windows systems. As of 0.12, is not \"creation time\", and on Unix systems, it never was. Objects returned from and its synchronous counterpart are of this type. If in the passed to those methods is , the numeric values will be instead of . Instances of <fs.WriteStream> are created and returned using the function. Emitted when the <fs.WriteStream>'s underlying file descriptor has been closed.\n• <integer> Integer file descriptor used by the <fs.WriteStream>. Emitted when the <fs.WriteStream>'s file is opened. Emitted when the <fs.WriteStream> is ready to be used. The number of bytes written so far. Does not include data that is still queued for writing. Closes . Optionally accepts a callback that will be executed once the is closed. The path to the file the stream is writing to as specified in the first argument to . If is passed as a string, then will be a string. If is passed as a <Buffer>, then will be a <Buffer>. This property is if the underlying file has not been opened yet, i.e. before the event is emitted. Returns an object containing commonly used constants for file system operations. The following constants are exported by and . Not every constant will be available on every operating system; this is especially important for Windows, where many of the POSIX specific definitions are not available. For portable applications it is recommended to check for their presence before use. To use more than one constant, use the bitwise OR operator. The following constants are meant for use as the parameter passed to , , and . Flag indicating that the file is visible to the calling process. This is useful for determining if a file exists, but says nothing about permissions. Default if no mode is specified. Flag indicating that the file can be read by the calling process. Flag indicating that the file can be written by the calling process. Flag indicating that the file can be executed by the calling process. This has no effect on Windows (will behave like ). The definitions are also available on Windows. The following constants are meant for use with . If present, the copy operation will fail with an error if the destination path already exists. If present, the copy operation will attempt to create a copy-on-write reflink. If the underlying platform does not support copy-on-write, then a fallback copy mechanism is used. If present, the copy operation will attempt to create a copy-on-write reflink. If the underlying platform does not support copy-on-write, then the operation will fail with an error. The definitions are also available on Windows. The following constants are meant for use with . Flag indicating to create the file if it does not already exist. Flag indicating that opening a file should fail if the flag is set and the file already exists. Flag indicating that if path identifies a terminal device, opening the path shall not cause that terminal to become the controlling terminal for the process (if the process does not already have one). Flag indicating that if the file exists and is a regular file, and the file is opened successfully for write access, its length shall be truncated to zero. Flag indicating that data will be appended to the end of the file. Flag indicating that the open should fail if the path is not a directory. Flag indicating reading accesses to the file system will no longer result in an update to the information associated with the file. This flag is available on Linux operating systems only. Flag indicating that the open should fail if the path is a symbolic link. Flag indicating that the file is opened for synchronized I/O with write operations waiting for file integrity. Flag indicating that the file is opened for synchronized I/O with write operations waiting for data integrity. Flag indicating to open the symbolic link itself rather than the resource it is pointing to. When set, an attempt will be made to minimize caching effects of file I/O. Flag indicating to open the file in nonblocking mode when possible. When set, a memory file mapping is used to access the file. This flag is available on Windows operating systems only. On other operating systems, this flag is ignored. On Windows, only , , , , , , , and are available. The following constants are meant for use with the <fs.Stats> object's property for determining a file's type. Bit mask used to extract the file type code. On Windows, only , , , , and , are available. The following constants are meant for use with the <fs.Stats> object's property for determining the access permissions for a file. File mode indicating readable, writable, and executable by others. On Windows, only and are available.\n\nBecause they are executed asynchronously by the underlying thread pool, there is no guaranteed ordering when using either the callback or promise-based methods. For example, the following is prone to error because the operation might complete before the operation: It is important to correctly order the operations by awaiting the results of one before invoking the other: Or, when using the callback APIs, move the call into the callback of the operation: Most operations accept file paths that may be specified in the form of a string, a <Buffer>, or a <URL> object using the protocol. String paths are interpreted as UTF-8 character sequences identifying the absolute or relative filename. Relative paths will be resolved relative to the current working directory as determined by calling . Example using an absolute path on POSIX: Example using a relative path on POSIX (relative to ): For most module functions, the or argument may be passed as a <URL> object using the protocol. On Windows, <URL>s with a host name convert to UNC paths, while <URL>s with drive letters convert to local absolute paths. <URL>s with no host name and no drive letter will result in an error: <URL>s with drive letters must use as a separator just after the drive letter. Using another separator will result in an error. On all other platforms, <URL>s with a host name are unsupported and will result in an error: A <URL> having encoded slash characters will result in an error on all platforms: On Windows, <URL>s having encoded backslash will result in an error: Paths specified using a <Buffer> are useful primarily on certain POSIX operating systems that treat file paths as opaque byte sequences. On such systems, it is possible for a single file path to contain sub-sequences that use multiple character encodings. As with string paths, <Buffer> paths may be relative or absolute: Example using an absolute path on POSIX: On Windows, Node.js follows the concept of per-drive working directory. This behavior can be observed when using a drive path without a backslash. For example can potentially return a different result than . For more information, see this MSDN page. On POSIX systems, for every process, the kernel maintains a table of currently open files and resources. Each open file is assigned a simple numeric identifier called a file descriptor. At the system-level, all file system operations use these file descriptors to identify and track each specific file. Windows systems use a different but conceptually similar mechanism for tracking resources. To simplify things for users, Node.js abstracts away the differences between operating systems and assigns all open files a numeric file descriptor. The callback-based , and synchronous methods open a file and allocate a new file descriptor. Once allocated, the file descriptor may be used to read data from, write data to, or request information about the file. Operating systems limit the number of file descriptors that may be open at any given time so it is critical to close the descriptor when operations are completed. Failure to do so will result in a memory leak that will eventually cause an application to crash. The promise-based APIs use a <FileHandle> object in place of the numeric file descriptor. These objects are better managed by the system to ensure that resources are not leaked. However, it is still required that they are closed when operations are completed: All callback and promise-based file system APIs (with the exception of ) use libuv's threadpool. This can have surprising and negative performance implications for some applications. See the documentation for more information. The following flags are available wherever the option takes a string.\n• : Open file for appending. The file is created if it does not exist.\n• : Like but fails if the path exists.\n• : Open file for reading and appending. The file is created if it does not exist.\n• : Like but fails if the path exists.\n• : Open file for appending in synchronous mode. The file is created if it does not exist.\n• : Open file for reading and appending in synchronous mode. The file is created if it does not exist.\n• : Open file for reading. An exception occurs if the file does not exist.\n• : Open file for reading in synchronous mode. An exception occurs if the file does not exist.\n• : Open file for reading and writing. An exception occurs if the file does not exist.\n• : Open file for reading and writing in synchronous mode. Instructs the operating system to bypass the local file system cache. This is primarily useful for opening files on NFS mounts as it allows skipping the potentially stale local cache. It has a very real impact on I/O performance so using this flag is not recommended unless it is needed. This doesn't turn or into a synchronous blocking call. If synchronous operation is desired, something like should be used.\n• : Open file for writing. The file is created (if it does not exist) or truncated (if it exists).\n• : Like but fails if the path exists.\n• : Open file for reading and writing. The file is created (if it does not exist) or truncated (if it exists).\n• : Like but fails if the path exists. can also be a number as documented by ; commonly used constants are available from . On Windows, flags are translated to their equivalent ones where applicable, e.g. to , or to , as accepted by . The exclusive flag ( flag in ) causes the operation to return an error if the path already exists. On POSIX, if the path is a symbolic link, using returns an error even if the link is to a path that does not exist. The exclusive flag might not work with network file systems. On Linux, positional writes don't work when the file is opened in append mode. The kernel ignores the position argument and always appends the data to the end of the file. Modifying a file rather than replacing it may require the option to be set to rather than the default . The behavior of some flags are platform-specific. As such, opening a directory on macOS and Linux with the flag, as in the example below, will return an error. In contrast, on Windows and FreeBSD, a file descriptor or a will be returned. On Windows, opening an existing hidden file using the flag (either through , , or ) will fail with . Existing hidden files can be opened for writing with the flag. A call to or can be used to reset the file contents."
    },
    {
        "link": "https://blog.logrocket.com/reading-writing-json-files-node-js-complete-tutorial",
        "document": "Editor’s note: This article was last updated by Oyinkansola Awosan on 18 October 2024 to cover handling large JSON files using and to add information about the third-party library jsonfile.\n\nNode.js provides built-in modules and third-party libraries for reading and writing JSON files. It offers flexible methods to suit various needs, such as handling small JSON objects or large datasets. These modules and libraries make it easy to work with structured data in JSON format. More often than not, this JSON data needs to be read from or written to a file for persistence, and the Node runtime environment has the built-in module specifically for working with files.\n\nIn the Node runtime environment, you can use the built-in function and modules to load or read JSON files. Because the function is available for each module, you don’t need to require it. However, you must require the module before using it.\n\nIn the following sections, we will dive into how to read JSON files using the built-in module and the function.\n\nFirst, let’s create a JSON file. To do that, we can input the data below in a file called\n\nYou can use the method to read JSON files. It asynchronously reads the contents of the entire file in memory and is therefore not the most optimal method for reading large JSON files.\n\nThe method takes three arguments. The code snippet below shows its function signature:\n• The first argument, , is the file name or the file descriptor\n• The second is an optional object argument\n• The third is a function. You can also pass a string as the second argument instead of an object. If you pass a string, then it has to be encoded\n\nThe function takes two arguments. The first argument is the object if an error occurs, and the second is the serialized JSON data:\n\nIn the example above, we import the module, then use to read our previously created JSON file, . The code retrieves the file’s content, checks for errors, and, if successful, parses the JSON data into a JavaScript object, which is then printed.\n\nMake sure to deserialize the JSON string passed to the function before you start working with the resulting JavaScript object.\n\nYou can use the function to synchronously load JSON files in Node. After loading a file using , it is cached. Therefore, loading the file again using will load the cached version. In a server environment, the file will be loaded again in the next server restart.\n\nTherefore, it is advisable to use for loading static JSON files such as configuration files that don’t change often. Don’t use if the JSON file you load keeps changing, because it will cache the loaded file, and use the cached version if you require the same file again. Your latest changes will not be reflected.\n\nAssuming you have a file with the following contents:\n\nYou can load the file in a JavaScript file using the code below. will always load the JSON data as a JavaScript object:\n\nis another built-in method for reading files in Node similar to . The difference between the two is that reads the file asynchronously while reads the file synchronously. Therefore, blocks the event loop and execution of the remaining code until all the data has been read.\n\nCheck out this article for more information about the difference between synchronous and asynchronous code.\n\nBelow is the function signature of :\n\nrefers to the location of the JSON file you wish to read. Optionally, you can provide an object as the second argument.\n\nIn the code snippet below, we are reading JSON data from the file using :\n\nHow to write to JSON files in Node.js\n\nJust like reading JSON files, the module provides built-in methods for writing to JSON files. You can use the , as discussed above, and the methods, as discussed below. The difference between the two is that:\n\nBefore writing a JSON file, make sure to serialize the JavaScript object to a JSON string using the method. will format your JSON data in a single line if you do not pass the optional formatting argument to the method specifying how to format your JSON data.\n\nTo write a JSON file, the module is also required. Here, we will use the method. The method takes four arguments. The code snippet below shows its function signature:\n\nWhen the method is given the path of an existing JSON file, it will overwrite that file’s data. It will create a new file if the file does not exist:\n\nHere, we use the method to write the JSON string to a file named and ask for a success or error message depending on which one occurs.\n\nUnlike , writes to a file synchronously. If you use , you will block the execution of the event loop and the rest of the code until the operation is successful or an error occurs. It will create a new file if the path you pass doesn’t exist and overwrite it if it does.\n\nIn the code snippet below, we are writing to the file. We wrap the code in so that we can catch any errors:\n\nNode doesn’t have a built-in function for appending or updating the fields of an existing JSON file out of the box. However, you can read the JSON file using the method of the module, update it, and overwrite the JSON file with the updated JSON.\n\nBelow is a code snippet illustrating how to do this:\n\nThere are other methods for reading and writing JSON files, which we’ll cover in the following sections.\n\nSerialization is the process of modifying an object or data structure to a format that is easy to store or transfer over the internet. You can recover the serialized data by applying the reverse process.\n\nDeserialization refers to transforming the serialized data structure to its original format. You will almost always need to serialize JSON or JavaScript objects to a JSON string in Node. You can do so with the method before writing it to a storage device or transmitting it over the internet:\n\nOn the other hand, after reading the JSON file, you will need to deserialize the JSON string to a plain JavaScript object using the method before accessing or manipulating the data:\n\nand are globally available methods in Node. You don’t need to install or require them before using them.\n\nThe module is built-in, and it provides functions that you can use to read and write data in the JSON format and much more.\n\nEach function exposed by the module has synchronous, callback, and promise-based forms. The synchronous and callback variants of a method are accessible from the synchronous and callback API. The promise-based variant of a function is accessible from the promise-based API.\n\nThe synchronous methods of the built-in module block the event loop and further execution of the remaining code until the operation has succeeded or failed. More often than not, blocking the event loop is not something you want to do.\n\nThe names of all synchronous functions end with the characters. For example, and are both synchronous functions.\n\nYou can access the synchronous API by requiring :\n\nUnlike the synchronous methods that block the execution of the remaining code until the operation has succeeded or failed, the corresponding methods of the callback API are asynchronous. You’ll pass a callback function to the method as the last argument.\n\nThe callback function is invoked with an object as the first argument if an error occurs. The remainder of the arguments to the callback function depend on the method.\n\nYou can also access the methods of the callback API by requiring like the synchronous API:\n\nThe promise-based API is asynchronous, like the callback API. It returns a promise, which you can manage via promise chaining or async/await.\n\nYou can access the promise-based API by requiring :\n\nWe used the CommonJS syntax to access the modules in the code snippets above. We’ll continue using the CommonJS syntax throughout this article. You can also use ES6 modules if you want.\n\nAccording to the Node documentation, the callback API of the built-in module is more performant than the promise-based API. Therefore, most examples in this article will use the callback API.\n\nRead and write to JSON files using third-party npm packages\n\nIn this section, we’ll look at the most popular third-party Node packages for reading and writing data in JSON format.\n\njsonfile is a popular npm package for reading and writing JSON files in Node. You can install it using the following command:\n\nIt is similar to the and methods of the built-in module, though jsonfile has some advantages over the built-in methods:\n• It serializes and deserializes JSON out of the box\n• It has a built-in utility for appending data to a JSON file\n\nYou can see the jsonfile package in action in the code snippet below:\n\nYou can also use promise chaining instead of passing a callback function like the example above:\n\nfs-extra is another popular Node package you can use to work with files. Though you can use this package for managing JSON files, it has methods whose functions extend beyond just reading and writing JSON files.\n\nAs its name suggests, fs-extra has all the functionalities provided by the module and more. According to the documentation, you can use the fs-extra package instead of the module.\n\nBefore using it, you need to first install fs-extra from npm:\n\nThe code below shows how you can read JSON files using the method of the fs-extra package. You can use a callback function, promise chaining, or async/await:\n\nThe code below illustrates how you can write JSON data using the method:\n\nJust like the module, fs-extra has both asynchronous and synchronous methods. You don’t need to stringify your JavaScript object before writing to a JSON file.\n\nSimilarly, you don’t need to parse to a JavaScript object after reading a JSON file. The module does it for you out of the box.\n\nbfj is another npm package you can use to handle data in JSON format. According to the documentation, it was created for managing large JSON datasets:\n\nTo install bfj from the npm package registry, run the following code:\n\nYou can read JSON data using the method, which is asynchronous and returns a promise.\n\n Assuming you have a file, you can use the following code to read it:\n\nSimilarly, you can use the method to write data to a JSON file:\n\nbfj was created purposely for handling large JSON data. It is also slow, so you should only use it if you are handling relatively large JSON datasets.\n\nAs explained above, the built-in functions of the synchronous and asynchronous APIs read the entire file into memory. This is inefficient in terms of both time and memory as you need to wait until the entire file is read into memory before processing. If you are dealing with a large JSON file, you may wait for a long time. Similarly, you may run out of memory while reading large JSON files.\n\nTo remedy these issues, you may want to use streams to read and process JSON data. Streams in Node.js enable you to handle data in chunks rather than loading the entire file into memory. This is useful for managing memory usage and improving performance when reading and writing large files. The stream-json package comes in handy when streaming large JSON data.\n\nThe method in Node.js’s fs (file system) module is used to read large files in chunks or streams, rather than loading the entire file into memory at once. This approach is particularly useful for efficiently handling large files, such as logs and JSON data.\n\nHere, we will look at how to use , but first, we need to install the package as seen below:\n\nIn the example below, we used with the package to read and parse . This reduces your application’s memory footprint and enables you to process chunks of data immediately after they become available:\n\nBest practices and common pitfalls when reading and writing JSON files\n• When dealing with file operations, it’s essential to first create a backup of datasets to avoid losing or corrupting the data\n• The method loads the entire JSON file into memory and caches it. For JSON files that change frequently, it’s best to avoid and use module functions instead\n• Error handling is essential, especially when using synchronous and promise-based APIs in conjunction with async/await because it prevents application failures\n• Using the parameter in improves JSON string readability, but it’s best avoided for network transmissions to reduce bundle size\n• Note that, according to Node.js documentation, the promise-based API is not thread-safe\n\nIt is not uncommon to encounter the error when serializing a JavaScript object using the function. This error occurs when you attempt to stringify a JavaScript object that references itself, as in the example below:\n\nThere is no straightforward fix to this error. However, you can manually find and replace the circular references with serializable values or use a third-party library like cycle.js, which was created by Douglas Crockford, the brain behind the JSON format.\n\nA fork of the library is maintained at the npm package registry as . You can install it like so:\n\nThen, you can use it in your application, as shown below:\n\nThe function of the package highlighted above will create a copy of the object, look for duplicate references, which might be circular references, and replace them with objects of the form .\n\nYou can then stringify and parse the resulting object without encountering the mentioned above. After that, you can store the resulting object on disk or transfer it over the network.\n\nYou can use the function of the package to get a copy of the original object.\n\nAs explained in the above sections, JSON is one of the most popular formats for data exchange over the internet. The Node runtime environment has the built-in module you can use to work with files in general. The module has methods that you can use to read and write to JSON files using the callback API, promise-based API, or synchronous API.\n\nBecause methods of the callback API are more performant than those of the promise-based API, you are better off using the callback API.\n\nIn addition to the built-in module, several popular third-party packages such as jsonfile, fs-extra, and bfj exist. They have additional utility functions that make working with JSON files a breeze. On the flip side, you should evaluate the limitations of adding third-party packages to your application."
    },
    {
        "link": "https://heynode.com/tutorial/readwrite-json-files-nodejs",
        "document": "By the end of this tutorial you should be able to work with JSON files using Node’s built-in fs module.\n\nWhen you want to store data between server restarts with Node, JSON files are a simple and convenient choice. Whether you are reading a config file or persisting data for your application, Node has some built in utilities that make it easy to read and write JSON files. Using JSON files in your app can be a useful way to persist data. We will look at a few different methods for working with JSON files.\n\nSay you have a customer.json file saved to disk that holds a record for a customer in your store.\n\nAs part of your store app, you want to access the customer’s address, and then update the order count after an order is placed.\n\nIn this tutorial, we are going to look at how to read and write to our customer.json file.\n\nAccessing files in Node is done with the native module fs, which gives you functions to watch, read, and write files along with many other tools to work with the filesystem. Because it’s a native module, we can require it in our code without installing it. Just call .\n\nThe module gives us the option of synchronous or asynchronous versions of many of its functions. The synchronous versions block execution of other code until they are done accessing the filesystem, reading, or writing data. An async function will run without blocking other code. Learn more about sync/async behavior.\n\nThis synchronous behavior can be useful in some places, like at startup when reading a config file before any other code is run, but becomes a big issue when used in a webserver where all incoming requests would be blocked while a synchronous file read is running. For this reason, you generally want to use the async versions of functions in your code. We will focus on async operations, but will also show the synchronous equivalent.\n\nTo read and write files asynchronously with we will use and .\n\nWe also will use the global JSON helper to convert objects to JSON strings, and JSON strings to objects.\n\nThe simplest way to read a JSON file is to require it. Passing with the path to a JSON file will synchronously read and parse the data into a JavaScript object.\n\nBut reading JSON files with require has its downsides. The file will only be read once; requiring it again returns the cached data from the first time require was run. This is fine for loading static data on startup (like config data). But for reading a file that changes on disk, like our customer.json might, we need to manually read the file using the asynchronous .\n\nTo access the customer’s address, we need to:\n• Read the JSON data from the file\n\nTo load the data from customer.json file, we will use , passing it the path to our file, an optional encoding type, and a callback to receive the file data.\n\nIf the file is successfully read, the contents will be passed to the callback.\n• ./customer.json is the relative path to the the file is an optional parameter for the encoding of the file we are reading, this can be left out. If not specified the function will return a instead of a .\n• is the callback function that runs after the file has been read.\n\nNow we have the contents of the file as a JSON string, but we need to turn the string into an object.\n\nBefore we can use the data from the callback in our code, we must turn it into an object. takes JSON data as input and returns a new JavaScript object. Otherwise, we would just have a string of data with properties we can’t access.\n\ncan throw exception errors and crash our program if passed an invalid JSON string. To prevent crashing we wrap JSON.parse in a try catch statement to gracefully catch any errors.\n\nThis example shows reading and parsing a JSON file:\n\nUsing the from reading customer.json, we create an object, and can access the address property. If throws an error, we handle it in the block.\n\nNow we have an object representation of the data in our customer.json file!\n\nWe can also read the file synchronously using . Instead of taking a callback, returns the file content after reading the file.\n\nWe can use this knowledge to create a reusable helper function to read and parse a JSON file. Here we create a function called that will read and parse a JSON file for us. It takes the path to the file and a callback to receive the parsed object and any errors. It will catch any errors thrown by for us.\n\nBoth and take an optional argument. If you specify a character encoding you'll get a in return. If you do not specify a character encoding both functions will return a .\n\nThis is because Node does not, and cannot, assume what kind of content a file contains. Even if you can. In order to handle this lack of definition, Node will read the file byte for byte and return it as an un-opinionated buffer which you can process as desired.\n\nIf you do know the content of the file, and can provide that detail to Node in the form of an argument it generally makes the code both more performant and easier to understand.\n\nWriting JSON to the filesystem is similar to reading it. We will use to asynchronously write data to a newCustomer.json file.\n\nFirst, to write data to a JSON file, we must create a JSON string of the data with . This returns a JSON string representation of a JavaScript object, which can be written to a file. Similar to parsing data into an object when reading a file, we must turn our data into a string to be able to write it to a file.\n\nCreate a customer object with our data below, and turn it into a string.\n\nNote: If you try to write an object to a file without stringifying it, your file will be empty and look like this:\n\nOnce the data is stringified, we can use to create a new customer file. We pass the filepath, our customer data to write, and a callback that will be excecuted after the file is written. If the newCustomer.json file doesn’t already exist, it will be created; if it does exist, it will be overwritten!\n\nHere is an example of writing a JSON file with\n\nAnd that’s it! Once the callback runs, the file has been written to disk. Note: we are only passed an error object; the filedata we wrote isn’t passed to the callback. We can also write a file synchronously in the same way using :\n\nAfter your file is finished writing, it will look something like this:\n\nStringifying by default puts your data all on a single line. Optionally, you can make the output file human-readable by passing the number of spaces to indent by to :\n\nAbove, we told stringify to indent the data with 2 spaces. Now your output file should look like this:\n\nNow that we are able to read and write our customer files, we can use them as a simple kind of database. If we want to update the data in the JSON file, we can read the contents, change the data, and then write the new data back to the file:\n\nDefinitely not the most efficient database you could choose, but working with JSON files like this is a simple way to persist data in your project.\n\nJSON is one of the most common types of data you’ll work with in Node, and being able to read and write JSON files is very useful. You’ve learned how to use and to asynchronously work with the filesystem, as well as how to parse data to and from JSON format, and catch errors from .\n\nYou can use require to read a JSON file at startup to synchronously parse a JSON file in one line. And now you can use a simple JSON file as a data store.\n\nIf you want to learn more, you can read up on what JSON actually is, and find out more about synchronous vs asynchronous code.\n• Learn about using Node.js Streams to read really large files.\n• Walk through this example with a co-worker. Are all the concepts clear to you? Do you need to review anything?"
    },
    {
        "link": "https://stackoverflow.com/questions/10011011/how-do-i-read-a-json-file-into-server-memory",
        "document": "I am doing some experimentation with Node.js and would like to read a JSON object, either from a text file or a .js file (which is better??) into memory so that I can access that object quickly from code. I realize that there are things like Mongo, Alfred, etc out there, but that is not what I need right now.\n\nHow do I read a JSON object out of a text or js file and into server memory using JavaScript/Node?"
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-work-with-files-using-the-fs-module-in-node-js",
        "document": "The author selected the COVID-19 Relief Fund to receive a donation as part of the Write for DOnations program.\n\nWorking with files is as common for development purposes as it is for non-development purposes. In daily computer use, a user would likely read and write data to files in various directories in order to accomplish tasks like saving a downloaded file or accessing data to be used in another application. In the same way, a back-end program or command line interface (CLI) tool might need to write downloaded data to a file in order to save it, or a data-intensive application may need to export to JSON, CSV, or Excel formats. These programs would need to communicate with the filesystem of the operating system on which they are running.\n\nWith Node.js, you can programmatically manipulate files with the built-in module. The name is short for “file system,” and the module contains all the functions you need to read, write, and delete files on the local machine. This unique aspect of Node.js makes JavaScript a useful language for back-end and CLI tool programming.\n\nIn this article, you will use the module to read a file created via the command line, create and write to a new file, delete the file that you created, and move the first file into a different folder. The module supports interacting with files synchronously, asynchronously, or via streams; this tutorial will focus on how to use the asynchronous, Promise-based API, the most commonly used method for Node.js developers.\n• You must have Node.js installed on your computer to access the module and follow the tutorial. This tutorial uses Node.js version 10.22.0. To install Node.js on macOS or Ubuntu 18.04, follow the steps in How To Install Node.js and Create a Local Development Environment on macOS or the Installing Using a PPA section of How To Install Node.js on Ubuntu 18.04.\n• This article uses JavaScript Promises to work with files, particularly with the syntax. If you’re not familiar with Promises, syntax, or asynchronous programming, check out our guide on How To Write Asynchronous Code in Node.js.\n\nIn this step, you’ll write a program to read files in Node.js. To do this, you’ll need to import the module, a standard Node.js module for working with files, and then use the module’s function. Your program will read the file, store its contents in a variable, then log its contents to the console.\n\nThe first step will be to set up the coding environment for this activity and the ones in the later sections.\n\nCreate a folder to store your code. In your terminal, make a folder called :\n\nChange your working directory to the newly created folder with the command:\n\nIn this folder, you’ll create two files. The first file will be a new file with content that your program will read later. The second file will be the Node.js module that reads the file.\n\nCreate the file with the following command:\n\nThe command prints its string argument to the terminal. You use to redirect ’s output to a new file, .\n\nNow, create and open in your text editor of choice. This tutorial uses , a terminal text editor. You can open this file with like this:\n\nThe code for this file can be broken up into three sections. First, you need to import the Node.js module that allows your program to work with files. In your text editor, type this code:\n\nAs mentioned earlier, you use the module to interact with the filesystem. Notice, though, that you are importing the part of the module.\n\nWhen the module was first created, the primary way to write asynchronous code in Node.js was through callbacks. As promises grew in popularity, the Node.js team worked to support them in the module out of the box. In Node.js version 10, they created a object in the module that uses promises, while the main module continues to expose functions that use callbacks. In this program, you are importing the promise version of the module.\n\nOnce the module is imported, you can create an asynchronous function to read the file. Asynchronous functions begin with the keyword. With an asynchronous function, you can resolve promises using the keyword, instead of chaining the promise with the method.\n\nCreate a new function that accepts one argument, a string called . Your function will use the module to load the file into a variable using syntax.\n\nYou define the function with the keyword so you can later use the accompanying keyword. To capture errors in your asynchronous file reading operation, you enclose the call to with a block. Within the section, you load a file to a variable with the function. The only required argument for that function is the file path, which is given as a string.\n\nThe returns a object by default. A object can store any kind of file type. When you log the contents of the file, you convert those bytes into text by using the method of the buffer object.\n\nIf an error is caught, typically if the file is not found or the program does not have permission to read the file, you log the error you received in the console.\n\nFinally, call the function on the file with the following highlighted line:\n\nBe sure to save your contents. With , you can save and exit by pressing .\n\nYour program will now read the file you created earlier and log its contents to the terminal. Confirm this by executing your module with :\n\nYou will receive the following output:\n\nYou’ve now read a file with the module’s function using the syntax.\n\nNow that you’ve read a file with the module, you will next create a file and write text to it.\n\nIn this step, you will write files with the function of the module. You will create a CSV file in Node.js that keeps track of a grocery bill. The first time you write the file, you will create the file and add the headers. The second time, you will append data to the file.\n\nOpen a new file in your text editor:\n\nBegin your code by importing the module:\n\nYou will continue to use syntax as you create two functions. The first function will be to make the CSV file. The second function will be to add data to the CSV file.\n\nIn your text editor, enter the following highlighted code:\n\nThis asynchronous function first creates a variable that contains the column headings of your CSV file. You then use the function of the module to create a file and write data to it. The first argument is the file path. As you provided just the file name, Node.js will create the file in the same directory that you’re executing the code in. The second argument is the data you are writing, in this case the variable.\n\nNext, create a new function to add items to your grocery list. Add the following highlighted function in your text editor:\n\nThe asynchronous function accepts three arguments: the name of the grocery item, the amount you are buying, and the price per unit. These arguments are used with template literal syntax to form the variable, which is the data you are writing to the file.\n\nYou then use the method as you did in the function. However, this time you have a third argument: a JavaScript object. This object has a key with the value . Flags tell Node.js how to interact with the file on the system. By using the flag , you are telling Node.js to append to the file, not overwrite it. If you don’t specify a flag, it defaults to , which creates a new file if none exists or overwrites a file if it already exists. You can learn more about filesystem flags in the Node.js documentation.\n\nTo complete your script, use these functions. Add the following highlighted lines at the end of the file:\n\nTo call the functions, you first create a wrapper function with . Since the keyword can not be used from the global scope as of the writing of this tutorial, you must wrap the asynchronous functions in an . Notice that this function is anonymous, meaning it has no name to identify it.\n\nYour and functions are asynchronous functions. Without enclosing these calls in another function, you cannot guarantee the order of the content. The wrapper you created is defined with the keyword. Within that function you order the function calls using the keyword.\n\nFinally, the definition is enclosed in parentheses. These tell JavaScript that the code inside them is a function expression. The parentheses at the end of the function and before the semicolon are used to invoke the function immediately. This is called an Immediately-Invoked Function Expression (IIFE). By using an IIFE with an anonymous function, you can test that your code produces a CSV file with three lines: the column headers, a line for , and the last line for .\n\nNow, run your code with the command:\n\nThere will be no output. However, a new file will exist in your current directory.\n\nUse the command to display the contents of :\n\nYou will receive the following output:\n\nYour call to created a new file and added the column headings for your CSV. The subsequent calls to then added your two lines of data.\n\nWith the function, you can create and edit files. Next, you will delete files, a common operation when you have temporary files or need to make space on a hard drive.\n\nIn this step, you will delete files with the function in the module. You will write a Node.js script to delete the file that you created in the last section.\n\nIn your terminal, create a new file for this Node.js module:\n\nNow you will write code that creates an asynchronous function. That function will accept a file path as an argument, passing it to the function to remove it from your filesystem.\n\nIn your text editor, write the following code:\n\nThe function accepts one argument: the file path of the file you want to be deleted.\n\nExit , ensuring that you save the contents of the file by entering .\n\nNow, execute the program. Run the following command in your terminal:\n\nYou will receive the following output:\n\nTo confirm that the file no longer exists, use the command in your current directory:\n\nThis command will display these files:\n\nYou’ve now confirmed that your file was deleted with the function.\n\nSo far you’ve learned how to read, write, edit, and delete files. The following section uses a function to move files to different folders. After learning that function, you will be able to do the most critical file management tasks in Node.js.\n\nFolders are used to organize files, so being able to programmatically move files from one folder to another makes file management easier. You can move files in Node.js with the function. In this step, you’ll move a copy of the file into a new folder.\n\nBefore you can code your Node.js module, you need to set a few things up. Begin by creating a folder that you’ll be moving your file into. In your terminal, create a folder in your current directory:\n\nNow, copy the file that was used in the first step using the command:\n\nFinish the setup by opening a JavaScript file to contain your code:\n\nIn your Node.js module, you’ll create a function called that calls the function. When using the function, you need to provide the file path of the original file and the path of the destination location. For this example, you’ll use a function to move the file into the folder. You’ll also change its name to .\n\nEnter the following code in your open text editor:\n\nAs mentioned earlier, the function takes two arguments: the source and destination file paths. This function can move files to other folders, rename a file in its current directory, or move and rename at the same time. In your code, you are moving and renaming your file.\n\nNext, execute this program with . Enter this command to run the program:\n\nYou will receive this output:\n\nTo confirm that the file no longer exists in your current directory, you can use the command:\n\nThis command will display these files and folder:\n\nYou can now use to list the files in the subfolder:\n\nYour moved file will appear in the output:\n\nYou have now used the function to move a file from your current directory into a subfolder. You also renamed the file with the same function call.\n\nIn this article, you learned various functions to manage files with Node.js. You first loaded the contents of a file with . You then created new files and appended data to an existing file with the function. You permanently removed a file with the function, and then move and renamed a file with .\n\nWorking with files programmatically is an important function of Node.js. Programs might need to output files for a user to use, or may need to store data for an application that is not always running. With the module’s functions, developers have control of how files are used in our Node.js programs.\n\nTo learn more about the module, you can read the Node.js documentation. If you’d like to continue learning Node.js, you can return to the How To Code in Node.js series, or browse programming projects and setups on our Node topic page."
    }
]