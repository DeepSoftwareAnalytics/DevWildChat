[
    {
        "link": "https://pkg.go.dev/net/http",
        "document": "Get, Head, Post, and PostForm make HTTP (or HTTPS) requests: The caller must close the response body when finished with it: For control over HTTP client headers, redirect policy, and other settings, create a Client: For control over proxies, TLS configuration, keep-alives, compression, and other settings, create a Transport: Clients and Transports are safe for concurrent use by multiple goroutines and for efficiency should only be created once and re-used. ListenAndServe starts an HTTP server with a given address and handler. The handler is usually nil, which means to use DefaultServeMux. Handle and HandleFunc add handlers to DefaultServeMux: More control over the server's behavior is available by creating a custom Server: Starting with Go 1.6, the http package has transparent support for the HTTP/2 protocol when using HTTPS. Programs that must disable HTTP/2 can do so by setting [Transport.TLSNextProto] (for clients) or [Server.TLSNextProto] (for servers) to a non-nil, empty map. Alternatively, the following GODEBUG settings are currently supported: GODEBUG=http2client=0 # disable HTTP/2 client support GODEBUG=http2server=0 # disable HTTP/2 server support GODEBUG=http2debug=1 # enable verbose HTTP/2 debug logs GODEBUG=http2debug=2 # ... even more verbose, with frame dumps Please report any issues before disabling HTTP/2 support: https://golang.org/s/http2bug The http package's Transport and Server both automatically enable HTTP/2 support for simple configurations. To enable HTTP/2 for more complex configurations, to use lower-level HTTP/2 features, or to use a newer version of Go's http2 package, import \"golang.org/x/net/http2\" directly and use its ConfigureTransport and/or ConfigureServer functions. Manually configuring HTTP/2 via the golang.org/x/net/http2 package takes precedence over the net/http package's built-in HTTP/2 support.\n\nCanonicalHeaderKey returns the canonical format of the header key s. The canonicalization converts the first letter and any letter following a hyphen to upper case; the rest are converted to lowercase. For example, the canonical key for \"accept-encoding\" is \"Accept-Encoding\". If s contains a space or invalid header field bytes, it is returned without modifications. DetectContentType implements the algorithm described at https://mimesniff.spec.whatwg.org/ to determine the Content-Type of the given data. It considers at most the first 512 bytes of data. DetectContentType always returns a valid MIME type: if it cannot determine a more specific one, it returns \"application/octet-stream\". Error replies to the request with the specified error message and HTTP code. It does not otherwise end the request; the caller should ensure no further writes are done to w. The error message should be plain text. Error deletes the Content-Length header, sets Content-Type to “text/plain; charset=utf-8”, and sets X-Content-Type-Options to “nosniff”. This configures the header properly for the error message, in case the caller had set it up expecting a successful output. Handle registers the handler for the given pattern in DefaultServeMux. The documentation for ServeMux explains how patterns are matched. HandleFunc registers the handler function for the given pattern in DefaultServeMux. The documentation for ServeMux explains how patterns are matched. package main import ( \"io\" \"log\" \"net/http\" ) func main() { h1 := func(w http.ResponseWriter, _ *http.Request) { io.WriteString(w, \"Hello from a HandleFunc #1!\n\n\") } h2 := func(w http.ResponseWriter, _ *http.Request) { io.WriteString(w, \"Hello from a HandleFunc #2!\n\n\") } http.HandleFunc(\"/\", h1) http.HandleFunc(\"/endpoint\", h2) log.Fatal(http.ListenAndServe(\":8080\", nil)) } ListenAndServe listens on the TCP network address addr and then calls Serve with handler to handle requests on incoming connections. Accepted connections are configured to enable TCP keep-alives. The handler is typically nil, in which case DefaultServeMux is used. package main import ( \"io\" \"log\" \"net/http\" ) func main() { // Hello world, the web server helloHandler := func(w http.ResponseWriter, req *http.Request) { io.WriteString(w, \"Hello, world!\n\n\") } http.HandleFunc(\"/hello\", helloHandler) log.Fatal(http.ListenAndServe(\":8080\", nil)) } ListenAndServeTLS acts identically to ListenAndServe, except that it expects HTTPS connections. Additionally, files containing a certificate and matching private key for the server must be provided. If the certificate is signed by a certificate authority, the certFile should be the concatenation of the server's certificate, any intermediates, and the CA's certificate. package main import ( \"io\" \"log\" \"net/http\" ) func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, req *http.Request) { io.WriteString(w, \"Hello, TLS!\n\n\") }) // One can use generate_cert.go in crypto/tls to generate cert.pem and key.pem. log.Printf(\"About to listen on 8443. Go to https://127.0.0.1:8443/\") err := http.ListenAndServeTLS(\":8443\", \"cert.pem\", \"key.pem\", nil) log.Fatal(err) } MaxBytesReader is similar to io.LimitReader but is intended for limiting the size of incoming request bodies. In contrast to io.LimitReader, MaxBytesReader's result is a ReadCloser, returns a non-nil error of type *MaxBytesError for a Read beyond the limit, and closes the underlying reader when its Close method is called. MaxBytesReader prevents clients from accidentally or maliciously sending a large request and wasting server resources. If possible, it tells the ResponseWriter to close the connection after the limit has been reached. NotFound replies to the request with an HTTP 404 not found error. ParseHTTPVersion parses an HTTP version string according to RFC 7230, section 2.6. \"HTTP/1.0\" returns (1, 0, true). Note that strings without a minor version, such as \"HTTP/2\", are not valid. ParseTime parses a time header (such as the Date: header), trying each of the three formats allowed by HTTP/1.1: TimeFormat, time.RFC850, and time.ANSIC. ProxyFromEnvironment returns the URL of the proxy to use for a given request, as indicated by the environment variables HTTP_PROXY, HTTPS_PROXY and NO_PROXY (or the lowercase versions thereof). Requests use the proxy from the environment variable matching their scheme, unless excluded by NO_PROXY. The environment values may be either a complete URL or a \"host[:port]\", in which case the \"http\" scheme is assumed. An error is returned if the value is a different form. A nil URL and nil error are returned if no proxy is defined in the environment, or a proxy should not be used for the given request, as defined by NO_PROXY. As a special case, if req.URL.Host is \"localhost\" (with or without a port number), then a nil URL and nil error will be returned. ProxyURL returns a proxy function (for use in a Transport) that always returns the same URL. Redirect replies to the request with a redirect to url, which may be a path relative to the request path. The provided code should be in the 3xx range and is usually StatusMovedPermanently, StatusFound or StatusSeeOther. If the Content-Type header has not been set, Redirect sets it to \"text/html; charset=utf-8\" and writes a small HTML body. Setting the Content-Type header to any value, including nil, disables that behavior. Serve accepts incoming HTTP connections on the listener l, creating a new service goroutine for each. The service goroutines read requests and then call handler to reply to them. The handler is typically nil, in which case DefaultServeMux is used. HTTP/2 support is only enabled if the Listener returns *tls.Conn connections and they were configured with \"h2\" in the TLS Config.NextProtos. ServeContent replies to the request using the content in the provided ReadSeeker. The main benefit of ServeContent over io.Copy is that it handles Range requests properly, sets the MIME type, and handles If-Match, If-Unmodified-Since, If-None-Match, If-Modified-Since, and If-Range requests. If the response's Content-Type header is not set, ServeContent first tries to deduce the type from name's file extension and, if that fails, falls back to reading the first block of the content and passing it to DetectContentType. The name is otherwise unused; in particular it can be empty and is never sent in the response. If modtime is not the zero time or Unix epoch, ServeContent includes it in a Last-Modified header in the response. If the request includes an If-Modified-Since header, ServeContent uses modtime to decide whether the content needs to be sent at all. The content's Seek method must work: ServeContent uses a seek to the end of the content to determine its size. Note that *os.File implements the io.ReadSeeker interface. If the caller has set w's ETag header formatted per RFC 7232, section 2.3, ServeContent uses it to handle requests using If-Match, If-None-Match, or If-Range. If an error occurs when serving the request (for example, when handling an invalid range request), ServeContent responds with an error message. By default, ServeContent strips the Cache-Control, Content-Encoding, ETag, and Last-Modified headers from error responses. The GODEBUG setting httpservecontentkeepheaders=1 causes ServeContent to preserve these headers. ServeFile replies to the request with the contents of the named file or directory. If the provided file or directory name is a relative path, it is interpreted relative to the current directory and may ascend to parent directories. If the provided name is constructed from user input, it should be sanitized before calling ServeFile. As a precaution, ServeFile will reject requests where r.URL.Path contains a \"..\" path element; this protects against callers who might unsafely use filepath.Join on r.URL.Path without sanitizing it and then use that filepath.Join result as the name argument. As another special case, ServeFile redirects any request where r.URL.Path ends in \"/index.html\" to the same path, without the final \"index.html\". To avoid such redirects either modify the path or use ServeContent. Outside of those two special cases, ServeFile does not use r.URL.Path for selecting the file or directory to serve; only the file or directory provided in the name argument is used. ServeFileFS replies to the request with the contents of the named file or directory from the file system fsys. The files provided by fsys must implement io.Seeker. If the provided name is constructed from user input, it should be sanitized before calling ServeFileFS. As a precaution, ServeFileFS will reject requests where r.URL.Path contains a \"..\" path element; this protects against callers who might unsafely use filepath.Join on r.URL.Path without sanitizing it and then use that filepath.Join result as the name argument. As another special case, ServeFileFS redirects any request where r.URL.Path ends in \"/index.html\" to the same path, without the final \"index.html\". To avoid such redirects either modify the path or use ServeContent. Outside of those two special cases, ServeFileFS does not use r.URL.Path for selecting the file or directory to serve; only the file or directory provided in the name argument is used. ServeTLS accepts incoming HTTPS connections on the listener l, creating a new service goroutine for each. The service goroutines read requests and then call handler to reply to them. The handler is typically nil, in which case DefaultServeMux is used. Additionally, files containing a certificate and matching private key for the server must be provided. If the certificate is signed by a certificate authority, the certFile should be the concatenation of the server's certificate, any intermediates, and the CA's certificate. SetCookie adds a Set-Cookie header to the provided ResponseWriter's headers. The provided cookie must have a valid Name. Invalid cookies may be silently dropped. StatusText returns a text for the HTTP status code. It returns the empty string if the code is unknown."
    },
    {
        "link": "https://medium.com/@emonemrulhasan35/net-http-package-in-go-e178c67d87f1",
        "document": "In Go when we start to know about http things and stuff, we will get to know a package which is net/http. Then some questions arise in our mind. Like why do we need this? When will this package be beneficial for us? What are the functionalities of this package? Today I will discuss it in a short manner so that it seems to be understood easily.\n\nWhy do we need this?\n\nHTTP is the foundation of the World Wide Web, serving as the primary means of communication between clients (for example: web browsers) and servers. By using the net/http package, we can create HTTP servers, handle incoming requests, and send requests to other servers and also we can manage responses with respect to a request. It makes it easy for us to work with HTTP and makes it easy to create web applications and services.\n\nWhat can be achieved by net/http package?\n\nThis package provides many functionality to work with HTTP. Such as\n\nWith this package, we can create web servers that listen for incoming HTTP requests. We can define functions. They are called handlers, to handle those requests and generate appropriate responses. For different requests we need to define different handlers which will manage the request and will also give the response. We can specify routes to direct requests to specific handlers based on the requested URL. This allows us to build the core infrastructure for web applications.\n\nThe package enables us to access and process information from incoming HTTP requests, such as headers and the data sent in the request body. Similarly, we can construct and send HTTP requests to other servers, including setting headers, providing data in the request body, and processing the responses received. It means using this package we can do custom requests to other servers.\n\nMiddleware allows us to add additional functionality to our HTTP server’s request processing pipeline. For example, We can use logging middleware by which we can log requests and responses. We can use authorization middleware to ensure only authenticated users can access certain routes, or rate-limiting middleware to control the number of requests from a specific client.\n\nWe can use the “net/http” package to serve static files, such as HTML, CSS, JavaScript, and images, directly from our HTTP server. This is important for web applications that require delivering static assets to clients.\n\nWhen will this package be beneficial for us?\n\nThere will be some scenarios when this package can be beneficial for us. Such as\n\nIf we are building a web application or service in Go, the “net/http” package provides the necessary tools to create an HTTP server that can handle incoming requests and generate appropriate responses. We can define routes, process data, and serve dynamic content to clients.\n\nIf our application needs to interact with external HTTP APIs, the “net/http” package allows us to send HTTP requests to those APIs, process the responses, and work with the received data. We can retrieve data from external services and integrate it into our application.\n\nWhen building microservices in Go, the “net/http” package helps us create lightweight HTTP servers. These servers can communicate with each other over HTTP, forming a scalable and resilient microservices architecture. Each microservice can expose its functionality through HTTP endpoints, allowing them to work together seamlessly.\n\nSo, for summary we can say net/http packages provided below key features.\n\nWe can create an HTTP Server that will listen to incoming requests and how to handle those requests and what to do with those requests. The package provides two powerful functions for handling requests and responses. They are http.HandleFunc and HTTP.Handler. These are used to register different routes of the server.\n\nWe can create an HTTP client to send HTTP requests to remote servers and receive responses. The package provides the http.Client type for creating and configuring an HTTP client.\n\nThe package provides various structures and functions to handle HTTP requests. We can access information such as the request method, URL, headers, and request body. You can also write response data, set response headers, and handle different HTTP status codes.\n\nThe package allows us to define routes and route handlers for different URL patterns. We can use the http.HandleFunc function to register a handler function for a specific URL pattern. It means for a specific route we will make a specific http.Handlerfunc which will be registered in a handler. In the http.Handlerfunc we will define what to do with the request and what will be the response. For different routes we need to define different http.HandlerFunc and each of the http.Handlerfunc will be registered into different handler. Whenever a request is made, the route will hit the corresponding handler for which handler the route was defined. Alternatively, we can use the http.ServeMux type to create a custom router with more advanced routing capabilities.\n\nWe can use middleware to modify the behaviour of an HTTP server or client. Middleware functions can intercept requests and responses, perform additional processing, and pass the request to the next middleware or handler. The package provides the http.Handler interface that allows you to chain multiple middleware functions together.\n\nLet’s understand it easily, assume we have multiple handlers for multiple routes. We want whenever a request will be made from the client side, we need to give some data as response for that request. And data is stored in a remote server. We defined http.Handlerfunc for each of the handlers. Handlers perform request handling and managing response through handler function. We want the handler to take the request and after that the handler can modify the request or can’t. Then we will give the request to something(assume as middleware) and that will take the data from the remote server and give the data to the handler and the handler will send the response to the client. Don’t be confused between handler and handler function. Handler function is the definition for handling request and managing response and get registered in a handler. This example is simply given to take the idea but not exactly.\n\nThe package provides functions and types to work with HTTP cookies. We can set cookies in the response headers, read cookies from the request, and manipulate cookie values.\n\nExplanation: In this example, we create a simple HTTP server that listens on port 8086. The server responds with the “Hello, Emon!” message for any incoming request to the root (“/”) URL. The http.HandleFunc function is used to register a handler function for the root URL.\n\nExplanation: In this example, we extend the previous HTTP server example to handle multiple routes. The server responds with different messages based on the URL path. For the root (“/”) URL, it responds with “Hello, Emon!”, and for the “/users” URL, it responds with “Welcome to Emon’s blog!”.\n\nExplanation: In this example, we create an HTTP client using the http.Client type. The client makes a GET request to the “https://api.example.com/data\" URL and receives a response. The response body is read and printed to the console.\n\nExplanation: The provided code defines an HTTP handler function for the ‘/users’ route using the ‘http’ package. This function responds to incoming HTTP requests on that route, processing them according to the specific request method (e.g., GET or POST).\n\nThe handler function is designed to accept two arguments: ResponseWriter and Request. ResponseWriter is an interface that aids in sending data back to the client as a response, while Request is a structured data containing details about the incoming request, such as its HTTP method, URL, and headers.\n\nWithin the handler function, a switch statement is used to identify the request method and execute different code blocks based on the method type. If the method is GET, the function will handle the GET request accordingly. Alternatively, if the method is POST, it will handle the POST request accordingly.\n\nIn case the method is anything other than GET or POST, the handler will respond by sending an ‘Invalid request method’ message back to the client using the http.Error function, along with a StatusMethodNotAllowed HTTP status code."
    },
    {
        "link": "https://go.dev/src/net/http/server.go",
        "document": ""
    },
    {
        "link": "https://golang.google.cn/pkg/net/http",
        "document": "Unless otherwise noted, these are defined in RFC 7231 section 4.3.\n\nHTTP status codes as registered with IANA. See: https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml\n\nDefaultMaxHeaderBytes is the maximum permitted size of the headers in an HTTP request. This can be overridden by setting [Server.MaxHeaderBytes].\n\nDefaultMaxIdleConnsPerHost is the default value of Transport's MaxIdleConnsPerHost.\n\nTimeFormat is the time format to use when generating times in HTTP headers. It is like time.RFC1123 but hard-codes GMT as the time zone. The time being formatted must be in UTC for Format to generate the correct format.\n\nFor parsing this time format, see ParseTime.\n\nTrailerPrefix is a magic prefix for [ResponseWriter.Header] map keys that, if present, signals that the map entry is actually for the response trailers, and not the response headers. The prefix is stripped after the ServeHTTP call finishes and the values are sent in the trailers.\n\nThis mechanism is intended only for trailers that are not known prior to the headers being written. If the set of trailers is fixed or known before the header is written, the normal Go trailers mechanism is preferred:\n\nErrors used by the HTTP server.\n\nDefaultClient is the default Client and is used by Get, Head, and Post.\n\nDefaultServeMux is the default ServeMux used by Serve.\n\nErrAbortHandler is a sentinel panic value to abort a handler. While any panic from ServeHTTP aborts the response to the client, panicking with ErrAbortHandler also suppresses logging of a stack trace to the server's error log.\n\nErrBodyReadAfterClose is returned when reading a Request or Response Body after the body has been closed. This typically happens when the body is read after an HTTP Handler calls WriteHeader or Write on its ResponseWriter.\n\nErrHandlerTimeout is returned on ResponseWriter Write calls in handlers which have timed out.\n\nErrLineTooLong is returned when reading request or response bodies with malformed chunked encoding.\n\nErrMissingFile is returned by FormFile when the provided file field name is either not present in the request or not a file field.\n\nErrNoCookie is returned by Request's Cookie method when a cookie is not found.\n\nErrNoLocation is returned by the Response.Location method when no Location header is present.\n\nErrSchemeMismatch is returned when a server returns an HTTP response to an HTTPS client.\n\nErrServerClosed is returned by the Server.Serve, ServeTLS, ListenAndServe, and ListenAndServeTLS methods after a call to Server.Shutdown or Server.Close.\n\nErrSkipAltProtocol is a sentinel error value defined by Transport.RegisterProtocol.\n\nErrUseLastResponse can be returned by Client.CheckRedirect hooks to control how redirects are processed. If returned, the next request is not sent and the most recent response is returned with its body unclosed.\n\nNoBody is an io.ReadCloser with no bytes. Read always returns EOF and Close always returns nil. It can be used in an outgoing client request to explicitly signal that a request has zero bytes. An alternative, however, is to simply set [Request.Body] to nil.\n\nCanonicalHeaderKey returns the canonical format of the header key s. The canonicalization converts the first letter and any letter following a hyphen to upper case; the rest are converted to lowercase. For example, the canonical key for \"accept-encoding\" is \"Accept-Encoding\". If s contains a space or invalid header field bytes, it is returned without modifications.\n\nDetectContentType implements the algorithm described at https://mimesniff.spec.whatwg.org/ to determine the Content-Type of the given data. It considers at most the first 512 bytes of data. DetectContentType always returns a valid MIME type: if it cannot determine a more specific one, it returns \"application/octet-stream\".\n\nError replies to the request with the specified error message and HTTP code. It does not otherwise end the request; the caller should ensure no further writes are done to w. The error message should be plain text.\n\nError deletes the Content-Length header, sets Content-Type to “text/plain; charset=utf-8”, and sets X-Content-Type-Options to “nosniff”. This configures the header properly for the error message, in case the caller had set it up expecting a successful output.\n\nHandle registers the handler for the given pattern in DefaultServeMux. The documentation for ServeMux explains how patterns are matched.\n\nHandleFunc registers the handler function for the given pattern in DefaultServeMux. The documentation for ServeMux explains how patterns are matched.\n\nListenAndServe listens on the TCP network address addr and then calls Serve with handler to handle requests on incoming connections. Accepted connections are configured to enable TCP keep-alives.\n\nThe handler is typically nil, in which case DefaultServeMux is used.\n\nListenAndServeTLS acts identically to ListenAndServe, except that it expects HTTPS connections. Additionally, files containing a certificate and matching private key for the server must be provided. If the certificate is signed by a certificate authority, the certFile should be the concatenation of the server's certificate, any intermediates, and the CA's certificate.\n\nMaxBytesReader is similar to io.LimitReader but is intended for limiting the size of incoming request bodies. In contrast to io.LimitReader, MaxBytesReader's result is a ReadCloser, returns a non-nil error of type *MaxBytesError for a Read beyond the limit, and closes the underlying reader when its Close method is called.\n\nMaxBytesReader prevents clients from accidentally or maliciously sending a large request and wasting server resources. If possible, it tells the ResponseWriter to close the connection after the limit has been reached.\n\nNotFound replies to the request with an HTTP 404 not found error.\n\nParseHTTPVersion parses an HTTP version string according to RFC 7230, section 2.6. \"HTTP/1.0\" returns (1, 0, true). Note that strings without a minor version, such as \"HTTP/2\", are not valid.\n\nParseTime parses a time header (such as the Date: header), trying each of the three formats allowed by HTTP/1.1: TimeFormat, time.RFC850, and time.ANSIC.\n\nProxyFromEnvironment returns the URL of the proxy to use for a given request, as indicated by the environment variables HTTP_PROXY, HTTPS_PROXY and NO_PROXY (or the lowercase versions thereof). Requests use the proxy from the environment variable matching their scheme, unless excluded by NO_PROXY.\n\nThe environment values may be either a complete URL or a \"host[:port]\", in which case the \"http\" scheme is assumed. An error is returned if the value is a different form.\n\nA nil URL and nil error are returned if no proxy is defined in the environment, or a proxy should not be used for the given request, as defined by NO_PROXY.\n\nAs a special case, if req.URL.Host is \"localhost\" (with or without a port number), then a nil URL and nil error will be returned.\n\nProxyURL returns a proxy function (for use in a Transport) that always returns the same URL.\n\nRedirect replies to the request with a redirect to url, which may be a path relative to the request path.\n\nThe provided code should be in the 3xx range and is usually StatusMovedPermanently, StatusFound or StatusSeeOther.\n\nIf the Content-Type header has not been set, Redirect sets it to \"text/html; charset=utf-8\" and writes a small HTML body. Setting the Content-Type header to any value, including nil, disables that behavior.\n\nServe accepts incoming HTTP connections on the listener l, creating a new service goroutine for each. The service goroutines read requests and then call handler to reply to them.\n\nThe handler is typically nil, in which case DefaultServeMux is used.\n\nHTTP/2 support is only enabled if the Listener returns *tls.Conn connections and they were configured with \"h2\" in the TLS Config.NextProtos.\n\nServeContent replies to the request using the content in the provided ReadSeeker. The main benefit of ServeContent over io.Copy is that it handles Range requests properly, sets the MIME type, and handles If-Match, If-Unmodified-Since, If-None-Match, If-Modified-Since, and If-Range requests.\n\nIf the response's Content-Type header is not set, ServeContent first tries to deduce the type from name's file extension and, if that fails, falls back to reading the first block of the content and passing it to DetectContentType. The name is otherwise unused; in particular it can be empty and is never sent in the response.\n\nIf modtime is not the zero time or Unix epoch, ServeContent includes it in a Last-Modified header in the response. If the request includes an If-Modified-Since header, ServeContent uses modtime to decide whether the content needs to be sent at all.\n\nThe content's Seek method must work: ServeContent uses a seek to the end of the content to determine its size. Note that *os.File implements the io.ReadSeeker interface.\n\nIf the caller has set w's ETag header formatted per RFC 7232, section 2.3, ServeContent uses it to handle requests using If-Match, If-None-Match, or If-Range.\n\nIf an error occurs when serving the request (for example, when handling an invalid range request), ServeContent responds with an error message. By default, ServeContent strips the Cache-Control, Content-Encoding, ETag, and Last-Modified headers from error responses. The GODEBUG setting httpservecontentkeepheaders=1 causes ServeContent to preserve these headers.\n\nServeFile replies to the request with the contents of the named file or directory.\n\nIf the provided file or directory name is a relative path, it is interpreted relative to the current directory and may ascend to parent directories. If the provided name is constructed from user input, it should be sanitized before calling ServeFile.\n\nAs a precaution, ServeFile will reject requests where r.URL.Path contains a \"..\" path element; this protects against callers who might unsafely use filepath.Join on r.URL.Path without sanitizing it and then use that filepath.Join result as the name argument.\n\nAs another special case, ServeFile redirects any request where r.URL.Path ends in \"/index.html\" to the same path, without the final \"index.html\". To avoid such redirects either modify the path or use ServeContent.\n\nOutside of those two special cases, ServeFile does not use r.URL.Path for selecting the file or directory to serve; only the file or directory provided in the name argument is used.\n\nServeFileFS replies to the request with the contents of the named file or directory from the file system fsys. The files provided by fsys must implement io.Seeker.\n\nIf the provided name is constructed from user input, it should be sanitized before calling ServeFileFS.\n\nAs a precaution, ServeFileFS will reject requests where r.URL.Path contains a \"..\" path element; this protects against callers who might unsafely use filepath.Join on r.URL.Path without sanitizing it and then use that filepath.Join result as the name argument.\n\nAs another special case, ServeFileFS redirects any request where r.URL.Path ends in \"/index.html\" to the same path, without the final \"index.html\". To avoid such redirects either modify the path or use ServeContent.\n\nOutside of those two special cases, ServeFileFS does not use r.URL.Path for selecting the file or directory to serve; only the file or directory provided in the name argument is used.\n\nServeTLS accepts incoming HTTPS connections on the listener l, creating a new service goroutine for each. The service goroutines read requests and then call handler to reply to them.\n\nThe handler is typically nil, in which case DefaultServeMux is used.\n\nAdditionally, files containing a certificate and matching private key for the server must be provided. If the certificate is signed by a certificate authority, the certFile should be the concatenation of the server's certificate, any intermediates, and the CA's certificate.\n\nSetCookie adds a Set-Cookie header to the provided ResponseWriter's headers. The provided cookie must have a valid Name. Invalid cookies may be silently dropped.\n\nStatusText returns a text for the HTTP status code. It returns the empty string if the code is unknown.\n\nA Client is an HTTP client. Its zero value (DefaultClient) is a usable client that uses DefaultTransport.\n\nThe [Client.Transport] typically has internal state (cached TCP connections), so Clients should be reused instead of created as needed. Clients are safe for concurrent use by multiple goroutines.\n\nA Client is higher-level than a RoundTripper (such as Transport) and additionally handles HTTP details such as cookies and redirects.\n\nWhen following redirects, the Client will forward all headers set on the initial Request except:\n• when forwarding sensitive headers like \"Authorization\", \"WWW-Authenticate\", and \"Cookie\" to untrusted targets. These headers will be ignored when following a redirect to a domain that is not a subdomain match or exact match of the initial domain. For example, a redirect from \"foo.com\" to either \"foo.com\" or \"sub.foo.com\" will forward the sensitive headers, but a redirect to \"bar.com\" will not.\n• when forwarding the \"Cookie\" header with a non-nil cookie Jar. Since each redirect may mutate the state of the cookie jar, a redirect may possibly alter a cookie set in the initial request. When forwarding the \"Cookie\" header, any mutated cookies will be omitted, with the expectation that the Jar will insert those mutated cookies with the updated values (assuming the origin matches). If Jar is nil, the initial cookies are forwarded without change.\n\nCloseIdleConnections closes any connections on its Transport which were previously connected from previous requests but are now sitting idle in a \"keep-alive\" state. It does not interrupt any connections currently in use.\n\nIf [Client.Transport] does not have a Client.CloseIdleConnections method then this method does nothing.\n\nDo sends an HTTP request and returns an HTTP response, following policy (such as redirects, cookies, auth) as configured on the client.\n\nAn error is returned if caused by client policy (such as CheckRedirect), or failure to speak HTTP (such as a network connectivity problem). A non-2xx status code doesn't cause an error.\n\nIf the returned error is nil, the Response will contain a non-nil Body which the user is expected to close. If the Body is not both read to EOF and closed, the Client's underlying RoundTripper (typically Transport) may not be able to re-use a persistent TCP connection to the server for a subsequent \"keep-alive\" request.\n\nThe request Body, if non-nil, will be closed by the underlying Transport, even on errors. The Body may be closed asynchronously after Do returns.\n\nOn error, any Response can be ignored. A non-nil Response with a non-nil error only occurs when CheckRedirect fails, and even then the returned [Response.Body] is already closed.\n\nGenerally Get, Post, or PostForm will be used instead of Do.\n\nIf the server replies with a redirect, the Client first uses the CheckRedirect function to determine whether the redirect should be followed. If permitted, a 301, 302, or 303 redirect causes subsequent requests to use HTTP method GET (or HEAD if the original request was HEAD), with no body. A 307 or 308 redirect preserves the original HTTP method and body, provided that the [Request.GetBody] function is defined. The NewRequest function automatically sets GetBody for common standard library body types.\n\nAny returned error will be of type *url.Error. The url.Error value's Timeout method will report true if the request timed out.\n\nGet issues a GET to the specified URL. If the response is one of the following redirect codes, Get follows the redirect after calling the [Client.CheckRedirect] function:\n\nAn error is returned if the [Client.CheckRedirect] function fails or if there was an HTTP protocol error. A non-2xx response doesn't cause an error. Any returned error will be of type *url.Error. The url.Error value's Timeout method will report true if the request timed out.\n\nWhen err is nil, resp always contains a non-nil resp.Body. Caller should close resp.Body when done reading from it.\n\nTo make a request with custom headers, use NewRequest and Client.Do.\n\nTo make a request with a specified context.Context, use NewRequestWithContext and Client.Do.\n\nHead issues a HEAD to the specified URL. If the response is one of the following redirect codes, Head follows the redirect after calling the [Client.CheckRedirect] function:\n\nTo make a request with a specified context.Context, use NewRequestWithContext and Client.Do.\n\nPost issues a POST to the specified URL.\n\nCaller should close resp.Body when done reading from it.\n\nIf the provided body is an io.Closer, it is closed after the request.\n\nTo set custom headers, use NewRequest and Client.Do.\n\nTo make a request with a specified context.Context, use NewRequestWithContext and Client.Do.\n\nSee the Client.Do method documentation for details on how redirects are handled.\n\nPostForm issues a POST to the specified URL, with data's keys and values URL-encoded as the request body.\n\nThe Content-Type header is set to application/x-www-form-urlencoded. To set other headers, use NewRequest and Client.Do.\n\nWhen err is nil, resp always contains a non-nil resp.Body. Caller should close resp.Body when done reading from it.\n\nSee the Client.Do method documentation for details on how redirects are handled.\n\nTo make a request with a specified context.Context, use NewRequestWithContext and Client.Do.\n\nThe CloseNotifier interface is implemented by ResponseWriters which allow detecting when the underlying connection has gone away.\n\nThis mechanism can be used to cancel long operations on the server if the client has disconnected before the response is ready.\n\nDeprecated: the CloseNotifier interface predates Go's context package. New code should use Request.Context instead.\n\nA ConnState represents the state of a client connection to a server. It's used by the optional [Server.ConnState] hook.\n\nA Cookie represents an HTTP cookie as sent in the Set-Cookie header of an HTTP response or the Cookie header of an HTTP request.\n\nParseCookie parses a Cookie header value and returns all the cookies which were set in it. Since the same cookie name can appear multiple times the returned Values can contain more than one value for a given key.\n\nParseSetCookie parses a Set-Cookie header value and returns a cookie. It returns an error on syntax error.\n\nString returns the serialization of the cookie for use in a Cookie header (if only Name and Value are set) or a Set-Cookie response header (if other fields are set). If c is nil or c.Name is invalid, the empty string is returned.\n\nValid reports whether the cookie is valid.\n\nA CookieJar manages storage and use of cookies in HTTP requests.\n\nImplementations of CookieJar must be safe for concurrent use by multiple goroutines.\n\nA Dir implements FileSystem using the native file system restricted to a specific directory tree.\n\nWhile the [FileSystem.Open] method takes '/'-separated paths, a Dir's string value is a directory path on the native file system, not a URL, so it is separated by filepath.Separator, which isn't necessarily '/'.\n\nNote that Dir could expose sensitive files and directories. Dir will follow symlinks pointing out of the directory tree, which can be especially dangerous if serving from a directory in which users are able to create arbitrary symlinks. Dir will also allow access to files and directories starting with a period, which could expose sensitive directories like .git or sensitive files like .htpasswd. To exclude files with a leading period, remove the files/directories from the server or create a custom FileSystem implementation.\n\nAn empty Dir is treated as \".\".\n\nOpen implements FileSystem using os.Open, opening files for reading rooted and relative to the directory d.\n\nA File is returned by a FileSystem's Open method and can be served by the FileServer implementation.\n\nThe methods should behave the same as those on an *os.File.\n\nA FileSystem implements access to a collection of named files. The elements in a file path are separated by slash ('/', U+002F) characters, regardless of host operating system convention. See the FileServer function to convert a FileSystem to a Handler.\n\nThis interface predates the fs.FS interface, which can be used instead: the FS adapter function converts an fs.FS to a FileSystem.\n\nFS converts fsys to a FileSystem implementation, for use with FileServer and NewFileTransport. The files provided by fsys must implement io.Seeker.\n\nThe Flusher interface is implemented by ResponseWriters that allow an HTTP handler to flush buffered data to the client.\n\nThe default HTTP/1.x and HTTP/2 ResponseWriter implementations support Flusher, but ResponseWriter wrappers may not. Handlers should always test for this ability at runtime.\n\nNote that even for ResponseWriters that support Flush, if the client is connected through an HTTP proxy, the buffered data may not reach the client until the response completes.\n\nHTTP2Config defines HTTP/2 configuration parameters common to both Transport and Server.\n\n[Handler.ServeHTTP] should write reply headers and data to the ResponseWriter and then return. Returning signals that the request is finished; it is not valid to use the ResponseWriter or read from the [Request.Body] after or concurrently with the completion of the ServeHTTP call.\n\nDepending on the HTTP client software, HTTP protocol version, and any intermediaries between the client and the Go server, it may not be possible to read from the [Request.Body] after writing to the ResponseWriter. Cautious handlers should read the [Request.Body] first, and then reply.\n\nExcept for reading the body, handlers should not modify the provided Request.\n\nIf ServeHTTP panics, the server (the caller of ServeHTTP) assumes that the effect of the panic was isolated to the active request. It recovers the panic, logs a stack trace to the server error log, and either closes the network connection or sends an HTTP/2 RST_STREAM, depending on the HTTP protocol. To abort a handler so the client sees an interrupted response but the server doesn't log an error, panic with the value ErrAbortHandler.\n\nAllowQuerySemicolons returns a handler that serves requests by converting any unescaped semicolons in the URL query to ampersands, and invoking the handler h.\n\nThis restores the pre-Go 1.17 behavior of splitting query parameters on both semicolons and ampersands. (See golang.org/issue/25192). Note that this behavior doesn't match that of many proxies, and the mismatch can lead to security issues.\n\nAllowQuerySemicolons should be invoked before Request.ParseForm is called.\n\nFileServer returns a handler that serves HTTP requests with the contents of the file system rooted at root.\n\nAs a special case, the returned file server redirects any request ending in \"/index.html\" to the same path, without the final \"index.html\".\n\nTo use the operating system's file system implementation, use http.Dir:\n\nTo use an fs.FS implementation, use http.FileServerFS instead.\n\nFileServerFS returns a handler that serves HTTP requests with the contents of the file system fsys. The files provided by fsys must implement io.Seeker.\n\nAs a special case, the returned file server redirects any request ending in \"/index.html\" to the same path, without the final \"index.html\".\n\nMaxBytesHandler returns a Handler that runs h with its ResponseWriter and [Request.Body] wrapped by a MaxBytesReader.\n\nNotFoundHandler returns a simple request handler that replies to each request with a “404 page not found” reply.\n\nRedirectHandler returns a request handler that redirects each request it receives to the given url using the given status code.\n\nThe provided code should be in the 3xx range and is usually StatusMovedPermanently, StatusFound or StatusSeeOther.\n\nStripPrefix returns a handler that serves HTTP requests by removing the given prefix from the request URL's Path (and RawPath if set) and invoking the handler h. StripPrefix handles a request for a path that doesn't begin with prefix by replying with an HTTP 404 not found error. The prefix must match exactly: if the prefix in the request contains escaped characters the reply is also an HTTP 404 not found error.\n\nTimeoutHandler returns a Handler that runs h with the given time limit.\n\nThe new Handler calls h.ServeHTTP to handle each request, but if a call runs for longer than its time limit, the handler responds with a 503 Service Unavailable error and the given message in its body. (If msg is empty, a suitable default message will be sent.) After such a timeout, writes by h to its ResponseWriter will return ErrHandlerTimeout.\n\nTimeoutHandler supports the Pusher interface but does not support the Hijacker or Flusher interfaces.\n\nThe HandlerFunc type is an adapter to allow the use of ordinary functions as HTTP handlers. If f is a function with the appropriate signature, HandlerFunc(f) is a Handler that calls f.\n\nA Header represents the key-value pairs in an HTTP header.\n\nThe keys should be in canonical form, as returned by CanonicalHeaderKey.\n\nAdd adds the key, value pair to the header. It appends to any existing values associated with key. The key is case insensitive; it is canonicalized by CanonicalHeaderKey.\n\nClone returns a copy of h or nil if h is nil.\n\nDel deletes the values associated with key. The key is case insensitive; it is canonicalized by CanonicalHeaderKey.\n\nGet gets the first value associated with the given key. If there are no values associated with the key, Get returns \"\". It is case insensitive; textproto.CanonicalMIMEHeaderKey is used to canonicalize the provided key. Get assumes that all keys are stored in canonical form. To use non-canonical keys, access the map directly.\n\nSet sets the header entries associated with key to the single element value. It replaces any existing values associated with key. The key is case insensitive; it is canonicalized by textproto.CanonicalMIMEHeaderKey. To use non-canonical keys, assign to the map directly.\n\nValues returns all values associated with the given key. It is case insensitive; textproto.CanonicalMIMEHeaderKey is used to canonicalize the provided key. To use non-canonical keys, access the map directly. The returned slice is not a copy.\n\nWriteSubset writes a header in wire format. If exclude is not nil, keys where exclude[key] == true are not written. Keys are not canonicalized before checking the exclude map.\n\nThe Hijacker interface is implemented by ResponseWriters that allow an HTTP handler to take over the connection.\n\nThe default ResponseWriter for HTTP/1.x connections supports Hijacker, but HTTP/2 connections intentionally do not. ResponseWriter wrappers may also not support Hijacker. Handlers should always test for this ability at runtime.\n\nMaxBytesError is returned by MaxBytesReader when its read limit is exceeded.\n\nDeprecated: Not all errors in the http package related to protocol errors are of type ProtocolError.\n\nProtocols is a set of HTTP protocols. The zero value is an empty set of protocols.\n• None HTTP1 is the HTTP/1.0 and HTTP/1.1 protocols. HTTP1 is supported on both unsecured TCP and secured TLS connections.\n• None HTTP2 is the HTTP/2 protcol over a TLS connection.\n• None UnencryptedHTTP2 is the HTTP/2 protocol over an unsecured TCP connection.\n\nPusher is the interface implemented by ResponseWriters that support HTTP/2 server push. For more background, see https://tools.ietf.org/html/rfc7540#section-8.2.\n\nA Request represents an HTTP request received by a server or to be sent by a client.\n\nThe field semantics differ slightly between client and server usage. In addition to the notes on the fields below, see the documentation for Request.Write and RoundTripper.\n\nNewRequestWithContext returns a new Request given a method, URL, and optional body.\n\nIf the provided body is also an io.Closer, the returned [Request.Body] is set to body and will be closed (possibly asynchronously) by the Client methods Do, Post, and PostForm, and Transport.RoundTrip.\n\nNewRequestWithContext returns a Request suitable for use with Client.Do or Transport.RoundTrip. To create a request for use with testing a Server Handler, either use the net/http/httptest.NewRequest function, use ReadRequest, or manually update the Request fields. For an outgoing client request, the context controls the entire lifetime of a request and its response: obtaining a connection, sending the request, and reading the response headers and body. See the Request type's documentation for the difference between inbound and outbound request fields.\n\nIf body is of type *bytes.Buffer, *bytes.Reader, or *strings.Reader, the returned request's ContentLength is set to its exact value (instead of -1), GetBody is populated (so 307 and 308 redirects can replay the body), and Body is set to NoBody if the ContentLength is 0.\n\nReadRequest reads and parses an incoming request from b.\n\nReadRequest is a low-level function and should only be used for specialized applications; most code should use the Server to read requests and handle them via the Handler interface. ReadRequest only supports HTTP/1.x requests. For HTTP/2, use golang.org/x/net/http2.\n\nAddCookie adds a cookie to the request. Per RFC 6265 section 5.4, AddCookie does not attach more than one Cookie header field. That means all cookies, if any, are written into the same line, separated by semicolon. AddCookie only sanitizes c's name and value, and does not sanitize a Cookie header already present in the request.\n\nBasicAuth returns the username and password provided in the request's Authorization header, if the request uses HTTP Basic Authentication. See RFC 2617, Section 2.\n\nClone returns a deep copy of r with its context changed to ctx. The provided ctx must be non-nil.\n\nClone only makes a shallow copy of the Body field.\n\nFor an outgoing client request, the context controls the entire lifetime of a request and its response: obtaining a connection, sending the request, and reading the response headers and body.\n\nContext returns the request's context. To change the context, use Request.Clone or Request.WithContext.\n\nThe returned context is always non-nil; it defaults to the background context.\n\nFor incoming server requests, the context is canceled when the client's connection closes, the request is canceled (with HTTP/2), or when the ServeHTTP method returns.\n\nCookie returns the named cookie provided in the request or ErrNoCookie if not found. If multiple cookies match the given name, only one cookie will be returned.\n\nCookies parses and returns the HTTP cookies sent with the request.\n\nCookiesNamed parses and returns the named HTTP cookies sent with the request or an empty slice if none matched.\n\nFormFile returns the first file for the provided form key. FormFile calls Request.ParseMultipartForm and Request.ParseForm if necessary.\n\nFormValue returns the first value for the named component of the query. The precedence order:\n\nFormValue calls Request.ParseMultipartForm and Request.ParseForm if necessary and ignores any errors returned by these functions. If key is not present, FormValue returns the empty string. To access multiple values of the same key, call ParseForm and then inspect [Request.Form] directly.\n\nMultipartReader returns a MIME multipart reader if this is a multipart/form-data or a multipart/mixed POST request, else returns nil and an error. Use this function instead of Request.ParseMultipartForm to process the request body as a stream.\n\nFor all requests, ParseForm parses the raw query from the URL and updates r.Form.\n\nFor POST, PUT, and PATCH requests, it also reads the request body, parses it as a form and puts the results into both r.PostForm and r.Form. Request body parameters take precedence over URL query string values in r.Form.\n\nIf the request Body's size has not already been limited by MaxBytesReader, the size is capped at 10MB.\n\nFor other HTTP methods, or when the Content-Type is not application/x-www-form-urlencoded, the request Body is not read, and r.PostForm is initialized to a non-nil, empty value.\n\nParseMultipartForm parses a request body as multipart/form-data. The whole request body is parsed and up to a total of maxMemory bytes of its file parts are stored in memory, with the remainder stored on disk in temporary files. ParseMultipartForm calls Request.ParseForm if necessary. If ParseForm returns an error, ParseMultipartForm returns it but also continues parsing the request body. After one call to ParseMultipartForm, subsequent calls have no effect.\n\nPathValue returns the value for the named path wildcard in the ServeMux pattern that matched the request. It returns the empty string if the request was not matched against a pattern or there is no such wildcard in the pattern.\n\nPostFormValue returns the first value for the named component of the POST, PUT, or PATCH request body. URL query parameters are ignored. PostFormValue calls Request.ParseMultipartForm and Request.ParseForm if necessary and ignores any errors returned by these functions. If key is not present, PostFormValue returns the empty string.\n\nProtoAtLeast reports whether the HTTP protocol used in the request is at least major.minor.\n\nReferer returns the referring URL, if sent in the request.\n\nReferer is misspelled as in the request itself, a mistake from the earliest days of HTTP. This value can also be fetched from the Header map as Header[\"Referer\"]; the benefit of making it available as a method is that the compiler can diagnose programs that use the alternate (correct English) spelling req.Referrer() but cannot diagnose programs that use Header[\"Referrer\"].\n\nSetBasicAuth sets the request's Authorization header to use HTTP Basic Authentication with the provided username and password.\n\nWith HTTP Basic Authentication the provided username and password are not encrypted. It should generally only be used in an HTTPS request.\n\nThe username may not contain a colon. Some protocols may impose additional requirements on pre-escaping the username and password. For instance, when used with OAuth2, both arguments must be URL encoded first with url.QueryEscape.\n\nSetPathValue sets name to value, so that subsequent calls to r.PathValue(name) return value.\n\nUserAgent returns the client's User-Agent, if sent in the request.\n\nWithContext returns a shallow copy of r with its context changed to ctx. The provided ctx must be non-nil.\n\nFor outgoing client request, the context controls the entire lifetime of a request and its response: obtaining a connection, sending the request, and reading the response headers and body.\n\nTo create a new request with a context, use NewRequestWithContext. To make a deep copy of a request with a new context, use Request.Clone.\n\nWrite writes an HTTP/1.1 request, which is the header and body, in wire format. This method consults the following fields of the request:\n\nIf Body is present, Content-Length is <= 0 and [Request.TransferEncoding] hasn't been set to \"identity\", Write adds \"Transfer-Encoding: chunked\" to the header. Body is closed after it is sent.\n\nWriteProxy is like Request.Write but writes the request in the form expected by an HTTP proxy. In particular, Request.WriteProxy writes the initial Request-URI line of the request with an absolute URI, per section 5.3 of RFC 7230, including the scheme and host. In either case, WriteProxy also writes a Host header, using either r.Host or r.URL.Host.\n\nResponse represents the response from an HTTP request.\n\nThe Client and Transport return Responses from servers once the response headers have been received. The response body is streamed on demand as the Body field is read.\n\nGet issues a GET to the specified URL. If the response is one of the following redirect codes, Get follows the redirect, up to a maximum of 10 redirects:\n\nAn error is returned if there were too many redirects or if there was an HTTP protocol error. A non-2xx response doesn't cause an error. Any returned error will be of type *url.Error. The url.Error value's Timeout method will report true if the request timed out.\n\nWhen err is nil, resp always contains a non-nil resp.Body. Caller should close resp.Body when done reading from it.\n\nGet is a wrapper around DefaultClient.Get.\n\nTo make a request with custom headers, use NewRequest and DefaultClient.Do.\n\nTo make a request with a specified context.Context, use NewRequestWithContext and DefaultClient.Do.\n\nHead issues a HEAD to the specified URL. If the response is one of the following redirect codes, Head follows the redirect, up to a maximum of 10 redirects:\n\nTo make a request with a specified context.Context, use NewRequestWithContext and DefaultClient.Do.\n\nPost issues a POST to the specified URL.\n\nCaller should close resp.Body when done reading from it.\n\nIf the provided body is an io.Closer, it is closed after the request.\n\nTo set custom headers, use NewRequest and DefaultClient.Do.\n\nSee the Client.Do method documentation for details on how redirects are handled.\n\nTo make a request with a specified context.Context, use NewRequestWithContext and DefaultClient.Do.\n\nPostForm issues a POST to the specified URL, with data's keys and values URL-encoded as the request body.\n\nThe Content-Type header is set to application/x-www-form-urlencoded. To set other headers, use NewRequest and DefaultClient.Do.\n\nWhen err is nil, resp always contains a non-nil resp.Body. Caller should close resp.Body when done reading from it.\n\nSee the Client.Do method documentation for details on how redirects are handled.\n\nTo make a request with a specified context.Context, use NewRequestWithContext and DefaultClient.Do.\n\nReadResponse reads and returns an HTTP response from r. The req parameter optionally specifies the Request that corresponds to this Response. If nil, a GET request is assumed. Clients must call resp.Body.Close when finished reading resp.Body. After that call, clients can inspect resp.Trailer to find key/value pairs included in the response trailer.\n\nCookies parses and returns the cookies set in the Set-Cookie headers.\n\nLocation returns the URL of the response's \"Location\" header, if present. Relative redirects are resolved relative to [Response.Request]. ErrNoLocation is returned if no Location header is present.\n\nProtoAtLeast reports whether the HTTP protocol used in the response is at least major.minor.\n\nWrite writes r to w in the HTTP/1.x server response format, including the status line, headers, body, and optional trailer.\n\nThis method consults the following fields of the response r:\n\nThe Response Body is closed after it is sent.\n\nA ResponseController is used by an HTTP handler to control the response.\n\nA ResponseController may not be used after the [Handler.ServeHTTP] method has returned.\n\nThe ResponseWriter should be the original value passed to the [Handler.ServeHTTP] method, or have an Unwrap method returning the original ResponseWriter.\n\nIf the ResponseWriter implements any of the following methods, the ResponseController will call them as appropriate:\n\nIf the ResponseWriter does not support a method, ResponseController returns an error matching ErrNotSupported.\n\nEnableFullDuplex indicates that the request handler will interleave reads from [Request.Body] with writes to the ResponseWriter.\n\nFor HTTP/1 requests, the Go HTTP server by default consumes any unread portion of the request body before beginning to write the response, preventing handlers from concurrently reading from the request and writing the response. Calling EnableFullDuplex disables this behavior and permits handlers to continue to read from the request while concurrently writing the response.\n\nFor HTTP/2 requests, the Go HTTP server always permits concurrent reads and responses.\n\nHijack lets the caller take over the connection. See the Hijacker interface for details.\n\nSetReadDeadline sets the deadline for reading the entire request, including the body. Reads from the request body after the deadline has been exceeded will return an error. A zero value means no deadline.\n\nSetting the read deadline after it has been exceeded will not extend it.\n\nSetWriteDeadline sets the deadline for writing the response. Writes to the response body after the deadline has been exceeded will not block, but may succeed if the data has been buffered. A zero value means no deadline.\n\nSetting the write deadline after it has been exceeded will not extend it.\n\nA ResponseWriter interface is used by an HTTP handler to construct an HTTP response.\n\nA ResponseWriter may not be used after [Handler.ServeHTTP] has returned.\n\nRoundTripper is an interface representing the ability to execute a single HTTP transaction, obtaining the Response for a given Request.\n\nA RoundTripper must be safe for concurrent use by multiple goroutines.\n\nDefaultTransport is the default implementation of Transport and is used by DefaultClient. It establishes network connections as needed and caches them for reuse by subsequent calls. It uses HTTP proxies as directed by the environment variables HTTP_PROXY, HTTPS_PROXY and NO_PROXY (or the lowercase versions thereof).\n\nNewFileTransport returns a new RoundTripper, serving the provided FileSystem. The returned RoundTripper ignores the URL host in its incoming requests, as well as most other properties of the request.\n\nThe typical use case for NewFileTransport is to register the \"file\" protocol with a Transport, as in:\n\nNewFileTransportFS returns a new RoundTripper, serving the provided file system fsys. The returned RoundTripper ignores the URL host in its incoming requests, as well as most other properties of the request. The files provided by fsys must implement io.Seeker.\n\nThe typical use case for NewFileTransportFS is to register the \"file\" protocol with a Transport, as in:\n\nSameSite allows a server to define a cookie attribute making it impossible for the browser to send this cookie along with cross-site requests. The main goal is to mitigate the risk of cross-origin information leakage, and provide some protection against cross-site request forgery attacks.\n\nServeMux is an HTTP request multiplexer. It matches the URL of each incoming request against a list of registered patterns and calls the handler for the pattern that most closely matches the URL.\n\nPatterns can match the method, host and path of a request. Some examples:\n• \"/index.html\" matches the path \"/index.html\" for any host and method.\n• \"GET /static/\" matches a GET request whose path begins with \"/static/\".\n• \"example.com/\" matches any request to the host \"example.com\".\n• \"/b/{bucket}/o/{objectname...}\" matches paths whose first segment is \"b\" and whose third segment is \"o\". The name \"bucket\" denotes the second segment and \"objectname\" denotes the remainder of the path.\n\nIn general, a pattern looks like\n\nAll three parts are optional; \"/\" is a valid pattern. If METHOD is present, it must be followed by at least one space or tab.\n\nLiteral (that is, non-wildcard) parts of a pattern match the corresponding parts of a request case-sensitively.\n\nA pattern with no method matches every method. A pattern with the method GET matches both GET and HEAD requests. Otherwise, the method must match exactly.\n\nA pattern with no host matches every host. A pattern with a host matches URLs on that host only.\n\nA path can include wildcard segments of the form {NAME} or {NAME...}. For example, \"/b/{bucket}/o/{objectname...}\". The wildcard name must be a valid Go identifier. Wildcards must be full path segments: they must be preceded by a slash and followed by either a slash or the end of the string. For example, \"/b_{bucket}\" is not a valid pattern.\n\nNormally a wildcard matches only a single path segment, ending at the next literal slash (not %2F) in the request URL. But if the \"...\" is present, then the wildcard matches the remainder of the URL path, including slashes. (Therefore it is invalid for a \"...\" wildcard to appear anywhere but at the end of a pattern.) The match for a wildcard can be obtained by calling Request.PathValue with the wildcard's name. A trailing slash in a path acts as an anonymous \"...\" wildcard.\n\nThe special wildcard {$} matches only the end of the URL. For example, the pattern \"/{$}\" matches only the path \"/\", whereas the pattern \"/\" matches every path.\n\nFor matching, both pattern paths and incoming request paths are unescaped segment by segment. So, for example, the path \"/a%2Fb/100%25\" is treated as having two segments, \"a/b\" and \"100%\". The pattern \"/a%2fb/\" matches it, but the pattern \"/a/b/\" does not.\n\nIf two or more patterns match a request, then the most specific pattern takes precedence. A pattern P1 is more specific than P2 if P1 matches a strict subset of P2’s requests; that is, if P2 matches all the requests of P1 and more. If neither is more specific, then the patterns conflict. There is one exception to this rule, for backwards compatibility: if two patterns would otherwise conflict and one has a host while the other does not, then the pattern with the host takes precedence. If a pattern passed to ServeMux.Handle or ServeMux.HandleFunc conflicts with another pattern that is already registered, those functions panic.\n\nAs an example of the general rule, \"/images/thumbnails/\" is more specific than \"/images/\", so both can be registered. The former matches paths beginning with \"/images/thumbnails/\" and the latter will match any other path in the \"/images/\" subtree.\n\nAs another example, consider the patterns \"GET /\" and \"/index.html\": both match a GET request for \"/index.html\", but the former pattern matches all other GET and HEAD requests, while the latter matches any request for \"/index.html\" that uses a different method. The patterns conflict.\n\nConsider a ServeMux with a handler for a subtree, registered using a trailing slash or \"...\" wildcard. If the ServeMux receives a request for the subtree root without a trailing slash, it redirects the request by adding the trailing slash. This behavior can be overridden with a separate registration for the path without the trailing slash or \"...\" wildcard. For example, registering \"/images/\" causes ServeMux to redirect a request for \"/images\" to \"/images/\", unless \"/images\" has been registered separately.\n\nServeMux also takes care of sanitizing the URL request path and the Host header, stripping the port number and redirecting any request containing . or .. segments or repeated slashes to an equivalent, cleaner URL. Escaped path elements such as \"%2e\" for \".\" and \"%2f\" for \"/\" are preserved and aren't considered separators for request routing.\n\nThe pattern syntax and matching behavior of ServeMux changed significantly in Go 1.22. To restore the old behavior, set the GODEBUG environment variable to \"httpmuxgo121=1\". This setting is read once, at program startup; changes during execution will be ignored.\n• Wildcards are just ordinary literal path segments in 1.21. For example, the pattern \"/{x}\" will match only that path in 1.21, but will match any one-segment path in 1.22.\n• In 1.21, no pattern was rejected, unless it was empty or conflicted with an existing pattern. In 1.22, syntactically invalid patterns will cause ServeMux.Handle and ServeMux.HandleFunc to panic. For example, in 1.21, the patterns \"/{\" and \"/a{x}\" match themselves, but in 1.22 they are invalid and will cause a panic when registered.\n• In 1.22, each segment of a pattern is unescaped; this was not done in 1.21. For example, in 1.22 the pattern \"/%61\" matches the path \"/a\" (\"%61\" being the URL escape sequence for \"a\"), but in 1.21 it would match only the path \"/%2561\" (where \"%25\" is the escape for the percent sign).\n• When matching patterns to paths, in 1.22 each segment of the path is unescaped; in 1.21, the entire path is unescaped. This change mostly affects how paths with %2F escapes adjacent to slashes are treated. See https://go.dev/issue/21955 for details.\n\nHandle registers the handler for the given pattern. If the given pattern conflicts, with one that is already registered, Handle panics.\n\nHandleFunc registers the handler function for the given pattern. If the given pattern conflicts, with one that is already registered, HandleFunc panics.\n\nHandler returns the handler to use for the given request, consulting r.Method, r.Host, and r.URL.Path. It always returns a non-nil handler. If the path is not in its canonical form, the handler will be an internally-generated handler that redirects to the canonical path. If the host contains a port, it is ignored when matching handlers.\n\nThe path and host are used unchanged for CONNECT requests.\n\nHandler also returns the registered pattern that matches the request or, in the case of internally-generated redirects, the path that will match after following the redirect.\n\nIf there is no registered handler that applies to the request, Handler returns a “page not found” handler and an empty pattern.\n\nServeHTTP dispatches the request to the handler whose pattern most closely matches the request URL.\n\nA Server defines parameters for running an HTTP server. The zero value for Server is a valid configuration.\n\nClose immediately closes all active net.Listeners and any connections in state StateNew, StateActive, or StateIdle. For a graceful shutdown, use Server.Shutdown.\n\nClose does not attempt to close (and does not even know about) any hijacked connections, such as WebSockets.\n\nClose returns any error returned from closing the Server's underlying Listener(s).\n\nListenAndServe listens on the TCP network address s.Addr and then calls Serve to handle requests on incoming connections. Accepted connections are configured to enable TCP keep-alives.\n\nIf s.Addr is blank, \":http\" is used.\n\nListenAndServe always returns a non-nil error. After Server.Shutdown or Server.Close, the returned error is ErrServerClosed.\n\nListenAndServeTLS listens on the TCP network address s.Addr and then calls ServeTLS to handle requests on incoming TLS connections. Accepted connections are configured to enable TCP keep-alives.\n\nFilenames containing a certificate and matching private key for the server must be provided if neither the Server's TLSConfig.Certificates nor TLSConfig.GetCertificate are populated. If the certificate is signed by a certificate authority, the certFile should be the concatenation of the server's certificate, any intermediates, and the CA's certificate.\n\nIf s.Addr is blank, \":https\" is used.\n\nListenAndServeTLS always returns a non-nil error. After Server.Shutdown or Server.Close, the returned error is ErrServerClosed.\n\nRegisterOnShutdown registers a function to call on Server.Shutdown. This can be used to gracefully shutdown connections that have undergone ALPN protocol upgrade or that have been hijacked. This function should start protocol-specific graceful shutdown, but should not wait for shutdown to complete.\n\nServe accepts incoming connections on the Listener l, creating a new service goroutine for each. The service goroutines read requests and then call s.Handler to reply to them.\n\nHTTP/2 support is only enabled if the Listener returns *tls.Conn connections and they were configured with \"h2\" in the TLS Config.NextProtos.\n\nServe always returns a non-nil error and closes l. After Server.Shutdown or Server.Close, the returned error is ErrServerClosed.\n\nServeTLS accepts incoming connections on the Listener l, creating a new service goroutine for each. The service goroutines perform TLS setup and then read requests, calling s.Handler to reply to them.\n\nFiles containing a certificate and matching private key for the server must be provided if neither the Server's TLSConfig.Certificates, TLSConfig.GetCertificate nor config.GetConfigForClient are populated. If the certificate is signed by a certificate authority, the certFile should be the concatenation of the server's certificate, any intermediates, and the CA's certificate.\n\nServeTLS always returns a non-nil error. After Server.Shutdown or Server.Close, the returned error is ErrServerClosed.\n\nSetKeepAlivesEnabled controls whether HTTP keep-alives are enabled. By default, keep-alives are always enabled. Only very resource-constrained environments or servers in the process of shutting down should disable them.\n\nShutdown gracefully shuts down the server without interrupting any active connections. Shutdown works by first closing all open listeners, then closing all idle connections, and then waiting indefinitely for connections to return to idle and then shut down. If the provided context expires before the shutdown is complete, Shutdown returns the context's error, otherwise it returns any error returned from closing the Server's underlying Listener(s).\n\nWhen Shutdown is called, Serve, ListenAndServe, and ListenAndServeTLS immediately return ErrServerClosed. Make sure the program doesn't exit and waits instead for Shutdown to return.\n\nShutdown does not attempt to close nor wait for hijacked connections such as WebSockets. The caller of Shutdown should separately notify such long-lived connections of shutdown and wait for them to close, if desired. See Server.RegisterOnShutdown for a way to register shutdown notification functions.\n\nOnce Shutdown has been called on a server, it may not be reused; future calls to methods such as Serve will return ErrServerClosed.\n\nTransport is an implementation of RoundTripper that supports HTTP, HTTPS, and HTTP proxies (for either HTTP or HTTPS with CONNECT).\n\nBy default, Transport caches connections for future re-use. This may leave many open connections when accessing many hosts. This behavior can be managed using Transport.CloseIdleConnections method and the [Transport.MaxIdleConnsPerHost] and [Transport.DisableKeepAlives] fields.\n\nTransports should be reused instead of created as needed. Transports are safe for concurrent use by multiple goroutines.\n\nA Transport is a low-level primitive for making HTTP and HTTPS requests. For high-level functionality, such as cookies and redirects, see Client.\n\nTransport uses HTTP/1.1 for HTTP URLs and either HTTP/1.1 or HTTP/2 for HTTPS URLs, depending on whether the server supports HTTP/2, and how the Transport is configured. The DefaultTransport supports HTTP/2. To explicitly enable HTTP/2 on a transport, set [Transport.Protocols].\n\nResponses with status codes in the 1xx range are either handled automatically (100 expect-continue) or ignored. The one exception is HTTP status code 101 (Switching Protocols), which is considered a terminal status and returned by Transport.RoundTrip. To see the ignored 1xx responses, use the httptrace trace package's ClientTrace.Got1xxResponse.\n\nTransport only retries a request upon encountering a network error if the connection has been already been used successfully and if the request is idempotent and either has no body or has its [Request.GetBody] defined. HTTP requests are considered idempotent if they have HTTP methods GET, HEAD, OPTIONS, or TRACE; or if their Header map contains an \"Idempotency-Key\" or \"X-Idempotency-Key\" entry. If the idempotency key value is a zero-length slice, the request is treated as idempotent but the header is not sent on the wire.\n\nCancelRequest cancels an in-flight request by closing its connection. CancelRequest should only be called after Transport.RoundTrip has returned.\n\nDeprecated: Use Request.WithContext to create a request with a cancelable context instead. CancelRequest cannot cancel HTTP/2 requests. This may become a no-op in a future release of Go.\n\nCloseIdleConnections closes any connections which were previously connected from previous requests but are now sitting idle in a \"keep-alive\" state. It does not interrupt any connections currently in use.\n\nRegisterProtocol registers a new protocol with scheme. The Transport will pass requests using the given scheme to rt. It is rt's responsibility to simulate HTTP request semantics.\n\nRegisterProtocol can be used by other packages to provide implementations of protocol schemes like \"ftp\" or \"file\".\n\nIf rt.RoundTrip returns ErrSkipAltProtocol, the Transport will handle the Transport.RoundTrip itself for that one request, as if the protocol were not registered.\n\nFor higher-level HTTP client support (such as handling of cookies and redirects), see Get, Post, and the Client type.\n\nLike the RoundTripper interface, the error types returned by RoundTrip are unspecified."
    },
    {
        "link": "https://dev.to/romulogatto/introduction-to-web-development-with-go-nethttp-package-9al",
        "document": "Introduction to Web Development with Go (net/http package)\n\nGo is a powerful programming language that has gained popularity in recent years, especially for web development. With its simplicity and efficiency, it provides developers with the tools they need to build high-performance websites and web applications.\n\nIn this article, we will explore the fundamentals of web development using Go's package. This built-in package provides a robust set of functionalities to create HTTP servers and handle HTTP requests/responses efficiently.\n\nBefore diving into web development with Go, you'll need to set up your development environment. Follow these steps:\n• None Install Go: Head over to the official documentation and download the appropriate binary distribution for your operating system.\n• None Verify Installation: Open a terminal or command prompt window and run the following command:\n\n\n\nIf you see an output similar to , congratulations! You have successfully installed Go.\n• None Set up Workspace: Create a workspace directory where you will store all your Go code projects. This directory should be outside of the standard system paths like or .\n• None Configure Environment Variables: Add your workspace's bin folder path ( ) to the environment variable so that you can invoke your executables easily from any location.\n• None IDE/Editor Setup: Choose an IDE or text editor that supports Go syntax highlighting and offers useful extensions or plugins for code completion, formatting, and debugging purposes. Some popular choices include Visual Studio Code (with Go extension), IntelliJ IDEA (with Golang Plugin), or Sublime Text (with golangconfig).\n\nWith your development environment now set up correctly let's move on to exploring web development in Go!\n\nTo get started with Go web development, let's create a basic HTTP server that listens for incoming requests and responds with a simple \"Hello, World!\" message.\n\nCreate a new file called in your workspace directory and add the following code:\n\n\n\nLet's go through what this code does step-by-step:\n• None The function handles incoming HTTP requests. It takes two parameters: , which is an interface to write the response to the client, and , which represents the HTTP request received.\n• None Inside the function, we use the function to write \"Hello, World!\" as our response directly into the response writer ( ) passed as an argument.\n• None In the function, we register our handler ( ) with Go's default multiplexer ( ). This tells Go to route all incoming requests to this specific handler.\n• None Finally, we start our server by calling . It takes two parameters: a port number (in this case 8080), and an optional parameter for handling custom routers (set as nil for now).\n\nTo run your web server locally, open a terminal or command prompt window in your workspace directory and execute this command:\n\n\n\nVisit http://localhost:8080 in your web browser. You should see \"Hello, World!\" displayed on the page.\n\nCongratulations! You've just created your first web server using Go's net/http package!\n\nIn this article, we've covered the basics of web development with Go's package. We started by setting up our development environment and creating a simple \"Hello, World!\" server.\n\nGo's package provides extensive capabilities for building robust web applications. With its powerful features like routing, middleware support, and concurrent handling of requests, you can build scalable and efficient web services.\n\nBy continuing to explore the various functions and methods available in the package documentation, you'll be able to develop complex web applications with ease using Go."
    },
    {
        "link": "https://codedodle.com/go-reverse-proxy-example.html",
        "document": "Go’s httputil package makes it really easy to create a reverse proxy. In this article, I’ll show you how to create a simple reverse proxy and ways you can extend and develop more complex features using it as the base.\n\nThe simplest version of Go reverse proxy requires just a couple lines of code. For example, this is a perfectly valid reverse proxy:-\n\nFor this setup, all requests received on :8080 are proxied to the origin server at http://localhost:8888. For the purpose of this article, I’m running a dummy server that prints out the request details.\n\nFirst, create a new ReverseProxy instance using from httputil.\n\nThen, feed the ReverseProxy instance directly to http.Handle: :-\n\nAnd the reason why this works is because ReverseProxy satisfies the http.Handler interface through its ServeHTTP method implementation. This makes it a Handler type — which is what http.Handle is expecting for its second parameter.\n\nThat said, in many applications, you might not want to use ReverseProxy.ServeHTTP directly. Instead, you might want to inject some middleware here by chaining up the ServeHTTP method. We’ll talk more about this in the Middleware section below.\n\nIn terms of the headers, by default, everything is passed on to the origin which includes request headers and query parameters, EXCEPT:-\n• X-Forwarded-For header – ReverseProxy will add or append the client IP to this header\n• User-Agent – when using the default Director (more on this in the following section) ReverseProxy explicit sets it to “” if no User-Agent header is found in the request.\n\nFor one reason or another, you might want to modify the user requests before passing them on to the origin server.\n\nFor example, you might want to add information about the particular proxy server that is handling the request: ip, type, version, etc.\n\nIn another case, you might want to share more information about the client, such as their country.\n\nBefore we get to actually changing the requests, let’s refactor our code.\n\nThis code below works in exactly the same way as the code in the previous section, except that the code that creates the proxy has moved into a function called NewProxy.\n\nRoughly, there are three ways to modify a client requests:\n• create your own Director function and call the default Director function, chaining the Direction functions in effect. (The approach is inspired by this awesome article)\n\nHere’s how the second approach works:-\n\nThe reason why you want to call the original director function is because it does a couple of things like setting the host, scheme, and update the URL path. You can absolutely do all these manually in your own custom Director, but I just like the fact that it’s done for me. For more details, check out its source code.\n\nFor modifying responses, ReverseProxy provides a “hook” for your custom function.\n\nTo use that hook, just write a function to ModifyResponse of your ReverseProxy instance.\n\nFor example, this code will add a Server header to all responses.\n\nUnlike the Director function above, there’s no default ModifyResponse in the httputil package. So, there’s no worries about overriding any default behavior.\n\nAnother way to change the response is by adding a middleware. See the following section.\n\nA great way to add functionalities to your custom reverse proxy is by adding a middleware by chaining the handlers.\n\nFor the proxy that we’re developing, we’ll create our own ServeHTTP function and call ReverseProxy’s ServeHTTP from it.\n\nFirst, let’s refactor the code a little bit by creating a new struct type SimpleProxy.\n\nSimpleProxy is a thin wrapper over ReverseProxy and it is considered a Handler type (because it implements its own ServeHTTP method).\n\nInside SimpleProxy’s ServeHTTP method, you can do all sorts of things like modifying requests and response, implement caching, block requests, log information, routing to different origin servers (load balancing), and the list goes on.\n\nHere’s the dummy backend server I used for testing. It prints out the request headers and body.\n\nIn the sample output above, you can see that the “Some-Header” item in the request header has been set correctly by the Director function we created earlier.\n\nSimilar, “Server: Codedodle” shows up in the response header as a result of our custom ModifyResponse function.\n\nHop-by-hop headers are headers that are meant to be consumed by the first node that handles them. A reverse proxy would consume these headers before creating its own hop-by-hop headers and forward them to the origin server.\n\nHere’s the list of headers classified as hop-by-hop by ReverseProxy:-\n\nBelow are some useful webpages I used to develop this article. You should check them out if you need more information on ReverseProxy.\n• The Right Use of ‘ReverseProxy’ in Golang – JoshSoftware Link – a great introduction and excellent review guide for those of you who are working with ReverseProxy.\n• Golang Reverse Proxy – Link – in this article, the author shows you how to instantiate a ReverseProxy instance without using the builtin constructor function . This involves creating your own Director function and making the right configurations. The article also shows you can roll out your own ErrorHandler and use it in ReverseProxy — one of the aspects I have not covered above."
    },
    {
        "link": "https://prabeshthapa.medium.com/learn-reverse-proxy-by-creating-one-yourself-using-go-87be2a29d1e",
        "document": "Learn reverse proxy by creating one yourself using GO It is a server that sits in between client machines and servers. There are different types of proxy servers but all of them can be generalized into two: Forward and Reverse A sits in front of the clients and sends request on behalf of client to web servers . When request is sent by clients, forward proxy intercepts the request and then sends request to web servers on their behalf. It acts on behalf of client. It is generally used when you don’t want server to know your address as forward proxy send request on client behalf. A sits in front of the web servers and intercepts all traffic sent by client to web servers . It intercepts request coming from clients and then send those request to appropriate web servers. It is generally used to improve security, performance and for reliability.\n\nLet’s first create all the required directories so that it will make our life easier. : It will contain entry function for our project. : It will hold configuration code to load values from yaml data into our application : It will hold code to create and run HTTP proxy server. : It will contain the configuration yaml file for our project. Now again, let’s create all the files that is required in this project : It will hold recepies to run and stop our application. : It will hold our reverse proxy configuration. -> It is used at entrypoint to our code -> It will hold code to load configuration : It will contain functions to creating new proxy and proxy handler : It will be a simple http handler to check if our server is running or not. : It will be used to create and run HTTP server All the required files are created, your directory structure should look like this\n\nOnce this is all done, we are ready to start coding. What are we doing here is, we are defining some parameters for our reverse proxy so that we can tune it in future without modifying the code. We are also specifying the reverse proxy where we will have list of and each resource will contain following : Name of the resource : Ednpoint it will be serving at : Destination URL where the incoming request at will be forwarded to. Copy and pase the fllowing code into file. server:\n\n host: \"localhost\"\n\n listen_port: \"8080\"\n\n\n\nresources:\n\n - name: Server1\n\n endpoint: /server1\n\n destination_url: \"http://localhost:9001\"\n\n - name: Server2\n\n endpoint: /server2\n\n destination_url: \"http://localhost:9002\"\n\n - name: Server3\n\n endpoint: /server3\n\n destination_url: \"http://localhost:9003\" As you can see that we are trying to create a reverse proxy which will accept request at and proxy it to our demo server and same for other endpoints.\n\nLoading data from config.yaml to our application Now we have created our configuration file, let’s write code to load configuration into our program. Copy and paste the following code into . package configs\n\n\n\nimport (\n\n \"fmt\"\n\n \"strings\"\n\n \"github.com/spf13/viper\"\n\n)\n\ntype resource struct {\n\n Name string\n\n Endpoint string\n\n Destination_URL string\n\n}\n\ntype configuration struct {\n\n Server struct {\n\n Host string\n\n Listen_port string\n\n }\n\n Resources []resource\n\n}\n\nvar Config *configuration\n\nfunc NewConfiguration() (*configuration, error) {\n\n viper.AddConfigPath(\"data\")\n\n viper.SetConfigName(\"config\")\n\n viper.SetConfigType(\"yaml\")\n\n viper.AutomaticEnv()\n\n viper.SetEnvKeyReplacer(strings.NewReplacer(`.`, `_`))\n\n err := viper.ReadInConfig()\n\n if err != nil {\n\n return nil, fmt.Errorf(\"error loading config file: %s\", err)\n\n }\n\n err = viper.Unmarshal(&Config)\n\n if err != nil {\n\n return nil, fmt.Errorf(\"error reading config file: %s\", err)\n\n }\n\n return Config, nil\n\n} We are using Viper to load config yaml files into our go program. You can see how its done using this video here: Use configuration file in Go project to manage app settings What we did above it, we create a custom data type of type struct called . then we created a variable called of type which will hold the data from yaml file once its loaded. then we created a function called which will use viper and load configuration from yaml file to our variable . As you noticed, we are using function with first letter uppercase which means it will be exported. We will later call this function get our configuration values.\n\nCreating and running http server for our reverse proxy Let’s implement the function that we called in . Go to and paste in following code package server\n\n\n\nimport (\n\n \"fmt\"\n\n \"net/http\"\n\n \"net/url\"\n\n \"github.com/pgaijin66/lightweight-reverse-proxy/internal/configs\"\n\n)\n\n// Run starts server and listens on defined port\n\nfunc Run() error {\n\n // load configurations from config file\n\n config, err := configs.NewConfiguration()\n\n if err != nil {\n\n fmt.Errorf(\"could not load configuration: %v\", err)\n\n }\n\n // Creates a new router\n\n mux := http.NewServeMux()\n\n // Registering the healthcheck endpoint\n\n mux.HandleFunc(\"/ping\", ping)\n\n // Iterating through the configuration resource and registering them\n\n // into the router.\n\n for _, resource := range config.Resources {\n\n url, _ := url.Parse(resource.Destination_URL)\n\n proxy := NewProxy(url)\n\n mux.HandleFunc(resource.Endpoint, ProxyRequestHandler(proxy, url, resource.Endpoint))\n\n }\n\n // Running proxy server\n\n if err := http.ListenAndServe(config.Server.Host+\":\"+config.Server.Listen_port, mux); err != nil {\n\n return fmt.Errorf(\"could not start the server: %v\", err)\n\n }\n\n return nil\n\n} In above code snippet, we are creating a function called which loads configuration by calling function from package we created and stores into a variable called . We create a new server called using package We register route called to call our http handler which we have not created yet. Then we iterate through the resources and register them into our router as that we what we want to achieve i.e when someone tries to access then our reverse proxy will intercept that request and forward it to which is their . Now we have registered all the routes, we are ready to start the server which we do by calling . As you saw, our function returns an and If everything works out well we return otherwise return an error. Let’s quickly implement our healthcheck handler. Copy and paste following code into . Before we jump next, let’s understand what this code block is doing As i said above it iterated through the endpints and registers handler for them. But its doing a bit more than that. We are iterating through each resources in which gives us individual on each iteration and each resource holds , and . Now for each resource, we are taking it’s destination URl and parsing it. The reason we are parsing it is our function to create new proxy will take as an argument. since is a string, we are paring it and getting url which is of type . Then we call function called with as our input. This will return us with a new proxy of type . Now we register the to the handler returned by our . As we saw above, our function takes three parameters revese proxy, destination URL and endpoint."
    },
    {
        "link": "https://medium.com/@abhinavv.singh/reverse-proxy-in-go-handling-millions-of-traffic-seamlessly-a76b12d49494",
        "document": "In modern web applications, managing large volumes of traffic efficiently and securely is one of the most important aspects of system architecture. A reverse proxy is an essential tool for handling this challenge, acting as an intermediary that sits between clients and backend servers. This article will delve into the implementation of a reverse proxy in Go, discuss how it can handle millions of traffic requests, and share real-life challenges and solutions I faced during its implementation.\n\nA reverse proxy server acts as an intermediary between clients (such as web browsers or mobile apps) and backend servers.\n\nUnlike a forward proxy, which forwards requests from clients to the internet, a reverse proxy serves multiple backend servers. It can distribute incoming traffic across multiple servers, manage SSL/TLS encryption, handle load balancing, and improve security by hiding the identity and structure of the backend systems."
    },
    {
        "link": "https://gist.github.com/JalfResi/6287706",
        "document": "You signed in with another tab or window. Reload to refresh your session.\n\nYou signed out in another tab or window. Reload to refresh your session.\n\nYou switched accounts on another tab or window. Reload to refresh your session."
    },
    {
        "link": "https://pkg.go.dev/net/http/httputil",
        "document": "DumpRequest returns the given request in its HTTP/1.x wire representation. It should only be used by servers to debug client requests. The returned representation is an approximation only; some details of the initial request are lost while parsing it into an http.Request. In particular, the order and case of header field names are lost. The order of values in multi-valued headers is kept intact. HTTP/2 requests are dumped in HTTP/1.x form, not in their original binary representations. If body is true, DumpRequest also returns the body. To do so, it consumes req.Body and then replaces it with a new io.ReadCloser that yields the same bytes. If DumpRequest returns an error, the state of req is undefined. The documentation for http.Request.Write details which fields of req are included in the dump. package main import ( \"fmt\" \"io\" \"log\" \"net/http\" \"net/http/httptest\" \"net/http/httputil\" \"strings\" ) func main() { ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { dump, err := httputil.DumpRequest(r, true) if err != nil { http.Error(w, fmt.Sprint(err), http.StatusInternalServerError) return } fmt.Fprintf(w, \"%q\", dump) })) defer ts.Close() const body = \"Go is a general-purpose language designed with systems programming in mind.\" req, err := http.NewRequest(\"POST\", ts.URL, strings.NewReader(body)) if err != nil { log.Fatal(err) } req.Host = \"www.example.org\" resp, err := http.DefaultClient.Do(req) if err != nil { log.Fatal(err) } defer resp.Body.Close() b, err := io.ReadAll(resp.Body) if err != nil { log.Fatal(err) } fmt.Printf(\"%s\", b) } \"POST / HTTP/1.1\\r\n\nHost: www.example.org\\r\n\nAccept-Encoding: gzip\\r\n\nContent-Length: 75\\r\n\nUser-Agent: Go-http-client/1.1\\r\n\n\\r\n\nGo is a general-purpose language designed with systems programming in mind.\" DumpRequestOut is like DumpRequest but for outgoing client requests. It includes any headers that the standard http.Transport adds, such as User-Agent. package main import ( \"fmt\" \"log\" \"net/http\" \"net/http/httputil\" \"strings\" ) func main() { const body = \"Go is a general-purpose language designed with systems programming in mind.\" req, err := http.NewRequest(\"PUT\", \"http://www.example.org\", strings.NewReader(body)) if err != nil { log.Fatal(err) } dump, err := httputil.DumpRequestOut(req, true) if err != nil { log.Fatal(err) } fmt.Printf(\"%q\", dump) } \"PUT / HTTP/1.1\\r\n\nHost: www.example.org\\r\n\nUser-Agent: Go-http-client/1.1\\r\n\nContent-Length: 75\\r\n\nAccept-Encoding: gzip\\r\n\n\\r\n\nGo is a general-purpose language designed with systems programming in mind.\" DumpResponse is like DumpRequest but dumps a response. package main import ( \"fmt\" \"log\" \"net/http\" \"net/http/httptest\" \"net/http/httputil\" ) func main() { const body = \"Go is a general-purpose language designed with systems programming in mind.\" ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { w.Header().Set(\"Date\", \"Wed, 19 Jul 1972 19:00:00 GMT\") fmt.Fprintln(w, body) })) defer ts.Close() resp, err := http.Get(ts.URL) if err != nil { log.Fatal(err) } defer resp.Body.Close() dump, err := httputil.DumpResponse(resp, true) if err != nil { log.Fatal(err) } fmt.Printf(\"%q\", dump) } \"HTTP/1.1 200 OK\\r\n\nContent-Length: 76\\r\n\nContent-Type: text/plain; charset=utf-8\\r\n\nDate: Wed, 19 Jul 1972 19:00:00 GMT\\r\n\n\\r\n\nGo is a general-purpose language designed with systems programming in mind.\n\n\" NewChunkedReader returns a new chunkedReader that translates the data read from r out of HTTP \"chunked\" format before returning it. The chunkedReader returns io.EOF when the final 0-length chunk is read. NewChunkedReader is not needed by normal applications. The http package automatically decodes chunking when reading response bodies. NewChunkedWriter returns a new chunkedWriter that translates writes into HTTP \"chunked\" format before writing them to w. Closing the returned chunkedWriter sends the final 0-length chunk that marks the end of the stream but does not send the final CRLF that appears after trailers; trailers and the last CRLF must be written separately. NewChunkedWriter is not needed by normal applications. The http package adds chunking automatically if handlers don't set a Content-Length header. Using NewChunkedWriter inside a handler would result in double chunking or chunking with a Content-Length length, both of which are wrong.\n\nA BufferPool is an interface for getting and returning temporary byte slices for use by io.CopyBuffer. ClientConn is an artifact of Go's early HTTP implementation. It is low-level, old, and unused by Go's current HTTP stack. We should have deleted it before Go 1. Deprecated: Use Client or Transport in package net/http instead. NewClientConn is an artifact of Go's early HTTP implementation. It is low-level, old, and unused by Go's current HTTP stack. We should have deleted it before Go 1. Deprecated: Use the Client or Transport in package net/http instead. NewProxyClientConn is an artifact of Go's early HTTP implementation. It is low-level, old, and unused by Go's current HTTP stack. We should have deleted it before Go 1. Deprecated: Use the Client or Transport in package net/http instead. Close calls ClientConn.Hijack and then also closes the underlying connection. Do is convenience method that writes a request and reads a response. Hijack detaches the ClientConn and returns the underlying connection as well as the read-side bufio which may have some left over data. Hijack may be called before the user or Read have signaled the end of the keep-alive logic. The user should not call Hijack while ClientConn.Read or ClientConn.Write is in progress. Pending returns the number of unanswered requests that have been sent on the connection. Read reads the next response from the wire. A valid response might be returned together with an ErrPersistEOF, which means that the remote requested that this be the last request serviced. Read can be called concurrently with ClientConn.Write, but not with another Read. Write writes a request. An ErrPersistEOF error is returned if the connection has been closed in an HTTP keep-alive sense. If req.Close equals true, the keep-alive connection is logically closed after this request and the opposing server is informed. An ErrUnexpectedEOF indicates the remote closed the underlying TCP connection, which is usually considered as graceful close. A ProxyRequest contains a request to be rewritten by a ReverseProxy. SetURL routes the outbound request to the scheme, host, and base path provided in target. If the target's path is \"/base\" and the incoming request was for \"/dir\", the target request will be for \"/base/dir\". SetURL rewrites the outbound Host header to match the target's host. To preserve the inbound request's Host header (the default behavior of NewSingleHostReverseProxy): SetXForwarded sets the X-Forwarded-For, X-Forwarded-Host, and X-Forwarded-Proto headers of the outbound request.\n• The X-Forwarded-For header is set to the client IP address.\n• The X-Forwarded-Host header is set to the host name requested by the client.\n• The X-Forwarded-Proto header is set to \"http\" or \"https\", depending on whether the inbound request was made on a TLS-enabled connection. If the outbound request contains an existing X-Forwarded-For header, SetXForwarded appends the client IP address to it. To append to the inbound request's X-Forwarded-For header (the default behavior of ReverseProxy when using a Director function), copy the header from the inbound request before calling SetXForwarded: ReverseProxy is an HTTP Handler that takes an incoming request and sends it to another server, proxying the response back to the client. 1xx responses are forwarded to the client if the underlying transport supports ClientTrace.Got1xxResponse. package main import ( \"fmt\" \"io\" \"log\" \"net/http\" \"net/http/httptest\" \"net/http/httputil\" \"net/url\" ) func main() { backendServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, \"this call was relayed by the reverse proxy\") })) defer backendServer.Close() rpURL, err := url.Parse(backendServer.URL) if err != nil { log.Fatal(err) } frontendProxy := httptest.NewServer(&httputil.ReverseProxy{ Rewrite: func(r *httputil.ProxyRequest) { r.SetXForwarded() r.SetURL(rpURL) }, }) defer frontendProxy.Close() resp, err := http.Get(frontendProxy.URL) if err != nil { log.Fatal(err) } b, err := io.ReadAll(resp.Body) if err != nil { log.Fatal(err) } fmt.Printf(\"%s\", b) } this call was relayed by the reverse proxy NewSingleHostReverseProxy returns a new ReverseProxy that routes URLs to the scheme, host, and base path provided in target. If the target's path is \"/base\" and the incoming request was for \"/dir\", the target request will be for /base/dir. NewSingleHostReverseProxy does not rewrite the Host header. To customize the ReverseProxy behavior beyond what NewSingleHostReverseProxy provides, use ReverseProxy directly with a Rewrite function. The ProxyRequest SetURL method may be used to route the outbound request. (Note that SetURL, unlike NewSingleHostReverseProxy, rewrites the Host header of the outbound request by default.) ServerConn is an artifact of Go's early HTTP implementation. It is low-level, old, and unused by Go's current HTTP stack. We should have deleted it before Go 1. Deprecated: Use the Server in package net/http instead. NewServerConn is an artifact of Go's early HTTP implementation. It is low-level, old, and unused by Go's current HTTP stack. We should have deleted it before Go 1. Deprecated: Use the Server in package net/http instead. Close calls ServerConn.Hijack and then also closes the underlying connection. Hijack detaches the ServerConn and returns the underlying connection as well as the read-side bufio which may have some left over data. Hijack may be called before Read has signaled the end of the keep-alive logic. The user should not call Hijack while ServerConn.Read or ServerConn.Write is in progress. Pending returns the number of unanswered requests that have been received on the connection. Read returns the next request on the wire. An ErrPersistEOF is returned if it is gracefully determined that there are no more requests (e.g. after the first request on an HTTP/1.0 connection, or after a Connection:close on a HTTP/1.1 connection). Write writes resp in response to req. To close the connection gracefully, set the Response.Close field to true. Write should be considered operational until it returns an error, regardless of any errors returned on the ServerConn.Read side."
    },
    {
        "link": "https://medium.com/@abhinavv.singh/reverse-proxy-in-go-handling-millions-of-traffic-seamlessly-a76b12d49494",
        "document": "In modern web applications, managing large volumes of traffic efficiently and securely is one of the most important aspects of system architecture. A reverse proxy is an essential tool for handling this challenge, acting as an intermediary that sits between clients and backend servers. This article will delve into the implementation of a reverse proxy in Go, discuss how it can handle millions of traffic requests, and share real-life challenges and solutions I faced during its implementation.\n\nA reverse proxy server acts as an intermediary between clients (such as web browsers or mobile apps) and backend servers.\n\nUnlike a forward proxy, which forwards requests from clients to the internet, a reverse proxy serves multiple backend servers. It can distribute incoming traffic across multiple servers, manage SSL/TLS encryption, handle load balancing, and improve security by hiding the identity and structure of the backend systems."
    },
    {
        "link": "https://medium.com/google-cloud/the-most-straightforward-load-balancer-youll-write-in-go-9d1213a62eff",
        "document": "This will be a series for sure, and as the first article in the series we will come to the basics. In order to do so, we’ll implement a load balancer with a random algorithm. A Load Balancer builds upon a reverse-proxy.\n\nSTOP THIS MADNESS AND SHOW ME THE CODE\n\nWhat the heck is a reverse proxy?\n\nThe reverse-proxy is software that sits in the middle between two parts of the communication, the Cloud Service that provides ‘a service to their clients’ and their clients. A reverse-proxy provides intelligence to the communication and by intelligence I mean:\n\nTo effectively code a load balancer we need to define its behaviour through a Backend Service.\n\nA backend service is a set of configurations that controls the Load Balancer behaviour.\n• The Protocol to use to connect to the backends\n• An associated Backend (the machines hosting the service our clients are interested in)\n\nThey represent the instances running the service we are interested in putting behind a load balancer.\n\nBut how does it exactly decides to which application instance direct the traffic from an specific request?\n\nThe load balancing algorithm is set by the function. As it can be better elaborate it enables to depict in a glance how the Load Balancer distributes traffic.\n\nYou got to specify the when defining the , like below:"
    },
    {
        "link": "https://dev.to/vivekalhat/building-a-simple-load-balancer-in-go-70d",
        "document": "Load balancers are crucial in modern software development. If you've ever wondered how requests are distributed across multiple servers, or why certain websites feel faster even during heavy traffic, the answer often lies in efficient load balancing.\n\nIn this post, we'll build a simple application load balancer using Round Robin algorithm in Go. The aim of this post is to understand how a load balancer works under the hood, step by step.\n\nA load balancer is a system that distributes incoming network traffic across multiple servers. It ensures that no single server bears too much load, preventing bottlenecks and improving the overall user experience. Load balancing approach also ensure that if one server fails, then the traffic can be automatically re-routed to another available server, thus reducing the impact of the failure and increasing availability.\n\nWhy do we use Load Balancers?\n• High availability: By distributing traffic, load balancers ensure that even if one server fails, traffic can be routed to other healthy servers, making the application more resilient.\n• Scalability: Load balancers allow you to scale your system horizontally by adding more servers as traffic increases.\n• Efficiency: It maximizes resource utilization by ensuring all servers share the workload equally.\n\nThere are different algorithms and strategies to distribute the traffic:\n• Round Robin: One of the simplest methods available. It distributes requests sequentially among the available servers. Once it reaches the last server, it starts again from the beginning.\n• Weighted Round Robin: Similar to round robin algorithm except each server is assigned some fixed numerical weighting. This given weight is used to determine the server for routing traffic.\n• Least Connections: Routes traffic to the server with the least active connections.\n• IP Hashing: Select the server based on the client's IP address.\n\nIn this post, we'll focus on implementing a Round Robin load balancer.\n\nA round robin algorithm sends each incoming request to the next available server in a circular manner. If server A handles the first request, server B will handle the second, and server C will handle the third. Once all servers have received a request, it starts again from server A.\n\nNow, let's jump into the code and build our load balancer!\n\nWe'll first define a simple struct with a field to keep track of which server should handle next request. The ensures that our code is safe to use concurrently.\n\nEach server we load balance is defined by the struct:\n\n\n\nHere, each server has a URL and an flag, which indicates whether the server is available to handle requests.\n\nThe heart of our load balancer is the round robin algorithm. Here's how it works:\n• This method loops through the list of servers in a round robin fashion. If the selected server is healthy, it returns that server to handle the incoming request.\n• We are using to ensure that only one goroutine can access and modify the field of the load balancer at a time. This ensures that the round robin algorithm operates correctly when multiple requests are being processed concurrently.\n• Each also has its own . When we check the field, we lock the server's to prevent concurrent access from multiple goroutines.\n• Without locking it is possible that another goroutine could be changing the value which could result in reading an incorrect or inconsistent data.\n• We unlock the as soon as we have updated the field or read the field value to keep the critical section as small as possible. In this way, we are using to avoid any race condition.\n\nOur configuration is stored in a file, which contains the server URLs and health check intervals (more on it in below section).\n\n\n\nThe configuration file might look like this:\n\n\n\nWe want to make sure that the servers are healthy before routing any incoming traffic to them. This is done by sending periodic health checks to each server:\n\n\n\nEvery few seconds (as specified in the config), the load balancer sends a request to each server to check if it is healthy. If a server is down, the flag is set to , preventing future traffic from being routed to it.\n\nWhen the load balancer receives a request, it forwards the request to the next available server using a reverse proxy. In Golang, the package provides a built-in way to handle reverse proxying, and we will use it in our code through the function:\n\n\n\nA reverse proxy is a server that sits between a client and one or more backend severs. It receives the client's request, forwards it to one of the backend servers, and then returns the server's response to the client. The client interacts with the proxy, unaware of which specific backend server is handling the request.\n\nIn our case, the load balancer acts as a reverse proxy, sitting in front of multiple servers and distributing incoming HTTP requests across them.\n\nWhen a client makes a request to the load balancer, it selects the next available healthy server using the round robin algorithm implementation in function and proxies the client request to that server. If no healthy server is available then we send service unavailable error to the client.\n\n\n\nThe method proxies the request to the actual server, and we also add a custom header for debugging purposes (though in production, we should avoid exposing internal server details like this).\n\nFinally, we start the load balancer on the specified port:\n\n\n\nIn this post, we built a basic load balancer from scratch in Golang using a round robin algorithm. This is a simple yet effective way to distribute traffic across multiple servers and ensure that your system can handle higher loads efficiently.\n\nThere's a lot more to explore, such as adding sophisticated health checks, implementing different load balancing algorithms, or improving fault tolerance. But this basic example can be a solid foundation to build upon.\n\nYou can find the source code in this GitHub repo."
    },
    {
        "link": "https://kasvith.me/posts/lets-create-a-simple-lb-go",
        "document": "Load Balancers plays a key role in Web Architecture. They allow distributing load among a set of backends. This makes services more scalable. Also since there are multiple backends configured the service become highly available as load balancer can pick up a working server in case of a failure.\n\nAfter playing with professional Load Balancers like NGINX I tried creating a simple Load Balancer for fun. I implemented it using Golang. Go is a modern language which supports concurrency as a first-class citizen. Go has a rich standard library which allows writing high-performance applications with fewer lines of codes. It also produces a statically linked single binary for easy distributions.\n\n#How does our simple load balancer work\n\nLoad Balancers have different strategies for distributing the load across a set of backends.\n• Round Robin - Distribute load equally, assumes all backends have the same processing power\n• Weighted Round Robin - Additional weights can be given considering the backend's processing power\n• Least Connections - Load is distributed to the servers with least active connections\n\nFor our simple load balancer, we would try implementing the simplest one among these methods, Round Robin.\n\nRound Robin is simple in terms. It gives equal opportunities for workers to perform tasks in turns.\n\nAs shown in the figure about this happens cyclically. But we can't directly use that aren't we?\n\nWhat if a backend is down? We probably don't want to route traffic there. So this cannot be directly used unless we put some conditions on it. We need to route traffic only to backends which are up and running.\n\nAfter revising the plan, we know now we want a way to track all the details about a Backend. We need to track whether it's alive or dead and also keep track of the Url as well.\n\nWe can simply define a struct like this to hold our backends.\n\nDon't worry I will reason about the fields in the .\n\nNow we need a way to track all the backends in our load balancer, for that we can simply use a Slice. And also a counter variable. We can define it as\n\n#Use of the ReverseProxy\n\nAs we already identified, the sole purpose of the load balancer is to route traffic to different backends and return the results to the original client.\n\nWhich is exactly what we want. There is no need to reinvent the wheel. We can simply relay our original requests through the .\n\nWith we can initialize a reverse proxy which would relay requests to the passed . In the above example, all the requests are now passed to localhost:8080 and the results are sent back to the original client. You can find more examples here.\n\nIf we take a look at ServeHTTP method signature, it has the signature of an HTTP handler, that's why we could pass it to the in .\n\nYou can find more examples in docs.\n\nFor our simple load balancer we could initiate the with the associated in the , so that will route our requests to the .\n\nWe need to skip dead backends during the next pick. But to do anything we need a way to count.\n\nMultiple clients will connect to the load balancer and when each of them requests a next peer to pass the traffic on race conditions could occur. To prevent it we could lock the with a . But that would be an overkill, besides we don't want to lock the ServerPool at all. We just want to increase the counter by one\n\nTo meet that requirement, the ideal solution is to make this increment atomically. And Go supports that well via package.\n\nIn here, we are increasing the current value by one atomically and returns the index by modding with the length of the slice. Which means the value always will be between 0 and length of the slice. In the end, we are interested in a particular index, not the total count.\n\nWe already know that our requests are routed in a cycle for each backend. All we have to skip dead ones, that's it.\n\nalways return a value that's capped between 0 and the length of the slice. At any point, we get a next peer and if it's not alive we would have to search through the slice in a cycle.\n\nAs shown in the figure above, we want to traverse from next to the entire list, which can be done simply by traversing But to pick an index, we want to cap it between slice length. It can be easily done with modding operation.\n\nAfter we find a working backend through the search, we mark it as the current one.\n\nBelow you can see the code for the above operation.\n\nThere is a serious issue we need to consider. Our structure has a variable which could be modified or accessed by different goroutines same time.\n\nWe know there would be more goroutines reading from this rather than writing to it. So we have picked to serialize the access to the .\n\nWith all the background we created, we can formulate the following simple method to load balance our requests. It will only fail when our all backends are offline.\n\nThis method can be simply passed as a to the http server.\n\nOur current has a serious issue. We don't know if a backend is healthy or not. To know this we have to try out a backend and check whether it is alive.\n\nWe can do this in two ways,\n• Active: While performing the current request, we find the selected backend is unresponsive, mark it as down.\n• Passive: We can ping backends on fixed intervals and check status\n\ntriggers a callback function, on any error. We can use that to detect any failure. Here is the implementation\n\nIn here we leverage the power of closures to design this error handler. It allows us to capture outer variables like server url into our method. It will check for existing retry count and if it is less than 3, we again send the same request to the same backend. The reason behind this is due to temporary errors the server may reject your requests and it may be available after a short delay(possibly the server ran out of sockets to accept more clients). So we have put a timer to delay the retry for around 10 milliseconds. We increases the retry count with every request.\n\nAfter every retry failed, we mark this backend as down.\n\nNext thing we want to do is attempting a new backend to the same request. We do it by keeping a count of the attempts using the context package. After increasing the attempt count, we pass it back to to pick a new peer to process the request.\n\nNow we can't do this indefinitely, thus we need to check from whether the maximum attempts already taken before processing the request further.\n\nWe can simply get the attempt count from the request and if it has exceeded the max count, eliminate the request.\n\npackage allows you to store useful data in an Http request. We heavily utilized this to track request specific data such as Attempt count and Retry count.\n\nFirst, we need to specify keys for the context. It is recommended to use non-colliding integer keys rather than strings. Go provides keyword to implement constants incrementally, each containing a unique value. That is a perfect solution defining integer keys.\n\nThen we can retrieve the value as usually we do with a HashMap like follows. The default return value may depend on the use case.\n\nPassive health checks allow to recover dead backends or identify them. We ping the backends with fixed intervals to check their status.\n\nTo ping, we try to establish a TCP connection. If the backend responses, we mark it as alive. This method can be changed to call a specific endpoint like if you like. Make sure to close the connection once it established to reduce the additional load in the server. Otherwise, it will try to maintain the connection and it would run out of resources eventually.\n\nNow we can iterate the servers and mark their status like follows,\n\nTo run this periodically we can start a timer in Go. Once a timer created it allows you to listen for the event using a channel.\n\nIn the above snippet, channel will return a value per 20s. allows to detect this event. waits until at least one case statement could be executed if there is no case.\n\nWe covered a lot of stuff in this article.\n\nThere is a lot we can do to improve our tiny load balancer.\n• Use a heap for sort out alive backends to reduce search surface\n\nYou can find the source code to repository here.\n\nThank you for reading this article 😄"
    },
    {
        "link": "https://linkedin.com/pulse/load-balancing-golang-david-dut",
        "document": "Load balancing is the process of efficiently distributing incoming network traffic across a group of backend servers. Normally I would go about this with nginx or HAproxy but decided to try it out with golang. I believe its possible with python too, will look into that hopefully.\n\nIn an instance where there are constant requests from users mostly common with banking systems etc, having a traffic ‘cop’ in between the user requests goes a long way to efficiently maximize the requests to maximize on speed and capacity utilization to ensure no server is overworked. If one server goes down, the load balancer redirects traffic to the remaining online servers.\n\nIn the above instance, when a user makes a request, it goes through the load balancer to determine which server is available.\n\nA reverse proxy is required in this as well for security. We are using the http util package to create the reverse proxy. The reverse proxy redirects the request while hiding the address of the server\n\ntype simpleServer struct addr string proxy *httputil.ReverseProxy } func newSimpleServer(addr string) *simpleServer { serverUrl, err := url.Parse(addr) handleErr(err) return &simpleServer{ addr: addr, proxy: httputil.NewSingleHostReverseProxy(serverUrl), } } The loadbalancer will be implemented as a struct with a port, server and roundrobincount to check between the alive servers. type LoadBalancer struct { port string roundRobinCount int servers []Server } func NewLoadBalancer(port string, servers []Server) *LoadBalancer { return &LoadBalancer{ port: port, roundRobinCount: 0, servers: servers, } }{\n\nWe also create a function to create a new loadbalancer and server based on the struct.\n• isAlive method checks if the server is up or not and\n• Get address method to get address of the server\n\nWe have a main function which creates a server list and calls the server proxy function to get the next available server. Thus checks if the server is alive through roundrobin."
    }
]