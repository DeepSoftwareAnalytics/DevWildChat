[
    {
        "link": "https://docs.python.org/3/library/json.html",
        "document": "JSON (JavaScript Object Notation), specified by RFC 7159 (which obsoletes RFC 4627) and by ECMA-404, is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript ).\n\nexposes an API familiar to users of the standard library and modules.\n\nUsing from the shell to validate and pretty-print:\n\nSerialize obj as a JSON formatted stream to fp (a -supporting file-like object) using this Python-to-JSON conversion table. Unlike and , JSON is not a framed protocol, so trying to serialize multiple objects with repeated calls to using the same fp will result in an invalid JSON file.\n• None obj (object) – The Python object to be serialized.\n• None fp (file-like object) – The file-like object obj will be serialized to. The module always produces objects, not objects, therefore must support input.\n• None skipkeys (bool) – If , keys that are not of a basic type ( , , , , ) will be skipped instead of raising a . Default .\n• None ensure_ascii (bool) – If (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If , these characters will be outputted as-is.\n• None check_circular (bool) – If , the circular reference check for container types is skipped and a circular reference will result in a (or worse). Default .\n• None allow_nan (bool) – If , serialization of out-of-range values ( , , ) will result in a , in strict compliance with the JSON specification. If (the default), their JavaScript equivalents ( , , ) are used.\n• None cls (a subclass) – If set, a custom JSON encoder with the method overridden, for serializing into custom datatypes. If (the default), is used.\n• None indent (int | str | None) – If a positive integer or string, JSON array elements and object members will be pretty-printed with that indent level. A positive integer indents that many spaces per level; a string (such as ) is used to indent each level. If zero, negative, or (the empty string), only newlines are inserted. If (the default), the most compact representation is used.\n• None separators (tuple | None) – A two-tuple: . If (the default), separators defaults to if indent is , and otherwise. For the most compact JSON, specify to eliminate whitespace.\n• None default (callable | None) – A function that is called for objects that can’t otherwise be serialized. It should return a JSON encodable version of the object or raise a . If (the default), is raised.\n• None sort_keys (bool) – If , dictionaries will be outputted sorted by key. Default . Changed in version 3.2: Allow strings for indent in addition to integers. Changed in version 3.4: Use as default if indent is not . Changed in version 3.6: All optional parameters are now keyword-only. Serialize obj to a JSON formatted using this conversion table. The arguments have the same meaning as in . Keys in key/value pairs of JSON are always of the type . When a dictionary is converted into JSON, all the keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON and then back into a dictionary, the dictionary may not equal the original one. That is, if x has non-string keys. Deserialize fp to a Python object using the JSON-to-Python conversion table.\n• None fp (file-like object) – A -supporting text file or binary file containing the JSON document to be deserialized.\n• None cls (a subclass) – If set, a custom JSON decoder. Additional keyword arguments to will be passed to the constructor of cls. If (the default), is used.\n• None object_hook (callable | None) – If set, a function that is called with the result of any object literal decoded (a ). The return value of this function will be used instead of the . This feature can be used to implement custom decoders, for example JSON-RPC class hinting. Default .\n• None object_pairs_hook (callable | None) – If set, a function that is called with the result of any object literal decoded with an ordered list of pairs. The return value of this function will be used instead of the . This feature can be used to implement custom decoders. If object_hook is also set, object_pairs_hook takes priority. Default .\n• None parse_float (callable | None) – If set, a function that is called with the string of every JSON float to be decoded. If (the default), it is equivalent to . This can be used to parse JSON floats into custom datatypes, for example .\n• None parse_int (callable | None) – If set, a function that is called with the string of every JSON int to be decoded. If (the default), it is equivalent to . This can be used to parse JSON integers into custom datatypes, for example .\n• None parse_constant (callable | None) – If set, a function that is called with one of the following strings: , , or . This can be used to raise an exception if invalid JSON numbers are encountered. Default .\n• None JSONDecodeError – When the data being deserialized is not a valid JSON document.\n• None UnicodeDecodeError – When the data being deserialized does not contain UTF-8, UTF-16 or UTF-32 encoded data.\n• None All optional parameters are now keyword-only.\n• None fp can now be a binary file. The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.11: The default parse_int of now limits the maximum length of the integer string via the interpreter’s integer string conversion length limitation to help avoid denial of service attacks. Identical to , but instead of a file-like object, deserialize s (a , or instance containing a JSON document) to a Python object using this conversion table. Changed in version 3.6: s can now be of type or . The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.9: The keyword argument encoding has been removed.\n\nPerforms the following translations in decoding by default: It also understands , , and as their corresponding values, which is outside the JSON spec. object_hook is an optional function that will be called with the result of every JSON object decoded and its return value will be used in place of the given . This can be used to provide custom deserializations (e.g. to support JSON-RPC class hinting). object_pairs_hook is an optional function that will be called with the result of every JSON object decoded with an ordered list of pairs. The return value of object_pairs_hook will be used instead of the . This feature can be used to implement custom decoders. If object_hook is also defined, the object_pairs_hook takes priority. parse_float is an optional function that will be called with the string of every JSON float to be decoded. By default, this is equivalent to . This can be used to use another datatype or parser for JSON floats (e.g. ). parse_int is an optional function that will be called with the string of every JSON int to be decoded. By default, this is equivalent to . This can be used to use another datatype or parser for JSON integers (e.g. ). parse_constant is an optional function that will be called with one of the following strings: , , . This can be used to raise an exception if invalid JSON numbers are encountered. If strict is false ( is the default), then control characters will be allowed inside strings. Control characters in this context are those with character codes in the 0–31 range, including (tab), , and . If the data being deserialized is not a valid JSON document, a will be raised. Changed in version 3.6: All parameters are now keyword-only. Return the Python representation of s (a instance containing a JSON document). will be raised if the given JSON document is not valid. Decode a JSON document from s (a beginning with a JSON document) and return a 2-tuple of the Python representation and the index in s where the document ended. This can be used to decode a JSON document from a string that may have extraneous data at the end. Supports the following objects and types by default: Changed in version 3.4: Added support for int- and float-derived Enum classes. To extend this to recognize other objects, subclass and implement a method with another method that returns a serializable object for if possible, otherwise it should call the superclass implementation (to raise ). If skipkeys is false (the default), a will be raised when trying to encode keys that are not , , or . If skipkeys is true, such items are simply skipped. If ensure_ascii is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is. If check_circular is true (the default), then lists, dicts, and custom encoded objects will be checked for circular references during encoding to prevent an infinite recursion (which would cause a ). Otherwise, no such check takes place. If allow_nan is true (the default), then , , and will be encoded as such. This behavior is not JSON specification compliant, but is consistent with most JavaScript based encoders and decoders. Otherwise, it will be a to encode such floats. If sort_keys is true (default: ), then the output of dictionaries will be sorted by key; this is useful for regression tests to ensure that JSON serializations can be compared on a day-to-day basis. If indent is a non-negative integer or string, then JSON array elements and object members will be pretty-printed with that indent level. An indent level of 0, negative, or will only insert newlines. (the default) selects the most compact representation. Using a positive integer indent indents that many spaces per level. If indent is a string (such as ), that string is used to indent each level. Changed in version 3.2: Allow strings for indent in addition to integers. If specified, separators should be an tuple. The default is if indent is and otherwise. To get the most compact JSON representation, you should specify to eliminate whitespace. Changed in version 3.4: Use as default if indent is not . If specified, default should be a function that gets called for objects that can’t otherwise be serialized. It should return a JSON encodable version of the object or raise a . If not specified, is raised. Changed in version 3.6: All parameters are now keyword-only. Implement this method in a subclass such that it returns a serializable object for o, or calls the base implementation (to raise a ). For example, to support arbitrary iterators, you could implement like this: # Let the base class default method raise the TypeError Return a JSON string representation of a Python data structure, o. For example: Encode the given object, o, and yield each string representation as available. For example:\n\nThe JSON format is specified by RFC 7159 and by ECMA-404. This section details this module’s level of compliance with the RFC. For simplicity, and subclasses, and parameters other than those explicitly mentioned, are not considered. This module does not comply with the RFC in a strict fashion, implementing some extensions that are valid JavaScript but not valid JSON. In particular:\n• None Infinite and NaN number values are accepted and output;\n• None Repeated names within an object are accepted, and only the value of the last name-value pair is used. Since the RFC permits RFC-compliant parsers to accept input texts that are not RFC-compliant, this module’s deserializer is technically RFC-compliant under default settings. The RFC requires that JSON be represented using either UTF-8, UTF-16, or UTF-32, with UTF-8 being the recommended default for maximum interoperability. As permitted, though not required, by the RFC, this module’s serializer sets ensure_ascii=True by default, thus escaping the output so that the resulting strings only contain ASCII characters. Other than the ensure_ascii parameter, this module is defined strictly in terms of conversion between Python objects and , and thus does not otherwise directly address the issue of character encodings. The RFC prohibits adding a byte order mark (BOM) to the start of a JSON text, and this module’s serializer does not add a BOM to its output. The RFC permits, but does not require, JSON deserializers to ignore an initial BOM in their input. This module’s deserializer raises a when an initial BOM is present. The RFC does not explicitly forbid JSON strings which contain byte sequences that don’t correspond to valid Unicode characters (e.g. unpaired UTF-16 surrogates), but it does note that they may cause interoperability problems. By default, this module accepts and outputs (when present in the original ) code points for such sequences. The RFC does not permit the representation of infinite or NaN number values. Despite that, by default, this module accepts and outputs , , and as if they were valid JSON number literal values: # Neither of these calls raises an exception, but the results are not valid JSON In the serializer, the allow_nan parameter can be used to alter this behavior. In the deserializer, the parse_constant parameter can be used to alter this behavior. The RFC specifies that the names within a JSON object should be unique, but does not mandate how repeated names in JSON objects should be handled. By default, this module does not raise an exception; instead, it ignores all but the last name-value pair for a given name: The object_pairs_hook parameter can be used to alter this behavior. The old version of JSON specified by the obsolete RFC 4627 required that the top-level value of a JSON text must be either a JSON object or array (Python or ), and could not be a JSON null, boolean, number, or string value. RFC 7159 removed that restriction, and this module does not and has never implemented that restriction in either its serializer or its deserializer. Regardless, for maximum interoperability, you may wish to voluntarily adhere to the restriction yourself. Some JSON deserializer implementations may set limits on:\n• None the maximum level of nesting of JSON objects and arrays\n• None the range and precision of JSON numbers\n• None the content and maximum length of JSON strings This module does not impose any such limits beyond those of the relevant Python datatypes themselves or the Python interpreter itself. When serializing to JSON, beware any such limitations in applications that may consume your JSON. In particular, it is common for JSON numbers to be deserialized into IEEE 754 double precision numbers and thus subject to that representation’s range and precision limitations. This is especially relevant when serializing Python values of extremely large magnitude, or when serializing instances of “exotic” numerical types such as .\n\nThe module provides a simple command line interface to validate and pretty-print JSON objects. If the optional and arguments are not specified, and will be used respectively: Changed in version 3.5: The output is now in the same order as the input. Use the option to sort the output of dictionaries alphabetically by key. The JSON file to be validated or pretty-printed: python -m json.tool mp_films.json \"title\": \"And Now for Something Completely Different\", If infile is not specified, read from . Write the output of the infile to the given outfile. Otherwise, write it to . Sort the output of dictionaries alphabetically by key. Disable escaping of non-ascii characters, see for more information."
    },
    {
        "link": "https://realpython.com/python-json",
        "document": "Python’s module provides you with the tools you need to effectively handle JSON data. You can convert Python data types to a JSON-formatted string with or write them to files using . Similarly, you can read JSON data from files with and parse JSON strings with .\n\nJSON, or JavaScript Object Notation, is a widely-used text-based format for data interchange. Its syntax resembles Python dictionaries but with some differences, such as using only double quotes for strings and lowercase for Boolean values. With built-in tools for validating syntax and manipulating JSON files, Python makes it straightforward to work with JSON data.\n\nBy the end of this tutorial, you’ll understand that:\n• JSON in Python is handled using the standard-library module, which allows for data interchange between JSON and Python data types.\n• JSON is a good data format to use with Python as it’s human-readable and straightforward to serialize and deserialize, which makes it ideal for use in APIs and data storage.\n• You write JSON with Python using to serialize data to a file.\n• You can minify and prettify JSON using Python’s module.\n\nSince its introduction, JSON has rapidly emerged as the predominant standard for the exchange of information. Whether you want to transfer data with an API or store information in a document database, it’s likely you’ll encounter JSON. Fortunately, Python provides robust tools to facilitate this process and help you manage JSON data efficiently.\n\nWhile JSON is the most common format for data distribution, it’s not the only option for such tasks. Both XML and YAML serve similar purposes. If you’re interested in how the formats differ, then you can check out the tutorial on how to serialize your data with Python.\n\nThe acronym JSON stands for JavaScript Object Notation. As the name suggests, JSON originated from JavaScript. However, JSON has transcended its origins to become language-agnostic and is now recognized as the standard for data interchange. The popularity of JSON can be attributed to native support by the JavaScript language, resulting in excellent parsing performance in web browsers. On top of that, JSON’s straightforward syntax allows both humans and computers to read and write JSON data effortlessly. To get a first impression of JSON, have a look at this example code: You’ll learn more about the JSON syntax later in this tutorial. For now, recognize that the JSON format is text-based. In other words, you can create JSON files using the code editor of your choice. Once you set the file extension to , most code editors display your JSON data with syntax highlighting out of the box: The screenshot above shows how VS Code displays JSON data using the Bearded color theme. You’ll have a closer look at the syntax of the JSON format next! In the previous section, you got a first impression of how JSON data looks. And as a Python developer, the JSON structure probably reminds you of common Python data structures, like a dictionary that contains a string as a key and a value. If you understand the syntax of a dictionary in Python, you already know the general syntax of a JSON object. Note: Later in this tutorial, you’ll learn that you’re free to use lists and other data types at the top level of a JSON document. The similarity between Python dictionaries and JSON objects is no surprise. One idea behind establishing JSON as the go-to data interchange format was to make working with JSON as convenient as possible, independently of which programming language you use: [A collection of key-value pairs and arrays] are universal data structures. Virtually all modern programming languages support them in one form or another. It makes sense that a data format that is interchangeable with programming languages is also based on these structures. (Source) To explore the JSON syntax further, create a new file named and add a more complex JSON structure as the content of the file: In the code above, you see data about a dog named Frieda, which is formatted as JSON. The top-level value is a JSON object. Just like Python dictionaries, you wrap JSON objects inside curly braces ( ). In line 1, you start the JSON object with an opening curly brace ( ), and then you close the object at the end of line 20 with a closing curly brace ( ). Note: Although whitespace doesn’t matter in JSON, it’s customary for JSON documents to be formatted with two or four spaces to indicate indentation. If the file size of the JSON document is important, then you may consider minifying the JSON file by removing the whitespace. You’ll learn more about minifying JSON data later in the tutorial. Inside the JSON object, you can define zero, one, or more key-value pairs. If you add multiple key-value pairs, then you must separate them with a comma ( ). A key-value pair in a JSON object is separated by a colon ( ). On the left side of the colon, you define a key. A key is a string you must wrap in double quotes ( ). Unlike Python, JSON strings don’t support single quotes ( ). The values in a JSON document are limited to the following data types: Either or without quotes Just like in dictionaries and lists, you’re able to nest data in JSON objects and arrays. For example, you can include an object as the value of an object. Also, you’re free to use any other allowed value as an item in a JSON array. As a Python developer, you may need to pay extra attention to the Boolean values. Instead of using or in title case, you must use the lowercase JavaScript-style Booleans or . Unfortunately, there are some other details in the JSON syntax that you may stumble over as a developer. You’ll have a look at them next. The JSON standard doesn’t allow any comments, trailing commas, or single quotes for strings. This can be confusing to developers who are used to Python dictionaries or JavaScript objects. Here’s a smaller version of the JSON file from before with invalid syntax:\n• Line 5 has a trailing comma after the final key-value pair.\n• Line 10 contains a trailing comma in the array. Using double quotes is something you can get used to as a Python developer. Comments can be helpful in explaining your code, and trailing commas can make moving lines around in your code less fragile. This is why some developers like to use Human JSON (Hjson) or JSON with comments (JSONC). Hjson gives you the freedom to use comments, ditch commas between properties, or create quoteless strings. Apart from the curly braces ( ), the Hjson syntax look like a mix of YAML and JSON. JSONC is a bit stricter than Hjson. Compared to regular JSON, JSONC allows you to use comments and trailing commas. You may have encountered JSONC when editing the file of VS Code. Inside its configuration files, VS Code works in a JSONC mode. For common JSON files, VS Code is more strict and points out JSON syntax errors. If you want to make sure you write valid JSON, then your coding editor can be of great help. The invalid JSON document above contains marks for each occurrence of incorrect JSON syntax: When you don’t want to rely on your code editor, you can also use online tools to verify that the JSON syntax you write is correct. Popular online tools for validating JSON are JSON Lint and JSON Formatter. Later in the tutorial, you’ll learn how to validate JSON documents from the comfort of your terminal. But before that, it’s time to find out how you can work with JSON data in Python.\n\nPython supports the JSON format through the built-in module named . The module is specifically designed for reading and writing strings formatted as JSON. That means you can conveniently convert Python data types into JSON data and the other way around. The act of converting data into the JSON format is referred to as serialization. This process involves transforming data into a series of bytes for storage or transmission over a network. The opposite process, deserialization, involves decoding data from the JSON format back into a usable form within Python. You’ll start with the serialization of Python code into JSON data with the help of the module. One of the most common actions when working with JSON in Python is to convert a Python dictionary into a JSON object. To get an impression of how this works, hop over to your Python REPL and follow along with the code below: After importing the module, you can use to convert a Python dictionary to a JSON-formatted string, which represents a JSON object. It’s important to understand that when you use , you get a Python string in return. In other words, you don’t create any kind of JSON data type. The result is similar to what you’d get if you used Python’s built-in function: Using gets more interesting when your Python dictionary doesn’t contain strings as keys or when values don’t directly translate to a JSON format: In the dictionary, the keys , , and are numbers. Once you use , the dictionary keys become strings in the JSON-formatted string. Note: When you convert a dictionary to JSON, the dictionary keys will always be strings in JSON. The Boolean Python values of your dictionary become JSON Booleans. As mentioned before, the tiny but significant difference between JSON Booleans and Python Booleans is that JSON Booleans are lowercase. The cool thing about Python’s module is that it takes care of the conversion for you. This can come in handy when you’re using variables as dictionary keys: When converting Python data types into JSON, the module receives the evaluated values. While doing so, sticks tightly to the JSON standard. For example, when converting integer keys like to the string . The module allows you to convert common Python data types to JSON. Here’s an overview of all Python data types and values that you can convert to JSON values: Note that different Python data types like lists and tuples serialize to the same JSON data type. This can cause problems when you convert JSON data back to Python, as the data type may not be the same as before. You’ll explore this pitfall later in this tutorial when you learn how to read JSON. Dictionaries are probably the most common Python data type that you’ll use as a top-level value in JSON. But you can convert the data types listed above just as smoothly as dictionaries using . Take a Boolean or a list, for example: A JSON document may contain a single scalar value, like a number, at the top level. That’s still valid JSON. But more often than not, you want to work with a collection of key-value pairs. Similar to how not every data type can be used as a dictionary key in Python, not all keys can be converted into JSON key strings: You can’t use dictionaries, lists, or tuples as JSON keys. For dictionaries and lists, this rule makes sense as they’re not hashable. But even when a tuple is hashable and allowed as a key in a dictionary, you’ll get a when you try to use a tuple as a JSON key: : keys must be str, int, float, bool or None, not tuple By providing the argument, you can prevent getting a when creating JSON data with unsupported Python keys: When you set in to , then Python skips the keys that are not supported and would otherwise raise a . The result is a JSON-formatted string that only contains a subset of the input dictionary. In practice, you usually want your JSON data to resemble the input object as close as possible. So, you must use with caution to not lose information when calling . Note: If you’re ever in a situation where you need to convert an unsupported object into JSON, then you can consider creating a subclass of the and implementing a method. When you use , you can use additional arguments to control the look of the resulting JSON-formatted string. For example, you can sort the dictionary keys by setting the parameter to : When you set to , then Python sorts the keys alphabetically for you when serializing a dictionary. Sorting the keys of a JSON object can come in handy when your dictionary keys formerly represented the column names of a database, and you want to display them in an organized fashion to the user. Another notable parameter of is , which you’ll probably use the most when serializing JSON data. You’ll explore later in this tutorial in the prettify JSON section. When you convert Python data types into the JSON format, you usually have a goal in mind. Most commonly, you’ll use JSON to persist and exchange data. To do so, you need to save your JSON data outside of your running Python program. Conveniently, you’ll explore saving JSON data to a file next. The JSON format can come in handy when you want to save data outside of your Python program. Instead of spinning up a database, you may decide to use a JSON file to store data for your workflows. Again, Python has got you covered. To write Python data into an external JSON file, you use . This is a similar function to the one you saw earlier, but without the s at the end of its name: In lines 3 to 22, you define a dictionary that you write to a JSON file in line 25 using a context manager. To properly indicate that the file contains JSON data, you set the file extension to . When you use , then it’s good practice to define the encoding. For JSON, you commonly want to use as the encoding when reading and writing files: The RFC requires that JSON be represented using either UTF-8, UTF-16, or UTF-32, with UTF-8 being the recommended default for maximum interoperability. (Source) The function has two required arguments:\n• The object you want to write\n• The file you want to write into Other than that, there are a bunch of optional parameters for . The optional parameters of are the same as for . You’ll investigate some of them later in this tutorial when you prettify and minify JSON files.\n\nIn the former sections, you learned how to serialize Python data into JSON-formatted strings and JSON files. Now, you’ll see what happens when you load JSON data back into your Python program. In parallel to and , the library provides two functions to deserialize JSON data into a Python object: As a rule of thumb, you work with when your data is already present in your Python program. You use with external files that are saved on your disk. The conversion from JSON data types and values to Python follows a similar mapping as before when you converted Python objects into the JSON format: When you compare this table to the one in the previous section, you may recognize that Python offers a matching data type for all JSON types. That’s very convenient because this way, you can be sure you won’t lose any information when deserializing JSON data to Python. Note: Deserialization is not the exact reverse of the serialization process. The reason for this is that JSON keys are always strings, and not all Python data types can be converted to JSON data types. This discrepancy means that certain Python objects may not retain their original type when serialized and then deserialized. To get a better feeling for the conversion of data types, you’ll start with serializing a Python object to JSON and then convert the JSON data back to Python. That way, you can spot differences between the Python object you serialize and the Python object you end up with after deserializing the JSON data. To investigate how to load a Python dictionary from a JSON object, revisit the example from before. Start by creating a dictionary and then serialize the Python dictionary to a JSON string using : By passing into , you’re creating a string with a JSON object that you save in . If you want to convert back to a Python dictionary, then you can use : By using , you can convert JSON data back into Python objects. With the knowledge about JSON that you’ve gained so far, you may already suspect that the content of the dictionary is not identical to the content of : The difference between and is subtle but can be impactful in your Python programs. In JSON, the keys must always be strings. When you converted to using , the integer key became the string . When you used , there was no way for Python to know that the string key should be an integer again. That’s why your dictionary key remained a string after deserialization. You’ll investigate a similar behavior by doing another conversion roundtrip with other Python data types! To explore how different data types behave in a roundtrip from Python to JSON and back, take a portion of the dictionary from a former section. Note how the dictionary contains different data types as values: The dictionary contains a bunch of common Python data types as values. For example, a string in line 2, a Boolean in line 3, a in line 7, and a tuple in line 8, just to name a few. Next, convert to a JSON-formatted string and back to Python again. Afterward, have a look at the newly created dictionary: You can convert every JSON data type perfectly into a matching Python data type. The JSON Boolean deserializes into , converts back into , and objects and arrays become dictionaries and lists. Still, there’s one exception that you may encounter in roundtrips: When you serialize a Python tuple, it becomes a JSON array. When you load JSON, a JSON array correctly deserializes into a list because Python has no way of knowing that you want the array to be a tuple. Problems like the one described above can always be an issue when you’re doing data roundtrips. When the roundtrip happens in the same program, you may be more aware of the expected data types. Data type conversions may be even more obfuscated when you’re dealing with external JSON files that originated in another program. You’ll investigate a situation like this next! In a previous section, you created a file that saved a file. If you need to refresh your memory, you can expand the collapsible section below that shows the code again: Take a look at the data types of the dictionary. Is there a data type in a value that the JSON format doesn’t support? When you want to write content to a JSON file, you use . The counterpart to is . As the name suggests, you can use to load a JSON file into your Python program. Jump back into the Python REPL and load the JSON file from before: Just like when writing files, it’s a good idea to use a context manager when reading a file in Python. That way, you don’t need to bother with closing the file again. When you want to read a JSON file, then you use inside the statement’s block. The argument for the function must be either a text file or a binary file. The Python object that you get from depends on the top-level data type of your JSON file. In this case, the JSON file contains an object at the top level, which deserializes into a dictionary. When you deserialize a JSON file as a Python object, then you can interact with it natively—for example, by accessing the value of the key with square bracket notation ( ). Still, there’s a word of caution here. Import the original dictionary from before and compare it to : When you load a JSON file as a Python object, then any JSON data type happily deserializes into Python. That’s because Python knows about all data types that the JSON format supports. Unfortunately, it’s not the same the other way around. As you learned before, there are Python data types like that you can convert into JSON, but you’ll end up with an data type in the JSON file. Once you convert the JSON data back to Python, then an array deserializes into the Python data type. Generally, being cautious about data type conversions should be the concern of the Python program that writes the JSON. With the knowledge you have about JSON files, you can always anticipate which Python data types you’ll end up with as long as the JSON file is valid. If you use , then the content of the file you load must contain valid JSON syntax. Otherwise, you’ll receive a . Luckily, Python caters to you with more tools you can use to interact with JSON. For example, it allows you to check a JSON file’s validity from the convenience of the terminal.\n\nSo far, you’ve explored the JSON syntax and have already spotted some common JSON pitfalls like trailing commas and single quotes for strings. When writing JSON, you may have also spotted some annoying details. For example, neatly indented Python dictionaries end up being a blob of JSON data. In the last section of this tutorial, you’ll try out some techniques to make your life easier as you work with JSON data in Python. To start, you’ll give your JSON object a well-deserved glow-up. One huge advantage of the JSON format is that JSON data is human-readable. Even more so, JSON data is human-writable. This means you can open a JSON file in your favorite text editor and change the content to your liking. Well, that’s the idea, at least! Editing JSON data by hand is not particularly easy when your JSON data looks like this in the text editor: Even with word wrapping and syntax highlighting turned on, JSON data is hard to read when it’s a single line of code. And as a Python developer, you probably miss some whitespace. But worry not, Python has got you covered! When you call or to serialize a Python object, then you can provide the argument. Start by trying out with different indentation levels: The default value for is . When you call without or with as a value, you’ll end up with one line of a compact JSON-formatted string. If you want linebreaks in your JSON string, then you can set to or provide an empty string. Although probably less useful, you can even provide a negative number as the indentation or any other string. More commonly, you’ll provide values like or for : When you use positive integers as the value for when calling , then you’ll indent every level of the JSON object with the given count as spaces. Also, you’ll have newlines for each key-value pair. Note: To actually see the whitespace in the REPL, you can wrap the calls in function calls. The parameter works exactly the same for as it does for . Go ahead and write the dictionary into a JSON file with an indentation of spaces: When you set the indentation level when serializing JSON data, then you end up with prettified JSON data. Have a look at how the file looks in your editor: Python can work with JSON files no matter how they’re indented. As a human, you probably prefer a JSON file that contains newlines and is neatly indented. A JSON file that looks like this is way more convenient to edit. The convenience of being able to edit JSON data in the editor comes with a risk. When you move key-value pairs around or add strings with one quote instead of two, you end up with an invalid JSON. To swiftly check if a JSON file is valid, you can leverage Python’s . You can run the module as an executable in the terminal using the switch. To see in action, also provide as the positional argument: When you run only with an option, then Python validates the JSON file and outputs the JSON file’s content in the terminal if the JSON is valid. Running in the example above means that contains valid JSON syntax. Note: The prints the JSON data with an indentation of 4 by default. You’ll explore this behavior in the next section. To make complain, you need to invalidate your JSON document. You can make the JSON data of invalid by removing the comma ( ) between the key-value pairs: After saving , run again to validate the file: The module successfully stumbles over the missing comma in . Python notices that there’s a delimiter missing once the property name enclosed in double quotes starts in line 3 at position 5. Go ahead and try fixing the JSON file again. You can also be creative with invalidating and check how reports your error. But keep in mind that only reports the first error. So you may need to go back and forth between fixing a JSON file and running . Once is valid, you may notice that the output always looks the same. Of course, like any well-made command-line interface, offers you some options to control the program. In the previous section, you used to validate a JSON file. When the JSON syntax was valid, showed the content with newlines and an indentation of four spaces. To control how prints the JSON, you can set the option. If you followed along with the tutorial, then you’ve got a file that doesn’t contain newlines or indentation. Alternatively, you can download in the materials by clicking the link below: Free Bonus: Click here to download the free sample code that shows you how to work with JSON data in Python. When you pass in to , then you can pretty print the content of the JSON file in your terminal. When you set , then you can control which indentation level uses to display the code: Seeing the prettified JSON data in the terminal is nifty. But you can step up your game even more by providing another option to the run! By default, writes the output to , just like you commonly do when calling the function. But you can also redirect the output of into a file by providing a positional argument: With as the value of the option, you write the output into the JSON file instead of showing the content in the terminal. If the file doesn’t exist yet, then Python creates the file on the way. If the target file already exists, then you overwrite the file with the new content. Note: You can prettify a JSON file in place by using the same file as and arguments. You can verify that the file exists by running the terminal command: The whitespace you added to comes with a price. Compared to the original, unindented file, the file size of is now around double that. Here, the 308-byte increase may not be significant. But when you’re dealing with big JSON data, then a good-looking JSON file will take up quite a bit of space. Having a small data footprint is especially useful when serving data over the web. Since the JSON format is the de facto standard for exchanging data over the web, it’s worth keeping the file size as small as possible. And again, Python’s has got your back! As you know by now, Python is a great helper when working with JSON. You can minify JSON data with Python in two ways:\n• Use the module in your Python code Before, you used with the option to add whitespace. Instead of using here, you can use provide to do the opposite and remove any whitespace between the key-value pairs of your JSON: After calling the module, you provide a JSON file as the and another JSON file as the . If the target JSON file exists, then you overwrite its contents. Otherwise, you create a new file with the filename you provide. Just like with , you provide the same file as a source and target file to minify the file in-place. In the example above, you minify into . Run the command to see how many bytes you squeezed out of the original JSON file: Compared to , the file size of is 337 bytes smaller. That’s even 29 bytes less than the original file that didn’t contain any indentation. To investigate where Python managed to remove even more whitespace from the original JSON, open the Python REPL again and minify the content of the original file with Python’s module: In the code above, you use Python’s to get the content of as text. Then, you use to deserialize to , which is a Python dictionary. You could use to get a Python dictionary right away, but you need the JSON data as a string first to compare it properly. That’s also why you use to create and then use instead of leveraging directly to save the minified JSON data in . As you learned before, needs JSON data as the first argument and then accepts a value for the indentation. The default value for is , so you could skip setting the argument explicitly like you do above. But with , you’re making your intention clear that you don’t want any indentation, which will be a good thing for others who read your code later. The parameter for allows you to define a tuple with two values:\n• The separator between the key-value pairs or list items. By default, this separator is a comma followed by a space ( ).\n• The separator between the key and the value. By default, this separator is a colon followed by a space ( ). By setting to , you continue to use valid JSON separators. But you tell Python not to add any spaces after the comma ( ) and the colon ( ). That means that the only whitespace left in your JSON data can be whitespace appearing in key names and values. That’s pretty tight! With both and containing your JSON strings, it’s time to compare them: You can already spot the difference between and when you look at the output. You then use the function to verify that the size of is indeed smaller. If you’re curious about why the length of the JSON strings almost exactly matches the file size of the written files, then looking into Unicode & character encodings in Python is a great idea. Both and are excellent helpers when you want to make JSON data look prettier, or if you want to minify JSON data to save some bytes. With the module, you can conveniently interact with JSON data in your Python programs. That’s great when you need to have more control over the way you interact with JSON. The module comes in handy when you want to work with JSON data directly in your terminal."
    },
    {
        "link": "https://geeksforgeeks.org/read-json-file-using-python",
        "document": "The full form of JSON is JavaScript Object Notation. It means that a script (executable) file which is made of text in a programming language, is used to store and transfer the data. Python supports JSON through a built-in package called JSON. To use this feature, we import the JSON package in Python script. The text in JSON is done through quoted-string which contains the value in key-value mapping within { }.\n\nIt’s pretty easy to load a JSON object in Python. Python has a built-in package called JSON, which can be used to work with JSON data. It’s done by using the JSON module, which provides us with a lot of methods which among loads() and load() methods are gonna help us to read the JSON file.\n\nHere we are going to read a JSON file named data.json the screenshot of the file is given below.\n\nDeserialize a JSON String to an Object in Python\n\nThe Deserialization of JSON means the conversion of JSON objects into their respective Python objects. The load()/loads() method is used for it. If you have used JSON data from another program or obtained it as a string format of JSON, then it can easily be deserialized with load()/loads(), which is usually used to load from string, otherwise, the root object is in list or dict. See the following table given below.\n\nIn the below code, firstly we import the JSON module, open the file using the file handling open() function, and then store the data into the variable ‘data’ using the json.load() function. After that, we iterate over the data and print it.\n\nThis example shows reading from both string and JSON file using json.loads() method. Firstly, we have a JSON string stored in a variable ‘j_string’ and convert this JSON string into a Python dictionary using json.loads() method that is stored in the variable ‘y’ after that we print it. Secondly, we read JSON String stored in a file using json.loads() for that we first convert the JSON file into a string using the file handling same as in the above example and then convert it into the string using read() function and rest of the procedure is same as we follow before using json.loads() method.\n\nExample: Here in the output we can see both the output of the reading string and file using json.loads() method\n\nHow to convert the JSON data into Python objects?\n\nWhat is the best Python library for reading JSON files?\n\nHow to read nested JSON in Python?"
    },
    {
        "link": "https://zyte.com/blog/json-parsing-with-python",
        "document": "JSON (JavaScript Object Notation) is a text-based data format used for exchanging and storing data between web applications. It simplifies the data transmission process between different programming languages and platforms.\n\nThe has become increasingly popular in recent years. It’s a simple and flexible way of representing data that can be easily understood and parsed by both humans and machines. JSON consists of key-value pairs enclosed in curly braces, separated by a colon.\n\nPython provides various and manipulating JSON data, making it a popular choice for data analysts, web developers, and data scientists.\n\nIn this guide, we’ll explore the syntax and data types of JSON, as well as the Python libraries and methods used for parsing JSON data, including more advanced options like JMESPath and ChompJS, which are very useful for web scraping data."
    },
    {
        "link": "https://w3schools.com/python/python_json.asp",
        "document": "JSON is a syntax for storing and exchanging data.\n\nPython has a built-in package called , which can be used to work with JSON data.\n\nIf you have a JSON string, you can parse it by using the method.\n\nIf you have a Python object, you can convert it into a JSON string by using the method.\n\nYou can convert Python objects of the following types, into JSON strings:\n\nWhen you convert from Python to JSON, Python objects are converted into the JSON (JavaScript) equivalent:\n\nThe example above prints a JSON string, but it is not very easy to read, with no indentations and line breaks.\n\nThe method has parameters to make it easier to read the result:\n\nYou can also define the separators, default value is (\", \", \": \"), which means using a comma and a space to separate each object, and a colon and a space to separate keys from values:\n\nThe method has parameters to order the keys in the result:\n\nUse the parameter to specify if the result should be sorted or not: Try it Yourself »"
    },
    {
        "link": "https://stackoverflow.com/questions/73766578/reading-multiple-json-files-in-python-using-jupiter-notebook",
        "document": "I am trying to read a folder containing multiple JSON files, for example l am trying to analyze the first JSON file in the folder but getting errors.\n\nThis is code for the location and importing the first file\n\nHowever, l am getting the following error"
    },
    {
        "link": "https://stackoverflow.com/questions/12451431/loading-and-parsing-a-json-file-with-multiple-json-objects",
        "document": "Just like Martijn Pieters' answer but maybe a bit more pythonic, and most of all, which enables streaming of data (see second part of the answer):\n\nThe function returns an iterator that applies to every item of , yielding the results (cf map() python doc).\n\n And the transforms this iterator into... a list :)\n\n But you can imagine to directly use the iterator returned by map instead: it iterates over each of your json lines. Note that in that case you need to do it in the context: that is the strength of this approach, the json lines are not fully loaded in a list, they are streamed: the map function read each line of the file when is called by the . \n\n It would give:\n\nAnd I have nothing to add to Martijn's answer for explanations about what is a jsonl (json line by line file) and why use it!"
    },
    {
        "link": "https://realpython.com/python-json",
        "document": "Python’s module provides you with the tools you need to effectively handle JSON data. You can convert Python data types to a JSON-formatted string with or write them to files using . Similarly, you can read JSON data from files with and parse JSON strings with .\n\nJSON, or JavaScript Object Notation, is a widely-used text-based format for data interchange. Its syntax resembles Python dictionaries but with some differences, such as using only double quotes for strings and lowercase for Boolean values. With built-in tools for validating syntax and manipulating JSON files, Python makes it straightforward to work with JSON data.\n\nBy the end of this tutorial, you’ll understand that:\n• JSON in Python is handled using the standard-library module, which allows for data interchange between JSON and Python data types.\n• JSON is a good data format to use with Python as it’s human-readable and straightforward to serialize and deserialize, which makes it ideal for use in APIs and data storage.\n• You write JSON with Python using to serialize data to a file.\n• You can minify and prettify JSON using Python’s module.\n\nSince its introduction, JSON has rapidly emerged as the predominant standard for the exchange of information. Whether you want to transfer data with an API or store information in a document database, it’s likely you’ll encounter JSON. Fortunately, Python provides robust tools to facilitate this process and help you manage JSON data efficiently.\n\nWhile JSON is the most common format for data distribution, it’s not the only option for such tasks. Both XML and YAML serve similar purposes. If you’re interested in how the formats differ, then you can check out the tutorial on how to serialize your data with Python.\n\nThe acronym JSON stands for JavaScript Object Notation. As the name suggests, JSON originated from JavaScript. However, JSON has transcended its origins to become language-agnostic and is now recognized as the standard for data interchange. The popularity of JSON can be attributed to native support by the JavaScript language, resulting in excellent parsing performance in web browsers. On top of that, JSON’s straightforward syntax allows both humans and computers to read and write JSON data effortlessly. To get a first impression of JSON, have a look at this example code: You’ll learn more about the JSON syntax later in this tutorial. For now, recognize that the JSON format is text-based. In other words, you can create JSON files using the code editor of your choice. Once you set the file extension to , most code editors display your JSON data with syntax highlighting out of the box: The screenshot above shows how VS Code displays JSON data using the Bearded color theme. You’ll have a closer look at the syntax of the JSON format next! In the previous section, you got a first impression of how JSON data looks. And as a Python developer, the JSON structure probably reminds you of common Python data structures, like a dictionary that contains a string as a key and a value. If you understand the syntax of a dictionary in Python, you already know the general syntax of a JSON object. Note: Later in this tutorial, you’ll learn that you’re free to use lists and other data types at the top level of a JSON document. The similarity between Python dictionaries and JSON objects is no surprise. One idea behind establishing JSON as the go-to data interchange format was to make working with JSON as convenient as possible, independently of which programming language you use: [A collection of key-value pairs and arrays] are universal data structures. Virtually all modern programming languages support them in one form or another. It makes sense that a data format that is interchangeable with programming languages is also based on these structures. (Source) To explore the JSON syntax further, create a new file named and add a more complex JSON structure as the content of the file: In the code above, you see data about a dog named Frieda, which is formatted as JSON. The top-level value is a JSON object. Just like Python dictionaries, you wrap JSON objects inside curly braces ( ). In line 1, you start the JSON object with an opening curly brace ( ), and then you close the object at the end of line 20 with a closing curly brace ( ). Note: Although whitespace doesn’t matter in JSON, it’s customary for JSON documents to be formatted with two or four spaces to indicate indentation. If the file size of the JSON document is important, then you may consider minifying the JSON file by removing the whitespace. You’ll learn more about minifying JSON data later in the tutorial. Inside the JSON object, you can define zero, one, or more key-value pairs. If you add multiple key-value pairs, then you must separate them with a comma ( ). A key-value pair in a JSON object is separated by a colon ( ). On the left side of the colon, you define a key. A key is a string you must wrap in double quotes ( ). Unlike Python, JSON strings don’t support single quotes ( ). The values in a JSON document are limited to the following data types: Either or without quotes Just like in dictionaries and lists, you’re able to nest data in JSON objects and arrays. For example, you can include an object as the value of an object. Also, you’re free to use any other allowed value as an item in a JSON array. As a Python developer, you may need to pay extra attention to the Boolean values. Instead of using or in title case, you must use the lowercase JavaScript-style Booleans or . Unfortunately, there are some other details in the JSON syntax that you may stumble over as a developer. You’ll have a look at them next. The JSON standard doesn’t allow any comments, trailing commas, or single quotes for strings. This can be confusing to developers who are used to Python dictionaries or JavaScript objects. Here’s a smaller version of the JSON file from before with invalid syntax:\n• Line 5 has a trailing comma after the final key-value pair.\n• Line 10 contains a trailing comma in the array. Using double quotes is something you can get used to as a Python developer. Comments can be helpful in explaining your code, and trailing commas can make moving lines around in your code less fragile. This is why some developers like to use Human JSON (Hjson) or JSON with comments (JSONC). Hjson gives you the freedom to use comments, ditch commas between properties, or create quoteless strings. Apart from the curly braces ( ), the Hjson syntax look like a mix of YAML and JSON. JSONC is a bit stricter than Hjson. Compared to regular JSON, JSONC allows you to use comments and trailing commas. You may have encountered JSONC when editing the file of VS Code. Inside its configuration files, VS Code works in a JSONC mode. For common JSON files, VS Code is more strict and points out JSON syntax errors. If you want to make sure you write valid JSON, then your coding editor can be of great help. The invalid JSON document above contains marks for each occurrence of incorrect JSON syntax: When you don’t want to rely on your code editor, you can also use online tools to verify that the JSON syntax you write is correct. Popular online tools for validating JSON are JSON Lint and JSON Formatter. Later in the tutorial, you’ll learn how to validate JSON documents from the comfort of your terminal. But before that, it’s time to find out how you can work with JSON data in Python.\n\nPython supports the JSON format through the built-in module named . The module is specifically designed for reading and writing strings formatted as JSON. That means you can conveniently convert Python data types into JSON data and the other way around. The act of converting data into the JSON format is referred to as serialization. This process involves transforming data into a series of bytes for storage or transmission over a network. The opposite process, deserialization, involves decoding data from the JSON format back into a usable form within Python. You’ll start with the serialization of Python code into JSON data with the help of the module. One of the most common actions when working with JSON in Python is to convert a Python dictionary into a JSON object. To get an impression of how this works, hop over to your Python REPL and follow along with the code below: After importing the module, you can use to convert a Python dictionary to a JSON-formatted string, which represents a JSON object. It’s important to understand that when you use , you get a Python string in return. In other words, you don’t create any kind of JSON data type. The result is similar to what you’d get if you used Python’s built-in function: Using gets more interesting when your Python dictionary doesn’t contain strings as keys or when values don’t directly translate to a JSON format: In the dictionary, the keys , , and are numbers. Once you use , the dictionary keys become strings in the JSON-formatted string. Note: When you convert a dictionary to JSON, the dictionary keys will always be strings in JSON. The Boolean Python values of your dictionary become JSON Booleans. As mentioned before, the tiny but significant difference between JSON Booleans and Python Booleans is that JSON Booleans are lowercase. The cool thing about Python’s module is that it takes care of the conversion for you. This can come in handy when you’re using variables as dictionary keys: When converting Python data types into JSON, the module receives the evaluated values. While doing so, sticks tightly to the JSON standard. For example, when converting integer keys like to the string . The module allows you to convert common Python data types to JSON. Here’s an overview of all Python data types and values that you can convert to JSON values: Note that different Python data types like lists and tuples serialize to the same JSON data type. This can cause problems when you convert JSON data back to Python, as the data type may not be the same as before. You’ll explore this pitfall later in this tutorial when you learn how to read JSON. Dictionaries are probably the most common Python data type that you’ll use as a top-level value in JSON. But you can convert the data types listed above just as smoothly as dictionaries using . Take a Boolean or a list, for example: A JSON document may contain a single scalar value, like a number, at the top level. That’s still valid JSON. But more often than not, you want to work with a collection of key-value pairs. Similar to how not every data type can be used as a dictionary key in Python, not all keys can be converted into JSON key strings: You can’t use dictionaries, lists, or tuples as JSON keys. For dictionaries and lists, this rule makes sense as they’re not hashable. But even when a tuple is hashable and allowed as a key in a dictionary, you’ll get a when you try to use a tuple as a JSON key: : keys must be str, int, float, bool or None, not tuple By providing the argument, you can prevent getting a when creating JSON data with unsupported Python keys: When you set in to , then Python skips the keys that are not supported and would otherwise raise a . The result is a JSON-formatted string that only contains a subset of the input dictionary. In practice, you usually want your JSON data to resemble the input object as close as possible. So, you must use with caution to not lose information when calling . Note: If you’re ever in a situation where you need to convert an unsupported object into JSON, then you can consider creating a subclass of the and implementing a method. When you use , you can use additional arguments to control the look of the resulting JSON-formatted string. For example, you can sort the dictionary keys by setting the parameter to : When you set to , then Python sorts the keys alphabetically for you when serializing a dictionary. Sorting the keys of a JSON object can come in handy when your dictionary keys formerly represented the column names of a database, and you want to display them in an organized fashion to the user. Another notable parameter of is , which you’ll probably use the most when serializing JSON data. You’ll explore later in this tutorial in the prettify JSON section. When you convert Python data types into the JSON format, you usually have a goal in mind. Most commonly, you’ll use JSON to persist and exchange data. To do so, you need to save your JSON data outside of your running Python program. Conveniently, you’ll explore saving JSON data to a file next. The JSON format can come in handy when you want to save data outside of your Python program. Instead of spinning up a database, you may decide to use a JSON file to store data for your workflows. Again, Python has got you covered. To write Python data into an external JSON file, you use . This is a similar function to the one you saw earlier, but without the s at the end of its name: In lines 3 to 22, you define a dictionary that you write to a JSON file in line 25 using a context manager. To properly indicate that the file contains JSON data, you set the file extension to . When you use , then it’s good practice to define the encoding. For JSON, you commonly want to use as the encoding when reading and writing files: The RFC requires that JSON be represented using either UTF-8, UTF-16, or UTF-32, with UTF-8 being the recommended default for maximum interoperability. (Source) The function has two required arguments:\n• The object you want to write\n• The file you want to write into Other than that, there are a bunch of optional parameters for . The optional parameters of are the same as for . You’ll investigate some of them later in this tutorial when you prettify and minify JSON files.\n\nIn the former sections, you learned how to serialize Python data into JSON-formatted strings and JSON files. Now, you’ll see what happens when you load JSON data back into your Python program. In parallel to and , the library provides two functions to deserialize JSON data into a Python object: As a rule of thumb, you work with when your data is already present in your Python program. You use with external files that are saved on your disk. The conversion from JSON data types and values to Python follows a similar mapping as before when you converted Python objects into the JSON format: When you compare this table to the one in the previous section, you may recognize that Python offers a matching data type for all JSON types. That’s very convenient because this way, you can be sure you won’t lose any information when deserializing JSON data to Python. Note: Deserialization is not the exact reverse of the serialization process. The reason for this is that JSON keys are always strings, and not all Python data types can be converted to JSON data types. This discrepancy means that certain Python objects may not retain their original type when serialized and then deserialized. To get a better feeling for the conversion of data types, you’ll start with serializing a Python object to JSON and then convert the JSON data back to Python. That way, you can spot differences between the Python object you serialize and the Python object you end up with after deserializing the JSON data. To investigate how to load a Python dictionary from a JSON object, revisit the example from before. Start by creating a dictionary and then serialize the Python dictionary to a JSON string using : By passing into , you’re creating a string with a JSON object that you save in . If you want to convert back to a Python dictionary, then you can use : By using , you can convert JSON data back into Python objects. With the knowledge about JSON that you’ve gained so far, you may already suspect that the content of the dictionary is not identical to the content of : The difference between and is subtle but can be impactful in your Python programs. In JSON, the keys must always be strings. When you converted to using , the integer key became the string . When you used , there was no way for Python to know that the string key should be an integer again. That’s why your dictionary key remained a string after deserialization. You’ll investigate a similar behavior by doing another conversion roundtrip with other Python data types! To explore how different data types behave in a roundtrip from Python to JSON and back, take a portion of the dictionary from a former section. Note how the dictionary contains different data types as values: The dictionary contains a bunch of common Python data types as values. For example, a string in line 2, a Boolean in line 3, a in line 7, and a tuple in line 8, just to name a few. Next, convert to a JSON-formatted string and back to Python again. Afterward, have a look at the newly created dictionary: You can convert every JSON data type perfectly into a matching Python data type. The JSON Boolean deserializes into , converts back into , and objects and arrays become dictionaries and lists. Still, there’s one exception that you may encounter in roundtrips: When you serialize a Python tuple, it becomes a JSON array. When you load JSON, a JSON array correctly deserializes into a list because Python has no way of knowing that you want the array to be a tuple. Problems like the one described above can always be an issue when you’re doing data roundtrips. When the roundtrip happens in the same program, you may be more aware of the expected data types. Data type conversions may be even more obfuscated when you’re dealing with external JSON files that originated in another program. You’ll investigate a situation like this next! In a previous section, you created a file that saved a file. If you need to refresh your memory, you can expand the collapsible section below that shows the code again: Take a look at the data types of the dictionary. Is there a data type in a value that the JSON format doesn’t support? When you want to write content to a JSON file, you use . The counterpart to is . As the name suggests, you can use to load a JSON file into your Python program. Jump back into the Python REPL and load the JSON file from before: Just like when writing files, it’s a good idea to use a context manager when reading a file in Python. That way, you don’t need to bother with closing the file again. When you want to read a JSON file, then you use inside the statement’s block. The argument for the function must be either a text file or a binary file. The Python object that you get from depends on the top-level data type of your JSON file. In this case, the JSON file contains an object at the top level, which deserializes into a dictionary. When you deserialize a JSON file as a Python object, then you can interact with it natively—for example, by accessing the value of the key with square bracket notation ( ). Still, there’s a word of caution here. Import the original dictionary from before and compare it to : When you load a JSON file as a Python object, then any JSON data type happily deserializes into Python. That’s because Python knows about all data types that the JSON format supports. Unfortunately, it’s not the same the other way around. As you learned before, there are Python data types like that you can convert into JSON, but you’ll end up with an data type in the JSON file. Once you convert the JSON data back to Python, then an array deserializes into the Python data type. Generally, being cautious about data type conversions should be the concern of the Python program that writes the JSON. With the knowledge you have about JSON files, you can always anticipate which Python data types you’ll end up with as long as the JSON file is valid. If you use , then the content of the file you load must contain valid JSON syntax. Otherwise, you’ll receive a . Luckily, Python caters to you with more tools you can use to interact with JSON. For example, it allows you to check a JSON file’s validity from the convenience of the terminal.\n\nSo far, you’ve explored the JSON syntax and have already spotted some common JSON pitfalls like trailing commas and single quotes for strings. When writing JSON, you may have also spotted some annoying details. For example, neatly indented Python dictionaries end up being a blob of JSON data. In the last section of this tutorial, you’ll try out some techniques to make your life easier as you work with JSON data in Python. To start, you’ll give your JSON object a well-deserved glow-up. One huge advantage of the JSON format is that JSON data is human-readable. Even more so, JSON data is human-writable. This means you can open a JSON file in your favorite text editor and change the content to your liking. Well, that’s the idea, at least! Editing JSON data by hand is not particularly easy when your JSON data looks like this in the text editor: Even with word wrapping and syntax highlighting turned on, JSON data is hard to read when it’s a single line of code. And as a Python developer, you probably miss some whitespace. But worry not, Python has got you covered! When you call or to serialize a Python object, then you can provide the argument. Start by trying out with different indentation levels: The default value for is . When you call without or with as a value, you’ll end up with one line of a compact JSON-formatted string. If you want linebreaks in your JSON string, then you can set to or provide an empty string. Although probably less useful, you can even provide a negative number as the indentation or any other string. More commonly, you’ll provide values like or for : When you use positive integers as the value for when calling , then you’ll indent every level of the JSON object with the given count as spaces. Also, you’ll have newlines for each key-value pair. Note: To actually see the whitespace in the REPL, you can wrap the calls in function calls. The parameter works exactly the same for as it does for . Go ahead and write the dictionary into a JSON file with an indentation of spaces: When you set the indentation level when serializing JSON data, then you end up with prettified JSON data. Have a look at how the file looks in your editor: Python can work with JSON files no matter how they’re indented. As a human, you probably prefer a JSON file that contains newlines and is neatly indented. A JSON file that looks like this is way more convenient to edit. The convenience of being able to edit JSON data in the editor comes with a risk. When you move key-value pairs around or add strings with one quote instead of two, you end up with an invalid JSON. To swiftly check if a JSON file is valid, you can leverage Python’s . You can run the module as an executable in the terminal using the switch. To see in action, also provide as the positional argument: When you run only with an option, then Python validates the JSON file and outputs the JSON file’s content in the terminal if the JSON is valid. Running in the example above means that contains valid JSON syntax. Note: The prints the JSON data with an indentation of 4 by default. You’ll explore this behavior in the next section. To make complain, you need to invalidate your JSON document. You can make the JSON data of invalid by removing the comma ( ) between the key-value pairs: After saving , run again to validate the file: The module successfully stumbles over the missing comma in . Python notices that there’s a delimiter missing once the property name enclosed in double quotes starts in line 3 at position 5. Go ahead and try fixing the JSON file again. You can also be creative with invalidating and check how reports your error. But keep in mind that only reports the first error. So you may need to go back and forth between fixing a JSON file and running . Once is valid, you may notice that the output always looks the same. Of course, like any well-made command-line interface, offers you some options to control the program. In the previous section, you used to validate a JSON file. When the JSON syntax was valid, showed the content with newlines and an indentation of four spaces. To control how prints the JSON, you can set the option. If you followed along with the tutorial, then you’ve got a file that doesn’t contain newlines or indentation. Alternatively, you can download in the materials by clicking the link below: Free Bonus: Click here to download the free sample code that shows you how to work with JSON data in Python. When you pass in to , then you can pretty print the content of the JSON file in your terminal. When you set , then you can control which indentation level uses to display the code: Seeing the prettified JSON data in the terminal is nifty. But you can step up your game even more by providing another option to the run! By default, writes the output to , just like you commonly do when calling the function. But you can also redirect the output of into a file by providing a positional argument: With as the value of the option, you write the output into the JSON file instead of showing the content in the terminal. If the file doesn’t exist yet, then Python creates the file on the way. If the target file already exists, then you overwrite the file with the new content. Note: You can prettify a JSON file in place by using the same file as and arguments. You can verify that the file exists by running the terminal command: The whitespace you added to comes with a price. Compared to the original, unindented file, the file size of is now around double that. Here, the 308-byte increase may not be significant. But when you’re dealing with big JSON data, then a good-looking JSON file will take up quite a bit of space. Having a small data footprint is especially useful when serving data over the web. Since the JSON format is the de facto standard for exchanging data over the web, it’s worth keeping the file size as small as possible. And again, Python’s has got your back! As you know by now, Python is a great helper when working with JSON. You can minify JSON data with Python in two ways:\n• Use the module in your Python code Before, you used with the option to add whitespace. Instead of using here, you can use provide to do the opposite and remove any whitespace between the key-value pairs of your JSON: After calling the module, you provide a JSON file as the and another JSON file as the . If the target JSON file exists, then you overwrite its contents. Otherwise, you create a new file with the filename you provide. Just like with , you provide the same file as a source and target file to minify the file in-place. In the example above, you minify into . Run the command to see how many bytes you squeezed out of the original JSON file: Compared to , the file size of is 337 bytes smaller. That’s even 29 bytes less than the original file that didn’t contain any indentation. To investigate where Python managed to remove even more whitespace from the original JSON, open the Python REPL again and minify the content of the original file with Python’s module: In the code above, you use Python’s to get the content of as text. Then, you use to deserialize to , which is a Python dictionary. You could use to get a Python dictionary right away, but you need the JSON data as a string first to compare it properly. That’s also why you use to create and then use instead of leveraging directly to save the minified JSON data in . As you learned before, needs JSON data as the first argument and then accepts a value for the indentation. The default value for is , so you could skip setting the argument explicitly like you do above. But with , you’re making your intention clear that you don’t want any indentation, which will be a good thing for others who read your code later. The parameter for allows you to define a tuple with two values:\n• The separator between the key-value pairs or list items. By default, this separator is a comma followed by a space ( ).\n• The separator between the key and the value. By default, this separator is a colon followed by a space ( ). By setting to , you continue to use valid JSON separators. But you tell Python not to add any spaces after the comma ( ) and the colon ( ). That means that the only whitespace left in your JSON data can be whitespace appearing in key names and values. That’s pretty tight! With both and containing your JSON strings, it’s time to compare them: You can already spot the difference between and when you look at the output. You then use the function to verify that the size of is indeed smaller. If you’re curious about why the length of the JSON strings almost exactly matches the file size of the written files, then looking into Unicode & character encodings in Python is a great idea. Both and are excellent helpers when you want to make JSON data look prettier, or if you want to minify JSON data to save some bytes. With the module, you can conveniently interact with JSON data in your Python programs. That’s great when you need to have more control over the way you interact with JSON. The module comes in handy when you want to work with JSON data directly in your terminal."
    },
    {
        "link": "https://geeksforgeeks.org/reading-and-writing-json-to-a-file-in-python",
        "document": "The full form of JSON is Javascript Object Notation. It means that a script (executable) file which is made of text in a programming language, is used to store and transfer the data. Python supports JSON through a built-in package called JSON. To use this feature, we import the JSON package in Python script. The text in JSON is done through quoted-string which contains the value in key-value mapping within { }. It is similar to the dictionary in Python.\n\nSerializing JSON refers to the transformation of data into a series of bytes (hence serial) to be stored or transmitted across a network. To handle the data flow in a file, the JSON library in Python uses dump() or dumps() function to convert the Python objects into their respective JSON object, so it makes it easy to write data to files. See the following table given below.\n\nMethod 1: Writing JSON to a file in Python using json.dumps()\n\nThe JSON package in Python has a function called json.dumps() that helps in converting a dictionary to a JSON object. It takes two parameters:\n• dictionary – the name of a dictionary which should be converted to a JSON object.\n• indent – defines the number of units for indentation\n\nAfter converting the dictionary to a JSON object, simply write it to a file using the “write” function.\n\nMethod 2: Writing JSON to a file in Python using json.dump()\n\nAnother way of writing JSON to a file is by using json.dump() method The JSON package has the “dump” function which directly writes the dictionary to a file in the form of JSON, without needing to convert it into an actual JSON object. It takes 2 parameters:\n• dictionary – the name of a dictionary which should be converted to a JSON object.\n• file pointer – pointer of the file opened in write or append mode.\n\nDeserialization is the opposite of Serialization, i.e. conversion of JSON objects into their respective Python objects. The load() method is used for it. If you have used JSON data from another program or obtained it as a string format of JSON, then it can easily be deserialized with load(), which is usually used to load from a string, otherwise, the root object is in a list or Dict.\n\nThe JSON package has json.load() function that loads the JSON content from a JSON file into a dictionary. It takes one parameter:"
    },
    {
        "link": "https://thenybble.de/posts/json-analysis",
        "document": "I’ve had the pleasure of having had to analyse multi-gigabyte JSON dumps in a project context recently. JSON itself is actually a rather pleasant format to consume, as it’s human-readable and there is a lot of tooling available for it. JQ allows expressing sophisticated processing steps in a single command line, and Jupyter with Python and Pandas allow easy interactive analysis to quickly find what you’re looking for.\n\nHowever, with multi-gigabyte files, analysis becomes quite a lot more difficult. Running a single command will take a long time. When you’re ~trial-and-error~iteratively building commands as I do, you’ll quickly grow tired of having to wait about a minute for your command to succeed, only to find out that it didn’t in fact return what you were looking for. Interactive analysis is similar. Reading all 20 gigabyte of JSON will take a fair amount of time. You might find out that the data doesn’t fit into RAM (which it well might, JSON is a human-readable format after all), or end up having to restart your Python kernel, which means you’ll have to endure the loading time again.\n\nOf course, there’s cloud-based offerings that are based on Apache Beam, Flink and many others. However, customer data doesn’t go on cloud services on my authority, so that’s out. Setting up an environment like Flink locally is doable, but a lot of effort for a one-off analysis.\n\nWhile trying to analyse files of this size, I’ve found two ways of doing efficient local processing of very large JSON files that I want to share. One is based on parallelizing the command line with GNU parallel, the other is based on Jupyter with the Dask library.\n\nIn the Beginning was the Command Line: JQ and Parallel#\n\nI try to find low-effort solutions to problems first, and most of the tasks I had for the JSON files were simple transformations that are easily expressible in ’s language. Extracting nested values or searching for specific JSON objects is very easily accomplished. As an example, imagine having 20 Gigabytes of structures like this (I’ve inserted the newlines for readability, the input we’re actually reading is all on one line):\n\nA query like will give you all subarticles having a subsubarticle with a size of “snug”. Running a similar command on a 10-gigabyte JSON file took about three minutes, which isn’t great, especially when you’re impatient (like I happen to be).\n\nLuckily, we can speed this up, if we have some information about the structure of the input file (we know the format is JSON, obviously). We’re using as a filter for single JSON objects, which means that we should be able to efficiently parallelize the search expression. Whenever I have to run shell commands in parallel, I reach for GNU parallel, which can handle shell commands, SSH access to remote servers for a DIY cluster, SQL insertion and lots more.\n\nIn this case, we know that our JSON objects in the file are delimited by a closing curly bracket followed by a newline, one JSON object per line. This means that we can tell to run in parallel on these JSON objects with the switch. Note that you could also tell parallel to interpret as a regular expression, which would allow you to correctly split the pretty-printed example above with a of . This is probably substantially slower, I wouldn’t use a tool that spits out 10 gigabyte of pretty-printed JSON, and if necessary, I would just use to collapse it again.\n\nSpawning a single process for every JSON object would not lead to a speedup (because executing new processes is expensive), which is why we tell to collect complete objects into blocks, and pass those to a process. The optimal block size will depend on the size of the input file, the throughput of your disk, your number of processors, and others. I’ve had sufficient speedup with a block size of 100 megabyte, but choosing a larger block size would probably not hurt. can split up files in an efficient manner using the option (for the reasons as to why this is more efficient, see here), so we can use this to provide input to our parallel processes.\n\nFinally, the worst part of every parallel job: Ordering the results. has lots of options for this. We want to keep our output in the original order, so we add the argument. The default configuration, , would buffer input for each job until it is finished. Depending on your exact query, this will require buffering to disk if the query output can’t fit in main memory. This is probably not the case, so using would be fine. However, we can do slightly better with , which, in combination with , starts output for the first job immediately, and buffers output for other jobs. This should require slightly less disk space or memory, at the cost of some CPU time. Both will be fine for “normal” queries, but do some benchmarking if your query generates large amounts of output.\n\nFinally, provide the input file with . Putting it all together, we get our finished command line:\n\nThis will run in parallel on your file on blocks of 100 megabyte, always containing complete JSON objects. You’ll get your query results in the original order, but much quicker than in the non-parallel case. Running on a 8-core/16-thread Ryzen processor, parallelizing the query from above leads to a run time of 30 seconds, which is a speedup of roughly 6. Not bad for some shell magic, eh? And here’s a screenshot showing glorious parallelization.\n\nAlso note that this approach generalizes to other text-based formats. If you have 10 gigabyte of CSV, you can use Miller for processing. For binary formats, you could use fq if you can find a workable record separator.\n\nUsing GNU parallel is nifty, but for interactive analyses, I prefer Python and Jupyter notebooks. One way of using a notebook with such a large file would be preprocessing it with the magic from the previous section. However, I prefer not having to switch environments while doing data analysis, and using your shell history as documentation is not a sustainable practice (ask me how I know).\n\nNaively reading 9 gigabytes of JSON data with Pandas’ quickly exhausts my 30 gigabytes of RAM, so there is clearly need for some preprocessing. Again, doing this preprocessing in an iterative fashion would be painful if we had to process the whole JSON file again to see our results. We could write some code to only process the first lines of the JSON file, but I was looking for a more general solution. I’ve mentioned Beam and Flink above, but had no success trying to get a local setup to work.\n\nDask does what we want: It can partition large datasets, process the partitions in parallel, and merge them back together to get our final output. Let’s create a new Python environment with , install the necessary dependencies and launch a Jupyter notebook:\n\nIf is not available, follow the installation instructions to get it set up on your machine. Now, we can get started. We import necessary packages and start a local cluster.\n\nThe dashboard link provides a dashboard that shows the activity going on in your local cluster in detail. Every distributed operation we’ll run will use this client. It’s almost like magic!\n\nNow, we can use that local cluster to read our large JSON file into a bag. A bag is an unordered structure, unlike a dataframe, which is ordered and partitioned by its index. It works well with unstructured and nested data, which is why we’re using it here to preprocess our JSON. We can read a text file into a partitioned bag with and the argument. Note that we’re loading into JSON immediately, as we know the payload is valid JSON.\n\nYou can get the first few items in the bag with . This will allow you to look at the data and do preprocessing. You can interactively test the preprocessing by adding extra map steps:\n\nThis will give you the first five article codes in the bag. Note that the function wasn’t called on every element on the bag, only the first five elements, just enough to give us our answer. This is the good thing about using Dask: You’re only running code as needed, which is very useful for finding suitable preprocessing steps.\n\nOnce you have a suitable pipeline, you can compute the full data with or turn it into a Dask dataframe with . Let’s say we wanted to extract the sizes and codes of our subsubarticles from the example above (it’s a very small file, but it’s an illustrative example only). Then, we’d do something like the following:\n\nThis will run the provided lambda function on each element of the bag, parallel for each partition. will split the list into distinct bag items to allow us to create a non-nested dataframe. Finally, will convert our data into a Dask dataframe. Calling will execute our pipeline for the whole dataset, which might take a while. However, due to the “laziness” of Dask, you’re able to inspect the intermediate steps in the pipeline interactively (with and ). Additionally, Dask will take care of restarting workers and spilling data to disk if memory is not sufficient. Once we have a Dask dataframe, we can dump it into a more efficient file format like Parquet, which we can then use in the rest of our Python code, either in parallel or in “regular” Pandas.\n\nFor 9 gigabytes of JSON, my Laptop was able to execute a data processing pipeline similar to the one above in 50 seconds. Additionally, I was able to build the pipeline in “standard” Python interactively, similar to how I build my queries.\n\nDask has a whole bunch of extra functionality for parallel processing of data, but I hope you’ve gotten a basic understanding of how it works. Compared to , you have the full power of Python on your hands, which make it easier to combine data from different sources (files and a database, for example), which is where the shell-based solution starts to struggle.\n\nI hope you’ve seen that processing large files doesn’t necessarily have to take place in the cloud. A recent laptop or desktop machine is often good enough to run preprocessing and statistics tasks with a bit of tooling. For me, that tooling consists of to answer quick questions during debugging and for deciding on ways to implement features, and Dask to do more involved exploratory data analysis."
    }
]