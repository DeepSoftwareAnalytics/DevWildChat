[
    {
        "link": "https://docs.docker.com/engine/network",
        "document": "Container networking refers to the ability for containers to connect to and communicate with each other, or to non-Docker workloads.\n\nContainers have networking enabled by default, and they can make outgoing connections. A container has no information about what kind of network it's attached to, or whether their peers are also Docker workloads or not. A container only sees a network interface with an IP address, a gateway, a routing table, DNS services, and other networking details. That is, unless the container uses the network driver.\n\nThis page describes networking from the point of view of the container, and the concepts around container networking. This page doesn't describe OS-specific details about how Docker networks work. For information about how Docker manipulates rules on Linux, see Packet filtering and firewalls.\n\nYou can create custom, user-defined networks, and connect multiple containers to the same network. Once connected to a user-defined network, containers can communicate with each other using container IP addresses or container names.\n\nThe following example creates a network using the network driver and running a container in the created network:\n\nThe following network drivers are available by default, and provide core networking functionality:\n\nFor more information about the different drivers, see Network drivers overview.\n\nA container can be connected to multiple networks.\n\nFor example, a frontend container may be connected to a bridge network with external access, and a network to communicate with containers running backend services that do not need external network access.\n\nA container may also be connected to different types of network. For example, an network to provide internet access, and a network for access to local services.\n\nWhen sending packets, if the destination is an address in a directly connected network, packets are sent to that network. Otherwise, packets are sent to a default gateway for routing to their destination. In the example above, the network's gateway must be the default gateway.\n\nThe default gateway is selected by Docker, and may change whenever a container's network connections change. To make Docker choose a specific default gateway when creating the container or connecting a new network, set a gateway priority. See option for the and commands.\n\nThe default is and the gateway in the network with the highest priority is the default gateway. So, when a network should always be the default gateway, it is enough to set its to .\n\nIn addition to user-defined networks, you can attach a container to another container's networking stack directly, using the flag format.\n\nThe following flags aren't supported for containers using the networking mode:\n\nThe following example runs a Redis container, with Redis binding to , then running the command and connecting to the Redis server over the interface.\n\nBy default, when you create or run a container using or , containers on bridge networks don't expose any ports to the outside world. Use the or flag to make a port available to services outside the bridge network. This creates a firewall rule in the host, mapping a container port to a port on the Docker host to the outside world. Here are some examples:\n\nIf you want to make a container accessible to other containers, it isn't necessary to publish the container's ports. You can enable inter-container communication by connecting the containers to the same network, usually a bridge network.\n\nPorts on the host's IPv6 addresses will map to the container's IPv4 address if no host IP is given in a port mapping, the bridge network is IPv4-only, and (default).\n\nFor more information about port mapping, including how to disable it and use direct routing to containers, see packet filtering and firewalls.\n\nWhen creating a network, IPv4 address allocation is enabled by default, it can be disabled using . IPv6 address allocation can be enabled using .\n\nBy default, the container gets an IP address for every Docker network it attaches to. A container receives an IP address out of the IP subnet of the network. The Docker daemon performs dynamic subnetting and IP address allocation for containers. Each network also has a default subnet mask and gateway.\n\nYou can connect a running container to multiple networks, either by passing the flag multiple times when creating the container, or using the command for already running containers. In both cases, you can use the or flags to specify the container's IP address on that particular network.\n\nIn the same way, a container's hostname defaults to be the container's ID in Docker. You can override the hostname using . When connecting to an existing network using , you can use the flag to specify an additional network alias for the container on that network.\n\nContainers use the same DNS servers as the host by default, but you can override this with .\n\nBy default, containers inherit the DNS settings as defined in the configuration file. Containers that attach to the default network receive a copy of this file. Containers that attach to a custom network use Docker's embedded DNS server. The embedded DNS server forwards external DNS lookups to the DNS servers configured on the host.\n\nYou can configure DNS resolution on a per-container basis, using flags for the or command used to start the container. The following table describes the available flags related to DNS configuration.\n\nYour container will have lines in which define the hostname of the container itself, as well as and a few other common things. Custom hosts, defined in on the host machine, aren't inherited by containers. To pass additional hosts into a container, refer to add entries to container hosts file in the reference documentation.\n\nIf your container needs to use a proxy server, see Use a proxy server."
    },
    {
        "link": "https://docs.docker.com/engine/network/links",
        "document": "The flag is a legacy feature of Docker. It may eventually be removed. Unless you absolutely need to continue using it, we recommend that you use user-defined networks to facilitate communication between two containers instead of using . One feature that user-defined networks do not support that you can do with is sharing environment variables between containers. However, you can use other mechanisms such as volumes to share environment variables between containers in a more controlled way. See Differences between user-defined bridges and the default bridge for some alternatives to using .\n\nThe information in this section explains legacy container links within the Docker default network which is created automatically when you install Docker.\n\nBefore the Docker networks feature, you could use the Docker link feature to allow containers to discover each other and securely transfer information about one container to another container. With the introduction of the Docker networks feature, you can still create links but they behave differently between default network and user defined networks.\n\nThis section briefly discusses connecting via a network port and then goes into detail on container linking in default network.\n\nLet's say you used this command to run a simple Python Flask application:\n\nWhen that container was created, the flag was used to automatically map any network port inside it to a random high port within an ephemeral port range on your Docker host. Next, when was run, you saw that port 5000 in the container was bound to port 49155 on the host.\n\nYou also saw how you can bind a container's ports to a specific port using the flag. Here port 80 of the host is mapped to port 5000 of the container:\n\nAnd you saw why this isn't such a great idea because it constrains you to only one container on that specific port.\n\nInstead, you may specify a range of host ports to bind a container port to that is different than the default ephemeral port range:\n\nThis would bind port 5000 in the container to a randomly available port between 8000 and 9000 on the host.\n\nThere are also a few other ways you can configure the flag. By default the flag binds the specified port to all interfaces on the host machine. But you can also specify a binding to a specific interface, for example only to the .\n\nThis would bind port 5000 inside the container to port 80 on the or interface on the host machine.\n\nOr, to bind port 5000 of the container to a dynamic port but only on the , you could use:\n\nYou can also bind UDP and SCTP (typically used by telecom protocols such as SIGTRAN, Diameter, and S1AP/X2AP) ports by adding a trailing or . For example:\n\nYou also learned about the useful shortcut which showed us the current port bindings. This is also useful for showing you specific port configurations. For example, if you've bound the container port to the on the host machine, then the output reflects that.\n\nNetwork port mappings are not the only way Docker containers can connect to one another. Docker also has a linking system that allows you to link multiple containers together and send connection information from one to another. When containers are linked, information about a source container can be sent to a recipient container. This allows the recipient to see selected data describing aspects of the source container.\n\nTo establish links, Docker relies on the names of your containers. You've already seen that each container you create has an automatically created name; indeed you've become familiar with our old friend during this guide. You can also name containers yourself. This naming provides two useful functions:\n• None It can be useful to name containers that do specific functions in a way that makes it easier for you to remember them, for example naming a container containing a web application .\n• None It provides Docker with a reference point that allows it to refer to other containers, for example, you can specify to link the container to container .\n\nYou can name your container by using the flag, for example:\n\nThis launches a new container and uses the flag to name the container . You can see the container's name using the command.\n\nYou can also use to return the container's name.\n\nLinks allow containers to discover each other and securely transfer information about one container to another container. When you set up a link, you create a conduit between a source container and a recipient container. The recipient can then access select data about the source. To create a link, you use the flag. First, create a new container, this time one containing a database.\n\nThis creates a new container called from the image, which contains a PostgreSQL database.\n\nNow, you need to delete the container you created previously so you can replace it with a linked one:\n\nNow, create a new container and link it with your container.\n\nThis links the new container with the container you created earlier. The flag takes the form:\n\nWhere is the name of the container we're linking to and is an alias for the link name. That alias is used shortly. The flag also takes the form:\n\nIn this case the alias matches the name. You could write the previous example as:\n\nNext, inspect your linked containers with :\n\nYou can see that the container is now linked to the container . Which allows it to access information about the container.\n\nSo what does linking the containers actually do? You've learned that a link allows a source container to provide information about itself to a recipient container. In our example, the recipient, , can access information about the source . To do this, Docker creates a secure tunnel between the containers that doesn't need to expose any ports externally on the container; when we started the container we did not use either the or flags. That's a big benefit of linking: we don't need to expose the source container, here the PostgreSQL database, to the network.\n\nDocker exposes connectivity information for the source container to the recipient container in two ways:\n\nDocker creates several environment variables when you link containers. Docker automatically creates environment variables in the target container based on the parameters. It also exposes all environment variables originating from Docker from the source container. These include variables from:\n• the commands in the source container's Dockerfile\n• the , , and options on the command when the source container is started\n\nThese environment variables enable programmatic discovery from within the target container of information related to the source container.\n\nDocker sets an environment variable for each target container listed in the parameter. For example, if a new container called is linked to a database container called via , then Docker creates a variable in the container.\n\nDocker also defines a set of environment variables for each port exposed by the source container. Each variable has a unique prefix in the form\n\nThe components in this prefix are:\n• the alias specified in the parameter (for example, )\n• a which is either TCP or UDP\n\nDocker uses this prefix format to define three distinct environment variables:\n• The variable contains the IP Address from the URL, for example .\n• The variable contains just the port number from the URL for example .\n• The variable contains just the protocol from the URL for example .\n\nIf the container exposes multiple ports, an environment variable set is defined for each one. This means, for example, if a container exposes 4 ports that Docker creates 12 environment variables, 3 for each port.\n\nAdditionally, Docker creates an environment variable called . This variable contains the URL of the source container's first exposed port. The 'first' port is defined as the exposed port with the lowest number. For example, consider the variable. If that port is used for both tcp and udp, then the tcp one is specified.\n\nFinally, Docker also exposes each Docker originated environment variable from the source container as an environment variable in the target. For each variable Docker creates an variable in the target container. The variable's value is set to the value Docker used when it started the source container.\n\nReturning back to our database example, you can run the command to list the specified container's environment variables.\n\nYou can see that Docker has created a series of environment variables with useful information about the source container. Each variable is prefixed with , which is populated from the you specified above. If the were , the variables would be prefixed with . You can use these environment variables to configure your applications to connect to the database on the container. The connection is secure and private; only the linked container can communicate with the container.\n\nUnlike host entries in the file, IP addresses stored in the environment variables are not automatically updated if the source container is restarted. We recommend using the host entries in to resolve the IP address of linked containers.\n\nThese environment variables are only set for the first process in the container. Some daemons, such as , scrub them when spawning shells for connection.\n\nIn addition to the environment variables, Docker adds a host entry for the source container to the file. Here's an entry for the container:\n\nYou can see two relevant host entries. The first is an entry for the container that uses the Container ID as a host name. The second entry uses the link alias to reference the IP address of the container. In addition to the alias you provide, the linked container's name, if unique from the alias provided to the parameter, and the linked container's hostname are also added to for the linked container's IP address. You can ping that host via any of these entries:\n\nHere, you used the command to ping the container using its host entry, which resolves to . You can use this host entry to configure an application to make use of your container.\n\nIf you restart the source container, the files on the linked containers are automatically updated with the source container's new IP address, allowing linked communication to continue."
    },
    {
        "link": "https://docs.docker.com/compose/how-tos/environment-variables/set-environment-variables",
        "document": "A container's environment is not set until there's an explicit entry in the service configuration to make this happen. With Compose, there are two ways you can set environment variables in your containers with your Compose file.\n\nYou can set environment variables directly in your container's environment with the attribute in your .\n\nIt supports both list and mapping syntax:\n\nSee attribute for more examples on how to use it.\n• You can choose not to set a value and pass the environment variables from your shell straight through to your containers. It works in the same way as :\n\nThe value of the variable in the container is taken from the value for the same variable in the shell in which Compose is run. Note that in this case no warning is issued if the variable in the shell environment is not set.\n• None You can also take advantage of interpolation. In the following example, the result is similar to the one above but Compose gives you a warning if the variable is not set in the shell environment or in an file in the project directory.\n\nA container's environment can also be set using files along with the attribute.\n\nUsing an file lets you use the same file for use by a plain command, or to share the same file within multiple services without the need to duplicate a long YAML block.\n\nIt can also help you keep your environment variables separate from your main configuration file, providing a more organized and secure way to manage sensitive information, as you do not need to place your file in the root of your project's directory.\n\nThe attribute also lets you use multiple files in your Compose application.\n\nThe paths to your file, specified in the attribute, are relative to the location of your file.\n• If multiple files are specified, they are evaluated in order and can override values set in previous files.\n• As of Docker Compose version 2.24.0, you can set your file, defined by the attribute, to be optional by using the field. When is set to and the file is missing, Compose silently ignores the entry.\n• As of Docker Compose version 2.30.0, you can use an alternative file format for the with the attribute. For more information, see .\n• Values in your file can be overridden from the command line by using .\n\nSimilar to , you can set environment variables temporarily with or its short form :\n• None You can also pass a variable from the shell or your environment files by not giving it a value:\n\nThe value of the variable in the container is taken from the value for the same variable in the shell in which Compose is run or from the environment files."
    },
    {
        "link": "https://stackoverflow.com/questions/30494050/how-do-i-pass-environment-variables-to-docker-containers",
        "document": "How can one access an external database from a container? Is the best way to hard code in the connection string?\n\nYou can pass environment variables to your containers with the (alias ) flag. An example from a startup script: Or, if you don't want to have the value on the command-line where it will be displayed by , etc., can pull in the value from the current environment if you just give it without the : If you have many environment variables and especially if they're meant to be secret, you can use an env-file: The --env-file flag takes a filename as an argument and expects each line to be in the VAR=VAL format, mimicking the argument passed to --env. Comment lines need only be prefixed with #\n\nYou can pass using parameters with the command as mentioned here and as mentioned by errata. However, the possible downside of this approach is that your credentials will be displayed in the process listing, where you run it. To make it more secure, you may write your credentials in a configuration file and do with as mentioned here. Then you can control the access of that configuration file so that others having access to that machine wouldn't see your credentials.\n\nIf you are using 'docker-compose' as the method to spin up your container(s), there is actually a useful way to pass an environment variable defined on your server to the Docker container. In your file, let's say you are spinning up a basic hapi-js container and the code looks like: Let's say that the local server that your docker project is on has an environment variable named 'NODE_DB_CONNECT' that you want to pass to your hapi-js container, and you want its new name to be 'HAPI_DB_CONNECT'. Then in the file, you would pass the local environment variable to the container and rename it like so: I hope this helps you to avoid hard-coding a database connect string in any file in your container!\n\nUsing , you can inherit environment variables in and subsequently any Dockerfile(s) called by to build images. This is useful when the command should execute commands specific to the environment. version: '3.1' services: my-service: build: #$RAILS_ENV is referencing the shell environment RAILS_ENV variable #and passing it to the Dockerfile ARG RAILS_ENV #the syntax below ensures that the RAILS_ENV arg will default to #production if empty. #note that is dockerfile: is not specified it assumes file name: Dockerfile context: . args: - RAILS_ENV=${RAILS_ENV:-production} environment: - RAILS_ENV=${RAILS_ENV:-production} FROM ruby:2.3.4 #give ARG RAILS_ENV a default value = production ARG RAILS_ENV=production #assign the $RAILS_ENV arg to the RAILS_ENV ENV so that it can be accessed #by the subsequent RUN call within the container ENV RAILS_ENV $RAILS_ENV #the subsequent RUN call accesses the RAILS_ENV ENV variable within the container RUN if [ \"$RAILS_ENV\" = \"production\" ] ; then echo \"production env\"; else echo \"non-production env: $RAILS_ENV\"; fi This way, I don't need to specify environment variables in files or / commands:\n\nThere are several ways to pass environment variables to the container including using docker-compose (best choice if possible). I recommend using an env file for easier organization and maintenance. IMPORTANT: The CLI has some limitations regarding (see below) environment variables. ISSUE: Docker run and environment variables with quotes and double quotes The subcommand strangely does not accept env files formatted as valid BASH (\"Shell\") scripts so it considers surrounding quotes and double quotes as part of the value of environment variables, so the container will get the value of (in an env file, for example)... ... as and not . Other than that, we'll have problems using the same env file in other contexts (including BASH itself). 🙄 This is quite strange behavior since .env files are regular BASH (\"Shell\") scripts. However, BASH (\"Shell\") offers us powerful features, so let's use it to our advantage in a workaround solution. My solution involves a Dockerfile, an env file, a BASH script file and the subcommand ( ) in a special way. The strategy consists of injecting your environment variables using another environment variable set in the subcommand and using the container itself to set these variables. #!/bin/bash # Some description a SOME_ENV_VAR_A=\"some value a\" # Some description b SOME_ENV_VAR_B=\"some value b\" # Some description c SOME_ENV_VAR_C=\"some value c\" [...] Injecting your environment variables using the run subcommand The docker-compose does not have this problem as it uses YAML. YAML does not consider surrounding quotes and double quotes as part of the value of environment variables, which is something that is not done with subcommand."
    },
    {
        "link": "https://docs.docker.com/compose/how-tos/networking",
        "document": "By default Compose sets up a single network for your app. Each container for a service joins the default network and is both reachable by other containers on that network, and discoverable by the service's name.\n\nFor example, suppose your app is in a directory called , and your looks like this:\n\nWhen you run , the following happens:\n• A container is created using 's configuration. It joins the network under the name .\n• A container is created using 's configuration. It joins the network under the name .\n\nEach container can now look up the service name or and get back the appropriate container's IP address. For example, 's application code could connect to the URL and start using the Postgres database.\n\nIt is important to note the distinction between and . In the above example, for , the is and the container port is (postgres default). Networked service-to-service communication uses the . When is defined, the service is accessible outside the swarm as well.\n\nWithin the container, your connection string to would look like , and from the host machine, the connection string would look like for example if your container is running locally.\n\nIf you make a configuration change to a service and run to update it, the old container is removed and the new one joins the network under a different IP address but the same name. Running containers can look up that name and connect to the new address, but the old address stops working.\n\nIf any containers have connections open to the old container, they are closed. It is a container's responsibility to detect this condition, look up the name again and reconnect.\n\nLinks allow you to define extra aliases by which a service is reachable from another service. They are not required to enable services to communicate. By default, any service can reach any other service at that service's name. In the following example, is reachable from at the hostnames and :\n\nSee the links reference for more information.\n\nWhen deploying a Compose application on a Docker Engine with Swarm mode enabled, you can make use of the built-in driver to enable multi-host communication.\n\nOverlay networks are always created as . You can optionally set the property to .\n\nConsult the Swarm mode section, to see how to set up a Swarm cluster, and the Getting started with multi-host networking to learn about multi-host overlay networks.\n\nInstead of just using the default app network, you can specify your own networks with the top-level key. This lets you create more complex topologies and specify custom network drivers and options. You can also use it to connect services to externally-created networks which aren't managed by Compose.\n\nEach service can specify what networks to connect to with the service-level key, which is a list of names referencing entries under the top-level key.\n\nThe following example shows a Compose file which defines two custom networks. The service is isolated from the service, because they do not share a network in common. Only can talk to both.\n\nNetworks can be configured with static IP addresses by setting the ipv4_address and/or ipv6_address for each attached network.\n\nNetworks can also be given a custom name:\n\nInstead of, or as well as, specifying your own networks, you can also change the settings of the app-wide default network by defining an entry under named :\n\nIf you want your containers to join a pre-existing network, use the option\n\nInstead of attempting to create a network called , Compose looks for a network called and connects your app's containers to it.\n\nFor full details of the network configuration options available, see the following references:"
    },
    {
        "link": "https://hub.docker.com/r/schickling/mailcatcher",
        "document": ""
    },
    {
        "link": "https://mailcatcher.me",
        "document": "Catches mail and serves it through a dream.\n\nMailCatcher runs a super simple SMTP server which catches any message sent to it to display in a web interface. Run mailcatcher, set your favourite app to deliver to smtp://127.0.0.1:1025 instead of your default SMTP server, then check out http://127.0.0.1:1080 to see the mail that's arrived so far.\n• Catches all mail and stores it for display.\n• Shows HTML, Plain Text and Source version of messages, as applicable.\n• Rewrites HTML enabling display of embedded, inline images/etc and opens links in a new window.\n• Lists attachments and allows separate downloading of parts.\n• Download original email to view in your native mail client(s).\n• Command line options to override the default SMTP/HTTP IP and port settings.\n• Mail appears instantly if your browser supports WebSockets, otherwise updates every thirty seconds.\n• Runs as a daemon in the background, optionally in foreground.\n\nUse to see the command line options. The brave can get the source from the GitHub repository.\n\nPlease don't put mailcatcher into your Gemfile. It will conflict with your applications gems at some point.\n\nInstead, pop a note in your README stating you use mailcatcher, and to run then to get started.\n\nUnder RVM your mailcatcher command may only be available under the ruby you install mailcatcher into. To prevent this, and to prevent gem conflicts, install mailcatcher into a dedicated gemset with a wrapper script:\n\nTo set up your rails app, I recommend adding this to your :\n\nFor projects using PHP, or PHP frameworks and application platforms like Drupal, you can set PHP's mail configuration in your php.ini to send via MailCatcher with:\n\nYou can do this in your Apache configuration like so:\n\nIf you've installed via RVM this probably won't work unless you've manually added your RVM bin paths to your system environment's PATH. In that case, run and put that path into the directive above instead of .\n\nIf starting on alternative SMTP IP and/or port with parameters like , add the same parameters to your command:\n\nFor use in Django, add the following configuration to your projects' settings.py\n\nA fairly RESTful URL schema means you can download a list of messages in JSON from , each message's metadata with , and then the pertinent parts with and for the default HTML and plain text version, for individual attachments by CID, or the whole message with .\n• Mail processing is fairly basic but easily modified. If something doesn't work for you, fork and fix it or file an issue and let me know. Include the whole message you're having problems with.\n• Encodings are difficult. MailCatcher does not completely support utf-8 straight over the wire, you must use a mail library which encodes things properly based on SMTP server capabilities.\n\nMailCatcher is just a mishmash of other people's hard work. Thank you so much to the people who have built the wonderful guts on which this project relies.\n\nI work on MailCatcher mostly in my own spare time. If you've found Mailcatcher useful and would like to help feed me and fund continued development and new features, please donate via PayPal. If you'd like a specific feature added to MailCatcher and are willing to pay for it, please email me.\n\nCopyright © 2010-2019 Samuel Cochran (sj26@sj26.com). Released under the MIT License, see LICENSE for details."
    },
    {
        "link": "https://github.com/schickling/dockerfiles/blob/master/mailcatcher/README.md",
        "document": "Link the container to another container and use the mailcatcher SMTP port via a ENV variable like .\n\nYou can run the web interface under a different root by specifying the environmental variable HTTPPATH. This can be used if you're proxying the incoming connection."
    },
    {
        "link": "https://mailtrap.io/blog/mailcatcher-guide",
        "document": "Setting up email workflows for your app might be difficult. The framework you use might not necessarily be built with emails in mind (think, ReactJS, for example). Even when you figure that out, how do you ensure the right emails are sent to the right recipients? How do you make them look beautiful on all screen sizes? How do you avoid random spam waves triggered accidentally when using production data in a pre-production environment? Some of these questions can be, to some extent, answered with a tool called MailCatcher.\n\nMailCatcher is a free tool that can intercept emails sent from any web or mobile app. It works as a fake SMTP server to which you redirect your messages instead of sending them to a real SMTP server. Emails sent this way arrive at a local server only and can be viewed in a web interface. Or maybe they don’t arrive at all. If the latter is the case, you probably have some work to do here.\n\nEach message that is received by MailCatcher can be opened and analyzed. You can look into its body, headers, attachments, and HTML code.\n\nMailCatcher works with any framework that supports SMTP and localhost, so the list of available options is very long. The tool can also be initiated over API.\n\nHow to set up MailCatcher?\n\nMailCatcher runs on Ruby, so you’ll need to have a development environment set up. Here’s how you can do this for the following OSs:\n\nMany other versions of Ubuntu and Mac OS are also covered under the links above. For each, solely the “Installing Ruby” part will be sufficient to set up the environment for installing MailCatcher.\n\nWhen you’re done, install MailCatcher with the following:\n\nOr use Bundler to do it.\n\nThen, specify the dependencies in a Gemfile:\n\n\n\nWhichever approach you choose, MailCatcher should be installed once you complete all the steps.\n\nAfter that, feel free to start it with:\n\nor just with:\n\nNOTE: Skipping the zeros is fine for most cases. But if you wish to use a docker for installation or simply want to share your MailCatcher view with other machines, add “0.0.0.0” at the end.\n\n\n\nOnce you start MailCatcher, you should see the following:\n\nSpeaking of a docker, instead of installing a gem as in the example above, you can use a dedicated docker image.\n\nFirst of all, add it to your file.\n\nMake sure this container is linked to your app container, and use the following SMTP settings:\n\nNow, you can set the workflows you were planning to test to be sent through smtp://[0.0.0.0]:1025 and access them at http://[0.0.0.0]:1080/\n\nFor the list of framework-specific instructions for installing MailCatcher, check the list on their homepage.\n\nWhen in doubt, also check the list of available commands by typing:\n\nA particularly useful option is to launch MailCatcher in the foreground, so others can connect to your local SMTP. You can do this with:\n\nDespite its basic functionalities, MailCatcher can effectively prevent you from spamming real users of your app. Since all the workflows you’re testing will be redirected to a local address, no message will ever be delivered to an actual SMTP server and then pushed to users’ inboxes (assuming you configured everything correctly).\n\nWith this tool, you can also easily see what really works and what doesn’t. In other words, you can see if a message that was supposed to be triggered was really sent. You can also be notified when a flood of emails is released after a simple action by a user and fix it before pushing it to production.\n\nMailCatcher can help you perform a basic inspection of the content and headers of your emails. You can access the HTML version of an email and check if the headers, including Return-Path address, are set correctly. You can also try out the links, preview the attachments, and diagnose what needs to be improved before an email is sent.\n\nFinally, MailCatcher is free to use, which might be appealing to those of you on a very low budget. The developer of this tool can be supported with donations, but other than that, all of the features listed above are free of charge.\n\nThis is all great, but are there any disadvantages to using this tool?\n\nYes, MailCatcher also has various limitations and drawbacks.\n\n\n\nNot developed further for years\n\nThe last release (0.6.4) was made available back in February 2016. Although there have been some minor updates to the repository since then, there’s little sign of new upcoming features. If you’re willing to pay for adding new functionalities, you’re encouraged to get in touch with the author.\n\nWhat you see at http://0.0.0.0:1080/ is a basic tool for verifying if emails are received or not and if headers were set up as expected. By all means, it can be enough for some tests, but if you need more, you’ll need to look somewhere else. MailCatcher will preview each message and might give some (visual) hints when something doesn’t render as expected. It’s important to keep in mind, though, that a thing or two might have been changed in the world of browsers since the last update to MailCatcher. For example, at the time of the last release, Google Chrome was just celebrating the launch of version 48.0.2564, Adobe Flash Player was in full swing, and HTML5 was just optional. At the time of writing, Chrome is in its 76th version, with new versions lurking right behind the horizon.\n\n\n\nTakes time and effort to set up\n\nSince MailCatcher is not a web service, you need to take care of hosting it somewhere. For that, you’ll need to set up a server and then install MailCatcher using the instructions we mentioned above. MailCatcher is built with Ruby and is usually deployed with Ubuntu. If this is not your field of expertise, it might take a bit of extra effort to get things going.\n\nBoth local and cloud-based testing environments have certain benefits, with the latter one being usually a preferred option for developers and QAs. Either way, we’ve covered the differences in another article.﻿\n\n\n\nNo use for teams\n\nMailCatcher’s SMTP server works only on localhost, which might be perfectly fine if you’re the only person tasked with testing email workflows. If you, however, want to have some help, share your progress with a remote manager, or need to keep a client in the loop, MailCatcher won’t be any good. As such, it’s good only for small, stationary teams and individuals.\n\nEasy to get lost in\n\nIf you try to test just a few emails, you’re fine with a basic inbox. If you, however, have a complex project to work on which involves numerous workflows, as well as different user permissions and teams, your inbox will quickly be flooded and almost impossible to navigate. This might cause delays and make it difficult to spot something important as you progress.\n\n\n\nIf any of the listed cons is a deal-breaker for you, you’ll be happy to know that there are some great MailCatcher alternatives. One of these alternatives is Mailtrap Email Sandbox.\n\nWith Mailtrap Email Sandbox, devs get a safe environment to test emails without the risk of spamming recipients in the process. Also, as it’s quite an advanced testing solution, Mailtrap Email Sandbox doesn’t come with the same limitations as MailCatcher, and here is how:\n• Mailtrap Email Sandbox is actively developed and maintained by a team committed to delivering exceptional service through guidance and support. The solution features are easily accessible through a user-friendly interface allowing for a simplified testing process.\n• Within Mailtrap Email Sandbox, users get features for solving various email testing challenges. The most notable ones are:\n• HTML/CSS analysis – get an estimation of how supported your email code is by popular email clients and be alerted about any problematic elements\n• Email preview – see how your email gets rendered by popular email clients and check its responsiveness\n• Spam analysis – get an overall spam score for your email and be alerted about any rules that might be seen as suspicious\n• Email forwarding – whitelist recipients and automatically or manually forward emails to them\n• Blacklist reporting – look for your sender IP/domain on common blacklists\n• Detailed tech info – see the original values of headers and SMTP transaction details\n• Multiple inboxes – create a virtual inbox for each of your projects and even project stages\n• It is cloud-based! Mailtrap Email Sandbox is technology-agnostic and compatible with any app or framework that supports SMTP. It also allows anyone you grant permission to access your inboxes, thus enabling better collaboration.\n• It has an easy setup process that takes only about 5 minutes. Plus, you have the option to choose between using an email-sending configuration code, SMTP credentials, or a dedicated email address for sending your testing emails.\n\nTo start using Mailtrap Email Sandbox, all you need to do is create a Mailtrap account and follow the setup instructions, as described in the Mailtrap knowledge base.\n\nOh, and yes, a forever-free plan is available for this testing solution, as well as five higher plans. This way, you can test things out and then pick what fits your needs best!"
    },
    {
        "link": "https://github.com/dockage/mailcatcher",
        "document": "MailCatcher runs a super simple SMTP server which catches any message sent to it to display in a web interface.\n\nAutomated builds of the image are available on Dockerhub and is the recommended method of installation.\n\nAlternately you can build the image locally.\n\nThe quickest way to get started is using docker-compose.\n\nAlternately, you can manually launch the container.\n• Where to get help: website, documentation\n• Maintained by: The Dockage team (info at dockage.dev)"
    }
]