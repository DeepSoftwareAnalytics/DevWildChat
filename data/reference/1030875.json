[
    {
        "link": "https://f5.com/company/blog/nginx/websocket-nginx",
        "document": ""
    },
    {
        "link": "http://nginx.org/en/docs/http/websocket.html",
        "document": "To turn a connection between a client and server from HTTP/1.1 into WebSocket, the protocol switch mechanism available in HTTP/1.1 is used.\n\nThere is one subtlety however: since the “Upgrade” is a hop-by-hop header, it is not passed from a client to proxied server. With forward proxying, clients may use the method to circumvent this issue. This does not work with reverse proxying however, since clients are not aware of any proxy servers, and special processing on a proxy server is required.\n\nSince version 1.3.13, nginx implements special mode of operation that allows setting up a tunnel between a client and proxied server if the proxied server returned a response with the code 101 (Switching Protocols), and the client asked for a protocol switch via the “Upgrade” header in a request.\n\nAs noted above, hop-by-hop headers including “Upgrade” and “Connection” are not passed from a client to proxied server, therefore in order for the proxied server to know about the client’s intention to switch a protocol to WebSocket, these headers have to be passed explicitly:\n\nA more sophisticated example in which a value of the “Connection” header field in a request to the proxied server depends on the presence of the “Upgrade” field in the client request header:\n\nBy default, the connection will be closed if the proxied server does not transmit any data within 60 seconds. This timeout can be increased with the proxy_read_timeout directive. Alternatively, the proxied server can be configured to periodically send WebSocket ping frames to reset the timeout and check if the connection is still alive."
    },
    {
        "link": "https://videosdk.live/developer-hub/websocket/nginx-websocket",
        "document": "WebSocket is a protocol that allows for persistent, two-way communication between a client and a server. Unlike HTTP, which follows a request-response model, WebSocket provides full-duplex communication channels over a single TCP connection. This makes it ideal for applications that require real-time updates, such as live chats, gaming, and financial tickers.\n\nNginx is widely used as a web server and reverse proxy due to its performance and scalability. When combined with WebSocket, Nginx can efficiently manage and route WebSocket connections, providing a robust solution for real-time web applications. Using Nginx with WebSocket helps ensure that your application can handle a high number of simultaneous connections while maintaining low latency and high throughput.\n\nBefore diving into the configuration, ensure you have the following prerequisites:\n• Nginx installed: You should have Nginx installed on your server. If not, we will cover the installation process.\n• Basic knowledge of Nginx configuration: Familiarity with the structure of Nginx configuration files and directives will be helpful.\n\nThis guide will walk you through the steps to configure Nginx to support WebSocket connections, ensuring your application can handle real-time communication efficiently.\n\nFirst, ensure that Nginx is installed on your server. You can install Nginx using the package manager for your operating system. For example, on Ubuntu, you can use the following commands:\n\nOnce Nginx is installed, familiarize yourself with its configuration file, typically located at . A basic Nginx configuration might look like this:\n\nThis configuration sets up a basic server listening on port 80. Next, we'll modify it to support WebSocket connections.\n\nTo enable WebSocket support, you'll need to configure Nginx to pass WebSocket traffic to your backend application. This involves setting the correct headers and using the directive. Here's an example configuration:\n\nThis configuration ensures that WebSocket traffic is correctly handled and forwarded to the backend server.\n\nHandling WebSocket connections requires setting specific headers to ensure the connection upgrade request is properly managed. The following example demonstrates how to handle WebSocket connections:\n\nThis configuration sets the necessary headers for WebSocket communication and ensures the connection upgrade is correctly processed.\n\nAfter configuring Nginx, it's crucial to test the WebSocket connection to ensure it's working correctly. You can use tools like to test the WebSocket server:\n\nWhen configuring Nginx with WebSocket, you may encounter common issues such as or errors. Here are some troubleshooting tips:\n• 502 Bad Gateway: Ensure your backend server is running and accessible from Nginx. Check the backend server's IP address and port in the directive.\n• 101 Switching Protocols: Verify that the and headers are correctly set in your Nginx configuration.\n\nUse Nginx logs to debug issues. Check the error log ( ) for detailed error messages and information."
    },
    {
        "link": "https://github.com/open-webui/open-webui/discussions/1235",
        "document": "To see all available qualifiers, see our documentation .\n\nSaved searches Use saved searches to filter your results more quickly\n\nWe read every piece of feedback, and take your input very seriously.\n\nYou signed in with another tab or window. Reload to refresh your session.\n\nYou signed out in another tab or window. Reload to refresh your session.\n\nYou switched accounts on another tab or window. Reload to refresh your session."
    },
    {
        "link": "https://forum.djangoproject.com/t/nginx-not-upgraded-to-websocket/27960",
        "document": "i have a Kubernetes cluster in which nginx:1.21.6 is running as a proxy.\n\nNginx should upgrade the connection to websocket at path /ws/ and forward it to the service http://dev-websocket:8000.\n\nSince some changes, however, the dev-websocket service seems to receive an HTTP connection. But I can’t find the problem.\n\n Everything works in my local development environment.\n\ndjango channels runs on dev-websocket behind daphne. The logs in the dev-websocket service should actually look like this:\n\nHowever, the output is currently:\n\nMy nginx.conf currently looks like this:\n\nWhy does nginx not seem to switch the connection to websocket and forwards the request as http to the dev-websocket service?"
    },
    {
        "link": "http://nginx.org/en/docs/http/websocket.html",
        "document": "To turn a connection between a client and server from HTTP/1.1 into WebSocket, the protocol switch mechanism available in HTTP/1.1 is used.\n\nThere is one subtlety however: since the “Upgrade” is a hop-by-hop header, it is not passed from a client to proxied server. With forward proxying, clients may use the method to circumvent this issue. This does not work with reverse proxying however, since clients are not aware of any proxy servers, and special processing on a proxy server is required.\n\nSince version 1.3.13, nginx implements special mode of operation that allows setting up a tunnel between a client and proxied server if the proxied server returned a response with the code 101 (Switching Protocols), and the client asked for a protocol switch via the “Upgrade” header in a request.\n\nAs noted above, hop-by-hop headers including “Upgrade” and “Connection” are not passed from a client to proxied server, therefore in order for the proxied server to know about the client’s intention to switch a protocol to WebSocket, these headers have to be passed explicitly:\n\nA more sophisticated example in which a value of the “Connection” header field in a request to the proxied server depends on the presence of the “Upgrade” field in the client request header:\n\nBy default, the connection will be closed if the proxied server does not transmit any data within 60 seconds. This timeout can be increased with the proxy_read_timeout directive. Alternatively, the proxied server can be configured to periodically send WebSocket ping frames to reset the timeout and check if the connection is still alive."
    },
    {
        "link": "https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy",
        "document": "This article describes the basic configuration of a proxy server. You will learn how to pass a request from NGINX to proxied servers over different protocols, modify client request headers that are sent to the proxied server, and configure buffering of responses coming from the proxied servers.\n\nProxying is typically used to distribute the load among several servers, seamlessly show content from different websites, or pass requests for processing to application servers over protocols other than HTTP.\n\nWhen NGINX proxies a request, it sends the request to a specified proxied server, fetches the response, and sends it back to the client. It is possible to proxy requests to an HTTP server (another NGINX server or any other server) or a non-HTTP server (which can run an application developed with a specific framework, such as PHP or Python) using a specified protocol. Supported protocols include FastCGI, uwsgi, SCGI, and memcached.\n\nTo pass a request to an HTTP proxied server, the proxy_pass directive is specified inside a location. For example:\n\nThis example configuration results in passing all requests processed in this location to the proxied server at the specified address. This address can be specified as a domain name or an IP address. The address may also include a port:\n\nNote that in the first example above, the address of the proxied server is followed by a URI, . If the URI is specified along with the address, it replaces the part of the request URI that matches the location parameter. For example, here the request with the URI will be proxied to . If the address is specified without a URI, or it is not possible to determine the part of URI to be replaced, the full request URI is passed (possibly, modified).\n\nTo pass a request to a non-HTTP proxied server, the appropriate directive should be used:\n\nNote that in these cases, the rules for specifying addresses may be different. You may also need to pass additional parameters to the server (see the reference documentation for more detail).\n\nThe proxy_pass directive can also point to a named group of servers. In this case, requests are distributed among the servers in the group according to the specified method.\n\nBy default, NGINX redefines two header fields in proxied requests, “Host” and “Connection”, and eliminates the header fields whose values are empty strings. “Host” is set to the variable, and “Connection” is set to .\n\nTo change these setting, as well as modify other header fields, use the proxy_set_header directive. This directive can be specified in a location or higher. It can also be specified in a particular server context or in the http block. For example:\n\nIn this configuration the “Host” field is set to the $host variable.\n\nTo prevent a header field from being passed to the proxied server, set it to an empty string as follows:\n\nBy default NGINX buffers responses from proxied servers. A response is stored in the internal buffers and is not sent to the client until the whole response is received. Buffering helps to optimize performance with slow clients, which can waste proxied server time if the response is passed from NGINX to the client synchronously. However, when buffering is enabled NGINX allows the proxied server to process responses quickly, while NGINX stores the responses for as much time as the clients need to download them.\n\nThe directive that is responsible for enabling and disabling buffering is proxy_buffering. By default it is set to and buffering is enabled.\n\nThe proxy_buffers directive controls the size and the number of buffers allocated for a request. The first part of the response from a proxied server is stored in a separate buffer, the size of which is set with the proxy_buffer_size directive. This part usually contains a comparatively small response header and can be made smaller than the buffers for the rest of the response.\n\nIn the following example, the default number of buffers is increased and the size of the buffer for the first portion of the response is made smaller than the default.\n\nIf buffering is disabled, the response is sent to the client synchronously while it is receiving it from the proxied server. This behavior may be desirable for fast interactive clients that need to start receiving the response as soon as possible.\n\nTo disable buffering in a specific location, place the proxy_buffering directive in the location with the parameter, as follows:\n\nIn this case NGINX uses only the buffer configured by proxy_buffer_size to store the current part of a response.\n\nA common use of a reverse proxy is to provide load balancing. Learn how to improve power, performance, and focus on your apps with rapid deployment in the free Five Reasons to Choose a Software Load Balancer ebook.\n\nIf your proxy server has several network interfaces, sometimes you might need to choose a particular source IP address for connecting to a proxied server or an upstream. This may be useful if a proxied server behind NGINX is configured to accept connections from particular IP networks or IP address ranges.\n\nSpecify the proxy_bind directive and the IP address of the necessary network interface:\n\nThe IP address can be also specified with a variable. For example, the variable passes the IP address of the network interface that accepted the request:"
    },
    {
        "link": "https://docs.nginx.com/nginx/admin-guide/load-balancer/using-proxy-protocol",
        "document": "This article explains how to configure NGINX and F5 NGINX Plus to accept the PROXY protocol, rewrite the IP address of a load balancer or proxy to the one received in the PROXY protocol header, configure simple logging of a client’s IP address, and enable the PROXY protocol between NGINX and a TCP upstream server.\n\nThe PROXY protocol enables NGINX and NGINX Plus to receive client connection information passed through proxy servers and load balancers such as HAproxy and Amazon Elastic Load Balancer (ELB).\n\nWith the PROXY protocol, NGINX can learn the originating IP address from HTTP, SSL, HTTP/2, SPDY, WebSocket, and TCP. Knowing the originating IP address of a client may be useful for setting a particular language for a website, keeping a denylist of IP addresses, or simply for logging and statistics purposes.\n\nThe information passed via the PROXY protocol is the client IP address, the proxy server IP address, and both port numbers.\n\nUsing this data, NGINX can get the originating IP address of the client in several ways:\n• With the and variables which capture the original client IP address and port. The and variables capture the IP address and port of the load balancer.\n• With the RealIP module which rewrites the values in the and variables, replacing the IP address and port of the load balancer with the original client IP address and port. The and variables retain the address and port of the load balancer, and the and variables retain the original client IP address and port anyway.\n• To accept the PROXY protocol v2, NGINX Plus R16 and later or NGINX Open Source 1.13.11 and later\n• To accept the PROXY protocol for HTTP, NGINX Plus R3 and later or NGINX Open Source 1.5.12 and later\n• For TCP client‑side PROXY protocol support, NGINX Plus R7 and later or NGINX Open Source 1.9.3 and later\n• To accept the PROXY protocol for TCP, NGINX Plus R11 and later or NGINX Open Source 1.11.4 and later\n• The Real‑IP modules for HTTP and Stream TCP are not included in NGINX Open Source by default; see Installing NGINX Open Source for details. No extra steps are required for NGINX Plus.\n\nTo configure NGINX to accept PROXY protocol headers, add the parameter to the directive in a block in the or block.\n\nNow you can use the and variables for the client IP address and port and additionally configure the HTTP and RealIP modules to replace the IP address of the load balancer in the and variables with the IP address and port of the client.\n\nChanging the Load Balancer’s IP Address To the Client IP Address\n\nYou can replace the address of the load balancer or TCP proxy with the client IP address received from the PROXY protocol. This can be done with the HTTP and RealIP modules. With these modules, the and variables retain the real IP address and port of the client, while the and variables retain the IP address and port of the load balancer.\n\nTo change the IP address from the load balancer’s IP address to the client’s IP address:\n• Make sure you’ve configured NGINX to accept the PROXY protocol headers. See Configuring NGINX to Accept the PROXY Protocol.\n• Make sure that your NGINX installation includes the HTTP and Stream Real‑IP modules: If not, recompile NGINX with these modules. See Installing NGINX Open Source for details. No extra steps are required for NGINX Plus.\n• In the directive for HTTP, Stream, or both, specify the IP address or the CIDR range of addresses of the TCP proxy or load balancer:\n• In the context, change the IP address of the load balancer to the IP address of the client received from the PROXY protocol header, by specifying the parameter to the directive:\n\nWhen you know the original IP address of the client, you can configure the correct logging:\n• For HTTP, configure NGINX to pass the client IP address to upstream servers using the variable with the directive:\n• Add the variable to the directive (HTTP or Stream):\n\nPROXY Protocol for a TCP Connection to an Upstream\n\nFor a TCP stream, the PROXY protocol can be enabled for connections between NGINX and an upstream server. To enable the PROXY protocol, include the directive in a block at the level:\n\nThe example assumes that there is a load balancer in front of NGINX to handle all incoming HTTPS traffic, for example Amazon ELB. NGINX accepts HTTPS traffic on port 443 ( ), TCP traffic on port 12345, and accepts the client’s IP address passed from the load balancer via the PROXY protocol as well (the parameter to the directive in both the and blocks.\n\nNGINX terminates HTTPS traffic (the and directives) and proxies the decrypted data to a backend server:\n\nIt includes the client IP address and port with the directives.\n\nThe variable specified in the directive also passes the client’s IP address to the log for both HTTP and TCP.\n\nAdditionally, a TCP server (the block) sends its own PROXY protocol data to its backend servers (the directive)."
    },
    {
        "link": "https://videosdk.live/developer-hub/websocket/nginx-websocket",
        "document": "WebSocket is a protocol that allows for persistent, two-way communication between a client and a server. Unlike HTTP, which follows a request-response model, WebSocket provides full-duplex communication channels over a single TCP connection. This makes it ideal for applications that require real-time updates, such as live chats, gaming, and financial tickers.\n\nNginx is widely used as a web server and reverse proxy due to its performance and scalability. When combined with WebSocket, Nginx can efficiently manage and route WebSocket connections, providing a robust solution for real-time web applications. Using Nginx with WebSocket helps ensure that your application can handle a high number of simultaneous connections while maintaining low latency and high throughput.\n\nBefore diving into the configuration, ensure you have the following prerequisites:\n• Nginx installed: You should have Nginx installed on your server. If not, we will cover the installation process.\n• Basic knowledge of Nginx configuration: Familiarity with the structure of Nginx configuration files and directives will be helpful.\n\nThis guide will walk you through the steps to configure Nginx to support WebSocket connections, ensuring your application can handle real-time communication efficiently.\n\nFirst, ensure that Nginx is installed on your server. You can install Nginx using the package manager for your operating system. For example, on Ubuntu, you can use the following commands:\n\nOnce Nginx is installed, familiarize yourself with its configuration file, typically located at . A basic Nginx configuration might look like this:\n\nThis configuration sets up a basic server listening on port 80. Next, we'll modify it to support WebSocket connections.\n\nTo enable WebSocket support, you'll need to configure Nginx to pass WebSocket traffic to your backend application. This involves setting the correct headers and using the directive. Here's an example configuration:\n\nThis configuration ensures that WebSocket traffic is correctly handled and forwarded to the backend server.\n\nHandling WebSocket connections requires setting specific headers to ensure the connection upgrade request is properly managed. The following example demonstrates how to handle WebSocket connections:\n\nThis configuration sets the necessary headers for WebSocket communication and ensures the connection upgrade is correctly processed.\n\nAfter configuring Nginx, it's crucial to test the WebSocket connection to ensure it's working correctly. You can use tools like to test the WebSocket server:\n\nWhen configuring Nginx with WebSocket, you may encounter common issues such as or errors. Here are some troubleshooting tips:\n• 502 Bad Gateway: Ensure your backend server is running and accessible from Nginx. Check the backend server's IP address and port in the directive.\n• 101 Switching Protocols: Verify that the and headers are correctly set in your Nginx configuration.\n\nUse Nginx logs to debug issues. Check the error log ( ) for detailed error messages and information."
    },
    {
        "link": "https://f5.com/company/blog/nginx/websocket-nginx",
        "document": ""
    }
]