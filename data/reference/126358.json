[
    {
        "link": "https://reddit.com/r/C_Programming/comments/10fpd7w/is_there_any_official_documentation_of_c",
        "document": "maybe some of you will say that the C programming language book is the best but is there any documentation official ."
    },
    {
        "link": "https://github.com/mcinglis/c-style",
        "document": "These are my favorite C programming practices. Some rules are as trivial as style, while others are more intricate. I follow a few rules religiously, and others I use as a guideline. I prioritize correctness, readability, simplicity and maintainability over speed because premature optimization is the root of all evil.\n\nWrite correct, readable, simple and maintainable software, and tune it when you're done, with benchmarks to identify the choke points. Also, modern compilers will change computational complexities. Simplicity can often lead you to the best solution anyway: it's easier to write a linked list than it is to get an array to grow, but it's harder to index a list than it is to index an array.\n\nBackwards compatibility (e.g. ANSI C) is rarely important to me. In my opinion, backwards compatibility holds everyone back. I think we should use new technologies and new techniques if we can, to move everyone forward, if only a bit.\n\nIf you don't agree with something here, that's perfectly fine. Pick and choose what you like, and what works for your own situation. These rules aren't intended to be universal admonitions about quality: they're just my preferences, and work well for what I do, and what I care about.\n\nWriting this guide has made me deeply consider, and reconsider, best C programming practices. I've changed my opinion multiple times on many of the rules in this document.\n\nSo, I'm certain I'm wrong on even more points. This is a constant work-in-progress; issues and pull-requests are very welcome. This guide is licensed under the Creative Commons Attribution-ShareAlike, so I'm not liable for anything you do with this, etc.\n\nNo excuses here. Always develop and compile with warnings on. It turns out, though, that and actually don't enable \"all\" warnings. There are a few others that can be really helpful:\n\nCompiling with optimizations on can also help to detect errors:\n\nThe GNU Make Manual touches on how to automatically generate the dependencies of your object files from the source file's s. The example rule given in the manual is a bit complicated. Here's the rules I use:\n\nC11 is better than C99, which is (far) better than C89. C11 support is still coming along in GCC and Clang, but many features are there. If you need to support other compilers in the medium-term, write to C99.\n\nAlways write to a standard, as in . Don't write to a dialect, like . Try to make do without non-standard language extensions: you'll thank yourself later.\n\nThe idea of tabs was that we'd use tabs for indentation levels, and spaces for alignment. This lets people choose an indentation width to their liking, without breaking alignment of columns.\n\nBut, alas, we (and our editors) rarely get it right. There are four main problems posed by using tabs and spaces:\n• Tabs for indentation lead to inconsistencies between opinions on line lengths. Someone who uses a tab width of 8 will hit 80 characters much sooner than someone who uses a tab width of 2. The only way to avoid this is to require a tab-width, which eliminates the benefit of tabs.\n• It's much harder to configure your editor to correctly handle tabs and spaces for each project, than it is to just handle spaces. See also: Tabs vs Spaces: An Eternal Holy War\n• It's harder to align things using only the space bar. It's much easier to hit tab twice than to hold the space bar for eight characters. A developer on your project will make this mistake eventually. If you use spaces for indentation and alignment, you can hit the tab key in either situation, which is quick, easy and not prone to errors.\n• It's easier to prevent tab/space errors on projects that use only spaces, because all they need to do is detect for any tabs at all. To prevent against tabs used for alignment on a project that uses tabs, you'll need to come up with a regular expression.\n\nCut the complexity, and use spaces everywhere. You may have to adjust to someone else's indent width every now and then. Tough luck!\n\n80-characters-per-line is a de-facto standard for viewing code. Readers of your code who rely on that standard, and have their terminal or editor sized to 80 characters wide, can fit more on the screen by placing windows side-by-side.\n\nYou should stick to a maximum of 79 characters so that there's always a space in the last column. This makes it more obvious the line doesn't continue onto the next line. It also provides a right-hand margin.\n\nIf you go over 80 characters, you're making your code significantly harder to read for people who try to rely on the 80-columns standard. Either your line will wrap, which is hard to read, or your readers will have to scroll the window to the right to get the last few characters. Either of these results in code that's harder to read than if you had just worked out a line-break yourself.\n\nIt's harder to read long lines because your eyes have to travel further to get to the start of the next line, and the further they have to go, the more likely you'll have to visually readjust. 100-wide and 120-wide styles are easier to write, but harder to read.\n\nIt can be very tempting to let a line here or there go over 79 characters, but your readers will pay the price every time they have to read such a line. Treat 79 characters as a hard limit - no ifs or buts. Work out how best to break long lines, and your readers will thank you.\n\nDo what everyone else is doing, and write for 80-column views, and we'll all be better off.\n• Programmers' Stack Exchange: Is the 80 character limit still relevant?\n\nUse comments everywhere, never\n\nStick to single-line comments, and cut the complexity. Compared to single-line comments, multi-line comments:\n• are rarely used with a blank margin, so they're just as character-heavy\n• have a style, which has to be specified and adhered to\n• often have on its own line, so they're more line-expensive\n• have weird rules about embedded and\n• are harder/impossible to block-edit, and to extend\n• are more visually-cluttering than\n\nYou have to use for inline comments in multi-line s, though:\n\nBut I often prefer to just add comments after the macro body describing the tricky bits. I think this makes the macro body easier to read, but still provides the (much-needed) documentation.\n\nDeveloping in the same language, using the same spelling and vocabulary, is important. This is especially true in free-software projects with contributors from around the world. You should use the same language consistently for your project, in code, comments and documentation.\n\nSo, for American English, write , , , , , , , , , and so on (see more). I'm Australian, but I appreciate that most programmers will be learning and using American English. Also, American English spelling is consistently more phonetic and consistent than British English. British English tends to evolve towards American English for this reason, I think.\n\nComment non-standard-library s to say what symbols you use from them\n\nNamespaces are one of the great advances of software development. Unfortunately, C missed out (scopes aren't namespaces). But, because namespaces are so fantastic, we should try to simulate them with comments.\n\nThis provides a few benefits:\n• readers aren't forced to refer to documentation or use to find out where a symbol is defined (or, if you don't follow the rule below, where it comes from): your code just tells them\n• developers have a hope of being able to determine which s can be removed and which can't\n• developers are forced to consider namespace pollution (which is otherwise ignored in most C code), and encourages them to only provide small, well-defined headers\n\nThe downside is that the comments aren't checked or enforced. I've been intending to write a checker for this for quite some time, but for now, there's nothing to stop the comments from becoming wrong - either mentioning symbols that aren't used anymore, or not mentioning symbols that are used. In your project, try to nip these problems in the bud, to stop it from spreading. You should always be able to trust your code. This maintenance is annoying, for sure, but I think comments are worth it in aggregate.\n\nFinding where things come from is always one of my main challenges when learning a codebase. It could be a whole lot easier. I've never seen any projects that write comments like this, but I'd love to see it become a thing.\n\nDon't depend on what your headers include. If your code uses a symbol, include the header file where that symbol is defined. Then, if your headers change their inclusions, your code won't break.\n\nAlso, combined with the comment rule above, this saves your readers and fellow developers from having to follow a trail of includes just to find the definition of a symbol you're using. Your code should just tell them where it comes from.\n\nUnified headers are generally bad, because they relieve the library developer of the responsibility to provide loosely-coupled modules clearly separated by their purpose and abstraction. Even if the developer (thinks she) does this anyway, a unified header increases compilation time, and couples the user's program to the entire library, regardless of if they need it. There are numerous other disadvantages, touched on in the points above.\n\nThere was a good exposé on unified headers on the Programmers' Stack Exchange. An answer mentions that it's reasonable for something like GTK+ to only provide a single header file. I agree, but I think that's due to the bad design of GTK+, and it's not intrinsic to a graphical toolkit.\n\nIt's harder for users to write multiple s just like it's harder for users to write types. Bringing difficulty into it is missing the forest for the trees.\n\nInclude guards let you include a header file \"twice\" without it breaking compilation.\n\nRob Pike argues against include guards, saying you should just never include files in include files. He says that include guards still \"result in thousands of needless lines of code passing through the lexical analyzer\".\n\nIn fact, GCC will detect include guards, and won't read such files a second time. I don't know if other compilers perform this optimization.\n\nI don't think it's a good idea to require your users include the dependencies of your header files. Your header file's dependencies shouldn't really be considered \"public\". It would enforce the rule \"don't depend on what your header files include\", but it falls apart as soon as header files are using things you don't need, like or . Users shouldn't have to care about that if they don't need it themselves.\n\nSo, always write include guards, and make your users' lives easy.\n\nGlobal variables are just hidden arguments to all the functions that use them. They make it really hard to understand what a function does, and how it is controlled.\n\nMutable global variables are especially evil and should be avoided at all costs. Conceptually, a global variable assignment is a bunch of s to set hidden, static variables. Yuck.\n\nYou should always try to design your functions to be completely controllable by their arguments. Even if you have a variable that will have to be passed around to lots of a functions - if it affects their computation, it should be a argument or a member of a argument. This always leads to better code and better design.\n\nFor example, removing global variables and constants from my Trie.c project resulted in the struct, which lets users tune the storage structure to their needs. It also opened up some really cool dynamic abilities, like swapping alphabets on the fly for the same trie.\n\nStatic variables in functions are just global variables scoped to that function; the arguments above apply equally to them. Just like global variables, static variables are often used as an easy way out of providing modular, pure functions. They're often defended in the name of performance (benchmarks first!). You don't need static variables, just like you don't need global variables. If you need persistent state, have the function accept that state as a argument. If you need to return something persistent, allocate memory for it.\n\nYour header files should only include things that users need to use your library. Internal functions or structs or macros should not be provided here; declare them in their respective source files. If it's needed among multiple source files, provide an internal header file.\n\nIf a function or global variable isn't exported in the header, declare it as in the source file to give it internal linkage. This eliminates the chance of name-clashes among object files, enables a few optimizations, and can improve the linking speed.\n\nimproves compile-time correctness. It isn't only for documenting read-only pointers. It should be used for every read-only variable and pointee.\n\nhelps the reader immensely in understanding a piece of functionality. If they can look at an initialization and be sure that that value won't change throughout the scope, they can reason about the rest of the scope much easier. Without , everything is up in the air; the reader is forced to comprehend the entire scope to understand what is and isn't being modified. If you consistently use , your reader will begin to trust you, and will be able to assume that a variable that isn't qualified with is a signal that it will be changed at some point in the scope.\n\nUsing everywhere you can also helps you, as a developer, reason about what's happening in the control flow of your program, and where mutability is spreading. It's amazing, when using , how much more helpful the compiler is, especially regarding pointers and pointees. You always want the compiler on your side.\n\nThe compiler will warn if a pointee loses ness in a function call (because that would let the pointee be modified), but it won't complain if a pointee gains ness. Thus, if you don't specify your pointer arguments as when they're read-only anyway, you discourage your users from using in their own code:\n\nThus, using isn't really a choice, at least for function signatures. Lots of people consider it beneficial, so everyone should consider it required, whether they like it or not. If you don't use , you force your users to either cast all calls to your functions (yuck), ignore warnings (asking for trouble), or remove those qualifiers (lose compile-time correctness).\n\nIf you're forced to work with a library that ignores , you can write a macro that casts for you:\n\nOnly provide qualifiers for pointees in function prototypes - for the argument names themselves is just an implementation detail.\n\nUnfortunately, C can't handle conversions from non-const pointee-pointees to const pointee-pointees. Thus, I recommend against making pointee-pointees .\n\nIf you can the pointees of your internal structs, do. Non-constant pointees can cause mutability to needlessly spread, which makes it harder to glean information from the remaining qualifiers. Because you have total control over your internal structs, if you need to remove the in future, you can.\n\nYou usually shouldn't the pointees of your external structs. Flexibility is important when they're part of the public interface. Consider it carefully. An exception to this that I often make is for fields are best assignable to string literals, such as fields. In this case, a type prevents you and your users from modifying the underlying string literals, which would prompt a segmentation fault.\n\nWhile it can be reasonable to the pointees of struct fields, it's never beneficial to the struct fields themselves. For example, it makes it painful to a value of that struct. If it really makes sense to stop the fields from changing beyond their original values, just define invariants that enforce whatever qualities you need. Also, you and your users can just define individual variables of that struct as to get the same effect.\n\nOnly make return-type pointees if you need to, and after careful consideration. I've found that when the compiler is hinting to add a to a return type, it often means that a should be removed somewhere; not added. It can harm flexibility, so be careful.\n\nFinally, never use typecasts or pointers to get around qualifiers - at least, for things you control. If the variable isn't constant, don't make it one.\n\nBecause of this rule, you should always pad the type qualifier with spaces.\n\nBut, always declare the name of any pointer argument to communicate if it's a pointer-to-array (plural name) or a pointer-to-value (singular name).\n\nFrom 21st Century C, by Ben Klemens:\n\nFor the vast majority of applications nowadays, space isn't an issue, but floating-point errors can still pose a threat. It's much harder for numeric drift to cause problems for s than it is for s. Unless you have a very specific reason to use s, use s instead. Don't use s \"because they will be faster\", because without benchmarks, you can't know if it actually makes any discernible difference. Finish development, then perform benchmarks to identify the choke-points, then use s in those areas, and see if it actually helps. Before then, prioritize everything else over any supposed performance improvements. Don't prematurely optimize.\n\nDeclaring variables where they're used reminds the reader of the type they're working with. It also suggests where to extract a function to minimize variable scope. Furthermore, it informs the reader as to where each variables are relevant. Declaring variables when they're needed almost always leads to initialization ( ), rather than just declaration ( ). Initializing a variable usually often means you can it, too.\n\nTo me, all declarations (i.e. non-initializations) are shifty.\n\nThis makes the types easier to change in future, because atomic lines are easier to edit. If you'll need to change all their types together, you should use your editor's block editing mode.\n\nI think it's alright to bunch semantically-connected struct members together, though, because struct definitions are much easier to comprehend than active code.\n\nIf the scope fits on a screen, and the variable is used in a lot of places, and there would be an obvious letter or two to represent it, try it out and see if it helps readability. It probably will!\n\nConsistency helps your readers understand what's happening. Using different names for the same values in functions is suspicious, and forces your readers to reason about unimportant things.\n\nExplicit comparisons tell the reader what they're working with, because it's not always obvious in C, and it is always important. Are we working with counts or characters or booleans or pointers? The first thing I do when I see a variable being tested for truthiness in C is to hunt down the declaration to find its type. I really wish the programmer had just told me in the comparison.\n\nI'll often skip this rule for boolean functions named as a predicate, like or . It's still not completely obvious what the conditional is checking for, but I usually consider the visual clutter of a or to be more of a hassle than a help to readers in this situation. Use your judgement.\n\nReadable (imperative) programs flow from top to bottom: not right to left. Unfortunately, this happens way too much in C programming. I think the habit and practice was started by The C Programming Language, and it's stuck with much of the culture ever since. It's a really bad habit, and makes it so much harder to follow what your program is doing. Never change state in an expression.\n\nDon't use multiple assignment unless the variables' values are semantically linked. If there are two variable assignments near each other that coincidentally have the same value, don't throw them into a multiple assignment just to save a line.\n\nUse the comma operator, as above, judiciously. Do without it if you can:\n\nAssign function calls to a variable to describe what it is, even if the variable is as simple as an . This avoids surprising your readers with state changes from non-pure functions hidden inside conditional contexts. To me, it's really unnatural to think about the expression inside an changing things on the outside world. It's much clear to assign the result of that state change to a variable, and then check that value.\n\nEven if you think it's obvious, and it will save you a line - it's not worth the potential for a slip-up. Stick to this rule, and don't think about it.\n\nIf the function name is a predicate, like or , and will read naturally in a conditional context, then I think it's alright to skip assigning its result. It's also probably fine to join these kind of functions in a boolean expression if you need to, but use your judgement. Complex boolean expressions should often be extracted to a function.\n\nAlways use brackets, because it's safer, easier to change, and easier to read because it's more consistent. For the same reasons, don't put a single-line statement on the same line as the condition.\n\nWhat follows is actual code from The C Programming Language. Don't do this:\n\nCERT attempts to explain the integer conversion rules, saying:\n\nExpert C Programming (a great book that explores the ANSI standard) also explains this in its first chapter. The takeaway is that you shouldn't declare variables just because they shouldn't be negative. If you want a larger maximum value, use a or (the next size up).\n\nIf your function will fail with a negative number, it will probably also fail with a large number - which is what it will get if passed a negative number. If your function will fail with a negative number, just assert that it's positive. Remember, lots of dynamic languages make do with a single integer type that can be either sign.\n\nUnsigned values offer no type safety; even with and , GCC doesn't bat an eyelid at .\n\nExpert C Programming also provides an example for why you should cast all macros that will evaluate to an unsigned value.\n\nThe branch won't be executed, because will evaluate to an (via ). So, will be promoted to an . in two's complement represents the largest possible unsigned value (bit-wise), so the expression will be false, and the program will return . The solution in this case would be to cast the result of :\n\nYou will need to use unsigned values to provide well-defined bit operations and modular arithmetic overflow. But, try to keep those values contained, and don't let them interact with signed values.\n\nActually, don't use either form if you can help it. Changing state should always be avoided (within reason). But, when you have to, and are obvious, simpler and less cryptic than and , and useful in other contexts and with other values. Also, there are no tricks about the evaluation of and and they don't have weird twin operators to provide alternative evaluations. Python does without and operators, and Douglas Crockford excluded them from the Good Parts of JavaScript, because we don't need them. Sticking to this rule also encourages you to avoid changing state within an expression.\n\nYou can and should make exceptions for commonly-seen combinations of operations. For example, skipping the operators when combining the equality and boolean operators is fine, because readers are probably used to that, and are confident of the result.\n\nThe fall-through mechanism is error-prone, and you almost never want the cases to fall through anyway, so the vast majority of es are longer than the equivalent. Worse, a missing will still compile: this tripped me up all the time when I used . Also, values have to be an integral constant expression, so they can't match against another variable. This discourages extractions of logic to functions. Furthermore, any statement inside a can be labelled and jumped to, which fosters highly-obscure bugs if, for example, you mistype .\n\nIf you need to map different constant values to behavior, like:\n\nA more explicit, testable and reusable approach is to define a function that uses ternary expressions to return a function pointer of the right type:\n\nYou should do a similar thing if you need to map between two sets of uncorrelated constant values, like:\n\nDon't use a where you can just use a boolean expression:\n\nIf you need the fall-through behavior of , like:\n\nThe equivalent is much more readable and it's obvious what's going to happen and why. The \"B stuff\" actually applies when too, and this is explicitly declared when you use an .\n\nYou should only need to use for performance tuning (once you've done benchmarks to identify hotspots!). Otherwise, there's always a safer, shorter, more-testable, and reusable alternative.\n\nIf you limit yourself to a maximum of one blank line within functions, this rule provides clear visual separation of global elements. This is a habit I learned from Python's PEP8 style guide.\n\nIf a few variables are only used in a contiguous sequence of lines, and only a single value is used after that sequence, then those first lines are a great candidate for extracting to a function.\n\nIf the body of were left in , then the variable will be in the scope for the remainder of the function even though it's only used for getting the . This kind of thing adds to the cognitive load of understanding a function, and should be fixed wherever possible.\n\nAnother tactic to limit the exposure of variables is to break apart complex expressions into blocks, like so:\n\nIt can often help the readability of your code if you replace variables that are only assigned to constant expressions, with those expressions.\n\nConsider the example above - the expression is repeated twice. It would be harder to read and follow if we inserted an extra line to define a variable. It's just another thing that the readers would have to keep in mind. Many programmers of other languages wouldn't think twice about repeating an array access.\n\nThis is beneficial for the same reason as minimizing the scope of variables.\n\nMacros that loop over the elements of a data structure are extremely confusing, because they're extra-syntactic and readers can't know the control flow without looking up the definition.\n\nTo understand your program, it's crucial that your readers can understand its control flow.\n\nDon't provide control-macros even as an option. They're universally harmful, so don't enable it. Users can define their own if they really want to.\n\nBy \"act differently\", I mean if things will break when users wouldn't expect them to. If a macro just looks different (e.g. the named arguments technique), then I don't consider that justification for an upper-case name. A macro should have an upper-case name if it:\n• repeats its arguments in its body, because this will break for non-pure expressions. Many compilers provide statement expressions to prevent this, but it's non-standard. If you do use statement expressions, then you don't need to upper-case your macro name, because it's not relevant to your users.\n• is wrapped in blocks or a control structure, because it can't be used as an expression then.\n• modifies the surrounding context, e.g., with a or .\n• takes an array literal as a named argument. (why)\n\nFor the same reasons why we should always minimize the scope of our variables, if it makes sense to limit the scope of a macro, we should.\n\nAlways initialize your string literals as arrays, because it lets you get the byte size with just . If you initialize them as pointers, you have to get the byte size with - I know I've been bitten more than once by forgetting the there.\n\nAlso, pointer initializations are less safe than array initializations, unless you compile with to ensure string literals are initialized with the type . Unfortunately, isn't included in or : you have to explicitly enable it. Without , you can assign string literals to a . But your program will seg-fault when you re-assign the elements of that pointer.\n\nThe benefit of initializing string literals as pointers is that those pointers will point to read-only memory, potentially allowing some optimizations. Initializing string literals as arrays essentially creates a mutable string is only \"artificially\" protected against modifications with - but this can be defeated with a cast.\n\nAgain, I advise against prematurely optimizing. Until you've finished development and have done benchmarks, performance should be your lowest priority. I haven't seen any tests on string literal definitions, but I'd be very surprised to see any notable speed improvements by defining string literals as pointers.\n\nAs mentioned in the rule on ing everything: never ever cast away a . Remove the instead. Don't worry about \"artificial\" protections. I know I'd much prefer my constant values to be protected by explicit, syntactic constructs that will warn when compiling, rather than implicit, obscure rules that will seg-fault when violated.\n\nFinally, sticking to array initializations saves you and your readers the conceptual overhead of switching between pointer initializations and array initializations, depending on if you need mutability or not.\n\nJust always initialize string literals as arrays, and keep it simple.\n\nThen, if you change the type of the variable later, you only have to change it once. You'll always get the correct size.\n\nYou can't do this with compound literals, though. I think it's a worth-while trade-off to remove a variable that's only used once.\n\nArrays become pointers in most expressions, including when passed as arguments to functions. Functions can never receive an array as a argument: only a pointer to the array. won't work like an array argument declaration would suggest: it would return the size of the pointer, not the array pointed to.\n\nStatic array indices in function arguments are nice, but only protect against very trivial situations, like when given a literal . Also, GCC doesn't warn about their violation yet, only Clang. I don't consider the confusing, non-obvious syntax to be worth the small compilation check.\n\nYeah, hints that the argument will be treated as an array, but so does a plural name like , so do that instead.\n\nIf you're working with an array of things, treat them as an array. Pointer arithmetic is confusing and bug-prone. Sticking to array indexing often lets you keep the important variables constant, and only the index variables non-constant.\n\nFor any function that takes a struct (or a pointer to a struct), all invariants of that struct should be true before and after the execution of the function. Invariants make it the caller's responsibility to provide valid data, and the function's responsibility to return valid data. Invariants save those functions from having to repeat assertions of those conditions, or worse, not even checking and working with invalid data.\n\nProvide an \"invariants\" comment section at the end of your struct definition, and list all the invariants you can think of. Also, implement and functions for users to check those assertions on values of the structs they create on their own. These functions are crucial to being able to trust that the invariants hold for values of that struct. Without them, how will the users know?\n\nHere's an example of a struct invariant.\n\nMy university faculty is pretty big on software correctness. It certainly rubbed off on me.\n\nWrite assertions to meaningfully crash your program before it does something stupid, like deleting data, or to prevent a security vulnerability, or just to prevent a segmentation fault. Good software fails fast.\n\nIf a function is given a pointer it will dereference, assert that it's not null. If it's given an array index, assert that it's within bounds. Assert for any consistency that you need between arguments.\n\nThat said, never depend on assertions for correctness. Your program should still work correctly when the assertion lines are removed.\n\nDon't mistake assertions for error-reporting. Assert things that you won't bother to check otherwise. If user input (not code) can invalidate an assertion, that's a bug. You should be filtering it before-hand, and reporting the errors in a readable fashion for your users.\n\nRepeating your calls improves the assertion error reporting. If you chain assertions together with , you won't know which condition failed.\n\nVariable-length arrays were introduced in C99 as a way to define dynamic-length arrays with automatic storage; no need for . For a few reasons, they've been made optional in C11. Thus, if you want to use variable-length arrays in C11, you'll have to write the version anyway. Instead, just don't use variable-length arrays.\n\nI'd advise against using variable-length arrays in C99, too. First, you have to check the values that control their size to protect against stack-smashing. Second, they can't be initialized. Finally, avoiding them will make it easier to upgrade to newer standards later on.\n\nis useful for polymorphism, but polymorphism is almost never as important as type safety. Void pointers are indispensable in many situations, but you should consider other, safer alternatives first.\n\nJust like working with uninitialized variables is dangerous, working with void pointers is dangerous: you want the compiler on your side. So ditch the as soon as you can.\n\nIf only certain fields of your struct should be set when certain other fields have certain values, use C11's anonymous structs and unions:\n\nThis is much more explicit and obvious than something like:\n\nIf it's valid to assign a value of one type to a variable of another type, then you don't have to cast it. You should only use typecasts when you need to, like:\n• making an array index an integer, but you can do this with assignment anyway\n• using compound literals for structs and arrays\n\nTitleCase names should be used for structs so that they're recognizable without the prefix. They also let you name struct variables as the same thing as their type without names clashing (e.g. a of type ). You should always define the struct name, even if you don't need to, because you might need to later (e.g. to use as an incomplete type). Also, having a name at the top helps readability when comments are inserted, or the struct definition becomes large.\n\nI don't typedef structs used for named arguments (see below), however, because the TitleCase naming would be weird. Anyway, if you're using a macro for named arguments, then the typedef is unnecessary and the struct definition is hidden.\n\nIf a user dislikes this practice of typedefing structs (which is fair, because it does have drawbacks - see below), they can always use the namespace instead.\n\nThis mistake is committed by way too many codebases. It masks what's really going on, and you have to read documentation or find the to learn how to work with it. Never do this in your own interfaces, and try to ignore the typedefs in other interfaces.\n\nThese criticisms apply equally to struct typedefs, as advised above. In my opinion, the visual clarity achieved by removing all the declarations is worth requiring users be aware of (or realize) the convention. Also, having a consistent naming scheme for structs, with TitleCase names, helps recognizability.\n\nPointer typedefs are particularly nefarious because they exclude the users from qualifying the pointee with . This is a huge loss, for reasons enumerated in other rules.\n\nFunction pointer typedefs are justified when you need to declare a function that returns a function pointer; the syntax without a typedef is unbearable. I'll also typedef a function pointer if the type is being repeated in many locations (more than three, or so). Some people like to typedef all function pointers, but this often masks what's going on and what's expected. Carefully consider if a function pointer typedef will actually help people understand what that type represents.\n\nBecause enums are mostly just integer constants, it's natural to name them the same way as d constants. The type prefix will communicate that it expects an enum value, and the lowercase value suffixes will communicate that they aren't quite integer constants.\n\nThere's no versatile, future-proof way to work with loops, arrays, or bit-fields of the otherwise. Always define a constant to denote the size of the enumeration, to avoid hard-coded values (by you or your users).\n\nI like to the size explicitly, rather than making it the last enum value. It seems natural to exclude the size of the enum from the actual enum itself - isn't a card suit I've ever heard of! It also protects against one of the previous enum values from being explicitly set (e.g. ), which would mean the last enum value wouldn't represent the size of the enum.\n\nHere's a list of the names reserved by future ISO C standards. and are identifiers that are reserved by future standards of C, so don't use them for your own identifiers.\n\nThese kinds of names could've provided a nice way to tell which types are part of the language standard and which types are provided by libraries. Unfortunately, it's not hard to find popular C libraries and projects that make this mistake, which dilutes the helpfulness of such a rule.\n\nThis mistake is made way too often: don't make the same mistake in your library!\n\nEvery pointer in a struct is an opportunity for a segmentation fault.\n\nIf the would-be pointer shouldn't be NULL, isn't an array of an unknown size, and isn't of the type of the struct itself, then don't make it a pointer. Just include a member of the type itself in the struct. Don't worry about the size of the containing struct until you've done benchmarks.\n\nThis rule helps readers reason about where values are being modified. It also improves the safety by making it impossible for functions that shouldn't receive from receiving -- this is a huge benefit over languages that require pass-by-reference semantics (and thus as a valid value almost everywhere).\n\nWhen you're reading a codebase that sticks to this rule, and its functions and types are maximally decomposed, you can often tell what a function does just by reading its prototype. This is in stark contrast to projects that pass pointers everywhere: you have no certainty anywhere.\n\nIn C, you can pass struct values to functions, and by pass-by-value semantics, they'll be copied into the stack frame of the receiving function. The original struct can't be modified by that function (although it can return the modification). Like , using this feature wherever you can makes it easier for your readers to reason about your program.\n\nDefining a \"modification\" gets tricky when you introduce structs with pointer members. I consider a modification to be something that affects the struct itself, or the pointees of the struct.\n\nIf a struct will be \"modified\" by a function, have that function accept a pointer of that struct even if it doesn't need to. This saves the readers from having to find and memorize every relevant struct definition, to be aware of which structs have pointer members.\n\nNote the const-ness of the argument above: this communicates that the country itself won't be modified, but a pointee (although it could also be taken to suggest that the pointer is for nullity, but the function name suggests otherwise). It also allows callers to pass in a pointer to a .\n\nThe other situation to use pointer arguments is if the function needs to accept as a valid value (i.e. the poor man's Maybe). If so, be sure use to signal that the pointer is not for modification, and so it can accept arguments.\n\nSticking to this rule means ditching incomplete struct types, but I don't really like them anyway. (see the \"C isn't object-oriented\" rule)\n\nThis encourages immutability, cultivates pure functions, and makes things simpler and easier to understand. It also improves safety by eliminating the possibility of a argument.\n\nThis isn't always the best way to go, but it's something you should always consider.\n\nI learnt this from 21st Century C. So many C interfaces could be improved immensely if they took advantage of this technique. The importance and value of (syntactic) named arguments is all-too-often overlooked in software development. If you're not convinced, read Bret Victor's Learnable Programming.\n\nDon't use named arguments everywhere. If a function's only argument happens to be a struct, that doesn't necessarily mean it should become the named arguments for that function. A good rule of thumb is that if the struct is used outside of that function, you shouldn't hide it with a macro like above.\n\nSometimes I'll bend this rule for named arguments, by having a particular field be at the top of the struct, so that callers can call the function without having to name that single argument:\n\nIf you want to allow this, document it explicitly. It's then your responsibility to version your library correctly, if you change the ordering of the fields.\n\nIf you're providing and functions only so you can allocate memory for a member of the struct, you've lost the benefits and safety of automatic storage. You may as well have the allocation and free methods allocate memory for the whole struct, so users can pass it outside the scope it was defined (without dereferencing it), if they want.\n\nIf you're seeking encapsulation in C, you're probably overcomplicating things. Encourage your users to access and set struct members directly; never prefix members with to denote an access level. Declare your struct invariants, and you don't need to worry about your users breaking things - it's their responsibility to provide a valid struct.\n\nAs advised in another rule, avoid mutability wherever you can.\n\nBut you should always provide an interface that allows for declarative programming:\n\nC doesn't have classes, methods, inheritance, (nice) object encapsulation, or real polymorphism. Not to be rude, but: deal with it. C might be able to achieve crappy, complicated imitations of those things, but it's just not worth it.\n\nAs it turns out, C already has an entirely-capable language model. In C, we define data structures, and we define functionality that uses combinations of those data structures. Data and functionality aren't intertwined in complicated contraptions, and this is a good thing.\n\nHaskell, at the forefront of language design, made the same decision to separate data and functionality. Learning Haskell is one of the best things a programmer can do to improve their technique, but I think it's especially beneficial for C programmers, because of the underlying similarities between C and Haskell. Yes, C doesn't have anonymous functions, and no, you won't be writing monads in C anytime soon. But by learning Haskell, you'll learn how to write good software without classes, without mutability, and with modularity. These qualities are very beneficial for good C programming.\n\nEmbrace and appreciate what C offers, rather than attempting to graft other paradigms onto it."
    },
    {
        "link": "https://he.kendallhunt.com/sites/default/files/heupload/Chen_IntroProgramming_Ch2.pdf",
        "document": ""
    },
    {
        "link": "https://quora.com/What-are-some-C-programming-best-practices",
        "document": "Something went wrong. Wait a moment and try again."
    },
    {
        "link": "https://upwork.com/resources/what-is-c",
        "document": "Check out our latest products, partners, and enhancements.\n\nNews and stories from the world’s work marketplace.\n\nInsights and tools for business leaders navigating a new world of work."
    },
    {
        "link": "https://tutorialspoint.com/pascal/pascal_loops.htm",
        "document": "There may be a situation, when you need to execute a block of code several number of times. In general, statements are executed sequentially: The first statement in a function is executed first, followed by the second, and so on.\n\nProgramming languages provide various control structures that allow for more complicated execution paths.\n\nA loop statement allows us to execute a statement or group of statements multiple times and following is the general form of a loop statement in most of the programming languages −\n\nPascal programming language provides the following types of loop constructs to handle looping requirements. Click the following links to check their details.\n\nwhile-do loop Repeats a statement or group of statements while a given condition is true. It tests the condition before executing the loop body. for-do loop Executes a sequence of statements multiple times and abbreviates the code that manages the loop variable. repeat-until loop Like a while statement, except that it tests the condition at the end of the loop body. nested loops You can use one or more loop inside any another while, for or repeat until loop.\n\nLoop control statements change execution from its normal sequence. When execution leaves a scope, all automatic objects that were created in that scope are destroyed.\n\nPascal supports the following control statements. Click the following links to check their details."
    },
    {
        "link": "https://lechaamwe.weebly.com/uploads/2/6/6/5/26654545/pe231_lecture6b.pdf",
        "document": ""
    },
    {
        "link": "https://en.wikipedia.org/wiki/Control_flow",
        "document": "In computer science, control flow (or flow of control) is the order in which individual statements, instructions or function calls of an imperative program are executed or evaluated. The emphasis on explicit control flow distinguishes an imperative programming language from a declarative programming language.\n\nWithin an imperative programming language, a control flow statement is a statement that results in a choice being made as to which of two or more paths to follow. For non-strict functional languages, functions and language constructs exist to achieve the same result, but they are usually not termed control flow statements.\n\nA set of statements is in turn generally structured as a block, which in addition to grouping, also defines a lexical scope.\n\nInterrupts and signals are low-level mechanisms that can alter the flow of control in a way similar to a subroutine, but usually occur as a response to some external stimulus or event (that can occur asynchronously), rather than execution of an in-line control flow statement.\n\nAt the level of machine language or assembly language, control flow instructions usually work by altering the program counter. For some central processing units (CPUs), the only control flow instructions available are conditional or unconditional branch instructions, also termed jumps.\n\nThe kinds of control flow statements supported by different languages vary, but can be categorized by their effect:\n• Continuation at a different statement (unconditional branch or jump)\n• Executing a set of statements only if some condition is met (choice - i.e., conditional branch)\n• Executing a set of statements zero or more times, until some condition is met (i.e., loop - the same as conditional branch)\n• Executing a set of distant statements, after which the flow of control usually returns (subroutines, coroutines, and continuations)\n• Stopping the program, preventing any further execution (unconditional halt)\n\nA label is an explicit name or number assigned to a fixed position within the source code, and which may be referenced by control flow statements appearing elsewhere in the source code. A label marks a position within source code and has no other effect.\n\nLine numbers are an alternative to a named label used in some languages (such as BASIC). They are whole numbers placed at the start of each line of text in the source code. Languages which use these often impose the constraint that the line numbers must increase in value in each following line, but may not require that they be consecutive. For example, in BASIC:\n\nIn other languages such as C and Ada, a label is an identifier, usually appearing at the start of a line and immediately followed by a colon. For example, in C:\n\nThe language ALGOL 60 allowed both whole numbers and identifiers as labels (both linked by colons to the following statement), but few if any other ALGOL variants allowed whole numbers. Early Fortran compilers only allowed whole numbers as labels. Beginning with Fortran-90, alphanumeric labels have also been allowed.\n\nThe goto statement (a combination of the English words go and to, and pronounced accordingly) is the most basic form of unconditional transfer of control.\n\nAlthough the keyword may either be in upper or lower case depending on the language, it is usually written as:\n\nThe effect of a goto statement is to cause the next statement to be executed to be the statement appearing at (or immediately after) the indicated label.\n\nGoto statements have been considered harmful by many computer scientists, notably Dijkstra.\n\nThe terminology for subroutines varies; they may alternatively be known as routines, procedures, functions (especially if they return results) or methods (especially if they belong to classes or type classes).\n\nIn the 1950s, computer memories were very small by current standards so subroutines were used mainly to reduce program size. A piece of code was written once and then used many times from various other places in a program.\n\nToday, subroutines are more often used to help make a program more structured, e.g., by isolating some algorithm or hiding some data access method. If many programmers are working on one program, subroutines are one kind of modularity that can help divide the work.\n\nIn structured programming, the ordered sequencing of successive commands is considered one of the basic control structures, which is used as a building block for programs alongside iteration, recursion and choice.\n\nIn May 1966, Böhm and Jacopini published an article[1] in Communications of the ACM which showed that any program with gotos could be transformed into a goto-free form involving only choice (IF THEN ELSE) and loops (WHILE condition DO xxx), possibly with duplicated code and/or the addition of Boolean variables (true/false flags). Later authors showed that choice can be replaced by loops (and yet more Boolean variables).\n\nThat such minimalism is possible does not mean that it is necessarily desirable; computers theoretically need only one machine instruction (subtract one number from another and branch if the result is negative), but practical computers have dozens or even hundreds of machine instructions.\n\nOther research showed that control structures with one entry and one exit were much easier to understand than any other form,[citation needed] mainly because they could be used anywhere as a statement without disrupting the control flow. In other words, they were composable. (Later developments, such as non-strict programming languages – and more recently, composable software transactions – have continued this strategy, making components of programs even more freely composable.)\n\nSome academics took a purist approach to the Böhm–Jacopini result and argued that even instructions like and from the middle of loops are bad practice as they are not needed in the Böhm–Jacopini proof, and thus they advocated that all loops should have a single exit point. This purist approach is embodied in the language Pascal (designed in 1968–1969), which up to the mid-1990s was the preferred tool for teaching introductory programming in academia.[2] The direct application of the Böhm–Jacopini theorem may result in additional local variables being introduced in the structured chart, and may also result in some code duplication.[3] Pascal is affected by both of these problems and according to empirical studies cited by Eric S. Roberts, student programmers had difficulty formulating correct solutions in Pascal for several simple problems, including writing a function for searching an element in an array. A 1980 study by Henry Shapiro cited by Roberts found that using only the Pascal-provided control structures, the correct solution was given by only 20% of the subjects, while no subject wrote incorrect code for this problem if allowed to write a return from the middle of a loop.[2]\n\nMost programming languages with control structures have an initial keyword which indicates the type of control structure involved.[clarification needed] Languages then divide as to whether or not control structures have a final keyword.\n• No final keyword: ALGOL 60, C, C++, Go, Haskell, Java, Pascal, Perl, PHP, PL/I, Python, PowerShell. Such languages need some way of grouping statements together:\n• C, C++, Go, Java, Perl, PHP, and PowerShell: curly brackets ...\n• Haskell: either indent level or curly brackets can be used, and they can be freely mixed\n• Final keyword: Ada, APL, ALGOL 68, Modula-2, Fortran 77, Mythryl, Visual Basic. The forms of the final keyword vary:\n• APL: final keyword is optionally + initial keyword, e.g., ... or ... , ... or ... , however, if adding an end condition, the end keyword becomes\n• Modula-2: same final keyword for everything\n• Visual Basic: every control structure has its own keyword. ... ; ... ; ... ; ...\n\nConditional expressions and conditional constructs are features of a programming language that perform different computations or actions depending on whether a programmer-specified Boolean condition evaluates to true or false.\n• . A form found in unstructured languages, mimicking a typical machine code instruction, would jump to (GOTO) a label or line number when the condition was met.\n• . Rather than being restricted to a jump, any simple statement, or nested block, could follow the THEN key keyword. This a structured form.\n• . As above, but with a second action to be performed if the condition is false. This is one of the most common forms, with many variations. Some require a terminal , others do not. C and related languages do not require a terminal keyword, or a 'then', but do require parentheses around the condition.\n• Conditional statements can be and often are nested inside other conditional statements. Some languages allow and to be combined into , avoiding the need to have a series of or other final statements at the end of a compound statement.\n• Some languages, such as early Fortran, a have a three-way or arithmetic if, testing whether a numeric value is negative, zero, or positive.\n• Some languages have a functional form of an statement, for instance Lisp's .\n• Some languages have an operator form of an statement, such as C's ternary operator.\n• Smalltalk uses and messages to implement conditionals, rather than any fundamental language construct.\n\nSwitch statements (or case statements, or multiway branches) compare a given value with specified constants and take action according to the first constant to match. There is usually a provision for a default action (\"else\", \"otherwise\") to be taken if no match succeeds. Switch statements can allow compiler optimizations, such as lookup tables. In dynamic languages, the cases may not be limited to constant expressions, and might extend to pattern matching, as in the shell script example on the right, where the implements the default case as a glob matching any string. Case logic can also be implemented in functional form, as in SQL's statement.\n\nA loop is a sequence of statements which is specified once but which may be carried out several times in succession. The code \"inside\" the loop (the body of the loop, shown below as xxx) is obeyed a specified number of times, or once for each of a collection of items, or until some condition is met, or indefinitely. When one of those items is itself also a loop, it is called a \"nested loop\".[4][5][6]\n\nIn functional programming languages, such as Haskell and Scheme, both recursive and iterative processes are expressed with tail recursive procedures instead of looping constructs that are syntactic.\n\nMost programming languages have constructions for repeating a loop a certain number of times. In most cases counting can go downwards instead of upwards and step sizes other than 1 can be used.\n\nIn these examples, if N < 1 then the body of loop may execute once (with I having value 1) or not at all, depending on the programming language.\n\nIn many programming languages, only integers can be reliably used in a count-controlled loop. Floating-point numbers are represented imprecisely due to hardware constraints, so a loop such as\n\n\n\nmight be repeated 9 or 10 times, depending on rounding errors and/or the hardware and/or the compiler version. Furthermore, if the increment of X occurs by repeated addition, accumulated rounding errors may mean that the value of X in each iteration can differ quite significantly from the expected sequence 0.1, 0.2, 0.3, ..., 1.0.\n\nMost programming languages have constructions for repeating a loop until some condition changes. Some variations test the condition at the start of the loop; others test it at the end. If the test is at the start, the body may be skipped completely; if it is at the end, the body is always executed at least once.\n\nA control break is a value change detection method used within ordinary loops to trigger processing for groups of values. Values are monitored within the loop and a change diverts program flow to the handling of the group event associated with them.\n\nSeveral programming languages (e.g., Ada, D, C++11, Smalltalk, PHP, Perl, Object Pascal, Java, C#, MATLAB, Visual Basic, Ruby, Python, JavaScript, Fortran 95 and later) have special constructs which allow implicit looping through all elements of an array, or all members of a set or collection.\n\nScala has for-expressions, which generalise collection-controlled loops, and also support other uses, such as asynchronous programming. Haskell has do-expressions and comprehensions, which together provide similar function to for-expressions in Scala.\n\nGeneral iteration constructs such as C's statement and Common Lisp's form can be used to express any of the above sorts of loops, and others, such as looping over some number of collections in parallel. Where a more specific looping construct can be used, it is usually preferred over the general iteration construct, since it often makes the purpose of the expression clearer.\n\nInfinite loops are used to assure a program segment loops forever or until an exceptional condition arises, such as an error. For instance, an event-driven program (such as a server) should loop forever, handling events as they occur, only stopping when the process is terminated by an operator.\n\nInfinite loops can be implemented using other control flow constructs. Most commonly, in unstructured programming this is jump back up (goto), while in structured programming this is an indefinite loop (while loop) set to never end, either by omitting the condition or explicitly setting it to true, as . Some languages have special constructs for infinite loops, typically by omitting the condition from an indefinite loop. Examples include Ada ( ),[7] Fortran ( ), Go ( ), and Ruby ( ).\n\nOften, an infinite loop is unintentionally created by a programming error in a condition-controlled loop, wherein the loop condition uses variables that never change within the loop.\n\nSometimes within the body of a loop there is a desire to skip the remainder of the loop body and continue with the next iteration of the loop. Some languages provide a statement such as (most languages), ,[8] (Fortran), or (Perl and Ruby), which will do this. The effect is to prematurely terminate the innermost loop body and then resume as normal with the next iteration. If the iteration is the last one in the loop, the effect is to terminate the entire loop early.\n\nSome languages, like Perl[9] and Ruby,[10] have a statement that restarts the current iteration from the start.\n\nRuby has a statement that restarts the entire loop from the initial iteration.[11]\n\nWhen using a count-controlled loop to search through a table, it might be desirable to stop searching as soon as the required item is found. Some programming languages provide a statement such as (most languages), (Visual Basic), or (Perl), which effect is to terminate the current loop immediately, and transfer control to the statement immediately after that loop. Another term for early-exit loops is loop-and-a-half.\n\nThe following example is done in Ada which supports both early exit from loops and loops with test in the middle. Both features are very similar and comparing both code snippets will show the difference: early exit must be combined with an if statement while a condition in the middle is a self-contained construct.\n\nPython supports conditional execution of code depending on whether a loop was exited early (with a statement) or not by using an else-clause with the loop. For example,\n\nThe clause in the above example is linked to the statement, and not the inner statement. Both Python's and loops support such an else clause, which is executed only if early exit of the loop has not occurred.\n\nSome languages support breaking out of nested loops; in theory circles, these are called multi-level breaks. One common use example is searching a multi-dimensional table. This can be done either via multilevel breaks (break out of N levels), as in bash[12] and PHP,[13] or via labeled breaks (break out and continue at given label), as in Go, Java and Perl.[14] Alternatives to multilevel breaks include single breaks, together with a state variable which is tested to break out another level; exceptions, which are caught at the level being broken out to; placing the nested loops in a function and using return to effect termination of the entire nested loop; or using a label and a goto statement. C does not include a multilevel break, and the usual alternative is to use a goto to implement a labeled break.[15] Python does not have a multilevel break or continue – this was proposed in PEP 3136, and rejected on the basis that the added complexity was not worth the rare legitimate use.[16]\n\nThe notion of multi-level breaks is of some interest in theoretical computer science, because it gives rise to what is today called the Kosaraju hierarchy.[17] In 1973 S. Rao Kosaraju refined the structured program theorem by proving that it is possible to avoid adding additional variables in structured programming, as long as arbitrary-depth, multi-level breaks from loops are allowed.[18] Furthermore, Kosaraju proved that a strict hierarchy of programs exists: for every integer n, there exists a program containing a multi-level break of depth n that cannot be rewritten as a program with multi-level breaks of depth less than n without introducing added variables.[17]\n\nOne can also out of a subroutine executing the looped statements, breaking out of both the nested loop and the subroutine. There are other proposed control structures for multiple breaks, but these are generally implemented as exceptions instead.\n\nIn his 2004 textbook, David Watt uses Tennent's notion of sequencer to explain the similarity between multi-level breaks and return statements. Watt notes that a class of sequencers known as escape sequencers, defined as \"sequencer that terminates execution of a textually enclosing command or procedure\", encompasses both breaks from loops (including multi-level breaks) and return statements. As commonly implemented, however, return sequencers may also carry a (return) value, whereas the break sequencer as implemented in contemporary languages usually cannot.[19]\n\nLoop variants and loop invariants are used to express correctness of loops.[20]\n\nIn practical terms, a loop variant is an integer expression which has an initial non-negative value. The variant's value must decrease during each loop iteration but must never become negative during the correct execution of the loop. Loop variants are used to guarantee that loops will terminate.\n\nA loop invariant is an assertion which must be true before the first loop iteration and remain true after each iteration. This implies that when a loop terminates correctly, both the exit condition and the loop invariant are satisfied. Loop invariants are used to monitor specific properties of a loop during successive iterations.\n\nSome programming languages, such as Eiffel contain native support for loop variants and invariants. In other cases, support is an add-on, such as the Java Modeling Language's specification for loop statements in Java.\n\nSome Lisp dialects provide an extensive sublanguage for describing Loops. An early example can be found in Conversional Lisp of Interlisp. Common Lisp[21] provides a Loop macro which implements such a sublanguage.\n• does not count as an infinite loop for this purpose, because it is not a dedicated language structure.\n• C's loop is a general loop construct, not specifically a counting one, although it is often used for that.\n• Deep breaks may be accomplished in APL, C, C++ and C# through the use of labels and gotos.\n• Iteration over objects was added in PHP 5.\n• A counting loop can be simulated by iterating over an incrementing list or generator, for instance, Python's .\n• Deep breaks may be accomplished through the use of exception handling.\n• There is no special construct, since the function can be used for this.\n• There is no special construct, but users can define general loop functions.\n• The C++11 standard introduced the range-based for. In the STL, there is a template function which can iterate on STL containers and call a unary function for each element. 22 The functionality also can be constructed as macro on these containers. 23\n• Count-controlled looping is effected by iteration across an integer interval; early exit by including an additional condition for exit.\n• Eiffel supports a reserved word , however it is used in exception handling, not loop control.\n• Requires loop variants to be integers; transfinite variants are not supported. [1]\n• D supports infinite collections, and the ability to iterate over those collections. This does not require any special construct.\n• Deep breaks can be achieved using and procedures.\n\nMany programming languages, especially those favoring more dynamic styles of programming, offer constructs for non-local control flow. These cause the flow of execution to jump out of a given context and resume at some predeclared point. Conditions, exceptions and continuations are three common sorts of non-local control constructs; more exotic ones also exist, such as generators, coroutines and the async keyword.\n\nThe earliest Fortran compilers had statements for testing exceptional conditions. These included the , , and statements. In the interest of machine independence, they were not included in FORTRAN IV and the Fortran 66 Standard. However since Fortran 2003 it is possible to test for numerical issues via calls to functions in the module.\n\nPL/I has some 22 standard conditions (e.g., ZERODIVIDE SUBSCRIPTRANGE ENDFILE) which can be raised and which can be intercepted by: ON condition action; Programmers can also define and use their own named conditions.\n\nLike the unstructured if, only one statement can be specified so in many cases a GOTO is needed to decide where flow of control should resume.\n\nUnfortunately, some implementations had a substantial overhead in both space and time (especially SUBSCRIPTRANGE), so many programmers tried to avoid using conditions.\n\nModern languages have a specialized structured construct for exception handling which does not rely on the use of or (multi-level) breaks or returns. For example, in C++ one can write:\n\nAny number and variety of clauses can be used above. If there is no matching a particular , control percolates back through subroutine calls and/or nested blocks until a matching is found or until the end of the main program is reached, at which point the program is forcibly stopped with a suitable error message.\n\nVia C++'s influence, is the keyword reserved for declaring a pattern-matching exception handler in other languages popular today, like Java or C#. Some other languages like Ada use the keyword to introduce an exception handler and then may even employ a different keyword ( in Ada) for the pattern matching. A few languages like AppleScript incorporate placeholders in the exception handler syntax to automatically extract several pieces of information when the exception occurs. This approach is exemplified below by the construct from AppleScript:\n\nDavid Watt's 2004 textbook also analyzes exception handling in the framework of sequencers (introduced in this article in the section on early exits from loops). Watt notes that an abnormal situation, generally exemplified with arithmetic overflows or input/output failures like file not found, is a kind of error that \"is detected in some low-level program unit, but [for which] a handler is more naturally located in a high-level program unit\". For example, a program might contain several calls to read files, but the action to perform when a file is not found depends on the meaning (purpose) of the file in question to the program and thus a handling routine for this abnormal situation cannot be located in low-level system code. Watts further notes that introducing status flags testing in the caller, as single-exit structured programming or even (multi-exit) return sequencers would entail, results in a situation where \"the application code tends to get cluttered by tests of status flags\" and that \"the programmer might forgetfully or lazily omit to test a status flag. In fact, abnormal situations represented by status flags are by default ignored!\" Watt notes that in contrast to status flags testing, exceptions have the opposite default behavior, causing the program to terminate unless the program deals with the exception explicitly in some way, possibly by adding explicit code to ignore it. Based on these arguments, Watt concludes that jump sequencers or escape sequencers are less suitable as a dedicated exception sequencer with the semantics discussed above.[24]\n\nIn Object Pascal, D, Java, C#, and Python a clause can be added to the construct. No matter how control leaves the the code inside the clause is guaranteed to execute. This is useful when writing code that must relinquish an expensive resource (such as an opened file or a database connection) when finished processing:\n\nSince this pattern is fairly common, C# has a special syntax:\n\nUpon leaving the -block, the compiler guarantees that the object is released, effectively binding the variable to the file stream while abstracting from the side effects of initializing and releasing the file. Python's statement and Ruby's block argument to are used to similar effect.\n\nAll the languages mentioned above define standard exceptions and the circumstances under which they are thrown. Users can throw exceptions of their own; C++ allows users to throw and catch almost any type, including basic types like , whereas other languages like Java are less permissive.\n\nC# 5.0 introduced the async keyword for supporting asynchronous I/O in a \"direct style\".\n\nGenerators, also known as semicoroutines, allow control to be yielded to a consumer method temporarily, typically using a keyword (yield description) . Like the async keyword, this supports programming in a \"direct style\".\n\nCoroutines are functions that can yield control to each other - a form of co-operative multitasking without threads.\n\nCoroutines can be implemented as a library if the programming language provides either continuations or generators - so the distinction between coroutines and generators in practice is a technical detail.\n\nIn a spoof Datamation article[31] in 1973, R. Lawrence Clark suggested that the GOTO statement could be replaced by the COMEFROM statement, and provides some entertaining examples. COMEFROM was implemented in one esoteric programming language named INTERCAL.\n\nDonald Knuth's 1974 article \"Structured Programming with go to Statements\",[32] identifies two situations which were not covered by the control structures listed above, and gave examples of control structures which could handle these situations. Despite their utility, these constructs have not yet found their way into mainstream programming languages.\n\nThe following was proposed by Dahl in 1972:[33]\n\nIf xxx1 is omitted, we get a loop with the test at the top (a traditional while loop). If xxx2 is omitted, we get a loop with the test at the bottom, equivalent to a do while loop in many languages. If while is omitted, we get an infinite loop. The construction here can be thought of as a do loop with the while check in the middle. Hence this single construction can replace several constructions in most programming languages.\n\nLanguages lacking this construct generally emulate it using an equivalent infinite-loop-with-break idiom:\n\nA possible variant is to allow more than one while test; within the loop, but the use of exitwhen (see next section) appears to cover this case better.\n\nIn Ada, the above loop construct (loop-while-repeat) can be represented using a standard infinite loop (loop - end loop) that has an exit when clause in the middle (not to be confused with the exitwhen statement in the following section).\n\nNaming a loop (like Read_Data in this example) is optional but permits leaving the outer loop of several nested loops.\n\nThis construct was proposed by Zahn in 1974.[34] A modified version is presented here.\n\nexitwhen is used to specify the events which may occur within xxx, their occurrence is indicated by using the name of the event as a statement. When some event does occur, the relevant action is carried out, and then control passes just after endexit. This construction provides a very clear separation between determining that some situation applies, and the action to be taken for that situation.\n\nexitwhen is conceptually similar to exception handling, and exceptions or similar constructs are used for this purpose in many languages.\n\nThe following simple example involves searching a two-dimensional table for a particular item.\n\nOne way to attack a piece of software is to redirect the flow of execution of a program. A variety of control-flow integrity techniques, including stack canaries, buffer overflow protection, shadow stacks, and vtable pointer verification, are used to defend against these attacks.[35][36][37]\n• None \"Structured Programming with Go To Statements\" . Archived from the original on 2009-08-24."
    },
    {
        "link": "https://cs.fsu.edu/~lacher/courses/COP4020/fall10/lectures/ControlFlow.pdf",
        "document": ""
    },
    {
        "link": "https://sciencedirect.com/topics/computer-science/control-flow-construct",
        "document": ""
    }
]