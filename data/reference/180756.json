[
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/csharp/asynchronous-programming/async-scenarios",
        "document": "If your code implements I/O-bound scenarios to support network data requests, database access, or file system read/writes, asynchronous programming is the best approach. You can also write asynchronous code for CPU-bound scenarios like expensive calculations.\n\nC# has a language-level asynchronous programming model that allows you to easily write asynchronous code without having to juggle callbacks or conform to a library that supports asynchrony. The model follows what is known as the Task-based asynchronous pattern (TAP).\n\nThe and objects represent the core of asynchronous programming. These objects are used to model asynchronous operations by supporting the and keywords. In most cases, the model is fairly simple for both I/O-bound and CPU-bound scenarios. Inside an method:\n• I/O-bound code starts an operation represented by a or object within the method.\n• CPU-bound code starts an operation on a background thread with the Task.Run method.\n\nIn both cases, an active represents an asynchronous operation that might not be complete.\n\nThe keyword is where the magic happens. It yields control to the caller of the method that contains the expression, and ultimately allows the UI to be responsive or a service to be elastic. While there are ways to approach asynchronous code other than by using the and expressions, this article focuses on the language-level constructs.\n\nWhen you implement asynchronous programming in your C# code, the compiler transforms your program into a state machine. This construct tracks various operations and state in your code, such as yielding execution when the code reaches an expression, and resuming execution when a background job completes.\n\nIn terms of computer science theory, asynchronous programming is an implementation of the Promise model of asynchrony.\n\nIn the asynchronous programming model, there are several key concepts to understand:\n• You can use asynchronous code for both I/O-bound and CPU-bound code, but the implementation is different.\n• Asynchronous code uses and objects as constructs to model work running in the background.\n• The keyword declares a method as an asynchronous method, which allows you to use the keyword in the method body.\n• When you apply the keyword, the code suspends the calling method and yields control back to its caller until the task completes.\n• You can only use the expression in an asynchronous method.\n\nIn this example, when the user selects a button, the app downloads data from a web service. You don't want to block the UI thread for the app during the download process. The following code accomplishes this task:\n\nThe code expresses the intent (downloading data asynchronously) without getting bogged down in interacting with objects.\n\nIn the next example, a mobile game inflicts damage on several agents on the screen in response to a button event. Performing the damage calculation can be expensive. Running the calculation on the UI thread can cause display and UI interaction issues during the calculation.\n\nThe best way to handle the task is to start a background thread to complete the work with the method. The operation yields by using an expression. The operation resumes when the task completes. This approach allows the UI to run smoothly while the work completes in the background.\n\nThe code clearly expresses the intent of the button event. It doesn't require managing a background thread manually, and it completes the task in a nonblocking manner.\n\nThe previous examples demonstrate how to use the modifier and expression for I/O-bound and CPU-bound work. An example for each scenario showcases how the code is different based on where the operation is bound. To prepare for your implementation, you need to understand how to identify when an operation is I/O-bound or CPU-bound. Your implementation choice can greatly affect the performance of your code and potentially lead to misusing constructs.\n\nThere are two primary questions to address before you write any code:\n\nAlways measure the execution of your code. You might discover that your CPU-bound work isn't costly enough compared with the overhead of context switches when multithreading. Every choice has tradeoffs. Pick the correct tradeoff for your situation.\n\nThe examples in this section demonstrate several ways you can write asynchronous code in C#. They cover a few scenarios you might encounter.\n\nThe following code downloads HTML from a given URL and counts the number of times the string \".NET\" occurs in the HTML. The code uses ASP.NET to define a Web API controller method, which performs the task and returns the count.\n\nYou can write similar code for a Universal Windows App and perform the counting task after a button press:\n\nIn some scenarios, the code needs to retrieve multiple pieces of data concurrently. The APIs provide methods that enable you to write asynchronous code that performs a nonblocking wait on multiple background jobs:\n\nThe following example shows how you might grab object data for a set of objects.\n\nYou can write this code more succinctly by using LINQ:\n\nAlthough you write less code by using LINQ, exercise caution when mixing LINQ with asynchronous code. LINQ uses deferred (or lazy) execution. Asynchronous calls don't happen immediately as they do in a loop, unless you force the generated sequence to iterate with a call to the or method. This example uses the Enumerable.ToArray method to perform the query eagerly and store the results in an array. This approach forces the statement to run and initiate the task.\n\nWith asynchronous programming, there are several details to keep in mind that can prevent unexpected behavior.\n\nWhen you use the modifier, you should include one or more expressions in the method body. If the compiler doesn't encounter an expression, the method fails to yield. Although the compiler generates a warning, the code still compiles and the compiler runs the method. The state machine generated by the C# compiler for the asynchronous method doesn't accomplish anything, so the entire process is highly inefficient.\n\nThe .NET style convention is to add the \"Async\" suffix to all asynchronous method names. This approach helps to more easily differentiate between synchronous and asynchronous methods. Certain methods that aren't explicitly called by your code (such as event handlers or web controller methods) don't necessarily apply in this scenario. Because these items aren't explicitly called by your code, using explicit naming isn't as important.\n\nEvent handlers must declare return types and can't use or return and objects as other methods do. When you write asynchronous event handlers, you need to use the modifier on a returning method for the handlers. Other implementations of returning methods don't follow the TAP model and can present challenges:\n• Exceptions thrown in an method can't be caught outside of that method\n• methods can cause negative side effects if the caller isn't expecting them to be asynchronous\n\nUse caution with asynchronous lambdas in LINQ\n\nIt's important to use caution when you implement asynchronous lambdas in LINQ expressions. Lambda expressions in LINQ use deferred execution, which means the code can execute at an unexpected time. The introduction of blocking tasks into this scenario can easily result in a deadlock, if the code isn't written correctly. Moreover, the nesting of asynchronous code can also make it difficult to reason about the execution of the code. Async and LINQ are powerful, but these techniques should be used together as carefully and clearly as possible.\n\nIf your program needs the result of a task, write code that implements the expression in a nonblocking manner. Blocking the current thread as a means to wait synchronously for a item to complete can result in deadlocks and blocked context threads. This programming approach can require more complex error-handling. The following table provides guidance on how access results from tasks in a nonblocking way:\n\nWhen an asynchronous method returns a object, performance bottlenecks might be introduced in certain paths. Because is a reference type, a object is allocated from the heap. If a method declared with the modifier returns a cached result or completes synchronously, the extra allocations can accrue significant time costs in performance critical sections of code. This scenario can become costly when the allocations occur in tight loops. For more information, see generalized async return types.\n\nDevelopers often inquire about when to use the Task.ConfigureAwait(Boolean) boolean. This API allows for a instance to configure the context for the state machine that implements any expression. When the boolean isn't set correctly, performance can degrade or deadlocks can occur. For more information, see ConfigureAwait FAQ.\n\nAvoid writing code that depends on the state of global objects or the execution of certain methods. Instead, depend only on the return values of methods. There are many benefits to writing code that is less-stateful:\n• More simple to mix asynchronous and synchronous code\n• Able to avoid race conditions in code\n• Simple to coordinate asynchronous code that depends on return values\n• (Bonus) Works well with dependency injection in code\n\nA recommended goal is to achieve complete or near-complete Referential Transparency in your code. This approach results in a predictable, testable, and maintainable codebase.\n\nThe following code represents the complete example, which is available in the Program.cs example file."
    },
    {
        "link": "https://learn.microsoft.com/en-us/dotnet/csharp/asynchronous-programming",
        "document": "The Task asynchronous programming (TAP) model provides a layer of abstraction over typical asynchronous coding. In this model, you write code as a sequence of statements, the same as usual. The difference is you can read your task-based code as the compiler processes each statement and before it starts processing the next statement. To accomplish this model, the compiler performs many transformations to complete each task. Some statements can initiate work and return a Task object that represents the ongoing work and the compiler must resolve these transformations. The goal of task asynchronous programming is to enable code that reads like a sequence of statements, but executes in a more complicated order. Execution is based on external resource allocation and when tasks complete.\n\nThe task asynchronous programming model is analogous to how people give instructions for processes that include asynchronous tasks. This article uses an example with instructions for making breakfast to show how the and keywords make it easier to reason about code that includes a series of asynchronous instructions. The instructions for making a breakfast might be provided as a list:\n• Spread butter and jam on the toast.\n\nIf you have experience with cooking, you might complete these instructions asynchronously. You start warming the pan for eggs, then start frying the bacon. You put the bread in the toaster, then start cooking the eggs. At each step of the process, you start a task, and then transition to other tasks that are ready for your attention.\n\nCooking breakfast is a good example of asynchronous work that isn't parallel. One person (or thread) can handle all the tasks. One person can make breakfast asynchronously by starting the next task before the previous task completes. Each cooking task progresses regardless of whether someone is actively watching the process. As soon as you start warming the pan for the eggs, you can begin frying the bacon. After the bacon starts to cook, you can put the bread in the toaster.\n\nFor a parallel algorithm, you need multiple people who cook (or multiple threads). One person cooks the eggs, another fries the bacon, and so on. Each person focuses on their one specific task. Each person who is cooking (or each thread) is blocked synchronously waiting for the current task to complete: Bacon ready to flip, bread ready to pop up in toaster, and so on.\n\nConsider the same list of synchronous instructions written as C# code statements:\n\nIf you interpret these instructions as a computer would, breakfast takes about 30 minutes to prepare. The duration is the sum of the individual task times. The computer blocks for each statement until all work completes, and then it proceeds to the next task statement. This approach can take significant time. In the breakfast example, the computer method creates an unsatisfying breakfast. Later tasks in the synchronous list, like toasting the bread, don't start until earlier tasks complete. Some food gets cold before the breakfast is ready to serve.\n\nIf you want the computer to execute instructions asynchronously, you must write asynchronous code. When you write client programs, you want the UI to be responsive to user input. Your application shouldn't freeze all interaction while downloading data from the web. When you write server programs, you don't want to block threads that might be serving other requests. Using synchronous code when asynchronous alternatives exist hurts your ability to scale out less expensively. You pay for blocked threads.\n\nSuccessful modern apps require asynchronous code. Without language support, writing asynchronous code requires callbacks, completion events, or other means that obscure the original intent of the code. The advantage of synchronous code is the step-by-step action that makes it easy to scan and understand. Traditional asynchronous models force you to focus on the asynchronous nature of the code, not on the fundamental actions of the code.\n\nThe previous code highlights an unfortunate programming practice: Writing synchronous code to perform asynchronous operations. The code blocks the current thread from doing any other work. The code doesn't interrupt the thread while there are running tasks. The outcome of this model is similar to staring at the toaster after you put in the bread. You ignore any interruptions and don't start other tasks until the bread pops up. You don't take the butter and jam out of the fridge. You might miss seeing a fire starting on the stove. You want to both toast the bread and handle other concerns at the same time. The same is true with your code.\n\nYou can start by updating the code so the thread doesn't block while tasks are running. The keyword provides a nonblocking way to start a task, then continue execution when the task completes. A simple asynchronous version of the breakfast code looks like the following snippet:\n\nThe code updates the method bodies of , , and to return , , and objects, respectively. The method names include the \"Async\" suffix. The method returns the object, although it doesn't have a expression, which is by design. For more information, see Evaluation of a void-returning async function.\n\nLet's apply the breakfast example to the updated code. The thread doesn't block while the eggs or bacon are cooking, but the code also doesn't start other tasks until the current work completes. You still put the bread in the toaster and stare at the toaster until the bread pops up, but you can now respond to interruptions. In a restaurant where multiple orders are placed, the cook can start a new order while another is already cooking.\n\nIn the updated code, the thread working on the breakfast isn't blocked while waiting for any started task that's unfinished. For some applications, this change is all you need. You can enable your app to support user interaction while data downloads from the web. In other scenarios, you might want to start other tasks while waiting for the previous task to complete.\n\nFor most operations, you want to start several independent tasks immediately. As each task completes, you initiate other work that's ready to start. When you apply this methodology to the breakfast example, you can prepare breakfast more quickly. You also get everything ready close to the same time, so you can enjoy a hot breakfast.\n\nThe System.Threading.Tasks.Task class and related types are classes you can use to apply this style of reasoning to tasks that are in progress. This approach enables you to write code that more closely resembles the way you create breakfast in real life. You start cooking the eggs, bacon, and toast at the same time. As each food item requires action, you turn your attention to that task, take care of the action, and then wait for something else that requires your attention.\n\nIn your code, you start a task and hold on to the Task object that represents the work. You use the method on the task to delay acting on the work until the result is ready.\n\nApply these changes to the breakfast code. The first step is to store the tasks for operations when they start, rather than using the expression:\n\nThese revisions don't help to get your breakfast ready any faster. The expression is applied to all tasks as soon as they start. The next step is to move the expressions for the bacon and eggs to the end of the method, before you serve the breakfast:\n\nYou now have an asynchronously prepared breakfast that takes about 20 minutes to prepare. The total cook time is reduced because some tasks run concurrently.\n\nThe code updates improve the preparation process by reducing the cook time, but they introduce a regression by burning the eggs and bacon. You start all the asynchronous tasks at once. You wait on each task only when you need the results. The code might be similar to program in a web application that makes requests to different microservices and then combines the results into a single page. You make all the requests immediately, and then apply the expression on all those tasks and compose the web page.\n\nThe previous code revisions help get everything ready for breakfast at the same time, except the toast. The process of making the toast is a composition of an asynchronous operation (toast the bread) with synchronous operations (spread butter and jam on the toast). This example illustrates an important concept about asynchronous programming:\n\nIn the previous updates, you learned how to use Task or Task<TResult> objects to hold running tasks. You wait on each task before you use its result. The next step is to create methods that represent the combination of other work. Before you serve breakfast, you want to wait on the task that represents toasting the bread before you spread the butter and jam.\n\nYou can represent this work with the following code:\n\nThe method has the modifier in its signature that signals to the compiler that the method contains an expression and contains asynchronous operations. The method represents the task that toasts the bread, then spreads the butter and jam. The method returns a Task<TResult> object that represents the composition of the three operations.\n\nThe revised main block of code now looks like this:\n\nThis code change illustrates an important technique for working with asynchronous code. You compose tasks by separating the operations into a new method that returns a task. You can choose when to wait on that task. You can start other tasks concurrently.\n\nUp to this point, your code implicitly assumes all tasks complete successfully. Asynchronous methods throw exceptions, just like their synchronous counterparts. The goals for asynchronous support for exceptions and error handling are the same as for asynchronous support in general. The best practice is to write code that reads like a series of synchronous statements. Tasks throw exceptions when they can't complete successfully. The client code can catch those exceptions when the expression is applied to a started task.\n\nIn the breakfast example, suppose the toaster catches fire while toasting the bread. You can simulate that problem by modifying the method to match the following code:\n\nAfter you make the code changes, run the application and check the output:\n\nNotice that quite a few tasks finish between the time when the toaster catches fire and the system observes the exception. When a task that runs asynchronously throws an exception, that task is faulted. The object holds the exception thrown in the Task.Exception property. Faulted tasks throw an exception when the expression is applied to the task.\n\nThere are two important mechanisms to understand about this process:\n• How an exception is stored in a faulted task\n• How an exception is unpackaged and rethrown when code waits ( ) on a faulted task\n\nWhen code running asynchronously throws an exception, the exception is stored in the object. The Task.Exception property is a System.AggregateException object because more than one exception might be thrown during asynchronous work. Any exception thrown is added to the AggregateException.InnerExceptions collection. If the property is null, a new object is created and the thrown exception is the first item in the collection.\n\nThe most common scenario for a faulted task is that the property contains exactly one exception. When your code waits on a faulted task, it rethrows the first AggregateException.InnerExceptions exception in the collection. This result is the reason why the output from the example shows an System.InvalidOperationException object rather than an object. Extracting the first inner exception makes working with asynchronous methods as similar as possible to working with their synchronous counterparts. You can examine the property in your code when your scenario might generate multiple exceptions.\n\nBefore you continue to the next section, comment out the following two statements in your method. You don't want to start another fire:\n\nYou can improve the series of expressions at the end of the previous code by using methods of the class. One API is the WhenAll method, which returns a Task object that completes when all the tasks in its argument list are complete. The following code demonstrates this method:\n\nAnother option is to use the WhenAny method, which returns a object that completes when any of its arguments complete. You can wait on the returned task because you know the task is done. The following code shows how you can use the WhenAny method to wait on the first task to finish and then process its result. After you process the result from the completed task, you remove the completed task from the list of tasks passed to the method.\n\nNear the end of the code snippet, notice the expression. The expression doesn't wait on the finished task, but rather waits on the object returned by the method. The result of the method is the completed (or faulted) task. The best practice is to wait on the task again, even when you know the task is complete. In this manner, you can retrieve the task result, or ensure any exception that causes the task to fault is thrown.\n\nHere's what the final version of the code looks like:\n\nThe code completes the asynchronous breakfast tasks in about 15 minutes. The total time is reduced because some tasks run concurrently. The code simultaneously monitors multiple tasks and takes action only as needed.\n\nThe final code is asynchronous. It more accurately reflects how a person might cook breakfast. Compare the final code with the first code sample in the article. The core actions are still clear by reading the code. You can read the final code the same way you read the list of instructions for making a breakfast, as shown at the beginning of the article. The language features for the and keywords provide the translation every person makes to follow the written instructions: Start tasks as you can and don't block while waiting for tasks to complete."
    },
    {
        "link": "https://pullrequest.com/blog/leveraging-async-await-in-asp-net-for-enhanced-performance",
        "document": "In the realm of ASP.NET, the async/await pattern stands as a powerful tool to enhance the performance and responsiveness of web applications. This approach, central to modern software development, allows developers to perform non-blocking operations, thereby improving the efficiency of resource utilization and application scalability. In this article, we’ll delve into practical strategies and code snippets that demonstrate how to effectively use async/await in ASP.NET, focusing on common pitfalls and secure remedies.\n\nAt its core, the async/await pattern in C# is designed to handle asynchronous operations without the complexity that traditionally accompanies asynchronous programming. The keyword marks a method for asynchronous operations, while is used to suspend the execution of the method until the awaited task is completed.\n\nIn this snippet, is an asynchronous method that returns a . The keyword ensures that the execution of is paused until completes, without blocking the thread.\n\nOne of the prime scenarios for async/await in ASP.NET is handling I/O bound operations like database calls, file reads/writes, or web requests. These operations can significantly benefit from asynchronous execution as they often involve waiting for external resources.\n\nConsider the following example of a database operation using Entity Framework:\n\nHere, is an async version of , ensuring that the database operation does not block the thread while it’s waiting for the response.\n\nOne of the most common issues with async/await is deadlocks. These occur when the synchronization context waits for an async operation to complete, but that operation is waiting for the context to be free.\n• Avoid using or on tasks; these methods can cause deadlocks in an ASP.NET context.\n• Always use when the context is not needed to resume execution, as in library code.\n\nWhile async/await is powerful, it’s not a silver bullet. Overusing it, especially for CPU-bound work, can lead to performance degradation. Remember, async/await is best used for I/O-bound operations.\n\nAsync/await improves scalability by freeing up threads while waiting for I/O operations to complete. This is particularly beneficial in web applications, where each request typically consumes a thread. By using async/await, you can serve more requests with the same number of threads.\n\nAsynchronous methods should include proper error handling to manage exceptions. Use try/catch blocks to catch exceptions from awaited tasks:\n\nWhenever possible, use asynchronous versions of library methods. For instance, if you’re working with Entity Framework, use instead of , or instead of in HttpClient.\n\nKeep an eye on your application’s performance metrics to understand the impact of asynchronous programming. Tools like Application Insights in Azure can be invaluable for this purpose.\n\nIf you’re working with ASP.NET Core, the benefits are even more pronounced due to its asynchronous nature. ASP.NET Core is designed to work with asynchronous programming models, making it easier to integrate async/await throughout your application.\n\nThe async/await pattern in ASP.NET is a powerful paradigm that, when used correctly, can significantly enhance the performance and scalability of your web applications. By understanding its proper use, avoiding common pitfalls, and adhering to best practices, you can ensure that your application remains responsive and efficient under load.\n\nFor more in-depth reading, Microsoft’s official documentation on async/await in ASP.NET is an excellent resource, providing detailed explanations and additional examples.\n\nRemember, while async/await is a powerful tool, it’s not a panacea. It should be used judiciously, especially in scenarios involving I/O bound operations, to truly reap its benefits in terms of performance and scalability."
    },
    {
        "link": "https://code-maze.com/asynchronous-programming-with-async-and-await-in-asp-net-core",
        "document": "In this article, we are going to learn about asynchronous programming with the async and await keywords in the ASP.NET Core projects. We are going to dive deep inside these keywords and explain their advantages and how they help us scale our application. Additionally, we are going to explain the complete process of converting the synchronous project to the asynchronous one by using the async and await keywords. Even though we are going to use the ASP.NET Core Web API project as our example project, the knowledge you will get from this article is applicable to any .NET application.\n\nVIDEO: Asynchronous Programming With Async and Await in .NET.\n\nBy using asynchronous programming, we avoid performance bottlenecks and enhance the responsiveness of our applications. It is a programming technique that allows us to execute our flows without blocking our application or causing the thread pool starvation.\n\nThe often misconception is that by using the async and await keywords we gain better performance in terms of the speed of our application. But that’s not the case. For example, if we have synchronous code that fetches the data from the database and it takes three seconds to complete, our asynchronous code won’t be any faster than that. But we do get an indirect performance improvement regarding how many concurrent requests our server can handle. In other words, we increase the scalability of our application by using the async and await keywords.\n\nSo, let’s talk a bit about scaling and learn why is it so important.\n\nWhen we deploy our API to the server, that server can handle only a certain amount of requests. If our API receives more requests than our server can handle, the overall performance of our application will suffer. So, what we can do is to add an additional server to handle those additional requests, and we call it horizontal scaling. The other thing we can do is to improve the allocated resources on that single server by increasing the memory or CPU power, and we call this vertical scaling. So in other words, if we create an application in such a way that the resource utilization is improved, we improve the scalability of our application. That’s exactly why async code is important. By its proper usage, we can increase the vertical scalability at the server level of our API.\n\nNow, let’s see how the synchronous and asynchronous requests work in ASP.NET Core.\n\nHow Synchronous and Asynchronous Requests Work in ASP.NET Core\n\nLet’s start with the synchronous request first.\n\nWhen a client sends a request to our API to fetch the list of companies from the database, the ASP.NET Core assigns the thread from a thread pool to handle that request. Just for the sake of simplicity, let’s imagine that our thread pool has two threads. So, we have used one thread. Now, the second request arrives and we have to use the second thread from a thread pool. As you can see, our thread pool is out of threads. If a third request arrives now, it has to wait for any of the first two requests to complete and return assigned threads to a thread pool. Only then the thread pool can assign that returned thread to a new request:\n\nAs a result of a request waiting for an available thread, our client experiences a slow down for sure. Additionally, if the client has to wait too long, they will receive an error response, usually, the service is unavailable (503). But this is not the only problem. Since the client expects the list of companies from the database, we know that it is an I/O operation. So, if we have a lot of companies in the database and it takes three seconds for the database to return a result to the API, our thread is doing nothing except waiting for the task to complete. So basically, we are blocking that thread and making it three seconds unavailable for any additional requests that arrive at our API.\n\nWith asynchronous requests, the situation is completely different.\n\nWhen a request arrives at our API, we still need a thread from a thread pool. So, that leaves us with only one thread left. But because this action is now asynchronous, as soon as our request reaches the I/O point where the database has to process the result for three seconds, the thread is returned to a thread pool. Now we again have two available threads and we can use them for any additional request. After the three seconds when the database returns the result to the API, the thread pool assigns the thread again to handle that response:\n\nThis means that we can handle a lot more requests, we are not blocking our threads, and we are not forcing threads to wait (and do nothing) for three seconds until the database finishes its work. All of these leads to improved scalability of our application.\n\nUsing the Async and Await Keywords in our ASP.NET Core Application\n\nThese two keywords – async and await – play a key role in asynchronous programming in ASP.NET Core. We use the async keyword in the method declaration and its purpose is to enable the await keyword within that method. So yes, you can’t use the await keyword without previously adding the async keyword in the method declaration. Also, using only the async keyword doesn’t make your method asynchronous, just the opposite, that method is still synchronous.\n\nThe await keyword performs an asynchronous wait on its argument. It does that in several steps. The first thing it does is to check whether the operation is already complete. If it is, it will continue the method execution synchronously. Otherwise, the await keyword is going to pause the async method execution and return an incomplete task. Once the operation completes, a few seconds later, the async method can continue with the execution.\n\nLet’s see this with a simple example:\n\nSo, even though our method is marked with the async keyword, it will start its execution synchronously. Once we log the required information in a synchronous manner, we continue to the next code line. There, we extract all the companies from the database. As you can see, we use the keyword here. If our database requires some time to process the result and return it back, the keyword is going to pause the method execution and return an incomplete task. During that time, the thread will be returned to a thread pool making itself available for another request. After the database operation completes, the async method will resume executing and will return the list of companies.\n\nFrom this example, we see the async method execution flow. But the question is, how does the await keyword know if the operation is completed or not? Well, this is where the Task comes into play.\n\nIn asynchronous programming we have three return types:\n• Task<TResult>, for an async method that returns a value\n• Task, to use it for an async method that does not return a value\n• void, which we can use for an event handler\n\nWhen our method returns Task<TResult>, as in our previous example, it will return a result of type TResult in an asynchronous manner. So, if we want to return we are going to use as the return type. Of course, as you saw in a previous example, if we want to return IEnumerable<Company>, we are going to use .\n\nWhen we don’t want to return a value from our async method, we usually return . This means that we can use the await keyword inside that method but without the return keyword.\n\nWe should use void only for the asynchronous event handlers which require a void return type. Like the button click handler in GUI applications. Other than that, we should always return a Task. Using void with the asynchronous method is not recommended because such methods are hard to test, catching errors is hard as well, and finally, there is no easy way to provide the caller with the status of the asynchronous operation. So, as you can read in many articles or books, we should avoid using the keyword with asynchronous methods.\n\nFrom C# 7.0 onward, we can specify any other return type, if it includes the method.\n\nNow, it is very important to understand that the Task represents an execution of the asynchronous method and not the result. The Task has several properties that indicate whether the operation completed successfully or not (Status, IsCompleted, IsCanceled, IsFaulted). With these properties, we can track the flow of our async operations. So, this is the answer to our question. With Task, we can track whether the operation is completed or not. This is also called TAP (Task-based Asynchronous Pattern).\n\nImplementing Asynchronous Programming with Async and Await Keywords in ASP.NET Core\n\nSo, it’s time to rewrite our synchronous project into the asynchronous one. In our GitHub repository, you can find a start folder with the starting project. Feel free to use it to follow along with the coding examples. You will find several projects inside the solution but the two most important classes for our examples are the class inside the CompanyEmployees project, and the class inside the Repository project:\n\nTo seed the data, just modify the connection string inside the file (if you have to) and run the command from PMC.\n\nSo, let’s open the file and inspect the method:\n\nJust a simple method that retrieves all the companies from the database ordering them by name.\n\nTo implement the asynchronous programming inside this method, we can follow what we have learned so far from this article:\n\nWe add the async keyword to the method signature and also we wrap the return type with Task. To use Task in our code, we have to add the using directive. Then, inside the method, we use the await keyword – we’ve already explained why we need it – and we convert the method to the method. The method comes from the namespace and it serves the purpose to execute our query in an asynchronous manner. Finally, as a result, we return the list of companies.\n\nIf we didn’t know better, we could’ve been tempted to execute our asynchronous operation with the property:\n\nWe can see that the property returns the result we require:\n\nWith this code, we are going to block the thread and potentially cause a deadlock in the application, which is the exact thing we are trying to avoid using the async and await keywords. It applies the same to the method that we can call on a Task.\n\nWith this out of the way, we can continue.\n\nSince our inherits from the interface, we have to add some modifications there as well:\n\nOf course, if you want, you can use a lambda expression body for our method:\n\nIt is up to you whether you want to do it this way.\n\nWhen we use asynchronous programming in our code, we have to implement it through the entire flow. Since our action inside the calls this async method from the repository class, we have to modify the action inside the controller as well:\n\nAs you can see, we do three things here. We add an keyword to the method signature, modify the return type by using , and we use the keyword when we call the awaitable method.\n\nThe rest of the code – the mapping part, the logging part, and the return of the result – will be executed after the awaitable operation completes. This represents continuation.\n\nThe await keyword does three things:\n• It helps us extract the result from the async operation – we already learned about that\n• Validates the success of the operation\n• Provides the Continuation for executing the rest of the code in the async method\n\nSo, in our action, all the code after awaiting an async operation is executed inside the continuation if the async operation was successful.\n\nWhen we talk about continuation, it can be confusing because you can read a lot of articles about SynchronizationContext and capture the current context to enable this continuation. Basically, when we await a task, a request context is captured when await decides to pause the method execution. Once the method is ready to resume its execution, the application takes a thread from a thread pool, assigns it to the context (SynchonizationContext), and resumes the execution. But this is the case for ASP.NET applications.\n\nWe don’t have in ASP.NET Core applications. ASP.NET Core avoids capturing and queuing the context, all it does is take the thread from a thread pool and assign it to the request. So, a lot less background work for the application to do.\n\nOne more thing. We are not limited to a single continuation. This means that in a single method, we can have multiple await keywords, like for example when we send an HTTP request using the HttpClient:\n\nHere you can see several continuations in action.\n\nBased on our previous knowledge, we are pretty sure you can convert the method and action from synchronous to asynchronous. The process is the same since both methods return Task<T>.\n\nThat said, let’s modify the interface first:\n\nThen, we have to modify the method itself:\n\nAnd that’s it. Both the and methods return Task<T> and we can use the same principle to convert them.\n\nBut, what about the method? Currently, it returns void. Well, as we said, if our async method doesn’t return any result, we are going to use just a Task for the return type.\n\nSo, let’s start with the interface modification:\n\nAs you can see, instead of the void keyword, we use just a Task.\n\nNow, we can modify the method implementation:\n\nBut what if our asynchronous operation fails?\n\nLet’s see how we can handle that.\n\nAs we mentioned in the continuation section of this article, the await keyword validates the success of the asynchronous operation. So, all we have to do is to wrap the code inside the try/catch block to catch those exceptions if they occur.\n\nJust for testing purposes, let’s modify the method by throwing a simple exception:\n\nNow, we can wrap our code from the action inside the block:\n\nPay attention that we removed the await keyword just to show you what the faulted async operation returns and how our code behaves without it.\n\nSo, if we place a breakpoint in this action and send the get request from Postman, we are going to see that the async operation returns a faulted task:\n\nThis task has a single exception and a property set to . But, as you can see, we didn’t enter the block, our code just continues with the execution. That’s because, without the await keyword, the task swallows the exception. Furthermore, there is no more continuation and the operation is not validated. If you continue the execution of this action, you will get an exception, but it will be the mapping exception and not the exception that we throw from our async method.\n\nSo, let’s return the await keyword where it belongs:\n\nNow, if we run our code, the await keyword will validate the operation, and as soon as it notices that the task has a faulted state, the code will continue execution inside the catch block. This means that we are going to get a valid error message in Postman and a valid log in the file:\n\nThere we go.\n\nOf course, if you don’t want to write try/catch blocks in every action in your project, you can use the Global Exception Handling technique, to catch exceptions in a single place.\n\nWe’ve covered a lot of areas in this article, and learned a lot about using the async and await keywords in ASP.NET Core applications. Of course, we can always extract some key points that we must pay attention to:\n• We always have to use the async and await keywords together. By using just the async keyword, our methods will not be asynchronous\n• When we don’t want to return a result from our async method, we should always return a Task\n• To validate our asynchronous operations, we have to use the await keyword while calling that operation\n• When we convert our synchronous code to asynchronous, we have to use the async and await keywords all the way up the chain\n• We should avoid using the keyword in asynchronous methods unless we are working with event handlers (Windows, WPF apps)\n• To get the result from an async operation, we should use the await keyword and not the Result property or the Wait method. These can cause a deadlock in our app\n\nSo, that’s it. We hope you learned a lot from this article.\n\nUntil the next one."
    },
    {
        "link": "https://medium.com/@deep_blue_day/long-story-short-async-await-best-practices-in-net-1f39d7d84050",
        "document": "Async all the way\n\nAs you start working with async methods, you will quickly realize that the asynchronous nature of the code starts spreading up and down your hierarchy of method calls — meaning, you need to make your invoking code asynchronous as well and so on.\n\nYou may be tempted to “stop” this by blocking in your code using Task.Result or Task.Wait, converting just a small part of the application and wrapping it in a synchronous API so the rest of the application is isolated from the changes. Unfortunately, this is a recipe for creating hard to track deadlocks.\n\nThe best solution to this problem is to allow async code to grow naturally through the codebase. If you follow this solution, you’ll see async code expand to its entry point, usually an event handler or controller action. Embrace async all the way!\n\nMore information in this article by MSDN.\n\nIf a method is declared async, make sure there is an await!\n\nAs we already discussed, when the compiler finds an async method, it turns the method into a State Machine. If your code does not have an await in its body, the compiler will generate a warning but the state machine will be created nevertheless, adding unnecessary overhead for an operation that will actually never yield.\n\nAsync void is a big no-no. As a rule of thumb consider using async Task instead of async void.\n\nThere are several reasons for this, including:\n• Exceptions thrown in an async void method can’t be caught outside of that method: When an exception is thrown out of an async Task or async Task<T> method, that exception is captured and placed on the Task object. With async void methods, there is no Task object, so any exceptions thrown out of an async void method will be raised directly on the SynchronizationContext that was active when the async void method started.\n\nConsider the example below. The catch block will never be reached.\n\nCompare to this code where instead of async void we have an async Task. In this case, the catch is actually reached.\n• async void methods can cause bad side effects if the caller isn’t expecting them to be async: If your asynchronous method returns nothing, use async Task (without “<T>” for the Task) as the return type.\n• Async void methods are very difficult to test: Because of the differences in error handling and composing, it’s difficult to write unit tests that call async void methods. The MSTest asynchronous testing support only works for async methods returning Task or Task<T>.\n\nThe exception to this best practice is asynchronous event handlers. Even in this case, it is recommended that you minimize the code written in the handler itself — await an async Task method that contains the actual logic.\n\nMore information in this article by MSDN.\n\nConsider using return Task instead of return await\n\nAs it was already discussed, every time you declare a method as async, the compiler to create a State Machine class that actually wraps your method logic. This adds a certain amount of overhead that may add up, particularly for mobile devices, where we have stricter resource constraints.\n\nSometimes the method does not need to be async, but return a Task<T> and let the other side handle it as appropriate. If the last sentence of your code is a return await you may actually consider refactoring it so that the return type of the method is Task<T> (instead of async T). With this, you are avoiding the generation of the state machine, thus making your code leaner. The only time we truly want to await is when we do something with the result of the async task in the continuation of the method.\n\nNote that if we don’t have return await, but return a Task<T> instead, the return happens right away, so, if the code is inside a try/catch block, the exception will not be caught. Similarly, if the code is inside a using block, it will dispose the object right away. See next best practice.\n\nDo not wrap return Task inside try..catch{} or using{} block\n\nReturn Task can cause unexpected behavior used inside a try..catch block (an exception thrown by the async method will never be caught) or inside a using block because the task will be returned right away.\n\nIf you need to wrap your async code in a try..catch or using block, use return await instead.\n\nMore information in this stack overflow thread.\n\nAvoid using .Wait() or .Result — Use GetAwaiter().GetResult() instead\n\nIf you have to block waiting the completion of an Async Task, use GetAwaiter().GetResult(). Wait and Result will wrap any exceptions within an AggregateException, which complicates error handling — The advantage of GetAwaiter().GetResult() is that it returns a normal exception instead of an AggregateException.\n\nMore information in this link.\n\nIf a method is async, add the Async suffix to its name\n\nThis is the convention used in .NET to more-easily differentiate synchronous and asynchronous methods (except event handlers or web controller methods, but those should not be explicitly called by your code anyway).\n\nAsync library methods should consider using Task.ConfigureAwait(false) to boost performance\n\n.NET framework has the notion of “synchronization context”, which represents a way to “get back to where you were before” — Whenever a Task is awaited, it captures current synchronization context before awaiting.\n\nUpon Task completion, the .Post() method of synchronization context is invoked to resume where it was before. This is useful to get back to UI thread or to resume back to same ASP.NET context, etc.\n\nWhen writing library code though, you rarely need to go back to the context where you were before. When Task.ConfigureAwait(false) is used, the code no longer tries to resume where it was before, instead, if possible, the code completes in the thread that completed the task, thus avoiding a context switch. This slightly boosts performance and can help avoid deadlocks as well.\n\nThis is particularly important when the library method is called a large number of times, to have better responsiveness.\n\nAs a rule of thumb use ConfigureAwait(false) for server-side processes in general. We don’t care which thread is used for the continuation, as opposed to applications where we need to come back to UI thread.\n\nNow…In ASP.NET Core, Microsoft did away with the SynchronizationContext, so in theory, you don’t need this. But, if you are writing library code that could be potentially reused in other applications (i.e: UI App, Legacy ASP.NET, Xamarin Forms), it remains a best practice.\n\nFor a good explanation on this concept, see this video by Channel 9.\n\nA fairly common use-case for async methods is to do work in the background, freeing up the UI thread to do other things, and maintain responsiveness. In this scenario, you may want to report progress back to the UI, so the user can follow the progress and interact with the operation.\n\nIn order to solve this common problem, .NET provides the IProgress<T> interface, which exposes a Report<T> method, which the async task invokes to report progress back to the caller. This interface is received as a parameter of the async method — the caller must provide an object that implements this interface.\n\n.NET provides Progress<T>, a default implementation of IProgress<T>, which is actually encouraged to be used, as it handles all the low-level logic related to saving and restoring the synchronization context. Progress<T> also exposes an event and an Action<T> callback — both are called when the task reports progress.\n\nTogether, IProgress<T> and Progress<T> provide an easy way to pass progress information from a background task to the UI thread.\n\nNote that <T> can be a simple value such as an int, or an object that provides contextual information about the progress, such as progress percentage, a string description of the current operation, ETA, and so on.\n\nDo consider how often you report progress. Depending on the operation at hand, you may find that your code reports progress several times per second, which may actually cause the UI to become less responsive. In this kind of scenario, it is recommended to report progress back in coarser-grained intervals.\n\nMore information in this article by official Microsoft .NET Blog.\n\nAnother common use-case for background tasks, is having the ability to cancel execution. .NET provides the CancellationToken class. The async method receives a CancellationToken, which is then shared by the caller code, and the async method, thus providing a mechanism to signal cancellation.\n\nIn the most common case, cancellation follows this flow:\n• The caller calls a cancelable async API, and passes the CancellationToken from the CancellationTokenSource (CancellationTokenSource.Token).\n• The caller requests cancellation using the CancellationTokenSource object (CancellationTokenSource.Cancel()).\n• The task acknowledges the cancellation and cancels itself, typically using the CancellationToken.ThrowIfCancellationRequested method.\n\nNote that in order for this mechanism to work, you will need to write code to check for the cancellation being requested at regular intervals (i.e: on every iteration of your code, or at natural stopping point in the logic). Ideally, once cancellation has been requested, an async Task should cancel as quickly as possible.\n\nYou should consider using cancellation for all methods that may take a long time to complete.\n\nMore information in this article by official Microsoft .NET Blog.\n\nReporting progress and cancellation — An example\n\nIf you need to wait for a period of time (for example, to retry to check if a resource becomes available), make sure to use Task.Delay — never use Thread.Sleep in this scenario.\n\nUse Task.WaitAny to wait for any task to complete. Use Task.WaitAll to wait for all tasks to complete."
    },
    {
        "link": "https://moesif.com/blog/technical/api-design/REST-API-Design-Best-Practices-for-Parameters-and-Query-String-Usage",
        "document": "When we’re designing APIs the goal’s to give our users some amount of power over the service we provide. While HTTP verbs and resource URLs allow for some basic interaction, oftentimes it’s necessary to provide additional functionality or else the system becomes too cumbersome to work with.\n\nAn example of this is pagination: we can’t send every article to a client in one response if we have millions in our database.\n\nA way to get this done is with parametrization.\n\nIn a programming language, we can request a return value from a function. If the function doesn’t take any parameters, we can’t directly affect this return value.\n\nSame goes with APIs, especially stateless ones like REST APIs. Roy Fielding said this eloquently:\n\nThere are many ways in HTTP to add parameters to our request: the query string, the body of POST, PUT and PATCH requests, and the header. Each has its own use-cases and rules.\n\nThe simplest way to add in all parameter data is to put everything in the body. Many APIs work this way. Every endpoint uses POST and all parameters are in the body. This is especially true in legacy APIs that accumulated more and more parameters over a decade or so, such that they no longer fit in the query string.\n\nWhile this is more often the case than not, I’d consider it an edge case in API design. If we ask the right questions up front, we can prevent such a result.\n\nWhat kind of parameter do we want to add?\n\nThe first question we should ask ourselves is what kind of parameter we want to add?\n\nMaybe it’s a parameter that is a header field already standardized in the HTTP specification.\n\nThere are many standardized fields. Sometimes we can reinvent the wheel and add the information to another place. I’m not saying we can’t do it differently. GraphQL, for example, did what I’d consider crazy things from a REST perspective, but it still works. Sometimes it’s just simpler to use what’s already there.\n\nTake for example the header. This allows us to define the format, or media type, the response should take. We can use this to tell the API that we need or . We can also use this to get the version of the API.\n\nThere is also a header we could use to prevent the API from sending us a cached response with , instead of using a query string as cache buster ( )\n\nAuthorization could be seen as a parameter as well. Depending on the detail of authorization of the API, different responses could result from authorized or unauthorized. HTTP defines an header for this purpose.\n\nAfter we check all the default header fields, the next step is to evaluate if we should create a custom header field for our parameter, or put it into the query string of our URL.\n\nWhen should we use the query string?\n\nIf we know the parameters we want to add don’t belong in a default header field, and aren’t sensitive, we should see if the query string is a good place for them.\n\nHistorically the use of the query string was, as the name implies, to query data. There was a HTML element that could be used to send some keywords to a server and the server would respond with a list of pages that matched the keywords.\n\nLater the query string was repurposed for web-forms to send data to a server via a GET request.\n\nTherefore, the main use-case of the query string is filtering and specifically two special cases of filtering: searching and pagination. I won’t go into detail here, because we’ve already tackled them in this article.\n\nBut as repurposing for web-forms shows, it can also be used for different types of parameters. A RESTful API could use a POST or PUT request with a body to send form data to a server.\n\nOne example would be a parameter for nested representations. By default, we return a plain representation of an article. When a query string is added to the endpoint, we return the comments of that article in-line, so only one request is needed.\n\nShould such a parameter go into a custom header or the query string is mostly a question of developer experience.\n\nThe HTTP specification states that header fields are kind of like function parameters, so they are indeed thought of as the parameters we want to use. However, adding a query string to an URL is quickly done and more obvious than creating a customer header in this case.\n\nParameters that stay the same on all endpoints are better suited for headers. For example, authentication tokens get sent on every request.\n\nParameters that are highly dynamic, especially when they’re only valid for a few endpoints, should go in the query string. For example filter parameters are different for every endpoint.\n\nOne question that often crops up is what to do about array parameters inside the query string?\n\nFor example, if we have multiple names we want to search.\n\nOne solution is the use of square brackets.\n\nMany implementations of HTTP servers and clients don’t care about this fact, but it should be kept in mind.\n\nAnother solution that is offered is simply using one parameter name multiple times:\n\nThis is a valid solution but can lead to a decrease in developer experience. Oftentimes clients just use a map-like data structure, that goes through a simple string conversion before being added to the URL, potentially leading to overriding the following values. A more complex conversion is needed before the request can be sent.\n\nAnother way is to separate the values with characters, which are allowed unencoded inside URLs.\n\nFor map-like data structures, we can use the character, which is also allowed unencoded.\n\nIt is also possible to URL-encode the whole query string, so that it can use whatever characters or format we want. It should be kept in mind that this can also decrease developer experience quite a bit.\n\nWhen shouldn’t we use the query string?\n\nThe query string is part of our URL, and our URL can be read by everyone sitting between the clients and the API, so we shouldn’t put sensitive data like passwords into the query string.\n\nAlso, developer experience suffers greatly if we don’t take URL design and length seriously. Sure, most HTTP clients will allow a five-figure length of characters in an URL, but debugging such kinds of strings is not very pleasant.\n\nSince anything can be defined as a resource, sometimes it can make more sense to use a POST endpoint for heavy parameter usage. This lets us send all the data in the body to the API.\n\nInstead of sending a GET request to a resource with multiple parameters in the query string, that could lead to a really long un-debuggable URL, we could design it as a resource (e.g. search-resource). Depending on the things our API needs to do to satisfy our request, we could even use this to cache our computation results.\n\nWe would POST a new request to our endpoint, that holds our search configuration/parameters in the body. A search ID is returned, which we can use later to GET the results of our search.\n\nAs with all best practices, our job as API designers and architects isn’t to follow one approach as “the best solution” but to find out how our APIs are used.\n\nThe most frequent use cases should be the simplest to accomplish and it should be really difficult for a user to do something wrong.\n\nThus, it’s always important to analyze our API usage patterns right from the start - the earlier we have data, the easier it is to implement changes if we messed up our design. Moesif’s analytics service can help with that.\n\nIf we go one way because it’s simpler to grasp or easier to implement, we have to look at what we get out of it.\n\nAs nested resources can be used to make URLs more readable, they can also become too long and unreadable if we nest too many. Same goes for parameters. If we find ourselves creating one endpoint that has a huge query string, it might be better to extract another resource out of it and send the parameters inside the body."
    },
    {
        "link": "https://stackoverflow.com/questions/4024271/rest-api-best-practices-where-to-put-parameters",
        "document": "Would it be considered better design to put these parameters in the URL path?\n\nWhat is the best practice here? Are there any general guidelines when to use 1 and when to use 2?\n\nA REST API can have parameters in at least two ways:\n\n. This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions.\n\n. This question needs to be more focused . It is not currently accepting answers.\n\nIf there are documented best practices, I have not found them yet. However, here are a few guidelines I use when determining where to put parameters in an url: Optional parameters tend to be easier to put in the query string. If you want to return a 404 error when the parameter value does not correspond to an existing resource then I would tend towards a path segment parameter. e.g. where 232 is not a valid customer id. If however you want to return an empty list then when the parameter is not found then I suggest using query string parameters. e.g. If a parameter affects an entire subtree of your URI space then use a path segment. e.g. a language parameter versus I prefer unique identifiers to be in a path segment rather than a query parameter. The official rules for URIs are found in this RFC spec here. There is also another very useful RFC spec here that defines rules for parameterizing URIs.\n\nLate answer but I'll add some additional insight to what has been shared, namely that there are several types of \"parameters\" to a request, and you should take this into account.\n• Locators - E.g. resource identifiers such as IDs or action/view\n• Filters - E.g. parameters that provide a search for, sorting or narrow down the set of results. Now let's look at the different places where these parameters could go. Generally you want State to be set in headers or cookies, depending on what type of state information it is. I think we can all agree on this. Use custom http headers (X-My-Header) if you need to. Similarly, Content only has one place to belong, which is in the request body, either as query strings or as http multipart and/or JSON content. This is consistent with what you receive from the server when it sends you content. So you shouldn't be rude and do it differently. Locators such as \"id=5\" or \"action=refresh\" or \"page=2\" would make sense to have as a URL path, such as where partly you know what each part is supposed to mean (the basics such as article and 5 obviously mean get me the data of type article with id 5) and additional parameters are specified as part of the URI. They can be in the form of , or if you know that after a certain point in the URI the \"folders\" are paired key-values. Filters always go in the query string, because while they are a part of finding the right data, they are only there to return a subset or modification of what the Locators return alone. The search in (subset) is a filter, and so is (modification). Think about what it does, not just what it's called! If \"view\" determines output format, then it is a filter ( ) because it returns a modification of the found resource rather than homing in on which resource we want. If it instead decides which specific part of the article we get to see ( ) then it is a locator. Remember, narrowing down a set of resources is filtering. Locating something specific within a resource is locating... duh. Subset filtering may return any number of results (even 0). Locating will always find that specific instance of something (if it exists). Modification filtering will return the same data as the locator, except modified (if such a modification is allowed). Hope this helped give people some eureka moments if they've been lost about where to put stuff!\n\nAccording to the URI standard the path is for hierarchical parameters and the query is for non-hierarchical parameters. Ofc. it can be very subjective what is hierarchical for you. In situations where multiple URIs are assigned to the same resource I like to put the parameters - necessary for identification - into the path and the parameters - necessary to build the representation - into the query. (For me this way it is easier to route.) For map reduce I like to use the following approaches: So it is really up to you (and your server side router) how you construct your URIs. note: Just to mention these parameters are query parameters. So what you are really doing is defining a simple query language. By complex queries (which contain operators like and, or, greater than, etc.) I suggest you to use an already existing query language. The capabilities of URI templates are very limited...\n\nThere are no hard and fast rules, but the rule of thumb from a purely conceptual standpoint that I like to use can briefly be summed up like this: a URI path (by definition) represents a resource and query parameters are essentially modifiers on that resource. So far that likely doesn't help... With a REST API you have the major methods of acting upon a single resource using , , and . Therefore whether something should be represented in the path or as a parameter can be reduced to whether those methods make sense for the representation in question. Would you reasonably something at that path and would it be semantically sound to do so? You could of course something just about anywhere and bend the back-end to handle it, but you should be ing what amounts to a representation of the actual resource and not some needlessly contextualized version of it. For collections the same can be done with . If you wanted to add to a particular collection what would be a URL that makes sense to to. This still leaves some gray areas as some paths could point to what amount to children of parent resources which is somewhat discretionary and dependent on their use. The one hard line that this draws is that any type of transitive representation should be done using a query parameter, since it would not have an underlying resource. In response to the real world example given in the original question (Twitter's API), the parameters represent a transitive query that filters on the state of the resources (rather than a hierarchy). In that particular example it would be entirely unreasonable to add to the collection represented by those constraints, and further that query would not be able to be represented as a path that would make any sense in the terms of an object graph. The adoption of this type of resource oriented perspective can easily map directly to the object graph of your domain model and drive the logic of your API to the point where everything works very cleanly and in a fairly self-documenting way once it snaps into clarity. The concept can also be made clearer by stepping away from systems that use traditional URL routing mapped on to a normally ill-fitting data model (i.e. an RDBMS). Apache Sling would certainly be a good place to start. The concept of object traversal dispatch in a system like Zope also provides a clearer analog.\n\nOne \"dimension\" of this topic has been left out yet it's very important: there are times when the \"best practices\" have to come into terms with the plaform we are implementing or augmenting with REST capabilities. Many web applications nowadays implement the MVC (Model, View, Controller) architecture. They assume a certain standard path is provided, even more so when those web applications come with an \"Enable SEO URLs\" option. Just to mention a fairly famous web application: an OpenCart e-commerce shop. When the admin enables the \"SEO URLs\" it expects said URLs to come in a quite standard MVC format like:\n• None is the MVC controller that shall process the URL (showing the special-offers page)\n• None is the controller's action or function name to call. (*)\n• None limit=25 is an option, stating that 25 items will be shown per page. (*) is a fictious function name I used for clarity. In reality, OpenCart and most MVC frameworks have a default, implied (and usually omitted in the URL) function that gets called when the user wants a default action to be performed. So the real world URL would be: With a now fairly standard application or frameworkd structure similar to the above, you'll often get a web server that is optimized for it, that rewrites URLs for it (the true \"non SEOed URL\" would be: ). Therefore you, as developer, are faced into dealing with the existing infrastructure and adapt your \"best practices\", unless you are the system admin, know exactly how to tweak an Apache / NGinx rewrite configuration (the latter can be nasty!) and so on. So, your REST API would often be much better following the referring web application's standards, both for consistency with it and ease / speed (and thus budget saving). To get back to the practical example above, a consistent REST API would be something with URLs like: with a mix of \"paths formed\" arguments and \"query formed\" arguments.\n\nYou can use both of them, there's not any strict rule about this subject, but using URI path variables has some advantages:\n• Cache: Most of the web cache services on the internet don't cache GET request when they contains query parameters. They do that because there are a lot of RPC systems using GET requests to change data in the server (fail!! Get must be a safe method) But if you use path variables, all of this services can cache your GET requests. It gives the user more information about the structure of the data. But if your data doesn't have any hierarchy relation you can still use Path variables, using comma or semi-colon: As a rule, use comma when the ordering of the parameters matter, use semi-colon when the ordering doesn't matter: Apart of those reasons, there are some cases when it's very common to use query string variables:\n• When you need the browser to automatically put HTML form variables into the URI\n• When you are dealing with algorithm. For example the google engine use query strings: To sum up, there's not any strong reason to use one of this methods but whenever you can, use URI variables."
    },
    {
        "link": "https://stackoverflow.com/questions/14202257/design-restful-query-api-with-a-long-list-of-query-parameters",
        "document": "Remember that with a REST API, it's all a question of your point of view.\n\nThe two key concepts in a REST API are the endpoints and the resources (entities). Loosely put, an endpoint either returns resources via GET or accepts resources via POST and PUT and so on (or a combination of the above).\n\nIt is accepted that with POST, the data you send may or may not result in the creation of a new resource and its associated endpoint(s), which will most likely not \"live\" under the POSTed URL. In other words, when you POST you send data somewhere for handling. The POST endpoint is not where the resource might normally be found.\n\nQuoting from RFC 2616 (with irrelevant parts omitted, and relevant parts highlighted):\n\nThe POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the resource identified by the Request-URI in the Request-Line. POST is designed to allow a uniform method to cover the following functions:\n• Providing a block of data, such as the result of submitting a form, to a data-handling process; The action performed by the POST method might not result in a resource that can be identified by a URI. In this case, either 200 (OK) or 204 (No Content) is the appropriate response status, depending on whether or not the response includes an entity that describes the result. If a resource has been created on the origin server, the response SHOULD be 201 (Created)...\n\nWe have grown used to endpoints and resources representing 'things' or 'data', be it a user, a message, a book - whatever the problem domain dictates. However, an endpoint can also expose a different resource - for example search results.\n\nConsider the following example:\n\nThis is a typical REST CRUD. However what if we added:\n\nThere is nothing un-RESTful about this endpoint. It accepts data (entity) in the form of the request body. That data is the Search Criteria - a DTO like any other. This endpoint produces a resource (entity) in response to the request: Search Results. The search results resource is a temporary one, served immediately to the client, without a redirect, and without being exposed from some other canonical URL.\n\nIt's still REST, except the entities aren't books - the request entity is book search criteria, and the response entity is book search results."
    },
    {
        "link": "https://medium.com/@jeffrey.faber/using-query-parameters-in-rest-api-design-9c40d79b4c44",
        "document": "Hey there! Let’s talk about REST APIs — those nifty tools that make modern web development a breeze! So, what are they exactly? Well, REST APIs are like communication wizards, allowing different systems to exchange data seamlessly over the internet. They connect your apps and websites to servers and make the magic happen.\n\nNow, why are these APIs so important? Think of them as the backbone of web development. They bring order to the chaos, enabling developers to build scalable and efficient systems with ease. It’s like having a well-organized map to navigate through the web labyrinth.\n\nNow, enter the hero of our story: query parameters! These little gems have a big role in REST API design. They’re like instructions you add to your API requests, helping you get exactly what you need from the server. With query parameters, you can filter, sort, and customize your API responses — talk about powerful tools.\n\nSo, next time you work with REST APIs, keep an eye out for those query parameters. They’ll level up your development game and make your applications even more user-friendly. Happy coding!\n\nAlright, let’s get cozy with query parameters and unravel their secrets in the world of REST APIs\n\nFirst things first, what exactly are query parameters? Well, think of them as the extra spices you add to your API requests. They’re those nifty key-value pairs that you attach to the end of your URL, like magic charms that bring special powers to your queries.\n\nSo, how do they work? It’s simple, really. Say you want to fetch information from a server, but you only need specific data, like all the posts from a certain category. Instead of getting the whole shebang and sifting through it, you can just append a query parameter to the URL, like “?category=tech,” and voilà! The server knows exactly what you want, and it delivers it pronto.\n\nNow, let’s clear up any confusion. Query parameters are not the same as other types of parameters in APIs. We have path parameters, which are like placeholders in the URL, and request body parameters, where you tuck data in the body of your request. But query parameters? They’re the stars of the show when it comes to customizing your API calls without messing up the URL structure.\n\nHere’s why you’ll fall in love with query parameters, they bring the superpowers of filtering, sorting, and pagination to your API requests. Imagine searching for products on an e-commerce site — you’d want to filter by price, sort by popularity, and load only a few results at a time. Query parameters make this a breeze.\n\nSo, whether you’re building a sleek website or crafting a cool mobile app, query parameters will be your trusty companions. They’ll make your API calls precise, efficient, and supercharged with just the data you need. Time to add some query parameter magic to your REST APIs.\n\nHey there! In Martini, you can make use of the Parameters tab as your command center for all things query and path parameters in your request. It’s like giving your parameters a little extra oomph! Now, under this tab, you’ll spot three cool columns: Name, Value, and Description. These are your tools to customize every parameter just the way you want. Time to dive in and give your request that personalized touch.\n\nBest Practices for Using Query Parameters\n\nFirst things first, let’s keep our URLs neat and tidy\n\nNobody likes a messy URL with a jumble of gibberish. So, when you’re naming your query parameters, make them meaningful and self-explanatory. Instead of using vague names like “param1” or “filter,” go for something descriptive like “category,” “date_range,” or “sort_by.” Trust me, your fellow developers will thank you, and future you will thank you too.\n\nNext up, data integrity is the name of the game\n\nWhen it comes to query parameters, we need to be diligent about using the right data types and validating them properly. You wouldn’t want your API to break just because someone passed in a string instead of a number, right? So, make sure you specify the expected data types for each parameter and set up validation checks to ensure the data is valid before processing it. This way, you’ll keep your API robust and resilient.\n\nWe all love a sleek and straightforward API, don’t we? So, avoid going overboard with query parameters. Limit them to the essentials, as too many parameters can quickly turn your API into a confusing labyrinth. Remember, it’s all about striking that balance between flexibility and simplicity.\n\nSecurity, my friends, is of the utmost importance\n\nQuery parameters may seem harmless, but if not handled carefully, they can open the door to security vulnerabilities. One common concern is exposing sensitive information in the URL, which could be logged in server logs or shared unknowingly. So, steer clear of passing sensitive data through query parameters. Instead, consider using other methods like request headers or request body parameters for such sensitive stuff.\n\nAlso, watch out for SQL injection attacks. If you’re using query parameters directly in database queries, make sure to sanitize and validate them to prevent malicious exploits.\n\nSo, how do we implement filtering functionalities using those trusty query parameters? It’s easier than you might think. Let’s say you have a list of products, and you want to fetch only the ones that fall into a specific category. Simply add a query parameter like “?category=electronics” to your API call, and voilà — you’ll get a neat list of all those shiny gadgets.\n\nBut that’s not all! Query parameters can handle more complex filtering tasks too. Imagine you want to fetch only the products that were added in the last month. Easy-peasy. Just add a query parameter like “?date_range=last_month,” and your server will work its magic to deliver exactly what you need.\n\nNow, let’s talk about the various filtering techniques at your disposal. You can filter data using different comparison operators, such as “=”, “<”, “>”, and more, to retrieve results that meet specific criteria. For example, you could fetch products with prices less than $50 by using the query parameter “?price_less_than=50.”\n\nBut wait, there’s more! You can combine multiple query parameters to apply multiple filters simultaneously. You’re not limited to just one parameter, so feel free to mix and match to your heart’s content.\n\nNow, here’s an important tip to keep in mind, while filtering is incredibly handy, overdoing it can affect API performance. Imagine fetching millions of records at once — not exactly the snappiest experience, right? So, consider pagination (which we’ll talk about later) or setting sensible limits to the number of results returned.\n\nRemember, every API call comes with a cost in terms of server resources and response time. Striking a balance between filtering flexibility and performance is key to crafting a stellar API experience for your users.\n\nSo, how do we enable sorting capabilities using those trusty query parameters? It’s as easy as snapping your fingers. When you want to sort your data in a specific way, just add a query parameter like “?sort_by=date” to your API call. Boom! Your server will work its magic and return the data in ascending order of dates.\n\nBut wait, there’s more! You’re not limited to just one type of sorting. Oh no, query parameters have got your back when it comes to exploring different sorting options. You can sort your data in ascending or descending order, simply by adding “?sort_order=asc” or “?sort_order=desc” to your API call. It’s like having a magical sorting hat for your data.\n\nAnd here’s where it gets really cool, you can even have multi-level sorting. That’s right, you can sort your data based on multiple criteria. Fancy sorting by date and then by price? Just add “?sort_by=date,price” to your API call, and you’ll get precisely what you’re looking for.\n\nNow, while sorting is super handy for presenting data in a user-friendly manner, it’s essential to handle complex sorting requirements with care. You see, sorting can have an impact on API performance, especially when dealing with large datasets. So, here’s a tip: consider optimizing your database queries to handle common sorting scenarios efficiently.\n\nSometimes, caching can be your best friend when it comes to handling frequent sorting requests. Caching can save previous query results, reducing the need for redundant sorting operations and improving response times.\n\nAnd hey, don’t forget about pagination (yes, we’ll get there soon!) to manage large sets of sorted data. Remember, striking a balance between user experience and performance is the key to a successful API.\n\nPicture this: you have a massive dataset, and you want to fetch all the records at once. Well, that’s like trying to eat a mountain of ice cream in one bite — not the best idea. Large data sets can slow down your API and leave your users waiting forever. That’s where pagination swoops in to save the day.\n\nPagination breaks down that colossal data into manageable chunks, making your API more responsive and user-friendly. Instead of returning everything at once, you return just a specific portion, or “page,” of the data. Users can then request additional pages as needed, leading to a smooth and speedy browsing experience.\n\nSo, how do we work this pagination magic with query parameters? Easy-peasy. We use parameters like ‘page’ and ‘limit’ to indicate which page we want and how many results we want per page. For instance, you could use “?page=1&limit=10” to fetch the first page with ten results.\n\nNow, let’s address some common issues and pitfalls that might trip you up along the way. One classic mistake is forgetting to set a sensible limit. Imagine trying to load thousands of records in one go — that’s asking for a performance nightmare! Be mindful of the ‘limit’ value and choose a number that strikes the right balance between efficiency and user experience.\n\nAnother issue to watch out for is dealing with changing data while paginating. What if new records are added or deleted between page requests? This could lead to data inconsistencies or even missing records. Consider using stable sorting and unique identifiers to maintain data integrity.\n\nLastly, don’t forget to communicate pagination details to your users. Let them know how many pages are available, their current page number, and any other relevant information. This way, your users will be in the loop and better equipped to navigate your API.\n\nSo, let’s talk caching. Imagine you have a resource-heavy API that serves data that doesn’t change too often. Without caching, your server would have to fetch and process the same data repeatedly for each request — talk about a waste of precious resources. That’s where caching comes in to save the day.\n\nWhen you use query parameters, you can tap into the power of caching to optimize API responses. Caching allows you to store the results of API calls in temporary storage (cache) and serve those same results for subsequent requests. This means that when users make identical requests with the same query parameters, your server can simply serve the cached response without hitting the database again. It’s like having a ready-to-serve dish that you don’t need to cook from scratch each time.\n\nNow, let’s explore cache keys and cache invalidation. When you cache API responses, you need a way to identify and retrieve them later. That’s where cache keys come in handy. Cache keys are unique identifiers generated from the combination of the API endpoint and its query parameters. They act like labels for your cached responses, making it easy to find and serve the right data when needed.\n\nBut remember, cache invalidation is crucial to keep your data fresh and accurate. When data changes or updates occur, you need to invalidate the corresponding cache entries. This ensures that users get the latest and most up-to-date information when necessary. So, when you receive a new request with the same query parameters, your server can fetch fresh data and update the cache accordingly.\n\nNow, let’s talk performance. Caching can significantly improve API response times and reduce server load. By serving cached data, your server doesn’t need to go through the whole data retrieval and processing cycle repeatedly. It’s like having a well-organized pantry where you can grab ready-to-use ingredients without rushing to the store each time you cook.\n\nHowever, caching is not a one-size-fits-all solution. It works best for static or infrequently changing data. For dynamic data that updates frequently, you might need to consider shorter cache lifetimes or use other strategies.\n\nAh, the world of query parameters isn’t always rainbows and unicorns. But fear not, my fellow developers — we’ve got this covered. Let’s talk about handling errors and those pesky edge cases with grace and finesse.\n\nFirst things first, incorrect or unsupported query parameters. Hey, we all make mistakes, right? So, when users pass in invalid or non-existent query parameters, it’s essential to handle it gracefully. Instead of breaking into a frenzy, provide clear and informative error messages. Let your users know what went wrong and how to fix it. It’s like giving them a friendly nudge in the right direction.\n\nAnd speaking of friendly, don’t forget about status codes. Those little HTTP codes hold a world of meaning. When something goes awry with query parameters, use the appropriate status codes to signal what happened. It’s like using emojis to express your feelings — they say a lot with just a tiny symbol.\n\nNow, what about potential conflicts or redundant query parameters? It’s like having a puzzle with extra pieces — things just don’t fit together smoothly. To avoid confusion, address these issues upfront. For example, if a user requests both “sort_by=date” and “sort_by=price,” you can gracefully handle this by choosing the most recent parameter or simply ignoring the redundant ones.\n\nKeep in mind that not all errors are equal. Some might be minor hiccups, while others could be deal-breakers. Think about how to prioritize and handle different error scenarios based on their impact on API functionality.\n\nBut wait, there’s more! Think about the bigger picture of error handling. Consider creating a comprehensive API documentation that guides users on the valid query parameters, expected values, and potential errors. It’s like giving them a well-drawn treasure map to navigate your API effortlessly.\n\nAnd there you have it — the magical world of query parameters in REST API design. Let’s take a moment to wrap up our journey and highlight the key takeaways.\n\nQuery parameters might seem like humble tools, but they play a crucial role in the grand symphony of REST API design. They allow you to personalize your API requests, filtering data to get exactly what you need and sorting it just the way you want. With the power of pagination, you can serve data in bite-sized chunks, making your API super-responsive and user-friendly.\n\nBut wait, there’s more! Query parameters also influence caching strategies, improving API performance and reducing server load. By leveraging caching, you serve data with lightning speed, like a well-stocked pantry ready to cook up delicious responses.\n\nRemember the best practices we covered? Keeping URLs readable, validating data, and addressing security concerns — all of these are essential for crafting well-designed APIs. And don’t forget about handling errors gracefully, guiding users through the maze of query parameters with clear error messages.\n\nSo, why do query parameters matter so much? Well, they’re like the paintbrushes of API design, giving you the power to create seamless, efficient, and flexible experiences for your users. By adopting best practices and guidelines, you’ll ensure that your REST APIs shine brightly in the vast web universe.\n\nNow, it’s your turn! As you venture into the world of REST API design, embrace the magic of query parameters. Tinker with filtering, sorting, and pagination — let your imagination soar! And above all, remember to sprinkle in those best practices to ensure your APIs are top-notch.\n\nSo, go forth, fellow developers, and wield query parameters like the sorcerers of API design that you are. Create APIs that amaze, captivate, and leave users in awe. With the right tools, a touch of finesse, and a dash of creativity, you’ll craft REST APIs that stand out in the bustling realm of web development. Happy coding and may your APIs be ever magical."
    },
    {
        "link": "https://stackoverflow.blog/2020/03/02/best-practices-for-rest-api-design",
        "document": "REST APIs are one of the most common kinds of web interfaces available today. They allow various clients including browser apps to communicate with services via the REST API. Therefore, it's very important to design REST APIs properly so that we won't run into problems down the road. We have to take into account security, performance, and ease of use for API consumers.\n\nOtherwise, we create problems for clients that use our APIs, which isn’t pleasant and detracts people from using our API. If we don’t follow commonly accepted conventions, then we confuse the maintainers of the API and the clients that use them since it’s different from what everyone expects.\n\nIn this article, we'll look at how to design REST APIs to be easy to understand for anyone consuming them, future-proof, and secure and fast since they serve data to clients that may be confidential.\n• Use nouns instead of verbs in endpoint paths\n\nA REST API is an application programming interface architecture style that conforms to specific architectural constraints, like stateless communication and cacheable data. It is not a protocol or standard. While REST APIs can be accessed through a number of communication protocols, most commonly, they are called over HTTPS, so the guidelines below apply to REST API endpoints that will be called over the internet.\n\nNote: For REST APIs called over the internet, you'll like want to follow the best practices for REST API authentication.\n\nEven though some people think REST should only return hypertext (including Roy Fielding who created the term) REST APIs should accept JSON for request payload and also send responses to JSON. JSON is the standard for transferring data. Almost every networked technology can use it: JavaScript has built-in methods to encode and decode JSON either through the Fetch API or another HTTP client. Server-side technologies have libraries that can decode JSON without doing much work.\n\nThere are other ways to transfer data. XML isn’t widely supported by frameworks without transforming the data ourselves to something that can be used, and that’s usually JSON. We can’t manipulate this data as easily on the client-side, especially in browsers. It ends up being a lot of extra work just to do normal data transfer.\n\nForm data is good for sending data, especially if we want to send files. But for text and numbers, we don’t need form data to transfer those since—with most frameworks—we can transfer JSON by just getting the data from it directly on the client side. It’s by far the most straightforward to do so.\n\nTo make sure that when our REST API app responds with JSON that clients interpret it as such, we should set Content-Type in the response header to application/json after the request is made. Many server-side app frameworks set the response header automatically. Some HTTP clients look at the Content-Type response header and parse the data according to that format.\n\nThe only exception is if we’re trying to send and receive files between client and server. Then we need to handle file responses and send form data from client to server. But that is a topic for another time.\n\nWe should also make sure that our endpoints return JSON as a response. Many server-side frameworks have this as a built-in feature.\n\nLet’s take a look at an example API that accepts JSON payloads. This example will use the Express back end framework for Node.js. We can use the body-parser middleware to parse the JSON request body, and then we can call the res.json method with the object that we want to return as the JSON response as follows:\n\nbodyParser.json() parses the JSON request body string into a JavaScript object and then assigns it to the req.body object.\n\nSet the Content-Type header in the response to application/json; charset=utf-8 without any changes. The method above applies to most other back end frameworks.\n\nUse nouns instead of verbs in endpoint paths\n\nWe shouldn't use verbs in our endpoint paths. Instead, we should use the nouns which represent the entity that the endpoint that we're retrieving or manipulating as the pathname.\n\nThis is because our HTTP request method already has the verb. Having verbs in our API endpoint paths isn’t useful and it makes it unnecessarily long since it doesn’t convey any new information. The chosen verbs could vary by the developer’s whim. For instance, some like ‘get’ and some like ‘retrieve’, so it’s just better to let the HTTP GET verb tell us what and endpoint does.\n\nThe action should be indicated by the HTTP request method that we're making. The most common methods include GET, POST, PUT, and DELETE.\n• POST submits new data to the server.\n\nWith the two principles we discussed above in mind, we should create routes like GET /articles/ for getting news articles. Likewise, POST /articles/ is for adding a new article , PUT /articles/:id is for updating the article with the given id. DELETE /articles/:id is for deleting an existing article with the given ID.\n\n/articles represents a REST API resource. For instance, we can use Express to add the following endpoints for manipulate articles as follows:\n\nIn the code above, we defined the endpoints to manipulate articles. As we can see, the path names do not have any verbs in them. All we have are nouns. The verbs are in the HTTP verbs.\n\nThe POST, PUT, and DELETE endpoints all take JSON as the request body, and they all return JSON as the response, including the GET endpoint.\n\nWhen designing endpoints, it makes sense to group those that contain associated information. That is, if one object can contain another object, you should design the endpoint to reflect that. This is good practice regardless of whether your data is structured like this in your database. In fact, it may be advisable to avoid mirroring your database structure in your endpoints to avoid giving attackers unnecessary information.\n\nFor example, if we want an endpoint to get the comments for a news article, we should append the /comments path to the end of the /articles path. We can do that with the following code in Express:\n\nIn the code above, we can use the GET method on the path '/articles/:articleId/comments'. We get comments on the article identified by articleId and then return it in the response. We add 'comments' after the '/articles/:articleId' path segment to indicate that it's a child resource of /articles.\n\nThis makes sense since comments are the children objects of the articles, assuming each article has its own comments. Otherwise, it’s confusing to the user since this structure is generally accepted to be for accessing child objects. The same principle also applies to the POST, PUT, and DELETE endpoints. They can all use the same kind of nesting structure for the path names.\n\nHowever, nesting can go too far. After about the second or third level, nested endpoints can get unwieldy. Consider, instead, returning the URL to those resources instead, especially if that data is not necessarily contained within the top level object.\n\nFor example, suppose you wanted to return the author of particular comments. You could use /articles/:articleId/comments/:commentId/author. But that's getting out of hand. Instead, return the URI for that particular user within the JSON response instead:\n\nTo eliminate confusion for API users when an error occurs, we should handle errors gracefully and return HTTP response codes that indicate what kind of error occurred. This gives maintainers of the API enough information to understand the problem that’s occurred. We don’t want errors to bring down our system, so we can leave them unhandled, which means that the API consumer has to handle them.\n• 401 Unauthorized - This means the user isn't not authorized to access a resource. It usually returns when the user isn't authenticated.\n• 403 Forbidden - This means the user is authenticated, but it's not allowed to access a resource.\n• 404 Not Found - This indicates that a resource is not found.\n• 500 Internal server error - This is a generic server error. It probably shouldn't be thrown explicitly.\n• 502 Bad Gateway - This indicates an invalid response from an upstream server.\n• 503 Service Unavailable - This indicates that something unexpected happened on server side (It can be anything like server overload, some parts of the system failed, etc.).\n\nWe should be throwing errors that correspond to the problem that our app has encountered. For example, if we want to reject the data from the request payload, then we should return a 400 response as follows in an Express API:\n\nIn the code above, we have a list of existing users in the users array with the given email.\n\nThen if we try to submit the payload with the email value that already exists in users, we'll get a 400 response status code with a 'User already exists' message to let users know that the user already exists. With that information, the user can correct the action by changing the email to something that doesn't exist.\n\nError codes need to have messages accompanied with them so that the maintainers have enough information to troubleshoot the issue, but attackers can’t use the error content to carry our attacks like stealing information or bringing down the system.\n\nWhenever our API does not successfully complete, we should fail gracefully by sending an error with information to help users make corrective action.\n\nThe databases behind a REST API can get very large. Sometimes, there's so much data that it shouldn’t be returned all at once because it’s way too slow or will bring down our systems. Therefore, we need ways to filter items.\n\nWe also need ways to paginate data so that we only return a few results at a time. We don't want to tie up resources for too long by trying to get all the requested data at once.\n\nFiltering and pagination both increase performance by reducing the usage of server resources. As more data accumulates in the database, the more important these features become.\n\nHere’s a small example where an API can accept a query string with various query parameters to let us filter out items by their fields:\n\nIn the code above, we have the req.query variable to get the query parameters. We then extract the property values by destructuring the individual query parameters into variables using the JavaScript destructuring syntax. Finally, we run filter on with each query parameter value to locate the items that we want to return.\n\nOnce we have done that, we return the results as the response. Therefore, when we make a GET request to the following path with the query string:\n\nas the returned response since we filtered by lastName and age.\n\nLikewise, we can accept the page query parameter and return a group of entries in the position from (page - 1) * 20 to page * 20.\n\nWe can also specify the fields to sort by in the query string. For instance, we can get the parameter from a query string with the fields we want to sort the data for. Then we can sort them by those individual fields.\n\nFor instance, we may want to extract the query string from a URL like:\n\nWhere + means ascending and - means descending. So we sort by author’s name in alphabetical order and datepublished from most recent to least recent.\n\nMost communication between client and server should be private since we often send and receive private information. Therefore, using SSL/TLS for security is a must.\n\nA SSL certificate isn't too difficult to load onto a server and the cost is free or very low. There's no reason not to make our REST APIs communicate over secure channels instead of in the open.\n\nPeople shouldn't be able to access more information that they requested. For example, a normal user shouldn't be able to access information of another user. They also shouldn't be able to access data of admins.\n\nTo enforce the principle of least privilege, we need to add role checks either for a single role, or have more granular roles for each user.\n\nIf we choose to group users into a few roles, then the roles should have the permissions that cover all they need and no more. If we have more granular permissions for each feature that users have access to, then we have to make sure that admins can add and remove those features from each user accordingly. Also, we need to add some preset roles that can be applied to a group users so that we don’t have to do that for every user manually.\n\nWe can add caching to return data from the local memory cache instead of querying the database to get the data every time we want to retrieve some data that users request. The good thing about caching is that users can get data faster. However, the data that users get may be outdated. This may also lead to issues when debugging in production environments when something goes wrong as we keep seeing old data.\n\nThere are many kinds of caching solutions like Redis, in-memory caching, and more. We can change the way data is cached as our needs change.\n\nFor instance, Express has the apicache middleware to add caching to our app without much configuration. We can add a simple in-memory cache into our server like so:\n\nThe code above just references the apicache middleware with apicache.middleware and then we have:\n\nto apply the caching to the whole app. We cache the results for five minutes, for example. We can adjust this for our needs.\n\nIf you are using caching, you should also include Cache-Control information in your headers. This will help users effectively use your caching system.\n\nWe should have different versions of API if we're making any changes to them that may break clients. The versioning can be done according to semantic version (for example, 2.0.6 to indicate major version 2 and the sixth patch) like most apps do nowadays.\n\nThis way, we can gradually phase out old endpoints instead of forcing everyone to move to the new API at the same time. The v1 endpoint can stay active for people who don’t want to change, while the v2, with its shiny new features, can serve those who are ready to upgrade. This is especially important if our API is public. We should version them so that we won't break third party apps that use our APIs.\n\nVersioning is usually done with /v1/, /v2/, etc. added at the start of the API path.\n\nFor example, we can do that with Express as follows:\n\nWe just add the version number to the start of the endpoint URL path to version them.\n\nThe most important takeaways for designing high-quality REST APIs is to have consistency by following web standards and conventions. JSON, SSL/TLS, and HTTP status codes are all standard building blocks of the modern web.\n\nPerformance is also an important consideration. We can increase it by not returning too much data at once. Also, we can use caching so that we don't have to query for data all the time.\n\nPaths of endpoints should be consistent, we use nouns only since the HTTP methods indicate the action we want to take. Paths of nested resources should come after the path of the parent resource. They should tell us what we’re getting or manipulating without the need to read extra documentation to understand what it’s doing."
    }
]