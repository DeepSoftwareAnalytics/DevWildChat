[
    {
        "link": "https://docs.python.org/3/library/sqlite3.html",
        "document": "SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.\n\nThe module was written by Gerhard Häring. It provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249, and requires SQLite 3.15.2 or newer.\n• None Tutorial teaches how to use the module.\n• None Reference describes the classes and functions this module defines.\n\nHow to use placeholders to bind values in SQL queries¶ SQL operations usually need to use values from Python variables. However, beware of using Python’s string operations to assemble queries, as they are vulnerable to SQL injection attacks. For example, an attacker can simply close the single quote and inject to select all rows: # Never do this -- insecure! SELECT * FROM stocks WHERE symbol = '' OR TRUE; --' Instead, use the DB-API’s parameter substitution. To insert a variable into a query string, use a placeholder in the string, and substitute the actual values into the query by providing them as a of values to the second argument of the cursor’s method. An SQL statement may use one of two kinds of placeholders: question marks (qmark style) or named placeholders (named style). For the qmark style, parameters must be a sequence whose length must match the number of placeholders, or a is raised. For the named style, parameters must be an instance of a (or a subclass), which must contain keys for all named parameters; any extra items are ignored. Here’s an example of both styles: # This is the named style used with executemany(): # This is the qmark style used in a SELECT query: PEP 249 numeric placeholders are not supported. If used, they will be interpreted as named placeholders. How to adapt custom Python types to SQLite values¶ SQLite supports only a limited set of data types natively. To store custom Python types in SQLite databases, adapt them to one of the Python types SQLite natively understands. There are two ways to adapt Python objects to SQLite types: letting your object adapt itself, or using an adapter callable. The latter will take precedence above the former. For a library that exports a custom type, it may make sense to enable that type to adapt itself. As an application developer, it may make more sense to take direct control by registering custom adapter functions. Suppose we have a class that represents a pair of coordinates, and , in a Cartesian coordinate system. The coordinate pair will be stored as a text string in the database, using a semicolon to separate the coordinates. This can be implemented by adding a method which returns the adapted value. The object passed to protocol will be of type . The other possibility is to create a function that converts the Python object to an SQLite-compatible type. This function can then be registered using . How to convert SQLite values to custom Python types¶ Writing an adapter lets you convert from custom Python types to SQLite values. To be able to convert from SQLite values to custom Python types, we use converters. Let’s go back to the class. We stored the x and y coordinates separated via semicolons as strings in SQLite. First, we’ll define a converter function that accepts the string as a parameter and constructs a object from it. Converter functions are always passed a object, no matter the underlying SQLite data type. We now need to tell when it should convert a given SQLite value. This is done when connecting to a database, using the detect_types parameter of . There are three options:\n• None Both: set detect_types to . Column names take precedence over declared types. The following example illustrates the implicit and explicit approaches: This section shows recipes for common adapters and converters. How to use connection shortcut methods¶ Using the , , and methods of the class, your code can be written more concisely because you don’t have to create the (often superfluous) objects explicitly. Instead, the objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a statement and iterate over it directly using only a single call on the object. # close() is not a shortcut method and it's not called automatically; # the connection object should be closed manually How to use the connection context manager¶ A object can be used as a context manager that automatically commits or rolls back open transactions when leaving the body of the context manager. If the body of the statement finishes without exceptions, the transaction is committed. If this commit fails, or if the body of the statement raises an uncaught exception, the transaction is rolled back. If is , a new transaction is implicitly opened after committing or rolling back. If there is no open transaction upon leaving the body of the statement, or if is , the context manager does nothing. The context manager neither implicitly opens a new transaction nor closes the connection. If you need a closing context manager, consider using . # con.rollback() is called after the with block finishes with an exception, # the exception is still raised and must be caught # Connection object used as context manager only commits or rollbacks transactions, # so the connection object should be closed manually How to work with SQLite URIs¶\n• None Do not implicitly create a new database file if it does not already exist; will raise if unable to create a new file: More information about this feature, including a list of parameters, can be found in the SQLite URI documentation. How to create and use row factories¶ By default, represents each row as a . If a does not suit your needs, you can use the class or a custom . While exists as an attribute both on the and the , it is recommended to set , so all cursors created from the connection will use the same row factory. provides indexed and case-insensitive named access to columns, with minimal memory overhead and performance impact over a . To use as a row factory, assign it to the attribute: \"SELECT 'Earth' AS name, 6378 AS radius\" The clause can be omitted in the statement, as in the above example. In such cases, SQLite returns a single row with columns defined by expressions, e.g. literals, with the given aliases . You can create a custom that returns each row as a , with column names mapped to values: Using it, queries now return a instead of a : can be used as follows: With some adjustments, the above recipe can be adapted to use a , or any other custom class, instead of a . By default, uses to adapt SQLite values with the data type. This works well for UTF-8 encoded text, but it might fail for other encodings and invalid UTF-8. You can use a custom to handle such cases. Because of SQLite’s flexible typing, it is not uncommon to encounter table columns with the data type containing non-UTF-8 encodings, or even arbitrary data. To demonstrate, let’s assume we have a database with ISO-8859-2 (Latin-2) encoded text, for example a table of Czech-English dictionary entries. Assuming we now have a instance connected to this database, we can decode the Latin-2 encoded text using this : For invalid UTF-8 or arbitrary data in stored in table columns, you can use the following technique, borrowed from the Unicode HOWTO: The module API does not support strings containing surrogates."
    },
    {
        "link": "https://docs.python.org/3.9/library/sqlite3.html",
        "document": "SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.\n\nThe sqlite3 module was written by Gerhard Häring. It provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249.\n\nTo use the module, start by creating a object that represents the database. Here the data will be stored in the file:\n\nThe special path name can be provided to create a temporary database in RAM.\n\nOnce a has been established, create a object and call its method to perform SQL commands:\n\nThe saved data is persistent: it can be reloaded in a subsequent session even after restarting the Python interpreter:\n\nTo retrieve data after executing a SELECT statement, either treat the cursor as an iterator, call the cursor’s method to retrieve a single matching row, or call to get a list of the matching rows.\n\nThis example uses the iterator form:\n\nSQL operations usually need to use values from Python variables. However, beware of using Python’s string operations to assemble queries, as they are vulnerable to SQL injection attacks (see the xkcd webcomic for a humorous example of what can go wrong):\n\nInstead, use the DB-API’s parameter substitution. To insert a variable into a query string, use a placeholder in the string, and substitute the actual values into the query by providing them as a of values to the second argument of the cursor’s method. An SQL statement may use one of two kinds of placeholders: question marks (qmark style) or named placeholders (named style). For the qmark style, must be a sequence. For the named style, it can be either a sequence or instance. The length of the sequence must match the number of placeholders, or a is raised. If a is given, it must contain keys for all named parameters. Any extra items are ignored. Here’s an example of both styles:\n\nString constant stating the supported DB-API level. Required by the DB-API. Hard-coded to . String constant stating the type of parameter marker formatting expected by the module. Required by the DB-API. Hard-coded to . The module supports both and DB-API parameter styles, because that is what the underlying SQLite library supports. However, the DB-API does not allow multiple values for the attribute. The version number of this module, as a string. This is not the version of the SQLite library. The version number of this module, as a tuple of integers. This is not the version of the SQLite library. The version number of the run-time SQLite library, as a string. The version number of the run-time SQLite library, as a tuple of integers. Integer constant required by the DB-API, stating the level of thread safety the module supports. Currently hard-coded to , meaning “Threads may share the module, but not connections.” However, this may not always be true. You can check the underlying SQLite library’s compile-time threaded mode using the following query: Note that the SQLITE_THREADSAFE levels do not match the DB-API 2.0 levels. This constant is meant to be used with the detect_types parameter of the function. Setting it makes the module parse the declared type for each column it returns. It will parse out the first word of the declared type, i. e. for “integer primary key”, it will parse out “integer”, or for “number(10)” it will parse out “number”. Then for that column, it will look into the converters dictionary and use the converter function registered for that type there. This constant is meant to be used with the detect_types parameter of the function. Setting this makes the SQLite interface parse the column name for each column it returns. It will look for a string formed [mytype] in there, and then decide that ‘mytype’ is the type of the column. It will try to find an entry of ‘mytype’ in the converters dictionary and then use the converter function found there to return the value. The column name found in does not include the type, i. e. if you use something like in your SQL, then we will parse out everything until the first for the column name and strip the preceding space: the column name would simply be “Expiration date”. Opens a connection to the SQLite database file database. By default returns a object, unless a custom factory is given. database is a path-like object giving the pathname (absolute or relative to the current working directory) of the database file to be opened. You can use to open a database connection to a database that resides in RAM instead of on disk. When a database is accessed by multiple connections, and one of the processes modifies the database, the SQLite database is locked until that transaction is committed. The timeout parameter specifies how long the connection should wait for the lock to go away until raising an exception. The default for the timeout parameter is 5.0 (five seconds). For the isolation_level parameter, please see the property of objects. SQLite natively supports only the types TEXT, INTEGER, REAL, BLOB and NULL. If you want to use other types you must add support for them yourself. The detect_types parameter and the using custom converters registered with the module-level function allow you to easily do that. detect_types defaults to 0 (i. e. off, no type detection), you can set it to any combination of and to turn type detection on. Due to SQLite behaviour, types can’t be detected for generated fields (for example ), even when detect_types parameter is set. In such case, the returned type is . By default, check_same_thread is and only the creating thread may use the connection. If set , the returned connection may be shared across multiple threads. When using multiple threads with the same connection writing operations should be serialized by the user to avoid data corruption. By default, the module uses its class for the connect call. You can, however, subclass the class and make use your class instead by providing your class for the factory parameter. Consult the section SQLite and Python types of this manual for details. The module internally uses a statement cache to avoid SQL parsing overhead. If you want to explicitly set the number of statements that are cached for the connection, you can set the cached_statements parameter. The currently implemented default is to cache 100 statements. If uri is , database is interpreted as a with a file path and an optional query string. The scheme part must be . The path can be a relative or absolute file path. The query string allows us to pass parameters to SQLite. Some useful URI tricks include: # Don't implicitly create a new database file if it does not already exist. # Will raise sqlite3.OperationalError if unable to open a database file. More information about this feature, including a list of recognized parameters, can be found in the SQLite URI documentation. Changed in version 3.7: database can now also be a path-like object, not only a string. Registers a callable to convert a bytestring from the database into a custom Python type. The callable will be invoked for all database values that are of the type typename. Confer the parameter detect_types of the function for how the type detection works. Note that typename and the name of the type in your query are matched in case-insensitive manner. Registers a callable to convert the custom Python type type into one of SQLite’s supported types. The callable callable accepts as single parameter the Python value, and must return a value of the following types: int, float, str or bytes. Returns if the string sql contains one or more complete SQL statements terminated by semicolons. It does not verify that the SQL is syntactically correct, only that there are no unclosed string literals and the statement is terminated by a semicolon. This can be used to build a shell for SQLite, as in the following example: \"Enter your SQL commands to execute in sqlite3.\" By default you will not get any tracebacks in user-defined functions, aggregates, converters, authorizer callbacks etc. If you want to debug them, you can call this function with flag set to . Afterwards, you will get tracebacks from callbacks on . Use to disable the feature again.\n\nAn SQLite database connection has the following attributes and methods: Get or set the current default isolation level. for autocommit mode or one of “DEFERRED”, “IMMEDIATE” or “EXCLUSIVE”. See section Controlling Transactions for a more detailed explanation. if a transaction is active (there are uncommitted changes), otherwise. Read-only attribute. The cursor method accepts a single optional parameter factory. If supplied, this must be a callable returning an instance of or its subclasses. This method commits the current transaction. If you don’t call this method, anything you did since the last call to is not visible from other database connections. If you wonder why you don’t see the data you’ve written to the database, please check you didn’t forget to call this method. This method rolls back any changes to the database since the last call to . This closes the database connection. Note that this does not automatically call . If you just close your database connection without calling first, your changes will be lost! Create a new object and call on it with the given sql and parameters. Return the new cursor object. Create a new object and call on it with the given sql and parameters. Return the new cursor object. Create a new object and call on it with the given sql_script. Return the new cursor object. Creates a user-defined function that you can later use from within SQL statements under the function name name. num_params is the number of parameters the function accepts (if num_params is -1, the function may take any number of arguments), and func is a Python callable that is called as the SQL function. If deterministic is true, the created function is marked as deterministic, which allows SQLite to perform additional optimizations. This flag is supported by SQLite 3.8.3 or higher, will be raised if used with older versions. The function can return any of the types supported by SQLite: bytes, str, int, float and . Changed in version 3.8: The deterministic parameter was added. The aggregate class must implement a method, which accepts the number of parameters num_params (if num_params is -1, the function may take any number of arguments), and a method which will return the final result of the aggregate. The method can return any of the types supported by SQLite: bytes, str, int, float and . Creates a collation with the specified name and callable. The callable will be passed two string arguments. It should return -1 if the first is ordered lower than the second, 0 if they are ordered equal and 1 if the first is ordered higher than the second. Note that this controls sorting (ORDER BY in SQL) so your comparisons don’t affect other SQL operations. Note that the callable will get its parameters as Python bytestrings, which will normally be encoded in UTF-8. The following example shows a custom collation that sorts “the wrong way”: To remove a collation, call with as callable: You can call this method from a different thread to abort any queries that might be executing on the connection. The query will then abort and the caller will get an exception. This routine registers a callback. The callback is invoked for each attempt to access a column of a table in the database. The callback should return if access is allowed, if the entire SQL statement should be aborted with an error and if the column should be treated as a NULL value. These constants are available in the module. The first argument to the callback signifies what kind of operation is to be authorized. The second and third argument will be arguments or depending on the first argument. The 4th argument is the name of the database (“main”, “temp”, etc.) if applicable. The 5th argument is the name of the inner-most trigger or view that is responsible for the access attempt or if this access attempt is directly from input SQL code. Please consult the SQLite documentation about the possible values for the first argument and the meaning of the second and third argument depending on the first one. All necessary constants are available in the module. This routine registers a callback. The callback is invoked for every n instructions of the SQLite virtual machine. This is useful if you want to get called from SQLite during long-running operations, for example to update a GUI. If you want to clear any previously installed progress handler, call the method with for handler. Returning a non-zero value from the handler function will terminate the currently executing query and cause it to raise an exception. Registers trace_callback to be called for each SQL statement that is actually executed by the SQLite backend. The only argument passed to the callback is the statement (as ) that is being executed. The return value of the callback is ignored. Note that the backend does not only run statements passed to the methods. Other sources include the transaction management of the sqlite3 module and the execution of triggers defined in the current database. Passing as trace_callback will disable the trace callback. Exceptions raised in the trace callback are not propagated. As a development and debugging aid, use to enable printing tracebacks from exceptions raised in the trace callback. This routine allows/disallows the SQLite engine to load SQLite extensions from shared libraries. SQLite extensions can define new functions, aggregates or whole new virtual table implementations. One well-known extension is the fulltext-search extension distributed with SQLite. Loadable extensions are disabled by default. See . # alternatively you can load the extension using an API call: \"select rowid, name, ingredients from recipe where name match 'pie'\" This routine loads an SQLite extension from a shared library. You have to enable extension loading with before you can use this routine. Loadable extensions are disabled by default. See . You can change this attribute to a callable that accepts the cursor and the original row as a tuple and will return the real result row. This way, you can implement more advanced ways of returning results, such as returning an object that can also access columns by name. If returning a tuple doesn’t suffice and you want name-based access to columns, you should consider setting to the highly-optimized type. provides both index-based and case-insensitive name-based access to columns with almost no memory overhead. It will probably be better than your own custom dictionary-based approach or even a db_row based solution. Using this attribute you can control what objects are returned for the data type. By default, this attribute is set to and the module will return objects for . If you want to return instead, you can set it to . You can also set it to any other callable that accepts a single bytestring parameter and returns the resulting object. See the following example code for illustration: # by default, rows are returned as str # but we can make sqlite3 always return bytestrings ... # the bytestrings will be encoded in UTF-8, unless you stored garbage in the # we can also implement a custom text_factory ... # here we implement one that appends \"foo\" to all strings Returns the total number of database rows that have been modified, inserted, or deleted since the database connection was opened. Returns an iterator to dump the database in an SQL text format. Useful when saving an in-memory database for later restoration. This function provides the same capabilities as the command in the sqlite3 shell. This method makes a backup of an SQLite database even while it’s being accessed by other clients, or concurrently by the same connection. The copy will be written into the mandatory argument target, that must be another instance. By default, or when pages is either or a negative integer, the entire database is copied in a single step; otherwise the method performs a loop copying up to pages pages at a time. If progress is specified, it must either be or a callable object that will be executed at each iteration with three integer arguments, respectively the status of the last iteration, the remaining number of pages still to be copied and the total number of pages. The name argument specifies the database name that will be copied: it must be a string containing either , the default, to indicate the main database, to indicate the temporary database or the name specified after the keyword in an statement for an attached database. The sleep argument specifies the number of seconds to sleep by between successive attempts to backup remaining pages, can be specified either as an integer or a floating point value. Example 1, copy an existing database into another: Example 2, copy an existing database into a transient copy:\n\nA instance has the following attributes and methods. Executes an SQL statement. Values may be bound to the statement using placeholders. will only execute a single SQL statement. If you try to execute more than one statement with it, it will raise a . Use if you want to execute multiple SQL statements with one call. Executes a parameterized SQL command against all parameter sequences or mappings found in the sequence seq_of_parameters. The module also allows using an iterator yielding parameters instead of a sequence. This is a nonstandard convenience method for executing multiple SQL statements at once. It issues a statement first, then executes the SQL script it gets as a parameter. This method disregards ; any transaction control must be added to sql_script. sql_script can be an instance of . Fetches the next row of a query result set, returning a single sequence, or when no more data is available. Fetches the next set of rows of a query result, returning a list. An empty list is returned when no more rows are available. The number of rows to fetch per call is specified by the size parameter. If it is not given, the cursor’s arraysize determines the number of rows to be fetched. The method should try to fetch as many rows as indicated by the size parameter. If this is not possible due to the specified number of rows not being available, fewer rows may be returned. Note there are performance considerations involved with the size parameter. For optimal performance, it is usually best to use the arraysize attribute. If the size parameter is used, then it is best for it to retain the same value from one call to the next. Fetches all (remaining) rows of a query result, returning a list. Note that the cursor’s arraysize attribute can affect the performance of this operation. An empty list is returned when no rows are available. Close the cursor now (rather than whenever is called). The cursor will be unusable from this point forward; a exception will be raised if any operation is attempted with the cursor. Required by the DB-API. Does nothing in . Required by the DB-API. Does nothing in . Although the class of the module implements this attribute, the database engine’s own support for the determination of “rows affected”/”rows selected” is quirky. For statements, the number of modifications are summed up into . As required by the Python DB API Spec, the attribute “is -1 in case no has been performed on the cursor or the rowcount of the last operation is not determinable by the interface”. This includes statements because we cannot determine the number of rows a query produced until all rows were fetched. With SQLite versions before 3.6.5, is set to 0 if you make a without any condition. This read-only attribute provides the row id of the last inserted row. It is only updated after successful or statements using the method. For other statements, after or , or if the insertion failed, the value of is left unchanged. The initial value of is . Inserts into tables are not recorded. Changed in version 3.6: Added support for the statement. Read/write attribute that controls the number of rows returned by . The default value is 1 which means a single row would be fetched per call. This read-only attribute provides the column names of the last query. To remain compatible with the Python DB API, it returns a 7-tuple for each column where the last six items of each tuple are . It is set for statements without any matching rows as well. This read-only attribute provides the SQLite database used by the object. A object created by calling will have a attribute that refers to con:\n\nThe following Python types can thus be sent to SQLite without any problem: This is how SQLite types are converted to Python types by default: The type system of the module is extensible in two ways: you can store additional Python types in an SQLite database via object adaptation, and you can let the module convert SQLite types to different Python types via converters. Using adapters to store additional Python types in SQLite databases¶ As described before, SQLite supports only a limited set of types natively. To use other Python types with SQLite, you must adapt them to one of the sqlite3 module’s supported types for SQLite: one of NoneType, int, float, str, bytes. There are two ways to enable the module to adapt a custom Python type to one of the supported ones. This is a good approach if you write the class yourself. Let’s suppose you have a class like this: Now you want to store the point in a single SQLite column. First you’ll have to choose one of the supported types to be used for representing the point. Let’s just use str and separate the coordinates using a semicolon. Then you need to give your class a method which must return the converted value. The parameter protocol will be . The other possibility is to create a function that converts the type to the string representation and register the function with . The module has two default adapters for Python’s built-in and types. Now let’s suppose we want to store objects not in ISO representation, but as a Unix timestamp. Writing an adapter lets you send custom Python types to SQLite. But to make it really useful we need to make the Python to SQLite to Python roundtrip work. Let’s go back to the class. We stored the x and y coordinates separated via semicolons as strings in SQLite. First, we’ll define a converter function that accepts the string as a parameter and constructs a object from it. Converter functions always get called with a object, no matter under which data type you sent the value to SQLite. Now you need to make the module know that what you select from the database is actually a point. There are two ways of doing this:\n• None Explicitly via the column name Both ways are described in section Module functions and constants, in the entries for the constants and . The following example illustrates both approaches. There are default adapters for the date and datetime types in the datetime module. They will be sent as ISO dates/ISO timestamps to SQLite. The default converters are registered under the name “date” for and under the name “timestamp” for . This way, you can use date/timestamps from Python without any additional fiddling in most cases. The format of the adapters is also compatible with the experimental SQLite date/time functions. The following example demonstrates this. If a timestamp stored in SQLite has a fractional part longer than 6 numbers, its value will be truncated to microsecond precision by the timestamp converter. The default “timestamp” converter ignores UTC offsets in the database and always returns a naive object. To preserve UTC offsets in timestamps, either leave converters disabled, or register an offset-aware converter with .\n\nThe underlying library operates in mode by default, but the Python module by default does not. mode means that statements that modify the database take effect immediately. A or statement disables mode, and a , a , or a that ends the outermost transaction, turns mode back on. The Python module by default issues a statement implicitly before a Data Modification Language (DML) statement (i.e. / / / ). You can control which kind of statements implicitly executes via the isolation_level parameter to the call, or via the property of connections. If you specify no isolation_level, a plain is used, which is equivalent to specifying . Other possible values are and . You can disable the module’s implicit transaction management by setting to . This will leave the underlying library operating in mode. You can then completely control the transaction state by explicitly issuing , , , and statements in your code. Note that disregards ; any transaction control must be added explicitly. Changed in version 3.6: used to implicitly commit an open transaction before DDL statements. This is no longer the case.\n\nUsing the nonstandard , and methods of the object, your code can be written more concisely because you don’t have to create the (often superfluous) objects explicitly. Instead, the objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a statement and iterate over it directly using only a single call on the object. # close is not a shortcut method and it's not called automatically, # so the connection object should be closed manually Accessing columns by name instead of by index¶ One useful feature of the module is the built-in class designed to be used as a row factory. Rows wrapped with this class can be accessed both by index (like tuples) and case-insensitively by name: \"select 'John' as name, 42 as age\" Using the connection as a context manager¶ Connection objects can be used as context managers that automatically commit or rollback transactions. In the event of an exception, the transaction is rolled back; otherwise, the transaction is committed: # con.rollback() is called after the with block finishes with an exception, the # exception is still raised and must be caught # Connection object used as context manager only commits or rollbacks transactions, # so the connection object should be closed manually"
    },
    {
        "link": "https://sqlite.org/docs.html",
        "document": ""
    },
    {
        "link": "https://geeksforgeeks.org/python-sqlite",
        "document": "Python SQLite3 module is used to integrate the SQLite database with Python. It is a standardized Python DBI API 2.0 and provides a straightforward and simple-to-use interface for interacting with SQLite databases. There is no need to install this module separately as it comes along with Python after the 2.5x version.\n\nThis Python SQLite tutorial will help to learn how to use SQLite3 with Python from basics to advance with the help of good and well-explained examples and also contains Exercises for honing your skills.\n• None SQLite Datatypes and its Corresponding Python Types\n• None Check if Table Exists in SQLite using Python\n• None How to list tables using SQLite3 in Python ?\n• None How to Alter a SQLite Table using Python ?\n• None How to Delete a Specific Row from SQLite Table using Python ?\n• None How to Update all the Values of a Specific Column of SQLite Table using Python ?\n• None How to Insert Image in SQLite using Python?\n• None How to Read Image in SQLite using Python?\n• None Count total number of changes made after connecting SQLite to Python\n• None How to Show all Columns in the SQLite Database using Python ?\n• None How to Count the Number of Rows of a Given SQLite Table using Python?\n• None How to import CSV file in SQLite database using Python ?\n• None How to Execute a Script in SQLite using Python?\n• None How to store Python functions in a Sqlite table?\n• None How to Create a Backup of a SQLite Database using Python?\n• None How to connect to SQLite database that resides in the memory using Python ?\n\nCan You Use SQLite with Python?\n\nHow to Use pysqlite?\n\nis an external library in Python that provides SQLite database access. It was the original interface to the SQLite relational database management system before it became integrated into Python’s standard library as . Since Python 2.5 and above, is included in Python’s standard library, which essentially provides the same functionalities as . If you are using Python 2.5 or later, it is recommended to use instead. Here’s a basic example of using : import sqlite3 # Connect to an SQLite database (or create it if it doesn't exist) conn = sqlite3.connect('example.db') # Create a cursor object using the cursor() method cursor = conn.cursor() # Create table cursor.execute('''CREATE TABLE IF NOT EXISTS stocks (date text, trans text, symbol text, qty real, price real)''') # Insert a row of data cursor.execute(\"INSERT INTO stocks VALUES ('2006-01-05','BUY','RHAT',100,35.14)\") # Save (commit) the changes conn.commit() # Close the connection conn.close()\n\nWhat is the Purpose of the Python SQLite Connector?\n\nWhat is the Difference Between SQLite and MySQL?\n\nYes, is part of Python’s standard library for versions 2.5 and later. It provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249. This means you don’t need to install anything extra if you’re using these versions of Python; you can start using SQLite databases in your applications right away."
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-use-the-sqlite3-module-in-python-3",
        "document": "The author selected the COVID-19 Relief Fund to receive a donation as part of the Write for DOnations program.\n\nSQLite is a self-contained, file-based SQL database. SQLite comes bundled with Python and can be used in any of your Python applications without having to install any additional software.\n\nIn this tutorial, we’ll go through the module in Python 3. We’ll create a connection to a SQLite database, add a table to that database, insert data into that table, and read and modify data in that table.\n\nFor this tutorial, we’ll be working primarily with an inventory of fish that we need to modify as fish are added to or removed from a fictional aquarium.\n\nTo get the most out of this tutorial, it is recommended to have some familiarity with programming in Python and some basic background with SQL.\n\nYou can review these tutorials for the necessary background information:\n• How to Code in Python3\n• An Introduction to Queries in MySQL\n\nWhen we connect to a SQLite database, we are accessing data that ultimately resides in a file on our computer. SQLite databases are fully featured SQL engines that can be used for many purposes. For now, we’ll consider a database that tracks the inventory of fish at a fictional aquarium.\n\nWe can connect to a SQLite database using the Python module:\n\ngives our Python program access to the module. The function returns a object that we will use to interact with the SQLite database held in the file . The file is created automatically by if does not already exist on our computer.\n\nWe can verify we successfully created our object by running:\n\nIf we run this Python code, we will see output like:\n\nis the total number of database rows that have been changed by . Since we have not executed any SQL commands yet, 0 is correct.\n\nIf, at any time, we find we want to start this tutorial again, we can delete the file from our computer.\n\nNow that we have connected to the SQLite database, we can start inserting and reading data from it.\n\nIn a SQL database, data is stored in tables. Tables define a set of columns, and contain 0 or more rows with data for each of the defined columns.\n\nWe will create a table named that tracks the following data:\n\nThe table will track a value for , , and for each fish at the aquarium. Two example rows are listed: one row for a named , and one row for a named .\n\nWe can create this table in SQLite using the we made in Step 1:\n\nreturns a object. objects allow us to send SQL statements to a SQLite database using . The string is a SQL statement that creates a table named with the three columns described earlier: of type , species of type , and of type .\n\nNow that we have created a table, we can insert rows of data into it:\n\nWe call two times: once to insert a row for the shark in tank , and once to insert a row for the cuttlefish in tank . is a SQL statement that allows us to add rows to a table.\n\nIn the next section, we will use a SQL statement to inspect the rows we just inserted into our table.\n\nIn Step 2, we added two rows to a SQLite table named . We can retrieve those rows using a SQL statement:\n\nIf we run this code, we will see output like the following:\n\nThe function runs a statement to retrieve values for the , , and columns in the table. retrieves all the results of the statement. When we we see a list of two tuples. Each tuple has three entries; one entry for each column we selected from the table. The two tuples have the data we inserted in Step 2: one tuple for the , and one tuple for the .\n\nIf we wanted to retrieve rows in the table that match a specific set of criteria, we can use a clause:\n\nIf we run this, we will see output like the following:\n\nAs with the previous example, allows us to fetch all the results of a statement. The clause in the statement filters for rows where the value of is . Notice that we use to substitute our variable into the statement. We expect to only match one row, and indeed we only see the row for the returned.\n\nRows in a SQLite database can be modified using and SQL statements.\n\nLet’s say, for example, that Sammy the shark was moved to tank number 2. We can change Sammy’s row in the table to reflect this change:\n\nWe issue an SQL statement to change the of to its new value of . The clause in the statement ensures we only change the value of if a row has .\n\nIf we run the following statement, we can confirm our update was made correctly:\n\nIf we run this, we will see output like the following:\n\nNotice that the row for now has the value of for its column.\n\nLet’s say that Sammy the shark was released into the wild and no longer held by the aquarium. Since Sammy no longer lives at the aquarium, it would make sense to remove the row from the table.\n\nWe issue a SQL statement to remove the row for the . The clause in the statement ensures we only delete a row if that row has .\n\nIf we run the following statement, we can confirm our deletion was made correctly:\n\nIf we run this code, we will see output like the following:\n\nNotice that the row for the is now gone, and only the remains.\n\nIn this tutorial, we’ve used two primary objects to interact with the SQLite database: a object named , and a object named .\n\nIn the same way that Python files should be closed when we are done working with them, and objects should also be closed when they are no longer needed.\n\nWe can use a statement to help us automatically close and objects:\n\nis a convenience function provided by the module. When a statement exits, ensures that is called on whatever object is passed to it. The function is used twice in this example. Once to ensure that the object returned by is automatically closed, and a second time to ensure that the object returned by is automatically closed.\n\nIf we run this code, we will see output like the following:\n\nSince is a SQL statement that always returns a single row with a single column with a value of , it makes sense to see a single tuple with as its only value returned by our code.\n\nThe module is a powerful part of the Python standard library; it lets us work with a fully featured on-disk SQL database without installing any additional software.\n\nIn this tutorial, we learned how to use the module to connect to a SQLite database, add data to that database, as well as read and modify data in that database. Along the way, we also learned about the risks of SQL injection attacks and how to use to automatically call on Python objects in statements.\n\nFrom here we can learn more about SQL databases in SQLite vs MySQL vs PostgreSQL: A Comparison Of Relational Database Management Systems."
    },
    {
        "link": "https://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python",
        "document": "I want to navigate from the root directory to all other directories within and print the same.\n\nAbove, and are directories.\n\nHowever, I need to print the O/P in the following manner:\n\nAbove, and are directories and the rest are files."
    },
    {
        "link": "https://stackoverflow.com/questions/45188708/how-to-prevent-directory-traversal-attack-from-python-code",
        "document": "Suppose the user content is all located in\n\nEnding with is important as heinrichj mentions to ensure the check below matches against a specific directory.\n\nYou need to verify the final request is in there:\n\nIf the requested path is allowed to be the itself, you would also need to allow entry if .\n\nI encourage you to make sure all stuff you want accessible by the user in one place."
    },
    {
        "link": "https://qwiet.ai/preventing-directory-traversal-attacks-best-practices-for-file-handling",
        "document": "Directory Traversal Attacks: they’re like the pickpockets of the web, sneaking around your server’s file system, looking for something valuable to snatch. But don’t worry; we’ve got the tools and techniques to catch these digital thieves red-handed. So, let’s get into the nitty-gritty of securing your file handling operations and making your server a no-go zone for directory traversal mischief.\n\nIn a Directory Traversal Attack, an attacker manipulates file paths in a way that allows them to access files and directories that should be restricted. Imagine someone trying to sneak backstage at a concert by finding a hidden path; only, in this case, the backstage holds sensitive data and system files.\n\nBefore we dive into the solutions, let’s get the basics right. Understanding how file paths work is crucial for securing them. A file path like ../../etc/passwd can be a red flag, signaling an attempt to move up directories to access sensitive files.\n\nIn this Python snippet, we’re using os.path.join to construct a file path. The user provides a file name, which is then appended to the /app/data/ directory. This is a basic example and not secure as-is, because a crafty user could input something like ../../etc/passwd to access restricted files.\n\nThe first line of defense is always validating what the user has provided. Make sure the input matches a certain pattern or set of allowed values.\n\nWe’re using Python’s re module to check if the user-provided file name contains only alphanumeric characters and underscores. If it doesn’t, we flag it as invalid.\n\nMany programming languages offer built-in functions to normalize file paths, effectively resolving “..” and “.” references.\n\nIn this Python example, os.path.normpath is used to normalize the file path. We then check if the normalized path starts with the allowed directory /app/data/. If it does, access is allowed.\n\nRestrict the types of operations that can be performed. If a feature only requires reading files, there should be no option to delete or modify them.\n\nWe’re explicitly checking if the operation is “read” before proceeding. Any other operation is flagged as not allowed.\n\nAccess control mechanisms can be implemented at the application level to ensure only authorized users can access certain files.\n\nIn this snippet, we’re checking the user’s role before allowing access to a file. Only users with an “admin” role are granted access.\n\nKeep an eye on file access logs to detect any suspicious activity.\n\nHere, we’re using Python’s logging module to log file access, including the user ID and the file path. This can help in auditing and identifying suspicious behavior.\n\nDirectory Traversal Attacks are deceptive but can be countered with the right strategies and tools. To bolster your defenses and ensure against directory traversal attacks, it’s essential to stay vigilant and consistent in your security protocols. Want to see how a tool like Qwiet can help you secure your security posture? Book a demo with us today."
    },
    {
        "link": "https://medium.com/pythons-gurus/mastering-recursion-in-python-130a1895df16",
        "document": "Recursion is a fundamental concept in programming, where a function calls itself in order to solve a problem. It is an important tool for data professionals and developers, especially when dealing with problems that have a repetitive or hierarchical structure. Recursion helps in simplifying complex problems by breaking them down into smaller, more manageable sub-problems.\n\nIn Python, recursion is a powerful technique that allows a function to call itself either directly or indirectly. This approach can be particularly useful for tasks like traversing trees, implementing search algorithms, or solving mathematical problems like calculating factorials and Fibonacci sequences.\n\nHi all, my name is CyCoderX and in this article I will provide a detailed explanation of recursion, along with examples and best practices for implementing recursive functions in Python.\n\nRecursion is a method where a function solves a problem by breaking it down into smaller instances of the same problem, which are then solved individually. To ensure that a recursive function doesn’t run infinitely, each recursive call works towards reaching a base case — a condition that stops the recursion from continuing.\n\nWhen a recursive function is called, it keeps breaking down the problem into smaller sub-problems. Each function call is placed on something called the call stack, and the function waits for the smaller sub-problem to return a result before proceeding.\n\nThe key to writing a recursive function is to:\n• Identify the base case: This is the condition where the problem is simple enough to be solved directly, without further recursive calls. The base case stops the recursion.\n• Define the recursive case: This is where the function calls itself to solve smaller sub-problems.\n\nOnce the base case is reached, the results are returned back up the call stack, with each function call completing its task and returning the final result.\n\nA classic example of recursion is calculating the factorial of a number. The factorial of a non-negative integer is the product of all integers less than or equal to . Using recursion, we can break this problem into a smaller one by calculating the factorial of until we reach the base case (when is 1 or 0).\n\nHere’s an example in Python:\n\nIn this example, the recursive case is , and the base case is when is 0 or 1, where the recursion stops.\n\nKeep in mind, there are various ways to write a factorial function in Python. This example is just to illustrate the concept. You can also simply import the factorial function from the math module.\n\nRecursion offers several advantages, especially in scenarios where the problem can naturally be divided into smaller sub-problems. Let’s explore some of the key benefits of using recursion:\n\nRecursion can simplify the implementation of complex problems by allowing you to break them down into smaller, more manageable parts. For example, problems like traversing trees or graphs can be implemented more elegantly using recursion, as it closely resembles the natural structure of these problems.\n\nConsider a problem where you need to traverse a directory structure (which resembles a tree). Each directory can contain files or subdirectories. Recursively visiting each subdirectory makes this problem much simpler:\n\nIn this example, the function recursively visits all subdirectories and prints the full path of each file. The problem becomes much easier to solve because recursion aligns naturally with the structure of the directory tree.\n\nRecursive solutions are often more concise and cleaner than their iterative counterparts. While an iterative approach might require managing a loop and keeping track of additional variables, recursion allows the problem to be solved in a more straightforward and elegant manner. This results in code that is often easier to read and maintain.\n\nMany algorithms, such as merge sort, quicksort, and binary search, follow the divide-and-conquer strategy, where a problem is divided into smaller sub-problems that are solved independently and then combined. Recursion is a natural fit for these algorithms, as it allows you to repeatedly break down the problem until it is simple enough to solve directly.\n\nFor example, consider the merge sort algorithm, which recursively divides the list into smaller sub-lists, sorts each sub-list, and then merges them back together:\n\nIn this example, the function divides the list into two halves, recursively sorts each half, and then merges them back together. Recursion makes it easy to break the problem down until the base case (when the list has one or no elements) is reached.\n\nWhile recursion is a powerful tool, it does come with certain trade-offs. In some cases, an iterative solution might be more efficient and practical than a recursive one. Here are some of the common disadvantages of recursion:\n\nEvery time a recursive function is called, a new frame is added to the call stack. This means that recursion can consume more memory and time than an iterative solution, particularly when the recursion depth becomes significant. Each recursive call involves overhead for maintaining the call stack, which can result in slower performance compared to an iterative loop.\n\nIn Python, this is particularly important to consider because Python’s default recursion depth is limited (usually to around 1000 calls). If the recursion depth exceeds this limit, you may encounter a .\n\nHere’s an example of recursion exceeding the depth limit:\n\nThe Python interpreter limits the depth of recursion to avoid running out of memory. For large problems, recursion may not always be the best approach due to this performance limitation.\n\nIf the recursion depth becomes too deep, you might run into a stack overflow error. This happens when the program exhausts the memory allocated for the call stack due to too many recursive calls. As mentioned earlier, Python raises a when this happens, but in other programming environments, this could crash the program entirely.\n\nFor example, consider calculating the Fibonacci sequence recursively. If we calculate the nth Fibonacci number using recursion without any optimization, the number of recursive calls grows exponentially, leading to performance degradation or a potential stack overflow:\n\nIn this case, for larger values of , the number of function calls becomes excessively large. This is because each call to makes two additional recursive calls to and . Without any form of optimization, this can cause performance issues.\n\nRecursive functions can be harder to debug than iterative functions, especially for beginners. It can be challenging to keep track of how many recursive calls have been made and what the state of each call is at any given point. This is especially true for problems where recursion depth is deep, or the base case is not clearly defined. Errors like missing a base case or making incorrect recursive calls can be difficult to trace.\n\nConsider the following recursive implementation of a function to calculate the sum of integers in a list:\n\nIf a mistake is made (for example, if the base case is incorrect or omitted), the program can end up in an infinite loop of recursive calls, which might be difficult to debug, particularly in complex problems.\n\nWhen to Use Recursion\n\nRecursion is best used when a problem can naturally be divided into smaller, similar sub-problems. Here are some scenarios where recursion is often the preferred approach:\n• Tree Traversals: Recursion is often the easiest way to traverse data structures like trees. For example, in-order, pre-order, and post-order tree traversal algorithms are naturally recursive.\n• Divide-and-Conquer Algorithms: Algorithms like quicksort and merge sort use recursion to divide the problem into smaller sub-problems.\n• Solving Puzzles: Problems like the Tower of Hanoi or generating permutations and combinations are often best solved using recursion.\n• Graphs: Recursion is commonly used in graph traversal algorithms, such as depth-first search (DFS).\n\nOn the other hand, when performance is a major concern, or when dealing with a problem that requires many repetitive recursive calls, an iterative solution might be more efficient.\n\nBest Practices for Using Recursion in Python\n\nWhen working with recursion in Python, it’s essential to follow best practices to write efficient, readable, and maintainable code. Here are some guidelines to help you effectively utilize recursion:\n\nEnsure that your base cases are well-defined and easily reachable. A clear base case is crucial for preventing infinite recursion and ensuring that the function eventually terminates. Take time to think through your base case and how your recursive calls will lead to it.\n\nIn this example, the base case is when is less than or equal to 0, ensuring that the recursion terminates.\n\nTail recursion is a form of recursion where the recursive call is the last operation in the function. Although Python does not optimize tail recursion like some other languages (such as Scheme), being aware of this can help you write clearer recursive functions.\n\nWhile Python won’t optimize tail calls, writing functions this way can help you think about how to manage state across recursive calls.\n\nFor problems that involve repeated calculations (like the Fibonacci sequence), consider using memoization. This technique involves caching the results of expensive function calls and returning the cached result when the same inputs occur again. This can greatly improve performance for recursive functions.\n\nIn this example, we use a dictionary to cache results, significantly reducing the time complexity.\n\nBe aware of the recursion depth in Python. You can use the module to check and set the maximum recursion depth. If you expect deep recursion, consider refactoring to an iterative solution or increasing the recursion limit using . However, use this with caution, as it can lead to stack overflow.\n\nTesting and debugging recursive functions can be more complex than iterative ones. Use print statements or a debugger to track the flow of function calls and variable values. Write unit tests to ensure that your base cases and recursive cases work as expected.\n\nRecursion is a powerful tool in Python that allows developers to solve complex problems through elegant and straightforward code. While it has its advantages, such as simplifying problem-solving and providing clear solutions, it’s essential to be mindful of its limitations, including performance overhead and stack depth.\n\nBy understanding when to use recursion and following best practices, data professionals can leverage recursion effectively in their projects. Whether traversing data structures, implementing algorithms, or solving mathematical problems, recursion remains an indispensable technique in a developer’s toolkit.\n\nThank you for reading, and happy coding!"
    },
    {
        "link": "https://medium.com/@sabahat-khan/how-to-recursively-traverse-files-and-directories-in-python-6020155713fa",
        "document": "\n• An IDE application to code your Python in. I will be using the Cloud9 IDE on AWS.\n• Basic knowledge of Python. This article will assume you already know about variables, loops, and if statements.\n\nThe task of this article is to create a Python script to learn about files on various machines. With this, we can check the files much more efficiently by automating the process through a script as opposed to manually traversing each file and directory.\n\nThe article will cover the following sections:\n• Creating a Function to Recursively Traverse the Files and Directories\n• Creating a Function to Create Dictionaries and Placing Them into a List\n\nCreating a Function to Recursively Traverse the Files and Directories\n\nTo start, we will be creating a function to recursively go through the files and directories. We can achieve this by using the function. Notice that there is an before the function. This is because the function is contained in the library. So to start with writing our program, we will be importing the library.\n\nTo import the library, type the following code at the top of your file:\n\nWith the library imported, we can now start writing our function using the keyword. We will start by defining a function called . The structure of the function will be as follows:\n\nBefore we continue writing our function, we will need something called a “parameter.” This parameter will serve as input for the user. The function’s output will vary depending on what the user uses as an input. When calling our function, we will also want our function to have a default value in case the user does not input anything. We can create a parameter with a default value as follows: . This tells the program that the parameter will serve as an input for the user and will have the default value of (representing the current working directory) in case no input is provided. Finishing the header of the function, we get the following:\n\nIn the function, we will use the list to capture the file paths.\n\nNow, we can use to iterate through the file path specified by the user. We will use a for loop to iterate through the function. The function can return the root, directories, and files. We will use this concept to capture these variables in each iteration.\n\nWe can use the following “for loop” header to loop through :\n\nThe variable will return the string that represents the root file path; the variable will return a list of directories that were traversed; and the variable will return a list of files that were traversed.\n\nThe task is to get the file path of the files that were traversed. To do so, we will be using the and variables.\n\nWe will start by iterating through each file in the variable by using a nested for loop:\n\nIf the user uses a default value of (this represents the current working directory), our code later on will not work with just the character. We will correct this by using os.cwd() to obtain the root instead. Otherwise, we can just set the root itself:\n\nNow that we have the root file path, all we need to do is just add the file to the file path to complete our desired file path. We will add the extra slash in case the root is not equal to the user input:\n\nFinally, at the end of our nested for loop, we add the following code to add our file path item to our list of file paths:\n\nThe last step is to return our file path list. We have now completed our walk_paths() function. The complete function should now look like the following:\n\n#This function goes through all of the files and subdirectories in the file path specified by the user\n\n#and appends all filepaths to a list. The function then returns this list\n\ndef walk_files(src_filepath = \".\"):\n\n filepath_list = []\n\n \n\n #This for loop uses the os.walk() function to walk through the files and directories\n\n #and records the filepaths of the files to a list\n\n for root, dirs, files in os.walk(src_filepath):\n\n \n\n #iterate through the files currently obtained by os.walk() and\n\n #create the filepath string for that file and add it to the filepath_list list\n\n for file in files:\n\n #Checks to see if the root is '.' and changes it to the correct current\n\n #working directory by calling os.getcwd(). Otherwise root_path will just be the root variable value.\n\n if root == '.':\n\n root_path = os.getcwd() + \"/\"\n\n else:\n\n root_path = root\n\n \n\n #This if statement checks to see if an extra '/' character is needed to append \n\n #to the filepath or not\n\n if (root_path != src_filepath) and (root != '.'):\n\n filepath = root_path + \"/\" + file\n\n else:\n\n filepath = root_path + file\n\n \n\n #Appends filepath to filepath_list if filepath does not currently exist in filepath_list\n\n if filepath not in filepath_list:\n\n filepath_list.append(filepath)\n\n \n\n #Return filepath_list \n\n return filepath_list\n\nWe will use this return list for our function, which will print these lists as a dictionary.\n\nCreating a Function to Create Dictionaries and Placing Them into a List\n\nWe will now create another function that will call the function and print the details of each file path by putting each item in a dictionary. We will call this function\n\nWe will have the same parameter variable with the same default value. We will thus have the following header:\n\nWe will now call the function to capture the returned list in a local list variable. We will use the parameter variable as the input of this function. We will also create a list to store the file path dictionary items:\n\nNow we will iterate through each item in our variable and append the file path and size to our list:\n\nSince we already have the file paths retrieved from the function, all that is left is to retrieve the size of each item in the variable. We can use the command to retrieve the size. We will check if is equal to the default value and call on instead. This is because does not recognize as a file path for the current directory. If the variable is not equal then it can use the variable directly:\n\nNow that we have both the file path and size, all we have to do is create a dictionary item and append this value to our\n\nThe last lines in our function will iterate and print each item after we have finished appending it to the list:\n\nWe have now completed all of the code necessary to walk through and print the details of file paths for our specified file path. Your completed function should look as follows:\n\nThe specified file path mentioned in this example will be different than the one you will specify. Please ensure to add a ‘/’ character at the end of your file path. Also, make sure to include the full directory. All that is left is to call our function which can be done as follows:\n\nYou should receive outputs similar to the one below:\n\nCongratulations! You have now completed the code. The full code should look like this:\n\nYou can also find my code on my Github account by clicking the link here: https://github.com/sabahatk/luit-gold-april-2024-repo/tree/main/Week-14-Project\n\nWe have now completed creating our Python code to traverse the files and print their file paths and sizes accordingly. We first started by creating a function to traverse the files and subdirectories and keep a list of file paths for each file. Afterward, we created another function that retrieves the sizes of each file path and placed both the file path and size details in a dictionary variable. Lastly, we appended the dictionaries to a list and printed each item in the list. Thank you for taking the time to read my article. I hope you enjoyed it and learned something new."
    }
]