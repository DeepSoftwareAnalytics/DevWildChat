[
    {
        "link": "https://getthematic.com/insights/history-of-text-analytics",
        "document": "Explore the history of text analytics, from its origins to advanced AI and NLP technologies of today.\n\nEvery day, over 3.5 quintillion bytes of data are created—much of it unstructured text. Without text analytics, this massive flow of information would be impossible to process.\n\nFrom customer sentiment analysis to fraud detection, text analytics turns raw words into insights. But it didn’t start with AI. In the 1800s, scholars manually counted words to study emotions. By the mid-20th century, content analysis helped decode propaganda, and later, machine learning and NLP transformed the field.\n\nWhy does history matter? The history of text analytics tells us how far we’ve come, from manual word counts to AI-driven insights. Each breakthrough shaped today’s tools, but more importantly, it reveals where we’re headed next.\n\nSo, go back to memory lane to better understand the wonders of text analytics.\n• Breakthroughs like wartime analysis, big data, and AI reshaped the field.\n\nBefore computers, scholars had only one tool for analyzing text—manual counting. In the early 1800s, researchers studied religious and literary texts by tracking word frequencies to identify recurring themes and sentiments. One famous example was biblical scholars analyzing scripture to uncover patterns in emotional expression and moral teachings.\n\nBy the late 19th century, linguists and social scientists expanded this approach. They manually categorized words and phrases to study public discourse, literature, and political speech, laying the groundwork for content analysis. These early methods, though limited, helped scholars understand how language reflects human thought, bias, and emotion.\n\nThis foundation in word frequency analysis would later evolve into quantitative content analysis, influencing fields like journalism, psychology, and social sciences. Though slow and labor-intensive, these early approaches proved that text data holds deep insights—if we have the right tools to analyze it.\n\nThe Rise of Content Analysis: Measuring Meaning in Text (Mid-20th Century)\n\nBy the mid-20th century, text analysis had moved beyond manual word counting into a more systematic approach—content analysis. One of the pioneers, Harold Lasswell, developed methods to study political propaganda by categorizing words, phrases, and themes in speeches and media. His work helped governments and researchers understand how language shaped public opinion, particularly during World War II.\n\nAs mass media grew, content analysis became essential in journalism, political science, and social research. Scholars transitioned from qualitative interpretations to quantitative methods, coding large amounts of text into measurable categories. This shift laid the foundation for modern text analytics approaches.\n\nBy applying statistical techniques to text, researchers could track trends, detect biases, and analyze sentiment—an approach that would later merge with machine learning and artificial intelligence, transforming how we extract insights from language.\n\nWorld War II accelerated the need for large-scale text analysis as intelligence agencies sought to decode enemy communications and sift through massive amounts of intercepted messages. This demand led to early computational linguistics, where researchers explored ways to automate text analysis using rule-based systems.\n\nOne of the key figures in this movement, Warren Weaver, envisioned a future where machine translation could automatically convert one language to another. His ideas sparked some of the earliest natural language processing (NLP) efforts, relying on syntax rules and statistical models to analyze text. However, early machine translation systems struggled with accuracy, highlighting the complexity of human language.\n\nBy the 1960s, text analytics methods evolved to include rule-based parsing, part-of-speech tagging, and statistical modeling. These breakthroughs laid the groundwork for modern NLP, enabling machines to process, categorize, and extract meaning from text—an essential step toward today’s AI-driven text analytics.\n\nAs computers became more powerful, text analytics moved from simple rules to more structured computational methods. Researchers developed part-of-speech tagging, stemming, and parsing techniques, allowing machines to break text into structured components. These methods helped with categorizing and coding qualitative data, making text more machine-readable.\n\nDuring this period, Symbolic AI gained traction, relying on rule-based and expert systems to process language. These systems used manually defined rules to identify sentence structures and word relationships, but they struggled with ambiguity and real-world language complexities.\n\nMeanwhile, vector-based representations, like TF-IDF and latent semantic analysis (LSA), introduced a statistical way to quantify the meaning of words. These approaches allowed computers to group similar words, detect themes, and improve text classification, setting the stage for machine learning-driven text analytics in the coming decades.\n\nText Mining & the Rise of Big Data (1990s-2000s): Extracting Insights at Scale\n\nThe explosion of digital text data in the 1990s transformed text analytics. With the rise of the internet, researchers needed new methods to process massive volumes of unstructured text. This led to TF-IDF (term frequency-inverse document frequency) and topic modeling, which helped identify patterns and extract key themes from large datasets.\n\nBy the 2000s, machine learning-powered sentiment analysis and entity recognition became mainstream, allowing businesses to track public opinion and detect important entities in text automatically. These advancements blurred the line between quantitative and qualitative text analysis, making it easier to process large-scale unstructured data. In industries like marketing, finance, and customer experience, text mining became a game-changer. Businesses used Voice of Customer (VoC) analytics to analyze feedback and improve decision-making. These innovations paved the way for AI-driven text analytics, which would dominate the next era.\n\nThe rise of deep learning and large language models (LLMs), like GPT and BERT, has redefined text analytics. Unlike earlier rule-based or statistical approaches, these AI-driven models understand context, detect emotions, and generate human-like responses with unprecedented accuracy.\n\nModern sentiment analysis uses AI to assess opinions at scale, helping brands track customer emotions in real-time. Entity recognition, topic modeling, and conversational AI have also improved, making chatbots, virtual assistants, and automated insights more effective.\n\nBusinesses rely on text analytics for social media, analyzing customer conversations, reviews, and trends to shape marketing strategies. AI-powered tools like thematic analysis software, help companies extract deeper insights from feedback, enhancing customer experience (CX) and market research.\n\nWith AI leading the way, text analytics has never been more powerful—and its evolution is far from over.\n\nThe History of Text Analytics: Where Is it Headed Next?\n\nThe journey of text analytics has been nothing short of revolutionary. From manual word counts in the 1800s to content analysis in the mid-20th century, researchers have long sought ways to make sense of language. The rise of machine translation and NLP in the 1960s paved the way for statistical models, text mining, and AI-driven analytics, transforming how we extract meaning from text.\n\nToday, deep learning and LLMs have made text analytics faster, smarter, and more scalable. As AI continues to evolve, expect more explainable AI, real-time text analysis, and seamless integration with voice, video, and other data sources.\n\nWant to see how AI-powered text analytics can transform your business? Try Thematic and uncover deep insights from your own data—faster, smarter, and with more accuracy than ever before!"
    },
    {
        "link": "https://linkedin.com/pulse/historical-critical-textual-analysis-ai-bridging-past-williams-phd-driec",
        "document": "In the quiet corners of dusty archives, historians labor over ancient manuscripts, piecing together fragments of the past. Their task is akin to solving a jigsaw puzzle with missing pieces—each document revealing a glimpse of bygone eras. But what if we could enlist the help of artificial intelligence (AI) to unlock hidden narratives and correct historical distortions? Welcome to the intersection of historical-critical textual analysis and AI—a realm where algorithms sift through centuries-old texts, shedding light on forgotten stories and challenging our understanding of history.\n\nHistorical-critical textual analysis is a scholarly approach that seeks to understand ancient texts within their historical context. Let's explore its tenets and how AI can amplify its impact:\n\n- Historians strive to uncover the primitive intent behind texts. What did the author truly mean? AI algorithms can assist by analyzing vast corpora of historical documents, drawing connections across a broader swath of the record.\n\n- AI helps historians reconstruct the context in which texts emerged. By considering events, social norms, and cultural nuances, we gain a richer understanding.\n\n- Whether it's deciphering court records or medieval manuscripts, AI accelerates the process, allowing us to glimpse the past more vividly.\n\n- AI tools parse this complexity, sifting through terabytes of information. They identify patterns, connections, and anomalies that human scholars might miss.\n\nAs AI reshapes historical inquiry, we stand at a digital renaissance. The historians of tomorrow wield neural networks alongside quills, unearthing forgotten voices and rewriting narratives. Let us embrace this symbiosis—a dance between silicon and parchment—as we unravel the tapestry of time."
    },
    {
        "link": "https://sangramsing.medium.com/natural-language-processing-for-historical-texts-f43f1670a5fe",
        "document": "Have you ever wished you could create your own, real-time version of the US census? You might also wish you had the ability to search through millions of words to locate every instance of a certain word or phrase. In this blog, I’ll demonstrate how to create a program that enables us to accomplish just that using machine learning techniques, and more especially, natural language processing.\n\nAn emerging technique called natural language processing (NLP) enables computers to comprehend and examine text data. NLP enables computers to interpret and extract data from unstructured language, including emails and news articles. Pre-processing is the process of obtaining data from natural language text.\n\nTokenization, stemming, stop words removal, and sentiment analysis are the four main types of NLP pre-processing procedures. Tokenization, the first phase, divides the content into word units known as tokens (single words). Next, stems with equivalent ends but various prefixes or suffixes are used (e.g., “running,” “runners”). By reducing numerous spellings of a term to its most basic form, stemming reduces noise in your dataset to just…"
    },
    {
        "link": "https://linkedin.com/pulse/deep-dives-history-how-ai-transforming-historical-research-dubov-cvahc",
        "document": "The world of historical research is undergoing a profound transformation thanks to the rise of Artificial Intelligence (AI). While the image of a historian may conjure up visions of dusty archives and meticulous manual analysis, the reality is rapidly changing. AI now empowers historians and archivists to delve into the past with unprecedented speed and depth, uncovering hidden patterns and making historical knowledge more accessible to a broader audience1.\n• Handwritten Text Recognition (HTR): HTR systems, such as Transkribus, revolutionize how historians interact with handwritten documents2. These AI-powered tools can accurately transcribe handwritten text, saving countless hours of manual labour and making historical documents more accessible for analysis.\n• AI Language Models: Large language models, like ChatGPT, are proving invaluable in historical research. They can translate old texts, summarize lengthy documents, and even generate insights by analyzing patterns in language3.\n• Computer Vision: Computer vision empowers AI systems to \"see\" and interpret images, making it a powerful tool for analyzing historical photographs, maps, and artifacts. For example, MapReader, a computer vision tool developed at the University of Lancaster, allows historians to extract data from historical maps, revealing changes in landscapes and societies over time 4.\n• Predictive Modeling: AI can create models that predict historical trends and outcomes based on existing data. This helps researchers understand the factors contributing to historical events and explore alternative scenarios6.\n• Natural Language Processing (NLP): NLP techniques enable AI systems to understand and analyze text, making it possible to decipher ancient languages, identify biases in historical narratives, and extract information from large text4.\n\nAI is also being used to unlock the secrets of encrypted historical documents. The Inria Back In Time project in France brings together experts in history, natural language processing (NLP), and cryptography to decipher historical texts that can no longer be read4. This project aims to create an online portal where researchers can upload scans of encrypted documents and have them automatically deciphered by AI, making these historical sources accessible once again.\n\nAI-powered tools like MapReader help extract data from historical maps and understand the impact of climate change on past societies. For example, a historian used MapReader to study the historical influence of climate change on the presence of curling ponds in Britain4. By analyzing maps from different periods, the researcher tracked the changing distribution of these ponds, revealing how climate variations affected leisure activities and social practices.\n\nBenefits and Limitations of AI in Historical Research\n\nOne of the most promising aspects of AI in historical research is its potential to address historical silences and uncover overlooked narratives. Historical silences arise when certain voices or perspectives are excluded from historical accounts, often due to systemic biases or power imbalances7. AI can help identify and amplify these marginalized voices by analyzing large datasets and uncovering hidden patterns. This can lead to a more inclusive and nuanced understanding of the past, challenging traditional narratives and offering new perspectives on historical events.\n\nAI is also transforming the way historians interact with historical databases. By incorporating generative AI products into databases and pre-training them with relevant research literature, we can enhance the analytical capabilities of these databases16. This allows AI to provide logical answers, understand the relationships between researcher instructions and data content, and offer more personalized and in-depth analysis. Researchers can engage in interactive Q&A sessions with these AI-powered databases, transforming the process of retrieving historical information into a dynamic and collaborative research experience.\n\nThe Future of History in the Age of AI\n\nAI is revolutionizing historical research, empowering historians and archivists to delve deeper into the past and make historical knowledge more accessible to a broader audience. While AI has limitations, its potential to transform the field is undeniable. By embracing AI responsibly and ethically, we can unlock new insights into our shared history and ensure that the past continues to inform our present and future.\n\nThe future of historical research lies in the intelligent collaboration between humans and AI. By combining both strengths, we can unlock new possibilities for understanding the past and ensure that history continues to be a source of knowledge, inspiration, and critical reflection for generations to come. I encourage you to explore the AI-powered historical resources available online and delve deeper into this fascinating field."
    },
    {
        "link": "https://dataversity.net/a-brief-history-of-natural-language-processing-nlp",
        "document": "In the early 1900s, a Swiss linguistics professor named Ferdinand de Saussure died, and in the process, almost deprived the world of the concept of “Language as a Science,” which eventually led to natural language processing. From 1906 to 1911, Professor Saussure offered three courses at the University of Geneva, where he developed an approach describing languages as “systems.” Within the language, a sound represents a concept – a concept that shifts meaning as the context changes. Saussure argued that meaning is created inside language, in the relations and differences between its parts. He proposed that “meaning” is created within a language’s relationships and contrasts. A shared language system makes communication possible. Saussure viewed society as a system of “shared” social norms that provides conditions for reasonable, “extended” thinking, resulting in decisions and actions by individuals. (The same view can be applied to modern computer languages.) Saussure died (in 1913) before publishing his theories. However, two of his colleagues, Albert Sechehaye and Charles Bally, recognized the importance of his concepts (imagine Sechehaye and Bally, days after Saussure’s death, drinking coffee together and wondering how to keep his discoveries from being lost forever). The two took the unusual steps of collecting “his notes for a manuscript” and “his students’ notes” from the courses. From these, they wrote the Cours de Linguistique Générale, published in 1916. The book laid the foundation for what has come to be called the structuralist approach, starting with linguistics, and later expanding to other fields, including computers. In 1950, Alan Turing wrote a paper describing a test for a “thinking” machine. He stated that if a machine could be part of a conversation through the use of a teleprinter, and it imitated a human so completely there were no noticeable differences, then the machine could be considered capable of thinking. Shortly after this, in 1952, the Hodgkin-Huxley model showed how the brain uses neurons in forming an electrical network. These events helped inspire the idea of artificial intelligence (AI), natural language processing (NLP), and the evolution of computers. Natural language processing (NLP) is an aspect of artificial intelligence that helps computers understand, interpret, and utilize human languages. NLP allows computers to communicate with people, using a human language. Natural language processing also provides computers with the ability to read text, hear speech, and interpret it. NLP draws from several disciplines, including computational linguistics and computer science, as it attempts to close the gap between human and computer communications. Generally speaking, NLP breaks down language into shorter, more basic pieces, called tokens (words, periods, etc.), and attempts to understand the relationships of the tokens. This process often uses higher-level NLP features, such as:\n• Topic Discovery and Modeling: Captures the themes and meanings of text collections, and applies advanced analytics to the text.\n• Sentiment Analysis: Identifies the general mood, or subjective opinions, stored in large amounts of text. Useful for opinion mining.\n• Text-to-Speech and Speech-to-Text Conversion: Transforms voice commands into text, and vice versa.\n• Machine Translation: Automatically translates the text or speech of one language into another. REGISTER FOR OUR DMBOK AND CDMP PREPARATION TRAINING PROGRAM\n\nNoam Chomsky published Syntactic Structures in 1957. In this book, he revolutionized linguistic concepts and concluded that for a computer to understand a language, the sentence structure would have to be changed. With this as his goal, Chomsky created a style of grammar called Phase-Structure Grammar, which methodically translated natural language sentences into a format that is usable by computers. (The overall goal was to create a computer capable of imitating the human brain, in terms of thinking and communicating – artificial intelligence.)\n\nIn 1958, the programming language LISP (Locator/Identifier Separation Protocol), a computer language still in use today, was released by John McCarthy. In 1964, ELIZA, a “typewritten” comment and response process, designed to imitate a psychiatrist using reflection techniques, was developed. (It did this by rearranging sentences and following relatively simple grammar rules, but there was no understanding on the computer’s part.) Also in 1964, the U.S. National Research Council (NRC) created the Automatic Language Processing Advisory Committee, or ALPAC, for short. This committee was tasked with evaluating the progress of natural language processing research.\n\nIn 1966, the NRC and ALPAC initiated the first AI and NLP stoppage, by halting the funding of research on natural language processing and machine translation. After 12 years of research, and $20 million, machine translations were still more expensive than manual human translations, and there were still no computers that came anywhere near being able to carry on a basic conversation. In 1966, artificial intelligence and natural language processing (NLP) research was considered a dead end by many (though not all).\n\nIt took nearly 14 years (until 1980) for natural language processes and artificial intelligence research to recover from the broken expectations created by extreme enthusiasts. In some ways, the AI stoppage had initiated a new phase of fresh ideas, with earlier concepts of machine translation being abandoned, and new ideas promoting new research, including expert systems. The mixing of linguistics and statistics, which had been popular in early NLP research, was replaced with a theme of pure statistics. The 1980s initiated a fundamental reorientation, with simple approximations replacing deep analysis, and the evaluation process becoming more rigorous.\n\nUntil the 1980s, the majority of NLP systems used complex, “handwritten” rules. But in the late 1980s, a revolution in NLP came about. This was the result of both the steady increase of computational power, and the shift to Machine Learning algorithms. While some of the early machine learning algorithms (decision trees provide a good example) produced systems similar to the old-school handwritten rules, research has increasingly focused on statistical models. These statistical models are capable of making soft, probabilistic decisions. Throughout the 1980s, IBM was responsible for the development of several successful, complicated statistical models.\n\nIn the 1990s, the popularity of statistical models for natural language processes analyses rose dramatically. The pure statistics NLP methods have become remarkably valuable in keeping pace with the tremendous flow of online text. N-Grams have become useful, recognizing and tracking clumps of linguistic data, numerically. In 1997, LSTM recurrent neural net (RNN) models were introduced, and found their niche in 2007 for voice and text processing. Currently, neural net models are considered the cutting edge of research and development in the NLP’s understanding of text and speech generation.\n\nIn 2001, Yoshio Bengio and his team proposed the first neural “language” model, using a feed-forward neural network. The feed-forward neural network describes an artificial neural network that does not use connections to form a cycle. In this type of network, the data moves only in one direction, from input nodes, through any hidden nodes, and then on to the output nodes. The feed-forward neural network has no cycles or loops, and is quite different from the recurrent neural networks.\n\nIn the year 2011, Apple’s Siri became known as one of the world’s first successful NLP/AI assistants. Siri’s automated speech recognition module translates the owner’s words into digitally interpreted concepts, and then the voice-command system matches those concepts to predefined commands, initiating specific actions. For example, if Siri asks, “Do you want to hear your balance?” it would understand a “Yes” or “No” response, and act accordingly.\n\nBy using machine learning techniques, the owner’s speaking pattern doesn’t have to match exactly with predefined expressions. The sounds just have to be reasonably close for an NLP system to translate the meaning correctly. By using a feedback loop, NLP engines can significantly improve the accuracy of their translations, and increase the system’s vocabulary. A well-trained system would understand the words, “Where can I get help with big data?” “Where can I find an expert in big data?” or “I need help with big data,” and provide the appropriate response.\n\nThe combination of a dialog manager with NLP makes it possible to develop a system capable of holding a conversation, and sounding human-like, with back-and-forth questions, prompts, and answers. Our modern AIs, however, are still not able to pass Alan Turing’s test, and currently do not sound like real human beings. (Not yet, anyway.)\n\nImage used under license from Shutterstock.com"
    },
    {
        "link": "https://deeplearning.ai/resources/natural-language-processing",
        "document": "Natural Language Processing (NLP) is one of the hottest areas of artificial intelligence (AI) thanks to applications like text generators that compose coherent essays, chatbots that fool people into thinking they’re sentient, and text-to-image programs that produce photorealistic images of anything you can describe. Recent years have brought a revolution in the ability of computers to understand human languages, programming languages, and even biological and chemical sequences, such as DNA and protein structures, that resemble language. The latest AI models are unlocking these areas to analyze the meanings of input text and generate meaningful, expressive output.\n\nNatural language processing (NLP) is the discipline of building machines that can manipulate human language — or data that resembles human language — in the way that it is written, spoken, and organized. It evolved from computational linguistics, which uses computer science to understand the principles of language, but rather than developing theoretical frameworks, NLP is an engineering discipline that seeks to build technology to accomplish useful tasks. NLP can be divided into two overlapping subfields: natural language understanding (NLU), which focuses on semantic analysis or determining the intended meaning of text, and natural language generation (NLG), which focuses on text generation by a machine. NLP is separate from — but often used in conjunction with — speech recognition, which seeks to parse spoken language into words, turning sound into text and vice versa.\n\nNLP is an integral part of everyday life and becoming more so as language technology is applied to diverse fields like retailing (for instance, in customer service chatbots) and medicine (interpreting or summarizing electronic health records). Conversational agents such as Amazon’s Alexa and Apple’s Siri utilize NLP to listen to user queries and find answers. The most sophisticated such agents — such as GPT-3, which was recently opened for commercial applications — can generate sophisticated prose on a wide variety of topics as well as power chatbots that are capable of holding coherent conversations. Google uses NLP to improve its search engine results, and social networks like Facebook use it to detect and filter hate speech.\n\nNLP is growing increasingly sophisticated, yet much work remains to be done. Current systems are prone to bias and incoherence, and occasionally behave erratically. Despite the challenges, machine learning engineers have many opportunities to apply NLP in ways that are ever more central to a functioning society.\n\nWhat is Natural Language Processing (NLP) Used For?\n\nNLP is used for a wide variety of language-related tasks, including answering questions, classifying text in a variety of ways, and conversing with users.\n\nHere are 11 tasks that can be solved by NLP:\n• Sentiment analysis is the process of classifying the emotional intent of text. Generally, the input to a sentiment classification model is a piece of text, and the output is the probability that the sentiment expressed is positive, negative, or neutral. Typically, this probability is based on either hand-generated features, word n-grams, TF-IDF features, or using deep learning models to capture sequential long- and short-term dependencies. Sentiment analysis is used to classify customer reviews on various online platforms as well as for niche applications like identifying signs of mental illness in online comments.\n• Toxicity classification is a branch of sentiment analysis where the aim is not just to classify hostile intent but also to classify particular categories such as threats, insults, obscenities, and hatred towards certain identities. The input to such a model is text, and the output is generally the probability of each class of toxicity. Toxicity classification models can be used to moderate and improve online conversations by silencing offensive comments, detecting hate speech, or scanning documents for defamation.\n• Machine translation automates translation between different languages. The input to such a model is text in a specified source language, and the output is the text in a specified target language. Google Translate is perhaps the most famous mainstream application. Such models are used to improve communication between people on social-media platforms such as Facebook or Skype. Effective approaches to machine translation can distinguish between words with similar meanings. Some systems also perform language identification; that is, classifying text as being in one language or another.\n• Named entity recognition aims to extract entities in a piece of text into predefined categories such as personal names, organizations, locations, and quantities. The input to such a model is generally text, and the output is the various named entities along with their start and end positions. Named entity recognition is useful in applications such as summarizing news articles and combating disinformation. For example, here is what a named entity recognition model could provide:\n• Spam detection is a prevalent binary classification problem in NLP, where the purpose is to classify emails as either spam or not. Spam detectors take as input an email text along with various other subtexts like title and sender’s name. They aim to output the probability that the mail is spam. Email providers like Gmail use such models to provide a better user experience by detecting unsolicited and unwanted emails and moving them to a designated spam folder.\n• Grammatical error correction models encode grammatical rules to correct the grammar within text. This is viewed mainly as a sequence-to-sequence task, where a model is trained on an ungrammatical sentence as input and a correct sentence as output. Online grammar checkers like Grammarly and word-processing systems like Microsoft Word use such systems to provide a better writing experience to their customers. Schools also use them to grade student essays.\n• Topic modeling is an unsupervised text mining task that takes a corpus of documents and discovers abstract topics within that corpus. The input to a topic model is a collection of documents, and the output is a list of topics that defines words for each topic as well as assignment proportions of each topic in a document. Latent Dirichlet Allocation (LDA), one of the most popular topic modeling techniques, tries to view a document as a collection of topics and a topic as a collection of words. Topic modeling is being used commercially to help lawyers find evidence in legal documents.\n• Text generation, more formally known as natural language generation (NLG), produces text that’s similar to human-written text. Such models can be fine-tuned to produce text in different genres and formats — including tweets, blogs, and even computer code. Text generation has been performed using Markov processes, LSTMs, BERT, GPT-2, LaMDA, and other approaches. It’s particularly useful for autocomplete and chatbots.\n• Autocomplete predicts what word comes next, and autocomplete systems of varying complexity are used in chat applications like WhatsApp. Google uses autocomplete to predict search queries. One of the most famous models for autocomplete is GPT-2, which has been used to write articles, song lyrics, and much more.\n• Chatbots automate one side of a conversation while a human conversant generally supplies the other side. They can be divided into the following two categories:\n• Database query: We have a database of questions and answers, and we would like a user to query it using natural language.\n• Conversation generation: These chatbots can simulate dialogue with a human partner. Some are capable of engaging in wide-ranging conversations. A high-profile example is Google’s LaMDA, which provided such human-like answers to questions that one of its developers was convinced that it had feelings.\n• Information retrieval finds the documents that are most relevant to a query. This is a problem every search and recommendation system faces. The goal is not to answer a particular query but to retrieve, from a collection of documents that may be numbered in the millions, a set that is most relevant to the query. Document retrieval systems mainly execute two processes: indexing and matching. In most modern systems, indexing is done by a vector space model through Two-Tower Networks, while matching is done using similarity or distance scores. Google recently integrated its search function with a multimodal information retrieval model that works with text, image, and video data.\n• Summarization is the task of shortening text to highlight the most relevant information. Researchers at Salesforce developed a summarizer that also evaluates factual consistency to ensure that its output is accurate. Summarization is divided into two method classes:\n• Extractive summarization focuses on extracting the most important sentences from a long text and combining these to form a summary. Typically, extractive summarization scores each sentence in an input text and then selects several sentences to form the summary.\n• Abstractive summarization produces a summary by paraphrasing. This is similar to writing the abstract that includes words and sentences that are not present in the original text. Abstractive summarization is usually modeled as a sequence-to-sequence task, where the input is a long-form text and the output is a summary.\n• Question answering deals with answering questions posed by humans in a natural language. One of the most notable examples of question answering was Watson, which in 2011 played the television game-show Jeopardy against human champions and won by substantial margins. Generally, question-answering tasks come in two flavors:\n• Multiple choice: The multiple-choice question problem is composed of a question and a set of possible answers. The learning task is to pick the correct answer.\n• Open domain: In open-domain question answering, the model provides answers to questions in natural language without any options provided, often by querying a large number of texts.\n\nNLP models work by finding relationships between the constituent parts of language — for example, the letters, words, and sentences found in a text dataset. NLP architectures use various methods for data preprocessing, feature extraction, and modeling. Some of these processes are:\n• Data preprocessing: Before a model processes text for a specific task, the text often needs to be preprocessed to improve model performance or to turn words and characters into a format the model can understand. Data-centric AI is a growing movement that prioritizes data preprocessing. Various techniques may be used in this data preprocessing:\n• Stemming and lemmatization: Stemming is an informal process of converting words to their base forms using heuristic rules. For example, “university,” “universities,” and “university’s” might all be mapped to the base univers. (One limitation in this approach is that “universe” may also be mapped to univers, even though universe and university don’t have a close semantic relationship.) Lemmatization is a more formal way to find roots by analyzing a word’s morphology using vocabulary from a dictionary. Stemming and lemmatization are provided by libraries like spaCy and NLTK.\n• Sentence segmentation breaks a large piece of text into linguistically meaningful sentence units. This is obvious in languages like English, where the end of a sentence is marked by a period, but it is still not trivial. A period can be used to mark an abbreviation as well as to terminate a sentence, and in this case, the period should be part of the abbreviation token itself. The process becomes even more complex in languages, such as ancient Chinese, that don’t have a delimiter that marks the end of a sentence.\n• Stop word removal aims to remove the most commonly occurring words that don’t add much information to the text. For example, “the,” “a,” “an,” and so on.\n• Tokenization splits text into individual words and word fragments. The result generally consists of a word index and tokenized text in which words may be represented as numerical tokens for use in various deep learning methods. A method that instructs language models to ignore unimportant tokens can improve efficiency.\n• Feature extraction: Most conventional machine-learning techniques work on the features – generally numbers that describe a document in relation to the corpus that contains it – created by either Bag-of-Words, TF-IDF, or generic feature engineering such as document length, word polarity, and metadata (for instance, if the text has associated tags or scores). More recent techniques include Word2Vec, GLoVE, and learning the features during the training process of a neural network.\n• Bag-of-Words: Bag-of-Words counts the number of times each word or n-gram (combination of n words) appears in a document. For example, below, the Bag-of-Words model creates a numerical representation of the dataset based on how many of each word in the word_index occur in the document.\n• TF-IDF: In Bag-of-Words, we count the occurrence of each word or n-gram in a document. In contrast, with TF-IDF, we weight each word by its importance. To evaluate a word’s significance, we consider two things:\n• Term Frequency: How important is the word in the document?\n\nTF(word in a document)= Number of occurrences of that word in document / Number of words in document\n• Inverse Document Frequency: How important is the term in the whole corpus?\n\nIDF(word in a corpus)=log(number of documents in the corpus / number of documents that include the word)\n\nA word is important if it occurs many times in a document. But that creates a problem. Words like “a” and “the” appear often. And as such, their TF score will always be high. We resolve this issue by using Inverse Document Frequency, which is high if the word is rare and low if the word is common across the corpus. The TF-IDF score of a term is the product of TF and IDF.\n• Word2Vec, introduced in 2013, uses a vanilla neural network to learn high-dimensional word embeddings from raw text. It comes in two variations: Skip-Gram, in which we try to predict surrounding words given a target word, and Continuous Bag-of-Words (CBOW), which tries to predict the target word from surrounding words. After discarding the final layer after training, these models take a word as input and output a word embedding that can be used as an input to many NLP tasks. Embeddings from Word2Vec capture context. If particular words appear in similar contexts, their embeddings will be similar.\n• GLoVE is similar to Word2Vec as it also learns word embeddings, but it does so by using matrix factorization techniques rather than neural learning. The GLoVE model builds a matrix based on the global word-to-word co-occurrence counts.\n• Modeling: After data is preprocessed, it is fed into an NLP architecture that models the data to accomplish a variety of tasks.\n• Numerical features extracted by the techniques described above can be fed into various models depending on the task at hand. For example, for classification, the output from the TF-IDF vectorizer could be provided to logistic regression, naive Bayes, decision trees, or gradient boosted trees. Or, for named entity recognition, we can use hidden Markov models along with n-grams.\n• Deep neural networks typically work without using extracted features, although we can still use TF-IDF or Bag-of-Words features as an input.\n• Language Models: In very basic terms, the objective of a language model is to predict the next word when given a stream of input words. Probabilistic models that use Markov assumption are one example:\n\nDeep learning is also used to create such language models. Deep-learning models take as input a word embedding and, at each time state, return the probability distribution of the next word as the probability for every word in the dictionary. Pre-trained language models learn the structure of a particular language by processing a large corpus, such as Wikipedia. They can then be fine-tuned for a particular task. For instance, BERT has been fine-tuned for tasks ranging from fact-checking to writing headlines.\n\nMost of the NLP tasks discussed above can be modeled by a dozen or so general techniques. It’s helpful to think of these techniques in two categories: Traditional machine learning methods and deep learning methods.\n• Logistic regression is a supervised classification algorithm that aims to predict the probability that an event will occur based on some input. In NLP, logistic regression models can be applied to solve problems such as sentiment analysis, spam detection, and toxicity classification.\n• Naive Bayes is a supervised classification algorithm that finds the conditional probability distribution P(label | text) using the following Bayes formula:\n\nand predicts based on which joint distribution has the highest probability. The naive assumption in the Naive Bayes model is that the individual words are independent. Thus:\n\nIn NLP, such statistical methods can be applied to solve problems such as spam detection or finding bugs in software code.\n• Decision trees are a class of supervised classification models that split the dataset based on different features to maximize information gain in those splits.\n• Latent Dirichlet Allocation (LDA) is used for topic modeling. LDA tries to view a document as a collection of topics and a topic as a collection of words. LDA is a statistical approach. The intuition behind it is that we can describe any topic using only a small set of words from the corpus.\n• Hidden Markov models: Markov models are probabilistic models that decide the next state of a system based on the current state. For example, in NLP, we might suggest the next word based on the previous word. We can model this as a Markov model where we might find the transition probabilities of going from word1 to word2, that is, P(word1|word2). Then we can use a product of these transition probabilities to find the probability of a sentence. The hidden Markov model (HMM) is a probabilistic modeling technique that introduces a hidden state to the Markov model. A hidden state is a property of the data that isn’t directly observed. HMMs are used for part-of-speech (POS) tagging where the words of a sentence are the observed states and the POS tags are the hidden states. The HMM adds a concept called emission probability; the probability of an observation given a hidden state. In the prior example, this is the probability of a word, given its POS tag. HMMs assume that this probability can be reversed: Given a sentence, we can calculate the part-of-speech tag from each word based on both how likely a word was to have a certain part-of-speech tag and the probability that a particular part-of-speech tag follows the part-of-speech tag assigned to the previous word. In practice, this is solved using the Viterbi algorithm.\n• Convolutional Neural Network (CNN): The idea of using a CNN to classify text was first presented in the paper “Convolutional Neural Networks for Sentence Classification” by Yoon Kim. The central intuition is to see a document as an image. However, instead of pixels, the input is sentences or documents represented as a matrix of words.\n• Recurrent Neural Network (RNN): Many techniques for text classification that use deep learning process words in close proximity using n-grams or a window (CNNs). They can see “New York” as a single instance. However, they can’t capture the context provided by a particular text sequence. They don’t learn the sequential structure of the data, where every word is dependent on the previous word or a word in the previous sentence. RNNs remember previous information using hidden states and connect it to the current task. The architectures known as Gated Recurrent Unit (GRU) and long short-term memory (LSTM) are types of RNNs designed to remember information for an extended period. Moreover, the bidirectional LSTM/GRU keeps contextual information in both directions, which is helpful in text classification. RNNs have also been used to generate mathematical proofs and translate human thoughts into words.\n• Autoencoders are deep learning encoder-decoders that approximate a mapping from X to X, i.e., input=output. They first compress the input features into a lower-dimensional representation (sometimes called a latent code, latent vector, or latent representation) and learn to reconstruct the input. The representation vector can be used as input to a separate model, so this technique can be used for dimensionality reduction. Among specialists in many other fields, geneticists have applied autoencoders to spot mutations associated with diseases in amino acid sequences.\n• Encoder-decoder sequence-to-sequence: The encoder-decoder seq2seq architecture is an adaptation to autoencoders specialized for translation, summarization, and similar tasks. The encoder encapsulates the information in a text into an encoded vector. Unlike an autoencoder, instead of reconstructing the input from the encoded vector, the decoder’s task is to generate a different desired output, like a translation or summary.\n• Transformers: The transformer, a model architecture first described in the 2017 paper “Attention Is All You Need” (Vaswani, Shazeer, Parmar, et al.), forgoes recurrence and instead relies entirely on a self-attention mechanism to draw global dependencies between input and output. Since this mechanism processes all words at once (instead of one at a time) that decreases training speed and inference cost compared to RNNs, especially since it is parallelizable. The transformer architecture has revolutionized NLP in recent years, leading to models including BLOOM, Jurassic-X, and Turing-NLG. It has also been successfully applied to a variety of different vision tasks, including making 3D images.\n\nOver the years, many NLP models have made waves within the AI community, and some have even made headlines in the mainstream news. The most famous of these have been chatbots and language models. Here are some of them:\n• Eliza was developed in the mid-1960s to try to solve the Turing Test; that is, to fool people into thinking they’re conversing with another human being rather than a machine. Eliza used pattern matching and a series of rules without encoding the context of the language.\n• Tay was a chatbot that Microsoft launched in 2016. It was supposed to tweet like a teen and learn from conversations with real users on Twitter. The bot adopted phrases from users who tweeted sexist and racist comments, and Microsoft deactivated it not long afterward. Tay illustrates some points made by the “Stochastic Parrots” paper, particularly the danger of not debiasing data.\n• BERT and his Muppet friends: Many deep learning models for NLP are named after Muppet characters, including ELMo, BERT, Big BIRD, ERNIE, Kermit, Grover, RoBERTa, and Rosita. Most of these models are good at providing contextual embeddings and enhanced knowledge representation.\n• Generative Pre-Trained Transformer 3 (GPT-3) is a 175 billion parameter model that can write original prose with human-equivalent fluency in response to an input prompt. The model is based on the transformer architecture. The previous version, GPT-2, is open source. Microsoft acquired an exclusive license to access GPT-3’s underlying model from its developer OpenAI, but other users can interact with it via an application programming interface (API). Several groups including EleutherAI and Meta have released open source interpretations of GPT-3.\n• Language Model for Dialogue Applications (LaMDA) is a conversational chatbot developed by Google. LaMDA is a transformer-based model trained on dialogue rather than the usual web text. The system aims to provide sensible and specific responses to conversations. Google developer Blake Lemoine came to believe that LaMDA is sentient. Lemoine had detailed conversations with AI about his rights and personhood. During one of these conversations, the AI changed Lemoine’s mind about Isaac Asimov’s third law of robotics. Lemoine claimed that LaMDA was sentient, but the idea was disputed by many observers and commentators. Subsequently, Google placed Lemoine on administrative leave for distributing proprietary information and ultimately fired him.\n• Mixture of Experts (MoE): While most deep learning models use the same set of parameters to process every input, MoE models aim to provide different parameters for different inputs based on efficient routing algorithms to achieve higher performance. Switch Transformer is an example of the MoE approach that aims to reduce communication and computational costs.\n\nMany languages and libraries support NLP. Here are a few of the most useful.\n• Python is the most-used programming language to tackle NLP tasks. Most libraries and frameworks for deep learning are written for Python. Here are a few that practitioners may find helpful:\n• Natural Language Toolkit (NLTK) is one of the first NLP libraries written in Python. It provides easy-to-use interfaces to corpora and lexical resources such as WordNet. It also provides a suite of text-processing libraries for classification, tagging, stemming, parsing, and semantic reasoning.\n• spaCy is one of the most versatile open source NLP libraries. It supports more than 66 languages. spaCy also provides pre-trained word vectors and implements many popular models like BERT. spaCy can be used for building production-ready systems for named entity recognition, part-of-speech tagging, dependency parsing, sentence segmentation, text classification, lemmatization, morphological analysis, entity linking, and so on.\n• Deep Learning libraries: Popular deep learning libraries include TensorFlow and PyTorch, which make it easier to create models with features like automatic differentiation. These libraries are the most common tools for developing NLP models.\n• Hugging Face offers open-source implementations and weights of over 135 state-of-the-art models. The repository enables easy customization and training of the models.\n• R: Many early NLP models were written in R, and R is still widely used by data scientists and statisticians. Libraries in R for NLP include TidyText, Weka, Word2Vec, SpaCyR, TensorFlow, and PyTorch.\n• Many other languages including JavaScript, Java, and Julia have libraries that implement NLP methods.\n\n\n\nNLP has been at the center of a number of controversies. Some are centered directly on the models and their outputs, others on second-order concerns, such as who has access to these systems, and how training them impacts the natural world.\n• Stochastic parrots: A 2021 paper titled “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” by Emily Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell examines how language models may repeat and amplify biases found in their training data. The authors point out that huge, uncurated datasets scraped from the web are bound to include social biases and other undesirable information, and models that are trained on them will absorb these flaws. They advocate greater care in curating and documenting datasets, evaluating a model’s potential impact prior to development, and encouraging research in directions other than designing ever-larger architectures to ingest ever-larger datasets.\n• Coherence versus sentience: Recently, a Google engineer tasked with evaluating the LaMDA language model was so impressed by the quality of its chat output that he believed it to be sentient. The fallacy of attributing human-like intelligence to AI dates back to some of the earliest NLP experiments.\n• Environmental impact: Large language models require a lot of energy during both training and inference. One study estimated that training a single large language model can emit five times as much carbon dioxide as a single automobile over its operational lifespan. Another study found that models consume even more energy during inference than training. As for solutions, researchers have proposed using cloud servers located in countries with lots of renewable energy as one way to offset this impact.\n• High cost leaves out non-corporate researchers: The computational requirements needed to train or deploy large language models are too expensive for many small companies. Some experts worry that this could block many capable engineers from contributing to innovation in AI.\n• Black box: When a deep learning model renders an output, it’s difficult or impossible to know why it generated that particular result. While traditional models like logistic regression enable engineers to examine the impact on the output of individual features, neural network methods in natural language processing are essentially black boxes. Such systems are said to be “not explainable,” since we can’t explain how they arrived at their output. An effective approach to achieve explainability is especially important in areas like banking, where regulators want to confirm that a natural language processing system doesn’t discriminate against some groups of people, and law enforcement, where models trained on historical data may perpetuate historical biases against certain groups.\n\n“Nonsense on stilts”: Writer Gary Marcus has criticized deep learning-based NLP for generating sophisticated language that misleads users to believe that natural language algorithms understand what they are saying and mistakenly assume they are capable of more sophisticated reasoning than is currently possible.\n\nHow To Get Started In Natural Language Processing (NLP)\n\nIf you are just starting out, many excellent courses can help.\n\nIf you want to learn more about NLP, try reading research papers. Work through the papers that introduced the models and techniques described in this article. Most are easy to find on arxiv.org. You might also take a look at these resources:\n• The Batch: A weekly newsletter that tells you what matters in AI. It’s the best way to keep up with developments in deep learning.\n• NLP News: A newsletter from Sebastian Ruder, a research scientist at Google, focused on what’s new in NLP.\n• Papers with Code: A web repository of machine learning research, tasks, benchmarks, and datasets.\n\nWe highly recommend learning to implement basic algorithms (linear and logistic regression, Naive Bayes, decision trees, and vanilla neural networks) in Python. The next step is to take an open-source implementation and adapt it to a new dataset or task.\n\nNLP is one of the fast-growing research domains in AI, with applications that involve tasks including translation, summarization, text generation, and sentiment analysis. Businesses use NLP to power a growing number of applications, both internal — like detecting insurance fraud, determining customer sentiment, and optimizing aircraft maintenance — and customer-facing, like Google Translate.\n\nAspiring NLP practitioners can begin by familiarizing themselves with foundational AI skills: performing basic mathematics, coding in Python, and using algorithms like decision trees, Naive Bayes, and logistic regression. Online courses can help you build your foundation. They can also help as you proceed into specialized topics. Specializing in NLP requires a working knowledge of things like neural networks, frameworks like PyTorch and TensorFlow, and various data preprocessing techniques. The transformer architecture, which has revolutionized the field since it was introduced in 2017, is an especially important architecture.\n\nNLP is an exciting and rewarding discipline, and has potential to profoundly impact the world in many positive ways. Unfortunately, NLP is also the focus of several controversies, and understanding them is also part of being a responsible practitioner. For instance, researchers have found that models will parrot biased language found in their training data, whether they’re counterfactual, racist, or hateful. Moreover, sophisticated language models can be used to generate disinformation. A broader concern is that training large models produces substantial greenhouse gas emissions.\n\nThis page is only a brief overview of what NLP is all about. If you have an appetite for more, DeepLearning.AI offers courses for everyone in their NLP journey, from AI beginners and those who are ready to specialize. No matter your current level of expertise or aspirations, remember to keep learning!"
    },
    {
        "link": "https://ibm.com/think/topics/natural-language-processing",
        "document": "NLP enables computers and digital devices to recognize, understand and generate text and speech by combining computational linguistics—the rule-based modeling of human language—together with statistical modeling, machine learning and deep learning. NLP research has helped enable the era of generative AI, from the communication skills of large language models (LLMs) to the ability of image generation models to understand requests. NLP is already part of everyday life for many, powering search engines, prompting chatbots for customer service with spoken commands, voice-operated GPS systems and question-answering digital assistants on smartphones such as Amazon’s Alexa, Apple’s Siri and Microsoft’s Cortana. NLP also plays a growing role in enterprise solutions that help streamline and automate business operations, increase employee productivity and simplify business processes.\n\nNLP enhances data analysis by enabling the extraction of insights from unstructured text data, such as customer reviews, social media posts and news articles. By using text mining techniques, NLP can identify patterns, trends and sentiments that are not immediately obvious in large datasets. Sentiment analysis enables the extraction of subjective qualities—attitudes, emotions, sarcasm, confusion or suspicion—from text. This is often used for routing communications to the system or the person most likely to make the next response. This allows businesses to better understand customer preferences, market conditions and public opinion. NLP tools can also perform categorization and summarization of vast amounts of text, making it easier for analysts to identify key information and make data-driven decisions more efficiently.\n\nNLP combines the power of computational linguistics together with machine learning algorithms and deep learning. Computational linguistics uses data science to analyze language and speech. It includes two main types of analysis: syntactical analysis and semantical analysis. Syntactical analysis determines the meaning of a word, phrase or sentence by parsing the syntax of the words and applying preprogrammed rules of grammar. Semantical analysis uses the syntactic output to draw meaning from the words and interpret their meaning within the sentence structure. The parsing of words can take one of two forms. Dependency parsing looks at the relationships between words, such as identifying nouns and verbs, while constituency parsing then builds a parse tree (or syntax tree): a rooted and ordered representation of the syntactic structure of the sentence or string of words. The resulting parse trees underly the functions of language translators and speech recognition. Ideally, this analysis makes the output—either text or speech—understandable to both NLP models and people. Self-supervised learning (SSL) in particular is useful for supporting NLP because NLP requires large amounts of labeled data to train AI models. Because these labeled datasets require time-consuming annotation—a process involving manual labeling by humans—gathering sufficient data can be prohibitively difficult. Self-supervised approaches can be more time-effective and cost-effective, as they replace some or all manually labeled training data.\n\n \n\n Three different approaches to NLP include:\n\nRecently, deep learning models have become the dominant mode of NLP, by using huge volumes of raw, unstructured data—both text and voice—to become ever more accurate. Deep learning can be viewed as a further evolution of statistical NLP, with the difference that it uses neural network models. There are several subcategories of models:\n• None Sequence-to-Sequence (seq2seq) models: Based on recurrent neural networks (RNN), they have mostly been used for machine translation by converting a phrase from one domain (such as the German language) into the phrase of another domain (such as English).\n• None Transformer models: They use tokenization of language (the position of each token—words or subwords) and self-attention (capturing dependencies and relationships) to calculate the relation of different language parts to one another. Transformer models can be efficiently trained by using self-supervised learning on massive text databases. A landmark in transformer models was Google’s bidirectional encoder representations from transformers (BERT), which became and remains the basis of how Google’s search engine works.\n• None Autoregressive models: This type of transformer model is trained specifically to predict the next word in a sequence, which represents a huge leap forward in the ability to generate text. Examples of autoregressive LLMs include GPT, Llama, Claude and the open-source Mistral.\n• None Foundation models: Prebuilt and curated foundation models can speed the launching of an NLP effort and boost trust in its operation. For example, the IBM® Granite™ foundation models are widely applicable across industries. They support NLP tasks including content generation and insight extraction. Additionally, they facilitate retrieval-augmented generation, a framework for improving the quality of response by linking the model to external sources of knowledge. The models also perform named entity recognition which involves identifying and extracting key information in a text.\n\nNLP text preprocessing prepares raw text for analysis by transforming it into a format that machines can more easily understand. It begins with tokenization, which involves splitting the text into smaller units like words, sentences or phrases. This helps break down complex text into manageable parts. Next, lowercasing is applied to standardize the text by converting all characters to lowercase, ensuring that words like \"Apple\" and \"apple\" are treated the same. Stop word removal is another common step, where frequently used words like \"is\" or \"the\" are filtered out because they don't add significant meaning to the text. Stemming or lemmatization reduces words to their root form (e.g., \"running\" becomes \"run\"), making it easier to analyze language by grouping different forms of the same word. Additionally, text cleaning removes unwanted elements such as punctuation, special characters and numbers that may clutter the analysis. After preprocessing, the text is clean, standardized and ready for machine learning models to interpret effectively.\n\nProcessed data is then used to train machine learning models, which learn patterns and relationships within the data. During training, the model adjusts its parameters to minimize errors and improve its performance. Once trained, the model can be used to make predictions or generate outputs on new, unseen data. The effectiveness of NLP modeling is continually refined through evaluation, validation and fine-tuning to enhance accuracy and relevance in real-world applications. Different software environments are useful throughout the said processes. For example, the Natural Language Toolkit (NLTK) is a suite of libraries and programs for English that is written in the Python programming language. It supports text classification, tokenization, stemming, tagging, parsing and semantic reasoning functionalities. TensorFlow is a free and open-source software library for machine learning and AI that can be used to train models for NLP applications. Tutorials and certifications abound for those interested in familiarizing themselves with such tools."
    },
    {
        "link": "https://geeksforgeeks.org/natural-language-processing-nlp-tutorial",
        "document": "Natural Language Processing (NLP) is the branch of Artificial Intelligence (AI) that gives the ability to machine understand and process human languages. Human languages can be in the form of text or audio format.\n\nThe applications of Natural Language Processing are as follows:\n• None Voice Assistants like Alexa, Siri, and Google Assistant use NLP for voice recognition and interaction.\n• None Tools like Grammarly, Microsoft Word, and Google Docs apply NLP for grammar checking and text analysis.\n• None Information extraction through Search engines such as Google and DuckDuckGo.\n• None Website bots and customer support chatbots leverage NLP for automated conversations and query handling.\n• None Google Translate and similar services use NLP for real-time translation between languages.\n\nThis NLP tutorial is designed for both beginners and professionals. Whether you are a beginner or a data scientist, this guide will provide you with the knowledge and skills you need to take your understanding of NLP to the next level.\n\nThere are two components of Natural Language Processing:\n\nText Normalization transforms text into a consistent format improves the quality and makes it easier to process in NLP tasks.\n\n1. Regular Expressions (RE) are sequences of characters that define search patterns.\n\n2. Tokenization is a process of splitting text into smaller units called tokens.\n\n3. Lemmatization reduces words to their base or root form.\n\n4. Stemming reduces works to their root by removing suffixes. Types of stemmers include:\n\n5. Stopword removal is a process to remove common words from the document.\n\n6. Parts of Speech (POS) Tagging assigns a part of speech to each word in sentence based on definition and context.\n\nText representation converts textual data into numerical vectors that are processed by the following methods:\n\nText Embedding Techniques refer to the methods and models used to create these vector representations, including traditional methods (like TFIDF and BOW) and more advanced approaches:\n\nDeep learning has revolutionized Natural Language Processing (NLP) by enabling models to automatically learn complex patterns and representations from raw text. Below are some of the key deep learning techniques used in NLP:\n\nPre-trained models understand language patterns, context and semantics. The provided models are trained on massive corpora and can be fine tuned for specific tasks.\n\nNatural Language Processing (NLP) emerged in 1950 when Alan Turing published his groundbreaking paper titled Computing Machinery and Intelligence. Turing’s work laid the foundation for NLP, which is a subset of Artificial Intelligence (AI) focused on enabling machines to automatically interpret and generate human language. Over time, NLP technology has evolved, giving rise to different approaches for solving complex language-related tasks.\n\nThe Heuristic-based approach to NLP was one of the earliest methods used in natural language processing. It relies on predefined rules and domain-specific knowledge. These rules are typically derived from expert insights. A classic example of this approach is Regular Expressions (Regex), which are used for pattern matching and text manipulation tasks.\n\nAs NLP advanced, Statistical NLP emerged, incorporating machine learning algorithms to model language patterns. This approach applies statistical rules and learns from data to tackle various language processing tasks. Popular machine learning algorithms in this category include:\n\nThe most recent advancement in NLP is the adoption of Deep Learning techniques. Neural networks, particularly Recurrent Neural Networks (RNNs), Long Short-Term Memory Networks (LSTMs), and Transformers, have revolutionized NLP tasks by providing superior accuracy. These models require large amounts of data and considerable computational power for training\n\nWhat is the most difficult part of natural language processing?\n\nWhat are the 4 pillars of NLP?\n\nWhat language is best for natural language processing?\n\nWhat is the life cycle of NLP?"
    },
    {
        "link": "https://epi.washington.edu/news/large-language-models-outshine-traditional-natural-language-processing-methods-for-identifying-rare-circumstances",
        "document": "Researchers have recently begun using Natural Language Processing (NLP) to analyze case files and other large batches of information more efficiently. However, traditional NLP requires a human to review case files and train the program to recognize nuanced or ambiguous language. For example, when a report says, “The patient reported that their head hurt,” the researcher wants NLP to recognize this as a headache, even though the report doesn’t use the word “headache.” Training the NLP to recognize such nuance requires manually reviewing enough case files with nuanced language to allow the NLP to learn the language patterns. This review is labor intensive and may not identify enough cases when circumstances are rare. Researchers wanted to know: Could a large language model—the artificial intelligence (AI) technology also used by ChatGPT—be trained to identify rare circumstances in large amounts of unstructured data?\n\nThe National Violent Death Reporting System (NVDRS) provides a wealth of information on violent deaths, offering unstructured incident narrative reports from coroners, medical examiners, and law enforcement. In a recent study, researchers from the University of Washington Department of Epidemiology used this database to test large language models by utilizing reports on female firearm suicides and the nuanced circumstances preceding them.\n\nUsing 1,462 reports from the NVDRS, researchers leveraged a large language model to analyze the narratives from each report. Differing from the traditional NLP approaches, the large language model does not require any annotated reports for training. The researchers focused on circumstances preceding female firearm suicides that did not occur often in NVDRS reports (e.g., sexual violence was noted as a precipitating factor in 38 of the 1462 reports) and asked the language models yes or no questions to test whether the model identified these circumstances. The large language models performed surprisingly well. One model called FLAN-UL2, originally developed by Google, can follow complex instructions as well as perform competitively in comprehension and arithmetic and causal reasoning.\n\n“With the traditional NLP approach, researchers need to manually annotate a subset of reports. Only then can they train the machine learning model to do the automatic annotations,” says UW Epidemiology PhD student Weipeng Zhou, who was the lead researcher on the study. “But large language models are gradually relaxing this constraint.” The results of this study show promise in avoiding the intensive human labor to text mine for the language that NLP can’t catch. AI language models like FLAN-UL2 can not only be trained, but can outperform NLP by a wide margin, in some scenarios where the traditional NLP struggles.\n\nWhile male firearm suicide rates have historically been higher, female firearm suicide rates saw a startling increase of 20 percent between 2010-2020, surpassing the rate increase among males. The study focused on “infrequent circumstances” when testing AI language models. Infrequent circumstances are various issues that an individual may have been dealing with prior to their death, such as sleep problems, loneliness, custody issues, or bullying. In theory, tracking these issues could give researchers and healthcare professionals the key to understand the statistical spike in female firearm suicides. Dr. Stephen Mooney, Department of Epidemiology Assistant Professor, says that it is use of the tool for future public health implications that makes this study particularly exciting. “The challenge of doing a lot of work using plain text records of individual stories or clinical information is that it’s really hard to identify things that are very important but happen rarely. What we tested is just one scenario where there are rare antecedent events that you can mine from text, but there are lots of scenarios where there may be important factors discussed in a clinical narrative where we would have a hard time finding with conventional NLP to date,” Mooney describes. “The large language model already has context for what certain words mean and we can much more efficiently identify those rarer scenarios.” By using a chatbot and yes or no questions, researchers can better understand the data in thousands of reports, making the process altogether faster as well as more intuitive.\n\n“People think of AI chatbots as something that can create language for humans, like writing an essay,” Mooney says. “I want people to be excited about their potential for use in deductive circumstances, too. It’s not just that these models can create new language, but also that they can classify information, or unlock data that is otherwise locked up.”\n\nThe study highlights the incredible potential of large language models in bridging the gap in gathering and analyzing unstructured information from many of these reports, not only in cases of female firearm suicides, but also unlocking critical insights for public health research. There are other ways large language models can be applied, such as a follow-up project being explored by Dr. Mooney and colleagues that tracks helmet use in bike and scooter collisions using reports from the emergency department. Language models can begin to help researchers analyze questions about helmet use or environmental factors that influence rider collisions. This approach offers an improvement over traditional methods, providing a valuable tool for researchers who, up until now, could only use NLP. While further exploration into the applications of AI language models is needed, their use could provide opportunities for future research or patient care."
    },
    {
        "link": "https://aisera.com/blog/natural-language-processing",
        "document": "Research on NLP started after 1950, however many linguistic scientists had worked on fundamentals in the early 1900s. According to Stanford University documents, after World War II, NLP researchers initially aimed at automating language translation. Notable figures like Noam Chomsky critiqued early models for their inability to differentiate between grammatically correct and incorrect nonsense. By the late 1950s, the field had split into symbolic and stochastic approaches, focusing on rule-based systems and statistical methods, respectively. After 1970, the landscape broadened to include logic-based paradigms and natural language understanding, exemplified by projects like SHRDLU. In this program, a computer manipulated blocks while answering questions in natural language, demonstrating remarkable accuracy in a limited domain. The conversation below was produced as a part of a demonstration for SHRDLU: Person: Put the littlest pyramid on top of it. Person: Does the shortest thing the tallest pyramid’s support supports support anything green? Person: What color is it? Computer: By “it,” I assume you mean the shortest thing the tallest pyramid’s support supports. This capability to resolve object relationships showed the potential for advanced NLP applications. From the 1980s onwards, empirical and probabilistic models gained traction. In recent decades, the internet’s growth and widespread computing have shifted NLP’s focus toward information extraction and consumer-level applications.\n\nAccording to the glossary of AI terms , Natural language understanding (NLU) is a subfield of NLP that aims to enable computers to understand human language in a way that is similar to how humans understand it. It involves the analysis of language models and various linguistic phenomena, such as syntax, semantics, and pragmatics, in order to capture the meaning and intent of natural language text. Analyzing text, also known as text mining, is discovering valuable insights from unstructured text data. It involves the application of various NLP techniques and methods to extract information, identify patterns, and reveal relationships within textual data. Both NLU and text analysis are crucial components of natural language processing systems and are used in a wide range of applications. For example, in sentiment analysis, NLU techniques are used to determine the sentiment of a piece of both text and speech processing in most speech recognition software. In contrast, analyzing text is used to identify the topics that are being discussed. Example application: Chatbots that can understand and respond to natural language queries from users. Example application: Identifying patterns and trends in customer feedback to improve products and services.\n\nUndoubtedly, Natural language processing (NLP) has revolutionized the way humans interact with computers and its behind the scene of conversational AI chatbots. NLP has become an indispensable tool for many industries, from healthcare to customer service, social media analysis to finance, NLP is utilized to solve complex problems and extract valuable insights from vast amounts of textual data. In this article, we explored the evolution of NLP systems, its techniques, tools, and approaches, and its practical applications. We discussed the benefits of implementing NLP, including enhancing productivity, enabling automation, and improving decision-making. However, we also highlighted the challenges associated with NLP, such as ambiguity, context understanding, and ethical considerations, emphasizing the ongoing research and efforts to address these issues. Request a free conversational AI demo today!"
    }
]