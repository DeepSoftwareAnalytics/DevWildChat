[
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/security/authentication-access/ownership-and-user-schema-separation?view=sql-server-ver16",
        "document": "A core concept of SQL Server security is that owners of objects have irrevocable permissions to administer them. You can't remove privileges from an object owner, and you can't drop users from a database if they own objects in it.\n\nUser-schema separation allows for more flexibility in managing database object permissions. A schema is a named container for database objects, which allows you to group objects into separate namespaces. For example, the AdventureWorks sample database contains schemas for Production, Sales, and HumanResources.\n\nThe four-part naming syntax for referring to objects specifies the schema name.\n\nSchemas can be owned by any database principal, and a single principal can own multiple schemas. You can apply security rules to a schema, which are inherited by all objects in the schema. Once you set up access permissions for a schema, those permissions are automatically applied as new objects are added to the schema. Users can be assigned a default schema, and multiple database users can share the same schema.\n\nBy default, when developers create objects in a schema, the objects are owned by the security principal that owns the schema, not the developer. Object ownership can be transferred with ALTER AUTHORIZATION Transact-SQL statement. A schema can also contain objects that are owned by different users and have more granular permissions than those assigned to the schema, although this isn't recommended because it adds complexity to managing permissions. Objects can be moved between schemas, and schema ownership can be transferred between principals. Database users can be dropped without affecting schemas.\n\nSQL Server ships with nine predefined schemas that have the same names as the built-in database users and roles: db_accessadmin, db_backupoperator, db_datareader, db_datawriter, db_ddladmin, db_denydatareader, db_denydatawriter, db_owner, db_securityadmin. These exist for backward compatibility. The recommendation is to not use them for user objects. You can drop the schemas that have the same names as the fixed database roles - unless they're already in use, in which case the drop-command returns an error and block the drop of the used schema.\n\nIf you drop these schemas from the database, they won't appear in new databases. Schemas that contain objects can't be dropped.\n\nThe following schemas can't be dropped:\n\nThe schema is the default schema of every database. By default, users created with the CREATE USER Transact-SQL command have as their default schema. The schema is owned by the user account.\n\nUsers who are assigned the as default schema don't inherit the permissions of the user account. No permissions are inherited from a schema by users; schema permissions are inherited by the database objects contained in the schema. The default schema for a user is solely used for object-reference in case the user omits the schema when querying objects."
    },
    {
        "link": "https://stackoverflow.com/questions/1062075/why-do-table-names-in-sql-server-start-with-dbo",
        "document": "Microsoft introduced schema in version 2005. For those who didn’t know about schema, and those who didn’t care, objects were put into a default schema .\n\nstands for DataBase Owner, but that’s not really important.\n\nThink of a schema as you would a folder for files:\n• You don’t need to refer to the schema if the object is in the same or default schema\n• You can reference an object in a different schema by using the schema as a prefix, the way you can reference a file in a different folder.\n• You can’t have two objects with the same name in a single schema, but you can in different schema\n• Using schema can help you to organise a larger number of objects\n• Schema can also be assigned to particular users and roles, so you can control access to who can do what.\n\nYou can generally access any object from any schema. However, it is possible to control which users have which access to particular schema, so you can use schema in your security model.\n\nBecause is the default, you normally don’t need to specify it within a single database:\n\nmean the same thing.\n\nI am inclined to disagree with the notion of always using the prefix, since the more you clutter your code with unnecessary detail, the harder it is to read and manage.\n\nFor the most part, you can ignore the schema. However, the schema will make itself apparent in the following situations:\n• None If you view the tables in either the object navigator or in an external application, such as Microsoft Excel or Access, you will see the prefix. You can still ignore it.\n• None If you reference a table in another database, you will need its full name in the form :\n• None For historical reasons, if you write a user defined scalar function, you will need to call it with the schema prefix: CREATE FUNCTION tax(@amount DECIMAL(6,2) RETURNS DECIMAL(6,2) AS BEGIN RETURN @amount * 0.1; END; GO SELECT total, dbo.tax(total) FROM pricelist; This does not apply to other objects, such as table functions, procedures and views.\n\nYou can use schema to overcome naming conflicts. For example, if every user has a personal schema, they can create additional objects without having to fight with other users over the name."
    },
    {
        "link": "https://reddit.com/r/SQL/comments/9msoos/significance_of_dbo",
        "document": "Hello all, newbie here.\n\nI've built myself a small database of a handful of tables on SQL Server (I'm the only user for now). None of the tables I use or the queries I run require any \"dbo.\" before the table names. I see that in examples online all the time, what does a database object do? I believe it means it's part of a schema, but can there be more than one schema for a DB? Why is it not necessary for me and it is in other examples? Should I be adding that to queries?"
    },
    {
        "link": "https://sqlshack.com/introducing-schema-documentation-in-sql-server",
        "document": "We often have a need to view object definitions in SQL Server, whether they be tables, triggers, or foreign keys. The built in tools are great for an object here and there, but are very cumbersome if you’re looking to generate create statements for a large number of objects.\n\nWe will be introducing (and reintroducing) many different system views that provide valuable information about objects within SQL Server. This will allow us to understand how to locate and use information about our data and then be able to perform extremely useful tasks, such as creating copies of our schema, validating correctness, or generating schema for testing purposes.\n\nBeing able to quickly display the CREATE statement for an object can be extremely useful. Not only does this allow us to review our database schema, but it allows us to use that information to build out copies of some or all of those structures. Why would we ever want to do this? There are many good reasons, some of which I’ll list here:\n• Generate a creation script, to be used to build those objects elsewhere.\n• Use the creation scripts from multiple databases in order to compare/contrast objects.\n• View all objects within a table in a single script.\n• View all or some objects in a database based on customized input.\n• Generate creation scripts for use in source control.\n\nSQL Server Management Studio allows you to right-click on any object that is viewable from the database tree and choose to generate a create statement from it, like this:\n\nThe resulting TSQL is as follows:\n\nWow…that is quite a bit of output for a single table. If all we needed was some information about this table, and we didn’t mind the extra output, then this would generally be adequate. If we were looking for schema creation scripts for an entire schema, database, or some other large segment of objects, then this approach would become cumbersome. Right-clicking a hundred times is not my idea of fun, nor is it something that can be easily automated.\n\nSome of the output can be customized. For example, if I wanted to turn off the scripting of extended properties, I could do so via the SSMS options as follows:\n\nWhile this menu allows for quite a bit of customization of scripting output, the idea of having to return to this menu whenever I would like to change what I am outputting does seem a bit slow. While clicking through menus is easy, it’s slow and manual, both attributes I don’t generally like to incorporate into my workday 🙂\n\nI’m always looking for ways to automate and speed up clunky or slow processes—especially those that rely on any significant element of manual labor. Typically, the more we are doing by hand as part of routine processes, the greater the chance something will go wrong. We’re human, and while I consider myself an expert in right-clicking, if I had to do that a hundred times every Monday in order to validate some portion of schema, it’s unclear whether I would make a mistake or lose my mind first.\n\nEither way, I’d like to propose an alternative to all of these possibilities. Using data collected from system views, we can do all of this ourselves. Once we have sufficiently researched and gathered data from system views, we can create a stored procedure using those collection processes and automate everything into a stored procedure call with a handful of parameters.\n\nWhat follows is an introduction to these views, how to use them in order to gather useful information about our database and the objects within.\n\nUsing System Metadata to Understand our Database\n\nSQL Server provides a wide variety of system views, each of which provides a vast array of information about objects within SQL Server. These allow us to learn about table attributes, system settings, or view what sorts of schema exist in any database.\n\nThis analysis will focus on the primary structures that make up any database and that house our data: schemas, tables, constraints, indexes, and triggers. We’ll also throw in extended properties in order to illustrate our ability to learn about some of the less used (but potentially handy) components within SQL Server.\n\nSchemas and tables are easy to understand. From within a database, we can view a list of schemas like this:\n\nRunning this query lists all schemas within our database. Schemas are useful for organizing database objects and/or applying more granular security to different types of data. When run on AdventureWorks, the results of the above query are:\n\nThe results are simply a list of schema names within the database. The view contains the schema name, its ID, and the ID of its owner. Database roles appear in the list as well. While their inclusion may seem confusing, eliminating them is easy when we join this view to other views of interest. This view contains all entities that are capable of owning others from the context of database schemas. Some of the schemas above are familiar, such as dbo (the default schema in SQL Server), and the AdventureWorks-specific ones, such as Sales, Purchasing, or HumanResources.\n\nTables represent our primary storage mechanism and are therefore very important to us. We can view lots of information about them as follows:\n\nAdding the check on is_ms_shipped will filter out any system tables. If you’d like the full list of all tables, including system objects, feel free to comment out or omit this filter. The results are as follows:\n\nThere are quite a few columns there, including another 2.5 pages worth that are off of the screen to the right! They include different bits of metadata that will be useful under a variety of circumstances. For the sake of our work here, we’ll simply stick to collecting table & schema names for those that are not system tables. We can join our two views above in order to list schemas and tables together:\n\nSchema_id can be used in order to join these views together and connect schemas to tables:\n\nAdding aliases to each column proves useful, since the names of each are “name”, which is not a terribly descriptive way to differentiate between schema and table names. Later on in this article, as we return information about many other types of objects, aliasing them with friendly names will greatly improve readability and the ability to understand the results quickly & easily. Ordering by schema and table names also allows us to more easily browse through the results.\n\nColumns contain each attribute of a table. Understanding them is imperative to understanding the contents of a table and the types of data that we store there. The following query adds sys.columns to our existing query, which provides additional information about each column, the table they belong to, and the schema the table belongs to:\n\nColumns are joined to tables using the object_id of the table, which is referenced by any columns contained within. The query above returns much more than column names, including details about each column that are useful when figuring out what kind of data each contains. The results begin to paint a clearer picture of our data:\n\nThe ordinal position tells us the column order, which is useful when inserting into a table, or determining the logical order for data. Other columns provide additional information, such as the column length, nullability, identity status, and more!\n\nThis is a great start, but we can learn more. Sys.types tells us more about the data type for each column, and can be joined directly to our previous query using user_type_id. The resulting type, when combined with length, precision, and scale, tell us exactly about a column’s data type and how it is defined:\n\nTo prevent our results from getting too cluttered, I’ve removed some of the columns previously discussed:\n\nThis additional information provides us with a familiar type name, such as DATETIME or INT, which may include customized user data types, such as NAME. We now have a basic understanding of what is in a table, and can now delve further into additional attributes.\n\nOne of the attributes previously identified in sys.columns was is_identity, which told us if a column was an identity or not. If it is, we also want to know the seed and increment of the column, which tell us how that identity will behave. This can be accomplished by joining sys.columns to sys.identity_columns:\n\nNote that the join to sys.identity_columns requires the use of both object_id, which indicates the table it belongs to, and also column_id, which specifies the unique ID of the column within that table. In order to most easily and accurately reference any column uniquely, we must use both object_id and column_id. The results of the above query show the additional information added to the end of the result set:\n\nThe results aren’t terribly exciting. IDENTITY(1,1) is the most common definition used for an identity column, but we’ve gained additional knowledge that will prove useful later on.\n\nA column can have at most a single default constraint associated with it. If one is defined, knowing its name and value are helpful in understanding the behavior of the column. A default often indicates a business rule or data need to ensure the column is not NULL, or is at least always populated with some important catchall value. We can gather this information from sys.default_constraints like this:\n\nNote that while this new view is joined on a schema, table, and column, the join on schema is unnecessary we are already are joining that view via sys.tables. Regardless, it is included for both documentation purposes and completeness. The results of the query show all columns, but if a default is defined, that information is also provided:\n\nWe can note a variety of defaults that take values of the current date, zero, and a new GUID unique identifier, though many other types can exist with whatever values you choose to assign. NULL indicates that a column has no default assigned to it. If we chose to join to sys.default_constraints using an INNER JOIN, then we would filter out all of the rows without defaults, leaving behind only the set of columns with default values defined.\n\nSimilar to default constraints, a column may only have a single computed definition associated with it. A computed column cannot be assigned values, and instead is automatically updated based on whatever definition is created for it. Information on this can be found in sys.computed_columns and joined back to sys.columns using object_id and column_id:\n\nThis new view inherits all of the columns in sys.columns, adding a few additional pieces of information. Of these, we will focus on the definition, which tells us in TSQL how that column is populated:\n\nSince sys.computed_columns contains all of the information in sys.columns, it is not necessary to include sys.columns when also querying it if all we care about are columns with computed values defined on them. If we want to include all columns with the computed definition being optional, then the LEFT JOIN between them is required. Any column with no row in sys.computed_columns will result in a NULL in the above query, indicating that it does not have a computed column definition.\n\nA table can only have one primary key associated with it, but this definition is important enough that we want to always capture it, regardless of what columns it is on, or if it is also a clustered index or not. Details about primary keys, as well as details on other indexes, can be found in sys.indexes. This view also holds data pertaining to other indexes on the table. Therefore, we can collect info on all indexes, including primary keys, in a single operation:\n\nThis query collects basic index data, such as whether it is clustered, filtered, or a primary key. It also uses XML to pull the index column details into a comma-separated list, for easy use later on. Collecting all of this data at once is efficient and convenient, and avoids the need to return for column lists, or to check any properties of an index later on.\n\nWhile the query above appears complex, if we remove the XML necessary to parse the column list, the resulting query would only be a simple SELECT from sys.indexes, sys.tables, and sys.schemas. While we could do this initially, and then add the column lists later on, collecting all of this data right now will simplify our TSQL and improve performance as we won’t need to perform additional schema searches and joins to that data once this is complete.\n\nThe results of the above query look like this:\n\nWe omit HEAP from the results as they are not needed for explicit documentation of tables as they are automatically implied in the heap’s definition. We get a fairly wide result set back, but it provides us everything we need to understand an index and its purpose and usage.\n\nForeign keys also represent column lists in one table that reference columns in a target table. We can view basic information on a foreign key using the system view sys.foreign_keys:\n\nThis query returns a list of foreign keys and the source/target tables referenced by it:\n\nThis is straight-forward, but we also want to collect the column lists from source and target tables in order to correctly include them in our data. A foreign key is often a relationship between a single column in one table and its corresponding column in another table, but could exist between groups of columns. As a result, we must write our TSQL to be able to handle either scenario. For now, let’s look at a list of columns in which a foreign key is defined by a row per column in the result set:\n\nSys.foreign_key_columns tells us the column relationships. From there, we need to join sys.tables and sys.columns twice: Once for the parent table and another for the foreign key table. Combining this information allows us to understand what columns reference and are referenced by any foreign key. If a foreign key has multiple columns participating in it, then it will be represented as multiple rows in the result set:\n\nSince we need to worry about two sets of data, collecting it takes a bit more work, but much of it is a duplication of concepts that we have already discussed previously.\n\nCheck constraints are relatively simple to collect information on. Since they are stored with their entire definitions intact, there is no need to query column metadata in order to construct them. Sys.check_constraints can be queried in order to view info on check constraints:\n\nSelecting the is_not_trusted column allows us to validate if the constraint was created with NOCHECK or not. The definition contains the exact constraint details as they were entered when it was created. The results are easy to read and understand:\n\nThe definition itself may be complex, but our efforts to collect this information are the same, regardless of how intricate the check constraint it.\n\nTriggers are stored in a very similar manner to check constraints. The only difference is that their definition is included in sys.sql_modules, whereas the trigger name and object information are stored in sys.triggers. Despite there being two tables involved, we can collect data on them in the same manner as with check constraints:\n\nNote that while we join to sys.triggers, we do not return any columns from that view. That is because the trigger definition provides all details of a trigger that would be found in a CREATE TRIGGER statement. Sys.sql_modules contains details about a variety of objects within SQL Server, such as stored procedures, triggers, and functions. Definitions within this view are all provided in their entirety, including the CREATE statement. As a result, there is no need to query for additional metadata, such as if the trigger is INSTEAD OF or AFTER, or if it is on UPDATE, DELETE, or INSERT. The results of the above query are as follows:\n\nThe results are far more simple than we would have expected! The entire definition is returned in a single column, which makes our work quite easy!\n\nExtended properties are a bit odd in terms of definition and usage. They can be linked to many different objects in SQL Server, such as tables, columns, or constraints. As a result, we need to not only collect their definition, but also the object they relate to. This is a feature that not everyone uses, but is a good example of how even the more oddball parts of SQL Server can be documented if necessary.\n\nSys.extended_properties contains all of the basic information about an extended property. The major_id and minor_id within the view provide us with information on what object the property references. Since we do not know precisely what type of object any extended property may reference up front, we need to LEFT JOIN all possible targets in order to collect a complete result set:\n\nIn this query, sys.extended_properties forms the base table. Sys.objects and sys.schemas are connected using an INNER JOIN, as their metadata will apply to all properties, regardless of type. From here, the remaining joins allow us to gather additional information about the object referenced in sys.objects. The WHERE clause limits the targets that we are interested in to the types of objects that we have discussed thus far (constraints, triggers, and columns).\n\nThe results of the above query will look like this:\n\nThe results tell us the name of the extended property, the type of object it references, information about that object, and the text stored in the extended property itself. Microsoft wasn’t terribly creative and named all extended properties “MS_Description”. You can name yours whatever you want, though, such as in this dinosaur table that I’ve created:\n\nSystem views provide a wealth of information about our data, how it is stored, and the constraints that we place on it. Using these views, we can quickly gather information about objects that are important to us, such as indexes or foreign keys. With this information, we can reconstruct our schema in a format that will assist in schema duplication, development and QA, and schema comparison.\n\nIn our next article, Creating the perfect schema documentation script, we will take everything we have discussed here and combine it into a script that will greatly improve our ability to document and understand a database and its structure.\n\nSome of the system views discussed here were also introduced in a previous 2-part article about searching SQL Server. If desired, we could combine these scripts such that the search script also returned the definition, as well. This could be a very efficient (and fun) way to find objects and their definition based on a keyword search:\n\n Searching SQL Server made easy – Searching catalog views\n\n Searching SQL Server made easy – Building the perfect search script\n\nOptions are documented for the built-in SQL Server scripting here:\n\n Generate SQL Server Scripts Wizard (Choose Script Options Page)\n\nSome basic instructions on this process can be found here:\n\n Generate Scripts (SQL Server Management Studio)\n\nLastly, information on catalog views, which provide the basis for this article, can be found here:\n\n Catalog Views (Transact-SQL)"
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/security/authentication-access/create-a-database-schema?view=sql-server-ver16",
        "document": "This article describes how to create a schema in SQL Server by using SQL Server Management Studio or Transact-SQL.\n• None To create a schema, you must have CREATE SCHEMA permission on the database.\n• None To specify another user as the owner of the schema being created, the caller must have IMPERSONATE permission on that user. If a database role is specified as the owner, the caller must meet one of the following criteria: membership in the role or ALTER permission on the role.\n• None Expand the database in which to create the new database schema.\n• None Right-click the Security folder, point to New, and select Schema.\n• None In the Schema - New dialog box, on the General page, enter a name for the new schema in the Schema name box.\n• None In the Schema owner box, enter the name of a database user or role to own the schema. Alternately, select Search to open the Search Roles and Users dialog box.\n\nA dialog box will not appear if you are creating a Schema using SSMS against an Azure SQL Database or an Azure Synapse Analytics. You will need to run the Create Schema Template T-SQL Statement that is generated.\n\nThe Schema - New dialog box also offers options on two extra pages: Permissions and Extended Properties.\n• None The Permissions page lists all possible securables and the permissions on those securables that can be granted to the login.\n• None The Extended properties page allows you to add custom properties to database users.\n• None In Object Explorer, connect to an instance of Database Engine.\n• None On the Standard bar, select New Query.\n• None The following example creates a schema named , and then creates a table named .\n• None More options can be performed in a single statement. The following example creates the schema owned by that contains the table . The statement grants to and denies to . CREATE SCHEMA Sprockets AUTHORIZATION Joe; GO CREATE TABLE NineProngs ( source INT, cost INT, partnumber INT ); GO GRANT SELECT ON SCHEMA::Sprockets TO Bob; GO DENY SELECT ON SCHEMA::Sprockets TO John; GO\n• None Execute the following statement to view the schemas in the current database:\n• None The new schema is owned by one of the following database-level principals: database user, database role, or application role. Objects created within a schema are owned by the owner of the schema, and have a in Ownership of schema-contained objects can be transferred to any database-level principal, but the schema owner always retains CONTROL permission on objects within the schema.\n• None The domain principal is added to the database as a schema when creating a database object if you specify a valid domain principal (user or group) as the object owner. The new schema is owned by that domain principal."
    },
    {
        "link": "https://stackoverflow.com/questions/2700726/sql-select-statement-filtering",
        "document": "Ok, so I'm trying to select an amount of rows from a column that holds the value 3, but only if there are no rows containing 10 or 4, if there are rows containing 10 or 4 I only want to show those.\n\nWhat would be a good syntax to do that? So far I've been attempting a CASE WHEN statement, but I can't seem to figure it out.\n\nAny help would be greatly appreciated."
    },
    {
        "link": "https://docs.data.world/documentation/sql/concepts/intermediate/GROUP_BY.html",
        "document": "enables you to use aggregate functions on groups of data returned from a query.\n\nis a modifier used on an aggregate function to limit the values used in an aggregation. All the columns in the select statement that aren’t aggregated should be specified in a clause in the query.\n\nReturning to a previous section, when we were working with aggregations, we used the aggregate function to find out the average deal size. If we wanted to know the average value of the deals won by each sales person from highest average to lowest, the query would look like:\n\nWe could even ascertain the average value of deals aggregated by manager by running a query with a join like this:\n\nThough it’s not required by SQL, it is advisable to include all non-aggregated columns from your clause in your clause. If you don’t, there are cases where the query will return the desired results, there are also instances where a random value from the non-aggregated row will be used as the representative for all the values returned by the query.\n\nFor example, let’s say you wanted to know the average deal by sales agent for each of their customers. If you used the query:\n\nyou would get back the following table which shows each sales agent one time and chooses a value at random from the accounts won by that sales person:\n\nTo get the average deal by sales agent for each account the query would look like this:\n\nThe first several rows of the table returned would look like this:\n\nIf you wanted to refine your query even more by running your aggregations against a limited set of the values in a column you could use the keyword. For example, if you wanted to know both the number of deals won by a sales agent and the number of those deals that had a value greater than 1000, you could use the query:\n\nThe first several rows of the resulting table would look like this:\n\nThe first several rows returned by the above query would look like:\n\nThere are two ways to do these exercises. The first is to use the “Try query” links to test your queries without saving them. The second is to create a data.world project and save your queries to it. If you are reading this documentation and completing the exercises as a tutorial, you will need to create your own project to save your work. Details and instructions are in the SQL tutorial which has instructions for setting up your project and links to all the current exercises.\n\nWrite a query that returns the patient column and a count of all the allergies the patient has from allergies table. Group your results by patient, and order them by the number of allergies from greatest to least.\n\nWrite a query that returns the patient column, the average of the value column relabeled as , the count of the value column relabeled as and the maximum value of the value column filtered for values over 30 and label it as . The query should be written against the observations_cleaned table and the results should all be for records where the description is “Body Mass Index”. Group your results by the patient column."
    },
    {
        "link": "https://docs.appsmith.com/connect-data/how-to-guides/fetch-and-filter-data-in-sql",
        "document": "This guide shows you how to retrieve and filter data by using a variety of SQL clauses.\n\nThe WHERE clause in SQL filters data based on specific conditions, enabling you to retrieve rows that match your criteria.\n\nExample 1: If you want to filter Table data based on specific criteria, such as gender, you can use a Select widget with the required option. Configure the query to fetch data using selectedOptionValue reference property, like: Learn more about Server-side Filter on Table. Example 2: If you want to create a dynamic WHERE clause query that depends on user input, such as allowing users to specify a name using an Input widget, prepared statements can't be effectively used in these cases because the structure of the query is not static.\n• Configure the query to fetch data using text reference property, like:\n• Using the keyword in MySQL is not supported in Appsmith. Use the operator instead.\n• / values should be without quotes i.e. instead of .\n\nServer-side pagination allows you to manage and display large datasets within your application. It involves fetching and displaying only a portion of data from the server at a time, enhancing performance.\n\nYou can use either a Table or List widget to display the paginated data, and you can implement pagination with offset or cursor-based techniques by using the reference properties of these widgets.\n\nLearn more about Server-side Pagination on Table and Server-side Pagination on List.\n\nConditional operators, like the AND operator, allow you to specify multiple conditions in your SQL queries. This can be handy when you need to narrow down your data retrieval based on several criteria.\n\nIf you want to perform search operations in your SQL queries, consider using LIKE or ILIKE operators, depending on your need for case sensitivity and partial matching. These operators enable pattern-based searches within your text data.\n• The character, which is used as a wildcard in LIKE and ILIKE patterns, needs to be inside the mustache binding .\n• Do not enclose the mustache binding within quotes.\n\nThe IN clause in SQL allows you to filter results based on multiple values.\n\nWhen working with IN statements, you may encounter situations where it's more convenient to use the ANY statement. The ANY keyword provides an alternative approach to achieving the same result.\n• When using this approach, provide all individual values in the list together, without separating them.\n• Do not enclose the mustache binding within quotes.\n\nExample : If you want to filter employee data based on a specific combination of name and department, you can use the following query: If you want to filter data based on countries selected in a Multi-select widget, turn off prepared statements for this query and use the following format:"
    },
    {
        "link": "https://medium.com/analytics-vidhya/introduction-to-sql-selecting-columns-and-filtering-rows-60413c018260",
        "document": "SQL (Structured Query Language) is a domain-specific language that is used in programming to manage data that is stored in a relational database management system. It was initially developed at IBM by Donald D. Chamberlin and Raymond F. Boyce in the early 1970s. The system was designed in order to manage and retrieve data that was stored in IBM’s original relational database management system, System R. SQL helped introduce the concept of accessing many records with one command and eliminated the need to specify how to reach a record. SQL can be used to create and modify databases in addition to querying databases.\n\nIn SQL, you can display data from a table using a SELECT statement. For example, let’s say you have a table named ‘colleges’ that contains all of the Colleges and Universities in the United States. If you want to select all of the College or University names (column ‘name’) from that table, you would enter the following query:\n\nThere are often situations where you would want to pull multiple columns when entering a query. If you want to pull all of the columns in a table, you would use an asterisk (*) after the SELECT statement. If you only want to pull certain columns, you would simply need to separate the column names with a comma in your query. Let’s say you want to select the number of undergraduates (column ‘undergraduate’) and graduates (column ‘graduate’) in addition to the name of the college. You would enter the following query:\n\nIn addition to querying certain rows and columns, you can also count the number of records that are in a table. To do this, you would enter the following query:\n\nIn SQL, the WHERE clause allows you to filter the rows that you query based on certain conditions (both numerically and text-wise). The different comparison operators you can use with the WHERE clause are as follows:\n• ≥ → Greater than or Equal to\n• ≤ → Less than or Equal to\n\nGoing back to our examples with Colleges and Universities, let’s say you want to filter the Colleges table to only output the name and undergraduate population of schools with more than 20,000 undergraduate students. In this scenario, you would enter the following query:\n\nNow let’s say that there is a column called ‘school_type’ that states whether the College or University is a ‘Liberal Arts’ school, a ‘National University’ or a ‘Community College’. If you want to find the name, undergraduate population and type of school for schools that have more than 4000 students and are Liberal Arts schools, you would have to enter an AND clause after the Where clause. The query would look like:\n\nAnother clause that could be helpful when querying a table is the OR clause. The distinction between the OR clause and the AND clause is that, with the OR clause, a row only needs to meet one of the specified conditions in order to be output in the results. In the above query, if the AND clause is replaced with the OR clause, all schools that have over 4000 undergrads will be output along with all schools that are Liberal Arts types.\n• Chamberlin, Donald (2012). “Early History of SQL”. IEEE Annals of the History of Computing. 34 (4): 78–82. doi:10.1109/MAHC.2012.61. S2CID 1322572\n• “Welcome to the Course!: SQL.” Campus.datacamp.com, campus.datacamp.com/courses/introduction-to-sql/."
    },
    {
        "link": "https://futurelearn.com/info/courses/data-analytics-for-business-manipulating-and-interpreting-your-data/0/steps/177501",
        "document": "Learn how to create queries that return specific data.\n\nBeing able to retrieve a set of columns from a database is useful, but we don’t really begin to leverage the power of SQL until we start to filter specific rows.\n\nWhen you query table information, you can filter records with the clause to extract only those records that fulfill a specific expression. Any row that doesn’t meet the conditions (the expression evaluates to false or NULL) is discarded. The clause follows the clause:\n\nThe resulting table has the same number of columns, but generally has considerably fewer rows that contain the information that meets your expression. The complexity of the expression can range from identifying a single record (or group of records) on a single criteria to identifying those with a long series of sub-expressions over many columns.\n\nExpressions are specified with a combination of ‘operators’. We use operators to test relationships between values, to test equality of values, or to evaluate multiple expressions based on logical conditions.\n\nEquality operators compare two values, which are known as operands, to see if the values are equal. The quality operators in SQLite are shown below.\n\nWhen used in a query, these can be used to select individual records.\n\nOr we can use them to retrieve records that meet a specified criteria.\n\nOr we can use them to return all the records that don’t meet the specified criteria.\n\nRelational operators compare two operands and return true if the operands meet the specified relationship. Relational operators in SQLite are shown below.\n\nWhen used in a query, this can identify records over, or under, certain values. For example, the query below looks for invoices over $20 and returns the customer and invoice identifiers for these orders.\n\nComparison operators can also be combined to find values within a range.\n\nThis would return the following table.\n\nThat brings us nicely to our final operators—logical operators.\n\nWe use logical operators to define multiple conditions required to return rows or records from a statement. SQLite supports the following logical operators.\n\nThe and operators require two expressions and will return values depending on how each expression evaluates. The operator requires both expressions to evaluate to true, whereas the operator will return a value if either expression evaluates to true.\n\nThe examples below show and in action.\n\nThe operator tests whether a value exists in a range of values, and includes its lower and upper expression, like the or ‘<= operators. ‘BETWEEN’ behaves similar to combining these two operators with an AND` operator. For example, BETWEEN 1 and 10 includes all numbers between 1 and 10, including 1 and 10 themselves.\n\nEarlier, we showed you this query:\n\nThis could be rewritten with :\n\ncan be used with other data types, such as dates.\n\nThe operator determines whether a value matches any value in a list. Lists can be a set of fixed values (as shown below), or the results from a subquery (we’ll look at subqueries in the next activity).\n\nWhen we use a list of fixed values, provides an alternative to multiple operators. The following queries would produce the same results.\n\nSo far we’ve been testing our expressions with exact values, such as 10, ‘London’, and ‘2010-01-01’. Sometimes we don’t know exactly what we’re looking for. This is where comes in. Use in your clause to query data on partial information, with a ‘pattern’ of information and the wildcard character . The wildcard can be used at the start, end, or start and end of the pattern. Let’s look at some examples to see how this works.\n\nIn our first example we’ll match tracks that start with ‘Rock’.\n\nThis would return tracks such as ‘Rock Bottom’, ‘Rock The Casbah’, and ‘Rocket’. (‘Rocket’ is included because the wildcard matches spaces and characters.)\n\nTo find tracks that end with ‘Rock’, you could use the pattern . This would return tracks such as AC/DC’s ‘Let There Be Rock’.\n\nFinally, we can use the wildcard at both ends of the pattern.\n\nThis would return the results from both of the patterns above, and tracks such as ‘We Will Rock You’ and ‘Clash City Rockers’.\n\nThe last logical operator we’ll look at is . The operator can be used to negate expressions.\n\nThis would return customers in cities other than London, Paris, and Milan.\n\nAs stated in the table, the operator can be used with , , and .\n\nA final expression we should mention is (or ).\n\nIn SQLite, is used to indicate unknown information. For example, a customer might not have provided a fax number, or we might not know the composer(s) of a particular music track. These would be in our database.\n\nWe can use and in our clauses to gain insight into our data.\n\nThe query below would return a list of users who have provided a fax number.\n\nOr we could find how many tracks don’t have information about the composer(s)."
    }
]