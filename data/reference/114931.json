[
    {
        "link": "https://learn.microsoft.com/en-us/windows/win32/winsock/getting-started-with-winsock",
        "document": "This section is a step-by-step guide to getting started with Windows Sockets programming. It's designed to provide an understanding of basic Winsock functions and data structures, and how they work together.\n\nThe client and server application that we use in this topic for illustration is a very basic client and server. More advanced code examples are included in the samples included with the Microsoft Windows Software Development Kit (SDK).\n\nThe first few steps are the same for both client and server applications.\n\nThe following articles describe the remaining steps for creating a Winsock client application.\n• Sending and receiving data on the client\n\nThe following articles describe the remaining steps for creating a Winsock server application.\n• Receiving and sending data on the server\n\nThe complete source code for these basic examples.\n\nSeveral more advanced Winsock client and server sample apps are available on GitHub. They're listed here in order from higher to lower performance, and are found in the following directories:\n• That folder contains three sample programs that use I/O completion ports. The programs include: a Winsock server, , that uses the WSAAccept function; a Winsock server, , that uses the AcceptEx function; and a simple multithreaded Winsock client, , used to test either of these servers. The server programs support multiple clients connecting by using TCP/IP, and sending arbitrary-sized data buffers that the server then echoes back to the client. For convenience, a simple client program, , was developed to connect and continually send data to the server to stress it using multiple threads. Winsock servers that use I/O completion ports provide the highest performance.\n• This folder contains a sample server program that uses overlapped I/O. The sample program uses the AcceptEx function and overlapped I/O to effectively handle multiple asynchronous connection requests from clients. The server uses the AcceptEx function to multiplex different client connections in a single-threaded Win32 application. Using overlapped I/O allows for greater scalability.\n• This folder contains a basic sample program that demonstrates the use of the WSAPoll function. The combined client and server program are non-blocking, and use the WSAPoll function to determine when it's possible to send or receive without blocking. This sample is for illustration, and isn't a high-performance server.\n• This folder contains three basic sample programs that demonstrate the use of multiple threads by a server. The programs include: a simple TCP/UDP server, ; a TCP-only server, , that uses the select function in a Win32 console application to support multiple client requests; and a client TCP/UDP program, , for testing the servers. The servers demonstrate the use of multiple threads to handle multiple client requests. That method has scalability issues since a separate thread is created for each client request.\n• This folder contains a basic sample server and client program. The server demonstrates the use of either non-blocking accept using the select function, or asynchronous accept using the WSAAsyncSelect function. This sample is for illustration, and isn't a high-performance server."
    },
    {
        "link": "https://learn.microsoft.com/en-us/windows/win32/winsock/complete-client-code",
        "document": "The following is the complete source code for the basic Winsock TCP/IP Client Application."
    },
    {
        "link": "https://stackoverflow.com/questions/15170898/communication-between-two-windows-created-using-tcp-sockets-win32-api",
        "document": "I want to Create two windows using WINAPI and then I want to communicate between them using TCP scokets. so far i have successfully created two windows and have successfully opened the sockets as well. but how two windows will communicate using this socket? here is the code i have written so far:\n\nanother problem is that the code sends data only once from server to client.Also other windows messages are not processed unless data is sent once from server to client :( someone help me please? SERVER WINDOW:"
    },
    {
        "link": "https://github.com/MicrosoftDocs/win32/blob/docs/desktop-src/WinSock/creating-a-basic-winsock-application.md",
        "document": "Begin programming the Winsock application. Use the Winsock API by including the Winsock 2 header files. The Winsock2.h header file contains most of the Winsock functions, structures, and definitions. The Ws2tcpip.h header file contains definitions introduced in the WinSock 2 Protocol-Specific Annex document for TCP/IP that includes newer functions and structures used to retrieve IP addresses.\n\nEnsure that the build environment links to the Winsock Library file Ws2_32.lib. Applications that use Winsock must be linked with the Ws2_32.lib library file. The #pragma comment indicates to the linker that the Ws2_32.lib file is needed.\n\nThe Iphlpapi.h header file is required if an application is using the IP Helper APIs. When the Iphlpapi.h header file is required, the #include line for the Winsock2.h header file should be placed before the #include line for the Iphlpapi.h header file.\n\nThe Winsock2.h header file internally includes core elements from the Windows.h header file, so there is not usually an #include line for the Windows.h header file in Winsock applications. If an #include line is needed for the Windows.h header file, this should be preceded with the #define WIN32_LEAN_AND_MEAN macro. For historical reasons, the Windows.h header defaults to including the Winsock.h header file for Windows Sockets 1.1. The declarations in the Winsock.h header file will conflict with the declarations in the Winsock2.h header file required by Windows Sockets 2.0. The WIN32_LEAN_AND_MEAN macro prevents the Winsock.h from being included by the Windows.h header. An example illustrating this is shown below."
    },
    {
        "link": "https://medium.com/@tharunappu2004/creating-a-simple-tcp-server-in-c-using-winsock-b75dde86dd39",
        "document": "Welcome to this step-by-step guide on creating a basic TCP server in C++ using the Winsock library. In this tutorial, we’ll walk through the process of setting up a server that can accept connections, send, and receive data. We’ll also create a corresponding client that can connect to the server and exchange messages.\n\nBefore we dive into the code, make sure you have the necessary tools installed:\n• Windows OS (as the Winsock library is Windows-specific)\n\nIn the server, the first step is to initialize the Winsock library. This involves loading the DLL and setting up the necessary variables. The following code demonstrates how to achieve this:\n\nNext, we create a socket to handle communication. The function is used for this purpose. It allows us to specify the address family, socket type, and protocol. In our case, we are creating a TCP socket:\n\nNow, we bind the socket to a specific IP address and port number. This is crucial for the server to listen for incoming connections:\n\nNow, we make the server listen for incoming connections using the function:\n\nWhen a client attempts to connect, the server uses the function to accept the incoming connection:\n\nNow that the server is set up and connected to a client, it can send and receive data. The following code demonstrates receiving data and sending a response:\n\nNow that we have our server code, let’s set up a simple client to connect to the server and exchange messages.\n\nThis step is similar to what we did in the server. Initialize Winsock and create a socket:\n\nConnect the client to the server using the function:\n\nSimilar to the server, the client can now send and receive data:\n\nCongratulations! You’ve successfully created a basic TCP server and client using Winsock in C++. This example demonstrates the fundamental steps involved in setting up a server, accepting connections, and exchanging data. Feel free to explore and expand upon this foundation to create more advanced networked applications.\n\nTo run this in vscode terminal:"
    },
    {
        "link": "https://stackoverflow.com/questions/57043016/how-to-send-audio-data-playing-on-pc-to-c-program-as-input",
        "document": "I'm a beginner when it comes to programming and I wanted to do a personal project in C++ to develop my skills. The project I had in mind involves playing audio on my laptop (running Windows 10), analyzing it, and sending data to an arduino that will change the color and brightness of LED lights in sync with the audio that's playing. I would like it so that I can simply, for example, just play a song on Spotify or a music video on Youtube etc. and the program will get data from that audio stream as an input. Elsewhere I've seen programs use audio from recorded WAV files or streams from a microphone as input, but not what I have in mind. I want to use this program for parties, so using a microphone as a workaround wouldn't be ideal.\n\nIs this even possible? And if so how should I approach this problem? Are there certain APIs I should look to or what? If the program gets audio as the input, would I still be able to play music on something like a bluetooth speaker as well? Or can it only send data to one place at a time?\n\nMy roommate who is much better at programming than me accomplished this on Mac using Swift, and while I don't have a Mac, would using Linux instead make this easier?"
    },
    {
        "link": "https://stackoverflow.com/questions/74861269/how-to-create-a-virtual-audio-input-output-device-on-windows-in-c",
        "document": "background:\n\n I want to broadcast the Windows system audio except my own app's one. application loopbackcapture exactly does what I want, but it only supports Windows 11 (I want a much more general solution, Windows 7/8/10/11).\n• create a virtual audio output device, and set it as system default.\n• capture audio from the virtual audio output device, and broadcast it.\n• route audio from the virtual audio output device to the system physical one.\n\nI tried VAC (Virtual Audio Cable), things work fine. However it does not provide any APIs to create virtual audio device and route audio streams between audio devices.\n\n So my question is how to create virtual audio devices and route audio streams between them.\n\n Thanks.\n• How to create a virtual audio input device to simulate a microphone in MacOS"
    },
    {
        "link": "https://cplusplus.com/forum/beginner/20033",
        "document": "This is a far more complicated question than you realize. Go look up digital signal processing on wikipedia or something.Basically, the way audio works is you have a series of samples taken every so often. If you make a graph of these samples, you'd use time as the X axis, and the sample as the Y axis. You then \"connect the dots\" to create the sound wave.Taking a handful of samples and trying to figure out what kind of sound it makes isEDIT:I just re-read your original post. If you want to determine the pitch of a sound, you'll need to do a Fourier transform. There are libraries that do this. Google for FFT libraries. But again.... even with a lib... it's more complicated than you think.As for the rest of your question:A quick skim of SDL documentation suggests it doesn't have support for audio input (only audio output).You'll have to use another library.On Windows, I know you can use waveIn, but it's a complicated process.1) Open an input device with waveInOpen2) Prepare one or a few buffers with waveInPrepareHeader3) Give those buffers to the output device with waveInAddBuffer4) Start recording with waveInStart5) Audio is recorded and fills your buffers6) Continue to provide additional buffers as needed for as long as you want to record audio7) Stop recording with waveInStop8) Free buffers with waveInUnprepareHeader9) Close input device with waveInCloseNone of the steps are trivial. If you're really interested in learning you can look it up on msdn here: http://msdn.microsoft.com/en-us/library/aa908147.aspx <-- link to waveIn documentation.Personally, I would start with waveOut and audio output streaming since it's more or less the same process -- but easier to figure out that you're doing it right/wrong and therefore easier to diagnose. I say try streaming a .wav file with waveOut first... and once you can do that successfully, then try to record something.I've done lots of work with waveOut in a previous life (it's been years), so I have a pretty good grasp of it if you have additional questions. I never actually used waveIn, but from the documentation it looks like it's pretty much the exact same idea.Also I'm not on Windows so unfortunately I won't be able to test things out for you, so you'll largely be on your own (unless someone else on here can help).So yeah....EDIT2:needless to say, this probably isn't a task for a beginner (I just realized this is the beginner's forum!). Audio streaming demands realtime attention, sometimes multithreading and thread safety, and other advanced programming concepts.There might be a lib out there that makes audio recording simpler. Try googling for audio recording libs. But note.... any lib you find will only record PCM data (ie: samples). Nothing will tell you what tones are playing -- you'll have to run the samples through an FFT and all that jazz to figure that out."
    },
    {
        "link": "https://github.com/Azure-Samples/cognitive-services-speech-sdk/blob/master/quickstart/cpp/windows/from-microphone/README.md",
        "document": "This sample demonstrates how to recognize speech with C++ using the Speech SDK for Windows. See the accompanying article on the SDK documentation page which describes how to build this sample from scratch in Visual Studio.\n• A subscription key for the Speech service. See Try the speech service for free.\n• A Windows PC with a working microphone and Microsoft Visual Studio installed. See the Speech SDK installation quickstart for details on system requirements and setup.\n• By building this sample you will download the Microsoft Cognitive Services Speech SDK. By downloading you acknowledge its license, see Speech SDK license agreement.\n• Download the sample code to your development PC.\n• Navigate to the folder containing this sample, and select the solution file contained within it.\n• Edit the source:\n• Replace the string with your own subscription key.\n• Replace the string with the service region of your subscription. For example, replace with if you are using the 30-day free trial subscription.\n• Set the active solution configuration and platform to the desired values under Build > Configuration Manager:\n\nNote If you are seeing red squigglies from IntelliSense for Speech SDK APIs, right-click into your editor window and select Rescan > Rescan Solution to resolve.\n\nTo debug the app and then run it, press F5 or use Debug > Start Debugging. To run the app without debugging, press Ctrl+F5 or use Debug > Start Without Debugging."
    },
    {
        "link": "https://medium.com/@shahidahmadkhan86/sound-in-windows-the-wasapi-in-c-23024cdac7c6",
        "document": "Have you ever wondered how to capture audio from your microphone and play it through the speakers yourself? doing it on the web in Javascript is super simple, but what about doing it in native applications? In this blog, we’ll capture audio from the microphone and play it through the speakers in Windows using the Windows Audio Session API (WASAPI)\n\nThe Windows audio session API is an interface that Windows provides to let programmers manage audio activities. This is the interface your browser most likely uses to render and capture audio data. Chromium, the open-source project on top of which the Chrome and Edge web browsers are built, uses WASAPI for audio.\n\nI will not explain the use of the COM library here as it’s a whole topic on its own, for that I suggest you read more on the Windows COM API. Also, if you want to learn more in-depth about the topic, I suggest reading the MSDN documentation, it’s pretty amazing.\n\nToday, I’ll give you an introduction to this interface and hopefully, you’ll leave with something valuable.\n\nHow does it work?\n\nWell, it all begins with what’s called an enumerator. The enumerator helps you choose the device you want to use to capture or render audio, but before we can do that, we need to do some housekeeping, we need to initialize the COM library. Check out this example:\n\nYou’ll see me using these statements all over the place, this is just so that we catch errors immediately and don’t lose our minds for two hours debugging. The first, third, and fourth parameters in the call tell Windows what interface to initialize and the last one is the target pointer to which the call will write the address of the object we create. In our case, we want to create an enumerator that’ll allow us to select a device to use.\n\nNext up, the enumerator interface has a method that’ll allow us to get the default recording and playback device.\n\nThe and enum values mean we need a recording device and a playback device respectively. The parameter just means default system audio, you can also get the default device for communication if you have that setup. The last parameter is a pointer to the pointer to which the system will write the address of the created object. After that, we release the enumerator as we don’t need it anymore.\n\nNext up, we activate these devices to get an interface through which we’ll do the actual recording and playback. There’s one more layer, we’ll get to that soon.\n\nThen, we get the Mix format. This structure specifies the sample rate, bits per sample, channels, and frame size of the audio we get from the recording device. We need to give this format to the playback interface to tell it the characteristics of the audio data to be played.\n\nAfter that, we need to do two more things. First, we need to initialize the interfaces we created and then get the corresponding services for actually recording and playing the audio.\n\nIn the method, the first parameter specifies how we want to initialize the client. There are two ways. The first is called shared mode, In shared mode the audio passes through the mixing engine to support allowing multiple applications to use the same device. The second one is exclusive mode, you can guess what that would do, you have exclusive access to the device but that also means no other application can use it. It has lower latency and a bunch of other nice things but comes at that cost.\n\nThe third parameter is the capture time in 100-nanosecond units, the number I have specified means one second.\n\nThe fifth parameter means the format to use. We use the one we got from the system just before.\n\nIn the next lines, we get the services for capturing and rendering audio data. We’ll do that next.\n\nThe first two variables are output parameters, that is, the capture service will fill those variables to tell us how many frames were captured and the flags on them.\n\nThe is a pointer that will store the address of the buffer captured.\n\nThe is a pointer that will store the address of the buffer to which we can write our audio data. You can write anything to it, we’ll write what we capture to it.\n\nIn the next four lines, we start the clients.\n\nAfter starting, we begin an infinite loop, you can have your exit condition there.\n\nIn the loop, first, we get the buffer, the address of that buffer is written to the variable, the number of frames captured, and the flags are written to the and variables respectively. We release the buffer as we no longer need it.\n\nAfter that, we get the buffer for the render service. It writes to the pointer, In that pointer is the address of the actual buffer we can write to. We can not release this just yet, after it’s released, the data is sent to the endpoint (device in exclusive mode and mixing engine in shared mode) so we first copy the data we have in the capture buffer using trusty ol’ and then, release it.\n\nYou’ll notice that in the size parameter is that is because the function from the capture service tells us the frames, but each frame is not just one byte, it has a size and that size is called the frame size, you can get it from the format you’re using. it’s the property.\n\nAnd with that, our loopback is done. we’re successfully looping the microphone to the speakers. In the next blog, we’ll abstract this to classes to make them easier to work with and develop a UDP server and a Relay to create a Voice communication app.\n\nTo compiler this, you need to link the library and some include (listed below). You this command to compile using GCC: and then run to hear your beautiful voice. peace :)\n\nFollowing is the whole code for reference:"
    }
]