[
    {
        "link": "https://geeksforgeeks.org/can-we-improve-the-performance-of-a-merge-sort-algorithm",
        "document": "Can we improve the performance of a merge sort algorithm?\n\nThe merge sort, in essence, is a divide-and-conquer algorithm. It breaks down a problem into multiple sub-problems, solves each individually, and finally combines these sub-problems solutions to form the final solution.\n\nThe key operation in merge sort is the merging step. This step is where the algorithm compares and combines the individual elements of the sublists. It takes advantage of the fact that each of the sublists is already sorted. The merging process continues until there is only one sorted list remaining.\n\nThe algorithm can be divided into two main steps:\n• Divide: The divide step computes the midpoint of the indices, taking constant time regardless of the subarray size.\n• Conquer (Merge): The conquer step recursively sorts two subarrays of approximately n/2 elements each. The time this step takes will be considered when we account for the subproblems. The combined step merges a total of n elements, taking Θ(n) time. This step is where the 'merge' in merge sort comes from.\n• None We can cut the running time of merge sort substantially with some carefully considered modifications to the implementation.\n• Use insertion sort for small subarrays. We can improve most recursive algorithms by handling small cases differently. Switching to insertion sort for small subarrays will improve the running time of a typical merge sort.\n• None This is because insertion sort, while worse in the long run, performs faster on small input sizes. Changing the base case of your merge sort so that if the array to sort is below a certain size 50–100 ), you switch to insertion sort, which can markedly improve the performance of the algorithm.\n\nWhy insertion sort for smaller dataset better than merge sort?\n\nImplementation of merge sort with insertion sort for better complexity and optimal performance.\n\n// Calculate the sizes of the two subarrays // Create temporary vectors to hold the two subarrays // Merge the two subarrays back into the original array // Copy the remaining elements of leftArray[], if there are any // Copy the remaining elements of rightArray[], if there are any // Divide the vector into two subarrays, sort them, and merge them // m is the point where the array is divided into two subarrays // Calculate the sizes of the two subarrays // Create temporary arrays to hold the two subarrays // Merge the two subarrays back into the original // Copy the remaining elements of leftArray[], if // Copy the remaining elements of rightArray[], if // Divide the array into two subarrays, sort them, and // m is the point where the array is divided # Calculate the sizes of the two subarrays # Create temporary lists to hold the two subarrays # Merge the two subarrays back into the original array # Copy the remaining elements of left_array[], if any # Copy the remaining elements of right_array[], if any # Divide the list into two subarrays, sort them, and merge them # m is the point where the array is divided into two subarrays # This code is contributed by rambabuguphka // Divide the vector into two subarrays, sort them, and merge them // This code is contributed by shivamgupta0987654321 // Function to merge two subarrays into the main array // This code is contributed by Tapesh(tapeshdua420)\n\nUnderstanding and leveraging the merge sort algorithm can significantly enhance your code’s performance, particularly when working with large datasets."
    },
    {
        "link": "https://stackoverflow.com/questions/33267096/how-to-improve-merge-sort-speed-in-python",
        "document": "From the prior thread linked to by Rishav Kundu:\n\nYou can initialise the whole result list in the top level call to mergesort:\n\nThen for the recursive calls you can use a helper function to which you pass not sublists, but indices into . And the bottom level calls read their values from and write into directly.\n\nFor this to work, the parameter to the seq array needs to be a reference to seq and also the helper array.\n\nYou can also add a parameter to keep track of what direction to merge, so that the copy back step is avoided. C example using mtoa flag that means merge from b to a (if false, it means merge a to b). On my system, Intel 2600K 3.4ghz, this code sorts 4 million pseudo random 32 bit unsigned integers in about 0.36 seconds, and 16 million in about 1.6 seconds.\n\nAnother option would be to use bottom up merge sort, which skips the recursion steps and just starts merging even runs with odd runs, with an initial run size of 1."
    },
    {
        "link": "https://codalien.com/blog/how-to-implement-merge-sort-in-python",
        "document": "Are you eager to enhance your coding skills by mastering one of the most efficient sorting algorithms? If so, delve into the world of merge sort in Python. Known for its powerful divide-and-conquer strategy, merge sort is indispensable for efficiently handling large datasets with precision. In this detailed guide, we’ll walk you through the complete process of implementing merge sort in Python, uncover its technical intricacies, and explore every facet of this essential algorithm. Prepare to elevate your understanding and prowess in sorting algorithms!\n\nNow, Let’s dive into the concept of Merge Sorting, starting from understanding what it is.\n\nMerge sort is a sophisticated comparison-based sorting algorithm that leverages the divide-and-conquer strategy. It systematically breaks down an array into smaller subarrays, sorts them individually, and then merges them back together in a sorted manner. This approach ensures efficient sorting with a time complexity of O(n log n).\n• Divide and Conquer: The array is recursively split into halves until each subarray contains a single element. Because breaking down the problem (sorting an array) into smaller, more manageable subproblems (sorting subarrays) and then combining the solutions to solve the original problem.\n• Stable Sort: Maintains the relative order of equal elements, which is crucial for certain applications.\n• Non-adaptive: Performance remains consistent regardless of the initial order of elements.\n• Recursive Algorithm (sorting algorithm): Merge sort uses a recursive approach to solve the sorting problem effectively.\n\nBefore starting implementing merge sort in Python, let’s delve into the advantages of merge sort:\n• Efficiency: Offers a time complexity of O(n log n), making it faster than simpler algorithms like bubble sort for large datasets.\n• Performance: Provides consistent sorting performance across various datasets.\n• Sorting Efficiency: Particularly effective and reliable for handling large datasets.\n\nHow to Implement Merge Sort in Python?\n\nLet’s Break Down the Merge Sort Processes before start implementing merge sort in python:\n• Divide: Split the array into two halves recursively.\n\nThe first step in implementing merge sort is dividing the array into two halves recursively. It si called Divide and Conquer Strategy. Here, Merge sort begins by dividing the array into smaller subarrays until each subarray contains a single element. This recursive division is fundamental to its efficiency and is handled by the function in Python:\n\nDivide: The array is recursively split into and until each subarray contains a single element ( ).\n\nAfter the array is divided into its smallest parts, merge sort sorts and merges these subarrays back into a single sorted array. The function is pivotal in this merging process:\n\nConquer: The function compares elements from and subarrays, appending the smaller (or equal) element to . It ensures that the merged array remains sorted.\n\nStep 3: Putting It All Together\n\nCombine: To implement merge sort on an entire array, combine the and functions:\n\nMerge sort operates with a time complexity of O(n log n), ensuring efficient sorting even for large datasets:\n• Combine: Each merge operation takes O(n) time, with log n levels of recursion.\n\nMerge sort requires additional space for temporary arrays used during merging, resulting in a space complexity of O(n).\n• Consistent Performance: Guarantees O(n log n) time complexity regardless of input.\n• Overhead: Recursive approach and array allocations may impact performance for smaller datasets.\n• Stable Sorting Needs: Essential for maintaining order in linked lists.\n\nMerge sort, renowned for its efficiency and stable sorting performance, offers developers two primary implementation variants: recursive and iterative approaches. While both methods aim to achieve the same goal of sorting arrays, they differ significantly in their implementation details and practical applications. Understanding the distinctions between recursive and iterative merge sort can empower developers to choose the most suitable approach based on performance requirements, memory constraints, and programming preferences:\n\nThe recursive implementation of merge sort is straightforward but may have limitations in memory-constrained environments.\n\nAn iterative approach to merge sort avoids recursion overhead by merging subarrays iteratively.\n\nMastering merge sort equips you with a fundamental skill in algorithmic thinking. Understanding its nuances and applications allows you to tackle complex sorting challenges with confidence. Whether you’re preparing for coding interviews or enhancing your programming toolkit, merge sort provides a robust solution for efficient and stable sorting."
    },
    {
        "link": "https://geeksforgeeks.org/merge-sort",
        "document": "Merge sort is a sorting algorithm that follows the divide-and-conquer approach. It works by recursively dividing the input array into smaller subarrays and sorting those subarrays then merging them back together to obtain the sorted array.\n\nIn simple terms, we can say that the process of merge sort is to divide the array into two halves, sort each half, and then merge the sorted halves back together. This process is repeated until the entire array is sorted.\n\nMerge sort is a popular sorting algorithm known for its efficiency and stability. It follows the divide-and-conquer approach to sort a given array of elements. \n\nHere’s a step-by-step explanation of how merge sort works:\n\nLet’s sort the array or list [38, 27, 43, 10] using Merge Sort\n\n// begin is for left index and end is right index // of the sub-array of arr to be sorted // l is for left index and r is right index of the // sub-array of arr to be sorted // Sort first and second halves // Find sizes of two subarrays to be merged // Initial indices of first and second subarrays // Copy remaining elements of L[] if any // Copy remaining elements of R[] if any // Sort first and second halves // Sort first and second halves // Copy the remaining elements of L[], if there are any // Copy the remaining elements of R[], if there are any // l is for left index and r is right index of the // sub-array of arr to be sorted // Sort first and second halves //This code is contributed by Susobhan Akhuli\n• None T(n) Represents the total time time taken by the algorithm to sort an array of size n.\n• None 2T(n/2) represents time taken by the algorithm to recursively sort the two halves of the array. Since each half has n/2 elements, we have two recursive calls with input size as (n/2).\n• None O(n) represents the time taken to merge the two sorted halves\n• Time Complexity:\n• Best Case: O(n log n), When the array is already sorted or nearly sorted.\n• Average Case: O(n log n), When the array is randomly ordered.\n• Worst Case: O(n log n), When the array is sorted in reverse order.\n• Auxiliary Space: O(n), Additional space is required for the temporary array used during merging.\n• None Merge Sort and its variations are used in library methods of programming languages.\n• None is used in Python, Java Android and Swift. The main reason why it is preferred to sort non-primitive types is stability which is not there in QuickSort.\n• None It is a preferred algorithm for sorting Linked lists.\n• None It can be easily parallelized as we can independently sort subarrays and then merge.\n• None The merge function of merge sort to efficiently solve the problems like union and intersection of two sorted arrays\n• Stability : Merge sort is a stable sorting algorithm, which means it maintains the relative order of equal elements in the input array.\n• Guaranteed worst-case performance: O(N logN) , which means it performs well even on large datasets.\n• Naturally Parallel : We independently merge subarrays that makes it suitable for parallel processing.\n• Space complexity: Merge sort requires additional memory to store the merged sub-arrays during the sorting process.\n• Not in-place: Merge sort is not an in-place sorting algorithm, which means it requires additional memory to store the sorted data. This can be a disadvantage in applications where memory usage is a concern.\n• Slower than QuickSort in general as QuickSort is more cache friendly because it works in-place."
    },
    {
        "link": "https://stackoverflow.com/questions/7063697/why-is-my-mergesort-so-slow-in-python",
        "document": "Umm.. 1,000 records?? You are still well within the polynomial cooefficient dominance here.. If I have selection-sort: 15 * n ^ 2 (reads) + 5 * n^2 (swaps) insertion-sort: 5 * n ^2 (reads) + 15 * n^2 (swaps) merge-sort: 200 * n * log(n) (reads) 1000 * n * log(n) (merges)\n\nYou're going to be in a close race for a lonng while.. By the way, 2x faster in sorting is NOTHING. Try 100x slower. That's where the real differences are felt. Try \"won't finish in my life-time\" algorithms (there are known regular expressions that take this long to match simple strings).\n\nSo try 1M or 1G records and let us know if you still thing merge-sort isn't doing too well.\n\nThat being said..\n\nThere are lots of things causing this merge-sort to be expensive. First of all, nobody ever runs quick or merge sort on small scale data-structures.. Where you have if (len <= 1), people generally put: if (len <= 16) : (use inline insertion-sort) else: merge-sort At EACH propagation level.\n\nSince insertion-sort is has smaller coefficent cost at smaller sizes of n. Note that 50% of your work is done in this last mile.\n\nNext, you are needlessly running array1.pop(0) instead of maintaining index-counters. If you're lucky, python is efficiently managing start-of-array offsets, but all else being equal, you're mutating input parameters\n\nAlso, you know the size of the target array during merge, why copy-and-double the merged_array repeatedly.. Pre-allocate the size of the target array at the start of the function.. That'll save at least a dozen 'clones' per merge-level.\n\nIn general, merge-sort uses 2x the size of RAM.. Your algorithm is probably using 20x because of all the temporary merge buffers (hopefully python can free structures before recursion). It breaks elegance, but generally the best merge-sort algorithms make an immediate allocation of a merge buffer equal to the size of the source array, and you perform complex address arithmetic (or array-index + span-length) to just keep merging data-structures back and forth. It won't be as elegent as a simple recursive problem like this, but it's somewhat close.\n\nIn C-sorting, cache-coherence is your biggest enemy. You want hot data-structures so you maximize your cache. By allocating transient temp buffers (even if the memory manager is returning pointers to hot memory) you run the risk of making slow DRAM calls (pre-filling cache-lines for data you're about to over-write). This is one advantage insertion-sort,selection-sort and quick-sort have over merge-sort (when implemented as above)\n\nSpeaking of which, something like quick-sort is both naturally-elegant code, naturally efficient-code, and doesn't waste any memory (google it on wikipedia- they have a javascript implementation from which to base your code). Squeezing the last ounce of performance out of quick-sort is hard (especially in scripting languages, which is why they generally just use the C-api to do that part), and you have a worst-case of O(n^2). You can try and be clever by doing a combination bubble-sort/quick-sort to mitigate worst-case."
    },
    {
        "link": "https://geeksforgeeks.org/inversion-count-in-array-using-merge-sort",
        "document": "Given an integer array arr[] of size n, find the inversion count in the array. Two array elements arr[i] and arr[j] form an inversion if arr[i] > arr[j] and i < j.\n\nNote: Inversion Count for an array indicates that how far (or close) the array is from being sorted. If the array is already sorted, then the inversion count is 0, but if the array is sorted in reverse order, the inversion count is maximum.\n\n[Naive Approach] Using Two Nested Loops – O(n^2) Time and O(1) Space\n\nTraverse through the array, and for every index, find the number of smaller elements on its right side in the array. This can be done using a nested loop. Sum up the inversion counts for all indices in the array and return the sum.\n\n// C++ program to Count Inversions in an array // Function to count inversions in the array // If the current element is greater // than the next, increment the count // C program to Count Inversions in an array // Function to count inversions in the array // If the current element is greater than the next, // Java program to Count Inversions in an array // Function to count inversions in the array // If the current element is greater than the next, # Python program to Count Inversions in an array # Function to count inversions in the array # If the current element is greater than the next, // C# program to Count Inversions in an array // Function to count inversions in the array // If the current element is greater than the next, // JavaScript program to Count Inversions in an array // If the current element is greater than the next,\n\n[Expected Approach] – O(n log n) Time and O(n) Space\n\nWe can use merge sort to count the inversions in an array. First, we divide the array into two halves: left half and right half. Next, we recursively count the inversions in both halves. While merging the two halves back together, we also count how many elements from the left half array are greater than elements from the right half array, as these represent cross inversions (i.e., element from the left half of the array is greater than an element from the right half during the merging process in the merge sort algorithm). Finally, we sum the inversions from the left half, right half, and the cross inversions to get the total number of inversions in the array. This approach efficiently counts inversions while sorting the array.\n\nLet’s understand the above intuition in more detailed form, as we get to know that we have to perform the merge sort on the given array. Below images represents dividing and merging steps of merge sort.\n\nDuring each merging step of the merge sort algorithm, we count cross inversions by comparing elements from the left half of the array with those from the right half. If we find an element arr[i] in the left half that is greater than an element arr[j] in the right half, we can conclude that all elements after i in the left half will also be greater than arr[j]. This allows us to count multiple inversions at once. Let’s suppose if there are k elements remaining in the left half after i, then there are k cross inversions for that particular arr[j]. The rest of the merging process continues as usual, where we combine the two halves into a sorted array. This efficient counting method significantly reduces the number of comparisons needed, enhancing the overall performance of the inversion counting algorithm.\n\nBelow Illustration represents the cross inversion of a particular step during the merging process in the merge sort algorithm:\n\n// C++ program to Count Inversions in an array using merge sort // This function merges two sorted subarrays arr[l..m] and arr[m+1..r] // and also counts inversions in the whole subarray arr[l..r] // Set up two vectors for left and right halves // Initialize inversion count (or result) and merge two halves // No increment in inversion count if left[] has a // If right is smaller, then it is smaller than n1-i // Function to count inversions in the array // Recursively count inversions in the left and // Count inversions such that greater element is in // the left half and smaller in the right half // C program to Count Inversions in an array using merge sort // This function merges two sorted subarrays arr[l..m] and arr[m+1..r] // and also counts inversions in the whole subarray arr[l..r] // Set up two arrays for left and right halves // if left[] has a smaller or equal element // If right is smaller, then it is smaller than n1-i // Function to count inversions in the array // in the left and right halves // Count inversions such that greater element is in // the left half and smaller in the right half // Java program to Count Inversions in an array using merge sort // This function merges two sorted subarrays arr[l..m] and arr[m+1..r] // and also counts inversions in the whole subarray arr[l..r] // Set up two arrays for left and right halves // if left[] has a smaller or equal element // If right is smaller, then it is smaller than n1-i // Function to count inversions in the array // in the left and right halves // Count inversions such that greater element is in // the left half and smaller in the right half # Python program to Count Inversions in an array using merge sort # This function merges two sorted subarrays arr[l..m] and arr[m+1..r] # and also counts inversions in the whole subarray arr[l..r] # Set up two lists for left and right halves # if left[] has a smaller or equal element # Function to count inversions in the array # in the left and right halves # Count inversions such that greater element is in # the left half and smaller in the right half // C# program to Count Inversions in an array using merge sort // This function merges two sorted subarrays arr[l..m] and arr[m+1..r] // and also counts inversions in the whole subarray arr[l..r] // Set up two arrays for left and right halves // if left[] has a smaller or equal element // Function to count inversions in the array // in the left and right halves // Count inversions such that greater element is in // the left half and smaller in the right half // JavaScript program to Count Inversions in an array using merge sort // This function merges two sorted subarrays arr[l..m] and arr[m+1..r] // and also counts inversions in the whole subarray arr[l..r] // Set up two arrays for left and right halves // if left[] has a smaller or equal element // Function to count inversions in the array // in the left and right halves // Count inversions such that greater element is in // the left half and smaller in the right half\n\nNote: The above code modifies (or sorts) the input array. If we want to count only inversions, we need to create a copy of the original array and perform operation on the copy array.\n\nYou may like to see:\n• None Count inversions in an array | Set 2 (Using Self-Balancing BST)\n• None Counting Inversions using Set in C++ STL\n• None Count inversions in an array | Set 3 (Using BIT)"
    },
    {
        "link": "https://medium.com/@ssbothwell/counting-inversions-with-merge-sort-4d9910dc95f0",
        "document": "In my last blog post I ended with Merge Sort and briefly mentioned inversion counting and that it can be useful for a simple recommendation engine. I wanted to explain this in a little more detail and give a proof of concept example.\n\nFirst of all, inversions are pairs of numbers, in a disordered list, where the larger of the two numbers is to the left of smaller number. In the following list: [ 1, 3, 5, 2, 4, 6 ] there are 3 inversions: (3,2), (5,2), and (5,4). We can visualize this like so:\n\nBy drawing lines between matching numbers in the disordered list and it’s ordered counterpart we create a series of crossed lines which correspond to each of the inversions. These inversions show the degree to which our list is out of order. If we have a good way to count inversions then we can map values to numbers and make comparisons between lists of values.\n\nFor example, if I wanted to find who in a group I most share the same hobbies with I could have everyone rank hobbies, map them to values based on my hobbies to establish an order, and run them through an inversion counting algorithm to see who’s hobbies most match mine. We would probably have to do a little extra cleanup work to get matching sets of data but after that it could look like this:\n\nI have 4 inversions with person A and 2 inversions with person B. So it looks like I should hangout with Person B.\n\nWe can achieve this by hand drawing the sorted and unsorted lists, but lets look at how we can do this programmatically, and for free, using Merge Sort. Lets briefly review Merge Sort:\n\nFirst we recursively split the input list in half into ‘a’ and ‘b’. Once we have recursed log2(n) times and get to single element lists and hit our base case. Now we work our way back up the recursion tree. At each level of recursion, the lists returned as ‘a’ and ‘b’ are iterated through and appended to ‘c’ such that ‘c’ is a sorted array.\n\nBecause the elements of ‘a’ and ‘b’ are appended to ‘c’ in order of least to greatest, and ‘a’ and ‘b’ are the list ‘c’ from the last returned recursive calls, ‘a’ and ‘b’ are always sorted. At each recursive step we compare the lowest values from ‘a’ and ‘b’, appending the lower value to ‘c’ and incrementing the iterator for the array which was the source of the appended value. Because ‘a’ and ‘b’ are already sorted, once one array is fully iterated and added to ‘c’ we can dump the entire remainder of the other array into ‘c’ as well.\n\nNow recall that an inversion is a a pair of numbers where the higher number comes before the lower number. This is precisely what is going on in Merge Sort when we combine ‘a’ and ‘b’. There are no inversions within ‘a’ or ‘b’ individually but there are inversions between ‘a’ and ‘b’. The conditional is checking for these inversions and correcting them as the elements are added to ‘c’.\n\nSo now we know when the inversions are being corrected. We need to know how many inversions are being corrected these moments. Consider the following example:\n\nBoth lists are sorted individually and but there are inversions between them. The first value in ‘b’ is 2 and makes up two inversions (3,2) and (5,2). Merge Sort will correct this like so:\n\nAll elements from ‘a’ that are smaller then b[j] are added to ‘c’ before b[j]. In other words, the amount of numbers in ‘a’ that are bigger then b[j] is the amount of numbers in ‘a’ which have not been appended to ‘c’ yet. We now know that b[j] is in an inversion pair with each element of ‘a’ that has not been appended to ‘c’. We also know that there are no inversions in ‘b’ because ‘b’ is already sorted! Thus we know exactly how many inversions b[j] is a part of.\n\nThe iterator ‘i’ already tracks how many elements in ‘a’ have been appended to ‘c’ so all we have to do is subtract ‘i’ from the length of ‘a’ and we get this number of inversions involving b[j]. If we keep a running tally of len(a)-i for every time an element from ‘b’ is smaller then an element in ‘a’ then we know the total number of inversions between ‘a’ and ‘b’.\n\nWe need to pass this value along between the levels of recursion to get the total inversions in the input. We do this by returning it with ‘c’, and end up with something like this:\n\nNotice that this is essentially the exact same algorithm as earlier on. Merge Sort was already counting inversions for us, we just needed to track it. Merge Sort with inversion counting, just like regular Merge Sort, is O(n log(n)) time.\n\nWith our inversion counting algorithm dialed in, we can go back to our recommendation engine hypothetical. All we need is a hash table to translate hobbies to integers where your hobby ranking is ordered 1..n. Use the hash table to translate other people’s hobby rankings into unordered lists (and filter out hobbies we don’t share) and process them with Merge Sort. The person with least inversions will have the closest matching set of hobbies.\n\nOf course, such a recommendation engine will have a number of problems in the real world. However, it is an interesting use of what is essentially a side effect of a common sorting algorithm. I’ll leave the implementation of this up to the reader."
    },
    {
        "link": "https://geeksforgeeks.org/python-program-for-count-inversions-in-an-array-set-1-using-merge-sort",
        "document": "Inversion Count for an array indicates – how far (or close) the array is from being sorted. If the array is already sorted, then the inversion count is 0, but if the array is sorted in the reverse order, the inversion count is the maximum. \n\nFormally speaking, two elements a[i] and a[j] form an inversion if a[i] > a[j] and i < j \n\nExample:\n\nApproach: Traverse through the array, and for every index, find the number of smaller elements on its right side of the array. This can be done using a nested loop. Sum up the counts for all index in the array and print the sum.\n• Traverse through the array from start to end\n• For every element, find the count of elements smaller than the current number up to that index using another loop.\n• Sum up the count of inversion for every index.\n• Time Complexity: O(n^2), Two nested loops are needed to traverse the array from start to end, so the Time complexity is O(n^2)\n\nApproach: \n\nSuppose the number of inversions in the left half and right half of the array (let be inv1 and inv2); what kinds of inversions are not accounted for in Inv1 + Inv2? The answer is – the inversions that need to be counted during the merge step. Therefore, to get the total number of inversions that needs to be added are the number of inversions in the left subarray, right subarray, and merge().\n\nHow to get the number of inversions in merge()? \n\nIn merge process, let i is used for indexing left sub-array and j for right sub-array. At any step in merge(), if a[i] is greater than a[j], then there are (mid – i) inversions. because left and right subarrays are sorted, so all the remaining elements in left-subarray (a[i+1], a[i+2] … a[mid]) will be greater than a[j]\n• The idea is similar to merge sort, divide the array into two equal or almost equal halves in each step until the base case is reached.\n• Create a function merge that counts the number of inversions when two halves of the array are merged, create two indices i and j, i is the index for the first half, and j is an index of the second half. if a[i] is greater than a[j], then there are (mid – i) inversions. because left and right subarrays are sorted, so all the remaining elements in left-subarray (a[i+1], a[i+2] … a[mid]) will be greater than a[j].\n• Create a recursive function to divide the array into halves and find the answer by summing the number of inversions is the first half, the number of inversion in the second half and the number of inversions by merging the two.\n• The base case of recursion is when there is only one element in the given half.\n• Time Complexity: O(n log n), The algorithm used is divide and conquer, So in each level, one full array traversal is needed, and there are log n levels, so the time complexity is O(n log n).\n\nNote that the above code modifies (or sorts) the input array. If we want to count only inversions, we need to create a copy of the original array and call mergeSort() on the copy to preserve the original array’s order."
    },
    {
        "link": "https://stackoverflow.com/questions/23484711/merge-sort-algorithm-counting-inversions",
        "document": "The Problem is, that you are counting only 1 inversion, if is true.\n\nBut since both lists are sorted at this point, it means you get an inversion for every element that is in . So you have to use instead of .\n• \n• you get four inversions: (5,1), (6,1), (7,1), (8,1)\n• \n• you get four inversions: (5,2), (6,2), (7,2), (8,2)\n• \n• you get four inversions: (5,3), (6,3), (7,3), (8,3)\n• \n• you get four inversions: (5,4), (6,4), (7,4), (8,4)\n• is empty\n• append to and get"
    },
    {
        "link": "https://stackoverflow.com/questions/14306088/merge-sort-to-count-split-inversions-in-python",
        "document": "I am trying to use mergesort--which I get--to count the number of split inversions in a list (that is, where an element in the first half of the unsorted list should appear after a given element in the second half of the unsorted list; for example [3 2 1 4] would contain the split inversion (3, 1), but not (3, 2) as 3 and 2 are both in the first half). When I get to the final print statement, I am getting the answer I expect--in this case 9--but the return value is all wonky since it's returning the split value through the recursion. I've tried all sorts of combinations of indexing to no avail. Any help? (using Python 2.7)"
    }
]