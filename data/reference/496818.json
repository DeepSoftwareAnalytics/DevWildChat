[
    {
        "link": "https://docs.kernel.org/PCI/pci.html",
        "document": "The world of PCI is vast and full of (mostly unpleasant) surprises. Since each CPU architecture implements different chip-sets and PCI devices have different requirements (erm, “features”), the result is the PCI support in the Linux kernel is not as trivial as one would wish. This short paper tries to introduce all potential driver authors to Linux APIs for PCI device drivers.\n\nA more complete resource is the third edition of “Linux Device Drivers” by Jonathan Corbet, Alessandro Rubini, and Greg Kroah-Hartman. LDD3 is available for free (under Creative Commons License) from: https://lwn.net/Kernel/LDD3/.\n\nHowever, keep in mind that all documents are subject to “bit rot”. Refer to the source code if things are not working as described here.\n\nPlease send questions/comments/patches about Linux PCI API to the “Linux PCI” <linux-pci@atrey.karlin.mff.cuni.cz> mailing list.\n\nPCI drivers “discover” PCI devices in a system via pci_register_driver(). Actually, it’s the other way around. When the PCI generic code discovers a new device, the driver with a matching “description” will be notified. Details on this below. pci_register_driver() leaves most of the probing for devices to the PCI layer and supports online insertion/removal of devices [thus supporting hot-pluggable PCI, CardBus, and Express-Card in a single driver]. pci_register_driver() call requires passing in a table of function pointers and thus dictates the high level structure of a driver. Once the driver knows about a PCI device and takes ownership, the driver generally needs to perform the following initialization:\n• None Set the DMA mask size (for both coherent and streaming DMA) When done using the device, and perhaps the module needs to be unloaded, the driver needs to take the following steps:\n• None Unregister from other subsystems (e.g. scsi or netdev) Most of these topics are covered in the following sections. For the rest look at LDD3 or <linux/pci.h> . If the PCI subsystem is not configured (CONFIG_PCI is not set), most of the PCI functions described below are defined as inline functions either completely empty or just returning an appropriate error codes to avoid lots of ifdefs in the drivers.\n\nPCI device drivers call during their initialization with a pointer to a structure describing the driver ( ): Pointer to table of device IDs the driver is interested in. Most drivers should export this table using MODULE_DEVICE_TABLE(pci,...). This probing function gets called (during execution of pci_register_driver() for already existing devices or later if a new device gets inserted) for all PCI devices which match the ID table and are not “owned” by the other drivers yet. This function gets passed a “struct pci_dev *” for each device whose entry in the ID table matches the device. The probe function returns zero when the driver chooses to take “ownership” of the device or an error code (negative number) otherwise. The probe function always gets called from process context, so it can sleep. The remove() function gets called whenever a device being handled by this driver is removed (either during deregistration of the driver or when it’s manually pulled out of a hot-pluggable slot). The remove function always gets called from process context, so it can sleep. Wake device from low power state. (Please see PCI Power Management for descriptions of PCI Power Management and the related functions.) Hook into reboot_notifier_list (kernel/sys.c). Intended to stop any idling DMA operations. Useful for enabling wake-on-lan (NIC) or changing the power state of a device before reboot. e.g. drivers/net/e100.c. Optional driver callback to allow configuration of number of VFs to enable via sysfs “sriov_numvfs” file. PF Driver callback to change number of MSI-X vectors on a VF. Triggered via sysfs “sriov_vf_msix_count”. This will change MSI-X Table Size in the VF Message Control registers. PF driver callback to get the total number of MSI-X vectors available for distribution to the VFs. Attributes attached to the device that will be created once it is bound to the driver. Device driver doesn’t use kernel DMA API for DMA. For most device drivers, no need to care about this flag as long as all DMAs are handled through the kernel DMA API. For some special ones, for example VFIO drivers, they know how to manage the DMA themselves and set this flag so that the IOMMU layer will allow them to setup and manage their own I/O address space. The ID table is an array of entries ending with an all-zero entry. Definitions with static const are generally preferred. Device class, subclass, and “interface” to match. See Appendix D of the PCI Local Bus Spec or include/linux/pci_ids.h for a full list of classes. Most drivers do not need to specify class/class_mask as vendor/device is normally sufficient. Limit which sub-fields of the class field are compared. See drivers/scsi/sym53c8xx_2/ for example of usage. Data private to the driver. Most drivers don’t need to use driver_data field. Best practice is to use driver_data as an index into a static list of equivalent device types, instead of using it as a pointer. Match only when dev->driver_override is this driver. Most drivers only need or to set up a pci_device_id table. New PCI IDs may be added to a device driver pci_ids table at runtime as shown below: All fields are passed in as hexadecimal values (no leading 0x). The vendor and device fields are mandatory, the others are optional. Users need pass only as many optional fields as necessary: Note that driver_data must match the value used by any of the pci_device_id entries defined in the driver. This makes the driver_data field mandatory if all the pci_device_id entries have a non-zero driver_data value. Once added, the driver probe routine will be invoked for any unclaimed PCI devices listed in its (newly updated) pci_ids list. When the driver exits, it just calls and the PCI layer automatically calls the remove hook for all devices handled by the driver. Please mark the initialization and cleanup functions where appropriate (the corresponding macros are defined in <linux/init.h>): Initialization code. Thrown away after the driver initializes. Tips on when/where to use the above attributes:\n• None The / functions (and all initialization functions called _only_ from these) should be marked __init/__exit.\n• None Do not mark the .\n• None Do NOT mark a function if you are not sure which mark to use. Better to not mark the function than mark the function wrong.\n\nAs noted in the introduction, most PCI drivers need the following steps for device initialization:\n• None Set the DMA mask size (for both coherent and streaming DMA) The driver can access PCI config space registers at any time. (Well, almost. When running BIST, config space can go away...but that will just result in a PCI Bus Master Abort and config reads will return garbage). Before touching any device registers, the driver needs to enable the PCI device by calling . This will:\n• None wake up the device if it was in suspended state,\n• None allocate I/O and memory regions of the device (if BIOS did not),\n• None allocate an IRQ (if BIOS did not). can fail! Check the return value. OS BUG: we don’t check resource allocations before enabling those resources. The sequence would make more sense if we called pci_request_resources() before calling . Currently, the device drivers can’t detect the bug when two devices have been allocated the same range. This is not a common problem and unlikely to get fixed soon. This has been discussed before but not changed as of 2.6.19: https://lore.kernel.org/r/20060302180025.GC28895@flint.arm.linux.org.uk/ will enable DMA by setting the bus master bit in the PCI_COMMAND register. It also fixes the latency timer value if it’s set to something bogus by the BIOS. will disable DMA by clearing the bus master bit. If the PCI device can use the PCI Memory-Write-Invalidate transaction, call . This enables the PCI_COMMAND bit for Mem-Wr-Inval and also ensures that the cache line size register is set correctly. Check the return value of as not all architectures or chip-sets may support Memory-Write-Invalidate. Alternatively, if Mem-Wr-Inval would be nice to have but is not required, call to have the system do its best effort at enabling Mem-Wr-Inval. Memory (MMIO), and I/O port addresses should NOT be read directly from the PCI device config space. Use the values in the pci_dev structure as the PCI “bus address” might have been remapped to a “host physical” address by the arch/chip-set specific kernel support. See The io_mapping functions for how to access device registers or device memory. The device driver needs to call to verify no other device is already using the same address resource. Conversely, drivers should call AFTER calling . The idea is to prevent two devices colliding on the same address range. See OS BUG comment above. Currently (2.6.19), The driver can only determine MMIO and IO Port resource availability _after_ calling . Generic flavors of are request_mem_region() (for MMIO ranges) and request_region() (for IO Port ranges). Use these for address resources that are not described by “normal” PCI BARs. Also see below. If anything below doesn’t make sense, please refer to Dynamic DMA mapping using the generic device. This section is just a reminder that drivers need to indicate DMA capabilities of the device and is not an authoritative source for DMA interfaces. While all drivers should explicitly indicate the DMA capability (e.g. 32 or 64 bit) of the PCI bus master, devices with more than 32-bit bus master capability for streaming data need the driver to “register” this capability by calling dma_set_mask() with appropriate parameters. In general this allows more efficient DMA on systems where System RAM exists above 4G _physical_ address. Drivers for all PCI-X and PCIe compliant devices must call dma_set_mask() as they are 64-bit DMA devices. Similarly, drivers must also “register” this capability if the device can directly address “coherent memory” in System RAM above 4G physical address by calling dma_set_coherent_mask(). Again, this includes drivers for all PCI-X and PCIe compliant devices. Many 64-bit “PCI” devices (before PCI-X) and some PCI-X devices are 64-bit DMA capable for payload (“streaming”) data but not control (“coherent”) data. Once the DMA masks are set, the driver can allocate “coherent” (a.k.a. shared) memory. See Dynamic DMA mapping using the generic device for a full description of the DMA APIs. This section is just a reminder that it needs to be done before enabling DMA on the device. Some drivers will need specific “capability” fields programmed or other “vendor specific” register initialized or reset. E.g. clearing pending interrupts. While calling is the last step described here, this is often just another intermediate step to initialize a device. This step can often be deferred until the device is opened for use. All interrupt handlers for IRQ lines should be registered with IRQF_SHARED and use the devid to map IRQs to devices (remember that all PCI IRQ lines can be shared). will associate an interrupt handler and device handle with an interrupt number. Historically interrupt numbers represent IRQ lines which run from the PCI device to the Interrupt controller. With MSI and MSI-X (more below) the interrupt number is a CPU “vector”. also enables the interrupt. Make sure the device is quiesced and does not have any interrupts pending before registering the interrupt handler. MSI and MSI-X are PCI capabilities. Both are “Message Signaled Interrupts” which deliver interrupts to the CPU via a DMA write to a Local APIC. The fundamental difference between MSI and MSI-X is how multiple “vectors” get allocated. MSI requires contiguous blocks of vectors while MSI-X can allocate several individual ones. MSI capability can be enabled by calling with the PCI_IRQ_MSI and/or PCI_IRQ_MSIX flags before calling . This causes the PCI support to program CPU vector data into the PCI device capability registers. Many architectures, chip-sets, or BIOSes do NOT support MSI or MSI-X and a call to pci_alloc_irq_vectors with just the PCI_IRQ_MSI and PCI_IRQ_MSIX flags will fail, so try to always specify PCI_IRQ_INTX as well. Drivers that have different interrupt handlers for MSI/MSI-X and legacy INTx should chose the right one based on the msi_enabled and msix_enabled flags in the pci_dev structure after calling pci_alloc_irq_vectors. There are (at least) two really good reasons for using MSI:\n• None MSI is an exclusive interrupt vector by definition. This means the interrupt handler doesn’t have to verify its device caused the interrupt.\n• None MSI avoids DMA/IRQ race conditions. DMA to host memory is guaranteed to be visible to the host CPU(s) when the MSI is delivered. This is important for both data coherency and avoiding stale control data. This guarantee allows the driver to omit MMIO reads to flush the DMA stream. See drivers/infiniband/hw/mthca/ or drivers/net/tg3.c for examples of MSI/MSI-X usage.\n\nWhen a PCI device driver is being unloaded, most of the following steps need to be performed:\n• None Unregister from other subsystems (e.g. scsi or netdev) How to do this is chip/device specific. If it’s not done, it opens the possibility of a “screaming interrupt” if (and only if) the IRQ is shared with another device. When the shared IRQ handler is “unhooked”, the remaining devices using the same IRQ line will still need the IRQ enabled. Thus if the “unhooked” device asserts IRQ line, the system will respond assuming it was one of the remaining devices asserted the IRQ line. Since none of the other devices will handle the IRQ, the system will “hang” until it decides the IRQ isn’t going to get handled and masks the IRQ (100,000 iterations later). Once the shared IRQ is masked, the remaining devices will stop functioning properly. Not a nice situation. This is another reason to use MSI or MSI-X if it’s available. MSI and MSI-X are defined to be exclusive interrupts and thus are not susceptible to the “screaming interrupt” problem. Once the device is quiesced (no more IRQs), one can call . This function will return control once any pending IRQs are handled, “unhook” the drivers IRQ handler from that IRQ, and finally release the IRQ if no one else is using it. It’s extremely important to stop all DMA operations BEFORE attempting to deallocate DMA control data. Failure to do so can result in memory corruption, hangs, and on some chip-sets a hard crash. Stopping DMA after stopping the IRQs can avoid races where the IRQ handler might restart DMA engines. While this step sounds obvious and trivial, several “mature” drivers didn’t get this step right in the past. Once DMA is stopped, clean up streaming DMA first. I.e. unmap data buffers and return buffers to “upstream” owners if there is one. Then clean up “coherent” buffers which contain the control data. See Dynamic DMA mapping using the generic device for details on unmapping interfaces. Most low level PCI device drivers support some other subsystem like USB, ALSA, SCSI, NetDev, Infiniband, etc. Make sure your driver isn’t losing resources from that other subsystem. If this happens, typically the symptom is an Oops (panic) when the subsystem attempts to call into a driver that has been unloaded. io_unmap() MMIO or IO Port resources and then call . This is the symmetric opposite of . Do not access device registers after calling . Call to mark the MMIO or IO Port range as available. Failure to do so usually results in the inability to reload the driver.\n\nYou can use to access the config space of a device represented by . All these functions return 0 when successful or an error code ( ) which can be translated to a text string by pcibios_strerror. Most drivers expect that accesses to valid PCI devices don’t fail. If you don’t have a struct pci_dev available, you can call to access a given device and function on that bus. If you access fields in the standard portion of the config header, please use symbolic names of locations and bits declared in <linux/pci.h>. If you need to access Extended PCI Capability registers, just call for the particular capability and it will find the corresponding register block for you.\n\nWhen displaying PCI device names to the user (for example when a driver wants to tell the user what card has it found), please use pci_name(pci_dev). Always refer to the PCI devices by a pointer to the pci_dev structure. All PCI layer functions use this identification and it’s the only reasonable one. Don’t use bus/slot/function numbers except for very special purposes -- on systems with multiple primary buses their semantics can be pretty complex. Don’t try to turn on Fast Back to Back writes in your driver. All devices on the bus need to be capable of doing it, so this is something which needs to be handled by platform and generic code, not individual drivers.\n\nConverting a driver from using I/O Port space to using MMIO space often requires some additional changes. Specifically, “write posting” needs to be handled. Many drivers (e.g. tg3, acenic, sym53c8xx_2) already do this. I/O Port space guarantees write transactions reach the PCI device before the CPU can continue. Writes to MMIO space allow the CPU to continue before the transaction reaches the PCI device. HW weenies call this “Write Posting” because the write completion is “posted” to the CPU before the transaction has reached its destination. Thus, timing sensitive code should add readl() where the CPU is expected to wait before doing other work. The classic “bit banging” sequence works fine for I/O Port space: The same sequence for MMIO space should be: It is important that “safe_mmio_reg” not have any side effects that interferes with the correct operation of the device. Another case to watch out for is when resetting a PCI device. Use PCI Configuration space reads to flush the writel(). This will gracefully handle the PCI master abort on all platforms if the PCI device is expected to not respond to a readl(). Most x86 platforms will allow MMIO reads to master abort (a.k.a. “Soft Fail”) and return garbage (e.g. ~0). But many RISC platforms will crash (a.k.a.”Hard Fail”)."
    },
    {
        "link": "https://kernel.org/doc/html/v6.8/PCI/pci.html",
        "document": "The world of PCI is vast and full of (mostly unpleasant) surprises. Since each CPU architecture implements different chip-sets and PCI devices have different requirements (erm, \"features\"), the result is the PCI support in the Linux kernel is not as trivial as one would wish. This short paper tries to introduce all potential driver authors to Linux APIs for PCI device drivers.\n\nA more complete resource is the third edition of \"Linux Device Drivers\" by Jonathan Corbet, Alessandro Rubini, and Greg Kroah-Hartman. LDD3 is available for free (under Creative Commons License) from: https://lwn.net/Kernel/LDD3/.\n\nHowever, keep in mind that all documents are subject to \"bit rot\". Refer to the source code if things are not working as described here.\n\nPlease send questions/comments/patches about Linux PCI API to the \"Linux PCI\" <linux-pci@atrey.karlin.mff.cuni.cz> mailing list.\n\nPCI drivers \"discover\" PCI devices in a system via pci_register_driver(). Actually, it's the other way around. When the PCI generic code discovers a new device, the driver with a matching \"description\" will be notified. Details on this below. pci_register_driver() leaves most of the probing for devices to the PCI layer and supports online insertion/removal of devices [thus supporting hot-pluggable PCI, CardBus, and Express-Card in a single driver]. pci_register_driver() call requires passing in a table of function pointers and thus dictates the high level structure of a driver. Once the driver knows about a PCI device and takes ownership, the driver generally needs to perform the following initialization:\n• None Set the DMA mask size (for both coherent and streaming DMA) When done using the device, and perhaps the module needs to be unloaded, the driver needs to take the follow steps:\n• None Unregister from other subsystems (e.g. scsi or netdev) Most of these topics are covered in the following sections. For the rest look at LDD3 or <linux/pci.h> . If the PCI subsystem is not configured (CONFIG_PCI is not set), most of the PCI functions described below are defined as inline functions either completely empty or just returning an appropriate error codes to avoid lots of ifdefs in the drivers.\n\nPCI device drivers call during their initialization with a pointer to a structure describing the driver ( ): Pointer to table of device IDs the driver is interested in. Most drivers should export this table using MODULE_DEVICE_TABLE(pci,...). This probing function gets called (during execution of pci_register_driver() for already existing devices or later if a new device gets inserted) for all PCI devices which match the ID table and are not \"owned\" by the other drivers yet. This function gets passed a \"struct pci_dev *\" for each device whose entry in the ID table matches the device. The probe function returns zero when the driver chooses to take \"ownership\" of the device or an error code (negative number) otherwise. The probe function always gets called from process context, so it can sleep. The remove() function gets called whenever a device being handled by this driver is removed (either during deregistration of the driver or when it's manually pulled out of a hot-pluggable slot). The remove function always gets called from process context, so it can sleep. Wake device from low power state. (Please see PCI Power Management for descriptions of PCI Power Management and the related functions.) Hook into reboot_notifier_list (kernel/sys.c). Intended to stop any idling DMA operations. Useful for enabling wake-on-lan (NIC) or changing the power state of a device before reboot. e.g. drivers/net/e100.c. Optional driver callback to allow configuration of number of VFs to enable via sysfs \"sriov_numvfs\" file. PF Driver callback to change number of MSI-X vectors on a VF. Triggered via sysfs \"sriov_vf_msix_count\". This will change MSI-X Table Size in the VF Message Control registers. PF driver callback to get the total number of MSI-X vectors available for distribution to the VFs. Attributes attached to the device that will be created once it is bound to the driver. Device driver doesn't use kernel DMA API for DMA. For most device drivers, no need to care about this flag as long as all DMAs are handled through the kernel DMA API. For some special ones, for example VFIO drivers, they know how to manage the DMA themselves and set this flag so that the IOMMU layer will allow them to setup and manage their own I/O address space. The ID table is an array of entries ending with an all-zero entry. Definitions with static const are generally preferred. Device class, subclass, and \"interface\" to match. See Appendix D of the PCI Local Bus Spec or include/linux/pci_ids.h for a full list of classes. Most drivers do not need to specify class/class_mask as vendor/device is normally sufficient. Limit which sub-fields of the class field are compared. See drivers/scsi/sym53c8xx_2/ for example of usage. Data private to the driver. Most drivers don't need to use driver_data field. Best practice is to use driver_data as an index into a static list of equivalent device types, instead of using it as a pointer. Match only when dev->driver_override is this driver. Most drivers only need or to set up a pci_device_id table. New PCI IDs may be added to a device driver pci_ids table at runtime as shown below: All fields are passed in as hexadecimal values (no leading 0x). The vendor and device fields are mandatory, the others are optional. Users need pass only as many optional fields as necessary: Note that driver_data must match the value used by any of the pci_device_id entries defined in the driver. This makes the driver_data field mandatory if all the pci_device_id entries have a non-zero driver_data value. Once added, the driver probe routine will be invoked for any unclaimed PCI devices listed in its (newly updated) pci_ids list. When the driver exits, it just calls and the PCI layer automatically calls the remove hook for all devices handled by the driver. Please mark the initialization and cleanup functions where appropriate (the corresponding macros are defined in <linux/init.h>): Initialization code. Thrown away after the driver initializes. Tips on when/where to use the above attributes:\n• None The / functions (and all initialization functions called _only_ from these) should be marked __init/__exit.\n• None Do not mark the .\n• None Do NOT mark a function if you are not sure which mark to use. Better to not mark the function than mark the function wrong.\n\nAs noted in the introduction, most PCI drivers need the following steps for device initialization:\n• None Set the DMA mask size (for both coherent and streaming DMA) The driver can access PCI config space registers at any time. (Well, almost. When running BIST, config space can go away...but that will just result in a PCI Bus Master Abort and config reads will return garbage). Before touching any device registers, the driver needs to enable the PCI device by calling . This will:\n• None wake up the device if it was in suspended state,\n• None allocate I/O and memory regions of the device (if BIOS did not),\n• None allocate an IRQ (if BIOS did not). can fail! Check the return value. OS BUG: we don't check resource allocations before enabling those resources. The sequence would make more sense if we called pci_request_resources() before calling . Currently, the device drivers can't detect the bug when two devices have been allocated the same range. This is not a common problem and unlikely to get fixed soon. This has been discussed before but not changed as of 2.6.19: https://lore.kernel.org/r/20060302180025.GC28895@flint.arm.linux.org.uk/ will enable DMA by setting the bus master bit in the PCI_COMMAND register. It also fixes the latency timer value if it's set to something bogus by the BIOS. will disable DMA by clearing the bus master bit. If the PCI device can use the PCI Memory-Write-Invalidate transaction, call . This enables the PCI_COMMAND bit for Mem-Wr-Inval and also ensures that the cache line size register is set correctly. Check the return value of as not all architectures or chip-sets may support Memory-Write-Invalidate. Alternatively, if Mem-Wr-Inval would be nice to have but is not required, call to have the system do its best effort at enabling Mem-Wr-Inval. Memory (MMIO), and I/O port addresses should NOT be read directly from the PCI device config space. Use the values in the pci_dev structure as the PCI \"bus address\" might have been remapped to a \"host physical\" address by the arch/chip-set specific kernel support. See The io_mapping functions for how to access device registers or device memory. The device driver needs to call to verify no other device is already using the same address resource. Conversely, drivers should call AFTER calling . The idea is to prevent two devices colliding on the same address range. See OS BUG comment above. Currently (2.6.19), The driver can only determine MMIO and IO Port resource availability _after_ calling . Generic flavors of are request_mem_region() (for MMIO ranges) and request_region() (for IO Port ranges). Use these for address resources that are not described by \"normal\" PCI BARs. Also see below. If anything below doesn't make sense, please refer to Dynamic DMA mapping using the generic device. This section is just a reminder that drivers need to indicate DMA capabilities of the device and is not an authoritative source for DMA interfaces. While all drivers should explicitly indicate the DMA capability (e.g. 32 or 64 bit) of the PCI bus master, devices with more than 32-bit bus master capability for streaming data need the driver to \"register\" this capability by calling dma_set_mask() with appropriate parameters. In general this allows more efficient DMA on systems where System RAM exists above 4G _physical_ address. Drivers for all PCI-X and PCIe compliant devices must call dma_set_mask() as they are 64-bit DMA devices. Similarly, drivers must also \"register\" this capability if the device can directly address \"coherent memory\" in System RAM above 4G physical address by calling dma_set_coherent_mask(). Again, this includes drivers for all PCI-X and PCIe compliant devices. Many 64-bit \"PCI\" devices (before PCI-X) and some PCI-X devices are 64-bit DMA capable for payload (\"streaming\") data but not control (\"coherent\") data. Once the DMA masks are set, the driver can allocate \"coherent\" (a.k.a. shared) memory. See Dynamic DMA mapping using the generic device for a full description of the DMA APIs. This section is just a reminder that it needs to be done before enabling DMA on the device. Some drivers will need specific \"capability\" fields programmed or other \"vendor specific\" register initialized or reset. E.g. clearing pending interrupts. While calling is the last step described here, this is often just another intermediate step to initialize a device. This step can often be deferred until the device is opened for use. All interrupt handlers for IRQ lines should be registered with IRQF_SHARED and use the devid to map IRQs to devices (remember that all PCI IRQ lines can be shared). will associate an interrupt handler and device handle with an interrupt number. Historically interrupt numbers represent IRQ lines which run from the PCI device to the Interrupt controller. With MSI and MSI-X (more below) the interrupt number is a CPU \"vector\". also enables the interrupt. Make sure the device is quiesced and does not have any interrupts pending before registering the interrupt handler. MSI and MSI-X are PCI capabilities. Both are \"Message Signaled Interrupts\" which deliver interrupts to the CPU via a DMA write to a Local APIC. The fundamental difference between MSI and MSI-X is how multiple \"vectors\" get allocated. MSI requires contiguous blocks of vectors while MSI-X can allocate several individual ones. MSI capability can be enabled by calling with the PCI_IRQ_MSI and/or PCI_IRQ_MSIX flags before calling . This causes the PCI support to program CPU vector data into the PCI device capability registers. Many architectures, chip-sets, or BIOSes do NOT support MSI or MSI-X and a call to pci_alloc_irq_vectors with just the PCI_IRQ_MSI and PCI_IRQ_MSIX flags will fail, so try to always specify PCI_IRQ_LEGACY as well. Drivers that have different interrupt handlers for MSI/MSI-X and legacy INTx should chose the right one based on the msi_enabled and msix_enabled flags in the pci_dev structure after calling pci_alloc_irq_vectors. There are (at least) two really good reasons for using MSI:\n• None MSI is an exclusive interrupt vector by definition. This means the interrupt handler doesn't have to verify its device caused the interrupt.\n• None MSI avoids DMA/IRQ race conditions. DMA to host memory is guaranteed to be visible to the host CPU(s) when the MSI is delivered. This is important for both data coherency and avoiding stale control data. This guarantee allows the driver to omit MMIO reads to flush the DMA stream. See drivers/infiniband/hw/mthca/ or drivers/net/tg3.c for examples of MSI/MSI-X usage.\n\nWhen a PCI device driver is being unloaded, most of the following steps need to be performed:\n• None Unregister from other subsystems (e.g. scsi or netdev) How to do this is chip/device specific. If it's not done, it opens the possibility of a \"screaming interrupt\" if (and only if) the IRQ is shared with another device. When the shared IRQ handler is \"unhooked\", the remaining devices using the same IRQ line will still need the IRQ enabled. Thus if the \"unhooked\" device asserts IRQ line, the system will respond assuming it was one of the remaining devices asserted the IRQ line. Since none of the other devices will handle the IRQ, the system will \"hang\" until it decides the IRQ isn't going to get handled and masks the IRQ (100,000 iterations later). Once the shared IRQ is masked, the remaining devices will stop functioning properly. Not a nice situation. This is another reason to use MSI or MSI-X if it's available. MSI and MSI-X are defined to be exclusive interrupts and thus are not susceptible to the \"screaming interrupt\" problem. Once the device is quiesced (no more IRQs), one can call . This function will return control once any pending IRQs are handled, \"unhook\" the drivers IRQ handler from that IRQ, and finally release the IRQ if no one else is using it. It's extremely important to stop all DMA operations BEFORE attempting to deallocate DMA control data. Failure to do so can result in memory corruption, hangs, and on some chip-sets a hard crash. Stopping DMA after stopping the IRQs can avoid races where the IRQ handler might restart DMA engines. While this step sounds obvious and trivial, several \"mature\" drivers didn't get this step right in the past. Once DMA is stopped, clean up streaming DMA first. I.e. unmap data buffers and return buffers to \"upstream\" owners if there is one. Then clean up \"coherent\" buffers which contain the control data. See Dynamic DMA mapping using the generic device for details on unmapping interfaces. Most low level PCI device drivers support some other subsystem like USB, ALSA, SCSI, NetDev, Infiniband, etc. Make sure your driver isn't losing resources from that other subsystem. If this happens, typically the symptom is an Oops (panic) when the subsystem attempts to call into a driver that has been unloaded. io_unmap() MMIO or IO Port resources and then call . This is the symmetric opposite of . Do not access device registers after calling . Call to mark the MMIO or IO Port range as available. Failure to do so usually results in the inability to reload the driver.\n\nYou can use to access the config space of a device represented by . All these functions return 0 when successful or an error code ( ) which can be translated to a text string by pcibios_strerror. Most drivers expect that accesses to valid PCI devices don't fail. If you don't have a struct pci_dev available, you can call to access a given device and function on that bus. If you access fields in the standard portion of the config header, please use symbolic names of locations and bits declared in <linux/pci.h>. If you need to access Extended PCI Capability registers, just call for the particular capability and it will find the corresponding register block for you.\n\nWhen displaying PCI device names to the user (for example when a driver wants to tell the user what card has it found), please use pci_name(pci_dev). Always refer to the PCI devices by a pointer to the pci_dev structure. All PCI layer functions use this identification and it's the only reasonable one. Don't use bus/slot/function numbers except for very special purposes -- on systems with multiple primary buses their semantics can be pretty complex. Don't try to turn on Fast Back to Back writes in your driver. All devices on the bus need to be capable of doing it, so this is something which needs to be handled by platform and generic code, not individual drivers.\n\nConverting a driver from using I/O Port space to using MMIO space often requires some additional changes. Specifically, \"write posting\" needs to be handled. Many drivers (e.g. tg3, acenic, sym53c8xx_2) already do this. I/O Port space guarantees write transactions reach the PCI device before the CPU can continue. Writes to MMIO space allow the CPU to continue before the transaction reaches the PCI device. HW weenies call this \"Write Posting\" because the write completion is \"posted\" to the CPU before the transaction has reached its destination. Thus, timing sensitive code should add readl() where the CPU is expected to wait before doing other work. The classic \"bit banging\" sequence works fine for I/O Port space: The same sequence for MMIO space should be: It is important that \"safe_mmio_reg\" not have any side effects that interferes with the correct operation of the device. Another case to watch out for is when resetting a PCI device. Use PCI Configuration space reads to flush the writel(). This will gracefully handle the PCI master abort on all platforms if the PCI device is expected to not respond to a readl(). Most x86 platforms will allow MMIO reads to master abort (a.k.a. \"Soft Fail\") and return garbage (e.g. ~0). But many RISC platforms will crash (a.k.a.\"Hard Fail\")."
    },
    {
        "link": "https://stackoverflow.com/questions/20901221/pci-express-bar-memory-mapping-basic-understanding",
        "document": "i'm also working on device driver (albeit on linux) with a custom board. Here is my attempt on answering your questions:\n\nThe BARs represent memory windows as seen by the host system (CPUs) to talk to the device. The device doesn't write into that window but merely answers TLPs (Transaction Layer Packets) requests (MRd*, MWr*).\n\nI would say \"bus-specific\" = \"physical\" addresses if your architecture doesn't have a bus layer traslation mechanism. Check this thread for more info.\n\nIn all the x86 consumer PCs i've used so far, the BAR address seemed to be allocated either by the BIOS or at OS boot. The driver has to work with whatever address has been allocated.\n\nThe term DMA seems to abused instead of bus mastering which I believe is the correct term in PCIe. In PCIe every device may be a bus master (if allowed in its command register bit 2). It does so by sending MRd, MWr TLPs to other devices in the bus (but generally to the system memory) and signalling interrupts to the CPU."
    },
    {
        "link": "https://olegkutkov.me/2021/01/07/writing-a-pci-device-driver-for-linux",
        "document": "In this article, I want to discuss some basics of the Linux PCI/PCIe drivers development. I think this issue is not properly covered, and some existing information is might be outdated.\n\nI will show basic concepts and important structures, and this is might be a good beginner guide for newbie driver developers.\n\nThe PCI bus is the most popular way to connect high-speed peripheral inside a modern computer system. It’s a video and network adapters, sound cards, storage devices, etc. Some custom and special devices, some acquisition boards with ADC, or any other interface might be custom and special devices. Even your modern laptop uses this bus to connect internal devices to the CPU, even without actual physical connectors.\n\n This bus is widely available on a different platforms, like x86 and ARM. These days, it’s quite common to use a PCI bus to connect a high-performance wireless chip to the SoC inside WiFi routers.\n\nThe original PCI bus was parallel with a lot of contacts and is currently obsolete. I will not focus on the obsolete PCI bus.\n\n Modern and faster PCIe bus uses single or multiple (1-16) pairs of differential wires (lanes, one pair for TX, and one for RX). You can tell the number of differential lines by the bus name, x1, x4, and x16. More lanes give a bigger throughput. Another difference between the PCI Express bus and the older PCI is the bus topology; PCI uses a shared parallel bus architecture. PCI Express is based on point-to-point topology, with separate serial links connecting every device to the root complex controller that can be integrated into the CPU. The PCI host and all devices share a common set of address, data, and control lines. You can read an excellent architecture explanation in this Wikipedia article.\n\nFrom the typical driver’s point of view, there is no difference between PCI and PCI Express. All differences are handled by the hardware and lower bus drivers of the Linux kernel. For the driver developer, API is the same.\n\nThe operating system PCI subsystem reflects the actual hardware configuration and interconnections. There might be multiple PCI buses and multiple devices on those buses. Every bus and device is assigned a unique number, which allows identifying each module. Also, a PCI device might have different “functions” or “endpoints.” All those endpoints are also numbered. The full system path to the device might look like this: <bus id>:<device id>:<function id>\n\n Additionally, every PCI device contains factory-programmed Vendor and Device IDs. These IDs are also unique and assigned by the PCI regulatory consortium.\n\n The Linux kernel can properly identify a device and load the proper driver using these IDs. Of course, every driver should have ID verification routines.\n\nThe primary userspace utility is This command can show a lot of useful information. Run this command with “-nn” argument to get all devices with IDs.\n\nYou can see many internal PCIe devices here, bridges, USB controllers, Audio and Network controllers, etc. All this information can be obtained manually from the sysfs:\n\nThe human-readable strings are not taken from the hardware. This is a local database of the : /usr/share/hwdata/pci.id\n\n You can always find the latest PCI ID database here: https://pci-ids.ucw.cz/\n\n Or you can check the Vendor ID here: https://pcisig.com/membership/member-companies\n\nThe Linux kernel assigns special memory regions, “Base Address Registers” (BARs), to communicate with the hardware. These memory addresses (and region length) are written to the PCI controller hardware during the system boot.\n\n You can find something like this In :\n\nThere is no way to determine installed PCI hardware. So the bus must be enumerated. Bus enumeration is performed by attempting to read the vendor ID and device ID (VID/DID) register for each combination of the bus number and device number at the device’s function #0.\n\nThe kernel can call the corresponding driver during the enumeration stage with a compatible VID/PID pair. Some devices (like PCI bridges) might be statically described in the device tree in an embedded system. The static hardware configuration is supported with “platform drivers”.\n\nEvery PCI compliant device should implement a basic set of register – configuration registers.\n\n The Linux kernel attempts to read these registers to identify and properly configure the device. All these registers are mapped to the memory and available for the driver developer for reading and writing.\n\nThe first 64 bytes of the registers are mandatory and should be implemented (by the hardware vendor) in any case.\n\nThe optional registers may contain zero values if there is nothing to provide from the hardware.\n\nVendor ID and Device ID are already well known and should contain valid identifiers of the hardware vendor.\n\nCommand registers define some capabilities. The operating system initializes these bits.\n\nStatus register holds different events of the PCI bus and is filled by the hardware.\n\nClass code defines a class of the device (Network adapter, for example). The full list of the class codes can be found here: https://wiki.osdev.org/PCI#Class_Codes\n\nBase Address Registers – “BAR” registers filled by the Linux kernel and used for the IO operations.\n\nSubsystem Vendor ID and Subsystem Device ID – helps to differentiate specific board/device model. This is is optional, of course.\n\nThe Linux kernel PCI implementation can be found in the kernel source tree .\n\n For driver developers kernel provides a header file . Here you can find all the required structures and functions.\n\nThe main PCI driver structure is . This is quite a big structure representing an actual device and can be used for the register’s access and IO operations. Typically you don’t need to remember all fields of the structure, only basic concepts.\n\nPCI driver entry point is . The driver developer should initialize this structure (set callbacks) and pass it to the kernel.\n\nThe structure field “id_table” should be initialized with the IDs array. Those IDs define compatible Vendor and Product IDs for devices. You can set here multiple pairs of VID/PID if your driver supports multiple devices. For example, declare support of VID = 0F1F + PID = 0F0E, and VID = 0F2F + PID = 0F0D:\n\nIt’s important to end this array with a single zero value.\n\nMost drivers should export this table using .\n\nThis macro is doing a few important things.\n\n If your driver is built-in and compiled with the kernel, then the driver information (device IDs table) will be statically integrated into the global devices table. This allows the kernel to run your driver automatically when compatible hardware is found.\n\n If your driver is built as a separate module, then the device table can be extracted with utility. This information is added to a cache and automatically loads your driver kernel object when compatible hardware is found.\n\nOther important fields of the are:\n\n.name – unique driver name, this string will be displayed in \n\n .probe – A callback function called by the kernel after the driver registration.\n\n .remove – A callback function called by the kernel during the driver unloading.\n\n .suspend – A callback function called by kernel when the system is going to suspend mode.\n\n .resume – A callback function called when the system resumes after the suspend mode.\n\nConfigured pci_driver should be registered and unregistered during the driver module loading and unloading. This allows the kernel to run your driver.\n\nTo access PCI configuration registers kernel provides a set of functions:\n\nYou can read and write 8, 16, and 32-bit data.\n\nThe argument “where” specifies the actual register offset. All accessible values are defined in\n\nFor example, read PCI device Vendor ID and Product ID:\n\nRead the “Interrupt state” of the Status register:\n\nSure, the kernel has many other functions, but we will not discuss them there.\n\nActual device control and data communication is made through the mapped memory (BARs). It’s a little bit tricky.\n\n Of course, it’s just a memory region(s). What to read and write is depends on the actual hardware. It’s required to get actual offsets, data types, and “magic” numbers somewhere. Typically this is done through the reverse engineering of the Windows driver. But this is outside the scope of this article.\n\n Sometimes hardware vendors are kind enough to share their protocols and specifications.\n\nTo access the device memory, we need to request the memory region, start and stop offsets and map this memory region to some local pointer.\n\nNow it’s possible to use to read and write from/to the device. The only correct way is to use special kernel routines. The data can be read and written in the 8, 16, and 32-bit chunks.\n\nYou might note that there is an alternatively IO API that can be found in some drivers.\n\nOn x86 and ARM platforms, / functions are just inline wrappers around these / functions. But for better portability and compatibility, it’s highly recommended to use functions.\n\nThe high-performance device supports Direct Memory Access. This is implemented with bus mastering. Buse mastering is the capability of devices on the PCI bus to take control of the bus and perform transfers to the mapped memory directly.\n\nBus mastering (if supported) can be enabled and disabled with the following functions:\n\nInterrupt handling is critical in device drivers.\n\n Hardware may generate an interrupt on data reception event, error, state changes, and so on. All interrupts should be handled most optimally.\n\nThere are two types of PCI interrupts:\n• Pin-based (INTx) interrupts, an old and classic way\n• MSI/MSI-X interrupts, modern and more optimal way, introduced in PCI 2.2\n\nIt’s highly recommended to use MSI interrupts when possible. There are a few reasons why using MSIs can be advantageous over traditional pin-based interrupts.\n\nPin-based PCI interrupts are often shared amongst several devices. To support this, the kernel must call each interrupt handler associated with an interrupt, which leads to reduced performance for the system. MSIs are never shared, so this problem cannot arise.\n\nWhen a device writes data to memory, then raises a pin-based interrupt, the interrupt may arrive before all the data has arrived in memory (this becomes more likely with devices behind PCI-PCI bridges). The interrupt handler must read a register on the device that raised the interrupt to ensure that all the data has arrived in memory. PCI transaction ordering rules require that all the data arrive in memory before the value may be returned from the register. Using MSI’s avoids this problem as the interrupt-generating write cannot pass the data writes, so by the time the interrupt is raised, the driver knows that all the data has arrived in memory.\n\nPlease note that not all machines support MSIs correctly.\n\nYou can find information about currently allocated interrupts in /proc/interrupts\n\n This information contains interrupt spreads over the CPU cores and interrupts types (MSI or pin-based).\n\n Typically interrupts are dynamically set for the CPU cores. A special daemon tries to spread interrupts in the most optimal way on some systems.\n\nAlso, you can manually select the CPU core for the selected interrupt. This might be helpful in some fine-tuning situations.\n\n The core assignment can be done via the SMP affinity mechanism.\n\n Just select required cores (in a binary pattern) and send this value (as HEX number) to , where X is the interrupt number.\n\n For example, put IRQ 44 to the first and third cores (set bits 0 and 2, from left to right):\n\nNow let’s see how to use both types of interrupts.\n\nThe classic pin-based interrupt can be requested with and\n\nFor the new drivers, it’s recommended to use\n\nThe first parameter, specifies the interrupt number to allocate. For some devices, for example, legacy PC devices such as the system timer or keyboard, this value is typically hard-coded. It is probed or otherwise determined programmatically and dynamically for most other devices.\n\nThe second parameter, Is the function to be called when the IRQ occurs.\n\n– Function called from the IRQ handler thread. If NULL – no IRQ thread is created.\n\n– Interrupt type flags; Possible values can be found here.\n\n– The string passed to request_irq is used in to show the owner of the .\n\n– This pointer is used for shared interrupt lines. It is a unique identifier used when the interrupt line is freed, and the driver may also use that to point to its own private data area (to identify which device is interrupting).\n\n\n\nIn the end, all requested IRQs should be released with\n\nA simple example, install and use interrupt #42:\n\nIn the case of MSI/MSIX interrupts, everything is almost the same, but it’s required to tell the PCI subsystem that we want to use MSI/MSIX interrupts.\n\nUse the following function:\n\nThis function allocates up to max_vecs interrupt vectors for a PCI device. It returns the number of vectors allocated or a negative error.\n\nThe flags argument is used to specify which type of interrupt can be used by the device and the driver (PCI_IRQ_LEGACY, PCI_IRQ_MSI, PCI_IRQ_MSIX). A convenient short-hand (PCI_IRQ_ALL_TYPES) is also available to ask for any possible kind of interrupt. If the PCI_IRQ_AFFINITY flag is set, will spread the interrupts around the available CPUs.\n\nOf course, interrupt type (MSI/MSIX) and the number of MSI interrupts depend on your hardware.\n\nI think it’s enough with boring theory.\n\n This is an example of the PCI device driver. This driver can load and register for specified VID/PID pairs. Some basic operations (config registers read, memory read/write) are performed.\n\nI worked in the Crimean Astrophysical observatory a few years ago and found a PCI interface board for 4 incremental linear or angular encoders. I decided to use this board, but there was no Linux driver.\n\n I contacted the vendor and proposed to them to write an open-source driver for Linux. They were kind enough and proposed the full documentation.\n\n This was a table with memory offsets and data sizes. Basically, at which offsets I can read sensor data and so on.\n\nI wrote this driver. The driver uses a character device interface to interact with the user.\n\n It’s quite simple and might be a good example to start PCI driver development."
    },
    {
        "link": "http://nixhacker.com/playing-with-pci-device-memory",
        "document": "In this new series of articles, we will learn about firmware security, i.e things like What included as firmware in a computer? What are the attack vectors? How to protect your firmware? etc. In the first part of the series, I will take you through basic of PCI device and its memory, since everything in firmware somehow depend on them, so you have to learn these before getting more into security specific stuff.\n\nPeripheral Component Interconnect (PCI) is a specification used for connection of computer buses or peripherals devices in motherboard. It is a 32 bit bus which can support 64 bit data transfer by performing 2 32 bit reads. It is an upgraded replacement of ISA bus which only supports 16 bit data transfer. Now PCI is revised with PCIe with almost similar firmware specification but much improved performance.\n\nEach PCI bus have devices attached and each device have functions. The topology for PCI bus looks like this:\n\nA common way to represent a specific device is using the following format B:D:F (eg 00:1f:0 is LPC controller in my system).\n\nYou can check all the PCI devices attached to your processor in linux using command.\n\nEach PCI device has a PCI Configuration space which is used to store configuration registers. Configuration registers are used for device configuration and communication purposes like identify the device, amount of memory and I/O address space needed by each device, maximum space required by the device etc.\n\nEach PCI device has upto 256 bytes of configuration space whereas PCIe device has 256 bytes + 4KB of extended configuration space. Out of 256 bytes, first 40 bytes are header and remaining bytes are device dependent region.\n\nThe registers structure of the header looks mostly like this(differ for PCI-to-PCI bridge and CardBus bridge).\n\nLet's take a look at few registers description, remaining we will check later when they are required.\n\nVendor Id: Identifies the manufacturer of the device. For eg: for intel devices, for nvidia device.\n\nDevice Id: Identifies the particular device by a vendor.\n\nHeader Type: Identifies the layout of the rest of the header that begins at byte of the header and also specifies whether the device has multiple functions. They can be of three types:\n• Type 0: General Device. (Most common one and the one we care in this article.\n\nYou can take a look at header structure for each header here: https://wiki.osdev.org/PCI.\n\nA PCI device configuration space can be accessed using either a through memory request or I/O request. Most PCI device has both mechanism available but PCIe can only be accessed using memory mapped area (sometime I/O access available for Backward compatibility).\n\nBit 0 in Command register is set then device will respond to I/O space access.\n\n Bit 1 in Command register is set then device will respond to memory space access.\n\nThe configuration space can only be accessed from kernel mode, so we will create a simple kernel module for everything we perform below.\n\nA simple layout of kernel module and Makefile for kernel module will look like this:\n\nTwo 32 bit I/O port locations are used to generate configuration space transaction\n\n(equivalent of IN operation) is used to define the specific pci device and offset you want to retrieve. The DWORD data get returned using (OUT operation).\n\n32 bit structure for defines like this:\n• When bit 31 is set, then only all read and write to CONFIG_DATA will be treated as configuration transaction.\n• Bit 24:30 are reserved and should return 0 on read.\n• You need to define the B::D::F and offset of configuration space to receive the DWORD value present on that device at a given offset.\n\nWe can use and calls from driver for I/O port operation.\n\nAfter loading the driver you can check the output using\n\nYou can verify your output using chipsec framework. Installation steps are mentioned in repo link.\n\nTo access the pci device configuration space, you can use following command.\n\nThe output will look like this:\n\nAnother way to access PCI device configuration space is using memory space. Each device is mapped to physical memory, where normal operations like read, write can be performed. For PCI, the memory access is optional but in PCIe device it is mostly the only way available to access PCI data.\n\nWe can get the memory mapped configuration space using the following process:\n\nFirst, find the specific device in the system from list of pci devices.\n\nThis function scans the list of PCI devices currently present in the system, and if the input arguments match the specified and IDs, it increments the reference count on the variable found, and returns it to the caller.\n\nAccess the data in BYTE, WORD or DWORD size.\n\nPerform write using the following calls:\n\nAfter the driver is done with the returned by the function, it must call the function to decrement the usage count properly back to allow the kernel to clean up the device if it is removed.\n\nFinding the vendor id and device name\n\nYou may think that, to find the device using we need and but those value can be found on configuration space only. If you don't have access to configuration space then you can look at device datasheet to get the correct and .\n\nYou can also cheat the value from linux pci maintenance code. First bytes are mapped to following file location .\n\nAnother way already mentioned above is using chipsec tool.\n\nSo, now let's write the code to retrieve first 4 bytes from device 0:0:0 (DRAM controller in most cases) from MMIO.\n\nYou will get similar output in .\n\nAgain, you can verify the output using chipsec.\n\nBase address registers(BAR) starts at an address in the configuration space and will be total 6(BAR[0] to BAR[5]) in number. BARs hold the memory addresses range used by the device. Structure of this register looks like this:\n\nCleared bit 0 indicate the device is mapped at memory location.\n\nUsing above structure, you can derive that, to get the base address, you need to it with i.e .\n\nEach memory block defined by BAR has limit along with base address.\n\nTo find the limit, you can write all 1's in that BAR and (NOT) the output. i.e .\n\nNow let's write a program to get the base address and limit of a BAR.\n\nYou will receive the similar kind of output in kernel logs:\n\nWe can read data directly at a physical address using chipsec. To verify if the base address is correct, read that physical memory location before writing the (to get the BAR limit) to the BAR and check the bytes. After writing to BAR, check the base address again. You will notice the bytes get replaced with . This happens because after changing the BAR, the device is no longer mapped to the previous location.\n\nYou can use following chipsec syntax to read physical memory\n\nEx: For BAR , data at base address before and after changing base address.\n\nLet's move to more recent protocol PCIe related stuff. PCIe has up to 4kb of configuration space(PCI config space + extended config space), which is always mapped to memory and cannot be accessed using the legacy PCI method (through ports and ). The extended space can be located either just after the 256 byte of configuration space or at MMIO location specify by RCRB (Root Complex Register Block).\n\nTill now, we have accessed the memory mapped configuration space using but we can also manually access the physical address where the configuration space is mapped, only if we know the Base address of PCI configuration space. This will also help to access the PCIe configuration space.\n\nBIOS on boot set PCIEXBAR register(64 bit) to a memory location where it wants the memory controller to start routine to PCI space. The space structure looks like this.\n\nYou can use following decoding to read an offset in a PCI device using PCIEXBAR.\n\nFinding PCIEXBAR: You can check your processor datasheet to confirm the PCI device and offset, where the PCIEXBAR register is located. For intel processor you can download the datasheets from here. For the processor that I am using(Intel 4th gen), this register is located at 0:0:0 (DRAM Controller) at offset .\n\nUsing the above information, let's try to access the first 4 bytes of device 0:0:0.\n\nYou will receive the similar output:\n\nYou can now retrieve the data using chipsec:\n\nThe returned data should be present at configuration space for device 0:0:0 at offset . After 256 bytes you will start seeing the bytes from extended configuration space.\n\nYou can find the sample code from the post here.\n\nWe have already cover enough stuff about PCI devices memory till now, so it's time to end this part here. In the next part, we will discuss PCI expansion roms and majorly go through security issues related to PCI based architecture. Stay tuned!!"
    },
    {
        "link": "https://stackoverflow.com/questions/40395221/pci-e-memory-space-access-with-mmap",
        "document": "I'm using PCI-e port on Freescale MPC8308 processor (which is based on PowerPC architecture) and I have some problems when trying to use it. The endpoint PCI-e device has memory space equal to 256 MB. I can easily read and write configuration space of the endpoint device by using \"pciutils\" package.\n\nAfter writing correct values in configuration registers and getting the permission to access the memory space; I tried to access memory space by using \"mmap()\" function in C and used the file descriptor located at :\n\nwhich was exactly 256 MB (equal to memory space of endpoint device) so it seems that I am using correct path for file descriptor. here you can find my code using \"mmap()\" as mentioned in https://github.com/billfarrow/pcimem:\n\nBut unfortunately when I try to use memory space by using returned address of \"mmap()\" function; I cannot read the read-only registers of endpoint device correctly. Also, when I read addresses bigger than \"0x7FFFFFC\", the MPC8308 reboots. Considering above situation, do I miss any steps to initialize the PCI-e interface? Should I change anything in the Linux kernel image or U-Boot codes? Is there anything different for using PowerPC PCI-e with mmap()? Do you have any example code that can help me read PCI-e memory space?"
    },
    {
        "link": "https://oreilly.com/library/view/linux-device-drivers/0596000081/ch13s02.html",
        "document": "Memory mapping is one of the most interesting features of modern Unix systems. As far as drivers are concerned, memory mapping can be used to provide user programs with direct access to device memory.\n\nA definitive example of mmap usage can be seen by looking at a subset of the virtual memory areas for the X Window System server:\n\nThe full list of the X server’s VMAs is lengthy, but most of the entries are not of interest here. We do see, however, three separate mappings of , which give some insight into how the X server works with the video card. The first mapping shows a 16 KB region mapped at . This address is far above the highest RAM address on the system; it is, instead, a region of memory on a PCI peripheral (the video card). It will be a control region for that card. The middle mapping is at , which is the standard location for video RAM in the 640 KB ISA hole. The last mapping is a rather larger one at and is the video memory itself. These regions can also be seen in :\n\nMapping a device means associating a range of user-space addresses to device memory. Whenever the program reads or writes in the assigned address range, it is actually accessing the device. In the X server example, using mmap allows quick and easy access to the video card’s memory. For a performance-critical application like this, direct access makes a large difference.\n\nAs you might suspect, not every device lends itself to the mmap abstraction; it makes no sense, for instance, for serial ports and other stream-oriented devices. Another limitation of mmap is that mapping is grained. The kernel can dispose of virtual addresses only at the level of page tables; therefore, the mapped area must be a multiple of and must live in physical memory starting at an address that is a multiple of . The kernel accommodates for size granularity by making a region slightly bigger if its size isn’t a multiple of the page size.\n\nThese limits are not a big constraint for drivers, because the program accessing the device is device dependent anyway. It needs to know how to make sense of the memory region being mapped, so the alignment is not a problem. A bigger constraint exists when ISA devices are used on some non-x86 platforms, because their hardware view of ISA may not be contiguous. For example, some Alpha computers see ISA memory as a scattered set of 8-bit, 16-bit, or 32-bit items, with no direct mapping. In such cases, you can’t use mmap at all. The inability to perform direct mapping of ISA addresses to Alpha addresses is due to the incompatible data transfer specifications of the two systems. Whereas early Alpha processors could issue only 32-bit and 64-bit memory accesses, ISA can do only 8-bit and 16-bit transfers, and there’s no way to transparently map one protocol onto the other.\n\nThere are sound advantages to using mmap when it’s feasible to do so. For instance, we have already looked at the X server, which transfers a lot of data to and from video memory; mapping the graphic display to user space dramatically improves the throughput, as opposed to an lseek/write implementation. Another typical example is a program controlling a PCI device. Most PCI peripherals map their control registers to a memory address, and a demanding application might prefer to have direct access to the registers instead of repeatedly having to call ioctl to get its work done.\n\nThe mmap method is part of the structure and is invoked when the mmap system call is issued. With mmap, the kernel performs a good deal of work before the actual method is invoked, and therefore the prototype of the method is quite different from that of the system call. This is unlike calls such as ioctl and poll, where the kernel does not do much before calling the method.\n\nThe system call is declared as follows (as described in the mmap(2) manual page):\n\nOn the other hand, the file operation is declared as\n\nThe argument in the method is the same as that introduced in Chapter 3, while contains the information about the virtual address range that is used to access the device. Much of the work has thus been done by the kernel; to implement mmap, the driver only has to build suitable page tables for the address range and, if necessary, replace with a new set of operations.\n\nThere are two ways of building the page tables: doing it all at once with a function called remap_page_range, or doing it a page at a time via the nopage VMA method. Both methods have their advantages. We’ll start with the “all at once” approach, which is simpler. From there we will start adding the complications needed for a real-world implementation.\n\nAs we have seen, the structure contains a set of operations that may be applied to the VMA. Now we’ll look at providing those operations in a simple way; a more detailed example will follow later on. Here, we will provide open and close operations for our VMA. These operations will be called anytime a process opens or closes the VMA; in particular, the open method will be invoked anytime a process forks and creates a new reference to the VMA. The open and close VMA methods are called in addition to the processing performed by the kernel, so they need not reimplement any of the work done there. They exist as a way for drivers to do any additional processing that they may require. We’ll use these methods to increment the module usage count whenever the VMA is opened, and to decrement it when it’s closed. In modern kernels, this work is not strictly necessary; the kernel will not call the driver’s release method as long as a VMA remains open, so the usage count will not drop to zero until all references to the VMA are closed. The 2.0 kernel, however, did not perform this tracking, so portable code will still want to be able to maintain the usage count. So, we will override the default with operations that keep track of the usage count. The code is quite simple—a complete mmap implementation for a modularized looks like the following: This code relies on the fact that the kernel initializes to the field in the newly created area before calling . The code just shown checks the current value of the pointer as a safety measure, should something change in future kernels. The strange macro that appears in this code is used to hide a difference in the structure across kernel versions. Since the offset is a number of pages in 2.4 and a number of bytes in 2.2 and earlier kernels, declares the macro to make the difference transparent (and the result is expressed in bytes).\n\nAlthough remap_page_range works well for many, if not most, driver mmap implementations, sometimes it is necessary to be a little more flexible. In such situations, an implementation using the nopage VMA method may be called for. The nopage method, remember, has the following prototype: When a user process attempts to access a page in a VMA that is not present in memory, the associated nopage function is called. The parameter will contain the virtual address that caused the fault, rounded down to the beginning of the page. The nopage function must locate and return the pointer that refers to the page the user wanted. This function must also take care to increment the usage count for the page it returns by calling the get_page macro: This step is necessary to keep the reference counts correct on the mapped pages. The kernel maintains this count for every page; when the count goes to zero, the kernel knows that the page may be placed on the free list. When a VMA is unmapped, the kernel will decrement the usage count for every page in the area. If your driver does not increment the count when adding a page to the area, the usage count will become zero prematurely and the integrity of the system will be compromised. One situation in which the nopage approach is useful can be brought about by the mremap system call, which is used by applications to change the bounding addresses of a mapped region. If the driver wants to be able to deal with mremap, the previous implementation won’t work correctly, because there’s no way for the driver to know that the mapped region has changed. The Linux implementation of mremap doesn’t notify the driver of changes in the mapped area. Actually, it does notify the driver if the size of the area is reduced via the unmap method, but no callback is issued if the area increases in size. The basic idea behind notifying the driver of a reduction is that the driver (or the filesystem mapping a regular file to memory) needs to know when a region is unmapped in order to take the proper action, such as flushing pages to disk. Growth of the mapped region, on the other hand, isn’t really meaningful for the driver until the program invoking mremap accesses the new virtual addresses. In real life, it’s quite common to map regions that are never used (unused sections of program code, for example). The Linux kernel, therefore, doesn’t notify the driver if the mapped region grows, because the nopage method will take care of pages one at a time as they are actually accessed. In other words, the driver isn’t notified when a mapping grows because nopage will do it later, without having to use memory before it is actually needed. This optimization is mostly aimed at regular files, whose mapping uses real RAM. The nopage method, therefore, must be implemented if you want to support the mremap system call. But once you have nopage, you can choose to use it extensively, with some limitations (described later). This method is shown in the next code fragment. In this implementation of mmap, the device method only replaces . The nopage method takes care of “remapping” one page at a time and returning the address of its structure. Because we are just implementing a window onto physical memory here, the remapping step is simple—we need only locate and return a pointer to the for the desired address. An implementation of using nopage looks like the following: Since, once again, we are simply mapping main memory here, the nopage function need only find the correct for the faulting address and increment its reference count. The required sequence of events is thus to calculate the desired physical address, turn it into a logical address with __va, and then finally to turn it into a with virt_to_page. It would be possible, in general, to go directly from the physical address to the , but such code would be difficult to make portable across architectures. Such code might be necessary, however, if one were trying to map high memory, which, remember, has no logical addresses. simple, being simple, does not worry about that (rare) case. If the nopage method is left , kernel code that handles page faults maps the zero page to the faulting virtual address. The zero page is a copy-on-write page that reads as zero and that is used, for example, to map the BSS segment. Therefore, if a process extends a mapped region by calling mremap, and the driver hasn’t implemented nopage, it will end up with zero pages instead of a segmentation fault. The nopage method normally returns a pointer to a . If, for some reason, a normal page cannot be returned (e.g., the requested address is beyond the device’s memory region), can be returned to signal the error. nopage can also return to indicate failures caused by resource limitations. Note that this implementation will work for ISA memory regions but not for those on the PCI bus. PCI memory is mapped above the highest system memory, and there are no entries in the system memory map for those addresses. Because there is thus no to return a pointer to, nopage cannot be used in these situations; you must, instead, use remap_page_range.\n\nAll the examples we’ve seen so far are reimplementations of ; they remap physical addresses into user space. The typical driver, however, wants to map only the small address range that applies to its peripheral device, not all of memory. In order to map to user space only a subset of the whole memory range, the driver needs only to play with the offsets. The following lines will do the trick for a driver mapping a region of bytes, beginning at physical address (which should be page aligned). unsigned long off = vma->vm_pgoff << PAGE_SHIFT; unsigned long physical = simple_region_start + off; unsigned long vsize = vma->vm_end - vma->vm_start; unsigned long psize = simple_region_size - off; if (vsize > psize) return -EINVAL; /* spans too high */ remap_page_range(vma_>vm_start, physical, vsize, vma->vm_page_prot); In addition to calculating the offsets, this code introduces a check that reports an error when the program tries to map more memory than is available in the I/O region of the target device. In this code, is the physical I/O size that is left after the offset has been specified, and is the requested size of virtual memory; the function refuses to map addresses that extend beyond the allowed memory range. Note that the user process can always use mremap to extend its mapping, possibly past the end of the physical device area. If your driver has no nopage method, it will never be notified of this extension, and the additional area will map to the zero page. As a driver writer, you may well want to prevent this sort of behavior; mapping the zero page onto the end of your region is not an explicitly bad thing to do, but it is highly unlikely that the programmer wanted that to happen. The simplest way to prevent extension of the mapping is to implement a simple nopage method that always causes a bus signal to be sent to the faulting process. Such a method would look like this:\n\nOf course, a more thorough implementation could check to see if the faulting address is within the device area, and perform the remapping if that is the case. Once again, however, nopage will not work with PCI memory areas, so extension of PCI mappings is not possible. In Linux, a page of physical addresses is marked as “reserved” in the memory map to indicate that it is not available for memory management. On the PC, for example, the range between 640 KB and 1 MB is marked as reserved, as are the pages that host the kernel code itself. An interesting limitation of remap_page_range is that it gives access only to reserved pages and physical addresses above the top of physical memory. Reserved pages are locked in memory and are the only ones that can be safely mapped to user space; this limitation is a basic requirement for system stability. Therefore, remap_page_range won’t allow you to remap conventional addresses—which include the ones you obtain by calling get_free_page. Instead, it will map in the zero page. Nonetheless, the function does everything that most hardware drivers need it to, because it can remap high PCI buffers and ISA memory. The limitations of remap_page_range can be seen by running mapper, one of the sample programs in in the files provided on the O’Reilly FTP site. mapper is a simple tool that can be used to quickly test the mmap system call; it maps read-only parts of a file based on the command-line options and dumps the mapped region to standard output. The following session, for instance, shows that doesn’t map the physical page located at address 64 KB—instead we see a page full of zeros (the host computer in this examples is a PC, but the result would be the same on other platforms): The inability of remap_page_range to deal with RAM suggests that a device like scullp can’t easily implement mmap, because its device memory is conventional RAM, not I/O memory. Fortunately, a relatively easy workaround is available to any driver that needs to map RAM into user space; it uses the nopage method that we have seen earlier. The way to map real RAM to user space is to use to deal with page faults one at a time. A sample implementation is part of the scullp module, introduced in Chapter 7. scullp is the page oriented char device. Because it is page oriented, it can implement mmap on its memory. The code implementing memory mapping uses some of the concepts introduced earlier in Section 13.1.” Before examining the code, let’s look at the design choices that affect the mmap implementation in scullp.\n• None scullp doesn’t release device memory as long as the device is mapped. This is a matter of policy rather than a requirement, and it is different from the behavior of scull and similar devices, which are truncated to a length of zero when opened for writing. Refusing to free a mapped scullp device allows a process to overwrite regions actively mapped by another process, so you can test and see how processes and device memory interact. To avoid releasing a mapped device, the driver must keep a count of active mappings; the field in the device structure is used for this purpose.\n• None Memory mapping is performed only when the scullp parameter is 0. The parameter controls how get_free_pages is invoked (see Chapter 7, Section 7.3). This choice is dictated by the internals of get_free_pages, the allocation engine exploited by scullp. To maximize allocation performance, the Linux kernel maintains a list of free pages for each allocation order, and only the page count of the first page in a cluster is incremented by get_free_pages and decremented by free_pages. The mmap method is disabled for a scullp device if the allocation order is greater than zero, because nopage deals with single pages rather than clusters of pages. (Return to Section 7.3.1 in Chapter 7 if you need a refresher on scullp and the memory allocation order value.) The last choice is mostly intended to keep the code simple. It is possible to correctly implement mmap for multipage allocations by playing with the usage count of the pages, but it would only add to the complexity of the example without introducing any interesting information. Code that is intended to map RAM according to the rules just outlined needs to implement open, close, and nopage; it also needs to access the memory map to adjust the page usage counts. This implementation of scullp_mmap is very short, because it relies on the nopage function to do all the interesting work: int scullp_mmap(struct file *filp, struct vm_area_struct *vma) { struct inode *inode = INODE_FROM_F(filp); /* refuse to map if order is not 0 */ if (scullp_devices[MINOR(inode->i_rdev)].order) return -ENODEV; /* don't do anything here: \"nopage\" will fill the holes */ vma->vm_ops = &scullp_vm_ops; vma->vm_flags |= VM_RESERVED; vma->vm_private_data = scullp_devices + MINOR(inode->i_rdev); scullp_vma_open(vma); return 0; } The purpose of the leading conditional is to avoid mapping devices whose allocation order is not 0. scullp’s operations are stored in the field, and a pointer to the device structure is stashed in the field. At the end, is called to update the usage count for the module and the count of active mappings for the device. open and close simply keep track of these counts and are defined as follows: The function sculls_vma_to_dev simply returns the contents of the field. It exists as a separate function because kernel versions prior to 2.4 lacked that field, requiring that other means be used to get that pointer. See Section 13.5 at the end of this chapter for details. Most of the work is then performed by nopage. In the scullp implementation, the parameter to nopage is used to calculate an offset into the device; the offset is then used to look up the correct page in the scullp memory tree. struct page *scullp_vma_nopage(struct vm_area_struct *vma, unsigned long address, int write) { unsigned long offset; ScullP_Dev *ptr, *dev = scullp_vma_to_dev(vma); struct page *page = NOPAGE_SIGBUS; void *pageptr = NULL; /* default to \"missing\" */ down(&dev->sem); offset = (address - vma->vm_start) + VMA_OFFSET(vma); if (offset >= dev->size) goto out; /* out of range */ /* * Now retrieve the scullp device from the list, then the page. * If the device has holes, the process receives a SIGBUS when * accessing the hole. */ offset >>= PAGE_SHIFT; /* offset is a number of pages */ for (ptr = dev; ptr && offset >= dev->qset;) { ptr = ptr->next; offset -= dev->qset; } if (ptr && ptr->data) pageptr = ptr->data[offset]; if (!pageptr) goto out; /* hole or end-of-file */ page = virt_to_page(pageptr); /* got it, now increment the count */ get_page(page); out: up(&dev->sem); return page; } scullp uses memory obtained with get_free_pages. That memory is addressed using logical addresses, so all scullp_nopage has to do to get a pointer is to call virt_to_page. The scullp device now works as expected, as you can see in this sample output from the mapper utility. Here we send a directory listing of (which is long) to the scullp device, and then use the mapper utility to look at pieces of that listing with mmap. morgana% ls -l /dev > /dev/scullp morgana% ./mapper /dev/scullp 0 140 mapped \"/dev/scullp\" from 0 to 140 total 77 -rwxr-xr-x 1 root root 26689 Mar 2 2000 MAKEDEV crw-rw-rw- 1 root root 14, 14 Aug 10 20:55 admmidi0 morgana% ./mapper /dev/scullp 8192 200 mapped \"/dev/scullp\" from 8192 to 8392 0 crw -- -- -- - 1 root root 113, 1 Mar 26 1999 cum1 crw -- -- -- - 1 root root 113, 2 Mar 26 1999 cum2 crw -- -- -- - 1 root root 113, 3 Mar 26 1999 cum3\n\nAlthough it’s rarely necessary, it’s interesting to see how a driver can map a virtual address to user space using mmap. A true virtual address, remember, is an address returned by a function like vmalloc or kmap—that is, a virtual address mapped in the kernel page tables. The code in this section is taken from scullv, which is the module that works like scullp but allocates its storage through vmalloc. Most of the scullv implementation is like the one we’ve just seen for scullp, except that there is no need to check the parameter that controls memory allocation. The reason for this is that vmalloc allocates its pages one at a time, because single-page allocations are far more likely to succeed than multipage allocations. Therefore, the allocation order problem doesn’t apply to vmalloced space. Most of the work of vmalloc is building page tables to access allocated pages as a continuous address range. The nopage method, instead, must pull the page tables back apart in order to return a pointer to the caller. Therefore, the nopage implementation for scullv must scan the page tables to retrieve the page map entry associated with the page. The function is similar to the one we saw for scullp, except at the end. This code excerpt only includes the part of nopage that differs from scullp: pgd_t *pgd; pmd_t *pmd; pte_t *pte; unsigned long lpage; /* * After scullv lookup, \"page\" is now the address of the page * needed by the current process. Since it's a vmalloc address, * first retrieve the unsigned long value to be looked up * in page tables. */ lpage = VMALLOC_VMADDR(pageptr); spin_lock(&init_mm.page_table_lock); pgd = pgd_offset(&init_mm, lpage); pmd = pmd_offset(pgd, lpage); pte = pte_offset(pmd, lpage); page = pte_page(*pte); spin_unlock(&init_mm.page_table_lock); /* got it, now increment the count */ get_page(page); out: up(&dev->sem); return page; The page tables are looked up using the functions introduced at the beginning of this chapter. The page directory used for this purpose is stored in the memory structure for kernel space, . Note that scullv obtains the prior to traversing the page tables. If that lock were not held, another processor could make a change to the page table while scullv was halfway through the lookup process, leading to erroneous results. The macro returns the correct value to be used in a page-table lookup from a vmalloc address. A simple cast of the value wouldn’t work on the x86 with kernels older than 2.1, because of a glitch in memory management. Memory management for the x86 changed in version 2.1.1, and is now defined as the identity function, as it has always been for the other platforms. Its use is still suggested, however, as a way of writing portable code. Based on this discussion, you might also want to map addresses returned by ioremap to user space. This mapping is easily accomplished because you can use remap_page_range directly, without implementing methods for virtual memory areas. In other words, remap_page_range is already usable for building new page tables that map I/O memory to user space; there’s no need to look in the kernel page tables built by vremap as we did in scullv."
    },
    {
        "link": "https://stackoverflow.com/questions/40115097/linux-mmap-access-to-pci-memory-region-from-user-space-application",
        "document": "As a first level test of my PCI driver I hoped I could gain access to the pci_iomap region via the /sys/bus/pci/devices/0000:01:00.0/resource0 file from my user application. The man page for mmap, the sample Program I found, and other posts seem to indicate that user process access should work. But some articles seem to indicate that the mmap call needs to be done from within the kernel via an ioctl accessor.\n\nMy Question is should mmap() of the PCI sysfs resource file work from application space?\n\nWhen I run my code mmap returns what looks like a valid address but I get a Bus error when I try and access the virtual address. I believe my end device a PCI to Xilinx AXI bridge which is on the FPGA is functioning ok since I can R/W to it over a windows PCIe utilty (Win Driver) I am on an NXP LS1021A ARM7 processor with Linux ver 3.12.37.\n\nNot that I want anyone to debug my code but what I am doing may be best explained by the code so I have included it also. I apologies if the pasted code doesn't display correctly. Hopefully it does.\n\nI run the code below and get root@ls1021aiot:~# pcimem /sys/bus/pci/devices/0000:01:00.0/resource0 0 w\n\n/sys/bus/pci/devices/0000:01:00.0/resource0 opened. Target offset is 0x0, page size is 4096 map mask is 0xFFF mmap(0, 4096, 0x3, 0x1, 3, 0x0) mmap(0, 4096, 0x3, 0x1, 3, 0x0) PCI Memory mapped 4096 byte region to map_base 0x76fb5000. PCI Memory mapped access 0x 76FB5000. Bus error"
    },
    {
        "link": "https://linuxquestions.org/questions/programming-9/mmap-tutorial-c-c-511265",
        "document": "Programming This forum is for all programming questions.\n\n The question does not have to be directly related to Linux and any language is fair game. \n\n \n\n \n\n \n\n I have read through \n\n \n\n Does anyone have any good examples of mmap that write to a file? I am trying to learn how to use mmap and am actively looking for a good tutorial, or a set of good examples that demonstrate mmap use.I have read through Memory Mapped Files , but it only demonstrates mmap with a read example. I realize that this example recommends simply using PROT_WRITE to write to a file, however I have tried doing so and get a Segmentation Fault when I run my program.Does anyone have any good examples of mmap that write to a file? I'm not 100% sure, but I think if you write to a memory-mapped file the space must already exist in the file. (i.e., if you mmap 1 meg, the file must be at least 1 meg.) I don't think mmap will append bytes to the end of a file. \n\n #include <stdio.h> #include <stdlib.h> #include <sys/types.h> #include <sys/stat.h> #include <unistd.h> #include <fcntl.h> #include <sys/mman.h> #define FILEPATH \"/tmp/mmapped.bin\" #define NUMINTS (1000) #define FILESIZE (NUMINTS * sizeof(int)) int main(int argc, char *argv[]) { int i; int fd; int result; int *map; /* mmapped array of int's */ /* Open a file for writing. * - Creating the file if it doesn't exist. * - Truncating it to 0 size if it already exists. (not really needed) * * Note: \"O_WRONLY\" mode is not sufficient when mmaping. */ fd = open(FILEPATH, O_RDWR | O_CREAT | O_TRUNC, (mode_t)0600); if (fd == -1) { perror(\"Error opening file for writing\"); exit(EXIT_FAILURE); } /* Stretch the file size to the size of the (mmapped) array of ints */ result = lseek(fd, FILESIZE-1, SEEK_SET); if (result == -1) { close(fd); perror(\"Error calling lseek() to 'stretch' the file\"); exit(EXIT_FAILURE); } /* Something needs to be written at the end of the file to * have the file actually have the new size. * Just writing an empty string at the current file position will do. * * Note: * - The current position in the file is at the end of the stretched * file due to the call to lseek(). * - An empty string is actually a single '\\0' character, so a zero-byte * will be written at the last byte of the file. */ result = write(fd, \"\", 1); if (result != 1) { close(fd); perror(\"Error writing last byte of the file\"); exit(EXIT_FAILURE); } /* Now the file is ready to be mmapped. */ map = mmap(0, FILESIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); if (map == MAP_FAILED) { close(fd); perror(\"Error mmapping the file\"); exit(EXIT_FAILURE); } /* Now write int's to the file as if it were memory (an array of ints). */ for (i = 1; i <=NUMINTS; ++i) { map[i] = 2 * i; } /* Don't forget to free the mmapped memory */ if (munmap(map, FILESIZE) == -1) { perror(\"Error un-mmapping the file\"); /* Decide here whether to close(fd) and exit() or not. Depends... */ } /* Un-mmaping doesn't close the file, so we still need to do that. */ close(fd); return 0; } Reading the file created by the example above, is simpler as we don't need to create a file and \"stretch\" it to the mmapped size. So just remove that part, and open the file for reading only, and remove the PROT_WRITE flag from the mmap call.\n\n \n\n #include <stdio.h> #include <stdlib.h> #include <sys/types.h> #include <sys/stat.h> #include <unistd.h> #include <fcntl.h> #include <sys/mman.h> #define FILEPATH \"/tmp/mmapped.bin\" #define NUMINTS (1000) #define FILESIZE (NUMINTS * sizeof(int)) int main(int argc, char *argv[]) { int i; int fd; int *map; /* mmapped array of int's */ fd = open(FILEPATH, O_RDONLY); if (fd == -1) { perror(\"Error opening file for reading\"); exit(EXIT_FAILURE); } map = mmap(0, FILESIZE, PROT_READ, MAP_SHARED, fd, 0); if (map == MAP_FAILED) { close(fd); perror(\"Error mmapping the file\"); exit(EXIT_FAILURE); } /* Read the file int-by-int from the mmap */ for (i = 1; i <=NUMINTS; ++i) { printf(\"%d: %d\n\n\", i, map[i]); } if (munmap(map, FILESIZE) == -1) { perror(\"Error un-mmapping the file\"); } close(fd); return 0; } Hope this helps. Here's a commented working example for writing to a file through mmap():Reading the file created by the example above, is simpler as we don't need to create a file and \"stretch\" it to the mmapped size. So just remove that part, and open the file for reading only, and remove the PROT_WRITE flag from the mmap call.Hope this helps. The forum rules do not permit advertising. Please visit http://www.linuxquestions.org/advertising/ for more information on advertising. Feel free to contact the forum admin if you have any questions about this policy. \n\n I tried the example programms. Note that you should add a (int*) before the mmap calls, like: Thanks for the example.\n\n \n\n When using PROT_READ, is there an advantage to using mmap()\n\n rather than \"normally\" reading the file into memory, e.g:\n\n <code>\n\n fread(map, sizeof(int), 1000, fd);\n\n </code>\n\n \n\n What I am looking for is a way to use mmap() to create a \"virtual\" memory map\n\n for the whole file, without actually reading it into memory.\n\n As I understand it, mmap() can not do this? What I am looking for is a way to use mmap() to create a \"virtual\" memory map for the whole file, without actually reading it into memory.\n\n As I understand it, mmap() can not do this? As I understand mmap(), that is exactly what mmap does: \"create a \"virtual\" memory map for the whole file, without actually reading it into memory\".\n\n \n\n If mmap() does not do that, what would? As I understand mmap(), that is exactly what mmap does: \"create a \"virtual\" memory map for the whole file, without actually reading it into memory\".If mmap() does not do that, what would? You are right - it does create a virtual map, rather than \"mirroring\" the file in RAM as I first thought. Hi to all:\n\n \n\n I was wondering, if I wanted to put some kind of marker at the end of a memmapped file so as to have something to mark the end of the file, what is the proper way to do this?\n\n \n\n For instance, I want to have a routine that will write out a variable amount of, say, ints to a file for whatever reason. This routine will create a new file or truncate an existing file, then write out however many ints are waiting to be written, then put a mark at the end of the file. A read routine will then later come back, remap the file, and read in ints until it finds the marker.\n\n \n\n I've thought about using an EOF marker for this, but this equates to a \"-1\" in decimal. If any of the ints written out to the file happen to be a \"-1\", the read routine will think that this is the EOF marker and happily stop reading.\n\n \n\n I know that one way to accomplish this is to build into the write routine to count the amount of data going out, then write that to the start of the file, or create a struct that will hold a count of the data separately from the data, but I'm looking for a way to do so as I've described above.\n\n \n\n Any advice would be helpful.\n\n \n\n Thanks!\n\n \n\n hex I was wondering, if I wanted to put some kind of marker at the end of a memmapped file so as to have something to mark the end of the file, what is the proper way to do this?\n\n \n\n For instance, I want to have a routine that will write out a variable amount of, say, ints to a file for whatever reason. This routine will create a new file or truncate an existing file, then write out however many ints are waiting to be written, then put a mark at the end of the file. A read routine will then later come back, remap the file, and read in ints until it finds the marker.\n\n \n\n I've thought about using an EOF marker for this, but this equates to a \"-1\" in decimal. If any of the ints written out to the file happen to be a \"-1\", the read routine will think that this is the EOF marker and happily stop reading.\n\n \n\n I know that one way to accomplish this is to build into the write routine to count the amount of data going out, then write that to the start of the file, or create a struct that will hold a count of the data separately from the data, but I'm looking for a way to do so as I've described above. What would you need and EOF-marker for when using mmap?\n\n \n\n Using mmap, you get to map a file's bytes. All of them, or part (offset + n). So you know the number of bytes since you allocated them yourself. Then you do not need an EOF marker, and you don't need to store the number of bytes (or ints or whatever) at the start.\n\n \n\n If the number of bytes may have changed, you can get the size of the file beforehand using stat(), then you know the number of bytes to mmap().\n\n \n\n If you want to read until EOF, use the normal ways to read/write files, using syscalls or the stdio library functions.\n\n \n\n Of course you could use some end-of-file marking byte if you want. For end-of-record purposes or so. But then you will need to make sure the byte marking end-of-whatever does not appear in the data... This can be very unhandy, especially if you want to read/write binary data. You may need to do some encoding/decoding to avoid having the value of the marker-byte appear in the data. What would you need and EOF-marker for when using mmap?Using mmap, you get to map a file's bytes. All of them, or part (offset + n). So you know the number of bytes since you allocated them yourself. Then you do not need an EOF marker, and you don't need to store the number of bytes (or ints or whatever) at the start.If the number of bytes may have changed, you can get the size of the file beforehand using stat(), then you know the number of bytes to mmap().If you want to read until EOF, use the normal ways to read/write files, using syscalls or the stdio library functions.Of course you could use some end-of-file marking byte if you want. For end-of-record purposes or so. But then you will need to make sure the byte marking end-of-whatever does not appear in the data... This can be very unhandy, especially if you want to read/write binary data. You may need to do some encoding/decoding to avoid having the value of the marker-byte appear in the data. HKO - Thank you. Stat'ing the file to find the size is exactly what I was looking for, but was obviously being too dense to think about it the correct way.\n\n \n\n This is just some quick dirty sample code to prove that your suggestion works like I need (for determining how many arbitrary ints have previously been written to a data file):\n\n ---\n\n #include <sys/types.h>\n\n #include <sys/stat.h>\n\n #include <fcntl.h>\n\n \n\n int main(int argc, char * argv[]){\n\n struct stat buffer;\n\n int status;\n\n int fd;\n\n fd = open(\"/tmp/mmapped.bin\", O_RDWR);\n\n status = fstat(fd, &buffer);\n\n printf(\"number of data items in file: %d\n\n\", buffer.st_size/sizeof(int));\n\n close(fd);\n\n return 0;\n\n }\n\n ---\n\n \n\n So far, the concept has worked perfectly. Thanks again!\n\n \n\n hex Stop and consider what mmap is designed to do: it grabs a section of the page and segment tables that define your program's virtual memory space, and arranges for memory reads-and-writes to that \"region of memory\" to be redirected to that file (instead of the usual virtual-memory swap file).\n\n \n\n This is exactly the sort of mechanism that's used to implement \"shared libraries,\" except that in this case the memory-segment allows both reads and writes.\n\n \n\n Now, then ... \"make of it what you will.\" \n\n \n\n \n\n \n\n \n\n You may not post new threads You may not post attachments You may not edit your posts \n\n \n\n \n\n \n\n All times are GMT -5. The time now is ."
    },
    {
        "link": "https://oreilly.com/library/view/linux-device-drivers/0596005903/ch15.html",
        "document": "This chapter delves into the area of Linux memory management, with an emphasis on techniques that are useful to the device driver writer. Many types of driver programming require some understanding of how the virtual memory subsystem works; the material we cover in this chapter comes in handy more than once as we get into some of the more complex and performance-critical subsystems. The virtual memory subsystem is also a highly interesting part of the core Linux kernel and, therefore, it merits a look.\n\nThe material in this chapter is divided into three sections:\n\nOf course, all of these techniques require an understanding of how Linux memory management works, so we start with an overview of that subsystem.\n\nRather than describing the theory of memory management in operating systems, this section tries to pinpoint the main features of the Linux implementation. Although you do not need to be a Linux virtual memory guru to implement mmap, a basic overview of how things work is useful. What follows is a fairly lengthy description of the data structures used by the kernel to manage memory. Once the necessary background has been covered, we can get into working with these structures. Linux is, of course, a virtual memory system, meaning that the addresses seen by user programs do not directly correspond to the physical addresses used by the hardware. Virtual memory introduces a layer of indirection that allows a number of nice things. With virtual memory, programs running on the system can allocate far more memory than is physically available; indeed, even a single process can have a virtual address space larger than the system’s physical memory. Virtual memory also allows the program to play a number of tricks with the process’s address space, including mapping the program’s memory to device memory. Thus far, we have talked about virtual and physical addresses, but a number of the details have been glossed over. The Linux system deals with several types of addresses, each with its own semantics. Unfortunately, the kernel code is not always very clear on exactly which type of address is being used in each situation, so the programmer must be careful. The following is a list of address types used in Linux. Figure 15-1 shows how these address types relate to physical memory. These are the regular addresses seen by user-space programs. User addresses are either 32 or 64 bits in length, depending on the underlying hardware architecture, and each process has its own virtual address space. The addresses used between the processor and the system’s memory. Physical addresses are 32- or 64-bit quantities; even 32-bit systems can use larger physical addresses in some situations. The addresses used between peripheral buses and memory. Often, they are the same as the physical addresses used by the processor, but that is not necessarily the case. Some architectures can provide an I/O memory management unit (IOMMU) that remaps addresses between a bus and main memory. An IOMMU can make life easier in a number of ways (making a buffer scattered in memory appear contiguous to the device, for example), but programming the IOMMU is an extra step that must be performed when setting up DMA operations. Bus addresses are highly architecture dependent, of course. These make up the normal address space of the kernel. These addresses map some portion (perhaps all) of main memory and are often treated as if they were physical addresses. On most architectures, logical addresses and their associated physical addresses differ only by a constant offset. Logical addresses use the hardware’s native pointer size and, therefore, may be unable to address all of physical memory on heavily equipped 32-bit systems. Logical addresses are usually stored in variables of type or . Memory returned from kmalloc has a kernel logical address. Kernel virtual addresses are similar to logical addresses in that they are a mapping from a kernel-space address to a physical address. Kernel virtual addresses do not necessarily have the linear, one-to-one mapping to physical addresses that characterize the logical address space, however. All logical addresses are kernel virtual addresses, but many kernel virtual addresses are not logical addresses. For example, memory allocated by vmalloc has a virtual address (but no direct physical mapping). The kmap function (described later in this chapter) also returns virtual addresses. Virtual addresses are usually stored in pointer variables. If you have a logical address, the macro _ _pa( ) (defined in <asm/page.h>) returns its associated physical address. Physical addresses can be mapped back to logical addresses with _ _va( ), but only for low-memory pages. Different kernel functions require different types of addresses. It would be nice if there were different C types defined, so that the required address types were explicit, but we have no such luck. In this chapter, we try to be clear on which types of addresses are used where. Physical memory is divided into discrete units called pages. Much of the system’s internal handling of memory is done on a per-page basis. Page size varies from one architecture to the next, although most systems currently use 4096-byte pages. The constant (defined in <asm/page.h>) gives the page size on any given architecture. If you look at a memory address—virtual or physical—it is divisible into a page number and an offset within the page. If 4096-byte pages are being used, for example, the 12 least-significant bits are the offset, and the remaining, higher bits indicate the page number. If you discard the offset and shift the rest of an offset to the right, the result is called a page frame number (PFN). Shifting bits to convert between page frame numbers and addresses is a fairly common operation; the macro tells how many bits must be shifted to make this conversion. The difference between logical and kernel virtual addresses is highlighted on 32-bit systems that are equipped with large amounts of memory. With 32 bits, it is possible to address 4 GB of memory. Linux on 32-bit systems has, until recently, been limited to substantially less memory than that, however, because of the way it sets up the virtual address space. The kernel (on the x86 architecture, in the default configuration) splits the 4-GB virtual address space between user-space and the kernel; the same set of mappings is used in both contexts. A typical split dedicates 3 GB to user space, and 1 GB for kernel space.[ ] The kernel’s code and data structures must fit into that space, but the biggest consumer of kernel address space is virtual mappings for physical memory. The kernel cannot directly manipulate memory that is not mapped into the kernel’s address space. The kernel, in other words, needs its own virtual address for any memory it must touch directly. Thus, for many years, the maximum amount of physical memory that could be handled by the kernel was the amount that could be mapped into the kernel’s portion of the virtual address space, minus the space needed for the kernel code itself. As a result, x86-based Linux systems could work with a maximum of a little under 1 GB of physical memory. In response to commercial pressure to support more memory while not breaking 32-bit application and the system’s compatibility, the processor manufacturers have added “address extension” features to their products. The result is that, in many cases, even 32-bit processors can address more than 4 GB of physical memory. The limitation on how much memory can be directly mapped with logical addresses remains, however. Only the lowest portion of memory (up to 1 or 2 GB, depending on the hardware and the kernel configuration) has logical addresses;[ ] the rest (high memory) does not. Before accessing a specific high-memory page, the kernel must set up an explicit virtual mapping to make that page available in the kernel’s address space. Thus, many kernel data structures must be placed in low memory; high memory tends to be reserved for user-space process pages. The term “high memory” can be confusing to some, especially since it has other meanings in the PC world. So, to make things clear, we’ll define the terms here: Memory for which logical addresses exist in kernel space. On almost every system you will likely encounter, all memory is low memory. Memory for which logical addresses do not exist, because it is beyond the address range set aside for kernel virtual addresses. On i386 systems, the boundary between low and high memory is usually set at just under 1 GB, although that boundary can be changed at kernel configuration time. This boundary is not related in any way to the old 640 KB limit found on the original PC, and its placement is not dictated by the hardware. It is, instead, a limit set by the kernel itself as it splits the 32-bit address space between kernel and user space. We will point out limitations on the use of high memory as we come to them in this chapter. Historically, the kernel has used logical addresses to refer to pages of physical memory. The addition of high-memory support, however, has exposed an obvious problem with that approach—logical addresses are not available for high memory. Therefore, kernel functions that deal with memory are increasingly using pointers to (defined in <linux/mm.h>) instead. This data structure is used to keep track of just about everything the kernel needs to know about physical memory; there is one for each physical page on the system. Some of the fields of this structure include the following: The number of references there are to this page. When the count drops to , the page is returned to the free list. The kernel virtual address of the page, if it is mapped; , otherwise. Low-memory pages are always mapped; high-memory pages usually are not. This field does not appear on all architectures; it generally is compiled only where the kernel virtual address of a page cannot be easily calculated. If you want to look at this field, the proper method is to use the page_address macro, described below. A set of bit flags describing the status of the page. These include , which indicates that the page has been locked in memory, and , which prevents the memory management system from working with the page at all. There is much more information within , but it is part of the deeper black magic of memory management and is not of concern to driver writers. The kernel maintains one or more arrays of entries that track all of the physical memory on the system. On some systems, there is a single array called . On some systems, however, the situation is more complicated. Nonuniform memory access (NUMA) systems and those with widely discontiguous physical memory may have more than one memory map array, so code that is meant to be portable should avoid direct access to the array whenever possible. Fortunately, it is usually quite easy to just work with pointers without worrying about where they come from. Some functions and macros are defined for translating between pointers and virtual addresses: This macro, defined in <asm/page.h>, takes a kernel logical address and returns its associated pointer. Since it requires a logical address, it does not work with memory from vmalloc or high memory. Returns the pointer for the given page frame number. If necessary, it checks a page frame number for validity with pfn_valid before passing it to pfn_to_page. Returns the kernel virtual address of this page, if such an address exists. For high memory, that address exists only if the page has been mapped. This function is defined in <linux/mm.h>. In most situations, you want to use a version of kmap rather than page_address. kmap returns a kernel virtual address for any page in the system. For low-memory pages, it just returns the logical address of the page; for high-memory pages, kmap creates a special mapping in a dedicated part of the kernel address space. Mappings created with kmap should always be freed with kunmap; a limited number of such mappings is available, so it is better not to hold on to them for too long. kmap calls maintain a counter, so if two or more functions both call kmap on the same page, the right thing happens. Note also that kmap can sleep if no mappings are available. kmap_atomic is a high-performance form of kmap. Each architecture maintains a small list of slots (dedicated page table entries) for atomic kmaps; a caller of kmap_atomic must tell the system which of those slots to use in the argument. The only slots that make sense for drivers are and (for code running directly from a call from user space), and and (for interrupt handlers). Note that atomic kmaps must be handled atomically; your code cannot sleep while holding one. Note also that nothing in the kernel keeps two functions from trying to use the same slot and interfering with each other (although there is a unique set of slots for each CPU). In practice, contention for atomic kmap slots seems to not be a problem. We see some uses of these functions when we get into the example code, later in this chapter and in subsequent chapters. On any modern system, the processor must have a mechanism for translating virtual addresses into its corresponding physical addresses. This mechanism is called a page table; it is essentially a multilevel tree-structured array containing virtual-to-physical mappings and a few associated flags. The Linux kernel maintains a set of page tables even on architectures that do not use such tables directly. A number of operations commonly performed by device drivers can involve manipulating page tables. Fortunately for the driver author, the 2.6 kernel has eliminated any need to work with page tables directly. As a result, we do not describe them in any detail; curious readers may want to have a look at Understanding The Linux Kernel by Daniel P. Bovet and Marco Cesati (O’Reilly) for the full story. The virtual memory area (VMA) is the kernel data structure used to manage distinct regions of a process’s address space. A VMA represents a homogeneous region in the virtual memory of a process: a contiguous range of virtual addresses that have the same permission flags and are backed up by the same object (a file, say, or swap space). It corresponds loosely to the concept of a “segment,” although it is better described as “a memory object with its own properties.” The memory map of a process is made up of (at least) the following areas:\n• None An area for the program’s executable code (often called text)\n• None Multiple areas for data, including initialized data (that which has an explicitly assigned value at the beginning of execution), uninitialized data (BSS),[ ] and the program stack\n• None One area for each active memory mapping The memory areas of a process can be seen by looking in /proc/ <pid/maps> (in which pid, of course, is replaced by a process ID). /proc/self is a special case of /proc/ pid, because it always refers to the current process. As an example, here are a couple of memory maps (to which we have added short comments in italics): The fields in each line are: Each field in /proc/*/maps (except the image name) corresponds to a field in : The beginning and ending virtual addresses for this memory area. A bit mask with the memory area’s read, write, and execute permissions. This field describes what the process is allowed to do with pages belonging to the area. The last character in the field is either for “private” or for “shared.” Where the memory area begins in the file that it is mapped to. An offset of means that the beginning of the memory area corresponds to the beginning of the file. The major and minor numbers of the device holding the file that has been mapped. Confusingly, for device mappings, the major and minor numbers refer to the disk partition holding the device special file that was opened by the user, and not the device itself. The inode number of the mapped file. The name of the file (usually an executable image) that has been mapped. When a user-space process calls mmap to map device memory into its address space, the system responds by creating a new VMA to represent that mapping. A driver that supports mmap (and, thus, that implements the mmap method) needs to help that process by completing the initialization of that VMA. The driver writer should, therefore, have at least a minimal understanding of VMAs in order to support mmap. Let’s look at the most important fields in (defined in <linux/mm.h>). These fields may be used by device drivers in their mmap implementation. Note that the kernel maintains lists and trees of VMAs to optimize area lookup, and several fields of are used to maintain this organization. Therefore, VMAs can’t be created at will by a driver, or the structures break. The main fields of VMAs are as follows (note the similarity between these fields and the /proc output we just saw): The virtual address range covered by this VMA. These fields are the first two fields shown in /proc/*/maps. A pointer to the structure associated with this area (if any). The offset of the area in the file, in pages. When a file or device is mapped, this is the file position of the first page mapped in this area. A set of flags describing this area. The flags of the most interest to device driver writers are and . marks a VMA as being a memory-mapped I/O region. Among other things, the flag prevents the region from being included in process core dumps. tells the memory management system not to attempt to swap out this VMA; it should be set in most device mappings. A set of functions that the kernel may invoke to operate on this memory area. Its presence indicates that the memory area is a kernel “object,” like the we have been using throughout the book. A field that may be used by the driver to store its own information. Like , the is defined in <linux/mm.h>; it includes the operations listed below. These operations are the only ones needed to handle the process’s memory needs, and they are listed in the order they are declared. Later in this chapter, some of these functions are implemented. The open method is called by the kernel to allow the subsystem implementing the VMA to initialize the area. This method is invoked any time a new reference to the VMA is made (when a process forks, for example). The one exception happens when the VMA is first created by mmap; in this case, the driver’s mmap method is called instead. When an area is destroyed, the kernel calls its close operation. Note that there’s no usage count associated with VMAs; the area is opened and closed exactly once by each process that uses it. When a process tries to access a page that belongs to a valid VMA, but that is currently not in memory, the nopage method is called (if it is defined) for the related area. The method returns the pointer for the physical page after, perhaps, having read it in from secondary storage. If the nopage method isn’t defined for the area, an empty page is allocated by the kernel. This method allows the kernel to “prefault” pages into memory before they are accessed by user space. There is generally no need for drivers to implement the populate method. The final piece of the memory management puzzle is the process memory map structure, which holds all of the other data structures together. Each process in the system (with the exception of a few kernel-space helper threads) has a (defined in <linux/sched.h>) that contains the process’s list of virtual memory areas, page tables, and various other bits of memory management housekeeping information, along with a semaphore ( ) and a spinlock ( ). The pointer to this structure is found in the task structure; in the rare cases where a driver needs to access it, the usual way is to use . Note that the memory management structure can be shared between processes; the Linux implementation of threads works in this way, for example. That concludes our overview of Linux memory management data structures. With that out of the way, we can now proceed to the implementation of the mmap system call.\n\nMemory mapping is one of the most interesting features of modern Unix systems. As far as drivers are concerned, memory mapping can be implemented to provide user programs with direct access to device memory. A definitive example of mmap usage can be seen by looking at a subset of the virtual memory areas for the X Window System server: The full list of the X server’s VMAs is lengthy, but most of the entries are not of interest here. We do see, however, four separate mappings of /dev/mem, which give some insight into how the X server works with the video card. The first mapping is at , which is the standard location for video RAM in the 640-KB ISA hole. Further down, we see a large mapping at , an address which is above the highest RAM address on the system. This is a direct mapping of the video memory on the adapter. These regions can also be seen in /proc/iomem: Mapping a device means associating a range of user-space addresses to device memory. Whenever the program reads or writes in the assigned address range, it is actually accessing the device. In the X server example, using mmap allows quick and easy access to the video card’s memory. For a performance-critical application like this, direct access makes a large difference. As you might suspect, not every device lends itself to the mmap abstraction; it makes no sense, for instance, for serial ports and other stream-oriented devices. Another limitation of mmap is that mapping is grained. The kernel can manage virtual addresses only at the level of page tables; therefore, the mapped area must be a multiple of and must live in physical memory starting at an address that is a multiple of . The kernel forces size granularity by making a region slightly bigger if its size isn’t a multiple of the page size. These limits are not a big constraint for drivers, because the program accessing the device is device dependent anyway. Since the program must know about how the device works, the programmer is not unduly bothered by the need to see to details like page alignment. A bigger constraint exists when ISA devices are used on some non-x86 platforms, because their hardware view of ISA may not be contiguous. For example, some Alpha computers see ISA memory as a scattered set of 8-bit, 16-bit, or 32-bit items, with no direct mapping. In such cases, you can’t use mmap at all. The inability to perform direct mapping of ISA addresses to Alpha addresses is due to the incompatible data transfer specifications of the two systems. Whereas early Alpha processors could issue only 32-bit and 64-bit memory accesses, ISA can do only 8-bit and 16-bit transfers, and there’s no way to transparently map one protocol onto the other. There are sound advantages to using mmap when it’s feasible to do so. For instance, we have already looked at the X server, which transfers a lot of data to and from video memory; mapping the graphic display to user space dramatically improves the throughput, as opposed to an lseek/write implementation. Another typical example is a program controlling a PCI device. Most PCI peripherals map their control registers to a memory address, and a high-performance application might prefer to have direct access to the registers instead of repeatedly having to call ioctl to get its work done. The mmap method is part of the structure and is invoked when the mmap system call is issued. With mmap, the kernel performs a good deal of work before the actual method is invoked, and, therefore, the prototype of the method is quite different from that of the system call. This is unlike calls such as ioctl and poll, where the kernel does not do much before calling the method. The system call is declared as follows (as described in the mmap(2) manual page): On the other hand, the file operation is declared as: The argument in the method is the same as that introduced in Chapter 3, while contains the information about the virtual address range that is used to access the device. Therefore, much of the work has been done by the kernel; to implement mmap, the driver only has to build suitable page tables for the address range and, if necessary, replace with a new set of operations. There are two ways of building the page tables: doing it all at once with a function called or doing it a page at a time via the nopage VMA method. Each method has its advantages and limitations. We start with the “all at once” approach, which is simpler. From there, we add the complications needed for a real-world implementation. The job of building new page tables to map a range of physical addresses is handled by remap_pfn_range and io_remap_page_range, which have the following prototypes: The value returned by the function is the usual or a negative error code. Let’s look at the exact meaning of the function’s arguments: The virtual memory area into which the page range is being mapped. The user virtual address where remapping should begin. The function builds page tables for the virtual address range between and . The page frame number corresponding to the physical address to which the virtual address should be mapped. The page frame number is simply the physical address right-shifted by bits. For most uses, the field of the VMA structure contains exactly the value you need. The function affects physical addresses from to . The dimension, in bytes, of the area being remapped. The “protection” requested for the new VMA. The driver can (and should) use the value found in . The arguments to remap_pfn_range are fairly straightforward, and most of them are already provided to you in the VMA when your mmap method is called. You may be wondering why there are two functions, however. The first (remap_pfn_range) is intended for situations where refers to actual system RAM, while io_remap_page_range should be used when points to I/O memory. In practice, the two functions are identical on every architecture except the SPARC, and you see remap_pfn_range used in most situations. In the interest of writing portable drivers, however, you should use the variant of remap_pfn_range that is suited to your particular situation. One other complication has to do with caching: usually, references to device memory should not be cached by the processor. Often the system BIOS sets things up properly, but it is also possible to disable caching of specific VMAs via the protection field. Unfortunately, disabling caching at this level is highly processor dependent. The curious reader may wish to look at the pgprot_noncached function from drivers/char/mem.c to see what’s involved. We won’t discuss the topic further here. If your driver needs to do a simple, linear mapping of device memory into a user address space, remap_pfn_range is almost all you really need to do the job. The following code is derived from drivers/char/mem.c and shows how this task is performed in a typical module called simple (Simple Implementation Mapping Pages with Little Enthusiasm): As you can see, remapping memory just a matter of calling remap_pfn_range to create the necessary page tables. As we have seen, the structure contains a set of operations that may be applied to the VMA. Now we look at providing those operations in a simple way. In particular, we provide open and close operations for our VMA. These operations are called whenever a process opens or closes the VMA; in particular, the open method is invoked anytime a process forks and creates a new reference to the VMA. The open and close VMA methods are called in addition to the processing performed by the kernel, so they need not reimplement any of the work done there. They exist as a way for drivers to do any additional processing that they may require. As it turns out, a simple driver such as simple need not do any extra processing in particular. So we have created open and close methods, which print a message to the system log informing the world that they have been called. Not particularly useful, but it does allow us to show how these methods can be provided, and see when they are invoked. To this end, we override the default with operations that call printk: To make these operations active for a specific mapping, it is necessary to store a pointer to in the field of the relevant VMA. This is usually done in the mmap method. If you turn back to the simple_remap_mmap example, you see these lines of code: Note the explicit call to simple_vma_open. Since the open method is not invoked on the initial mmap, we must call it explicitly if we want it to run. Although remap_pfn_range works well for many, if not most, driver mmap implementations, sometimes it is necessary to be a little more flexible. In such situations, an implementation using the nopage VMA method may be called for. One situation in which the nopage approach is useful can be brought about by the mremap system call, which is used by applications to change the bounding addresses of a mapped region. As it happens, the kernel does not notify drivers directly when a mapped VMA is changed by mremap. If the VMA is reduced in size, the kernel can quietly flush out the unwanted pages without telling the driver. If, instead, the VMA is expanded, the driver eventually finds out by way of calls to nopage when mappings must be set up for the new pages, so there is no need to perform a separate notification. The nopage method, therefore, must be implemented if you want to support the mremap system call. Here, we show a simple implementation of nopage for the simple device. The nopage method, remember, has the following prototype: When a user process attempts to access a page in a VMA that is not present in memory, the associated nopage function is called. The parameter contains the virtual address that caused the fault, rounded down to the beginning of the page. The nopage function must locate and return the pointer that refers to the page the user wanted. This function must also take care to increment the usage count for the page it returns by calling the get_page macro: This step is necessary to keep the reference counts correct on the mapped pages. The kernel maintains this count for every page; when the count goes to , the kernel knows that the page may be placed on the free list. When a VMA is unmapped, the kernel decrements the usage count for every page in the area. If your driver does not increment the count when adding a page to the area, the usage count becomes prematurely, and the integrity of the system is compromised. The nopage method should also store the type of fault in the location pointed to by the argument—but only if that argument is not . In device drivers, the proper value for will invariably be . If you are using nopage, there is usually very little work to be done when mmap is called; our version looks like this: The main thing mmap has to do is to replace the default ( ) pointer with our own operations. The nopage method then takes care of “remapping” one page at a time and returning the address of its structure. Because we are just implementing a window onto physical memory here, the remapping step is simple: we only need to locate and return a pointer to the for the desired address. Our nopage method looks like the following: Since, once again, we are simply mapping main memory here, the nopage function need only find the correct for the faulting address and increment its reference count. Therefore, the required sequence of events is to calculate the desired physical address, and turn it into a page frame number by right-shifting it bits. Since user space can give us any address it likes, we must ensure that we have a valid page frame; the pfn_valid function does that for us. If the address is out of range, we return , which causes a bus signal to be delivered to the calling process. Otherwise, pfn_to_page gets the necessary pointer; we can increment its reference count (with a call to get_page) and return it. The nopage method normally returns a pointer to a . If, for some reason, a normal page cannot be returned (e.g., the requested address is beyond the device’s memory region), can be returned to signal the error; that is what the simple code above does. nopage can also return to indicate failures caused by resource limitations. Note that this implementation works for ISA memory regions but not for those on the PCI bus. PCI memory is mapped above the highest system memory, and there are no entries in the system memory map for those addresses. Because there is no to return a pointer to, nopage cannot be used in these situations; you must use remap_pfn_range instead. If the nopage method is left , kernel code that handles page faults maps the zero page to the faulting virtual address. The zero page is a copy-on-write page that reads as and that is used, for example, to map the BSS segment. Any process referencing the zero page sees exactly that: a page filled with zeroes. If the process writes to the page, it ends up modifying a private copy. Therefore, if a process extends a mapped region by calling mremap, and the driver hasn’t implemented nopage, the process ends up with zero-filled memory instead of a segmentation fault. All the examples we’ve seen so far are reimplementations of /dev/mem; they remap physical addresses into user space. The typical driver, however, wants to map only the small address range that applies to its peripheral device, not all memory. In order to map to user space only a subset of the whole memory range, the driver needs only to play with the offsets. The following does the trick for a driver mapping a region of bytes, beginning at physical address (which should be page-aligned): unsigned long off = vma->vm_pgoff << PAGE_SHIFT; unsigned long physical = simple_region_start + off; unsigned long vsize = vma->vm_end - vma->vm_start; unsigned long psize = simple_region_size - off; if (vsize > psize) return -EINVAL; /* spans too high */ remap_pfn_range(vma, vma_>vm_start, physical, vsize, vma->vm_page_prot); In addition to calculating the offsets, this code introduces a check that reports an error when the program tries to map more memory than is available in the I/O region of the target device. In this code, is the physical I/O size that is left after the offset has been specified, and is the requested size of virtual memory; the function refuses to map addresses that extend beyond the allowed memory range. Note that the user process can always use mremap to extend its mapping, possibly past the end of the physical device area. If your driver fails to define a nopage method, it is never notified of this extension, and the additional area maps to the zero page. As a driver writer, you may well want to prevent this sort of behavior; mapping the zero page onto the end of your region is not an explicitly bad thing to do, but it is highly unlikely that the programmer wanted that to happen. The simplest way to prevent extension of the mapping is to implement a simple nopage method that always causes a bus signal to be sent to the faulting process. Such a method would look like this: As we have seen, the nopage method is called only when the process dereferences an address that is within a known VMA but for which there is currently no valid page table entry. If we have used remap_pfn_range to map the entire device region, the nopage method shown here is called only for references outside of that region. Thus, it can safely return to signal an error. Of course, a more thorough implementation of nopage could check to see whether the faulting address is within the device area, and perform the remapping if that is the case. Once again, however, nopage does not work with PCI memory areas, so extension of PCI mappings is not possible. An interesting limitation of remap_pfn_range is that it gives access only to reserved pages and physical addresses above the top of physical memory. In Linux, a page of physical addresses is marked as “reserved” in the memory map to indicate that it is not available for memory management. On the PC, for example, the range between 640 KB and 1 MB is marked as reserved, as are the pages that host the kernel code itself. Reserved pages are locked in memory and are the only ones that can be safely mapped to user space; this limitation is a basic requirement for system stability. Therefore, remap_pfn_range won’t allow you to remap conventional addresses, which include the ones you obtain by calling get_free_page. Instead, it maps in the zero page. Everything appears to work, with the exception that the process sees private, zero-filled pages rather than the remapped RAM that it was hoping for. Nonetheless, the function does everything that most hardware drivers need it to do, because it can remap high PCI buffers and ISA memory. The limitations of remap_pfn_range can be seen by running mapper, one of the sample programs in misc-progs in the files provided on O’Reilly’s FTP site. mapper is a simple tool that can be used to quickly test the mmap system call; it maps read-only parts of a file specified by command-line options and dumps the mapped region to standard output. The following session, for instance, shows that /dev/mem doesn’t map the physical page located at address 64 KB—instead, we see a page full of zeros (the host computer in this example is a PC, but the result would be the same on other platforms): The inability of remap_pfn_range to deal with RAM suggests that memory-based devices like scull can’t easily implement mmap, because its device memory is conventional RAM, not I/O memory. Fortunately, a relatively easy workaround is available to any driver that needs to map RAM into user space; it uses the nopage method that we have seen earlier. The way to map real RAM to user space is to use to deal with page faults one at a time. A sample implementation is part of the scullp module, introduced in Chapter 8. scullp is a page-oriented char device. Because it is page oriented, it can implement mmap on its memory. The code implementing memory mapping uses some of the concepts introduced in Section 15.1. Before examining the code, let’s look at the design choices that affect the mmap implementation in scullp :\n• None scullp doesn’t release device memory as long as the device is mapped. This is a matter of policy rather than a requirement, and it is different from the behavior of scull and similar devices, which are truncated to a length of when opened for writing. Refusing to free a mapped scullp device allows a process to overwrite regions actively mapped by another process, so you can test and see how processes and device memory interact. To avoid releasing a mapped device, the driver must keep a count of active mappings; the field in the device structure is used for this purpose.\n• None Memory mapping is performed only when the scullp parameter (set at module load time) is . The parameter controls how _ _get_free_pages is invoked (see Section 8.3). The zero-order limitation (which forces pages to be allocated one at a time, rather than in larger groups) is dictated by the internals of _ _get_free_pages, the allocation function used by scullp. To maximize allocation performance, the Linux kernel maintains a list of free pages for each allocation order, and only the reference count of the first page in a cluster is incremented by get_free_pages and decremented by free_pages. The mmap method is disabled for a scullp device if the allocation order is greater than zero, because nopage deals with single pages rather than clusters of pages. scullp simply does not know how to properly manage reference counts for pages that are part of higher-order allocations. (Return to Section 8.3.1 if you need a refresher on scullp and the memory allocation order value.) The zero-order limitation is mostly intended to keep the code simple. It is possible to correctly implement mmap for multipage allocations by playing with the usage count of the pages, but it would only add to the complexity of the example without introducing any interesting information. Code that is intended to map RAM according to the rules just outlined needs to implement the open, close, and nopage VMA methods; it also needs to access the memory map to adjust the page usage counts. This implementation of scullp_mmap is very short, because it relies on the nopage function to do all the interesting work: int scullp_mmap(struct file *filp, struct vm_area_struct *vma) { struct inode *inode = filp->f_dentry->d_inode; /* refuse to map if order is not 0 */ if (scullp_devices[iminor(inode)].order) return -ENODEV; /* don't do anything here: \"nopage\" will fill the holes */ vma->vm_ops = &scullp_vm_ops; vma->vm_flags |= VM_RESERVED; vma->vm_private_data = filp->private_data; scullp_vma_open(vma); return 0; } The purpose of the statement is to avoid mapping devices whose allocation order is not . scullp’s operations are stored in the field, and a pointer to the device structure is stashed in the field. At the end, is called to update the count of active mappings for the device. open and close simply keep track of the mapping count and are defined as follows: Most of the work is then performed by nopage. In the scullp implementation, the parameter to nopage is used to calculate an offset into the device; the offset is then used to look up the correct page in the scullp memory tree: struct page *scullp_vma_nopage(struct vm_area_struct *vma, unsigned long address, int *type) { unsigned long offset; struct scullp_dev *ptr, *dev = vma->vm_private_data; struct page *page = NOPAGE_SIGBUS; void *pageptr = NULL; /* default to \"missing\" */ down(&dev->sem); offset = (address - vma->vm_start) + (vma->vm_pgoff << PAGE_SHIFT); if (offset >= dev->size) goto out; /* out of range */ /* * Now retrieve the scullp device from the list,then the page. * If the device has holes, the process receives a SIGBUS when * accessing the hole. */ offset >>= PAGE_SHIFT; /* offset is a number of pages */ for (ptr = dev; ptr && offset >= dev->qset;) { ptr = ptr->next; offset -= dev->qset; } if (ptr && ptr->data) pageptr = ptr->data[offset]; if (!pageptr) goto out; /* hole or end-of-file */ page = virt_to_page(pageptr); /* got it, now increment the count */ get_page(page); if (type) *type = VM_FAULT_MINOR; out: up(&dev->sem); return page; } scullp uses memory obtained with get_free_pages. That memory is addressed using logical addresses, so all scullp_nopage has to do to get a pointer is to call virt_to_page. The scullp device now works as expected, as you can see in this sample output from the mapper utility. Here, we send a directory listing of /dev (which is long) to the scullp device and then use the mapper utility to look at pieces of that listing with mmap: morgana% morgana% mapped \"/dev/scullp\" from 0 (0x00000000) to 140 (0x0000008c) total 232 crw------- 1 root root 10, 10 Sep 15 07:40 adbmouse crw-r--r-- 1 root root 10, 175 Sep 15 07:40 agpgart morgana% mapped \"/dev/scullp\" from 8192 (0x00002000) to 8392 (0x000020c8) d0h1494 brw-rw---- 1 root floppy 2, 92 Sep 15 07:40 fd0h1660 brw-rw---- 1 root floppy 2, 20 Sep 15 07:40 fd0h360 brw-rw---- 1 root floppy 2, 12 Sep 15 07:40 fd0H360 Although it’s rarely necessary, it’s interesting to see how a driver can map a kernel virtual address to user space using mmap. A true kernel virtual address, remember, is an address returned by a function such as vmalloc—that is, a virtual address mapped in the kernel page tables. The code in this section is taken from scullv, which is the module that works like scullp but allocates its storage through vmalloc. Most of the scullv implementation is like the one we’ve just seen for scullp, except that there is no need to check the parameter that controls memory allocation. The reason for this is that vmalloc allocates its pages one at a time, because single-page allocations are far more likely to succeed than multipage allocations. Therefore, the allocation order problem doesn’t apply to vmalloced space. Beyond that, there is only one difference between the nopage implementations used by scullp and scullv. Remember that scullp, once it found the page of interest, would obtain the corresponding pointer with virt_to_page. That function does not work with kernel virtual addresses, however. Instead, you must use vmalloc_to_page. So the final part of the scullv version of nopage looks like: /* * After scullv lookup, \"page\" is now the address of the page * needed by the current process. Since it's a vmalloc address, * turn it into a struct page. */ page = vmalloc_to_page(pageptr); /* got it, now increment the count */ get_page(page); if (type) *type = VM_FAULT_MINOR; out: up(&dev->sem); return page; Based on this discussion, you might also want to map addresses returned by ioremap to user space. That would be a mistake, however; addresses from ioremap are special and cannot be treated like normal kernel virtual addresses. Instead, you should use remap_pfn_range to remap I/O memory areas into user space.\n\nMost I/O operations are buffered through the kernel. The use of a kernel-space buffer allows a degree of separation between user space and the actual device; this separation can make programming easier and can also yield performance benefits in many situations. There are cases, however, where it can be beneficial to perform I/O directly to or from a user-space buffer. If the amount of data being transferred is large, transferring data directly without an extra copy through kernel space can speed things up. One example of direct I/O use in the 2.6 kernel is the SCSI tape driver. Streaming tapes can pass a lot of data through the system, and tape transfers are usually record-oriented, so there is little benefit to buffering data in the kernel. So, when the conditions are right (the user-space buffer is page-aligned, for example), the SCSI tape driver performs its I/O without copying the data. That said, it is important to recognize that direct I/O does not always provide the performance boost that one might expect. The overhead of setting up direct I/O (which involves faulting in and pinning down the relevant user pages) can be significant, and the benefits of buffered I/O are lost. For example, the use of direct I/O requires that the write system call operate synchronously; otherwise the application does not know when it can reuse its I/O buffer. Stopping the application until each write completes can slow things down, which is why applications that use direct I/O often use asynchronous I/O operations as well. The real moral of the story, in any case, is that implementing direct I/O in a char driver is usually unnecessary and can be hurtful. You should take that step only if you are sure that the overhead of buffered I/O is truly slowing things down. Note also that block and network drivers need not worry about implementing direct I/O at all; in both cases, higher-level code in the kernel sets up and makes use of direct I/O when it is indicated, and driver-level code need not even know that direct I/O is being performed. The key to implementing direct I/O in the 2.6 kernel is a function called get_user_pages , which is declared in <linux/mm.h> with the following prototype: This function has several arguments: A pointer to the task performing the I/O; its main purpose is to tell the kernel who should be charged for any page faults incurred while setting up the buffer. This argument is almost always passed as . A pointer to the memory management structure describing the address space to be mapped. The structure is the piece that ties together all of the parts (VMAs) of a process’s virtual address space. For driver use, this argument should always be . is the (page-aligned) address of the user-space buffer, and is the length of the buffer in pages. If is nonzero, the pages are mapped for write access (implying, of course, that user space is performing a read operation). The flag tells get_user_pages to override the protections on the given pages to provide the requested access; drivers should always pass here. Output parameters. Upon successful completion, contain a list of pointers to the structures describing the user-space buffer, and contains pointers to the associated VMAs. The parameters should, obviously, point to arrays capable of holding at least pointers. Either parameter can be , but you need, at least, the pointers to actually operate on the buffer. get_user_pages is a low-level memory management function, with a suitably complex interface. It also requires that the mmap reader/writer semaphore for the address space be obtained in read mode before the call. As a result, calls to get_user_pages usually look something like: The return value is the number of pages actually mapped, which could be fewer than the number requested (but greater than zero). Upon successful completion, the caller has a array pointing to the user-space buffer, which is locked into memory. To operate on the buffer directly, the kernel-space code must turn each pointer into a kernel virtual address with kmap or kmap_atomic. Usually, however, devices for which direct I/O is justified are using DMA operations, so your driver will probably want to create a scatter/gather list from the array of pointers. We discuss how to do this in the section, Section 15.4.4.7. Once your direct I/O operation is complete, you must release the user pages. Before doing so, however, you must inform the kernel if you changed the contents of those pages. Otherwise, the kernel may think that the pages are “clean,” meaning that they match a copy found on the swap device, and free them without writing them out to backing store. So, if you have changed the pages (in response to a user-space read request), you must mark each affected page dirty with a call to: (This macro is defined in <linux/page-flags.h>). Most code that performs this operation checks first to ensure that the page is not in the reserved part of the memory map, which is never swapped out. Therefore, the code usually looks like: Since user-space memory is not normally marked reserved, this check should not strictly be necessary, but when you are getting your hands dirty deep within the memory management subsystem, it is best to be thorough and careful. Regardless of whether the pages have been changed, they must be freed from the page cache, or they stay there forever. The call to use is: This call should, of course, be made after the page has been marked dirty, if need be. One of the new features added to the 2.6 kernel was the asynchronous I/O capability. Asynchronous I/O allows user space to initiate operations without waiting for their completion; thus, an application can do other processing while its I/O is in flight. A complex, high-performance application can also use asynchronous I/O to have multiple operations going at the same time. The implementation of asynchronous I/O is optional, and very few driver authors bother; most devices do not benefit from this capability. As we will see in the coming chapters, block and network drivers are fully asynchronous at all times, so only char drivers are candidates for explicit asynchronous I/O support. A char device can benefit from this support if there are good reasons for having more than one I/O operation outstanding at any given time. One good example is streaming tape drives, where the drive can stall and slow down significantly if I/O operations do not arrive quickly enough. An application trying to get the best performance out of a streaming drive could use asynchronous I/O to have multiple operations ready to go at any given time. For the rare driver author who needs to implement asynchronous I/O, we present a quick overview of how it works. We cover asynchronous I/O in this chapter, because its implementation almost always involves direct I/O operations as well (if you are buffering data in the kernel, you can usually implement asynchronous behavior without imposing the added complexity on user space). Drivers supporting asynchronous I/O should include <linux/aio.h>. There are three file_operations methods for the implementation of asynchronous I/O: The aio_fsync operation is only of interest to filesystem code, so we do not discuss it further here. The other two, aio_read and aio_write, look very much like the regular read and write methods but with a couple of exceptions. One is that the parameter is passed by value; asynchronous operations never change the file position, so there is no reason to pass a pointer to it. These methods also take the (“I/O control block”) parameter, which we get to in a moment. The purpose of the aio_read and aio_write methods is to initiate a read or write operation that may or may not be complete by the time they return. If it is possible to complete the operation immediately, the method should do so and return the usual status: the number of bytes transferred or a negative error code. Thus, if your driver has a read method called my_read, the following aio_read method is entirely correct (though rather pointless): Note that the pointer is found in the field of the structure. If you support asynchronous I/O, you must be aware of the fact that the kernel can, on occasion, create “synchronous IOCBs.” These are, essentially, asynchronous operations that must actually be executed synchronously. One may well wonder why things are done this way, but it’s best to just do what the kernel asks. Synchronous operations are marked in the IOCB; your driver should query that status with: If this function returns a nonzero value, your driver must execute the operation synchronously. In the end, however, the point of all this structure is to enable asynchronous operations. If your driver is able to initiate the operation (or, simply, to queue it until some future time when it can be executed), it must do two things: remember everything it needs to know about the operation, and return to the caller. Remembering the operation information includes arranging access to the user-space buffer; once you return, you will not again have the opportunity to access that buffer while running in the context of the calling process. In general, that means you will likely have to set up a direct kernel mapping (with get_user_pages) or a DMA mapping. The error code indicates that the operation is not yet complete, and its final status will be posted later. When “later” comes, your driver must inform the kernel that the operation has completed. That is done with a call to aio_complete: Here, is the same IOCB that was initially passed to you, and is the usual result status for the operation. is a second result code that will be returned to user space; most asynchronous I/O implementations pass as . Once you call aio_complete, you should not touch the IOCB or user buffer again. The page-oriented scullp driver in the example source implements asynchronous I/O. The implementation is simple, but it is enough to show how asynchronous operations should be structured. The aio_read and aio_write methods don’t actually do much: struct async_work { struct kiocb *iocb; int result; struct work_struct work; }; static int scullp_defer_op(int write, struct kiocb *iocb, char *buf, size_t count, loff_t pos) { struct async_work *stuff; int result; /* Copy now while we can access the buffer */ if (write) result = scullp_write(iocb->ki_filp, buf, count, &pos); else result = scullp_read(iocb->ki_filp, buf, count, &pos); /* If this is a synchronous IOCB, we return our status now. */ if (is_sync_kiocb(iocb)) return result; /* Otherwise defer the completion for a few milliseconds. */ stuff = kmalloc (sizeof (*stuff), GFP_KERNEL); if (stuff = = NULL) return result; /* No memory, just complete now */ stuff->iocb = iocb; stuff->result = result; INIT_WORK(&stuff->work, scullp_do_deferred_op, stuff); schedule_delayed_work(&stuff->work, HZ/100); return -EIOCBQUEUED; } A more complete implementation would use get_user_pages to map the user buffer into kernel space. We chose to keep life simple by just copying over the data at the outset. Then a call is made to is_sync_kiocb to see if this operation must be completed synchronously; if so, the result status is returned, and we are done. Otherwise we remember the relevant information in a little structure, arrange for “completion” via a workqueue, and return . At this point, control returns to user space. Later on, the workqueue executes our completion function: Here, it is simply a matter of calling aio_complete with our saved information. A real driver’s asynchronous I/O implementation is somewhat more complicated, of course, but it follows this sort of structure.\n\nDirect memory access, or DMA , is the advanced topic that completes our overview of memory issues. DMA is the hardware mechanism that allows peripheral components to transfer their I/O data directly to and from main memory without the need to involve the system processor. Use of this mechanism can greatly increase throughput to and from a device, because a great deal of computational overhead is eliminated. Before introducing the programming details, let’s review how a DMA transfer takes place, considering only input transfers to simplify the discussion. Data transfer can be triggered in two ways: either the software asks for data (via a function such as read) or the hardware asynchronously pushes data to the system. In the first case, the steps involved can be summarized as follows:\n• None When a process calls read, the driver method allocates a DMA buffer and instructs the hardware to transfer its data into that buffer. The process is put to sleep.\n• None The hardware writes data to the DMA buffer and raises an interrupt when it’s done.\n• None The interrupt handler gets the input data, acknowledges the interrupt, and awakens the process, which is now able to read data. The second case comes about when DMA is used asynchronously. This happens, for example, with data acquisition devices that go on pushing data even if nobody is reading them. In this case, the driver should maintain a buffer so that a subsequent read call will return all the accumulated data to user space. The steps involved in this kind of transfer are slightly different:\n• None The hardware raises an interrupt to announce that new data has arrived.\n• None The interrupt handler allocates a buffer and tells the hardware where to transfer its data.\n• None The peripheral device writes the data to the buffer and raises another interrupt when it’s done.\n• None The handler dispatches the new data, wakes any relevant process, and takes care of housekeeping. A variant of the asynchronous approach is often seen with network cards. These cards often expect to see a circular buffer (often called a DMA ring buffer) established in memory shared with the processor; each incoming packet is placed in the next available buffer in the ring, and an interrupt is signaled. The driver then passes the network packets to the rest of the kernel and places a new DMA buffer in the ring. The processing steps in all of these cases emphasize that efficient DMA handling relies on interrupt reporting. While it is possible to implement DMA with a polling driver, it wouldn’t make sense, because a polling driver would waste the performance benefits that DMA offers over the easier processor-driven I/O.[ ] Another relevant item introduced here is the DMA buffer. DMA requires device drivers to allocate one or more special buffers suited to DMA. Note that many drivers allocate their buffers at initialization time and use them until shutdown—the word allocate in the previous lists, therefore, means “get hold of a previously allocated buffer.” This section covers the allocation of DMA buffers at a low level; we introduce a higher-level interface shortly, but it is still a good idea to understand the material presented here. The main issue that arrises with DMA buffers is that, when they are bigger than one page, they must occupy contiguous pages in physical memory because the device transfers data using the ISA or PCI system bus, both of which carry physical addresses. It’s interesting to note that this constraint doesn’t apply to the SBus (see Section 12.5), which uses virtual addresses on the peripheral bus. Some architectures can also use virtual addresses on the PCI bus, but a portable driver cannot count on that capability. Although DMA buffers can be allocated either at system boot or at runtime, modules can allocate their buffers only at runtime. Driver writers must take care to allocate the right kind of memory when it is used for DMA operations; not all memory zones are suitable. In particular, high memory may not work for DMA on some systems and with some devices—the peripherals simply cannot work with addresses that high. Most devices on modern buses can handle 32-bit addresses, meaning that normal memory allocations work just fine for them. Some PCI devices, however, fail to implement the full PCI standard and cannot work with 32-bit addresses. And ISA devices, of course, are limited to 24-bit addresses only. For devices with this kind of limitation, memory should be allocated from the DMA zone by adding the flag to the kmalloc or get_free_pages call. When this flag is present, only memory that can be addressed with 24 bits is allocated. Alternatively, you can use the generic DMA layer (which we discuss shortly) to allocate buffers that work around your device’s limitations. We have seen how get_free_pages can allocate up to a few megabytes (as order can range up to , currently 11), but high-order requests are prone to fail even when the requested buffer is far less than 128 KB, because system memory becomes fragmented over time.[ ] When the kernel cannot return the requested amount of memory or when you need more than 128 KB (a common requirement for PCI frame grabbers, for example), an alternative to returning is to allocate memory at boot time or reserve the top of physical RAM for your buffer. We described allocation at boot time in Section 8.6, but it is not available to modules. Reserving the top of RAM is accomplished by passing a argument to the kernel at boot time. For example, if you have 256 MB, the argument keeps the kernel from using the top megabyte. Your module could later use the following code to gain access to such memory: The allocator, part of the sample code accompanying the book, offers a simple API to probe and manage such reserved RAM and has been used successfully on several architectures. However, this trick doesn’t work when you have an high-memory system (i.e., one with more physical memory than could fit in the CPU address space). Another option, of course, is to allocate your buffer with the allocation flag. This approach does, however, severely stress the memory management subsystem, and it runs the risk of locking up the system altogether; it is best avoided unless there is truly no other way. If you are going to such lengths to allocate a large DMA buffer, however, it is worth putting some thought into alternatives. If your device can do scatter/gather I/O, you can allocate your buffer in smaller pieces and let the device do the rest. Scatter/gather I/O can also be used when performing direct I/O into user space, which may well be the best solution when a truly huge buffer is required. A device driver using DMA has to talk to hardware connected to the interface bus, which uses physical addresses, whereas program code uses virtual addresses. As a matter of fact, the situation is slightly more complicated than that. DMA-based hardware uses bus, rather than physical, addresses. Although ISA and PCI bus addresses are simply physical addresses on the PC, this is not true for every platform. Sometimes the interface bus is connected through bridge circuitry that maps I/O addresses to different physical addresses. Some systems even have a page-mapping scheme that can make arbitrary pages appear contiguous to the peripheral bus. At the lowest level (again, we’ll look at a higher-level solution shortly), the Linux kernel provides a portable solution by exporting the following functions, defined in <asm/io.h>. The use of these functions is strongly discouraged, because they work properly only on systems with a very simple I/O architecture; nonetheless, you may encounter them when working with kernel code. These functions perform a simple conversion between kernel logical addresses and bus addresses. They do not work in any situation where an I/O memory management unit must be programmed or where bounce buffers must be used. The right way of performing this conversion is with the generic DMA layer, so we now move on to that topic. DMA operations, in the end, come down to allocating a buffer and passing bus addresses to your device. However, the task of writing portable drivers that perform DMA safely and correctly on all architectures is harder than one might think. Different systems have different ideas of how cache coherency should work; if you do not handle this issue correctly, your driver may corrupt memory. Some systems have complicated bus hardware that can make the DMA task easier—or harder. And not all systems can perform DMA out of all parts of memory. Fortunately, the kernel provides a bus- and architecture-independent DMA layer that hides most of these issues from the driver author. We strongly encourage you to use this layer for DMA operations in any driver you write. Many of the functions below require a pointer to a . This structure is the low-level representation of a device within the Linux device model. It is not something that drivers often have to work with directly, but you do need it when using the generic DMA layer. Usually, you can find this structure buried inside the bus specific that describes your device. For example, it can be found as the field in or . The structure is covered in detail in Chapter 14. Drivers that use the following functions should include <linux/dma-mapping.h>. The first question that must be answered before attempting DMA is whether the given device is capable of such an operation on the current host. Many devices are limited in the range of memory they can address, for a number of reasons. By default, the kernel assumes that your device can perform DMA to any 32-bit address. If this is not the case, you should inform the kernel of that fact with a call to: The should show the bits that your device can address; if it is limited to 24 bits, for example, you would pass as . The return value is nonzero if DMA is possible with the given ; if dma_set_mask returns , you are not able to use DMA operations with this device. Thus, the initialization code in a driver for a device limited to 24-bit DMA operations might look like: if (dma_set_mask (dev, 0xffffff)) card->use_dma = 1; else { card->use_dma = 0; /* We'll have to live without DMA */ printk (KERN_WARN, \"mydev: DMA not supported\n\n\"); } Again, if your device supports normal, 32-bit DMA operations, there is no need to call dma_set_mask. A DMA mapping is a combination of allocating a DMA buffer and generating an address for that buffer that is accessible by the device. It is tempting to get that address with a simple call to virt_to_bus, but there are strong reasons for avoiding that approach. The first of those is that reasonable hardware comes with an IOMMU that provides a set of mapping registers for the bus. The IOMMU can arrange for any physical memory to appear within the address range accessible by the device, and it can cause physically scattered buffers to look contiguous to the device. Making use of the IOMMU requires using the generic DMA layer; virt_to_bus is not up to the task. Note that not all architectures have an IOMMU; in particular, the popular x86 platform has no IOMMU support. A properly written driver need not be aware of the I/O support hardware it is running over, however. Setting up a useful address for the device may also, in some cases, require the establishment of a bounce buffer. Bounce buffers are created when a driver attempts to perform DMA on an address that is not reachable by the peripheral device—a high-memory address, for example. Data is then copied to and from the bounce buffer as needed. Needless to say, use of bounce buffers can slow things down, but sometimes there is no alternative. DMA mappings must also address the issue of cache coherency. Remember that modern processors keep copies of recently accessed memory areas in a fast, local cache; without this cache, reasonable performance is not possible. If your device changes an area of main memory, it is imperative that any processor caches covering that area be invalidated; otherwise the processor may work with an incorrect image of main memory, and data corruption results. Similarly, when your device uses DMA to read data from main memory, any changes to that memory residing in processor caches must be flushed out first. These cache coherency issues can create no end of obscure and difficult-to-find bugs if the programmer is not careful. Some architectures manage cache coherency in the hardware, but others require software support. The generic DMA layer goes to great lengths to ensure that things work correctly on all architectures, but, as we will see, proper behavior requires adherence to a small set of rules. The DMA mapping sets up a new type, , to represent bus addresses. Variables of type should be treated as opaque by the driver; the only allowable operations are to pass them to the DMA support routines and to the device itself. As a bus address, may lead to unexpected problems if used directly by the CPU. The PCI code distinguishes between two types of DMA mappings, depending on how long the DMA buffer is expected to stay around: These mappings usually exist for the life of the driver. A coherent buffer must be simultaneously available to both the CPU and the peripheral (other types of mappings, as we will see later, can be available only to one or the other at any given time). As a result, coherent mappings must live in cache-coherent memory. Coherent mappings can be expensive to set up and use. Streaming mappings are usually set up for a single operation. Some architectures allow for significant optimizations when streaming mappings are used, as we see, but these mappings also are subject to a stricter set of rules in how they may be accessed. The kernel developers recommend the use of streaming mappings over coherent mappings whenever possible. There are two reasons for this recommendation. The first is that, on systems that support mapping registers, each DMA mapping uses one or more of them on the bus. Coherent mappings, which have a long lifetime, can monopolize these registers for a long time, even when they are not being used. The other reason is that, on some hardware, streaming mappings can be optimized in ways that are not available to coherent mappings. The two mapping types must be manipulated in different ways; it’s time to look at the details. A driver can set up a coherent mapping with a call to dma_alloc_coherent: This function handles both the allocation and the mapping of the buffer. The first two arguments are the device structure and the size of the buffer needed. The function returns the result of the DMA mapping in two places. The return value from the function is a kernel virtual address for the buffer, which may be used by the driver; the associated bus address, meanwhile, is returned in . Allocation is handled in this function so that the buffer is placed in a location that works with DMA; usually the memory is just allocated with get_free_pages (but note that the size is in bytes, rather than an order value). The argument is the usual value describing how the memory is to be allocated; it should usually be (usually) or (when running in atomic context). When the buffer is no longer needed (usually at module unload time), it should be returned to the system with dma_free_coherent: Note that this function, like many of the generic DMA functions, requires that all of the size, CPU address, and bus address arguments be provided. A DMA pool is an allocation mechanism for small, coherent DMA mappings. Mappings obtained from dma_alloc_coherent may have a minimum size of one page. If your device needs smaller DMA areas than that, you should probably be using a DMA pool. DMA pools are also useful in situations where you may be tempted to perform DMA to small areas embedded within a larger structure. Some very obscure driver bugs have been traced down to cache coherency problems with structure fields adjacent to small DMA areas. To avoid this problem, you should always allocate areas for DMA operations explicitly, away from other, non-DMA data structures. The DMA pool functions are defined in <linux/dmapool.h>. A DMA pool must be created before use with a call to: Here, is a name for the pool, is your device structure, is the size of the buffers to be allocated from this pool, is the required hardware alignment for allocations from the pool (expressed in bytes), and is, if nonzero, a memory boundary that allocations should not exceed. If is passed as 4096, for example, the buffers allocated from this pool do not cross 4-KB boundaries. When you are done with a pool, it can be freed with: You should return all allocations to the pool before destroying it. For this call, is the usual set of allocation flags. If all goes well, a region of memory (of the size specified when the pool was created) is allocated and returned. As with dma_alloc_coherent, the address of the resulting DMA buffer is returned as a kernel virtual address and stored in as a bus address. Unneeded buffers should be returned to the pool with: Streaming mappings have a more complicated interface than the coherent variety, for a number of reasons. These mappings expect to work with a buffer that has already been allocated by the driver and, therefore, have to deal with addresses that they did not choose. On some architectures, streaming mappings can also have multiple, discontiguous pages and multipart “scatter/gather” buffers. For all of these reasons, streaming mappings have their own set of mapping functions. When setting up a streaming mapping, you must tell the kernel in which direction the data is moving. Some symbols (of type ) have been defined for this purpose: These two symbols should be reasonably self-explanatory. If data is being sent to the device (in response, perhaps, to a write system call), should be used; data going to the CPU, instead, is marked with . If data can move in either direction, use . This symbol is provided only as a debugging aid. Attempts to use buffers with this “direction” cause a kernel panic. It may be tempting to just pick at all times, but driver authors should resist that temptation. On some architectures, there is a performance penalty to pay for that choice. When you have a single buffer to transfer, map it with dma_map_single: The return value is the bus address that you can pass to the device or if something goes wrong. Once the transfer is complete, the mapping should be deleted with dma_unmap_single: Here, the and arguments must match those used to map the buffer.\n• None The buffer must be used only for a transfer that matches the direction value given when it was mapped.\n• None Once a buffer has been mapped, it belongs to the device, not the processor. Until the buffer has been unmapped, the driver should not touch its contents in any way. Only after dma_unmap_single has been called is it safe for the driver to access the contents of the buffer (with one exception that we see shortly). Among other things, this rule implies that a buffer being written to a device cannot be mapped until it contains all the data to write.\n• None The buffer must not be unmapped while DMA is still active, or serious system instability is guaranteed. You may be wondering why the driver can no longer work with a buffer once it has been mapped. There are actually two reasons why this rule makes sense. First, when a buffer is mapped for DMA, the kernel must ensure that all of the data in that buffer has actually been written to memory. It is likely that some data is in the processor’s cache when dma_unmap_single is issued, and must be explicitly flushed. Data written to the buffer by the processor after the flush may not be visible to the device. Second, consider what happens if the buffer to be mapped is in a region of memory that is not accessible to the device. Some architectures simply fail in this case, but others create a bounce buffer. The bounce buffer is just a separate region of memory that is accessible to the device. If a buffer is mapped with a direction of , and a bounce buffer is required, the contents of the original buffer are copied as part of the mapping operation. Clearly, changes to the original buffer after the copy are not seen by the device. Similarly, bounce buffers are copied back to the original buffer by dma_unmap_single; the data from the device is not present until that copy has been done. Incidentally, bounce buffers are one reason why it is important to get the direction right. bounce buffers are copied both before and after the operation, which is often an unnecessary waste of CPU cycles. Occasionally a driver needs to access the contents of a streaming DMA buffer without unmapping it. A call has been provided to make this possible: This function should be called before the processor accesses a streaming DMA buffer. Once the call has been made, the CPU “owns” the DMA buffer and can work with it as needed. Before the device accesses the buffer, however, ownership should be transferred back to it with: The processor, once again, should not access the DMA buffer after this call has been made. Occasionally, you may want to set up a mapping on a buffer for which you have a pointer; this can happen, for example, with user-space buffers mapped with get_user_pages. To set up and tear down streaming mappings using pointers, use the following: The and arguments can be used to map part of a page. It is recommended, however, that partial-page mappings be avoided unless you are really sure of what you are doing. Mapping part of a page can lead to cache coherency problems if the allocation covers only part of a cache line; that, in turn, can lead to memory corruption and extremely difficult-to-debug bugs. Scatter/gather mappings are a special type of streaming DMA mapping. Suppose you have several buffers, all of which need to be transferred to or from the device. This situation can come about in several ways, including from a readv or writev system call, a clustered disk I/O request, or a list of pages in a mapped kernel I/O buffer. You could simply map each buffer, in turn, and perform the required operation, but there are advantages to mapping the whole list at once. Many devices can accept a scatterlist of array pointers and lengths, and transfer them all in one DMA operation; for example, “zero-copy” networking is easier if packets can be built in multiple pieces. Another reason to map scatterlists as a whole is to take advantage of systems that have mapping registers in the bus hardware. On such systems, physically discontiguous pages can be assembled into a single, contiguous array from the device’s point of view. This technique works only when the entries in the scatterlist are equal to the page size in length (except the first and last), but when it does work, it can turn multiple operations into a single DMA, and speed things up accordingly. Finally, if a bounce buffer must be used, it makes sense to coalesce the entire list into a single buffer (since it is being copied anyway). So now you’re convinced that mapping of scatterlists is worthwhile in some situations. The first step in mapping a scatterlist is to create and fill in an array of describing the buffers to be transferred. This structure is architecture dependent, and is described in <asm/scatterlist.h>. However, it always contains three fields: The pointer corresponding to the buffer to be used in the scatter/gather operation. The length of that buffer and its offset within the page To map a scatter/gather DMA operation, your driver should set the , , and fields in a entry for each buffer to be transferred. Then call: where is the number of scatterlist entries passed in. The return value is the number of DMA buffers to transfer; it may be less than . For each buffer in the input scatterlist, dma_map_sg determines the proper bus address to give to the device. As part of that task, it also coalesces buffers that are adjacent to each other in memory. If the system your driver is running on has an I/O memory management unit, dma_map_sg also programs that unit’s mapping registers, with the possible result that, from your device’s point of view, you are able to transfer a single, contiguous buffer. You will never know what the resulting transfer will look like, however, until after the call. Your driver should transfer each buffer returned by pci_map_sg. The bus address and length of each buffer are stored in the entries, but their location in the structure varies from one architecture to the next. Two macros have been defined to make it possible to write portable code: Returns the bus (DMA) address from this scatterlist entry. Returns the length of this buffer. Again, remember that the address and length of the buffers to transfer may be different from what was passed in to dma_map_sg. Once the transfer is complete, a scatter/gather mapping is unmapped with a call to dma_unmap_sg: Note that must be the number of entries that you originally passed to dma_map_sg and not the number of DMA buffers the function returned to you. Scatter/gather mappings are streaming DMA mappings, and the same access rules apply to them as to the single variety. If you must access a mapped scatter/gather list, you must synchronize it first: Normally, the DMA support layer works with 32-bit bus addresses, possibly restricted by a specific device’s DMA mask. The PCI bus, however, also supports a 64-bit addressing mode, the double-address cycle (DAC). The generic DMA layer does not support this mode for a couple of reasons, the first of which being that it is a PCI-specific feature. Also, many implementations of DAC are buggy at best, and, because DAC is slower than a regular, 32-bit DMA, there can be a performance cost. Even so, there are applications where using DAC can be the right thing to do; if you have a device that is likely to be working with very large buffers placed in high memory, you may want to consider implementing DAC support. This support is available only for the PCI bus, so PCI-specific routines must be used. To use DAC, your driver must include <linux/pci.h>. You must set a separate DMA mask: You can use DAC addressing only if this call returns . A special type ( ) is used for DAC mappings. To establish one of these mappings, call pci_dac_page_to_dma: DAC mappings, you will notice, can be made only from pointers (they should live in high memory, after all, or there is no point in using them); they must be created a single page at a time. The argument is the PCI equivalent of the used in the generic DMA layer; it should be , , or . DAC mappings require no external resources, so there is no need to explicitly release them after use. It is necessary, however, to treat DAC mappings like other streaming mappings, and observe the rules regarding buffer ownership. There is a set of functions for synchronizing DMA buffers that is analogous to the generic variety: As an example of how the DMA mappings might be used, we present a simple example of DMA coding for a PCI device. The actual form of DMA operations on the PCI bus is very dependent on the device being driven. Thus, this example does not apply to any real device; instead, it is part of a hypothetical driver called dad (DMA Acquisition Device). A driver for this device might define a transfer function like this: int dad_transfer(struct dad_dev *dev, int write, void *buffer, size_t count) { dma_addr_t bus_addr; /* Map the buffer for DMA */ dev->dma_dir = (write ? DMA_TO_DEVICE : DMA_FROM_DEVICE); dev->dma_size = count; bus_addr = dma_map_single(&dev->pci_dev->dev, buffer, count, dev->dma_dir); dev->dma_addr = bus_addr; /* Set up the device */ writeb(dev->registers.command, DAD_CMD_DISABLEDMA); writeb(dev->registers.command, write ? DAD_CMD_WR : DAD_CMD_RD); writel(dev->registers.addr, cpu_to_le32(bus_addr)); writel(dev->registers.len, cpu_to_le32(count)); /* Start the operation */ writeb(dev->registers.command, DAD_CMD_ENABLEDMA); return 0; } This function maps the buffer to be transferred and starts the device operation. The other half of the job must be done in the interrupt service routine, which looks something like this: void dad_interrupt(int irq, void *dev_id, struct pt_regs *regs) { struct dad_dev *dev = (struct dad_dev *) dev_id; /* Make sure it's really our device interrupting */ /* Unmap the DMA buffer */ dma_unmap_single(dev->pci_dev->dev, dev->dma_addr, dev->dma_size, dev->dma_dir); /* Only now is it safe to access the buffer, copy to user, etc. */ ... } Obviously, a great deal of detail has been left out of this example, including whatever steps may be required to prevent attempts to start multiple, simultaneous DMA operations. The ISA bus allows for two kinds of DMA transfers: native DMA and ISA bus master DMA. Native DMA uses standard DMA-controller circuitry on the motherboard to drive the signal lines on the ISA bus. ISA bus master DMA, on the other hand, is handled entirely by the peripheral device. The latter type of DMA is rarely used and doesn’t require discussion here, because it is similar to DMA for PCI devices, at least from the driver’s point of view. An example of an ISA bus master is the 1542 SCSI controller, whose driver is drivers/scsi/aha1542.c in the kernel sources. As far as native DMA is concerned, there are three entities involved in a DMA data transfer on the ISA bus: The controller holds information about the DMA transfer, such as the direction, the memory address, and the size of the transfer. It also contains a counter that tracks the status of ongoing transfers. When the controller receives a DMA request signal, it gains control of the bus and drives the signal lines so that the device can read or write its data. The device must activate the DMA request signal when it’s ready to transfer data. The actual transfer is managed by the DMAC; the hardware device sequentially reads or writes data onto the bus when the controller strobes the device. The device usually raises an interrupt when the transfer is over. The driver has little to do; it provides the DMA controller with the direction, bus address, and size of the transfer. It also talks to its peripheral to prepare it for transferring the data and responds to the interrupt when the DMA is over. The original DMA controller used in the PC could manage four “channels,” each associated with one set of DMA registers. Four devices could store their DMA information in the controller at the same time. Newer PCs contain the equivalent of two DMAC devices:[ ] the second controller (master) is connected to the system processor, and the first (slave) is connected to channel of the second controller.[ ] The channels are numbered from 0-7: channel 4 is not available to ISA peripherals, because it is used internally to cascade the slave controller onto the master. The available channels are, thus, 0-3 on the slave (the 8-bit channels) and 5-7 on the master (the 16-bit channels). The size of any DMA transfer, as stored in the controller, is a 16-bit number representing the number of bus cycles. The maximum transfer size is, therefore, 64 KB for the slave controller (because it transfers eight bits in one cycle) and 128 KB for the master (which does 16-bit transfers). Because the DMA controller is a system-wide resource, the kernel helps deal with it. It uses a DMA registry to provide a request-and-free mechanism for the DMA channels and a set of functions to configure channel information in the DMA controller. You should be used to kernel registries—we’ve already seen them for I/O ports and interrupt lines. The DMA channel registry is similar to the others. After <asm/dma.h> has been included, the following functions can be used to obtain and release ownership of a DMA channel: The argument is a number between 0 and 7 or, more precisely, a positive number less than . On the PC, is defined as to match the hardware. The argument is a string identifying the device. The specified name appears in the file /proc/dma, which can be read by user programs. The return value from request_dma is for success and or if there was an error. The former means that the requested channel is out of range, and the latter means that another device is holding the channel. We recommend that you take the same care with DMA channels as with I/O ports and interrupt lines; requesting the channel at open time is much better than requesting it from the module initialization function. Delaying the request allows some sharing between drivers; for example, your sound card and your analog I/O interface can share the DMA channel as long as they are not used at the same time. We also suggest that you request the DMA channel after you’ve requested the interrupt line and that you release it before the interrupt. This is the conventional order for requesting the two resources; following the convention avoids possible deadlocks. Note that every device using DMA needs an IRQ line as well; otherwise, it couldn’t signal the completion of data transfer. In a typical case, the code for open looks like the following, which refers to our hypothetical dad module. The dad device as shown uses a fast interrupt handler without support for shared IRQ lines. int dad_open (struct inode *inode, struct file *filp) { struct dad_device *my_device; /* ... */ if ( (error = request_irq(my_device.irq, dad_interrupt, SA_INTERRUPT, \"dad\", NULL)) ) return error; /* or implement blocking open */ if ( (error = request_dma(my_device.dma, \"dad\")) ) { free_irq(my_device.irq, NULL); return error; /* or implement blocking open */ } /* ... */ return 0; } The close implementation that matches the open just shown looks like this: Here’s how the /proc/dma file looks on a system with the sound card installed: It’s interesting to note that the default sound driver gets the DMA channel at system boot and never releases it. The entry is a placeholder, indicating that channel 4 is not available to drivers, as explained earlier. After registration, the main part of the driver’s job consists of configuring the DMA controller for proper operation. This task is not trivial, but fortunately, the kernel exports all the functions needed by the typical driver. The driver needs to configure the DMA controller either when read or write is called, or when preparing for asynchronous transfers. This latter task is performed either at open time or in response to an ioctl command, depending on the driver and the policy it implements. The code shown here is the code that is typically called by the read or write device methods. This subsection provides a quick overview of the internals of the DMA controller so you understand the code introduced here. If you want to learn more, we’d urge you to read <asm/dma.h> and some hardware manuals describing the PC architecture. In particular, we don’t deal with the issue of 8-bit versus 16-bit data transfers. If you are writing device drivers for ISA device boards, you should find the relevant information in the hardware manuals for the devices. The DMA controller is a shared resource, and confusion could arise if more than one processor attempts to program it simultaneously. For that reason, the controller is protected by a spinlock, called . Drivers should not manipulate the lock directly; however, two functions have been provided to do that for you: Acquires the DMA spinlock. This function also blocks interrupts on the local processor; therefore, the return value is a set of flags describing the previous interrupt state; it must be passed to the following function to restore the interrupt state when you are done with the lock. Returns the DMA spinlock and restores the previous interrupt status. The spinlock should be held when using the functions described next. It should not be held during the actual I/O, however. A driver should never sleep when holding a spinlock. The information that must be loaded into the controller consists of three items: the RAM address, the number of atomic items that must be transferred (in bytes or words), and the direction of the transfer. To this end, the following functions are exported by <asm/dma.h>: Indicates whether the channel must read from the device ( ) or write to it ( ). A third mode exists, , which is used to release control of the bus. Cascading is the way the first controller is connected to the top of the second, but it can also be used by true ISA bus-master devices. We won’t discuss bus mastering here. Assigns the address of the DMA buffer. The function stores the 24 least significant bits of in the controller. The argument must be a bus address (see the Section 15.4.3 earlier in this chapter). Assigns the number of bytes to transfer. The argument represents bytes for 16-bit channels as well; in this case, the number must be even. In addition to these functions, there are a number of housekeeping facilities that must be used when dealing with DMA devices: A DMA channel can be disabled within the controller. The channel should be disabled before the controller is configured to prevent improper operation. (Otherwise, corruption can occur because the controller is programmed via 8-bit data transfers and, therefore, none of the previous functions is executed atomically). This function tells the controller that the DMA channel contains valid data. The driver sometimes needs to know whether a DMA transfer has been completed. This function returns the number of bytes that are still to be transferred. The return value is after a successful transfer and is unpredictable (but not ) while the controller is working. The unpredictability springs from the need to obtain the 16-bit residue through two 8-bit input operations. This function clears the DMA flip-flop. The flip-flop is used to control access to 16-bit registers. The registers are accessed by two consecutive 8-bit operations, and the flip-flop is used to select the least significant byte (when it is clear) or the most significant byte (when it is set). The flip-flop automatically toggles when eight bits have been transferred; the programmer must clear the flip-flop (to set it to a known state) before accessing the DMA registers. Using these functions, a driver can implement a function like the following to prepare for a DMA transfer: Then, a function like the next one is used to check for successful completion of DMA: The only thing that remains to be done is to configure the device board. This device-specific task usually consists of reading or writing a few I/O ports. Devices differ in significant ways. For example, some devices expect the programmer to tell the hardware how big the DMA buffer is, and sometimes the driver has to read a value that is hardwired into the device. For configuring the board, the hardware manual is your only friend."
    }
]