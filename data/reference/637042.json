[
    {
        "link": "https://docs.unity3d.com/6000.0/Documentation/ScriptReference/Rigidbody.html",
        "document": "Adding a Rigidbody component to an object will put its motion under the control of Unity's physics engine. Even without adding any code, a Rigidbody object will be pulled downward by gravity and will react to collisions with incoming objects if the right Collider component is also present.\n\n\n\nThe Rigidbody also has a scripting API that lets you apply forces to the object and control it in a physically realistic way. For example, a car's behaviour can be specified in terms of the forces applied by the wheels. Given this information, the physics engine can handle most other aspects of the car's motion, so it will accelerate realistically and respond correctly to collisions.\n\n\n\nIn a script, the FixedUpdate function is recommended as the place to apply forces and change Rigidbody settings (as opposed to Update, which is used for most other frame update tasks). The reason for this is that physics updates are carried out in measured time steps that don't coincide with the frame update. FixedUpdate is called immediately before each physics update and so any changes made there will be processed directly.\n\n\n\nA common problem when starting out with Rigidbodies is that the game physics appears to run in \"slow motion\". This is actually due to the scale used for your models. The default gravity settings assume that one world unit corresponds to one metre of distance. With non-physical games, it doesn't make much difference if your models are all 100 units long but when using physics, they will be treated as very large objects. If a large scale is used for objects that are supposed to be small, they will appear to fall very slowly - the physics engine thinks they are very large objects falling over very large distances. With this in mind, be sure to keep your objects more or less at their scale in real life (so a car should be about 4 units = 4 metres, for example)."
    },
    {
        "link": "https://docs.unity3d.com/Manual/class-Rigidbody.html",
        "document": "Use the Rigidbody component to apply a Rigidbody to your GameObjectThe fundamental object in Unity scenes, which can represent characters, props, scenery, cameras, waypoints, and more. A GameObject’s functionality is defined by the Components attached to it. More info\n\nSee in Glossary. A Rigidbody provides a physics-based way to control the movement and position of a GameObject. Instead of the Transform properties, you can use simulated physics forces and torque to move the GameObject, and let the physics engineA system that simulates aspects of physical systems so that objects can accelerate correctly and be affected by collisions, gravity and other forces. More info\n\nSee in Glossary calculate the results. For more information, see Introduction to Rigidbody Physics.\n\nTo monitor the performance of a Rigidbody, use the Physics Debug Visualization tool.\n\nDefine the mass of the GameObject (in kilograms). Mass is set to 1 by default. As in real life, mass does not affect how quickly an item falls under gravity. To simulate resistance forces that slow down movement, use Drag. Define the decay rate of a Rigidbody’s linear velocity, to simulate drag, air resistance, or friction. Low values produce a slower decay rate, so that the GameObject moves faster for longer (this is useful for simulating heavy real-world objects). High values produce a faster decay rate, so that the GameObject slows down over a short amount of time (this is useful for simulating lightweight real-world objects). Define the decay rate of a Rigidbody’s rotational velocity, to simulate drag, air resistance, or friction. Low values produce a slower decay rate, so that the GameObject moves faster for longer (this is useful for simulating heavy real-world objects). High values produce a faster decay rate, so that the GameObject slows down over a short amount of time (this is useful for simulating lightweight real-world objects). Note that you cannot make the GameObject stop rotating just by setting its Angular Drag to infinity. Angular Drag is set to 0.05 by default. Automatic Center Of Mass \n\n Represents the average position of all mass in a Rigidbody for the purposes of physics calculations. By default it is computed from all colliders belonging to the Rigidbody, but can be modified via script. More info Enable Automatic Center Of Mass to use the physics system’s predicted center of mass for the Rigidbody, based on its shape and scale. Disable to set your own X, Y and Z coordinates for the center of mass. Enable Automatic Tensor to use the physics system’s predicted tensor and tensor rotation for the Rigidbody, based on all connected colliders \n\n An invisible shape that is used to handle physical collisions for an object. A collider doesn’t need to be exactly the same shape as the object’s mesh - a rough approximation is often more efficient and indistinguishable in gameplay. More info . Like mass, an inertia tensor defines how much force or torque is required to make a Rigidbody move; however, while mass affects linear movement, inertia tensor affects rotational movement. Disable to set your own X, Y and Z coordinates for the tensor instead (see properties below). Define the inertia tensor of this Rigidbody. The higher the Inertia Tensor value is, the more torque is required to make the Rigidbody rotate on its axis. Define the rotation of the inertia tensor. Toggle the effects of gravity on the Rigidbody. If enabled, the physics system applies a force to move the GameObject in the direction of simulated gravity (by default, down the y axis). Use Gravity is enabled by default. Toggle between physics-based and kinematic movement for the GameObject. When Is Kinematic is enabled, the physics system cannot apply forces to move or rotate the GameObject, instead, Unity can only move and rotate it via its Transform. See Introduction to Rigidbody physics: Rigidbody without physics-based movement for details. Is Kinematic is disabled by default. The Interpolate setting on a Rigidbody provides two options to smooth the appearance of a Rigidbody’s motion if it appears jittery at run time. These options are Interpolate and Extrapolate.\n\n\n\nBoth interpolation and extrapolation calculate the pose of the Rigidbody (that is, the position and rotation) between physics updates. Which one you should choose depends on which option produces the best visual outcome for your use case.\n\n\n\nFor detailed information on the Interpolate property, see Apply interpolation to a Rigidbody. Apply no interpolation or extrapolation. This is the default option. Use the pose and velocity of the Rigidbody from the previous two physics updates to calculate and apply the pose of the Rigidbody in the current frame.\n\n\n\nInterpolate is more accurate than Extrapolate, but it has a time lag of one physics update. It’s usually best for situations where accuracy is important; for example, if the Rigidbody’s velocity varies, or if there are other physics elements that influence the Rigidbody’s movement. Use the pose and velocity of the Rigidbody from the previous physics update, and predict the pose of the Rigidbody in the next physics update, to calculate and predict the pose in the current frame.\n\n\n\nExtrapolate makes the Rigidbody appear to move slightly ahead of where it should be, and can be slightly inaccurate. It’s usually best for situations where accuracy is not important; for example, if the Rigidbody moves at a constant velocity, and there are no other physics elements that influence the Rigidbody’s movement. Define how the physics system detects collisions between this Rigidbody’s collider and other colliders in the scene. Unity generates one collision per pair of colliders, and determines the method of collision detection based on this Collision Detection property. \n\n\n\nCollision Detection is set to Discrete by default. For more information on each collision detection type, see Continuous collision detection \n\n A collision detection method that calculates and resolves collisions over the entire physics simulation step. This can prevent fast-moving objects from tunnelling through walls during a simulation step. More info . The physics system uses discrete collision \n\n A collision occurs when the physics engine detects that the colliders of two GameObjects make contact or overlap, when at least one has a Rigidbody component and is in motion. More info detection to calculate collisions for this Rigidbody’s collider. Select Discrete if this Rigidbody is not involved in any fast-moving collisions. Discrete collision detection \n\n An automatic process performed by Unity which determines whether a moving GameObject with a Rigidbody and collider component has come into contact with any other colliders. More info is not very computationally intensive. The physics system uses sweep-based CCD to calculate collisions between this Rigidbody’s collider and any static colliders (that is, colliders without an associated Rigidbody). Select Continuous if this Rigidbody is involved in fast-moving collisions with static colliders. Sweep-based CCD is more computationally intensive than Discrete or Continuous Speculative. The physics system uses sweep-based CCD to calculate collisions between this Rigidbody’s collider and all other colliders, except for those that are set to Discrete collision detection. Select Continuous Dynamic if this Rigidbody is involved in fast-moving collisions with any colliders. Sweep-based CCD is more computationally intensive than Discrete or Continuous Speculative. The physics system uses speculative continuous collision detection \n\n A collision detection method that inflates broad-phase AABB of moving objects according to their velocities. This enables support for effects like rotations. More info to calculate collisions between this Rigidbody’s collider and all other colliders. Select Continuous Speculative if collision accuracy is not important for this Rigidbody. Speculative collision detection is more computationally intensive than Discrete, but less computationally intensive than Continuous or Continuous Dynamic. Stops the Rigidbody moving in the world X, Y and Z axes selectively. Stops the Rigidbody rotating around the local X, Y and Z axes selectively.\n\nThe Layer Overrides section provides properties that allow you to override the project-wide Layer-based collision detection settings for all colliders attached to this Rigidbody."
    },
    {
        "link": "https://discussions.unity.com/t/solved-correct-way-to-move-a-rigidbody-with-input/835512",
        "document": ""
    },
    {
        "link": "https://docs.unity.cn/Manual//class-Rigidbody.html",
        "document": "Automatic Center Of Mass \n\n Represents the average position of all mass in a Rigidbody for the purposes of physics calculations. By default it is computed from all colliders belonging to the Rigidbody, but can be modified via script. More info Enable Automatic Center Of Mass to use the physics system’s predicted center of mass for the Rigidbody, based on its shape and scale. Disable to set your own X, Y and Z coordinates for the center of mass.\n\nEnable Automatic Tensor to use the physics system’s predicted tensor and tensor rotation for the Rigidbody, based on all connected colliders \n\n An invisible shape that is used to handle physical collisions for an object. A collider doesn’t need to be exactly the same shape as the object’s mesh - a rough approximation is often more efficient and indistinguishable in gameplay. More info . Like mass, an inertia tensor defines how much force or torque is required to make a Rigidbody move; however, while mass affects linear movement, inertia tensor affects rotational movement. Disable to set your own X, Y and Z coordinates for the tensor instead (see properties below).\n\nDefine how the physics system detects collisions between this Rigidbody’s collider and other colliders in the scene. Unity generates one collision per pair of colliders, and determines the method of collision detection based on this Collision Detection property. \n\n\n\nCollision Detection is set to Discrete by default. For more information on each collision detection type, see Continuous collision detection \n\n A collision detection method that calculates and resolves collisions over the entire physics simulation step. This can prevent fast-moving objects from tunnelling through walls during a simulation step. More info .\n\nThe physics system uses discrete collision \n\n A collision occurs when the physics engine detects that the colliders of two GameObjects make contact or overlap, when at least one has a Rigidbody component and is in motion. More info detection to calculate collisions for this Rigidbody’s collider. Select Discrete if this Rigidbody is not involved in any fast-moving collisions. Discrete collision detection \n\n An automatic process performed by Unity which determines whether a moving GameObject with a Rigidbody and collider component has come into contact with any other colliders. More info is not very computationally intensive."
    },
    {
        "link": "https://discussions.unity.com/t/control-object-movement-using-rigidbody-addforce/469977",
        "document": ""
    },
    {
        "link": "https://discussions.unity.com/t/solved-player-movement-with-character-controller-and-joystick/689589",
        "document": ""
    },
    {
        "link": "https://medium.com/@jordantkay/building-the-core-movement-and-look-input-in-unitys-new-input-system-62a77f3963ba",
        "document": "The Structure: Correlation Between PlayerController.cs and PlayerLocomotionInput.cs\n\nThis script’s primary function is to collect input from the player. Using Unity’s New Input System, it listens for actions like movement and looking. The key here is the use of interfaces and callback methods tied to the input system, which ensures that input events are properly handled as they happen.\n\nCallbacks with the New Input System:\n• OnMove(InputValue value): When a player moves their joystick or presses a key for movement, this method receives the input and calculates a direction vector based on the X (horizontal) and Z (vertical) axis. This vector is stored for further use by the PlayerController.\n• OnLook(InputValue value): Similarly, this method captures the look input from the mouse or right stick and calculates a vector that will be used to rotate the camera and orient the player.\n\nThe Power of Callbacks: The new Input System’s event-based structure makes input handling more efficient. Instead of checking for input every frame (as you would in the old system), callbacks allow the system to respond immediately to input events, streamlining performance.\n\nThe PlayerController is where most of the movement logic happens. It takes the input values calculated in PlayerLocomotionInput.cs and translates them into actual movement and rotation for the character.\n• The controller calculates the character’s velocity based on input and applies it to the CharacterController component attached to the player object.\n• The math here breaks down to translating the input vector into motion along the game world’s X, Z, and Y axes, factoring in gravity and other forces.\n• To rotate the character based on camera input, PlayerController uses the input vector provided by OnLook. It then adjusts the character’s forward-facing direction to match the camera’s rotation. This ensures the character always moves in the direction the player is looking.\n\nCode Breakdown: How They Work Together\n\nHere’s how these two scripts interact:\n• PlayerLocomotionInput.cs collects player inputs, transforms them into movement and look vectors, and then passes this data to PlayerController.cs.\n• PlayerController.cs uses these vectors to calculate velocity and rotate the player in real-time. It applies the movement using Unity’s CharacterController component, ensuring smooth movement in all 8 directions.\n\nFor example, when you move the joystick to the left, OnMove in PlayerLocomotionInput triggers, updating the movement vector. The PlayerController then reads this vector, calculates the necessary velocity, and moves the character in the appropriate direction."
    },
    {
        "link": "https://discussions.unity.com/t/best-practice-when-creating-character-player-control-scripts/246818",
        "document": ""
    },
    {
        "link": "https://engineering.deptagency.com/creating-a-unity-animated-character-controller-with-c-best-practices-in-mind",
        "document": "Get started and apply some general C# coding best practices to help you create something that’s scalable from the very beginning and minimizes spaghetti code.\n\nOne of the most common things to do in unity is create a character controller so that you can take input and make something move and interact with its environment. There are lots of options for this along with tutorials on how to create your own, but what is often overlooked is how to make something that is maintainable and can scale as your game becomes more complex. Most tutorials produce code like this which is fine for understanding the basics of locomotion in Unity, but not something you would want to replicate for a character controller that will eventually have dozens of states.\n\nMy goal in this article is to help you get started and apply some general C# coding best practices along the way to help you create something that’s scalable from the very beginning and minimizes spaghetti code like the previous example.\n\nYou can download the source code from GitHub and here’s a video demo of what we are going to create:\n\nOur starting point will be a new scene with an empty game object added to represent the player, an empty game object to parent any ProBuilder game objects, a main camera and a Cinemachine FreeLook camera. We’ll add a few basic structures to our Environment and create some InputActions.\n\n\n\nYou can download our starting point from here: https://github.com/deptagency/animated-character-controller/releases/tag/step-0\n\nIf you want to learn more about the following topics, here are some useful links:\n\nWhen creating a character controller there are a few options available:\n\nWe’ll be using Unity’s Character Controller because we want to be able to interact with Unity’s physics (Nvidia PhysX) engine without having to implement our own collision handling but want to script how our character moves. This approach can become more restrictive when you want to have more control over collisions and outside of a tutorial we would be more likely to use a kinematic Rigidbody instead.\n\nThe first thing we are going to create is an interface to represent our characters' inputs. The reason for abstracting this is so that we can later reuse this controller with a different input implementation that might use something like a Nav Mesh Agent for an NPC instead of controlled input for our Player.\n\nSince we are only concerned with locomotion, we’ll create an interface and define it like this:\n• SpeedXZ represents the speed of horizontal movement clamped between zero and one.\n• RotationY represents the direction the character should face.\n• Jump represents whether we should jump (provided other conditions for a jump are satisfied).\n\nNow we can create a concrete implementation of this interface using Unity’s Input System:\n\nWe set the public variables in Update which runs every tick of our game. In addition to this we have methods that get called by Unity’s Input System for OnMovement, OnJump, and OnRun.\n\nFor OnMovement we convert the input to a using Z instead of Y axis since Unity (by default) uses Y for the vertical axis.\n\nOnJump we update our private variable to record the last time a jump was requested. This is so that we are more flexible in the timing of the jump input. Pressing the jump button fractionally too early can still be accepted instead of requiring pixel perfect timing.\n\nFor OnRun we just set our private variable to record the current state.\n\nThen, each time Update runs we can project the relative to our camera using so that the resulting DirectionXZ is relative to the camera’s perspective. Our RotationY just points in the same direction. SpeedXZ uses the magnitude with a multiplier based on whether we should be walking or running.\n\nBecause this script implements we can add it to our Player game object and assign the Main Camera to it. We also need to make sure that our Player game object has a Player Input component so that the Input System methods are called as we expect.\n\nIf we run the game now, we should be able to interact with our control schemes and see the values from our script change in the inspector.\n\nWe’re going to need something visual to know where our player is in the game world. Let’s download a free character mesh rigged for animation from Adobe’s mixamo.com. You can create a free account and then download any character you like, making sure to change the format to FBX for Unity (.Fbx).\n\nSave this to your Assets folder and highlight it from the Project panel. In the import settings, select the Rig tab and change the Animation Type to Humanoid and apply. This will create a Unity avatar based upon this character. Then, from the Animation tab, uncheck Import Animation and apply that. We will download animations later which we can apply for this avatar. Finally, drag the character into the scene as a child of your Player game object. Rename it to Avatar and reset the transform to make sure it is facing the forward (+Z) axis.\n\nNext thing to do is add a character controller to our Player game object. Update the Center.Y to half the height and update the height and radius until your collider covers your avatar without being oversized as shown in the example above with our Y Bot avatar. We are aligning the bottom of our collider with the floor which works well for a character controller but another popular approach is to float the collider above the feet to provide more flexibility for stair and slope traversal. This is something we might explore in a future post potentially.\n\nWith our player prepared, we just need to script out some motion but we want to avoid a messy and unmaintainable codebase so we are going to script that using a state machine pattern. Many Unity tutorials for a character controller will have a single script on the Player that handles input, collisions and movement without any state management at all. This doesn’t look problematic at first when you only have a few lines of code, but as you move beyond basic movement and want to handle idle, jumping, falling states etc you start to run into trouble. In addition to spaghetti code being hard to understand and maintain because of the hierarchy of if else statements, it can also begin to impact performance when you are checking all the logic for all states on every single update. There is really no need to check our falling logic when we are grounded for example.\n\nThis is the state machine we are going to create:\n\nA state machine works by managing a current state and owning the transition from one state to another. Individual states can implement a common abstraction that exposes methods the state machine can invoke as well as allowing states to interact with the state machine to conditionally change states or access the context to interact with other abstractions like input and our controller code.\n\nOur state abstraction will be similar to a with an Update method. We’ll have an empty constructor for any initialization (the equivalent of our Enter logic) and implement this as (the equivalent of our Exit logic). We’ll create a new instance of our next state whenever changing states.\n\nFirst we need to create our context interface:\n\nWe’ll return to this later to expose more properties and methods. Now, lets implement our abstract State Machine and State base classes:\n\nThis will show errors until we implement the abstract State class below but as you can see just handles changing from one state to another and allowing the current state to be updated.\n\nWe implement the methods as virtual so that they can be optionally overridden as needed. Next we can create our first state.\n\nThe first state we are going to create is our Moving state. In this state we can move around horizontally. This is where we will be able to use our to indirectly apply changes to our Character Controller. Instead of writing that code within the state for that we are going to use methods from that we will implement shortly. We do this so that we can avoid repeating the same logic in multiple places as several states will want to be able to move the character in this way.\n\nThe last thing we need is to create our implementation of . This governs the construction of our state machine and subsequent updates but also encapsulates any shared logic that we need to implement for controlling the character. By implementing also we can add this script as a component for our Player game object.\n\nWe have a Start method to retrieve any required components from our game object (and its children) and construct our state machine before setting the initial state.\n\nWe have an ApplyInputRotationY method to immediately rotate our game object but to avoid rotating too fast. We apply this directly to our transform because Unity’s Character Controller doesn’t deal with rotation. We also have an ApplyInputTranslationXZ method to accumulate translations to be later applied during our Update. We do this to avoid our character controller having to move the transform multiple times per tick.\n\nOur Update method runs every tick and first updates the state machine (which subsequently updates the current state), before we use our character controller to move the game object based on our cumulative translation vector. Finally, we reset that cumulative translation vector to zero so that we don’t reapply the same translations repeatedly.\n\nWe can now drag this script component onto our Player game object and play the scene to test our basic movement and should see something like this:\n\nNow we have a moving character, we should introduce some animation. However, we need to consider the concept of root motion before doing so. Root motion uses translation and rotation in the animations to apply motion to our character. Its advantage is that it avoids visual defects by misaligned motion and animation such as a sliding effect when the character moves faster and slower than the animation itself. We could use in-place animations but lets download some animations that are designed to use root motion and update our Moving state to utilize root motion instead.\n\nThe first thing we need to do is grab some animations so let’s return to Adobe’s mixamo.com and this time, go to the animations tab.\n\nDownload the following animations making sure to leave the in-place option unchecked:\n\nSave these to your Assets folder and highlight them from the Project panel. In the import settings, select the Rig tab and change the Animation Type to Humanoid, updating Avatar Definition to Copy From Other Avatar and selecting the avatar from earlier. Apply our changes. Then, from the Animation tab, check Loop Time and bake the Original root transform rotation and position (Y) to only keep root motion on the XZ plane.\n\nNow that we have some animations we can use Unity’s Mecanim Animation System to create some animation states and parameters for our base layer. This is also a state machine implementation that could be used with behaviors to separate concerns but is more suited to visual development than C# programming and can be opinionated when it comes to transitions and customization.\n\nInstead of having transitions and letting Mecanim decide what animation state is active, we will control the Animator from within our state machine implementation. As such, all we need are the states themselves and any parameters that are required by blend trees. There are lots of really detailed tutorials on the animation system and how it works but for these two animations we are simply going to create a 1D blend tree with 3 motions: Walking slowly, Walking, and Running. For Walking slowly we will just reuse the same Walking animation but play it at 0.5 speed. The blend parameter can be named SpeedXZ. Create an additional float parameter called SpeedY that we will use later too.\n\nBack in the code we will update our scripts to support root animation before applying it from our Moving state. First thing we need is a script to manage interactions with the Animator:\n\nThis script exposes methods to process (and reset) the root motion translation, update our Animator parameters such as SpeedXZ and SpeedY, and can cross fade to a specific animation state.\n\nRefactor to integration animation for our state machine\n\nThis is added to our Avatar game object and next we can update our ILocomotionContext interface:\n\nWe can now access our Animator from the in our state machine along with a method for applying root motion translation in our controller. Next we can update our to implement these new additions:\n\nThe last change is for our Moving state:\n\nIn the constructor we can cross fade to our Moving animation state and in Update we replaced our ApplyInputTranslationXZ with an alternative method call to ApplyRootMotionTranslation instead. Root motion could potentially affect our Y translation but because we baked the original root transform position (Y) in the animation clips that won’t be the case. We could implement something similar for root motion rotation but our animations don’t have any rotation so we aren’t concerned with that right now either.\n\nIf we run the game now we will have animated movement and be able to see the blend tree in effect when we press the run key (left shift) / button (gamepad west). We still move forward slowly even without any input but we will address this in the next section when adding additional states such as Idle.\n\nWe are at a point where we can start to see the benefit of our state machine now. We are going to add our second state which will be Idle and implement conditions for transitioning between the Moving and Idle states. This will prevent our character from moving when we don’t have any controller input. Idle is typically a more sensible starting state too, so we will update that at the same time.\n\nWe’ll need to download an Idle animation from Mixamo. Follow the same steps from earlier for an Idle animation and update the Import settings to use a humanoid rig with our avatar and bake the original rotation, and position across XZ and Y axis. Make sure you name the animation Idle and drag it into the Animator to create an animation state of the same name for that motion. Update the layer to use Idle as our default state and we are ready to make our script updates.\n\nWe will start by creating our new Idle state:\n\nThis is very similar to our moving state but we don’t call any methods to rotate or translate our character while Idle. Instead, we check for input magnitude and conditionally change to a Moving state. We can update our Moving state to include an inverse condition to conditionally change to an Idle state if we don’t have any input magnitude:\n\nWe can also optionally update our to use for the initial state change but these conditions would ensure that we quickly change to the correct state regardless of which starting state we choose.\n\nWe are now able to navigate our horizontal XZ plane but have not yet introduced the concept of gravity to ensure that our character remains grounded. If we remove the floor we continue to move horizontally but that’s not acceptable. Before we can introduce gravity we are going to create a Grounded state that encapsulates already being on the ground and we’ll move our Idle and Moving states to a sub-state machine within our Grounded state. This will allow us to avoid duplicating any logic that applies to both Idle and Moving and putting it in our Grounded state instead.\n\nThis Grounded state doesn’t map to an animation state. It’s only concerned with constructing a sub-state machine and conditionally setting its starting state to either Idle or Moving based on the input direction magnitude. It updates the sub-state machine every time it updates itself, and disposes the sub-state machine when it is disposed of. We can update our to use as the initial state it changes to and everything continues to work the same way as before, but now we are ready to introduce another new state to represent our character Falling.\n\nBefore we can fall we are going to need to be able to translate our character based on the effect of gravity. Gravity is usually approximated as an acceleration of 9.81m/s/s which means that every second the velocity on the -Y axis should increase by 9.81m/s which in turn means that every second the translation should changes based on the cumulative velocity produced by gravitational acceleration. Most games also include a multiplier so that gravity is higher than on Earth’s surface because this combined with a less realistic higher jump velocity produces that arcade feel.\n\nWe’re going to need to update our to support cumulative velocity and handle the gravitational acceleration. Let’s start with our interface:\n\nNow we can update our with some additional properties:\n\nWhen we are grounded and not moving upwards (+Y) we won’t apply gravity but will gently push our player into the ground using . We do this to ensure that our grounded collisions don’t suffer from the physics engine trying to resolve a collision and attempting to move our character just above the ground. Without this we could alternate between being Grounded and Falling every tick. If we aren’t grounded, we apply gravitational acceleration to our cumulative velocity but clamp to a terminal velocity to ensure there is a sensible maximum limit applied to our locomotion. We can set the value of in our Start method using our .\n\nWe need to apply these changes in our Update method:\n\nYou might have noticed that we are also setting the SpeedY parameter for our so let’s update that next using the same approach as we already have for SpeedXZ.\n\nWith the code in place we can create some animations for falling and landing along with equivalent states in our state machine. From mixamo.com, download animations for Falling Idle (renamed to Falling) and Falling to Landing (renamed to Landing) and Falling (renamed to Freefall). Update the import settings to use our Humanoid rig and avatar, and bake original rotation and position for all animations. Falling Idle and Falling can Loop Time also. Create a new 1D Blend Tree in your Animator called Falling and add motions for Falling and Freefall. Associate it with a new float property called SpeedY. It should look something like this:\n\nAlso drag your Landing animation into the Animator base layer to create a Landing animation state too. With the animation clips in place, let’s create our states:\n\nThis Landing state is really simple and just waits up to a maximum of 0.5 seconds before transitioning to our Grounded state. The faster we are moving horizontally, the less time we will spend in a Landing state. This state could also include a condition to immediately switch to a Falling state if we are no longer grounded to cater for cases where we only land momentarily but that’s a corner case we don’t need to handle right now.\n\nNext is our Falling state:\n\nOur Update method simply enables horizontal translation while falling and checks if we are grounded to conditionally change to the Landing state. We can adjust the multiplier for our movement if we want to be able to move less while airborne.\n\nWe now can change from Falling to Landing, and Landing to Grounded but we need to update our Grounded state to conditionally change to Falling before we can test this. In the GroundedState add the following condition to the end of our Update method:\n\nIf we run the game now, we should see our animated states in effect including a freefall animation as we approach terminal velocity.\n\nSince the hardest part of a jump is returning to the ground, adding a Jump state is pretty trivial. We’ll need to download another mixamo.com animation and import it in the usual way, baking the rotation and position for our downloaded animation clip. Dragging that into our Animator will create the animation state, and then we can script our Jump.\n\nAdd a float JumpHeight property defaulting to 2f along with a Jump method to our LocomotionController:\n\nThe jump velocity approximates the velocity necessary to overcome gravity and reach the defined jump height. Make sure to update to include this method so that we can call it from our states. With that in place, we can create our Jumping state:\n\nWe call the Jump method from the constructor and our Update method enables horizontal movement and checks when we reach the peak of our jump to transition to a Falling state.\n\nWe only want to be able to jump from a Grounded state, so update our GroundedState Update method to include the following condition:\n\nIf we test the jump now we’ll notice that the character jumps immediately but the animation crouches first giving an undesirable visual. We could use a coroutine to delay the change in velocity but I prefer an immediate jump so instead I will trim the animation clip to begin as the characters feet should leave the ground.\n\nFor the animation clip I chose, trimming the first 14.5ms is optimal. The last visual defect is a noticeable tilt as we transition from jumping to falling animation clips. This is because the falling animation start position and rotation is different to the end of the jumping animation end position and rotation. We can duplicate and edit our falling animation clip to fix this in Unity. Instead of covering that here, you can take a look at this video tutorial which is part of an excellent channel and series that covers Unity character controllers: https://youtu.be/hfBdtkC-nLg.\n\nIn the interest of brevity, there are some additional things we would typically implement that have been omitted from this tutorial. Some obvious next steps would include:\n• Projecting our movement onto a ground plane using its normal (the vector describing the orientation of a surface). This means that if we descend a slope we’ll bounce down as we alternate between falling and grounded states. By casting a ray down and getting the normal of the ground we can orient our movement along the ground to avoid this.\n• Implement a better way to navigate stairs. The character controller we used supports already but it’s a very crude implementation that we would normally enhance for a less jerky motion.\n• Replace the use of in our with an injected factory.\n\nThe purpose of the tutorial was to demonstrate the value of a state machine in the context of Unity character controllers and hopefully the benefit of this pattern was self-evident as we added more states to our character. We also demonstrated a structure that embraced SOLID principles so that we could change implementations like to reuse our character controller for other game objects like an NPC.\n\nIf you’re interested in learning more about DEPT’s capabilities with Unity for Gaming, XR, and experience development, or C# .NET in general, please reach out to us to discuss more."
    },
    {
        "link": "https://reddit.com/r/unrealengine/comments/109iej4/best_practices_for_character_controller",
        "document": "I'm going through and doing a massive code cleanup on my project right now, and I'm thinking about further breaking out the input handling over to my character controller class. The two relevant classes here are PlayerCharacter and PlayerCharacterController. Currently, the way the input is handled is as follows (using a simple jump command for an example):\n\nPlayerCharacterController.cpp (where PossessedPawn is a pre-cast reference to the PlayerCharacter)\n\nSimple enough and it works fine. However it also means I essentially end up with duplicate functions for every single one of my control inputs! Something like half of PlayerCharacter.cpp is just given over to handling these, something that in my mind should really be handled on the controller class.\n\nI've experimented, and this absolutely also works:\n\nNo need to have another function in the character class, the controller calls it directly. I'm now thinking of just rewriting the whole class this way.\n\nAre there any good reasons I shouldn't do things the second way? The only thing I can think of is that it might make it a little less modular, but I'm not planning on ever having another type of player-controlled pawn that wouldn't have all or most of the same functions (and if I did, it'd likely be so different as to warrant a whole separate controller class). The tradeoff of being able to remove a ton of pork from my character class and making it easier to manage seems worth it to me.\n\nPlease note this would apply to axis handling too, what about that? Would I see any performance hit from the controller having to call the character every tick for things like thumbstick inputs? Can't imagine I would (since it's got to call the character class either way), but figured I'd ask the community!"
    }
]