[
    {
        "link": "https://realpython.com/python-sockets",
        "document": "Socket programming is essential for network communication, enabling data exchange across different devices. In Python, sockets allow for inter-process communication (IPC) over networks. This tutorial provides a comprehensive guide on creating socket servers and clients, handling multiple connections, and managing errors in Python’s module.\n\nBy the end of this tutorial, you’ll understand that:\n• A socket in Python is an endpoint for sending or receiving data across a network using the socket API.\n• Socket programming in Python involves using sockets to establish communication between a server and clients over a network.\n• A simple echo server in Python can be created using sockets to listen for client connections and echo back received messages.\n• Handling multiple clients with Python sockets can be achieved using non-blocking sockets and the module for concurrent connections.\n• Connection errors in socket programs in Python can be managed by implementing error handling and using exceptions like .\n\nAlong the way, you’ll learn about the main functions and methods in Python’s module that let you write your own client-server applications based on TCP sockets. You’ll learn how to reliably send messages and data between endpoints and handle multiple connections simultaneously.\n\nNetworking and sockets are large subjects. Literal volumes have been written about them. If you’re new to sockets or networking, it’s completely normal if you feel overwhelmed with all of the terms and pieces. To get the most out of this tutorial, it’s best to download the source code and have it on hand for reference while reading:\n\nNow that you’ve gotten an overview of the socket API and how the client and server communicate, you’re ready to create your first client and server. You’ll begin with a simple implementation. The server will simply echo whatever it receives back to the client. Here’s the source code of the server: # Port to listen on (non-privileged ports are > 1023) Don’t worry about understanding everything above right now. There’s a lot going on in these few lines of code. This is just a starting point so you can see a basic server in action. Note: There’s a reference section at the end of this tutorial that has more information and links to additional resources. You’ll also find these and other useful links throughout the tutorial. Okay, so what exactly is happening in the API call? creates a socket object that supports the context manager type, so you can use it in a statement. There’s no need to call : # Use the socket object without calling s.close(). The arguments passed to are constants used to specify the address family and socket type. is the Internet address family for IPv4. is the socket type for TCP, the protocol that will be used to transport messages in the network. The method is used to associate the socket with a specific network interface and port number: The values passed to depend on the address family of the socket. In this example, you’re using (IPv4). So it expects a two-tuple: . can be a hostname, IP address, or empty string. If an IP address is used, should be an IPv4-formatted address string. The IP address is the standard IPv4 address for the loopback interface, so only processes on the host will be able to connect to the server. If you pass an empty string, the server will accept connections on all available IPv4 interfaces. represents the TCP port number to accept connections on from clients. It should be an integer from to , as is reserved. Some systems may require superuser privileges if the port number is less than . Here’s a note on using hostnames with : If you use a hostname in the host portion of IPv4/v6 socket address, the program may show a non-deterministic behavior, as Python uses the first address returned from the DNS resolution. The socket address will be resolved differently into an actual IPv4/v6 address, depending on the results from DNS resolution and/or the host configuration. For deterministic behavior use a numeric address in host portion. (Source) You’ll learn more about this later, in Using Hostnames. For now, just understand that when using a hostname, you could see different results depending on what’s returned from the name resolution process. These results could be anything. The first time you run your application, you might get the address . The next time, you get a different address, . The third time, you could get , and so on. In the server example, enables a server to accept connections. It makes the server a listening socket: The method has a parameter. It specifies the number of unaccepted connections that the system will allow before refusing new connections. Starting in Python 3.5, it’s optional. If not specified, a default value is chosen. If your server receives a lot of connection requests simultaneously, increasing the value may help by setting the maximum length of the queue for pending connections. The maximum value is system dependent. For example, on Linux, see . The method blocks execution and waits for an incoming connection. When a client connects, it returns a new socket object representing the connection and a tuple holding the address of the client. The tuple will contain for IPv4 connections or for IPv6. See Socket Address Families in the reference section for details on the tuple values. One thing that’s imperative to understand is that you now have a new socket object from . This is important because it’s the socket that you’ll use to communicate with the client. It’s distinct from the listening socket that the server is using to accept new connections: After provides the client socket object , an infinite loop is used to loop over blocking calls to . This reads whatever data the client sends and echoes it back using . If returns an empty object, , that signals that the client closed the connection and the loop is terminated. The statement is used with to automatically close the socket at the end of the block. Now, it’s time to look at the client’s source code: # The port used by the server In comparison to the server, the client is pretty simple. It creates a socket object, uses to connect to the server and calls to send its message. Lastly, it calls to read the server’s reply and then prints it. In this section, you’ll run the client and server to see how they behave and inspect what’s happening. Note: If you’re having trouble getting the examples or your own code to run from the command line, read How Do I Make My Own Command-Line Commands Using Python? or How to Run Your Python Scripts. If you’re on Windows, check the Python Windows FAQ. Open a terminal or command prompt, navigate to the directory that contains your scripts, ensure that you have Python 3.6 or above installed and on your path, then run the server: Your terminal will appear to hang. That’s because the server is blocked, or suspended, on : It’s waiting for a client connection. Now, open another terminal window or command prompt and run the client: In the server window, you should notice something like this: In the output above, the server printed the tuple returned from . This is the client’s IP address and TCP port number. The port number, , will most likely be different when you run it on your machine. To see the current state of sockets on your host, use . It’s available by default on macOS, Linux, and Windows. Here’s the netstat output from macOS after starting the server: Notice that is . If had used instead of , netstat would show this: is , which means all available host interfaces that support the address family will be used to accept incoming connections. In this example, was used (IPv4) in the call to . You can see this in the column: . The output above is trimmed to show the echo server only. You’ll likely see much more output, depending on the system you’re running it on. The things to notice are the columns , , and . In the last example above, netstat shows that the echo server is using an IPv4 TCP socket ( ), on port 65432 on all interfaces ( ), and it’s in the listening state ( ). Another way to access this, along with additional helpful information, is to use (list open files). It’s available by default on macOS and can be installed on Linux using your package manager, if it’s not already: gives you the , (process ID), and (user ID) of open Internet sockets when used with the option. Above is the echo server process. and have a lot of options available and differ depending on the OS that you’re running them on. Check the page or documentation for both. They’re definitely worth spending a little time with and getting to know. You’ll be rewarded. On macOS and Linux, use and . For Windows, use . Here’s a common error that you’ll encounter when a connection attempt is made to a port with no listening socket: Either the specified port number is wrong or the server isn’t running. Or maybe there’s a firewall in the path that’s blocking the connection, which can be easy to forget about. You may also see the error . Get a firewall rule added that allows the client to connect to the TCP port! There’s a list of common errors in the reference section.\n\nThe echo server definitely has its limitations. The biggest one is that it serves only one client and then exits. The echo client has this limitation too, but there’s an additional problem. When the client uses , it’s possible that it will return only one byte, from : The argument of used above is the maximum amount of data to be received at once. It doesn’t mean that will return bytes. The method also behaves this way. It returns the number of bytes sent, which may be less than the size of the data passed in. You’re responsible for checking this and calling as many times as needed to send all of the data: Applications are responsible for checking that all data has been sent; if only some of the data was transmitted, the application needs to attempt delivery of the remaining data. (Source) In the example above, you avoided having to do this by using : Unlike send(), this method continues to send data from bytes until either all data has been sent or an error occurs. is returned on success. (Source) You have two problems at this point:\n• How do you handle multiple connections concurrently?\n• You need to call and until all data is sent or received. What can you do? There are many approaches to concurrency. A popular approach is to use Asynchronous I/O. was introduced into the standard library in Python 3.4. The traditional choice is to use threads. The trouble with concurrency is it’s hard to get right. There are many subtleties to consider and guard against. All it takes is for one of these to manifest itself and your application may suddenly fail in not-so-subtle ways. This isn’t meant to scare you away from learning and using concurrent programming. If your application needs to scale, it’s a necessity if you want to use more than one processor or one core. However, for this tutorial, you’ll use something that’s even more traditional than threads and easier to reason about. You’re going to use the granddaddy of system calls: . The method allows you to check for I/O completion on more than one socket. So you can call to see which sockets have I/O ready for reading and/or writing. But this is Python, so there’s more. You’re going to use the selectors module in the standard library so that the most efficient implementation is used, regardless of the operating system you happen to be running on: This module allows high-level and efficient I/O multiplexing, built upon the select module primitives. Users are encouraged to use this module instead, unless they want precise control over the OS-level primitives used. (Source) Still, by using , you’re not able to run concurrently. That said, depending on your workload, this approach may still be plenty fast. It depends on what your application needs to do when it services a request, and the number of clients it needs to support. uses single-threaded cooperative multitasking and an event loop to manage tasks. With , you’ll be writing your own version of an event loop, albeit more simply and synchronously. When using multiple threads, even though you have concurrency, you currently have to use the GIL (Global Interpreter Lock) with CPython and PyPy. This effectively limits the amount of work you can do in parallel anyway. This is all to say that using may be a perfectly fine choice. Don’t feel like you have to use , threads, or the latest asynchronous library. Typically, in a network application, your application is I/O bound anyway: it could be waiting on the local network, for endpoints on the other side of the network, for disk writes, and so forth. If you’re getting requests from clients that initiate CPU bound work, look at the concurrent.futures module. It contains the class ProcessPoolExecutor, which uses a pool of processes to execute calls asynchronously. If you use multiple processes, the operating system is able to schedule your Python code to run in parallel on multiple processors or cores, without the GIL. For ideas and inspiration, see the PyCon talk John Reese - Thinking Outside the GIL with AsyncIO and Multiprocessing - PyCon 2018. In the next section, you’ll look at examples of a server and client that address these problems. They use to handle multiple connections simultaneously and call and as many times as needed.\n\nIn the next two sections, you’ll create a server and client that handles multiple connections using a object created from the selectors module. First, turn your attention to the multi-connection server. The first part sets up the listening socket: The biggest difference between this server and the echo server is the call to to configure the socket in non-blocking mode. Calls made to this socket will no longer block. When it’s used with , as you’ll see below, you can wait for events on one or more sockets and then read and write data when it’s ready. registers the socket to be monitored with for the events that you’re interested in. For the listening socket, you want read events: . To store whatever arbitrary data you’d like along with the socket, you’ll use . It’s returned when returns. You’ll use to keep track of what’s been sent and received on the socket. blocks until there are sockets ready for I/O. It returns a list of tuples, one for each socket. Each tuple contains a and a . The is a SelectorKey that contains a attribute. is the socket object, and is an event mask of the operations that are ready. If is , then you know it’s from the listening socket and you need to accept the connection. You’ll call your own function to get the new socket object and register it with the selector. You’ll look at that in a moment. If is not , then you know it’s a client socket that’s already been accepted, and you need to service it. is then called with and as arguments, and that’s everything you need to operate on the socket. Here’s what your function does: # Should be ready to read Because the listening socket was registered for the event , it should be ready to read. You call and then call to put the socket in non-blocking mode. Remember, this is the main objective in this version of the server because you don’t want it to block. If it blocks, then the entire server is stalled until it returns. That means other sockets are left waiting even though the server isn’t actively working. This is the dreaded “hang” state that you don’t want your server to be in. Next, you create an object to hold the data that you want included along with the socket using a . Because you want to know when the client connection is ready for reading and writing, both of those events are set with the bitwise OR operator: # Should be ready to read The mask, socket, and data objects are then passed to . Now take a look at to see how a client connection is handled when it’s ready: # Should be ready to read # Should be ready to write This is the heart of the simple multi-connection server. is the returned from that contains the socket object ( ) and data object. contains the events that are ready. If the socket is ready for reading, then will evaluate to , so is called. Any data that’s read is appended to so that it can be sent later. Note the block to check if no data is received: # Should be ready to read # Should be ready to write If no data is received, this means that the client has closed their socket, so the server should too. But don’t forget to call before closing, so it’s no longer monitored by . When the socket is ready for writing, which should always be the case for a healthy socket, any received data stored in is echoed to the client using . The bytes sent are then removed from the send buffer: # Should be ready to write The method returns the number of bytes sent. This number can then be used with slice notation on the buffer to discard the bytes sent. Now take a look at the multi-connection client, . It’s very similar to the server, but instead of listening for connections, it starts by initiating connections via : is read from the command-line and is the number of connections to create to the server. Just like the server, each socket is set to non-blocking mode. You use instead of because would immediately raise a exception. The method initially returns an error indicator, , instead of raising an exception that would interfere with the connection in progress. Once the connection is completed, the socket is ready for reading and writing and is returned by . After the socket is set up, the data you want to store with the socket is created using . The messages that the client will send to the server are copied using because each connection will call and modify the list. Everything needed to keep track of what the client needs to send, has sent, and has received, including the total number of bytes in the messages, is stored in the object . Check out the changes made from the server’s for the client’s version: def service_connection(key, mask): sock = key.fileobj data = key.data if mask & selectors.EVENT_READ: recv_data = sock.recv(1024) # Should be ready to read if recv_data: + if not recv_data or data.recv_total == data.msg_total: sel.unregister(sock) sock.close() if mask & selectors.EVENT_WRITE: + if not data.outb and data.messages: if data.outb: sent = sock.send(data.outb) # Should be ready to write data.outb = data.outb[sent:] It’s fundamentally the same but for one important difference. The client keeps track of the number of bytes it’s received from the server so that it can close its side of the connection. When the server detects this, it closes its side of the connection too. By doing this, the server depends on the client being well-behaved: the server expects the client to close its side of the connection when it’s done sending messages. If the client doesn’t close, the server will leave the connection open. In a real application, you may want to guard against this in your server by implementing a timeout to prevent client connections from accumulating if they don’t send a request after a certain amount of time. Now it’s time to run and . They both use command-line arguments. You can run them without arguments to see the options. For the server, pass and numbers: For the client, also pass the number of connections to create to the server, : Below is the server output when listening on the loopback interface on port 65432: python multiconn-server.py .0.0.1 Echoing b'Message 1 from client.Message 2 from client.' to ('127.0.0.1', 61354) Echoing b'Message 1 from client.Message 2 from client.' to ('127.0.0.1', 61355) Below is the client output when it creates two connections to the server above: python multiconn-client.py .0.0.1 Received b'Message 1 from client.Message 2 from client.' from connection 1 Received b'Message 1 from client.Message 2 from client.' from connection 2 Great! Now you’ve run the multi-connection client and server. In the next section, you’ll take this example even further.\n\nThe multi-connection client and server example is definitely an improvement compared with where you started. However, now you can take one more step and address the shortcomings of the previous example in a final implementation: the application client and server. You want a client and server that handle errors appropriately so that other connections aren’t affected. Obviously, your client or server shouldn’t come crashing down in a ball of fury if an exception isn’t caught. This is something you haven’t had to worry about until now, because the examples have intentionally left out error handling for brevity and clarity. Now that you’re familiar with the basic API, non-blocking sockets, and , you can add some error handling and address the elephant in the room, which the examples have kept hidden from you behind that large curtain over there. Remember that custom class that was mentioned way back in the introduction? That’s what you’re going to explore next. All errors raise exceptions. The normal exceptions for invalid argument types and out-of-memory conditions can be raised; starting from Python 3.3, errors related to socket or address semantics raise or one of its subclasses. (Source) So, one thing you need to do is catch . Another important consideration in relation to errors is timeouts. You’ll see them discussed in many places in the documentation. Timeouts happen and are a so-called normal error. Hosts and routers are rebooted, switch ports go bad, cables go bad, cables get unplugged, you name it. You should be prepared for these and other errors, handling them in your code. What about the elephant in the room? As hinted by the socket type , when using TCP, you’re reading from a continuous stream of bytes. It’s like reading from a file on disk, but instead you’re reading bytes from the network. However, unlike reading a file, there’s no . In other words, you can’t reposition the socket pointer, if there was one, and move around the data. When bytes arrive at your socket, there are network buffers involved. Once you’ve read them, they need to be saved somewhere, or else you will have dropped them. Calling again reads the next stream of bytes available from the socket. You’ll be reading from the socket in chunks. So, you need to call and save the data in a buffer until you’ve read enough bytes to have a complete message that makes sense to your application. It’s up to you to define and keep track of where the message boundaries are. As far as the TCP socket is concerned, it’s just sending and receiving raw bytes to and from the network. It knows nothing about what those raw bytes mean. This is why you need to define an application-layer protocol. What’s an application-layer protocol? Put simply, your application will send and receive messages. The format of these messages are your application’s protocol. In other words, the length and format that you choose for these messages define the semantics and behavior of your application. This is directly related to what you learned in the previous paragraph regarding reading bytes from the socket. When you’re reading bytes with , you need to keep up with how many bytes were read, and figure out where the message boundaries are. How can you do this? One way is to always send fixed-length messages. If they’re always the same size, then it’s easy. When you’ve read that number of bytes into a buffer, then you know you have one complete message. However, using fixed-length messages is inefficient for small messages where you’d need to use padding to fill them out. Also, you’re still left with the problem of what to do about data that doesn’t fit into one message. In this tutorial, you’ll learn a generic approach, one that’s used by many protocols, including HTTP. You’ll prefix messages with a header that includes the content length as well as any other fields you need. By doing this, you’ll only need to keep up with the header. Once you’ve read the header, you can process it to determine the length of the message’s content. With the content length, you can then read that number of bytes to consume it. You’ll implement this by creating a custom class that can send and receive messages that contain text or binary data. You can improve and extend this class for your own applications. The most important thing is that you’ll be able to see an example of how this is done. Before you get started, there’s something you need to know regarding sockets and bytes. As you learned earlier, when sending and receiving data via sockets, you’re sending and receiving raw bytes. If you receive data and want to use it in a context where it’s interpreted as multiple bytes, for example a 4-byte integer, you’ll need to take into account that it could be in a format that’s not native to your machine’s CPU. The client or server on the other end could have a CPU that uses a different byte order than your own. If this is the case, then you’ll need to convert it to your host’s native byte order before using it. This byte order is referred to as a CPU’s endianness. See Byte Endianness in the reference section for details. You’ll avoid this issue by taking advantage of Unicode for your message header and using the encoding UTF-8. Since UTF-8 uses an 8-bit encoding, there are no byte ordering issues. You can find an explanation in Python’s Encodings and Unicode documentation. Note that this applies to the text header only. You’ll use an explicit type and encoding defined in the header for the content that’s being sent, the message payload. This will allow you to transfer any data that you’d like (text or binary), in any format. You can easily determine the byte order of your machine by using . For example, you could see something like this: If you run this in a virtual machine that emulates a big-endian CPU (PowerPC), then something like this happens: In this example application, your application-layer protocol defines the header as Unicode text with a UTF-8 encoding. For the actual content in the message, the message payload, you’ll still have to swap the byte order manually if needed. This will depend on your application and whether or not it needs to process multi-byte binary data from a machine with a different endianness. You can help your client or server implement binary support by adding additional headers and using them to pass parameters, similar to HTTP. Don’t worry if this doesn’t make sense yet. In the next section, you’ll see how all of this works and fits together. Now you’ll fully define the protocol header. The protocol header is: The required headers, or sub-headers, in the protocol header’s dictionary are as follows: The byte order of the machine (uses ). This may not be required for your application. The length of the content in bytes. The type of content in the payload, for example, or . The encoding used by the content, for example, for Unicode text or for binary data. These headers inform the receiver about the content in the payload of the message. This allows you to send arbitrary data while providing enough information so that the content can be decoded and interpreted correctly by the receiver. Because the headers are in a dictionary, it’s easy to add additional headers by inserting key-value pairs as needed. There’s still a bit of a problem. You have a variable-length header, which is nice and flexible, but how do you know the length of the header when reading it with ? When you previously learned about using and message boundaries, you also learned that fixed-length headers can be inefficient. That’s true, but you’re going to use a small, 2-byte, fixed-length header to prefix the JSON header that contains its length. You can think of this as a hybrid approach to sending messages. In effect, you’re bootstrapping the message receive process by sending the length of the header first. This makes it easy for your receiver to deconstruct the message. To give you a better idea of the message format, check out a message in its entirety: A message starts with a fixed-length header of two bytes, which is an integer in network byte order. This is the length of the next header, the variable-length JSON header. Once you’ve read two bytes with , then you know you can process the two bytes as an integer and then read that number of bytes before decoding the UTF-8 JSON header. The JSON header contains a dictionary of additional headers. One of those is , which is the number of bytes of the message’s content (not including the JSON header). Once you’ve called and read bytes, then you’ve reached a message boundary, meaning you’ve read an entire message. Finally, the payoff! In this section, you’ll study the class and see how it’s used with when read and write events happen on the socket. This example application reflects what types of messages a client and server could reasonably use. You’re far beyond toy echo clients and servers at this point! To keep things simple and still demonstrate how things would work in a real application, this example uses an application protocol that implements a basic search feature. The client sends a search request and the server does a lookup for a match. If the request sent by the client isn’t recognized as a search, the server assumes it’s a binary request and returns a binary response. After reading the following sections, running the examples, and experimenting with the code, you’ll see how things work. You can then use the class as a starting point and modify it for your own use. The application is not that far off from the client and server example. The event loop code stays the same in and . What you’re going to do is move the message code into a class named and add methods to support reading, writing, and processing of the headers and content. This is a great example for using a class. As you learned before and you’ll see below, working with sockets involves keeping state. By using a class, you keep all of the state, data, and code bundled together in an organized unit. An instance of the class is created for each socket in the client and server when a connection is started or accepted. The class is mostly the same for both the client and the server for the wrapper and utility methods. They start with an underscore, like . These methods simplify working with the class. They help other methods by allowing them to stay shorter and support the DRY principle. The server’s class works in essentially the same way as the client’s and vice-versa. The difference is that the client initiates the connection and sends a request message, followed by processing the server’s response message. Conversely, the server waits for a connection, processes the client’s request message, and then sends a response message. With that, you should have a high-level overview of the individual components and their roles within the application. Understanding how the class works can be a challenge because there’s an aspect of its design that might not be immediately obvious. Why? Managing state. After a object is created, it’s associated with a socket that’s monitored for events using : # Should be ready to read The key idea here is that each object is created when a new connection is accepted. It’s associated with a socket and registered with a selector to monitor for incoming events. This setup allows the server to handle multiple connections concurrently, ensuring that messages can be read as soon as they’re available. Note: Some of the code examples in this section are from the server’s main script and class, but this section and discussion applies equally to the client as well. You’ll be alerted when the client’s version differs. When events are ready on the socket, they’re returned by . You can then get a reference back to the message object using the attribute on the object and call a method in : Looking at the event loop above, you’ll see that is in the driver’s seat. It’s blocking, waiting at the top of the loop for events. It’s responsible for waking up when read and write events are ready to be processed on the socket. Which means, indirectly, it’s also responsible for calling the method . That’s why is the entry point. Here’s what the method does: That’s good: is simple. It can only do two things: call and . This is where managing state comes in. If another method depended on state variables having a certain value, then they would only be called from and . This keeps the logic as simple as possible as events come in on the socket for processing. You might be tempted to use a mix of some methods that check the current state variables and, depending on their value, call other methods to process data outside or . In the end, this would likely prove too complex to manage and keep up with. You should definitely modify the class to suit your own needs so that it works best for you. But, you’ll probably have the best results if you keep the state checks and the calls to methods that depend on that state to the and methods if possible. Now look at . This is the server’s version, but the client’s is the same. It just uses a different method name, instead of : The method is called first. It calls to read data from the socket and store it in a receive buffer. Remember that when is called, all of the data that makes up a complete message may not have arrived yet. may need to be called again. This is why there are state checks for each part of the message before the appropriate method to process it is called. Before a method processes its part of the message, it first checks to make sure enough bytes have been read into the receive buffer. If they have, it processes its respective bytes, removes them from the buffer and writes its output to a variable that’s used by the next processing stage. Because there are three components to a message, there are three state checks and method calls: Next, check out . This is the server’s version: The method checks first for a . If one exists and a response hasn’t been created, is called. The method sets the state variable and writes the response to the send buffer. The method calls if there’s data in the send buffer. Remember that when is called, all of the data in the send buffer may not have been queued for transmission. The network buffers for the socket may be full, and may need to be called again. This is why there are state checks. The method should only be called once, but it’s expected that will need to be called multiple times. The client version of is similar: # Set selector to listen for read events, we're done writing. Because the client initiates a connection to the server and sends a request first, the state variable is checked. If a request hasn’t been queued, it calls . The method creates the request and writes it to the send buffer. It also sets the state variable so that it’s only called once. Just like for the server, calls if there’s data in the send buffer. The notable difference in the client’s version of is the last check to see if the request has been queued. This will be explained more in the section Client Main Script, but the reason for this is to tell to stop monitoring the socket for write events. If the request has been queued and the send buffer is empty, then you’re done writing and you’re only interested in read events. There’s no reason to be notified that the socket is writable. To wrap up this section, consider this thought: the main purpose of this section was to explain that is calling into the class via the method and to describe how state is managed. This is important because will be called many times over the life of the connection. Therefore, make sure that any methods that should only be called once are either checking a state variable themselves, or the state variable set by the method is checked by the caller. In the server’s main script , arguments are read from the command line that specify the interface and port to listen on: For example, to listen on the loopback interface on port , enter: Use an empty string for to listen on all interfaces. After creating the socket, a call is made to with the option : # Avoid bind() exception: OSError: [Errno 48] Address already in use Setting this socket option avoids the error Address already in use . You’ll see this when starting the server on a port that has connections in the TIME_WAIT state. For example, if the server actively closed a connection, it’ll remain in the state for two minutes or more, depending on the operating system. If you try to start the server again before the state expires, then you’ll get an exception of Address already in use . This is a safeguard to make sure that any delayed packets in the network aren’t delivered to the wrong application. The event loop catches any errors so that the server can stay up and continue to run: When a client connection is accepted, a object is created: # Should be ready to read The object is associated with the socket in the call to and is initially set to be monitored for read events only. Once the request has been read, you’ll modify it to listen for write events only. An advantage of taking this approach in the server is that in most cases, when a socket is healthy and there are no network issues, it’ll always be writable. If you told to also monitor , then the event loop would immediately wake up and notify you that this is the case. However, at this point, there’s no reason to wake up and call on the socket. There’s no response to send, because a request hasn’t been processed yet. This would consume and waste valuable CPU cycles. In the section Message Entry Point, you learned how the object was called into action when socket events were ready via . Now you’ll learn what happens as data is read on the socket and a component, or piece, of the message is ready to be processed by the server. The server’s message class is in , which is part of the source code you downloaded earlier. You can also download the code by clicking the link below: Get Your Code: Click here to get the free sample code you’ll use to learn about socket programming in Python. The methods appear in the class in the order in which processing takes place for a message. When the server has read at least two bytes, the fixed-length header can be processed: The fixed-length header is a 2-byte integer in network, or big-endian, byte order. It contains the length of the JSON header. You’ll use to read the value, decode it, and store it in . After processing the piece of the message it’s responsible for, removes it from the receive buffer. Just like with the fixed-length header, when there’s enough data in the receive buffer to contain the JSON header, it can be processed as well: The method is called to decode and deserialize the JSON header into a dictionary. Because the JSON header is defined as Unicode with a UTF-8 encoding, is hardcoded in the call. The result is saved to . After processing the piece of the message that it’s responsible for, removes it from the receive buffer. Next is the actual content, or payload, of the message. It’s described by the JSON header in . When bytes are available in the receive buffer, the request can be processed: # Set selector to listen for write events, we're done reading. After saving the message content to the variable, removes it from the receive buffer. Then, if the content type is JSON, decodes and deserializes it. If it’s not, this example application assumes that it’s a binary request and simply prints the content type. The last thing does is modify the selector to monitor write events only. In the server’s main script, , the socket is initially set to monitor read events only. Now that the request has been fully processed, you’re no longer interested in reading. A response can now be created and written to the socket. When the socket is writable, is called from : A response is created by calling other methods, depending on the content type. In this example application, a simple dictionary lookup is done for JSON requests when . For your own applications, you can define other methods that get called here. After creating the response message, the state variable is set so that doesn’t call again. Finally, the response is appended to the send buffer. This is seen by and sent via . One tricky bit to figure out is how to close the connection after the response is written. You can put the call to in the method : # Should be ready to write # Close when the buffer is drained. The response has been sent. Although it’s somewhat hidden, this is an acceptable trade-off given that the class only handles one message per connection. After the response is written, there’s nothing left for the server to do. It’s completed its work. In the client’s main script, , arguments are read from the command line and used to create requests and start connections to the server: After creating a dictionary representing the request from the command-line arguments, the host, port, and request dictionary are passed to : A socket is created for the server connection, as well as a object using the dictionary. Like for the server, the object is associated with the socket in the call to . However, for the client, the socket is initially set to be monitored for both read and write events. Once the request has been written, you’ll modify it to listen for read events only. This approach gives you the same advantage as the server: not wasting CPU cycles. After the request has been sent, you’re no longer interested in write events, so there’s no reason to wake up and process them. In the section Message Entry Point, you learned how the message object was called into action when socket events were ready via . Now you’ll learn what happens after data is read and written on the socket and a message is ready to be processed by the client. The client’s message class is in , which is part of the source code you downloaded earlier. You can also download the code by clicking the link below: Get Your Code: Click here to get the free sample code you’ll use to learn about socket programming in Python. The methods appear in the class in the order in which processing takes place for a message. The first task for the client is to queue the request: The dictionaries used to create the request, depending on what was passed on the command line, are in the client’s main script, . The request dictionary is passed as an argument to the class when a object is created. The request message is created and appended to the send buffer, which is then seen by and sent via . The state variable is set so that isn’t called again. After the request has been sent, the client waits for a response from the server. The methods for reading and processing a message in the client are the same as for the server. As response data is read from the socket, the header methods are called: and . The difference is in the naming of the final methods and the fact that they’re processing a response, not creating one: , , and . Last, but certainly not least, is the final call for : # Close when response has been processed Okay. You can now wrap the message class up. To conclude your learning about the class, it’s worth mentioning a couple of things that are important to notice with a few of the supporting methods. Any exceptions raised by the class are caught by the main script in the clause inside the event loop: # Check for a socket being monitored to continue. This is a really important line, for more than one reason! Not only does it make sure that the socket is closed, but also removes the socket from being monitored by . This greatly simplifies the code in the class and reduces complexity. If there’s an exception or you explicitly raise one yourself, you know will take care of the cleanup. The methods and also contain something interesting: # Should be ready to read The method has one too. These lines are important because they catch a temporary error and skip over it using . The temporary error is when the socket would block, for example if it’s waiting on the network or the other end of the connection, also known as its peer. By catching and skipping over the exception with , will eventually trigger a new call, and you’ll get another chance to read or write the data. After all of this hard work, it’s time to have some fun and run some searches! In these examples, you’ll run the server so that it listens on all interfaces by passing an empty string for the argument. This will allow you to run the client and connect from a virtual machine that’s on another network. It emulates a big-endian PowerPC machine. Now run the client and enter a search. See if you can find him: You might notice that the terminal is running a shell that’s using a text encoding of Unicode (UTF-8), so the output above prints nicely with emojis. Now see if you can find the puppies: Notice the byte string sent over the network for the request in the line. It’s easier to see if you look for the bytes printed in hex that represent the puppy emoji: . If your terminal is using Unicode with the encoding UTF-8, you’ll be able to enter the emoji for the search. This demonstrates that you’re sending raw bytes over the network and they need to be decoded by the receiver to be interpreted correctly. This is why you went to all of the trouble to create a header that contains the content type and encoding. Here’s the server output from both client connections above: python app-server.py Sending b'\\x00g{\"byteorder\": \"little\", \"content-type\": \"text/json\", \"content-encoding\": \"utf-8\", \"content-length\": 43}{\"result\": \"Follow the white rabbit. \\xf0\\x9f\\x90\\xb0\"}' to ('10.0.2.2', 55340) Look at the line to see the bytes that were written to the client’s socket. This is the server’s response message. You can also test sending binary requests to the server if the argument is anything other than : Because the request’s is not , the server treats it as a custom binary type and doesn’t perform JSON decoding. It simply prints the and returns the first ten bytes to the client: python app-server.py Sending b'\\x00\\x7f{\"byteorder\": \"little\", \"content-type\": \"binary/custom-server-binary-type\", \"content-encoding\": \"binary\", \"content-length\": 37}First 10 bytes of request: binary\\xf0\\x9f\\x98\\x83' to ('10.0.2.2', 55320) If everything is working as expected, you’re all set! However, if you run into any issues along the way, don’t worry. Here’s some guidance to help you get back on track.\n\nInevitably, something won’t work, and you’ll be wondering what to do. Don’t worry, it happens to everyone. Hopefully, with the help of this tutorial, your debugger, and your favorite search engine, you’ll be able to get going again with the source code part. If not, your first stop should be Python’s socket module documentation. Make sure you read all of the documentation for each function or method you’re calling. Also, read through the Reference section below for ideas. In particular, check the Errors section. Sometimes, it’s not all about the source code. The source code might be correct, and it’s just the other host, the client, or server. Or it could be the network. Maybe a router, firewall, or some other networking device is playing man-in-the-middle. For these types of issues, additional tools are essential. Below are a few tools and utilities that might help or at least provide some clues. will check if a host is alive and connected to the network by sending an ICMP echo request. It communicates directly with the operating system’s TCP/IP protocol stack, so it works independently from any application running on the host. Below is an example of running ping on macOS: Note the statistics at the end of the output. This can be helpful when you’re trying to discover intermittent connectivity problems. For example, is there any packet loss? How much latency is there? You can check the round-trip times. If there’s a firewall between you and the other host, a ping’s echo request may not be allowed. Some firewall administrators implement policies that enforce this. The idea is that they don’t want their hosts to be discoverable. If this is the case and you have firewall rules added to allow the hosts to communicate, then make sure that the rules also allow ICMP to pass between them. ICMP is the protocol used by , but it’s also the protocol TCP and other lower-level protocols use to communicate error messages. If you’re experiencing strange behavior or slow connections, this could be the reason. ICMP messages are identified by type and code. To give you an idea of the important information they carry, here are a few: See the article Path MTU Discovery for information regarding fragmentation and ICMP messages. This is an example of something that can cause strange behavior. In the section Viewing Socket State, you learned how can be used to display information about sockets and their current state. This utility is available on macOS, Linux, and Windows. That section didn’t mention the columns and in the example output. These columns will show you the number of bytes that are held in network buffers that are queued for transmission or receipt, but for some reason haven’t been read or written by the remote or local application. In other words, the bytes are waiting in network buffers in the operating system’s queues. One reason could be that the application is CPU bound or is otherwise unable to call or and process the bytes. Or there could be network issues affecting communications, like congestion or failing network hardware or cabling. To demonstrate this and see how much data you can send before seeing an error, you can try out a test client that connects to a test server and repeatedly calls . The test server never calls . It just accepts the connection. This causes the network buffers on the server to fill, which eventually raises an error on the client. Then run the client to see what the error is: Here’s output from while the client and server are still running, with the client printing out the error message above multiple times: The first entry is the server ( has port 65432): The second entry is the client ( has port 65432): The client sure was trying to write bytes, but the server wasn’t reading them. This caused the server’s network buffer queue to fill on the receive side and the client’s network buffer queue to fill on the send side. If you work with Windows, there’s a suite of utilities that you should definitely check out if you haven’t already: Windows Sysinternals. One of them is . TCPView is a graphical for Windows. In addition to addresses, port numbers, and socket state, it’ll show you running totals for the number of packets and bytes sent and received: Like with the Unix utility , you also get the process name and ID. Check the menus for other display options. Sometimes you need to see what’s happening on the wire. Forget about what the application log says or what the value is that’s being returned from a library call. You want to see what’s actually being sent or received on the network. Just like with debuggers, when you need to see it, there’s no substitute. Wireshark is a network protocol analyzer and traffic capture application that runs on macOS, Linux, and Windows, among others. There’s a GUI version named and also a terminal, text-based version named . Running a traffic capture is a great way to watch how an application behaves on the network and gather evidence about what it sends and receives, and how often and how much. You’ll also be able to see when a client or server closes or aborts a connection or stops responding. This information can be extremely helpful when you’re troubleshooting. There are many good tutorials and other resources on the web that will walk you through the basics of using Wireshark and TShark. Here’s an example of a traffic capture using Wireshark on the loopback interface: Here’s the same example shown above using : Next up, you’ll get more references to support your socket programming journey!\n\nYou can use this section as a general reference with additional information and links to external resources about networking and sockets. First, you may want to check out the Python official documentation: For further reading, consider exploring online tutorials and guides that provide practical examples and in-depth explanations of socket programming concepts. The following is from Python’s module documentation: All errors raise exceptions. The normal exceptions for invalid argument types and out-of-memory conditions can be raised; starting from Python 3.3, errors related to socket or address semantics raise or one of its subclasses. (Source) Here are some common errors you’ll probably encounter when working with sockets: Resource temporarily unavailable. For example, in non-blocking mode, when calling and the peer is busy and not reading, the send queue (network buffer) is full. Or there are issues with the network. Hopefully this is a temporary condition. Address already in use. Make sure that there’s not another process running that’s using the same port number and that your server is setting the socket option : . Connection reset by peer. The remote process crashed or did not close its socket properly, also known as an unclean shutdown. Or there’s a firewall or other device in the network path that’s missing rules or misbehaving. Operation timed out. No response from peer. Connection refused. No application listening on specified port. It’s good to familiarize yourself with these common socket errors, as understanding them can help you diagnose and troubleshoot network issues more effectively. and represent the address and protocol families used for the first argument to . APIs that use an address expect it to be in a certain format, depending on whether the socket was created with or : is a string with a hostname like or an IPv4 address like . is an integer. is a string with a hostname like or an IPv6 address like . is an integer. and represent the and members in the C struct . Note the excerpt below from Python’s socket module documentation regarding the value of the address tuple: For IPv4 addresses, two special forms are accepted instead of a host address: the empty string represents , and the string represents . This behavior is not compatible with IPv6, therefore, you may want to avoid these if you intend to support IPv6 with your Python programs. (Source) See Python’s Socket families documentation for more information. This tutorial uses IPv4 sockets, but if your network supports it, try testing and using IPv6 if possible. One way to support this easily is by using the function . It translates the and arguments into a sequence of five-tuples that contains all of the necessary arguments for creating a socket connected to that service. Note: will understand and interpret passed-in IPv6 addresses and hostnames that resolve to IPv6 addresses, in addition to IPv4. The following example returns address information for a TCP connection to on port : Results may differ on your system if IPv6 isn’t enabled. The values returned above can be used by passing them to and . There’s a client and server example in the Example section of Python’s socket module documentation. For context, this section applies mostly to using hostnames with and , or , when you intend to use the loopback interface, localhost. However, it also applies any time you’re using a hostname and there’s an expectation of it resolving to a certain address and having a special meaning to your application that affects its behavior or assumptions. This is in contrast to the typical scenario of a client using a hostname to connect to a server that’s resolved by DNS, like www.example.com. The following is from Python’s module documentation: If you use a hostname in the host portion of IPv4/v6 socket address, the program may show a non-deterministic behavior, as Python uses the first address returned from the DNS resolution. The socket address will be resolved differently into an actual IPv4/v6 address, depending on the results from DNS resolution and/or the host configuration. For deterministic behavior use a numeric address in host portion. (Source) The standard convention for the name “localhost” is for it to resolve to or , the loopback interface. This will more than likely be the case for you on your system, but maybe not. It depends on how your system is configured for name resolution. As with all things IT, there are always exceptions, and there are no guarantees that using the name “localhost” will connect to the loopback interface. For example, on Linux, see , the Name Service Switch configuration file. Another place to check on macOS and Linux is the file . On Windows, see . The file contains a static table of name-to-address mappings in a simple text format. DNS is another piece of the puzzle altogether. Interestingly enough, as of June 2018, there’s an RFC draft Let ‘localhost’ be localhost that discusses the conventions, assumptions, and security around using the name “localhost.” What’s important to understand is that when you use hostnames in your application, the returned addresses could literally be anything. Don’t make assumptions regarding a name if you have a security-sensitive application. Depending on your application and environment, this may or may not be a concern for you. Note: Security precautions and best practices still apply, even if your application isn’t explicitly security-sensitive. If your application accesses the network, it should be secured and maintained. This means, at a minimum:\n• System software updates and security patches are applied regularly, including Python. Are you using any third-party libraries? If so, make sure those are checked and updated too.\n• If possible, use a dedicated or host-based firewall to restrict connections to trusted systems only.\n• What DNS servers are configured? Do you trust them and their administrators?\n• Make sure that request data is sanitized and validated as much as possible prior to calling other code that processes it. Use fuzz tests for this and run them regularly. Regardless of whether or not you’re using hostnames, if your application needs to support secure connections through encryption and authentication, then you’ll probably want to look into using TLS. This is its own separate topic and beyond the scope of this tutorial. See Python’s ssl module documentation to get started. This is the same protocol that your web browser uses to connect securely to web sites. With interfaces, IP addresses, and name resolution to consider, there are many variables. What should you do? Here are some recommendations that you can use if you don’t have a network application review process: Use an IP address, such as or . Use an IP address, such as . To support more than one interface, use an empty string for all interfaces/addresses. See the security note above. Use an IP address, such as or . Use an IP address for consistency and non-reliance on name resolution. For the typical case, use a hostname. See the security note above. For clients or servers, if you need to authenticate the host that you’re connecting to, look into using TLS. A socket function or method that temporarily suspends your application is a blocking call. For example, , , , and block, meaning they don’t return immediately. Blocking calls have to wait on system calls (I/O) to complete before they can return a value. So you, the caller, are blocked until they’re done or a timeout or other error occurs. Blocking socket calls can be set to non-blocking mode so they return immediately. If you do this, then you’ll need to at least refactor or redesign your application to handle the socket operation when it’s ready. Because the call returns immediately, data may not be ready. The callee is waiting on the network and hasn’t had time to complete its work. If this is the case, then the current status is the value . Non-blocking mode is supported with .setblocking(). By default, sockets are always created in blocking mode. See Notes on socket timeouts for a description of the three modes. An interesting thing to note with TCP is that it’s completely legal for the client or server to close their side of the connection while the other side remains open. This is referred to as a “half-open” connection. It’s the application’s decision whether or not this is desirable. In general, it’s not. In this state, the side that has closed their end of the connection can no longer send data. They can only receive it. This approach isn’t necessarily recommended, but as an example, HTTP uses a header named “Connection” that’s used to standardize how applications should close or persist open connections. For details, see section 6.3 in RFC 7230, Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing. When designing and writing your application and its application-layer protocol, it’s a good idea to go ahead and work out how you expect connections to be closed. Sometimes this is obvious and simple, or it’s something that can take some initial prototyping and testing. It depends on the application and how the message loop is processed with its expected data. Just make sure that sockets are always closed in a timely manner after they complete their work. See Wikipedia’s article on endianness for details on how different CPUs store byte orderings in memory. When interpreting individual bytes, this isn’t a problem. However, when you’re handling multiple bytes that are read and processed as a single value, for example a 4-byte integer, the byte order needs to be reversed if you’re communicating with a machine that uses a different endianness. Byte order is also important for text strings that are represented as multi-byte sequences, like Unicode. Unless you’re always using true, strict ASCII and control the client and server implementations, you’re probably better off using Unicode with an encoding like UTF-8 or one that supports a byte order mark (BOM). It’s important to explicitly define the encoding used in your application-layer protocol. You can do this by mandating that all text is UTF-8 or using a “content-encoding” header that specifies the encoding. This prevents your application from having to detect the encoding, which you should avoid if possible. This becomes problematic when there is data involved that’s stored in files or a database and there’s no metadata available that specifies its encoding. When the data is transferred to another endpoint, it’ll have to try to detect the encoding. For a discussion, see Wikipedia’s Unicode article, which references RFC 3629: UTF-8, a transformation format of ISO 10646: However RFC 3629, the UTF-8 standard, recommends that byte order marks be forbidden in protocols using UTF-8, but discusses the cases where this may not be possible. In addition, the large restriction on possible patterns in UTF-8 (for instance there cannot be any lone bytes with the high bit set) means that it should be possible to distinguish UTF-8 from other character encodings without relying on the BOM. (Source) The takeaway from this is to always store the encoding used for data that’s handled by your application if it can vary. In other words, try to somehow store the encoding as metadata if it’s not always UTF-8 or some other encoding with a BOM. Then you can send that encoding in a header along with the data to tell the receiver what it is. The byte ordering used in TCP/IP is big-endian and is referred to as network order. Network order is used to represent integers in lower layers of the protocol stack, like IP addresses and port numbers. Python’s socket module includes functions that convert integers to and from network and host byte order: Convert 32-bit positive integers from network to host byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 4-byte swap operation. Convert 16-bit positive integers from network to host byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 2-byte swap operation. Convert 32-bit positive integers from host to network byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 4-byte swap operation. Convert 16-bit positive integers from host to network byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 2-byte swap operation. You can also use the module to pack and unpack binary data using format strings: The format string specifies that your data is packed as an unsigned short (2 bytes) in big-endian byte order, which is suitable for network transmission. Then, you use the same format specifier to unpack the binary data back into a Python integer."
    },
    {
        "link": "https://docs.python.org/3/howto/sockets.html",
        "document": "I’m only going to talk about INET (i.e. IPv4) sockets, but they account for at least 99% of the sockets in use. And I’ll only talk about STREAM (i.e. TCP) sockets - unless you really know what you’re doing (in which case this HOWTO isn’t for you!), you’ll get better behavior and performance from a STREAM socket than anything else. I will try to clear up the mystery of what a socket is, as well as some hints on how to work with blocking and non-blocking sockets. But I’ll start by talking about blocking sockets. You’ll need to know how they work before dealing with non-blocking sockets. Part of the trouble with understanding these things is that “socket” can mean a number of subtly different things, depending on context. So first, let’s make a distinction between a “client” socket - an endpoint of a conversation, and a “server” socket, which is more like a switchboard operator. The client application (your browser, for example) uses “client” sockets exclusively; the web server it’s talking to uses both “server” sockets and “client” sockets. Of the various forms of , sockets are by far the most popular. On any given platform, there are likely to be other forms of IPC that are faster, but for cross-platform communication, sockets are about the only game in town. They were invented in Berkeley as part of the BSD flavor of Unix. They spread like wildfire with the internet. With good reason — the combination of sockets with INET makes talking to arbitrary machines around the world unbelievably easy (at least compared to other schemes).\n\nRoughly speaking, when you clicked on the link that brought you to this page, your browser did something like the following: # now connect to the web server on port 80 - the normal http port When the completes, the socket can be used to send in a request for the text of the page. The same socket will read the reply, and then be destroyed. That’s right, destroyed. Client sockets are normally only used for one exchange (or a small set of sequential exchanges). What happens in the web server is a bit more complex. First, the web server creates a “server socket”: # bind the socket to a public host, and a well-known port A couple things to notice: we used so that the socket would be visible to the outside world. If we had used or we would still have a “server” socket, but one that was only visible within the same machine. specifies that the socket is reachable by any address the machine happens to have. A second thing to note: low number ports are usually reserved for “well known” services (HTTP, SNMP etc). If you’re playing around, use a nice high number (4 digits). Finally, the argument to tells the socket library that we want it to queue up as many as 5 connect requests (the normal max) before refusing outside connections. If the rest of the code is written properly, that should be plenty. Now that we have a “server” socket, listening on port 80, we can enter the mainloop of the web server: # now do something with the clientsocket # in this case, we'll pretend this is a threaded server There’s actually 3 general ways in which this loop could work - dispatching a thread to handle , create a new process to handle , or restructure this app to use non-blocking sockets, and multiplex between our “server” socket and any active s using . More about that later. The important thing to understand now is this: this is all a “server” socket does. It doesn’t send any data. It doesn’t receive any data. It just produces “client” sockets. Each is created in response to some other “client” socket doing a to the host and port we’re bound to. As soon as we’ve created that , we go back to listening for more connections. The two “clients” are free to chat it up - they are using some dynamically allocated port which will be recycled when the conversation ends. If you need fast IPC between two processes on one machine, you should look into pipes or shared memory. If you do decide to use AF_INET sockets, bind the “server” socket to . On most platforms, this will take a shortcut around a couple of layers of network code and be quite a bit faster.\n\nThe first thing to note, is that the web browser’s “client” socket and the web server’s “client” socket are identical beasts. That is, this is a “peer to peer” conversation. Or to put it another way, as the designer, you will have to decide what the rules of etiquette are for a conversation. Normally, the ing socket starts the conversation, by sending in a request, or perhaps a signon. But that’s a design decision - it’s not a rule of sockets. Now there are two sets of verbs to use for communication. You can use and , or you can transform your client socket into a file-like beast and use and . The latter is the way Java presents its sockets. I’m not going to talk about it here, except to warn you that you need to use on sockets. These are buffered “files”, and a common mistake is to something, and then for a reply. Without a in there, you may wait forever for the reply, because the request may still be in your output buffer. Now we come to the major stumbling block of sockets - and operate on the network buffers. They do not necessarily handle all the bytes you hand them (or expect from them), because their major focus is handling the network buffers. In general, they return when the associated network buffers have been filled ( ) or emptied ( ). They then tell you how many bytes they handled. It is your responsibility to call them again until your message has been completely dealt with. When a returns 0 bytes, it means the other side has closed (or is in the process of closing) the connection. You will not receive any more data on this connection. Ever. You may be able to send data successfully; I’ll talk more about this later. A protocol like HTTP uses a socket for only one transfer. The client sends a request, then reads a reply. That’s it. The socket is discarded. This means that a client can detect the end of the reply by receiving 0 bytes. But if you plan to reuse your socket for further transfers, you need to realize that there is no on a socket. I repeat: if a socket or returns after handling 0 bytes, the connection has been broken. If the connection has not been broken, you may wait on a forever, because the socket will not tell you that there’s nothing more to read (for now). Now if you think about that a bit, you’ll come to realize a fundamental truth of sockets: messages must either be fixed length (yuck), or be delimited (shrug), or indicate how long they are (much better), or end by shutting down the connection. The choice is entirely yours, (but some ways are righter than others). Assuming you don’t want to end the connection, the simplest solution is a fixed length message: The sending code here is usable for almost any messaging scheme - in Python you send strings, and you can use to determine its length (even if it has embedded characters). It’s mostly the receiving code that gets more complex. (And in C, it’s not much worse, except you can’t use if the message has embedded s.) The easiest enhancement is to make the first character of the message an indicator of message type, and have the type determine the length. Now you have two s - the first to get (at least) that first character so you can look up the length, and the second in a loop to get the rest. If you decide to go the delimited route, you’ll be receiving in some arbitrary chunk size, (4096 or 8192 is frequently a good match for network buffer sizes), and scanning what you’ve received for a delimiter. One complication to be aware of: if your conversational protocol allows multiple messages to be sent back to back (without some kind of reply), and you pass an arbitrary chunk size, you may end up reading the start of a following message. You’ll need to put that aside and hold onto it, until it’s needed. Prefixing the message with its length (say, as 5 numeric characters) gets more complex, because (believe it or not), you may not get all 5 characters in one . In playing around, you’ll get away with it; but in high network loads, your code will very quickly break unless you use two loops - the first to determine the length, the second to get the data part of the message. Nasty. This is also when you’ll discover that does not always manage to get rid of everything in one pass. And despite having read this, you will eventually get bit by it! In the interests of space, building your character, (and preserving my competitive position), these enhancements are left as an exercise for the reader. Lets move on to cleaning up. It is perfectly possible to send binary data over a socket. The major problem is that not all machines use the same formats for binary data. For example, network byte order is big-endian, with the most significant byte first, so a 16 bit integer with the value would be the two hex bytes . However, most common processors (x86/AMD64, ARM, RISC-V), are little-endian, with the least significant byte first - that same would be . Socket libraries have calls for converting 16 and 32 bit integers - where “n” means network and “h” means host, “s” means short and “l” means long. Where network order is host order, these do nothing, but where the machine is byte-reversed, these swap the bytes around appropriately. In these days of 64-bit machines, the ASCII representation of binary data is frequently smaller than the binary representation. That’s because a surprising amount of the time, most integers have the value 0, or maybe 1. The string would be two bytes, while a full 64-bit integer would be 8. Of course, this doesn’t fit well with fixed-length messages. Decisions, decisions.\n\nStrictly speaking, you’re supposed to use on a socket before you it. The is an advisory to the socket at the other end. Depending on the argument you pass it, it can mean “I’m not going to send anymore, but I’ll still listen”, or “I’m not listening, good riddance!”. Most socket libraries, however, are so used to programmers neglecting to use this piece of etiquette that normally a is the same as . So in most situations, an explicit is not needed. One way to use effectively is in an HTTP-like exchange. The client sends a request and then does a . This tells the server “This client is done sending, but can still receive.” The server can detect “EOF” by a receive of 0 bytes. It can assume it has the complete request. The server sends a reply. If the completes successfully then, indeed, the client was still receiving. Python takes the automatic shutdown a step further, and says that when a socket is garbage collected, it will automatically do a if it’s needed. But relying on this is a very bad habit. If your socket just disappears without doing a , the socket at the other end may hang indefinitely, thinking you’re just being slow. Please your sockets when you’re done. Probably the worst thing about using blocking sockets is what happens when the other side comes down hard (without doing a ). Your socket is likely to hang. TCP is a reliable protocol, and it will wait a long, long time before giving up on a connection. If you’re using threads, the entire thread is essentially dead. There’s not much you can do about it. As long as you aren’t doing something dumb, like holding a lock while doing a blocking read, the thread isn’t really consuming much in the way of resources. Do not try to kill the thread - part of the reason that threads are more efficient than processes is that they avoid the overhead associated with the automatic recycling of resources. In other words, if you do manage to kill the thread, your whole process is likely to be screwed up.\n\nIf you’ve understood the preceding, you already know most of what you need to know about the mechanics of using sockets. You’ll still use the same calls, in much the same ways. It’s just that, if you do it right, your app will be almost inside-out. In Python, you use to make it non-blocking. In C, it’s more complex, (for one thing, you’ll need to choose between the BSD flavor and the almost indistinguishable POSIX flavor , which is completely different from ), but it’s the exact same idea. You do this after creating the socket, but before using it. (Actually, if you’re nuts, you can switch back and forth.) The major mechanical difference is that , , and can return without having done anything. You have (of course) a number of choices. You can check return code and error codes and generally drive yourself crazy. If you don’t believe me, try it sometime. Your app will grow large, buggy and suck CPU. So let’s skip the brain-dead solutions and do it right. In C, coding is fairly complex. In Python, it’s a piece of cake, but it’s close enough to the C version that if you understand in Python, you’ll have little trouble with it in C: You pass three lists: the first contains all sockets that you might want to try reading; the second all the sockets you might want to try writing to, and the last (normally left empty) those that you want to check for errors. You should note that a socket can go into more than one list. The call is blocking, but you can give it a timeout. This is generally a sensible thing to do - give it a nice long timeout (say a minute) unless you have good reason to do otherwise. In return, you will get three lists. They contain the sockets that are actually readable, writable and in error. Each of these lists is a subset (possibly empty) of the corresponding list you passed in. If a socket is in the output readable list, you can be as-close-to-certain-as-we-ever-get-in-this-business that a on that socket will return something. Same idea for the writable list. You’ll be able to send something. Maybe not all you want to, but something is better than nothing. (Actually, any reasonably healthy socket will return as writable - it just means outbound network buffer space is available.) If you have a “server” socket, put it in the potential_readers list. If it comes out in the readable list, your will (almost certainly) work. If you have created a new socket to to someone else, put it in the potential_writers list. If it shows up in the writable list, you have a decent chance that it has connected. Actually, can be handy even with blocking sockets. It’s one way of determining whether you will block - the socket returns as readable when there’s something in the buffers. However, this still doesn’t help with the problem of determining whether the other end is done, or just busy with something else. Portability alert: On Unix, works both with the sockets and files. Don’t try this on Windows. On Windows, works with sockets only. Also note that in C, many of the more advanced socket options are done differently on Windows. In fact, on Windows I usually use threads (which work very, very well) with my sockets."
    },
    {
        "link": "https://datacamp.com/tutorial/a-complete-guide-to-socket-programming-in-python",
        "document": "Connecting devices to exchange information is what networking is all about. Sockets are an essential part of effective network communication as they are the underlying concept used to transmit messages between devices over local or global networks and different processes on the same machine. They provide a low-level interface that allows for fine-grained control over the traffic that is to be sent or received.\n\nThis low-level nature makes it possible to create very performant communication channels (or custom protocols) for specific use cases with low overhead that may be present in traditional protocols, which are built on top of socket communication.\n\nThis is what makes sockets exceptionally useful in real-time client-server applications that depend on instant message exchange or operate with huge amounts of data.\n\nIn this article, we will cover the basics of socket programming and provide a step-by-step guide to creating socket-based client and server applications using Python. So without further ado, let's dive right in!\n\nNetworking enables communication and information sharing of any kind.\n\nIt is a process of connecting two or more devices to allow them to exchange information. A collection of such interconnected devices is called a network.\n\nThere are a lot of networks that we can observe in our physical world: airline or powerline networks or cities interconnected with one another via highways are some good examples.\n\nIn much the same way, there are numerous networks in information technology; the most prominent and well-known of which is the internet, the global network of networks that connects myriad devices and the one that you are probably using right now to read this article.\n\nThe internet contains many more networks, which differ by scale or other properties, within itself: for example, local area networks (LANs), which typically link computers located in close proximity to one another. Machines in companies or other institutions (banks, universities, etc.) or even your home devices connected to a router comprise such a network.\n\nThere are also bigger or smaller types of networks like PANs (personal area network) which can simply be your smartphone connected to a laptop via Bluetooth, MANs (metropolitan area network), which can interconnect devices in the entire city, and WANs (wide area network), which can cover entire countries or the whole world. And yes, the biggest WAN network is the internet itself.\n\nIt goes without saying that computer networks can be very complex and consist of many elements. One of the most basic and crucial primitives is a communication protocol.\n\nCommunication protocols specify the rules of how and in what format information should be sent and received. These protocols are assembled into a hierarchy to manage the various tasks involved in network communication.\n\nIn other words, some protocols handle how hardware receives, sends, or routes packets, while others are more high-level and are concerned, for example, with application-level communication etc.\n\nSome commonly used and widely well-known network communication protocols include:\n\nAn example of a link layer protocol, meaning it sits very close to the hardware and is responsible for physically sending data from one device to another in a wireless environment.\n\nIP is a network layer protocol mainly responsible for routing packets and IP addressing.\n\nA reliable, connection-oriented protocol that provides full duplex communication and ensures data integrity and delivery. This is a transport layer protocol, which manages connections, detects errors, and controls information flow.\n\nA protocol from the same protocol suite as TCP. The main difference is that UDP is a more simple, fast, but unreliable connectionless protocol that does not perform any delivery checks and follows the paradigm of “fire-and-forget.” As TCP, UPD is also located on the transport layer.\n\nAn application layer protocol and the most commonly used protocol for browser-to-server communication on the web, used to serve websites in particular. It goes without saying that this article that you are reading right now was also served via HTTP. HTTP protocol builds on top of TCP and manages and transfers information relevant to web applications like headers, which are used to transfer metadata and cookies, different HTTP methods (GET, POST, DELETE, UPDATE) etc.\n\nAnother example of an application-level protocol used for devices with limited processing power and battery life, operating in unreliable network conditions (for example, gas sensors on a mining site or simply a smart light bulb in your house). MQTT is a standard messaging protocol used in IoT (Internet of Things). It is both lightweight and simple to use, designed with built-in retransmission mechanisms for enhanced reliability. If you're interested in using this protocol with Python, you can read this Python MQTT guide that provides an in-depth overview of the Paho MQTT client.\n\nAn important observation is that all the abovementioned protocols use sockets under the hood but add their own logic and data processing on top. This is due to sockets being a low-level interface for any network communications in modern devices as we will discuss in the next section.\n\nOf course, there are a lot of other important concepts and terms used in the context of networks. Here is a quick run-down on some of the most prominent ones that may arise in the rest of the tutorial:\n• Packet: a standard unit of data transmission in a computer network (one could colloquially compare it to the term “message”).\n• IP address: a numerical identifier that uniquely identifies a device on the network. An example of an IP address is: 192.168.0.0\n• Ports: a numerical identifier that uniquely identifies a process that is running on a device and handles particular network communications: for example, it serves your website over HTTP. While an IP address identifies the device, a port identifies the application (every application is a process or consists of processes). Some well-known port examples are: port 80, which is conventionally used by server applications to manage HTTP traffic, and port 443 for HTTPS (secure HTTP).\n• Gateway: a special kind of network node (device) which serves as an access point from one network to another. These networks may even use different protocols, so some protocol translation might be necessary to be performed by the gateway. An example of a gateway can be a router which connects a home local network to the Internet.\n\nA socket is an interface (gate) for communication between different processes located on the same or different machines. In the latter case, we speak about network sockets.\n\nNetwork sockets abstract away connection management. You can think of them as connection handlers. In Unix systems, in particular, sockets are simply files that support the same write-read operations but send all the data over the network.\n\nWhen a socket is in listening or connecting state, it is always bound to a combination of an IP address plus a port number which identifies the host (machine/device) and the process.\n\nSockets can listen for incoming connections or perform outbound connections themselves. When a connection is established, the listening socket (server socket) gets additionally bound to the IP and the port of the connecting side.\n\nOr alternatively, a new socket which is now bound to two pairs of IP addresses and port numbers of a listener and a requestor is created. This way, two connected sockets on different machines can identify one another and share a single connection for data transmission without blocking the listening socket that in the meantime continues listening for other connections.\n\nIn case of the connecting socket (client socket), it gets implicitly bound to the ip address of the device and a random accessible port number upon connection initiation. Then, upon connection establishment, a binding to the other communication side’s IP and port happens in much the same way as for a listening socket but without creating a new socket.\n\nSockets in the context of networks\n\nIn this tutorial, we are concerned not with socket implementation but with what sockets mean in the context of networks.\n\nOne can say that a socket is a connection endpoint (traffic destination) which is on one side associated with the host machine's IP address and the port number of the application for which the socket was created, and on the other, it is associated to the IP address and the port of the application running on another machine to which the connection is established.\n\nWhen we talk about socket programming, we instantiate socket objects in our code and perform operations on them (listen, connect, receive, send etc.). In this context, sockets are simply special objects we create in our program that have special methods for working with network connections and traffic.\n\nUnder the hood those methods call your operating system kernel, or more specifically, the network stack, which is a special part of the kernel responsible for managing network operations.\n\nNow, it’s also important to mention that sockets often appear in the context of client-server communication.\n\nThe idea is simple: sockets relate to connections; they are connection handlers. On the web, whenever you want to send or receive some data, you initiate a connection (which is being initiated through the interface called sockets).\n\nNow, either you or the party you are trying to connect to acts as a server and another party as a client. While a server serves data to clients, clients proactively connect and request data from a server. A server listens via a listening socket for new connections, establishes them, gets the client’s requests, and communicates the requested data in its response to the client.\n\nOn the other hand, a client creates a socket using the IP address and port of the server it wishes to connect to, initiates a connection, communicates its request to the server, and receives data in response. This seamless exchange of information between the client and server sockets forms the backbone of various network applications.\n\nThe fact that sockets form a backbone also means that there are various protocols built and used on top of them. Very common ones are UDP and TCP, which we have briefly talked about already. Sockets that use one of these transport protocols are called UDP or TCP sockets.\n\nApart from network sockets, there are also other types. For example, IPC (Inter Process Communication) sockets. IPC sockets are meant to transfer data between processes on the same machine, whereas network sockets can do the same across the network.\n\nThe good thing about IPC sockets is that they avoid a lot of the overhead of constructing packets and resolving the routes to send the data. Since in the context of IPC sender and receiver are local processes, communication via IPC sockets typically has lower latency.\n\nA good example of IPC sockets are Unix-sockets which are, as with everything in Unix, just files on the filesystem. They are not identified by the IP address and port but rather by the file path on the filesystem.\n\nNote that you can just as well use network sockets for inter-process communications if both server and receiver are on localhost (i.e., have an IP address 127.0.0.1).\n\nOf course, on the one hand, this adds additional latency because of the overhead associated with processing your data by the network stack, but on the other hand, this allows us not to worry about the underlying operating system, as network sockets are present and work on all systems as opposed to IPC sockets which are specific to a given OS or OS-family.\n\nFor socket programming in Python, we use the official built-in Python socket library consisting of functions, constants, and classes that are used to create, manage and work with sockets. Some commonly used functions of this library include:\n• bind(): Associates the socket to a specific address and port.\n• listen(): Starts listening for incoming connections on the socket.\n• accept(): Accepts a connection from a client and returns a new socket for communication.\n\nLet’s take a look at socket programming with a practical example written in Python. Here, our goal is to connect two applications and make them communicate with one another. We will be using Python socket library to create a server socket application that will communicate and exchange information with a client across a network.\n\nNote, however, that for educational purposes, our example is simplified, and the applications will be running locally and not talk over the actual network - we will use a loopback localhost address to connect the client to the server.\n\nThis means that both client and server will run on the same machine and the client will be initiating a connection to the same machine it is running on, albeit to a different process that represents the server.\n\nAlternatively, you could have your applications on two different devices and have them both connected to the same Wi-Fi router, which would form a local area network. Then the client running on one device could connect to the server running on a different machine.\n\nIn this case, however, you would need to know the IP addresses that your router assigned to your devices and use them instead of localhost (127.0.0.1) loopback IP address (to see IP addresses, use terminal command for Unix-like systems or - for Windows). After you obtain the IP addresses of your applications, you can change them in the code accordingly, and the example will still work.\n\nAnyway, we are going to start with our example. You will, of course, need to have Python installed if you want to follow along.\n\nLet’s start with creating a socket server (Python TCP server, in particular, since it will be working with TCP sockets, as we will see), which will exchange messages with clients. To clarify the terminology, while technically any server is a socket server, since sockets are always used under the hood to initiate network connections, we use the phrase “socket server” because our example explicitly makes use of socket programming.\n\nSo, follow the steps below:\n• Import the module in your Python script.\n• Add a function called . We will be adding most of our code there. When you add your code to the function, don’t forget to properly indent it:\n\nAs a next step, in , create a socket object using the function.\n\nThe first argument ( ) specifies the IP address family for IPv4 (other options include: for IPv6 family and for Unix-sockets)\n\nThe second argument ( indicates that we are using a TCP socket.\n\nIn case of using TCP, the operating system will create a reliable connection with in-order data delivery, error discovery and retransmission, and flow control. You will not have to think about implementing all those details.\n\nThere is also an option for specifying a UDP socket: . This will create a socket which implements all the features of UDP under the hood.\n\nIn case you want to go more low-level than that and build your own transport layer protocol on top of the TCP/IP network layer protocol used by sockets, you can use value for the second argument. In this case the operating system will not handle any higher level protocol features for you and you will have to implement all the headers, connection confirmation and retransmission functionalities yourself if you need them. There are also other values that you can read about in the documentation.\n\nDefine the hostname or server IP and port to indicate the address which the server will be reachable from and where it will listen for incoming connections. In this example, the server is listening on the local machine - this is defined by the variable set to (also called localhost).\n\nThe variable is set to , which is the port number that the server application will be identified by by the operating system (It is recommended to use values above 1023 for your port numbers to avoid collisions with ports used by system processes).\n\nPrepare the socket to receive connections by binding it to the IP address and port which we have defined before.\n\nSet up a listening state in the server socket using the function to be able to receive incoming client connections.\n\nThis function accepts an argument called which specifies the maximum number of queued unaccepted connections. In this example, we use the value for this argument. This means that only a single client can interact with the server. A connection attempt of any client performed while the server is working with another client will be refused.\n\nIf you specify a value that is bigger than , say , it tells the operating system how many clients can be put into the queue before the method is called on them.\n\nOnce is called a client is removed from the queue and is no longer counted towards this limit. This may become clearer once you see further parts of the code, but what this parameter essentially does can be illustrated as follows: once your listening server receives the connection request it will add this client to the queue and proceed to accepting it’s request. If before the server was able to internally call on the first client, it receives a connection request from a second client, it will push this second client to the same queue provided that there is enough space in it. The size of exactly this queue is controlled by the backlog argument. As soon as the server accepts the first client, this client is removed from the queue and the server starts communicating with it. The second client is still left in the queue, waiting for the server to get free and accept the connection.\n\nIf you omit the backlog argument, it will be set to your system’s default (under Unix, you can typically view this default in the file).\n\nNext, wait and accept incoming client connections. The method stalls the execution thread until a client connects. Then it returns a tuple pair of , where address is a tuple of the client's IP address and port, and is a new socket object which shares a connection with the client and can be used to communicate with it.\n\ncreates a new socket to communicate with the client instead of binding the listening socket (called in our example) to the client's address and using it for the communication, because the listening socket needs to listen to further connections from other clients, otherwise it would be blocked. Of course, in our case, we only ever handle a single client and refuse all the other connections while doing so, but this will be more relevant once we get to the multithreaded server example.\n\nAs soon as a connection with the client has been established (after calling the method), we initiate an infinite loop to communicate. In this loop, we perform a call to the method of the object. This method receives the specified number of bytes from the client - in our case 1024.\n\n1024 bytes is just a common convention for the size of the payload, as it’s a power of two which is potentially better for optimization purposes than some other arbitrary value. You are free to change this value however you like though.\n\nSince the data received from the client into the variable is in raw binary form, we transformed it from a sequence of bytes into a string using the function.\n\nThen we have an if statement, which breaks out of the communication loop in case we receive a message. This means that as soon as our server gets a string in request, it sends the confirmation back to the client and terminates its connection with it. Otherwise, we print the received message to the console. Confirmation in our case is just sending a string to the client.\n\nNote that the method that we use on the string in the if statement, simply converts it to lowercase. This way we don’t care whether the string was originally written using uppercase or lowercase characters.\n\nNow we should handle the normal response of the server to the client (that is when the client doesn’t wish to close the connection). Inside the while loop, right after , add the following lines, which will convert a response string ( in our case) to bytes and send it to the client. This way whenever server receives a message from the client which is not , it will send out the string in response:\n\nOnce we break out from the infinite while loop, the communication with the client is complete, so we close the client socket using the method to release system resources. We also close the server socket using the same method, which effectively shuts down our server. In a real world scenario, we would of course probably want our server to continue listening to other clients and not shut down after communicating with just a single one, but don’t worry, we will get to another example further below.\n\nFor now, add the following lines after the infinite while loop:\n\nNote: don’t forget to call the function at the end of your file. Simply use the following line of code:\n\nHere is the complete source code:\n\nNote that in order not to convolute and complicate this basic example, we omitted the error handling. You would of course want to add try-except blocks and make sure that you always close the sockets in the clause. Continue reading and we will see a more advanced example.\n\nAfter setting up your server, the next step is to set up a client that will connect and send requests to your server. So, let’s start with the steps below:\n• Define the function where we will place all our code:\n\nNext, use the function to create a TCP socket object which serves as the client's point of contact with the server.\n\nSpecify the IP address and port of the server to be able to connect to it. These should match the ip address and port that you set in before.\n\nEstablish a connection with the server using the method on the client socket object. Note that we did not bind the client socket to any IP address or port. This is normal for the client, because will automatically choose a free port and pick up an IP address that provides the best route to the server from the system’s network interfaces ( in our case) and bind the client socket to those.\n\nAfter having established a connection, we start an infinite communication loop to send multiple messages to the server. We get input from the user using Python’s built-in function, then encode it into bytes and trim to be 1024 bytes at max. After that we send the message to the server using .\n\nOnce the server receives a message from the client, it responds to it. Now, in our client code, we want to receive the server's response. For that, in the communication loop, we use the method to read 1024 bytes at most. Then we convert the response from bytes into a string using and then check if it is equal to the value . If this is the case, we break out of the loop which as we later see, will terminate the client’s connection. Otherwise, we print the server’s response into the console.\n\nFinally, after the while loop, close the client socket connection using the method. This ensures that resources are properly released and the connection is terminated (i.e. when we receive the message and break out of the while loop).\n\nNote: Again, don’t forget to call the function, which we have implemented above, at the end of the file as follows:\n\nHere is the complete code:\n\nTo test the the server and client implementation that we wrote above, perform the following:\n• In one terminal window, navigate to the directory where the file is located and run the following command to start the server:\n\nThis will bind the server socket to the localhost address (127.0.0.1) on port 8000 and start listening for incoming connections.\n• In the other terminal, navigate to the directory where the file is located and run the following command to start the client:\n\nThis will prompt for user input. You can then type in your message and press Enter. This will transfer your input to the server and display it in its terminal window. The server will send its response to the client and the latter will ask you for the input again. This will continue until you send the string to the server.\n\nWe have seen how a server responds to requests from a single client in the previous example, however, in many practical situations, numerous clients may need to connect to a single server at once. This is where multithreading comes in. Multithreading is used in situations where you need to handle several tasks (e.g. execute multiple functions) concurrently (at the same time).\n\nThe idea is to spawn a thread which is an independent set of instructions that can be handled by the processor. Threads are much more lightweight than the processes because they actually live within a process itself and you don’t have to allocate a lot of resources for themselves.\n\nNote that multithreading in Python is limited. Standard Python implementation (CPython) cannot run threads truly in parallel. Only a single thread is allowed to execute at a time due to the global interpreter lock (GIL). This is, however, a separate topic, which we are not going to discuss. For the sake of our example, using limited CPython threads is enough and gets the point across. In a real-world scenario, however, if you are going to use Python, you should look into asynchronous programming. We are not going to talk about it now, because it is again a separate topic and it usually abstracts away some low-level socket operations which we specifically focus on in this article.\n\nLet's look at the example below on how multithreading may be added to your server to handle a large number of clients. Note that this time we will also add some basic error handling using the try-except-finally blocks. To get started, follow the steps below:\n\nIn your python file, import the and modules to be able to work with both sockets and threads:\n\nDefine the function which will, as in the example above, create a server socket, bind it and listen to the incoming connections. Then call in an infinite while loop. This will always keep listening for new connections. After gets an incoming connection and returns, create a thread using constructor. This thread will execute the function which we are going to define later, and pass and to it as arguments ( tuple holds an IP address and a port of the connected client). After the thread is created, we call on it to begin its execution.\n\nRemember that call is blocking, so on the first iteration of the while loop, when we reach the line with , we halt and wait for a client connection without executing anything else. As soon as the client connects, method returns, and we continue the execution: spawn a thread, which will handle said client and go to the next iteration where we will again halt at the call waiting for another client to connect.\n\nAt the end of the function, we have some error handling which ensures that the server socket is always closed in case something unexpected happens.\n\nNote that the server in our example will only be stopped in case an unexpected error occurs. Otherwise, it will listen for the clients indefinitely, and you will have to kill the terminal if you want to stop it.\n\nNow, above the function, define another one called . This function will be the one executing in a separate thread for every client’s connection. It receives the client's socket object and the tuple as arguments.\n\nInside this function, we do the same as we did in a single threaded example plus some error handling: we start a loop to get messages from the client using .\n\nThen we check if we got a close message. If so, we respond with the string and close the connection by breaking out of the loop. Otherwise, we print out the client’s request string into the console and proceed to the next loop iteration to receive the next client’s message.\n\nAt the end of this function, we have some error handling for unexpected cases ( clause), and also a clause where we release using . This clause will always be executed no matter what, which ensures that the client socket is always properly released.\n\nWhen returns, the thread which executes it, will also be automatically released.\n\nNote: Don’t forget to call the function at the end of your file.\n\nNow, let's put the complete multithreading server code together:\n\nNote: In a real-world code, to prevent possible problems like race situations or data inconsistencies while dealing with multithreaded servers, it's vital to take thread safety and synchronization techniques into consideration. In our simple example this is, however, not a problem.\n\nNow that we have a server implementation able to handle multiple clients concurrently, we could use the same client implementation as seen above in the first basic examples to initiate connection, or we could update it slightly and add some error handling. Below you can find the code, which is identical to the previous client example with an addition of try-except blocks:\n\nIf you want to test the multi-client implementation, open several terminal windows for clients and one for the server. First start the server with . After that start a couple clients using . In the server terminal windows you will see how new clients get connected to the server. You can now proceed with sending messages from different clients by entering text into the respective terminals and all of them will be handled and printed to the console on the server side.\n\nWhile every network application uses sockets created by the OS under the hood, there are numerous systems that heavily rely on socket programming specifically, either for certain special use cases or to improve the performance. But how exactly is socket programming useful in the context of data science? Well, it definitely plays a meaningful role, whenever there is a need to receive or send huge amounts of data fast. Hence, socket programming is mainly used for data collection and real-time processing, distributed computing, and inter-process communication. But let's have a closer look at some particular applications in the field of data science.\n\nSockets are widely used to collect real-time data from different sources for further processing, forwarding to a database or to an analytics pipeline etc. For example, a socket can be used to instantly receive data from a financial system or social media API for subsequent processing by data scientists.\n\nData scientists may use socket connectivity to distribute the processing and computation of huge data sets across multiple machines. Socket programming is commonly used in Apache Spark and other distributed computing frameworks for communication between the nodes.\n\nSocket programming can be used when serving machine learning models to the users, allowing for instantaneous delivery of predictions and suggestions. In order to facilitate real-time decision-making, data scientists may use performant socket-based server applications that take in large amounts of data, process it using trained models to provide predictions, and then rapidly return the findings to the client.\n\nSockets can be used for IPC, which allows different processes running on the same machine to communicate with each other and exchange data. This is useful in data science to distribute complex and resource intensive computations across multiple processes. In fact, Python’s subprocessing library is often used for this purpose: it spawns several processes to utilize multiple processor cores and increase application performance when performing heavy calculations. Communication between such processes may be implemented via IPC sockets.\n\nSocket programming allows for real-time communication and collaboration among data scientists. In order to facilitate effective collaboration and knowledge sharing, socket-based chat apps or collaborative data analysis platforms are used.\n\nIt’s worth saying that in many of the above applications, data scientists might not be directly involved in working with sockets. They would typically use libraries, frameworks, and systems that abstract away all the low-level details of socket programming. However, under the hood all such solutions are based on socket communication and utilize socket programming.\n\nBecause sockets are a low-level concept of managing connections, developers working with them have to implement all the required infrastructure around to create robust and reliable applications. This of course comes with a lot of challenges. However, there are some best practices and general guidelines one may follow to overcome these issues. Below are some of the most often encountered problems with socket programming, along with some general tips:\n\nWorking with many connections at a time; managing multiple clients, and ensuring efficient handling of concurrent requests can certainly be challenging and non-trivial. It requires careful resource management and coordination to avoid bottlenecks\n• Keep track of active connections using data structures like lists or dictionaries. Or use advanced techniques like connection pooling which also help with scalability.\n• Use threading or asynchronous programming techniques to handle multiple client connections at the same time.\n\nDealing with errors, such as connection failures, timeouts, and data transmission issues, is crucial. Handling these errors and providing appropriate feedback to the clients can be challenging, especially when doing low-level socket programming.\n• Use try-except-finally blocks to catch and handle specific types of errors.\n• Provide informative error messages and consider employing logging to aid in troubleshooting.\n\nEnsuring optimal performance and minimizing latency are key concerns when dealing with high-volume data streams or real-time applications.\n• Optimize your code for performance by minimizing unnecessary data processing and network overhead.\n• Consider load balancing techniques to distribute client requests across multiple server instances.\n\nSecuring socket-based communication and implementing proper authentication mechanisms can be difficult. Ensuring data privacy, preventing unauthorized access, and protecting against malicious activities require careful consideration and implementation of secure protocols.\n• Utilize SSL/TLS security protocols to ensure secure data transmission by encrypting the information.\n• Ensure client identity by implementing secure authentication methods like token-based authentication, public-key cryptography, or username/password.\n• Ensure that confidential data, such as passwords or API keys, are safeguarded and encrypted or ideally not stored at all (only their hashes if needed).\n\nDealing with network interruptions, fluctuating bandwidth, and unreliable connections can pose challenges. Maintaining a stable connection, handling disconnections gracefully, and implementing reconnection mechanisms are essential for robust networked applications.\n• Use keep-alive messages to detect inactive or dropped connections.\n• Implement exponential backoff reconnection logic to establish a connection again if it's lost.\n\nLast but not the least mention is code maintainability. Because of the low-level nature of socket programming, developers find themselves writing more code. This might quickly turn into an unmaintainable spaghetti code, so it’s essential to organize and structure it as early as possible and spend extra effort on planning your code’s architecture.\n• Break up your code into classes or functions which ideally shouldn’t be too long.\n• Write unit tests early on by mocking your client and server implementations\n• Consider using more high-level libraries to deal with connections unless you absolutely must use socket programming.\n\nSockets are an integral part of all network applications. In this article, we have looked into socket programming in Python. Here are the key points to remember:\n• Sockets are interfaces that abstract away connection management.\n• Sockets enable communication between different processes (usually a client and a server) locally or over a network.\n• In Python, working with sockets is done through the library, which among the rest, provides a socket object with various methods like , , , .\n• Socket programming has various applications useful in data science, including data collection, inter-process communication, and distributed computing.\n\nWith socket programming skills, developers can create efficient, real-time network applications. By mastering the concepts and best practices, they can harness the full potential of socket programming to develop reliable and scalable solutions.\n\nHowever, socket programming is a very low-level technique, which is difficult to use because application engineers have to take every little detail of application communication into account.\n\nNowadays, we very often do not need to work with sockets directly as they are typically handled by the higher level libraries and frameworks, unless there is a need to really squeeze the performance out of the application or scale it.\n\nHowever, understanding sockets and having some insights into how things work under the hood leads to a better overall awareness as a developer or a data scientist and is always a good idea.\n\nTo learn more about Python’s role in network analysis, check out our Intermediate Network Analysis in Python course. You can also follow our Python Programming skill track to improve your Python programming skills."
    },
    {
        "link": "https://digitalocean.com/community/tutorials/python-socket-programming-server-client",
        "document": "Python’s socket module is a powerful tool for creating network applications. In this tutorial, you will learn the basics of Python socket programming, including how to create a simple client-server architecture, handle multiple clients using threading, and understand the differences between TCP and UDP sockets. You will learn how to establish connections, send and receive data, and build robust network applications using Python.\n\nWhat is Socket Programming in Python?\n\nTo understand Python socket programming, we need to know about three interesting topics - Socket Server, Socket Client, and Socket.\n\nSo, what is a server? Well, a server is software that waits for client requests and serves or processes them accordingly.\n\nOn the other hand, a client is a requester of this service. A client program requests some resources from the server, and the server responds to that request.\n\nThe socket is the endpoint of a bidirectional communications channel between the server and the client. Sockets may communicate within a process, between processes on the same machine, or between processes on different machines. For any communication with a remote program, we have to connect through a socket port. The main objective of this socket programming tutorial is to familiarize you with how socket servers and clients communicate with each other. You will also learn how to write a Python socket server program.\n\nWe have said earlier that a socket client requests for some resources to the socket server and the server responds to that request. So we will design both server and client model so that each can communicate with them. The steps can be considered like this.\n• Python socket server program executes at first and waits for any request\n• Python socket client program will initiate the conversation at first.\n• Then server program will response accordingly to client requests.\n• Client program will terminate if user enters “bye” message. Server program will also terminate when client program terminates, this is optional and we can keep server program running indefinitely or terminate with some specific command in client request.\n\nWe will save the Python socket server program as . To use python socket connection, we need to import socket module. Then, sequentially we need to perform some task to establish connection between server and client. We can obtain host address by using function. It is recommended to user port address above 1024 because port number lesser than 1024 are reserved for standard internet protocol. See the below python socket server example code, the comments will help you to understand the code.\n\nSo our python socket server is running on port 5000 and it will wait for client request. If you want the server to not quit when the client connection is closed, just remove the if condition and the statement. Python while loop is used to run the server program indefinitely and keep waiting for client request.\n\nWe will save python socket client program as . This program is similar to the server program, except binding. The main difference between server and client program is, in server program, it needs to bind host address and port address together. See the below python socket client example code, the comment will help you to understand the code.\n\nTo see the output, first run the socket server program. Then run the socket client program. After that, write something from client program. Then again write reply from server program. At last, write bye from client program to terminate both program. Below short video will show how it worked on my test run of socket server and client example programs.\n\nNotice that socket server is running on port 5000 but client also requires a socket port to connect to the server. This port is assigned randomly by client connect call. In this case, it’s .\n\nA server can utilize threads to handle multiple clients simultaneously. This approach allows the server to process multiple client connections concurrently, enhancing its responsiveness and ability to handle a large number of clients efficiently.\n\nHere’s an example of how this can be achieved in Python using the module:\n\nIn socket programming, sockets can operate in either blocking or non-blocking mode. This mode determines how the socket behaves when it is waiting for data to be received or sent.\n• Blocking Sockets: In blocking mode, operations like and will block the execution of the program until data is available. This means that the program will pause and wait for data to be received or a connection to be accepted. While this approach is simple to implement, it can lead to performance issues and unresponsiveness in applications that need to handle multiple tasks concurrently.\n• Non-Blocking Sockets: Non-blocking sockets, on the other hand, return immediately if no data is available. This approach prevents the application from freezing or becoming unresponsive due to socket operations. Non-blocking sockets are particularly useful in applications that need to handle multiple connections simultaneously, such as web servers or chat servers. However, they require more complex programming to handle the asynchronous nature of the operations.\n\nTCP (Transmission Control Protocol) and UDP (User Datagram Protocol) are two fundamental protocols in the internet protocol suite that enable communication over the internet. The key differences between them lie in their approach to establishing connections and ensuring data reliability.\n\nTCP is a connection-oriented protocol, which means a connection is established between the sender and receiver before data is sent. This ensures that data packets are delivered in the correct order and retransmitted if lost or corrupted, ensuring data integrity. TCP is suitable for applications that require guaranteed delivery of data, such as web browsing and file transfer.\n\nOn the other hand, UDP is a connectionless protocol, which means there is no dedicated end-to-end connection. Data is sent as a series of packets, and the receiver does not send an acknowledgement. This makes UDP faster but less reliable than TCP. UDP is commonly used for applications that require fast transmission and can tolerate some loss of data, such as video streaming and gaming.\n• Address Already in Use Error : This error occurs when a process is already using the port you’re trying to use. To resolve this, you can use the following command to identify the process using the port: Once you’ve identified the process, you can either stop the process or use a different port for your application.\n• : This error occurs when the client attempts to connect to a server that is not running or not listening on the specified port. To resolve this, ensure that the server is running and listening on the correct port before the client attempts to connect. Here’s a simple Python code block to check if a server is listening on a specific port:\n\nHere is an example of how to create a Python socket server:\n\n3. What is the difference between TCP and UDP sockets?\n\nTCP provides reliable communication, whereas UDP is faster but does not guarantee data integrity.\n\n4. How to handle multiple clients in Python socket programming?\n\nYou can use threading to manage multiple clients concurrently. Here’s an example of how you can modify the server code to handle multiple clients using threading:\n\nIn this tutorial, you learned the basics of Python socket programming, including how to create a simple client-server architecture, handle multiple clients using threading, and understand the differences between TCP and UDP sockets. To further enhance your knowledge of Python programming, we recommend checking out the following tutorials:\n\nThese tutorials will provide you with a deeper understanding of Python and its applications in network programming."
    },
    {
        "link": "https://docs.python.org/3/library/socket.html",
        "document": "This module provides access to the BSD socket interface. It is available on all modern Unix systems, Windows, MacOS, and probably additional platforms.\n\nThe Python interface is a straightforward transliteration of the Unix system call and library interface for sockets to Python’s object-oriented style: the function returns a socket object whose methods implement the various socket system calls. Parameter types are somewhat higher-level than in the C interface: as with and operations on Python files, buffer allocation on receive operations is automatic, and buffer length is implicit on send operations.\n\nDepending on the system and the build options, various socket families are supported by this module. The address format required by a particular socket object is automatically selected based on the address family specified when the socket object was created. Socket addresses are represented as follows:\n• None The address of an socket bound to a file system node is represented as a string, using the file system encoding and the error handler (see PEP 383). An address in Linux’s abstract namespace is returned as a bytes-like object with an initial null byte; note that sockets in this namespace can communicate with normal file system sockets, so programs intended to run on Linux may need to deal with both types of address. A string or bytes-like object can be used for either type of address when passing it as an argument. Changed in version 3.3: Previously, socket paths were assumed to use UTF-8 encoding. Changed in version 3.5: Writable bytes-like object is now accepted.\n• None A pair is used for the address family, where host is a string representing either a hostname in internet domain notation like or an IPv4 address like , and port is an integer.\n• None For IPv4 addresses, two special forms are accepted instead of a host address: represents , which is used to bind to all interfaces, and the string represents . This behavior is not compatible with IPv6, therefore, you may want to avoid these if you intend to support IPv6 with your Python programs.\n• None For address family, a four-tuple is used, where flowinfo and scope_id represent the and members in in C. For module methods, flowinfo and scope_id can be omitted just for backward compatibility. Note, however, omission of scope_id can cause problems in manipulating scoped IPv6 addresses. Changed in version 3.7: For multicast addresses (with scope_id meaningful) address may not contain (or ) part. This information is superfluous and may be safely omitted (recommended).\n• None Linux-only support for TIPC is available using the address family. TIPC is an open, non-IP based networked protocol designed for use in clustered computer environments. Addresses are represented by a tuple, and the fields depend on the address type. The general tuple form is , where:\n• None addr_type is one of , , or .\n• None scope is one of , , and .\n• None If addr_type is , then v1 is the server type, v2 is the port identifier, and v3 should be 0. If addr_type is , then v1 is the server type, v2 is the lower port number, and v3 is the upper port number. If addr_type is , then v1 is the node, v2 is the reference, and v3 should be set to 0.\n• None A tuple is used for the address family, where interface is a string representing a network interface name like . The network interface name can be used to receive packets from all network interfaces of this family.\n• None protocol require a tuple where both additional parameters are unsigned long integer that represent a CAN identifier (standard or extended).\n• None protocol require a tuple where additional parameters are 64-bit unsigned integer representing the ECU name, a 32-bit unsigned integer representing the Parameter Group Number (PGN), and an 8-bit integer representing the address.\n• None A string or a tuple is used for the protocol of the family. The string is the name of a kernel control using a dynamically assigned ID. The tuple can be used if ID and unit number of the kernel control are known or if a registered ID is used.\n• None supports the following protocols and address formats:\n• None accepts where is the Bluetooth address as a string and is an integer.\n• None accepts where is the Bluetooth address as a string and is an integer.\n• None accepts where is either an integer or a string with the Bluetooth address of the interface. (This depends on your OS; NetBSD and DragonFlyBSD expect a Bluetooth address while everything else expects an integer.)\n• None accepts where is a object containing the Bluetooth address in a string format. (ex. ) This protocol is not supported under FreeBSD.\n• None is a Linux-only socket based interface to Kernel cryptography. An algorithm socket is configured with a tuple of two to four elements , where:\n• None type is the algorithm type as string, e.g. , , or .\n• None name is the algorithm name and operation mode as string, e.g. , , or .\n• None allows communication between virtual machines and their hosts. The sockets are represented as a tuple where the context ID or CID and port are integers.\n• None is a low-level interface directly to network devices. The addresses are represented by the tuple where:\n• None ifname - String specifying the device name.\n• None proto - The Ethernet protocol number. May be to capture all protocols, one of the ETHERTYPE_* constants or any other Ethernet protocol number.\n• \n• None (the default) - Packet addressed to the local host.\n• None - Packet to some other host that has been caught by a device driver in promiscuous mode.\n• None - Packet originating from the local host that is looped back to a packet socket.\n• None addr - Optional bytes-like object specifying the hardware physical address, whose interpretation depends on the device.\n• None is a Linux-only socket based interface for communicating with services running on co-processors in Qualcomm platforms. The address family is represented as a tuple where the node and port are non-negative integers.\n• None is a variant of UDP which allows you to specify what portion of a packet is covered with the checksum. It adds two socket options that you can change. will change what portion of outgoing packets are covered by the checksum and will filter out packets which cover too little of their data. In both cases should be in . Such a socket should be constructed with for IPv4 or for IPv6.\n• None is a Windows-only socket based interface for communicating with Hyper-V hosts and guests. The address family is represented as a tuple where the and are UUID strings. The is the virtual machine identifier or a set of known VMID values if the target is not a specific virtual machine. Known VMID constants defined on are:\n• None - Used to bind on itself and accept connections from all partitions.\n• None - Used to bind on itself and accept connection from child partitions.\n• None - Used as a target to itself.\n• None - When used as a bind accepts connection from the parent partition. When used as an address target it will connect to the parent partition. The is the service identifier of the registered service. If you use a hostname in the host portion of IPv4/v6 socket address, the program may show a nondeterministic behavior, as Python uses the first address returned from the DNS resolution. The socket address will be resolved differently into an actual IPv4/v6 address, depending on the results from DNS resolution and/or the host configuration. For deterministic behavior use a numeric address in host portion. All errors raise exceptions. The normal exceptions for invalid argument types and out-of-memory conditions can be raised. Errors related to socket or address semantics raise or one of its subclasses. Non-blocking mode is supported through . A generalization of this based on timeouts is supported through .\n\nHere are four minimal example programs using the TCP/IP protocol: a server that echoes all data that it receives back (servicing only one client), and a client using it. Note that a server must perform the sequence , , , (possibly repeating the to service more than one client), while a client only needs the sequence , . Also note that the server does not / on the socket it is listening on but on the new socket returned by . The first two examples support IPv4 only. # Symbolic name meaning all available interfaces # The same port as used by the server The next two examples are identical to the above two, but support both IPv4 and IPv6. The server side will listen to the first address family available (it should listen to both instead). On most of IPv6-ready systems, IPv6 will take precedence and the server may not accept IPv4 traffic. The client side will try to connect to all the addresses returned as a result of the name resolution, and sends traffic to the first one connected successfully. # Symbolic name meaning all available interfaces # The same port as used by the server The next example shows how to write a very simple network sniffer with raw sockets on Windows. The example requires administrator privileges to modify the interface: # create a raw socket and bind it to the public interface The next example shows how to use the socket interface to communicate to a CAN network using the raw socket protocol. To use CAN with the broadcast manager protocol instead, open a socket with: After binding ( ) or connecting ( ) the socket, you can use the and operations (and their counterparts) on the socket object as usual. This last example might require special privileges: # CAN frame packing/unpacking (see 'struct can_frame' in <linux/can.h>) # create a raw socket and bind it to the 'vcan0' interface Running an example several times with too small delay between executions, could lead to this error: This is because the previous execution has left the socket in a state, and can’t be immediately reused. There is a flag to set, in order to prevent this, : the flag tells the kernel to reuse a local socket in state, without waiting for its natural timeout to expire. For an introduction to socket programming (in C), see the following papers:\n• None An Advanced 4.3BSD Interprocess Communication Tutorial, by Samuel J. Leffler et al, both in the UNIX Programmer’s Manual, Supplementary Documents 1 (sections PS1:7 and PS1:8). The platform-specific reference material for the various socket-related system calls are also a valuable source of information on the details of socket semantics. For Unix, refer to the manual pages; for Windows, see the WinSock (or Winsock 2) specification. For IPv6-ready APIs, readers may want to refer to RFC 3493 titled Basic Socket Interface Extensions for IPv6."
    },
    {
        "link": "https://docs.python.org/3/howto/logging.html",
        "document": "This page contains tutorial information. For links to reference information and a logging cookbook, please see Other resources.\n\nLogging is a means of tracking events that happen when some software runs. The software’s developer adds logging calls to their code to indicate that certain events have occurred. An event is described by a descriptive message which can optionally contain variable data (i.e. data that is potentially different for each occurrence of the event). Events also have an importance which the developer ascribes to the event; the importance can also be called the level or severity. When to use logging¶ You can access logging functionality by creating a logger via , and then calling the logger’s , , , and methods. To determine when to use logging, and to see which logger methods to use when, see the table below. It states, for each of a set of common tasks, the best tool to use for that task. The best tool for the task Display console output for ordinary usage of a command line script or program Report events that occur during normal operation of a program (e.g. for status monitoring or fault investigation) A logger’s (or method for very detailed output for diagnostic purposes) in library code if the issue is avoidable and the client application should be modified to eliminate the warning A logger’s method if there is nothing the client application can do about the situation, but the event should still be noted Report an error regarding a particular runtime event Report suppression of an error without raising an exception (e.g. error handler in a long-running server process) A logger’s , or method as appropriate for the specific error and application domain The logger methods are named after the level or severity of the events they are used to track. The standard levels and their applicability are described below (in increasing order of severity): Detailed information, typically of interest only when diagnosing problems. Confirmation that things are working as expected. An indication that something unexpected happened, or indicative of some problem in the near future (e.g. ‘disk space low’). The software is still working as expected. Due to a more serious problem, the software has not been able to perform some function. A serious error, indicating that the program itself may be unable to continue running. The default level is , which means that only events of this severity and higher will be tracked, unless the logging package is configured to do otherwise. Events that are tracked can be handled in different ways. The simplest way of handling tracked events is to print them to the console. Another common way is to write them to a disk file. A very simple example is: # will print a message to the console # will not print anything If you type these lines into a script and run it, you’ll see: printed out on the console. The message doesn’t appear because the default level is . The printed message includes the indication of the level and the description of the event provided in the logging call, i.e. ‘Watch out!’. The actual output can be formatted quite flexibly if you need that; formatting options will also be explained later. Notice that in this example, we use functions directly on the module, like , rather than creating a logger and calling functions on it. These functions operation on the root logger, but can be useful as they will call for you if it has not been called yet, like in this example. In larger programs you’ll usually want to control the logging configuration explicitly however - so for that reason as well as others, it’s better to create loggers and call their methods. A very common situation is that of recording logging events in a file, so let’s look at that next. Be sure to try the following in a newly started Python interpreter, and don’t just continue from the session described above: 'This message should go to the log file' 'And non-ASCII stuff, too, like Øresund and Malmö' Changed in version 3.9: The encoding argument was added. In earlier Python versions, or if not specified, the encoding used is the default value used by . While not shown in the above example, an errors argument can also now be passed, which determines how encoding errors are handled. For available values and the default, see the documentation for . And now if we open the file and look at what we have, we should find the log messages: DEBUG:__main__:This message should go to the log file INFO:__main__:So should this WARNING:__main__:And this, too ERROR:__main__:And non-ASCII stuff, too, like Øresund and Malmö This example also shows how you can set the logging level which acts as the threshold for tracking. In this case, because we set the threshold to , all of the messages were printed. If you want to set the logging level from a command-line option such as: and you have the value of the parameter passed for in some variable loglevel, you can use: to get the value which you’ll pass to via the level argument. You may want to error check any user input value, perhaps as in the following example: # assuming loglevel is bound to the string value obtained from the # command line argument. Convert to upper case to allow the user to The call to should come before any calls to a logger’s methods such as , , etc. Otherwise, that logging event may not be handled in the desired manner. If you run the above script several times, the messages from successive runs are appended to the file example.log. If you want each run to start afresh, not remembering the messages from earlier runs, you can specify the filemode argument, by changing the call in the above example to: The output will be the same as before, but the log file is no longer appended to, so the messages from earlier runs are lost. To log variable data, use a format string for the event description message and append the variable data as arguments. For example: As you can see, merging of variable data into the event description message uses the old, %-style of string formatting. This is for backwards compatibility: the logging package pre-dates newer formatting options such as and . These newer formatting options are supported, but exploring them is outside the scope of this tutorial: see Using particular formatting styles throughout your application for more information. To change the format which is used to display messages, you need to specify the format you want to use: 'This message should appear on the console' DEBUG:This message should appear on the console INFO:So should this WARNING:And this, too Notice that the ‘root’ which appeared in earlier examples has disappeared. For a full set of things that can appear in format strings, you can refer to the documentation for LogRecord attributes, but for simple usage, you just need the levelname (severity), message (event description, including variable data) and perhaps to display when the event occurred. This is described in the next section. That concludes the basic tutorial. It should be enough to get you up and running with logging. There’s a lot more that the logging package offers, but to get the best out of it, you’ll need to invest a little more of your time in reading the following sections. If you’re ready for that, grab some of your favourite beverage and carry on. If your logging needs are simple, then use the above examples to incorporate logging into your own scripts, and if you run into problems or don’t understand something, please post a question on the comp.lang.python Usenet group (available at https://groups.google.com/g/comp.lang.python) and you should receive help before too long. Still here? You can carry on reading the next few sections, which provide a slightly more advanced/in-depth tutorial than the basic one above. After that, you can take a look at the Logging Cookbook.\n\nThe logging library takes a modular approach and offers several categories of components: loggers, handlers, filters, and formatters.\n• None Loggers expose the interface that application code directly uses.\n• None Handlers send the log records (created by loggers) to the appropriate destination.\n• None Filters provide a finer grained facility for determining which log records to output.\n• None Formatters specify the layout of log records in the final output. Log event information is passed between loggers, handlers, filters and formatters in a instance. Logging is performed by calling methods on instances of the class (hereafter called loggers). Each instance has a name, and they are conceptually arranged in a namespace hierarchy using dots (periods) as separators. For example, a logger named ‘scan’ is the parent of loggers ‘scan.text’, ‘scan.html’ and ‘scan.pdf’. Logger names can be anything you want, and indicate the area of an application in which a logged message originates. A good convention to use when naming loggers is to use a module-level logger, in each module which uses logging, named as follows: This means that logger names track the package/module hierarchy, and it’s intuitively obvious where events are logged just from the logger name. The root of the hierarchy of loggers is called the root logger. That’s the logger used by the functions , , , and , which just call the same-named method of the root logger. The functions and the methods have the same signatures. The root logger’s name is printed as ‘root’ in the logged output. It is, of course, possible to log messages to different destinations. Support is included in the package for writing log messages to files, HTTP GET/POST locations, email via SMTP, generic sockets, queues, or OS-specific logging mechanisms such as syslog or the Windows NT event log. Destinations are served by handler classes. You can create your own log destination class if you have special requirements not met by any of the built-in handler classes. By default, no destination is set for any logging messages. You can specify a destination (such as console or file) by using as in the tutorial examples. If you call the functions , , , and , they will check to see if no destination is set; and if one is not set, they will set a destination of the console ( ) and a default format for the displayed message before delegating to the root logger to do the actual message output. The default format set by for messages is: You can change this by passing a format string to with the format keyword argument. For all options regarding how a format string is constructed, see Formatter Objects. The flow of log event information in loggers and handlers is illustrated in the following diagram. At least one handler objects have a threefold job. First, they expose several methods to application code so that applications can log messages at runtime. Second, logger objects determine which log messages to act upon based upon severity (the default filtering facility) or filter objects. Third, logger objects pass along relevant log messages to all interested log handlers. The most widely used methods on logger objects fall into two categories: configuration and message sending. These are the most common configuration methods:\n• None specifies the lowest-severity log message a logger will handle, where debug is the lowest built-in severity level and critical is the highest built-in severity. For example, if the severity level is INFO, the logger will handle only INFO, WARNING, ERROR, and CRITICAL messages and will ignore DEBUG messages.\n• None and add and remove handler objects from the logger object. Handlers are covered in more detail in Handlers.\n• None and add and remove filter objects from the logger object. Filters are covered in more detail in Filter Objects. You don’t need to always call these methods on every logger you create. See the last two paragraphs in this section. With the logger object configured, the following methods create log messages:\n• None , , , , and all create log records with a message and a level that corresponds to their respective method names. The message is actually a format string, which may contain the standard string substitution syntax of , , , and so on. The rest of their arguments is a list of objects that correspond with the substitution fields in the message. With regard to , the logging methods care only about a keyword of and use it to determine whether to log exception information.\n• None creates a log message similar to . The difference is that dumps a stack trace along with it. Call this method only from an exception handler.\n• None takes a log level as an explicit argument. This is a little more verbose for logging messages than using the log level convenience methods listed above, but this is how to log at custom log levels. returns a reference to a logger instance with the specified name if it is provided, or if not. The names are period-separated hierarchical structures. Multiple calls to with the same name will return a reference to the same logger object. Loggers that are further down in the hierarchical list are children of loggers higher up in the list. For example, given a logger with a name of , loggers with names of , , and are all descendants of . Loggers have a concept of effective level. If a level is not explicitly set on a logger, the level of its parent is used instead as its effective level. If the parent has no explicit level set, its parent is examined, and so on - all ancestors are searched until an explicitly set level is found. The root logger always has an explicit level set ( by default). When deciding whether to process an event, the effective level of the logger is used to determine whether the event is passed to the logger’s handlers. Child loggers propagate messages up to the handlers associated with their ancestor loggers. Because of this, it is unnecessary to define and configure handlers for all the loggers an application uses. It is sufficient to configure handlers for a top-level logger and create child loggers as needed. (You can, however, turn off propagation by setting the propagate attribute of a logger to .) objects are responsible for dispatching the appropriate log messages (based on the log messages’ severity) to the handler’s specified destination. objects can add zero or more handler objects to themselves with an method. As an example scenario, an application may want to send all log messages to a log file, all log messages of error or higher to stdout, and all messages of critical to an email address. This scenario requires three individual handlers where each handler is responsible for sending messages of a specific severity to a specific location. The standard library includes quite a few handler types (see Useful Handlers); the tutorials use mainly and in its examples. There are very few methods in a handler for application developers to concern themselves with. The only handler methods that seem relevant for application developers who are using the built-in handler objects (that is, not creating custom handlers) are the following configuration methods:\n• None The method, just as in logger objects, specifies the lowest severity that will be dispatched to the appropriate destination. Why are there two methods? The level set in the logger determines which severity of messages it will pass to its handlers. The level set in each handler determines which messages that handler will send on.\n• None selects a Formatter object for this handler to use.\n• None and respectively configure and deconfigure filter objects on handlers. Application code should not directly instantiate and use instances of . Instead, the class is a base class that defines the interface that all handlers should have and establishes some default behavior that child classes can use (or override). Formatter objects configure the final order, structure, and contents of the log message. Unlike the base class, application code may instantiate formatter classes, although you could likely subclass the formatter if your application needs special behavior. The constructor takes three optional arguments – a message format string, a date format string and a style indicator. If there is no message format string, the default is to use the raw message. If there is no date format string, the default date format is: with the milliseconds tacked on at the end. The is one of , , or . If one of these is not specified, then will be used. If the is , the message format string uses styled string substitution; the possible keys are documented in LogRecord attributes. If the style is , the message format string is assumed to be compatible with (using keyword arguments), while if the style is then the message format string should conform to what is expected by . The following message format string will log the time in a human-readable format, the severity of the message, and the contents of the message, in that order: Formatters use a user-configurable function to convert the creation time of a record to a tuple. By default, is used; to change this for a particular formatter instance, set the attribute of the instance to a function with the same signature as or . To change it for all formatters, for example if you want all logging times to be shown in GMT, set the attribute in the Formatter class (to for GMT display). Programmers can configure logging in three ways:\n• None Creating loggers, handlers, and formatters explicitly using Python code that calls the configuration methods listed above.\n• None Creating a logging config file and reading it using the function.\n• None Creating a dictionary of configuration information and passing it to the function. For the reference documentation on the last two options, see Configuration functions. The following example configures a very simple logger, a console handler, and a simple formatter using Python code: Running this module from the command line produces the following output: The following Python module creates a logger, handler, and formatter nearly identical to those in the example listed above, with the only difference being the names of the objects: Here is the logging.conf file: The output is nearly identical to that of the non-config-file-based example: You can see that the config file approach has a few advantages over the Python code approach, mainly separation of configuration and code and the ability of noncoders to easily modify the logging properties. The function takes a default parameter, , which defaults to for reasons of backward compatibility. This may or may not be what you want, since it will cause any non-root loggers existing before the call to be disabled unless they (or an ancestor) are explicitly named in the configuration. Please refer to the reference documentation for more information, and specify for this parameter if you wish. The dictionary passed to can also specify a Boolean value with key , which if not specified explicitly in the dictionary also defaults to being interpreted as . This leads to the logger-disabling behaviour described above, which may not be what you want - in which case, provide the key explicitly with a value of . Note that the class names referenced in config files need to be either relative to the logging module, or absolute values which can be resolved using normal import mechanisms. Thus, you could use either (relative to the logging module) or (for a class defined in package and module , where is available on the Python import path). In Python 3.2, a new means of configuring logging has been introduced, using dictionaries to hold configuration information. This provides a superset of the functionality of the config-file-based approach outlined above, and is the recommended configuration method for new applications and deployments. Because a Python dictionary is used to hold configuration information, and since you can populate that dictionary using different means, you have more options for configuration. For example, you can use a configuration file in JSON format, or, if you have access to YAML processing functionality, a file in YAML format, to populate the configuration dictionary. Or, of course, you can construct the dictionary in Python code, receive it in pickled form over a socket, or use whatever approach makes sense for your application. Here’s an example of the same configuration as above, in YAML format for the new dictionary-based approach: For more information about logging using a dictionary, see Configuration functions. What happens if no configuration is provided¶ If no logging configuration is provided, it is possible to have a situation where a logging event needs to be output, but no handlers can be found to output the event. The event is output using a ‘handler of last resort’, stored in . This internal handler is not associated with any logger, and acts like a which writes the event description message to the current value of (therefore respecting any redirections which may be in effect). No formatting is done on the message - just the bare event description message is printed. The handler’s level is set to , so all events at this and greater severities will be output. Changed in version 3.2: For versions of Python prior to 3.2, the behaviour is as follows:\n• None If is (production mode), the event is silently dropped.\n• None If is (development mode), a message ‘No handlers could be found for logger X.Y.Z’ is printed once. To obtain the pre-3.2 behaviour, can be set to . When developing a library which uses logging, you should take care to document how the library uses logging - for example, the names of loggers used. Some consideration also needs to be given to its logging configuration. If the using application does not use logging, and library code makes logging calls, then (as described in the previous section) events of severity and greater will be printed to . This is regarded as the best default behaviour. If for some reason you don’t want these messages printed in the absence of any logging configuration, you can attach a do-nothing handler to the top-level logger for your library. This avoids the message being printed, since a handler will always be found for the library’s events: it just doesn’t produce any output. If the library user configures logging for application use, presumably that configuration will add some handlers, and if levels are suitably configured then logging calls made in library code will send output to those handlers, as normal. A do-nothing handler is included in the logging package: (since Python 3.1). An instance of this handler could be added to the top-level logger of the logging namespace used by the library (if you want to prevent your library’s logged events being output to in the absence of logging configuration). If all logging by a library foo is done using loggers with names matching ‘foo.x’, ‘foo.x.y’, etc. then the code: should have the desired effect. If an organisation produces a number of libraries, then the logger name specified can be ‘orgname.foo’ rather than just ‘foo’. It is strongly advised that you do not log to the root logger in your library. Instead, use a logger with a unique and easily identifiable name, such as the for your library’s top-level package or module. Logging to the root logger will make it difficult or impossible for the application developer to configure the logging verbosity or handlers of your library as they wish. It is strongly advised that you do not add any handlers other than to your library’s loggers. This is because the configuration of handlers is the prerogative of the application developer who uses your library. The application developer knows their target audience and what handlers are most appropriate for their application: if you add handlers ‘under the hood’, you might well interfere with their ability to carry out unit tests and deliver logs which suit their requirements.\n\nThe numeric values of logging levels are given in the following table. These are primarily of interest if you want to define your own levels, and need them to have specific values relative to the predefined levels. If you define a level with the same numeric value, it overwrites the predefined value; the predefined name is lost. Levels can also be associated with loggers, being set either by the developer or through loading a saved logging configuration. When a logging method is called on a logger, the logger compares its own level with the level associated with the method call. If the logger’s level is higher than the method call’s, no logging message is actually generated. This is the basic mechanism controlling the verbosity of logging output. Logging messages are encoded as instances of the class. When a logger decides to actually log an event, a instance is created from the logging message. Logging messages are subjected to a dispatch mechanism through the use of handlers, which are instances of subclasses of the class. Handlers are responsible for ensuring that a logged message (in the form of a ) ends up in a particular location (or set of locations) which is useful for the target audience for that message (such as end users, support desk staff, system administrators, developers). Handlers are passed instances intended for particular destinations. Each logger can have zero, one or more handlers associated with it (via the method of ). In addition to any handlers directly associated with a logger, all handlers associated with all ancestors of the logger are called to dispatch the message (unless the propagate flag for a logger is set to a false value, at which point the passing to ancestor handlers stops). Just as for loggers, handlers can have levels associated with them. A handler’s level acts as a filter in the same way as a logger’s level does. If a handler decides to actually dispatch an event, the method is used to send the message to its destination. Most user-defined subclasses of will need to override this . Defining your own levels is possible, but should not be necessary, as the existing levels have been chosen on the basis of practical experience. However, if you are convinced that you need custom levels, great care should be exercised when doing this, and it is possibly a very bad idea to define custom levels if you are developing a library. That’s because if multiple library authors all define their own custom levels, there is a chance that the logging output from such multiple libraries used together will be difficult for the using developer to control and/or interpret, because a given numeric value might mean different things for different libraries.\n\nFormatting of message arguments is deferred until it cannot be avoided. However, computing the arguments passed to the logging method can also be expensive, and you may want to avoid doing it if the logger will just throw away your event. To decide what to do, you can call the method which takes a level argument and returns true if the event would be created by the Logger for that level of call. You can write code like this: so that if the logger’s threshold is set above , the calls to and are never made. In some cases, can itself be more expensive than you’d like (e.g. for deeply nested loggers where an explicit level is only set high up in the logger hierarchy). In such cases (or if you want to avoid calling a method in tight loops), you can cache the result of a call to in a local or instance variable, and use that instead of calling the method each time. Such a cached value would only need to be recomputed when the logging configuration changes dynamically while the application is running (which is not all that common). There are other optimizations which can be made for specific applications which need more precise control over what logging information is collected. Here’s a list of things you can do to avoid processing during logging which you don’t need: What you don’t want to collect How to avoid collecting it Information about where calls were made from. Set to . This avoids calling , which may help to speed up your code in environments like PyPy (which can’t speed up code that uses ). Current process name when using to manage multiple processes. Current name when using . Also note that the core logging module only includes the basic handlers. If you don’t import and , they won’t take up any memory."
    },
    {
        "link": "https://docs.python.org/3/library/logging.html",
        "document": "This module defines functions and classes which implement a flexible event logging system for applications and libraries.\n\nThe key benefit of having the logging API provided by a standard library module is that all Python modules can participate in logging, so your application log can include your own messages integrated with messages from third-party modules.\n\nIf you run myapp.py, you should see this in myapp.log:\n\nThe key feature of this idiomatic usage is that the majority of code is simply creating a module level logger with , and using that logger to do any needed logging. This is concise, while allowing downstream code fine-grained control if needed. Logged messages to the module-level logger get forwarded to handlers of loggers in higher-level modules, all the way up to the highest-level logger known as the root logger; this approach is known as hierarchical logging.\n\nFor logging to be useful, it needs to be configured: setting the levels and destinations for each logger, potentially changing how specific modules log, often based on command-line arguments or application configuration. In most cases, like the one above, only the root logger needs to be so configured, since all the lower level loggers at module level eventually forward their messages to its handlers. provides a quick way to configure the root logger that handles many use cases.\n\nThe module provides a lot of functionality and flexibility. If you are unfamiliar with logging, the best way to get to grips with it is to view the tutorials (see the links above and on the right).\n\nThe basic classes defined by the module, together with their attributes and methods, are listed in the sections below.\n• None Loggers expose the interface that application code directly uses.\n• None Handlers send the log records (created by loggers) to the appropriate destination.\n• None Filters provide a finer grained facility for determining which log records to output.\n• None Formatters specify the layout of log records in the final output.\n\nLoggers have the following attributes and methods. Note that Loggers should NEVER be instantiated directly, but always through the module-level function . Multiple calls to with the same name will always return a reference to the same Logger object. The is potentially a period-separated hierarchical value, like (though it could also be just plain , for example). Loggers that are further down in the hierarchical list are children of loggers higher up in the list. For example, given a logger with a name of , loggers with names of , , and are all descendants of . In addition, all loggers are descendants of the root logger. The logger name hierarchy is analogous to the Python package hierarchy, and identical to it if you organise your loggers on a per-module basis using the recommended construction . That’s because in a module, is the module’s name in the Python package namespace. This is the logger’s name, and is the value that was passed to to obtain the logger. This attribute should be treated as read-only. The threshold of this logger, as set by the method. Do not set this attribute directly - always use , which has checks for the level passed to it. The parent logger of this logger. It may change based on later instantiation of loggers which are higher up in the namespace hierarchy. This value should be treated as read-only. If this attribute evaluates to true, events logged to this logger will be passed to the handlers of higher level (ancestor) loggers, in addition to any handlers attached to this logger. Messages are passed directly to the ancestor loggers’ handlers - neither the level nor filters of the ancestor loggers in question are considered. If this evaluates to false, logging messages are not passed to the handlers of ancestor loggers. Spelling it out with an example: If the propagate attribute of the logger named evaluates to true, any event logged to via a method call such as will [subject to passing that logger’s level and filter settings] be passed in turn to any handlers attached to loggers named , and the root logger, after first being passed to any handlers attached to . If any logger in the chain , , has its attribute set to false, then that is the last logger whose handlers are offered the event to handle, and propagation stops at that point. The constructor sets this attribute to . If you attach a handler to a logger and one or more of its ancestors, it may emit the same record multiple times. In general, you should not need to attach a handler to more than one logger - if you just attach it to the appropriate logger which is highest in the logger hierarchy, then it will see all events logged by all descendant loggers, provided that their propagate setting is left set to . A common scenario is to attach handlers only to the root logger, and to let propagation take care of the rest. The list of handlers directly attached to this logger instance. This attribute should be treated as read-only; it is normally changed via the and methods, which use locks to ensure thread-safe operation. This attribute disables handling of any events. It is set to in the initializer, and only changed by logging configuration code. This attribute should be treated as read-only. Sets the threshold for this logger to level. Logging messages which are less severe than level will be ignored; logging messages which have severity level or higher will be emitted by whichever handler or handlers service this logger, unless a handler’s level has been set to a higher severity level than level. When a logger is created, the level is set to (which causes all messages to be processed when the logger is the root logger, or delegation to the parent when the logger is a non-root logger). Note that the root logger is created with level . The term ‘delegation to the parent’ means that if a logger has a level of NOTSET, its chain of ancestor loggers is traversed until either an ancestor with a level other than NOTSET is found, or the root is reached. If an ancestor is found with a level other than NOTSET, then that ancestor’s level is treated as the effective level of the logger where the ancestor search began, and is used to determine how a logging event is handled. If the root is reached, and it has a level of NOTSET, then all messages will be processed. Otherwise, the root’s level will be used as the effective level. See Logging Levels for a list of levels. Changed in version 3.2: The level parameter now accepts a string representation of the level such as ‘INFO’ as an alternative to the integer constants such as . Note, however, that levels are internally stored as integers, and methods such as e.g. and will return/expect to be passed integers. Indicates if a message of severity level would be processed by this logger. This method checks first the module-level level set by and then the logger’s effective level as determined by . Indicates the effective level for this logger. If a value other than has been set using , it is returned. Otherwise, the hierarchy is traversed towards the root until a value other than is found, and that value is returned. The value returned is an integer, typically one of , etc. Returns a logger which is a descendant to this logger, as determined by the suffix. Thus, would return the same logger as would be returned by . This is a convenience method, useful when the parent logger is named using e.g. rather than a literal string. Returns a set of loggers which are immediate children of this logger. So for example might return a set containing loggers named and , but a logger named wouldn’t be included in the set. Likewise, might return a set including a logger named , but it wouldn’t include one named . Logs a message with level on this logger. The msg is the message format string, and the args are the arguments which are merged into msg using the string formatting operator. (Note that this means that you can use keywords in the format string, together with a single dictionary argument.) No % formatting operation is performed on msg when no args are supplied. There are four keyword arguments in kwargs which are inspected: exc_info, stack_info, stacklevel and extra. If exc_info does not evaluate as false, it causes exception information to be added to the logging message. If an exception tuple (in the format returned by ) or an exception instance is provided, it is used; otherwise, is called to get the exception information. The second optional keyword argument is stack_info, which defaults to . If true, stack information is added to the logging message, including the actual logging call. Note that this is not the same stack information as that displayed through specifying exc_info: The former is stack frames from the bottom of the stack up to the logging call in the current thread, whereas the latter is information about stack frames which have been unwound, following an exception, while searching for exception handlers. You can specify stack_info independently of exc_info, e.g. to just show how you got to a certain point in your code, even when no exceptions were raised. The stack frames are printed following a header line which says: This mimics the which is used when displaying exception frames. The third optional keyword argument is stacklevel, which defaults to . If greater than 1, the corresponding number of stack frames are skipped when computing the line number and function name set in the created for the logging event. This can be used in logging helpers so that the function name, filename and line number recorded are not the information for the helper function/method, but rather its caller. The name of this parameter mirrors the equivalent one in the module. The fourth keyword argument is extra which can be used to pass a dictionary which is used to populate the of the created for the logging event with user-defined attributes. These custom attributes can then be used as you like. For example, they could be incorporated into logged messages. For example: would print something like The keys in the dictionary passed in extra should not clash with the keys used by the logging system. (See the section on LogRecord attributes for more information on which keys are used by the logging system.) If you choose to use these attributes in logged messages, you need to exercise some care. In the above example, for instance, the has been set up with a format string which expects ‘clientip’ and ‘user’ in the attribute dictionary of the . If these are missing, the message will not be logged because a string formatting exception will occur. So in this case, you always need to pass the extra dictionary with these keys. While this might be annoying, this feature is intended for use in specialized circumstances, such as multi-threaded servers where the same code executes in many contexts, and interesting conditions which arise are dependent on this context (such as remote client IP address and authenticated user name, in the above example). In such circumstances, it is likely that specialized s would be used with particular s. If no handler is attached to this logger (or any of its ancestors, taking into account the relevant attributes), the message will be sent to the handler set on . Changed in version 3.2: The stack_info parameter was added. Changed in version 3.5: The exc_info parameter can now accept exception instances. Changed in version 3.8: The stacklevel parameter was added. Logs a message with level on this logger. The arguments are interpreted as for . Logs a message with level on this logger. The arguments are interpreted as for . There is an obsolete method which is functionally identical to . As is deprecated, please do not use it - use instead. Logs a message with level on this logger. The arguments are interpreted as for . Logs a message with level on this logger. The arguments are interpreted as for . Logs a message with integer level level on this logger. The other arguments are interpreted as for . Logs a message with level on this logger. The arguments are interpreted as for . Exception info is added to the logging message. This method should only be called from an exception handler. Adds the specified filter filter to this logger. Removes the specified filter filter from this logger. Apply this logger’s filters to the record and return if the record is to be processed. The filters are consulted in turn, until one of them returns a false value. If none of them return a false value, the record will be processed (passed to handlers). If one returns a false value, no further processing of the record occurs. Adds the specified handler hdlr to this logger. Removes the specified handler hdlr from this logger. Finds the caller’s source filename and line number. Returns the filename, line number, function name and stack information as a 4-element tuple. The stack information is returned as unless stack_info is . The stacklevel parameter is passed from code calling the and other APIs. If greater than 1, the excess is used to skip stack frames before determining the values to be returned. This will generally be useful when calling logging APIs from helper/wrapper code, so that the information in the event log refers not to the helper/wrapper code, but to the code that calls it. Handles a record by passing it to all handlers associated with this logger and its ancestors (until a false value of propagate is found). This method is used for unpickled records received from a socket, as well as those created locally. Logger-level filtering is applied using . This is a factory method which can be overridden in subclasses to create specialized instances. Checks to see if this logger has any handlers configured. This is done by looking for handlers in this logger and its parents in the logger hierarchy. Returns if a handler was found, else . The method stops searching up the hierarchy whenever a logger with the ‘propagate’ attribute set to false is found - that will be the last logger which is checked for the existence of handlers. Changed in version 3.7: Loggers can now be pickled and unpickled.\n\ncan be used by and for more sophisticated filtering than is provided by levels. The base filter class only allows events which are below a certain point in the logger hierarchy. For example, a filter initialized with ‘A.B’ will allow events logged by loggers ‘A.B’, ‘A.B.C’, ‘A.B.C.D’, ‘A.B.D’ etc. but not ‘A.BB’, ‘B.A.B’ etc. If initialized with the empty string, all events are passed. Returns an instance of the class. If name is specified, it names a logger which, together with its children, will have its events allowed through the filter. If name is the empty string, allows every event. Is the specified record to be logged? Returns false for no, true for yes. Filters can either modify log records in-place or return a completely different record instance which will replace the original log record in any future processing of the event. Note that filters attached to handlers are consulted before an event is emitted by the handler, whereas filters attached to loggers are consulted whenever an event is logged (using , , etc.), before sending an event to handlers. This means that events which have been generated by descendant loggers will not be filtered by a logger’s filter setting, unless the filter has also been applied to those descendant loggers. You don’t actually need to subclass : you can pass any instance which has a method with the same semantics. Changed in version 3.2: You don’t need to create specialized classes, or use other classes with a method: you can use a function (or other callable) as a filter. The filtering logic will check to see if the filter object has a attribute: if it does, it’s assumed to be a and its method is called. Otherwise, it’s assumed to be a callable and called with the record as the single parameter. The returned value should conform to that returned by . Changed in version 3.12: You can now return a instance from filters to replace the log record rather than modifying it in place. This allows filters attached to a to modify the log record before it is emitted, without having side effects on other handlers. Although filters are used primarily to filter records based on more sophisticated criteria than levels, they get to see every record which is processed by the handler or logger they’re attached to: this can be useful if you want to do things like counting how many records were processed by a particular logger or handler, or adding, changing or removing attributes in the being processed. Obviously changing the LogRecord needs to be done with some care, but it does allow the injection of contextual information into logs (see Using Filters to impart contextual information).\n\nThe LogRecord has a number of attributes, most of which are derived from the parameters to the constructor. (Note that the names do not always correspond exactly between the LogRecord constructor parameters and the LogRecord attributes.) These attributes can be used to merge data from the record into the format string. The following table lists (in alphabetical order) the attribute names, their meanings and the corresponding placeholder in a %-style format string. If you are using {}-formatting ( ), you can use as the placeholder in the format string. If you are using $-formatting ( ), use the form . In both cases, of course, replace with the actual attribute name you want to use. In the case of {}-formatting, you can specify formatting flags by placing them after the attribute name, separated from it with a colon. For example: a placeholder of would format a millisecond value of as . Refer to the documentation for full details on the options available to you. You shouldn’t need to format this yourself. The tuple of arguments merged into to produce , or a dict whose values are used for the merge (when there is only one argument, and it is a dictionary). Human-readable time when the was created. By default this is of the form ‘2003-07-08 16:49:45,896’ (the numbers after the comma are millisecond portion of the time). Time when the was created (as returned by / 1e9). You shouldn’t need to format this yourself. Exception tuple (à la ) or, if no exception has occurred, . Name of function containing the logging call. Source line number where the logging call was issued (if available). The logged message, computed as . This is set when is invoked. Millisecond portion of the time when the was created. You shouldn’t need to format this yourself. The format string passed in the original logging call. Merged with to produce , or an arbitrary object (see Using arbitrary objects as messages). Name of the logger used to log the call. Full pathname of the source file where the logging call was issued (if available). Process name (if available). Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded. You shouldn’t need to format this yourself. Stack frame information (where available) from the bottom of the stack in the current thread, up to and including the stack frame of the logging call which resulted in the creation of this record. Thread name (if available). name (if available).\n\nIn addition to the classes described above, there are a number of module-level functions. Return a logger with the specified name or, if name is , return the root logger of the hierarchy. If specified, the name is typically a dot-separated hierarchical name like ‘a’, ‘a.b’ or ‘a.b.c.d’. Choice of these names is entirely up to the developer who is using logging, though it is recommended that be used unless you have a specific reason for not doing that, as mentioned in Logger Objects. All calls to this function with a given name return the same logger instance. This means that logger instances never need to be passed between different parts of an application. Return either the standard class, or the last class passed to . This function may be called from within a new class definition, to ensure that installing a customized class will not undo customizations already applied by other code. For example: Return a callable which is used to create a . Added in version 3.2: This function has been provided, along with , to allow developers more control over how the representing a logging event is constructed. See for more information about the how the factory is called. This is a convenience function that calls , on the root logger. The handling of the arguments is in every way identical to what is described in that method. The only difference is that if the root logger has no handlers, then is called, prior to calling on the root logger. For very short scripts or quick demonstrations of facilities, and the other module-level functions may be convenient. However, most programs will want to carefully and explicitly control the logging configuration, and should therefore prefer creating a module-level logger and calling (or other level-specific methods) on it, as described at the beginnning of this documentation. Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . There is an obsolete function which is functionally identical to . As is deprecated, please do not use it - use instead. Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for . Exception info is added to the logging message. This function should only be called from an exception handler. Logs a message with level level on the root logger. The arguments and behavior are otherwise the same as for . Provides an overriding level level for all loggers which takes precedence over the logger’s own level. When the need arises to temporarily throttle logging output down across the whole application, this function can be useful. Its effect is to disable all logging calls of severity level and below, so that if you call it with a value of INFO, then all INFO and DEBUG events would be discarded, whereas those of severity WARNING and above would be processed according to the logger’s effective level. If is called, it effectively removes this overriding level, so that logging output again depends on the effective levels of individual loggers. Note that if you have defined any custom logging level higher than (this is not recommended), you won’t be able to rely on the default value for the level parameter, but will have to explicitly supply a suitable value. Changed in version 3.7: The level parameter was defaulted to level . See bpo-28524 for more information about this change. Associates level level with text levelName in an internal dictionary, which is used to map numeric levels to a textual representation, for example when a formats a message. This function can also be used to define your own levels. The only constraints are that all levels used must be registered using this function, levels should be positive integers and they should increase in increasing order of severity. If you are thinking of defining your own levels, please see the section on Custom Levels. Returns a mapping from level names to their corresponding logging levels. For example, the string “CRITICAL” maps to . The returned mapping is copied from an internal mapping on each call to this function. Returns the textual or numeric representation of logging level level. If level is one of the predefined levels , , , or then you get the corresponding string. If you have associated levels with names using then the name you have associated with level is returned. If a numeric value corresponding to one of the defined levels is passed in, the corresponding string representation is returned. The level parameter also accepts a string representation of the level such as ‘INFO’. In such cases, this functions returns the corresponding numeric value of the level. If no matching numeric or string value is passed in, the string ‘Level %s’ % level is returned. Levels are internally integers (as they need to be compared in the logging logic). This function is used to convert between an integer level and the level name displayed in the formatted log output by means of the format specifier (see LogRecord attributes), and vice versa. Changed in version 3.4: In Python versions earlier than 3.4, this function could also be passed a text level, and would return the corresponding numeric value of the level. This undocumented behaviour was considered a mistake, and was removed in Python 3.4, but reinstated in 3.4.2 due to retain backward compatibility. Returns a handler with the specified name, or if there is no handler with that name. Returns an immutable set of all known handler names. Creates and returns a new instance whose attributes are defined by attrdict. This function is useful for taking a pickled attribute dictionary, sent over a socket, and reconstituting it as a instance at the receiving end. Does basic configuration for the logging system by creating a with a default and adding it to the root logger. The functions , , , and will call automatically if no handlers are defined for the root logger. This function does nothing if the root logger already has handlers configured, unless the keyword argument force is set to . This function should be called from the main thread before other threads are started. In versions of Python prior to 2.7.1 and 3.2, if this function is called from multiple threads, it is possible (in rare circumstances) that a handler will be added to the root logger more than once, leading to unexpected results such as messages being duplicated in the log. The following keyword arguments are supported. Specifies that a be created, using the specified filename, rather than a . If filename is specified, open the file in this mode. Defaults to . Use the specified format string for the handler. Defaults to attributes , and separated by colons. Use the specified date/time format, as accepted by . If format is specified, use this style for the format string. One of , or for printf-style, or respectively. Defaults to . Set the root logger level to the specified level. Use the specified stream to initialize the . Note that this argument is incompatible with filename - if both are present, a is raised. If specified, this should be an iterable of already created handlers to add to the root logger. Any handlers which don’t already have a formatter set will be assigned the default formatter created in this function. Note that this argument is incompatible with filename or stream - if both are present, a is raised. If this keyword argument is specified as true, any existing handlers attached to the root logger are removed and closed, before carrying out the configuration as specified by the other arguments. If this keyword argument is specified along with filename, its value is used when the is created, and thus used when opening the output file. If this keyword argument is specified along with filename, its value is used when the is created, and thus used when opening the output file. If not specified, the value ‘backslashreplace’ is used. Note that if is specified, it will be passed as such to , which means that it will be treated the same as passing ‘errors’. Changed in version 3.2: The style argument was added. Changed in version 3.3: The handlers argument was added. Additional checks were added to catch situations where incompatible arguments are specified (e.g. handlers together with stream or filename, or stream together with filename). Changed in version 3.8: The force argument was added. Changed in version 3.9: The encoding and errors arguments were added. Informs the logging system to perform an orderly shutdown by flushing and closing all handlers. This should be called at application exit and no further use of the logging system should be made after this call. When the logging module is imported, it registers this function as an exit handler (see ), so normally there’s no need to do that manually. Tells the logging system to use the class klass when instantiating a logger. The class should define such that only a name argument is required, and the should call . This function is typically called before any loggers are instantiated by applications which need to use custom logger behavior. After this call, as at any other time, do not instantiate loggers directly using the subclass: continue to use the API to get your loggers. Set a callable which is used to create a . factory – The factory callable to be used to instantiate a log record. Added in version 3.2: This function has been provided, along with , to allow developers more control over how the representing a logging event is constructed. The factory has the following signature: The full pathname of the file where the logging call was made. The line number in the file where the logging call was made. The arguments for the logging message. The name of the function or method which invoked the logging call. A stack traceback such as is provided by , showing the call hierarchy."
    },
    {
        "link": "https://stackoverflow.com/questions/6386698/how-to-write-to-a-file-using-the-logging-python-module",
        "document": "I prefer to use a configuration file. It allows me to switch logging levels, locations, etc without changing code when I go from development to release. I simply package a different config file with the same name, and with the same defined loggers.\n\nHere is my code for the log config file"
    },
    {
        "link": "https://signoz.io/guides/how-to-write-to-a-file-using-the-logging-python-module",
        "document": ""
    },
    {
        "link": "https://realpython.com/python-logging",
        "document": "Logging in Python lets you record important information about your program’s execution. You use the built-in module to capture logs, which provide insights into application flow, errors, and usage patterns. With Python logging, you can create and configure loggers, set log levels, and format log messages without installing additional packages. You can also generate log files to store records for later analysis.\n\nBy the end of this tutorial, you’ll understand that:\n• You can use logging for debugging, performance analysis, and monitoring usage patterns.\n• Logging in Python works by configuring loggers and setting log levels.\n• Using a logging library provides structured logging and control over log output.\n• You should prefer logging over because it decreases the maintainance burden and allows you to manage log levels.\n\nYou’ll do the coding for this tutorial in the Python standard REPL. If you prefer Python files, then you’ll find a full logging example as a script in the materials of this tutorial. You can download this script by clicking the link below:\n\nIf you commonly use Python’s function to get information about the flow of your programs, then logging is the natural next step for you. This tutorial will guide you through creating your first logs and show you how to make logging grow with your projects.\n\nThe module in Python’s standard library is a ready-to-use, powerful module that’s designed to meet the needs of beginners as well as enterprise teams. Note: Since logs offer a variety of insights, the module is often used by other third-party Python libraries, too. Once you’re more advanced in the practice of logging, you can integrate your log messages with the ones from those libraries to produce a homogeneous log for your application. To leverage this versatility, it’s a good idea to get a better understanding of how the module works under the hood. For example, you could take a stroll through the module’s source code The main component of the module is something called the logger. You can think of the logger as a reporter in your code that decides what to record, at what level of detail, and where to store or send these records. To get a first impression of how the module and a logger work, open the Python standard REPL and enter the code below: The output shows the severity level before each message along with , which is the name the module gives to its default logger. This output shows the default format that can be configured to include things like a timestamp or other details. In the example above, you’re sending a message on the logger. The log level of the message is . Log levels are an important aspect of logging. By default, there are five standard levels indicating the severity of events. Each has a corresponding function that can be used to log events at that level of severity. Note: There’s also a log level, which you’ll encounter later in this tutorial when you learn about custom logging handlers. Here are the five default log levels, in order of increasing severity: Provides detailed information that’s valuable to you as a developer. Provides general information about what’s going on with your program. Indicates that there’s something you should look into. Alerts you to an unexpected problem that’s occured in your program. Tells you that a serious error has occurred and may have crashed your app. The module provides you with a default logger that allows you to get started with logging without needing to do much configuration. However, the functions listed in the table above reveal a quirk that you may not expect: \"This is an info message\" \"This is an error message\" Notice that the and messages didn’t get logged. This is because, by default, the logging module logs the messages with a severity level of or above. You can change that by configuring the logging module to log events of all levels. To set up your basic logging configuration and adjust the log level, the module comes with a function. As a Python developer, this camel-cased function name may look unusual to you as it doesn’t follow the PEP 8 naming conventions: “This is because it was adopted from Log4j, a logging utility in Java. It is a known issue in the package but by the time it was decided to add it to the standard library, it had already been adopted by users and changing it to meet PEP8 requirements would cause backwards compatibility issues.” (Source) Later in this tutorial, you’ll learn about common parameters for . For now, you’ll focus on the parameter to set the log level of the logger: By using the parameter, you can set what level of log messages you want to record. This can be done by passing one of the constants available in the class. You can use either the constant itself, its numeric value, or the string value as the argument: Setting a log level will enable all logging calls at the defined level and higher. For example, when you set the log level to , all events at or above the level will be logged. By default, logs contain the log level, the logger’s name, and the log message. That’s good for a start. But you can enhance your logs with additional data by leveraging the parameter of . The parameter accepts a string that can contain a number of predefined attributes. You can think of these attributes as placeholders that you format into the string. The default value of looks like this: This format is called -style string format. You may also find log formats with a dollar sign and curly braces ( ), which are related to the class. If you’re used to modern Python string formatting, then you’re probably more familiar with using curly braces ( ) to format your strings. You can define the style of your string with the parameter. The options for are , , or . When you provide a argument, then your string must match the targeted style. Otherwise, you’ll receive a . Note: Calling to configure the logger only works if the logger hasn’t been configured before. All functions automatically call without arguments if has never been called. So, for example, once you call , you’ll no longer be able to configure the logger with . Restart the REPL and start a logger with a different style format. Before trying out other attributes for your logs, stick with the default format structure from before: As mentioned before, the parameter accepts a string that can contain a number of predefined attributes. The ones you choose to use will depend on the insights that you want to get from your logs. Besides the message text and the log level, it usually makes sense to also have a timestamp in the log record. A timestamp can give you the exact time the program sent the log message. This can help you monitor code performance or notice patterns around when some errors occur. To add a timestamp to your logs, you can use the attribute in your string of . By default, also shows you milliseconds. If you don’t need to be that exact or if you want to customize the timestamp, then you must add to your call: In the example above, you prefix your logs with a timestamp. The directives you use to format the timestamp in the string are year ( ), month ( ), day ( ), hour ( ), and minutes ( ). For an overview of all the date directives that you can embed into the format string, you can have a look at the documentation. Additional information, like the time of your log message, becomes even more important when you want to keep a log of incidents over time or when you want to persist your logs in an external file. So far, you’ve logged the messages into your console. But if you want to archive your logs, then it’s a good idea to save log messages in a file that grows over time. To save your logs in a file, you can set up your logger’s with the argument. Just like when working with files in Python and using the function, you must provide a filepath. It’s also good practice to set an encoding and the mode the file should be opened in: With the configuration above, you save your logs in an file instead of showing the messages in the console. To add all logs to the file and not overwrite any existing logs, you set to , which is short for “append”. The is a basic text file that you can open in any text editor: Besides formatting your log records, it can also be a good idea to archive your logs in date-formatted folders and adjust the names of the log files. You can even get creative and format your log records in such a way that you can save your logs as CSV files and create your own programs to practice parsing CSV files. In most cases, you want to include dynamic information from your application in the logs. You’ve seen that the logging functions take a string as an argument. By leveraging Python’s f-strings, you can create verbose debug messages that contain variable information: First, you configure your logger and set the debug level to to show the debug messages. Then, you define a variable with the value . Using self-documenting expressions, you can interpolate a variable name and its value in an f-string by appending an equal sign ( ) to the variable name. Note: F-strings are eagerly evaluated. That means that they are interpolated even if the log message is never handled. If you’re interpolating a lot of lower level log messages, you should consider using the modulo operator ( ) for interpolation instead of f-strings. This style is supported by natively, such that you can write code like the following: In this case, you use as a placeholder for the string referred to by . Note that is passed as a parameter to . If the debug message is not handled, then Python will never do the interpolation. Using the module to see the current value of variables is a good first step when debugging your application. If you want to get even more insights about your code, then it can make sense to send exceptions to your logger. The module also allows you to capture the full stack traces in an application. Exception information can be captured if the parameter is passed as , and the logging functions are called like this: Since you’re logging into the file, you can keep track of stack traces in the file: 2024-07-22 15:04 - ERROR - DonutCalculationError Traceback (most recent call last): File \"<stdin>\", line 2, in <module> ZeroDivisionError: division by zero If isn’t set to , the output of the above program wouldn’t tell you anything about the exception, which, in a real-world scenario, might not be as simple as a . Since logging errors is such a common task, comes with a function that can save you some typing. If you’re logging from an exception handler, which you’ll learn more about later, then you can use the function. This function logs a message with the level and adds exception information to the message. Here’s an example of how you’ll get the same output as above using : Calling is like calling . Since the function always dumps exception information, you should only call from an exception handler. When you use , it shows a log at the level of . If you don’t want that, you can call any of the other logging functions from to and pass the parameter as .\n\nSo far, you’ve seen the default logger named , which is used by the module whenever functions like , , and so on are called. Calling the default logger directly is a handy way to get a first impression of how logging works. The downside of working with the logger directly is that the configuration can be cumbersome as you’re relying on a single . For bigger projects, you’ll need more flexibility for your logging needs. Generally, it’s a good idea to define your own custom logger. You can do so by creating an object of the class, which you can find in the module. You can instantiate a class by calling the function and providing a name for your logger: While you could use any string as the name, it’s good practice to pass as the name parameter. That way, your logger’s name is always the module’s name in the Python package namespace. When you call , you notice that you don’t see any additional logging information, such as the logger’s name or the log level. To format the log, you may be tempted to call on your custom logger. However, unlike the logger, you can’t configure a custom logger using . Instead, you have to configure your custom logger using handlers and formatters, which give you way more flexibility. Handlers come into the picture when you want to configure your own loggers. For example, when you want to send the log messages to different destinations like the standard output stream or a file. Note: A logger that you create can have one or more handlers. That means you can send your logs to multiple places when they’re generated. Here’s an example of adding two handlers to a custom logger. Start by importing to create your logger and then two handlers: The class will send your logs to the console. The class writes your log records to a file. To define where and how you want to write the logs, you provide a file path, an opening mode, and the encoding. After you’ve instantiated your handlers, you must add them to the logger. For this, you use the method: You can list all the handlers that a logger uses by looking at the property. In the example above, you can see the string representations of both handlers. Besides the class name, the representation of the handlers shows where the log will be written. For the , the logs are written to the standard error stream ( ) stream, which is the output channel that Python uses by default. For the , you can see the location where your log records will be saved. In the parentheses of the class representation, you’ll see the log level of your handlers. Currently, the log level is . As you might expect, means that the log level for the logging handlers is not set, yet. You’ll revisit the log levels again later in the tutorial. For now, put your logging handler into action: When you call , then both handlers take over the message. The output from is displayed right away in your console. To see if also did its job, open : Perfect! Both handlers work as expected. With one call of your custom logger, you can distribute your log messages into different directions using handlers. The module comes with many handy handlers for specific purposes. For example, , which creates a new log file once a file size limit is reached, or , with which you can create a new log file for defined intervals. So far, the messages look a bit plain. As you learned before, one of the strengths of logging is that it can enrich your information with metadata like timestamps or log levels. This is where formatters come into play! Handlers send your logs to the output destination you define. With a formatter, you can control the output format by specifying a string format as you did before with the argument of . Just like with handlers, you need to instantiate a class first before working with a formatter. For formatters, you use the class of the module. To get a first impression of how a formatter works, you’ll revisit the code from before and add to the mix. Start by adding the formatter to and try it out: Here, you instantiate a formatter that shows a timestamp, the log level, and the log message. By calling with as an argument, you define the formatting of the handler you attach the formatter to. Note: Unlike , which is a method of , is a method of . With both and added to , your call also ended up in . But since you only set the formatter for , the log record in remains unstyled. By defining and setting different formatters for your handlers, you can control the amount of additional information that displays in your log messages. But you don’t have to stop there! You can even show debug messages in your console but save more severe log levels in a file, or vice versa. Similar to calling , you can also set the log level in handlers. This is useful when you want to set multiple handlers for the same logger but want different severity levels for each. For example, while developing an application, you may want logs with level and higher to be logged to the console, but everything with level and above to be saved to a file. Start by creating a custom logger and explore its default log level: The default log level of your custom level is , which stands for . Still, the string representation of your logger shows the log level. That’s because a custom logger inherits the log level of its parent logger if you haven’t yet set the log level manually. Besides having a look at the string representation of a logger, you can also call the method: The returned value of is an integer that stands for the log level. Here’s an overview of the numeric representations of log levels: You can use either the numeric value or a log level string to set the log level of your custom logger: You use the method to set the log level of your logger. Any handler that you add to the logger will recognize this log level: \"Just checking in, again!\" INFO - Just checking in, again! Since the log level of is set to , the that you added to doesn’t show logs that have a log level lower than . You may argue that you haven’t set the log level of yet, and you’re right. At this point, has the level : But even setting a handler’s log level lower than the associated logger won’t show messages below the logger’s log level: The debug message still doesn’t show, even though you allowed to show log records for the level and above. This behavior of your logger and its handlers can be confusing at first. Note: You define the lowest allowed log level on the logger itself. Handlers can’t show logs lower than the defined log level of the logger they’re connected to. With this behavior in mind, it can be helpful during development to set your logger’s log level to and let each handler decide their lowest log level: In the example above, you set different log levels for and . Since the log level of is , you can see all logs in the console. If you have a look at the file that writes to, then you can verify that the and logs were saved to the file: By leveraging different log levels, you can control where you log information. When you do so, it’s important to remember that handlers can never log levels below their logger’s log level. Instead, handlers log any level above the set log level. In other words, setting the log level will filter out any log messages below that level, and every log message at or above that level will be shown. If you only want to show a specific log level, then you can gain even more control by adding a filter to a handler. If you’re interested in the log records your Python program produces, you’re probably also interested in more severe log levels like or even . So, most of the time, you’ll be fine collecting all log records of a certain log level and above with specific handlers. However, there are situations where it may make sense to handle messages for a specific log level differently. That’s when a can come in handy. The important part of the specifications for the object is this: The filtering logic will check to see if the filter object has a attribute: if it does, it’s assumed to be a and its method is called. Otherwise, it’s assumed to be a callable and called with the record as the single parameter. The returned value should conform to that returned by . (Source) In other words, there are three approaches to creating filters for logging. You can create a:\n• Subclass of and overwrite the method For the subclass and class, must accept a log record and return a Boolean. Inside the method’s body, it makes sense to define a conditional statement that checks the provided record. The callable can be a basic function with one parameter for the log record that your handler passes in. The return value must be a Boolean. Using a callable is arguably the most convenient when creating basic filters, so you’ll explore this approach further. With the theory in place, it’s time to put the logging filter into practice. The filter you’ll create will make sure the handler that outputs logs into the console only shows messages: First, you create a callable named with a parameter. The passed in log record will be an instance of . In , you return if the attribute of your log record is “DEBUG”. Any log record that isn’t on the log level will return and will not be shown by the handler you attach the filter to. To add a filter to a handler, you use the method of the class. The argument for must be a filter. In the code above, you’re passing in a reference to to attach the filter to . For , you’ve set the log level to . Without any other adjustments, the handler will show all log records of the level and above. With your filter in place, you’re surpressing higher log levels and only showing debug messages in the console. Since you didn’t add a filter to , this handler happily logs records for the set log level and above. Your custom loggers become highly customizable tools that can show exactly the output you want to see. A custom logger can be as basic as a root logger. But by combining handlers, formatters, and filters, you can make your custom loggers into an eloquent field reporter for your code."
    }
]