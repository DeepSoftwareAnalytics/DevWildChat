[
    {
        "link": "https://chromium.googlesource.com/libyuv/libyuv",
        "document": "libyuv is an open source project that includes YUV scaling and conversion functionality.\n• Scale YUV to prepare content for compression, with point, bilinear or box filter.\n• Convert to YUV from webcam formats for compression.\n• Rotate by 90/180/270 degrees to adjust for mobile devices in portrait mode.\n\nSee Getting started for instructions on how to get started developing.\n\nYou can also browse the docs directory for more documentation."
    },
    {
        "link": "https://registry.khronos.org/OpenGL-Refpages/gl4/html/glBlendFunc.xhtml",
        "document": "Specifies how the red, green, blue, and alpha destination blending factors are computed. The following symbolic constants are accepted: GL_ZERO , GL_ONE , GL_SRC_COLOR , GL_ONE_MINUS_SRC_COLOR , GL_DST_COLOR , GL_ONE_MINUS_DST_COLOR , GL_SRC_ALPHA , GL_ONE_MINUS_SRC_ALPHA , GL_DST_ALPHA , GL_ONE_MINUS_DST_ALPHA . GL_CONSTANT_COLOR , GL_ONE_MINUS_CONSTANT_COLOR , GL_CONSTANT_ALPHA , and GL_ONE_MINUS_CONSTANT_ALPHA . The initial value is GL_ZERO .\n\nFor glBlendFunci , specifies the index of the draw buffer for which to set the blend function.\n\nPixels can be drawn using a function that blends the incoming (source) RGBA values with the RGBA values that are already in the frame buffer (the destination values). Blending is initially disabled. Use glEnable and with argument to enable and disable blending.\n\ndefines the operation of blending for all draw buffers when it is enabled. defines the operation of blending for a single draw buffer specified by when enabled for that draw buffer. specifies which method is used to scale the source color components. specifies which method is used to scale the destination color components. Both parameters must be one of the following symbolic constants: , , , , , , , , , , , , , , , , , , and . The possible methods are described in the following table. Each method defines four scale factors, one each for red, green, blue, and alpha. In the table and in subsequent equations, first source, second source and destination color components are referred to as , and , respectively. The color specified by glBlendColor is referred to as . They are understood to have integer values between 0 and , where\n\nSource and destination scale factors are referred to as and . The scale factors described in the table, denoted , represent either source or destination factors. All scale factors have range .\n\nTo determine the blended RGBA values of a pixel, the system uses the following equations:\n\nDespite the apparent precision of the above equations, blending arithmetic is not exactly specified, because blending operates with imprecise integer color values."
    },
    {
        "link": "https://registry.khronos.org/OpenGL-Refpages/es3.0/html/glBlendFunc.xhtml",
        "document": "Specifies how the red, green, blue, and alpha destination blending factors are computed. The following symbolic constants are accepted: GL_ZERO , GL_ONE , GL_SRC_COLOR , GL_ONE_MINUS_SRC_COLOR , GL_DST_COLOR , GL_ONE_MINUS_DST_COLOR , GL_SRC_ALPHA , GL_ONE_MINUS_SRC_ALPHA , GL_DST_ALPHA , GL_ONE_MINUS_DST_ALPHA . GL_CONSTANT_COLOR , GL_ONE_MINUS_CONSTANT_COLOR , GL_CONSTANT_ALPHA , and GL_ONE_MINUS_CONSTANT_ALPHA . The initial value is GL_ZERO .\n\nPixels can be drawn using a function that blends the incoming (source) RGBA values with the RGBA values that are already in the frame buffer (the destination values). Blending is initially disabled. Use glEnable and glDisable with argument to enable and disable blending.\n\ndefines the operation of blending when it is enabled. specifies which method is used to scale the source color components. specifies which method is used to scale the destination color components. Both parameters must be one of the following symbolic constants: , , , , , , , , , , , , , , , The possible methods are described in the following table. Each method defines four scale factors, one each for red, green, blue, and alpha. In the table and in subsequent equations, source and destination color components are referred to as , and , respectively. The color specified by glBlendColor is referred to as .\n\nSource and destination scale factors are referred to as and . The scale factors described in the table, denoted , represent either source or destination factors. All scale factors have range .\n\nPrior to blending, unsigned normalized fixed-point color components undergo an implied conversion to floating-point using equation 2.1. This conversion must leave the values 0 and 1 invariant. Blending computations are treated as if carried out in floating-point and will be performed with a precision and dynamic range no lower than that used to represent destination components. If the value of for the framebuffer attachment corresponding to the destination buffer is , the R, G, and B destination color values (after conversion from fixed-point to floating-point) are considered to be encoded for the sRGB color space and hence must be linearized prior to their use in blending. Each R, G, and B component is converted in the same fashion described for sRGB texture components.\n\nTo determine the blended RGBA values of a pixel, the system uses the following equations:\n\nIf the value of for the framebuffer attachment corresponding to the destination buffer is , the R, G, and B values after blending are converted into the non-linear sRGB color space by computing where cl is the R, G, or B element and cs is the result (effectively converted into an sRGB color space). If is not , then cs = cl: The resulting cs values for R, G, and B, and the unmodified A form a new RGBA color value. If the color buffer is fixed-point, each component is clamped to the range [0; 1] and then converted to a fixed-point value using equation"
    },
    {
        "link": "https://stackoverflow.com/questions/5466848/opengl-texture-blending-problems",
        "document": "I'm creating a 2d application for the iPad using OpenGL ES and having some issue drawing transparent images.\n\nI'm using png-24 images with full transparency. I'm also changing the color of some of some textures, which are white with some areas transparent or semi-transparent. That all works fine.\n\nWhen I try to set the alpha value of one of these textures, however, it's not working quite right. The colors are much too saturated, and if the alpha value = 0, i'm left with a white rather than transparent image over a light grey background. When such a transparent image is over a dark image, the dark image becomes a color similar to color of the transparent image.\n\nI've tried a many parameter combinations of the and with no success.\n\nI'm not very knowledgable about OpenGL, so if anyone has any suggestions, that would be great. Let me know if there are any details that would help.\n\nHere is the initialization of OpenGL"
    },
    {
        "link": "https://learnopengl.com/Advanced-OpenGL/Blending",
        "document": "in OpenGL is commonly known as the technique to implement within objects. Transparency is all about objects (or parts of them) not having a solid color, but having a combination of colors from the object itself and any other object behind it with varying intensity. A colored glass window is a transparent object; the glass has a color of its own, but the resulting color contains the colors of all the objects behind the glass as well. This is also where the name blending comes from, since we several pixel colors (from different objects) to a single color. Transparency thus allows us to see through objects.\n\nTransparent objects can be completely transparent (letting all colors through) or partially transparent (letting colors through, but also some of its own colors). The amount of transparency of an object is defined by its color's value. The alpha color value is the 4th component of a color vector that you've probably seen quite often now. Up until this chapter, we've always kept this 4th component at a value of giving the object transparency. An alpha value of would result in the object having complete transparency. An alpha value of tells us the object's color consist of 50% of its own color and 50% of the colors behind the object.\n\nThe textures we've used so far all consisted of color components: red, green and blue, but some textures also have an embedded alpha channel that contains an value per texel. This alpha value tells us exactly which parts of the texture have transparency and by how much. For example, the following window texture has an alpha value of at its glass part and an alpha value of at its corners. The glass part would normally be completely red, but since it has 75% transparency it largely shows the page's background through it, making it seem a lot less red:\n\nWe'll soon be adding this windowed texture to the scene from the depth testing chapter, but first we'll discuss an easier technique to implement transparency for pixels that are either fully transparent or fully opaque.\n\nSome effects do not care about partial transparency, but either want to show something or nothing at all based on the color value of a texture. Think of grass; to create something like grass with little effort you generally paste a grass texture onto a 2D quad and place that quad into your scene. However, grass isn't exactly shaped like a 2D square so you only want to display some parts of the grass texture and ignore the others.\n\nThe following texture is exactly such a texture where it either is full opaque (an alpha value of ) or it is fully transparent (an alpha value of ) and nothing in between. You can see that wherever there is no grass, the image shows the page's background color instead of its own.\n\nSo when adding vegetation to a scene we don't want to see a square image of grass, but rather only show the actual grass and see through the rest of the image. We want to the fragments that show the transparent parts of the texture, not storing that fragment into the color buffer.\n\nBefore we get into that we first need to learn how to load a transparent texture. To load textures with alpha values there's not much we need to change. automatically loads an image's alpha channel if it's available, but we do need to tell OpenGL our texture now uses an alpha channel in the texture generation procedure:\n\nAlso make sure that you retrieve all color components of the texture in the fragment shader, not just the RGB components:\n\nNow that we know how to load transparent textures it's time to put it to the test by adding several of these leaves of grass throughout the basic scene introduced in the depth testing chapter.\n\nWe create a small array where we add several vectors to represent the location of the grass leaves:\n\nEach of the grass objects is rendered as a single quad with the grass texture attached to it. It's not a perfect 3D representation of grass, but it's a lot more efficient than loading and rendering a large number of complex models. With a few tricks like adding randomized rotations and scales you can get pretty convincing results with quads.\n\nBecause the grass texture is going to be displayed on a quad object we'll need to create another VAO again, fill the VBO, and set the appropriate vertex attribute pointers. Then after we've rendered the floor and the two cubes we're going to render the grass leaves:\n\nRunning the application will now look a bit like this:\n\nThis happens because OpenGL by default does not know what to do with alpha values, nor when to discard them. We have to manually do this ourselves. Luckily this is quite easy thanks to the use of shaders. GLSL gives us the command that (once called) ensures the fragment will not be further processed and thus not end up into the color buffer. Thanks to this command we can check whether a fragment has an alpha value below a certain threshold and if so, discard the fragment as if it had never been processed:\n\nHere we check if the sampled texture color contains an alpha value lower than a threshold of and if so, discard the fragment. This fragment shader ensures us that it only renders fragments that are not (almost) completely transparent. Now it'll look like it should:\n\nYou can find the source code here.\n\nWhile discarding fragments is great and all, it doesn't give us the flexibility to render semi-transparent images; we either render the fragment or completely discard it. To render images with different levels of transparency we have to enable . Like most of OpenGL's functionality we can enable blending by enabling :\n\nNow that we've enabled blending we need to tell OpenGL how it should actually blend.\n\nBlending in OpenGL happens with the following equation:\n• \\(\\bar{\\color{green}C}_{source}\\): the source color vector. This is the color output of the fragment shader.\n• \\(\\bar{\\color{red}C}_{destination}\\): the destination color vector. This is the color vector that is currently stored in the color buffer.\n• \\(\\color{green}F_{source}\\): the source factor value. Sets the impact of the alpha value on the source color.\n• \\(\\color{red}F_{destination}\\): the destination factor value. Sets the impact of the alpha value on the destination color.\n\nAfter the fragment shader has run and all the tests have passed, this is let loose on the fragment's color output and with whatever is currently in the color buffer. The source and destination colors will automatically be set by OpenGL, but the source and destination factor can be set to a value of our choosing. Let's start with a simple example:\n\nWe have two squares where we want to draw the semi-transparent green square on top of the red square. The red square will be the destination color (and thus should be first in the color buffer) and we are now going to draw the green square over the red square.\n\nThe question then arises: what do we set the factor values to? Well, we at least want to multiply the green square with its alpha value so we want to set the \\(F_{src}\\) equal to the alpha value of the source color vector which is . Then it makes sense to let the destination square have a contribution equal to the remainder of the alpha value. If the green square contributes 60% to the final color we want the red square to contribute 40% of the final color e.g. . So we set \\(F_{destination}\\) equal to one minus the alpha value of the source color vector. The equation thus becomes:\n\nThe result is that the combined square fragments contain a color that is 60% green and 40% red:\n\nThe resulting color is then stored in the color buffer, replacing the previous color.\n\nSo this is great and all, but how do we actually tell OpenGL to use factors like that? Well it just so happens that there is a function for this called .\n\nThe function expects two parameters that set the option for the and . OpenGL defined quite a few options for us to set of which we'll list the most common options below. Note that the constant color vector \\(\\bar{\\color{blue}C}_{constant}\\) can be separately set via the function.\n\nTo get the blending result of our little two square example, we want to take the \\(alpha\\) of the source color vector for the source factor and \\(1 - alpha\\) of the same color vector for the destination factor. This translates to as follows:\n\nIt is also possible to set different options for the RGB and alpha channel individually using :\n\nThis function sets the RGB components as we've set them previously, but only lets the resulting alpha component be influenced by the source's alpha value.\n\nOpenGL gives us even more flexibility by allowing us to change the operator between the source and destination part of the equation. Right now, the source and destination components are added together, but we could also subtract them if we want. allows us to set this operation and has 5 possible options:\n• : the default, adds both colors to each other: \\(\\bar{C}_{result} = \\color{green}{Src} + \\color{red}{Dst}\\).\n• : subtracts both colors from each other: \\(\\bar{C}_{result} = \\color{green}{Src} - \\color{red}{Dst}\\).\n• : takes the component-wise minimum of both colors: \\(\\bar{C}_{result} = min(\\color{red}{Dst}, \\color{green}{Src})\\).\n• : takes the component-wise maximum of both colors: \\(\\bar{C}_{result} = max(\\color{red}{Dst}, \\color{green}{Src})\\).\n\nUsually we can simply omit a call to because is the preferred blending equation for most operations, but if you're really trying your best to break the mainstream circuit any of the other equations could suit your needs.\n\nNow that we know how OpenGL works with regards to blending it's time to put our knowledge to the test by adding several semi-transparent windows. We'll be using the same scene as in the start of this chapter, but instead of rendering a grass texture we're now going to use the transparent window texture from the start of this chapter.\n\nFirst, during initialization we enable blending and set the appropriate blending function:\n\nSince we enabled blending there is no need to discard fragments so we'll reset the fragment shader to its original version:\n\nThis time (whenever OpenGL renders a fragment) it combines the current fragment's color with the fragment color currently in the color buffer based on the alpha value of . Since the glass part of the window texture is semi-transparent we should be able to see the rest of the scene by looking through this window.\n\nIf you take a closer look however, you may notice something is off. The transparent parts of the front window are occluding the windows in the background. Why is this happening?\n\nThe reason for this is that depth testing works a bit tricky combined with blending. When writing to the depth buffer, the depth test does not care if the fragment has transparency or not, so the transparent parts are written to the depth buffer as any other value. The result is that the background windows are tested on depth as any other opaque object would be, ignoring transparency. Even though the transparent part should show the windows behind it, the depth test discards them.\n\nSo we cannot simply render the windows however we want and expect the depth buffer to solve all our issues for us; this is also where blending gets a little nasty. To make sure the windows show the windows behind them, we have to draw the windows in the background first. This means we have to manually sort the windows from furthest to nearest and draw them accordingly ourselves.\n\nTo make blending work for multiple objects we have to draw the most distant object first and the closest object last. The normal non-blended objects can still be drawn as normal using the depth buffer so they don't have to be sorted. We do have to make sure they are drawn first before drawing the (sorted) transparent objects. When drawing a scene with non-transparent and transparent objects the general outline is usually as follows:\n• Draw all the transparent objects in sorted order.\n\nOne way of sorting the transparent objects is to retrieve the distance of an object from the viewer's perspective. This can be achieved by taking the distance between the camera's position vector and the object's position vector. We then store this distance together with the corresponding position vector in a data structure from the STL library. A automatically sorts its values based on its keys, so once we've added all positions with their distance as the key they're automatically sorted on their distance value:\n\nThe result is a sorted container object that stores each of the window positions based on their key value from lowest to highest distance.\n\nThen, this time when rendering, we take each of the map's values in reverse order (from farthest to nearest) and then draw the corresponding windows in correct order:\n\nWe take a reverse iterator from the to iterate through each of the items in reverse order and then translate each window quad to the corresponding window position. This relatively simple approach to sorting transparent objects fixes the previous problem and now the scene looks like this:\n\nYou can find the complete source code with sorting here.\n\nWhile this approach of sorting the objects by their distance works well for this specific scenario, it doesn't take rotations, scaling or any other transformation into account and weirdly shaped objects need a different metric than simply a position vector.\n\nSorting objects in your scene is a difficult feat that depends greatly on the type of scene you have, let alone the extra processing power it costs. Completely rendering a scene with solid and transparent objects isn't all that easy. There are more advanced techniques like but these are out of the scope of this chapter. For now you'll have to live with normally blending your objects, but if you're careful and know the limitations you can get pretty decent blending implementations."
    },
    {
        "link": "https://stackoverflow.com/questions/4429932/glblendfunc-with-32-bit-rgba-textures",
        "document": "I have a texture that is semi-transparent with varying opacity at different locations. I have the main texture bitmap, and a mask bitmap. When the program executes, the alpha values from the mask bitmap are loaded into the alpha values of the main texture bitmap. The areas that I want to be transparent have a value of 255 alpha, and the areas that I want to remain totally opaque have values of 0 alpha. There are in-between values also for mid-transparency.\n\nI have tried all manner of glBlendFunc() settings, but it is either completely invisible or it acts on the RGB colors of the source texture."
    }
]