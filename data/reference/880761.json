[
    {
        "link": "https://stackoverflow.com/questions/362059/what-is-the-big-o-of-a-nested-loop-where-number-of-iterations-in-the-inner-loop",
        "document": "Let us trace the number of times each loop executes in each iteration.\n\nIn the first iteration of the outer loop (i = 0), the inner loop executes times.\n\nIn the second iteration of the outer loop (i = 1), the inner loop executes times.\n\nIn the third iteration of the outer loop (i = 2), the inner loop executes times.\n\nIn the th iteration of the outer loop (i = N - 3), the inner loop executes times.\n\nIn the th iteration of the outer loop (i = N - 2), the inner loop executes time.\n\nIn the last ( th) iteration of the outer loop (i = N - 1), the inner loop executes times.\n\nTherefore, the total number of times this code executes is\n\nSubstituting this in the Sum of Natural numbers Formula,\n\nAlso, do take a look at these"
    },
    {
        "link": "https://reddit.com/r/learnprogramming/comments/yqhyhh/what_is_the_big_o_notation_for_a_nested_for_loop",
        "document": "Hi all. I have a question regarding big O notation when it comes to time complexity. If I understand correctly, if I have an array of N elements, and carry out a nested loop over all N elements, then the time complexity will be O(N2 ), e.g.\n\nIf that is true, then that makes sense intuitively--N x N = N2 . But what if the second loop doesn't start at 0, but starts at element i--what is the time complexity? e.g.\n\nIt looks like the time complexity should still be greater than O(N), but now less than O(N2 ). So my educated guess would be O(NlogN). Is that correct? If not, what am I misunderstanding?\n\nI ask because the two solutions I've seen to the Maximum Subarray LeetCode problem say the time complexity of such a nested loop is still O(N2 ) (here and here)."
    },
    {
        "link": "https://geeksforgeeks.org/how-to-analyse-loops-for-complexity-analysis-of-algorithms",
        "document": "We have discussed Asymptotic Analysis, Worst, Average and Best Cases and Asymptotic Notations in previous posts. In this post, an analysis of iterative programs with simple examples is discussed.\n\nThe analysis of loops for the complexity analysis of algorithms involves finding the number of operations performed by a loop as a function of the input size. This is usually done by determining the number of iterations of the loop and the number of operations performed in each iteration.\n\nHere are the general steps to analyze loops for complexity analysis:\n\nDetermine the number of iterations of the loop. This is usually done by analyzing the loop control variables and the loop termination condition.\n\nDetermine the number of operations performed in each iteration of the loop. This can include both arithmetic operations and data access operations, such as array accesses or memory accesses.\n\nExpress the total number of operations performed by the loop as a function of the input size. This may involve using mathematical expressions or finding a closed-form expression for the number of operations performed by the loop.\n\nDetermine the order of growth of the expression for the number of operations performed by the loop. This can be done by using techniques such as big O notation or by finding the dominant term and ignoring lower-order terms.\n\nThe time complexity of a function (or set of statements) is considered as O(1) if it doesn’t contain a loop, recursion, and call to any other non-constant time function. \n\n i.e. set of non-recursive and non-loop statements\n\nIn computer science, O(1) refers to constant time complexity, which means that the running time of an algorithm remains constant and does not depend on the size of the input. This means that the execution time of an O(1) algorithm will always take the same amount of time regardless of the input size. An example of an O(1) algorithm is accessing an element in an array using an index.\n• None A loop or recursion that runs a constant number of times is also considered O(1). For example, the following loop is O(1).\n\nThe Time Complexity of a loop is considered as O(n) if the loop variables are incremented/decremented by a constant amount. For example following functions have O(n) time complexity. Linear time complexity, denoted as O(n), is a measure of the growth of the running time of an algorithm proportional to the size of the input. In an O(n) algorithm, the running time increases linearly with the size of the input. For example, searching for an element in an unsorted array or iterating through an array and performing a constant amount of work for each element would be O(n) operations. In simple words, for an input of size n, the algorithm takes n steps to complete the operation.\n\nThe time complexity is defined as an algorithm whose performance is directly proportional to the squared size of the input data, as in nested loops it is equal to the number of times the innermost statement is executed. For example, the following sample loops have O(n2) time complexity\n\nQuadratic time complexity, denoted as O(n^2), refers to an algorithm whose running time increases proportional to the square of the size of the input. In other words, for an input of size n, the algorithm takes n * n steps to complete the operation. An example of an O(n^2) algorithm is a nested loop that iterates over the entire input for each element, performing a constant amount of work for each iteration. This results in a total of n * n iterations, making the running time quadratic in the size of the input.\n\nExample: Selection sort and Insertion Sort have O(n2) time complexity.\n\nThe time Complexity of a loop is considered as O(Logn) if the loop variables are divided/multiplied by a constant amount. And also for recursive calls in the recursive function, the Time Complexity is considered as O(Logn).\n\nThe Time Complexity of a loop is considered as O(LogLogn) if the loop variables are reduced/increased exponentially by a constant amount.\n\nSee this for mathematical details.\n\nHow to combine the time complexities of consecutive loops?\n\nWhen there are consecutive loops, we calculate time complexity as a sum of the time complexities of individual loops.\n\nTo combine the time complexities of consecutive loops, you need to consider the number of iterations performed by each loop and the amount of work performed in each iteration. The total time complexity of the algorithm can be calculated by multiplying the number of iterations of each loop by the time complexity of each iteration and taking the maximum of all possible combinations.\n\nFor example, consider the following code:\n\nHere, the outer loop performs n iterations, and the inner loop performs m iterations for each iteration of the outer loop. So, the total number of iterations performed by the inner loop is n * m, and the total time complexity is O(n * m).\n\nIn another example, consider the following code:\n\nHere, the outer loop performs n iterations, and the inner loop performs i iterations for each iteration of the outer loop, where i is the current iteration count of the outer loop. The total number of iterations performed by the inner loop can be calculated by summing the number of iterations performed in each iteration of the outer loop, which is given by the formula sum(i) from i=1 to n, which is equal to n * (n + 1) / 2. Hence, the total time complex\n\n\n\nHow to calculate time complexity when there are many if, else statements inside loops?\n\nAs discussed here, the worst-case time complexity is the most useful among best, average and worst. Therefore we need to consider the worst case. We evaluate the situation when values in if-else conditions cause a maximum number of statements to be executed. \n\nFor example, consider the linear search function where we consider the case when an element is present at the end or not present at all. \n\nWhen the code is too complex to consider all if-else cases, we can get an upper bound by ignoring if-else and other complex control statements.\n\nHow to calculate the time complexity of recursive functions?\n\nThe time complexity of a recursive function can be written as a mathematical recurrence relation. To calculate time complexity, we must know how to solve recurrences. We will soon be discussing recurrence-solving techniques as a separate post.\n\nQuiz on Analysis of Algorithms \n\nFor more details, please refer: Design and Analysis of Algorithms.\n\nPlease write comments if you find anything incorrect, or you want to share more information about the topic discussed above."
    },
    {
        "link": "https://jawblet.medium.com/find-the-big-o-notation-of-any-nested-loop-with-series-d30fb367ec38",
        "document": "If, like me, you haven’t looked at series since high school algebra:\n\nA sequence is an ordered list of sequential terms. A series is the sum of the sequence. They can be arithmetic or geometric.\n\nArithmetic: the terms differ by the same constant (1, 3, 5, 7…)\n\nGeometric: the terms differ by the same ratio (2, 4, 8, 16…)\n\nNested loops can always be assessed as a series. This allows us to find the entire loops’ amount of iterations at once.\n\nThe number of terms, n, is the amount of times the outer loop turns.\n\nThis is the variable in the series’ equation since the order of growth is factor of the input. The value of n is the number of iterations within each turn.\n\nexecuting the body one time each: 1 + 1 + 1 = 3\n\nIf that was a nested loop:\n\nThe entire loop still turns three times, but within each execution there are three additional executions of the body: 3 + 3 + 3 = 9\n\nFinally, if it was loop with two loops inside (triple loop):\n\nThe entire loop still turns three times, but within each turn there are three additional executions of the body, and within each of those turns are three more executions: 3*3 + 3*3 + 3*3 = 27\n\nSay if instead of incrementing to , there was a variable :\n\nIf this was a series, it would be: n*n + n*n + n*n … n times.\n\nThis is an arithmetic series with a difference of 0 or a geometric series with a ratio of 1. Either works, but plugged into the arithmetic series formula, it is:\n\nThe big-O notation of n³ is O(n³).\n\nThis is a pretty easy Big-O problem to understand by looking at, but it helps show that ALL loops, including single loops, are technically a series.\n\nGiven the loop first mentioned above:\n\nFrom looking at the loops, it might seem like the intuitive answer is O(n log n). The first loop seems like O(log) and the second seems O(n) and you can multiply them to get O(n log n). This is not correct, since this doesn’t consider is that the second loop is not a straightforward linear loop.\n\nImagine this question was about the single outer loop:\n\nThe relationship between n and the number of turns is logarithmic. Given i = n, this loop is divides i by 2 each turn, returning about how many times n is divisible by 2. In other words, x so 2ˣ = n.\n\ni = 16\n\ni = 8\n\ni = 4 \n\ni = 2\n\ni = 1 (after this, , and the loop stops)\n\nIf just the outer loop were present, this would run 5 times.\n\nYou might be thinking that log₂ 16 = 4, not 5. So is the relationship really logarithmic? If you did more of these out, a general pattern would emerge, where the number of iterations would always be ⌈log n⌉ or log n + 1.\n\nSince lower-order terms are dropped for Big-O, this loops’ big-O notation is O(log n). More important than plotting the exact number of iterations, is the relationship between the input n and the number of iterations, which is logarithmic due the fact mentioned above that i is halved on each iteration, roughly looping x times where x satisfies 2ˣ = n.\n\nNow adding back in the inner loop:\n\nWe need to generalize the series above, since the runtime needs to apply to all n. Generalizing the series above gets:\n\nIt’s evident this is a geometric series since there’s a common ratio 1/2 between all terms. Applying the formula above:\n\na = 16 (first term can be an arbitrary integer)\n\nn= log(n) (number of terms—remember we found this above when looking at the outer loop)\n\nTo find order of growth, drop the coefficients and lower-order terms.\n\nTherefore, it is linear.\n\nThis another problem that is hard to “eyeball” for Big-O but is solved with a series.\n\nFor the outer loop, i is doubled on each iteration. i is 2 raised to the number of iterations (2⁰ = 1, 2¹ = 2, 2² = 4, 2³ = 8). Same as before, this is logarithmic, since the number of iterations roughly equals x times where x satisfies 2ˣ = n.\n\nThe inner loop iterates while j is greater than 1. j doubles each iteration of i. Every time j doubles, it will take exactly one more iteration of j to divide it by 2 so j / 2 = 0.\n\nTaken to the conclusion, when i = n, j will iterate log n times, since (as we’ve shown) the question how many times can n be divided by 2 before n = 0? is the same as asking 2ˣ = n?\n\nThis is an arithmetic series, it can be expressed as:\n\nWithout even simplifying the entire thing, it’s clear that the highest-order term will be log²n, as we can drop the 0 and the 1/2."
    },
    {
        "link": "https://medium.com/enjoy-algorithm/analysis-of-loop-in-programming-cc9a644ef8cd",
        "document": "Loops are a fundamental operation in programming and are used to solve a variety of problems. Many problem-solving approaches in coding involve different types of loop structures. In fact, some approaches are entirely based on loops, such as:\n• Problem solving using data structures like stack, queue, hash table, etc.\n\nThe efficiency of an algorithm that uses these approaches often depends on the loop structure and the operations within the loop.\n\nThere are two common loop patterns that often appear in our solutions:\n• Single loop: This can involve a loop that runs in constant time, a loop that runs n times, a loop that grows exponentially, a loop that runs based on a specific condition, a loop that runs with a data structure, consecutive single loops, etc.\n• Nested loops: This can involve two nested loops, three nested loops, a single loop with nested loops, etc.\n\nOne way to design a better algorithm or optimize the code further is to learn how to analyze the time complexity of loops using Big-O notation. This is not difficult to learn, and with some practice on various loop patterns, you will be able to make optimization decisions quickly, saving time in the analysis process.\n\nSteps to analyze the time complexity of the loop\n• Counting the total loop iteration in the worst case: We can get this insight by considering the worst-case scenario, initial and final value of the loop variable, loop condition, and increment or decrement operation. Most of the time, loop will be running for each data element or total input size.\n• Calculating the time complexity of the code in the loop body: The loop executes this code on each iteration. This code may contain conditional statements, comparison operations, swapping operations, assignment operations, etc.\n• The time complexity of loop = (Count of loop iterations in the worst case) * (Time complexity of the code in the loop body). We represent this in the form of Big-O notation by ignoring lower-order terms and coefficients.\n\nSometimes, we can also follow another simple approach:\n• Identify the most critical operation inside the loop, which executes the maximum number of times in the worst case. This critical operation would be the dominating factor in the time complexity function.\n• Now calculate the total count of this operation for the complete loop in terms of input size. Representing this expression in terms of Big-O notation will give the time complexity of the loop.\n\nLet’s analyze the time complexity of the various loop pattern.\n\nTime complexity analysis of a single for and while loop\n\nSingle for and while loop running constant times: O(1)\n\nHere loop is running constant times and performing O(1) operation at each iteration of the loop. Time complexity = c * O(1) = O(1) * O(1) = O(1).\n\nBest examples of such loops: Accessing an element in an array, Finding minimum value in the min-heap, Searching elements in the hash table [O(1) average], Finding median in a sorted array, swapping two variables, etc.\n\nSingle for loop running n times and incrementing or decrementing by a constant: O(n)\n\nHere both loops are running n times and performing O(1) operation at each iteration of the loop. Time complexity = n * O(1) = O(n) * O(1) = O(n).\n\nFor better understanding, You can explore the analysis of these coding problems\n\nSingle for and while loop running constant multiple of n times: O(n)\n\nHere loop is running cn times and performing O(1) operation at each iteration of the loop. Time complexity = cn * O(1) = O(n) * O(1) = O(n).\n\nTwo pointers single for and while loop: O(n)\n\nIn the above loop, based on some conditions, we are either incrementing l or decrementing r by one and performing an O(1) operation at each step of the iteration. Loop will run n times because l and r are starting from opposite ends and end when l > r. So time complexity = n*O(1) = O(n).\n\nFor better understanding, You can explore the analysis of two pointers solution to these coding problems\n• Check two arrays are subset or not\n\nA single for and while loop incrementing or decrementing by a constant factor: O(logn)\n\nHere loop is running in the range of 1 to n, and the loop variable increases or decreases by a factor of 2 at each step. So we need to count the total number of iterations performed by the loop to calculate the time complexity.\n\nLet’s assume the loop will terminate after k steps where the loop variable increases or decreases by a factor of 2. Then 2^k must be equal to the n i.e. 2^k = n and k = logn = O(logn).\n\nSo the loop will run O(logn) number of times and do O(1) operation at each step. Time complexity = k * O(1) = O(logn)* O(1) = O(logn).\n\nBest examples of such loop patterns: Iterative binary search, iterative approach to find the nth power of a number, exponential search, iterative approach to find the nth power of a matrix, etc.\n\nSingle for and while loop incrementing by some constant power: O(log(logn))\n\nHere, the loop is running in the range of 1 to n, but the loop variable increases by factor i power constant c. So, how do we calculate the total number of loop steps? Let’s think!\n• The first iteration of the loop is starting with i = 2.\n• At second iteration, value of i = 2^c.\n• At third iteration, value of i = (2^c)^c = 2^(c²).\n• And it will go so on till the end. At any ith iteration the value of i = 2^(c^i).\n\nSo loop will run logc(log(n)) number of times, where each iteration is taking O(1) time. So the overall time complexity = O(log(log(n))) * O(1) = O(log(log(n))).\n\nFor calculating such consecutive loops, we need to do the sum of the time complexities of each loop. So overall time complexity = Time complexity of loop 1 + Time complexity of loop 2 = O(m) + O(n) = O(m + n).\n\nFor better understanding, You can explore the analysis of these coding problems.\n• Product of array except self\n\nTime complexity analysis of the nested for and while loops\n\nThe time complexity of nested loops is equal to the number of times the innermost statement is executed.\n\nTwo nested for and while loops: O(n²)\n\nIn the above nested-loop example, the inner loop is running n times for every iteration of the outer loop. So total number of nested loop iteration = Total number of iteration of outer loop * Total number of iteration of inner loop = n * n = n² = O(n²).\n\nAt each step of the iteration, the nested loop is doing an O(1) operation. So overall time complexity = O(n²) * O(1) = O(n²).\n\nIn the above nested loop example, outer loop is running n times and for every iteration of the outer loop, inner loop is running (n — i) times. So total number of nested loop iteration = (n — 1) + (n — 2) + (n — 3)…..+ 2 + 1 = Sum of arithmatic series from i = 0 to n — 1 = n(n — 1)/2 = n²/2 — n/2 = O(n²).\n\nAt each step of the iteration, the nested loop is doing an O(1) operation. So overall time complexity = O(n²) * O(1) = O(n²).\n\nNote: It’s an exercise for you to analyze the following loop.\n\nFor better understanding, You can explore the analysis of iterative solution of these coding problems.\n\nWe need to do the sum of the time complexities of each loop. In such a case, the time complexity is dominated by the time complexity of the nested loop.\n\nTime complexity = Time complexity of loop 1 + Time complexity of loop 2 + Time complexity of loop 3 = O(n) + O(mn) + O(n) = O(mn).\n\nThree nested for and while loops: O(n³)\n\nAll three nested loops are running n times and doing O(1) operation at each iteration, so time complexity = n * n * n*O(1) = n³ * O(1) = O(n³)*O(1) = O(n³).\n\nIn the above three nested loop situations, the outer loop runs n — 1 time, but two inner loops run n — i and j — i + 1 time. So what would be the total count of the nested loop iterations? Let’s think.\n\nNow we solve this tripple summation by expanding the summation one by one.\n\nHigher-order term in T(n) is n³, then T(n) = O(n³). We are ignoring lower-order terms and coefficients. Note: There is one error in the third line of the above image. Instead of + i(n — i), it would be — i (n — i).\n\nExplore these coding problems to learn more about the time complexity analysis of for and while loops\n• Count the number of possible triangles\n• Check whether two strings are anagram or not\n• Check if two arrays are equal or not\n\nFor more content, you can explore our free DSA course and coding interview blogs.\n\nIf you have any queries/doubts/feedback, please write us at contact@enjoyalgorithms.com. Enjoy learning, Enjoy algorithms!"
    },
    {
        "link": "https://geeksforgeeks.org/understanding-time-complexity-simple-examples",
        "document": "A lot of students get confused while understanding the concept of time complexity, but in this article, we will explain it with a very simple example.\n\nQ. Imagine a classroom of 100 students in which you gave your pen to one person. You have to find that pen without knowing to whom you gave it.\n\nHere are some ways to find the pen and what the O order is.\n• O(n2): You go and ask the first person in the class if he has the pen. Also, you ask this person about the other 99 people in the classroom if they have that pen and so on, \n\n This is what we call O(n\n• O(n): Going and asking each student individually is O(N).\n• O(log n): Now I divide the class into two groups, then ask: “Is it on the left side, or the right side of the classroom?” Then I take that group and divide it into two and ask again, and so on. Repeat the process till you are left with one student who has your pen. This is what you mean by O(log n).\n\nI might need to do:\n• O(n2) only one student knows on which student the pen is hidden\n• O(n) one student had the pen and only they knew it\n• O(log n) all the students knew , but would only tell me if I guessed the right side.\n\nNOTE: We are interested in the rate of growth over time with respect to the inputs taken during the program execution.\n\nIs the Time Complexity of an Algorithm/Code the same as the Running/Execution Time of Code?\n\nThe Time Complexity of an algorithm/code is not equal to the actual time required to execute a particular code, but the number of times a statement executes. We can prove this by using the time command.\n\nFor example: Write code in C/C++ or any other language to find the maximum between N numbers, where N varies from 10, 100, 1000, and 10000. For Linux based operating system (Fedora or Ubuntu), use the below commands:\n\nYou will get surprising results i.e.:\n• None For N = 10: you may get 0.5 ms time,\n• None For N = 10,000: you may get 0.2 ms time.\n• None Also, you will get different timings on different machines. Even if you will not get the same timings on the same machine for the same code, the reason behind that is the current network load.\n\nSo, we can say that the actual time required to execute code is machine-dependent (whether you are using Pentium 1 or Pentium 5) and also it considers network load if your machine is in LAN/WAN.\n\nWhat is meant by the Time Complexity of an Algorithm?\n\nNow, the question arises if time complexity is not the actual time required to execute the code, then what is it?\n\nExample 1: Consider the below simple code to print Hello World\n\nTime Complexity: In the above code “Hello World” is printed only once on the screen. \n\nSo, the time complexity is constant: O(1) i.e. every time a constant amount of time is required to execute code, no matter which operating system or which machine configurations you are using. \n\nAuxiliary Space: O(1)\n\nTime Complexity: In the above code “Hello World !!!” is printed only n times on the screen, as the value of n can change. \n\nSo, the time complexity is linear: O(n) i.e. every time, a linear amount of time is required to execute code.\n\nAuxiliary Space: O(1)\n\nHow To Find The Time Complexity Of An Algorithm?\n\nNow let us see some other examples and the process to find the time complexity of an algorithm:\n\nExample: Let us consider a model machine that has the following specifications:\n\nQ1. Find the Sum of 2 numbers on the above machine:\n\nFor any machine, the pseudocode to add two numbers will be something like this:\n• None The above code will take 2 units of time(constant):\n• None one for arithmetic operations and\n• None one for return. (as per the above conventions).\n\nQ2. Find the sum of all elements of a list/array\n\nThe pseudocode to do so can be given as:\n\n\n\nTo understand the time complexity of the above code, let’s see how much time each statement will take:\n\nTherefore the total cost to perform sum operation\n\nTherefore, the time complexity of the above code is O(n)\n\nQ3. Find the sum of all elements of a matrix\n\nFor this one, the complexity is a polynomial equation (quadratic equation for a square matrix)\n• None Since Tsum is in order of n Time Complexity = O(n2)\n\nTime Complexity: O(n*m)\n\nThe program iterates through all the elements in the 2D array using two nested loops. The outer loop iterates n times and the inner loop iterates m times for each iteration of the outer loop. Therefore, the time complexity of the program is O(n*m).\n\nAuxiliary Space: O(n*m)\n\nThe program uses a fixed amount of auxiliary space to store the 2D array and a few integer variables. The space required for the 2D array is nm integers. The program also uses a single integer variable to store the sum of the elements. Therefore, the auxiliary space complexity of the program is O(nm + 1), which simplifies to O(n*m).\n\nIn conclusion, the time complexity of the program is O(nm), and the auxiliary space complexity is also O(nm).\n\nTo compare algorithms, let us define a few objective measures:\n• Execution times: Not a good measure as execution times are specific to a particular computer.\n• The number of statements executed: Not a good measure, since the number of statements varies with the programming language as well as the style of the individual programmer.\n• Ideal solution: Let us assume that we express the running time of a given algorithm as a function of the input size n (i.e., f(n)) and compare these different functions corresponding to running times. This kind of comparison is independent of machine time, programming style, etc. \n\n Therefore, an ideal solution can be used to compare algorithms.\n• None Analysis of Algorithms | Set 2 (Worst, Average and Best Cases)"
    },
    {
        "link": "https://stackoverflow.com/questions/79047040/complexity-analysis-for-computing-the-square-of-a-graph",
        "document": "My friend and I were trying to do a CLRS problem but we're confused about the answer, more specifically the time complexity of the best algorithm:\n\nThe 2-path of a directed graph G = (V, E) is the graph G^2 = (V, E^2) that provides an edge between nodes (u, v) if and only if the original graph G contains a path with at most two edges between u and v. Propose an efficient algorithm for computing G^2 from G given an Adjacency List.\n\nThe algorithm was a simple brute force algorithm (I can't think of anything else, simply adding the edges will take these many steps at least). Iterate over all nodes, and all their edges and for each neighbor add all of their neighbors to the adjacency list of the node in question. Repeat for all nodes.\n\nI know that the runtime is T = V + E + sum of (in degrees * out degrees) across all vectors. I just don't know how to characterize the complexity of the last term. I know this is right because each node n's neighbors are visited when considering the direct neighbors of n and when node n itself is being considered as an immediate neighbor (which can be measured by the in degree) and all of the out degree nodes will be added to the corresponding adjacency list each time. So the runtime is (in degree + 1) * out degree summed over all nodes. This can be simplified as follows:\n\nIs there anyway to simplify the last term?\n\nUnable to quantify it, I took a different approach and got O(VE + V) ~ O(VE) which involved adding an node to the adjacency list of the transpose of the source node. ChatGPT is insistent on it being O(V+E) but refuses to highlight why."
    },
    {
        "link": "https://math.stackexchange.com/questions/3161736/time-complexity-for-computing-sum-of-first-n-squares",
        "document": "Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers."
    },
    {
        "link": "https://algocademy.com/link?problem=sum-of-squares&lang=py&solution=1",
        "document": "Best Time To Buy Stock in Python\n\nBest Time To Buy Stock in Python\n\nBest Time To Buy Stock in Python\n\nBest Time To Buy Stock in Python\n\nBest Time To Buy Stock in Python\n\nBest Time To Buy Stock in Python\n\nBinary Strings With At Most K Consecutive Ones in Python\n\nBinary Strings With At Most K Consecutive Ones in Python\n\nBinary Strings With K Ones On Even Positions in Python\n\nBinary Strings With K Ones On Even Positions in Python\n\nBinary Strings With K Ones in Python\n\nBinary Strings With K Ones in Python\n\nBinary Strings Without Consecutive Ones in Python\n\nBinary Strings Without Consecutive Ones in Python\n\nPermutations Of Given Length in Python\n\nPermutations Of Given Length in Python\n\nBinary Strings Of Given Length in Python\n\nBinary Strings Of Given Length in Python\n\nSubarray Of Given Sum Ii in Python\n\nSubarray Of Given Sum Ii in Python\n\nLongest Subarray With At Most K Distinct Integers in Python\n\nLongest Subarray With At Most K Distinct Integers in Python\n\nLongest Subarray With Sum At Most S in Python\n\nLongest Subarray With Sum At Most S in Python\n\nIntersection Of Two Linked Lists in Python\n\nIntersection Of Two Linked Lists in Python\n\nRemove Nth Node From End Of List in Python\n\nRemove Nth Node From End Of List in Python\n\nGenerate Binary Strings With K Ones in Python\n\nGenerate Binary Strings With K Ones in Python\n\nLongest Subarray With At Most K Distinct Integers in Python\n\nLongest Subarray With At Most K Distinct Integers in Python\n\nContainer With Most Water in Python\n\nContainer With Most Water in Python\n\nMax Sum Of Three Subarrays in Python\n\nMax Sum Of Three Subarrays in Python\n\nMax Sum Of Three Subarrays in Python\n\nMax Sum Of Three Subarrays in Python\n\nMax Sum Of Three Subarrays in Python\n\nMax Sum Of Three Subarrays in Python\n\nSubarray Of Given Sum in Python\n\nSubarray Of Given Sum in Python\n\nLongest Subarray With Sum At Most S in Python\n\nLongest Subarray With Sum At Most S in Python\n\nMax Sum Of Three Subarrays in Python\n\nMax Sum Of Three Subarrays in Python\n\nMax Val And Number Of Occurrences in Python\n\nMax Val And Number Of Occurrences in Python\n\nLongest Common Prefix Of Two Strings in Python\n\nLongest Common Prefix Of Two Strings in Python\n\nContinue In For Loops in Python\n\nContinue In For Loops in Python\n\nBreak In For Loops in Python\n\nBreak In For Loops in Python\n\nLooping Through Arrays With Indices in Python\n\nLooping Through Arrays With Indices in Python\n\nThe For Loop in Python\n\nThe For Loop in Python\n\nThe While Loop in Python\n\nThe While Loop in Python\n\nWhy For Loops in Python\n\nWhy For Loops in Python\n\nSecond Largest Value in Python\n\nSecond Largest Value in Python\n\nMinimum Value Of Three in Python\n\nMinimum Value Of Three in Python\n\nAllow To Contest in Python\n\nAllow To Contest in Python\n\nReducing If Else To Boolean Expression in Python\n\nReducing If Else To Boolean Expression in Python\n\nIf Else in Python\n\nIf Else in Python\n\nLast Two Digit Sum in Python\n\nLast Two Digit Sum in Python\n\nYour First Challenge in Python\n\nYour First Challenge in Python\n\nBuggy Code Return Instead Of Print in Python\n\nBuggy Code Return Instead Of Print in Python\n\nQuiz Return Instead Of Print in Python\n\nQuiz Return Instead Of Print in Python\n\nBuggy Code Print Instead Of Return in Python\n\nBuggy Code Print Instead Of Return in Python\n\nQuiz Print Instead Of Return in Python\n\nQuiz Print Instead Of Return in Python\n\nWhy Parameters And Arguments in Python\n\nWhy Parameters And Arguments in Python\n\nConvert Hours And Mins Into Seconds in Python\n\nConvert Hours And Mins Into Seconds in Python\n\nThe Power Of Variables in Python\n\nThe Power Of Variables in Python\n\nSum of Squares in Python (Time Complexity: O(n))\n\nGiven a non-negative integer n, compute and return the sum of\n\n 12 + 22 + 32 + ... + n2\n\nThe core challenge of this problem is to compute the sum of squares of the first natural numbers. This problem is significant in various mathematical and computational applications, such as in statistical formulas and algorithm analysis.\n\nPotential pitfalls include misunderstanding the range of numbers to sum (from 1 to ) and ensuring the correct calculation of squares.\n\nTo solve this problem, we can use a simple iterative approach:\n• Iterate through numbers from 1 to .\n• For each number , add to .\n• Return the value of .\n\nThis approach is straightforward and easy to understand. However, it is not the most optimized in terms of mathematical elegance.\n\nHere is a step-by-step breakdown of the algorithm:\n• Use a loop to iterate from 1 to .\n• In each iteration, compute the square of the current number and add it to .\n• After the loop ends, return the value of .\n\nThe time complexity of this approach is because we iterate through the numbers from 1 to once. The space complexity is as we only use a constant amount of extra space for the variable.\n• : The sum should be 0.\n\nTo test the solution comprehensively, consider a variety of test cases:\n• Break down the problem into smaller, manageable parts.\n• Consider both naive and optimized solutions.\n• Think about edge cases and how to handle them.\n\nUnderstanding and solving the sum of squares problem helps in grasping basic iteration and summation concepts. It is a fundamental problem that appears in various mathematical and computational contexts. Practice and exploration of similar problems can further enhance problem-solving abilities.\n\nFor further reading and practice:"
    },
    {
        "link": "https://stackoverflow.com/questions/57608846/time-complexity-of-minimum-number-of-squares-whose-sum-equals-to-given-number-n",
        "document": "What is the exact time complexity of this code ?\n\nI know its exponential but what kind of exponential like 2^n , sqrt(n) ^ sqrt(n) etc.\n\nIf attach some proof, that would be great.\n\nIn my opinion, since each for loop is calling the same recursion for sqrt(n) number of time and each call is for (n - x*x)) ~ n...\n\nSo it should be n ^ sqrt(n)."
    }
]