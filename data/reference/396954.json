[
    {
        "link": "https://numpy.org/doc/2.2",
        "document": "NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\n\nNew to NumPy? Check out the Absolute Beginner’s Guide. It contains an introduction to NumPy’s main concepts and links to additional tutorials. The user guide provides in-depth information on the key concepts of NumPy with useful background information and explanation. The reference guide contains a detailed description of the functions, modules, and objects included in NumPy. The reference describes how the methods work and which parameters can be used. It assumes that you have an understanding of the key concepts. Want to add to the codebase? Can help add translation or a flowchart to the documentation? The contributing guidelines will guide you through the process of improving NumPy."
    },
    {
        "link": "https://numpy.org/doc",
        "document": ""
    },
    {
        "link": "https://wiki.python.org/moin/NumPy",
        "document": ""
    },
    {
        "link": "https://w3schools.com/python/numpy/numpy_intro.asp",
        "document": "NumPy is a Python library used for working with arrays.\n\nIt also has functions for working in domain of linear algebra, fourier transform, and matrices.\n\nNumPy was created in 2005 by Travis Oliphant. It is an open source project and you can use it freely.\n\nIn Python we have lists that serve the purpose of arrays, but they are slow to process.\n\nNumPy aims to provide an array object that is up to 50x faster than traditional Python lists.\n\nThe array object in NumPy is called , it provides a lot of supporting functions that make working with very easy.\n\nArrays are very frequently used in data science, where speed and resources are very important.\n\nData Science: is a branch of computer science where we study how to store, use and analyze data for deriving information from it.\n\nWhy is NumPy Faster Than Lists?\n\nNumPy arrays are stored at one continuous place in memory unlike lists, so processes can access and manipulate them very efficiently.\n\nThis behavior is called locality of reference in computer science.\n\nThis is the main reason why NumPy is faster than lists. Also it is optimized to work with latest CPU architectures.\n\nWhich Language is NumPy written in?\n\nNumPy is a Python library and is written partially in Python, but most of the parts that require fast computation are written in C or C++.\n\nWhere is the NumPy Codebase?\n\nThe source code for NumPy is located at this github repository https://github.com/numpy/numpy\n\ngithub: enables many people to work on the same codebase."
    },
    {
        "link": "https://docs.python.org/3/library/math.html",
        "document": "This module provides access to the mathematical functions defined by the C standard.\n\nThese functions cannot be used with complex numbers; use the functions of the same name from the module if you require support for complex numbers. The distinction between functions which support complex numbers and those which don’t is made since most users do not want to learn quite as much mathematics as required to understand complex numbers. Receiving an exception instead of a complex result allows earlier detection of the unexpected complex number used as a parameter, so that the programmer can determine how and why it was generated in the first place.\n\nThe following functions are provided by this module. Except when explicitly noted otherwise, all return values are floats.\n\nReturn the number of ways to choose k items from n items without repetition and without order. Evaluates to when and evaluates to zero when . Also called the binomial coefficient because it is equivalent to the coefficient of k-th term in polynomial expansion of . Raises if either of the arguments are not integers. Raises if either of the arguments are negative. Return n factorial as an integer. Raises if n is not integral or is negative. Changed in version 3.10: Floats with integral values (like ) are no longer accepted. Return the greatest common divisor of the specified integer arguments. If any of the arguments is nonzero, then the returned value is the largest positive integer that is a divisor of all arguments. If all arguments are zero, then the returned value is . without arguments returns . Changed in version 3.9: Added support for an arbitrary number of arguments. Formerly, only two arguments were supported. Return the integer square root of the nonnegative integer n. This is the floor of the exact square root of n, or equivalently the greatest integer a such that a² ≤ n. For some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using . Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is . without arguments returns . Return the number of ways to choose k items from n items without repetition and with order. Evaluates to when and evaluates to zero when . If k is not specified or is , then k defaults to n and the function returns . Raises if either of the arguments are not integers. Raises if either of the arguments are negative.\n\nReturn the ceiling of x, the smallest integer greater than or equal to x. If x is not a float, delegates to , which should return an value. Return the absolute value of x. Return the floor of x, the largest integer less than or equal to x. If x is not a float, delegates to , which should return an value. Fused multiply-add operation. Return , computed as though with infinite precision and range followed by a single round to the format. This operation often provides better accuracy than the direct expression . This function follows the specification of the fusedMultiplyAdd operation described in the IEEE 754 standard. The standard leaves one case implementation-defined, namely the result of and . In these cases, returns a NaN, and does not raise any exception. Return the floating-point remainder of , as defined by the platform C library function . Note that the Python expression may not return the same result. The intent of the C standard is that be exactly (mathematically; to infinite precision) equal to for some integer n such that the result has the same sign as x and magnitude less than . Python’s returns a result with the sign of y instead, and may not be exactly computable for float arguments. For example, is , but the result of Python’s is , which cannot be represented exactly as a float, and rounds to the surprising . For this reason, function is generally preferred when working with floats, while Python’s is preferred when working with integers. Return the fractional and integer parts of x. Both results carry the sign of x and are floats. Note that has a different call/return pattern than its C equivalents: it takes a single argument and return a pair of values, rather than returning its second return value through an ‘output parameter’ (there is no such thing in Python). Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference , where is the closest integer to the exact value of the quotient . If is exactly halfway between two consecutive integers, the nearest even integer is used for . The remainder thus always satisfies . Special cases follow IEEE 754: in particular, is x for any finite x, and and raise for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating point, the result of this operation is always exactly representable: no rounding error is introduced. Return x with the fractional part removed, leaving the integer part. This rounds toward 0: is equivalent to for positive x, and equivalent to for negative x. If x is not a float, delegates to , which should return an value. For the , , and functions, note that all floating-point numbers of sufficiently large magnitude are exact integers. Python floats typically carry no more than 53 bits of precision (the same as the platform C double type), in which case any float x with necessarily has no fractional bits.\n\nReturn a float with the magnitude (absolute value) of x but the sign of y. On platforms that support signed zeros, returns -1.0. Return the mantissa and exponent of x as the pair . m is a float and e is an integer such that exactly. If x is zero, returns , otherwise . This is used to “pick apart” the internal representation of a float in a portable way. Note that has a different call/return pattern than its C equivalents: it takes a single argument and return a pair of values, rather than returning its second return value through an ‘output parameter’ (there is no such thing in Python). Return if the values a and b are close to each other and otherwise. Whether or not two values are considered close is determined according to given absolute and relative tolerances. If no errors occur, the result will be: . rel_tol is the relative tolerance – it is the maximum allowed difference between a and b, relative to the larger absolute value of a or b. For example, to set a tolerance of 5%, pass . The default tolerance is , which assures that the two values are the same within about 9 decimal digits. rel_tol must be nonnegative and less than . abs_tol is the absolute tolerance; it defaults to and it must be nonnegative. When comparing to , is computed as , which is for any nonzero and rel_tol less than . So add an appropriate positive abs_tol argument to the call. The IEEE 754 special values of , , and will be handled according to IEEE rules. Specifically, is not considered close to any other value, including . and are only considered close to themselves. Return if x is neither an infinity nor a NaN, and otherwise. (Note that is considered finite.) Return if x is a positive or negative infinity, and otherwise. Return if x is a NaN (not a number), and otherwise. Return . This is essentially the inverse of function . Return the floating-point value steps steps after x towards y. If x is equal to y, return y, unless steps is zero.\n• None goes up: towards positive infinity.\n• None goes down: towards minus infinity.\n• None goes towards zero.\n• None goes away from zero. Return the value of the least significant bit of the float x:\n• None If x is a NaN (not a number), return x.\n• None If x is equal to zero, return the smallest positive denormalized representable float (smaller than the minimum positive normalized float, ).\n• None If x is equal to the largest positive representable float, return the value of the least significant bit of x, such that the first float smaller than x is .\n• None Otherwise (x is a positive finite number), return the value of the least significant bit of x, such that the first float bigger than x is . ULP stands for “Unit in the Last Place”. See also and .\n\nReturn e raised to the power x, where e = 2.718281… is the base of natural logarithms. This is usually more accurate than or . Return e raised to the power x, minus 1. Here e is the base of natural logarithms. For small floats x, the subtraction in can result in a significant loss of precision; the function provides a way to compute this quantity to full precision: With one argument, return the natural logarithm of x (to base e). With two arguments, return the logarithm of x to the given base, calculated as . Return the natural logarithm of 1+x (base e). The result is calculated in a way which is accurate for x near zero. Return the base-2 logarithm of x. This is usually more accurate than . returns the number of bits necessary to represent an integer in binary, excluding the sign and leading zeros. Return the base-10 logarithm of x. This is usually more accurate than . Return x raised to the power y. Exceptional cases follow the IEEE 754 standard as far as possible. In particular, and always return , even when x is a zero or a NaN. If both x and y are finite, x is negative, and y is not an integer then is undefined, and raises . Unlike the built-in operator, converts both its arguments to type . Use or the built-in function for computing exact integer powers. Changed in version 3.11: The special cases and were changed to return instead of raising , for consistency with IEEE 754.\n\nReturn the Euclidean distance between two points p and q, each given as a sequence (or iterable) of coordinates. The two points must have the same dimension. Return an accurate floating-point sum of values in the iterable. Avoids loss of precision by tracking multiple intermediate partial sums. The algorithm’s accuracy depends on IEEE-754 arithmetic guarantees and the typical case where the rounding mode is half-even. On some non-Windows builds, the underlying C library uses extended precision addition and may occasionally double-round an intermediate sum causing it to be off in its least significant bit. For further discussion and two alternative approaches, see the ASPN cookbook recipes for accurate floating-point summation. Return the Euclidean norm, . This is the length of the vector from the origin to the point given by the coordinates. For a two dimensional point , this is equivalent to computing the hypotenuse of a right triangle using the Pythagorean theorem, . Changed in version 3.8: Added support for n-dimensional points. Formerly, only the two dimensional case was supported. Changed in version 3.10: Improved the algorithm’s accuracy so that the maximum error is under 1 ulp (unit in the last place). More typically, the result is almost always correctly rounded to within 1/2 ulp. Calculate the product of all the elements in the input iterable. The default start value for the product is . When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. Return the sum of products of values from two iterables p and q. Raises if the inputs do not have the same length. For float and mixed int/float inputs, the intermediate products and sums are computed with extended precision.\n\nThe mathematical constant π = 3.141592…, to available precision. The mathematical constant e = 2.718281…, to available precision. The mathematical constant τ = 6.283185…, to available precision. Tau is a circle constant equal to 2π, the ratio of a circle’s circumference to its radius. To learn more about Tau, check out Vi Hart’s video Pi is (still) Wrong, and start celebrating Tau day by eating twice as much pie! A floating-point positive infinity. (For negative infinity, use .) Equivalent to the output of . A floating-point “not a number” (NaN) value. Equivalent to the output of . Due to the requirements of the IEEE-754 standard, and are not considered to equal to any other numeric value, including themselves. To check whether a number is a NaN, use the function to test for NaNs instead of or . Example: Changed in version 3.11: It is now always available. CPython implementation detail: The module consists mostly of thin wrappers around the platform C math library functions. Behavior in exceptional cases follows Annex F of the C99 standard where appropriate. The current implementation will raise for invalid operations like or (where C99 Annex F recommends signaling invalid operation or divide-by-zero), and for results that overflow (for example, ). A NaN will not be returned from any of the functions above unless one or more of the input arguments was a NaN; in that case, most functions will return a NaN, but (again following C99 Annex F) there are some exceptions to this rule, for example or . Note that Python makes no effort to distinguish signaling NaNs from quiet NaNs, and behavior for signaling NaNs remains unspecified. Typical behavior is to treat all NaNs as though they were quiet. Complex number versions of many of these functions."
    },
    {
        "link": "https://medium.com/@tommanzur/best-practices-in-scikit-learn-6b606b384ee1",
        "document": "Before feeding data into Scikit-learn models, use Pandas for data manipulation. Pandas’ DataFrame is ideal for handling and cleaning your dataset.\n\nFeature engineering is crucial for improving model performance. Create new features or transform existing ones to better capture underlying patterns.\n\nScaling your features is vital, especially for algorithms sensitive to feature scales, such as SVM or k-NN."
    },
    {
        "link": "https://medium.com/@sumit.kaul.87/a-comprehensive-guide-to-scikit-learn-machine-learning-in-python-with-code-examples-8e4670877d03",
        "document": "Scikit-learn is one of the most popular and powerful libraries for machine learning in Python. It provides a simple and efficient toolkit for data mining and data analysis, and it is built on top of NumPy, SciPy, and Matplotlib. Whether you’re a beginner or an experienced data scientist, Scikit-learn offers a wide range of algorithms and tools for tasks like classification, regression, clustering, and more. In this blog post, we will explore the key features of Scikit-learn, provide code examples for common machine learning tasks, and discuss best practices for using this powerful library.\n\n6. Best Practices for Using Scikit-Learn\n\nScikit-learn is an open-source library that provides simple and efficient tools for data analysis and modeling. It is widely used for machine learning tasks because of its robust, easy-to-use interface and its extensive collection of algorithms. Scikit-learn covers a wide range of machine learning techniques, including classification, regression, clustering, dimensionality reduction, model selection, and preprocessing.\n• Wide Range of Algorithms: Scikit-learn includes implementations of many popular machine learning algorithms, such as decision trees, support vector machines, k-nearest neighbors, and more.\n• Data Preprocessing: Tools for data preprocessing, including scaling, normalization, and encoding, are built into the library.\n• Model Selection and Evaluation: Scikit-learn provides tools for cross-validation, hyperparameter tuning, and evaluation metrics.\n• Extensibility: Scikit-learn is built on top of NumPy, SciPy, and Matplotlib, making it highly compatible with other Python data science libraries.\n\nBefore diving into code examples, you’ll need to set up Scikit-learn in your Python environment.\n\nData preprocessing is a crucial step in any machine learning pipeline. Scikit-learn provides a wide range of tools to help with this.\n\nScikit-learn makes it easy to build and evaluate machine learning models. Let’s go through some common examples.\n\n6. Best Practices for Using Scikit-Learn\n• Start with Simple Models: Begin with simple models like linear regression or logistic regression before moving to more complex ones.\n• Feature Engineering: Spend time on feature engineering and data preprocessing as they are crucial for model performance.\n• Cross-Validation: Use cross-validation techniques to ensure your model generalizes well to unseen data.\n• Hyperparameter Tuning: Use tools like or to find the best hyperparameters for your model.\n• Pipeline Integration: Use Scikit-learn’s to streamline the preprocessing and modeling steps.\n\nScikit-learn is a versatile and powerful library that simplifies the process of building and evaluating machine learning models. Its comprehensive set of tools, combined with its simplicity, makes it an indispensable tool for data scientists and machine learning engineers. By following the examples and best practices outlined in this post, you can start building robust machine learning models with Scikit-learn and enhance your data science projects.\n\nFeel free to reach out here if you have any questions or need further assistance with AI, Cloud, DevOps, Enterprise Architecture, MLOps"
    },
    {
        "link": "https://geeksforgeeks.org/learning-model-building-scikit-learn-python-machine-learning-library",
        "document": "Building machine learning models from scratch can be complex and time-consuming. However with the right tools and frameworks this process can become significantly easier. Scikit-learn is one such tool that makes machine learning model creation easy. It provides user-friendly tools for tasks like Classification, Regression, Clustering and many more.\n\nThe latest version of Scikit-learn is 1.1 and it requires Python 3.8 or newer.\n\nBefore installing scikit-learn, ensure that you have NumPy and SciPy installed. Once you have a working installation of NumPy and SciPy, the easiest way to install scikit-learn is using pip:\n\nLet us get started with the modeling process now.\n\nA dataset is nothing but a collection of data. A dataset generally has two main components:\n• Features : They are also known as predictors, inputs or attributes. These are simply the variables of our data. They can be more than one and hence represented by a feature matrix (‘x’ is a common notation to represent feature matrix). A list of all the feature names is termed feature names\n• Response : They are also known as the target, label or output. This is the output variable depending on the feature variables. We generally have a single output variable column and it is represented by a response vector ( ‘y’ is a common notation to represent response vector). All the possible values taken by a response vector are termed target names\n\n1. Loading exemplar dataset: Scikit-learn comes with few loaded example datasets like the iris and digits datasets for classification and the boston house prices dataset for regression.\n\nGiven below is an example of how we can load an exemplar dataset:\n• loads the Iris dataset into the variable\n• Features and Targets contains the input data (features like petal length, width, etc) and contains the target values (species of the iris flower).\n• Names provide the names of the features and the target labels respectively.\n• Inspecting Data : We print the feature names and target names check the type of and display the first 5 rows of the feature data to understand the structure.\n\n2. Loading external dataset: Now consider the case when we want to load an external dataset. For this we can use the pandas library for easily loading and manipulating datasets.\n\nFor this you can refer to our article on How to import csv file in pandas\n\nIn machine learning working with large datasets can be computationally expensive. For this we split the data into two parts: training data and testing data. This approach helps reduce computational cost and also helps to evaluate model’s performance and accuracy on unseen data.\n• None Split the dataset into two pieces: a training set and a testing set.\n• None Train the model on the training set.\n• None Test the model on the testing set and evaluate how well our model did.\n\n2. Import and Use to Split the Data\n\nIn this step we import from . This function splits the dataset into two parts: a training set and a testing set.\n• None : These are the features and target values used for training the model.\n• None : These are the features and target values used for testing the model after it has been trained.\n• None : 40% of the data is allocated to the testing set while the remaining 60% is used for training.\n• None : This ensures that the split is consistent, meaning you’ll get the same random split every time you run the code.\n\n3. Check the Shapes of the Split Data\n\nWhen splitting data into training and testing sets verifying the shape ensures that both sets have correct proportions of data avoiding any potential errors in model evaluation or training.\n• None The number of rows in should be 60% of the original dataset, and the number of rows in\n• None should have the same number of rows as should have the same number of rows as\n\nIt’s important to handle categorical data correctly because machine learning algorithms typically require numerical input to process the data. If categorical data is not encoded algorithms may misinterpret the categories leading to incorrect results. This is why we need to handle categorical data by encoding it. Scikit-learn provides several techniques for encoding categorical variables into numerical values.\n\n1. Label Encoding: It converts each category into a unique integer. For example in a column with categories like ‘cat’, ‘dog’, and ‘bird’, label encoding would convert them to 0, 1 and 2 respectively.\n• None is initialized to create an encoder object that will convert categorical values into numerical labels.\n• fits the encoder to the categorical datavand then transforms the categories into corresponding numeric labels.\n\nThis method is useful when the categorical values have an inherent order like “Low”, “Medium” and “High” but it can be problematic for unordered categories.\n\n2. OneHotEncoding: It creates binary columns for each category where each column represents a category. For example if you have a column with values ‘cat’ ‘dog’ and ‘bird’ OneHotEncoding will create three new columns (one for each category) where each row will have a 1 in the column corresponding to its category and 0s in the others.\n• None expects the input data to be in a 2D array i.e each sample should be a row, and each feature should be a column thats why we reshape\n• None creates an encoder object that will convert categorical variables into binary columns.\n• None method is used to fit the encoder to the categorical data and transform\n\nThis method is useful for categorical variables without any inherent order ensuring that no numeric relationships are implied between the categories.\n\nNow it’s time to train our models using our dataset. Scikit-learn provides a wide range of machine learning algorithms that have a unified/consistent interface for fitting, predicting accuracy, etc. The example given below uses Logistic Regression.\n• None The classifier is trained using the data and the corresponding response vector\n• None This is done by calling , where the logistic regression model adjusts its weights.\n• None Now, we need to test our classifier on the X_test data, log_reg.predict method is used for this purpose. It returns the predicted response vector y_pred\n• None Now, we are interested in finding the accuracy of our model by comparing y_test y_pred . This is done using the metrics module’s method accuracy_score\n• None Consider the case when you want your model to make predictions on new sample data . Then the sample input can simply be passed in the same way as we pass any feature matrix.\n• None Here we used it as sample = [[3, 5, 4, 2], [2, 3, 5, 4]]\n• Pre-built functions : It offers ready to use functions for common tasks like data preprocessing, model training and prediction eliminating the need to write algorithms from scratch.\n• Efficient model evaluation : It includes tools for model evaluation such as cross-validation and performance metrics making it easy to assess and improve model accuracy.\n• Variety of algorithms : It provides a wide range of algorithms for classification, regression, clustering and more like support vector machines, random forests and k-means.\n• Integration with scientific libraries : Built on top of NumPy, SciPy and matplotlib making it easy to integrate with other libraries for data analysis.\n• Consistent and simple interface : Scikit-learn provides a uniform API across different models making it easy to switch between algorithms without having to learn a new syntax.\n• Extensive model tuning options : It offers a wide range of tuning parameters and grid search tools to fine-tune models for better performance.\n• Active community and support : The library has a large, engaged community ensuring regular updates, bug fixes and a wealth of user-contributed resources like forums, blogs and Q&A sites.\n\nScikit-learn stands as one of the most important library in the field of machine learning providing a straightforward and powerful set of tools for building and deploying models. Whether you are a beginner or an experienced data scientist it is used by everyone for making machine learning models."
    },
    {
        "link": "https://digitalocean.com/community/tutorials/python-scikit-learn-tutorial",
        "document": "Scikit-learn is one of the most widely used Python libraries for machine learning. Whether you’re working on classification, regression, or clustering tasks, Scikit-learn provides simple and efficient tools to build and evaluate models.\n\nIt features several regression, classification, and clustering algorithms, including SVMs, gradient boosting, k-means, random forests, and DBSCAN. It is designed to work with Python Numpy and SciPy.\n\nWhat is Scikit-learn in Python?\n\nScikit Learn is written in Python (most of it), and some of its core algorithms are written in Cython for even better performance. Scikit-learn is used to build models and it is not recommended to use it for reading, manipulating and summarizing data as there are better frameworks available for the purpose. It is open source and released under BSD license.\n\nIt provides various tools for:\n\nScikit assumes you have a running Python 2.7 or above platform with NumPY (1.8.2 and above) and SciPY (0.13.3 and above) packages on your device. Once we have these packages installed we can proceed with the installation. For pip installation, run the following command in the terminal:\n\nIf you like , you can also use the conda for package installation, run the following command:\n\nOnce you are done with the installation, you can use scikit-learn easily in your Python code by importing it as:\n\nLet’s start with loading a dataset to play with. Let’s load a simple dataset named Iris. It is a dataset of a flower, it contains 150 observations about different measurements of the flower. Let’s see how to load the dataset using scikit-learn.\n\nWe are printing shape of data for ease, you can also print whole data if you wish so, running the codes gives an output like this:\n\nNow we have loaded data, let’s try learning from it and predict on new data. For this purpose we have to create an estimator and then call its fit method.\n\nHere is what we get when we run this script:\n\nCreating various models is rather simple using scikit-learn. Let’s start with a simple example of regression.\n\nRunning the model should return a point that can be plotted on the same line:\n\nLet’s try a simple classification algorithm. This classifier uses an algorithm based on ball trees to represent the training samples.\n\nLet’s run the classifier and check results, the classifier should return 0. Let’s try the example:\n\nThis is the simplest clustering algorithm. The set is divided into ‘k’ clusters and each observation is assigned to a cluster. This is done iteratively until the clusters converge. We will create one such clustering model in the following program:\n\nOn running the program we’ll see separate clusters in the list. Here is the output for above code snippet: .\n\nScikit-learn is ideal for traditional machine learning models, while TensorFlow and PyTorch excel in deep learning and large-scale AI applications.\n\nScikit-learn is a powerful library for machine learning, but it’s optimized for small to medium-sized datasets. When working with large datasets, you need to handle them efficiently. Here are some strategies:\n• Use : This method supports incremental learning for large datasets. It’s particularly useful when you can’t fit the entire dataset into memory at once.\n• Apply Feature Selection: Reducing the number of features in your dataset can significantly reduce memory usage and computation time.\n• Leverage for Parallel Processing: This library can be used to distribute tasks across multiple cores, which can greatly speed up your computations.\n\nHere’s an example of using :\n\n1. What is Scikit-learn used for?\n\nScikit-learn is used for traditional machine learning tasks such as classification, regression, clustering, and feature selection.\n\n2. How does Scikit-learn compare to TensorFlow and PyTorch?\n\nScikit-learn is better suited for small-scale, traditional machine learning tasks, while TensorFlow and PyTorch are designed for deep learning and large-scale computations.\n\nNo, Scikit-learn is not designed for deep learning. Instead, it integrates well with deep learning libraries when needed.\n\n5. How do I optimize model performance in Scikit-learn?\n\nOptimizing model performance is crucial to achieve the best results in machine learning. Here are some strategies to optimize model performance in Scikit-learn:\n\nHyperparameter Tuning: Use GridSearchCV to perform hyperparameter tuning. This involves searching for the best combination of hyperparameters that result in the best model performance.\n\nFeature Selection: Apply feature selection techniques to reduce the dimensionality of your dataset. This can help in reducing overfitting, improving model interpretability, and enhancing model performance.\n\nEnsemble Methods: Utilize ensemble methods like Random Forests and Gradient Boosting. These methods combine the predictions of multiple models to produce a more accurate and robust prediction model.\n\nIn this tutorial, you learned about the versatility of Scikit-Learn, which simplifies the implementation of various machine learning algorithms. We have delved into examples of Regression, Classification, and Clustering. Despite being in the development phase and maintained by volunteers, Scikit-Learn is widely popular in the community. We encourage you to experiment with your own examples.\n\nYou can also check out these tutorials:"
    },
    {
        "link": "https://scikit-learn.org/stable/common_pitfalls.html",
        "document": "The purpose of this chapter is to illustrate some common pitfalls and anti-patterns that occur when using scikit-learn. It provides examples of what not to do, along with a corresponding correct example.\n\nscikit-learn provides a library of Dataset transformations, which may clean (see Preprocessing data), reduce (see Unsupervised dimensionality reduction), expand (see Kernel Approximation) or generate (see Feature extraction) feature representations. If these data transforms are used when training a model, they also must be used on subsequent datasets, whether it’s test data or data in a production system. Otherwise, the feature space will change, and the model will not be able to perform effectively. For the following example, let’s create a synthetic dataset with a single feature: The train dataset is scaled, but not the test dataset, so model performance on the test dataset is worse than expected: Instead of passing the non-transformed to , we should transform the test data, the same way we transformed the training data: Alternatively, we recommend using a , which makes it easier to chain transformations with estimators, and reduces the possibility of forgetting a transformation: Pipelines also help avoiding another common pitfall: leaking the test data into the training data.\n\nData leakage occurs when information that would not be available at prediction time is used when building the model. This results in overly optimistic performance estimates, for example from cross-validation, and thus poorer performance when the model is used on actually novel data, for example during production. A common cause is not keeping the test and train data subsets separate. Test data should never be used to make choices about the model. The general rule is to never call on the test data. While this may sound obvious, this is easy to miss in some cases, for example when applying certain pre-processing steps. Although both train and test data subsets should receive the same preprocessing transformation (as described in the previous section), it is important that these transformations are only learnt from the training data. For example, if you have a normalization step where you divide by the average value, the average should be the average of the train subset, not the average of all the data. If the test subset is included in the average calculation, information from the test subset is influencing the model. Below are some tips on avoiding data leakage:\n• None Always split the data into train and test subsets first, particularly before any preprocessing steps.\n• None Never include test data when using the and methods. Using all the data, e.g., , can result in overly optimistic scores. Conversely, the method should be used on both train and test subsets as the same preprocessing should be applied to all the data. This can be achieved by using on the train subset and on the test subset.\n• None The scikit-learn pipeline is a great way to prevent data leakage as it ensures that the appropriate method is performed on the correct data subset. The pipeline is ideal for use in cross-validation and hyper-parameter tuning functions. An example of data leakage during preprocessing is detailed below. We here choose to illustrate data leakage with a feature selection step. This risk of leakage is however relevant with almost all transformations in scikit-learn, including (but not limited to) , , and . A number of Feature selection functions are available in scikit-learn. They can help remove irrelevant, redundant and noisy features as well as improve your model build time and performance. As with any other type of preprocessing, feature selection should only use the training data. Including the test data in feature selection will optimistically bias your model. To demonstrate we will create this binary classification problem with 10,000 randomly generated features: Using all the data to perform feature selection results in an accuracy score much higher than chance, even though our targets are completely random. This randomness means that our and are independent and we thus expect the accuracy to be around 0.5. However, since the feature selection step ‘sees’ the test data, the model has an unfair advantage. In the incorrect example below we first use all the data for feature selection and then split the data into training and test subsets for model fitting. The result is a much higher than expected accuracy score: To prevent data leakage, it is good practice to split your data into train and test subsets first. Feature selection can then be formed using just the train dataset. Notice that whenever we use or , we only use the train dataset. The score is now what we would expect for the data, close to chance: Here again, we recommend using a to chain together the feature selection and model estimators. The pipeline ensures that only the training data is used when performing and the test data is used only for calculating the accuracy score: The pipeline can also be fed into a cross-validation function such as . Again, the pipeline ensures that the correct data subset and estimator method is used during fitting and predicting:\n\nSome scikit-learn objects are inherently random. These are usually estimators (e.g. ) and cross-validation splitters (e.g. ). The randomness of these objects is controlled via their parameter, as described in the Glossary. This section expands on the glossary entry, and describes good practices and common pitfalls w.r.t. this subtle parameter. For an optimal robustness of cross-validation (CV) results, pass instances when creating estimators, or leave to . Passing integers to CV splitters is usually the safest option and is preferable; passing instances to splitters may sometimes be useful to achieve very specific use-cases. For both estimators and splitters, passing an integer vs passing an instance (or ) leads to subtle but significant differences, especially for CV procedures. These differences are important to understand when reporting results. For reproducible results across executions, remove any use of . Using or instances, and repeated calls to and # The parameter determines whether multiple calls to fit (for estimators) or to split (for CV splitters) will produce the same results, according to these rules:\n• None If an integer is passed, calling or multiple times always yields the same results.\n• None If or a instance is passed: and will yield different results each time they are called, and the succession of calls explores all sources of entropy. is the default value for all parameters. We here illustrate these rules for both estimators and CV splitters. Since passing is equivalent to passing the global instance from ( ), we will not explicitly mention here. Everything that applies to instances also applies to using . Passing instances means that calling multiple times will not yield the same results, even if the estimator is fitted on the same data and with the same hyper-parameters: We can see from the snippet above that repeatedly calling has produced different models, even if the data was the same. This is because the Random Number Generator (RNG) of the estimator is consumed (i.e. mutated) when is called, and this mutated RNG will be used in the subsequent calls to . In addition, the object is shared across all objects that use it, and as a consequence, these objects become somewhat inter-dependent. For example, two estimators that share the same instance will influence each other, as we will see later when we discuss cloning. This point is important to keep in mind when debugging. If we had passed an integer to the parameter of the , we would have obtained the same models, and thus the same scores each time. When we pass an integer, the same RNG is used across all calls to . What internally happens is that even though the RNG is consumed when is called, it is always reset to its original state at the beginning of . Randomized CV splitters have a similar behavior when a instance is passed; calling multiple times yields different data splits: We can see that the splits are different from the second time is called. This may lead to unexpected results if you compare the performance of multiple estimators by calling many times, as we will see in the next section. While the rules that govern the parameter are seemingly simple, they do however have some subtle implications. In some cases, this can even lead to wrong conclusions. Different `random_state` types lead to different cross-validation procedures Depending on the type of the parameter, estimators will behave differently, especially in cross-validation procedures. Consider the following snippet: We see that the cross-validated scores of and are different, as should be expected since we didn’t pass the same parameter. However, the difference between these scores is more subtle than it looks, and the cross-validation procedures that were performed by significantly differ in each case:\n• None Since was passed an integer, every call to uses the same RNG: this means that all random characteristics of the random forest estimator will be the same for each of the 5 folds of the CV procedure. In particular, the (randomly chosen) subset of features of the estimator will be the same across all folds.\n• None Since was passed a instance, each call to starts from a different RNG. As a result, the random subset of features will be different for each folds. While having a constant estimator RNG across folds isn’t inherently wrong, we usually want CV results that are robust w.r.t. the estimator’s randomness. As a result, passing an instance instead of an integer may be preferable, since it will allow the estimator RNG to vary for each fold. Here, will use a non-randomized CV splitter (as is the default), so both estimators will be evaluated on the same splits. This section is not about variability in the splits. Also, whether we pass an integer or an instance to isn’t relevant for our illustration purpose: what matters is what we pass to the estimator. Another subtle side effect of passing instances is how will work: Since a instance was passed to , and are not clones in the strict sense, but rather clones in the statistical sense: and will still be different models, even when calling on the same data. Moreover, and will influence each-other since they share the same internal RNG: calling will consume ’s RNG, and calling will consume ’s RNG, since they are the same. This bit is true for any estimators that share a parameter; it is not specific to clones. If an integer were passed, and would be exact clones and they would not influence each other. Even though is rarely used in user code, it is called pervasively throughout scikit-learn codebase: in particular, most meta-estimators that accept non-fitted estimators call internally ( , , , etc.). When passed a instance, CV splitters yield different splits each time is called. When comparing different estimators, this can lead to overestimating the variance of the difference in performance between the estimators: Directly comparing the performance of the estimator vs the estimator on each fold would be a mistake: the splits on which the estimators are evaluated are different. Indeed, will internally call on the same instance, but the splits will be different each time. This is also true for any tool that performs model selection via cross-validation, e.g. and : scores are not comparable fold-to-fold across different calls to , since would have been called multiple times. Within a single call to , however, fold-to-fold comparison is possible since the search estimator only calls once. For comparable fold-to-fold results in all scenarios, one should pass an integer to the CV splitter: . While fold-to-fold comparison is not advisable with instances, one can however expect that average scores allow to conclude whether one estimator is better than another, as long as enough folds and data are used. What matters in this example is what was passed to . Whether we pass a instance or an integer to is not relevant for our illustration purpose. Also, neither nor are randomized estimators. In order to obtain reproducible (i.e. constant) results across multiple program executions, we need to remove all uses of , which is the default. The recommended way is to declare a variable at the top of the program, and pass it down to any object that accepts a parameter: We are now guaranteed that the result of this script will always be 0.84, no matter how many times we run it. Changing the global variable to a different value should affect the results, as expected. It is also possible to declare the variable as an integer. This may however lead to less robust cross-validation results, as we will see in the next section. We do not recommend setting the global seed by calling . See here for a discussion. When we evaluate a randomized estimator performance by cross-validation, we want to make sure that the estimator can yield accurate predictions for new data, but we also want to make sure that the estimator is robust w.r.t. its random initialization. For example, we would like the random weights initialization of a to be consistently good across all folds: otherwise, when we train that estimator on new data, we might get unlucky and the random initialization may lead to bad performance. Similarly, we want a random forest to be robust w.r.t the set of randomly selected features that each tree will be using. For these reasons, it is preferable to evaluate the cross-validation performance by letting the estimator use a different RNG on each fold. This is done by passing a instance (or ) to the estimator initialization. When we pass an integer, the estimator will use the same RNG on each fold: if the estimator performs well (or bad), as evaluated by CV, it might just be because we got lucky (or unlucky) with that specific seed. Passing instances leads to more robust CV results, and makes the comparison between various algorithms fairer. It also helps limiting the temptation to treat the estimator’s RNG as a hyper-parameter that can be tuned. Whether we pass instances or integers to CV splitters has no impact on robustness, as long as is only called once. When is called multiple times, fold-to-fold comparison isn’t possible anymore. As a result, passing integer to CV splitters is usually safer and covers most use-cases."
    }
]