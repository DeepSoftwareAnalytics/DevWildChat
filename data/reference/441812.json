[
    {
        "link": "https://fastapi.tiangolo.com/tutorial/sql-databases",
        "document": "FastAPI doesn't require you to use a SQL (relational) database. But you can use any database that you want.\n\nHere we'll see an example using SQLModel.\n\nSQLModel is built on top of SQLAlchemy and Pydantic. It was made by the same author of FastAPI to be the perfect match for FastAPI applications that need to use SQL databases.\n\nAs SQLModel is based on SQLAlchemy, you can easily use any database supported by SQLAlchemy (which makes them also supported by SQLModel), like:\n\nIn this example, we'll use SQLite, because it uses a single file and Python has integrated support. So, you can copy this example and run it as is.\n\nLater, for your production application, you might want to use a database server like PostgreSQL.\n\nThis is a very simple and short tutorial, if you want to learn about databases in general, about SQL, or more advanced features, go to the SQLModel docs.\n\nFirst, make sure you create your virtual environment, activate it, and then install :\n\nWe'll create the simplest first version of the app with a single SQLModel model first.\n\nLater we'll improve it increasing security and versatility with multiple models below. 🤓\n\nThe class is very similar to a Pydantic model (in fact, underneath, it actually is a Pydantic model).\n\nThere are a few differences:\n• tells SQLModel that this is a table model, it should represent a table in the SQL database, it's not just a data model (as would be any other regular Pydantic class).\n• tells SQLModel that the is the primary key in the SQL database (you can learn more about SQL primary keys in the SQLModel docs). By having the type as , SQLModel will know that this column should be an in the SQL database and that it should be .\n• tells SQLModel that it should create a SQL index for this column, that would allow faster lookups in the database when reading data filtered by this column. SQLModel will know that something declared as will be a SQL column of type (or , depending on the database).\n\nA SQLModel (underneath it's actually a SQLAlchemy ) is what holds the connections to the database.\n\nYou would have one single object for all your code to connect to the same database.\n\nUsing allows FastAPI to use the same SQLite database in different threads. This is necessary as one single request could use more than one thread (for example in dependencies).\n\nDon't worry, with the way the code is structured, we'll make sure we use a single SQLModel session per request later, this is actually what the is trying to achieve.\n\nWe then add a function that uses to create the tables for all the table models.\n\nA is what stores the objects in memory and keeps track of any changes needed in the data, then it uses the to communicate with the database.\n\nWe will create a FastAPI dependency with that will provide a new for each request. This is what ensures that we use a single session per request. 🤓\n\nThen we create an dependency to simplify the rest of the code that will use this dependency.\n\nWe will create the database tables when the application starts.\n\nHere we create the tables on an application startup event.\n\nFor production you would probably use a migration script that runs before you start your app. 🤓\n\nBecause each SQLModel model is also a Pydantic model, you can use it in the same type annotations that you could use Pydantic models.\n\nFor example, if you declare a parameter of type , it will be read from the JSON body.\n\nThe same way, you can declare it as the function's return type, and then the shape of the data will show up in the automatic API docs UI.\n\nHere we use the dependency (a ) to add the new to the instance, commit the changes to the database, refresh the data in the , and then return it.\n\nWe can read s from the database using a . We can include a and to paginate the results.\n\nWe can also delete a .\n\nYou can run the app:\n\nThen go to the UI, you will see that FastAPI is using these models to document the API, and it will use them to serialize and validate the data too.\n\nNow let's refactor this app a bit to increase security and versatility.\n\nIf you check the previous app, in the UI you can see that, up to now, it lets the client decide the of the to create. 😱\n\nWe shouldn't let that happen, they could overwrite an we already have assigned in the DB. Deciding the should be done by the backend or the database, not by the client.\n\nAdditionally, we create a for the hero, but so far, we are returning it everywhere, that's not very secret... 😅\n\nWe'll fix these things by adding a few extra models. Here's where SQLModel will shine. ✨\n\nIn SQLModel, any model class that has is a table model.\n\nAnd any model class that doesn't have is a data model, these ones are actually just Pydantic models (with a couple of small extra features). 🤓\n\nWith SQLModel, we can use inheritance to avoid duplicating all the fields in all the cases.\n\nLet's start with a model that has all the fields that are shared by all the models:\n\nThen let's create , the actual table model, with the extra fields that are not always in the other models:\n\nBecause inherits form , it also has the fields declared in , so all the fields for are:\n\nNext, we create a model, this is the one that will be returned to the clients of the API.\n\nIt has the same fields as , so it won't include .\n\nFinally, the identity of our heroes is protected! 🥷\n\nIt also re-declares . By doing this, we are making a contract with the API clients, so that they can always expect the to be there and to be an (it will never be ).\n\nAll the fields in are the same as in , with declared as (not ):\n\nNow we create a model, this is the one that will validate the data from the clients.\n\nIt has the same fields as , and it also has .\n\nNow, when the clients create a new hero, they will send the , it will be stored in the database, but those secret names won't be returned in the API to the clients.\n\nThe fields of are:\n\nWe didn't have a way to update a hero in the previous version of the app, but now with multiple models, we can do it. 🎉\n\nThe data model is somewhat special, it has all the same fields that would be needed to create a new hero, but all the fields are optional (they all have a default value). This way, when you update a hero, you can send just the fields that you want to update.\n\nBecause all the fields actually change (the type now includes and they now have a default value of ), we need to re-declare them.\n\nWe don't really need to inherit from because we are re-declaring all the fields. I'll leave it inheriting just for consistency, but this is not necessary. It's more a matter of personal taste. 🤷\n\nThe fields of are:\n\nNow that we have multiple models, we can update the parts of the app that use them.\n\nWe receive in the request a data model, and from it, we create a table model.\n\nThis new table model will have the fields sent by the client, and will also have an generated by the database.\n\nThen we return the same table model as is from the function. But as we declare the with the data model, FastAPI will use to validate and serialize the data.\n\nWe can do the same as before to read s, again, we use to ensure that the data is validated and serialized correctly.\n\nWe can update a hero. For this we use an HTTP operation.\n\nAnd in the code, we get a with all the data sent by the client, only the data sent by the client, excluding any values that would be there just for being the default values. To do it we use . This is the main trick. 🪄\n\nThen we use to update the with the data from .\n\nDeleting a hero stays pretty much the same.\n\nWe won't satisfy the desire to refactor everything in this one. 😅\n\nYou can run the app again:\n\nIf you go to the API UI, you will see that it is now updated, and it won't expect to receive the from the client when creating a hero, etc.\n\nYou can use SQLModel to interact with a SQL database and simplify the code with data models and table models.\n\nYou can learn a lot more at the SQLModel docs, there's a longer mini tutorial on using SQLModel with FastAPI. 🚀"
    },
    {
        "link": "https://fastapi.tiangolo.com/fa/tutorial/sql-databases",
        "document": ""
    },
    {
        "link": "https://mattermost.com/blog/building-a-crud-fastapi-app-with-sqlalchemy",
        "document": "Learning how to build web apps with FastAPI — a modern Python web framework that allows you to build high-performance web apps — is worth your time. FastAPI is easy to learn, fast to code, and ready for production.\n\nIn this tutorial, you ‘ll learn how to build the backend of a basic app using FastAPI with a database set up with SQLAlchemy. The app will be a CRUD web app in which you’ll learn the basics of how to use API requests to do the common CRUD operations: create, read, update, and delete. You will build a todo app that’s easy to build and fun to learn. It will teach you the foundations of how to access FastAPI endpoints.\n\nTo follow along with this tutorial, you should understand:\n• What SQLAlchemy is and what an object-relational mapper (ORM) is\n• (Optional) How to set up a database, especially PostgreSQL\n\nBe sure to fork this repo to be able to use it. You can also follow along step-by-step to produce the same result.\n\nTo set up FastAPI for a basic project, you need to install two things from pip: FastAPI and Uvicorn. FastAPI is the API we will be using and that’s why we’re here. But what is Uvicorn? It’s an asynchronous server gateway interface (ASGI). In plain English, it’s a Python channel between the server and the client, and it can communicate between the two in an asynchronous way. So it fits well with FastAPI because the latter is an async framework. Thus, a Uvicorn web server can delegate workers to process FastAPI requests concurrently.\n\nBefore installing both, you need to create a virtual environment if you’re building this app locally:\n\nTo picture what you’re going to build at the end of this tutorial, let’s see what the app will look like:\n\nAs you can see, the backend of this app consists of five endpoints.\n• One POST request for the create operation\n• Two GET requests for the read operation\n• One PUT request for the update operation\n• And one DELETE request for the delete operation\n\nLet’s set up the database and start configuring our data.\n\nIf you already have a database set up, you might need to skip this section.\n\nTo create a PostgreSQL database on Linux, make sure the PostgreSQL service is running on your machine. To do that, open your terminal and run the following:\n\nIf it’s active, you’re good to go and skip the next command. If it’s not, you may want to start the service first:\n\nOnce that’s done, create a new database:\n\nAssuming that the username of your Postgres database engine is , a new database is created called .\n\nSimilarly, if you’re using Mac OS, you might need to run the PostgreSQL service from your terminal:\n\nNext, enter the PostgreSQL client command through the terminal-based interface . You can do a similar command to the one discussed in the Linux subsection or break this command down into two subcommand:\n\nNow, enter the CLI and then create a new database inside that interface:\n\nHere, we’re sure there is a database called because we will use this database in the next sections. If you’d prefer, you can use your own database that you set up with your desired database engine.\n\nIf you don’t want to run PostgreSQL directly on your machine, you could also utilize the official Docker image to the same effect. Unfortunately, configuring that setup is outside the scope of this tutorial.\n\nOne useful option for database model management in FastAPI is SQLAlchemy. I’ll use its ORM to facilitate accessing databases with writing objects that Python is familiar with. We need to install two things: and , which is a driver to interact with the Postgres database from Python.\n\nNote: I have installed instead of to avoid the warning of renaming the library. In that warning, there’s a recommendation to use the binary version.\n\nNavigate into that folder and create a new file called :\n\nOpen your file and build your first app with the following few lines:\n\nOpen your terminal again and enter the following:\n\nNote: The here points to the script, while the app is the FastAPI instance inside the file. We follow this argument with to enable reloading the server after any change happens to the app.Go to the browser and enter the following URL . You should see the following expected JSON response:\n\nFastAPI provides automated documentation created by Swagger UI which allows you to test your API right from the browser; you don’t need Postman to test your FastAPI endpoints anymore.\n\nTo check it out, head over to URL. Here’s how it looks with the home endpoint that we created in the last Python snippet:\n\nYou can try it out and test the API by clicking on the Try it out button. You’ll see no parameters needed for this endpoint as there are no arguments sent to the home() function. Click on the Execute button. You’ll get the response body as expected:\n\nTo be able to interact with the Postgres database using SQLAlchemy, you need to set up the session:\n\nAs you can see, the object is defined as the string URL of the database that you should connect to. It has a as the driver and postgres as the username. Change the password to your own. If you’re using a host other than the localhost, change it as well. The is the database that we set up and the default port is .\n\nNote: You may omit the username and password fields to be default if you don’t have a specific username or password attached to your PostgreSQL. However, leaving both fields blank is not encouraged in a production environment. Just consider it for development.\n\nThe engine instance is very important. It’s the starting point of any SQLAlchemy application. We use it to instantiate a session that establishes all conversations with the database.\n\nAn important step to deal with web apps that use data is data modeling. In our basic todo app, we need just the note/text that we want to write and whether that todo item is completed or not.\n\nSo, let’s model it that way:\n\nOne way to create tables using SQLAlchemy is to do a declarative mapping. You’ll map classes with specific configurations; each class should inherit from the class. This class is constructed from the declarative mapper, .\n\nInside the class, you’ll find the definitions of each attribute and their data types.\n\nFinally, the creates all table objects. In this case, it will just create one table which is the todos table.\n\nNow, let’s see how we can link SQLAlchemy with FastAPI to build our CRUD app endpoints. First, get rid of the endpoint; we’ll set up new functions for each operation.\n\nMoving forward, we’ll use with each request to allow asynchronous calls.\n\nThis endpoint establishes a POST request to the API with the function. This function has two arguments: which is a required string data type and as an optional boolean data type with a default value of .\n\nNotice here when an argument of a route function does not have an = sign, it’s considered a required field.\n\nNow, the object is instantiated from a class having the text and arguments. You’ll have an attribute automatically generated for each request as it’s set up as a primary key when we modeled the database.\n\nUsing adds that object to the Postgres database. But you can’t see it in your database yet until you commit it using .\n\nLet’s open the Swagger UI using on your browser and test this create operation.\n\nClick on the Try it out button and enter the text that you want to do. See if you’ve already finished that task or not by selecting the value of field from the dropdown.\n\nYou should see a JSON response as expected returning a key-value pair of a “ ” with the value of the task text you entered.\n\nLet’s set up a GET request with the following:\n\nNow, is a Query object. Calling method on this object allows you to do a operation. So, this request should query all records of the todos table. A response would look like a list of JSON responses.\n\nPractice with the Swagger interface and test creating some todos and fetching them back with this GET request.\n\nYou want to do a bit more complicated request and get all completed tasks. So, send another GET request:\n\nThis endpoint should list all done todos. The is another query object that filters all True values of the attribute. Calling the method in the return statement should list all the done tasks.\n\nYou entered a todo with a typo or you want to update the status and mark it as done. You can send a PUT request to do your desired update:\n\nThe is the task string that you want to update the todo to say. It’s set as an empty string by default because you might need to just update the attribute. We make a condition for that. If it’s an empty string, the should stay the same. But if this attribute is changed, the text attribute should have the value.\n\nThe is the Query object representing the todo item with the associated id. This is passed in the path parameter inside the endpoint . Calling method on the object converts it to a Table object and fetches the first record of that query. This record is the one associated with the passed id.\n\nWe then check for the to make sure it has a non-empty string. If so, the now has that newly updated text. This means the text attribute in the table will be changed for that particular id.\n\nThe is then assigned to the value passed in the argument and the change is committed to the database. The final return is the response for the id passed.\n\nIn the todo app, the user may want to delete a todo item. You can implement a deletion method like so:\n\nLike the update operation, you need a unique identifier to be able to fetch that record from the database and delete it. That’s why we pass the id argument to the path parameter . After you fetch the todo object from the database, you can delete it with and then commit it to the database using .\n\nAt the end of the day, here is my todo list I experimented with:\n\nOrganizing your app helps you to refactor it easily — especially when it gets bigger. Let’s restructure this app in a modular way. To do this, we will create two simple modules instead of the all-in-one script we used.\n\nWe will divide the SQLAlchemy models into the module, and the main entry point of the app main.py which contains the routes.\n\nYou can consult it in this repo. You’ll find an additional script, other than what we mentioned, called which, as the name suggests, inserts data into the database through SQLAlchemy.\n\nThis practical tutorial covered how to build a Todo app with FastAPI. We talked about how to do basic operations like CRUD to be able to create, read, update, and delete fields from our app. We used SQLAlchemy as an ORM to communicate with the PostgreSQL database engine. We’ve also seen how FastAPI provides automated documentation through Swagger and learned how to structure your FastAPI project to be maintainable and organized.\n\nNow, it’s your turn to put these learnings into practice! If you like content like this, browse the Mattermost library and continue your learning.\n\nThis blog post was created as part of the Mattermost Community Writing Program and is published under the CC BY-NC-SA 4.0 license. To learn more about the Mattermost Community Writing Program, check this out."
    },
    {
        "link": "https://neurelo.com/post/how-to-integrate-fastapi-with-sqlalchemy",
        "document": "FastAPI is a high-performance, web framework for making APIs using Python based on typical Python type hints. Meanwhile, SQLAlchemy is a toolkit in Python used for working with SQL and object-relational mapping (ORM). By bringing together these two powerful resources, developers can effectively create strong and scalable web applications.\n\nIn this article, we will discuss integrating FastAPI with SQLAlchemy and touch on key issues such as setting up the development environment, configuring the project, database operations (CRUD), dependency injection handling, Alembic integration for migrations, testing, and best practices.\n\nAn Introduction to FastAPI and SQLAlchemy\n\nFastAPI is among the frameworks used for building APIs using regular Python type hints for validation in Python 3.7+. It's designed to be a framework that's easy for developers to learn and use while still being powerful and efficient. There is also automatic data validation, serialization, and OpenAPI documentation generation.\n\nSQLAlchemy is a precise SQL toolkit as well as an ORM library for Python. Developers can write code against the database using objects instead of raw SQL queries thanks to SQLAlchemy’s ORM.\n\nCombining FastAPI with SQLAlchemy provides several advantages:\n• Type safety: For catching errors early during development, FastAPI has type safety via Python type hints.\n• Developer productivity: Combining tools like FastAPI’s automated documentation generation and ORMs such as SQLAlchemy increases developer productivity.\n\nAlthough there are several benefits of using SQLAlchemy, you should also know the possible risks:\n\nAlthough there are several benefits of using SQLAlchemy, you should also know the possible risks:\n• Performance Overhead: ORMs tend to add performance overhead, especially for complex queries.\n• Steep Learning Curve: The learning curve of SQLAlchemy can be a little overwhelming for beginners, and you might need to spend some time on it.\n• Abstraction Leakage: At times, the ORM abstraction can \"leak,\" meaning that developers actually have to write SQL.\n• Complexity with large projects: As your project grows in proportion, all of ORM's complexities can become difficult to maintain.\n\nTo get started, you need to set up the development environment. Make sure you have Python 3.7+ installed. We will use the pipenv package to create a virtual environment for our project. You can install the pipenv package using the command below.\n\n\n\nCreate the virtual environment using the following command:\n\nCreate a new file, main.py, in the root directory of the project and add the following code:\n\nThe above code block configures the SQLAlchemy engine, session, and models and defines the Pydantic models for request and response validation. You can replace test.db with the name of your database.\n\nNow that you have the SQLAlchemy engine ready, we will start building the CRUD API. We will use different HTTP methods for each request, including POST, GET, DELETE, and PUT. Let’s get started.\n\nIn the POST request below, we are taking ItemCreate (defined above) as the request body and saving the data in the database.\n\nIn the code snippet below, we are using item_id as the path parameter to fetch the details of the item. We return an HTTP Exception if we don’t find the item in the database.\n\n\n\nYou can test the endpoint using the following curl request:\n\nWe will use the PUT HTTP method to update the row in the database based on item_id. We return an HTTP Exception if we don’t find data for the respective item_id.\n\n\n\nYou can test the endpoint using the following curl request:\n\nIn the following code snippet, we are performing a delete operation based on item_id provided by the user using the DELETE HTTP method.\n\n\n\nYou can test the endpoint using the following curl request:\n\nFastAPI provides a powerful dependency injection system that allows you to easily manage dependencies. Dependency injection is a design pattern that allows you to decouple your code by passing dependencies to your functions and classes instead of instantiating them directly.\n\nIn our example, we used dependency injection to manage the database session:\n\nAlembic is a lightweight database migration library for SQLAlchemy. It helps manage database schema changes over time, making it easier to handle database migrations in a structured and version-controlled manner.\n\nIf you haven’t already installed Alembic, you can do so using the command below.\n\n\n\nOnce that's done, initialize Alembic in your project. This will create an Alembic directory with a configuration file named alembic.ini:\n\n\n\nNow we need to open the alembic.ini file. Open it and set the sqlalchemy.url to use your SQLite database URL:\n\n\n\nAfter modifying the alembic.ini file, we need to modify the env.py file in the Alembic directory to correctly configure the database URL and import your SQLAlchemy models. You can replace the existing code with the following code in the env.py file.\n\nWith the configuration in place, we can now create a new migration script. Alembic will compare the current state of the database with your models and generate an appropriate migration script.\n\n\n\nApply the generated migration to update your database schema.\n\n\n\nWhenever you make changes to your database models, you can create and apply new migration scripts to keep your database schema in sync with your application models.\n\nWriting test cases for your applications is crucial as it ensures that new changes don't break any application functionality. Pytest is one of the most common Python libraries used for writing test cases.\n\nFor our FastAPI application, we will use testclient provided by the library itself. We are using a Pytest fixture named client to override the get_db dependency of the application. This is to ensure that the tests use the test database instead of the production database.\n\nNote: This code is for demonstration and testing purposes only. It is not production ready, and you might want to thoroughly test and implement proper error handling, security measures, and optimizations before deploying to production.\n\nFor the whole code, check out the GitHub Repository.\n• Connection pooling: Make sure you use connection pooling to manage your database connections effectively.\n• Optimize queries: Improve performance using the query optimization features that come with SQLAlchemy.\n• Exception handling: Develop a way of handling exceptions that doesn't break your application when something goes wrong.\n• Bulk operations: Always prefer to perform bulk insert and update while interacting with multiple records because it decreases the database round trip.\n• Cache responses: Caching allows us to keep frequently used information in memory, reducing dependency on databases and increasing web response times.\n• Monitor performance: You can use different monitoring tools to analyze how your app performs and determine where the most shortcomings are.\n\nFastAPI integrated with SQLAlchemy provides an effective method of creating web applications with Python. We discussed how to set up the environment, configure FastAPI with SQLAlchemy, perform CRUD operations to implement dependency injection, and manage migrations through Alembic. We finished with testing and best practices. By following these steps, you will be able to design sturdy and scalable web applications that are easier to maintain or modify without interrupting their functionality.\n\nWhile using ORMs is flexible and powerful, it's worth considering the level of database abstraction they provide. You may want to add another layer of abstraction by designing a higher-level API layer. This approach prevents exposing direct database operations in your API endpoints.\n\nFor example, constructing service layers that wrap CRUD operations can help avoid overexposure of database details. This can lead to better separation of concerns and, subsequently, more manageable long-term codebases, especially in the context of larger projects.\n\nAlternatively, for developers looking to focus their time on building their application, and not on database programming, Neurelo offers a platform that auto-generates CRUD APIs, uses AI-powered complex query generators, built-in observability, Git-like migration and much more. Try it yourself.\n\nThis post was written by Keshav Malik, a highly skilled and enthusiastic security engineer. Keshav has a passion for automation, hacking, and exploring different tools and technologies. With a love for finding innovative solutions to complex problems, Keshav is constantly seeking new opportunities to grow and improve as a professional. He is dedicated to staying ahead of the curve and is always on the lookout for the latest and greatest tools and technologies."
    },
    {
        "link": "https://dassum.medium.com/building-rest-apis-using-fastapi-sqlalchemy-uvicorn-8a163ccf3aa1",
        "document": "FastAPI is a modern, fast (high-performance), web framework that enables developers to build APIs with Python 3.6+ based on standard Python type hints. We are going to use a Python package called Pydantic, which enforces type hints at runtime. It provides user-friendly errors, allowing us to catch any invalid data.\n\nThe key features of FastAPI are:\n• Fast: Very high performance, on par with NodeJS and Go.\n• Fast to code: It allows for significant increases in development speed.\n• Easy: Designed to be easy to use and learn. Less time reading docs.\n• Standards-based: It’s based on the open standards for APIs, OpenAPI and JSON Schema.\n\nSwagger is a set of open-source tools built around the OpenAPI Specification that can help to design, build, document, and consume REST APIs. The major Swagger tools include:\n• Swagger Editor — browser-based editor where you can write OpenAPI specs\n• Swagger Codegen — generates server stubs and client libraries from an OpenAPI spec\n\nSQLAlchemy is the Python SQL toolkit and Object Relational Mapper that gives application developers the full power and flexibility of SQL.\n\nIt provides a full suite of well-known enterprise-level persistence patterns, designed for efficient and high-performing database access, adapted into a simple and Pythonic domain language.\n\nUvicorn is a lightning-fast ASGI server implementation, using uvloop and httptools. It supports HTTP/1.1 and WebSockets. Support for HTTP/2 is planned.\n\nThe aim of this tutorial is to work with FastAPI that helps us to create a production environment-ready Python application along with Swagger UI without a hitch. We will learn to build Rest APIs using Python 3, FastAPI and SQLAlchemy, and share the API using Swagger UI.\n\nWe are going to create REST API providing access to item and store resources. Here’s the API design for the same:\n\nFollowing are the steps required to create the sample FastAPI-based API for an Item and Store management application:\n\nWe require Python 3 with Pipenv and Git installed. Pipenv is a package and a virtual environment manager which uses under the hood. It provides more advanced features like version locking and dependency isolation between projects.\n\nOnce the prerequisites are in place we can begin creating our application.\n\na) Create a Sample Item Management Flask Application\n\nTo begin with our application, create a folder called in any directory on the disk for our project.\n\nOnce we are inside the project folder, execute the following commands to activate the VirtualEnv.\n\nThe virtual environment will now be activated, which will provide the required project isolation and version locking.\n\nNext, install all the required dependencies using Pipenv as shown.\n\nAfter we execute the above commands, the required dependencies will be installed.\n\nWe can see now two files, which have been created inside our project folder, namely, and .\n• contains all the names of the dependencies we just installed.\n• is intended to specify, based on the dependencies present in , which specific version of those should be used, avoiding the risks of automatically upgrading dependencies that depend upon each other and breaking your project dependency tree.\n\nNote: Here, we have installed all the dependencies with specific versions, which worked on my machine while writing this tutorial. If we don’t specify any version then the latest version of that dependency will be installed, which might not be compatible with other dependencies.\n\nNow, let’s start with writing some code for our application.\n\nTo start with our application , let’s configure the database first. FastAPI supports multiple databases, such as :\n• Microsoft SQL Server, and so on.\n\nFor our application, we’ll use SQLite, because it uses a single file and Python has integrated support. FastAPI works with any database and any style of library to talk to the database. A common pattern is to use an “ORM”: an “object-relational mapping” library. ORM is a technique that lets us query and manipulate data from a database using an object-oriented paradigm. ORMs can be thought of as a translator converting our code from one form to another. With an ORM, we normally create a class that represents a table in a SQL database and each attribute of the class represents a column, with a name and a type. In this tutorial we will use SQLAlchemy ORM framework.\n\nTo integrate database with our application, create a file with the following content.\n\nThe above code does the following:\n• First, we have imported packages which are required to create SQLAlchemy and database session to connect to the SQLite database. The database file will be created in the same directory with the name .\n• Then, we created the SQLAlchemy engine using the database created above.\n\nNote: is only required for\n• class represents database session. The class itself is not a database session yet. But, once we create an instance of the class, this instance will be the actual database session. To create the class, we used the function from .\n• Finally, we used the function that returns a class to create class. Later, we will inherit from this class to create each of the database models or classes(the ORM models).\n• We also defined a function called , which can used to create independent database session for each request. We will use the same session throughout the request and then close it after the request is finished. In the function , is used to create a database session for each request. Close it after finishing the request.\n\nNext, we will create database models for our data storage and organization. For our application, we need to create two database models Item, Store and its repositories. We will be using , which we created earlier in (Step 2) to create our SQLAlchemy models. It provides a class called that is a declarative base, which can be used to declare our models.\n\nCreate the package and add two files named and . We will add all the database entities in and it’s corresponding repository in .\n\nThe models.py file should contain the following content:\n\nThe above code in does the following:\n• We started off by creating the Item Model class in .\n• In , we declared the table name where this model will be mapped to.\n• From , we defined the table columns along with their data types. We use from SQLAlchemy as the default value. Here, acts as Foreign key reference for .\n• From to , we added some helper methods to print the object at runtime.\n• In , we declared the Store Model class and in we declared the table name where this model will be mapped to.\n• From , we defined the stores table columns along with their data types.\n• In we define the provided by SQLAlchemy ORM. This will become, more or less, a “magic” attribute that will contain the values from other tables related to this one.\n• From to , we added some helper methods to print the object at runtime.\n\nThe repositories.py file contains some reusable functions to interact with the data in the database. It has the following content:\n\nThe above code in does the following:\n• We started off by creating the ItemRepo class in and StoreRepo class in .\n• From , we defined some helper methods, which we can use to perform CRUD operations on database model.\n• From , we defined some helper methods, which we can use to perform CRUD operations on database model.\n\nLet’s add a file schemas.py inside the package . This file will contain the Pydantic models for our SQLAlchemy models. These Pydantic models define more or less a schema (a valid data shape).\n\nBased on the official documentation,\n\nPydantic is primarily a parsing library, not a validation library. Validation is a means to an end: building a model which conforms to the types and constraints provided. In other words, pydantic guarantees the types and constraints of the output model, not the input data.\n\nAll the data validations are performed under the hood by Pydantic.\n\nThe schemas.py file should contain the following content:\n\nFirst, we need to import from and then use it to create subclasses defining the schema, or data shapes, we want to receive. The above code in does the following:\n• We started off by creating Pydantic model(schema) in and Pydantic model(schema) in . These classes contain the common attributes, which we need while creating or reading data. When a model attribute has a default value or is not required, then we can make that attribute optional. Here, we have used as the default value for description in .\n• Then we added and classes, which inherit from and , respectively. Thus, they will have all the attributes of the Parent class, plus any additional data (attributes) needed for creation.\n• Finally, we created Pydantic models (schemas) and that will be used to read the data from the database and returning it from the API. In the Pydantic models for reading, and , we added an internal class. This class is used to provide configurations to Pydantic. In the class, we set the attribute .\n\nNow, let us create our application entry point. In the root directory of the project, create a file named with the following content:\n\nAnd, now in the file let's integrate and use all the other parts we created in the above steps. The above code within does the following:\n\nIn we defined a variable , which will be an “instance” of the class . This will be the main point of interaction for our APIs.\n\nIn we create all the tables in the database during the application startup using the SQLAlchemy models defined in step 3.\n\nFrom to , we defined a global exception Handler for our application.\n\nFrom to contains various REST endpoints available to consumers on resource Item and Store.\n\nLet’s check some sample REST endpoints we have defined in our application.\n\nIn we can see that we have defined an endpoint operation decorator to create an Item. This API will be used by the consumers to create an Item with given details. The tells FastAPI that the function right below is in charge of handling requests that go to the path using a operation. This is a decorator related to an endpoint operation, or an endpoint operation decorator.\n\nFrom to we defined the endpoint operation function or the function that goes below the endpoint operation decorator. This function will be called by FastAPI whenever it receives a request to the specified URL ( ) using a operation. In this case, it is an function. and is used to support concurrency and improve performance. For this endpoint we expect the client to send the request as request body.\n\nA request body is data sent by the client to our API. And response body is the data that our API sends back to the client. To declare a request body, we will use Pydantic models defined in step 3, with all their power and benefits.\n\nWe also have used normal functions for other endpoints, as we can see in instead of using\n\nNote: If you don’t know the difference between functions and functions and when to use them, check out Concurrency and async/await in the FastAPI documentation.\n\nIn we have used path parameters with type. The value of the path parameter will be passed to our function as the argument .\n\nHere, we just explored the capability of using both and functions in FastAPI.\n\nSimilarly, we have defined other REST endpoints for our application.\n\nTill now we have written all the code required for our application to run. Now, if we try to run the application using the command, it won’t run. To run it, we need a server program.\n\nFastAPI is the framework that we have used to build our API, and Uvicorn is the server that we will use to serve the requests. We have already installed Uvicorn. That will be our server.\n\nFinally, in we configure the application to run at port=9000 using Uvicorn ASGI server.\n\nOur application is ready now. We can start the application by executing the below command:\n\nWe are done with all the coding part and it’s testing time. Once the application is started successfully, we can navigate to . The system will bring up a page that looks something like this:\n\nFastAPI provides automatically generated documentation interfaces for our APIs, which we can interact with through a web interface. We can see that when we navigate to .\n\nLet’s test our application now to ensure everything is working fine.\n\nLet’s add an Item to the Store we created above.\n\nNow if we look at the Stores again, it will contain the Item we created above.\n\nSimilarly, we can explore other REST APIs.\n\nBecause FastAPI is built on top of the OpenAPI standard, it also provides an alternative API documentation using ReDoc, which we can access at :\n\nThe JSON Schemas of our Pydantic models, which we defined in (step 3 ) will be part of the OpenAPI generated for our application and will be shown in the interactive API documentation:\n\nWe can see that the attributes of in the API documentation are exactly the ones that we declared for our Pydantic model.\n\nThese JSON Schemas will also be used in the API documentation inside each path operation that needs them:\n\nSwagger UI also helps the developers with API testing, either in case of any issues reported or while adding new API’s to the existing application.\n\nIn this tutorial, we saw how easy it is to create a comprehensive REST API using FastAPI. FastAPI uses the best practices by default while providing the best developer experience as possible. Here, we learned how to:\n• Use path parameters to get a unique URL path per item\n• Use API best practices like validation, serialization, and documentation\n• Using both normal and async ways of handling requests.\n\nIf you would like to refer to the full code, do check:"
    },
    {
        "link": "https://stackoverflow.com/questions/15727155/how-to-paginate-in-flask-sqlalchemy-for-db-session-joined-queries",
        "document": "Say, we have the following relationships:\n• a person can have many email addresses\n\nSo, it's a many to many relationship. I have three tables: emails, providers, and users. Emails have two foreign ids for provider and user.\n\nNow, given a specific person, I want to print all the email providers and the email address it hosts for this person, if it exists. (If the person do not have an email at Gmail, I still want Gmail be in the result. I believe otherwise I only need a left inner join to solve this.)\n\nI figured out how to do this with the following subqueries (following the sqlalchemy tutorial):\n\nThis works okay (it returns a 4-tuple of , all the information that I want), but I later found out this is not using the Flask class, so that provided by Flask-SQLAlchemy does not work. Apparently is not the Flask-SQLAlchemy Query instance.\n\nI tried to do but that returns only columns in the email table though I want both the provider info and the emails.\n\nMy question: how can I do the same thing with Flask-SQLAlchemy so that I do not have to re-implement pagination that is already there?\n\nI guess the simplest option at this point is to implement my own paginate function, but I'd love to know if there is another proper way of doing this."
    },
    {
        "link": "https://stackoverflow.com/questions/9916094/sqlalchemy-and-going-through-a-large-result-set",
        "document": "I need to read data from all of the rows of a large table, but I don't want to pull all of the data into memory at one time. Is there a SQLAlchemy function that will handle paging? That is, pull several rows into memory and then fetch more when necessary.\n\nI understand you can do this with and as this article suggests, but I'd rather not handle that if I don't have to."
    },
    {
        "link": "http://docs.sqlalchemy.org/en/latest/orm/session_basics.html",
        "document": "What does the Session do ?¶ In the most general sense, the establishes all conversations with the database and represents a “holding zone” for all the objects which you’ve loaded or associated with it during its lifespan. It provides the interface where SELECT and other queries are made that will return and modify ORM-mapped objects. The ORM objects themselves are maintained inside the , inside a structure called the identity map - a data structure that maintains unique copies of each object, where “unique” means “only one object with a particular primary key”. The in its most common pattern of use begins in a mostly stateless form. Once queries are issued or other objects are persisted with it, it requests a connection resource from an that is associated with the , and then establishes a transaction on that connection. This transaction remains in effect until the is instructed to commit or roll back the transaction. When the transaction ends, the connection resource associated with the is released to the connection pool managed by the engine. A new transaction then starts with a new connection checkout. The ORM objects maintained by a are instrumented such that whenever an attribute or a collection is modified in the Python program, a change event is generated which is recorded by the . Whenever the database is about to be queried, or when the transaction is about to be committed, the first flushes all pending changes stored in memory to the database. This is known as the unit of work pattern. When using a , it’s useful to consider the ORM mapped objects that it maintains as proxy objects to database rows, which are local to the transaction being held by the . In order to maintain the state on the objects as matching what’s actually in the database, there are a variety of events that will cause objects to re-access the database in order to keep synchronized. It is possible to “detach” objects from a , and to continue using them, though this practice has its caveats. It’s intended that usually, you’d re-associate detached objects with another when you want to work with them again, so that they can resume their normal task of representing database state.\n\nBy this point, many users already have questions about sessions. This section presents a mini-FAQ (note that we have also a real FAQ) of the most basic issues one is presented with when using a . Just one time, somewhere in your application’s global scope. It should be looked upon as part of your application’s configuration. If your application has three .py files in a package, you could, for example, place the line in your file; from that point on your other modules say “from mypackage import Session”. That way, everyone else just uses , and the configuration of that session is controlled by that central point. If your application starts up, does imports, but does not know what database it’s going to be connecting to, you can bind the at the “class” level to the engine later on, using . In the examples in this section, we will frequently show the being created right above the line where we actually invoke . But that’s just for example’s sake! In reality, the would be somewhere at the module level. The calls to instantiate would then be placed at the point in the application where database conversations begin. When do I construct a , when do I commit it, and when do I close it?¶\n• None As a general rule, keep the lifecycle of the session separate and external from functions and objects that access and/or manipulate database data. This will greatly help with achieving a predictable and consistent transactional scope.\n• None Make sure you have a clear notion of where transactions begin and end, and keep transactions short, meaning, they end at the series of a sequence of operations, instead of being held open indefinitely. A is typically constructed at the beginning of a logical operation where database access is potentially anticipated. The , whenever it is used to talk to the database, begins a database transaction as soon as it starts communicating. This transaction remains in progress until the is rolled back, committed, or closed. The will begin a new transaction if it is used again, subsequent to the previous transaction ending; from this it follows that the is capable of having a lifespan across many transactions, though only one at a time. We refer to these two concepts as transaction scope and session scope. It’s usually not very hard to determine the best points at which to begin and end the scope of a , though the wide variety of application architectures possible can introduce challenging situations.\n• None Web applications. In this case, it’s best to make use of the SQLAlchemy integrations provided by the web framework in use. Or otherwise, the basic pattern is create a at the start of a web request, call the method at the end of web requests that do POST, PUT, or DELETE, and then close the session at the end of web request. It’s also usually a good idea to set to False so that subsequent access to objects that came from a within the view layer do not need to emit new SQL queries to refresh the objects, if the transaction has been committed already.\n• None A background daemon which spawns off child forks would want to create a local to each child process, work with that through the life of the “job” that the fork is handling, then tear it down when the job is completed.\n• None For a command-line script, the application would create a single, global that is established when the program begins to do its work, and commits it right as the program is completing its task.\n• None For a GUI interface-driven application, the scope of the may best be within the scope of a user-generated event, such as a button push. Or, the scope may correspond to explicit user interaction, such as the user “opening” a series of records, then “saving” them. As a general rule, the application should manage the lifecycle of the session externally to functions that deal with specific data. This is a fundamental separation of concerns which keeps data-specific operations agnostic of the context in which they access and manipulate that data. ### this is the **wrong way to do it** ### Keep the lifecycle of the session (and usually the transaction) separate and external. The example below illustrates how this might look, and additionally makes use of a Python context manager (i.e. the keyword) in order to manage the scope of the and its transaction automatically: ### this is a **better** (but not the only) way to do it ### Changed in version 1.4: The may be used as a context manager without the use of external helper functions. Yeee…no. It’s somewhat used as a cache, in that it implements the identity map pattern, and stores objects keyed to their primary key. However, it doesn’t do any kind of query caching. This means, if you say , even if is right there, in the identity map, the session has no idea about that. It has to issue SQL to the database, get the rows back, and then when it sees the primary key in the row, then it can look in the local identity map and see that the object is already there. It’s only when you say that the doesn’t have to issue a query. Additionally, the Session stores object instances using a weak reference by default. This also defeats the purpose of using the Session as a cache. The is not designed to be a global object from which everyone consults as a “registry” of objects. That’s more the job of a second level cache. SQLAlchemy provides a pattern for implementing second level caching using dogpile.cache, via the Dogpile Caching example. How can I get the for a certain object?¶ Use the classmethod available on : The newer Runtime Inspection API system can also be used: Is the Session thread-safe? Is AsyncSession safe to share in concurrent tasks?¶ The is a mutable, stateful object that represents a single database transaction. An instance of therefore cannot be shared among concurrent threads or asyncio tasks without careful synchronization. The is intended to be used in a non-concurrent fashion, that is, a particular instance of should be used in only one thread or task at a time. When using the object from SQLAlchemy’s asyncio extension, this object is only a thin proxy on top of a , and the same rules apply; it is an unsynchronized, mutable, stateful object, so it is not safe to use a single instance of in multiple asyncio tasks at once. An instance of or represents a single logical database transaction, referencing only a single at a time for a particular or to which the object is bound (note that these objects both support being bound to multiple engines at once, however in this case there will still be only one connection per engine in play within the scope of a transaction). A database connection within a transaction is also a stateful object that is intended to be operated upon in a non-concurrent, sequential fashion. Commands are issued on the connection in a sequence, which are handled by the database server in the exact order in which they are emitted. As the emits commands upon this connection and receives results, the itself is transitioning through internal state changes that align with the state of commands and data present on this connection; states which include if a transaction were begun, committed, or rolled back, what SAVEPOINTs if any are in play, as well as fine-grained synchronization of the state of individual database rows with local ORM-mapped objects. When designing database applications for concurrency, the appropriate model is that each concurrent task / thread works with its own database transaction. This is why when discussing the issue of database concurrency, the standard terminology used is multiple, concurrent transactions. Within traditional RDMS there is no analogue for a single database transaction that is receiving and processing multiple commands concurrently. The concurrency model for SQLAlchemy’s and is therefore Session per thread, AsyncSession per task. An application that uses multiple threads, or multiple tasks in asyncio such as when using an API like would want to ensure that each thread has its own , each asyncio task has its own . The best way to ensure this use is by using the standard context manager pattern locally within the top level Python function that is inside the thread or task, which will ensure the lifespan of the or is maintained within a local scope. For applications that benefit from having a “global” where it’s not an option to pass the object to specific functions and methods which require it, the approach can provide for a “thread local” object; see the section Contextual/Thread-local Sessions for background. Within the asyncio context, the object is the asyncio analogue for , however is more challenging to configure as it requires a custom “context” function."
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-query-tables-and-paginate-data-in-flask-sqlalchemy",
        "document": "The author selected the Free and Open Source Fund to receive a donation as part of the Write for DOnations program.\n\nFlask is a lightweight Python web framework that provides useful tools and features for creating web applications in the Python Language. SQLAlchemy is an SQL toolkit that provides efficient and high-performing database access for relational databases. It provides ways to interact with several database engines such as SQLite, MySQL, and PostgreSQL. It gives you access to the database’s SQL functionalities. And it also gives you an Object Relational Mapper (ORM), which allows you to make queries and handle data using simple Python objects and methods. Flask-SQLAlchemy is a Flask extension that makes using SQLAlchemy with Flask easier, providing you tools and methods to interact with your database in your Flask applications through SQLAlchemy.\n\nIn this tutorial, you’ll use Flask and Flask-SQLAlchemy to create an employee management system with a database that has a table for employees. Each employee will have a unique ID, a first name, a last name, a unique email, an integer value for their age, a date for the day they joined the company, and a boolean value to determine whether an employee is currently active or out of office.\n\nYou’ll use the Flask shell to query a table, and get table records based on a column value (for example, an email). You’ll retrieve employees’ records on certain conditions, such as getting only active employees or getting a list of out-of-office employees. You’ll order the results by a column value, and count and limit query results. Finally, you’ll use pagination to display a certain number of employees per page in a web application.\n• A local Python 3 programming environment. Follow the tutorial for your distribution in How To Install and Set Up a Local Programming Environment for Python 3 series. In this tutorial we’ll call our project directory .\n• An understanding of basic Flask concepts, such as routes, view functions, and templates. If you are not familiar with Flask, check out How to Create Your First Web Application Using Flask and Python and How to Use Templates in a Flask Application.\n• An understanding of basic HTML concepts. You can review our How To Build a Website with HTML tutorial series for background knowledge.\n• An understanding of basic Flask-SQLAlchemy concepts, such as setting up a database, creating database models, and inserting data into the database. See How to Use Flask-SQLAlchemy to Interact with Databases in a Flask Application for background knowledge.\n\nStep 1 — Setting up the Database and Model\n\nIn this step, you’ll install the necessary packages, and set up your Flask application, the Flask-SQLAlchemy database, and the employee model that represents the table where you’ll store your employee data. You’ll insert a few employees into the table, and add a route and a page where all employees are displayed on your application’s index page.\n\nFirst, with your virtual environment activated, install Flask and Flask-SQLAlchemy:\n\nOnce the installation is complete, you will receive output with the following line at the end:\n\nWith the required packages installed, open a new file called in your directory. This file will have code for setting up the database and your Flask routes:\n\nAdd the following code to . This code will set up an SQLite database and an employee database model representing the table you’ll use to store your employee data:\n\nHere, you import the module, which gives you access to miscellaneous operating system interfaces. You’ll use it to construct a file path for your database file.\n\nFrom the package, you import helpers you need for your application: the class to create a Flask application instance, to render templates, the object to handle requests, to construct URLs, and the function for redirecting users. For more information on routes and templates, see How To Use Templates in a Flask Application.\n\nYou then import the class from the Flask-SQLAlchemy extension, which gives you access to all the functions and classes from SQLAlchemy, in addition to helpers and functionality that integrates Flask with SQLAlchemy. You’ll use it to create a database object that connects to your Flask application.\n\nTo construct a path for your database file, you define a base directory as the current directory. You use the function to get the absolute path of the current file’s directory. The special variable holds the pathname of the current file. You store the absolute path of the base directory in a variable called .\n\nYou then create a Flask application instance called , which you use to configure two Flask-SQLAlchemy configuration keys:\n• : The database URI to specify the database you want to establish a connection with. In this case, the URI follows the format . You use the function to intelligently join the base directory you constructed and stored in the variable with the file name. This will connect to a database file in your directory. The file will be created once you initiate the database.\n• : A configuration to enable or disable tracking modifications of objects. You set it to to disable tracking, which uses less memory. For more, see the configuration page in the Flask-SQLAlchemy documentation.\n\nAfter configuring SQLAlchemy by setting a database URI and disabling tracking, you create a database object using the class, passing the application instance to connect your Flask application with SQLAlchemy. You store your database object in a variable called , which you’ll use to interact with your database.\n\nAfter setting up the application instance and the database object, you inherit from the class to create a database model called . This model represents the table, and it has the following columns:\n• : The employee’s first name, a string with a maximum length of 100 characters. signifies that this column should not be empty.\n• : The employee’s last name, a string with a maximum length of 100 characters. signifies that this column should not be empty.\n• : The employee’s email, a string with a maximum length of 100 characters. signifies that each email should be unique. signifies that it’s value should not be empty.\n• : The employee’s age, an integer value.\n• : The date at which the employee was hired. You set as the column type to declare it as a column that holds dates.\n• : A column which will hold a boolean value to indicate whether the employee is currently active or out of office.\n\nThe special function allows you to give each object a string representation to recognize it for debugging purposes. In this case, you use the employee’s first and last name to represent each employee object.\n\nNow that you’ve set the database connection and the employee model, you’ll write a Python program to create your database and table and populate the table with some employee data.\n\nOpen a new file called in your directory:\n\nAdd the following code to delete existing database tables to start from a clean database, create the table, and insert nine employees into it:\n\nHere, you import the class from the module to use it to set employee hire dates.\n\nYou import the database object and the model. You call the function to delete all existing tables to avoid the chance of an already populated table existing in the database, which might cause issues. This deletes all database data whenever you execute the program. For more information on creating, modifying, and deleting database tables, see How to Use Flask-SQLAlchemy to Interact with Databases in a Flask Application.\n\nYou then create several instances of the model, which represent the employees you’ll query in this tutorial, and add them to the database session using the function. Lastly, you commit the transaction and apply the changes to the database using the .\n\nTo take a look at the data you added to your database, make sure your virtual environment is activated, and open the Flask shell to query all employees and display their data:\n\nRun the following code to query all employees and display their data:\n\nYou use the method of the attribute to get all employees. You loop through the results, and display employee information. For the column, you use a conditional statement to display the current status of the employee, either or .\n\nYou can see that all of the employees we’ve added to the database are properly displayed.\n\nNext, you’ll create a Flask route to display employees. Open for editing:\n\nAdd the following route at the end of the file:\n\nThis queries all employees, renders an template, and passes it the employees you fetch.\n\nAdd the following to :\n\nHere, you use a title block and add some CSS styling. You add a navbar with two items, one for the index page, and one for an inactive About page. This navbar will be reused throughout the application in the templates that inherit from this base template. The content block will be replaced with the content of each page. For more on templates, check out How to Use Templates in a Flask Application.\n\nNext, open a new template you rendered in :\n\nAdd the following code to the file:\n\nHere, you loop through employees and display each employee’s information. If the employee is active you add an (Active) label, otherwise you display an (Out of Office) label.\n\nWhile in your directory with your virtual environment activated, tell Flask about the application ( in this case) using the environment variable. Then set the environment variable to to run the application in development mode and get access to the debugger. For more information about the Flask debugger, see How To Handle Errors in a Flask Application. Use the following commands to do this:\n\nWith the development server running, visit the following URL using your browser:\n\nYou’ll see the employees you added to the database in a page similar to the following:\n\nLeave the server running, open another terminal, and continue to the next step.\n\nYou’ve displayed the employees you have in your database on the index page. Next, you’ll use the Flask shell to query employees using different methods.\n\nIn this step, you’ll use the Flask shell to query records, and filter and retrieve results using multiple methods and conditions.\n\nWith your programming environment activated, set the and variables, and open the Flask shell:\n\nImport the object and the model:\n\nAs you’ve seen in the previous step, you can use the method on the attribute to get all the records in a table:\n\nThe output will be a list of objects representing all employees:\n\nSimilarly, you can use the method to get the first record:\n\nThe output will be an object that holds the first employee’s data:\n\nIn most database tables, records are identified with a unique ID. Flask-SQLAlchemy allows you to fetch a record using its ID with the method:\n\nRetrieving a Record or Multiple Records by a Column Value\n\nTo get a record using the value of one of its columns, use the method. For example, to get a record using its ID value, similar to the method:\n\nYou use because may return multiple results.\n\nFor another example, you can get an employee using their age:\n\nFor an example where the query result holds more than one matching record, use the column and the first name , which is a name shared by two employees:\n\nHere, you use to get the full list. You can also use to get only the first result:\n\nYou’ve fetched records through column values. Next, you’ll query your table using logical conditions.\n\nIn complex, full-featured web applications, you often need to query records from the database using complicated conditionals, such as fetching employees based on a combination of conditions that take into account their location, availability, role, and responsibilities. In this step, you’ll get practice using conditional operators. You’ll use the method on the attribute to filter query results using logical conditions with different operators. For example, you can use logical operators to fetch a list of which employees are currently out of office, or employees due for a promotion, and maybe provide a calendar of employee vacation time, etc.\n\nThe simplest logical operator you can use is the equality operator , which behaves in a similar way to . For example, to get all the records where the value of the column is , you can use the method like so:\n\nHere you use the syntax as an argument to the method. The method is a shortcut for this syntax.\n\nThe result is the same as the result of the method with the same condition:\n\nLike , you can also use the method to get the first result:\n\nThe method allows you to use the Python operator to get records. For example, to get a list of out-of-office employees, you can use the following approach:\n\nHere you use the condition to filter results.\n\nYou can use the operator to get a record where the value of a given column is less than the given value. For example, to get a list of employees under 32 years old:\n\nUse the operator for records that are less than or equal to the given value. For example, to include employees aged 32 in the previous query:\n\nSimilarly, the operator gets a record where the value of a given column is greater than the given value. For example, to get employees over 32:\n\nAnd the operator is for records that are greater than or equal to the given value. For example, you can again include 32-year-old employees in the previous query:\n\nSQLAlchemy also provides a way to get records where a column’s value matches a value from a given list of values using the method on the column like so:\n\nHere, you use a condition with the syntax , where is any type of object you can iterate through. For another example, you can use the Python function to get employees from a certain age range. The following query gets all the employees that are in their thirties.\n\nSimilar to the method, you can use the method to get records where a column value is not in a given iterable:\n\nHere, you get all employees except those with a first name in the list.\n\nYou can join several conditions together using the function, which works like Python’s operator.\n\nFor example, let’s say you want to get all the employees that are 32 years old and are currently active. First, you can check who is 32 using the method (you can also use if you want):\n\nHere, you see that John and Jane are the employees that are 32 years old. John is active, and Jane is out of office.\n\nTo get the employees that are 32 and active, you’ll use two conditions with the method:\n\nTo join these two conditions together, use the function like so:\n\nHere, you use the syntax .\n\nUsing on the query returns a list of all the records that match the two conditions. You can use the method to get the first result:\n\nFor a more complex example, you can use the with the function to get employees who were hired in a specific time span. In this example, you get all the employees hired in the year 2019:\n\nHere you import the function, and you filter results using the function to combine the following two conditions:\n• : This is for employees hired the first of January 2019 or later.\n• : This is for employees hired before the first of January 2020.\n\nCombining the two conditions fetches employees hired from the first day of 2019 and before the first day of 2020.\n\nSimilar to , the function combines two conditions, and it behaves like the operator in Python. It fetches all records that meet one of two conditions. For example, to get employees aged 32 or 52, you can combine two conditions with the function as follows:\n\nYou can also use the and methods on string values in conditions you pass to the method. For example, to get all the employees whose first name starts with the string and those with a last name that ends with the string :\n\nHere you combine the following two conditions:\n• : Matches employees with a first name that starts with .\n• : Matches employees with a last name that ends with .\n\nYou can now filter query results using logical conditions in your Flask-SQLAlchemy applications. Next, you’ll order, limit, and count the results you get from the database.\n\nIn web applications, you often need to order your records when displaying them. For example, you might have a page to display the latest hires in each department to let the rest of the team know about new hires, or you can order employees by displaying the oldest hires first to recognize long-tenured employees. You will also need to limit your results in certain cases, such as displaying only the latest three hires on a small sidebar. And you often need to count the results of a query, for example, to display the number of employees who are currently active. In this step, you’ll learn how to order, limit, and count results.\n\nTo order results using the values of a specific column, use the method. For example, to order results by the employees’ first name:\n\nAs the output shows, the results are ordered alphabetically by the employee’s first name.\n\nYou can order by other columns. For example, you can use the last name to order employees:\n\nYou can also order employees by their hire date:\n\nAs the output shows, this orders results from the earliest hire to the latest hire. To reverse the order and make it descending from the latest hire to the earliest, use the method like so:\n\nYou can also combine the method with the method to order filtered results. The following example gets all the employees hired in 2021 and orders them by age:\n\nHere, you use the function with two conditions: for employees hired on the first day of 2021 or later, and for employees hired before the first day of 2022. You then use the method to order the resulting employees by their age.\n\nIn most real world cases, when querying a database table, you might get up to millions of matching results, and it is sometimes necessary to limit results to a certain number. To limit results in Flask-SQLAlchemy, you can use the method. The following example queries the table and returns only the first three matching results:\n\nYou can use with other methods, such as and . For example, you can get the last two employees hired in 2021 using the method like so:\n\nHere, you use the same query in the previous section with an additional method call.\n\nTo count the number of results of a query, you can use the method. For example, to get the number of employees that are currently in the database:\n\nYou can combine the method with other query methods similar to . For example, to get the number of employees hired in 2021:\n\nHere you use the same query you used previously for getting all the employees that were hired in 2021. And you use the to retrieve the number of entries, which is 3.\n\nYou’ve ordered, limited, and counted query results in Flask-SQLAlchemy. Next, you’ll learn how to split query results into multiple pages and how to create a pagination system in your Flask applications.\n\nIn this step, you’ll modify the main route to make the index page display employees on multiple pages to make navigating the employee list easier.\n\nFirst, you’ll use the Flask shell to see a demonstration of how to use the pagination feature in Flask-SQLAlchemy. Open the Flask shell if you haven’t already:\n\nLet’s say you want to split the employee records in your table into multiple pages, with two items per page. You can do this using the query method like so:\n\nYou use the parameter of the query method to specify the page you want to access, which is the first page in this case. The parameter specifies the number of items each page must have. In this case you set it to to make each page have two items.\n\nThe variable here is a pagination object, which gives you access to attributes and methods you’ll use to manage your pagination.\n\nYou access the page’s items using the attribute.\n\nTo access the next page, you can use the method of the pagination object like so, the returned result is also a pagination object:\n\nYou can get a pagination object for the previous page using the method. In the following example you access the pagination object for the fourth page, then you access the pagination object of its previous page, which is page 3:\n\nYou can access the current page number using the attribute like so:\n\nTo get the total number of pages, use the attribute of the pagination object. In the following example, both and return the same value because the total number of pages is a constant:\n\nFor the total number of items, use the attribute of the pagination object:\n\nHere, since you query all employees, the total number of items in the pagination is 9, because there are nine employees in the database.\n\nFollowing are some of the other attributes that pagination objects have:\n• : if there is a next page.\n• : if there is a previous page.\n• : The number of items per page.\n\nThe pagination object also has an method you can loop through to access page numbers. For example, you can print all page numbers like so:\n\nThe following is a demonstration of how to access all pages and their items using a pagination object and the method:\n\nHere, you create a pagination object that starts from the first page. You loop through pages using a loop with the pagination method. You print the page number and page items, and you set the object to the pagination object of its next page using the method.\n\nYou can also use the and the methods with the method to paginate filtered and ordered query results. For example, you can get employees over thirty and order results by age and paginate the results like so:\n\nNow that you have a solid understanding of how pagination works in Flask-SQLAlchemy, you will edit the index page of your application to display employees on multiple pages for easier navigation.\n\nTo access different pages, you’ll use URL parameters, also known as URL query strings, which are a way to pass information to the application through the URL. Parameters are passed to the application in the URL after a symbol. For example, to pass a parameter with different values you can use the following URLs:\n\nHere, the first URL passes a value to the URL parameter . The second URL passes a value to the same parameter.\n\nEdit the index route to look as follows:\n\nHere, you get the value of the URL parameter using the object and its method. For example will get the value from the URL parameter. You pass as a default value, and you pass the Python type as an argument to the parameter to make sure the value is an integer.\n\nNext you create a object, ordering query results by the first name. You pass the URL parameter value to the method, and you split results into two items per page by passing the value to the parameter.\n\nLastly, you pass the object you constructed to the rendered template.\n\nNext, edit the template to display pagination items:\n\nChange the content tag by adding an heading that indicates the current page, and changing the loop to loop through the object instead of the object, which is no longer available:\n\nIf you haven’t already, set the and environment variables and run the development server:\n\nNow, navigate to the index page with different values for the URL parameter:\n\nYou’ll see different pages with two items each, and different items on each page, as you’ve seen previously in the Flask shell.\n\nIf the given page number does not exit, you’ll get a HTTP error, which is the case with the last URL in the preceding URL list.\n\nNext, you’ll create a pagination widget to navigate between pages, you’ll use a few attributes and methods of the pagination object to display all page numbers, each number links to its dedicated page, and a button for going back if the current page has a previous page, and a button for going to the next page if it exists.\n\nThe pagination widget will look as follows:\n\nEdit the file by adding the following highlighted tag below the content tag:\n\nHere, you use the condition to add a link to the previous page if the current page isn’t the first page. You link to the previous page using the function call, in which you link to the index view function, passing the value to the URL parameter.\n\nTo display links to all the available page numbers, you loop through the items of the method which gives you a page number on each loop.\n\nYou use the condition to see whether the current page number isn’t the same as the number in the current loop. If the condition is true, you link to the page to allow the user to change the current page to another page. Otherwise, if the current page is the same as the loop number, you display the number without a link. This allows users to know the current page number in the pagination widget.\n\nLastly, you use the condition to see whether the current page has a next page, in which case you link to it using the call and a link.\n\nNavigate to the index page in your browser:\n\nYou’ll see the pagination widget is fully functional:\n\nHere, you use for moving to the next page and for the previous page, but you can also use any other characters you’d like, such as and or images in tags.\n\nYou’ve displayed employees on multiple pages and learned how to handle pagination in Flask-SQLAlchemy. And you can now use your pagination widget on other Flask applications you build.\n\nYou used Flask-SQLAlchemy to create an employee management system. You queried a table and filtered results based on column values and simple and complex logical conditions. You ordered, counted, and limited query results. And you created a pagination system to display a certain number of records on each page in your web application, and navigate between pages.\n\nYou can use what you’ve learned in this tutorial in combination with concepts explained in some of our other Flask-SQLAlchemy tutorials to add more functionality to your employee management system:\n• How to Use Flask-SQLAlchemy to Interact with Databases in a Flask Application to learn how to add, edit, or delete employees.\n• How to Use One-to-Many Database Relationships with Flask-SQLAlchemy to learn how to use one-to-many relationships to create a department table to link each employee to the department they belong to.\n• How To Use Many-to-Many Database Relationships with Flask-SQLAlchemy to learn how to use many-to-many relationships to create a table and link it to the table, where each employee has many tasks and each task is assigned to multiple employees.\n\nIf you would like to read more about Flask, check out the other tutorials in the How To Build Web Applications with Flask series."
    },
    {
        "link": "https://flask-sqlalchemy.readthedocs.io/en/stable/queries",
        "document": "See SQLAlchemy’s Querying Guide and other SQLAlchemy documentation for more information about querying data with the ORM. Queries are executed through . They can be constructed using . Executing a select returns a object that has many methods for working with the returned rows.\n\nIf you write a Flask view function it’s often useful to return a error for missing entries. Flask-SQLAlchemy provides some extra query methods.\n• None will raise a 404 if the row with the given id doesn’t exist, otherwise it will return the instance.\n• None will raise a 404 if the query does not return any results, otherwise it will return the first result.\n• None will raise a 404 if the query does not return exactly one result, otherwise it will return the result. You can add a custom message to the 404 error:\n\nYou may see uses of or to build queries. That query interface is considered legacy in SQLAlchemy. Prefer using the instead."
    }
]