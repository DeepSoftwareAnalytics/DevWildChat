[
    {
        "link": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html",
        "document": "Calculate the T-test for the means of two independent samples of scores.\n\nThis is a test for the null hypothesis that 2 independent samples have identical average (expected) values. This test assumes that the populations have identical variances by default.\n\nThe arrays must have the same shape, except in the dimension corresponding to axis (the first, by default). If an int, the axis of the input along which to compute the statistic. The statistic of each axis-slice (e.g. row) of the input will appear in a corresponding element of the output. If , the input will be raveled before computing the statistic. If True (default), perform a standard independent 2 sample test that assumes equal population variances [1]. If False, perform Welch’s t-test, which does not assume equal population variance [2].\n• None : if a NaN is present in the axis slice (e.g. row) along which the statistic is computed, the corresponding entry of the output will be NaN.\n• None : NaNs will be omitted when performing the calculation. If insufficient data remains in the axis slice along which the statistic is computed, the corresponding entry of the output will be NaN.\n• None : if a NaN is present, a will be raised. If 0 or None (default), use the t-distribution to calculate p-values. Otherwise, permutations is the number of random permutations that will be used to estimate p-values using a permutation test. If permutations equals or exceeds the number of distinct partitions of the pooled data, an exact test is performed instead (i.e. each distinct partition is used exactly once). See Notes for details. Deprecated since version 1.17.0: permutations is deprecated and will be removed in SciPy 1.7.0. Use the n_resamples argument of , instead, and pass the instance as the method argument. If seed is None (or np.random), the singleton is used. If seed is an int, a new instance is used, seeded with seed. If seed is already a or instance then that instance is used. Pseudorandom number generator state used to generate permutations (used only when permutations is not None). Deprecated since version 1.17.0: random_state is deprecated and will be removed in SciPy 1.7.0. Use the rng argument of , instead, and pass the instance as the method argument. Defines the alternative hypothesis. The following options are available (default is ‘two-sided’):\n• None ‘two-sided’: the means of the distributions underlying the samples are unequal.\n• None ‘less’: the mean of the distribution underlying the first sample is less than the mean of the distribution underlying the second sample.\n• None ‘greater’: the mean of the distribution underlying the first sample is greater than the mean of the distribution underlying the second sample. If nonzero, performs a trimmed (Yuen’s) t-test. Defines the fraction of elements to be trimmed from each end of the input samples. If 0 (default), no elements will be trimmed from either side. The number of trimmed elements from each tail is the floor of the trim times the number of elements. Valid range is [0, .5). Defines the method used to compute the p-value. If method is an instance of / , the p-value is computed using / with the provided configuration options and other appropriate settings. Otherwise, the p-value is computed by comparing the test statistic against a theoretical t-distribution. If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array. An object with the following attributes: The p-value associated with the given alternative. The number of degrees of freedom used in calculation of the t-statistic. This is always NaN for a permutation t-test. The object also has the following method: Computes a confidence interval around the difference in population means for the given confidence level. The confidence interval is returned in a with fields and . When a permutation t-test is performed, the confidence interval is not computed, and fields and contain NaN.\n\nSuppose we observe two independent samples, e.g. flower petal lengths, and we are considering whether the two samples were drawn from the same population (e.g. the same species of flower or two species with similar petal characteristics) or two different populations.\n\nThe t-test quantifies the difference between the arithmetic means of the two samples. The p-value quantifies the probability of observing as or more extreme values assuming the null hypothesis, that the samples are drawn from populations with the same population means, is true. A p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that our observation is not so unlikely to have occurred by chance. Therefore, we do not reject the null hypothesis of equal population means. If the p-value is smaller than our threshold, then we have evidence against the null hypothesis of equal population means.\n\nBy default, the p-value is determined by comparing the t-statistic of the observed data against a theoretical t-distribution.\n\n(In the following, note that the argument permutations itself is deprecated, but a nearly identical test may be performed by creating an instance of with and passing it as the method argument.) When , where\n• None is the number of observations in a,\n• None is the total number of observations in a and b, and\n\nthe data are pooled (concatenated), randomly assigned to either group a or b, and the t-statistic is calculated. This process is performed repeatedly (permutation times), generating a distribution of the t-statistic under the null hypothesis, and the t-statistic of the observed data is compared to this distribution to determine the p-value. Specifically, the p-value reported is the “achieved significance level” (ASL) as defined in 4.4 of [3]. Note that there are other ways of estimating p-values using randomized permutation tests; for other options, see the more general .\n\nWhen , an exact test is performed: the data are partitioned between the groups in each distinct way exactly once.\n\nThe permutation test can be computationally expensive and not necessarily more accurate than the analytical test, but it does not make strong assumptions about the shape of the underlying distribution.\n\nUse of trimming is commonly referred to as the trimmed t-test. At times called Yuen’s t-test, this is an extension of Welch’s t-test, with the difference being the use of winsorized means in calculation of the variance and the trimmed sample size in calculation of the statistic. Trimming is recommended if the underlying distribution is long-tailed or contaminated with outliers [4].\n\nThe statistic is calculated as , where is the standard error. Therefore, the statistic will be positive when the sample mean of a is greater than the sample mean of b and negative when the sample mean of a is less than the sample mean of b.\n\nBeginning in SciPy 1.9, inputs (not recommended for new code) are converted to before the calculation is performed. In this case, the output will be a scalar or of appropriate shape rather than a 2D . Similarly, while masked elements of masked arrays are ignored, the output will be a scalar or rather than a masked array with ."
    },
    {
        "link": "https://docs.scipy.org/doc/scipy/reference/stats.html",
        "document": "This module contains a large number of probability distributions, summary and frequency statistics, correlation functions and statistical tests, masked statistics, kernel density estimation, quasi-Monte Carlo functionality, and more.\n\nStatistics is a very large area, and there are topics that are out of scope for SciPy and are covered by other packages. Some of the most important ones are:\n• None statsmodels: regression, linear models, time series analysis, extensions to topics also covered by .\n\nCompute several descriptive statistics of the passed array. Compute the weighted geometric mean along the specified axis. Calculate the weighted harmonic mean along the specified axis. Calculate the weighted power mean along the specified axis. Compute the kurtosis (Fisher or Pearson) of a dataset. Return an array of the modal (most common) value in the passed array. Calculate the nth moment about the mean for a sample. Compute the expectile at the specified level. Return the n th k-statistic ( so far). Return an unbiased estimator of the variance of the k-statistic. Compute the trimmed standard error of the mean. Return mean of array after trimming a specified fraction of extreme values Calculate the geometric standard deviation of an array. Compute the interquartile range of the data along the specified axis. Compute standard error of the mean. Bayesian confidence intervals for the mean, var, and std. 'Frozen' distributions for mean, variance, and standard deviation of data. Calculate the Shannon entropy/relative entropy of given distribution(s). Given a sample of a distribution, estimate the differential entropy. Compute the median absolute deviation of the data along the given axis.\n\nSciPy has many functions for performing hypothesis tests that return a test statistic and a p-value, and several of them return confidence intervals and/or other related information. The headings below are based on common uses of the functions within, but due to the wide variety of statistical procedures, any attempt at coarse-grained categorization will be imperfect. Also, note that tests within the same heading are not interchangeable in general (e.g. many have different distributional assumptions). One sample tests are typically used to assess whether a single sample was drawn from a specified distribution or a distribution with specified properties (e.g. zero mean). Calculate the T-test for the mean of ONE group of scores. Perform a test that the probability of success is p. Perform a quantile test and compute a confidence interval of the quantile. Test whether the skew is different from the normal distribution. Perform the Jarque-Bera goodness of fit test on sample data. Anderson-Darling test for data coming from a particular distribution. Perform the one-sample Cramér-von Mises test for goodness of fit. Performs the one-sample Kolmogorov-Smirnov test for goodness of fit. Paired sample tests are often used to assess whether two samples were drawn from the same distribution; they differ from the independent sample tests below in that each observation in one sample is treated as paired with a closely-related observation in the other sample (e.g. when environmental factors are controlled between observations within a pair but not among pairs). They can also be interpreted or used as one-sample tests (e.g. tests on the mean or median of differences between paired observations). Calculate the t-test on TWO RELATED samples of scores, a and b. These tests are often used to assess whether there is a relationship (e.g. linear) between paired observations in multiple samples or among the coordinates of multivariate observations. Calculate a linear least-squares regression for two sets of measurements. Compute the xi correlation and perform a test of independence Computes the Siegel estimator for a set of points (x, y). Computes the Theil-Sen estimator for a set of points (x, y). Perform Page's Test, a measure of trend in observations between treatments. These association tests and are to work with samples in the form of contingency tables. Supporting functions are available in . Chi-square test of independence of variables in a contingency table. Independent sample tests are typically used to assess whether multiple samples were independently drawn from the same distribution or different distributions with a shared property (e.g. equal means). Some tests are specifically for comparing two samples. T-test for means of two independent samples from descriptive statistics. Calculate the T-test for the means of two independent samples of scores. Perform the Mann-Whitney U rank test on two independent samples. Perform the Baumgartner-Weiss-Schindler test on two independent samples. Compute the Wilcoxon rank-sum statistic for two samples. Compute the Brunner-Munzel test on samples x and y. Perform the two-sample Cramér-von Mises test for goodness of fit. Performs the two-sample Kolmogorov-Smirnov test for goodness of fit. Performs the (one-sample or two-sample) Kolmogorov-Smirnov test for goodness of fit. Others are generalized to multiple samples. Perform Tukey's HSD test for equality of means over multiple treatments. The following functions can reproduce the p-value and confidence interval results of most of the functions above, and often produce accurate results in a wider variety of conditions. They can also be used to perform hypothesis tests and generate confidence intervals for custom statistics. This flexibility comes at the cost of greater computational requirements and stochastic results. Performs a permutation test of a given statistic on provided data. Simulate the power of a hypothesis test under an alternative hypothesis. Instances of the following object can be passed into some hypothesis test functions to perform a resampling or Monte Carlo version of the hypothesis test. These functions are for assessing the results of individual tests as a whole. Functions for performing specific multiple hypothesis tests (e.g. post hoc tests) are listed above. Combine p-values from independent tests that bear upon the same hypothesis. The following functions are related to the tests above but do not belong in the above categories."
    },
    {
        "link": "https://docs.scipy.org/doc/scipy",
        "document": "Want to build from source rather than use a Python distribution or pre-built SciPy binary? This guide will describe how to set up your build environment, and how to build SciPy itself, including the many options for customizing that build."
    },
    {
        "link": "https://docs.scipy.org/doc/scipy/release/1.8.0-notes.html",
        "document": "SciPy 1.8.0 is the culmination of 6 months of hard work. It contains many new features, numerous bug-fixes, improved test coverage and better documentation. There have been a number of deprecations and API changes in this release, which are documented below. All users are encouraged to upgrade to this release, as there are a large number of bug-fixes and optimizations. Before upgrading, we recommend that users check that their own code does not use deprecated SciPy functionality (to do so, run your code with and check for s). Our development attention will now shift to bug-fix releases on the 1.8.x branch, and on adding new features on the master branch.\n\nThis release requires Python 3.8+ and NumPy 1.17.3 or greater.\n\nFor running on PyPy, PyPy3 6.0+ is required.\n\nAdded an parameter to the real transforms in which controls whether the modified definition of DCT/DST is used without changing the overall scaling. backend registration is now smoother, operating with a single registration call and no longer requiring a context manager. introduces a new optional keyword-only argument, . takes in a tuple of extra arguments if any (default is ), which is then internally used to pass into the callable function (needing these extra arguments) which we wish to integrate. has a new method, , which constructs a design matrix of b-splines in the sparse CSR format. A new method in class allows to convert a object to object. gained three new public array structure investigation functions. returns information about the bandedness of an array and can be used to test for triangular structure discovery, while and test the array for exact and approximate symmetric/Hermitian structure. introduces two new optional keyword only arguments, and . can take values, (default), in which case all the one hot direction vectors will be used for verifying the input analytical gradient function and , in which case a random direction vector will be used for the same purpose. (default is ) can be used for reproducing the return value of function. It will be used only when . The method has been rewritten to use Cython bindings. This also fixes an issue with the callback altering the state of the optimization. Added optional parameters and for adapative step size adjustment in . The argument to is now optional so that it may have a default value consistent with most other functions in . Add argument, default , to , and add new pairing option to construct analog and minimal discrete SOS arrays. uses zpk2sos; add argument here as well, and pass it on to . and now work for even window lengths. Added the Chirp Z-transform and Zoom FFT available as and . An array API has been added for early testing and feedback; this work is ongoing, and users should expect minor API refinements over the next few releases. Please refer to the docstring for more information. introduces optional keyword only argument, which accepts either, (Edmonds Karp algorithm) or (Dinic’s algorithm). Moreover, is used as default value for which means that Dinic’s algorithm is used for computing maximum flow unless specified. See, the comparison between the supported algorithms in this comment. Parameters , now default to 1e-6 in to match with default values in . Add the Transpose-Free Quasi-Minimal Residual algorithm (TFQMR) for general nonsingular non-Hermitian linear systems in . The sparse SVD library PROPACK is now vendored with SciPy, and an interface is exposed via scipy.sparse.svds with . For some problems, this may be faster and/or more accurate than the default, ARPACK. PROPACK functionality is currently opt-in–you must specify at runtime to use it due to potential issues on Windows that we aim to resolve in the next release. iterative solvers now have a nonzero initial guess option, which may be specified as . The method has been added for sparse matrices. now supports item assignment and has a new method. Add in favour of which will be deprecated in the next release. The new function computes the logarithm of the logistic sigmoid function. The function is formulated to provide accurate results for large positive and negative inputs, so it avoids the problems that would occur in the naive implementation . A suite of five new functions for elliptic integrals: . These are the Carlson symmetric elliptic integrals, which have computational advantages over the classical Legendre integrals. Previous versions included some elliptic integrals from the Cephes library ( ) but was missing the integral of third kind (Legendre’s Pi), which can be evaluated using the new Carlson functions. The new Carlson elliptic integral functions can be evaluated in the complex plane, whereas the Cephes library’s functions are only defined for real inputs. Several defects in have been corrected. Approximately correct values are now returned for near , fixing #8054. Evaluation for such is now calculated through a series derived by López and Temme (2013) that converges in these regions. In addition, degenerate cases with one or more of , , and/or a non-positive integer are now handled in a manner consistent with mpmath’s hyp2f1 implementation, which fixes #7340. These fixes were made as part of an effort to rewrite the Fortran 77 implementation of hyp2f1 in Cython piece by piece. This rewriting is now roughly 50% complete. introduces two new optional keyword-only arguments, and . is either or . In the latter, random permutations are performed to improve the centered discrepancy. is either 1 or 2. 1 corresponds to the classical LHS while 2 has better sub-projection properties. This construction is referred to as an orthogonal array based LHS of strength 2. In both cases, the output is still a LHS. is faster as the underlying Van der Corput sequence was ported to Cython. The parameter was added to the and functions to allow one-sided hypothesis testing. Similarly, the masked versions of , , , , and now also have an parameter. Random variate generators to sample from arbitrary univariate non-uniform continuous and discrete distributions have been added to the new submodule. Implementations of a C library UNU.RAN are used for performance. The generators added are: The set of functions now have improved performance for the , , , and statistic calculations. and now have faster Pythran-based implementations. Some general efficiency improvements to handling of values in several functions. Added the parameter to and prevent the undesirable return of a masked array from the function in some cases. performs an exact or randomized permutation test of a given statistic on provided data.\n\nSciPy has always documented what its public API consisted of in its API reference docs, however there never was a clear split between public and private namespaces in the code base. In this release, all namespaces that were private but happened to miss underscores in their names have been deprecated. These include (as examples, there are many more): All functions and other objects in these namespaces that were meant to be public are accessible from their respective public namespace (e.g. ). The design principle is that any public object must be accessible from a single namespace only; there are a few exceptions, mostly for historical reasons (e.g., and overlap). For other libraries aiming to provide a SciPy-compatible API, it is now unambiguous what namespace structure to follow. See gh-14360 for more details. has been deprecated from and moved to the submodule. It now uses the C implementation of the UNU.RAN library so the result of methods like may vary slightly. Parameter has been deprecated and renamed to . The parameter has also been deprecated and will be removed in a future release of SciPy.\n• None #12146: DOC: add docs to explain behaviour of newton’s mehod on arrays\n• None #12889: MAINT: deal with cases in `minimize` for `(bounds.lb == bounds.ub).any()\n• None #13143: MAINT: deal with cases in `minimize` for `(bounds.lb == bounds.ub).any()…\n• None #13839: MAINT: set same tolerance between LSMR and LSQR\n• None #14132: DOC: badge with version of the doc in the navbar\n• None #14173: BUG: Fixed an issue wherein `geometric_slerp` would return…\n• None #14210: BUG: Fix Nelder-Mead logic when using a non-1D x0 and adapative\n• None #14219: ENH: sparse.linalg: Use the faster “sqrt” from “math” and be…\n• None #14224: MAINT: Modify to use new random API in benchmarks\n• None #14254: BUG: Fixed an issue wherein `SphericalVoronoi` could raise…\n• None #14258: DOC: fix stats.pearsonr example that was failing in CI\n• None #14259: CI: pin mypy to 0.902 and fix one CI failure\n• None #14260: BLD: optimize: fix some warnings in moduleTNC and minpack.h\n• None #14287: TST: Add testing for hyp2f1 for complex values in anticipation…\n• None #14301: MAINT: fix the last build warning in `optimize/_trlib/`\n• None #14308: ENH: use Pythran to speedup somersd and _tau_b\n• None #14377: Fix behavior of binary morphology with output=input when iterations=1\n• None #14403: Fix off by one error in doc string.\n• None #14404: DOC: docstring fix for default of n param of interpolate.pade\n• None #14411: MAINT: minor cleanups in usage of `compute_uv` keyword of `svd`\n• None #14413: DOC:interpolate: Fix the docstring example of “lagrange”\n• None #14423: CI: remove printing of skipped and xfailed tests from Azure test…\n• None #14454: MAINT: Begin translation of hyp2f1 for complex numbers into Cython\n• None #14456: CI: Lint with flake8 instead of pyflakes + pycodestyle\n• None #14496: MAINT: switch to using spmatrix.toarray instead of .todense\n• None #14507: CI: Add lint_diff docs & option to run only on specified files/dirs\n• None #14513: DOC: added reference and example in jacobi docstring\n• None #14520: BUG: diffev maxfun can be reached partway through population\n• None #14532: ENH: sparse.linalg: The solution is zero when R.H.S. is zero\n• None #14556: Fix the link to details of the strongly connected components…\n• None #14572: Set min length of the knot array for BSpline.design_matrix\n• None #14665: BLD: fix confusing “import pip” failure that should be caught\n• None #14689: MAINT: replace IOError alias with OSError or other appropriate…\n• None #14692: MAINT: Translation of hyp2f1 for complex numbers into Cython,…\n• None #14697: CI: add `cffi` in the benchmark CI job, and in environment.yml\n• None #14706: BUG: Fix hyp2f1 to return correct values in regions near exp(±iπ/3).\n• None #14708: BENCH: shorten svds benchmark that is timing out in CI\n• None #14743: TST:sparse.linalg: Use the more convenient “assert_normclose”…\n• None #14759: BLD: change section name in site.cfg.example from ALL to DEFAULT\n• None #14762: TST: add a seed to the pickling test of RBFInterpolator\n• None #14796: MAINT: Allow F401 and F403 in module init files\n• None #14832: MAINT: py3.10 in more jobs and bump some 3.8 to 3.9\n• None #14868: [MRG] BUG: Update lobpcg.py to validate the accuracy and issue…\n• None #14871: MAINT: removed a pitfall where a built-in name was being shadowed\n• None #14961: CI: use https protocol for git in CircleCI\n• None #15010: TST: remove fragile test which checks if g77 is linked\n• None #15020: ENH: sparse.linalg: Fixed the issue that the initial guess “x0”…\n• None #15034: DOC: use numpydoc format for C function in `_superlumodule.c`\n• None #15037: New example for gaussian_filter\n• None #15053: TST: Add some test skips to get wheel builder CI green again\n• None #15083: MAINT: stats: separate UNU.RAN functionality to its own submodule\n• None #15111: ENH: Add special.log_expit and use it in stats.logistic\n• None #15139: Use constrained_layout in Lomb-Scargle example\n• None #15181: BUG: The pytest decorator for conditional skipping is ‘skipif’\n• None #15192: MAINT: Replace use of `pytest.warns(None)` with `warnings.catch_warnings`\n• None #15268: CI: pin setuptools to 59.6.0 and Pythran to 0.10.0 for Windows…\n• None #15318: BLD: update pyproject.toml to not pin numpy for aarch64 + PyPy\n• None #15332: CI: pin numpy to 1.21.5 for the doc build on CircleCI\n• None #15335: CI: pin numpy to 1.21.5 in the Azure refguide check job"
    },
    {
        "link": "https://tec.citius.usc.es/stac/doc/scipy.stats.ttest_ind.html",
        "document": "Calculates the T-test for the means of TWO INDEPENDENT samples of scores.\n\nThis is a two-sided test for the null hypothesis that 2 independent samples have identical average (expected) values. This test assumes that the populations have identical variances.\n\nThe arrays must have the same shape, except in the dimension corresponding to (the first, by default). Axis can equal None (ravel array first), or an integer (the axis over which to operate on a and b). If True (default), perform a standard independent 2 sample test that assumes equal population variances [R16]. If False, perform Welch’s t-test, which does not assume equal population variance [R17].\n\nWe can use this test, if we observe two independent samples from the same or different population, e.g. exam scores of boys and girls or of two ethnic groups. The test measures whether the average (expected) value differs significantly across samples. If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages.\n\nWhen n1 != n2, the equal variance t-statistic is no longer equal to the unequal variance t-statistic:\n\nT-test with different means, variance, and n:"
    },
    {
        "link": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html",
        "document": "Calculate the T-test for the means of two independent samples of scores.\n\nThis is a test for the null hypothesis that 2 independent samples have identical average (expected) values. This test assumes that the populations have identical variances by default.\n\nThe arrays must have the same shape, except in the dimension corresponding to axis (the first, by default). If an int, the axis of the input along which to compute the statistic. The statistic of each axis-slice (e.g. row) of the input will appear in a corresponding element of the output. If , the input will be raveled before computing the statistic. If True (default), perform a standard independent 2 sample test that assumes equal population variances [1]. If False, perform Welch’s t-test, which does not assume equal population variance [2].\n• None : if a NaN is present in the axis slice (e.g. row) along which the statistic is computed, the corresponding entry of the output will be NaN.\n• None : NaNs will be omitted when performing the calculation. If insufficient data remains in the axis slice along which the statistic is computed, the corresponding entry of the output will be NaN.\n• None : if a NaN is present, a will be raised. If 0 or None (default), use the t-distribution to calculate p-values. Otherwise, permutations is the number of random permutations that will be used to estimate p-values using a permutation test. If permutations equals or exceeds the number of distinct partitions of the pooled data, an exact test is performed instead (i.e. each distinct partition is used exactly once). See Notes for details. Deprecated since version 1.17.0: permutations is deprecated and will be removed in SciPy 1.7.0. Use the n_resamples argument of , instead, and pass the instance as the method argument. If seed is None (or np.random), the singleton is used. If seed is an int, a new instance is used, seeded with seed. If seed is already a or instance then that instance is used. Pseudorandom number generator state used to generate permutations (used only when permutations is not None). Deprecated since version 1.17.0: random_state is deprecated and will be removed in SciPy 1.7.0. Use the rng argument of , instead, and pass the instance as the method argument. Defines the alternative hypothesis. The following options are available (default is ‘two-sided’):\n• None ‘two-sided’: the means of the distributions underlying the samples are unequal.\n• None ‘less’: the mean of the distribution underlying the first sample is less than the mean of the distribution underlying the second sample.\n• None ‘greater’: the mean of the distribution underlying the first sample is greater than the mean of the distribution underlying the second sample. If nonzero, performs a trimmed (Yuen’s) t-test. Defines the fraction of elements to be trimmed from each end of the input samples. If 0 (default), no elements will be trimmed from either side. The number of trimmed elements from each tail is the floor of the trim times the number of elements. Valid range is [0, .5). Defines the method used to compute the p-value. If method is an instance of / , the p-value is computed using / with the provided configuration options and other appropriate settings. Otherwise, the p-value is computed by comparing the test statistic against a theoretical t-distribution. If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array. An object with the following attributes: The p-value associated with the given alternative. The number of degrees of freedom used in calculation of the t-statistic. This is always NaN for a permutation t-test. The object also has the following method: Computes a confidence interval around the difference in population means for the given confidence level. The confidence interval is returned in a with fields and . When a permutation t-test is performed, the confidence interval is not computed, and fields and contain NaN.\n\nSuppose we observe two independent samples, e.g. flower petal lengths, and we are considering whether the two samples were drawn from the same population (e.g. the same species of flower or two species with similar petal characteristics) or two different populations.\n\nThe t-test quantifies the difference between the arithmetic means of the two samples. The p-value quantifies the probability of observing as or more extreme values assuming the null hypothesis, that the samples are drawn from populations with the same population means, is true. A p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that our observation is not so unlikely to have occurred by chance. Therefore, we do not reject the null hypothesis of equal population means. If the p-value is smaller than our threshold, then we have evidence against the null hypothesis of equal population means.\n\nBy default, the p-value is determined by comparing the t-statistic of the observed data against a theoretical t-distribution.\n\n(In the following, note that the argument permutations itself is deprecated, but a nearly identical test may be performed by creating an instance of with and passing it as the method argument.) When , where\n• None is the number of observations in a,\n• None is the total number of observations in a and b, and\n\nthe data are pooled (concatenated), randomly assigned to either group a or b, and the t-statistic is calculated. This process is performed repeatedly (permutation times), generating a distribution of the t-statistic under the null hypothesis, and the t-statistic of the observed data is compared to this distribution to determine the p-value. Specifically, the p-value reported is the “achieved significance level” (ASL) as defined in 4.4 of [3]. Note that there are other ways of estimating p-values using randomized permutation tests; for other options, see the more general .\n\nWhen , an exact test is performed: the data are partitioned between the groups in each distinct way exactly once.\n\nThe permutation test can be computationally expensive and not necessarily more accurate than the analytical test, but it does not make strong assumptions about the shape of the underlying distribution.\n\nUse of trimming is commonly referred to as the trimmed t-test. At times called Yuen’s t-test, this is an extension of Welch’s t-test, with the difference being the use of winsorized means in calculation of the variance and the trimmed sample size in calculation of the statistic. Trimming is recommended if the underlying distribution is long-tailed or contaminated with outliers [4].\n\nThe statistic is calculated as , where is the standard error. Therefore, the statistic will be positive when the sample mean of a is greater than the sample mean of b and negative when the sample mean of a is less than the sample mean of b.\n\nBeginning in SciPy 1.9, inputs (not recommended for new code) are converted to before the calculation is performed. In this case, the output will be a scalar or of appropriate shape rather than a 2D . Similarly, while masked elements of masked arrays are ignored, the output will be a scalar or rather than a masked array with ."
    },
    {
        "link": "https://datacamp.com/tutorial/an-introduction-to-python-t-tests",
        "document": "In today's data-driven world, businesses can't rely on intuition alone to make critical decisions. Instead, they need to use statistical techniques like hypothesis testing to back up their actions with solid data. One popular test for this purpose is the t-test, which allows you to compare the means of two groups and determine whether they're statistically different.\n\nBut how do you apply the t-test in practice, and how do you interpret the results? In this tutorial, we'll explore these questions and more. Specifically, we'll walk you through an example scenario where you want to assess the success of a new feature a business has launched. We'll show you how to use t-tests in Python and its powerful libraries to analyze the output.\n\nBy the end of this tutorial, you'll have a solid understanding of t-tests and be able to apply them to your own data with confidence.\n\nIn this tutorial, we’ll explore the different types of t-tests – one-sample test, two-sample test, paired t-test, and welch’s test – as well as their applications and when to use them.\n\nBefore we delve deeper into the details of the t-test, let us quickly understand some of the associated terminologies that will help strengthen your conceptual grasp of this statistical test.\n\nHypothesis testing is the process of starting with an assumption or null hypothesis and attempting to find evidence to reject it. The null hypothesis represents the status quo, while the alternative hypothesis represents the opposite of the null hypothesis.\n\nFor example, we can use hypothesis testing to determine whether a new feature launched by a business receives a good customer response and is reflected in the success metric. Check out our hypothesis testing course to learn more about the subject.\n\nThe p-value is the probability of obtaining results as extreme as the observed ones, assuming the null hypothesis is true. A small p-value indicates that the probability of obtaining the observed results is very low, given that the null hypothesis is correct.\n\nThe significance level, denoted by alpha, represents the probability of rejecting the null hypothesis, assuming it is true. It is also known as a Type 1 error.\n\nStatistical significance refers to the confidence that the observed result is not due to chance. It is important to note that statistical significance does not necessarily mean practical significance, as the observed result could still be negligible in practical terms. Sampling error can also contribute to statistical significance if the sample does not accurately represent the larger population.\n\nUnderstanding the assumptions of a statistical test is crucial to ensure accurate and reliable results. The t-test is no exception. Any violation of its assumptions could lead to misleading conclusions, which would be counterproductive. Let's explore the four assumptions of the t-test in detail:\n\nFirstly, the property of independence states that observations are not influenced by any implicit factor in the data and are not correlated over time. To ensure independence, various techniques can be applied to deal with dependent data, as explained by the University of Texas at Austin.\n\nSecondly, the presence of outliers, or anomalous data records, can impact the lower t-statistic value and lead to increased variance in the data, affecting the probability of rejecting the null hypothesis. Therefore, it's crucial to identify and understand the underlying reasons for anomalous behavior to determine whether it is legitimate or erroneous data. Consulting a domain expert can help in comprehending the data's true behavior.\n\nThirdly, the t-test is only valid for normally distributed data. Skewed data may lead to incorrect rejection of the null hypothesis. However, it's difficult to test for normal distribution with limited data points. In such cases, nonparametric tests that do not assume the data's distribution can be used, or data transformation can be performed as a corrective measure to achieve normality.cases, it is suggested to either use a nonparametric test (which does not make a distributional assumption of data) or perform data transformation as a corrective measure toward normality.\n\nFinally, the two populations being compared should have equal variances for the t-test to hold. This can be tested graphically using a Q-Q plot.\n\nNow that we have a better understanding of the t-test assumptions, let's explore different types of t-tests through a Python example. By the end of this tutorial, you will have the necessary knowledge to perform t-tests and interpret their results with confidence.\n\nThe one-sample t-test is a statistical hypothesis test that helps determine if an unknown population mean (mu) does not equal a claimed value.\n\nn = number of examples in the sample\n\nLet’s understand this by using an example. A company claims to produce ball bearings of 10 cm diameter (null hypothesis), and you decide to audit if that is true. You collect 21 ball bearings from multiple shops around the city and measure their diameter. You must determine if the company’s claim is false (alternate hypothesis) based on the measurements.\n\nThe test is designed as follows:\n\nTo declare the claims as false, you need to statistically prove that the measurements from the sample of bearings are different from the 10 cm claimed by the company. As the sample size is 21 (which is less than 30), we use a t-test. Here the sample mean is 11 cm, and the standard deviation is 1 cm.\n\nLet us learn how to conduct a one-sample t-test in Python using the function.\n\nThe value of t-statistic comes out to be 4.69 which seems to be very far from the mean of zero in a t-distribution. To quantify such extreme value, we refer to a p-value (which is introduced in the terminology section). The p-value is less than the default significance level of 0.05, which indicates that the probability of such an extreme outcome is close to zero and that the null hypothesis can be rejected.\n\nNote that the significance level is set at the beginning of the experiment.\n\nLet’s perform the one sample t-test without the ttest_1samp() function. The t-statistic, in this case, is defined by the difference between sample and population means divided by the standard error, as discussed in the previous section.\n• First, compute the sample mean (x_bar)\n• Next, compute the sample standard deviation with the degree of freedom of one (it represents the standard deviation of the sample).\n• Compute the standard error by dividing the standard deviation by the square root of the sample size.\n• Use the one-sample t-statistic formula as explained earlier.\n• Compute the p-value to establish the significance of the t-statistic.\n\nHow to Perform Two-sample t-test in Python\n\nLet’s extend our example by assuming that the company sets up another factory to produce identical ball bearings. We need to find out if the ball bearings from the two factories are of different sizes. For such a scenario, we use the two-sample test. Here the t-statistic is defined as below.\n\nLet’s consider that the first factory shares 21 samples of ball bearings where the mean diameter of the sample comes out to be 10.5 cm. On the other hand, the second factory shares 25 samples with a mean diameter of 9.5 cm. Both have a standard deviation of 1 cm.\n\nReferring to the p-value of 0.0026 which is less than the significance level of 0.05, we reject the null hypothesis stating that the bearings from the two factories are not identical.\n\nHow to Perform Paired t-test in Python\n\nUpon sharing these results with the company, it decides to improve its manufacturing technology by introducing a new casting machine. It starts this pilot from one of the factories and conducts a test to identify if the new casting machine leads to a change in the diameter of the bearings by comparing two samples of 25 bearings – one before the new machine was introduced and the other sample after it.\n\nThe mean diameter comes out to be 10.5cm and 9.9cm, respectively.\n\nLet’s perform a paired t-test to verify if the change is statistically significant.\n\nThe low p-value indicates that the null hypothesis is rejected, i.e., there is no change in the diameter of the ball bearings after introducing the new casting machine.\n\nThe assumptions paired t-test are valid on the differences of the pair and not on the original observations. Hence, it is important to ensure that the differences between the pairs are symmetrically distributed and do not have outliers among them.\n\nHow to Perform Welch's t-test in Python\n\nAfter a successful pilot from the new casting machine at one factory, the company wants to try another pilot at its second factory with a new rubbing machine. This machine is known to produce highly accurate ball bearings but is affected by temperature changes and power fluctuations. The company needs to identify if the ball bearings from the two factories are different by comparing 21 samples from the first factory and 25 from the second factory.\n\nThe mean diameter of bearings from the first factory turns out to be 9.9 cm with a standard deviation of 1 cm, whereas the mean diameter from the second factory turns out to be 10 cm with a standard deviation of 3 cm. As the standard deviation of the two samples is different, we will use Welch’s t-test.\n\nThe observed p-value is greater than the significance level of 0.05 which indicates that we fail to reject the null hypothesis implying that the bearings from the two factories are identical. We can not be sure of the results due to the high standard deviation of the samples from the second factory; hence we will need to collect more samples to perform the z-test.\n\nUnlike other t-tests, Welch's t-test is applicable for unequal population variances\n\nData has the power to uncover the true underlying phenomenon impacting business decisions only if interrogated rightly. It requires a robust understanding of different statistical tests to know which one to apply and when. This tutorial focuses on t-tests and explains their underlying assumptions, such as independent and identically distributed observations and normal distribution.\n\nBesides giving a quick primer on hypothesis testing, this tutorial also gives a comprehensive view of different types of t-tests with the help of an example. You are highly encouraged to practice conducting a t-test using python and evaluate which one should be used to assess the statistical significance of your experiment."
    },
    {
        "link": "https://pythonfordatascience.org/independent-samples-t-test-python",
        "document": ""
    },
    {
        "link": "https://geeksforgeeks.org/how-to-conduct-a-two-sample-t-test-in-python",
        "document": "In this article, we are going to see how to conduct a two-sample T-test in Python.\n\nThis test has another name as the independent samples t-test. It is basically used to check whether the unknown population means of given pair of groups are equal. tt allows one to test the null hypothesis that the means of two groups are equal\n\nBefore conducting the two-sample t-test using Python let us discuss the assumptions of this parametric test. Basically, there are three assumptions that we can make regarding the data groups:\n• Whether the two samples data groups are independent.\n• Whether the data elements in respective groups follow any normal distribution.\n• Whether the given two samples have similar variances. This assumption is also known as the homogeneity assumption.\n\nNote that even if our data groups don’t follow the three assumptions discussed above. This is because there is an alternate test present if our data do not fall in the normal distribution or we can transform the dependent data group using different techniques like square root, log, etc\n\nLet us consider an example, we are given two-sample data, each containing heights of 15 students of a class. We need to check whether two different class students have the same mean height. There are three ways to conduct a two-sample T-Test in Python.\n\nScipy stands for scientific python and as the name implies it is a scientific python library and it uses Numpy under the cover. This library provides a variety of functions that can be quite useful in data science. Firstly, let’s create the sample data. Now let’s perform two sample T-Test. For this purpose, we have ttest_ind() function in Python.\n\nNote that by default equal_var is True\n\nBefore conducting the two-sample T-Test we need to find if the given data groups have the same variance. If the ratio of the larger data groups to the small data group is less than 4:1 then we can consider that the given data groups have equal variance. To find the variance of a data group, we can use the below syntax,\n\nHere, the ratio is 12.260 / 7.7275 which is less than 4:1.\n\nTwo sample t-test has the following hypothesis:\n\nHere, since the p-value (0.53004) is greater than alpha = 0.05 so we cannot reject the null hypothesis of the test. We do not have sufficient evidence to say that the mean height of students between the two data groups is different.\n\nPingouin is a statistical-type package project that is based on Pandas and NumPy. Pingouin provides a wide range of features. The package is used to conduct the T-Test but also for computing the degree of freedoms, Bayes factor, etc.\n\nFirstly, let’s create the sample data. We are creating two arrays and now let’s perform two sample T-Test. For this purpose, we have ttest() function in the pingouin package of Python. The syntax is given below,\n\nNote that by default equal_var is True\n\nThis is the time to analyze the result. The p-value of the test comes out to be equal to 0.523, which is greater than the significance level alpha (that is, 0.05). This implies that we can say that the average height of students in one class is statistically not different from the average height of students in another class. Also, the Cohen’s D that is obtained in a t-test is in terms of the relative strength. According to Cohen:\n• cohen-d = 0.2 is considered as the ‘small’ effect size\n• cohen-d = 0.5 is considered as the ‘medium’ effect size\n• cohen-d = 0.8 is considered as the ‘large’ effect size\n\nIt implies that even if the two data groups’ means don’t differ by 0.2 standard deviations or more then the difference is trivial, even if it is statistically significant.\n\nStatsmodels is a python library that is specifically used to compute different statistical models and for conducting statistical tests. This library makes use of R-style modules and dataframes.\n\nFirstly, let’s create the sample data. We are creating two arrays and now let’s perform the two-sample T-test. Statsmodels library provides ttest_ind() function to conduct two-sample T-Test whose syntax is given below,\n\nThis is the time to analyze the result. The p-value of the test comes out to be equal to 0.521, which is greater than the significance level alpha (that is, 0.05). This implies that we can say that the average height of students in one class is statistically not different from the average height of students in another class."
    },
    {
        "link": "https://builtin.com/data-science/t-test-python",
        "document": "The t-test is a common statistical method used to determine whether there is a significant difference between the means of two groups. In the field of statistics and data analysis, t-tests are widely used to compare sample populations and infer conclusions about the larger population.\n\nIn this article, we will discuss the assumptions of a t-test, its benefits when using Python and how to perform various types of t-tests in Python with examples. We will also provide troubleshooting tips for using t-tests in Python.\n\nWhat Are the Assumptions of a T-Test?\n\nA t-test is based on several assumptions that need to be met for the results to be valid. Violations of these assumptions may lead to incorrect conclusions. These assumptions are:\n\nThe data points in each group should be independent of each other. This means that the outcome of one observation should not affect the outcome of another observation. Independence can be achieved by using random sampling or experimental designs that account for potential confounding factors. In cases where independence can’t be assumed, alternative tests such as mixed-effects models or repeated measures analysis of variance (ANOVA) may be more appropriate.\n\nThe data should follow a normal distribution in each group. Normality can be visually assessed using histograms or quantile-quantile (Q-Q) plots, or tested using formal tests such as the Shapiro-Wilk test or the Kolmogorov-Smirnov test. However, t-tests are relatively robust to violations of normality when the sample size is large. For small sample sizes or severely non-normal data, non-parametric alternatives such as the Mann-Whitney U-test or the Wilcoxon signed-rank test can be used.\n\nThe variances of the two groups should be approximately equal, although there are variations of the t-test that can handle unequal variances. To assess the equality of variances, you can use graphical methods like boxplots, or perform a formal test like Levene’s test or Bartlett’s test. If the variances are not equal, a Welch’s t-test can be used as it does not assume equal variances.\n\nIf these assumptions are not met, the results of the t-test may not be reliable. In these cases, it may be necessary to use a non-parametric test, which does not make these assumptions.\n\nT-tests are a powerful tool for comparing the means of two groups. However, it’s important to make sure that the assumptions of the test are met before using it.\n\nMore on Data Science8 Types of Data Analysis\n\nWhat Are the Steps of a T-Test?\n\nA t-test involves several steps to determine whether there is a significant difference between the means of two groups. These steps include:\n\nStart by formulating a null hypothesis, which states that there is no significant difference between the means of the two groups. You will also need an alternative hypothesis, which states that there is a significant difference between the means.\n\nThe significance level, also known as alpha, is the probability of rejecting the null hypothesis when it is actually true. The most common significance level is 0.05, meaning that there is a 5 percent chance of rejecting the null hypothesis when it is actually true.\n\nCollect the data for both groups and ensure that it meets the assumptions of the t-test: independence of observations, normality and equal variances).\n\nUse the appropriate t-test formula to calculate the t-statistic, which measures the difference between the means of the two groups relative to the variation within the groups.\n\nCalculate the p-value, which represents the probability of obtaining a t-statistic as extreme or more extreme than the observed value, assuming that the null hypothesis is true.\n\nCompare the p-value to the significance level. If the p-value is less than the significance level, reject the null hypothesis and conclude that there is a significant difference between the means of the two groups. If the p-value is greater than the significance level, fail to reject the null hypothesis and conclude that there is no significant difference between the means of the two groups.\n\nUsing Python for t-tests offers several benefits:\n• None Python is a powerful and versatile programming language that can be used for a variety of tasks, including data analysis.\n• None There are several Python libraries available for t-tests, including SciPy and NumPy.\n• None T-tests can be performed quickly and easily in Python.\n• None The results of t-tests can be easily visualized in Python.\n\nIn statistical testing, a one-sample t-test is used when we want to compare a sample mean with a population mean. A one-sample t-test examines whether the mean of a sample is statistically different from a known or hypothesized population mean.\n\nFor instance, consider a hypothetical scenario where we have test scores from a sample of students and we want to compare the mean of these scores with a hypothesized population mean. Let’s assume the population mean is 70.\n\nIn this context, our null hypothesis is that the mean score of our sample is equal to 70 (the population mean). The alternative hypothesis is that the sample mean is not equal to the population mean.\n\nWe can use Python’s SciPy stats package to perform a one-sample t-test. Below is the Python code for this task:\n\nThe function in the code above performs a one-sample t-test and returns two values: the t-statistic and the p-value.\n\nThe t-statistic is a measure that shows the difference between the sample mean and the hypothesized population mean. The greater the absolute value of the t-statistic, the larger the difference between the two means.\n\nThe p-value is a probability that measures the evidence against the null hypothesis. A smaller p-value indicates stronger evidence in favor of the alternative hypothesis. If the p-value is less than our chosen significance level (0.05 in this case), we reject the null hypothesis, suggesting there is a significant difference between the sample mean and the hypothesized population mean.\n\nIf the p-value is greater than our significance level, we fail to reject the null hypothesis, suggesting there is no significant difference between the sample mean and the hypothesized population mean.\n\nThis way, by performing a one-sample t-test, we can determine whether the mean of a sample is significantly different from a given population mean.\n\nIn this case, our p-value (0.0478) is less than the significance level (0.05). Therefore, we reject the null hypothesis and conclude that there is a significant difference between the sample mean and the hypothesized population mean of 70. This suggests that the mean test score of our sample of students is significantly different from the population mean.\n\nTo demonstrate the use of a t-test, we will use the famous “Iris” data set available in the Seaborn library. The Iris data set contains information on 150 iris flowers from three different species (setosa, versicolor, and virginica), with 50 samples from each species. The data set has four features: sepal length, sepal width, petal length and petal width.\n\nIn this example, we will perform a t-test to compare the mean petal lengths of iris setosa and iris versicolor.\n\nThis t-test compares the mean petal lengths of iris setosa and iris versicolor. The obtained p-value, which is approximately 5.40e-62 indicates that there is a significant difference between the two species.\n\nMore on Data ScienceAn Introduction to the Confusion Matrix in Python\n\nTips for Using T-Test in Python\n• None Ensure that your data meets the assumptions of the t-test before proceeding with the analysis. If your data violates any of the assumptions, consider using alternative statistical tests.\n• None Remove or impute missing values in your dataset before performing the t-test. Missing values can lead to inaccurate results.\n• None Ensure that the data type of your input is correct. For example, using a list instead of a NumPy array can lead to errors.\n• None Always consider the context of your study when interpreting p-values. A low p-value indicates that the results are statistically significant but does not prove causality or the practical significance of the difference.\n• None Utilize libraries like SciPy and NumPy to simplify the process of performing a t-test and other statistical analyses in Python."
    }
]