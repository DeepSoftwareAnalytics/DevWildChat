[
    {
        "link": "https://realpython.com/python-pyqt-qthread",
        "document": "PyQt graphical user interface (GUI) applications have a main thread of execution that runs the event loop and GUI. If you launch a long-running task in this thread, then your GUI will freeze until the task terminates. During that time, the user won’t be able to interact with the application, resulting in a bad user experience. Luckily, PyQt’s class allows you to work around this issue.\n\nIn this tutorial, you’ll learn how to:\n• Use best practices for developing GUI applications with PyQt’s thread support\n\nFor a better understanding of how to use PyQt’s threads, some previous knowledge of GUI programming with PyQt and Python multithreaded programming would be helpful.\n\nLong-running tasks occupying the main thread of a GUI application and causing the application to freeze is a common issue in GUI programming that almost always results in a bad user experience. For example, consider the following GUI application: Say you need the Counting label to reflect the total number of clicks on the Click me! button. Clicking the Long-Running Task! button will launch a task that takes a lot of time to finish. Your long-running task could be a file download, a query to a large database, or any other resource-intensive operation. Here’s a first approach to coding this application using PyQt and a single thread of execution: In this Freezing GUI application, creates all the required graphical components for the GUI. A click on the Click me! button calls , which makes the text of the Counting label reflect the number of button clicks. Note: PyQt was first developed to target Python 2, which has an keyword. To avoid a name conflict on those earlier versions of PyQt, an underscore was added to the end of . Even though PyQt5 targets only Python 3, which doesn’t have an keyword, the library provides two methods to start an application’s event loop: Both variations of the method work the same, so you can use either one in your applications. Clicking the Long-Running Task! button calls , which performs a task that takes seconds to complete. This is a hypothetical task that you coded using , which suspends the execution of the calling thread for the given number of seconds, . In , you also call to make the Long-Running Step label reflect the progress of the operation. Does this application work as you intend? Run the application and check out its behavior: When you click the Click me! button, the label shows the number of clicks. However, if you click the Long-Running Task! button, then the application becomes frozen and unresponsive. The buttons no longer respond to clicks and the labels don’t reflect the application’s state. After five seconds, the application’s GUI gets updated again. The Counting label shows ten clicks, reflecting five clicks that occurred while the GUI was frozen. The Long-Running Step label doesn’t reflect the progress of your long-running operation. It jumps from zero to five without showing the intermediate steps. Note: Even though your application’s GUI freezes during the long-running task, the application still registers events such as clicks and keystrokes. It’s just unable to process them until the main thread gets released. The application’s GUI freezes as a result of a blocked main thread. The main thread is busy processing a long-running task and doesn’t immediately respond to the user’s actions. This is an annoying behavior because the user doesn’t know for sure if the application is working correctly or if it’s crashed. Fortunately, there are some techniques you can use to work around this issue. A commonly used solution is to run your long-running task outside of the application’s main thread using a worker thread. In the sections below, you’ll learn how to use PyQt’s built-in thread support to solve the issue of unresponsive or frozen GUIs and provide the best possible user experience in your applications.\n\nSometimes you can divide your programs into several smaller subprograms, or tasks, that you can run in several threads. This might make your programs faster, or it might help you improve the user experience by preventing your programs from freezing while executing long-running tasks. A thread is a separate flow of execution. In most operating systems, a thread is a component of a process, and processes can have multiple threads executing concurrently. Each process represents an instance of a program or application that is currently running in a given computer system. You can have as many threads as you need. The challenge is determining the right number of threads to use. If you’re working with I/O-bound threads, then the number of threads will be limited by your available system resources. On the other hand, if you’re working with CPU-bound threads, then you’ll benefit from having a number of threads that is equal to or less than the number of CPU cores in your system. Building programs that are capable of running multiple tasks using different threads is a programming technique known as multithreaded programming. Ideally, with this technique, several tasks run independently at the same time. However, this isn’t always possible. There are at least two elements that can prevent a program from running several threads in parallel: For example, if you have a single-core CPU machine, then you can’t run multiple threads at the same time. However, some single-core CPUs can simulate parallel thread execution by allowing the operating system to schedule the processing time between multiple threads. This makes your threads appear to run in parallel even though they’re really running one at a time. On the other hand, if you have a multi-core CPU machine or a computer cluster, then you might be able to run multiple threads at the same time. In this case, your programming language becomes an important factor. Some programming languages have internal components that actually prohibit the real execution of multiple threads in parallel. In these cases, threads just appear to run in parallel because they take advantage of the task scheduling system. Multithreaded programs are usually more difficult to write, maintain, and debug than single-threaded programs because of the complexity related to sharing resources between threads, synchronizing data access, and coordinating thread execution. This can cause several problems:\n• Race condition is when the application’s behavior becomes nondeterministic due to the unpredictable order of events. It’s often the result of two or more threads accessing a shared resource without proper synchronization. For example, reading and writing memory from different threads can lead to a race condition if the reading and writing operations are performed in the wrong order.\n• Deadlock happens when threads wait indefinitely for a locked resource to be freed. For example, if a thread locks a resource and doesn’t unlock it after use, then other threads won’t be able to use that resource and will wait indefinitely. Deadlocks can also happen if thread A is waiting for thread B to unlock a resource, and thread B is waiting for thread A to unlock a different resource. Both threads will end up waiting forever.\n• Livelock is a situation in which two or more threads repeatedly act in response to each other’s actions. Livelocked threads are unable to make further progress on their specific task because they’re too busy responding to each other. However, they’re not blocked or dead.\n• Starvation happens when a process never gains access to the resources it needs for finishing its work. For example, if you have a process that can’t gain CPU time access, then the process is starving for CPU time and can’t do its work. When building multithreaded applications, you need to be careful to protect your resources from concurrent writing or state modification access. In other words, you need to prevent multiple threads from accessing a given resource at the same time. A wide range of applications can benefit from using multithreaded programming in at least three ways:\n• Making your applications faster by taking advantage of multi-core processors\n• Simplifying the application structure by dividing it into smaller subtasks\n• Keeping your application responsive and up to date by offloading long-running tasks to worker threads In Python’s C implementation, also known as CPython, threads don’t run in parallel. CPython has a global interpreter lock (GIL), which is a lock that basically allows only one Python thread to run at a time. This can negatively affect the performance of threaded Python applications because of the overhead that results from the context switching between threads. However, multithreading in Python can help you solve the problem of freezing or unresponsive applications while processing long-running tasks.\n\nQt, and therefore PyQt, provides its own infrastructure to create multithreaded applications using . PyQt applications can have two different kinds of threads: The application’s main thread always exists. This is where the application and its GUI run. On the other hand, the existence of worker threads depends on the application’s processing needs. For example, if your application commonly runs heavy tasks that take a lot of time to finish, then you might want to have worker threads to run those tasks and avoid freezing the application’s GUI. In PyQt applications, the main thread of execution is also known as the GUI thread because it handles all widgets and other GUI components. Python starts this thread when you run the application. The application’s event loop runs in this thread after you call on the object. This thread handles your windows, dialogs, and also the communication with the host operating system. By default, any event or task that takes place in the application’s main thread, including the user’s events on the GUI itself, will run synchronously, or one task after another. So, if you start a long-running task in the main thread, then the application needs to wait for that task to finish, and the GUI becomes unresponsive. It’s important to note that you must create and update all your widgets in the GUI thread. However, you can execute other long-running tasks in worker threads and use their results to feed the GUI components of your application. This means that GUI components will act as consumers that are fed information from the threads performing the actual work. You can create as many worker threads as you need in your PyQt applications. Worker threads are secondary threads of execution that you can use to offload long-running tasks from the main thread and prevent GUI freezing. You can create worker threads using . Each worker thread can have its own event loop and support PyQt’s signals and slots mechanism to communicate with the main thread. If you create an object from any class that inherits from in a particular thread, then that object is said to belong to, or have an affinity to, that thread. Its children must also belong to the same thread. isn’t a thread itself. It’s a wrapper around an operating system thread. The real thread object is created when you call . provides a high-level application programming interface (API) to manage threads. This API includes signals, such as and , that are emitted when the thread starts and finishes. It also includes methods and slots, such as , , , , , and . Like with any other threading solutions, with you must protect your data and resources from concurrent, or simultaneous, access. Otherwise you’ll face a lot of problems, including deadlocks, data corruption, and so on.\n\nA common use for threads in a GUI application is to offload long-running tasks to worker threads so that the GUI remains responsive to the user’s interactions. In PyQt, you use to create and manage worker threads. According to Qt’s documentation, there are two main ways to create worker threads with :\n• Instantiate directly and create a worker , then call on the worker using the thread as an argument. The worker must contain all the required functionality to execute a specific task.\n• Subclass and reimplement . The implementation of must contain all the required functionality to execute a specific task. Instantiating provides a parallel event loop. An event loop allows objects owned by the thread to receive signals on their slots, and these slots will be executed within the thread. On the other hand, subclassing allows running parallel code without an event loop. With this approach, you can always create an event loop by calling exec() explicilty. In this tutorial, you’ll use the first approach, which requires the following steps:\n• Prepare a worker object by subclassing and put your long-running task in it.\n• Create a new instance of the worker class.\n• Move the worker object into the newly created thread by calling .\n• Connect the required signals and slots to guarantee interthread communication. You can turn your Freezing GUI application into a Responsive GUI application using these steps: First, you do some required imports. Then you run the steps that you saw before. In step 1, you create , a subclass of . In , you create two signals, and . Note that you must create signals as class attributes. You also create a method called , where you put all the required code to perform your long-running task. In this example, you simulate a long-running task using a loop that iterates times, with a one-second delay in each iteration. The loop also emits the signal, which indicates the operation’s progress. Finally, emits the signal to point out that the processing has finished. In steps 2 to 4, you create an instance of , which will provide the space for running this task, as well as an instance of . You move your worker object to the thread by calling on , using as an argument. In step 5, you connect the following signals and slots:\n• The thread’s signal to the worker’s slot to ensure that when you start the thread, will be called automatically\n• The worker’s signal to the thread’s slot to quit when finishes its work\n• The signal to the slot in both objects to delete the worker and the thread objects when the work is done Finally, in step 6, you start the thread using . Once you have the thread running, you do some resets to make the application behave coherently. You disable the Long-Running Task! button to prevent the user from clicking it while the task is running. You also connect the thread’s signal with a function that enables the Long-Running Task! button when the thread finishes. Your final connection resets the text of the Long-Running Step label. If you run this application, then you’ll get the following window on your screen: Since you offloaded the long-running task to a worker thread, your application is now fully responsive. That’s it! You’ve successfully used PyQt’s to solve the frozen GUI issue that you saw in previous sections.\n\nIf your GUI applications rely heavily on multithreading, then you’ll face significant overhead related to creating and destroying threads. You’ll also have to consider how many threads you can start on a given system so that your applications remain efficient. Fortunately, PyQt’s thread support provides you with a solution to these issues, too. Each application has a global thread pool. You can get a reference to it by calling . Note: Even though using the default thread pool is a fairly common choice, you can also create your own thread pool by instantiating , which provides a collection of reusable threads. The global thread pool maintains and manages a suggested number of threads generally based on the number of cores in your current CPU. It also handles the queuing and execution of tasks in your application’s threads. The threads in the pool are reusable, which prevents the overhead associated with creating and destroying threads. To create tasks and run them in a thread pool, you use . This class represents a task or piece of code that needs to be run. The process of creating and executing runnable tasks involves three steps:\n• Subclass and reimplement with the code for the task that you want to run.\n• Instantiate the subclass of to create a runnable task.\n• Call with the runnable task as an argument. must contain the required code for the task at hand. The call to launches your task in one of the available threads in the pool. If there’s no available thread, then puts the task in the pool’s run queue. When a thread becomes available, the code within gets executed in that thread. Here’s a GUI application that shows how you can implement this process in your code: # Your long-running task goes here ...\n• On lines 19 to 28, you subclass and reimplement with the code you want to execute. In this case, you use the usual loop for simulating a long-running task. The call to notifies you about the operation’s progress by printing a message to your terminal screen.\n• On line 52, you get the number of available threads. This number will depend on your specific hardware and is normally based on the cores of your CPU.\n• On line 53, you update the text of the label to reflect how many threads you can run.\n• On line 55, you start a loop that iterates over the available threads.\n• On line 57, you instantiate , passing the loop variable as an argument to identify the current thread. Then you call on the thread pool, using your runnable task as an argument. It’s important to note that some of the examples in this tutorial use with a basic configuration to print messages to the screen. You need to do this because isn’t a thread-safe function, so using it might cause a mess in your output. Fortunately, the functions in are thread safe, so you can use them in multithreaded applications. If you run this application, then you’ll get the following behavior: When you click the Click me! button, the application launches up to four threads. In the background terminal, the application reports the progress of each thread. If you close the application, then the threads will continue running until they finish their respective tasks. There’s no way of stopping a object from the outside in Python. To work around this, you can create a global Boolean variable and systematically check it from inside your subclasses to terminate them when your variable becomes . Another drawback of using and is that doesn’t support signals and slots, so interthread communication can be challenging. On the other hand, automatically manages a thread pool and handles the queuing and execution of runnable tasks in those threads. The threads in the pool are reusable, which helps reduce your application’s overhead.\n\nIf you’re doing multithreaded programming with PyQt, then you might need to establish communication between your application’s main thread and your worker threads. This allows you to get feedback on the progress of worker threads and update the GUI accordingly, send data to your threads, allow the users to interrupt the execution, and so on. PyQt’s signals and slots mechanism provides a robust and safe way of communicating with worker threads in a GUI application. On the other hand, you might also need to establish communication between worker threads, such as sharing buffers of data or any other kind of resource. In this case, you need to make sure that you’re properly protecting your data and resources from concurrent access. A thread-safe object is an object that can be accessed concurrently by multiple threads and is guaranteed to be in a valid state. PyQt’s signals and slots are thread safe, so you can use them to establish interthread communication as well as to share data between threads. You can connect signals emitted from a thread to slots within the thread or within a different thread. This means that you can execute code in a thread as a response to a signal emitted in the same thread or in another thread. This establishes a safe bridge of communication between threads. Signals can also contain data, so if you emit a signal that holds data, then you’ll receive that data in all the slots connected to the signal. In the Responsive GUI application example, you used the signals and slots mechanism to establish communication between threads. For example, you connected the worker’s signal to the application’s slot. holds an integer value indicating the long-running task’s progress, and receives that value as an argument so it can update the Long-Running Step label. Establishing connections between signals and slots in different threads is the foundation of interthread communication in PyQt. At this point, a good exercise for you to try might be to use a object instead of the Long-Running Step label to show the progress of the operation in the Responsive GUI application using signals and slots. Creating multithreaded applications often requires that multiple threads have access to the same data or resources. If multiple threads access the same data or resource concurrently, and at least one of them writes or modifies this shared resource, then you might face crashes, memory or data corruption, deadlocks, or other issues. There are at least two approaches that allow you to protect your data and resources against concurrent access:\n• Avoid shared state with the following techniques:\n• Synchronize access to a shared state with the following techniques: If you need to share resources, then you should use the second approach. Atomic operations are carried out in a single execution step, so they can’t be interrupted by other threads. They ensure that only one thread will modify a resource at a given time. Note: For a reference on how CPython manages atomic operations, check out What kinds of global value mutation are thread-safe? Note that other Python implementations may behave differently, so if you’re using a different implementation, then take a look at its documentation for further detail on atomic operations and thread safety. Mutual exclusion is a common pattern in multithreaded programming. Access to data and resources is protected using locks, which are a synchronization mechanism that typically allows only one thread to access a resource at a given time. For example, if thread A needs to update a global variable, then it can acquire a lock on that variable. This prevents thread B from accessing the variable at the same time. Once thread A finishes updating the variable, it releases the lock, and thread B can access the variable. This is based on the principle mutual exclusion, which enforces synchronized access by making threads wait for one another when accessing data and resources. It’s important to mention that using locks has a significant cost and can reduce the overall performance of your application. Thread synchronization forces most threads to wait until a resource becomes available, so you won’t be taking advantage of parallel execution anymore. PyQt provides a few convenient classes for protecting resources and data from concurrent access:\n• is a lock class that allows you to manage mutual exclusion. You can lock a mutex in a given thread to gain exclusive access to a shared resource. Once the mutex is unlocked, other threads can get access to the resource.\n• is similar to but distinguishes between reading and writing access. With this type of lock, you can allow multiple threads to have simultaneous read-only access to a shared resource. If a thread needs to write to the resource, then all other threads must be blocked until the writing is complete.\n• is a generalization of that protects a certain number of identical resources. If a semaphore is protecting n resources, and you try to lock n + 1 resources, then the semaphore gets blocked, preventing threads from accessing the resources. With PyQt’s lock classes, you can secure your data and resources and prevent a lot of problems. The next section shows an example of how to use for these purposes. is commonly used in multithreaded PyQt applications to prevent multiple threads from accessing shared data and resources concurrently. In this section, you’ll code a GUI application that uses a object to protect a global variable from concurrent write access. To learn how to use , you’ll code an example that manages a bank account from which two people can withdraw money at any time. In this case, you need to protect the account balance from parallel access. Otherwise, people could end up withdrawing more money than they have in the bank. For example, suppose you have an account with $100. Two people check the available balance at the same time and see that the account has $100. They each think that they can withdraw $60 and leave $40 in the account, so they proceed with the transaction. The resulting balance in the account will be -$20, which might be a significant problem. To code the example, you’ll start by importing the required modules, functions, and classes. You also add a basic configuration and define two global variables: is a global variable that you’ll use to store the current balance in the bank account. is a object that you’ll use to protect from parallel access. In other words, with , you’ll prevent multiple threads from accessing at the same time. The next step is to create a subclass of that holds the code for managing how to withdraw money from the bank account. You’ll call that class : In , you first define two signals:\n• indicates when the class processes its work.\n• indicates when gets updated. Then you define . In this method, you do the following:\n• Show a message that points out the person who wants to withdraw some money\n• Use a statement to use from within\n• Call on to acquire the lock and protect the from parallel access\n• Check if the account balance allows withdrawing the amount at hand\n• Call to simulate that the operation takes some time to complete\n• Decrement the balance by the required amount of money\n• Show messages to notify if the transaction was accepted or not\n• Emit the signal to notify that the balance has been updated\n• Release the lock to allow other threads to access\n• Emit the signal to notify that the operation has finished This application will show a window like this: Here’s the required code for creating this GUI: The Current Balance label shows the account’s available balance. If you click the Withdraw Money! button, then the application will simulate two people trying to withdraw money from the account at the same time. You’ll simulate these two people using threads: This method contains the required code for creating a thread for each person. In this example, you connect the thread’s signal with the worker’s , so when the thread starts, this method will run automatically. You also connect the worker’s signal to a method called . This method will update the Current Balance label with the current account . Anytime a person withdraws money, the account’s balance gets reduced by the requested amount. This method updates the text of the Current Balance label to reflect the changes in the account balance. To complete the application, you need to create the two people and start a thread for each of them: First, you add as an instance attribute to the initializer of your . This variable will hold a list of threads to prevent the threads from getting out of scope once returns. Then you define to create two people and a thread for each of them. In , you perform the following operations:\n• Clear the thread in if any to remove threads that have been destroyed already\n• Create a dictionary containing two people, and . Each person will try to withdraw a random amount of money from the bank account\n• Create a thread for each person using a list comprehension and With this last piece of code, you’re almost done. You just need to create the application and the window and then run the event loop: If you run this application from your command line, then you’ll get the following behavior: The output in the background terminal shows that the threads work. Using a object in this example allows you to protect the bank account balance and synchronize the access to it. This prevents users from withdrawing an amount of money that exceeds the available balance."
    },
    {
        "link": "https://stackoverflow.com/questions/41026032/pyqt5-how-to-send-a-signal-to-a-worker-thread",
        "document": "How do you send a signal to a worker thread? Exactly the same way as sending a signal from a worker thread to the GUI. I expected it to be more different.\n\n@three-pineapples linked to an excellent example of bi-directional communication between the main thread and a worker thread.\n\nIf you want to create a custom signal in the main GUI thread, you need to make sure you inherit QObject and then you'll be able to create custom signals.\n\nI updated my code in the original post to include the UI file so you can run it, and I included an example of a custom signal in the GUI thread that sends a signal to the worker.\n\nHowever you will not see the output of the print statement until the for loop has finished as it blocks the worker from processing signals, as @three-pineapples also stated.\n\nSo, although it's not the best example, hopefully if someone is having the same trouble understanding the concept, maybe this will help."
    },
    {
        "link": "https://sihabsahariar.medium.com/a-comprehensive-pyqt5-tutorial-on-qthread-and-qthreadpool-66aa5b768496",
        "document": "PyQt5 is a Python binding of the cross-platform GUI toolkit Qt, implemented as a Python plug-in. It allows developers to create powerful and versatile graphical user interfaces (GUIs) with Python. One of the key features of PyQt5 is its ability to work with threads.\n\nMultithreading is a programming technique that allows a single program to run multiple threads concurrently. This can be useful for tasks that take a long time to complete, such as network communication or file operations, as it allows the program to perform other tasks while waiting for the long-running task to complete.\n\nIn PyQt5, there are several ways to work with threads. In this article, we will cover two common approaches: using the class and the class.\n\nThe class is a subclass of and is used to create and manage threads. To use a , you need to subclass it and implement the method. This method contains the code that will be executed in the separate thread.\n\nHere is a simple example of how to use to run a long-running task in a separate thread:\n\nThis code creates a PyQt5 application with a main window that contains a progress bar and a start button. When the start button is clicked, a worker thread is started that runs a task that takes a certain amount of time to complete. The task updates the progress bar as it runs and emits a signal when it has completed.\n\nThe worker is implemented as a QObject subclass called . It has two signals: and . The method is decorated with the decorator, which means that it can be connected to a signal and run in a separate thread.\n\nThe class is a subclass of and has a method that is called when the start button is clicked. This method disables the start button, sets the maximum value of the progress bar, and emits a signal with the number of steps in the task.\n\nThe method is called when the signal is emitted from the worker and updates the value of the progress bar. The method is called when the signal is emitted from the worker and updates the value of the progress bar and re-enables the start button.\n\nThe worker is moved to a separate thread using the method and the thread is started using the method.\n\nFinally, the main window is shown and the PyQt5 application event loop is started using\n\nThe class is a global thread pool that can be used to run tasks in separate threads. To use it, you need to create a object and pass it to the method of the object.\n\nHere is an example of how to use to run a long-running task in a separate thread:\n\nThis code creates a PyQt5 application with a main window that contains a button. When the button is clicked, it starts a worker task in a separate thread using the class. The worker task simply prints a message and sleeps for a short time each iteration, for a total of nine iterations.\n\nThe class subclasses and overrides the method. This method contains the code that will be executed in the separate thread. The class subclasses and sets up the user interface with a button. When the button is clicked, the method is called. The method creates an instance of the class and passes it to the method of the global object. This will execute the method of the class in a separate thread. Finally, the main function creates an instance of the class and starts the PyQt5 application event loop using .\n\nand are two different approaches to working with threads in PyQt5.\n\nis a subclass of that is used to create and manage threads. To use it, you need to subclass and implement the method, which contains the code that will be executed in the separate thread.\n\nis a global thread pool that can be used to run tasks in separate threads. To use it, you need to create a object and pass it to the method of the object.\n\nBoth and can be used to run long-running tasks in separate threads, but there are some key differences between them:\n• is more flexible and allows you to create and customize individual threads, while is a generic thread pool that can be used to run any task.\n• is slower to start and stop than , as it involves creating and destroying a new thread each time. , on the other hand, reuses existing threads and can start and stop tasks more quickly.\n• allows you to create threads that can share data and interact with the main thread, while is designed to run tasks in a more isolated manner.\n\nIn general, is better suited for tasks that require more customization and interaction with the main thread, while is better suited for tasks that are more independent and can be run in a generic thread pool."
    },
    {
        "link": "https://forum.qt.io/topic/99182/qthread-create-in-pyqt5",
        "document": "Your browser does not seem to support JavaScript. As a result, your viewing experience will be diminished, and you have been placed in read-only mode.\n\nPlease download a browser that supports JavaScript, or enable it if it's disabled (i.e. NoScript)."
    },
    {
        "link": "https://stackoverflow.com/questions/16879971/example-of-the-right-way-to-use-qthread-in-pyqt",
        "document": "In my opinion, by far the best explanation, with example code which is initially unresponsive, and is then improved, is to be found here.\n\nNote that this does indeed use the desired (non-subclassed) and approach, which the article claims to be the preferred approach.\n\nThe above linked page also provides the PyQt5 equivalent to the C Qt page giving the definitive explanation by Maya Posch from 2011. I think she was probably using Qt4 at the time, but that page is still applicable in Qt5 (hence PyQt5) and well worth studying in depth, including many of the comments (and her replies).\n\nJust in case the first link above one day goes 404 (which would be terrible!), this is the essential Python code which is equivalent to Maya's C code:\n\nNB in the example on that page is the object. I think you may have to be quite careful about what you attach instances to as properties: instances which are destroyed when they go out of scope, but which have a property, or indeed a local instance which goes out of scope, seem to be capable of causing some inexplicable Python crashes, which aren't picked up by (or the ). Caution advised.\n\n... where looks something like this:"
    },
    {
        "link": "https://stackoverflow.com/questions/38544493/python-socket-programming-exception-handling",
        "document": "Since you're doing exactly the same actions in all the exception blocks and catching the same exception, you could put , and in the same block. Like so:\n\nNote that since is also in the section in your example, it will always get called, even after an exception has occurred. So you'd end up with another exception occurring when you try to close an already closed socket. By not putting it in the block and only in , you can avoid that situation.\n\nIf you do intend to handle each error in a different way, then you can leave them separate as you already have. But make sure to / at the end of the exception block so that you don't try the next. It's done that way in the socket examples, by using a in the loop.\n\nNesting them would help if you wanted to do something different in the exception block. But if not you'd be repeating the block every time. And if you wanted to do something different, when you exit the nested- s, you wouldn't be certain of which level it has completed or raised an exception - would need to use flag values etc. to merely track that. So for your example of the same error handling code, at the very least, do something like this in your block:\n\nThey do that in the examples, linked above.\n\nApart from logging, you shouldn't really be doing the same exception handling at each stage. Probably need to handle those separately.\n\nsets the timeout for each socket operation, not just the first connect. Also implies that it's in blocking mode."
    },
    {
        "link": "https://labex.io/tutorials/python-how-to-implement-error-handling-in-python-socket-communication-398023",
        "document": "Now that we understand basic error handling, let's explore some advanced techniques to make our socket applications even more robust. In this step, we'll implement:\n\nLet's create an enhanced client that automatically retries the connection if it fails. Create a new file named in the directory:\n\nimport socket import sys import time ## Define server address and port HOST = '127.0.0.1' PORT = 65432 ## Configure retry parameters MAX_RETRIES = 3 RETRY_DELAY = 2 ## seconds def connect_with_retry(host, port, max_retries, retry_delay): \"\"\"Attempt to connect to a server with retry mechanism\"\"\" client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client_socket.settimeout(5) ## Set timeout for connection attempts print(f\"Socket created successfully\") print(f\"Socket timeout set to 5 seconds\") attempt = 0 while attempt < max_retries: attempt += 1 try: print(f\"Connection attempt {attempt}/{max_retries}...\") client_socket.connect((host, port)) print(f\"Connected to server at {host}:{port}\") return client_socket except socket.timeout: print(f\"Connection attempt timed out\") except ConnectionRefusedError: print(f\"Connection refused. Make sure the server is running.\") except socket.error as e: print(f\"Connection error: {e}\") if attempt < max_retries: print(f\"Retrying in {retry_delay} seconds...\") time.sleep(retry_delay) ## If we get here, all connection attempts failed print(f\"Failed to connect after {max_retries} attempts\") client_socket.close() return None try: ## Attempt to connect with retry client_socket = connect_with_retry(HOST, PORT, MAX_RETRIES, RETRY_DELAY) ## Proceed if connection was successful if client_socket: try: ## Send data to the server message = \"Hello, Server with Retry!\" client_socket.sendall(message.encode('utf-8')) print(f\"Sent: {message}\") ## Receive data from the server data = client_socket.recv(1024) print(f\"Received: {data.decode('utf-8')}\") except socket.error as e: print(f\"Error during data exchange: {e}\") finally: ## Clean up the connection client_socket.close() print(f\"Socket closed\") except KeyboardInterrupt: print(f\"\n\nClient shutting down...\") if 'client_socket' in locals() and client_socket: client_socket.close() print(f\"Socket closed\") sys.exit(0)\n\nLet's create an enhanced server that can handle multiple clients and gracefully handle disconnections. Create a new file named in the same directory:\n\nimport socket import sys import time ## Define server address and port HOST = '127.0.0.1' PORT = 65432 def handle_client(client_socket, client_address): \"\"\"Handle a client connection\"\"\" print(f\"Handling connection from {client_address}\") try: ## Set a timeout for receiving data client_socket.settimeout(30) ## 30 seconds timeout for inactivity ## Receive and echo data while True: try: ## Receive data from the client data = client_socket.recv(1024) if not data: ## If no data is received, the client has disconnected print(f\"Client {client_address} disconnected gracefully\") break print(f\"Received from {client_address}: {data.decode('utf-8')}\") ## Echo the data back to the client client_socket.sendall(data) print(f\"Sent to {client_address}: {data.decode('utf-8')}\") except socket.timeout: print(f\"Connection with {client_address} timed out due to inactivity\") break except ConnectionResetError: print(f\"Connection with {client_address} was reset by the client\") break except socket.error as e: print(f\"Error with client {client_address}: {e}\") break finally: ## Clean up the connection client_socket.close() print(f\"Connection with {client_address} closed\") try: ## Create a socket object server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) print(f\"Socket created successfully\") ## Allow reuse of address server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) ## Bind the socket to the specified address and port server_socket.bind((HOST, PORT)) print(f\"Socket bound to {HOST}:{PORT}\") ## Listen for incoming connections server_socket.listen(5) ## Allow up to 5 pending connections print(f\"Socket is listening for connections\") ## Set timeout for accept operation server_socket.settimeout(60) ## 60 seconds timeout for accept ## Accept connections and handle them while True: try: print(f\"Waiting for a connection...\") client_socket, client_address = server_socket.accept() print(f\"Connected to client: {client_address}\") ## Handle this client handle_client(client_socket, client_address) except socket.timeout: print(f\"No connections received in the last 60 seconds, still waiting...\") except socket.error as e: print(f\"Error accepting connection: {e}\") ## Small delay to prevent CPU hogging in case of persistent errors time.sleep(1) except socket.error as e: print(f\"Socket error occurred: {e}\") except KeyboardInterrupt: print(f\"\n\nServer shutting down...\") finally: ## Clean up the server socket if 'server_socket' in locals(): server_socket.close() print(f\"Server socket closed\") sys.exit(0)\n\nLet's create a server with proper logging capabilities. Create a new file named in the same directory:\n\nimport socket import sys import time import logging ## Configure logging logging.basicConfig( level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[ logging.FileHandler(\"server_log.txt\"), logging.StreamHandler() ] ) ## Define server address and port HOST = '127.0.0.1' PORT = 65432 def handle_client(client_socket, client_address): \"\"\"Handle a client connection with logging\"\"\" logging.info(f\"Handling connection from {client_address}\") try: ## Set a timeout for receiving data client_socket.settimeout(30) ## 30 seconds timeout for inactivity ## Receive and echo data while True: try: ## Receive data from the client data = client_socket.recv(1024) if not data: ## If no data is received, the client has disconnected logging.info(f\"Client {client_address} disconnected gracefully\") break logging.info(f\"Received from {client_address}: {data.decode('utf-8')}\") ## Echo the data back to the client client_socket.sendall(data) logging.info(f\"Sent to {client_address}: {data.decode('utf-8')}\") except socket.timeout: logging.warning(f\"Connection with {client_address} timed out due to inactivity\") break except ConnectionResetError: logging.error(f\"Connection with {client_address} was reset by the client\") break except socket.error as e: logging.error(f\"Error with client {client_address}: {e}\") break finally: ## Clean up the connection client_socket.close() logging.info(f\"Connection with {client_address} closed\") try: ## Create a socket object server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) logging.info(f\"Socket created successfully\") ## Allow reuse of address server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) ## Bind the socket to the specified address and port server_socket.bind((HOST, PORT)) logging.info(f\"Socket bound to {HOST}:{PORT}\") ## Listen for incoming connections server_socket.listen(5) ## Allow up to 5 pending connections logging.info(f\"Socket is listening for connections\") ## Set timeout for accept operation server_socket.settimeout(60) ## 60 seconds timeout for accept ## Accept connections and handle them while True: try: logging.info(f\"Waiting for a connection...\") client_socket, client_address = server_socket.accept() logging.info(f\"Connected to client: {client_address}\") ## Handle this client handle_client(client_socket, client_address) except socket.timeout: logging.info(f\"No connections received in the last 60 seconds, still waiting...\") except socket.error as e: logging.error(f\"Error accepting connection: {e}\") ## Small delay to prevent CPU hogging in case of persistent errors time.sleep(1) except socket.error as e: logging.critical(f\"Socket error occurred: {e}\") except KeyboardInterrupt: logging.info(f\"Server shutting down...\") finally: ## Clean up the server socket if 'server_socket' in locals(): server_socket.close() logging.info(f\"Server socket closed\") sys.exit(0)\n• Test the retry mechanism by running the retry client without a server: You should see the client attempting to connect multiple times: Socket created successfully Socket timeout set to 5 seconds Connection attempt 1/3... Connection refused. Make sure the server is running. Retrying in 2 seconds... Connection attempt 2/3... Connection refused. Make sure the server is running. Retrying in 2 seconds... Connection attempt 3/3... Connection refused. Make sure the server is running. Failed to connect after 3 attempts\n• Start the robust server and try connecting with the retry client: You should see a successful connection and data exchange.\n• Test the logging server to see how logs are recorded: After the exchange, you can check the log file: You should see detailed logs of the connection and data exchange.\n\nIn these examples, we've implemented several advanced error handling techniques:\n• Retry mechanisms: Automatically retry failed operations a set number of times with delays between attempts.\n• Structured logging: Use Python's logging module to record detailed information about errors and operations.\n• Resource cleanup: Ensure all resources are properly closed, even in error conditions.\n\nThese techniques help create more robust socket applications that can handle a wide range of error conditions gracefully."
    },
    {
        "link": "https://medium.com/pipedrive-engineering/socket-timeout-an-important-but-not-simple-issue-with-python-4bb3c58386b4",
        "document": "During my experience working with Python, I’ve had several cases where a network client was left hanging while trying to request a server. After spending some time researching, the root cause was identified and it was found that the server was waiting for a response but there was silence (like being ghosted on a Tinder match).\n\nOf course, an operating system can raise a error, but it doesn’t always seem to happen on hang connections. If it did, probably wouldn’t even run into this issue on the job.\n\nIn order to avoid the annoying problem of waiting for an undetermined amount of time, sockets (which are responsible for network communication) support a timeout option which raises an error based on a time limit. Unfortunately, when developers develop their amazing network libraries, they may omit such non-obvious cases and forget to provide socket timeout settings, despite of the docs recommendation:\n\nLet’s look at a simple example of how to simulate hang socket (at a minimum level in Mac OS):\n\nAt this moment, the client is hanging, waiting for the server to enable to connection accepting, like .\n\nIt won’t actually hang for eternity, and after some time should eventually raise a . This happens because the system function timed out at the system level with the error . As mentioned above, it seems the error doesn’t always happen or it could be that the timeout value can be obscenely large. In either case, it’s not controlled in your code. The variant which I will show has been much more reliable for me.\n\nBefore I go into showing issue solution, let’s go deep into Python socket implementation in order to understand why it hangs.\n• is a C-function, which is called on . Its code is clear and we see that it calls ↓\n• function, and this code is harder to understand, but I will give a hint — we are interesting in ↓\n• function, which has an eternal cycle , where socket communication happens and where it tries to wait for an established connection as well.\n• Also in is a processes timeout option in . If a timeout is achieved it returns the error: .\n\nLet’s see how the timeout option helps with a hang socket:\n\nAs said above, this option can be omitted in libraries which use sockets. Fortunately, Python gives you a chance to set up socket timeout for all new sockets, which will be created during application work:\n\nIf this would be enough, the article would finish here. Unfortunately, socket timeout can be reset with a that some libraries do rather rashly.\n\nA solution for this is monkey-patching of the module, like this:\n\nBut in the socket there is another way to reset timeout:\n\nLet’s see what happens under the hood of this method:\n\nHere it changes the timeout, without worrying about its default value. Why it works this way you can read more about in the socket docs, but it’s easy to patch:\n\nNo more hang sockets any longer."
    },
    {
        "link": "https://realpython.com/python-sockets",
        "document": "Socket programming is essential for network communication, enabling data exchange across different devices. In Python, sockets allow for inter-process communication (IPC) over networks. This tutorial provides a comprehensive guide on creating socket servers and clients, handling multiple connections, and managing errors in Python’s module.\n\nBy the end of this tutorial, you’ll understand that:\n• A socket in Python is an endpoint for sending or receiving data across a network using the socket API.\n• Socket programming in Python involves using sockets to establish communication between a server and clients over a network.\n• A simple echo server in Python can be created using sockets to listen for client connections and echo back received messages.\n• Handling multiple clients with Python sockets can be achieved using non-blocking sockets and the module for concurrent connections.\n• Connection errors in socket programs in Python can be managed by implementing error handling and using exceptions like .\n\nAlong the way, you’ll learn about the main functions and methods in Python’s module that let you write your own client-server applications based on TCP sockets. You’ll learn how to reliably send messages and data between endpoints and handle multiple connections simultaneously.\n\nNetworking and sockets are large subjects. Literal volumes have been written about them. If you’re new to sockets or networking, it’s completely normal if you feel overwhelmed with all of the terms and pieces. To get the most out of this tutorial, it’s best to download the source code and have it on hand for reference while reading:\n\nNow that you’ve gotten an overview of the socket API and how the client and server communicate, you’re ready to create your first client and server. You’ll begin with a simple implementation. The server will simply echo whatever it receives back to the client. Here’s the source code of the server: # Port to listen on (non-privileged ports are > 1023) Don’t worry about understanding everything above right now. There’s a lot going on in these few lines of code. This is just a starting point so you can see a basic server in action. Note: There’s a reference section at the end of this tutorial that has more information and links to additional resources. You’ll also find these and other useful links throughout the tutorial. Okay, so what exactly is happening in the API call? creates a socket object that supports the context manager type, so you can use it in a statement. There’s no need to call : # Use the socket object without calling s.close(). The arguments passed to are constants used to specify the address family and socket type. is the Internet address family for IPv4. is the socket type for TCP, the protocol that will be used to transport messages in the network. The method is used to associate the socket with a specific network interface and port number: The values passed to depend on the address family of the socket. In this example, you’re using (IPv4). So it expects a two-tuple: . can be a hostname, IP address, or empty string. If an IP address is used, should be an IPv4-formatted address string. The IP address is the standard IPv4 address for the loopback interface, so only processes on the host will be able to connect to the server. If you pass an empty string, the server will accept connections on all available IPv4 interfaces. represents the TCP port number to accept connections on from clients. It should be an integer from to , as is reserved. Some systems may require superuser privileges if the port number is less than . Here’s a note on using hostnames with : If you use a hostname in the host portion of IPv4/v6 socket address, the program may show a non-deterministic behavior, as Python uses the first address returned from the DNS resolution. The socket address will be resolved differently into an actual IPv4/v6 address, depending on the results from DNS resolution and/or the host configuration. For deterministic behavior use a numeric address in host portion. (Source) You’ll learn more about this later, in Using Hostnames. For now, just understand that when using a hostname, you could see different results depending on what’s returned from the name resolution process. These results could be anything. The first time you run your application, you might get the address . The next time, you get a different address, . The third time, you could get , and so on. In the server example, enables a server to accept connections. It makes the server a listening socket: The method has a parameter. It specifies the number of unaccepted connections that the system will allow before refusing new connections. Starting in Python 3.5, it’s optional. If not specified, a default value is chosen. If your server receives a lot of connection requests simultaneously, increasing the value may help by setting the maximum length of the queue for pending connections. The maximum value is system dependent. For example, on Linux, see . The method blocks execution and waits for an incoming connection. When a client connects, it returns a new socket object representing the connection and a tuple holding the address of the client. The tuple will contain for IPv4 connections or for IPv6. See Socket Address Families in the reference section for details on the tuple values. One thing that’s imperative to understand is that you now have a new socket object from . This is important because it’s the socket that you’ll use to communicate with the client. It’s distinct from the listening socket that the server is using to accept new connections: After provides the client socket object , an infinite loop is used to loop over blocking calls to . This reads whatever data the client sends and echoes it back using . If returns an empty object, , that signals that the client closed the connection and the loop is terminated. The statement is used with to automatically close the socket at the end of the block. Now, it’s time to look at the client’s source code: # The port used by the server In comparison to the server, the client is pretty simple. It creates a socket object, uses to connect to the server and calls to send its message. Lastly, it calls to read the server’s reply and then prints it. In this section, you’ll run the client and server to see how they behave and inspect what’s happening. Note: If you’re having trouble getting the examples or your own code to run from the command line, read How Do I Make My Own Command-Line Commands Using Python? or How to Run Your Python Scripts. If you’re on Windows, check the Python Windows FAQ. Open a terminal or command prompt, navigate to the directory that contains your scripts, ensure that you have Python 3.6 or above installed and on your path, then run the server: Your terminal will appear to hang. That’s because the server is blocked, or suspended, on : It’s waiting for a client connection. Now, open another terminal window or command prompt and run the client: In the server window, you should notice something like this: In the output above, the server printed the tuple returned from . This is the client’s IP address and TCP port number. The port number, , will most likely be different when you run it on your machine. To see the current state of sockets on your host, use . It’s available by default on macOS, Linux, and Windows. Here’s the netstat output from macOS after starting the server: Notice that is . If had used instead of , netstat would show this: is , which means all available host interfaces that support the address family will be used to accept incoming connections. In this example, was used (IPv4) in the call to . You can see this in the column: . The output above is trimmed to show the echo server only. You’ll likely see much more output, depending on the system you’re running it on. The things to notice are the columns , , and . In the last example above, netstat shows that the echo server is using an IPv4 TCP socket ( ), on port 65432 on all interfaces ( ), and it’s in the listening state ( ). Another way to access this, along with additional helpful information, is to use (list open files). It’s available by default on macOS and can be installed on Linux using your package manager, if it’s not already: gives you the , (process ID), and (user ID) of open Internet sockets when used with the option. Above is the echo server process. and have a lot of options available and differ depending on the OS that you’re running them on. Check the page or documentation for both. They’re definitely worth spending a little time with and getting to know. You’ll be rewarded. On macOS and Linux, use and . For Windows, use . Here’s a common error that you’ll encounter when a connection attempt is made to a port with no listening socket: Either the specified port number is wrong or the server isn’t running. Or maybe there’s a firewall in the path that’s blocking the connection, which can be easy to forget about. You may also see the error . Get a firewall rule added that allows the client to connect to the TCP port! There’s a list of common errors in the reference section.\n\nThe echo server definitely has its limitations. The biggest one is that it serves only one client and then exits. The echo client has this limitation too, but there’s an additional problem. When the client uses , it’s possible that it will return only one byte, from : The argument of used above is the maximum amount of data to be received at once. It doesn’t mean that will return bytes. The method also behaves this way. It returns the number of bytes sent, which may be less than the size of the data passed in. You’re responsible for checking this and calling as many times as needed to send all of the data: Applications are responsible for checking that all data has been sent; if only some of the data was transmitted, the application needs to attempt delivery of the remaining data. (Source) In the example above, you avoided having to do this by using : Unlike send(), this method continues to send data from bytes until either all data has been sent or an error occurs. is returned on success. (Source) You have two problems at this point:\n• How do you handle multiple connections concurrently?\n• You need to call and until all data is sent or received. What can you do? There are many approaches to concurrency. A popular approach is to use Asynchronous I/O. was introduced into the standard library in Python 3.4. The traditional choice is to use threads. The trouble with concurrency is it’s hard to get right. There are many subtleties to consider and guard against. All it takes is for one of these to manifest itself and your application may suddenly fail in not-so-subtle ways. This isn’t meant to scare you away from learning and using concurrent programming. If your application needs to scale, it’s a necessity if you want to use more than one processor or one core. However, for this tutorial, you’ll use something that’s even more traditional than threads and easier to reason about. You’re going to use the granddaddy of system calls: . The method allows you to check for I/O completion on more than one socket. So you can call to see which sockets have I/O ready for reading and/or writing. But this is Python, so there’s more. You’re going to use the selectors module in the standard library so that the most efficient implementation is used, regardless of the operating system you happen to be running on: This module allows high-level and efficient I/O multiplexing, built upon the select module primitives. Users are encouraged to use this module instead, unless they want precise control over the OS-level primitives used. (Source) Still, by using , you’re not able to run concurrently. That said, depending on your workload, this approach may still be plenty fast. It depends on what your application needs to do when it services a request, and the number of clients it needs to support. uses single-threaded cooperative multitasking and an event loop to manage tasks. With , you’ll be writing your own version of an event loop, albeit more simply and synchronously. When using multiple threads, even though you have concurrency, you currently have to use the GIL (Global Interpreter Lock) with CPython and PyPy. This effectively limits the amount of work you can do in parallel anyway. This is all to say that using may be a perfectly fine choice. Don’t feel like you have to use , threads, or the latest asynchronous library. Typically, in a network application, your application is I/O bound anyway: it could be waiting on the local network, for endpoints on the other side of the network, for disk writes, and so forth. If you’re getting requests from clients that initiate CPU bound work, look at the concurrent.futures module. It contains the class ProcessPoolExecutor, which uses a pool of processes to execute calls asynchronously. If you use multiple processes, the operating system is able to schedule your Python code to run in parallel on multiple processors or cores, without the GIL. For ideas and inspiration, see the PyCon talk John Reese - Thinking Outside the GIL with AsyncIO and Multiprocessing - PyCon 2018. In the next section, you’ll look at examples of a server and client that address these problems. They use to handle multiple connections simultaneously and call and as many times as needed.\n\nIn the next two sections, you’ll create a server and client that handles multiple connections using a object created from the selectors module. First, turn your attention to the multi-connection server. The first part sets up the listening socket: The biggest difference between this server and the echo server is the call to to configure the socket in non-blocking mode. Calls made to this socket will no longer block. When it’s used with , as you’ll see below, you can wait for events on one or more sockets and then read and write data when it’s ready. registers the socket to be monitored with for the events that you’re interested in. For the listening socket, you want read events: . To store whatever arbitrary data you’d like along with the socket, you’ll use . It’s returned when returns. You’ll use to keep track of what’s been sent and received on the socket. blocks until there are sockets ready for I/O. It returns a list of tuples, one for each socket. Each tuple contains a and a . The is a SelectorKey that contains a attribute. is the socket object, and is an event mask of the operations that are ready. If is , then you know it’s from the listening socket and you need to accept the connection. You’ll call your own function to get the new socket object and register it with the selector. You’ll look at that in a moment. If is not , then you know it’s a client socket that’s already been accepted, and you need to service it. is then called with and as arguments, and that’s everything you need to operate on the socket. Here’s what your function does: # Should be ready to read Because the listening socket was registered for the event , it should be ready to read. You call and then call to put the socket in non-blocking mode. Remember, this is the main objective in this version of the server because you don’t want it to block. If it blocks, then the entire server is stalled until it returns. That means other sockets are left waiting even though the server isn’t actively working. This is the dreaded “hang” state that you don’t want your server to be in. Next, you create an object to hold the data that you want included along with the socket using a . Because you want to know when the client connection is ready for reading and writing, both of those events are set with the bitwise OR operator: # Should be ready to read The mask, socket, and data objects are then passed to . Now take a look at to see how a client connection is handled when it’s ready: # Should be ready to read # Should be ready to write This is the heart of the simple multi-connection server. is the returned from that contains the socket object ( ) and data object. contains the events that are ready. If the socket is ready for reading, then will evaluate to , so is called. Any data that’s read is appended to so that it can be sent later. Note the block to check if no data is received: # Should be ready to read # Should be ready to write If no data is received, this means that the client has closed their socket, so the server should too. But don’t forget to call before closing, so it’s no longer monitored by . When the socket is ready for writing, which should always be the case for a healthy socket, any received data stored in is echoed to the client using . The bytes sent are then removed from the send buffer: # Should be ready to write The method returns the number of bytes sent. This number can then be used with slice notation on the buffer to discard the bytes sent. Now take a look at the multi-connection client, . It’s very similar to the server, but instead of listening for connections, it starts by initiating connections via : is read from the command-line and is the number of connections to create to the server. Just like the server, each socket is set to non-blocking mode. You use instead of because would immediately raise a exception. The method initially returns an error indicator, , instead of raising an exception that would interfere with the connection in progress. Once the connection is completed, the socket is ready for reading and writing and is returned by . After the socket is set up, the data you want to store with the socket is created using . The messages that the client will send to the server are copied using because each connection will call and modify the list. Everything needed to keep track of what the client needs to send, has sent, and has received, including the total number of bytes in the messages, is stored in the object . Check out the changes made from the server’s for the client’s version: def service_connection(key, mask): sock = key.fileobj data = key.data if mask & selectors.EVENT_READ: recv_data = sock.recv(1024) # Should be ready to read if recv_data: + if not recv_data or data.recv_total == data.msg_total: sel.unregister(sock) sock.close() if mask & selectors.EVENT_WRITE: + if not data.outb and data.messages: if data.outb: sent = sock.send(data.outb) # Should be ready to write data.outb = data.outb[sent:] It’s fundamentally the same but for one important difference. The client keeps track of the number of bytes it’s received from the server so that it can close its side of the connection. When the server detects this, it closes its side of the connection too. By doing this, the server depends on the client being well-behaved: the server expects the client to close its side of the connection when it’s done sending messages. If the client doesn’t close, the server will leave the connection open. In a real application, you may want to guard against this in your server by implementing a timeout to prevent client connections from accumulating if they don’t send a request after a certain amount of time. Now it’s time to run and . They both use command-line arguments. You can run them without arguments to see the options. For the server, pass and numbers: For the client, also pass the number of connections to create to the server, : Below is the server output when listening on the loopback interface on port 65432: python multiconn-server.py .0.0.1 Echoing b'Message 1 from client.Message 2 from client.' to ('127.0.0.1', 61354) Echoing b'Message 1 from client.Message 2 from client.' to ('127.0.0.1', 61355) Below is the client output when it creates two connections to the server above: python multiconn-client.py .0.0.1 Received b'Message 1 from client.Message 2 from client.' from connection 1 Received b'Message 1 from client.Message 2 from client.' from connection 2 Great! Now you’ve run the multi-connection client and server. In the next section, you’ll take this example even further.\n\nThe multi-connection client and server example is definitely an improvement compared with where you started. However, now you can take one more step and address the shortcomings of the previous example in a final implementation: the application client and server. You want a client and server that handle errors appropriately so that other connections aren’t affected. Obviously, your client or server shouldn’t come crashing down in a ball of fury if an exception isn’t caught. This is something you haven’t had to worry about until now, because the examples have intentionally left out error handling for brevity and clarity. Now that you’re familiar with the basic API, non-blocking sockets, and , you can add some error handling and address the elephant in the room, which the examples have kept hidden from you behind that large curtain over there. Remember that custom class that was mentioned way back in the introduction? That’s what you’re going to explore next. All errors raise exceptions. The normal exceptions for invalid argument types and out-of-memory conditions can be raised; starting from Python 3.3, errors related to socket or address semantics raise or one of its subclasses. (Source) So, one thing you need to do is catch . Another important consideration in relation to errors is timeouts. You’ll see them discussed in many places in the documentation. Timeouts happen and are a so-called normal error. Hosts and routers are rebooted, switch ports go bad, cables go bad, cables get unplugged, you name it. You should be prepared for these and other errors, handling them in your code. What about the elephant in the room? As hinted by the socket type , when using TCP, you’re reading from a continuous stream of bytes. It’s like reading from a file on disk, but instead you’re reading bytes from the network. However, unlike reading a file, there’s no . In other words, you can’t reposition the socket pointer, if there was one, and move around the data. When bytes arrive at your socket, there are network buffers involved. Once you’ve read them, they need to be saved somewhere, or else you will have dropped them. Calling again reads the next stream of bytes available from the socket. You’ll be reading from the socket in chunks. So, you need to call and save the data in a buffer until you’ve read enough bytes to have a complete message that makes sense to your application. It’s up to you to define and keep track of where the message boundaries are. As far as the TCP socket is concerned, it’s just sending and receiving raw bytes to and from the network. It knows nothing about what those raw bytes mean. This is why you need to define an application-layer protocol. What’s an application-layer protocol? Put simply, your application will send and receive messages. The format of these messages are your application’s protocol. In other words, the length and format that you choose for these messages define the semantics and behavior of your application. This is directly related to what you learned in the previous paragraph regarding reading bytes from the socket. When you’re reading bytes with , you need to keep up with how many bytes were read, and figure out where the message boundaries are. How can you do this? One way is to always send fixed-length messages. If they’re always the same size, then it’s easy. When you’ve read that number of bytes into a buffer, then you know you have one complete message. However, using fixed-length messages is inefficient for small messages where you’d need to use padding to fill them out. Also, you’re still left with the problem of what to do about data that doesn’t fit into one message. In this tutorial, you’ll learn a generic approach, one that’s used by many protocols, including HTTP. You’ll prefix messages with a header that includes the content length as well as any other fields you need. By doing this, you’ll only need to keep up with the header. Once you’ve read the header, you can process it to determine the length of the message’s content. With the content length, you can then read that number of bytes to consume it. You’ll implement this by creating a custom class that can send and receive messages that contain text or binary data. You can improve and extend this class for your own applications. The most important thing is that you’ll be able to see an example of how this is done. Before you get started, there’s something you need to know regarding sockets and bytes. As you learned earlier, when sending and receiving data via sockets, you’re sending and receiving raw bytes. If you receive data and want to use it in a context where it’s interpreted as multiple bytes, for example a 4-byte integer, you’ll need to take into account that it could be in a format that’s not native to your machine’s CPU. The client or server on the other end could have a CPU that uses a different byte order than your own. If this is the case, then you’ll need to convert it to your host’s native byte order before using it. This byte order is referred to as a CPU’s endianness. See Byte Endianness in the reference section for details. You’ll avoid this issue by taking advantage of Unicode for your message header and using the encoding UTF-8. Since UTF-8 uses an 8-bit encoding, there are no byte ordering issues. You can find an explanation in Python’s Encodings and Unicode documentation. Note that this applies to the text header only. You’ll use an explicit type and encoding defined in the header for the content that’s being sent, the message payload. This will allow you to transfer any data that you’d like (text or binary), in any format. You can easily determine the byte order of your machine by using . For example, you could see something like this: If you run this in a virtual machine that emulates a big-endian CPU (PowerPC), then something like this happens: In this example application, your application-layer protocol defines the header as Unicode text with a UTF-8 encoding. For the actual content in the message, the message payload, you’ll still have to swap the byte order manually if needed. This will depend on your application and whether or not it needs to process multi-byte binary data from a machine with a different endianness. You can help your client or server implement binary support by adding additional headers and using them to pass parameters, similar to HTTP. Don’t worry if this doesn’t make sense yet. In the next section, you’ll see how all of this works and fits together. Now you’ll fully define the protocol header. The protocol header is: The required headers, or sub-headers, in the protocol header’s dictionary are as follows: The byte order of the machine (uses ). This may not be required for your application. The length of the content in bytes. The type of content in the payload, for example, or . The encoding used by the content, for example, for Unicode text or for binary data. These headers inform the receiver about the content in the payload of the message. This allows you to send arbitrary data while providing enough information so that the content can be decoded and interpreted correctly by the receiver. Because the headers are in a dictionary, it’s easy to add additional headers by inserting key-value pairs as needed. There’s still a bit of a problem. You have a variable-length header, which is nice and flexible, but how do you know the length of the header when reading it with ? When you previously learned about using and message boundaries, you also learned that fixed-length headers can be inefficient. That’s true, but you’re going to use a small, 2-byte, fixed-length header to prefix the JSON header that contains its length. You can think of this as a hybrid approach to sending messages. In effect, you’re bootstrapping the message receive process by sending the length of the header first. This makes it easy for your receiver to deconstruct the message. To give you a better idea of the message format, check out a message in its entirety: A message starts with a fixed-length header of two bytes, which is an integer in network byte order. This is the length of the next header, the variable-length JSON header. Once you’ve read two bytes with , then you know you can process the two bytes as an integer and then read that number of bytes before decoding the UTF-8 JSON header. The JSON header contains a dictionary of additional headers. One of those is , which is the number of bytes of the message’s content (not including the JSON header). Once you’ve called and read bytes, then you’ve reached a message boundary, meaning you’ve read an entire message. Finally, the payoff! In this section, you’ll study the class and see how it’s used with when read and write events happen on the socket. This example application reflects what types of messages a client and server could reasonably use. You’re far beyond toy echo clients and servers at this point! To keep things simple and still demonstrate how things would work in a real application, this example uses an application protocol that implements a basic search feature. The client sends a search request and the server does a lookup for a match. If the request sent by the client isn’t recognized as a search, the server assumes it’s a binary request and returns a binary response. After reading the following sections, running the examples, and experimenting with the code, you’ll see how things work. You can then use the class as a starting point and modify it for your own use. The application is not that far off from the client and server example. The event loop code stays the same in and . What you’re going to do is move the message code into a class named and add methods to support reading, writing, and processing of the headers and content. This is a great example for using a class. As you learned before and you’ll see below, working with sockets involves keeping state. By using a class, you keep all of the state, data, and code bundled together in an organized unit. An instance of the class is created for each socket in the client and server when a connection is started or accepted. The class is mostly the same for both the client and the server for the wrapper and utility methods. They start with an underscore, like . These methods simplify working with the class. They help other methods by allowing them to stay shorter and support the DRY principle. The server’s class works in essentially the same way as the client’s and vice-versa. The difference is that the client initiates the connection and sends a request message, followed by processing the server’s response message. Conversely, the server waits for a connection, processes the client’s request message, and then sends a response message. With that, you should have a high-level overview of the individual components and their roles within the application. Understanding how the class works can be a challenge because there’s an aspect of its design that might not be immediately obvious. Why? Managing state. After a object is created, it’s associated with a socket that’s monitored for events using : # Should be ready to read The key idea here is that each object is created when a new connection is accepted. It’s associated with a socket and registered with a selector to monitor for incoming events. This setup allows the server to handle multiple connections concurrently, ensuring that messages can be read as soon as they’re available. Note: Some of the code examples in this section are from the server’s main script and class, but this section and discussion applies equally to the client as well. You’ll be alerted when the client’s version differs. When events are ready on the socket, they’re returned by . You can then get a reference back to the message object using the attribute on the object and call a method in : Looking at the event loop above, you’ll see that is in the driver’s seat. It’s blocking, waiting at the top of the loop for events. It’s responsible for waking up when read and write events are ready to be processed on the socket. Which means, indirectly, it’s also responsible for calling the method . That’s why is the entry point. Here’s what the method does: That’s good: is simple. It can only do two things: call and . This is where managing state comes in. If another method depended on state variables having a certain value, then they would only be called from and . This keeps the logic as simple as possible as events come in on the socket for processing. You might be tempted to use a mix of some methods that check the current state variables and, depending on their value, call other methods to process data outside or . In the end, this would likely prove too complex to manage and keep up with. You should definitely modify the class to suit your own needs so that it works best for you. But, you’ll probably have the best results if you keep the state checks and the calls to methods that depend on that state to the and methods if possible. Now look at . This is the server’s version, but the client’s is the same. It just uses a different method name, instead of : The method is called first. It calls to read data from the socket and store it in a receive buffer. Remember that when is called, all of the data that makes up a complete message may not have arrived yet. may need to be called again. This is why there are state checks for each part of the message before the appropriate method to process it is called. Before a method processes its part of the message, it first checks to make sure enough bytes have been read into the receive buffer. If they have, it processes its respective bytes, removes them from the buffer and writes its output to a variable that’s used by the next processing stage. Because there are three components to a message, there are three state checks and method calls: Next, check out . This is the server’s version: The method checks first for a . If one exists and a response hasn’t been created, is called. The method sets the state variable and writes the response to the send buffer. The method calls if there’s data in the send buffer. Remember that when is called, all of the data in the send buffer may not have been queued for transmission. The network buffers for the socket may be full, and may need to be called again. This is why there are state checks. The method should only be called once, but it’s expected that will need to be called multiple times. The client version of is similar: # Set selector to listen for read events, we're done writing. Because the client initiates a connection to the server and sends a request first, the state variable is checked. If a request hasn’t been queued, it calls . The method creates the request and writes it to the send buffer. It also sets the state variable so that it’s only called once. Just like for the server, calls if there’s data in the send buffer. The notable difference in the client’s version of is the last check to see if the request has been queued. This will be explained more in the section Client Main Script, but the reason for this is to tell to stop monitoring the socket for write events. If the request has been queued and the send buffer is empty, then you’re done writing and you’re only interested in read events. There’s no reason to be notified that the socket is writable. To wrap up this section, consider this thought: the main purpose of this section was to explain that is calling into the class via the method and to describe how state is managed. This is important because will be called many times over the life of the connection. Therefore, make sure that any methods that should only be called once are either checking a state variable themselves, or the state variable set by the method is checked by the caller. In the server’s main script , arguments are read from the command line that specify the interface and port to listen on: For example, to listen on the loopback interface on port , enter: Use an empty string for to listen on all interfaces. After creating the socket, a call is made to with the option : # Avoid bind() exception: OSError: [Errno 48] Address already in use Setting this socket option avoids the error Address already in use . You’ll see this when starting the server on a port that has connections in the TIME_WAIT state. For example, if the server actively closed a connection, it’ll remain in the state for two minutes or more, depending on the operating system. If you try to start the server again before the state expires, then you’ll get an exception of Address already in use . This is a safeguard to make sure that any delayed packets in the network aren’t delivered to the wrong application. The event loop catches any errors so that the server can stay up and continue to run: When a client connection is accepted, a object is created: # Should be ready to read The object is associated with the socket in the call to and is initially set to be monitored for read events only. Once the request has been read, you’ll modify it to listen for write events only. An advantage of taking this approach in the server is that in most cases, when a socket is healthy and there are no network issues, it’ll always be writable. If you told to also monitor , then the event loop would immediately wake up and notify you that this is the case. However, at this point, there’s no reason to wake up and call on the socket. There’s no response to send, because a request hasn’t been processed yet. This would consume and waste valuable CPU cycles. In the section Message Entry Point, you learned how the object was called into action when socket events were ready via . Now you’ll learn what happens as data is read on the socket and a component, or piece, of the message is ready to be processed by the server. The server’s message class is in , which is part of the source code you downloaded earlier. You can also download the code by clicking the link below: Get Your Code: Click here to get the free sample code you’ll use to learn about socket programming in Python. The methods appear in the class in the order in which processing takes place for a message. When the server has read at least two bytes, the fixed-length header can be processed: The fixed-length header is a 2-byte integer in network, or big-endian, byte order. It contains the length of the JSON header. You’ll use to read the value, decode it, and store it in . After processing the piece of the message it’s responsible for, removes it from the receive buffer. Just like with the fixed-length header, when there’s enough data in the receive buffer to contain the JSON header, it can be processed as well: The method is called to decode and deserialize the JSON header into a dictionary. Because the JSON header is defined as Unicode with a UTF-8 encoding, is hardcoded in the call. The result is saved to . After processing the piece of the message that it’s responsible for, removes it from the receive buffer. Next is the actual content, or payload, of the message. It’s described by the JSON header in . When bytes are available in the receive buffer, the request can be processed: # Set selector to listen for write events, we're done reading. After saving the message content to the variable, removes it from the receive buffer. Then, if the content type is JSON, decodes and deserializes it. If it’s not, this example application assumes that it’s a binary request and simply prints the content type. The last thing does is modify the selector to monitor write events only. In the server’s main script, , the socket is initially set to monitor read events only. Now that the request has been fully processed, you’re no longer interested in reading. A response can now be created and written to the socket. When the socket is writable, is called from : A response is created by calling other methods, depending on the content type. In this example application, a simple dictionary lookup is done for JSON requests when . For your own applications, you can define other methods that get called here. After creating the response message, the state variable is set so that doesn’t call again. Finally, the response is appended to the send buffer. This is seen by and sent via . One tricky bit to figure out is how to close the connection after the response is written. You can put the call to in the method : # Should be ready to write # Close when the buffer is drained. The response has been sent. Although it’s somewhat hidden, this is an acceptable trade-off given that the class only handles one message per connection. After the response is written, there’s nothing left for the server to do. It’s completed its work. In the client’s main script, , arguments are read from the command line and used to create requests and start connections to the server: After creating a dictionary representing the request from the command-line arguments, the host, port, and request dictionary are passed to : A socket is created for the server connection, as well as a object using the dictionary. Like for the server, the object is associated with the socket in the call to . However, for the client, the socket is initially set to be monitored for both read and write events. Once the request has been written, you’ll modify it to listen for read events only. This approach gives you the same advantage as the server: not wasting CPU cycles. After the request has been sent, you’re no longer interested in write events, so there’s no reason to wake up and process them. In the section Message Entry Point, you learned how the message object was called into action when socket events were ready via . Now you’ll learn what happens after data is read and written on the socket and a message is ready to be processed by the client. The client’s message class is in , which is part of the source code you downloaded earlier. You can also download the code by clicking the link below: Get Your Code: Click here to get the free sample code you’ll use to learn about socket programming in Python. The methods appear in the class in the order in which processing takes place for a message. The first task for the client is to queue the request: The dictionaries used to create the request, depending on what was passed on the command line, are in the client’s main script, . The request dictionary is passed as an argument to the class when a object is created. The request message is created and appended to the send buffer, which is then seen by and sent via . The state variable is set so that isn’t called again. After the request has been sent, the client waits for a response from the server. The methods for reading and processing a message in the client are the same as for the server. As response data is read from the socket, the header methods are called: and . The difference is in the naming of the final methods and the fact that they’re processing a response, not creating one: , , and . Last, but certainly not least, is the final call for : # Close when response has been processed Okay. You can now wrap the message class up. To conclude your learning about the class, it’s worth mentioning a couple of things that are important to notice with a few of the supporting methods. Any exceptions raised by the class are caught by the main script in the clause inside the event loop: # Check for a socket being monitored to continue. This is a really important line, for more than one reason! Not only does it make sure that the socket is closed, but also removes the socket from being monitored by . This greatly simplifies the code in the class and reduces complexity. If there’s an exception or you explicitly raise one yourself, you know will take care of the cleanup. The methods and also contain something interesting: # Should be ready to read The method has one too. These lines are important because they catch a temporary error and skip over it using . The temporary error is when the socket would block, for example if it’s waiting on the network or the other end of the connection, also known as its peer. By catching and skipping over the exception with , will eventually trigger a new call, and you’ll get another chance to read or write the data. After all of this hard work, it’s time to have some fun and run some searches! In these examples, you’ll run the server so that it listens on all interfaces by passing an empty string for the argument. This will allow you to run the client and connect from a virtual machine that’s on another network. It emulates a big-endian PowerPC machine. Now run the client and enter a search. See if you can find him: You might notice that the terminal is running a shell that’s using a text encoding of Unicode (UTF-8), so the output above prints nicely with emojis. Now see if you can find the puppies: Notice the byte string sent over the network for the request in the line. It’s easier to see if you look for the bytes printed in hex that represent the puppy emoji: . If your terminal is using Unicode with the encoding UTF-8, you’ll be able to enter the emoji for the search. This demonstrates that you’re sending raw bytes over the network and they need to be decoded by the receiver to be interpreted correctly. This is why you went to all of the trouble to create a header that contains the content type and encoding. Here’s the server output from both client connections above: python app-server.py Sending b'\\x00g{\"byteorder\": \"little\", \"content-type\": \"text/json\", \"content-encoding\": \"utf-8\", \"content-length\": 43}{\"result\": \"Follow the white rabbit. \\xf0\\x9f\\x90\\xb0\"}' to ('10.0.2.2', 55340) Look at the line to see the bytes that were written to the client’s socket. This is the server’s response message. You can also test sending binary requests to the server if the argument is anything other than : Because the request’s is not , the server treats it as a custom binary type and doesn’t perform JSON decoding. It simply prints the and returns the first ten bytes to the client: python app-server.py Sending b'\\x00\\x7f{\"byteorder\": \"little\", \"content-type\": \"binary/custom-server-binary-type\", \"content-encoding\": \"binary\", \"content-length\": 37}First 10 bytes of request: binary\\xf0\\x9f\\x98\\x83' to ('10.0.2.2', 55320) If everything is working as expected, you’re all set! However, if you run into any issues along the way, don’t worry. Here’s some guidance to help you get back on track.\n\nInevitably, something won’t work, and you’ll be wondering what to do. Don’t worry, it happens to everyone. Hopefully, with the help of this tutorial, your debugger, and your favorite search engine, you’ll be able to get going again with the source code part. If not, your first stop should be Python’s socket module documentation. Make sure you read all of the documentation for each function or method you’re calling. Also, read through the Reference section below for ideas. In particular, check the Errors section. Sometimes, it’s not all about the source code. The source code might be correct, and it’s just the other host, the client, or server. Or it could be the network. Maybe a router, firewall, or some other networking device is playing man-in-the-middle. For these types of issues, additional tools are essential. Below are a few tools and utilities that might help or at least provide some clues. will check if a host is alive and connected to the network by sending an ICMP echo request. It communicates directly with the operating system’s TCP/IP protocol stack, so it works independently from any application running on the host. Below is an example of running ping on macOS: Note the statistics at the end of the output. This can be helpful when you’re trying to discover intermittent connectivity problems. For example, is there any packet loss? How much latency is there? You can check the round-trip times. If there’s a firewall between you and the other host, a ping’s echo request may not be allowed. Some firewall administrators implement policies that enforce this. The idea is that they don’t want their hosts to be discoverable. If this is the case and you have firewall rules added to allow the hosts to communicate, then make sure that the rules also allow ICMP to pass between them. ICMP is the protocol used by , but it’s also the protocol TCP and other lower-level protocols use to communicate error messages. If you’re experiencing strange behavior or slow connections, this could be the reason. ICMP messages are identified by type and code. To give you an idea of the important information they carry, here are a few: See the article Path MTU Discovery for information regarding fragmentation and ICMP messages. This is an example of something that can cause strange behavior. In the section Viewing Socket State, you learned how can be used to display information about sockets and their current state. This utility is available on macOS, Linux, and Windows. That section didn’t mention the columns and in the example output. These columns will show you the number of bytes that are held in network buffers that are queued for transmission or receipt, but for some reason haven’t been read or written by the remote or local application. In other words, the bytes are waiting in network buffers in the operating system’s queues. One reason could be that the application is CPU bound or is otherwise unable to call or and process the bytes. Or there could be network issues affecting communications, like congestion or failing network hardware or cabling. To demonstrate this and see how much data you can send before seeing an error, you can try out a test client that connects to a test server and repeatedly calls . The test server never calls . It just accepts the connection. This causes the network buffers on the server to fill, which eventually raises an error on the client. Then run the client to see what the error is: Here’s output from while the client and server are still running, with the client printing out the error message above multiple times: The first entry is the server ( has port 65432): The second entry is the client ( has port 65432): The client sure was trying to write bytes, but the server wasn’t reading them. This caused the server’s network buffer queue to fill on the receive side and the client’s network buffer queue to fill on the send side. If you work with Windows, there’s a suite of utilities that you should definitely check out if you haven’t already: Windows Sysinternals. One of them is . TCPView is a graphical for Windows. In addition to addresses, port numbers, and socket state, it’ll show you running totals for the number of packets and bytes sent and received: Like with the Unix utility , you also get the process name and ID. Check the menus for other display options. Sometimes you need to see what’s happening on the wire. Forget about what the application log says or what the value is that’s being returned from a library call. You want to see what’s actually being sent or received on the network. Just like with debuggers, when you need to see it, there’s no substitute. Wireshark is a network protocol analyzer and traffic capture application that runs on macOS, Linux, and Windows, among others. There’s a GUI version named and also a terminal, text-based version named . Running a traffic capture is a great way to watch how an application behaves on the network and gather evidence about what it sends and receives, and how often and how much. You’ll also be able to see when a client or server closes or aborts a connection or stops responding. This information can be extremely helpful when you’re troubleshooting. There are many good tutorials and other resources on the web that will walk you through the basics of using Wireshark and TShark. Here’s an example of a traffic capture using Wireshark on the loopback interface: Here’s the same example shown above using : Next up, you’ll get more references to support your socket programming journey!\n\nYou can use this section as a general reference with additional information and links to external resources about networking and sockets. First, you may want to check out the Python official documentation: For further reading, consider exploring online tutorials and guides that provide practical examples and in-depth explanations of socket programming concepts. The following is from Python’s module documentation: All errors raise exceptions. The normal exceptions for invalid argument types and out-of-memory conditions can be raised; starting from Python 3.3, errors related to socket or address semantics raise or one of its subclasses. (Source) Here are some common errors you’ll probably encounter when working with sockets: Resource temporarily unavailable. For example, in non-blocking mode, when calling and the peer is busy and not reading, the send queue (network buffer) is full. Or there are issues with the network. Hopefully this is a temporary condition. Address already in use. Make sure that there’s not another process running that’s using the same port number and that your server is setting the socket option : . Connection reset by peer. The remote process crashed or did not close its socket properly, also known as an unclean shutdown. Or there’s a firewall or other device in the network path that’s missing rules or misbehaving. Operation timed out. No response from peer. Connection refused. No application listening on specified port. It’s good to familiarize yourself with these common socket errors, as understanding them can help you diagnose and troubleshoot network issues more effectively. and represent the address and protocol families used for the first argument to . APIs that use an address expect it to be in a certain format, depending on whether the socket was created with or : is a string with a hostname like or an IPv4 address like . is an integer. is a string with a hostname like or an IPv6 address like . is an integer. and represent the and members in the C struct . Note the excerpt below from Python’s socket module documentation regarding the value of the address tuple: For IPv4 addresses, two special forms are accepted instead of a host address: the empty string represents , and the string represents . This behavior is not compatible with IPv6, therefore, you may want to avoid these if you intend to support IPv6 with your Python programs. (Source) See Python’s Socket families documentation for more information. This tutorial uses IPv4 sockets, but if your network supports it, try testing and using IPv6 if possible. One way to support this easily is by using the function . It translates the and arguments into a sequence of five-tuples that contains all of the necessary arguments for creating a socket connected to that service. Note: will understand and interpret passed-in IPv6 addresses and hostnames that resolve to IPv6 addresses, in addition to IPv4. The following example returns address information for a TCP connection to on port : Results may differ on your system if IPv6 isn’t enabled. The values returned above can be used by passing them to and . There’s a client and server example in the Example section of Python’s socket module documentation. For context, this section applies mostly to using hostnames with and , or , when you intend to use the loopback interface, localhost. However, it also applies any time you’re using a hostname and there’s an expectation of it resolving to a certain address and having a special meaning to your application that affects its behavior or assumptions. This is in contrast to the typical scenario of a client using a hostname to connect to a server that’s resolved by DNS, like www.example.com. The following is from Python’s module documentation: If you use a hostname in the host portion of IPv4/v6 socket address, the program may show a non-deterministic behavior, as Python uses the first address returned from the DNS resolution. The socket address will be resolved differently into an actual IPv4/v6 address, depending on the results from DNS resolution and/or the host configuration. For deterministic behavior use a numeric address in host portion. (Source) The standard convention for the name “localhost” is for it to resolve to or , the loopback interface. This will more than likely be the case for you on your system, but maybe not. It depends on how your system is configured for name resolution. As with all things IT, there are always exceptions, and there are no guarantees that using the name “localhost” will connect to the loopback interface. For example, on Linux, see , the Name Service Switch configuration file. Another place to check on macOS and Linux is the file . On Windows, see . The file contains a static table of name-to-address mappings in a simple text format. DNS is another piece of the puzzle altogether. Interestingly enough, as of June 2018, there’s an RFC draft Let ‘localhost’ be localhost that discusses the conventions, assumptions, and security around using the name “localhost.” What’s important to understand is that when you use hostnames in your application, the returned addresses could literally be anything. Don’t make assumptions regarding a name if you have a security-sensitive application. Depending on your application and environment, this may or may not be a concern for you. Note: Security precautions and best practices still apply, even if your application isn’t explicitly security-sensitive. If your application accesses the network, it should be secured and maintained. This means, at a minimum:\n• System software updates and security patches are applied regularly, including Python. Are you using any third-party libraries? If so, make sure those are checked and updated too.\n• If possible, use a dedicated or host-based firewall to restrict connections to trusted systems only.\n• What DNS servers are configured? Do you trust them and their administrators?\n• Make sure that request data is sanitized and validated as much as possible prior to calling other code that processes it. Use fuzz tests for this and run them regularly. Regardless of whether or not you’re using hostnames, if your application needs to support secure connections through encryption and authentication, then you’ll probably want to look into using TLS. This is its own separate topic and beyond the scope of this tutorial. See Python’s ssl module documentation to get started. This is the same protocol that your web browser uses to connect securely to web sites. With interfaces, IP addresses, and name resolution to consider, there are many variables. What should you do? Here are some recommendations that you can use if you don’t have a network application review process: Use an IP address, such as or . Use an IP address, such as . To support more than one interface, use an empty string for all interfaces/addresses. See the security note above. Use an IP address, such as or . Use an IP address for consistency and non-reliance on name resolution. For the typical case, use a hostname. See the security note above. For clients or servers, if you need to authenticate the host that you’re connecting to, look into using TLS. A socket function or method that temporarily suspends your application is a blocking call. For example, , , , and block, meaning they don’t return immediately. Blocking calls have to wait on system calls (I/O) to complete before they can return a value. So you, the caller, are blocked until they’re done or a timeout or other error occurs. Blocking socket calls can be set to non-blocking mode so they return immediately. If you do this, then you’ll need to at least refactor or redesign your application to handle the socket operation when it’s ready. Because the call returns immediately, data may not be ready. The callee is waiting on the network and hasn’t had time to complete its work. If this is the case, then the current status is the value . Non-blocking mode is supported with .setblocking(). By default, sockets are always created in blocking mode. See Notes on socket timeouts for a description of the three modes. An interesting thing to note with TCP is that it’s completely legal for the client or server to close their side of the connection while the other side remains open. This is referred to as a “half-open” connection. It’s the application’s decision whether or not this is desirable. In general, it’s not. In this state, the side that has closed their end of the connection can no longer send data. They can only receive it. This approach isn’t necessarily recommended, but as an example, HTTP uses a header named “Connection” that’s used to standardize how applications should close or persist open connections. For details, see section 6.3 in RFC 7230, Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing. When designing and writing your application and its application-layer protocol, it’s a good idea to go ahead and work out how you expect connections to be closed. Sometimes this is obvious and simple, or it’s something that can take some initial prototyping and testing. It depends on the application and how the message loop is processed with its expected data. Just make sure that sockets are always closed in a timely manner after they complete their work. See Wikipedia’s article on endianness for details on how different CPUs store byte orderings in memory. When interpreting individual bytes, this isn’t a problem. However, when you’re handling multiple bytes that are read and processed as a single value, for example a 4-byte integer, the byte order needs to be reversed if you’re communicating with a machine that uses a different endianness. Byte order is also important for text strings that are represented as multi-byte sequences, like Unicode. Unless you’re always using true, strict ASCII and control the client and server implementations, you’re probably better off using Unicode with an encoding like UTF-8 or one that supports a byte order mark (BOM). It’s important to explicitly define the encoding used in your application-layer protocol. You can do this by mandating that all text is UTF-8 or using a “content-encoding” header that specifies the encoding. This prevents your application from having to detect the encoding, which you should avoid if possible. This becomes problematic when there is data involved that’s stored in files or a database and there’s no metadata available that specifies its encoding. When the data is transferred to another endpoint, it’ll have to try to detect the encoding. For a discussion, see Wikipedia’s Unicode article, which references RFC 3629: UTF-8, a transformation format of ISO 10646: However RFC 3629, the UTF-8 standard, recommends that byte order marks be forbidden in protocols using UTF-8, but discusses the cases where this may not be possible. In addition, the large restriction on possible patterns in UTF-8 (for instance there cannot be any lone bytes with the high bit set) means that it should be possible to distinguish UTF-8 from other character encodings without relying on the BOM. (Source) The takeaway from this is to always store the encoding used for data that’s handled by your application if it can vary. In other words, try to somehow store the encoding as metadata if it’s not always UTF-8 or some other encoding with a BOM. Then you can send that encoding in a header along with the data to tell the receiver what it is. The byte ordering used in TCP/IP is big-endian and is referred to as network order. Network order is used to represent integers in lower layers of the protocol stack, like IP addresses and port numbers. Python’s socket module includes functions that convert integers to and from network and host byte order: Convert 32-bit positive integers from network to host byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 4-byte swap operation. Convert 16-bit positive integers from network to host byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 2-byte swap operation. Convert 32-bit positive integers from host to network byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 4-byte swap operation. Convert 16-bit positive integers from host to network byte order. On machines where the host byte order is the same as network byte order, this is a no-op; otherwise, it performs a 2-byte swap operation. You can also use the module to pack and unpack binary data using format strings: The format string specifies that your data is packed as an unsigned short (2 bytes) in big-endian byte order, which is suitable for network transmission. Then, you use the same format specifier to unpack the binary data back into a Python integer."
    },
    {
        "link": "https://stackoverflow.com/questions/11865685/handling-a-timeout-error-in-python-sockets",
        "document": "adds all the names without leading underscores (or only the names defined in the modules attribute) in into your current module.\n\nIn the above code with , you just want to catch as you've pulled into your current namespace.\n\npulls in the definitions of everything inside of , but it doesn't add itself.\n\nMany people consider problematic and try to avoid it. This is because common variable names in two or more modules that are imported in this way will clobber one another.\n\nFor example, consider the following three Python files:\n\nIf you run , you'll see just the output \"this is b's foo function\".\n\nFor this reason I'd suggest either importing the module and using it or importing specific names from the module:\n\nFor example, your code would look like this with explicit imports:\n\nIt is just a tiny bit more typing, but everything's explicit and it's pretty obvious to the reader where everything comes from."
    }
]