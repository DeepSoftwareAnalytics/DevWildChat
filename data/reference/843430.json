[
    {
        "link": "http://docs.sqlalchemy.org/en/latest/orm/queryguide/relationships.html",
        "document": "A big part of SQLAlchemy is providing a wide range of control over how related objects get loaded when querying. By “related objects” we refer to collections or scalar associations configured on a mapper using . This behavior can be configured at mapper construction time using the parameter to the function, as well as by using ORM loader options with the construct.\n\nThe loading of relationships falls into three categories; lazy loading, eager loading, and no loading. Lazy loading refers to objects that are returned from a query without the related objects loaded at first. When the given collection or reference is first accessed on a particular object, an additional SELECT statement is emitted such that the requested collection is loaded.\n\nEager loading refers to objects returned from a query with the related collection or scalar reference already loaded up front. The ORM achieves this either by augmenting the SELECT statement it would normally emit with a JOIN to load in related rows simultaneously, or by emitting additional SELECT statements after the primary one to load collections or scalar references at once.\n\n“No” loading refers to the disabling of loading on a given relationship, either that the attribute is empty and is just never loaded, or that it raises an error when it is accessed, in order to guard against unwanted lazy loads.\n\nThe other, and possibly more common way to configure loading strategies is to set them up on a per-query basis against specific attributes using the method. Very detailed control over relationship loading is available using loader options; the most common are , and . The option accepts a class-bound attribute referring to the specific class/attribute that should be targeted: The loader options can also be “chained” using method chaining to specify how loading should occur further levels deep: Chained loader options can be applied against a “lazy” loaded collection. This means that when a collection or association is lazily loaded upon access, the specified option will then take effect: Above, the query will return objects without the collections loaded. When the collection on a particular object is first accessed, it will lazy load the related objects, but additionally apply eager loading to the collection on each member of . The relationship attributes used to indicate loader options include the ability to add additional filtering criteria to the ON clause of the join that’s created, or to the WHERE criteria involved, depending on the loader strategy. This can be achieved using the method which will pass through an option such that loaded results are limited to the given filter criteria: When using limiting criteria, if a particular collection is already loaded it won’t be refreshed; to ensure the new criteria takes place, apply the Populate Existing execution option: In order to add filtering criteria to all occurrences of an entity throughout a query, regardless of loader strategy or where it occurs in the loading process, see the function. Using method chaining, the loader style of each link in the path is explicitly stated. To navigate along a path without changing the existing loader style of a particular attribute, the method/function may be used: A similar approach can be used to specify multiple sub-options at once, using the method: Using load_only() on related objects and collections - illustrates examples of combining relationship and column-oriented loader options. The loader options applied to an object’s lazy-loaded collections are “sticky” to specific object instances, meaning they will persist upon collections loaded by that specific object for as long as it exists in memory. For example, given the previous example: if the collection on a particular object loaded by the above query is expired (such as when a object’s transaction is committed or rolled back, or is used), when the collection is next accessed in order to re-load it, the collection will again be loaded using subquery eager loading. This stays the case even if the above object is accessed from a subsequent query that specifies a different set of options. To change the options on an existing object without expunging it and re-loading, they must be set explicitly in conjunction using the Populate Existing execution option: # change the options on Parent objects that were already loaded If the objects loaded above are fully cleared from the , such as due to garbage collection or that were used, the “sticky” options will also be gone and the newly created objects will make use of new options if loaded again. A future SQLAlchemy release may add more alternatives to manipulating the loader options on already-loaded objects.\n\nBy default, all inter-object relationships are lazy loading. The scalar or collection attribute associated with a contains a trigger which fires the first time the attribute is accessed. This trigger typically issues a SQL call at the point of access in order to load the related object or objects: The one case where SQL is not emitted is for a simple many-to-one relationship, when the related object can be identified by its primary key alone and that object is already present in the current . For this reason, while lazy loading can be expensive for related collections, in the case that one is loading lots of objects with simple many-to-ones against a relatively small set of possible target objects, lazy loading may be able to refer to these objects locally without emitting as many SELECT statements as there are parent objects. This default behavior of “load upon attribute access” is known as “lazy” or “select” loading - the name “select” because a “SELECT” statement is typically emitted when the attribute is first accessed. Lazy loading can be enabled for a given attribute that is normally configured in some other way using the loader option: # force lazy loading for an attribute that is set to # load some other way normally The strategy produces an effect that is one of the most common issues referred to in object relational mapping; the N plus one problem, which states that for any N objects loaded, accessing their lazy-loaded attributes means there will be N+1 SELECT statements emitted. In SQLAlchemy, the usual mitigation for the N+1 problem is to make use of its very capable eager load system. However, eager loading requires that the attributes which are to be loaded be specified with the up front. The problem of code that may access other attributes that were not eagerly loaded, where lazy loading is not desired, may be addressed using the strategy; this loader strategy replaces the behavior of lazy loading with an informative error being raised: Above, a object loaded from the above query will not have the collection loaded; if some code later on attempts to access this attribute, an ORM exception is raised. may be used with a so-called “wildcard” specifier to indicate that all relationships should use this strategy. For example, to set up only one attribute as eager loading, and all the rest as raise: The above wildcard will apply to all relationships not just on besides , but all those on the objects as well. To set up for only the objects, specify a full path with : Conversely, to set up the raise for just the objects: The option applies only to relationship attributes. For column-oriented attributes, the option supports the option which works in the same way. The “raiseload” strategies do not apply within the unit of work flush process. That means if the process needs to load a collection in order to finish its work, it will do so while bypassing any directives.\n\nJoined eager loading is the oldest style of eager loading included with the SQLAlchemy ORM. It works by connecting a JOIN (by default a LEFT OUTER join) to the SELECT statement emitted, and populates the target scalar/collection from the same result set as that of the parent. At the mapping level, this looks like: Joined eager loading is usually applied as an option to a query, rather than as a default loading option on the mapping, in particular when used for collections rather than many-to-one-references. This is achieved using the loader option: When including in reference to a one-to-many or many-to-many collection, the method must be applied to the returned result, which will uniquify the incoming rows by primary key that otherwise are multiplied out by the join. The ORM will raise an error if this is not present. This is not automatic in modern SQLAlchemy, as it changes the behavior of the result set to return fewer ORM objects than the statement would normally return in terms of number of rows. Therefore SQLAlchemy keeps the use of explicit, so there’s no ambiguity that the returned objects are being uniqified on primary key. The JOIN emitted by default is a LEFT OUTER JOIN, to allow for a lead object that does not refer to a related row. For an attribute that is guaranteed to have an element, such as a many-to-one reference to a related object where the referencing foreign key is NOT NULL, the query can be made more efficient by using an inner join; this is available at the mapping level via the flag: At the query option level, via the flag: The JOIN will right-nest itself when applied in a chain that includes an OUTER JOIN: If using database row locking techniques when emitting the SELECT, meaning the method is being used to emit SELECT..FOR UPDATE, the joined table may be locked as well, depending on the behavior of the backend in use. It’s not recommended to use joined eager loading at the same time as SELECT..FOR UPDATE for this reason. Since joined eager loading seems to have many resemblances to the use of , it often produces confusion as to when and how it should be used. It is critical to understand the distinction that while is used to alter the results of a query, goes through great lengths to not alter the results of the query, and instead hide the effects of the rendered join to only allow for related objects to be present. The philosophy behind loader strategies is that any set of loading schemes can be applied to a particular query, and the results don’t change - only the number of SQL statements required to fully load related objects and collections changes. A particular query might start out using all lazy loads. After using it in context, it might be revealed that particular attributes or collections are always accessed, and that it would be more efficient to change the loader strategy for these. The strategy can be changed with no other modifications to the query, the results will remain identical, but fewer SQL statements would be emitted. In theory (and pretty much in practice), nothing you can do to the would make it load a different set of primary or related objects based on a change in loader strategy. How in particular achieves this result of not impacting entity rows returned in any way is that it creates an anonymous alias of the joins it adds to your query, so that they can’t be referenced by other parts of the query. For example, the query below uses to create a LEFT OUTER JOIN from to , however the added against is not valid - the entity is not named in the query: Above, is not valid since is not in the FROM list. The correct way to load the records and order by email address is to use : The statement above is of course not the same as the previous one, in that the columns from are not included in the result at all. We can add back in, so that there are two joins - one is that which we are ordering on, the other is used anonymously to load the contents of the collection: What we see above is that our usage of is to supply JOIN clauses we’d like to use in subsequent query criterion, whereas our usage of only concerns itself with the loading of the collection, for each in the result. In this case, the two joins most probably appear redundant - which they are. If we wanted to use just one JOIN for collection loading as well as ordering, we use the option, described in Routing Explicit Joins/Statements into Eagerly Loaded Collections below. But to see why does what it does, consider if we were filtering on a particular : Above, we can see that the two JOINs have very different roles. One will match exactly one row, that of the join of and where . The other LEFT OUTER JOIN will match all rows related to , and is only used to populate the collection, for those objects that are returned. By changing the usage of to another style of loading, we can change how the collection is loaded completely independently of SQL used to retrieve the actual rows we want. Below we change into : When using joined eager loading, if the query contains a modifier that impacts the rows returned externally to the joins, such as when using DISTINCT, LIMIT, OFFSET or equivalent, the completed statement is first wrapped inside a subquery, and the joins used specifically for joined eager loading are applied to the subquery. SQLAlchemy’s joined eager loading goes the extra mile, and then ten miles further, to absolutely ensure that it does not affect the end result of the query, only the way collections and related objects are loaded, no matter what the format of the query is.\n\nIn most cases, selectin loading is the most simple and efficient way to eagerly load collections of objects. The only scenario in which selectin eager loading is not feasible is when the model is using composite primary keys, and the backend database does not support tuples with IN, which currently includes SQL Server. “Select IN” eager loading is provided using the argument to or by using the loader option. This style of loading emits a SELECT that refers to the primary key values of the parent object, or in the case of a many-to-one relationship to the those of the child objects, inside of an IN clause, in order to load related associations: Above, the second SELECT refers to , where the “5” and “7” are the primary key values for the previous two objects loaded; after a batch of objects are completely loaded, their primary key values are injected into the clause for the second SELECT. Because the relationship between and has a simple primary join condition and provides that the primary key values for can be derived from , the statement has no joins or subqueries at all. For simple many-to-one loads, a JOIN is also not needed as the foreign key value from the parent object is used: by “simple” we mean that the condition expresses an equality comparison between the primary key of the “one” side and a straight foreign key of the “many” side, without any additional criteria. Select IN loading also supports many-to-many relationships, where it currently will JOIN across all three tables to match rows from one side to the other. Things to know about this kind of loading include:\n• None The strategy emits a SELECT for up to 500 parent primary key values at a time, as the primary keys are rendered into a large IN expression in the SQL statement. Some databases like Oracle Database have a hard limit on how large an IN expression can be, and overall the size of the SQL string shouldn’t be arbitrarily large.\n• None As “selectin” loading relies upon IN, for a mapping with composite primary keys, it must use the “tuple” form of IN, which looks like . This syntax is not currently supported on SQL Server and for SQLite requires at least version 3.15. There is no special logic in SQLAlchemy to check ahead of time which platforms support this syntax or not; if run against a non-supporting platform, the database will return an error immediately. An advantage to SQLAlchemy just running the SQL out for it to fail is that if a particular database does start supporting this syntax, it will work without any changes to SQLAlchemy (as was the case with SQLite).\n\nThe eager loader is mostly legacy at this point, superseded by the strategy which is of much simpler design, more flexible with features such as Yield Per, and emits more efficient SQL statements in most cases. As relies upon re-interpreting the original SELECT statement, it may fail to work efficiently when given very complex source queries. may continue to be useful for the specific case of an eager loaded collection for objects that use composite primary keys, on the Microsoft SQL Server backend that continues to not have support for the “tuple IN” syntax. Subquery loading is similar in operation to selectin eager loading, however the SELECT statement which is emitted is derived from the original statement, and has a more complex query structure as that of selectin eager loading. Subquery eager loading is provided using the argument to or by using the loader option. The operation of subquery eager loading is to emit a second SELECT statement for each relationship to be loaded, across all result objects at once. This SELECT statement refers to the original SELECT statement, wrapped inside of a subquery, so that we retrieve the same list of primary keys for the primary object being returned, then link that to the sum of all the collection members to load them at once: Things to know about this kind of loading include:\n• None The SELECT statement emitted by the “subquery” loader strategy, unlike that of “selectin”, requires a subquery, and will inherit whatever performance limitations are present in the original query. The subquery itself may also incur performance penalties based on the specifics of the database in use.\n• None “subquery” loading imposes some special ordering requirements in order to work correctly. A query which makes use of in conjunction with a limiting modifier such as , or should always include against unique column(s) such as the primary key, so that the additional queries emitted by include the same ordering as used by the parent query. Without it, there is a chance that the inner query could return the wrong rows: # incorrect if User.name is not unique Why is ORDER BY recommended with LIMIT (especially with subqueryload())? - detailed example\n• None “subquery” loading also incurs additional performance / complexity issues when used on a many-levels-deep eager load, as subqueries will be nested repeatedly.\n• None “subquery” loading is not compatible with the “batched” loading supplied by Yield Per, both for collection and scalar relationships. For the above reasons, the “selectin” strategy should be preferred over “subquery”.\n\nThe behavior of is such that joins are created automatically, using anonymous aliases as targets, the results of which are routed into collections and scalar references on loaded objects. It is often the case that a query already includes the necessary joins which represent a particular collection or scalar reference, and the joins added by the joinedload feature are redundant - yet you’d still like the collections/references to be populated. For this SQLAlchemy supplies the option. This option is used in the same manner as the option except it is assumed that the object will explicitly include the appropriate joins, typically using methods like . Below, we specify a join between and and additionally establish this as the basis for eager loading of : If the “eager” portion of the statement is “aliased”, the path should be specified using , which allows the specific construct to be passed: # use an alias of the Address entity The path given as the argument to needs to be a full path from the starting entity. For example if we were loading , the option would be used as: When we use , we are constructing ourselves the SQL that will be used to populate collections. From this, it naturally follows that we can opt to modify what values the collection is intended to store, by writing our SQL to load a subset of elements for collections or scalar attributes. SQLAlchemy now has a much simpler way to do this, by allowing WHERE criteria to be added directly to loader options such as and using . See the section Adding Criteria to loader options for examples. The techniques described here still apply if the related collection is to be queried using SQL criteria or modifiers more complex than a simple WHERE clause. As an example, we can load a object and eagerly load only particular addresses into its collection by filtering the joined data, routing it using , also using Populate Existing to ensure any already-loaded collections are overwritten: The above query will load only objects which contain at least object that contains the substring in its field; the collection will contain only these entries, and not any other entries that are in fact associated with the collection. In all cases, the SQLAlchemy ORM does not overwrite already loaded attributes and collections unless told to do so. As there is an identity map in use, it is often the case that an ORM query is returning objects that were in fact already present and loaded in memory. Therefore, when using to populate a collection in an alternate way, it is usually a good idea to use Populate Existing as illustrated above so that an already-loaded collection is refreshed with the new data. The option will reset all attributes that were already present, including pending changes, so make sure all data is flushed before using it. Using the with its default behavior of autoflush is sufficient. The customized collection we load using is not “sticky”; that is, the next time this collection is loaded, it will be loaded with its usual default contents. The collection is subject to being reloaded if the object is expired, which occurs whenever the , methods are used assuming default session settings, or the or methods are used. Adding Criteria to loader options - modern API allowing WHERE criteria directly within any relationship loader option"
    },
    {
        "link": "https://docs.sqlalchemy.org/14/orm/loading_relationships.html",
        "document": "A big part of SQLAlchemy is providing a wide range of control over how related objects get loaded when querying. By “related objects” we refer to collections or scalar associations configured on a mapper using . This behavior can be configured at mapper construction time using the parameter to the function, as well as by using options with the object.\n\nThe loading of relationships falls into three categories; lazy loading, eager loading, and no loading. Lazy loading refers to objects are returned from a query without the related objects loaded at first. When the given collection or reference is first accessed on a particular object, an additional SELECT statement is emitted such that the requested collection is loaded.\n\nEager loading refers to objects returned from a query with the related collection or scalar reference already loaded up front. The achieves this either by augmenting the SELECT statement it would normally emit with a JOIN to load in related rows simultaneously, or by emitting additional SELECT statements after the primary one to load collections or scalar references at once.\n\n“No” loading refers to the disabling of loading on a given relationship, either that the attribute is empty and is just never loaded, or that it raises an error when it is accessed, in order to guard against unwanted lazy loads.\n\nThe primary forms of relationship loading are:\n• None lazy loading - available via or the option, this is the form of loading that emits a SELECT statement at attribute access time to lazily load a related reference on a single object at a time. Lazy loading is detailed at Lazy Loading.\n• None joined loading - available via or the option, this form of loading applies a JOIN to the given SELECT statement so that related rows are loaded in the same result set. Joined eager loading is detailed at Joined Eager Loading.\n• None subquery loading - available via or the option, this form of loading emits a second SELECT statement which re-states the original query embedded inside of a subquery, then JOINs that subquery to the related table to be loaded to load all members of related collections / scalar references at once. Subquery eager loading is detailed at Subquery Eager Loading.\n• None select IN loading - available via or the option, this form of loading emits a second (or more) SELECT statement which assembles the primary key identifiers of the parent objects into an IN clause, so that all members of related collections / scalar references are loaded at once by primary key. Select IN loading is detailed at Select IN loading.\n• None raise loading - available via , , or the option, this form of loading is triggered at the same time a lazy load would normally occur, except it raises an ORM exception in order to guard against the application making unwanted lazy loads. An introduction to raise loading is at Preventing unwanted lazy loads using raiseload.\n• None no loading - available via , or the option; this loading style turns the attribute into an empty attribute ( or ) that will never load or have any loading effect. This seldom-used strategy behaves somewhat like an eager loader when objects are loaded in that an empty attribute or collection is placed, but for expired objects relies upon the default value of the attribute being returned on access; the net effect is the same except for whether or not the attribute name appears in the collection. may be useful for implementing a “write-only” attribute but this usage is not currently tested or formally supported.\n\nThe other, and possibly more common way to configure loading strategies is to set them up on a per-query basis against specific attributes using the method. Very detailed control over relationship loading is available using loader options; the most common are , , and . The option accepts either the string name of an attribute against a parent, or for greater specificity can accommodate a class-bound attribute directly: The loader options can also be “chained” using method chaining to specify how loading should occur further levels deep: Chained loader options can be applied against a “lazy” loaded collection. This means that when a collection or association is lazily loaded upon access, the specified option will then take effect: Above, the query will return objects without the collections loaded. When the collection on a particular object is first accessed, it will lazy load the related objects, but additionally apply eager loading to the collection on each member of . The above examples, using , are now referred to as 1.x style queries. The options system is available as well for 2.0 style queries using the method: Under the hood, is ultimately using the above based mechanism. The relationship attributes used to indicate loader options include the ability to add additional filtering criteria to the ON clause of the join that’s created, or to the WHERE criteria involved, depending on the loader strategy. This can be achieved using the method which will pass through an option such that loaded results are limited to the given filter criteria: When using limiting criteria, if a particular collection is already loaded it won’t be refreshed; to ensure the new criteria takes place, apply the option: In order to add filtering criteria to all occurrences of an entity throughout a query, regardless of loader strategy or where it occurs in the loading process, see the function. Using method chaining, the loader style of each link in the path is explicitly stated. To navigate along a path without changing the existing loader style of a particular attribute, the method/function may be used: A similar approach can be used to specify multiple sub-options at once, using the method: Deferred Loading across Multiple Entities - illustrates examples of combining relationship and column-oriented loader options. The loader options applied to an object’s lazy-loaded collections are “sticky” to specific object instances, meaning they will persist upon collections loaded by that specific object for as long as it exists in memory. For example, given the previous example: if the collection on a particular object loaded by the above query is expired (such as when a object’s transaction is committed or rolled back, or is used), when the collection is next accessed in order to re-load it, the collection will again be loaded using subquery eager loading.This stays the case even if the above object is accessed from a subsequent query that specifies a different set of options.To change the options on an existing object without expunging it and re-loading, they must be set explicitly in conjunction with the method: # change the options on Parent objects that were already loaded If the objects loaded above are fully cleared from the , such as due to garbage collection or that were used, the “sticky” options will also be gone and the newly created objects will make use of new options if loaded again. A future SQLAlchemy release may add more alternatives to manipulating the loader options on already-loaded objects.\n\nBy default, all inter-object relationships are lazy loading. The scalar or collection attribute associated with a contains a trigger which fires the first time the attribute is accessed. This trigger typically issues a SQL call at the point of access in order to load the related object or objects: The one case where SQL is not emitted is for a simple many-to-one relationship, when the related object can be identified by its primary key alone and that object is already present in the current . For this reason, while lazy loading can be expensive for related collections, in the case that one is loading lots of objects with simple many-to-ones against a relatively small set of possible target objects, lazy loading may be able to refer to these objects locally without emitting as many SELECT statements as there are parent objects. This default behavior of “load upon attribute access” is known as “lazy” or “select” loading - the name “select” because a “SELECT” statement is typically emitted when the attribute is first accessed. Lazy loading can be enabled for a given attribute that is normally configured in some other way using the loader option: # force lazy loading for an attribute that is set to # load some other way normally The strategy produces an effect that is one of the most common issues referred to in object relational mapping; the N plus one problem, which states that for any N objects loaded, accessing their lazy-loaded attributes means there will be N+1 SELECT statements emitted. In SQLAlchemy, the usual mitigation for the N+1 problem is to make use of its very capable eager load system. However, eager loading requires that the attributes which are to be loaded be specified with the up front. The problem of code that may access other attributes that were not eagerly loaded, where lazy loading is not desired, may be addressed using the strategy; this loader strategy replaces the behavior of lazy loading with an informative error being raised: Above, a object loaded from the above query will not have the collection loaded; if some code later on attempts to access this attribute, an ORM exception is raised. may be used with a so-called “wildcard” specifier to indicate that all relationships should use this strategy. For example, to set up only one attribute as eager loading, and all the rest as raise: The above wildcard will apply to all relationships not just on besides , but all those on the objects as well. To set up for only the objects, specify a full path with : Conversely, to set up the raise for just the objects: The option applies only to relationship attributes. For column-oriented attributes, the option supports the option which works in the same way. Changed in version 1.4.0: The “raiseload” strategies do not take place within the unit of work flush process, as of SQLAlchemy 1.4.0. This means that if the unit of work needs to load a particular attribute in order to complete its work, it will perform the load. It’s not always easy to prevent a particular relationship load from occurring within the UOW process particularly with less common kinds of relationships. The lazy=”raise” case is more intended for explicit attribute access within the application space.\n\nJoined eager loading is the most fundamental style of eager loading in the ORM. It works by connecting a JOIN (by default a LEFT OUTER join) to the SELECT statement emitted by a and populates the target scalar/collection from the same result set as that of the parent. At the mapping level, this looks like: Joined eager loading is usually applied as an option to a query, rather than as a default loading option on the mapping, in particular when used for collections rather than many-to-one-references. This is achieved using the loader option: The JOIN emitted by default is a LEFT OUTER JOIN, to allow for a lead object that does not refer to a related row. For an attribute that is guaranteed to have an element, such as a many-to-one reference to a related object where the referencing foreign key is NOT NULL, the query can be made more efficient by using an inner join; this is available at the mapping level via the flag: At the query option level, via the flag: The JOIN will right-nest itself when applied in a chain that includes an OUTER JOIN: On older versions of SQLite, the above nested right JOIN may be re-rendered as a nested subquery. Older versions of SQLAlchemy would convert right-nested joins into subqueries in all cases. Using in the context of eager loading relationships is not officially supported or recommended by SQLAlchemy and may not work with certain queries on various database backends. When is successfully used with a query that involves , SQLAlchemy will attempt to emit SQL that locks all involved tables. A central concept of joined eager loading when applied to collections is that the object must de-duplicate rows against the leading entity being queried. Such as above, if the object we loaded referred to three objects, the result of the SQL statement would have had three rows; yet the returns only one object. As additional rows are received for a object just loaded in a previous row, the additional columns that refer to new objects are directed into additional results within the collection of that particular object. This process is very transparent, however does imply that joined eager loading is incompatible with “batched” query results, provided by the method, when used for collection loading. Joined eager loading used for scalar references is however compatible with . The method will result in an exception thrown if a collection based joined eager loader is in play. To “batch” queries with arbitrarily large sets of result data while maintaining compatibility with collection-based joined eager loading, emit multiple SELECT statements, each referring to a subset of rows using the WHERE clause, e.g. windowing. Alternatively, consider using “select IN” eager loading which is potentially compatible with , provided that the database driver in use supports multiple, simultaneous cursors (SQLite, PostgreSQL drivers, not MySQL drivers or SQL Server ODBC drivers). Since joined eager loading seems to have many resemblances to the use of , it often produces confusion as to when and how it should be used. It is critical to understand the distinction that while is used to alter the results of a query, goes through great lengths to not alter the results of the query, and instead hide the effects of the rendered join to only allow for related objects to be present. The philosophy behind loader strategies is that any set of loading schemes can be applied to a particular query, and the results don’t change - only the number of SQL statements required to fully load related objects and collections changes. A particular query might start out using all lazy loads. After using it in context, it might be revealed that particular attributes or collections are always accessed, and that it would be more efficient to change the loader strategy for these. The strategy can be changed with no other modifications to the query, the results will remain identical, but fewer SQL statements would be emitted. In theory (and pretty much in practice), nothing you can do to the would make it load a different set of primary or related objects based on a change in loader strategy. How in particular achieves this result of not impacting entity rows returned in any way is that it creates an anonymous alias of the joins it adds to your query, so that they can’t be referenced by other parts of the query. For example, the query below uses to create a LEFT OUTER JOIN from to , however the added against is not valid - the entity is not named in the query: Above, is not valid since is not in the FROM list. The correct way to load the records and order by email address is to use : The statement above is of course not the same as the previous one, in that the columns from are not included in the result at all. We can add back in, so that there are two joins - one is that which we are ordering on, the other is used anonymously to load the contents of the collection: What we see above is that our usage of is to supply JOIN clauses we’d like to use in subsequent query criterion, whereas our usage of only concerns itself with the loading of the collection, for each in the result. In this case, the two joins most probably appear redundant - which they are. If we wanted to use just one JOIN for collection loading as well as ordering, we use the option, described in Routing Explicit Joins/Statements into Eagerly Loaded Collections below. But to see why does what it does, consider if we were filtering on a particular : Above, we can see that the two JOINs have very different roles. One will match exactly one row, that of the join of and where . The other LEFT OUTER JOIN will match all rows related to , and is only used to populate the collection, for those objects that are returned. By changing the usage of to another style of loading, we can change how the collection is loaded completely independently of SQL used to retrieve the actual rows we want. Below we change into : When using joined eager loading, if the query contains a modifier that impacts the rows returned externally to the joins, such as when using DISTINCT, LIMIT, OFFSET or equivalent, the completed statement is first wrapped inside a subquery, and the joins used specifically for joined eager loading are applied to the subquery. SQLAlchemy’s joined eager loading goes the extra mile, and then ten miles further, to absolutely ensure that it does not affect the end result of the query, only the way collections and related objects are loaded, no matter what the format of the query is.\n\nSubqueryload eager loading is configured in the same manner as that of joined eager loading; for the parameter, we would specify rather than , and for the option we use the option rather than the option. The operation of subquery eager loading is to emit a second SELECT statement for each relationship to be loaded, across all result objects at once. This SELECT statement refers to the original SELECT statement, wrapped inside of a subquery, so that we retrieve the same list of primary keys for the primary object being returned, then link that to the sum of all the collection members to load them at once: The subqueryload strategy has many advantages over joined eager loading in the area of loading collections. First, it allows the original query to proceed without changing it at all, not introducing in particular a LEFT OUTER JOIN that may make it less efficient. Secondly, it allows for many collections to be eagerly loaded without producing a single query that has many JOINs in it, which can be even less efficient; each relationship is loaded in a fully separate query. Finally, because the additional query only needs to load the collection items and not the lead object, it can use an inner JOIN in all cases for greater query efficiency. Disadvantages of subqueryload include that the complexity of the original query is transferred to the relationship queries, which when combined with the use of a subquery, can on some backends in some cases (notably MySQL) produce significantly slow queries. Additionally, the subqueryload strategy can only load the full contents of all collections at once, is therefore incompatible with “batched” loading supplied by , both for collection and scalar relationships. The newer style of loading provided by solves these limitations of . A query which makes use of in conjunction with a limiting modifier such as , , or should always include against unique column(s) such as the primary key, so that the additional queries emitted by include the same ordering as used by the parent query. Without it, there is a chance that the inner query could return the wrong rows: # incorrect if User.name is not unique Why is ORDER BY recommended with LIMIT (especially with subqueryload())? - detailed example\n\nSelect IN loading is similar in operation to subquery eager loading, however the SELECT statement which is emitted has a much simpler structure than that of subquery eager loading. In most cases, selectin loading is the most simple and efficient way to eagerly load collections of objects. The only scenario in which selectin eager loading is not feasible is when the model is using composite primary keys, and the backend database does not support tuples with IN, which currently includes SQL Server. “Select IN” eager loading is provided using the argument to or by using the loader option. This style of loading emits a SELECT that refers to the primary key values of the parent object, or in the case of a many-to-one relationship to the those of the child objects, inside of an IN clause, in order to load related associations: Above, the second SELECT refers to , where the “5” and “7” are the primary key values for the previous two objects loaded; after a batch of objects are completely loaded, their primary key values are injected into the clause for the second SELECT. Because the relationship between and has a simple primary join condition and provides that the primary key values for can be derived from , the statement has no joins or subqueries at all. Changed in version 1.3: selectin loading can omit the JOIN for a simple one-to-many collection. For simple many-to-one loads, a JOIN is also not needed as the foreign key value from the parent object is used: Changed in version 1.3.6: selectin loading can also omit the JOIN for a simple many-to-one relationship. Select IN loading also supports many-to-many relationships, where it currently will JOIN across all three tables to match rows from one side to the other. Things to know about this kind of loading include:\n• None The SELECT statement emitted by the “selectin” loader strategy, unlike that of “subquery”, does not require a subquery nor does it inherit any of the performance limitations of the original query; the lookup is a simple primary key lookup and should have high performance.\n• None The special ordering requirements of subqueryload described at The Importance of Ordering also don’t apply to selectin loading; selectin is always linking directly to a parent primary key and can’t really return the wrong result.\n• None “selectin” loading, unlike joined or subquery eager loading, always emits its SELECT in terms of the immediate parent objects just loaded, and not the original type of object at the top of the chain. So if eager loading many levels deep, “selectin” loading still will not require any JOINs for simple one-to-many or many-to-one relationships. In comparison, joined and subquery eager loading always refer to multiple JOINs up to the original parent.\n• None The strategy emits a SELECT for up to 500 parent primary key values at a time, as the primary keys are rendered into a large IN expression in the SQL statement. Some databases like Oracle have a hard limit on how large an IN expression can be, and overall the size of the SQL string shouldn’t be arbitrarily large.\n• None As “selectin” loading relies upon IN, for a mapping with composite primary keys, it must use the “tuple” form of IN, which looks like . This syntax is not currently supported on SQL Server and for SQLite requires at least version 3.15. There is no special logic in SQLAlchemy to check ahead of time which platforms support this syntax or not; if run against a non-supporting platform, the database will return an error immediately. An advantage to SQLAlchemy just running the SQL out for it to fail is that if a particular database does start supporting this syntax, it will work without any changes to SQLAlchemy (as was the case with SQLite). In general, “selectin” loading is probably superior to “subquery” eager loading in most ways, save for the syntax requirement with composite primary keys and possibly that it may emit many SELECT statements for larger result sets. As always, developers should spend time looking at the statements and results generated by their applications in development to check that things are working efficiently.\n\nThe behavior of is such that joins are created automatically, using anonymous aliases as targets, the results of which are routed into collections and scalar references on loaded objects. It is often the case that a query already includes the necessary joins which represent a particular collection or scalar reference, and the joins added by the joinedload feature are redundant - yet you’d still like the collections/references to be populated. For this SQLAlchemy supplies the option. This option is used in the same manner as the option except it is assumed that the will specify the appropriate joins explicitly. Below, we specify a join between and and additionally establish this as the basis for eager loading of : If the “eager” portion of the statement is “aliased”, the path should be specified using , which allows the specific construct to be passed: # use an alias of the Address entity The path given as the argument to needs to be a full path from the starting entity. For example if we were loading , the option would be used as: When we use , we are constructing ourselves the SQL that will be used to populate collections. From this, it naturally follows that we can opt to modify what values the collection is intended to store, by writing our SQL to load a subset of elements for collections or scalar attributes. As an example, we can load a object and eagerly load only particular addresses into its collection by filtering the joined data, routing it using , also using to ensure any already-loaded collections are overwritten: The above query will load only objects which contain at least object that contains the substring in its field; the collection will contain only these entries, and not any other entries that are in fact associated with the collection. In all cases, the SQLAlchemy ORM does not overwrite already loaded attributes and collections unless told to do so. As there is an identity map in use, it is often the case that an ORM query is returning objects that were in fact already present and loaded in memory. Therefore, when using to populate a collection in an alternate way, it is usually a good idea to use as illustrated above so that an already-loaded collection is refreshed with the new data. will reset all attributes that were already present, including pending changes, so make sure all data is flushed before using it. Using the with its default behavior of autoflush is sufficient. The customized collection we load using is not “sticky”; that is, the next time this collection is loaded, it will be loaded with its usual default contents. The collection is subject to being reloaded if the object is expired, which occurs whenever the , methods are used assuming default session settings, or the or methods are used.\n\nThis is an advanced technique! Great care and testing should be applied. The ORM has various edge cases where the value of an attribute is locally available, however the ORM itself doesn’t have awareness of this. There are also cases when a user-defined system of loading attributes is desirable. To support the use case of user-defined loading systems, a key function is provided. This function is basically equivalent to Python’s own function, except that when applied to a target object, SQLAlchemy’s “attribute history” system which is used to determine flush-time changes is bypassed; the attribute is assigned in the same way as if the ORM loaded it that way from the database. The use of can be combined with another key event known as to produce attribute-population behaviors when an object is loaded. One such example is the bi-directional “one-to-one” case, where loading the “many-to-one” side of a one-to-one should also imply the value of the “one-to-many” side. The SQLAlchemy ORM does not consider backrefs when loading related objects, and it views a “one-to-one” as just another “one-to-many”, that just happens to be one row. Given the following mapping: If we query for an row, and then ask it for , we will get an extra SELECT: This SELECT is redundant because is the same value as . We can create an on-load rule to populate this for us: Now when we query for , we will get from the joined eager load, and from our event:"
    },
    {
        "link": "https://stackoverflow.com/questions/24115323/how-to-eagerly-load-objects-from-sqlalchemy-queries",
        "document": "I've tried setting several options on my query such as:\n\nBut I keep getting errors:\n\nIf I change this to:\n\nI want to detach my objects from the session and pass them back into client code that will only read the properties. Before I added options I was getting DetachedInstanceErrors.\n\nHow can I return fully hydrated objects from an sqlalchemy (0.9.4) query whose properties can be read by other parts of my code after the session is closed?"
    },
    {
        "link": "https://tutorialspoint.com/sqlalchemy/sqlalchemy_orm_eager_loading.htm",
        "document": "Eager load reduces the number of queries. SQLAlchemy offers eager loading functions invoked via query options which give additional instructions to the Query. These options determine how to load various attributes via the Query.options() method.\n\nWe want that Customer.invoices should load eagerly. The orm.subqueryload() option gives a second SELECT statement that fully loads the collections associated with the results just loaded. The name subquery causes the SELECT statement to be constructed directly via the Query re-used and embedded as a subquery into a SELECT against the related table.\n\nThis results in the following two SQL expressions −\n\nTo access the data from two tables, we can use the below program −\n\nThe output of the above program is as follows −\n\nThe other function is called orm.joinedload(). This emits a LEFT OUTER JOIN. Lead object as well as the related object or collection is loaded in one step.\n\nThis emits following expression giving same output as above −\n\nThe OUTER JOIN resulted in two rows, but it gives one instance of Customer back. This is because Query applies a uniquing strategy, based on object identity, to the returned entities. Joined eager loading can be applied without affecting the query results.\n\nThe subqueryload() is more appropriate for loading related collections while joinedload() is better suited for many-to-one relationship."
    },
    {
        "link": "http://docs.sqlalchemy.org/en/latest/orm/queryguide",
        "document": "This section provides an overview of emitting queries with the SQLAlchemy ORM using 2.0 style usage.\n\nReaders of this section should be familiar with the SQLAlchemy overview at SQLAlchemy Unified Tutorial, and in particular most of the content here expands upon the content at Using SELECT Statements.\n\nIn the SQLAlchemy 2.x series, SQL SELECT statements for the ORM are constructed using the same construct as is used in Core, which is then invoked in terms of a using the method (as are the and constructs now used for the ORM-Enabled INSERT, UPDATE, and DELETE statements feature). However, the legacy object, which performs these same steps as more of an “all-in-one” object, continues to remain available as a thin facade over this new system, to support applications that were built on the 1.x series without the need for wholesale replacement of all queries. For reference on this object, see the section Legacy Query API."
    },
    {
        "link": "http://docs.sqlalchemy.org/en/latest/faq/performance.html",
        "document": "Looking for performance issues typically involves two strategies. One is query profiling, and the other is code profiling. Sometimes just plain SQL logging (enabled via python’s logging module or via the argument on ) can give an idea how long things are taking. For example, if you log something right after a SQL operation, you’d see something like this in your log: if you logged right after the operation, you know it took 334ms to complete the SQL part of things. Logging SQL will also illustrate if dozens/hundreds of queries are being issued which could be better organized into much fewer queries. When using the SQLAlchemy ORM, the “eager loading” feature is provided to partially ( ) or fully ( , ) automate this activity, but without the ORM “eager loading” typically means to use joins so that results across multiple tables can be loaded in one result set instead of multiplying numbers of queries as more depth is added (i.e. …) For more long-term profiling of queries, or to implement an application-side “slow query” monitor, events can be used to intercept cursor executions, using a recipe like the following: Above, we use the and events to establish an interception point around when a statement is executed. We attach a timer onto the connection using the dictionary; we use a stack here for the occasional case where the cursor execute events may be nested. If logging reveals that individual queries are taking too long, you’d need a breakdown of how much time was spent within the database processing the query, sending results over the network, being handled by the DBAPI, and finally being received by SQLAlchemy’s result set and/or ORM layer. Each of these stages can present their own individual bottlenecks, depending on specifics. For that you need to use the Python Profiling Module. Below is a simple recipe which works profiling into a context manager: # uncomment this to see who's calling what The output of profiling can be used to give an idea where time is being spent. A section of profiling output looks like this: Above, we can see that the SQLAlchemy function was called 222 times (recursively, and 21 times from the outside), taking a total of .011 seconds for all calls combined. The specifics of these calls can tell us where the time is being spent. If for example, you see time being spent within , e.g. against the DBAPI: this would indicate that the database is taking a long time to start returning results, and it means your query should be optimized, either by adding indexes or restructuring the query and/or underlying schema. For that task, analysis of the query plan is warranted, using a system such as EXPLAIN, SHOW PLAN, etc. as is provided by the database backend. If on the other hand you see many thousands of calls related to fetching rows, or very long calls to , it may mean your query is returning more rows than expected, or that the fetching of rows itself is slow. The ORM itself typically uses to fetch rows (or if the option is used). An inordinately large number of rows would be indicated by a very slow call to at the DBAPI level: An unexpectedly large number of rows, even if the ultimate result doesn’t seem to have many rows, can be the result of a cartesian product - when multiple sets of rows are combined together without appropriately joining the tables together. It’s often easy to produce this behavior with SQLAlchemy Core or ORM query if the wrong objects are used in a complex query, pulling in additional FROM clauses that are unexpected. On the other hand, a fast call to at the DBAPI level, but then slowness when SQLAlchemy’s is asked to do a , may indicate slowness in processing of datatypes, such as unicode conversions and similar: # the DBAPI cursor is fast... 2 0.020 0.040 0.020 0.040 {method 'fetchall' of 'sqlite3.Cursor' objects} ... # but SQLAlchemy's result proxy is slow, this is type-level processing 2 0.100 0.200 0.100 0.200 lib/sqlalchemy/engine/result.py:778(fetchall) In some cases, a backend might be doing type-level processing that isn’t needed. More specifically, seeing calls within the type API that are slow are better indicators - below is what it looks like when we use a type like this: the profiling output of this intentionally slow operation can be seen like this: that is, we see many expensive calls within the system, and the actual time consuming thing is the call. Make sure to check the Dialect documentation for notes on known performance tuning suggestions at this level, especially for databases like Oracle. There may be systems related to ensuring numeric accuracy or string processing that may not be needed in all cases. There also may be even more low-level points at which row-fetching performance is suffering; for example, if time spent seems to focus on a call like , that could indicate that everything is fast except for the actual network connection, and too much time is spent with data moving over the network. To detect slowness in ORM fetching of rows (which is the most common area of performance concern), calls like and will illustrate individual ORM object populations: # the ORM calls _instance for each ORM-loaded row it sees, and # populate_state for each ORM-loaded row that results in the population # of an object's attributes 220/20 0.001 0.000 0.010 0.000 lib/sqlalchemy/orm/loading.py:327(_instance) 220/20 0.000 0.000 0.009 0.000 lib/sqlalchemy/orm/loading.py:284(populate_state) The ORM’s slowness in turning rows into ORM-mapped objects is a product of the complexity of this operation combined with the overhead of cPython. Common strategies to mitigate this include:\n• None fetch individual columns instead of full entities, that is:\n• None Use result caching - see Dogpile Caching for an in-depth example of this.\n• None Consider a faster interpreter like that of PyPy. The output of a profile can be a little daunting but after some practice they are very easy to read."
    },
    {
        "link": "https://stackoverflow.com/questions/27174217/sqlalchemy-query-using-joinedload-exponentially-slower-with-each-new-filter-clau",
        "document": "This was working perfectly, however I added two new filter queries:\n\nIf I add just the first filter the application hangs for a couple of seconds, if I add both the application hangs indefinitely\n\nWhat am I doing wrong here? How do I make this query fast?\n\nThank you for your help\n\nEDIT: This is the sql generated, unfortunately the class and variable names are in Portuguese, I just translated them to English so it would be easier to undertand, so Loja = Store, Vendedores = Salesmen, Pedido = Order, Comission = Comissao"
    },
    {
        "link": "https://soshace.com/2023/03/27/optimizing-database-interactions-in-python-sqlalchemy-best-practices",
        "document": "Databases are the lifeblood of modern applications, powering everything from simple blogs to complex e-commerce platforms. Python, one of the most popular and versatile programming languages, has a rich ecosystem of tools and libraries to interact with databases efficiently and effectively. Among these tools, SQLAlchemy stands out as a powerful and elegant solution that simplifies database interactions for Python developers. It brings the best of both worlds: the speed and performance of raw SQL and the ease and maintainability of Object Relational Mapping (ORM).\n\nIn this article, I will dive into the world of SQLAlchemy, uncovering the best practices for optimizing database interactions in Python applications. From designing efficient data models to managing transactions, I will guide you through a range of techniques that will help you build scalable and high-performing applications. I will also explore how to integrate SQLAlchemy with Flask, one of Python’s most popular web frameworks, to create seamless database-driven web applications.\n\nWhether you’re a seasoned developer or just starting with databases, this article will provide you with invaluable insights and practical examples to elevate your Python database skills. So, buckle up and get ready to embark on an exciting journey into Python, SQLAlchemy, and Flask!\n\nSQLAlchemy is a powerful Object Relational Mapper (ORM) library for Python that streamlines the interaction between Python code and relational databases. It provides an efficient and flexible way to query and manipulate data while abstracting the underlying database system.\n\nORM is a programming technique that maps database tables to Python classes and table records to class instances. This allows developers to work with database records using familiar object-oriented concepts, making the interaction with databases more intuitive and efficient.\n\nTo install SQLAlchemy, simply run the following command:\n\nOrganize your project files with the following structure:\n\nIn app/database.py, establish a connection with a database using the create_engine function from SQLAlchemy:\n\nReplace sqlite:///example.db with the connection string for your specific database.\n\nIn app/models.py, define Python classes for each table in the database, inheriting from Base, and map columns as class attributes:\n\nIn app/__init__.py, import the engine and Base objects to initialize the database:\n\nIn main.py, import the app module to run the application:\n\nNow, your application is set up with a proper structure and naming, ready for further development.\n\nA session in SQLAlchemy represents the “working space” for your application’s database operations. It helps manage transactions, connections, and queries. In app/database.py, create a session factory using the sessionmaker function:\n\nTo perform Create, Read, Update, and Delete (CRUD) operations, create a session instance and use it to interact with the database. For example, in main.py:\n\nRemember to commit changes using session.commit() and close the session using session.close() when finished.\n\nYou can use the filter, filter_by, and order_by methods to refine your queries. For instance, to find all books by a specific author and sort them by title:\n\nBest Practices for Efficient and Secure Database Interactions\n\nIt’s essential to manage database connections efficiently, especially in web applications with multiple concurrent users. Use the create_engine function to configure a connection pool that automatically handles connections:\n\nIn this example, the connection pool will have ten connections, with the option to overflow up to twenty additional connections if needed.\n\nUsing parameterized queries can help prevent SQL injection attacks and improve the readability of your code. SQLAlchemy automatically parameterizes queries when using its query API. For example:\n\nIn this example, the author_name variable is automatically parameterized, preventing potential SQL injection vulnerabilities.\n\nEager loading is the process of fetching related data in a single query, while lazy loading fetches related data only when needed. To avoid the N+1 query problem and reduce the number of queries made to the database, use eager loading. With SQLAlchemy, you can use the joinedload and subqueryload functions to load related data more efficiently:\n\nIn this eager loading example, the joinedload function ensures that the books for each author are fetched in a single query, rather than making a separate query for each author’s books. Lazy loading, on the other hand, can be beneficial when you don’t need all related data at once. By default, SQLAlchemy uses lazy loading for relationships. Here’s an example of lazy loading:\n\nIn this lazy loading example, the books for each author are fetched only when the author.books attribute is accessed. This can lead to multiple queries, which might be acceptable if you don’t need all the related data upfront.\n\nIt’s essential to analyze the SQL queries generated by SQLAlchemy to ensure their efficiency. Use the echo parameter when creating the engine to log SQL queries:\n\nBy reviewing the logged queries, you can identify potential bottlenecks and optimize your queries accordingly.\n\nProper indexing can significantly improve the performance of your database. Identify columns that are frequently used in WHERE, JOIN, and ORDER BY clauses, and add indexes to them. In SQLAlchemy, you can define indexes in your models:\n\nIn this example, an index is added to the title column of the Book table, which can help speed up queries involving this column. By following these best practices, you can ensure efficient and secure database interactions in your Python applications using SQLAlchemy and Flask.\n\nAlembic is a powerful migration tool for SQLAlchemy that allows you to apply incremental changes to your database schema while preserving existing data. By creating and managing migrations, Alembic helps to keep your database schema up to date as your application evolves. It integrates seamlessly with SQLAlchemy and can be easily configured to work with Flask applications, making it an essential tool for managing database schema changes in Python projects.\n\nConfigure the alembic.ini file with your database connection string. Then, create a new migration script:\n\nEdit the generated migration script to define the schema changes. Finally, apply the migration to the database:\n\nWhen you need to modify your database schema, create a new Alembic migration script and define the necessary changes in the upgrade and downgrade functions.\n\nWhen unit testing SQLAlchemy applications, use an in-memory SQLite database and session.rollback() to isolate test cases and ensure a clean state between tests:\n\nSome common issues with SQLAlchemy include incorrect relationship configurations and inefficient queries. Consult the SQLAlchemy documentation and use the query profiler to diagnose and resolve these issues.\n\nFlask-SQLAlchemy is an easy-to-use extension commonly employed to facilitate the seamless integration of SQLAlchemy with Flask web applications. This extension helps developers by simplifying the setup process and providing convenient functionality for working with databases in their Flask projects.\n\nWith Flask-SQLAlchemy, you can implement CRUD operations in a similar manner as with vanilla SQLAlchemy:\n\nIn this example, I use the db.session object provided by Flask-SQLAlchemy to manage transactions.\n\nBy following best practices with SQLAlchemy, you can optimize your database interactions and create efficient, secure, and maintainable applications. Some key takeaways include:\n\nTo deepen your understanding of SQLAlchemy and related topics, consult the following resources:\n\nAs I have covered the key aspects of optimizing database interactions in Python using SQLAlchemy and Flask, you are now well-equipped to develop efficient and maintainable applications. It is essential to continue expanding your knowledge and staying up-to-date with the latest best practices, as well as regularly reviewing your application’s performance to identify areas for improvement.\n\nFor further exploration and advanced topics, consider the following resources:\n• SQLAlchemy Recipes: A collection of usage patterns, techniques, and tips for working with SQLAlchemy more effectively.\n• Flask Mega-Tutorial: A comprehensive tutorial that covers Flask web application development, including using SQLAlchemy for database interactions.\n• Database Design Patterns: Understand the common database design mistakes and learn how to avoid them in your applications.\n• Python and PostgreSQL: If you are interested in using PostgreSQL as your database, this resource provides a detailed guide on integrating PostgreSQL with Python using SQLAlchemy and other tools.\n\nBy staying informed and continuously learning, you will be able to develop applications that can scale and perform well even under demanding workloads. Remember to collaborate with other developers, participate in online communities, and share your knowledge to help grow and strengthen the Python and SQLAlchemy ecosystems."
    },
    {
        "link": "http://docs.sqlalchemy.org/en/latest/orm/queryguide/relationships.html",
        "document": "A big part of SQLAlchemy is providing a wide range of control over how related objects get loaded when querying. By “related objects” we refer to collections or scalar associations configured on a mapper using . This behavior can be configured at mapper construction time using the parameter to the function, as well as by using ORM loader options with the construct.\n\nThe loading of relationships falls into three categories; lazy loading, eager loading, and no loading. Lazy loading refers to objects that are returned from a query without the related objects loaded at first. When the given collection or reference is first accessed on a particular object, an additional SELECT statement is emitted such that the requested collection is loaded.\n\nEager loading refers to objects returned from a query with the related collection or scalar reference already loaded up front. The ORM achieves this either by augmenting the SELECT statement it would normally emit with a JOIN to load in related rows simultaneously, or by emitting additional SELECT statements after the primary one to load collections or scalar references at once.\n\n“No” loading refers to the disabling of loading on a given relationship, either that the attribute is empty and is just never loaded, or that it raises an error when it is accessed, in order to guard against unwanted lazy loads.\n\nThe other, and possibly more common way to configure loading strategies is to set them up on a per-query basis against specific attributes using the method. Very detailed control over relationship loading is available using loader options; the most common are , and . The option accepts a class-bound attribute referring to the specific class/attribute that should be targeted: The loader options can also be “chained” using method chaining to specify how loading should occur further levels deep: Chained loader options can be applied against a “lazy” loaded collection. This means that when a collection or association is lazily loaded upon access, the specified option will then take effect: Above, the query will return objects without the collections loaded. When the collection on a particular object is first accessed, it will lazy load the related objects, but additionally apply eager loading to the collection on each member of . The relationship attributes used to indicate loader options include the ability to add additional filtering criteria to the ON clause of the join that’s created, or to the WHERE criteria involved, depending on the loader strategy. This can be achieved using the method which will pass through an option such that loaded results are limited to the given filter criteria: When using limiting criteria, if a particular collection is already loaded it won’t be refreshed; to ensure the new criteria takes place, apply the Populate Existing execution option: In order to add filtering criteria to all occurrences of an entity throughout a query, regardless of loader strategy or where it occurs in the loading process, see the function. Using method chaining, the loader style of each link in the path is explicitly stated. To navigate along a path without changing the existing loader style of a particular attribute, the method/function may be used: A similar approach can be used to specify multiple sub-options at once, using the method: Using load_only() on related objects and collections - illustrates examples of combining relationship and column-oriented loader options. The loader options applied to an object’s lazy-loaded collections are “sticky” to specific object instances, meaning they will persist upon collections loaded by that specific object for as long as it exists in memory. For example, given the previous example: if the collection on a particular object loaded by the above query is expired (such as when a object’s transaction is committed or rolled back, or is used), when the collection is next accessed in order to re-load it, the collection will again be loaded using subquery eager loading. This stays the case even if the above object is accessed from a subsequent query that specifies a different set of options. To change the options on an existing object without expunging it and re-loading, they must be set explicitly in conjunction using the Populate Existing execution option: # change the options on Parent objects that were already loaded If the objects loaded above are fully cleared from the , such as due to garbage collection or that were used, the “sticky” options will also be gone and the newly created objects will make use of new options if loaded again. A future SQLAlchemy release may add more alternatives to manipulating the loader options on already-loaded objects.\n\nBy default, all inter-object relationships are lazy loading. The scalar or collection attribute associated with a contains a trigger which fires the first time the attribute is accessed. This trigger typically issues a SQL call at the point of access in order to load the related object or objects: The one case where SQL is not emitted is for a simple many-to-one relationship, when the related object can be identified by its primary key alone and that object is already present in the current . For this reason, while lazy loading can be expensive for related collections, in the case that one is loading lots of objects with simple many-to-ones against a relatively small set of possible target objects, lazy loading may be able to refer to these objects locally without emitting as many SELECT statements as there are parent objects. This default behavior of “load upon attribute access” is known as “lazy” or “select” loading - the name “select” because a “SELECT” statement is typically emitted when the attribute is first accessed. Lazy loading can be enabled for a given attribute that is normally configured in some other way using the loader option: # force lazy loading for an attribute that is set to # load some other way normally The strategy produces an effect that is one of the most common issues referred to in object relational mapping; the N plus one problem, which states that for any N objects loaded, accessing their lazy-loaded attributes means there will be N+1 SELECT statements emitted. In SQLAlchemy, the usual mitigation for the N+1 problem is to make use of its very capable eager load system. However, eager loading requires that the attributes which are to be loaded be specified with the up front. The problem of code that may access other attributes that were not eagerly loaded, where lazy loading is not desired, may be addressed using the strategy; this loader strategy replaces the behavior of lazy loading with an informative error being raised: Above, a object loaded from the above query will not have the collection loaded; if some code later on attempts to access this attribute, an ORM exception is raised. may be used with a so-called “wildcard” specifier to indicate that all relationships should use this strategy. For example, to set up only one attribute as eager loading, and all the rest as raise: The above wildcard will apply to all relationships not just on besides , but all those on the objects as well. To set up for only the objects, specify a full path with : Conversely, to set up the raise for just the objects: The option applies only to relationship attributes. For column-oriented attributes, the option supports the option which works in the same way. The “raiseload” strategies do not apply within the unit of work flush process. That means if the process needs to load a collection in order to finish its work, it will do so while bypassing any directives.\n\nJoined eager loading is the oldest style of eager loading included with the SQLAlchemy ORM. It works by connecting a JOIN (by default a LEFT OUTER join) to the SELECT statement emitted, and populates the target scalar/collection from the same result set as that of the parent. At the mapping level, this looks like: Joined eager loading is usually applied as an option to a query, rather than as a default loading option on the mapping, in particular when used for collections rather than many-to-one-references. This is achieved using the loader option: When including in reference to a one-to-many or many-to-many collection, the method must be applied to the returned result, which will uniquify the incoming rows by primary key that otherwise are multiplied out by the join. The ORM will raise an error if this is not present. This is not automatic in modern SQLAlchemy, as it changes the behavior of the result set to return fewer ORM objects than the statement would normally return in terms of number of rows. Therefore SQLAlchemy keeps the use of explicit, so there’s no ambiguity that the returned objects are being uniqified on primary key. The JOIN emitted by default is a LEFT OUTER JOIN, to allow for a lead object that does not refer to a related row. For an attribute that is guaranteed to have an element, such as a many-to-one reference to a related object where the referencing foreign key is NOT NULL, the query can be made more efficient by using an inner join; this is available at the mapping level via the flag: At the query option level, via the flag: The JOIN will right-nest itself when applied in a chain that includes an OUTER JOIN: If using database row locking techniques when emitting the SELECT, meaning the method is being used to emit SELECT..FOR UPDATE, the joined table may be locked as well, depending on the behavior of the backend in use. It’s not recommended to use joined eager loading at the same time as SELECT..FOR UPDATE for this reason. Since joined eager loading seems to have many resemblances to the use of , it often produces confusion as to when and how it should be used. It is critical to understand the distinction that while is used to alter the results of a query, goes through great lengths to not alter the results of the query, and instead hide the effects of the rendered join to only allow for related objects to be present. The philosophy behind loader strategies is that any set of loading schemes can be applied to a particular query, and the results don’t change - only the number of SQL statements required to fully load related objects and collections changes. A particular query might start out using all lazy loads. After using it in context, it might be revealed that particular attributes or collections are always accessed, and that it would be more efficient to change the loader strategy for these. The strategy can be changed with no other modifications to the query, the results will remain identical, but fewer SQL statements would be emitted. In theory (and pretty much in practice), nothing you can do to the would make it load a different set of primary or related objects based on a change in loader strategy. How in particular achieves this result of not impacting entity rows returned in any way is that it creates an anonymous alias of the joins it adds to your query, so that they can’t be referenced by other parts of the query. For example, the query below uses to create a LEFT OUTER JOIN from to , however the added against is not valid - the entity is not named in the query: Above, is not valid since is not in the FROM list. The correct way to load the records and order by email address is to use : The statement above is of course not the same as the previous one, in that the columns from are not included in the result at all. We can add back in, so that there are two joins - one is that which we are ordering on, the other is used anonymously to load the contents of the collection: What we see above is that our usage of is to supply JOIN clauses we’d like to use in subsequent query criterion, whereas our usage of only concerns itself with the loading of the collection, for each in the result. In this case, the two joins most probably appear redundant - which they are. If we wanted to use just one JOIN for collection loading as well as ordering, we use the option, described in Routing Explicit Joins/Statements into Eagerly Loaded Collections below. But to see why does what it does, consider if we were filtering on a particular : Above, we can see that the two JOINs have very different roles. One will match exactly one row, that of the join of and where . The other LEFT OUTER JOIN will match all rows related to , and is only used to populate the collection, for those objects that are returned. By changing the usage of to another style of loading, we can change how the collection is loaded completely independently of SQL used to retrieve the actual rows we want. Below we change into : When using joined eager loading, if the query contains a modifier that impacts the rows returned externally to the joins, such as when using DISTINCT, LIMIT, OFFSET or equivalent, the completed statement is first wrapped inside a subquery, and the joins used specifically for joined eager loading are applied to the subquery. SQLAlchemy’s joined eager loading goes the extra mile, and then ten miles further, to absolutely ensure that it does not affect the end result of the query, only the way collections and related objects are loaded, no matter what the format of the query is.\n\nIn most cases, selectin loading is the most simple and efficient way to eagerly load collections of objects. The only scenario in which selectin eager loading is not feasible is when the model is using composite primary keys, and the backend database does not support tuples with IN, which currently includes SQL Server. “Select IN” eager loading is provided using the argument to or by using the loader option. This style of loading emits a SELECT that refers to the primary key values of the parent object, or in the case of a many-to-one relationship to the those of the child objects, inside of an IN clause, in order to load related associations: Above, the second SELECT refers to , where the “5” and “7” are the primary key values for the previous two objects loaded; after a batch of objects are completely loaded, their primary key values are injected into the clause for the second SELECT. Because the relationship between and has a simple primary join condition and provides that the primary key values for can be derived from , the statement has no joins or subqueries at all. For simple many-to-one loads, a JOIN is also not needed as the foreign key value from the parent object is used: by “simple” we mean that the condition expresses an equality comparison between the primary key of the “one” side and a straight foreign key of the “many” side, without any additional criteria. Select IN loading also supports many-to-many relationships, where it currently will JOIN across all three tables to match rows from one side to the other. Things to know about this kind of loading include:\n• None The strategy emits a SELECT for up to 500 parent primary key values at a time, as the primary keys are rendered into a large IN expression in the SQL statement. Some databases like Oracle Database have a hard limit on how large an IN expression can be, and overall the size of the SQL string shouldn’t be arbitrarily large.\n• None As “selectin” loading relies upon IN, for a mapping with composite primary keys, it must use the “tuple” form of IN, which looks like . This syntax is not currently supported on SQL Server and for SQLite requires at least version 3.15. There is no special logic in SQLAlchemy to check ahead of time which platforms support this syntax or not; if run against a non-supporting platform, the database will return an error immediately. An advantage to SQLAlchemy just running the SQL out for it to fail is that if a particular database does start supporting this syntax, it will work without any changes to SQLAlchemy (as was the case with SQLite).\n\nThe eager loader is mostly legacy at this point, superseded by the strategy which is of much simpler design, more flexible with features such as Yield Per, and emits more efficient SQL statements in most cases. As relies upon re-interpreting the original SELECT statement, it may fail to work efficiently when given very complex source queries. may continue to be useful for the specific case of an eager loaded collection for objects that use composite primary keys, on the Microsoft SQL Server backend that continues to not have support for the “tuple IN” syntax. Subquery loading is similar in operation to selectin eager loading, however the SELECT statement which is emitted is derived from the original statement, and has a more complex query structure as that of selectin eager loading. Subquery eager loading is provided using the argument to or by using the loader option. The operation of subquery eager loading is to emit a second SELECT statement for each relationship to be loaded, across all result objects at once. This SELECT statement refers to the original SELECT statement, wrapped inside of a subquery, so that we retrieve the same list of primary keys for the primary object being returned, then link that to the sum of all the collection members to load them at once: Things to know about this kind of loading include:\n• None The SELECT statement emitted by the “subquery” loader strategy, unlike that of “selectin”, requires a subquery, and will inherit whatever performance limitations are present in the original query. The subquery itself may also incur performance penalties based on the specifics of the database in use.\n• None “subquery” loading imposes some special ordering requirements in order to work correctly. A query which makes use of in conjunction with a limiting modifier such as , or should always include against unique column(s) such as the primary key, so that the additional queries emitted by include the same ordering as used by the parent query. Without it, there is a chance that the inner query could return the wrong rows: # incorrect if User.name is not unique Why is ORDER BY recommended with LIMIT (especially with subqueryload())? - detailed example\n• None “subquery” loading also incurs additional performance / complexity issues when used on a many-levels-deep eager load, as subqueries will be nested repeatedly.\n• None “subquery” loading is not compatible with the “batched” loading supplied by Yield Per, both for collection and scalar relationships. For the above reasons, the “selectin” strategy should be preferred over “subquery”.\n\nThe behavior of is such that joins are created automatically, using anonymous aliases as targets, the results of which are routed into collections and scalar references on loaded objects. It is often the case that a query already includes the necessary joins which represent a particular collection or scalar reference, and the joins added by the joinedload feature are redundant - yet you’d still like the collections/references to be populated. For this SQLAlchemy supplies the option. This option is used in the same manner as the option except it is assumed that the object will explicitly include the appropriate joins, typically using methods like . Below, we specify a join between and and additionally establish this as the basis for eager loading of : If the “eager” portion of the statement is “aliased”, the path should be specified using , which allows the specific construct to be passed: # use an alias of the Address entity The path given as the argument to needs to be a full path from the starting entity. For example if we were loading , the option would be used as: When we use , we are constructing ourselves the SQL that will be used to populate collections. From this, it naturally follows that we can opt to modify what values the collection is intended to store, by writing our SQL to load a subset of elements for collections or scalar attributes. SQLAlchemy now has a much simpler way to do this, by allowing WHERE criteria to be added directly to loader options such as and using . See the section Adding Criteria to loader options for examples. The techniques described here still apply if the related collection is to be queried using SQL criteria or modifiers more complex than a simple WHERE clause. As an example, we can load a object and eagerly load only particular addresses into its collection by filtering the joined data, routing it using , also using Populate Existing to ensure any already-loaded collections are overwritten: The above query will load only objects which contain at least object that contains the substring in its field; the collection will contain only these entries, and not any other entries that are in fact associated with the collection. In all cases, the SQLAlchemy ORM does not overwrite already loaded attributes and collections unless told to do so. As there is an identity map in use, it is often the case that an ORM query is returning objects that were in fact already present and loaded in memory. Therefore, when using to populate a collection in an alternate way, it is usually a good idea to use Populate Existing as illustrated above so that an already-loaded collection is refreshed with the new data. The option will reset all attributes that were already present, including pending changes, so make sure all data is flushed before using it. Using the with its default behavior of autoflush is sufficient. The customized collection we load using is not “sticky”; that is, the next time this collection is loaded, it will be loaded with its usual default contents. The collection is subject to being reloaded if the object is expired, which occurs whenever the , methods are used assuming default session settings, or the or methods are used. Adding Criteria to loader options - modern API allowing WHERE criteria directly within any relationship loader option"
    },
    {
        "link": "https://medium.com/@yashwanthnandam/optimizing-sqlalchemy-queries-in-flask-05d0caeec501",
        "document": "When I first started working with SQLAlchemy in my Flask application, everything seemed smooth. My queries were working well, and performance was acceptable during early development. But as my database grew, query times started creeping up — and suddenly, I found myself with a 1300ms query, making my once-fast app sluggish. The goal of this article is to show you practical ways I used to reduce SQLAlchemy query execution time in a Flask app from 1300ms to just 200ms. I’ll walk you through how I identified and fixed performance bottlenecks using profiling tools, query optimizations, and batch operations, with real examples and results. Disclaimer: GPT-4 assisted me in writing this article, combining its insights with my personal experiments\n• Conclusion: How We Went from 1300ms to 200ms\n\nTo get started, let me explain the query that was giving me trouble. I was querying all Order records, including their related User data. Here's how my code initially looked: Pretty straightforward, right? Well, this simplicity masked a much deeper issue. SQLAlchemy was issuing a separate query for each order.user lookup, leading to the classic N+1 problem.\n• N queries to fetch User for each order: 700ms This was unacceptable, especially as the application scaled. Something had to be done.\n\nThe first thing I tried was query caching. For read-heavy data, caching frequent queries can be an effective strategy. I decided to cache the entire query result using Flask-Cache: With this setup, the first request would still take 1300ms, but subsequent requests would hit the cache and avoid hitting the database altogether. While this was a noticeable improvement, caching wasn’t enough for dynamic data where frequent updates happen, and I knew I had to improve the underlying query itself.\n\nNext, I looked into SQLAlchemy’s eager loading feature. SQLAlchemy defaults to lazy-loading related objects (like the User for each Order ), meaning each related lookup triggers a new query, causing the N+1 problem. By using , I could fetch the related User data in a single query. This change drastically reduced the number of database queries by loading all the related data in a single SQL join, improving performance dramatically. At this point, we had already shaved off 900ms from the original 1300ms query. But there was still room for improvement, especially for cases involving complex relationships.\n\nAfter addressing the simple foreign key relationship (Order → User), I noticed another potential issue with many-to-many relationships between Order and Item. For every order, I needed to display the associated items, and again, the N+1 problem reared its head. The solution was to use SQLAlchemy’s for more complex relationships, which performs a separate query for the relationship and then fetches everything in a single round trip. This ensured that the Order and its related Items were fetched in one go, rather than issuing a new query for each order. The N+1 problem was now fully resolved for both simple and complex relationships, leaving the application much more performant. But we weren’t done yet.\n\nIn scenarios where bulk operations like inserts or updates were involved, I was noticing performance hits due to executing individual queries for each record. For example, creating 1000 new Order records with separate statements was taking too long. This reduced the number of queries from 1000 to just one, saving a lot of time in the process. This brought us to the final performance benchmark: 1300ms all the way down to 200ms. A remarkable 84% reduction in query time, making the application far more scalable and responsive."
    }
]