[
    {
        "link": "https://geeksforgeeks.org/paging-in-operating-system",
        "document": "Paging is a memory management scheme that eliminates the need for a contiguous allocation of physical memory. The process of retrieving processes in the form of pages from the secondary storage into the main memory is known as paging. The basic purpose of paging is to separate each procedure into pages.\n\nThe mapping between logical pages and physical page frames is maintained by the page table, which is used by the memory management unit to translate logical addresses into physical addresses. The page table maps each logical page number to a physical page frame number. By using a Page Table, the operating system keeps track of the mapping between logical addresses (used by programs) and physical addresses (actual locations in memory).\n\nWhy Paging is used for memory Management?\n\nPaging is a memory management technique that addresses common challenges in allocating and managing memory efficiently. Here we can understand why paging is needed as a Memory Management technique:\n• Memory isn’t always available in a single block: Programs often need more memory than what is available in a single continuous block. Paging breaks memory into smaller, fixed-size pieces, making it easier to allocate scattered free spaces.\n• Processes size can increase or decrease: programs don’t need to occupy continuous memory, so they can grow dynamically without the need to be moved.\n• Logical Address or Virtual Address: , also known as the Virtual Address, is the address generated by the CPU when a program accesses memory.\n• Logical Address Space or Virtual Address Space: The Logical Address Space, also known as the Virtual Address Space, refers to the set of all possible logical addresses that a process can generate during its execution. It is a conceptual range of memory addresses used by a program and is independent of the actual physical memory (RAM).\n• Physical Address: is the actual location in the computer’s physical memory (RAM) where data or instructions are stored. It is used by the memory hardware to access specific data in the system’s memory.\n• Physical Address Space: The Physical Address Space refers to the total range of addresses available in a computer’s physical memory (RAM). It represents the actual memory locations that can be accessed by the system hardware to store or retrieve data.\n• Logical to bodily address mapping: In paging, the logical address area of a technique is divided into constant-sized pages, and each web page is mapped to a corresponding physical body within the main reminiscence. This permits the working gadget to manipulate the memory in an extra flexible way, as it is able to allocate and deallocate frames as needed.\n• Fixed web page and frame length: Paging makes use of a set web page length, which is usually identical to the size of a frame within the most important memory. This facilitates simplifying the reminiscence control technique and improves device performance.\n• Page desk entries: Each page within the logical address area of a method is represented through a , which contains facts approximately the corresponding bodily body in the predominant memory. This consists of the frame range, in addition to other manipulate bits which can be used by the running machine to manage the reminiscence.\n• A number of page desk entries: The range of page desk entries in a manner’s page desk is identical to the wide variety of pages inside the logical deal with the area of the technique.\n• Page table stored in important memory: The web page desk for each system is typically saved in important reminiscence, to allow for green get right of entry to and change by the operating device. However, this could additionally introduce overhead, because the web page table must be updated on every occasion a system is swapped in or out of the main memory.\n\nPaging is a method used by operating systems to manage memory efficiently. In paging, the physical memory is divided into fixed-size blocks called page frames, which are the same size as the pages used by the process. The process’s logical address space is also divided into fixed-size blocks called pages, which are the same size as the page frames.\n\nWhen a process requests memory, the operating system allocates one or more page frames to the process and maps the process’s logical pages to the physical page frames. When a program runs, its pages are loaded into any available frames in the physical memory.\n\nThis approach prevents fragmentation issues by keeping memory allocation uniform. Each program has a page table, which the operating system uses to keep track of where each page is stored in physical memory. When a program accesses data, the system uses this table to convert the program’s address into a physical memory address.\n\nPaging allows for better memory use and makes it easier to manage. It also supports virtual memory, letting parts of programs be stored on disk and loaded into memory only when needed. This way, even large programs can run without fitting entirely into main memory.\n\nThe mapping from virtual to physical address is done by the Memory Management Unit (MMU) which is a hardware device and this mapping is known as the paging technique.\n• None The Physical Address Space is conceptually divided into a number of fixed-size blocks, called frames\n• None The Logical Address Space is also split into fixed-size blocks, called pages\n\nThe address generated by the CPU is divided into\n• Page number(p): Number of bits required to represent the pages in\n• Page offset(d): Number of bits required to represent a particular word in a page or page size of Logical Address Space or word number of a page or page offset.\n\nA Physical Address is divided into two main parts:\n• Frame Number(f): Number of bits required to represent the frame of Physical Address Space or Frame number frame\n• Frame Offset(d): Number of bits required to represent a particular word in a frame or frame size of Physical Address Space or word number of a frame or frame offset.\n\nSo, a physical address in this scheme may be represented as follows:\n• None Each entry in TLB consists of two parts: a tag and a value.\n• None When this memory is used, then an item is compared with all tags simultaneously. If the item is found, then the corresponding value is returned.\n\nPaging is a memory management technique used in operating systems to manage memory and allocate memory to processes. In paging, memory is divided into fixed-size blocks called pages, and processes are allocated memory in terms of these pages. Each page is of the same size, and the size is typically a power of 2, such as 4KB or 8 KB.\n\nThe hardware implementation of the page table can be done by using dedicated registers. But the usage of the register for the page table is satisfactory only if the page table is small. If the page table contains a large number of entries then we can use TLB(translation Look-aside buffer), a special, small, fast look-up hardware cache.\n• None Each entry in TLB consists of two parts: a tag and a value.\n• None When this memory is used, then an item is compared with all tags simultaneously. If the item is found, then the corresponding value is returned.\n\nRead more about – TLB hit and miss\n• Eliminates External Fragmentation: Paging divides memory into fixed-size blocks (pages and frames), so processes can be loaded wherever there is free space in memory. This prevents wasted space due to fragmentation.\n• Efficient Memory Utilization: Since pages can be placed in non-contiguous memory locations, even small free spaces can be utilized, leading to better memory allocation.\n• Supports Virtual Memory: Paging enables the implementation of virtual memory, allowing processes to use more memory than physically available by swapping pages between RAM and secondary storage.\n• Ease of Swapping: Individual pages can be moved between physical memory and disk (swap space) without affecting the entire process, making swapping faster and more efficient.\n• Improved Security and Isolation: Each process works within its own set of pages, preventing one process from accessing another’s memory space.\n• Internal Fragmentation: If the size of a process is not a perfect multiple of the page size, the unused space in the last page results in internal fragmentation.\n• Increased Overhead: Table requires additional memory and processing. For large processes, the page table can grow significantly, consuming valuable memory resources.\n• Page Table Lookup Time: Accessing memory requires translating logical addresses to physical addresses using the page table. This additional step increases memory access time, although Translation Lookaside Buffers (TLBs) can help reduce the impact.\n• I/O Overhead During Page Faults: When a required page is not in physical memory (page fault), it needs to be fetched from secondary storage, causing delays and increased I/O operations.\n• Complexity in Implementation: Paging requires sophisticated hardware and software support, including the Memory Management Unit (MMU) and algorithms for which add complexity to the system.\n\nA memory management unit (MMU) is a technique used to convert logical address to physical address. Logical address is the address generated by CPU for each page and physical address is the real address of the frame where page is going to be stored.\n\nWhenever a page has to be accessed by CPU using the logical address, it requires physical address for accessing the page. Logical address comprises of two parts: Page Number and Offset.\n\nAlso read – Multilevel Paging in Operating System\n\nAlso read – Paged Segmentation and Segmented Paging\n\nIn conclusion, paging is a memory management technique that helps computers in storing data efficiently and it also helps in retrieve data as it breaks the memory into small, fixed size chunks called pages. It helps in handling larger amount of data without the issue of fragmentation that improves the performance and usability.\n\nWhat is the use of Paging in an Operating System?\n\nWhat is the basic advantage of Paging?\n\nWhat is the effect of Paging?"
    },
    {
        "link": "https://phoenixnap.com/kb/paging",
        "document": "Paging is a memory management technique in operating systems that enables processes to access more memory than is physically available. The system improves performance and resource utilization and reduces the risk of page faults. This method is also known as swapping in Unix-like systems.\n\nThis article explains what paging in operating systems is and how it works.\n\nPaging is a memory management method that enables processes to use virtual storage. A process has access to the pages it needs without waiting for them to be loaded into physical memory. The technique stores and retrieves data from a computer's secondary or virtual storage (hard drive, SSD, etc.) to the primary storage (RAM).\n\nWhen a process tries to access a page that is not in RAM, the OS brings in the page from the virtual memory.\n\nPaging improves the efficiency of memory management. By dividing memory into pages, the operating system moves pages in and out of memory as needed. Keeping only the frequently used pages reduces the number of page faults, which improves system performance and responsiveness.\n\nPaging enables an OS to transfer data between secondary (virtual) and primary (physical) memory. Both storage types are divided into fixed-size blocks. The blocks in primary memory are frames, while those in secondary storage are pages.\n\nWhenever a program executes, it splits into pages, and the OS automatically stores them in secondary memory.\n\nWhen the process requests memory, the OS allocates page frames from the primary memory to the process. Next, the OS moves program pages from the secondary memory to the primary memory frames.\n\nThe logical pages and physical page frames maintain the relationship using a structure called the page table. The memory management unit (MMU) uses the page table to translate logical addresses (virtual memory) into physical addresses (physical memory).\n\nUse the following command to print the page table in the terminal/command prompt in Linux:\n\nFor the command to work, find the process ID first using the , top, , or command. For instance, if the PID for the running process of choice is 17422, print the table with the following command:\n\nThe command output consists of multiple lines, each with four columns except for the first. The first line shows the process ID (PID) and the name. The remaining lines list the mapped virtual page addresses for the process.\n\nThe columns in the output have the following information:\n• Mode. The permissions for the page.\n• Mapping. The name of the file or object the page is mapped to.\n\nKnowing the associated terminology is essential to understanding the paging process. Below is a list of common terminology when working with paging:\n• Pages. Fixed-sized blocks of logical/secondary memory. Pages represent a unit of information transfer between main memory and secondary storage. A page set is a process working set. A working set constantly changes as the process accesses different parts of memory.\n• Page table. A data structure that enables the memory management unit (MMU) to translate logical addresses into physical addresses.\n• Physical memory. The actual memory available to the computer, usually in the form of RAM. In paging, the physical, or main, memory splits into fixed-size blocks or page frames, each with a unique address. The frames are the same size as the pages used by the process.\n• Virtual memory (logical/secondary memory). A hard disk or solid-state drive that serves as an extension of the main memory. It compensates for physical memory shortages by temporarily bringing in data from RAM. The logical memory is divided into the same size blocks, called pages. Each page has a logical address within the virtual memory.\n• Memory management unit (MMU). A hardware component that translates logical addresses into physical addresses. The MMU also manages the allocation and deallocation of pages in memory.\n• Logical address (virtual address). When a program runs, the CPU generates a logical address for each page. The MMU translates logical into physical addresses.\n• Physical address. Each frame within a physical memory has a unique physical address. Addresses represent a specific location of a process in actual memory.\n• Physical address space. The range of all possible physical addresses a system is able to reference.\n\nPaging involves the systematic retrieval and display of segmented information. The paging workflow either ends with a page hit or encounters a page fault.\n\nThe workflow follows these steps:\n\n2. The OS allocates the process segments into the same-sized pages in the virtual memory. It also creates corresponding page frames in physical memory.\n\n3. The OS creates a page table, which maps the process's logical pages to the physical page frames.\n\n4. Another process requests access to the process frame or page.\n\n5a. The requested page is already in the main memory, and the process continues execution, creating a page hit.\n\n5b. If the requested page is not in the main memory, the system is dealing with the page fault or page miss. The paging process continues to resolve the issue:\n\n6. The memory management unit (MMU) uses the page table to identify the process's correct location (correct page frame) in the physical memory.\n\n7. The page table updates with the correct physical address.\n\n8. The OS brings the page into page frames in the primary memory,\n\n9. The process resumes from the point of interruption, and can now access the page. The page fault resolves.\n\nThe paging implementation offers multiple methods, and the choice of a specific technique depends on several factors. This includes the OS type, available memory, and the process's requirements.\n\nFor example, demand paging is a good choice for operating systems that need to be efficient. On the other hand, anticipatory paging is a better choice for operating systems that need to be responsive.\n\nThe text below explains the different paging techniques:\n• Demand paging. The most common memory management technique in modern operating systems like Windows, Linux, and macOS. It optimizes memory usage by keeping only the currently used page in memory.\n• Anticipatory paging. A more aggressive form of demand paging that preloads the pages near the requested page as soon as possible. The goal is to reduce page faults and latency by predicting which pages not in RAM are likely to be needed soon.\n• Prepaging. Prepaging is a less aggressive form of anticipatory paging. The system preloads any pages that might be needed in the near future (but not immediately or soon).\n• Free page queue, stealing, and reclamation. These techniques manage memory by keeping track of free frames and reallocating the frames as needed.\n• The free page queue. A list of page frames available for allocation. By ensuring the queue never empties, the process minimizes dealing with page faults.\n• Page stealing. A process of freeing up page frames. Pages that haven't been referenced recently are removed from memory. The free page frames are then added to the free page queue.\n• Reclaiming. Reclaiming (in conjunction with stealing) frees up page frames no longer in use. However, reclaiming is more aggressive. The OS can even reclaim the pages that are likely to restart soon.\n• Pre-cleaning. The process saves the contents of modified pages back to disk, even if those pages are likely to be modified again soon. When a new program runs, the system does not have to wait for the pages to be read from disk, which improves the start-up time.\n• Copy-on-write paging. When a process attempts to write to a page that is already in use by another process, the OS creates a copy of the page and gives the process exclusive access to the copy. This ensures that the two processes cannot overwrite each other's data.\n• Segmented paging. Combines paging with segmentation by splitting the main memory into variable-sized segments, each with a page table. The segments divide into even smaller, fixed-sized pages. Unlike virtual memory, which employs page-based division, segments handle the mapping of virtual to physical memory addresses.\n• Inverted paging. A technique where the page table is in memory, and the physical memory is divided into frames. When a process needs to access a page, it looks up the page table to find the physical frame.\n\nA page fault occurs when a process tries to access a page not present in physical memory. The page is unavailable either because it has not been in use recently or because there is insufficient memory.\n• The page has never been loaded into memory before.\n• The page has been removed from memory to make room for another page.\n• The page has been modified in memory and needs to be written back to disk.\n\nThe best strategy for dealing with page faults depends on several factors, including the OS type, the available memory, and the processes. The OS handles page faults using either a paging method or by terminating the process.\n\nPossible solutions are to do one of the following:\n• Terminate the program if the page is not important or if the program is not in a critical section. Different page replacement algorithms determine which page to evict when a page fault occurs. The most common page replacement algorithms include Least Recently Used (LRU), First In, First Out (FIFO), and Optimal.\n• Move an unused page to the secondary memory and bring in the page causing the page fault to the primary memory. The goal is to ensure the program is able to continue running.\n• Preload pages that the operating system predicts are going to be needed soon (anticipatory paging or prepaging). This helps reduce page faults but also leads to wasting memory if the preloaded pages are unused.\n\nThrashing occurs in virtual memory when the page fault rate becomes so high that the system spends more time servicing page faults and not enough time executing user code.\n\nThe feedback loop that causes thrashing begins when a process experiences a page fault. The operating system (OS) must then load the requested page from the disk into memory, which is time-consuming.\n\nIf the OS receives multiple page faults in a brief period, it spends all the time servicing page faults and none executing user code.\n\nIf thrashing occurs, the system continues to slow down until it becomes unusable. The only way to fix thrashing is to address the underlying causes. Some of the causes include:\n• Too many processes. When the operating system runs too many processes, it can't keep up with the demands. This leads to a high page faults rate, as the operating system has to swap pages in and out of memory frequently.\n• Too much memory usage. Processes that use a lot of memory prevent the operating system from simultaneously keeping all the pages in memory. This also leads to a high rate of page faults.\n• Poor page replacement algorithm. The page replacement algorithm decides which page to evict when a page fault occurs. If the page replacement algorithm is not good, it evicts frequently used pages, which leads to a high rate of page faults.\n• A high degree of multiprogramming. When the multiprogramming degree is high, processes run simultaneously in the system. This puts a strain on the operating system and leads to thrashing.\n• Lack of frames: If there are not enough frames available in memory, the operating system has to evict pages from memory when new pages arrive.\n\nDifferent methods to prevent thrashing are:\n\nPaging allows operating systems to use physical memory more efficiently and improves system performance. Key paging advantages are:\n• Reducing external fragmentation. Paging allows the operating system to use more memory than possible if all pages are simultaneously resident in memory. The OS moves pages not currently in use onto the disk and then swaps them back in when needed.\n• Improving memory usage. Paging improves performance by reducing the time the CPU waits for pages to load from the disk. The operating system keeps the most frequently used pages in memory and only swaps out the pages not used as often.\n• Simplifying memory management. Paging streamlines memory management for the operating system. Therefore, the OS only has to keep track of the pages currently in memory rather than the entire address space of each process.\n• Efficient swapping. With paging, the operating system does not have to consider fragmentation when swapping out a page. Moreover, the OS chooses the page least likely to be used.\n• Supports virtual memory. Virtual memory support means each process has its own address space, even if the physical memory is not large enough to accommodate all the processes.\n\nPaging is a very effective way to use physical memory, but it also adds complexity to the OS and causes page faults. While the advantages outweigh the disadvantages, the following list represents key drawbacks:\n• Increased overhead. Paging introduces overhead, as the operating system has to track which pages are in memory and which are on disk. Therefore, this overhead reduces performance, especially on systems with slow disks.\n• Page faults. Paging can lead to page faults. The faults occur when the operating system needs to load a page from the disk into memory. When they happen frequently, the system slows down.\n• Complexity. Paging is a complex and challenging system to implement and debug.\n• Internal fragmentation. Paging increases internal fragmentation, as the last page of a process is not fully used, leading to wasted memory.\n• Page table overhead: Paging requires page tables, which consume significant memory. Multilevel page tables and variable page sizes (super-pages) mitigate the issue.\n\nAfter reading this text, you now understand how paging in operating systems works, and the advantages and disadvantages.\n\nNext, learn how to check memory usage in Linux to monitor the system efficiently."
    },
    {
        "link": "https://workat.tech/core-cs/tutorial/paging-in-operating-system-os-knbcthp3w8o7",
        "document": ""
    },
    {
        "link": "https://simplilearn.com/paging-in-os-article",
        "document": ""
    },
    {
        "link": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-paging.pdf",
        "document": ""
    },
    {
        "link": "https://geeksforgeeks.org/difference-between-paging-and-segmentation",
        "document": "In computer operating systems, memory management is crucial for efficient use of resources. Paging and segmentation are two fundamental techniques used to organize and allocate memory. Paging divides memory into fixed-size blocks called pages, simplifying management by treating memory as a uniform structure.\n\nSegmentation, in contrast, divides memory into variable-sized segments based on logical units, offering flexibility in organizing data and code. Both methods have distinct advantages and are chosen based on the specific needs and complexities of applications and system architectures.\n\nPaging is a method or technique which is used for non-contiguous memory allocation. It is a fixed-size partitioning theme (scheme). In paging, both main memory and secondary memory are divided into equal fixed-size partitions. The partitions of the secondary memory area unit and main memory area unit are known as pages and frames respectively.\n\nPaging is a memory management method accustomed to fetching processes from the secondary memory into the main memory in the form of pages. in paging, each process is split into parts wherever the size of every part is the same as the page size. The size of the last half could also be but the page size. The pages of the process area unit hold on within the frames of main memory relying upon their accessibility.\n\nSegmentation is another non-contiguous memory allocation scheme like paging. Like paging, in segmentation, the process isn’t divided indiscriminately into mounted(fixed) size pages. It is a variable-size partitioning theme. like paging, in segmentation, secondary and main memory are not divided into partitions of equal size. The partitions of secondary memory area units are known as segments. The details concerning every segment are hold in a table known as segmentation table. Segment table contains two main data concerning segment, one is Base, which is the bottom address of the segment and another is Limit, which is the length of the segment.\n\nIn segmentation, the CPU generates a logical address that contains the Segment number and segment offset. If the segment offset is a smaller amount than the limit then the address called valid address otherwise it throws miscalculation because the address is invalid. \n\n\n\nThe above figure shows the translation of a logical address to a physical address.\n\n, the program is divided into fixed or mounted size pages. , the program is divided into variable size segments. For the paging operating system is accountable. Here, the segment size is given by the user. It is faster in comparison to segmentation. In paging, the logical address is split into a page number and page offset. Here, the logical address is split into segment number and segment offset. Paging comprises a page table that encloses the base address of every page. While segmentation also comprises the segment table which encloses segment number and segment offset. The page table is employed to keep up the page data. In paging, the operating system must maintain a free frame list. In segmentation, the operating system maintains a list of holes in the main memory. Paging is invisible to the user. Segmentation is visible to the user. In paging, the processor needs the page number, and offset to calculate the absolute address. In segmentation, the processor uses segment number, and offset to calculate the full address. It is hard to allow sharing of procedures between processes. Facilitates sharing of procedures between the processes. This protection is hard to apply. Easy to apply for protection in segmentation. The size of the page needs always be equal to the size of frames. There is no constraint on the size of segments. A page is referred to as a physical unit of information. A segment is referred to as a logical unit of information.\n\nIn conclusion, paging and segmentation are both methods used in operating systems to manage memory, but they approach memory organization differently. Paging divides memory into fixed-size blocks (pages) for efficient management and allocation, while segmentation divides memory into variable-sized logical units (segments) for more flexible data and code organization.\n\nWhat is the difference between paging and frames?\n\nWhat are the two types of paging?\n\nWhat is the difference between paging and threading?"
    },
    {
        "link": "https://geeksforgeeks.org/segmentation-in-operating-system",
        "document": "A process is divided into Segments. The chunks that a program is divided into which are not necessarily all of the exact sizes are called segments. Segmentation gives the user’s view of the process which paging does not provide. Here the user’s view is mapped to physical memory.\n• Virtual Memory Segmentation: Each process is divided into a number of segments, but the segmentation is not done all at once. This segmentation may or may not take place at the run time of the program.\n• Simple Segmentation: Each process is divided into a number of segments, all of which are loaded into memory at run time, though not necessarily contiguously.\n\nThere is no simple relationship between logical addresses and physical addresses in segmentation. A table stores the information about all such segments and is called Segment Table.\n\nIt maps a two-dimensional Logical address into a one-dimensional Physical address. It’s each table entry has:\n• Base Address: It contains the starting physical address where the segments reside in memory.\n• Segment Limit: Also known as segment offset. It specifies the length of the segment.\n\nThe address generated by the CPU is divided into:\n• Segment number (s): Number of bits required to represent the segment.\n• Segment offset (d): Number of bits required to represent the position of data within a segment.\n• Reduced Internal Fragmentation : Segmentation can reduce internal fragmentation compared to fixed-size paging, as segments can be sized according to the actual needs of a process. However, internal fragmentation can still occur if a segment is allocated more space than it is actually used.\n• None Segment Table consumes less space in comparison to Page table in paging.\n• None As a complete module is loaded all at once, segmentation improves CPU utilization.\n• None The user’s perception of physical memory is quite similar to segmentation. Users can divide user programs into modules via segmentation. These modules are nothing more than separate processes’ codes.\n• None The user specifies the segment size, whereas, in paging, the hardware determines the page size.\n• None Segmentation is a method that can be used to segregate data from security operations.\n• Flexibility: Segmentation provides a higher degree of flexibility than paging. Segments can be of variable size, and processes can be designed to have multiple segments, allowing for more fine-grained memory allocation.\n• Sharing: Segmentation allows for sharing of memory segments between processes. This can be useful for inter-process communication or for sharing code libraries.\n• Protection: Segmentation provides a level of protection between segments, preventing one process from accessing or modifying another process’s memory segment. This can help increase the security and stability of the system.\n• External Fragmentation : As processes are loaded and removed from memory, the free memory space is broken into little pieces, causing external fragmentation. This is a notable difference from paging, where external fragmentation is significantly lesser.\n• None Overhead is associated with keeping a segment table for each activity.\n• None Due to the need for two memory accesses, one for the segment table and the other for main memory, access time to retrieve the instruction increases.\n• Fragmentation: As mentioned, segmentation can lead to external fragmentation as memory becomes divided into smaller segments. This can lead to wasted memory and decreased performance.\n• Overhead: Using a segment table can increase overhead and reduce performance. Each segment table entry requires additional memory, and accessing the table to retrieve memory locations can increase the time needed for memory operations.\n• Complexity: Segmentation can be more complex to implement and manage than paging. In particular, managing multiple segments per process can be challenging, and the potential for segmentation faults can increase as a result.\n\n2. Why is Segmentation used in OS?"
    },
    {
        "link": "https://stackoverflow.com/questions/68708130/segmentation-vs-paging-performance-difference-and-application-in-os",
        "document": "It is a common error to presume that refers to the implementation of the segment based protection mechanism in the intel 432, 80[2345]86 architectures, and the vestigial remnants carried into the AMD64 architecture. Segmented architectures existed at least 20 years before the 432 or 80286 ever saw the light of lithography.\n\nIn general terms, the management of segments which were the last phase of translation, was troublesome because simply growing a segment could require copying a large amount of memory.\n\nIn more specific terms, for example the intel 80x86 architecture, the page-level translation occurred after the segment translation. This meant that the changing the allocation base of a segment merely required relocating page table entries, so really not a big deal.\n\nUnfortunately, in the intel case, it meant that pointers had to be constructed of a pair: (seg, offset). Two pointers could thus only be reasonable compared or computed if their seg component matched, and the notion of such an odd pointer caused all sorts of programming difficulties.\n\nDespite that some operating systems employed segmentation: OS2 and QNX are ones I am familiar with. OS/2, may or may not have been performant; I never got past diskette 18 of the 32 diskette installation system.\n\nQNX, however, was a marvelously performing operating system, being both able to squeeze into very small footprints, and well utilize large footprints of the day. In those days small footprints were < 1M (yes, 10^6), and large ones 64M ( 64 * 10^6 ). It employed segment translation over page translation as described above. For 32 bit programs, it only supported a non-segmented application model, however the underlying system extensively used segments as high speed aliasing and protection devices. 16 bit programs suffered with the ugly segment model.\n\nTL;DR Intel's segment model is only one, and arguably amongst the worst.\n\nOperating systems can employ it transparently for a variety of optimisations.\n\nOther segmentation models are less intrusive, but have fallen almost out of favour.\n\nARM architecture has a MPU which is a flexible segment based protection unit, however performs no translation."
    },
    {
        "link": "https://quora.com/What-are-differences-between-simple-paging-and-virtual-memory-paging",
        "document": "Something went wrong. Wait a moment and try again."
    },
    {
        "link": "https://cseweb.ucsd.edu/classes/sp17/cse120-a/applications/ln/lecture11and12.html",
        "document": "\n• Make effective use of available memory\n• Somewhat less important in systems where memory is cheap\n• Very important in small, portable, battery-driven systems like PalmPilot.\n• Support the memory paradigms used by programming languages\n• Each programming language has a different view of memory\n• Fortan doesn't have dynamic memory -- ask only at beginning\n• Safety and Robustness\n• Make causing damage more difficult for programmers and users\n• Regardless of cause, minimize damage\n• For example, keep different tasks in different address spaces.\n\n\n\nMonoprogramming \n\n \n\nThe user taks area, including the stack, heap, and code segments is internally managed by the program.\n• Statically divide memory into a partition for each task, not necessarily fo equal size\n• Partitions must be at least as large as necessary. They can be larger, but should be as tight a fit as possible.\n• The excess space within a partition is a form of wastage called internal fragmentation.\n• Try to keep free memory in big chunks\n• Allocate only what is needed to tasks\n\n\n\nThis approach can lead to thin slices of free memory that are too small to satisfy any processes request. This type of wastage is called external fragmentation. The solution is to try to keep free memory in chunks rather than in many small pieces. This is easier said than done.\n\nThe hardware and operating system cooperate to provide a mapping from a virtual address sapce to the physical address apce. This mapping should be completely transparent to the user process with only a minimal performance impact. There are two distinct strategies: Paging splits the address space into equal sized units called pages. While segmentation splits the memory into unequal units that may have sizes more meaningful or appropriate to the program. These two ideas can be combined. As a practical matter paging is easier to implement than segmentation.\n• Divide physical memory into equal sized memory units called frames. The page size should be a power of two, because this improves the performance of supporting hardware.\n• Divide the logical memory into units called pages. The pages must be the same size as the frames\n• Define a mapping from the logical (virtual) address space to the physical address space The mapping must be fast and simple. It is typically done by a table lookup. The page size should be a power of two, because division by powers of two is trivial. We typically consider divide a virtual address into two fields: a page number and an offset, with the offset taking the high-order bits. The example below is typically of machines with 32-bit addresses. This provides a 4K page size:\n\nMapping From The Virtual Address To The Physical Address\n\nSince the table is stored in physical memory, lookups cause memory references. This increases the memory access latency; even with caching, address trasnlation can be very costly. The \"fix\" is a very specialized cache, the Tranlation Buffer (TB) also known as the Translation Lookaside Buffer (TLB). The TLB stores the most recent mappings from virtual addresses to physical addresses. It exists in hardware and is invisible to the OS, except the OS has the ability to flush (and possibly reload) it. This is necessary since each process has its own virtual address space, the old entries must be invalidated when a context-switch occurs. Failing to flush the TB is a common mistake. Some TB's keep task ID's associated with the mappings to prevent the need to flush. The TB operates at cache speeds and many architectures can do the TLB and cache lookups in parallel.\n\nIf a TB miss occurs, the translation must be found in the page table and the new mapping must be stored in the TB. On CISC machines this is typically done entirely in hardware. The table is kept in the hardware-specified format \n\nand the harware is told its address, usually via a register. On RISC machines, the update (fill) process is handled by software. The OS is informed of the miss via a trap generated by the hardware.\n\nSmall page sizes yield a finer grained memory system. The mapping between the memory requested and allocated can be much tighter. But smaller pages mean more pages and that means a bigger page table. A bigger page table not only requres a bigger TB (costly) but also occupies more space in memory (greater overhead). By constrast large page sizes yield a coarse grained mapping. This leads to more internal fragmentation, because allocations are rounded to the nearest whole page. But the TB doesn't have to be as large (cheaper) and the page table is smaller (less overhead). Page tables are typically 1K-8K. The choice of page table size implies an engineering trade-off. Sometimes it is made in hardware, but other hardware allows a variable page size via a register.\n\nThe offset field of the virtual address is the index into the page table, that is a 1D array. The contents of that cell, among other things, contain the physical address of the frame in memory. The biggest drawback of single-level page tables is their size. They must contain one entry for each virtual address. This is an enormous number of entries, especially considering that the virtual address space, by design, should be far larger than is ever required. Consider the large hole between the stack and the heap: there is an entry for every unused page. Multilevel page tables are one solution to this problem. We'll consider what in practice is the most popular type: the 2-level page table. It boils down to a page table of page tables. We now divide our virtual address into three fields: the directory # (page table #1), the page number (page table #2), and the offset. We still must create a directory entries to span our virtual address space, but these entries are much coarser in grain. Fewer entries can cover the entire address space. We only create page tables (page table #2) for those directory entries that are actually used. In the common case -- processes with sparse memory usage -- this saves space. But it also costs time. We now must make an additional access to memory to do a page table lookup. It is also important to note that multi-level page tables consume more memory than single-level page tables if most of the address space is actually used; the difference is lost in the overhead of the additional structure. Segmentation is a technique for allocating memory in chunks of varying and meaningful sizes instead of one arbitrary page size. Since the segment sizes are selected by the compiler, internal fragmentation is reduced. Of course, since the segments are of different sizes, we have the same problems with external fragmentation and compaction that we discussed when we talked about variable sized partions for multiprogramming. For this reason, among others, we'll find that although segmentation is supported by popular processors like those in the x86 family, paging is most often used by processors that support it, including those in the x86 family. When programmers think of memory they see it as a collection of different objects, not as a linear array of bytes or pages. These objects, unlike pages vary in size. It is this view of memory they segmentation seeks to support. A program might be broken down into segments for the code, stack and heap. In addition, separate segments might be created for statically allocated data structures such as heaps and arrays. Each of these segments is exactly the necessary size, so internal fragmentation is eliminated. These segments are then numbered. An address in memory is specificed as a tuple consisting of the segment number and the offset within the segment: Just as was the case for paging, we must provide a mechanism for mapping from this logical view of memory, to the linearly addressable physical memory. This mechanism is the segment table Since the segments are defined by the compiler, the segment table can be fixed at link time. The table contains one entry for each segment. The entry contains the base and limit for the segment. The base is the physical address of the beginning of the segment in memory. The limit is the length of the segment, so that the last physical address within the segment is specified by the base plus the bound (base + bound). Since each program enjoys its own virtual address space, each process has it's own segment table. The sement table of the current process is kept in memory and is referenced by two hardware registers, the segment-table base register (STBR) and the segment-table length register (STLR). On certain architectures, if the segment table is small enough, it can be stored entirely in registers within the CPU. When an address is specified as a tuple , the hardware translates it to a physical address using the segment table. The hardware checks the entry in the table specified by the offset number of find the base address of the segment. If the segment-number is out-of-bounds, the address is not valid. It then checks the limit to ensure that the offset is less than the limit. If the offset is not less than the limit, the address is invalid. If the address is valid, it is translated to physical address base+offset. Since segments represent logical units of a program, they are ideal for sharing. For example, it is logical for the code segment of several processes corresponding to the same program to be shared. Appropriate protection and security can be enforced by associating this information with the segment table. When statically allocated arrays and other complex structures are associated with their own segment, bounds checking becomes almost free. It happens as a natural consequence of the lookup in the page table and requires no additional instructions. Although segmentation eliminates internal fragmentation, it does so at the expense of external fragmentation. It is possible that although a sufficient amount of memory is available, it will be partitioned into small pieces by existing segments. This results in unusuable memory and a failed request. The impact of external fragmentation depends on the average segment size. If the segments are generally small, they can usually fit into an available space. If they are large, there is a greater chance that the available space will be partitioned into free blocks that are too small to be accomodating. As we discussed in the context of multiprogramming with variable partitions, the placement and replacement strategies can also affect fragmentation. Depending on the policy employed, the underlying data structures and their maintenence can also add substantial overhead to memory management. Compaction systems that are capable of relocating the segments of existing processes can ease this cost by making the allocated segments physically contiguous. This approach is very expensive because it requires extensive memory-memory copies. It also requires a runtime rebindable loader. Supporting a virtual address space larger than the physical address space requires what is called a backing store. A backing store is storage large enought to hold all of the data that could fit into the virtual address space. The backing store is usually a secondary storage device like disk. When we consider memory from this perspective, we find that smaller, faster, and memore expensive storage devices are actually being used as a cache for larger, slower, and less-expensive device. This model for a system's memory is called the memory hierarchy. Swapping is another technique that involves replacing the entire address space each time a task context-switches. This technique is transparent to the user, but the I/O cost is trememndous."
    }
]