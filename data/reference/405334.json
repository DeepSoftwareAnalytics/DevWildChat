[
    {
        "link": "https://stackoverflow.com/questions/5797852/in-node-js-how-do-i-include-functions-from-my-other-files",
        "document": "Or...am I supposed to turn \"tools\" into a module, and then require it? << seems hard, I rather do the basic import of the tools.js file.\n\nWhat if I have a functions inside \"tools.js\". How would I import them to use in apps.js?\n\nIf, despite all the other answers, you still want to traditionally include a file in a node.js source file, you can use this:\n• The empty string concatenation is necessary to get the file content as a string and not an object (you can also use if you prefer).\n• The eval() can't be used inside a function and must be called inside the global scope otherwise no functions or variables will be accessible (i.e. you can't create a utility function or something like that). Please note that in most cases this is bad practice and you should instead write a module. However, there are rare situations, where pollution of your local context/namespace is what you really want. Please also note this won't work with (when you are in \"strict mode\") because functions and variables defined in the \"imported\" file can't be accessed by the code that does the import. Strict mode enforces some rules defined by newer versions of the language standard. This may be another reason to avoid the solution described here.\n\nYou need no new functions nor new modules. You simply need to execute the module you're calling if you don't want to use namespace. or in any other .js like myController.js : which force us to use a namespace and call tools like in my case I have a file with controllers ctrls.js and I can use in every context as public class after\n\nHere is a plain and simple explanation: // Include the public functions from 'helpers.js' var helpers = require('./helpers'); // Let's assume this is the data which comes from the database or somewhere else var databaseName = 'Walter'; var databaseSurname = 'Heisenberg'; // Use the function from 'helpers.js' in the main file, which is server.js var fullname = helpers.concatenateNames(databaseName, databaseSurname); // 'module.exports' is a node.JS specific feature, it does not work with regular JavaScript module.exports = { // This is the function which will be called in the main file, which is server.js // The parameters 'name' and 'surname' will be provided inside the function // when the function is called in the main file. // Example: concatenameNames('John,'Doe'); concatenateNames: function (name, surname) { var wholeName = name + \" \" + surname; return wholeName; }, sampleFunctionTwo: function () { } }; // Private variables and functions which will not be accessible outside this file var privateFunction = function () { };\n\nThe vm module in Node.js provides the ability to execute JavaScript code within the current context (including global object). See http://nodejs.org/docs/latest/api/vm.html#vm_vm_runinthiscontext_code_filename Note that, as of today, there's a bug in the vm module that prevenst runInThisContext from doing the right when invoked from a new context. This only matters if your main program executes code within a new context and then that code calls runInThisContext. See https://github.com/joyent/node/issues/898 Sadly, the with(global) approach that Fernando suggested doesn't work for named functions like \"function foo() {}\" In short, here's an include() function that works for me:\n\nAnother way to do this in my opinion, is to execute everything in the lib file when you call require() function using (function(/* things here */){})(); doing this will make all these functions global scope, exactly like the eval() solution (function () { funcOne = function() { console.log('mlt funcOne here'); } funcThree = function(firstName) { console.log(firstName, 'calls funcThree here'); } name = \"Mulatinho\"; myobject = { title: 'Node.JS is cool', funcFour: function() { return console.log('internal funcFour() called here'); } } })(); And then in your main code you can call your functions by name like: bash-3.2$ node -v v7.2.1 bash-3.2$ node main.js mlt funcOne here Alex calls funcThree here Mulatinho { title: 'Node.JS is cool', funcFour: [Function: funcFour] } internal funcFour() called here undefined Pay atention to the undefined when you call my object.funcFour(), it will be the same if you load with eval(). Hope it helps :)\n\nI just want to add, in case you need just certain functions imported from your tools.js, then you can use a destructuring assignment which is supported in node.js since version 6.4 - see node.green. Example: (both files are in the same folder) This also avoids that you assign those functions as properties of another object as its the case in the following (common) assignment: where you need to call . Don't forget to prefix your file name with the correct path - even if both files are in the same folder, you need to prefix with Without a leading '/', './', or '../' to indicate a file, the module must either be a core module or is loaded from a node_modules folder."
    },
    {
        "link": "https://stackoverflow.com/questions/27464168/how-to-include-scripts-located-inside-the-node-modules-folder",
        "document": "Usually, you don't want to expose any of your internal paths for how your server is structured to the outside world. What you can is make a static route in your server that fetches its files from whatever directory they happen to reside in. So, if your files are in . Then, the script tag in your pages just looks like this:\n\nIf you were using express with nodejs, a static route is as simple as this:\n\nThen, any browser requests from will automatically be fetched from your directory at .\n\nNote: Newer versions of NPM put more things at the top level, not nested so deep so if you are using a newer version of NPM, then the path names will be different than indicated in the OP's question and in the current answer. But, the concept is still the same. You find out where the files are physically located on your server drive and you make an with to make a pseudo-path to those files so you aren't exposing the actual server file system organization to the client.\n\nIf you don't want to make a static route like this, then you're probably better off just copying the public scripts to a path that your web server does treat as or whatever top level designation you want to use. Usually, you can make this copying part of your build/deployment process.\n\nIf you want to make just one particular file public in a directory and not everything found in that directory with it, then you can manually create individual routes for each file rather than use such as:\n\nAnd the code to create a route for that\n\nOr, if you want to still delineate routes for scripts with , you could do this:\n\nAnd the code to create a route for that"
    },
    {
        "link": "https://reddit.com/r/learnjavascript/comments/rshjkk/how_do_i_call_a_javascript_function_inside_a_js",
        "document": "It seems like the function is never defined even whenever I try to access it from the JS console within the browser. I basically want to be able to call the JS function with some arguments from within the HTML file. How can I do this? It seems that if I am trying to pass the arguments to the server and trying to get it back using an AJAX request within the JS module that I am probably going the very very long way round."
    },
    {
        "link": "https://stanleyulili.com/node/node-modules-import-and-use-functions-from-another-file",
        "document": "In Node.js, any file that consists of JavaScript code in a file ending with is a module. A module can contain definitions of functions, classes, objects, or variables that can be referenced or used in another Javascript file.\n\nWhen your application starts getting larger, maintaining a single file becomes a difficult task. it is easy to get lost in the codebase and lose track of what a particular piece of code is doing. The problem get's worse when you are debugging code.\n\nTo make it easier to maintain, reuse and organize code, you need to split the code into multiple files. This process is called modularization. Each module contains functions or classes that handle a specific functionality.\n\nFunctions in one module can be imported and called in other modules saving you from having to copy function definitions into the other files. A module can be edited or debugged separately making it easier for you to add or remove new features.\n\nIn this tutorial, you will learn how to create Node.js modules. You will also learn how to include functions defined in one file and use them in another file. Some of the topics we will explore are:\n\nTo follow this tutorial, create a directory in your home directory or anywhere you want.\n\nGet into the directory.\n\nNow you are all set to follow the tutorial and practice the code.\n\nModules are created in Node.js by creating a JavaScript file. Every time you create a new file with extension, it becomes a module.\n\nLet's write our first module. We will start by creating two functions to do simple calculations.\n\nType the following code and save it as inside your directory.\n\nThe file is now a module. The two functions and are only available in our file. They encapsulated, meaning they can not be accessed outside the file. if you try to call them in another file, you will get an error.\n\nInside the folder. Create another file . Let's try to call the function in our file.\n\nYou will get an error.\n\nAs we have learned in the previous example, we can't access the functions defined in one module in another module by default. To access the module functions, we have to export the functions and import them in the file we want to call the functions.\n\nLets export the function in the file.\n\nGo to the end of the file and add .\n\nWhat's happening now in our file is that we have added the function to object. Adding the function to will make it available in any file that imports the module.\n\nYou are not limited to exporting functions. You can export variables, objects, and classes, etc.\n\nTo include functions defined in another file in Node.js, we need to import the module. we will use the keyword at the top of the file.\n\nThe result of is then stored in a variable which is used to invoke the functions using the dot notation.\n\nTo see that in action, let's import the module by requiring it inside the file and invoke the function with dot notation.\n\nIf we run our code now, we should get the following output:\n\nWhat's happening in the code above is that we are importing the module.\n\nWhen importing the file , it is important to prefix it with inside . This tells Node.js that we are importing a local module(a module created by yourself such as the module).\n\nWhen requiring the module, you can leave out the file as extension as we have done or you can put the file extension( ) of the file you want to import.\n\nWhen imports the module, it returns an object with as it's a method and stores it in the variable.\n\nThe object returned by is the object from the module were we exported only one method .\n\nSince an object is what is returned by , to access the function, we used dot notation by prefixing the object name( ) to call the function and then store the result of the function in the variable.\n\nThere are a couple of ways to export multiple functions and values with .\n\nIn file, you can import them as follows:\n\nYou can also use the destructuring syntax to unpack the properties of the object returned by and store them in variables.\n\nAnother way to export multiple functions is to define the functions inside object.\n\nYou can also define each function indepedently as a method of .\n\nInside the project directory, create a directory and move the file into it.\n\nTo import file inside the directory, require by prefixing it with the directory name.\n\nThese are modules that you can create yourself and use them in your application. A good example of a local module is the module we created and imported in the file in this tutorial.\n\nTo recap, to import a local module, you have to or or .\n\nYou don't have to add the \".js\" extension, Node.js can still load your local module without it as we have learned.\n\nThese are modules that come with Node.js by default. You do not have to download them in your project.\n\nSome of the most popular and frequently used core modules are , , , etc.\n\nTo import a core module, you have to use the method with the core module's name passed as the argument.\n\nThird-party modules are modules that are downloaded with a package manager such as npm. These modules are usually stored in the folder.\n\nYou can install third-party modules globally or locally in your project.\n\nExamples of third party modules are , , , etc.\n\nTo import a third-party module, you have to use the method that takes the third-party module's name as an argument.\n\nIn this tutorial, we covered how to create and export a module, import a module and went over different ways to export multiple functions and values, and also different types of modules in Node.js.\n\nIf you have any insights or suggestions, feel free to leave a comment."
    },
    {
        "link": "https://freecodecamp.org/news/requiring-modules-in-node-js-everything-you-need-to-know-e7fbd119be8",
        "document": "Node uses two core modules for managing module dependencies:\n• The module, which appears to be available on the global scope — no need to .\n• The module, which also appears to be available on the global scope — no need to .\n\nYou can think of the module as the command and the module as the organizer of all required modules.\n\nRequiring a module in Node isn’t that complicated of a concept.\n\nThe main object exported by the module is a function (as used in the above example). When Node invokes that function with a local file path as the function’s only argument, Node goes through the following sequence of steps:\n• Resolving: To find the absolute path of the file.\n• Loading: To determine the type of the file content.\n• Wrapping: To give the file its private scope. This is what makes both the and objects local to every file we require.\n• Evaluating: This is what the VM eventually does with the loaded code.\n• Caching: So that when we require this file again, we don’t go over all the steps another time.\n\nIn this article, I’ll attempt to explain with examples these different stages and how they affect the way we write modules in Node.\n\nLet me first create a directory to host all the examples using my terminal:\n\nAll the commands in the rest of this article will be run from within .\n\nLet me introduce you to the object. You can check it out in a simple REPL session:\n\nEvery module object gets an property to identify it. This is usually the full path to the file, but in a REPL session it’s simply\n\nNode modules have a one-to-one relation with files on the file-system. We require a module by loading the content of a file into memory.\n\nHowever, since Node allows many ways to require a file (for example, with a relative path or a pre-configured path), before we can load the content of a file into the memory we need to find the absolute location of that file.\n\nWhen we require a module, without specifying a path:\n\nNode will look for in all the paths specified by — in order.\n\nThe paths list is basically a list of node_modules directories under every directory from the current directory to the root directory. It also includes a few legacy directories whose use is not recommended.\n\nIf Node can’t find in any of these paths, it will throw a “cannot find module error.”\n\nIf you now create a local directory and put a in there, the line will find it.\n\nIf another file existed in any of the other paths, for example, if we have a directory under the home directory and we have a different file in there:\n\nWhen we from within the directory — which has its own , the file under the home directory will not be loaded at all:\n\nIf we remove the local directory under and try to require one more time, the file under the home’s directory would be used:\n\nModules don’t have to be files. We can also create a folder under and place an file in there. The same line will use that folder’s file:\n\nNote how it ignored the home directory’s path again since we have a local one now.\n\nAn file will be used by default when we require a folder, but we can control what file name to start with under the folder using the property in . For example, to make the line resolve to a different file under the folder, all we need to do is add a file in there and specify which file should be used to resolve this folder:\n\nIf you want to only resolve the module and not execute it, you can use the function. This behaves exactly the same as the main function, but does not load the file. It will still throw an error if the file does not exist and it will return the full path to the file when found.\n\nThis can be used, for example, to check whether an optional package is installed or not and only use it when it’s available.\n\nBesides resolving modules from within the directories, we can also place the module anywhere we want and require it with either relative paths ( and ) or with absolute paths starting with .\n\nIf, for example, the file was under a folder instead of the folder, we can require it with:\n\nCreate a file and add a line there to identify it. Also, the object itself:\n\nDo the same for an file, which is what we’ll be executing with the node command. Make this file require :\n\nNow execute the file with node:\n\nNote how the main module is now listed as the parent for the module. However, the module was not listed as a child of the module. Instead, we have the value there because this is a circular reference. If Node prints the module object, it will go into an infinite loop. That’s why it simply replaces the reference with .\n\nMore importantly now, what happens if the module required the main module? This is where we get into what’s known as the circular modular dependency, which is allowed in Node.\n\nTo understand it better, let’s first understand a few other concepts on the module object.\n\nIn any module, exports is a special object. If you’ve noticed above, every time we’ve printed a module object, it had an exports property which has been an empty object so far. We can add any attribute to this special exports object. For example, let’s export an id attribute for and :\n\nWhen we now execute , we’ll see these attributes as managed on each file’s object:\n\nI’ve removed some attributes in the above output to keep it brief, but note how the object now has the attributes we defined in each module. You can put as many attributes as you want on that exports object, and you can actually change the whole object to be something else. For example, to change the exports object to be a function instead of an object, we do the following:\n\nWhen you run now, you’ll see how the object is a function:\n\nNote how we did not do to make the object into a function. We can’t actually do that because the variable inside each module is just a reference to which manages the exported properties. When we reassign the variable, that reference is lost and we would be introducing a new variable instead of changing the object.\n\nThe object in every module is what the function returns when we require that module. For example, change the line in into:\n\nThe above will capture the properties exported in into the constant. When we run now, the very last line will output:\n\nLet’s also talk about the attribute on every module. So far, every time we printed a module object, we saw a attribute on that object with a value of .\n\nThe module uses the attribute to track which modules have been loaded (true value) and which modules are still being loaded (false value). We can, for example, see the module fully loaded if we print its object on the next cycle of the event loop using a call:\n\nThe output of that would be:\n\nNote how in this delayed output both and are fully loaded.\n\nThe object becomes complete when Node finishes loading the module (and labels it so). The whole process of requiring/loading a module is synchronous. That’s why we were able to see the modules fully loaded after one cycle of the event loop.\n\nThis also means that we cannot change the object asynchronously. We can’t, for example, do the following in any module:\n\nLet’s now try to answer the important question about circular dependency in Node: What happens when module 1 requires module 2, and module 2 requires module 1?\n\nTo find out, let’s create the following two files under , and and have them require each other:\n\nWhen we run we see the following:\n\nWe required before was fully loaded, and since required while it wasn’t fully loaded, what we get from the object at that point are all the properties exported prior to the circular dependency. Only the property was reported because both and were exported after required and printed .\n\nNode keeps this really simple. During the loading of a module, it builds the object. You can require the module before it’s done loading and you’ll just get a partial exports object with whatever was defined so far.\n\nWe can natively require JSON files and C++ addon files with the require function. You don’t even need to specify a file extension to do so.\n\nIf a file extension was not specified, the first thing Node will try to resolve is a file. If it can’t find a file, it will try a file and it will parse the file if found as a JSON text file. After that, it will try to find a binary file. However, to remove ambiguity, you should probably specify a file extension when requiring anything other than files.\n\nRequiring JSON files is useful if, for example, everything you need to manage in that file is some static configuration values, or some values that you periodically read from an external source. For example, if we had the following file:\n\nWe can require it directly like this:\n\nRunning the above code will have this output:\n\nIf Node can’t find a or a file, it will look for a file and it would interpret the file as a compiled addon module.\n\nThe Node documentation site has a sample addon file which is written in C++. It’s a simple module that exposes a function and the hello function outputs “world.”\n\nYou can use the package to compile and build the file into a file. You just need to configure a binding.gyp file to tell what to do.\n\nOnce you have the file (or whatever name you specify in ) then you can natively require it just like any other module:\n\nWe can actually see the support of the three extensions by looking at .\n\nLooking at the functions for each extension, you can clearly see what Node will do with each. It uses for files, for files, and for files.\n\nAll code you write in Node will be wrapped in functions\n\nNode’s wrapping of modules is often misunderstood. To understand it, let me remind you about the / relation.\n\nWe can use the object to export properties, but we cannot replace the object directly because it’s just a reference to\n\nHow exactly does this object, which appears to be global for every module, get defined as a reference on the object?\n\nLet me ask one more question before explaining Node’s wrapping process.\n\nIn a browser, when we declare a variable in a script like this:\n\nThat variable will be globally available in all scripts after the script that defined it.\n\nThis is not the case in Node. When we define a variable in one module, the other modules in the program will not have access to that variable. So how come variables in Node are magically scoped?\n\nThe answer is simple. Before compiling a module, Node wraps the module code in a function, which we can inspect using the property of the module.\n\nNode does not execute any code you write in a file directly. It executes this wrapper function which will have your code in its body. This is what keeps the top-level variables that are defined in any module scoped to that module.\n\nThis wrapper function has 5 arguments: , , , , and . This is what makes them appear to look global when in fact they are specific to each module.\n\nAll of these arguments get their values when Node executes the wrapper function. is defined as a reference to prior to that. and are both specific to the function to be executed, and / variables will contain the wrapped module’s absolute filename and directory path.\n\nYou can see this wrapping in action if you run a script with a problem on its first line:\n\nNote how the first line of the script as reported above was the wrapper function, not the bad reference.\n\nMoreover, since every module gets wrapped in a function, we can actually access that function’s arguments with the keyword:\n\nThe first argument is the object, which starts empty. Then we have the / objects, both of which are instances that are associated with the file that we’re executing. They are not global variables. The last 2 arguments are the file’s path and its directory path.\n\nThe wrapping function’s return value is . Inside the wrapped function, we can use the object to change the properties of , but we can’t reassign exports itself because it’s just a reference.\n\nWhat happens is roughly equivalent to:\n\nIf we change the whole object, it would no longer be a reference to . This is the way JavaScript reference objects work everywhere, not just in this context.\n\nThere is nothing special about . It’s an object that acts mainly as a function that takes a module name or path and returns the object. We can simply override the object with our own logic if we want to.\n\nFor example, maybe for testing purposes, we want every call to be mocked by default and just return a fake object instead of the required module exports object. This simple reassignment of require will do the trick:\n\nAfter doing the above reassignment of , every call in the script will just return the mocked object.\n\nThe require object also has properties of its own. We’ve seen the property, which is a function that performs only the resolving step of the require process. We’ve also seen above.\n\nThere is also which can be helpful to determine if the script is being required or run directly.\n\nSay, for example, that we have this simple function in :\n\nThe function takes a numeric argument and a string argument and it prints that header in a frame of stars controlled by the size we specify.\n\nWe want to use this file in two ways:\n• From the command line directly like this:\n\nPassing 8 and Hello as command line arguments to print “Hello” in a frame of 8 stars.\n• With . Assuming the required module will export the function and we can just call it:\n\nTo print the header “Hey” in a frame of 5 stars.\n\nThose are two different usages. We need a way to determine if the file is being run as a stand-alone script or if it is being required by other scripts.\n\nThis is where we can use this simple if statement:\n\nSo we can use this condition to satisfy the usage requirements above by invoking the printInFrame function differently:\n\nWhen the file is not being required, we just call the function with elements. Otherwise, we just change the object to be the function itself.\n\nAll modules will be cached\n\nCaching is important to understand. Let me use a simple example to demonstrate it.\n\nSay that you have the following file that prints a cool looking header:\n\nWe want to display this header every time we require the file. So when we require the file twice, we want the header to show up twice.\n\nThe second require will not show the header because of modules’ caching. Node caches the first call and does not load the file on the second call.\n\nWe can see this cache by printing after the first require. The cache registry is simply an object that has a property for every required module. Those properties values are the objects used for each module. We can simply delete a property from that object to invalidate that cache. If we do that, Node will re-load the module to re-cache it.\n\nHowever, this is not the most efficient solution for this case. The simple solution is to wrap the log line in with a function and export that function. This way, when we require the file, we get a function that we can execute to invoke the log line every time:\n\nThat’s all I have for this topic. Thanks for reading. Until next time!"
    },
    {
        "link": "https://stackoverflow.com/questions/27464168/how-to-include-scripts-located-inside-the-node-modules-folder",
        "document": "Usually, you don't want to expose any of your internal paths for how your server is structured to the outside world. What you can is make a static route in your server that fetches its files from whatever directory they happen to reside in. So, if your files are in . Then, the script tag in your pages just looks like this:\n\nIf you were using express with nodejs, a static route is as simple as this:\n\nThen, any browser requests from will automatically be fetched from your directory at .\n\nNote: Newer versions of NPM put more things at the top level, not nested so deep so if you are using a newer version of NPM, then the path names will be different than indicated in the OP's question and in the current answer. But, the concept is still the same. You find out where the files are physically located on your server drive and you make an with to make a pseudo-path to those files so you aren't exposing the actual server file system organization to the client.\n\nIf you don't want to make a static route like this, then you're probably better off just copying the public scripts to a path that your web server does treat as or whatever top level designation you want to use. Usually, you can make this copying part of your build/deployment process.\n\nIf you want to make just one particular file public in a directory and not everything found in that directory with it, then you can manually create individual routes for each file rather than use such as:\n\nAnd the code to create a route for that\n\nOr, if you want to still delineate routes for scripts with , you could do this:\n\nAnd the code to create a route for that"
    },
    {
        "link": "https://medium.com/@jayjethava101/node-js-project-structure-best-practices-and-example-for-clean-code-3e1f5530fd3b",
        "document": "Discover the top best practices for organizing a Node.js project to improve scalability, maintainability, and readability with a well-planned folder.\n• Creating the Folder in the Directory\n\nTo get started with a Node.js application using a modular project structure, follow these steps:\n\nFirst, you’ll need to install the necessary dependencies for your project:\n\nNext, create a .env file at the root level of your project. This file will hold all your configuration constants, such as API keys, database credentials, and other environment-specific variables. Here’s an example:\n\nIt’s crucial to ensure sensitive information is not pushed to version control, especially when using GitHub. Create a .gitignore file in the root of your project and add the following:\n• Why .env? Your .env file contains confidential project details such as database credentials, API secrets, and other sensitive information. Pushing this to a public repository could expose your project to security vulnerabilities.\n• Why node_modules/? The node_modules folder contains all the installed dependencies, which can be easily recreated by running npm install. Including this folder in your repository would unnecessarily increase the size of your project.\n\nTo keep your project organised, create a folder named src at the root level. This folder will hold all your source code files and modules, enabling a clean, modular project structure. For example, your folder structure might look like this:\n• server.js: This file serves as the main entry point, where the server is started.\n• app.js: Handles application configuration, such as middleware, route registration, etc.\n• modules/: Contains a folder for each module of your application (e.g., user, post). Inside each module:\n• model.js: Defines the database schema or model for that module.\n• index.js: Acts as the entry point for the module, typically exporting routes or integrating the module into the app.\n• service.js: Contains the business logic, abstracting complex operations and interactions with the model.\n\nNow, configure your Express app with necessary middewares inside :\n\nIn the server.js file, set up your Node.js server inside :\n\nTo easily start your Node.js application, define a start script in your package.json file. This will allow you to run your app using the npm start command.\n\nIn the package.json, add the following to the scripts section:\n\nWhen you enter the command — ‘npm start’ in the terminal, the node server will be up and running on the specified port.\n\nFirst, update your .env file with your database credentials:\n\nIn the src folder, create a folder named configs for storing various configuration files (e.g., database configuration, Firebase configuration, etc.):\n\nInside the configs folder, create a file called db.js to define the database configuration based on the environment (development or production):\n\nIn the src folder, create a folder named utils for storing utility components like database connections, common services (e.g., email, Firebase notifications), etc.\n\nInside src/utils/db.js, set up the database connection using Sequelize:\n\nYou can now import the database connection from db.js wherever database access is required, such as when defining models or interacting with the database.\n\nIn the modules/user/model.js file, define the schema for the User table:\n\nIn the modules/user/service.js file, define methods for implementing business logic and database interactions:\n• createUser: Handles the creation of new users.\n\nIn the modules/user/controller.js file, define functions to handle HTTP requests:\n\nIn the modules/user/index.js file, define the Express router for handling various routes:\n\nNow that you have defined the User module, import and register the routes in the main app.js file:\n\nThis ensures the User module is set up with a model, service, controller, and routes, making the structure modular and easy to scale.\n\nNow, you can call your API using endpoints like:\n\nThis allows you to add a new user to the system by making a POST request with the required data. Similarly, you can create additional routes for other CRUD operations, such as fetching users, updating profiles, or deleting records, all using the modular structure you’ve set up.\n\nThat’s it! You now have a fully modular Node.js project structure with Express and Sequelize. Feel free to extend this by adding more modules, services, and routes as needed.\n\nFor the complete code and setup, check out the GitHub repository:\n\n👉🏻https://github.com/Jay-Jethava/express-modular-project-structure.git"
    },
    {
        "link": "https://stackoverflow.com/questions/29704454/running-scripts-inside-multiple-node-project-directories-with-npm",
        "document": "I have one main project which has multiple node projects inside that as subdirectories. each one with their own directories and files. I want to have an npm script defined in my main files which runs npm scripts from each of those projects concurrently.\n\nMy directory structure is like this:\n\nNow, obviously I could copy and paste the commands in 's script and 's start script into a bash script and run that instead. But I want to be able to change those scripts without having to manually change the bash script every time. Is there a way to do this?"
    },
    {
        "link": "https://julie.io/writing/javascript-node-modules",
        "document": "The JavaScript ecosystem and how it stores modules locally in the project can be frickle. Especially when coming from another language, many developers will struggle with dependency hell in Node.js. Let’s look at some best practices to avoid that.\n\nI also struggled when I first developing with JavaScript. Node.js has a package manager npm, which helps a great deal. Unfortunately most people don’t leverage it’s power. But once you master it, it usually just works.\n\nNote: In this article, I always refer to npm. But these best practices also apply to yarn.\n\nThe best thing about JavaScript is the vibrant community. JavaScript is the most popular language on GitHub - by far with 2.3 million pull requests. The runner-up, Python has less than half at 1 million. This activity reflect how there are so many node modules and the nested dependency structure common in the JavaScript ecosystem.\n\nDependency managers help us normalize our code across environments and different developer machines, preventing the “it works for me problem”. But npm is unlike most other dependency managers. It stores dependencies locally and in the folder, which can cause headaches for many.\n\nWith other package managers like Bundler for Ruby, you don’t actually see the code of your dependencies in your project. You can import them out of thin air - well out of a central cache. Here are the largest frustrations with the folder:\n• it can be very large and easily explode to thousands of files\n• there is no global caching\n• you need internet with every\n\nWhile I also find these points frustrating, at some point I chose to stop fighting and always focus on shipping. This is only possible when you follow JavaScript best practices.\n\nProblem: It works for me 🤷‍♂️\n\nGlobal installations are the biggest cause of the “it works for me problem”. While in most cases you can get away with this sin, actively developed and constantly improving frameworks (which is good!) can cause inconsistencies. The most common use-case I have seen at work is generating a production-ready optimized SPA frontend. Some optimization may suddenly fail.\n\nWhy? The developer was running:\n\nInstead, you should follow this pattern:\n\nwhich would execute the version of the angular-cli specified in the block inside .\n\nThis simple difference will solve 95% of your problems. Most new developers probably stumble because documentation will simply say or and the npm run-script practice is at best a footnote.\n\nNote my script is named not just build. Also note I used a semicolon to scope my command. I prefer to use the format to concisely communicate what a command does. Here is an example from my express-es6-starter:\n\nConventions help remove the mental effort required when figuring out what a command does. Keep in mind the context won’t necessarily be development vs. production environments.\n\nNew JavaScript developers may think OK, I will use the versioned dependency like this:\n\nJust use an npm script as described above. The effect is the same. I’ve also seen references to when importing modules. Don’t. If you need to do that, your module isn’t packaged properly as a module. At work I see teams using this because they are writing work in progress libraries. My advice is to use a git submodule until your library is mature enough to be published. Clean code is more important than forcing yourself to adhere to best practices. When you or your code isn’t ready yet, you lose too much time in your development workflow.\n\nThis code is system generated, which means the source is elsewhere. A general best practice it to never check in generated code. That’s why a standard for Node.js projects will look like this:\n\nMost importantly dependencies may depend on your operating system. That’s why continuous integration is important. Your development and production environments probably use different operating systems.\n\nIt sounds terrible to have native bindings in a dependency but this is not uncommon in Node.js. According to the Node.js Foundation, “30 percent of all modules rely indirectly on native modules”.\n\n30%! That’s crazy, right? How is that even maintainable? Well, the JavaScript ecosystem is open source and supported by many individual contributors and with significant support from companies like Google and Microsoft, who also use these technologies. So as crazy as this sounds, it works thanks to the community.\n\nSo now that you understand that your dependencies are system specific and might include native modules, you should never assume that your folder will work in production. I’ve seen developers try because the step can take a long time and you want to minimize deployment time.\n\nSo how do you avoid slow deployments?\n\nThe same way you do it on your computer. The folder is not generated from scratch each time. Once it already exists, the install step runs significantly faster.\n\nSo a good PaaS will handle any caching between deployments and builds for you. For example, Heroku has a node modules caching feature in their platform, which is on by default, but customizable. The Microsoft Azure Cloud also offers a caching feature for node modules.\n\nBut Cloud Foundry goes against best practice. They recommend you push your folder too. WTF, seriously?! When you push an app, you see in the console:\n\nIn their documentation it says:\n\nIt doesn’t make sense to me to recommend that developers should risk failure in production because of an incompatibilty due to native bindings in dependencies. Exact versioning with can help you quickly apply a hotfix, rolling back and locking your app to the last functioning version. But that’s a code smell.\n\nI spent an hour on Friday debugging a reference project for teams that used to deploy fine - and still does with PCF dev. So the cause is our implementation of Cloud Foundry in our cloud. But the deployment fails unless I push the folder.\n\nNote that Heroku default documentation and configurations reflect best practice, ignoring the possibly system dependent folder. Unfortunately Cloud Foundry does the opposite, defaulting to bad practice - because someone requested it. It should be the other way around. A product should let you override best practice for edge cases. But defaulting to bad practice is just 🤦‍♀️.\n\nOnly install what you need\n\nThe file let’s your categorize your dependencies:\n• are not installed when running which is best practice.\n• if a package fails to install, overrides default behavior and continues\n\nDon’t take all your dev tools overhead with you to production. To test you’ve categorized your dependencies properly without deploying just remove it and try to start your app:\n\nIf it doesn’t work, check that you didn’t accidentally include a dev dependency in your source code or still referred to dev tools like babel in your npm scripts.\n\nWhen you running code, make sure it’s been compiled to ES5.\n\nMaybe you don’t need it. If you have a single page application, you can avoid dependencies altogether by having your build server generate the production-optimized frontend and throwing it in a nginx server, for example.\n\nThat’s it for now. Later next week I’ll finish and publish a post about using Best Practices when using Node.js in Docker, especially when it comes to the challenge."
    },
    {
        "link": "https://github.com/nodejs/help/issues/681",
        "document": "As the title says I was wondering if it were possible to use the same modules folder for multiple projects so that I don't have to continuously install them using the command prompt.\n\nIs it possible? If so how do I proceed?"
    }
]