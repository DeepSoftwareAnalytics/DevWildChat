[
    {
        "link": "https://jump.dev/JuMP.jl/stable",
        "document": "Welcome to the documentation for JuMP.\n\nJuMP is a domain-specific modeling language for mathematical optimization embedded in Julia.\n\nJuMP makes it easy to formulate and solve a range of problem classes, including linear programs, integer programs, conic programs, semidefinite programs, and constrained nonlinear programs. Here’s an example:\n\nThere are a few ways to get started with JuMP:\n• Read the introductory tutorials Getting started with Julia and Getting started with JuMP.\n• Browse some of our modeling tutorials, including classics such as The diet problem, or the Maximum likelihood estimation problem using nonlinear programming.\n\nNeed help? Join the community forum to search for answers to commonly asked questions. Before asking a question, make sure to read the post make it easier to help you, which contains a number of tips on how to ask a good question.\n\nHow the documentation is structured\n\nHaving a high-level overview of how this documentation is structured will help you know where to look for certain things.\n• None Tutorials contain worked examples of solving problems with JuMP. Start here if you are new to JuMP, or you have a particular problem class you want to model.\n• None The Manual contains short code-snippets that explain how to achieve specific tasks in JuMP. Look here if you want to know how to achieve a particular task, such as how to Delete a variable or how to Modify an objective coefficient.\n• None The API Reference contains a complete list of the functions you can use in JuMP. Look here if you want to know how to use a particular function.\n• None The Background information section contains background reading material to provide context to JuMP. Look here if you want an understanding of what JuMP is and why we created it, rather than how to use it.\n• None The Developer docs section contains information for people contributing to JuMP development or writing JuMP extensions. Don't worry about this section if you are using JuMP to formulate and solve problems as a user.\n• None The MathOptInterface section is a self-contained copy of the documentation for MathOptInterface. Look here for functions and constants beginning with , as well as for general information on how MathOptInterface works.\n\nIf you find JuMP useful in your work, we kindly request that you cite the following paper (preprint):\n\nJuMP is a Sponsored Project of NumFOCUS, a 501(c)(3) nonprofit charity in the United States. NumFOCUS provides JuMP with fiscal, legal, and administrative support to help ensure the health and sustainability of the project. Visit numfocus.org for more information.\n\nYou can support JuMP by donating.\n\nDonations to JuMP are managed by NumFOCUS. For donors in the United States, your gift is tax-deductible to the extent provided by law. As with any donation, you should consult with your tax adviser about your particular tax situation.\n\nJuMP's largest expense is the annual JuMP-dev workshop. Donations will help us provide travel support for JuMP-dev attendees and take advantage of other opportunities that arise to support JuMP development.\n\nJuMP is licensed under the MPL-2.0 software license. Consult the license and the Mozilla FAQ for more information. In addition, JuMP is typically used in conjunction with solver packages and extensions which have their own licences. Consult their package repositories for the specific licenses that apply."
    },
    {
        "link": "https://jump.dev/JuMP.jl/stable/manual/constraints",
        "document": "JuMP is based on the MathOptInterface (MOI) API. Because of this, JuMP uses the following standard form to represent problems:\n\nEach constraint, $f_i(x) \\in \\mathcal{S}_i$, is composed of a function and a set. For example, instead of calling $a^\\top x \\le b$ a less-than-or-equal-to constraint, we say that it is a scalar-affine-in-less-than constraint, where the function $a^\\top x$ belongs to the less-than set $(-\\infty, b]$. We use the shorthand function-in-set to refer to constraints composed of different types of functions and sets.\n\nThis page explains how to write various types of constraints in JuMP. For nonlinear constraints, see Nonlinear Modeling instead.\n\nAdd a constraint to a JuMP model using the macro. The syntax to use depends on the type of constraint you wish to add.\n\nJuMP normalizes constraints by moving all of the terms containing variables to the left-hand side and all of the constant terms to the right-hand side. Thus, we get:\n\nIn addition to affine functions, JuMP also supports constraints with quadratic terms. For example:\n\nYou can also add constraints to JuMP using vectorized linear algebra. For example:\n\nThe two constraints, and are similar, but subtly different. The first creates a single constraint that is a in constraint. The second creates a vector of in constraints.\n\nWhich formulation to choose depends on the solver, and what you want to do with the constraint object or .\n• If you are using a conic solver, expect the dual of to be a , and do not intend to delete a row in the constraint, choose the formulation.\n• If you are using a solver that expects a list of scalar constraints, for example HiGHS, or you wish to delete part of the constraint or access a single row of the constraint, for example, , then use the broadcast .\n\nJuMP reformulates both constraints into the other form if needed by the solver, but choosing the right format for a particular solver is more efficient.\n\nYou can also use , , , and as comparison operators in the constraint.\n\nInequalities between matrices are not supported, due to the common ambiguity between elementwise inequalities and a constraint.\n\nInstead, use the Set inequality syntax to specify a set like or :\n\nThere are two exceptions: if the result of the left-hand side minus the right-hand side is a matrix or a matrix, you may use the non-broadcasting equality syntax:\n\nThis will add only three rows to the constraint matrix because the symmetric constraints are redundant. In contrast, the broadcasting syntax adds four linear constraints:\n\nThe same holds for matrices:\n\nThe macro supports creating collections of constraints. We'll cover some brief syntax here; read the Constraint containers section for more details:\n\nSets can be any Julia type that supports iteration:\n\nand you can filter elements in the sets using the syntax:\n\nWhen you create constraints, JuMP registers them inside the model using their corresponding symbol. Get a registered name using :\n\nTo reduce the likelihood of accidental bugs, and because JuMP registers constraints inside a model, creating two constraints with the same name is an error:\n\nA common reason for encountering this error is adding constraints in a loop.\n\nAs a work-around, JuMP provides anonymous constraints. Create an anonymous constraint by omitting the name argument:\n\nCreate a container of anonymous constraints by dropping the name in front of the :\n\nIn addition to the symbol that constraints are registered with, constraints have a name that is used for printing and writing to file formats.\n\nGet and set the name of a constraint using and :\n\nOverride the default choice of name using the keyword:\n\nNote that names apply to each element of the container, not to the container of constraints:\n\nIf the name is not present, will be returned:\n\nYou can only look up individual constraints using . Something like this will not work:\n\nTo look up a collection of constraints, do not use . Instead, register them using the syntax:\n\nIt's common for new users to experience confusion relating to constraints. Part of the problem is the difference between the name that a constraint is registered under and the name used for printing.\n• Constraints can be named or anonymous.\n• Named constraints have the form . For named constraints:\n• The name of the constraint is set to .\n• A Julia variable is created that binds to the JuMP constraint.\n• The name is registered as a key in the model with the value .\n• Anonymous constraints have the form . For anonymous constraints:\n• The name of the constraint is set to .\n• You control the name of the Julia variable used as the binding.\n• No name is registered as a key in the model.\n• The keyword can override the name of the constraint.\n• You can manually register names in the model via .\n\nHere's an example of the differences:\n\nIf you have many calls, use the macro to improve readability:\n\nThe macro returns a tuple of the constraints that were defined.\n\nJuMP adopts the notion of conic duality from MathOptInterface. For linear programs, a feasible dual on a constraint is nonnegative and a feasible dual on a constraint is nonpositive. If the constraint is an equality constraint, it depends on which direction is binding.\n\nThe dual value associated with a constraint in the most recent solution can be accessed using the function. Use to check if the model has a dual solution available to query. For example:\n\nTo help users who may be less familiar with conic duality, JuMP provides , which returns a value that can be interpreted as the improvement in the objective in response to an infinitesimal relaxation (on the scale of one unit) in the right-hand side of the constraint. can be used only on linear constraints with a , , or comparison operator.\n\nIn the example above, returned regardless of the optimization sense. However, in the second case when the optimization sense is , returns:\n\nTo query the dual variables associated with a variable bound, first obtain a constraint reference using one of , , or , and then call on the returned constraint reference. The function may simplify this process as it returns the shadow price of an active bound of a variable (or zero, if no active bound exists).\n\nThis section explains how to modify the constant term in a constraint. There are multiple ways to achieve this goal; we explain three options.\n\nUse to modify the right-hand side (constant) term of a linear or quadratic constraint. Use to query the right-hand side term.\n\nIf constraints are complicated, for example, they are composed of a number of components, each of which has a constant term, then it may be difficult to calculate what the right-hand side term is in the standard form.\n\nFor this situation, JuMP includes the ability to fix variables to a value using the function. Fixing a variable sets its lower and upper bound to the same value. Thus, changes in a constant term can be simulated by adding a new variable and fixing it to different values. Here is an example:\n\nThe constraint is now equivalent to .\n\nThe third option is to use . The constant given is added to the function of a -in- constraint. In the following example, adding to the function has the effect of removing to the right-hand side:\n\nIn the case of interval constraints, the constant is removed from each bound:\n\nTo modify the coefficients for a linear term in a constraint, use . To query the current coefficient, use .\n\nTo modify the coefficients of a vector-valued constraint, use .\n\nUse to delete a constraint from a model. Use to check if a constraint belongs to a model and has not been deleted.\n\nDeleting a constraint does not unregister the symbolic reference from the model. Therefore, creating a new constraint of the same name will throw an error:\n\nAfter calling , call to remove the symbolic reference:\n\nProvide a starting value (also called warmstart) for a constraint's primal and dual solutions using and .\n\nQuery the starting value for a constraint's primal and dual solution using and . If no start value has been set, the methods will return .\n\nLike Variable containers, JuMP provides a mechanism for building groups of constraints compactly. References to these groups of constraints are returned in containers. Three types of constraint containers are supported: s, s, and s. We explain each of these in the following.\n\nOne way of adding a group of constraints compactly is the following:\n\nJuMP returns references to the three constraints in an that is bound to the Julia variable . This array can be accessed and sliced as you would with any Julia array:\n\nAnonymous containers can also be constructed by dropping the name (for example, ) before the square brackets:\n\nJust like , JuMP will form an of constraints when it can determine at parse time that the indices are one-based integer ranges. Therefore will create an , but will not. A special case is which will produce an . If JuMP cannot determine that the indices are one-based integer ranges (for example, in the case of ), JuMP will create a instead.\n\nThe syntax for constructing a of constraints is very similar to the syntax for constructing a of variables.\n\nThe syntax for constructing a of constraints is very similar to the syntax for constructing a of variables.\n\nWhen creating a container of constraints, JuMP will attempt to choose the tightest container type that can store the constraints. However, because this happens at parse time, it does not always make the best choice. Just like in , you can force the type of container using the keyword. For syntax and the reason behind this, take a look at the variable docs.\n\nContainers are often used to create constraints over a set of indices. However, you'll often have cases in which you are repeating the indices:\n\nThis is hard to read and leads to a lot of copy-paste. A more readable way is to use a for-loop:\n\nQuery the types of function-in-set constraints in a model using :\n\nFor a given combination of function and set type, use to access the number of constraints and to access a list of their references:\n\nYou can also count the total number of constraints in the model, but you must explicitly choose whether to count constraints such as bound and integrality constraints:\n\nThe same also applies for :\n\nIf you need finer-grained control on which constraints to include, use a variant of:\n\nUse to get an instance of an object that stores the constraint data:\n\nBecause JuMP is based on MathOptInterface, you can add any constraints supported by MathOptInterface using the function-in-set syntax. For a list of supported functions and sets, read Standard form problem.\n\nFor example, the following two constraints are equivalent:\n\nYou can also use any set defined by MathOptInterface:\n\nFor modeling convenience, the syntax is short-hand for .\n\nTherefore, the following calls are equivalent:\n\nNon-zero constants are not supported in this syntax:\n\nA constrains the variables and to the set:\n\nand $t \\ge 0$. It can be added as follows:\n\nA constrains the variables , , and to the set:\n\nand $t, u \\ge 0$. It can be added as follows:\n\nIn a Special Ordered Set of Type 1 (often denoted SOS-I or SOS1), at most one element can take a non-zero value.\n\nAlthough not required for feasibility, solvers can benefit from an ordering of the variables (for example, the variables represent different factories to build, at most one factory can be built, and the factories can be ordered according to cost). To induce an ordering, a vector of weights can be provided, and the variables are ordered according to their corresponding weight.\n\nFor example, in the constraint:\n\nIn a Special Ordered Set of Type 2 (SOS-II), at most two elements can be non-zero, and if there are two non-zeros, they must be consecutive according to the ordering induced by a weight vector.\n\nThe possible non-zero pairs are ( , ) and ( , ):\n\nIf the weight vector is omitted, JuMP induces an ordering from :\n\nIndicator constraints consist of a binary variable and a linear constraint. The constraint holds when the binary variable takes the value . The constraint may or may not hold when the binary variable takes the value .\n\nTo enforce the constraint when the binary variable is , use:\n\nIf the constraint must hold when is zero, add or before the binary variable;\n\nTo constrain a matrix to be positive semidefinite (PSD), use :\n\nThe inequality between two square matrices and is understood as constraining to be positive semidefinite.\n\nSolvers supporting PSD constraints usually expect to be given a matrix that is symbolically symmetric, that is, for which the expression in corresponding off-diagonal entries are the same. In our example, the expressions of entries and are respectively and which are different.\n\nTo bridge the gap between the constraint modeled and what the solver expects, solvers may add an equality constraint to force symmetry. Use to explicitly tell the solver that the matrix is symmetric:\n\nNote that the lower triangular entries are ignored even if they are different so use it with caution:\n\nA mixed complementarity constraint consists of finding in the interval , such that the following holds:\n\nJuMP supports mixed complementarity constraints via or in the macro. The interval set is obtained from the variable bounds on .\n\nFor example, to define the problem with , do:\n\nThis problem has a unique solution at .\n\nThe perp operator can be entered in most editors (and the Julia REPL) by typing .\n\nAn alternative approach that does not require the symbol uses the function as follows:\n\nIn both cases, the mapping is supplied as the first argument, and the matching variable is supplied as the second.\n\nAdd a Boolean constraint (a set) using the operator with a right-hand side term:\n\nBoolean constraints should not be added using the operator because JuMP will rewrite the constraint as , and because constraints like require parentheses to disambiguate between and . In contrast, is equivalent to :"
    },
    {
        "link": "https://discourse.julialang.org/t/constraints-handling-in-jump-moi/8813",
        "document": "I’ve been looking at the code of the new JuMP with MOI, and I would like to understand how to update the things that are going to break in my code. In particular, I have been doing the following things\n• Inspect a linear constraint breaking it down using and\n• Interrogating variables in constraints to identify where they come from\n• loading and saving a solution from a JLD file by simply setting or storing the value of I see that the new JuMP model object has less elements than the previous one. This gives less access to info to develop advanced algorithms that are solver-independent. Could you help me understand how things like the ones I listed are going to be done in the future?.\n\nI’ve been looking at the code of the new JuMP with MOI, and I would like to understand how to update the things that are going to break in my code. Great! This is a good time to start doing so unless you need NLP (that’s in progress). Please don’t hesitate to file issues. Documentation on the JuMP side is missing, but should be okay at the MOI level. It’s not unlikely that the JuMP API will go through a big renaming once it’s more stabilized. I see that the new JuMP model object has less elements than the previous one. This gives less access to info to develop advanced algorithms that are solver-independent. The lack of context might suggest this, but it’s actually the opposite case. The JuMP/MOI model is designed to be more transparent in how it stores data. There are no more ad-hoc, undocumented arrays for storing different types of constraints. Everything except nonlinear objects is stored directly in the field which has a well-defined (and mostly documented) interface for accessing any property you might want. There are currently some JuMP-level wrappers for accessing these, but you can also query them directly. Inspect a linear constraint breaking it down using and Interrogating variables in constraints to identify where they come from Variables still have the same field. However, the current JuMP/MOI model by default doesn’t support constraints containing variables that belong to different models. loading and saving a solution from a JLD file by simply setting or storing the value of m.colVal The good news is that we now have the infrastructure in place to handle solutions objects (i.e., a solver returning more than one solution, creating a solution and checking its feasibility, separating the result solution from the starting point etc.), but that’s not really hooked up yet. (I’m cringing at the name) was never a public interface. The new way to do this is to create an array of all the variables in the model and ask for its . You can do this with the attribute which returns MOI variable indices. You construct a JuMP variable from a model and a MOI variable index. It would be a reasonable feature request to ask for a JuMP-level API for this.\n\nThank you for the clarifications. I read the MOI documentation and now I am less scared of it. About the constraints with variables with different models. I am currently developing on top of Plasmo (J.Jalving, U Wisc), which defines a graph of models with linking constraints, those have variables from different models. From what I read in MOI, to do advanced things the user would have to play a lot with , is this the intention or are you planning to bring more power to the JuMP layer?. Also, at some point you mentioned things like indicator constraints (which I’m interested in) will be easier with MOI. Do you have an idea on how would that be?. Indicator constraints take 3 arguments: a binary variable, a value (0 or 1), and a linear constraint. As in , which MOI function would be used to generate something like that?. Finally, where is the right place to ask these kind of questions or to request no features. I have a long shopping list of things I would like to see in JuMP. For example, I was thinking about writing a solution object with Excel export.\n\nFrom what I read in MOI, to do advanced things the user would have to play a lot with m.moibackend.instance, is this the intention or are you planning to bring more power to the JuMP layer?. You should never need to touch , that’s an implementation detail that could change if changes. At the moment you may need to deal with , but the intention is for everything to have a nice JuMP-level wrapper. Open an issue on JuMP whenever you find a need to interact with directly. Definitely open an issue at MathOptInterfaceUtilities if you find a need to touch . Also, at some point you mentioned things like indicator constraints (which I’m interested in) will be easier with MOI. Do you have an idea on how would that be?. Indicator constraints take 3 arguments: a binary variable, a value (0 or 1), and a linear constraint. As in y = 1 => 2x <= 5, which MOI function would be used to generate something like that?. Define to be the 2-dimensional set \\mathcal{I}_{param} = \\{ (x,y) : x = param, y \\le 0 \\} \\cup \\{ (x,y) : x = 1 - param, y \\in \\mathbb{R} \\}. Then (x, 2y - 5) \\in \\mathcal{I}_1 means that x = 1 implies 2y \\le 5. The expression (x, 2y-5) is representable as a where the solver can throw an error if the first output component isn’t a single variable. Finally, where is the right place to ask these kind of questions or to request no features. I have a long shopping list of things I would like to see in JuMP. For example, I was thinking about writing a solution object with Excel export. Discourse or the gitter channel are appropriate for these kinds of questions. You can open issues on JuMP to discuss new potential features."
    },
    {
        "link": "https://github.com/jump-dev/NLopt.jl",
        "document": "NLopt.jl is a wrapper for the NLopt library for nonlinear optimization.\n\nNLopt provides a common interface for many different optimization algorithms, including:\n• Algorithms using function values only (derivative-free) and also algorithms exploiting user-supplied gradients.\n\nis licensed under the MIT License.\n\nThe underlying solver, stevengj/nlopt, is licensed under the LGPL v3.0 license.\n\nIn addition to installing the package, this will also download and install the NLopt binaries. You do not need to install NLopt separately.\n\nThe following example code solves the nonlinearly constrained minimization problem from the NLopt Tutorial.\n\nA common feature request is for a callback that can used to trace the solution over the iterations of the optimizer.\n\nThere is no native support for this in NLopt. Instead, add the callback to your objective function.\n\nNLopt implements the MathOptInterface interface for nonlinear optimization, which means that it can be used interchangeably with other optimization packages from modeling packages like JuMP. Note that NLopt does not exploit sparsity of Jacobians.\n\nYou can use NLopt with JuMP as follows:\n\nThe attribute is required. The value must be one of the supported NLopt algorithms.\n\nThe parameter is required, and all others are optional. The meaning and acceptable values of all parameters, except , match the descriptions below from the specialized NLopt API.\n\nThe parameter is an absolute feasibility tolerance applied to all constraints.\n\nSome algorithms in NLopt require derivatives, which you must manually provide in the branch of your objective and constraint functions.\n\nTo stay simple and lightweight, NLopt does not provide ways to automatically compute derivatives. If you do not have analytic expressions for the derivatives, use a package such as ForwardDiff.jl to compute automatic derivatives.\n\nHere is an example of how to wrap a function using ForwardDiff so that it is compatible with NLopt:\n\nThe main purpose of this section is to document the syntax and unique features of the Julia interface. For more detail on the underlying features, please refer to the C documentation in the NLopt Reference.\n\nTo use NLopt in Julia, your Julia program should include the line:\n\nwhich imports the NLopt module and its symbols. Alternatively, you can use if you want to keep all the NLopt symbols in their own namespace. You would then prefix all functions below with , for example and so on.\n\nThe NLopt API revolves around an object of type .\n\nThe object should normally be created via the constructor:\n\ngiven an algorithm (see NLopt Algorithms for possible values) and the dimensionality of the problem ( , the number of optimization parameters).\n\nWhereas in C the algorithms are specified by constants of the form like , the Julia values are symbols of the form with the prefix replaced by to create a Julia symbol.\n\nThere is also a function to make a copy of a given object (equivalent to in the C API).\n\nIf there is an error in these functions, an exception is thrown.\n\nThe algorithm and dimension parameters of the object are immutable (cannot be changed without constructing a new object). Query them using:\n\nGet a string description of the algorithm via:\n\nThe objective function is specified by calling one of:\n\ndepending on whether one wishes to minimize or maximize the objective function , respectively.\n\nThe function must be of the form:\n\nThe return value must be the value of the function at the point , where is a array of length of the optimization parameters.\n\nIn addition, if the argument is not empty (that is, ), then is a array of length which should (upon return) be set to the gradient of the function with respect to the optimization parameters at .\n\nNot all of the optimization algorithms (below) use the gradient information: for algorithms listed as \"derivative-free,\" the argument will always be empty and need never be computed. For algorithms that do use gradient information, may still be empty for some calls.\n\nNote that must be modified in-place by your function . Generally, this means using indexing operations to overwrite the contents of . For example will not work, because it points to a new array rather than overwriting the old contents; instead, use an explicit loop or use .\n\nwhere and are real arrays of length (the same as the dimension passed to the constructor).\n\nFor convenience, you can instead use a single scalar for or in order to set the lower/upper bounds for all optimization parameters to a single constant.\n\nTo retrieve the values of the lower or upper bounds, use:\n\nboth of which return arrays.\n\nTo specify an unbounded dimension, you can use or .\n\nSpecify nonlinear inequality and equality constraints by the functions:\n\nwhere the arguments have the same form as the objective function above.\n\nThe optional arguments specify a tolerance (which defaults to zero) that is used to judge feasibility for the purposes of stopping the optimization.\n\nEach call to these function adds a new constraint to the set of constraints, rather than replacing the constraints.\n\nRemove all of the inequality and equality constraints from a given problem with:\n\nSpecify vector-valued nonlinear inequality and equality constraints by the functions:\n\nwhere is an array of the tolerances in each constraint dimension; the dimensionality of the constraint is determined by .\n\nThe constraint function must be of the form:\n\nwhere is a array whose length equals the dimensionality of the constraint (same as the length of above), which upon return, should be set in-place to the constraint results at the point . Any return value of the function is ignored.\n\nIn addition, if the argument is not empty (that is, ), then is a matrix of size × which should (upon return) be set in-place (see above) to the gradient of the function with respect to the optimization parameters at . That is, should upon return contain the partial derivative ∂f /∂x .\n\nNot all of the optimization algorithms (below) use the gradient information: for algorithms listed as \"derivative-free,\" the argument will always be empty and need never be computed. For algorithms that do use gradient information, may still be empty for some calls.\n\nYou can add multiple vector-valued constraints and/or scalar constraints in the same problem.\n\nAs explained in the C API Reference and the Introduction, you have multiple options for different stopping criteria that you can specify. (Unspecified stopping criteria are disabled; that is, they have innocuous defaults.)\n\nFor each stopping criteria, there are two functions that you can use to get and set the value of the stopping criterion.\n\nStop when an objective value of at least is found. (Defaults to .)\n\nRelative tolerance on function value. (Defaults to .)\n\nAbsolute tolerance on function value. (Defaults to .)\n\nRelative tolerances on the optimization parameters. (Defaults to .)\n\nAbsolute tolerances on the optimization parameters. (Defaults to .)\n\nIn the case of , you can either set it to a scalar (to use the same tolerance for all inputs) or a vector of length (the dimension specified in the constructor) to use a different tolerance for each parameter.\n\nStop when the number of function evaluations exceeds . (0 or negative for no limit, which is the default.)\n\nStop when the optimization time (in seconds) exceeds . (0 or negative for no limit, which is the default.)\n\nIn certain cases, the caller may wish to force the optimization to halt, for some reason unknown to NLopt. For example, if the user presses Ctrl-C, or there is an error of some sort in the objective function. You can do this by throwing any exception inside your objective/constraint functions: the optimization will be halted gracefully, and the same exception will be thrown to the caller. The Julia equivalent of from the C API is to throw a exception.\n\nOnce all of the desired optimization parameters have been specified in a given object , you can perform the optimization by calling:\n\nOn input, is an array of length (the dimension of the problem from the constructor) giving an initial guess for the optimization parameters. The return value is a array containing the optimized values of the optimization parameters. contains the optimized value of the objective function, and contains a symbol indicating the NLopt return code (below).\n\nis the same but modifies in-place (as well as returning ).\n\nThe possible return values are the same as the return values in the C API, except that the prefix is replaced with . That is, the return values are like instead .\n\nSome of the algorithms, especially and , use a different optimization algorithm as a subroutine, typically for local optimization. You can change the local search algorithm and its tolerances by setting:\n\nHere, is another object whose parameters are used to determine the local search algorithm, its stopping criteria, and other algorithm parameters. (However, the objective function, bounds, and nonlinear-constraint parameters of are ignored.) The dimension of must match that of .\n\nThis makes a copy of the object, so you can freely change your original afterwards without affecting .\n\nJust as in the C API, you can set the initial step sizes for derivative-free optimization algorithms with:\n\nHere, is an array of the (nonzero) initial steps for each dimension, or a single number if you wish to use the same initial steps for all dimensions.\n\nreturns the initial step that will be used for a starting guess of in .\n\nJust as in the C API, you can get and set the initial population for stochastic optimization with:\n\nA of zero, the default, implies that the heuristic default will be used as decided upon by individual algorithms.\n\nFor stochastic optimization algorithms, NLopt uses pseudorandom numbers generated by the Mersenne Twister algorithm, based on code from Makoto Matsumoto.\n\nBy default, the seed for the random numbers is generated from the system time, so that you will get a different sequence of pseudorandom numbers each time you run your program. If you want to use a \"deterministic\" sequence of pseudorandom numbers, that is, the same sequence from run to run, you can set the seed by calling:\n\nTo reset the seed based on the system time, you can call .\n\nNormally, you don't need to call this as it is called automatically. However, it might be useful if you want to \"re-randomize\" the pseudorandom numbers after calling to set a deterministic seed.\n\nJust as in the C API, you can get and set the number M of stored vectors for limited-memory quasi-Newton algorithms, via integer-valued property\n\nThe default is , in which case NLopt uses a heuristic nonzero value as determined by individual algorithms.\n\nThe version number of NLopt is given by the global variable:\n\nwhere is a built-in Julia type from the Julia standard library.\n\nThe underlying NLopt library is threadsafe; however, re-using the same object across multiple threads is not.\n\nAs an example, instead of:\n\nThis module was initially written by Steven G. Johnson, with subsequent contributions by several other authors (see the git history)."
    },
    {
        "link": "http://jumper.readthedocs.org/en/latest/jumper.html",
        "document": "JuMP is a domain-specific modeling language for mathematical programming embedded in Julia. It currently supports a number of open-source and commercial solvers (Clp, Cbc, GLPK, Gurobi, MOSEK, and CPLEX) via a generic solver-independent interface provided by the MathProgBase package. This manual will assume you are familiar with JuMP already. If you are not, please read the JuMP manual first. Robust optimization is one way to address optimization under uncertainty. Uncertainties in the problem are modeled as lying inside convex sets, and feasible solutions to a robust optimization problem must be feasible for all scenarios that lie in these uncertainty sets. There are computationally tractable ways to solve these problems, although implementation of these can be tedious and/or brittle. JuMPeR stands for “Julia for Mathematical Programming - extensions for Robust”. It builds on the groundwork laid by JuMP by adding a new type, , and allowing users to express robust optimization problems in a natural way. JuMPeR handles both reformulations of the problem into certain equivalents, or manages cutting-plane methods to solve the problems iteratively. Users can extend JuMPeR by providing oracles that implement reformulations and cutting-plane generation algorithms for new uncertainty sets.\n\nJuMPeR is under active development. Some names may change in the future, and should be considered temporary. We first introduce a new model type, , that we will use as we previously used . We can mostly use the same commands you use with a plain JuMP : , , . The main exceptions are that you must use to solve the model, and to display the model. The type can be created and used as it is used in plain JuMP. The first major addition is the type, which represents a coefficient or scalar in the problem that is uncertain. It behaves much like a , in that it can be combined with other ``Uncertain``s and ``Variable``s in expressions to form constraints. When modeling robust optimization problems, the following restrictions apply at this time:\n• No quadratic terms - e.g. no terms, no terms. is allowed.\n• No uncertain terms in the objective. The correct approach is to create an auxiliary variable that represents the objective value and transform the original objective into a constraint. This is subject to change.\n• No macros for constraints using uncertainties. For now, the non-macro version, , must be used. The other implication is that the convenience syntax is not available - instead the Julia must be used. Uncertains can be created using similar to how variables are created, with the main difference being that uncertainties do not have a type (i.e. defining integer-restricted uncertainties is not supported at this time.) Here we will solve a toy model with two variables and two uncertainties. The two uncertains live in a range and are not connected in anyway.: # We need to use RobustModel, not Model # @defVar is the same as in a plain JuMP model # @defUnc is very similar to @defVar # The bounds on our uncertains completely define the # We will use the non-macro version of setObjective, although # we could use the macro version if we wanted to. # Remember: objectives must be certain. # We now add constraints as we normally would, with a few # variations. Notice we are multiplying an uncertain and a # variable (e.g. u1*x[1]). We also have to use the non-macro # versions of addConstraint. The solution will ensure # feasibility for all realizations of u1 and u2 # Solve the model - notice solveRobust in place of solve # Also notice we did not say how it should be solved! We'll # Display the solution - just like JuMP It is completely possible to use JuMPeR without understanding the details of this section. However, if you wish to develop custom uncertainty sets not handled by an existing oracle, you will need to. In base JuMP we have the type which represents an affine expression of variables, e.g. . To handle uncertainties in this framework we need to introduce new types of affine expression. By combining uncertainties, variables and numbers we obtain the following new types:\n• - an affine expression containing only numbers and uncertains, e.g. where and are of type .\n• - an affine expression containing both where are uncertain (thus this constraint can be said to have uncertain right-hand-side). Another way to think about these (and is indeed how it is internally handled) is that we define an affine expression by its coefficient type, and the “things” the coefficients are multiplied with. That is (loosely): For the precise details, the best reference is the JuMP and JuMPeR source code, as well as the existing oracles.\n\nMultiple methods exist in the literature for solving robust optimization problems, and it is beyond the scope of this manual to go into too many details. The main methods are:\n• Reformulation: take uncertain constraints and replace them with new constraints and possibly new variables to form a certain problem. Usually exploits duality properties of the uncertainty set.\n• Cutting-plane: solve a relaxed version of the problem (i.e. with no uncertain constraints). Given the solution to this relaxed problem, try to generate new constraints that will make the current solution infeasible - usually by solving a optimization problem in the space of the uncertainty set. Other things to consider are sampling a set of constraints from the uncertainty set, partially generating reformulations, or really whatever you can think of. The important thing is that at the end of the solve, the problem must be feasible with respect to all constraints. In a way we can think of “reformulation” as operations performed before any solving, and “cutting-plane” as operations performed during solve. JuMPeR seperates the reformulation and cutting-plane logic into oracles. Oracles can be thought of as “robustifying operators” that take an uncertain problem and ensure the solution will be robust. At various points during the solve, JuMPeR will interact with the oracles associated with the constraints to coordinate reformulations, cutting-planes, etc. JuMPeR comes with multiple oracles, and users of JuMPeR can make and share their own - allowing users to easily swap and try out new uncertainty sets with little fuss. Oracles can be associated with one or more constraints. By default all constraints use the inbuilt that, as the name suggests, handles reformulations and cutting planes when the uncertainty set is polyhedral. We can alternatively specify a particular constraint by passing a third argument to , i.e. To create an oracle one must understand the structure of the solving algorithm inside JuMPeR’s\n• A new model, referred to as the master, is created with the originals variables and certain constraints.\n• Each oracle is notified of the constraints it must handle using .\n• Each oracle is given time to do any general setup, now that is is aware of what it must do. For example, it may take the dual of the uncertainty set in order to more efficiently reformulate multiple constraints.\n• Oracles that want to will now reformulate their constraints (or, alteratively, generate samples).\n• The master problem will now be solved.\n• Oracles can now use the master solution to generate new constraints (cutting-planes). If no oracles add constraints, we end the solution process. Otherwise, we re-solve. We will now detail the four functions an oracle must provide.\n\nWe will now consider a worked example using a polyhedral uncertainty set. We are trying to allocate percentages of the money in our portfolio to different assets. We are provided a matrix where the rows correspond to monthly returns for each asset, and the columns are the returns for each asset. Our goal is solve a robust optimization problem that maximizes the return of the porfolio over the worst case in the uncertainty set. We will obtain less conservate solutions by exploiting the covariance information stored in the returns matrix to construct a polyhedral uncertainty set. The particular robust optimization model we will solve is as follows: # where x_i is the percent allocation for asset i, and r_i is the # where A is such that A*A' = Covariance matrix Let begin by creating our function, : # Idea: multivariate normals can be described as # Instead of building uncertainty set limiting variation of r Note that our function takes three arguments: the matrix of past observed returns , the uncertainty set “size” , and which will be a Boolean that determines whether we solve with cuts or reformulation. We will also assume that a constant is defined globally, , that is the number of assets available to chose from.: Here we set up our model with Gurobi selected as the solver, with output suppressed. JuMPeR doesn’t support uncertain objectives, so we will make the objective a constraint.: The rest of the model structure follows naturally from the mathematical definition. Note the objective-as-a-constraint, and the use of instead of . Next we will define the uncertainty set, which is notable only in that the constraints only involve uncertainties and numbers - no variables.: # First, link returns to the standard normals # Finally, limit how much the standard normals can vary from means We now have everything we need to solve the problem. We are using the default , and can choose whether we use cutting planes or reformulation. This can done with the option for . Finally, we will return the portfolios allocation.: To evaluate this code, we will generate synthetic correlated data. The following code generates that data use a common market factor random normal combined with idiosyncratic normals for each asset: # - num_samples is number of samples to take Let us evaluate the distribution of results for different levels of conservatism. We will generate a “past” dataset we can optimize over, and a “future” dataset we will evaluate on. Let us try the following code: If we evaluate this code, we build the following table:"
    },
    {
        "link": "https://coin-or.github.io/Ipopt",
        "document": ""
    },
    {
        "link": "https://juliapackages.com/p/ipopt",
        "document": "Ipopt.jl is a wrapper for the Ipopt solver.\n\nThis wrapper is maintained by the JuMP community and is not a COIN-OR project.\n\nIf you need help, please ask a question on the JuMP community forum.\n\nIf you have a reproducible example of a bug, please open a GitHub issue.\n\nis licensed under the MIT License.\n\nThe underlying solver, coin-or/Ipopt, is licensed under the Eclipse public license.\n\nIn addition to installing the package, this will also download and install the Ipopt binaries. You do not need to install Ipopt separately.\n\nTo use a custom binary, read the Custom solver binaries section of the JuMP documentation.\n\nFor details on using a different linear solver, see the section below. You do not need a custom binary to change the linear solver.\n\nYou can use Ipopt with JuMP as follows:\n\nThe Ipopt optimizer supports the following constraints and attributes.\n\nSupported options are listed in the Ipopt documentation.\n\nIpopt provides a callback that can be used to log the status of the optimization during a solve. It can also be used to terminate the optimization by returning . Here is an example:\n\nSee the Ipopt documentation for an explanation of the arguments to the callback. They are identical to the output contained in the logging table printed to the screen.\n\nTo access the current solution and primal, dual, and complementarity violations of each iteration, use and . The two functions are identical to the ones in the Ipopt C interface.\n\nIpopt.jl wraps the Ipopt C interface with minimal modifications.\n\nA complete example is available in the file.\n\nFor simplicity, the five callbacks required by Ipopt are slightly different to the C interface. They are as follows:\n\neval_f Fills `grad_f` in-place with the gradient of the objective function evaluated at eval_grad_f Fills `g` in-place with the value of the constraints evaluated at `x`. eval_g - Fill `rows` and `cols` with the 1-indexed sparsity structure - Fill `values` with the elements of the Jacobian matrix according to the If `values === nothing`, `x` is an undefined object. Accessing any elements in it will cause Julia to segfault. eval_jac_g - Fill `rows` and `cols` with the 1-indexed sparsity structure - Fill `values` with the Hessian matrix according to the sparsity structure. If `values === nothing`, `x` is an undefined object. Accessing any elements in it will cause Julia to segfault. eval_h\n\nIf you get a termination status , it is probably because you have some undefined value in your model, for example, a division by zero. Fix this by removing the division, or by imposing variable bounds so that you cut off the undefined region.\n\nThere are two versions available: LBT and OpenBLAS. LBT is the recommended option for Julia ≥ v1.9.\n\nInstall this download into your current environment using:\n\nThen, use a linear solver in HSL by setting the and attributes:\n\nThe available HSL solvers are , , , , and . We recommend using either sequential BLAS and LAPACK backends or a multithreaded version limited to one thread when employing the linear solvers , or . These solvers already leverage parallelism via OpenMP, and enabling multiple threads in BLAS and LAPACK may result in thread oversubscription.\n\nDue to the security policy of macOS, Mac users may need to delete the quarantine attribute of the ZIP archive before extracting. For example:\n\nDownload Pardiso from https://www.pardiso-project.org. Save the shared library somewhere, and record the filename.\n\nThen, use Pardiso by setting the and attributes:\n\nIf you use Ipopt.jl with Julia ≥ v1.9, the linear solver SPRAL is available. You can use it by setting the attribute:\n\nNote that the following environment variables must be set before starting Julia:\n\nWith Julia v1.9 or later, Ipopt and the linear solvers MUMPS (default), SPRAL, and HSL are compiled with (LBT), a library that can change between BLAS and LAPACK backends at runtime.\n\nNote that the BLAS and LAPACK backends loaded at runtime must be compiled with 32-bit integers. The default BLAS and LAPACK backend is OpenBLAS, and we rely on the Julia artifact if no backend is loaded before .\n\nUsing LBT, we can also switch dynamically to other BLAS backends such as Intel MKL, BLIS, and Apple Accelerate. Because Ipopt and the linear solvers heavily rely on BLAS and LAPACK routines, using an optimized backend for a particular platform can improve the performance.\n\nIf you have and installed, switch to sequential and reference version of BLAS and LAPACK with:\n\nIf you have MKL.jl installed, switch to MKL by adding to your code:\n\nIf you have and installed, switch to BLIS with:\n\nIf you are using macOS ≥ v13.4 and you have AppleAccelerate.jl installed, add to your code:\n\nCheck what backends are loaded using:"
    },
    {
        "link": "https://discourse.julialang.org/t/speed-up-ipopt-solver/89984",
        "document": "I have a non-linear problem which I am solving with Ipopt and JuMP. The problem originally spans over around 70 days (divided in quarter-hourly periods), but I have started to solve the model for less periods. The problem aims to maximize expected profits of a market participant subject to prices which can be bid in auctions. When I run the problem for one day (96 periods) Ipopt finds a solution after around 20 Seconds. When I change the period length to two days, it runs for ages and until now did not find a solution. The same happens if I change the number of periods to less than a day (i.e. 16 quarter-hourly periods) or if I relax some boundaries on the prices that can be offered. I am new to Julia and therefore struggling what to do now. I would be very thankful for advice on how I can proceed when facing such a problem.\n\nNonlinear optimization problems can be notoriously tricky to solve. Sometimes a model can fail for no apparent reason, even when just changing a few parameters. Some things you can try:\n• If possible, set upper and lower bounds on all variables. Use your knowledge of the system you’re modeling to make them as tight as possible without eliminating physically possible solutions.\n• Use “warm starts” whenever you can. That is, give reasonable starting values to all variables. You can e.g. use the output of a previous model run with different parameters, or a simplified linear model. In your case, since the model solved for a single day, you might try using optimal variable values from the 1-day run as starting values for both days in the 2-day run.\n• Experiment with solver parameters. In some nonlinear energy system models I’ve worked with, setting the IPOPT parameter “mu_strategy” to “adaptive” decreases solve time and helps stability. But settings like this can be quite problem specific.\n• Another more advanced IPOPT technique: try using a different internal linear solver (see this section of the README). Switching to HSL MA86 was a significant improvement in our latest model, and was well worth the extra effort in manual compilation and needing to run IPOPT (and all of Julia) in Linux instead of Windows. No need for an extra Linux machine, running it in Windows Subsystem for Linux worked perfectly. Just some immediate ideas off the top of my head. There are lots of other tricks that may work, so let’s see if others chime in with more.\n\nthanks a lor for your answer. See below the Ipopt output for the one day example: This program contains Ipopt, a library for large-scale nonlinear optimization.\n\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n\n For more information visit GitHub - coin-or/Ipopt: COIN-OR Interior Point Optimizer IPOPT This is Ipopt version 3.14.4, running with linear solver MUMPS 5.4.1. Number of nonzeros in equality constraint Jacobian…: 3840\n\n Number of nonzeros in inequality constraint Jacobian.: 960\n\n Number of nonzeros in Lagrangian Hessian…: 0 Total number of variables…: 10206\n\n variables with only lower bounds: 9684\n\n variables with lower and upper bounds: 0\n\n variables with only upper bounds: 522\n\n Total number of equality constraints…: 1056\n\n Total number of inequality constraints…: 576\n\n inequality constraints with only lower bounds: 192\n\n inequality constraints with lower and upper bounds: 0\n\n inequality constraints with only upper bounds: 384 Number of objective function evaluations = 280\n\n Number of objective gradient evaluations = 276\n\n Number of equality constraint evaluations = 280\n\n Number of inequality constraint evaluations = 280\n\n Number of equality constraint Jacobian evaluations = 276\n\n Number of inequality constraint Jacobian evaluations = 276\n\n Number of Lagrangian Hessian evaluations = 0\n\n Total seconds in IPOPT = 16.336 Indeed the problem is non-convex. I am maximizing expected profit = probability of price being accepted in an auction * price * quantity with the acceptance probability decreasing with higher price.\n\nIt’s possible that the order of magnitude of the objective is too high compared to that of the constraints. Interior-point methods are quite sensitive to numerics. Can you try dividing your objective by, say, 100000? That is, instead of maximizing\n\n expected profit = probability of price being accepted in an auction * price * quantity ,\n\n you maximize\n\n expected profit = probability of price being accepted in an auction * price * quantity/100000 .\n\n The solution will be the same, but you bring the objective back in the [0, 20] range.\n\nNumber of nonzeros in equality constraint Jacobian…: 3840\n\n Number of nonzeros in inequality constraint Jacobian.: 960\n\n Number of nonzeros in Lagrangian Hessian…: 0 Total number of variables…: 10206\n\n variables with only lower bounds: 9684\n\n variables with lower and upper bounds: 0\n\n variables with only upper bounds: 522\n\n Total number of equality constraints…: 1056\n\n Total number of inequality constraints…: 576\n\n inequality constraints with only lower bounds: 192\n\n inequality constraints with lower and upper bounds: 0\n\n inequality constraints with only upper bounds: 384 There is something that puzzles me in Ipopt’s log above.\n• The problem has 10206 variables, and 1632 constraints excluding variable bounds (576 equality and 1056 inequality constraints). So far so good.\n• The constraints’ Jacobian has size 1,632x10,206, but according to Ipopt it has only 4,800 non-zeros. This means that at least 5,406 columns in the Jacobian are zeros, which suggests that the corresponding variables do not appear in any constraint\n• The Lagrangian Hessian has 0 non-zero coefficients, which is also weird. Can you share your problem’s formulation and a reproducible example?\n\nit is a bit difficult for me to provide a reproducible example because the problem includes user-defined functions indeed which rely on an external dataset. But I will try to generate a simplified example! Yes, I use user-defined functions (for example a function calculating the acceptance probability of an offered price in an auction)."
    },
    {
        "link": "https://help.agi.com/stk/LinkedDocuments/IPOPTreference.pdf",
        "document": ""
    },
    {
        "link": "https://github.com/jump-dev/Ipopt.jl",
        "document": "Ipopt.jl is a wrapper for the Ipopt solver.\n\nThis wrapper is maintained by the JuMP community and is not a COIN-OR project.\n\nIf you need help, please ask a question on the JuMP community forum.\n\nIf you have a reproducible example of a bug, please open a GitHub issue.\n\nis licensed under the MIT License.\n\nThe underlying solver, coin-or/Ipopt, is licensed under the Eclipse public license.\n\nIn addition to installing the package, this will also download and install the Ipopt binaries. You do not need to install Ipopt separately.\n\nTo use a custom binary, read the Custom solver binaries section of the JuMP documentation.\n\nFor details on using a different linear solver, see the section below. You do not need a custom binary to change the linear solver.\n\nYou can use Ipopt with JuMP as follows:\n\nThe Ipopt optimizer supports the following constraints and attributes.\n\nSupported options are listed in the Ipopt documentation.\n\nIpopt provides a callback that can be used to log the status of the optimization during a solve. It can also be used to terminate the optimization by returning . Here is an example:\n\nSee the Ipopt documentation for an explanation of the arguments to the callback. They are identical to the output contained in the logging table printed to the screen.\n\nTo access the current solution and primal, dual, and complementarity violations of each iteration, use and . The two functions are identical to the ones in the Ipopt C interface.\n\nIpopt.jl wraps the Ipopt C interface with minimal modifications.\n\nA complete example is available in the file.\n\nFor simplicity, the five callbacks required by Ipopt are slightly different to the C interface. They are as follows:\n\neval_f Fills `grad_f` in-place with the gradient of the objective function evaluated at eval_grad_f Fills `g` in-place with the value of the constraints evaluated at `x`. eval_g - Fill `rows` and `cols` with the 1-indexed sparsity structure - Fill `values` with the elements of the Jacobian matrix according to the If `values === nothing`, `x` is an undefined object. Accessing any elements in it will cause Julia to segfault. eval_jac_g - Fill `rows` and `cols` with the 1-indexed sparsity structure - Fill `values` with the Hessian matrix according to the sparsity structure. If `values === nothing`, `x` is an undefined object. Accessing any elements in it will cause Julia to segfault. eval_h\n\nIf you get a termination status , it is probably because you have some undefined value in your model, for example, a division by zero. Fix this by removing the division, or by imposing variable bounds so that you cut off the undefined region.\n\nThere are two versions available: LBT and OpenBLAS. LBT is the recommended option for Julia ≥ v1.9.\n\nInstall this download into your current environment using:\n\nThen, use a linear solver in HSL by setting the and attributes:\n\nThe available HSL solvers are , , , , and . We recommend using either sequential BLAS and LAPACK backends or a multithreaded version limited to one thread when employing the linear solvers , or . These solvers already leverage parallelism via OpenMP, and enabling multiple threads in BLAS and LAPACK may result in thread oversubscription.\n\nDue to the security policy of macOS, Mac users may need to delete the quarantine attribute of the ZIP archive before extracting. For example:\n\nDownload Pardiso from https://www.pardiso-project.org. Save the shared library somewhere, and record the filename.\n\nThen, use Pardiso by setting the and attributes:\n\nIf you use Ipopt.jl with Julia ≥ v1.9, the linear solver SPRAL is available. You can use it by setting the attribute:\n\nNote that the following environment variables must be set before starting Julia:\n\nWith Julia v1.9 or later, Ipopt and the linear solvers MUMPS (default), SPRAL, and HSL are compiled with (LBT), a library that can change between BLAS and LAPACK backends at runtime.\n\nNote that the BLAS and LAPACK backends loaded at runtime must be compiled with 32-bit integers. The default BLAS and LAPACK backend is OpenBLAS, and we rely on the Julia artifact if no backend is loaded before .\n\nUsing LBT, we can also switch dynamically to other BLAS backends such as Intel MKL, BLIS, and Apple Accelerate. Because Ipopt and the linear solvers heavily rely on BLAS and LAPACK routines, using an optimized backend for a particular platform can improve the performance.\n\nIf you have and installed, switch to sequential and reference version of BLAS and LAPACK with:\n\nIf you have MKL.jl installed, switch to MKL by adding to your code:\n\nIf you have and installed, switch to BLIS with:\n\nIf you are using macOS ≥ v13.4 and you have AppleAccelerate.jl installed, add to your code:\n\nCheck what backends are loaded using:"
    }
]