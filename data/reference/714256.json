[
    {
        "link": "https://dev.mysql.com/doc/en/create-table-foreign-keys.html",
        "document": "MySQL supports foreign keys, which permit cross-referencing related data across tables, and foreign key constraints, which help keep the related data consistent.\n\nA foreign key relationship involves a parent table that holds the initial column values, and a child table with column values that reference the parent column values. A foreign key constraint is defined on the child table.\n\nThe essential syntax for a defining a foreign key constraint in a or statement includes the following:\n\nForeign key constraint usage is described under the following topics in this section:\n\nForeign key constraints are subject to the following conditions and restrictions:\n• None Parent and child tables must use the same storage engine, and they cannot be defined as temporary tables.\n• None Creating a foreign key constraint requires the privilege on the parent table.\n• None Corresponding columns in the foreign key and the referenced key must have similar data types. The size and sign of fixed precision types such as and must be the same. The length of string types need not be the same. For nonbinary (character) string columns, the character set and collation must be the same.\n• None MySQL supports foreign key references between one column and another within a table. (A column cannot have a foreign key reference to itself.) In these cases, a “child table record” refers to a dependent record within the same table.\n• None MySQL requires indexes on foreign keys and referenced keys so that foreign key checks can be fast and not require a table scan. In the referencing table, there must be an index where the foreign key columns are listed as the first columns in the same order. Such an index is created on the referencing table automatically if it does not exist. This index might be silently dropped later if you create another index that can be used to enforce the foreign key constraint. , if given, is used as described previously.\n• None Previously, allowed a foreign key to reference any index column or group of columns, even a non-unique index or partial index, an extension of standard SQL. This is still allowed for backwards compatibility, but is now deprecated; in addition, it must be enabled by setting . If this is done, there must still be an index in the referenced table where the referenced columns are the first columns in the same order. Hidden columns that adds to an index are also considered in such cases (see Section 17.6.2.1, “Clustered and Secondary Indexes”). You should expect support for use of nonstandard keys to be removed in a future version of MySQL, and migrate away from their use. always requires an explicit unique key (or primary key) on any column referenced as a foreign key.\n• None Index prefixes on foreign key columns are not supported. Consequently, and columns cannot be included in a foreign key because indexes on those columns must always include a prefix length.\n• None does not currently support foreign keys for tables with user-defined partitioning. This includes both parent and child tables. This restriction does not apply for tables that are partitioned by or (the only user partitioning types supported by the storage engine); these may have foreign key references or be the targets of such references.\n• None A table in a foreign key relationship cannot be altered to use another storage engine. To change the storage engine, you must drop any foreign key constraints first. For information about how the MySQL implementation of foreign key constraints differs from the SQL standard, see Section 1.7.2.3, “FOREIGN KEY Constraint Differences”.\n\nWhen an or operation affects a key value in the parent table that has matching rows in the child table, the result depends on the referential action specified by and subclauses of the clause. Referential actions include:\n• None : Delete or update the row from the parent table and automatically delete or update the matching rows in the child table. Both and are supported. Between two tables, do not define several clauses that act on the same column in the parent table or in the child table. If a clause is defined on both tables in a foreign key relationship, making both tables a parent and child, an or subclause defined for one clause must be defined for the other in order for cascading operations to succeed. If an or subclause is only defined for one clause, cascading operations fail with an error.\n• None : Delete or update the row from the parent table and set the foreign key column or columns in the child table to . Both and clauses are supported. If you specify a action, make sure that you have not declared the columns in the child table as .\n• None : Rejects the delete or update operation for the parent table. Specifying (or ) is the same as omitting the or clause.\n• None : A keyword from standard SQL. For , this is equivalent to ; the delete or update operation for the parent table is immediately rejected if there is a related foreign key value in the referenced table. supports deferred checks, and specifies a deferred check; when this is used, constraint checks are not performed until commit time. Note that for tables, this causes all foreign key checks made for both parent and child tables to be deferred.\n• None : This action is recognized by the MySQL parser, but both and reject table definitions containing or clauses. For storage engines that support foreign keys, MySQL rejects any or operation that attempts to create a foreign key value in a child table if there is no matching candidate key value in the parent table. For an or that is not specified, the default action is always . As the default, an or clause that is specified explicitly does not appear in output or in tables dumped with mysqldump. , which is an equivalent non-default keyword, appears in output and in tables dumped with mysqldump. For tables, is not supported where the reference is to the parent table's primary key. For tables, is not supported where the child table contains one or more columns of any of the or types. (Bug #89511, Bug #27484882) performs cascading operations using a depth-first search algorithm on the records of the index that corresponds to the foreign key constraint. A foreign key constraint on a stored generated column cannot use , , or as referential actions, nor can it use or as referential actions. A foreign key constraint on the base column of a stored generated column cannot use , , or as or referential actions.\n\nIn MySQL, InnoDB and NDB tables support checking of foreign key constraints. Foreign key checking is controlled by the variable, which is enabled by default. Typically, you leave this variable enabled during normal operation to enforce referential integrity. The variable has the same effect on tables as it does for tables. The variable is dynamic and supports both global and session scopes. For information about using system variables, see Section 7.1.9, “Using System Variables”. Disabling foreign key checking is useful when:\n• None Dropping a table that is referenced by a foreign key constraint. A referenced table can only be dropped after is disabled. When you drop a table, constraints defined on the table are also dropped.\n• None Reloading tables in different order than required by their foreign key relationships. For example, mysqldump produces correct definitions of tables in the dump file, including foreign key constraints for child tables. To make it easier to reload dump files for tables with foreign key relationships, mysqldump automatically includes a statement in the dump output that disables . This enables you to import the tables in any order in case the dump file contains tables that are not correctly ordered for foreign keys. Disabling also speeds up the import operation by avoiding foreign key checks.\n• None Performing an operation on a table that has a foreign key relationship. When is disabled, foreign key constraints are ignored, with the following exceptions:\n• None Recreating a table that was previously dropped returns an error if the table definition does not conform to the foreign key constraints that reference the table. The table must have the correct column names and types. It must also have indexes on the referenced keys. If these requirements are not satisfied, MySQL returns Error 1005 that refers to errno: 150 in the error message, which means that a foreign key constraint was not correctly formed.\n• None Altering a table returns an error (errno: 150) if a foreign key definition is incorrectly formed for the altered table.\n• None Dropping an index required by a foreign key constraint. The foreign key constraint must be removed before dropping the index.\n• None It is permitted to drop a database that contains tables with foreign keys that are referenced by tables outside the database.\n• None It is permitted to drop a table with foreign keys referenced by other tables.\n• None Enabling does not trigger a scan of table data, which means that rows added to a table while is disabled are not checked for consistency when is re-enabled.\n\nMySQL extends metadata locks, as necessary, to tables that are related by a foreign key constraint. Extending metadata locks prevents conflicting DML and DDL operations from executing concurrently on related tables. This feature also enables updates to foreign key metadata when a parent table is modified. In earlier MySQL releases, foreign key metadata, which is owned by the child table, could not be updated safely. If a table is locked explicitly with , any tables related by a foreign key constraint are opened and locked implicitly. For foreign key checks, a shared read-only lock ( ) is taken on related tables. For cascading updates, a shared-nothing write lock ( ) is taken on related tables that are involved in the operation.\n\nIn the event of a foreign key error involving tables (usually Error 150 in the MySQL Server), information about the latest foreign key error can be obtained by checking output. mysql> SHOW ENGINE INNODB STATUS\\G ... ------------------------ LATEST FOREIGN KEY ERROR ------------------------ 2018-04-12 14:57:24 0x7f97a9c91700 Transaction: TRANSACTION 7717, ACTIVE 0 sec inserting mysql tables in use 1, locked 1 4 lock struct(s), heap size 1136, 3 row lock(s), undo log entries 3 MySQL thread id 8, OS thread handle 140289365317376, query id 14 localhost root update INSERT INTO child VALUES (NULL, 1), (NULL, 2), (NULL, 3), (NULL, 4), (NULL, 5), (NULL, 6) Foreign key constraint fails for table `test`.`child`: , CONSTRAINT `child_ibfk_1` FOREIGN KEY (`parent_id`) REFERENCES `parent` (`id`) ON DELETE CASCADE ON UPDATE CASCADE Trying to add in child table, in index par_ind tuple: DATA TUPLE: 2 fields; 0: len 4; hex 80000003; asc ;; 1: len 4; hex 80000003; asc ;; But in parent table `test`.`parent`, in index PRIMARY, the closest match we can find is record: PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 4; hex 80000004; asc ;; 1: len 6; hex 000000001e19; asc ;; 2: len 7; hex 81000001110137; asc 7;; ... If a user has table-level privileges for all parent tables, and error messages for foreign key operations expose information about parent tables. If a user does not have table-level privileges for all parent tables, more generic error messages are displayed instead ( and ). An exception is that, for stored programs defined to execute with privileges, the user against which privileges are assessed is the user in the program clause, not the invoking user. If that user has table-level parent table privileges, parent table information is still displayed. In this case, it is the responsibility of the stored program creator to hide the information by including appropriate condition handlers."
    },
    {
        "link": "https://dev.mysql.com/doc/en/create-table.html",
        "document": "creates a table with the given name. You must have the privilege for the table.\n\nBy default, tables are created in the default database, using the storage engine. An error occurs if the table exists, if there is no default database, or if the database does not exist.\n\nMySQL has no limit on the number of tables. The underlying file system may have a limit on the number of files that represent tables. Individual storage engines may impose engine-specific constraints. permits up to 4 billion tables.\n\nFor information about the physical representation of a table, see Section 15.1.20.1, “Files Created by CREATE TABLE”.\n\nThere are several aspects to the statement, described under the following topics in this section:\n\nYou can use the keyword when creating a table. A table is visible only within the current session, and is dropped automatically when the session is closed. For more information, see Section 15.1.20.2, “CREATE TEMPORARY TABLE Statement”.\n\nThere is a hard limit of 4096 columns per table, but the effective maximum may be less for a given table and depends on the factors discussed in Section 10.4.7, “Limits on Table Column Count and Row Size”.\n\nSeveral keywords apply to creation of indexes, foreign keys, and constraints. For general background in addition to the following descriptions, see Section 15.1.15, “CREATE INDEX Statement”, Section 15.1.20.5, “FOREIGN KEY Constraints”, and Section 15.1.20.6, “CHECK Constraints”.\n\nTable options are used to optimize the behavior of the table. In most cases, you do not have to specify any of them. These options apply to all storage engines unless otherwise indicated. Options that do not apply to a given storage engine may be accepted and remembered as part of the table definition. Such options then apply if you later use to convert the table to use a different storage engine.\n\ncan be used to control partitioning of the table created with .\n\nNot all options shown in the syntax for at the beginning of this section are available for all partitioning types. Please see the listings for the following individual types for information specific to each type, and see Chapter 26, Partitioning, for more complete information about the workings of and uses for partitioning in MySQL, as well as additional examples of table creation and other statements relating to MySQL partitioning.\n\nPartitions can be modified, merged, added to tables, and dropped from tables. For basic information about the MySQL statements to accomplish these tasks, see Section 15.1.9, “ALTER TABLE Statement”. For more detailed descriptions and examples, see Section 26.3, “Partition Management”.\n• None If used, a clause begins with . This clause contains the function that is used to determine the partition; the function returns an integer value ranging from 1 to , where is the number of partitions. (The maximum number of user-defined partitions which a table may contain is 1024; the number of subpartitions—discussed later in this section—is included in this maximum.) The expression ( ) used in a clause cannot refer to any columns not in the table being created; such references are specifically not permitted and cause the statement to fail with an error. (Bug #29444)\n• None Hashes one or more columns to create a key for placing and locating rows. is an expression using one or more table columns. This can be any valid MySQL expression (including MySQL functions) that yields a single integer value. For example, these are both valid statements using : You may not use either or clauses with . uses the remainder of divided by the number of partitions (that is, the modulus). For examples and additional information, see Section 26.2.4, “HASH Partitioning”. The keyword entails a somewhat different algorithm. In this case, the number of the partition in which a row is stored is calculated as the result of one or more logical operations. For discussion and examples of linear hashing, see Section 26.2.4.1, “LINEAR HASH Partitioning”.\n• None This is similar to , except that MySQL supplies the hashing function so as to guarantee an even data distribution. The argument is simply a list of 1 or more table columns (maximum: 16). This example shows a simple table partitioned by key, with 4 partitions: For tables that are partitioned by key, you can employ linear partitioning by using the keyword. This has the same effect as with tables that are partitioned by . That is, the partition number is found using the operator rather than the modulus (see Section 26.2.4.1, “LINEAR HASH Partitioning”, and Section 26.2.5, “KEY Partitioning”, for details). This example uses linear partitioning by key to distribute data between 5 partitions: The option is supported with . causes the server to use the same key-hashing functions as MySQL 5.1; means that the server employs the key-hashing functions implemented and used by default for new partitioned tables in MySQL 5.5 and later. (Partitioned tables created with the key-hashing functions employed in MySQL 5.5 and later cannot be used by a MySQL 5.1 server.) Not specifying the option has the same effect as using . This option is intended for use chiefly when upgrading or downgrading partitioned tables between MySQL 5.1 and later MySQL versions, or for creating tables partitioned by or on a MySQL 5.5 or later server which can be used on a MySQL 5.1 server. For more information, see Section 15.1.9.1, “ALTER TABLE Partition Operations”. is shown when necessary in the output of using versioned comments in the same manner as mysqldump. is always omitted from output, even if this option was specified when creating the original table. You may not use either or clauses with .\n• None In this case, shows a range of values using a set of operators. When using range partitioning, you must define at least one partition using . You cannot use with range partitioning. For tables partitioned by , must be used with either an integer literal value or an expression that evaluates to a single integer value. In MySQL 8.4, you can overcome this limitation in a table that is defined using , as described later in this section. Suppose that you have a table that you wish to partition on a column containing year values, according to the following scheme. A table implementing such a partitioning scheme can be realized by the statement shown here: CREATE TABLE t1 ( year_col INT, some_data INT ) PARTITION BY RANGE (year_col) ( PARTITION p0 VALUES LESS THAN (1991), PARTITION p1 VALUES LESS THAN (1995), PARTITION p2 VALUES LESS THAN (1999), PARTITION p3 VALUES LESS THAN (2002), PARTITION p4 VALUES LESS THAN (2006), PARTITION p5 VALUES LESS THAN MAXVALUE ); statements work in a consecutive fashion. works to specify “leftover” values that are greater than the maximum value otherwise specified. clauses work sequentially in a manner similar to that of the portions of a block (as found in many programming languages such as C, Java, and PHP). That is, the clauses must be arranged in such a way that the upper limit specified in each successive is greater than that of the previous one, with the one referencing coming last of all in the list.\n• None This variant on facilitates partition pruning for queries using range conditions on multiple columns (that is, having conditions such as or WHERE a = 1 AND b = 10 AND c < 10 ). It enables you to specify value ranges in multiple columns by using a list of columns in the clause and a set of column values in each partition definition clause. (In the simplest case, this set consists of a single column.) The maximum number of columns that can be referenced in the and is 16. The used in the clause may contain only names of columns; each column in the list must be one of the following MySQL data types: the integer types; the string types; and time or date column types. Columns using , , , , , or spatial data types are not permitted; columns that use floating-point number types are also not permitted. You also may not use functions or arithmetic expressions in the clause. The clause used in a partition definition must specify a literal value for each column that appears in the clause; that is, the list of values used for each clause must contain the same number of values as there are columns listed in the clause. An attempt to use more or fewer values in a clause than there are in the clause causes the statement to fail with the error Inconsistency in usage of column lists for partitioning.... You cannot use for any value appearing in . It is possible to use more than once for a given column other than the first, as shown in this example: CREATE TABLE rc ( a INT NOT NULL, b INT NOT NULL ) PARTITION BY RANGE COLUMNS(a,b) ( PARTITION p0 VALUES LESS THAN (10,5), PARTITION p1 VALUES LESS THAN (20,10), PARTITION p2 VALUES LESS THAN (50,MAXVALUE), PARTITION p3 VALUES LESS THAN (65,MAXVALUE), PARTITION p4 VALUES LESS THAN (MAXVALUE,MAXVALUE) ); Each value used in a value list must match the type of the corresponding column exactly; no conversion is made. For example, you cannot use the string for a value that matches a column that uses an integer type (you must use the numeral instead), nor can you use the numeral for a value that matches a column that uses a string type (in such a case, you must use a quoted string: ). For more information, see Section 26.2.1, “RANGE Partitioning”, and Section 26.4, “Partition Pruning”.\n• None This is useful when assigning partitions based on a table column with a restricted set of possible values, such as a state or country code. In such a case, all rows pertaining to a certain state or country can be assigned to a single partition, or a partition can be reserved for a certain set of states or countries. It is similar to , except that only may be used to specify permissible values for each partition. is used with a list of values to be matched. For instance, you could create a partitioning scheme such as the following: CREATE TABLE client_firms ( id INT, name VARCHAR(35) ) PARTITION BY LIST (id) ( PARTITION r0 VALUES IN (1, 5, 9, 13, 17, 21), PARTITION r1 VALUES IN (2, 6, 10, 14, 18, 22), PARTITION r2 VALUES IN (3, 7, 11, 15, 19, 23), PARTITION r3 VALUES IN (4, 8, 12, 16, 20, 24) ); When using list partitioning, you must define at least one partition using . You cannot use with . For tables partitioned by , the value list used with must consist of integer values only. In MySQL 8.4, you can overcome this limitation using partitioning by , which is described later in this section.\n• None This variant on facilitates partition pruning for queries using comparison conditions on multiple columns (that is, having conditions such as or WHERE a = 1 AND b = 10 AND c = 5 ). It enables you to specify values in multiple columns by using a list of columns in the clause and a set of column values in each partition definition clause. The rules governing regarding data types for the column list used in and the value list used in are the same as those for the column list used in and the value list used in , respectively, except that in the clause, is not permitted, and you may use . There is one important difference between the list of values used for with as opposed to when it is used with . When used with , each element in the clause must be a set of column values; the number of values in each set must be the same as the number of columns used in the clause, and the data types of these values must match those of the columns (and occur in the same order). In the simplest case, the set consists of a single column. The maximum number of columns that can be used in the and in the elements making up the is 16. The table defined by the following statement provides an example of a table using partitioning: CREATE TABLE lc ( a INT NULL, b INT NULL ) PARTITION BY LIST COLUMNS(a,b) ( PARTITION p0 VALUES IN( (0,0), (NULL,NULL) ), PARTITION p1 VALUES IN( (0,1), (0,2), (0,3), (1,1), (1,2) ), PARTITION p2 VALUES IN( (1,0), (2,0), (2,1), (3,0), (3,1) ), PARTITION p3 VALUES IN( (1,3), (2,2), (2,3), (3,2), (3,3) ) );\n• None The number of partitions may optionally be specified with a clause, where is the number of partitions. If both this clause and any clauses are used, must be equal to the total number of any partitions that are declared using clauses. Whether or not you use a clause in creating a table that is partitioned by or , you must still include at least one clause in the table definition (see below).\n• None A partition may optionally be divided into a number of subpartitions. This can be indicated by using the optional clause. Subpartitioning may be done by or . Either of these may be . These work in the same way as previously described for the equivalent partitioning types. (It is not possible to subpartition by or .) The number of subpartitions can be indicated using the keyword followed by an integer value.\n• None Rigorous checking of the value used in or clauses is applied and this value must adhere to the following rules:\n• None The value must be a positive, nonzero integer.\n• None The value must be an integer literal, and cannot not be an expression. For example, is not permitted, even though evaluates to . (Bug #15890)\n• None Each partition may be individually defined using a clause. The individual parts making up this clause are as follows:\n• None Specifies a logical name for the partition.\n• None For range partitioning, each partition must include a clause; for list partitioning, you must specify a clause for each partition. This is used to determine which rows are to be stored in this partition. See the discussions of partitioning types in Chapter 26, Partitioning, for syntax examples.\n• None MySQL accepts a option for both and . Currently, the only way in which this option can be used is to set all partitions or all subpartitions to the same storage engine, and an attempt to set different storage engines for partitions or subpartitions in the same table raises the error ERROR 1469 (HY000): The mix of handlers in the partitions is not permitted in this version of MySQL.\n• None An optional clause may be used to specify a string that describes the partition. Example: COMMENT = 'Data for the years previous to 1999' The maximum length for a partition comment is 1024 characters.\n• None and may be used to indicate the directory where, respectively, the data and indexes for this partition are to be stored. Both the and the must be absolute system path names. The directory specified in a clause must be known to . For more information, see Using the DATA DIRECTORY Clause. You must have the privilege to use the or partition option. CREATE TABLE th (id INT, name VARCHAR(30), adate DATE) PARTITION BY LIST(YEAR(adate)) ( PARTITION p1999 VALUES IN (1995, 1999, 2003) DATA DIRECTORY = '/var/appdata/95/data' INDEX DIRECTORY = '/var/appdata/95/idx', PARTITION p2000 VALUES IN (1996, 2000, 2004) DATA DIRECTORY = '/var/appdata/96/data' INDEX DIRECTORY = '/var/appdata/96/idx', PARTITION p2001 VALUES IN (1997, 2001, 2005) DATA DIRECTORY = '/var/appdata/97/data' INDEX DIRECTORY = '/var/appdata/97/idx', PARTITION p2002 VALUES IN (1998, 2002, 2006) DATA DIRECTORY = '/var/appdata/98/data' INDEX DIRECTORY = '/var/appdata/98/idx' ); and behave in the same way as in the statement's clause as used for tables. One data directory and one index directory may be specified per partition. If left unspecified, the data and indexes are stored by default in the table's database directory. The and options are ignored for creating partitioned tables if is in effect.\n• None May be used to specify, respectively, the maximum and minimum number of rows to be stored in the partition. The values for and must be positive integers. As with the table-level options with the same names, these act only as “suggestions” to the server and are not hard limits.\n• None May be used to designate an file-per-table tablespace for the partition by specifying . All partitions must belong to the same storage engine. Placing table partitions in shared tablespaces is not supported. Shared tablespaces include the system tablespace and general tablespaces.\n• None The partition definition may optionally contain one or more clauses. Each of these consists at a minimum of the , where is an identifier for the subpartition. Except for the replacement of the keyword with , the syntax for a subpartition definition is identical to that for a partition definition. Subpartitioning must be done by or , and can be done only on or partitions. See Section 26.2.6, “Subpartitioning”.\n\nPartitioning by generated columns is permitted. For example:\n\nPartitioning sees a generated column as a regular column, which enables workarounds for limitations on functions that are not permitted for partitioning (see Section 26.6.3, “Partitioning Limitations Relating to Functions”). The preceding example demonstrates this technique: cannot be used directly in the clause, but a generated column defined using is permitted."
    },
    {
        "link": "https://geeksforgeeks.org/mysql-foreign-key-constraint",
        "document": "A FOREIGN KEY is a field/column(or collection of fields) in a table that refers to a PRIMARY KEY in another table. It is used for linking one or more than one table together. FOREIGN KEY is also called referencing key. A Foreign key creates a link (relation) between two tables thus creating referential integrity.\n\nIn this article, we will learn about how to use foreign keys in MySQL with examples.\n\nThe FOREIGN KEY creates a relationship between the columns in the current table or let's say table A (the one with the foreign key) and the referenced table or table B (the one with the unique key).\n\nFOREIGN KEY creates a parent-child type of relationship where the table with the FOREIGN KEY in the child table refers to the primary or unique key column in the parent table.\n\nHow to Define FOREIGN KEY in MySQL\n\nThere are 2 ways to create a FOREIGN KEY in MySQL:\n\nWe can create a FOREIGN KEY while creating the table, or add a FOREIGN KEY after the creation of the table.\n\nCREATE method can be used to define your FOREIGN KEY in MYSQL in the following way:\n• child_table : The name of the table where the foreign key is being defined.\n• child_id : The primary key column of the child_table.\n• parent_id : The foreign key column in the child_table that refers to the primary key in the parent table.\n\nLet us understand the concept of MySQL FOREIGN KEY with an example.\n\nWe are two tables namely Users and Orders. The Users table will be the parent table, as it contains the PRIMARY KEY (user_ID) and referenced by foreign key (User_ID). And Orders table will be the child table.\n\nExplanation: We have created two table users and orders. orders table has a foreign key on field user_id that references the primary key user_id of users table.\n\nWe can define a foreign key using the ALTER TABLE statement in MySQL. This is the case where you already have a table and need to get a foreign key in it.\n\nThe foreign key constraint helps maintain referential integrity between the two tables.\n\nLet us apply this in an example and understand the working.\n\nWe will create two tables orders and customers.\n\nNow in the orders table, let us add the foreign key using ALTER TABLE.\n\nTable structure verification can be done by using some SQL queries. The following queries can help you inspect the structure of the tables and also confirm if there is a foreign key available:\n\nThis lists all the tables in your database\n\nThe structure of specific table can be viewed with this query.\n\nNow the foreign keys in a table can be listed using the following query.\n\n\n\nQuery:\n\nThe SET NULL action in a foreign key constraint is used to delete or update row in the parent table while setting the foreign key column in the child table to NULL. [NULL here refers to empty or not known]\n\nLet me simplify this with help of an example:\n\nWe have two tables: employees and departments. Employee table has the information about the employees along with the dept_id (the department to which they belong).\n\nThe departments table has the department name and its corresponding id, in the dept_id column. (for ex. 101 for HR, 102 for IT...)\n\nThe employees table has the dept_id as foreign key that refers to the primary key (dept_id) in the departments table. Now in a scenario where the department is deleted, the corresponding dept_id in the employees table will automatically change NULL.\n\nSo even when a department is deleted, we still have record of the employees that were from that department. This is an important rule that helps us to retain data and avoid errors in the employee table even when something in the departments table is changed or deleted.\n\nNow let's update the department_id in the departments table and set it to NULL in employees table\n\nNow let's delete a department and set corresponding dept_id to NULL in employees table\n\nThe foreign key can be dropped using the DROP FOREIGN KEY clause.\n\nForeign key checks are rulebooks/ mechanisms that ensure the consistency of relationships between tables. These help us maintain referential integrity, preventing actions that could disturb the relationships.\n\nLet us understand the concept of foreign key checks. Foreign key checks are in two modes: Enabled or Disabled.\n\nNow when we need to perform some special actions like bulk updation, insertion or deletion we may need to disable these checks temporarily to avoid errors. It's crucial to re-enable foreign key checks promptly after the bulk update or deletion to ensure that data integrity is restored.\n\nIn conclusion, effectively utilizing foreign keys in MySQL is important for designing robust and well-structured relational databases. Foreign keys serve as a very helpful tool in maintaining referential integrity, ensuring that relationships between tables are consistent and reliable.\n\nWhat is a FOREIGN KEY in MySQL?\n\nWhat is the purpose of a FOREIGN KEY?"
    },
    {
        "link": "https://dev.mysql.com/doc/mysql-tutorial-excerpt/8.0/en/example-foreign-keys.html",
        "document": "MySQL supports foreign keys, which permit cross-referencing related data across tables, and foreign key constraints, which help keep the related data consistent.\n\nA foreign key relationship involves a parent table that holds the initial column values, and a child table with column values that reference the parent column values. A foreign key constraint is defined on the child table.\n\nThis following example relates and tables through a single-column foreign key and shows how a foreign key constraint enforces referential integrity.\n\nCreate the parent and child tables using the following SQL statements:\n\nInsert a row into the parent table, like this:\n\nVerify that the data was inserted. You can do this simply by selecting all rows from , as shown here:\n\nInsert a row into the child table using the following SQL statement:\n\nThe insert operation is successful because 1 is present in the parent table.\n\nInsertion of a row into the child table with a value that is not present in the parent table is rejected with an error, as you can see here:\n\nThe operation fails because the specified value does not exist in the parent table.\n\nTrying to delete the previously inserted row from the parent table also fails, as shown here:\n\nThis operation fails because the record in the child table contains the referenced id ( ) value.\n\nWhen an operation affects a key value in the parent table that has matching rows in the child table, the result depends on the referential action specified by and subclauses of the clause. Omitting and clauses (as in the current child table definition) is the same as specifying the option, which rejects operations that affect a key value in the parent table that has matching rows in the parent table.\n\nTo demonstrate and referential actions, drop the child table and recreate it to include and subclauses with the option. The option automatically deletes or updates matching rows in the child table when deleting or updating rows in the parent table.\n\nInsert some rows into the child table using the statement shown here:\n\nVerify that the data was inserted, like this:\n\nUpdate the ID in the parent table, changing it from 1 to 2, using the SQL statement shown here:\n\nVerify that the update was successful by selecting all rows from the parent table, as shown here:\n\nVerify that the referential action updated the child table, like this:\n\nTo demonstrate the referential action, delete records from the parent table where ; this deletes all records in the parent table.\n\nBecause all records in the child table are associated with , the referential action removes all records from the child table, as shown here:\n\nFor more information about foreign key constraints, see FOREIGN KEY Constraints."
    },
    {
        "link": "https://datacamp.com/doc/mysql/mysql-create-table",
        "document": "The `CREATE TABLE` statement in MySQL is used to define a new table in the database. It specifies the table name, columns, and their data types, along with any constraints.\n\nThe `CREATE TABLE` statement is used when you need to set up a new table structure in your database to store data. It is an essential part of database schema design.\n\nIn this syntax, `table_name` is the name of the new table, and each column is defined by its name, datatype, and optional constraints.\n\nThis example creates a simple `students` table with two columns: an integer `id` and a string `name` of up to 100 characters.\n\nHere, the `employees` table is created with a primary key constraint on `employee_id` and a unique constraint on `email` to ensure data integrity.\n\nThis example creates an `orders` table with a foreign key constraint, linking `customer_id` to the `customer_id` column in the `customers` table for relational integrity.\n\nThis example demonstrates the use of `AUTO_INCREMENT` for `product_id` to automatically generate unique identifiers, and a default value of `0.00` for the `price` column.\n• Plan your schema. Carefully plan your table structure and relationships before creating tables to ensure efficient data retrieval and storage.\n• Use meaningful names. Choose clear and descriptive names for tables and columns to improve readability and maintainability.\n• Define constraints. Use constraints (e.g., `PRIMARY KEY`, `UNIQUE`, `FOREIGN KEY`) to enforce data integrity and prevent invalid data entry. Constraints are rules applied to columns to maintain accuracy and reliability of data.\n• Consider data types. Choose data types carefully for performance optimization. Large VARCHAR lengths can impact storage, so use appropriate lengths based on the expected data size.\n• Consider indexing. Create indexes on columns that are frequently used in search conditions to improve query performance."
    },
    {
        "link": "https://coderpad.io/blog/development/optimize-mysql-database-schema",
        "document": "According to the TIOBE index, MySQL is listed among the top databases used in developing APIs for web and mobile applications. The performance and user experience of your app depend on the performance of your database. That is why database engineers and web developers are often required to know how to tune a database for optimal performance.\n\nWhen tuning a slow database, we usually begin by optimizing the queries we write. But another way you can speed up your database is by optimizing your schema.\n\nThis guide presumes that you are an experienced engineer with basic knowledge of relational databases like MySQL, PostgreSQL, etc. By the end of this article, you will:\n• Learn the different techniques that can be used to optimize a database schema\n\nA database schema, or just schema for short, is a blueprint that represents the organization of data in your database. It represents the general structure of the logical features of a database including elements such as tables, fields, records, columns, triggers, functions, procedures, indexes, and keys as well as the relationships they have with one other.\n\nDatabase schemas help with database optimization to drive faster query response times by aiding efficient retrieval of data. Database schema design refers to the various practices or techniques involved in constructing a database schema.\n\nGood database schema design can be a deciding factor to measure query performance.\n\nWhile database schemas are used by database administrators to model and build the structure of a database, Entity Relationship Diagrams (ERDs) are used to visually represent the relationship between entities in your database. ERDs are much easier to understand by end-users and business owners.\n\nERDs are used to show the relationship between tables, which are usually represented in squares, and lines, which show primary and secondary key constraints between the tables. You will often find symbols and line connectors explaining the type of relationship between the entities (one-to-one, one-to-many, many-to-many).\n\nA poorly designed schema can significantly hurt database performance and query execution speed. Inefficiently organized data consume lots of system resources. They are also very confusing and hard to maintain by database administrators. This is why designing a good schema is important.\n\nSome of the benefits of well-designed schemas include:\n• Making your data easy to understand, analyze and interpret.\n\nHow to Create a Database Schema in MySQL\n\nThere are several ways to create a schema in MySQL. You can easily use the MySQL Workbench Tool to create the schema; under the hood, MySQL Workbench creates an SQL file and runs it on your behalf. You can also create a SQL file in a text editor and define your schema in it. The most common approach, however, would be to make use of an existing ORM to define your schemas.\n\nTo create a schema using MySQL Workbench, you can follow the following steps:\n\n1. Open MySQL Workbench and connect to your MySQL instance.\n\n2. In the SQL Editor view, locate and click on the create schema button:\n\n3. Enter the name for your schema and click the “Apply” button.\n\n4. The next screen allows you to customize the schema by applying an SQL script. You can use this screen to define the tables, columns, constraints, indexes, etc.\n\n5. Finally, you can click on “Apply” to execute the script.\n\nIf you are a terminal freak like me 😂, you can avoid the steps above by creating a new SQL file to define your schemas. When done you can run a command to execute the SQL script file in this manner:\n\nIf you’re already logged into the MySQL shell, you can run the following instead:\n\nYou can also run direct commands to create a database with tables and columns, etc as demonstrated in the following steps:\n\nAfter logging in to the MySQL shell, create an database using this command:\n\nHow to Optimize a Schema for Performance\n\nWhen designing a database schema, we have to ensure that it is optimized for performance. In this section, we discuss in-depth the different techniques you can use to do so.\n\nA lot of database admins and programmers often struggle with understanding the information stored in existing databases. This is mostly because of the naming conventions that were used to create the tables and columns.\n\nA table name must describe the entity it represents and the column names must properly describe the properties of the entity. When you use confusing words for the table or column names, they become unreadable and you make it hard for that entity to be understood by others.\n\nYou can adopt the following rules to ensure proper naming convention in your database schemas:\n• Avoid acronyms or short words for tables and column names. Remember not everyone may understand the acronym you use. Instead, try to write the names fully and clearly.\n• Use underscores to separate words e.g. instead of .\n• Avoid using reserved words for your tables and column names because they will lead to a syntax error.\n• Avoid using special characters for your tables and column names.\n• Table names should be in the singular form e.g. instead of .\n• Use simple words that inform the underlying data represented. For example, a table that represents cities in a country can be simply named instead of .\n\nUsing the wrong data types to represent data in your schema can increase disk space usage, and affect query performance and data retrieval speed. You should always use the proper types to describe the data you wish to store.\n\nThankfully, we are not short of options when it comes to picking the right data type as MySQL provides a large variety. You can follow the guidelines below when deciding on what data type to choose.\n\nA common mistake in schema design is using large data types to represent data. If you care about saving some disk space, you should consider going for the smallest data type that represents the data you’re trying to store.\n\nAn example is when you wish to save strings. Let’s say you have a column that saves usernames shorter than 30 characters. You can use the to represent data in that column.\n\nFor text that may be longer, such as a user’s bio, you can limit the text to, let’s say, 255 characters and use .\n\nFor yes or no values, a is significantly better and more performant than a . This is because the has a fixed length of exactly 1 byte, whereas , because of its variable length nature, will have to store extra information about the length of characters which takes about 2 more bytes. You can also use the type to represent booleans in MySQL.\n\nUse the right data types\n\nIn SQL, it’s very possible to represent data in as many data types. But choosing the right one is the sweet spot to optimizing your schema.\n\nAn example (also a common question asked) is how to represent dates in SQL. MySQL provides the , , and types to represent dates. They are quite similar and often can be used to achieve the same thing, but still have quite a few differentiating factors. According to theofficial documentation,\n• The type is used for values with a date part but no time part.\n• The type is used for values that have both date and time parts in the ‘YYYY-MM-DD hh:mm:ss’ format.\n• The is also used for values that have both date and time parts but it expects values in the range ‘1970-01-01 00:00:01’ UTC to ‘2038-01-19 03:14:07’ UTC.\n\nSo whenever you want to represent a field that contains only dates, you’ll be better off with the type. But if you want to keep track of the time you can use the or the data types. Another reason you may want to choose the or types is if you need automatic initialization and updates to the current date and time for your data.\n\nAvoid Nulls as much as possible\n\nAnother design flaw with database schemas is setting as a default even when you don’t mean it. Columns that have data types make it difficult for MYSQL to optimize queries that access them.\n\nIf you need to improve disk usage, data access, and query speed a little, you should instead use as default if you are sure that there won’t be any values in a column.\n\nReferential integrity is a data quality concept that prevents data inconsistency and loss. It can be used to ensure that changes in a table reflect in other tables. It is also used to enforce constraints across tables in your database.\n\nFor example, a primary key constraint enforces that a primary key of a table cannot be null when referenced. You can also create constraints between tables by matching the primary key of a table with the foreign key of another table.\n\nFailure to add these constraints will make data integrity dependent on business logic only, making it prone to human error.\n\nThe following example shows how we can enforce referential integrity with foreign keys:\n\nLog into your MySQL shell from your terminal:\n\nCreate a database using the following command:\n\nOur database is quite small and only has two tables, an table, and a table. Both tables share a one-to-many relationship. This means that:\n• An can create many .\n• An can only belong to one .\n\nWe will create the two tables, define the columns for each table, and link them together. But before we dive into that, we have to make sure the design meets the following constraints:\n• We create the tables using the database engine.\n• We must index the columns that will hold the foreign and primary keys.\n• We also need to ensure that the data types of the related columns are the same.\n\nThe following example shows how we would create the two tables, add constraints and establish the 1-n (One-to-many) relationship between them.\n\nThe following example shows another way you can create a 1-n (one-to-many) relationship between tables in MySQL using a composite key:\n\nThe relationship is one-to-many because the foreign keys we defined in both examples lack the constraint on them. This is the main difference between a 1-1 and 1-n relationship in SQL.\n\nFor our example, we will use the first method since we do not need to create a composite key, also it’s far easier to type. Run the command in the first example to create the tables.\n\nNext, we add some authors to our database:\n\nWe can confirm the inserts by inspecting the table’s records:\n\nLet’s add some data to our table. Run the following:\n\nJust as we did for the authors, we can confirm that we inserted our data correctly:\n\nNormally, if we were to query data to be sent to an application, we would probably use a query to combine the data in related tables as follows:\n\nNote that using an will only select rows that have data on both sides of the relationship. To select all the rows, you can use a or .\n\nFinally, the most important bit. Let’s test the constraint rules we defined by inserting an article with an invalid like 7:\n\nMySQL performed a referential integrity check which our query failed to obey and this resulted in an error thrown by the MySQL server.\n\nBecause of the rules we have set up in our schema, we have prevented human error from ruining the data integrity of our database, as well as prevented data loss. This is the main reason why you need to enforce referential integrity in your databases.\n\nNormalization is a database design technique that involves efficiently organizing data to eliminate data redundancy and correct data dependency. The concept of normalizing data was developed by E.F.Codd in 1970 [1]. Knowing and applying the principles of normalization can drastically improve your databases’ performance.\n\nNormal Forms are a series of guidelines that ensure data is normalized. The steps mentioned in the guidelines are usually done in sequence, one form before the next.\n\nThere are about seven (7) types of normal forms: First Normal Form (1NF), Second Normal Form (2NF), Third Normal Form (3NF), Boyce-Codd Normal Form (BCNF), Fourth Normal Form (4NF), Fifth Normal Form (5NF) and the Domain-Key Normal Form (DKNF).\n\nIn practical database design, we mainly use up to the Third or occasionally the Fourth Normal Form. You rarely need to worry about the others, so I have skipped them. But if you want to read about the others, check out this resource.\n\nThe First Normal Form lays the foundation for organizing a database. A relation achieves 1NF when it has only single viewed attributes (neither repeating). The rules to achieving that include:\n• Eliminate duplicate columns from the same table\n• Ensure that each column contains only one value (no arrays permitted)\n• No tables should have repeating groups of related data. Create individual tables for each group of related data, and identify each row with a unique column or set of columns (PRIMARY key)\n\nThe Second Normal Form continues where the First Normal Form rules stop. It further addresses the removal of duplicate data.\n\nA relation achieves 2NF when every non-key attribute is functionally dependent on the primary key. To achieve this:\n• You must first meet the requirements of the First Normal Form\n• Place subsets of data that apply to multiple rows in their own separate tables so that dependency can be preserved.\n• Use foreign keys to establish relationships between the new tables and their predecessors.\n\nA table satisfies the Third Normal Form when:\n• It meets the requirements of the Second Normal Form and\n• All the columns in the table are fully dependent on the primary key.\n\nThe example below shows a table representing data that needs to be normalized:\n\nIf we apply the First, Second, and Third Normal Form rules to our database design, we would have the following results:\n• It meets the requirements of the Third Normal Form and\n• It meets the requirements of BCNF and\n• It has no multivalued dependency.\n• Normalized tables are generally smaller than denormalized tables, which makes them occupy less storage and perform better.\n• You don’t have to use or in your queries when fetching data anymore because there’s a lack of redundancy. This speeds up query response times.\n• Most queries that retrieve data from normalized tables often involve joins and joins can be expensive compared to normal single table select queries\n• Some columns may perform better when placed within an index in the same table, but due to normalization, these columns are usually placed in separate tables.\n\nBased on the pros and cons of both normalized and denormalized databases, we can deduce that there’s no one fit for normalization. You can play with both approaches and stick with what works best or even mix the two. If you find your database queries performing slow or you are experiencing storage issues, it could be that you have redundant data present in your database. This is a good case to optimize your schema by normalizing it.\n\nGood database design is critical to the success of a DBMS. It makes life so easy for you, the database admin, your end-users, and even the MySQL server. Luckily for us, MySQL has evolved and provides many great tools and features that we can utilize when designing optimal databases.\n\nA well-designed schema is a foundation for MySQL database performance. Schema optimization can make your queries faster by reducing the amount of traffic and time required to query your database. In a previous article, we explained various techniques on how to optimize query performance in MySQL. If you have not read that article, I recommend you do so. In our next article, we will talk about indexes and how they can affect the performance of your database.\n\nI’m Elvis Duru. I create helpful content for web developers with a focus on React, Node.js, SQL/NoSQL Databases, and more! Let’s connect on Twitter.\n\n[1] E. F. Codd. A Relational Model of Data for Large Shared Data Banks. Communications of the ACM, 13(6):377-387, Jun 1970."
    },
    {
        "link": "https://dev.mysql.com/doc/mysql/en/optimize-overview.html",
        "document": "Database performance depends on several factors at the database level, such as tables, queries, and configuration settings. These software constructs result in CPU and I/O operations at the hardware level, which you must minimize and make as efficient as possible. As you work on database performance, you start by learning the high-level rules and guidelines for the software side, and measuring performance using wall-clock time. As you become an expert, you learn more about what happens internally, and start measuring things such as CPU cycles and I/O operations.\n\nTypical users aim to get the best database performance out of their existing software and hardware configurations. Advanced users look for opportunities to improve the MySQL software itself, or develop their own storage engines and hardware appliances to expand the MySQL ecosystem.\n\nThe most important factor in making a database application fast is its basic design:\n• None Are the tables structured properly? In particular, do the columns have the right data types, and does each table have the appropriate columns for the type of work? For example, applications that perform frequent updates often have many tables with few columns, while applications that analyze large amounts of data often have few tables with many columns.\n• None Are the right indexes in place to make queries efficient?\n• None Are you using the appropriate storage engine for each table, and taking advantage of the strengths and features of each storage engine you use? In particular, the choice of a transactional storage engine such as or a nontransactional one such as can be very important for performance and scalability. is the default storage engine for new tables. In practice, the advanced performance features mean that tables often outperform the simpler tables, especially for a busy database.\n• None Does each table use an appropriate row format? This choice also depends on the storage engine used for the table. In particular, compressed tables use less disk space and so require less disk I/O to read and write the data. Compression is available for all kinds of workloads with tables, and for read-only tables.\n• None Does the application use an appropriate locking strategy? For example, by allowing shared access when possible so that database operations can run concurrently, and requesting exclusive access when appropriate so that critical operations get top priority. Again, the choice of storage engine is significant. The storage engine handles most locking issues without involvement from you, allowing for better concurrency in the database and reducing the amount of experimentation and tuning for your code.\n• None Are all memory areas used for caching sized correctly? That is, large enough to hold frequently accessed data, but not so large that they overload physical memory and cause paging. The main memory areas to configure are the buffer pool and the key cache.\n\nAny database application eventually hits hardware limits as the database becomes more and more busy. A DBA must evaluate whether it is possible to tune the application or reconfigure the server to avoid these bottlenecks, or whether more hardware resources are required. System bottlenecks typically arise from these sources:\n• None Disk seeks. It takes time for the disk to find a piece of data. With modern disks, the mean time for this is usually lower than 10ms, so we can in theory do about 100 seeks a second. This time improves slowly with new disks and is very hard to optimize for a single table. The way to optimize seek time is to distribute the data onto more than one disk.\n• None Disk reading and writing. When the disk is at the correct position, we need to read or write the data. With modern disks, one disk delivers at least 10–20MB/s throughput. This is easier to optimize than seeks because you can read in parallel from multiple disks.\n• None CPU cycles. When the data is in main memory, we must process it to get our result. Having large tables compared to the amount of memory is the most common limiting factor. But with small tables, speed is usually not the problem.\n• None Memory bandwidth. When the CPU needs more data than can fit in the CPU cache, main memory bandwidth becomes a bottleneck. This is an uncommon bottleneck for most systems, but one to be aware of."
    },
    {
        "link": "https://percona.com/blog/mysql-101-parameters-to-tune-for-mysql-performance",
        "document": "This post was originally published in June 2020 and was updated in September 2023.\n\nWhile there is no magic bullet for MySQL performance tuning, there are a few areas that can be focused on upfront that can dramatically improve the performance of your MySQL installation. While much information has been published on this topic over the years, I wanted to break down some of the more critical settings that anyone can implement with no guesswork required.\n\nDepending on the version of MySQL you are running, some of the default values used in this post may differ from your install, but the premise is still largely the same.\n\nWhat are the Benefits of MySQL Performance Tuning?\n\nMySQL tuning offers several significant advantages for effective database management and optimization. Let’s explore these benefits in more detail.\n\nBy adjusting configuration settings, you can markedly enhance the overall efficiency of your MySQL database. This results in expedited query execution, reduced resource utilization, and more efficient exploitation of the available hardware resources.\n\nOne of the standout advantages of performance tuning lies in the significant enhancement of query response times. A finely tuned database processes queries more efficiently, leading to swifter results. This reduction in latency ensures that applications and websites provide a more rapid and responsive user experience.\n\nOptimizing resource-intensive queries and configurations can lead to a reduced burden on your server. This not only enhances performance but also enables you to make more efficient use of your hardware resources, potentially resulting in cost savings on infrastructure.\n\nWhether you operate an e-commerce platform, a content management system, or any other application reliant on MySQL, users will notice and appreciate the improved speed and responsiveness. This can significantly elevate user satisfaction and engagement.\n\nAs your data volume and user base expand, a finely tuned database can seamlessly accommodate increased workloads without compromising performance. This scalability ensures that your applications can grow in tandem with your business or user demands, maintaining a high level of operational efficiency.\n\nWhat are the Common Performance Issues in MySQL Databases?\n\nMySQL databases often encounter various performance challenges that limit their efficiency and responsiveness. It is crucial to identify and rectify these issues to optimize your database fully. Here are some of the most common performance concerns in MySQL:\n• None Slow queries are a common problem in MySQL databases, causing longer execution times and leading to a poor user experience. These issues often arise from suboptimal query design, missing or ineffective indexes, or dealing with large datasets. Detecting and optimizing slow queries is an important step in enhancing database performance.\n• None An improperly configured server may not allocate sufficient resources or be optimized for the specific workload. Tuning MySQL configuration parameters in line with your database’s needs helps your database perform optimally.\n• None While proper indexing is crucial for query optimization, inefficient indexing can become a performance bottleneck. Common issues include an excess of indexes, redundant indexing, or selecting inappropriate columns to index. An unoptimized indexing strategy can impede data insertion and retrieval operations.\n• None Resource contention emerges when multiple database operations vie for the same system resources simultaneously. This results in performance deterioration as queries and transactions queue up to access vital resources such as CPU, memory, or disk I/O. Striking a balance in resource allocation and minimizing contention ensures seamless database operations.\n• None MySQL employs locks to manage concurrent data access, but excessive locking and blocking can lead to decreased performance. Lengthy transactions, uncommitted transactions, or lock conflicts can cause other queries to wait, impacting database responsiveness.\n• None Inefficient query design, such as utilizing SELECT * instead of specifying necessary columns, can escalate data transfer and processing overhead. Regularly optimizing query structures is vital.\n• None Over time, tables and indexes can become fragmented due to data insertions, updates, and deletions, leading to suboptimal disk I/O and reduced performance. Regular maintenance tasks like defragmenting tables and rebuilding indexes can help improve efficiency.\n• None MySQL relies heavily on the availability of hardware resources to perform at its best. Inadequate CPU, memory, or storage can lead to bottlenecks and performance degradation, so remedying these issues involves upgrading hardware or optimizing resource utilization through query and server configuration adjustments.\n\nUnlocking the full potential of your MySQL database requires more than just its initial setup. To ensure your database operates at peak efficiency, you need to fine-tune its performance. In this section, we’ll explore six key MySQL performance tuning tips that can significantly enhance your database’s responsiveness, scalability, and overall efficiency.\n\nImproving MySQL query performance and minimizing query execution time is a crucial step in enhancing database efficiency. One effective strategy is query rewriting, where you restructure your SQL queries to be more efficient. This may entail eliminating unnecessary subqueries, simplifying intricate joins, and optimizing conditions in the WHERE clause. By fine-tuning your queries, you lighten the workload on your MySQL server, leading to quicker response times and an overall boost in database performance.\n\nIndexing is another powerful technique for query optimization. Properly indexing your database tables can significantly accelerate query execution. By creating indexes on columns commonly used in WHERE clauses or JOIN operations, MySQL can quickly locate the relevant data, reducing the need for full table scans. Additionally, regularly analyzing and optimizing your indexes is essential to ensure they remain effective as your data evolves. \n\n \n\n Query plan analysis can also provide valuable insights. MySQL provides tools to examine query execution plans, allowing you to identify bottlenecks, suboptimal join methods, or missing indexes.\n\nMonitoring and analyzing resource utilization in your MySQL database is crucial for maintaining optimal performance and preventing potential bottlenecks. Key metrics such as CPU usage, memory usage, and disk I/O offer insights into how efficiently your database server operates.\n\nHigh CPU usage, for example, can indicate that your server is under heavy processing load, possibly due to poorly optimized queries or increased user activity.\n\nMemory usage is another critical metric to watch because if your database server consistently uses a large portion of available memory, it might lead to slow query performance as data retrieval from disk becomes more frequent. Efficient memory management, including optimizing query caches and buffer pools, can help strike the right balance between memory consumption and query response times.\n\nLastly, monitoring disk I/O is essential because slow I/O operations can severely impact database performance. By analyzing disk I/O metrics, you can optimize queries to reduce disk reads or upgrade to faster storage solutions.\n\nIndexing plays a pivotal role in database performance, and its impact on query performance cannot be overstated. When you search for specific data within a database table, an index allows the database engine to quickly pinpoint the relevant rows, significantly reducing the time it takes to retrieve information. Without proper indexing, queries would need to scan through the entire table, which can lead to slow and resource-intensive operations, especially in large datasets.\n\nTo maximize indexing benefits, be sure to follow best practices. Start by wisely selecting columns to index, focusing on those in frequent WHERE clauses or JOIN operations. Avoid over-indexing, which can bloat storage and slow writes. Next, pick the right index type, like B-tree, hash, or full-text, aligning with your needs.\n\nRegular maintenance of indexes is also vital, especially as your database evolves. Periodically assess query performance to pinpoint areas for optimization and consider adding, removing, or modifying indexes.\n\nInnoDB configuration settings wield substantial influence over MySQL performance. Key parameters like the buffer pool size significantly impact efficiency by determining how much data MySQL can cache in memory for rapid access. Thread concurrency settings dictate the number of simultaneous connections MySQL can handle efficiently, and transaction isolation levels, such as Read Committed or Repeatable Read, affect how locking mechanisms operate, impacting concurrency and query execution speed.\n\nUtilizing caching mechanisms is a potent technique for accelerating query response times within MySQL databases. These mechanisms operate by retaining frequently accessed data or query outcomes in memory, enabling subsequent requests for the same information to be retrieved significantly faster than the alternative of fetching it directly from disk.\n\nOne commonly employed caching strategy is query caching, wherein MySQL preserves the outcomes of SELECT queries alongside the respective query. Consequently, if an identical query is made later, the cached results can be swiftly delivered, reducing query execution time.\n\nAnother highly beneficial caching method is key-value caching. In this approach, specific data, such as frequently accessed database rows or objects, is stored in a caching system, which facilitates rapid data retrieval without the necessity to access the database\n\nRoutine maintenance tasks are vital for maintaining the health and optimal performance of your database over time. Among these tasks, data pruning is a critical practice involving the periodic removal of outdated or unnecessary data from your database. By pruning, you can prevent the database from becoming bloated and experiencing performance degradation over time. Pruning also helps to meet compliance requirements for data retention policies, ensuring your database only contains relevant and valuable information.\n\nIndex reorganization is another essential maintenance activity because, over time, as data is inserted, updated, and deleted, indexes can become fragmented or inefficient. Reorganizing them helps to maintain integrity and ensures that query performance remains optimized.\n\nLastly, because statistics provide the query optimizer with information about data distribution, it’s important to update them regularly. Without up-to-date statistics, queries may be poorly optimized, leading to slower response times and decreased overall performance.\n\nInitial MySQL tuning can be broken down to the following categories:\n• Tuning for best performance / best practices\n\nDepending on the hardware you have installed MySQL on, some variables need to be set based on the machine (or VM) specifications. The following variables are largely dependent on your hardware:\n• Generally, set to 50% – 70% of your total RAM as a starting point.\n• It does not need to be set any larger than the total database size.\n• Percona Monitoring and Management (PMM) can offer additional insight, showing your buffer pool usage and allowing you to tune accordingly.\n• This is generally set between 128M – 2G.\n• Should be large enough to hold at most an hour or so of logs.\n• This is more than enough so that MySQL can reorder writes to use sequential I/O during the flushing and checkpointing processes.\n• PMM can offer additional insight, as if you are using more than 50% of your log space, you may benefit from a log file size increase.\n• Setting to “1” (default in 5.7) gives the most durability.\n• Setting to “0” or “2” will give more performance, but less durability.\n• Setting this to O_DIRECT will avoid a performance penalty from double buffering.\n\nMySQL Tuning for Best Performance & Best Practices\n• Setting this to “ON” will generate an independent InnoDB table space for every table in the database.\n• Setting this to “OFF” avoids unnecessary updating of InnoDB statistics and can greatly improve read speeds.\n• A best practice is to set this to “8” unless the buffer pool size is < 1G, in which case set to “1”.\n• Setting both of these to “0” will entirely disable the query cache.\n\nTo tune further, more information will be required. The best way to gather this information is to install a MySQL monitoring / graphing tool like Percona Monitoring and Management platform. Once you have a tool installed, we can dive into the individual metrics and start customizing based on the data.\n\nI would recommend starting with one of the most impactful variables – the innodb_buffer_pool_size. Compare the RAM and number of free pages on your instance to the total buffer pool size. Based on these metrics, you can determine if you need to increase or decrease your overall buffer pool size setting.\n\nNext, take a look at your metrics for the InnoDB Log File usage. The rule of thumb is that your log files should hold approximately one hour of data. If you see that your data written to the log files hourly exceeds the total size of the log files, you would want to increase the innodb_log_file_size variable and restart MySQL. You could also verify with “SHOW ENGINE INNODB STATUS;” via the MySQL CLI to assist in calculating a good InnoDB log file size.\n\nOther InnoDB settings that can be further tuned for better performance are:\n• Setting this to “2” (interleaved mode) can remove the need for an auto-inc lock (at the table level) and can increase performance when using multi-row insert statements to insert values into a table with an auto increment primary key. Note that this requires either ROW or MIXED binlog format.\n• These settings will impact your database if you are utilizing a write-heavy workflow. This does not apply to read (SELECT) traffic. To tune these values, it is best to know how many iops your system can perform. It is a good idea to run sysbench or another benchmark tool to determine your storage throughput.\n• PMM can offer additional insight, showing your IO usage and allowing you to tune accordingly.\n\nWhile this article may not cover everything on performance tuning, the suggestions above should clear some of the low hanging fruit and get your system closer to an ideal setup. As with all database tuning, your process should be an ongoing one based on current information.\n• Examine the settings proposed above, and implement if they make sense for your environment/workload.\n• None Install a good MySQL monitoring tool to give insight into the database (\n• Stay current on your monitoring graphs to determine other areas where you may need to tune.\n\nWhat is MySQL performance tuning, and why is it important?\n\nMySQL tuning encompasses the practice of enhancing the efficiency, responsiveness, and overall performance of a MySQL database. This optimization process entails fine-tuning database settings, configurations, and query performance to ensure that MySQL functions at its best.\n\nHow do I know if my MySQL database needs performance tuning?\n\nSlow query response times, increased resource utilization, frequent database downtime, or a decline in overall system performance are signs that your MySQL database needs performance tuning.\n\nWhat are the key benefits of optimizing MySQL database performance?\n\nOptimizing the performance of a MySQL database provides numerous benefits, including faster query execution, diminished resource utilization, increased scalability to accommodate expanding workloads, heightened user satisfaction, and cost savings by optimizing hardware resource usage. Additionally, it helps maintain the reliability and availability of your database.\n\nWhat are the common performance issues in MySQL databases?\n\nMySQL databases frequently encounter common performance challenges, including slow queries, ineffective indexing, resource conflicts, suboptimal configuration settings, and inadequate hardware resources. These issues can result in diminished database performance and can be improved through performance tuning.\n\nCan you explain the importance of query optimization in MySQL?\n\nQuery optimization is crucial in MySQL because it significantly impacts database performance. Well-optimized queries execute faster, consume fewer resources, and reduce the load on the database server, all of which improve system performance and enhance the user experience.\n\nHow can Percona help with MySQL performance tuning?\n\nPercona offers expertise and solutions for MySQL performance tuning, and our team of database experts can assess your database environment, identify performance bottlenecks, and recommend optimizations. Whether you need consulting, support, or software solutions, Percona can assist you in achieving the best performance from your MySQL database."
    },
    {
        "link": "https://smit90.medium.com/mysql-best-practices-optimizing-performance-and-reliability-with-advanced-concepts-c4f5ebedbcbe",
        "document": "MySQL is one of the most popular relational database management systems in the world, and for good reason. It’s open-source, scalable, and offers excellent performance when configured and managed correctly. Whether you’re a seasoned database administrator or just starting with MySQL, following best practices can help you harness its full potential while ensuring reliability. In this blog post, we’ll explore some MySQL best practices, complete with examples, to help you optimize performance and reliability.\n\nIndexing is a crucial part of database optimization. It helps MySQL locate data quickly, reducing query execution times. Always analyze your query patterns and create indexes on columns commonly used in WHERE clauses.\n\nSelect the appropriate data types for your columns. Smaller data types require less storage and result in faster queries. Avoid using VARCHAR when CHAR will suffice and use INT for integers instead of VARCHAR.\n\nWrite efficient SQL queries. Avoid using SELECT * and fetch only the data you need. Use JOINs carefully and consider denormalization when it can improve query performance.\n\nSchedule regular backups of your MySQL database to prevent data loss in case of failures. Use tools like mysqldump or implement automated backup solutions.\n\nMySQL replication involves creating copies of your database for redundancy. It ensures high availability and load distribution. Set up master-slave or master-master replication depending on your needs.\n\nRegularly monitor your MySQL server’s performance and resource utilization. Tools like MySQL Performance Schema and third-party monitoring solutions can help you identify and address issues proactively.\n\nGrant only necessary permissions to database users. Avoid using the root user for everyday tasks. Create separate users with the minimum required privileges.\n\nUtilize firewalls and network security groups to restrict access to your MySQL server. Allow only trusted IP addresses to connect to the database server.\n\nPartitioning allows you to divide large tables into smaller, more manageable pieces. This can significantly improve query performance, especially for tables with millions of rows.\n\nInnoDB is the default storage engine for MySQL, and it’s designed for high-performance and reliability. Utilize InnoDB’s features like row-level locking, foreign key support, and transactional capabilities.\n\nMySQL’s query cache stores the result of SELECT queries, reducing the overhead of query execution. While it can improve read-heavy workloads, it’s crucial to use it judiciously as it can negatively impact performance for frequently updated tables.\n\nMySQL Cluster provides high availability with automated failover and data replication across multiple nodes. It’s an excellent choice for mission-critical applications.\n\nImplementing point-in-time recovery allows you to restore your MySQL database to a specific point in time, reducing data loss in case of disasters.\n\nExample (Using binary logs for point-in-time recovery):\n\n6. Encryption at Rest and in Transit 🛡️\n\nEncrypt your data at rest using mechanisms like Transparent Data Encryption (TDE) and encrypt data in transit using SSL/TLS to protect sensitive information.\n\nMySQL 8.0 introduced support for roles, making it easier to manage user permissions and improve security by implementing the principle of least privilege.\n\nOptimizing MySQL performance and ensuring reliability are essential for any application relying on this powerful database system. By following these best practices, you can unlock MySQL’s full potential, keep your data safe, and enjoy a high-performing database environment. Remember, the key to success is a combination of well-thought-out configuration, regular monitoring, and continuous improvement. So, go ahead, implement these best practices, and watch your MySQL-powered application soar to new heights! 🚀🔒📊By implementing partitioning, leveraging InnoDB, using query caching wisely, and exploring advanced concepts like MySQL Cluster and point-in-time recovery, you can build a robust and high-performing database environment. 🌟🔒🌐"
    },
    {
        "link": "https://severalnines.com/blog/mysql-storage-engine-optimization-configuring-innodb-optimization-high-performance",
        "document": "InnoDB is one of the most widely used storage engines in MySQL. This storage engine is known as a high-reliability and a high-performance storage engine and its key advantages include supporting row-level locking, foreign keys and following the ACID model. InnoDB replaces MyISAM as the default storage engine since MySQL 5.5, which was released in 2010.\n\nThis storage engine can be incredibly performant and powerful if optimized properly – today we’re taking a look at the things we can do to make it perform at the very best of its ability, but before we dive into InnoDB though, we should understand what the aforementioned ACID model is.\n\nWhat is ACID and Why is it Important?\n\nACID is a set of properties of database transactions.The acronym translates to four words: Atomicity, Consistency, Isolation and Durability. In short, these properties ensure that database transactions are processed reliably and warrant data validity despite errors, power outages or any such issues. A database management system that adheres to these principles is said to be an ACID-compliant DBMS. Here’s how everything works in InnoDB:\n• None Atomicity ensures that the statements in a transaction operate as an indivisible unit and that their effects are seen collectively or not at all;\n• None Consistency is handled by MySQL’s logging mechanisms which record all changes to the database;\n• None Durability is also maintained because InnoDB maintains a log file that tracks all changes to the system.\n\nNow that we have covered ACID, we should probably look at how InnoDB looks under the hood. Here’s how InnoDB looks like from the inside (image courtesy of Percona):\n\nFrom the image above we can clearly see that InnoDB has a few parameters crucial to its performance and these are as follows:\n• parameter describes the system tablespace (the system tablespace is the storage area for the InnoDB data dictionary, the double write and change buffers and undo logs). The parameter depicts the file where data derived from InnoDB tables will be stored;\n• parameter is a memory buffer that InnoDB uses to cache data and indexes of its tables;\n• parameter is used to write to the log files on disk;\n• parameter controls the balance between strict ACID compliance and higher performance;\n• parameter is the length of time in seconds an InnoDB transaction waits for a row lock before giving up;\n• parameter defines the method used to flush data to InnoDB data files and log files which can affect I/O throughput.\n\nInnoDB also stores the data from its tables in a file called ibdata1 – the logs however are stored in two separate files named ib_logfile0 and ib_logfile1: all of those three files reside in the /var/lib/mysql directory.\n\nIn order to make InnoDB as performant as possible, we must fine tune these parameters and optimize them as much as we can by looking at our available hardware resources.\n\nIn order to adjust InnoDB’s performance on your hardware, follow these steps:\n• In order to extend innodb_data_file_path automatically, specify the autoextend attribute in the setting and restart the server. For example:\n\nWhen the autoextend parameter is used, the data file automatically increases in size by 8MB increments each time space is required. A new auto-extending data file can also be specified like so (in this case, the new data file is called ibdata2):\n• When using InnoDB, the main mechanism used is the buffer pool. InnoDB heavily relies on the buffer pool and as a rule of thumb, the innodb_buffer_pool_size parameter should be about 60% to 80% of the total available RAM on the server. Keep in mind that you should leave some RAM for the processes running in the OS as well;\n• InnoDB’s innodb_log_file_size should be set as big as possible, but not bigger than necessary. In this case, keep in mind that a bigger log file size is better for performance, but the bigger it is, the more recovery time after a crash is required. As such, there is no “one size fits all” solution, but it’s said that the combined size of the log files should be large enough. This helps the MySQL server from regularly working on checkpointing and disk flushing activity. This saves too much CPU and disk IO and can run smoothly during its peak time or high workload activity. Although the recommended approach is to test and experiment it yourself and find the optimal value yourself;\n• The innodb_log_buffer_size value should be set to at least 16M. A large log buffer allows large transactions to run without a need to write the log to disk before the transactions commit saving some disk I/O;\n• When tuning innodb_flush_log_at_trx_commit, keep in mind that this parameter accepts three values – 0, 1 and 2. With a value of 1 you get ACID compliance and with values 0 or 2 you get more performance, but less reliability because in that case transactions for which logs have not yet been flushed to disk can be lost in a crash;\n• In order to set innodb_lock_wait_timeout to a proper value, keep in mind that this parameter defines the time in seconds (the default value is 50) before issuing the following error and rolling back the current statement:\n• In InnoDB, there are multiple flush methods available. By default this setting is set to “async_unbuffered” on Windows machines if the value is set to NULL and to “fsync” in Linux machines. Here’s what the methods are and what they do:\n• None You should also consider enabling innodb_file_per_table setting. This parameter is ON by default in MySQL 5.6 and higher. This parameter relieves you of management issues relating to InnoDB tables by storing them in separate files and avoiding bloated main dictionaries and system tables. Enabling this variable also avoids from facing data recovery complexity when a certain table is corrupted\n• None Now that you modified these settings per the instructions outlined above, you should be almost ready to go! Before you hit the ground running though, you should probably keep an eye on the busiest file in the entire InnoDB infrastructure – the ibdata1.\n\nThere are several classes of information that are stored in ibdata1:\n• None The doublewrite buffer – such a buffer enables InnoDB to recover from half-written pages. The purpose of such a buffer is to prevent data corruption;\n• None The insert buffer – such a buffer is used by InnoDB to buffer updates to the same page so they can be performed at once and not one after another.\n\nWhen dealing with big data sets, the ibdata1 file can get extremely large and this can be the core of a very frustrating problem – the file can only grow and by default, it cannot shrink. You can shut down MySQL and delete this file but this is not recommended unless you know what you are doing. When deleted, MySQL will not function properly as the dictionary and system tables are gone, thus the main system table is corrupted.\n\nIn order to shrink ibdata1 once and for all, follow these steps:\n• None Dump all data from InnoDB databases. You can use mysqldump or mysqlpump for this action;\n• None Drop all databases except for the mysql, and databases;\n• None Add the following to your my.cnf file: [mysqld] innodb_file_per_table = 1 innodb_flush_method = O_DIRECT innodb_log_file_size = 25% of innodb_buffer_pool_size innodb_buffer_pool_size = up to 60-80% of available RAM.\n• and * files (these will be recreated upon the next restart of MySQL);\n• None Start MySQL and restore the data from the dump you took before. After performing the steps outlined above, the file will still grow, but it will no longer contain the data from InnoDB tables – the file will only contain metadata and each InnoDB table will exist outside of . Now, if you go to the directory, you will see two files representing each table you have with the InnoDB engine. The files will look like so:\n\nThe .frm file contains the storage engine header and the .ibd file contains the table data and indexes of your table.\n\nBefore rolling out the changes though, make sure to fine-tune the parameters according to your infrastructure. These parameters can make or break InnoDB performance so make sure to keep an eye on them at all times. Now you should be good to go!\n\nTo summarize, optimizing the performance of InnoDB can be a great benefit if you develop applications that require data integrity and high performance at the same time – InnoDB allows you to change how much memory the engine is allowed to consume, to change the log file size, the flush method the engine uses and so on – these changes can make InnoDB perform extremely well if they are tuned properly. Before performing any enhancements though, beware of the consequences of your actions to both your server and MySQL.\n\nAs always, before optimizing anything for performance always take (and test!) backups so you can restore your data if necessary and always test any changes on a local server before rolling out the changes to production."
    }
]