[
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/json/json-data-sql-server?view=sql-server-ver16",
        "document": "Applies to: SQL Server 2016 (13.x) and later versions Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics SQL database in Microsoft Fabric\n\nJSON is a popular textual data format that's used for exchanging data in modern web and mobile applications. JSON is also used for storing unstructured data in log files or NoSQL databases such as Microsoft Azure Cosmos DB. Many REST web services return results that are formatted as JSON text or accept data that's formatted as JSON. For example, most Azure services, such as Azure Search, Azure Storage, and Azure Cosmos DB, have REST endpoints that return or consume JSON. JSON is also the main format for exchanging data between webpages and web servers by using AJAX calls.\n\nJSON functions, first introduced in SQL Server 2016 (13.x), enable you to combine NoSQL and relational concepts in the same database. You can combine classic relational columns with columns that contain documents formatted as JSON text in the same table, parse and import JSON documents in relational structures, or format relational data to JSON text.\n\nHere's an example of JSON text:\n\nBy using SQL Server built-in functions and operators, you can do the following things with JSON text:\n• Run any Transact-SQL query on the converted JSON objects.\n• Format the results of Transact-SQL queries in JSON format.\n\nThe next sections discuss the key capabilities that SQL Server provides with its built-in JSON support.\n\nThe new json data type that stores JSON documents in a native binary format that provides the following benefits over storing JSON data in varchar/nvarchar:\n• More efficient reads, as the document is already parsed\n• More efficient writes, as the query can update individual values without accessing the entire document\n• No change in compatibility with existing code\n\nUsing the JSON same functions described in this article remain the most efficient way to query the json data type. For more information on the native json data type, see JSON data type.\n\nExtract values from JSON text and use them in queries\n\nIf you have JSON text that's stored in database tables, you can read or modify values in the JSON text by using the following built-in functions:\n• JSON_QUERY (Transact-SQL) extracts an object or an array from a JSON string.\n• JSON_MODIFY (Transact-SQL) changes a value in a JSON string.\n\nIn the following example, the query uses both relational and JSON data (stored in a column named ) from a table called :\n\nApplications and tools see no difference between the values taken from scalar table columns and the values taken from JSON columns. You can use values from JSON text in any part of a Transact-SQL query (including WHERE, ORDER BY, or GROUP BY clauses, window aggregates, and so on). JSON functions use JavaScript-like syntax for referencing values inside JSON text.\n\nFor more information, see Validate, Query, and Change JSON Data with Built-in Functions (SQL Server), JSON_VALUE (Transact-SQL), and JSON_QUERY (Transact-SQL).\n\nIf you must modify parts of JSON text, you can use the JSON_MODIFY (Transact-SQL) function to update the value of a property in a JSON string and return the updated JSON string. The following example updates the value of a property in a variable that contains JSON:\n\nYou don't need a custom query language to query JSON in SQL Server. To query JSON data, you can use standard T-SQL. If you must create a query or report on JSON data, you can easily convert JSON data to rows and columns by calling the rowset function. For more information, see Parse and Transform JSON Data with OPENJSON.\n\nThe following example calls and transforms the array of objects that is stored in the variable to a rowset that can be queried with a standard Transact-SQL statement:\n\ntransforms the array of JSON objects into a table in which each object is represented as one row, and key/value pairs are returned as cells. The output observes the following rules:\n• converts JSON values to the types that are specified in the clause.\n• can handle both flat key/value pairs and nested, hierarchically organized objects.\n• You don't have to return all the fields that are contained in the JSON text.\n• You can optionally specify a path after the type specification to reference a nested property or to reference a property by a different name.\n• The optional prefix in the path specifies that values for the specified properties must exist in the JSON text.\n\nFor more information, see Parse and Transform JSON Data with OPENJSON and OPENJSON (Transact-SQL).\n\nJSON documents might have sub-elements and hierarchical data that can't be directly mapped into the standard relational columns. In this case, you can flatten JSON hierarchy by joining parent entity with sub-arrays.\n\nIn the following example, the second object in the array has sub-array representing person skills. Every sub-object can be parsed using additional function call:\n\nThe array is returned in the first as original JSON text fragment and passed to another function using operator. The second function parses JSON array and return string values as single column rowset that will be joined with the result of the first .\n\njoins first-level entity with sub-array and return flatten resultset. Due to JOIN, the second row is repeated for every skill.\n\nFormat SQL Server data or the results of SQL queries as JSON by adding the clause to a statement. Use to delegate the formatting of JSON output from your client applications to SQL Server. For more information, see Format query results as JSON with FOR JSON.\n\nThe following example uses PATH mode with the clause:\n\nThe clause formats SQL results as JSON text that can be provided to any app that understands JSON. The PATH option uses dot-separated aliases in the SELECT clause to nest objects in the query results.\n\nFor more information, see Format query results as JSON with FOR JSON and FOR Clause (Transact-SQL).\n\nJSON aggregate functions enable construction of JSON objects or arrays based on an aggregate from SQL data.\n• JSON_OBJECTAGG constructs a JSON object from an aggregation of SQL data or columns.\n• JSON_ARRAYAGG constructs a JSON array from an aggregation of SQL data or columns.\n\nUse cases for JSON data in SQL Server\n\nJSON support in SQL Server and Azure SQL Database lets you combine relational and NoSQL concepts. You can easily transform relational to semi-structured data and vice-versa. JSON isn't a replacement for existing relational models, however. Here are some specific use cases that benefit from the JSON support in SQL Server and in SQL Database.\n\nConsider denormalizing your data model with JSON fields in place of multiple child tables.\n\nStore info about products with a wide range of variable attributes in a denormalized model for flexibility.\n\nLoad, query, and analyze log data stored as JSON files with all the power of the Transact-SQL language.\n\nWhen you need real-time analysis of IoT data, load the incoming data directly into the database instead of staging it in a storage location.\n\nTransform relational data from your database easily into the JSON format used by the REST APIs that support your web site.\n\nSQL Server provides a hybrid model for storing and processing both relational and JSON data by using standard Transact-SQL language. You can organize collections of your JSON documents in tables, establish relationships between them, combine strongly typed scalar columns stored in tables with flexible key/value pairs stored in JSON columns, and query both scalar and JSON values in one or more tables by using full Transact-SQL.\n\nJSON text is stored in or columns and is indexed as plain text. Any SQL Server feature or component that supports text supports JSON, so there are almost no constraints on interaction between JSON and other SQL Server features. You can store JSON in In-memory or Temporal tables, apply Row-Level Security predicates on JSON text, and so on.\n\nHere are some use cases that show how you can use the built-in JSON support in SQL Server.\n\nJSON is a textual format so the JSON documents can be stored in columns in a SQL Database. Since type is supported in all SQL Server subsystems you can put JSON documents in tables with clustered columnstore indexes, memory optimized tables, or external files that can be read using OPENROWSET or PolyBase.\n\nTo learn more about your options for storing, indexing, and optimizing JSON data in SQL Server, see the following articles:\n\nYou can format information that's stored in files as standard JSON or line-delimited JSON. SQL Server can import the contents of JSON files, parse it by using the or functions, and load it into tables.\n• None If your JSON documents are stored in local files, on shared network drives, or in Azure Files locations that can be accessed by SQL Server, you can use bulk import to load your JSON data into SQL Server.\n• None If your line-delimited JSON files are stored in Azure Blob storage or the Hadoop file system, you can use PolyBase to load JSON text, parse it in Transact-SQL code, and load it into tables.\n\nIf you must load JSON data from an external service into SQL Server, you can use to import the data into SQL Server instead of parsing the data in the application layer.\n\nIn supported platforms, use the native json data type instead of nvarchar(max) for improved performance and more efficient storage.\n\nYou can provide the content of the JSON variable by an external REST service, send it as a parameter from a client-side JavaScript framework, or load it from external files. You can easily insert, update, or merge results from JSON text into a SQL Server table.\n\nIf you must filter or aggregate JSON data for reporting purposes, you can use to transform JSON to relational format. You can then use standard Transact-SQL and built-in functions to prepare the reports.\n\nYou can use both standard table columns and values from JSON text in the same query. You can add indexes on the expression to improve the performance of the query. For more information, see Index JSON data.\n\nIf you have a web service that takes data from the database layer and returns it in JSON format, or if you have JavaScript frameworks or libraries that accept data formatted as JSON, you can format JSON output directly in a SQL query. Instead of writing code or including a library to convert tabular query results and then serialize objects to JSON format, you can use to delegate the JSON formatting to SQL Server.\n\nFor example, you might want to generate JSON output that's compliant with the OData specification. The web service expects a request and response in the following format:\n\nThis OData URL represents a request for the ProductID and ProductName columns for the product with 1. You can use to format the output as expected in SQL Server.\n\nThe output of this query is JSON text that's fully compliant with the OData spec. Formatting and escaping are handled by SQL Server. SQL Server can also format query results in any format, such as OData JSON or GeoJSON.\n\nTo get the AdventureWorks sample database, download at least the database file and the samples and scripts file from GitHub.\n\nAfter you restore the sample database to an instance of SQL Server, extract the samples file, and then open the file from the JSON folder. Run the scripts in this file to reformat some existing data as JSON data, test sample queries and reports over the JSON data, index the JSON data, and import and export JSON.\n\nHere's what you can do with the scripts that are included in the file:\n• None Denormalize the existing schema to create columns of JSON data.\n• None Store information from , , , , and other tables that contain information related to sales order into JSON columns in the table.\n• None Store information from and tables in the table as arrays of JSON objects.\n• None Import and export JSON. Create and run procedures that export the content of the and the tables as JSON results, and import and update the and the tables by using JSON input.\n• None Run query examples. Run some queries that call the stored procedures and views that you created in steps 2 and 4.\n• None Clean up scripts. Don't run this part if you want to keep the stored procedures and views that you created in steps 2 and 4."
    },
    {
        "link": "https://stackoverflow.com/questions/57135701/sql-like-query-on-json-data",
        "document": "I have JSON data (no schema) stored in a SQL Server column and need to run search queries on it.\n\nSQL Server 2017 has JSON_XXXX methods but they work on pre-known schema. In my case, the schema of objects is not defined precisely and could change.\n\nCurrently to search the columns e.g. find Make=Mercedes-Benz. I'm using a search phrase \"%\\\"Make\\\":\\\"Mercedes-Benz\\\"%\". This works quite well IF exact make name is used. I'd like user to be able to search using partial names as well e.g. just typing 'Benz' or 'merc'.\n\nIs it possible to structure a SQL query using wild cards that'll work for me? Any other options?"
    },
    {
        "link": "https://stackoverflow.com/questions/17688349/sql-like-operator-to-find-words-in-stored-json",
        "document": "I have this JSON stored in a MySQL DB, column name:\n\nI want to make a search using operator to find all categories with \"Category\" word:\n\nAt the moment I'm doing it this way, but it only return a complete phrase:\n\nHow can I build a query that returns all categories containing the word \"Category\"?"
    },
    {
        "link": "https://geeksforgeeks.org/working-with-json-in-sql",
        "document": "JSON stands for Javascript Object Notation. It is mainly used in storing and transporting data. Mostly all NoSQL databases like MongoDB, CouchDB, etc., use JSON format data. Whenever your data from one server has to be transferred to a web page, JSON format is the preferred format for front-end applications like Android, iOS, React, Angular, etc.\n\nIn this article, we will learn how to store, retrieve, and manipulate JSON data in SQL Server using various SQL functions. We will learn how JSON fits into SQL, demonstrate how to store JSON data in SQL tables and cover the most common JSON functions like ISJSON(), JSON_VALUE(), JSON_MODIFY(), and more.\n\nWhat is JSON in SQL Server?\n\nJSON is a lightweight data-interchange format that is easy for humans to read and write. SQL Server introduced native support for JSON handling starting from SQL Server 2016. This allows you to store JSON data in NVARCHAR columns and use SQL functions to parse, query, and modify JSON data.\n\nIn SQL Server, you can store JSON data as a string in an NVARCHAR column. SQL Server treats JSON data as a string, allowing you to parse it when necessary.\n\nNow let us create a table named “Authors” and let us insert some data into it as shown below:\n\nJSON is a beautiful option for bridging NoSQL and relational worlds. Hence, in case if you have the data got exported from MongoDB and need to import them in SQL Server, we can follow below approaches\n\nJSON documents can be stored as-is in NVARCHAR columns either in LOB storage format or Relational storage format. Raw JSON documents have to be parsed, and they may contain Non-English text. By using nvarchar(max) data type, we can store JSON documents with a max capacity of 2 GB in size. If the JSON data is not huge, we can go for NVARCHAR(4000), or else we can go for NVARCHAR(max) for performance reasons.\n\nThe main reason for keeping the JSON document in NVARCHAR format is for Cross feature compatibility. NVARCHAR works with X feature i.e. all the SQL server components such as Hekaton(OLTP), temporal, or column store tables, etc. As JSON behavior is also in that way, it is represented as NVARCHAR datatype.\n\nBefore SQL Server 2016, JSON was stored in the database as text. Hence, there was a need to change the database schema and migration occurred as JSON type in NVarchar format\n\nJSON is just treated as an Object in JavaScript and hence called as Javascript Object Notation. There is no specific standardized JSON object type on client-side available similar to XmlDom object.\n\nLet us see the important functionalities available in SQL Server which can be used with JSON data.\n\nThis function is used to check whether the given input json string is in JSON format or not. If it is in JSON format, it returns 1 as output or else 0. i.e. it returns either 1 or 0 in INT format.\n\nThe output will be a scalar value from the given JSON string. Parsing of JSON string is done and there are some specific formats are there for providing the path. For example\n\nUsed to extract an array of data or objects from the JSON string.\n\nThere is an option called “JSON_MODIFY” in (Transact-SQL) function is available to update the value of a property in a JSON string and return the updated JSON string. Whenever there is a requirement to change JSON text, we can do that\n\nThis function is used for Exporting SQL Server data as JSON format. This is a useful function to export SQL data into JSON format. There are two options available with FOR JSON\n• AUTO: As it is nested JSON sub-array is created based on the table hierarchy.\n• PATH: By using this we can define the structure of JSON in a customized way.\n\nThis function is used for importing JSON as String data. We can import JSON as a text file by using OPENROWSET function and in that the BULK option should be enabled. It returns a single string field with BulkColumn as its column name.\n\nNote: Even large data also can be placed. As a sample, we showed only a single row.\n\nSINGLE_BLOB, which reads a file as varbinary(max). SINGLE_NCLOB, which reads a file as nvarchar(max) — If the contents are in Non-English text like Japanese or Chinese etc., data, we need to go in this pattern. We used SINGLE_CLOB, which reads a file as varchar(max).\n\nIt will generate a relational table with its contents from the JSON string. Each row is created which can be got by iterating through JSON object elements, OPENJSON can be used to parse the JSON as a text. Let us have a JSON placed in an external file and its contents are\n\nWe can see that for “Strings” key like “authorname” and “skills” got type as 1 and “int” key like “id” and “age” got type as 2. Similarly, for boolean, the type is 3. For arrays, it is 4 and for object, it is 5. OPENJSON parses only the root level of the JSON.\n\nIn case if the JSON is nested, we need to use Path variables\n\nWe can even make the skillsets as columns of data as\n\nSaving the rowset into Table: Here the number of columns should match the count that is present inside with:\n\nThere is an option called “JSON_MODIFY” in (Transact-SQL) function is available to update the value of a property in a JSON string and return the updated JSON string. Whenever there is a requirement to change JSON text, we can do that\n\nHandling JSON in SQL Server enables seamless interaction with modern web applications and NoSQL databases. The ability to store, query, and manipulate JSON data directly in SQL Server enhances the flexibility and efficiency of your data management system. SQL Server’s native JSON functions—such as ISJSON(), JSON_VALUE(), JSON_QUERY(), and JSON_MODIFY()—make it easier to integrate and work with JSON data without needing a separate NoSQL system."
    },
    {
        "link": "https://docs.oracle.com/database/122/ADJSN/generation.htm",
        "document": "You can use SQL/JSON functions , , , and to construct JSON data from non-JSON data in the database. The JSON data is returned as a SQL value. These generation functions make it easy to construct JSON data directly from a SQL query. They allow non-JSON data to be represented as JSON objects and JSON arrays. You can generate complex, hierarchical JSON documents by nesting calls to these functions. Nested subqueries can generate JSON collections that represent one-to-many relationships.Foot 1 The Best Way to Construct JSON Data from Non-JSON Data Alternatives to using the SQL/JSON generation functions are generally error prone or inefficient.\n• Using string concatenation to generate JSON documents is error prone. In particular, there are a number of complex rules that must be respected concerning when and how to escape special characters, such as double quotation marks ( ). It is easy to overlook or misunderstand these rules, which can result in generating incorrect JSON data.\n• Reading non-JSON result sets from the database and using client-side application code to generate JSON data is typically quite inefficient, particularly due to network overhead. When representing one-to-many relationships as JSON data, multiple operations are often required, to collect all of the non-JSON data needed. If the documents to be generated represent multiple levels of one-to-many relationships then this technique can be quite costly. The SQL/JSON generation functions do not suffer from such problems; they are designed for the job of constructing JSON data from non-JSON database data.\n• By using SQL subqueries with these functions, you can generate an entire set of JSON documents using a single SQL statement, which allows the generation operation to be optimized.\n• Because only the generated documents are returned to a client, network overhead is minimized: there is at most one round trip per document generated.\n• Functions and construct a JSON object or array, respectively, given as arguments SQL name–value pairs and values, respectively. The number of arguments corresponds to the number of object members and array elements, respectively (except when an argument expression evaluates to SQL and the clause applies). Each name must have the syntax of a SQL identifier. Each value can be any SQL value, including a value computed using a scalar SQL (sub)query that returns at most one item (a single row with a single column — an error is raised if such a query argument returns more than one row.)\n• Functions , and are aggregate SQL functions. They transform information that is contained in the rows of a grouped SQL query into JSON objects and arrays, respectively. Evaluation of the arguments determines the number of object members and array elements, respectively; that is, the size of the result reflects the current queried data. For , the order of object members is unspecified. For , the order of array elements reflects the query result order. You can use SQL in the query to control the array element order. Formats of Input Values for JSON_OBJECT and JSON_ARRAY For function you can use any SQL value of the supported data types as arguments. Similarly for the value arguments of name–value pairs that you pass to function . In some cases you know or expect that such a value is in fact JSON data (represented as a SQL string or number). You can add keywords after any input value expression to declare this expectation for the value that results from that expression. If Oracle can determine that the value is in fact JSON data then it is treated as if it were followed by an explicit declaration. This is the case, for instance, if the value expression is an invocation of a SQL/JSON generation function. specify , and if Oracle determine that the value is JSON data, then it is assumed to be ordinary (non-JSON) SQL data. In that case it is serialized as follows (any other SQL value raises an error):\n• A or value is wrapped in double quotation marks ( ).\n• A numeric value is converted to a JSON number. (It is not quoted.)\n• A or value is converted to ISO 8601 format, and the result is enclosed in double quotation marks ( ).\n• A PL/SQL value is converted to JSON or . (It is not quoted.)\n• A value is converted to JSON , regardless of the data type. If you dospecify, and if Oracledetermine that the value is JSON data, then it is assumed to be ordinary (non-JSON) SQL data. In that case it is serialized as follows (any other SQL value raises an error): Because Oracle SQL treats an empty string as there is no way to construct an empty JSON string ( ). The format of an input argument can affect the format of the data that is returned by the function. In particular, if an input is determined to be of format JSON then it is treated as JSON data when computing the return value. Example 19-1 illustrates this — it explicitly uses to interpret the SQL string as JSON Boolean value . You can optionally specify a SQL -handling clause, a clause, and keyword .\n• -handling clause — Determines how a SQL value resulting from input evaluation is handled.\n• — An input SQL value is converted to JSON for output. This is the default behavior for and .\n• — An input SQL value results in no corresponding output. This is the default behavior for and .\n• clause — The SQL data type used for the function return value. The default is .\n• keyword — If present, the returned JSON data is checked, to be sure it is well-formed. If is present and the returned data is not well-formed then an error is raised. The generated JSON data is returned from the function as a SQL value, whose size can be controlled by the optional clause. For the aggregate SQL functions ( and ), you can also specify as the SQL data type in the clause. JSON values within the returned data are derived from SQL values in the input as follows:\n• A non- and non-number SQL value is converted to a JSON string.\n• A SQL value is handled by the optional -handling clause. Example 19-1 Declaring an Input Value To Be JSON This example specifies for SQL string values and , in order that the JSON Boolean values and are used. SELECT json_object('name' VALUE first_name || ' ' || last_name, 'hasCommission' VALUE CASE WHEN commission_pct IS NULL THEN 'false' ELSE 'true' END ) FROM employees WHERE first_name LIKE 'W%'; JSON_OBJECT('NAME'ISFIRST_NAME||''||LAST_NAME,' ----------------------------------------------- {\"name\":\"William Gietz\",\"hasCommission\": } {\"name\":\"William Smith\",\"hasCommission\": } {\"name\":\"Winston Taylor\",\"hasCommission\": }\n\nSQL/JSON function constructs JSON objects from name–value pairs. Each pair is provided as an explicit argument. Each name of a pair must evaluate to a SQL identifier. Each value of a pair can be any SQL expression. The name and value are separated by keyword . The evaluated arguments you provide to are explicit object field names and field values. The resulting object has an member for each pair of name–value arguments you provide (except when an value expression evaluates to SQL and the clause applies). Example 19-2 Using JSON_OBJECT to Construct JSON Objects This example constructs a JSON object for each employee of table (from standard database schema ) whose salary is less than 15000. The object includes, as the value of its field , an object with fields and . Because the return value of is JSON data, is deduced for the input format of field — the explicit here is not needed. SELECT ('id' VALUE employee_id, 'name' VALUE first_name || ' ' || last_name, 'hireDate' VALUE hire_date, 'pay' VALUE salary, 'contactInfo' VALUE ('mail' VALUE email, 'phone' VALUE phone_number) FORMAT JSON) FROM employees WHERE salary > 15000; -- The query returns rows such as this (pretty-printed here for clarity): {\"id\":101, \"name\":\"Neena Kochhar\", \"hireDate\":\"21-SEP-05\", \"pay\":17000, \"contactInfo\":{\"mail\":\"NKOCHHAR\", \"phone\":\"515.123.4568\"}} Example 19-3 Using JSON_OBJECT With ABSENT ON NULL This example queries table from standard database schema to create JSON objects with fields and . The default -handling behavior for json_object is . In order to prevent the creation of a field with a JSON value, the example uses . The SQL value for column when column has value means that no field is created for that location. SELECT JSON_OBJECT('city' VALUE city, 'province' VALUE state_province ) FROM locations WHERE city LIKE 'S%'; JSON_OBJECT('CITY'ISCITY,'PROVINCE'ISSTATE_PROVINCEABSENTONNULL) ---------------------------------------------------------------- {\"city\":\"Southlake\", :\"Texas\"} {\"city\":\"South San Francisco\", :\"California\"} {\"city\":\"South Brunswick\", :\"New Jersey\"} {\"city\":\"Seattle\", :\"Washington\"} {\"city\":\"Sydney\", :\"New South Wales\"} {\"city\":\"Stretford\", :\"Manchester\"} {\"city\":\"Sao Paulo\", :\"Sao Paulo\"}\n\nSQL/JSON function constructs a JSON array from the results of evaluating its argument SQL expressions. Each argument can be any SQL expression. Array element order is the same as the argument order. The evaluated arguments you provide to are explicit array element values. The resulting array has an element for each argument you provide (except when an argument expression evaluates to SQL and the clause applies). An argument expression that evaluates to a SQL number is converted to a JSON number. A non- and non-number argument value is converted to a JSON string. Example 19-4 Using JSON_ARRAY to Construct a JSON Array This example constructs a JSON object for each job in database table (from standard database schema ). The fields of the objects are the job title and salary range. The salary range (field ) is an array of two numeric values, the minimum and maximum salaries for the job. These values are taken from SQL columns and . SELECT json_object('title' VALUE job_title, 'salaryRange' VALUE (min_salary, max_salary)) FROM jobs; JSON_OBJECT('TITLE'ISJOB_TITLE,'SALARYRANGE'ISJSON_ARRAY(MIN_SALARY,MAX_SALARY)) -------------------------------------------------------------------------------- {\"title\":\"President\",\"salaryRange\":[20080,40000]} {\"title\":\"Administration Vice President\",\"salaryRange\":[15000,30000]} {\"title\":\"Administration Assistant\",\"salaryRange\":[3000,6000]} {\"title\":\"Finance Manager\",\"salaryRange\":[8200,16000]} {\"title\":\"Accountant\",\"salaryRange\":[4200,9000]} {\"title\":\"Accounting Manager\",\"salaryRange\":[8200,16000]} {\"title\":\"Public Accountant\",\"salaryRange\":[4200,9000]} {\"title\":\"Sales Manager\",\"salaryRange\":[10000,20080]} {\"title\":\"Sales Representative\",\"salaryRange\":[6000,12008]} {\"title\":\"Purchasing Manager\",\"salaryRange\":[8000,15000]} {\"title\":\"Purchasing Clerk\",\"salaryRange\":[2500,5500]} {\"title\":\"Stock Manager\",\"salaryRange\":[5500,8500]} {\"title\":\"Stock Clerk\",\"salaryRange\":[2008,5000]} {\"title\":\"Shipping Clerk\",\"salaryRange\":[2500,5500]} {\"title\":\"Programmer\",\"salaryRange\":[4000,10000]} {\"title\":\"Marketing Manager\",\"salaryRange\":[9000,15000]} {\"title\":\"Marketing Representative\",\"salaryRange\":[4000,9000]} {\"title\":\"Human Resources Representative\",\"salaryRange\":[4000,9000]} {\"title\":\"Public Relations Representative\",\"salaryRange\":[4500,10500]}\n\nFootnote 1: The behavior of the SQL/JSON generation functions for JSON data is similar to that of the SQL/XML generation functions for XML data."
    },
    {
        "link": "https://stackoverflow.com/questions/12806386/is-there-any-standard-for-json-api-response-format",
        "document": "Do standards or best practices exist for structuring JSON responses from an API? Obviously, every application's data is different, so that much I'm not concerned with, but rather the \"response boilerplate\", if you will. An example of what I mean:\n\nAssuming you question is about REST webservices design and more precisely concerning success/error. I think there are 3 different types of design.\n• None Use only HTTP Status code to indicate if there was an error and try to limit yourself to the standard ones (usually it should suffice).\n• Pros: It is a standard independent of your api.\n• Cons: Less information on what really happened.\n• None Use HTTP Status + json body (even if it is an error). Define a uniform structure for errors (ex: code, message, reason, type, etc) and use it for errors, if it is a success then just return the expected json response.\n• Pros: Still standard as you use the existing HTTP status codes and you return a json describing the error (you provide more information on what happened).\n• Cons: The output json will vary depending if it is a error or success.\n• None Forget the http status (ex: always status 200), always use json and add at the root of the response a boolean responseValid and a error object (code,message,etc) that will be populated if it is an error otherwise the other fields (success) are populated.\n• None Pros: The client deals only with the body of the response that is a json string and ignores the status(?). It's up to you to choose :) Depending on the API I would choose 2 or 3 (I prefer 2 for json rest apis). Another thing I have experienced in designing REST Api is the importance of documentation for each resource (url): the parameters, the body, the response, the headers etc + examples. I would also recommend you to use jersey (jax-rs implementation) + genson (java/json databinding library). You only have to drop genson + jersey in your classpath and json is automatically supported.\n• None Solution 2 is the hardest to implement but the advantage is that you can nicely handle exceptions and not only business errors, initial effort is more important but you win on the long term.\n• None Solution 3 is the easy to implement on both, server side and client but it's not so nice as you will have to encapsulate the objects you want to return in a response object containing also the responseValid + error.\n\nI will not be as arrogant to claim that this is a standard so I will use the \"I prefer\" form. I prefer terse response (when requesting a list of /articles I want a JSON array of articles). In my designs I use HTTP for status report, a 200 returns just the payload. 400 returns a message of what was wrong with request: If there was error with processing on my side, I return 501 with a message: {\"message\" : \"Could not connect to data store.\"} From what I've seen quite a few REST-ish frameworks tend to be along these lines. JSON is supposed to be a payload format, it's not a session protocol. The whole idea of verbose session-ish payloads comes from the XML/SOAP world and various misguided choices that created those bloated designs. After we realized all of it was a massive headache, the whole point of REST/JSON was to KISS it, and adhere to HTTP. I don't think that there is anything remotely standard in either JSend and especially not with the more verbose among them. XHR will react to HTTP response, if you use jQuery for your AJAX (like most do) you can use / and / callbacks to capture errors. I can't see how encapsulating status reports in JSON is any more useful than that.\n\nFor what it's worth I do this differently. A successful call just has the JSON objects. I don't need a higher level JSON object that contains a success field indicating true and a payload field that has the JSON object. I just return the appropriate JSON object with a 200 or whatever is appropriate in the 200 range for the HTTP status in the header. However, if there is an error (something in the 400 family) I return a well-formed JSON error object. For example, if the client is POSTing a User with an email address and phone number and one of these is malformed (i.e. I cannot insert it into my underlying database) I will return something like this: Important bits here are that the \"field\" property must match the JSON field exactly that could not be validated. This allows clients to know exactly what went wrong with their request. Also, \"message\" is in the locale of the request. If both the \"emailAddress\" and \"phoneNumber\" were invalid then the \"errors\" array would contain entries for both. A 409 (Conflict) JSON response body might look like this: { \"description\" : \"Already Exists\" \"errors\" : [ { \"field\" : \"phoneNumber\", \"message\" : \"Phone number already exists for another user.\" } ], } With the HTTP status code and this JSON the client has all they need to respond to errors in a deterministic way and it does not create a new error standard that tries to complete replace HTTP status codes. Note, these only happen for the range of 400 errors. For anything in the 200 range I can just return whatever is appropriate. For me it is often a HAL-like JSON object but that doesn't really matter here. The one thing I thought about adding was a numeric error code either in the the \"errors\" array entries or the root of the JSON object itself. But so far we haven't needed it.\n\nThe point of JSON is that it is completely dynamic and flexible. Bend it to whatever whim you would like, because it's just a set of serialized JavaScript objects and arrays, rooted in a single node. What the type of the rootnode is is up to you, what it contains is up to you, whether you send metadata along with the response is up to you, whether you set the mime-type to or leave it as is up to you (as long as you know how to handle the edge cases). Build a lightweight schema that you like.\n\n Personally, I've found that analytics-tracking and mp3/ogg serving and image-gallery serving and text-messaging and network-packets for online gaming, and blog-posts and blog-comments all have very different requirements in terms of what is sent and what is received and how they should be consumed. So the last thing I'd want, when doing all of that, is to try to make each one conform to the same boilerplate standard, which is based on XML2.0 or somesuch. That said, there's a lot to be said for using schemas which make sense to you and are well thought out.\n\n Just read some API responses, note what you like, criticize what you don't, write those criticisms down and understand why they rub you the wrong way, and then think about how to apply what you learned to what you need.\n\nI used to follow this standard, was pretty good, easy, and clean on the client layer. Normally, the HTTP status 200, so that's a standard check which I use at the top. and I normally use the following JSON I also use a template for the API's dynamic response; try { // query and what not. response.payload = new { data = new { pagination = new Pagination(), customer = new Customer(), notifications = 5 } } // again something here if we get here success has to be true // I follow an exit first strategy, instead of building a pyramid // of doom. response.success = true; } catch(Exception exception){ response.success = false; response.message = exception.GetStackTrace(); _logger.Fatal(exception, this.GetFacadeName()) } return response; { \"success\": boolean, \"message\": \"some message\", \"payload\": { \"data\" : [] \"message\": \"\" ... // put whatever you want to here. } } on the client layer I would use the following: if(response.code != 200) { // woops something went wrong. return; } if(!response.success){ console.debug ( response.message ); return; } // if we are here then success has to be true. if(response.payload) { .... } notice how I break early avoiding the pyramid of doom.\n\nThere is no lawbreaking or outlaw standard other than common sense. If we abstract this like two people talking, the standard is the best way they can accurately understand each other in minimum words in minimum time. In our case, 'minimum words' is optimizing bandwidth for transport efficiency and 'accurately understand' is the structure for parser efficiency; which ultimately ends up with the less the data, and the common the structure; so that it can go through a pin hole and can be parsed through a common scope (at least initially). Almost in every cases suggested, I see separate responses for 'Success' and 'Error' scenario, which is kind of ambiguity to me. If responses are different in these two cases, then why do we really need to put a 'Success' flag there? Is it not obvious that the absence of 'Error' is a 'Success'? Is it possible to have a response where 'Success' is TRUE with an 'Error' set? Or the way, 'Success' is FALSE with no 'Error' set? Just one flag is not enough? I would prefer to have the 'Error' flag only, because I believe there will be less 'Error' than 'Success'. Also, should we really make the 'Error' a flag? What about if I want to respond with multiple validation errors? So, I find it more efficient to have an 'Error' node with each error as child to that node; where an empty (counts to zero) 'Error' node would denote a 'Success'."
    },
    {
        "link": "https://w3c.github.io/json-ld-bp",
        "document": "Coming up with a data format for your API is a common problem. It can be hard to choose between different data representations, what names you want to pick, and even harder if you want to leave room for extensibility. How do you make all these decisions? How do you make your API easy to use so people can use short strings to reference common things, but URLs to enable people to come up with their own so it isn't limiting? How can you make it easy for other people to add their own data in and make it interoperable? How do you consume data from other similar apps? There are technologies that can help you do this. Now, it isn't perfect – sometimes it won't solve your problem, but it could maybe solve a lot of them. The use of JSON on the web has grown immensely in the last decade, particularly with the explosion of APIs that eschew XML in favor of what is considered to be a more developer friendly format which is directly compatible with JavaScript. As a result, different sites have chosen their own proprietary representations for interacting with their sites, sometimes described using frameworks such as [[swagger]] which imply a particular URI composition for interacting with their services. This practice leads to vendor-specific semantic silos, where the meaning of a particular JSON document makes sense only by programming directly to the API documentation for a given service. As services grow they often introduce incompatible changes leading to a Version 2 or Version 3 of their API requiring developers to update client code to properly handle JSON documents. In many cases, even small changes can lead to incompatibilities. Additionally, composing information from multiple APIs becomes problematic, due to namespace or document format conventions that may differ between API endpoints. Moreover, the same principles are often repeated across different endpoints using arbitrary identifiers (name, email, website, etc.); the community needs to learn to stop repeating itself ( concept) and reuse common conventions, although this does not necessarily have to mean using exactly the same identifiers within the JSON itself (see JSON-LD Context). This Note proposes to outline a number of best practices for API designers or JSON developers based on the principles of separation of data model from syntax, the use of discoverable identifiers describing document contents, and general organizing principles that allow documents to be machine understandable (read, interpreted as JSON-LD using Linked Data, RDF and RDFS vocabulary, and data model principles). Key among these is the notion of vocabulary re-use, so that each endpoint does not need to separately describe the properties and structure of their JSON documents. Schema.org provides a great example of doing this, and includes an extension mechanism that may already be familiar to API designers. JSON-LD is JSON, and good JSON-LD is first and foremost good JSON. Since it is also Linked Data, developers and especially data publishers may find further useful advice at Data on the Web Best Practices [[dwbp]] and [[ld-bp]].\n\nPublish data using developer friendly JSON JSON [[json]] is the most popular format for publishing data through APIs; developers like it, it is easy to parse, and it is supported natively in most programming languages. For example, the following is reasonably idiomatic JSON which can also be interpreted as JSON-LD, given the appropriate context. { \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\" } Use a top-level object JSON documents may be in the form of a object, or an array of objects. For most purposes, developers need a single entry point, so the JSON SHOULD be in the form of a single top-level object. Use native values When possible, property values SHOULD use native JSON datatypes such as numbers (integer, decimal and floating point) and booleans (`true` and `false`). JSON has a single numeric type, so using native representation of numbers can lose precision. Assume arrays are unordered JSON specifies that the values in an array are ordered, however in many cases arrays are also used for values which are unordered. Unless specified within the JSON-LD Context, multiple array values SHOULD be presumed to be unordered. (See in [[JSON-LD]]). Use well-known identifiers when describing data By sticking to basic JSON data expression, and providing a JSON-LD Context, all keys used within a JSON document can have unambiguous meaning, as they bind to URLs which describe their meaning. By adding an `@context` entry, the previous example can now be interpreted as JSON-LD. { ****\"@context\": \"http://schema.org\"****, \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\" } When expanding such a data representation, a JSON-LD processor replaces these terms with the URIs they expand to (as well as making property values unambiguous): [ { \"http://schema.org/familyName\": [{\"@value\": \"Obama\"}], \"http://schema.org/givenName\": [{\"@value\": \"Barack\"}], \"http://schema.org/jobTitle\": [{\"@value\": \"44th President of the United States\"}], \"http://schema.org/name\": [{\"@value\": \"Barack Obama\"}] } ] Expanded form is not useful as is, but is necessary for performing further algorithmic transformations of JSON-LD data and is useful when validating that JSON-LD entity descriptions say what the publisher means. Provide one or more types for JSON objects Principles of Linked Data dictate that messages SHOULD be self describing, which includes adding a `type` to such messages. Many APIs use JSON messages where the type of information being conveyed is inferred from the retrieval endpoint. For example, when retrieving information about a Github Commit, you might see the following response: { \"sha\": \"7638417db6d59f3c431d3e1f261cc637155684cd\", \"url\": \"https://api.github.com/repos/octocat/Hello-World/git/commits/7638417db6d59f3c431d3e1f261cc637155684cd\", \"author\": { \"date\": \"2014-11-07T22:01:45Z\", \"name\": \"Scott Chacon\", \"email\": \"schacon@gmail.com\" }, \"committer\": { \"date\": \"2014-11-07T22:01:45Z\", \"name\": \"Scott Chacon\", \"email\": \"schacon@gmail.com\" }, \"message\": \"added readme, because im a good github citizen\n\n\", \"tree\": { \"url\": \"https://api.github.com/repos/octocat/Hello-World/git/trees/691272480426f78a0138979dd3ce63b77f706feb\", \"sha\": \"691272480426f78a0138979dd3ce63b77f706feb\" }, \"parents\": [ { \"url\": \"https://api.github.com/repos/octocat/Hello-World/git/commits/1acc419d4d6a9ce985db7be48c6349a0475975b5\", \"sha\": \"1acc419d4d6a9ce985db7be48c6349a0475975b5\" } ] } The only way to know this is a commit s to infer it based on the published API documentation, and the fact that it was returned from an endpoint defined for retrieving information about commits. { \"@context\": \"http://schema.org\", \"id\": \"http://www.wikidata.org/entity/Q76\", ****\"type\": \"Person\"****, \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\" } Identify objects with a unique identifier Entities described in JSON objects often describe web resources having a URL; entity descriptions SHOULD use an identifier uniquely identifying that entity. In this case, using the resource location as the identity of the object is consistent with this practice. Adding an `id` entry (an alias for `@id`) allows the same person to be referred to from different locations. { \"@context\": \"http://schema.org\", ****\"id\": \"http://www.wikidata.org/entity/Q76\"****, \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\" } There can be ambiguity if an identifier describes the entity description, or directly represents that entity itself. As an example, Barack Obama may have a Wikidata entry `http://www.wikidata.org/entity/Q76`, but it would be a mistake to say that `http://www.wikidata.org/entity/Q76` is Barack Obama. However, it is common to use this pattern, particularly if the type of the entity describes a Person, rather than a WebPage. Things not strings When describing attributes, entity references SHOULD be used instead of string literals. In some cases, when describing an attribute of an entity, it is tempting to using string values which have no independent meaning. Such values are often used for well known things. A JSON-LD context can define a term for such values, which allow them to appear as strings within the message, but be associated with specific identifiers. In this case, the property must be defined with type `@vocab` so that values will be interpreted relative to a vocabulary rather than the file location. { \"@context\": [\"http://schema.org\", ****{ \"gender\": {\"@id\": \"schema:gender\", \"@type\": \"@vocab\"} }****], \"id\": \"http://www.wikidata.org/entity/Q76\", \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\", ****\"gender\": \"Male\"**** } Nest referenced inline objects When multiple related entity descriptions are provided inline, related entities SHOULD be nested. For example, when relating one entity to another, where the related entity is described in the same message: { \"@context\": \"http://schema.org\", \"id\": \"http://www.wikidata.org/entity/Q76\", \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\", ****\"spouse\": { \"id\": \"http://www.wikidata.org/entity/Q13133\", \"type\": \"Person\", \"name\": \"Michelle Obama\", \"spouse\": \"http://www.wikidata.org/entity/Q76\" }**** } In this example, the `spouse` relationship is bi-directional, we have arbitrarily rooted the message with Barack Obama, and created a symmetric relationship from Michelle back to Barack by reference, rather than by nesting. When describing an inverse relationship, use a referenced property FIXME\n\nExternal references SHOULD use typed term When using a property intended to reference another entity, properties SHOULD be defined to type string values as being references. For example, the `schema:image` property a `Thing` to an `Image`: { \"@context\": \"http://schema.org\", \"id\": \"http://www.wikidata.org/entity/Q76\", \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\", ****\"image\": \"https://commons.wikimedia.org/wiki/File:President_Barack_Obama.jpg\"**** } This will be interpreted as a reference, rather than a string literal, because (at the time of publication), the schema.org JSON-LD Context defines `image` to be of type `@id`: If not defined as such in a remote context, terms may be (re-) defined in a local context: { \"@context\": [\"http://schema.org\", ****{ \"image\": { \"@id\": \"schema:image\", \"@type\": \"@id\"} }****], \"id\": \"http://www.wikidata.org/entity/Q76\", \"type\": \"Person\", \"name\": \"Barack Obama\", \"givenName\": \"Barack\", \"familyName\": \"Obama\", \"jobTitle\": \"44th President of the United States\", \"image\": \"https://commons.wikimedia.org/wiki/File:President_Barack_Obama.jpg\" } Ordering of array elements Unless specifically described ordered as an `@list`, do not depend on the order of elements in an array. By default, arrays in JSON-LD do not convey any ordering of contained elements . However, for the processing of contexts, the ordering of elements in arrays does matter. When writing array-based contexts, this fact should be kept in mind. Ordered contexts in arrays allow inheritance and overriding of context entries. When processing the following example, the first `name` entry will be overridden by the second `name` entry. { \"@context\": [ { \"id\": \"@id\", \"name\": \"http://schema.org/name\" }, { \"name\": \"http://xmlns.com/foaf/0.1/name\" } ], \"@id\": \"http://www.wikidata.org/entity/Q76\", ****\"name\": \"Barack Obama\"**** } Order is important when processing protected terms. While the first example will cause a term redefinition error, the second example will not throw this error. { \"@context\": [ { \"@version\": 1.1, \"name\": { \"@id\": \"http://schema.org/name\", \"@protected\": true } }, { \"name\": \"http://xmlns.com/foaf/0.1/name\" } ], \"@id\": \"http://www.wikidata.org/entity/Q76\", ****\"name\": \"Barack Obama\"**** } { \"@context\": [ { \"name\": \"http://xmlns.com/foaf/0.1/name\" }, { \"@version\": 1.1, \"Person\": \"http://schema.org/Person\", \"knows\": \"http://schema.org/knows\", \"name\": { \"@id\": \"http://schema.org/name\", \"@protected\": true } } ], \"@id\": \"http://www.wikidata.org/entity/Q76\", ****\"name\": \"Barack Obama\"**** }\n\nWhile most use of JSON-LD SHOULD NOT require a client to change the data representation, JSON-LD does allow the use of various algorithms to re-shape a JSON-LD document. These require the use of the JSON-LD Context, which is typically represented using a link to a remote document. Because it is remote, processing time can be severely impacted by the time it takes to retrieve this context. Cache JSON-LD Contexts Services providing a JSON-LD Context SHOULD set HTTP cache-control headers to allow liberal caching of such contexts, and clients SHOULD attempt to use a locally cached version of these documents. Typically, libraries used to process JSON-LD documents should do this for you. (See also [[json-ld-best-practice-caching]])."
    },
    {
        "link": "https://developer.mozilla.org/en-US/docs/Learn_web_development/Core/Scripting/JSON",
        "document": "JavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax. It is commonly used for transmitting data in web applications (e.g., sending some data from the server to the client, so it can be displayed on a web page, or vice versa). You'll come across it quite often, so in this article, we give you all you need to work with JSON using JavaScript, including parsing JSON so you can access data within it, and creating JSON. An understanding of HTML and the fundamentals of CSS, familiarity with JavaScript basics as covered in previous lessons.\n• What JSON is — a very commonly used data format based on JavaScript object syntax.\n• That JSON can also contain arrays.\n• Retrieve JSON as a JavaScript object using mechanisms available in Web APIs (for example, in the Fetch API).\n• Converting between objects and text using and .\n\nNo, really, what is JSON? JSON is a text-based data format following JavaScript object syntax. It represents structured data as a string, which is useful when you want to transmit data across a network. Even though it closely resembles JavaScript object literal syntax, it can be used independently from JavaScript. Many programming environments feature the ability to read (parse) and generate JSON. In JavaScript, the methods for parsing and generating JSON are provided by the object. Note: Converting a string to a native object is called deserialization, while converting a native object to a string so it can be transmitted across the network is called serialization. A JSON string can be stored in its own file, which is basically just a text file with an extension of , and a MIME type of .\n\nAs described above, JSON is a string whose format very much resembles JavaScript object literal format. The following is a valid JSON string representing an object. Note how it is also a valid JavaScript object literal — just with some more syntax restrictions. { \"squadName\": \"Super hero squad\", \"homeTown\": \"Metro City\", \"formed\": 2016, \"secretBase\": \"Super tower\", \"active\": true, \"members\": [ { \"name\": \"Molecule Man\", \"age\": 29, \"secretIdentity\": \"Dan Jukes\", \"powers\": [\"Radiation resistance\", \"Turning tiny\", \"Radiation blast\"] }, { \"name\": \"Madame Uppercut\", \"age\": 39, \"secretIdentity\": \"Jane Wilson\", \"powers\": [ \"Million tonne punch\", \"Damage resistance\", \"Superhuman reflexes\" ] }, { \"name\": \"Eternal Flame\", \"age\": 1000000, \"secretIdentity\": \"Unknown\", \"powers\": [ \"Immortality\", \"Heat Immunity\", \"Inferno\", \"Teleportation\", \"Interdimensional travel\" ] } ] } If you load this JSON in your JavaScript program as a string, you can parse it into a normal object and then access the data inside it using the same dot/bracket notation we looked at in the JavaScript object basics article. For example:\n• First, we have the variable name — .\n• Inside that, we want to access the property, so we use .\n• contains an array populated by objects. We want to access the second object inside the array, so we use .\n• Inside this object, we want to access the property, so we use .\n• Inside the property is an array containing the selected hero's superpowers. We want the third one, so we use . The key takeaway is that there's really nothing special about working with JSON; after you've parsed it into a JavaScript object, you work with it just like you would with an object declared using the same object literal syntax. Note: We've made the JSON seen above available inside a variable in our JSONTest.html example (see the source code). Try loading this up and then accessing data inside the variable via your browser's JavaScript console.\n\nAbove we mentioned that JSON text basically looks like a JavaScript object inside a string. We can also convert arrays to/from JSON. The below example is perfectly valid JSON: You have to access array items (in its parsed version) by starting with an array index, for example . The JSON can also contain a single primitive. For example, , , or are all valid JSON.\n\nTo begin with, make local copies of our heroes.html and style.css files. The latter contains some simple CSS to style our page, while the former contains some very simple body HTML, plus a element to contain the JavaScript code we will be writing in this exercise: We have made our JSON data available on our GitHub, at https://mdn.github.io/learning-area/javascript/oojs/json/superheroes.json. We are going to load the JSON into our script, and use some nifty DOM manipulation to display it, like this:\n\nThe top-level function looks like this: To obtain the JSON, we use an API called Fetch. This API allows us to make network requests to retrieve resources from a server via JavaScript (e.g. images, text, JSON, even HTML snippets), meaning that we can update small sections of content without having to reload the entire page. In our function, the first four lines use the Fetch API to fetch the JSON from the server:\n• we declare the variable to store the GitHub URL\n• we use the URL to initialize a new object.\n• we make the network request using the function, and this returns a object\n• we retrieve the response as JSON using the function of the object. Note: The API is asynchronous. You can learn about asynchronous functions in detail in our Asynchronous JavaScript module, but for now, we'll just say that we need to add the keyword before the name of the function that uses the fetch API, and add the keyword before the calls to any asynchronous functions. After all that, the variable will contain the JavaScript object based on the JSON. We are then passing that object to two function calls — the first one fills the with the correct data, while the second one creates an information card for each hero on the team, and inserts it into the .\n\nNow that we've retrieved the JSON data and converted it into a JavaScript object, let's make use of it by writing the two functions we referenced above. First of all, add the following function definition below the previous code: Here we first create an h1 element with , set its to equal the property of the object, then append it to the header using . We then do a very similar operation with a paragraph: create it, set its text content and append it to the header. The only difference is that its text is set to a template literal containing both the and properties of the object.\n\nNext, add the following function at the bottom of the code, which creates and displays the superhero cards: function populateHeroes(obj) { const section = document.querySelector(\"section\"); const heroes = obj.members; for (const hero of heroes) { const myArticle = document.createElement(\"article\"); const myH2 = document.createElement(\"h2\"); const myPara1 = document.createElement(\"p\"); const myPara2 = document.createElement(\"p\"); const myPara3 = document.createElement(\"p\"); const myList = document.createElement(\"ul\"); myH2.textContent = hero.name; myPara1.textContent = `Secret identity: ${hero.secretIdentity}`; myPara2.textContent = `Age: ${hero.age}`; myPara3.textContent = \"Superpowers:\"; const superPowers = hero.powers; for (const power of superPowers) { const listItem = document.createElement(\"li\"); listItem.textContent = power; myList.appendChild(listItem); } myArticle.appendChild(myH2); myArticle.appendChild(myPara1); myArticle.appendChild(myPara2); myArticle.appendChild(myPara3); myArticle.appendChild(myList); section.appendChild(myArticle); } } To start with, we store the property of the JavaScript object in a new variable. This array contains multiple objects that contain the information for each hero. Next, we use a for...of loop to loop through each object in the array. For each one, we:\n• Create several new elements: an , an , three s, and a .\n• Set the to contain the current hero's .\n• Fill the three paragraphs with their , , and a line saying \"Superpowers:\" to introduce the information in the list.\n• Store the property in another new constant called — this contains an array that lists the current hero's superpowers.\n• Use another loop to loop through the current hero's superpowers — for each one we create an element, put the superpower inside it, then put the inside the element ( ) using .\n• The very last thing we do is to append the , s, and inside the ( ), then append the inside the . The order in which things are appended is important, as this is the order they will be displayed inside the HTML. Note: If you are having trouble getting the example to work, try referring to our heroes-finished.html source code (see it running live also.) Note: If you are having trouble following the dot/bracket notation we are using to access the JavaScript object, it can help to have the superheroes.json file open in another tab or your text editor, and refer to it as you look at our JavaScript. You should also refer back to our JavaScript object basics article for more information on dot and bracket notation.\n\nThe above example was simple in terms of accessing the JavaScript object, because we converted the network response directly into a JavaScript object using . But sometimes we aren't so lucky — sometimes we receive a raw JSON string, and we need to convert it to an object ourselves. And when we want to send a JavaScript object across the network, we need to convert it to JSON (a string) before sending it. Luckily, these two problems are so common in web development that a built-in JSON object is available in browsers, which contains the following two methods:\n• : Accepts a JSON string as a parameter, and returns the corresponding JavaScript object.\n• : Accepts an object as a parameter, and returns the equivalent JSON string. You can see the first one in action in our heroes-finished-json-parse.html example (see the source code) — this does exactly the same thing as the example we built up earlier, except that:\n• we retrieve the response as text rather than JSON, by calling the method of the response\n• we then use to convert the text to a JavaScript object. The key snippet of code is here: As you might guess, works the opposite way. Try entering the following lines into your browser's JavaScript console one by one to see it in action: let myObj = { name: \"Chris\", age: 38 }; myObj; let myString = JSON.stringify(myObj); myString; Here we're creating a JavaScript object, then checking what it contains, then converting it to a JSON string using — saving the return value in a new variable — then checking it again."
    },
    {
        "link": "https://stackoverflow.blog/2022/06/02/a-beginners-guide-to-json-the-data-format-for-the-internet",
        "document": "As the web grows in popularity and power, so does the amount of data stored and transferred between systems, many of which know nothing about each other. From early on, the format that this data was transferred in mattered, and like the web, the best formats were open standards that anyone could use and contribute to. XML gained early popularity, as it looked like HTML, the foundation of the web. But it was clunky and confusing.\n\nThat’s where JSON (JavaScript Object Notation) comes in. If you’ve consumed an API in the last five to ten years, you’ve probably seen JSON data. While the format was first developed in the early 2000s, the first standards were published in 2006. Understanding what JSON is and how it works is a foundational skill for any web developer.\n\nIn this article, we’ll cover the basics of what JSON looks like and how to use it in your web applications, as well as talk about serialized JSON—JST and JWT—and the competing data formats.\n\nWhat JSON looks like\n\nJSON is a human-readable format for storing and transmitting data. As the name implies, it was originally developed for JavaScript, but can be used in any language and is very popular in web applications. The basic structure is built from one or more keys and values:\n\nYou’ll often see a collection of key:value pairs enclosed in brackets described as a JSON object. While the key is any string, the value can be a string, number, array, additional object, or the literals, false, true and null. For example, the following is valid JSON:\n\nJSON doesn't have to have only key:value pairs; the specification allows to any value to be passed without a key. However, almost all of the JSON objects that you see will contain key:value pairs.\n\nOne of the most common uses for JSON is when using an API, both in requests and responses. It is much more compact than other standards and allows for easy consumption in web browsers as JavaScript can easily parse JSON strings, only requiring JSON.parse() to start using it.\n\nJSON.parse(string) takes a string of valid JSON and returns a JavaScript object. For example, it can be called on the body of an API response to give you a usable object. The inverse of this function is JSON.stringify(object) which takes a JavaScript object and returns a string of JSON, which can then be transmitted in an API request or response.\n\nJSON isn’t required by REST or GraphQL, both very popular API formats. However, they are often used together, particularly with GraphQL, where it is best practice to use JSON due to it being small and mostly text. If necessary, it compresses very well with GZIP.\n\nGraphQL's requests aren’t made in JSON, instead using a system that resembles JSON, like this\n\nWhich will return the relevant data, and if using JSON, it will match very closely:\n\nIn some cases, you may want to load JSON from a file, such as for configuration files or mock data. Using pure JavaScript, it currently isn’t possible to import a JSON file, however a proposal has been created to allow this. In addition, it is a very common feature in bundlers and compilers, like webpack and Babel. Currently, you can get equivalent functionality by exporting a JavaScript Object the same as your desired JSON from a JavaScript file.\n\nNow this object will be stored in the constant, data, and will be accessible throughout your application using import or require statements. Note that this will import a copy of the data, so modifying the object won’t write the data back to the file or allow the modified data to be used in other files.\n\nOnce you have a variable containing your data, in this example data, to access a key’s value inside it, you could use either data.key or data[\"key\"]. Square brackets must be used for array indexing; for example if that value was an array, you could do data.key[0], but data.key.0 wouldn’t work.\n\nObject modification works in the same way. You can just set data.key = \"foo\" and that key will now have the value “foo”. Although only the final element in the chain of objects can be replaced; for example if you tried to set data.key.foo.bar to something, it would fail as you would first have to set data.key.foo to an object.\n\nJSON isn’t the only web-friendly data standard out there. The major competitor for JSON in APIs is XML. Instead of the following JSON:\n\nin XML, you’d instead have:\n\nJSON was standardized much later than XML, with the specification for XML coming in 1998, whereas Ecma International standardized JSON in 2013. XML was extremely popular and seen in standards such as AJAX (Asynchronous JavaScript and XML) and the XMLHttpRequest function in JavaScript.\n\nXML used by a major API standard: Simple Object Access Protocol (SOAP). This standard can be significantly more verbose than REST and GraphQL, in part due to the usage of XML and because the standard includes more information, such as describing the XML namespace as part of the envelope system. This might be a reason why SOAP usage has declined for years.\n\nAnother alternative is YAML, which is much more similar in length to JSON compared to XML, with the same example being:\n\nHowever, unlike XML, YAML doesn’t really compete with JSON as an API data format. Instead, it’s primarily used for configuration files— Kubernetes primarily uses YAML to configure infrastructure. YAML offers features that JSON doesn’t have, such as comments. Unlike JSON and XML, browsers cannot parse YAML, so a parser would need to be added as a library if you want to use YAML for data interchange.\n\nWhile many of JSONs use cases transmit it as clear text, the format can be used for secure data transfers as well. JSON web signatures (JWS) are JSON objects securely signed using either a secret or a public/private key pair. These are composed of a header, payload, and signature.\n\nThe header specifies the type of token and the signing algorithm being used. The only required field is alg to specify the encryption algorithm used, but many other keys can be included, such as typ for the type of signature it is.\n\nThe payload of a JWS is the information being transmitted and doesn’t need to be formatted in JSON though commonly is.\n\nThe signature is constructed by applying the encryption algorithm specified in the header to the base64 versions of the header and payload joined by a dot. The final JWS is then the base64 header, base64 payload, and signature joined by dots. For example:\n\nJSON Web Tokens (JWT) are a special form of a JWS. These are particularly useful for authorization: when a user logs into a website, they will be provided with a JWT. For each subsequent request, they will include this token as a bearer token in the authorization header.\n\nTo create a JWT from a JWS, you’ll need to configure each section specifically. In the header, ensure that the typ key is JWT. For the alg key, the options of HS256 (HMAC SHA-256) and none (unencrypted) must be supported by the authorization server in order to be a conforming JWT implementation, so can always be used. Additional algorithms are recommended but not enforced.\n\nIn the payload are a series of keys called claims, which are pieces of information about a subject, as JWTs are most commonly used for authentication, this is commonly a user, but could be anything when used for exchanging information.\n\nThe signature is then constructed in the same way as all other JWSs.\n\nCompared to Security Assertion Markup Language Tokens (SAML), a similar standard that uses XML, JSON allows for JWTs to be smaller than SAML tokens and is easier to parse due to the use of both tokens in the browser, where JavaScript is the primary language, and can easily parse JSON.\n\nJSON has come to be one of the most popular standards for data interchange, being easy for humans to read while being lightweight to ensure small transmission size. Its success has also been caused by it being equivalent to JavaScript objects, making it simple to process in web frontends. However, JSON isn’t the solution for everything, and alternate standards like YAML are more popular for things like configuration files, so it’s important to consider your purpose before choosing."
    },
    {
        "link": "https://apidog.com/blog/json-api-responses",
        "document": "APIs (Application Programming Interfaces) have emerged as the cornerstone of software development, enabling disparate systems to communicate and share data seamlessly. As we delve into the world of APIs, one aspect that stands out is the format of the responses they return. The JSON (JavaScript Object Notation) format has become the de facto standard for API responses, prized for its simplicity, ease of use, and language-agnostic nature.\n\nIn this blog post, we’ll explore the intricacies of API response JSON format, often referred to as the lingua franca of the web. We’ll uncover why developers favor it, how it streamlines the process of data interchange, and the best practices for structuring JSON responses. Whether you’re a seasoned developer or just starting out, understanding the nuances of JSON will enhance your ability to design, consume, and debug APIs.\n\nAPIs, or Application Programming Interfaces, are the unsung heroes of our connected world. They are the conduits through which different software applications exchange data and functionalities, making them integral to the seamless operation of the digital ecosystem.\n\nAt their core, APIs are sets of rules and protocols that dictate how software components should interact. They enable developers to tap into existing services and platforms, leveraging their capabilities without having to reinvent the wheel. This not only saves time and resources but also fosters innovation by allowing for the integration of diverse technologies.\n\nThe significance of APIs cannot be overstated. They are the building blocks of modern software development, powering everything from web applications to mobile apps, and from cloud services to IoT devices. APIs facilitate the interoperability between systems, making it possible for your favorite apps to communicate with one another, share data, and offer a cohesive user experience.\n\nThe Role of JSON in API Responses\n\nJSON, or JavaScript Object Notation, plays a pivotal role in API responses due to its lightweight nature and easy readability. It serves as a universal language for data interchange between servers and web applications.\n• Human-readable: JSON is self-describing and easy to understand, even for those who are not developers.\n• Lightweight: Its simplicity allows for quick parsing and a smaller data footprint compared to other formats like XML.\n• Language-agnostic: JSON is supported by most programming languages, making it highly versatile for backend and frontend development.\n\nWhen an API is called, the server responds with a JSON-formatted text that represents the data requested. This could be anything from user information to a list of products. The JSON format ensures that this data can be easily parsed by the client application and used as needed.\n\nFor example, a simple API response in JSON format might look like this:\n\nIn this snippet, we see a user object with properties and values encoded in a way that’s both easy to read and easy to process programmatically.\n\nThe Impact of JSON on APIs\n\nThe adoption of JSON has streamlined the development process, enabling faster, more efficient, and more reliable data exchange. It has become the backbone of RESTful APIs, which are the standard for web services today.\n\nAnatomy of an API Response in JSON Format\n\nThe anatomy of an API response in JSON format is akin to the structure of a well-organized document. It consists of key-value pairs that represent data in a structured, hierarchical manner. Let’s dissect this anatomy to understand its components better.\n\nAt the highest level, a JSON response typically starts with a root element, which can be either an object or an array. An object is denoted by curly braces , while an array is denoted by square brackets .\n\nAn object represents a single entity and contains one or more key-value pairs. The keys are strings, and the values can be strings, numbers, objects, arrays, , , or .\n\nAn array is an ordered collection of values, which can be of any type, including objects and other arrays.\n\nThe key-value pairs within an object are the fundamental units of data representation in JSON. They are separated by commas, and the key and value are separated by a colon.\n\nIn this example:\n• The root element is an object.\n• The object contains three key-value pairs: , , and .\n• The key contains an object with its own nested key-value pairs.\n• The key within the object contains an array of values.\n• The key within the object contains another object.\n\nUnderstanding the structure of a JSON API response is crucial for developers as it allows them to parse the data correctly and integrate it into their applications. It’s the clarity and predictability of this structure that make JSON an invaluable format in the world of APIs.\n\nThe API response JSON format in Apidog is designed to be intuitive and easy to work with for developers.\n\nIt typically includes the following components:\n• Status Code: Indicates the result of the API call, such as success or error.\n• Headers: Provide metadata about the response, like content type and cache directives.\n• Body: Contains the actual data payload, formatted as a JSON object or array.\n\nFor example, a successful response from an API might look like this:\n\nApidog emphasizes clear documentation and structured responses to ensure efficient data exchange and error handling.\n\nWhen structuring JSON API responses, adhering to best practices is crucial for ensuring that the data is easily consumable and maintainable. Here are some guidelines to follow:\n\n1. Keep it Intuitive and Consistent\n• Use clear, descriptive key names that accurately reflect the data they hold.\n• Maintain a consistent structure across all API endpoints to avoid confusion.\n• While JSON allows for nesting, overdoing it can make the response complex and harder to parse. Limit nesting to what’s necessary for logical grouping.\n• Leverage HTTP status codes to indicate the success or failure of an API request. This helps clients handle responses appropriately.\n• In case of an error, include a message that explains what went wrong and possibly how to fix it.\n• For endpoints that can return large data sets, implement pagination to improve performance and usability.\n\n6. HATEOAS (Hypermedia as the Engine of Application State)\n• Consider using HATEOAS principles to include hyperlinks in your API responses, guiding clients through the available actions.\n• Be mindful of sensitive data. Ensure that private information is not exposed unintentionally in your API responses.\n• Document your API responses thoroughly. Clear documentation is invaluable for developers who will consume your API.\n\nBy following these best practices, you can create JSON API responses that are not only functional but also a pleasure to work with. Remember, the goal is to make the data exchange process as smooth and efficient as possible for all parties involved.\n\nParsing JSON API responses is a fundamental skill for developers working with APIs. It involves converting the JSON-formatted string received from an API into a data structure that can be manipulated and used within an application.\n\nUtilizing Parsed Data:Once the JSON response is parsed, the data can be used in various ways depending on the application’s requirements. For instance:\n• Processing a list of products in an e-commerce app.\n\nBest Practices for Parsing and Utilization:\n• Error Handling: Always include error handling when parsing JSON to manage unexpected or malformed data.\n• Data Validation: Validate the parsed data to ensure it meets the expected format and type.\n• Efficient Data Access: Access the data in a way that is efficient and does not hinder application performance.\n\nIn essence, JSON’s role in API responses is a testament to its efficiency and adaptability, making it an industry standard. By following best practices in JSON formatting, developers can ensure their applications are robust and user-centric. Apidog stands as a prime example of these principles in action, providing a clear path for developers to master API responses and build the interconnected applications of tomorrow."
    }
]