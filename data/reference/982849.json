[
    {
        "link": "https://thepythoncodingbook.com/2023/01/18/best-practices-in-python-functions",
        "document": "You’ve covered a lot of material in this Intermediate Python Functions Series. In this final article, you’ll read about some best practices in Python functions.\n\nThis topic is different from the previous ones discussed in this series. You won’t get a , or any other error if you don’t follow best practices. Your code may still work exactly the same if you use best practices or if you don’t, although bugs are more likely to creep into your code if you don’t.\n\nLet’s see why it still matters to know and use best practices. There were two options when writing this article: either write a very long article covering every possible best practice or write a much more concise article highlighting two key best practices. I’ve chosen to go down the route of writing a short article and focus on the two I think are most relevant.\n\nHere’s an overview of the seven articles in this series:\n• Introduction to the series: Do you know all your functions terminology well?\n• Choosing whether to use positional or keyword arguments when calling a function\n• Using optional arguments by including default values when defining a function\n• Using any number of optional positional and keyword arguments: and\n• Using positional-only arguments and keyword-only arguments: the “rogue” forward slash / or asterisk * in function signatures\n• [This article] Best practices when defining and using functions\n\nStart The Function Name With A Verb\n\nLet’s start with a function you’ve seen often in this series of articles:\n\nIt is clear from the name of the function what the function does. It greets a person! If you choose to call the function , it will be unclear what the function is doing with that greeting.\n\nAnd you should always avoid calling a function or or other names with no descriptive value.\n\nLet’s look at another example. Let’s assume you’re reading code that displays shapes and patterns. You see a function called . Is this function drawing a square or working out the square of a number to use in some calculation? You may be able to figure this out quickly by reading further or running the code. However, if the function name were , you wouldn’t even need to ask yourself the question about the function’s purpose.\n\nDid you notice what’s common in the two best practice examples you read about above? Here are a few more examples of best practice in Python function names compared to versions that you should avoid:\n\nA function performs an action. In the languages we use for human communication, such as English, verbs perform a similar role of denoting an action. Therefore, the best practice in Python functions is to use a verb as the first word in a function name to describe what the function does.\n\nIn the examples you read in the table above, the parameter name is also different in some cases. This series is about functions, so I’ll focus on function names. But when choosing variable names, including parameter names, you often want to use a noun which tells you what the value stored in the variable represents.\n\nWrite A Function That Only Does One Thing\n\nLet’s assume you’re writing a program that deals with historical temperatures which you want to analyse. The data is in Fahrenheit, but you need to work in Celsius and then find the range of temperature in a subset of the data by subtracting the minimum value from the maximum value.\n\nYou decide to write the function . You’ve followed the ‘start with a verb’ best practice and feel you’ve written a descriptive name. All good, then, right?\n\nThere’s a word in your function that’s a giveaway for the next best practice I’ll write about. This is the word “and” in the function name. If you feel the need to add an “and” in your function name, you probably want to write two functions instead.\n\nA function should only perform one action. In this example, you can write a function and another function called .\n\nThis rule sounds simple enough initially. However, some nuance is involved in defining a “single action”.\n\nFor example, consider the function , which takes a string with a person’s full name and returns a string with the initials. This function may need to split the string to separate the components in the full name, such as first name, last name, and perhaps middle names. Then, it will need to extract the first letter from each subcomponent and concatenate them with periods after each letter.\n\nThese are several actions. Does this mean this function goes against the “perform one action” best practice? Every programmer will need to make these decisions in the context of the program and application they’re writing. In this example, it’s likely that grouping the steps listed above into a single function is fine. The single action you want to perform is to get the initials from a name.\n\nAs a rule, if the steps you want to include in a function will always be performed together, then you probably want them in the same function. You’ll get better at making these decisions.\n\nBest practices in Python functions matter. They often make sure code is more readable for others and your future self. They also make bugs less likely and the code more maintainable.\n\nProgrammers will have different views on what constitutes a best practice. You’ll have to make up your mind on which ones to follow. And you may find that as you progress through your Python learning journey, you’ll also change your views on which best practices to adopt!\n\nThis is the final article in the Intermediate Python Functions Series\n• Chapter 3: Power-up Your Coding: Create Your Own Functions for an in-depth introduction to Python functions\n• Chapter 6: Functions Revisited. This chapter covers topics that will be dealt with later on in the series\n• The White Room: Understanding Programming. In this article, I briefly referred to parameters as boxes which store data. This is part of a broader analogy I like to use. You can read more in this chapter\n• Using Python Optional Arguments When Defining Functions is an article I wrote for Real Python if you want to read ahead."
    },
    {
        "link": "https://kdnuggets.com/5-tips-for-writing-better-python-functions",
        "document": "This tutorial covers five simple yet effective practices for writing better and maintainable Python functions.\n\nWe all write functions when coding in Python. But do we necessarily write good functions? Well, let’s find out.\n\nFunctions in Python let you write modular code. When you have a task you need to perform at multiple places, you can wrap the logic of the task into a Python function. And you can call the function every time you need to perform that specific task. As simple as it seems to get started with Python functions, writing maintainable and performant functions is not so straightforward.\n\nAnd that’s why we’ll explore a few practices that’ll help you write cleaner and easy-to-maintain Python functions. Let's get started…\n\n1. Write Functions That Do Only One Thing\n\nWhen writing functions in Python, it's often tempting to put all related tasks into a single function. While this can help you code things up quickly, it’ll only make your code a pain to maintain in the near future. Not only will this make understanding what a function does more difficult but also leads to other issues such as too many parameters (more on that later!).\n\nAs a good practice, you should always try to make your function do only one thing—one task—and do that well. But sometimes, for a single task, you may need to work through a series of subtasks. So how do you decide if and how the function should be refactored?\n\nDepending on what the function is trying to do and how complex the task is, you can work out the separation of concerns between subtasks. And then identify a suitable level at which you can refactor the function into multiple functions—each focusing on a specific subtask.\n\nHere’s an example. Look at the function :\n\nIt's quite easy to see that it can be refactored into two functions: one calculating the sales metrics and another on writing the sales metrics to a file like so:\n\nNow it’s easier to debug any concerns with the calculation of sales metrics and file operations separately. And here’s a sample function call:\n\nYou should be able to see the ‘sales_report.txt’ file in your working directory with the sales metrics. This is a simple example to get started, but this is helpful especially when you're working on more complex functions.\n\nPython is a dynamically typed language. So you do not need to declare types for the variables you create. But you can add type hints to specify the expected data type for variables. When you define the function, you can add the expected data types for the parameters and the return values.\n\nBecause Python does not enforce types at runtime, adding type hints has no effect at runtime. But there still are benefits to using type hints, especially on the maintainability front:\n• Adding type hints to Python functions serves as inline documentation and gives a better idea of what the function does and what values it consumes and returns.\n• When you add type hints to your functions, you can configure your IDE to leverage these type hints. So you’ll get helpful warnings if you try to pass an argument of invalid type in one or more function calls, implement functions whose return values do not match the expected type, and the like. So you can minimize errors upfront.\n• You can optionally use static type checkers like mypy to catch errors earlier rather than letting type mismatches introduce subtle bugs that are difficult to debug.\n\nNow let's add type hints to the function like so:\n\nWith the modified version, you get to know that the function takes in a list of dictionaries. The keys of the dictionary should all be strings and the values can either be integers or floating point values. The function also returns a dictionary. Let’s take a sample function call:\n\nIn this example, type hints help us get a better idea of how the function works. Going forward, we'll add type hints for all the better versions of Python functions we write.\n\n3. Accept Only the Arguments You Actually Need\n\nIf you are a beginner or have just started your first dev role, it’s important to think about the different parameters when defining the function signature. It's quite common to introduce additional parameters in the function signature that the function never actually processes.\n\nEnsuring that the function takes in only the arguments that are actually necessary keeps function calls cleaner and more maintainable in general. On a related note, too many parameters in the function signature also make it a pain to maintain. So how do you go about defining easy-to-maintain functions with the right number of parameters?\n\nIf you find yourself writing a function signature with a growing number of parameters, the first step is to remove all unused parameters from the signature. If there are too many parameters even after this step, go back to tip #1: break down the task into multiple subtasks and refactor the function into multiple smaller functions. This will help keep the number of parameters in check.\n\nIt’s time for a simple example. Here the function definition to calculate student grades contains the parameter that’s never used:\n\nYou can rewrite the function without the parameter like so:\n\nHere's the output of the function call:\n\nIn practice, most Python functions take in multiple arguments. You can pass in arguments to Python functions as positional arguments, keyword arguments, or a mix of both. Read Python Function Arguments: A Definitive Guide for a quick review of function arguments.\n\nSome arguments are naturally positional. But sometimes having function calls containing only positional arguments can be confusing. This is especially true when the function takes in multiple arguments of the same data type, some required and some optional.\n\nIf you recall, with positional arguments, the arguments are passed to the parameters in the function signature in the same order in which they appear in the function call. So change in order of arguments can introduce subtle bugs and type errors.\n\nIt’s often helpful to make optional arguments keyword-only. This also makes adding optional parameters much easier—without breaking existing calls.\n\nHere’s an example. The function takes in an optional string:\n\nSay you want to make the optional a keyword-only argument. Here’s how you can do it:\n\nNow try passing in all arguments as positional:\n\nYou’ll get an error as shown:\n\n5. Don’t Return Lists From Functions; Use Generators Instead\n\nIt's quite common to write Python functions that generate sequences such as a list of values. But as much as possible, you should avoid returning lists from Python functions. Instead you can rewrite them as generator functions. Generators use lazy evaluation; so they yield elements of the sequence on demand rather than computing all the values ahead of time. Read Getting Started with Python Generators for an introduction to how generators work in Python.\n\nAs an example, take the following function that generates the Fibonacci sequence up to a certain upper limit:\n\nIt’s a recursive implementation that’s computationally expensive and populating the list and returning it seems more verbose than necessary. Here’s an improved version of the function that uses generators:\n\nIn this case, the function returns a generator object which you can then loop through to get the elements of the sequence:\n\nAs you can see, using generators can be much more efficient especially for large input sizes. Also, you can chain multiple generators together, so you can create efficient data processing pipelines with generators.\n\nAnd that’s a wrap. You can find all the code on GitHub. Here’s a review of the different tips we went over:\n• Write functions that do only one thing\n• Accept only the arguments you actually need\n• Don't return lists from functions; use generators instead\n\nI hope you found them helpful! If you aren’t already, try out these practices when writing Python functions. Happy coding!\n\n \n\n\n\nBala Priya C is a developer and technical writer from India. She likes working at the intersection of math, programming, data science, and content creation. Her areas of interest and expertise include DevOps, data science, and natural language processing. She enjoys reading, writing, coding, and coffee! Currently, she's working on learning and sharing her knowledge with the developer community by authoring tutorials, how-to guides, opinion pieces, and more. Bala also creates engaging resource overviews and coding tutorials."
    },
    {
        "link": "https://reddit.com/r/Python/comments/o9psjn/best_practice_for_function_placement_within_a_code",
        "document": "I am new to Python(<1 year) and want my code to be clean, clear and legible. I wasn't able to get a good answer to this question via stack overflow/google so I figured I would reach out to the reddit community. ..\n\nWhere do you place your functions? Do you place them at the start of your code? Do you leave it wherever you originally create it within the code? Do you want it to be just before it's first usage? Is there a consensus amongst the community or is it like the wild west?\n\nAny help or tips would be greatly appreciated, TIA!"
    },
    {
        "link": "https://peps.python.org/pep-0008",
        "document": "This document gives coding conventions for the Python code comprising the standard library in the main Python distribution. Please see the companion informational PEP describing style guidelines for the C code in the C implementation of Python. This document and PEP 257 (Docstring Conventions) were adapted from Guido’s original Python Style Guide essay, with some additions from Barry’s style guide . This style guide evolves over time as additional conventions are identified and past conventions are rendered obsolete by changes in the language itself. Many projects have their own coding style guidelines. In the event of any conflicts, such project-specific guides take precedence for that project.\n\nA Foolish Consistency is the Hobgoblin of Little Minds One of Guido’s key insights is that code is read much more often than it is written. The guidelines provided here are intended to improve the readability of code and make it consistent across the wide spectrum of Python code. As PEP 20 says, “Readability counts”. A style guide is about consistency. Consistency with this style guide is important. Consistency within a project is more important. Consistency within one module or function is the most important. However, know when to be inconsistent – sometimes style guide recommendations just aren’t applicable. When in doubt, use your best judgment. Look at other examples and decide what looks best. And don’t hesitate to ask! In particular: do not break backwards compatibility just to comply with this PEP! Some other good reasons to ignore a particular guideline:\n• When applying the guideline would make the code less readable, even for someone who is used to reading code that follows this PEP.\n• To be consistent with surrounding code that also breaks it (maybe for historic reasons) – although this is also an opportunity to clean up someone else’s mess (in true XP style).\n• Because the code in question predates the introduction of the guideline and there is no other reason to be modifying that code.\n• When the code needs to remain compatible with older versions of Python that don’t support the feature recommended by the style guide.\n\nContinuation lines should align wrapped elements either vertically using Python’s implicit line joining inside parentheses, brackets and braces, or using a hanging indent . When using a hanging indent the following should be considered; there should be no arguments on the first line and further indentation should be used to clearly distinguish itself as a continuation line: # Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest. # Arguments on first line forbidden when not using vertical alignment. # Further indentation required as indentation is not distinguishable. The 4-space rule is optional for continuation lines. # Hanging indents *may* be indented to other than 4 spaces. When the conditional part of an -statement is long enough to require that it be written across multiple lines, it’s worth noting that the combination of a two character keyword (i.e. ), plus a single space, plus an opening parenthesis creates a natural 4-space indent for the subsequent lines of the multiline conditional. This can produce a visual conflict with the indented suite of code nested inside the -statement, which would also naturally be indented to 4 spaces. This PEP takes no explicit position on how (or whether) to further visually distinguish such conditional lines from the nested suite inside the -statement. Acceptable options in this situation include, but are not limited to: # Add a comment, which will provide some distinction in editors # Since both conditions are true, we can frobnicate. # Add some extra indentation on the conditional continuation line. The closing brace/bracket/parenthesis on multiline constructs may either line up under the first non-whitespace character of the last line of list, as in: or it may be lined up under the first character of the line that starts the multiline construct, as in: Tabs should be used solely to remain consistent with code that is already indented with tabs. Limit all lines to a maximum of 79 characters. For flowing long blocks of text with fewer structural restrictions (docstrings or comments), the line length should be limited to 72 characters. Limiting the required editor window width makes it possible to have several files open side by side, and works well when using code review tools that present the two versions in adjacent columns. The default wrapping in most tools disrupts the visual structure of the code, making it more difficult to understand. The limits are chosen to avoid wrapping in editors with the window width set to 80, even if the tool places a marker glyph in the final column when wrapping lines. Some web based tools may not offer dynamic line wrapping at all. Some teams strongly prefer a longer line length. For code maintained exclusively or primarily by a team that can reach agreement on this issue, it is okay to increase the line length limit up to 99 characters, provided that comments and docstrings are still wrapped at 72 characters. The Python standard library is conservative and requires limiting lines to 79 characters (and docstrings/comments to 72). The preferred way of wrapping long lines is by using Python’s implied line continuation inside parentheses, brackets and braces. Long lines can be broken over multiple lines by wrapping expressions in parentheses. These should be used in preference to using a backslash for line continuation. Backslashes may still be appropriate at times. For example, long, multiple -statements could not use implicit continuation before Python 3.10, so backslashes were acceptable for that case: Another such case is with statements. Make sure to indent the continued line appropriately. Should a Line Break Before or After a Binary Operator? For decades the recommended style was to break after binary operators. But this can hurt readability in two ways: the operators tend to get scattered across different columns on the screen, and each operator is moved away from its operand and onto the previous line. Here, the eye has to do extra work to tell which items are added and which are subtracted: # operators sit far away from their operands To solve this readability problem, mathematicians and their publishers follow the opposite convention. Donald Knuth explains the traditional rule in his Computers and Typesetting series: “Although formulas within a paragraph always break after binary operations and relations, displayed formulas always break before binary operations” . Following the tradition from mathematics usually results in more readable code: In Python code, it is permissible to break before or after a binary operator, as long as the convention is consistent locally. For new code Knuth’s style is suggested. Surround top-level function and class definitions with two blank lines. Extra blank lines may be used (sparingly) to separate groups of related functions. Blank lines may be omitted between a bunch of related one-liners (e.g. a set of dummy implementations). Use blank lines in functions, sparingly, to indicate logical sections. Python accepts the control-L (i.e. ^L) form feed character as whitespace; many tools treat these characters as page separators, so you may use them to separate pages of related sections of your file. Note, some editors and web-based code viewers may not recognize control-L as a form feed and will show another glyph in its place. Code in the core Python distribution should always use UTF-8, and should not have an encoding declaration. In the standard library, non-UTF-8 encodings should be used only for test purposes. Use non-ASCII characters sparingly, preferably only to denote places and human names. If using non-ASCII characters as data, avoid noisy Unicode characters like z̯̯͡a̧͎̺l̡͓̫g̹̲o̡̼̘ and byte order marks. All identifiers in the Python standard library MUST use ASCII-only identifiers, and SHOULD use English words wherever feasible (in many cases, abbreviations and technical terms are used which aren’t English). Open source projects with a global audience are encouraged to adopt a similar policy.\n• Imports should usually be on separate lines: It’s okay to say this though:\n• Imports are always put at the top of the file, just after any module comments and docstrings, and before module globals and constants. Imports should be grouped in the following order: You should put a blank line between each group of imports.\n• Absolute imports are recommended, as they are usually more readable and tend to be better behaved (or at least give better error messages) if the import system is incorrectly configured (such as when a directory inside a package ends up on ): However, explicit relative imports are an acceptable alternative to absolute imports, especially when dealing with complex package layouts where using absolute imports would be unnecessarily verbose: Standard library code should avoid complex package layouts and always use absolute imports.\n• When importing a class from a class-containing module, it’s usually okay to spell this: If this spelling causes local name clashes, then spell them explicitly: and use and .\n• Wildcard imports ( ) should be avoided, as they make it unclear which names are present in the namespace, confusing both readers and many automated tools. There is one defensible use case for a wildcard import, which is to republish an internal interface as part of a public API (for example, overwriting a pure Python implementation of an interface with the definitions from an optional accelerator module and exactly which definitions will be overwritten isn’t known in advance). When republishing names this way, the guidelines below regarding public and internal interfaces still apply. Module level “dunders” (i.e. names with two leading and two trailing underscores) such as , , , etc. should be placed after the module docstring but before any import statements except imports. Python mandates that future-imports must appear in the module before any other code except docstrings: \"\"\"This is the example module.\n\nWhen to Use Trailing Commas Trailing commas are usually optional, except they are mandatory when making a tuple of one element. For clarity, it is recommended to surround the latter in (technically redundant) parentheses: When trailing commas are redundant, they are often helpful when a version control system is used, when a list of values, arguments or imported items is expected to be extended over time. The pattern is to put each value (etc.) on a line by itself, always adding a trailing comma, and add the close parenthesis/bracket/brace on the next line. However it does not make sense to have a trailing comma on the same line as the closing delimiter (except in the above case of singleton tuples):\n\nThe naming conventions of Python’s library are a bit of a mess, so we’ll never get this completely consistent – nevertheless, here are the currently recommended naming standards. New modules and packages (including third party frameworks) should be written to these standards, but where an existing library has a different style, internal consistency is preferred. Names that are visible to the user as public parts of the API should follow conventions that reflect usage rather than implementation. There are a lot of different naming styles. It helps to be able to recognize what naming style is being used, independently from what they are used for. The following naming styles are commonly distinguished:\n• (or CapWords, or CamelCase – so named because of the bumpy look of its letters ). This is also sometimes known as StudlyCaps. Note: When using acronyms in CapWords, capitalize all the letters of the acronym. Thus HTTPServerError is better than HttpServerError. There’s also the style of using a short unique prefix to group related names together. This is not used much in Python, but it is mentioned for completeness. For example, the function returns a tuple whose items traditionally have names like , , and so on. (This is done to emphasize the correspondence with the fields of the POSIX system call struct, which helps programmers familiar with that.) The X11 library uses a leading X for all its public functions. In Python, this style is generally deemed unnecessary because attribute and method names are prefixed with an object, and function names are prefixed with a module name. In addition, the following special forms using leading or trailing underscores are recognized (these can generally be combined with any case convention):\n• : weak “internal use” indicator. E.g. does not import objects whose names start with an underscore.\n• : used by convention to avoid conflicts with Python keyword, e.g. :\n• : when naming a class attribute, invokes name mangling (inside class FooBar, becomes ; see below).\n• : “magic” objects or attributes that live in user-controlled namespaces. E.g. , or . Never invent such names; only use them as documented. Never use the characters ‘l’ (lowercase letter el), ‘O’ (uppercase letter oh), or ‘I’ (uppercase letter eye) as single character variable names. In some fonts, these characters are indistinguishable from the numerals one and zero. When tempted to use ‘l’, use ‘L’ instead. Identifiers used in the standard library must be ASCII compatible as described in the policy section of PEP 3131. Modules should have short, all-lowercase names. Underscores can be used in the module name if it improves readability. Python packages should also have short, all-lowercase names, although the use of underscores is discouraged. When an extension module written in C or C++ has an accompanying Python module that provides a higher level (e.g. more object oriented) interface, the C/C++ module has a leading underscore (e.g. ). Class names should normally use the CapWords convention. The naming convention for functions may be used instead in cases where the interface is documented and used primarily as a callable. Note that there is a separate convention for builtin names: most builtin names are single words (or two words run together), with the CapWords convention used only for exception names and builtin constants. Names of type variables introduced in PEP 484 should normally use CapWords preferring short names: , , . It is recommended to add suffixes or to the variables used to declare covariant or contravariant behavior correspondingly: Because exceptions should be classes, the class naming convention applies here. However, you should use the suffix “Error” on your exception names (if the exception actually is an error). (Let’s hope that these variables are meant for use inside one module only.) The conventions are about the same as those for functions. Modules that are designed for use via should use the mechanism to prevent exporting globals, or use the older convention of prefixing such globals with an underscore (which you might want to do to indicate these globals are “module non-public”). Function names should be lowercase, with words separated by underscores as necessary to improve readability. Variable names follow the same convention as function names. mixedCase is allowed only in contexts where that’s already the prevailing style (e.g. threading.py), to retain backwards compatibility. Always use for the first argument to instance methods. Always use for the first argument to class methods. If a function argument’s name clashes with a reserved keyword, it is generally better to append a single trailing underscore rather than use an abbreviation or spelling corruption. Thus is better than . (Perhaps better is to avoid such clashes by using a synonym.) Use the function naming rules: lowercase with words separated by underscores as necessary to improve readability. Use one leading underscore only for non-public methods and instance variables. To avoid name clashes with subclasses, use two leading underscores to invoke Python’s name mangling rules. Python mangles these names with the class name: if class Foo has an attribute named , it cannot be accessed by . (An insistent user could still gain access by calling .) Generally, double leading underscores should be used only to avoid name conflicts with attributes in classes designed to be subclassed. Note: there is some controversy about the use of __names (see below). Constants are usually defined on a module level and written in all capital letters with underscores separating words. Examples include and . Always decide whether a class’s methods and instance variables (collectively: “attributes”) should be public or non-public. If in doubt, choose non-public; it’s easier to make it public later than to make a public attribute non-public. Public attributes are those that you expect unrelated clients of your class to use, with your commitment to avoid backwards incompatible changes. Non-public attributes are those that are not intended to be used by third parties; you make no guarantees that non-public attributes won’t change or even be removed. We don’t use the term “private” here, since no attribute is really private in Python (without a generally unnecessary amount of work). Another category of attributes are those that are part of the “subclass API” (often called “protected” in other languages). Some classes are designed to be inherited from, either to extend or modify aspects of the class’s behavior. When designing such a class, take care to make explicit decisions about which attributes are public, which are part of the subclass API, and which are truly only to be used by your base class. With this in mind, here are the Pythonic guidelines:\n• Public attributes should have no leading underscores.\n• If your public attribute name collides with a reserved keyword, append a single trailing underscore to your attribute name. This is preferable to an abbreviation or corrupted spelling. (However, notwithstanding this rule, ‘cls’ is the preferred spelling for any variable or argument which is known to be a class, especially the first argument to a class method.) Note 1: See the argument name recommendation above for class methods.\n• For simple public data attributes, it is best to expose just the attribute name, without complicated accessor/mutator methods. Keep in mind that Python provides an easy path to future enhancement, should you find that a simple data attribute needs to grow functional behavior. In that case, use properties to hide functional implementation behind simple data attribute access syntax. Note 1: Try to keep the functional behavior side-effect free, although side-effects such as caching are generally fine. Note 2: Avoid using properties for computationally expensive operations; the attribute notation makes the caller believe that access is (relatively) cheap.\n• If your class is intended to be subclassed, and you have attributes that you do not want subclasses to use, consider naming them with double leading underscores and no trailing underscores. This invokes Python’s name mangling algorithm, where the name of the class is mangled into the attribute name. This helps avoid attribute name collisions should subclasses inadvertently contain attributes with the same name. Note 1: Note that only the simple class name is used in the mangled name, so if a subclass chooses both the same class name and attribute name, you can still get name collisions. Note 2: Name mangling can make certain uses, such as debugging and , less convenient. However the name mangling algorithm is well documented and easy to perform manually. Note 3: Not everyone likes name mangling. Try to balance the need to avoid accidental name clashes with potential use by advanced callers. Any backwards compatibility guarantees apply only to public interfaces. Accordingly, it is important that users be able to clearly distinguish between public and internal interfaces. Documented interfaces are considered public, unless the documentation explicitly declares them to be provisional or internal interfaces exempt from the usual backwards compatibility guarantees. All undocumented interfaces should be assumed to be internal. To better support introspection, modules should explicitly declare the names in their public API using the attribute. Setting to an empty list indicates that the module has no public API. Even with set appropriately, internal interfaces (packages, modules, classes, functions, attributes or other names) should still be prefixed with a single leading underscore. An interface is also considered internal if any containing namespace (package, module or class) is considered internal. Imported names should always be considered an implementation detail. Other modules must not rely on indirect access to such imported names unless they are an explicitly documented part of the containing module’s API, such as or a package’s module that exposes functionality from submodules.\n• Code should be written in a way that does not disadvantage other implementations of Python (PyPy, Jython, IronPython, Cython, Psyco, and such). For example, do not rely on CPython’s efficient implementation of in-place string concatenation for statements in the form or . This optimization is fragile even in CPython (it only works for some types) and isn’t present at all in implementations that don’t use refcounting. In performance sensitive parts of the library, the form should be used instead. This will ensure that concatenation occurs in linear time across various implementations.\n• Comparisons to singletons like None should always be done with or , never the equality operators. Also, beware of writing when you really mean if x is not None – e.g. when testing whether a variable or argument that defaults to None was set to some other value. The other value might have a type (such as a container) that could be false in a boolean context!\n• Use operator rather than . While both expressions are functionally identical, the former is more readable and preferred:\n• When implementing ordering operations with rich comparisons, it is best to implement all six operations ( , , , , , ) rather than relying on other code to only exercise a particular comparison. To minimize the effort involved, the decorator provides a tool to generate missing comparison methods. PEP 207 indicates that reflexivity rules are assumed by Python. Thus, the interpreter may swap with , with , and may swap the arguments of and . The and operations are guaranteed to use the operator and the function uses the operator. However, it is best to implement all six operations so that confusion doesn’t arise in other contexts.\n• Always use a def statement instead of an assignment statement that binds a lambda expression directly to an identifier: The first form means that the name of the resulting function object is specifically ‘f’ instead of the generic ‘<lambda>’. This is more useful for tracebacks and string representations in general. The use of the assignment statement eliminates the sole benefit a lambda expression can offer over an explicit def statement (i.e. that it can be embedded inside a larger expression)\n• Derive exceptions from rather than . Direct inheritance from is reserved for exceptions where catching them is almost always the wrong thing to do. Design exception hierarchies based on the distinctions that code catching the exceptions is likely to need, rather than the locations where the exceptions are raised. Aim to answer the question “What went wrong?” programmatically, rather than only stating that “A problem occurred” (see PEP 3151 for an example of this lesson being learned for the builtin exception hierarchy) Class naming conventions apply here, although you should add the suffix “Error” to your exception classes if the exception is an error. Non-error exceptions that are used for non-local flow control or other forms of signaling need no special suffix.\n• Use exception chaining appropriately. should be used to indicate explicit replacement without losing the original traceback. When deliberately replacing an inner exception (using ), ensure that relevant details are transferred to the new exception (such as preserving the attribute name when converting KeyError to AttributeError, or embedding the text of the original exception in the new exception message).\n• When catching exceptions, mention specific exceptions whenever possible instead of using a bare clause: A bare clause will catch SystemExit and KeyboardInterrupt exceptions, making it harder to interrupt a program with Control-C, and can disguise other problems. If you want to catch all exceptions that signal program errors, use (bare except is equivalent to ). A good rule of thumb is to limit use of bare ‘except’ clauses to two cases:\n• If the exception handler will be printing out or logging the traceback; at least the user will be aware that an error has occurred.\n• If the code needs to do some cleanup work, but then lets the exception propagate upwards with . can be a better way to handle this case.\n• When catching operating system errors, prefer the explicit exception hierarchy introduced in Python 3.3 over introspection of values.\n• Additionally, for all try/except clauses, limit the clause to the absolute minimum amount of code necessary. Again, this avoids masking bugs: # Will also catch KeyError raised by handle_value()\n• When a resource is local to a particular section of code, use a statement to ensure it is cleaned up promptly and reliably after use. A try/finally statement is also acceptable.\n• Context managers should be invoked through separate functions or methods whenever they do something other than acquire and release resources: The latter example doesn’t provide any information to indicate that the and methods are doing something other than closing the connection after a transaction. Being explicit is important in this case.\n• Be consistent in return statements. Either all return statements in a function should return an expression, or none of them should. If any return statement returns an expression, any return statements where no value is returned should explicitly state this as , and an explicit return statement should be present at the end of the function (if reachable):\n• Use and instead of string slicing to check for prefixes or suffixes. startswith() and endswith() are cleaner and less error prone:\n• Object type comparisons should always use isinstance() instead of comparing types directly:\n• For sequences, (strings, lists, tuples), use the fact that empty sequences are false:\n• Don’t write string literals that rely on significant trailing whitespace. Such trailing whitespace is visually indistinguishable and some editors (or more recently, reindent.py) will trim them.\n• Don’t compare boolean values to True or False using :\n• Use of the flow control statements / / within the finally suite of a , where the flow control statement would jump outside the finally suite, is discouraged. This is because such statements will implicitly cancel any active exception that is propagating through the finally suite: With the acceptance of PEP 484, the style rules for function annotations have changed.\n• Function annotations should use PEP 484 syntax (there are some formatting recommendations for annotations in the previous section).\n• The experimentation with annotation styles that was recommended previously in this PEP is no longer encouraged.\n• However, outside the stdlib, experiments within the rules of PEP 484 are now encouraged. For example, marking up a large third party library or application with PEP 484 style type annotations, reviewing how easy it was to add those annotations, and observing whether their presence increases code understandability.\n• The Python standard library should be conservative in adopting such annotations, but their use is allowed for new code and for big refactorings.\n• For code that wants to make a different use of function annotations it is recommended to put a comment of the form: near the top of the file; this tells type checkers to ignore all annotations. (More fine-grained ways of disabling complaints from type checkers can be found in PEP 484.)\n• Like linters, type checkers are optional, separate tools. Python interpreters by default should not issue any messages due to type checking and should not alter their behavior based on annotations.\n• Users who don’t want to use type checkers are free to ignore them. However, it is expected that users of third party library packages may want to run type checkers over those packages. For this purpose PEP 484 recommends the use of stub files: .pyi files that are read by the type checker in preference of the corresponding .py files. Stub files can be distributed with a library, or separately (with the library author’s permission) through the typeshed repo . PEP 526 introduced variable annotations. The style recommendations for them are similar to those on function annotations described above:\n• Annotations for module level variables, class and instance variables, and local variables should have a single space after the colon.\n• There should be no space before the colon.\n• If an assignment has a right hand side, then the equality sign should have exactly one space on both sides:\n• Although the PEP 526 is accepted for Python 3.6, the variable annotation syntax is the preferred syntax for stub files on all versions of Python (see PEP 484 for details)."
    },
    {
        "link": "https://jessica-miles.medium.com/writing-functions-in-python-a-beginners-guide-ed9182db959b",
        "document": "It’s worth briefly returning to the concept I mentioned above: you can ask your function to make decisions about certain things so you don’t have to do it manually. The normality test code segment is a very simple example of coding a decision that I would otherwise have to make manually: in addition to printing the result of the test, I’m also having the code determine if the p-value is significant at an alpha level of 0.05, and telling me the result of that decision. Although I could actually make this decision quite easily myself by looking at the value, much more complex logic could be written for more nuanced decisions.\n\nNow that I’ve got working code for each of the exploratory steps that I want to perform, I can combine them into a function.\n• Write the function definition using the format with empty parentheses (no parameters) to start with. Make sure to put a colon at the end.\n• Add an empty multiline string using a set of triple quotes ( ), as a placeholder for your docstring. We’ll come back to this later.\n• Add to the end of your function body as a placeholder for the eventual stopping point. The keyword is how we indicate the point at which the function will terminate and code execution will continue at the point where the function was originally called. Optionally, the function can pass a return variable or value back to the calling code, usually representing the fruits of its labor. We’re setting the output equal to for now, and you can come back and update it later.\n\nIt’s not mandatory for functions to explicitly return a value. In this example, we could easily just print all the visualizations and statistics so we can read through them, and may not be interested in having our function actually return anything else. If you don’t include a statement at all, will be implicit. I recommend including as a placeholder to remind you to think carefully whether there is something you might want to return. If not, you can just leave as-is or remove it with no change in functionality. Also, keep in mind that you can have multiple statements if your function returns different values, or terminates from different branches of the logic tree depending the circumstances.\n\n3. Copy your code into the function body\n• Starting now, and continuing as you modify the function, be sure to add descriptive comments so you can easily skim through and find which tasks each section of code performs. You’ll be glad you did when you return to a function you wrote weeks or months ago and need to remember how it works to make an update! Just put a at the beginning of each comment line.\n• Remember that in Python, groups of statements like loops and functions need to be indented, and the indentation in the statements you coded separately may need to be adjusted.\n\nIt’s generally recommended to use a consistent number of spaces (2 or 4 spaces are common) instead of tab characters to indent code blocks. Tab characters may be interpreted in different ways, and mixing them with spaces for indentation will cause issues with code execution. If you’re working in a Jupyter Notebook, you can use for indentation and by default it will automatically be converted to 4 spaces (you can also customize this setting). Jupyter Notebook will also maintain the appropriate level of indentation when you hit enter when writing within a block of code. This is great, since it keeps your code consistent and runnable outside Jupyter Notebooks, but still allows you to use shortcuts to save time. You can select multiple lines of code and and use to indent the whole group one level, or to de-indent the whole group by one level. The ability to use these shortcuts to indent or un-indent multiple lines of code at once is very useful when assembling code you wrote outside a function, and adding loops as your function becomes more complex.\n\nParameters are the values a function expects as inputs. They may represent variables to be updated or transformed, values to be used in calculations, or options indicating which tasks the function should or shouldn’t perform. Selecting which variables in the body of the function should be parameterized is key to having a flexible function that can be easily reused with varying inputs.\n\nWhen considering which variables should be parameterized in your first draft, ask yourself:\n• What will definitely change each time I run this? These should definitely become parameters.\n• Is there anything I’ve hard-coded in my first draft that I might want to adjust in the future? These could become parameters up front, or you could also just assign values to variables at the top of the function, so you can easily assign them from parameters later.\n\nIn our example, I’m using predictor and target columns stored in a Pandas dataframe, and if I want to use this function on a different dataframe then I’ll definitely want that to be passed in. I also want to be able to explore a custom subset of predictor columns that will change each time I run the function, so I’ll create a parameter for the list of predictor column names. And finally, although for this project my target will always be , I want to use the function for future projects where the target will be named something else, so I should have a parameter for that too.\n• Add each parameter to the function definition, inside the parentheses. The names will be used not only to refer to that variable in the body of the function, but also as the keyword argument names when the function is called.\n• Choose parameter names that aren’t too long, and will naturally bring to mind what they stand for. Shorter names will be easy to refer to throughout the function body and easier to refer to when calling the function.\n• Use the same rules for naming parameters as for naming functions (all lower-case, with underscores to separate words).\n• If there is a variable or value you’re using like a constant for now but think you might want to adjust later, add it as default parameter so you don’t have to specify it as an argument every time you call the function. To make a default parameter, assign a value to it in the function definition using the equals sign.\n\nAny parameter not assigned a value in the definition (non-default) will be considered required. In , and are both required because we haven’t assigned any values to them. If we tried to call this function with only one argument (such as ), we would get an error. If you assign default values to parameters, they will be optional to include as arguments when the function is called. Default parameters that are assigned values are usually placed at the end of the parameter list. If we had the function , would be optional when the function is called because it has been assigned the default value of . We would only need to provide an argument for so calling this like will work fine assuming we’re OK with having the default value of . However, we do still have the option to specify a value other than the default for if we want to, such as ( ). Using default parameters helps simplify calling a function, since fewer arguments need to be passed and someone calling the function doesn’t need to understand every single argument in order to get started. But for less common or more advanced functionality, the optional argument values still can be easily customized.\n• Remember to keep things simple to start with and add more complexity and flexibility as needed. Start with just parameterizing what is obvious and necessary and don’t “boil the ocean” trying to think of every option you might ever want to specify.\n\nOnce you’ve decided which variables should be parameterized and chosen names for them, go through the function body be sure to replace the hard-coded values or previous variable names with the new parameters.\n\n5. Code your return value (or not)\n\nIf your function was naturally designed to output a calculated value or object, just use this step to make sure you’re returning whatever that is at the end of the function. Replace the initial placeholder with your final variable or expression.\n\nIf you’re building a function to print graphs or a report like in our example, consider whether returning a dictionary or dataframe of some of the information might also be helpful. In our example, the primary goal is to print visualizations and descriptive statistics of different predictors, but we’re also performing a normality test and calculating the Pearson correlation coefficient. Right now, we’re printing that information along with the graphs, but if I had a large number of columns I might want to compile the results in one place so I could filter or sort it instead of reading back through a bunch of printed statements.\n\nFor this example, I decided to add a few lines of code to compile some of the statistics and test result in a list of lists, and then convert that list to a dataframe that will be returned.\n\nNow that we have the basics of our function coded, it’s time to test out the function and make sure it’s working as expected.\n\nIt’s easier to to troubleshoot problems if you have a shorter list of things you’ve changed since it last worked.\n• If you’re working in a Jupyter Notebook, make sure to execute the cell containing the function to load up its most recent version.\n• If your function returns a value, don’t forget to set a variable equal to the output of the function when you call it, so you can capture the output.\n\nSuccess! In addition to the graphs and printouts that I had coded earlier, now I also get a dataframe with a bunch of the statistics I calculated for each column, so I can easily review them without scrolling back through the graphs.\n\nA note about the different ways you can pass arguments when calling a function:\n\nWhen you pass arguments to a function, you can do so by keywords, or by position. Passing arguments using keywords means that you include the parameter name as well as the value or variable, using an equals sign to connect the argument value with the proper function parameter. Here’s an example of passing arguments by keywords: The benefit of using keywords include: - It’s easy to tell which value each argument is being passed to - The keyword arguments can be in any order, since the argument names are specified If you pass arguments positionally, you don’t include the names, but you must pass them in the order in which they occurred in the function definition. Without the keywords, the compiler relies on the order to match up the argument values with the function parameters. I generally recommend passing arguments using keywords because I think it makes code more readable and I like the flexibility of being able to pass them in any order (makes it easier to add another argument to the end of the list, if needed). But ultimately it’s up to you!\n\n7. Add a docstring (even just a basic one)\n\nA docstring is a block of text that you add as the very first thing after the function definition. Docstrings explains what the function does, what arguments it takes, and what it outputs, and can also include other helpful info such as code examples. They’re an easy way for the author of the function, who is the expert on what it does and how it works, to provide built-in instructions to anyone who might want to use it.\n\nIn a Jupyter Notebook, you can show the docstring for a built-in Python function by typing the name of the function, then the opening parentheses, then on your keyboard. This initially shows the beginning of the docstring, but you can click the button to show a deeper pop-up, or the button to open a separate container on the bottom of the notebook that is easier to scroll through.\n\nThe function signature (the names of the arguments and the order in which they occur) is automatically pulled up when you summon the docstring even if you haven’t added anything manually, but without any further explanation it would be difficult for anyone else to know what the function does. Even future-you who may want to use this function a few months from now will appreciate a reminder on what it does and what to pass as each argument!\n\nYou don’t have to write a novel, but I highly recommend creating a docstring in your first draft that includes at least these basics:\n• A brief summary of what the function does\n• A list of the parameters/arguments including name, data type(s) accepted, whether it’s optional or required, and brief description of what the value or object should represent\n• A description of what the function returns, if anything\n• If there is anything you specifically know your function does NOT support yet, include that information as well\n\nSee the PEP docstring conventions here for more best practices.\n\nAt this point we’ve made a basic function for exploring data by showing visualizations and statistics and running a normality test. I’ve tested it on a few of my predictor columns, and confirmed it works.\n\nI initially developed this example function using just two predictor columns, both of which were continuous numeric variables. The method proved useful, and I gained valuable insight into these types of variables by plotting a histogram, boxplot, and scatterplot against the target. But if I also have categorical variables or binary variables, I probably need to use other methods to understand the distribution of the values and how they relate to the target.\n\nBy keeping my first draft simple I was able to get a working and useful function up and running fairly quickly, but at the cost of having a fairly narrow scope that may not work on future data sets.\n\nIn real life, I went back and updated the initial function a whole bunch of times to incorporate support for different types of data I encountered, and make the output more flexible. Here’s a list of some of the things I eventually updated, so you can get a sense for just how much more I added after the first draft:\n• Added logic to evaluate what type of data was in each column (continuous or categorical) based partly on column type in the dataframe but also on the number of unique values\n• Depending on data type, generated different types of graphs and statistics ( instead of ) for what the function judged were categorical.\n• Added parameters for each type of chart to allow them to be turned off, which involved having to make the number of axes in the figure be calculated dynamically\n• Added dynamic sizing for the matplotlib figure to allow the barplot for categorical variables to show all values even if they had high cardinality\n\nIt did take some work, but I ended up with a robust function that can handle lots of different types of data, and that I can easily reuse in many data science projects to come!\n\nThe approach of starting simple and building iteratively means you don’t have to get overwhelmed trying to think of every exception or scenario in the beginning: start with the basics and let your own usage of the first draft guide what you add in the second draft and beyond."
    },
    {
        "link": "https://realpython.com/python-async-features",
        "document": "Have you heard of asynchronous programming in Python? Are you curious to know more about Python async features and how you can use them in your work? Perhaps you’ve even tried to write threaded programs and run into some issues. If you’re looking to understand how to use Python async features, then you’ve come to the right place.\n• What an asynchronous program is\n• Why you might want to write an asynchronous program\n• How to use Python async features\n\nAll of the example code in this article have been tested with Python 3.7.2. You can grab a copy to follow along by clicking the link below:\n\nA synchronous program is executed one step at a time. Even with conditional branching, loops and function calls, you can still think about the code in terms of taking one execution step at a time. When each step is complete, the program moves on to the next one. Here are two examples of programs that work this way:\n• Batch processing programs are often created as synchronous programs. You get some input, process it, and create some output. Steps follow one after the other until the program reaches the desired output. The program only needs to pay attention to the steps and their order.\n• Command-line programs are small, quick processes that run in a terminal. These scripts are used to create something, transform one thing into something else, generate a report, or perhaps list out some data. This can be expressed as a series of program steps that are executed sequentially until the program is done. An asynchronous program behaves differently. It still takes one execution step at a time. The difference is that the system may not wait for an execution step to be completed before moving on to the next one. This means that the program will move on to future execution steps even though a previous step hasn’t yet finished and is still running elsewhere. This also means that the program knows what to do when a previous step does finish running. Why would you want to write a program in this manner? The rest of this article will help you answer that question and give you the tools you need to elegantly solve interesting asynchronous problems. A web server’s basic unit of work is, more or less, the same as batch processing. The server will get some input, process it, and create the output. Written as a synchronous program, this would create a working web server. It would also be an absolutely terrible web server. Why? In this case, one unit of work (input, process, output) is not the only purpose. The real purpose is to handle hundreds or even thousands of units of work as quickly as possible. This can happen over long periods of time, and several work units may even arrive all at once. Can a synchronous web server be made better? Sure, you could optimize the execution steps so that all the work coming in is handled as quickly as possible. Unfortunately, there are limitations to this approach. The result could be a web server that doesn’t respond fast enough, can’t handle enough work, or even one that times out when work gets stacked up. Note: There are other limitations you might see if you tried to optimize the above approach. These include network speed, file IO speed, database query speed, and the speed of other connected services, to name a few. What these all have in common is that they are all IO functions. All of these items are orders of magnitude slower than the CPU’s processing speed. In a synchronous program, if an execution step starts a database query, then the CPU is essentially idle until the database query is returned. For batch-oriented programs, this isn’t a priority most of the time. Processing the results of that IO operation is the goal. Often, this can take longer than the IO operation itself. Any optimization efforts would be focused on the processing work, not the IO. Asynchronous programming techniques allow your programs to take advantage of relatively slow IO processes by freeing the CPU to do other work. When you start trying to understand asynchronous programming, you might see a lot of discussion about the importance of blocking, or writing non-blocking code. (Personally, I struggled to get a good grasp of these concepts from the people I asked and the documentation I read.) What is non-blocking code? What’s blocking code, for that matter? Would the answers to these questions help you write a better web server? If so, how could you do it? Let’s find out! Writing asynchronous programs requires that you think differently about programming. While this new way of thinking can be hard to wrap your head around, it’s also an interesting exercise. That’s because the real world is almost entirely asynchronous, and so is how you interact with it. Imagine this: you’re a parent trying to do several things at once. You have to balance the checkbook, do the laundry, and keep an eye on the kids. Somehow, you’re able to do all of these things at the same time without even thinking about it! Let’s break it down:\n• Balancing the checkbook is a synchronous task. One step follows another until it’s done. You’re doing all the work yourself.\n• However, you can break away from the checkbook to do laundry. You unload the dryer, move clothes from the washer to the dryer, and start another load in the washer.\n• Working with the washer and dryer is a synchronous task, but the bulk of the work happens after the washer and dryer are started. Once you’ve got them going, you can walk away and get back to the checkbook task. At this point, the washer and dryer tasks have become asynchronous. The washer and dryer will run independently until the buzzer goes off (notifying you that the task needs attention).\n• Watching your kids is another asynchronous task. Once they are set up and playing, they can do so independently for the most part. This changes when someone needs attention, like when someone gets hungry or hurt. When one of your kids yells in alarm, you react. The kids are a long-running task with high priority. Watching them supersedes any other tasks you might be doing, like the checkbook or laundry. These examples can help to illustrate the concepts of blocking and non-blocking code. Let’s think about this in programming terms. In this example, you’re like the CPU. While you’re moving the laundry around, you (the CPU) are busy and blocked from doing other work, like balancing the checkbook. But that’s okay because the task is relatively quick. On the other hand, starting the washer and dryer does not block you from performing other tasks. It’s an asynchronous function because you don’t have to wait for it to finish. Once it’s started, you can go back to something else. This is called a context switch: the context of what you’re doing has changed, and the machine’s buzzer will notify you sometime in the future when the laundry task is complete. As a human, this is how you work all the time. You naturally juggle multiple things at once, often without thinking about it. As a developer, the trick is how to translate this kind of behavior into code that does the same kind of thing.\n\nProgramming Parents: Not as Easy as It Looks! If you recognize yourself (or your parents) in the example above, then that’s great! You’ve got a leg up in understanding asynchronous programming. Again, you’re able to switch contexts between competing tasks fairly easily, picking up some tasks and resuming others. Now you’re going to try and program this behavior into virtual parents! How would you create a parent program to do the above tasks in a completely synchronous manner? Since watching the kids is a high-priority task, perhaps your program would do just that. The parent watches over the kids while waiting for something to happen that might need their attention. However, nothing else (like the checkbook or laundry) would get done in this scenario. Now, you can re-prioritize the tasks any way you want, but only one of them would happen at any given time. This is the result of a synchronous, step-by-step approach. Like the synchronous web server described above, this would work, but it might not be the best way to live. The parent wouldn’t be able to complete any other tasks until the kids fell asleep. All other tasks would happen afterward, well into the night. (A couple of weeks of this and many real parents might jump out the window!) If you used polling, then you could change things up so that multiple tasks are completed. In this approach, the parent would periodically break away from the current task and check to see if any other tasks need attention. Let’s make the polling interval something like fifteen minutes. Now, every fifteen minutes your parent checks to see if the washer, dryer or kids need any attention. If not, then the parent can go back to work on the checkbook. However, if any of those tasks do need attention, then the parent will take care of it before going back to the checkbook. This cycle continues on until the next timeout out of the polling loop. This approach works as well since multiple tasks are getting attention. However, there are a couple of problems:\n• The parent may spend a lot of time checking on things that don’t need attention: The washer and dryer haven’t yet finished, and the kids don’t need any attention unless something unexpected happens.\n• The parent may miss completed tasks that do need attention: For instance, if the washer finished its cycle at the beginning of the polling interval, then it wouldn’t get any attention for up to fifteen minutes! What’s more, watching the kids is supposedly the highest priority task. They couldn’t tolerate fifteen minutes with no attention when something might be going drastically wrong. You could address these issues by shortening the polling interval, but now your parent (the CPU) would be spending more time context switching between tasks. This is when you start to hit a point of diminishing returns. (Once again, a couple of weeks living like this and, well… See the previous comment about windows and jumping.) “If I could only clone myself…” If you’re a parent, then you’ve probably had similar thoughts! Since you’re programming virtual parents, you can essentially do this by using threading. This is a mechanism that allows multiple sections of one program to run at the same time. Each section of code that runs independently is known as a thread, and all threads share the same memory space. If you think of each task as a part of one program, then you can separate them and run them as threads. In other words, you can “clone” the parent, creating one instance for each task: watching the kids, monitoring the washer, monitoring the dryer, and balancing the checkbook. All of these “clones” are running independently. This sounds like a pretty nice solution, but there are some issues here as well. One is that you’ll have to explicitly tell each parent instance what to do in your program. This can lead to some problems since all instances share everything in the program space. For example, say that Parent A is monitoring the dryer. Parent A sees that the clothes are dry, so they take control of the dryer and begin unloading the clothes. At the same time, Parent B sees that the washer is done, so they take control of the washer and begin removing clothes. However, Parent B also needs to take control of the dryer so they can put the wet clothes inside. This can’t happen, because Parent A currently has control of the dryer. After a short while, Parent A has finished unloading clothes. Now they want to take control of the washer and start moving clothes into the empty dryer. This can’t happen, either, because Parent B currently has control of the washer! These two parents are now deadlocked. Both have control of their own resource and want control of the other resource. They’ll wait forever for the other parent instance to release control. As the programmer, you’d have to write code to work this situation out. Note: Threaded programs allow you to create multiple, parallel paths of execution that all share the same memory space. This is both an advantage and a disadvantage. Any memory shared between threads is subject to one or more threads trying to use the same shared memory at the same time. This can lead to data corruption, data read in an invalid state, and data that’s just messy in general. In threaded programming, the context switch happens under system control, not the programmer. The system controls when to switch contexts and when to give threads access to shared data, thereby changing the context of how the memory is being used. All of these kinds of problems are manageable in threaded code, but it’s difficult to get right, and hard to debug when it’s wrong. Here’s another issue that might arise from threading. Suppose that a child gets hurt and needs to be taken to urgent care. Parent C has been assigned the task of watching over the kids, so they take the child right away. At the urgent care, Parent C needs to write a fairly large check to cover the cost of seeing the doctor. Meanwhile, Parent D is at home working on the checkbook. They’re unaware of this large check being written, so they’re very surprised when the family checking account is suddenly overdrawn! Remember, these two parent instances are working within the same program. The family checking account is a shared resource, so you’d have to work out a way for the child-watching parent to inform the checkbook-balancing parent. Otherwise, you’d need to provide some kind of locking mechanism so that the checkbook resource can only be used by one parent at a time, with updates.\n\nNow you’re going to take some of the approaches outlined in the thought experiments above and turn them into functioning Python programs. All of the examples in this article have been tested with Python 3.7.2. The file indicates which modules you’ll need to install to run all the examples. If you haven’t yet downloaded the file, you can do so now: Download Code: Click here to download the code you’ll use to learn about async features in Python in this tutorial. You also might want to set up a Python virtual environment to run the code so you don’t interfere with your system Python. This first example shows a somewhat contrived way of having a task retrieve work from a queue and process that work. A queue in Python is a nice FIFO (first in first out) data structure. It provides methods to put things in a queue and take them out again in the order they were inserted. In this case, the work is to get a number from the queue and have a loop count up to that number. It prints to the console when the loop begins, and again to output the total. This program demonstrates one way for multiple synchronous tasks to process the work in a queue. The program named in the repository is listed in full below: This is the main entry point for the program # Put some work in the queue Let’s take a look at what each line does:\n• Line 1 imports the module. This is where the program stores work to be done by the tasks.\n• Lines 3 to 13 define . This function pulls work out of and processes the work until there isn’t any more to do.\n• Line 20 creates the . All tasks use this shared resource to retrieve work.\n• Lines 23 to 24 put work in . In this case, it’s just a random count of values for the tasks to process.\n• Line 27 creates a list of task tuples, with the parameter values those tasks will be passed.\n• Lines 30 to 31 iterate over the list of task tuples, calling each one and passing the previously defined parameter values. The task in this program is just a function accepting a string and a queue as parameters. When executed, it looks for anything in the queue to process. If there is work to do, then it pulls values off the queue, starts a loop to count up to that value, and outputs the total at the end. It continues getting work off the queue until there is nothing left and it exits. When this program is run, it produces the output you see below: This shows that does all the work. The loop that hits within consumes all the work on the queue and processes it. When that loop exits, gets a chance to run. However, it finds that the queue is empty, so prints a statement that says it has nothing to do and then exits. There’s nothing in the code to allow both and to switch contexts and work together. The next version of the program allows the two tasks to work together. Adding a statement means the loop will yield control at the specified point while still maintaining its context. This way, the yielding task can be restarted later. The statement turns into a generator. A generator function is called just like any other function in Python, but when the statement is executed, control is returned to the caller of the function. This is essentially a context switch, as control moves from the generator function to the caller. The interesting part is that control can be given back to the generator function by calling on the generator. This is a context switch back to the generator function, which picks up execution with all function variables that were defined before the still intact. The loop in takes advantage of this when it calls . This statement restarts the task at the point where it previously yielded. All of this means that you’re in control when the context switch happens: when the statement is executed in . This is a form of cooperative multitasking. The program is yielding control of its current context so that something else can run. In this case, it allows the loop in to run two instances of as a generator function. Each instance consumes work from the same queue. This is sort of clever, but it’s also a lot of work to get the same results as the first program. The program demonstrates this simple concurrency and is listed below: This is the main entry point for the program # Put some work in the queue Here’s what’s happening in the code above:\n• Lines 3 to 11 define as before, but the addition of on Line 10 turns the function into a generator. This where the context switch is made and control is handed back to the loop in .\n• Line 25 creates the task list, but in a slightly different manner than you saw in the previous example code. In this case, each task is called with its parameters as its entered in the list variable. This is necessary to get the generator function running the first time.\n• Lines 31 to 36 are the modifications to the loop in that allow to run cooperatively. This is where control returns to each instance of when it yields, allowing the loop to continue and run another task.\n• Line 32 gives control back to , and continues its execution after the point where was called.\n• Line 36 sets the variable. The loop ends when all tasks have been completed and removed from . This is the output produced when you run this program: You can see that both and are running and consuming work from the queue. This is what’s intended, as both tasks are processing work, and each is responsible for two items in the queue. This is interesting, but again, it takes quite a bit of work to achieve these results. The trick here is using the statement, which turns into a generator and performs a context switch. The program uses this context switch to give control to the loop in , allowing two instances of a task to run cooperatively. Notice how outputs its total first. This might lead you to think that the tasks are running asynchronously. However, this is still a synchronous program. It’s structured so the two tasks can trade contexts back and forth. The reason why outputs its total first is that it’s only counting to 10, while is counting to 15. simply arrives at its total first, so it gets to print its output to the console before . Note: All of the example code that follows from this point use a module called codetiming to time and output how long sections of code took to execute. There is a great article here on RealPython that goes into depth about the codetiming module and how to use it. This module is part of the Python Package Index and is built by Geir Arne Hjelle, who is part of the Real Python team. Geir Arne has been a great help to me reviewing and suggesting things for this article. If you are writing code that needs to include timing functionality, Geir Arne’s codetiming module is well worth looking at. To make the codetiming module available for the examples that follow you’ll need to install it. This can be done with with this command: , or with this command: . The file is part of the example code repository. The next version of the program is the same as the last, except for the addition of a in the body of your task loop. This adds a delay based on the value retrieved from the work queue to every iteration of the task loop. The delay simulates the effect of a blocking call occurring in your task. A blocking call is code that stops the CPU from doing anything else for some period of time. In the thought experiments above, if a parent wasn’t able to break away from balancing the checkbook until it was complete, that would be a blocking call. does the same thing in this example, because the CPU can’t do anything else but wait for the delay to expire. This is the main entry point for the program # Put some work in the queue Here’s what’s different in the code above:\n• Line 1 imports the module to give the program access to .\n• Line 3 imports the the code from the module.\n• Line 6 creates the instance used to measure the time taken for each iteration of the task loop.\n• Line 11 changes to include a to mimic an IO delay. This replaces the loop that did the counting in .\n• Line 12 stops the instance and outputs the elapsed time since was called.\n• Line 30 creates a context manager that will output the elapsed time the entire while loop took to execute. When you run this program, you’ll see the following output: As before, both and are running, consuming work from the queue and processing it. However, even with the addition of the delay, you can see that cooperative concurrency hasn’t gotten you anything. The delay stops the processing of the entire program, and the CPU just waits for the IO delay to be over. This is exactly what’s meant by blocking code in Python async documentation. You’ll notice that the time it takes to run the entire program is just the cumulative time of all the delays. Running tasks this way is not a win. The next version of the program has been modified quite a bit. It makes use of Python async features using asyncio/await provided in Python 3. The and modules have been replaced with the package. This gives your program access to asynchronous friendly (non-blocking) sleep and queue functionality. The change to defines it as asynchronous with the addition of the prefix on line 4. This indicates to Python that the function will be asynchronous. The other big change is removing the and statements, and replacing them with . This creates a non-blocking delay that will perform a context switch back to the caller . The loop inside no longer exists. Instead of , there’s a call to . This tells two things:\n• Create two tasks based on and start running them.\n• Wait for both of these to be completed before moving forward. The last line of the program runs . This creates what’s known as an event loop). It’s this loop that will run , which in turn will run the two instances of . The event loop is at the heart of the Python async system. It runs all the code, including . When task code is executing, the CPU is busy doing work. When the keyword is reached, a context switch occurs, and control passes back to the event loop. The event loop looks at all the tasks waiting for an event (in this case, an timeout) and passes control to a task with an event that’s ready. is non-blocking in regards to the CPU. Instead of waiting for the delay to timeout, the CPU registers a sleep event on the event loop task queue and performs a context switch by passing control to the event loop. The event loop continuously looks for completed events and passes control back to the task waiting for that event. In this way, the CPU can stay busy if work is available, while the event loop monitors the events that will happen in the future. Note: An asynchronous program runs in a single thread of execution. The context switch from one section of code to another that would affect data is completely in your control. This means you can atomize and complete all shared memory data access before making a context switch. This simplifies the shared memory problem inherent in threaded code. The code is listed below: This is the main entry point for the program # Put some work in the queue Here’s what’s different between this program and :\n• Line 1 imports to gain access to Python async functionality. This replaces the import.\n• Line 2 imports the the code from the module.\n• Line 4 shows the addition of the keyword in front of the definition. This informs the program that can run asynchronously.\n• Line 5 creates the instance used to measure the time taken for each iteration of the task loop.\n• Line 10 replaces with the non-blocking , which also yields control (or switches contexts) back to the main event loop.\n• Line 11 stops the instance and outputs the elapsed time since was called.\n• Lines 21 to 22 put work into in an asynchronous manner using the keyword.\n• Line 25 creates a context manager that will output the elapsed time the entire while loop took to execute.\n• Lines 26 to 29 create the two tasks and gather them together, so the program will wait for both tasks to complete.\n• Line 32 starts the program running asynchronously. It also starts the internal event loop. When you look at the output of this program, notice how both and start at the same time, then wait at the mock IO call: This indicates that is non-blocking, and that other work is being done. At the end of the program, you’ll notice the total elapsed time is essentially half the time it took for to run. That’s the advantage of a program that uses Python async features! Each task was able to run at the same time. The total execution time of the program is now less than the sum of its parts. You’ve broken away from the synchronous model! The next version of the program is kind of a step forward as well as a step back. The program is doing some actual work with real IO by making HTTP requests to a list of URLs and getting the page contents. However, it’s doing so in a blocking (synchronous) manner. The program has been modified to import the wonderful module to make the actual HTTP requests. Also, the queue now contains a list of URLs, rather than numbers. In addition, no longer increments a counter. Instead, gets the contents of a URL retrieved from the queue, and prints how long it took to do so. The code is listed below: This is the main entry point for the program # Put some work in the queue\n• Line 2 imports , which provides a convenient way to make HTTP calls.\n• Line 3 imports the the code from the module.\n• Line 6 creates the instance used to measure the time taken for each iteration of the task loop.\n• Line 12 introduces a delay, similar to . However, this time it calls , which returns the contents of the URL retrieved from .\n• Line 13 stops the instance and outputs the elapsed time since was called.\n• Lines 23 to 32 put the list of URLs into .\n• Line 39 creates a context manager that will output the elapsed time the entire while loop took to execute. When you run this program, you’ll see the following output: Just like in earlier versions of the program, turns into a generator. It also performs a context switch that lets the other task instance run. Each task gets a URL from the work queue, retrieves the contents of the page, and reports how long it took to get that content. As before, allows both your tasks to run cooperatively. However, since this program is running synchronously, each call blocks the CPU until the page is retrieved. Note the total time it took to run the entire program at the end. This will be meaningful for the next example. This version of the program modifies the previous one to use Python async features. It also imports the module, which is a library to make HTTP requests in an asynchronous fashion using . The tasks here have been modified to remove the call since the code to make the HTTP call is no longer blocking. It also performs a context switch back to the event loop. The program is listed below: This is the main entry point for the program # Put some work in the queue\n• Line 2 imports the library, which provides an asynchronous way to make HTTP calls.\n• Line 3 imports the the code from the module.\n• Line 6 creates the instance used to measure the time taken for each iteration of the task loop.\n• Line 8 creates an response context manager. It also makes an HTTP call to the URL taken from .\n• Line 12 uses the session to get the text retrieved from the URL asynchronously.\n• Line 13 stops the instance and outputs the elapsed time since was called.\n• Line 39 creates a context manager that will output the elapsed time the entire while loop took to execute. When you run this program, you’ll see the following output: Take a look at the total elapsed time, as well as the individual times to get the contents of each URL. You’ll see that the duration is about half the cumulative time of all the HTTP calls. This is because the HTTP calls are running asynchronously. In other words, you’re effectively taking better advantage of the CPU by allowing it to make multiple requests at once. Because the CPU is so fast, this example could likely create as many tasks as there are URLs. In this case, the program’s run time would be that of the single slowest URL retrieval.\n\nThis article has given you the tools you need to start making asynchronous programming techniques a part of your repertoire. Using Python async features gives you programmatic control of when context switches take place. This means that many of the tougher issues you might see in threaded programming are easier to deal with. Asynchronous programming is a powerful tool, but it isn’t useful for every kind of program. If you’re writing a program that calculates pi to the millionth decimal place, for instance, then asynchronous code won’t help you. That kind of program is CPU bound, without much IO. However, if you’re trying to implement a server or a program that performs IO (like file or network access), then using Python async features could make a huge difference. To sum it up, you’ve learned:\n• How asynchronous programs are different, but also powerful and manageable\n• Why you might want to write asynchronous programs\n• How to use the built-in async features in Python You can get the code for all of the example programs used in this tutorial: Download Code: Click here to download the code you’ll use to learn about async features in Python in this tutorial. Now that you’re equipped with these powerful skills, you can take your programs to the next level! Test your knowledge with our interactive “Getting Started With Async Features in Python” quiz. You’ll receive a score upon completion to help you track your learning progress: Getting Started With Async Features in Python In this quiz, you'll test your understanding of asynchronous programming in Python. You'll revisit the concepts of synchronous and asynchronous programs, and why you might want to write an asynchronous program. You'll also test your knowledge on how to use Python async features."
    },
    {
        "link": "https://medium.com/simform-engineering/asynchronous-programming-in-python-9ed85d5ed8a1",
        "document": "Unlocking the Power of Asynchronous Programming in Python\n\nAre you tired of writing synchronous code in Python that blocks your application’s performance while waiting for I/O operations to complete? Then it’s time to switch to asynchronous programming.\n\nIn the ever-evolving world of programming, efficiency and performance are key factors that developers constantly strive to optimize. Asynchronous programming has emerged as a powerful technique to enhance the responsiveness and scalability of applications. This article aims to provide a comprehensive guide to asynchronous programming in Python, exploring its benefits, implementation, and best practices.\n\nIn synchronous programming, tasks are carried out one after another in a specific order. However, asynchronous programming takes a different approach, allowing tasks to run in parallel. This means that independent tasks can be executed alongside the main operation, providing results once completed.\n\nWith asynchronous programming, a program can become faster and more responsive. Information can be presented to the user as it is processed, preventing any unresponsiveness and delivering a smoother user experience.\n\nOne of the key benefits of asynchronous programming is better error handling. If an operation running in a separate thread fails for some reason, you can handle that error or anomaly without shutting down the entire project.\n\nOffloading tasks to different threads also enables you to easily add new features or scale up your processing power to handle more requests. This scalability makes asynchronous programming valuable for enhancing processing power and accommodating growth.\n\nThe differences between asynchronous and Synchronous programming models include:\n• The asynchronous model is multi-threaded, which means operations or programs can run in parallel. On the other hand, the Synchronous model is single-threaded, so only one operation or program will run at a time.\n• Asynchronous is non-blocking, which means it can send multiple requests to a server simultaneously. Synchronous is blocking — it sends the server only one request at a time and waits for that request to be answered by the server.\n• Asynchronous increases throughput because multiple operations can run at the same time. Synchronous is slower and more methodical.\n• Asynchronous and Synchronous methods benefit different stakeholders: Asynchronous benefits users, while Synchronous benefits developers.\n\nSynchronous programming is ideal for scenarios where you need to focus on a single task, especially if it’s computationally heavy or highly dependent on another task that can’t be run in parallel. Let’s take a look at a couple of examples:\n• Web Pages: When you load a web page synchronously, it actually helps search engines find and categorize your page’s content more easily. It ensures that everything is processed in a specific order, making it simpler for search engines to understand and index your page.\n• Video Rendering: Now, video rendering is a task that requires a lot of CPU power. If you were to run other tasks in parallel with video rendering, it would put an excessive load on the CPU, potentially leading to performance issues. By handling video rendering synchronously, you can allocate the necessary resources and ensure that it receives the full attention of the CPU for optimal processing.\n\nAsynchronous programming comes into play when you have multiple tasks that are independent of each other or when certain tasks require significant time and can be run in the background. Here are a couple of examples:\n• Database Manipulation: Large databases are notorious for the long time queries take when trying to retrieve information from them. By using separate threads for these queries, you can let the rest of your application keep functioning while waiting for the results. This way, you avoid blocking the user interface or interrupting other important processes.\n• Dashboards: Imagine having a complex dashboard with an abundance of information to present. To ensure a seamless user experience, you can employ different threads to keep each part of the dashboard updated in real-time or as the system can handle it. This allows the user to interact with the dashboard smoothly, even when there are multiple data sources and frequent updates happening in the background.\n\nAsyncio is a library that provides tools for asynchronous programming in Python. It works by using coroutines, which are functions that can be paused and resumed at specific points in the code. This allows the program to switch between multiple tasks without blocking the main thread.\n\nWhen a coroutine encounters an I/O operation, such as fetching data from a web API, it intelligently pauses itself and allows other coroutines to run. Once the I/O operation is complete, the coroutine resumes execution from where it left off.\n\n1) Coroutines: In Python, coroutines are functions that can be paused and resumed, allowing other code to be executed in between. They are defined using the keyword, and can be called using the keyword.\n\n2) Tasks: A task is a wrapper around a coroutine that is used to schedule and manage the coroutine’s execution. In Asyncio, tasks are created using the function.\n\n3) Event Loops: An event loop is a central scheduler that manages coroutines and other asynchronous tasks. In Asyncio, the event loop is created using the function.\n\nExecutors offer a powerful abstraction that simplifies the management and control of concurrent tasks in Python. By utilizing an executor, you can effortlessly organize and schedule the execution of a set of tasks in a concurrent manner. It abstracts away the complexity of managing threads or processes, making it easier to write concurrent code.\n\nThere are two main types of executors in Python: and . The former is used to run tasks in a thread pool, while the latter is used to run tasks in a process pool. Both types of executors provide a similar interface, and you can choose the one that best suits your needs.\n\nThe Executor class defines three methods used to control our pool; they are: submit(), map(), and shutdown().\n• submit(): Dispatch a function to be executed and return a future object.\n• map(): Apply a function to an iterable of elements.\n\nThread Pool Executor is a mechanism that allows for the execution of tasks in a thread pool. It is a way to manage a collection of threads that can be reused to execute multiple tasks. Thread Pool Executors are commonly used in programming languages like Java and C++, and they have recently become available in Python as well.\n\nThread Pool Executors allow you to execute a set of tasks in a thread pool and return the results when they are ready. They provide a way to manage the number of threads that are being used and ensure that tasks are executed in an efficient manner. This is especially useful in applications where tasks take a long time to complete, as it allows other tasks to continue to be executed in the meantime.\n• max_workers: It is a number of Threads (the size of a pool). Python 3.8 onwards, the default value is min(32, os.cpu_count() + 4). Out of these, 5 threads are preserved for I/O bound tasks.\n• thread_name_prefix: thread_name_prefix was added from Python 3.6 onwards to give names to threads for easier debugging purposes.\n• initializer: initializer takes a callable, which is invoked at the start of each worker thread.\n• initargs: It’s a tuple of arguments passed to the initializer.\n\nIf you are dealing with tasks that require heavy computing power, then you are most likely familiar with the limitations of a single-threaded application. A single-threaded application only utilizes one CPU core, which can be limiting for complex and time-consuming tasks. This is where the Process Pool Executor comes in.\n\nProcess Pool Executor is a module in Python’s concurrent.futures library that allows for the execution of tasks using multiple processes. It works by creating a pool of worker processes that can execute tasks in parallel. By utilizing multiple processes, Process Pool Executor can increase the efficiency of your code and reduce the time it takes to complete tasks.\n\nOther methods that are used in Process Pool Executor along with executor methods are:\n• – return the result from the asynchronous operation\n• – return an exception that occurred while running the asynchronous operation\n\nBest Practices for Asynchronous Programming in Python\n\nWhile asynchronous programming can provide many benefits, it can also be challenging to implement correctly. Here are some best practices for developers who want to use asynchronous programming in Python:\n\nPython offers several frameworks for asynchronous programming, such as Asyncio, Twisted, and Tornado. Developers should choose the framework that best suits their needs based on factors such as performance, ease of use, and compatibility with other tools.\n\nAsynchronous programming in Python relies on the event loop, which manages the execution of tasks. Developers should have a good understanding of how the event loop works and how to write code that interacts with it correctly.\n\nPython 3.5 introduced the async and await keywords, making writing Asynchronous code easier. Developers should use these keywords instead of callbacks or other techniques whenever possible.\n\nAsynchronous programming in Python relies heavily on non-blocking I/O. Developers should use libraries that support non-blocking IO, such as aiohttp, whenever possible.\n\nAsynchronous programming can make it challenging to manage shared states correctly. Developers should be careful when using shared states and use synchronization techniques such as locks or semaphores to ensure that data is accessed safely.\n\nIn conclusion, asynchronous programming in Python is a powerful tool to help developers create more efficient and scalable applications. By following best practices and using the right tools like Asyncio, and Excetuors, Pools, developers can harness the power of asynchronous programming to create applications that meet the needs of their users.\n\nThe choice of the tools totally depends on the requirements of the project. For example, if you need to carry out heavy computation work, it’s better to go with Process Pool Executors. Similarly, you can pick your set of rules based on the tasks you need to complete."
    },
    {
        "link": "https://stackoverflow.com/questions/63695151/how-to-pass-parameters-to-multiple-async-tasks-in-python",
        "document": "Right now I have some code that looks like this:\n\nAs you can see above, I have 3 async functions that do separate things simultaneously. I was wondering if theres any way to easily create many functions based off of user input? Essentially what I want to have it be able to do is this:\n\nAnd then once it had gotten that data it would run like this script:\n\nSo pretty much it would make functions based off of certain veriables (such as userinput1) and then do this however many times specified (amount_of_needed_functions) and then run all of these simultaneously. Sorry this is a bit of confusing question but I'm quite lost as where to start researching this. Thanks!"
    },
    {
        "link": "https://reddit.com/r/learnpython/comments/1f1if85/best_practices_for_calling_async_methods_many",
        "document": "I'm noob in the OOP so any tips and remarks will be highly appreciated.\n\nI'm trying to use the python library for the OneDrive API (msgraph), to read/write from/to Excel sheets.\n\nMy idea is to model the API calls as objects i.e. call to get the meta for an Excel document (like sheets ids, size, created date, author etc.) to be modeled as a single object, and call to read/write to that document as a second object - is enpoints modeled as objects a standard practice ?\n\nIn the second object (I called it Worksheet) I have a method that retrieves the worksheet id, which is an argument ultimately needed for any other method in that class\n\nCalling the same method in every other method feels weird. The other thig that I came up with was passing the worksheet_id as an argument and then in a separate file (main .py) calling it once storing it into a variable and then passing it to any other method that needs to be called, but this also feels a bit weird. I feel like I'm missing somethign fundamental here."
    },
    {
        "link": "https://medium.com/@moraneus/mastering-pythons-asyncio-a-practical-guide-0a673265cf04",
        "document": "When you dive into Python’s world, one gem that truly shines for handling modern web and network tasks is . This toolkit is Python's answer to writing clean, efficient, and scalable code for concurrent I/O operations. It might sound a bit intimidating at first, with its event loops, coroutines, and futures. But once you get the hang of it, you'll wonder how you ever lived without it. So, let's break it down, step by step, with examples and a peek at how things look on the other side of the async fence.\n\nBefore jumping into examples, it’s crucial to grasp the core concepts of :\n• Event Loop: The central execution device provided by . It manages and distributes the execution of different tasks. It's responsible for handling events and scheduling asynchronous routines.\n• Coroutines: Asynchronous functions declared with . These functions can be paused and resumed at await points, allowing I/O operations to run in the background.\n• Futures: Objects that represent the result of work that has not yet been completed. They are returned from tasks scheduled by the event loop.\n• Tasks: Scheduled coroutines that are wrapped into a Future object by the event loop, allowing their execution.\n\nFirst off, is all about writing code that can do multiple things at once, without actually doing them at the same time. It’s like having a chef in a kitchen who starts cooking a stew, and knows it’ll take time to simmer, so they begin prepping a salad instead of just standing around. This is the essence of async programming — keep moving efficiently without unnecessary waiting.\n\nThe keyword in Python is an essential part of asynchronous programming, introduced in Python 3.5. It is used to pause the execution of an function until an awaitable object (like coroutines, Tasks, Futures, or I/O) completes, allowing other tasks to run in the meantime. This key feature enables efficient handling of I/O-bound and high-level structured network code.\n• Context: can only be used inside functions. Attempting to use it outside such a context results in a syntax error.\n• Purpose: Its primary purpose is to yield control back to the event loop, suspending the execution of the enclosing coroutine until the awaited object is resolved. This non-blocking behavior is what makes asynchronous programming efficient, especially for I/O-bound tasks.\n• Awaitables: The objects that can be used with must be awaitable. The most common awaitables are coroutines declared with , but others include asyncio Tasks, Futures, or any object with an method.\n\nImagine you’re tasked with printing “Hello, World!” after a 2-second pause. The synchronous approach is straightforward:\n\nIt does the job, but everything comes to a halt while waiting for those 2 seconds.\n\nNow, let’s switch gears to , showing the asynchronous way:\n\nWith , while we wait, the event loop can do other tasks, like checking emails or playing a tune, making our code non-blocking and more efficient:\n\nIn this modified version, the function uses to run and concurrently. This means that while the program is waiting for the function to complete its 2-second sleep, it starts and potentially completes the function, effectively doing another task during the wait time.\n\nFetching web pages is a classic example to demonstrate the power of async programming. Let’s compare fetching URLs synchronously vs. asynchronously.\n\nSynchronous HTTP requests is mostly made by the library, fetching two web pages in a row looks something like this:\n\nThis code is as simple as it gets, but it waits idly for each request to complete before moving to the next.\n\nLet’s amp up the efficiency with and which can be used for asynchronous HTTP requests:\n\nThis async version doesn’t wait around. While one page is being fetched, it starts on the next, drastically cutting down total wait time.\n\nLet’s explore a different use case for concurrent execution with , moving away from web requests. This time, we'll focus on reading multiple files asynchronously. This can be particularly useful when dealing with large files or I/O-bound tasks that do not involve network communication.\n\nIn a synchronous setup, reading multiple files one after the other can significantly increase execution time, especially with large files:\n\nFor the asynchronous version, we’ll use , a library that provides support for asynchronous file operations. If you haven't installed yet, you can do so using pip:\n\nWith , we can perform file I/O operations without blocking the event loop, allowing us to read multiple files concurrently.\n\nThe asynchronous version, by leveraging and , allows for concurrent reading of multiple files. This approach significantly reduces the total execution time compared to the synchronous version, which reads each file one after the other. By performing I/O operations concurrently, we can improve the efficiency of programs that need to handle multiple file operations.\n\nSometimes, you can’t escape synchronous functions but still want to enjoy the async ride. Here’s how you can mix them:\n\nThe provided code snippet demonstrates how to integrate synchronous functions within an asynchronous environment using Python’s library.\n• This async function demonstrates how to run the synchronous in a way that does not block the event loop. It achieves this by utilizing .\n• schedules to run in a separate thread or process, depending on the executor used. The default executor ( specified as the first argument) runs tasks in a thread pool.\n• is used to wait for the completion of without blocking the event loop, allowing other asynchronous operations to progress in the meantime.\n• The async function showcases how to run both synchronous and asynchronous tasks together without blocking.\n• is used to schedule concurrent execution of the and potentially other asynchronous tasks. By using , you ensure that the event loop can manage multiple tasks, running them concurrently where possible.\n• Finally, is called to run the coroutine, which effectively starts the event loop and executes the tasks scheduled within .\n\nWhy Is This Approach Needed?\n• Integration of Legacy Code: In real-world applications, you often encounter legacy code that is synchronous in nature. Rewriting large codebases for async compatibility is not always feasible. This approach allows you to integrate such code into your async applications seamlessly.\n• Working with Blocking I/O: Some operations, especially those involving blocking I/O, don’t have asynchronous equivalents, or you might be working with third-party libraries that only offer synchronous functions. This technique allows those operations to be offloaded to a thread, freeing the event loop to handle other async tasks.\n• CPU-bound Tasks: Although CPU-bound tasks are usually better handled by multiprocessing due to Python’s Global Interpreter Lock (GIL), you might sometimes choose to run them in threads for simplicity or because the computational overhead is not excessively high. Using allows these tasks to coexist with I/O-bound asynchronous tasks.\n\nIn Python’s asynchronous programming model, a is a low-level awaitable object that represents an eventual result of an asynchronous operation. When you create a Future, you're essentially declaring a placeholder for a result that will be available at some point in the future. Futures are a crucial part of the library, allowing for fine-grained control over asynchronous operations.\n• Role: Futures are used to bridge low-level asynchronous operations with high-level asyncio applications. They provide a way to manage the state of an asynchronous operation: pending, finished (with a result), or failed (with an exception).\n• Usage: Typically, you don’t need to create Futures yourself when using high-level functions and constructs (like Tasks, which are a subclass of Future). However, understanding Futures is essential for interfacing with lower-level async APIs or when building complex asynchronous systems.\n\nA Future object has several key methods and properties:\n• : Sets the result of the Future. This will mark it as done and notify all awaiting coroutines.\n• : Sets an exception as the result of the Future. This also marks it as done but will raise the exception when awaited.\n• : Adds a callback function to be called when the Future is done (either completed with a result or an exception).\n• : Returns the result of the Future. If the Future is not done, it will raise an . If the Future is completed with an exception, this method will re-raise the exception.\n• : Returns if the Future is done. A Future is considered done if it has a result or an exception.\n• is an async function simulating an asynchronous task that takes a object and some as arguments. It waits for 1 second to mimic some async work. Based on the value, it either sets a result on the using or raises an exception using .\n• is a callback function that prints the result of the Future once it's done. It checks if the operation succeeded or failed by calling , which either returns the result or re-raises the exception set in the Future.\n• In the coroutine, a Future object is created, and is added as its callback using . The is then awaited with the Future and sample data (\"success\" or any other value to simulate failure).\n• After completed, check if the Future is done using . It then attempts to print the result directly, handling any potential exceptions.\n\nThis example succinctly demonstrates the basic mechanisms of managing asynchronous operations with Futures in Python’s asyncio, including setting results, handling exceptions, using callbacks, and retrieving operation outcomes.\n\nAdopting in Python applications can significantly improve the performance and scalability of I/O-bound and network-driven programs. By understanding and applying the concepts of event loops, coroutines, futures, and tasks, developers can write efficient, non-blocking code that can handle thousands of simultaneous connections with ease. The examples provided in this article, are few, but yet, showcase the versatility of and demonstrate how it can be used to achieve concurrency in Python applications, offering a clear advantage over traditional synchronous code for certain types of tasks.\n\nIf you enjoyed this article and found it valuable, please consider giving it a clap to show your support. Feel free to explore my other articles, where I cover a wide range of topics related to Python programming and others. By following me, you’ll stay updated on my latest content and insights. I look forward to sharing more knowledge and connecting with you through future articles. Until then, keep coding, keep learning, and most importantly, enjoy the journey!"
    }
]