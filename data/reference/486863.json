[
    {
        "link": "https://docs.python.org/3/library/urllib.parse.html",
        "document": "This module defines a standard interface to break Uniform Resource Locator (URL) strings up in components (addressing scheme, network location, path etc.), to combine the components back into a URL string, and to convert a “relative URL” to an absolute URL given a “base URL.”\n\nThe module has been designed to match the internet RFC on Relative Uniform Resource Locators. It supports the following URL schemes: , , , , , , , , , , , , , , , , , , , , , , , , , , , .\n\nThe module defines functions that fall into two broad categories: URL parsing and URL quoting. These are covered in detail in the following sections.\n\nThis module’s functions use the deprecated term (or ), which was introduced in RFC 1808. However, this term has been obsoleted by RFC 3986, which introduced the term as its replacement. The use of is continued for backward compatibility.\n\nThe URL parsing functions focus on splitting a URL string into its components, or on combining URL components into a URL string. Parse a URL into six components, returning a 6-item named tuple. This corresponds to the general structure of a URL: . Each tuple item is a string, possibly empty. The components are not broken up into smaller parts (for example, the network location is a single string), and % escapes are not expanded. The delimiters as shown above are not part of the result, except for a leading slash in the path component, which is retained if present. For example: Following the syntax specifications in RFC 1808, urlparse recognizes a netloc only if it is properly introduced by ‘//’. Otherwise the input is presumed to be a relative URL and thus to start with a path component. The scheme argument gives the default addressing scheme, to be used only if the URL does not specify one. It should be the same type (text or bytes) as urlstring, except that the default value is always allowed, and is automatically converted to if appropriate. If the allow_fragments argument is false, fragment identifiers are not recognized. Instead, they are parsed as part of the path, parameters or query component, and is set to the empty string in the return value. The return value is a named tuple, which means that its items can be accessed by index or as named attributes, which are: Reading the attribute will raise a if an invalid port is specified in the URL. See section Structured Parse Results for more information on the result object. Unmatched square brackets in the attribute will raise a . Characters in the attribute that decompose under NFKC normalization (as used by the IDNA encoding) into any of , , , , or will raise a . If the URL is decomposed before parsing, no error will be raised. As is the case with all named tuples, the subclass has a few additional methods and attributes that are particularly useful. One such method is . The method will return a new ParseResult object replacing specified fields with new values. does not perform validation. See URL parsing security for details. Changed in version 3.3: The fragment is now parsed for all URL schemes (unless allow_fragments is false), in accordance with RFC 3986. Previously, an allowlist of schemes that support fragments existed. Changed in version 3.6: Out-of-range port numbers now raise , instead of returning . Changed in version 3.8: Characters that affect netloc parsing under NFKC normalization will now raise . Parse a query string given as a string argument (data of type application/x-www-form-urlencoded). Data are returned as a dictionary. The dictionary keys are the unique query variable names and the values are lists of values for each name. The optional argument keep_blank_values is a flag indicating whether blank values in percent-encoded queries should be treated as blank strings. A true value indicates that blanks should be retained as blank strings. The default false value indicates that blank values are to be ignored and treated as if they were not included. The optional argument strict_parsing is a flag indicating what to do with parsing errors. If false (the default), errors are silently ignored. If true, errors raise a exception. The optional encoding and errors parameters specify how to decode percent-encoded sequences into Unicode characters, as accepted by the method. The optional argument max_num_fields is the maximum number of fields to read. If set, then throws a if there are more than max_num_fields fields read. The optional argument separator is the symbol to use for separating the query arguments. It defaults to . Use the function (with the parameter set to ) to convert such dictionaries into query strings. Changed in version 3.10: Added separator parameter with the default value of . Python versions earlier than Python 3.10 allowed using both and as query parameter separator. This has been changed to allow only a single separator key, with as the default separator. Parse a query string given as a string argument (data of type application/x-www-form-urlencoded). Data are returned as a list of name, value pairs. The optional argument keep_blank_values is a flag indicating whether blank values in percent-encoded queries should be treated as blank strings. A true value indicates that blanks should be retained as blank strings. The default false value indicates that blank values are to be ignored and treated as if they were not included. The optional argument strict_parsing is a flag indicating what to do with parsing errors. If false (the default), errors are silently ignored. If true, errors raise a exception. The optional encoding and errors parameters specify how to decode percent-encoded sequences into Unicode characters, as accepted by the method. The optional argument max_num_fields is the maximum number of fields to read. If set, then throws a if there are more than max_num_fields fields read. The optional argument separator is the symbol to use for separating the query arguments. It defaults to . Use the function to convert such lists of pairs into query strings. Changed in version 3.10: Added separator parameter with the default value of . Python versions earlier than Python 3.10 allowed using both and as query parameter separator. This has been changed to allow only a single separator key, with as the default separator. Construct a URL from a tuple as returned by . The parts argument can be any six-item iterable. This may result in a slightly different, but equivalent URL, if the URL that was parsed originally had unnecessary delimiters (for example, a with an empty query; the RFC states that these are equivalent). This is similar to , but does not split the params from the URL. This should generally be used instead of if the more recent URL syntax allowing parameters to be applied to each segment of the path portion of the URL (see RFC 2396) is wanted. A separate function is needed to separate the path segments and parameters. This function returns a 5-item named tuple: The return value is a named tuple, its items can be accessed by index or as named attributes: Reading the attribute will raise a if an invalid port is specified in the URL. See section Structured Parse Results for more information on the result object. Unmatched square brackets in the attribute will raise a . Characters in the attribute that decompose under NFKC normalization (as used by the IDNA encoding) into any of , , , , or will raise a . If the URL is decomposed before parsing, no error will be raised. Following some of the WHATWG spec that updates RFC 3986, leading C0 control and space characters are stripped from the URL. , and tab characters are removed from the URL at any position. does not perform validation. See URL parsing security for details. Changed in version 3.6: Out-of-range port numbers now raise , instead of returning . Changed in version 3.8: Characters that affect netloc parsing under NFKC normalization will now raise . Changed in version 3.10: ASCII newline and tab characters are stripped from the URL. Changed in version 3.12: Leading WHATWG C0 control and space characters are stripped from the URL. Combine the elements of a tuple as returned by into a complete URL as a string. The parts argument can be any five-item iterable. This may result in a slightly different, but equivalent URL, if the URL that was parsed originally had unnecessary delimiters (for example, a ? with an empty query; the RFC states that these are equivalent). Construct a full (“absolute”) URL by combining a “base URL” (base) with another URL (url). Informally, this uses components of the base URL, in particular the addressing scheme, the network location and (part of) the path, to provide missing components in the relative URL. For example: The allow_fragments argument has the same meaning and default as for . If url is an absolute URL (that is, it starts with or ), the url’s hostname and/or scheme will be present in the result. For example: If you do not want that behavior, preprocess the url with and , removing possible scheme and netloc parts. Because an absolute URL may be passed as the parameter, it is generally not secure to use with an attacker-controlled . For example in, , if can contain an absolute URL, the result of will be the absolute URL. Changed in version 3.5: Behavior updated to match the semantics defined in RFC 3986. If url contains a fragment identifier, return a modified version of url with no fragment identifier, and the fragment identifier as a separate string. If there is no fragment identifier in url, return url unmodified and an empty string. The return value is a named tuple, its items can be accessed by index or as named attributes: See section Structured Parse Results for more information on the result object. Changed in version 3.2: Result is a structured object rather than a simple 2-tuple. Extract the url from a wrapped URL (that is, a string formatted as , , or ). If url is not a wrapped URL, it is returned without changes.\n\nThe and APIs do not perform validation of inputs. They may not raise errors on inputs that other applications consider invalid. They may also succeed on some inputs that might not be considered URLs elsewhere. Their purpose is for practical functionality rather than purity. Instead of raising an exception on unusual input, they may instead return some component parts as empty strings. Or components may contain more than perhaps they should. We recommend that users of these APIs where the values may be used anywhere with security implications code defensively. Do some verification within your code before trusting a returned component part. Does that make sense? Is that a sensible ? Is there anything strange about that ? etc. What constitutes a URL is not universally well defined. Different applications have different needs and desired constraints. For instance the living WHATWG spec describes what user facing web clients such as a web browser require. While RFC 3986 is more general. These functions incorporate some aspects of both, but cannot be claimed compliant with either. The APIs and existing user code with expectations on specific behaviors predate both standards leading us to be very cautious about making API behavior changes.\n\nThe URL parsing functions were originally designed to operate on character strings only. In practice, it is useful to be able to manipulate properly quoted and encoded URLs as sequences of ASCII bytes. Accordingly, the URL parsing functions in this module all operate on and objects in addition to objects. If data is passed in, the result will also contain only data. If or data is passed in, the result will contain only data. Attempting to mix data with or in a single function call will result in a being raised, while attempting to pass in non-ASCII byte values will trigger . To support easier conversion of result objects between and , all return values from URL parsing functions provide either an method (when the result contains data) or a method (when the result contains data). The signatures of these methods match those of the corresponding and methods (except that the default encoding is rather than ). Each produces a value of a corresponding type that contains either data (for methods) or data (for methods). Applications that need to operate on potentially improperly quoted URLs that may contain non-ASCII data will need to do their own decoding from bytes to characters before invoking the URL parsing methods. The behaviour described in this section applies only to the URL parsing functions. The URL quoting functions use their own rules when producing or consuming byte sequences as detailed in the documentation of the individual URL quoting functions.\n\nThe result objects from the , and functions are subclasses of the type. These subclasses add the attributes listed in the documentation for those functions, the encoding and decoding support described in the previous section, as well as an additional method: Return the re-combined version of the original URL as a string. This may differ from the original URL in that the scheme may be normalized to lower case and empty components may be dropped. Specifically, empty parameters, queries, and fragment identifiers will be removed. For results, only empty fragment identifiers will be removed. For and results, all noted changes will be made to the URL returned by this method. The result of this method remains unchanged if passed back through the original parsing function: The following classes provide the implementations of the structured parse results when operating on objects: Concrete class for results containing data. The method returns a instance. Concrete class for results containing data. The method returns a instance. Concrete class for results containing data. The method returns a instance. The following classes provide the implementations of the parse results when operating on or objects: Concrete class for results containing data. The method returns a instance. Concrete class for results containing data. The method returns a instance. Concrete class for results containing data. The method returns a instance.\n\nThe URL quoting functions focus on taking program data and making it safe for use as URL components by quoting special characters and appropriately encoding non-ASCII text. They also support reversing these operations to recreate the original data from the contents of a URL component if that task isn’t already covered by the URL parsing functions above. Replace special characters in string using the escape. Letters, digits, and the characters are never quoted. By default, this function is intended for quoting the path section of a URL. The optional safe parameter specifies additional ASCII characters that should not be quoted — its default value is . string may be either a or a object. Changed in version 3.7: Moved from RFC 2396 to RFC 3986 for quoting URL strings. “~” is now included in the set of unreserved characters. The optional encoding and errors parameters specify how to deal with non-ASCII characters, as accepted by the method. encoding defaults to . errors defaults to , meaning unsupported characters raise a . encoding and errors must not be supplied if string is a , or a is raised. Note that is equivalent to . Like , but also replace spaces with plus signs, as required for quoting HTML form values when building up a query string to go into a URL. Plus signs in the original string are escaped unless they are included in safe. It also does not have safe default to . Like , but accepts a object rather than a , and does not perform string-to-bytes encoding. Replace escapes with their single-character equivalent. The optional encoding and errors parameters specify how to decode percent-encoded sequences into Unicode characters, as accepted by the method. string may be either a or a object. encoding defaults to . errors defaults to , meaning invalid sequences are replaced by a placeholder character. Changed in version 3.9: string parameter supports bytes and str objects (previously only str). Like , but also replace plus signs with spaces, as required for unquoting HTML form values. Replace escapes with their single-octet equivalent, and return a object. string may be either a or a object. If it is a , unescaped non-ASCII characters in string are encoded into UTF-8 bytes. Convert a mapping object or a sequence of two-element tuples, which may contain or objects, to a percent-encoded ASCII text string. If the resultant string is to be used as a data for POST operation with the function, then it should be encoded to bytes, otherwise it would result in a . The resulting string is a series of pairs separated by characters, where both key and value are quoted using the quote_via function. By default, is used to quote the values, which means spaces are quoted as a character and ‘/’ characters are encoded as , which follows the standard for GET requests ( ). An alternate function that can be passed as quote_via is , which will encode spaces as and not encode ‘/’ characters. For maximum control of what is quoted, use and specify a value for safe. When a sequence of two-element tuples is used as the query argument, the first element of each tuple is a key and the second is a value. The value element in itself can be a sequence and in that case, if the optional parameter doseq evaluates to , individual pairs separated by are generated for each element of the value sequence for the key. The order of parameters in the encoded string will match the order of parameter tuples in the sequence. The safe, encoding, and errors parameters are passed down to quote_via (the encoding and errors parameters are only passed when a query element is a ). To reverse this encoding process, and are provided in this module to parse query strings into Python data structures. Refer to urllib examples to find out how the method can be used for generating the query string of a URL or data for a POST request. Working Group for the URL Standard that defines URLs, domains, IP addresses, the application/x-www-form-urlencoded format, and their API. This is the current standard (STD66). Any changes to urllib.parse module should conform to this. Certain deviations could be observed, which are mostly for backward compatibility purposes and for certain de-facto parsing requirements as commonly observed in major browsers. This specifies the parsing requirements of IPv6 URLs. Document describing the generic syntactic requirements for both Uniform Resource Names (URNs) and Uniform Resource Locators (URLs). This Request For Comments includes the rules for joining an absolute and a relative URL, including a fair number of “Abnormal Examples” which govern the treatment of border cases. This specifies the formal syntax and semantics of absolute URLs."
    },
    {
        "link": "https://stackoverflow.com/questions/40557606/how-to-url-encode-in-python-3",
        "document": "You misread the documentation. You need to do two things:\n• Quote each key and value from your dictionary, and\n\nLuckily does both those things in a single step, and that's the function you should be using."
    },
    {
        "link": "https://stackoverflow.com/questions/1695183/how-can-i-percent-encode-url-parameters-in-python",
        "document": "Replace special characters in string using the escape. Letters, digits, and the characters are never quoted. By default, this function is intended for quoting the path section of a URL. The optional safe parameter specifies additional ASCII characters that should not be quoted — its default value is .\n\nThat means passing for safe will solve your first issue:\n\nBy the way, have a look at urlencode.\n\nAbout the second issue, there was a bug report about it and it was fixed in Python 3.\n\nFor Python 2, you can work around it by encoding as UTF-8 like this:"
    },
    {
        "link": "https://python.readthedocs.io/fr/hack-in-language/library/urllib.parse.html",
        "document": "This module defines a standard interface to break Uniform Resource Locator (URL) strings up in components (addressing scheme, network location, path etc.), to combine the components back into a URL string, and to convert a « relative URL » to an absolute URL given a « base URL. »\n\nThe module has been designed to match the Internet RFC on Relative Uniform Resource Locators. It supports the following URL schemes: , , , , , , , , , , , , , , , , , , , , , , , .\n\nThe module defines functions that fall into two broad categories: URL parsing and URL quoting. These are covered in detail in the following sections.\n\nThe URL parsing functions focus on splitting a URL string into its components, or on combining URL components into a URL string. Parse a URL into six components, returning a 6-tuple. This corresponds to the general structure of a URL: . Each tuple item is a string, possibly empty. The components are not broken up in smaller parts (for example, the network location is a single string), and % escapes are not expanded. The delimiters as shown above are not part of the result, except for a leading slash in the path component, which is retained if present. For example: Following the syntax specifications in RFC 1808, urlparse recognizes a netloc only if it is properly introduced by “//”. Otherwise the input is presumed to be a relative URL and thus to start with a path component. If the scheme argument is specified, it gives the default addressing scheme, to be used only if the URL does not specify one. The default value for this argument is the empty string. If the allow_fragments argument is false, fragment identifiers are not recognized and parsed as part of the preceding component. The default value for this argument is . The return value is actually an instance of a subclass of . This class has the following additional read-only convenience attributes: See section Structured Parse Results for more information on the result object. Modifié dans la version 3.3: The fragment is now parsed for all URL schemes (unless allow_fragment is false), in accordance with RFC 3986. Previously, a whitelist of schemes that support fragments existed. Parse a query string given as a string argument (data of type application/x-www-form-urlencoded). Data are returned as a dictionary. The dictionary keys are the unique query variable names and the values are lists of values for each name. The optional argument keep_blank_values is a flag indicating whether blank values in percent-encoded queries should be treated as blank strings. A true value indicates that blanks should be retained as blank strings. The default false value indicates that blank values are to be ignored and treated as if they were not included. The optional argument strict_parsing is a flag indicating what to do with parsing errors. If false (the default), errors are silently ignored. If true, errors raise a exception. The optional encoding and errors parameters specify how to decode percent-encoded sequences into Unicode characters, as accepted by the method. Use the function (with the parameter set to ) to convert such dictionaries into query strings. Modifié dans la version 3.2: Add encoding and errors parameters. Parse a query string given as a string argument (data of type application/x-www-form-urlencoded). Data are returned as a list of name, value pairs. The optional argument keep_blank_values is a flag indicating whether blank values in percent-encoded queries should be treated as blank strings. A true value indicates that blanks should be retained as blank strings. The default false value indicates that blank values are to be ignored and treated as if they were not included. The optional argument strict_parsing is a flag indicating what to do with parsing errors. If false (the default), errors are silently ignored. If true, errors raise a exception. The optional encoding and errors parameters specify how to decode percent-encoded sequences into Unicode characters, as accepted by the method. Use the function to convert such lists of pairs into query strings. Modifié dans la version 3.2: Add encoding and errors parameters. Construct a URL from a tuple as returned by . The parts argument can be any six-item iterable. This may result in a slightly different, but equivalent URL, if the URL that was parsed originally had unnecessary delimiters (for example, a with an empty query; the RFC states that these are equivalent). This is similar to , but does not split the params from the URL. This should generally be used instead of if the more recent URL syntax allowing parameters to be applied to each segment of the path portion of the URL (see RFC 2396) is wanted. A separate function is needed to separate the path segments and parameters. This function returns a 5-tuple: (addressing scheme, network location, path, query, fragment identifier). The return value is actually an instance of a subclass of . This class has the following additional read-only convenience attributes: See section Structured Parse Results for more information on the result object. Combine the elements of a tuple as returned by into a complete URL as a string. The parts argument can be any five-item iterable. This may result in a slightly different, but equivalent URL, if the URL that was parsed originally had unnecessary delimiters (for example, a ? with an empty query; the RFC states that these are equivalent). Construct a full (« absolute ») URL by combining a « base URL » (base) with another URL (url). Informally, this uses components of the base URL, in particular the addressing scheme, the network location and (part of) the path, to provide missing components in the relative URL. For example: The allow_fragments argument has the same meaning and default as for . If url is an absolute URL (that is, starting with or ), the url’s host name and/or scheme will be present in the result. For example: If you do not want that behavior, preprocess the url with and , removing possible scheme and netloc parts. Modifié dans la version 3.5: Behaviour updated to match the semantics defined in RFC 3986. If url contains a fragment identifier, return a modified version of url with no fragment identifier, and the fragment identifier as a separate string. If there is no fragment identifier in url, return url unmodified and an empty string. The return value is actually an instance of a subclass of . This class has the following additional read-only convenience attributes: See section Structured Parse Results for more information on the result object. Modifié dans la version 3.2: Result is a structured object rather than a simple 2-tuple.\n\nThe URL parsing functions were originally designed to operate on character strings only. In practice, it is useful to be able to manipulate properly quoted and encoded URLs as sequences of ASCII bytes. Accordingly, the URL parsing functions in this module all operate on and objects in addition to objects. If data is passed in, the result will also contain only data. If or data is passed in, the result will contain only data. Attempting to mix data with or in a single function call will result in a being raised, while attempting to pass in non-ASCII byte values will trigger . To support easier conversion of result objects between and , all return values from URL parsing functions provide either an method (when the result contains data) or a method (when the result contains data). The signatures of these methods match those of the corresponding and methods (except that the default encoding is rather than ). Each produces a value of a corresponding type that contains either data (for methods) or data (for methods). Applications that need to operate on potentially improperly quoted URLs that may contain non-ASCII data will need to do their own decoding from bytes to characters before invoking the URL parsing methods. The behaviour described in this section applies only to the URL parsing functions. The URL quoting functions use their own rules when producing or consuming byte sequences as detailed in the documentation of the individual URL quoting functions.\n\nThe result objects from the , and functions are subclasses of the type. These subclasses add the attributes listed in the documentation for those functions, the encoding and decoding support described in the previous section, as well as an additional method: Return the re-combined version of the original URL as a string. This may differ from the original URL in that the scheme may be normalized to lower case and empty components may be dropped. Specifically, empty parameters, queries, and fragment identifiers will be removed. For results, only empty fragment identifiers will be removed. For and results, all noted changes will be made to the URL returned by this method. The result of this method remains unchanged if passed back through the original parsing function: The following classes provide the implementations of the structured parse results when operating on objects: Concrete class for results containing data. The method returns a instance. Concrete class for results containing data. The method returns a instance. Concrete class for results containing data. The method returns a instance. The following classes provide the implementations of the parse results when operating on or objects: Concrete class for results containing data. The method returns a instance. Concrete class for results containing data. The method returns a instance. Concrete class for results containing data. The method returns a instance.\n\nThe URL quoting functions focus on taking program data and making it safe for use as URL components by quoting special characters and appropriately encoding non-ASCII text. They also support reversing these operations to recreate the original data from the contents of a URL component if that task isn’t already covered by the URL parsing functions above. Replace special characters in string using the escape. Letters, digits, and the characters are never quoted. By default, this function is intended for quoting the path section of URL. The optional safe parameter specifies additional ASCII characters that should not be quoted — its default value is . string may be either a or a . The optional encoding and errors parameters specify how to deal with non-ASCII characters, as accepted by the method. encoding defaults to . errors defaults to , meaning unsupported characters raise a . encoding and errors must not be supplied if string is a , or a is raised. Note that is equivalent to . Like , but also replace spaces by plus signs, as required for quoting HTML form values when building up a query string to go into a URL. Plus signs in the original string are escaped unless they are included in safe. It also does not have safe default to . Like , but accepts a object rather than a , and does not perform string-to-bytes encoding. Replace escapes by their single-character equivalent. The optional encoding and errors parameters specify how to decode percent-encoded sequences into Unicode characters, as accepted by the method. encoding defaults to . errors defaults to , meaning invalid sequences are replaced by a placeholder character. Like , but also replace plus signs by spaces, as required for unquoting HTML form values. Replace escapes by their single-octet equivalent, and return a object. string may be either a or a . If it is a , unescaped non-ASCII characters in string are encoded into UTF-8 bytes. Convert a mapping object or a sequence of two-element tuples, which may contain or objects, to a « percent-encoded » string. If the resultant string is to be used as a data for POST operation with function, then it should be properly encoded to bytes, otherwise it would result in a . The resulting string is a series of pairs separated by characters, where both key and value are quoted using above. When a sequence of two-element tuples is used as the query argument, the first element of each tuple is a key and the second is a value. The value element in itself can be a sequence and in that case, if the optional parameter doseq is evaluates to True, individual pairs separated by are generated for each element of the value sequence for the key. The order of parameters in the encoded string will match the order of parameter tuples in the sequence. The safe, encoding, and errors parameters are passed down to (the encoding and errors parameters are only passed when a query element is a ). To reverse this encoding process, and are provided in this module to parse query strings into Python data structures. Refer to urllib examples to find out how urlencode method can be used for generating query string for a URL or data for POST. Modifié dans la version 3.2: Query parameter supports bytes and string objects. This is the current standard (STD66). Any changes to urllib.parse module should conform to this. Certain deviations could be observed, which are mostly for backward compatibility purposes and for certain de-facto parsing requirements as commonly observed in major browsers. This specifies the parsing requirements of IPv6 URLs. Document describing the generic syntactic requirements for both Uniform Resource Names (URNs) and Uniform Resource Locators (URLs). This Request For Comments includes the rules for joining an absolute and a relative URL, including a fair number of « Abnormal Examples » which govern the treatment of border cases. This specifies the formal syntax and semantics of absolute URLs."
    },
    {
        "link": "https://docs.python.org/3/library/urllib.request.html",
        "document": "The module defines functions and classes which help in opening URLs (mostly HTTP) in a complex world — basic and digest authentication, redirections, cookies and more.\n\nThe module defines the following functions:\n\nOpen url, which can be either a string containing a valid, properly encoded URL, or a object. data must be an object specifying additional data to be sent to the server, or if no such data is needed. See for details. urllib.request module uses HTTP/1.1 and includes header in its HTTP requests. The optional timeout parameter specifies a timeout in seconds for blocking operations like the connection attempt (if not specified, the global default timeout setting will be used). This actually only works for HTTP, HTTPS and FTP connections. If context is specified, it must be a instance describing the various SSL options. See for more details. This function always returns an object which can work as a context manager and has the properties url, headers, and status. See for more detail on these properties. For HTTP and HTTPS URLs, this function returns a object slightly modified. In addition to the three new methods above, the msg attribute contains the same information as the attribute — the reason phrase returned by server — instead of the response headers as it is specified in the documentation for . For FTP, file, and data URLs and requests explicitly handled by legacy and classes, this function returns a object. Note that may be returned if no handler handles the request (though the default installed global uses to ensure this never happens). In addition, if proxy settings are detected (for example, when a environment variable like is set), is default installed and makes sure the requests are handled through the proxy. The legacy function from Python 2.6 and earlier has been discontinued; corresponds to the old . Proxy handling, which was done by passing a dictionary parameter to , can be obtained by using objects. The default opener raises an auditing event with arguments , , , taken from the request object. Changed in version 3.2: cafile and capath were added. HTTPS virtual hosts are now supported if possible (that is, if is true). data can be an iterable object. Changed in version 3.10: HTTPS connection now send an ALPN extension with protocol indicator when no context is given. Custom context should set ALPN protocols with . Changed in version 3.13: Remove cafile, capath and cadefault parameters: use the context parameter instead.\n\nThe following classes are provided:\n\nThis class is an abstraction of a URL request. url should be a string containing a valid, properly encoded URL. data must be an object specifying additional data to send to the server, or if no such data is needed. Currently HTTP requests are the only ones that use data. The supported object types include bytes, file-like objects, and iterables of bytes-like objects. If no nor header field has been provided, will set these headers according to the type of data. will be used to send bytes objects, while as specified in RFC 7230, Section 3.3.1 will be used to send files and other iterables. For an HTTP POST request method, data should be a buffer in the standard application/x-www-form-urlencoded format. The function takes a mapping or sequence of 2-tuples and returns an ASCII string in this format. It should be encoded to bytes before being used as the data parameter. headers should be a dictionary, and will be treated as if was called with each key and value as arguments. This is often used to “spoof” the header value, which is used by a browser to identify itself – some HTTP servers only allow requests coming from common browsers as opposed to scripts. For example, Mozilla Firefox may identify itself as , while ’s default user agent string is (on Python 2.6). All header keys are sent in camel case. An appropriate header should be included if the data argument is present. If this header has not been provided and data is not , will be added as a default. The next two arguments are only of interest for correct handling of third-party HTTP cookies: origin_req_host should be the request-host of the origin transaction, as defined by RFC 2965. It defaults to . This is the host name or IP address of the original request that was initiated by the user. For example, if the request is for an image in an HTML document, this should be the request-host of the request for the page containing the image. unverifiable should indicate whether the request is unverifiable, as defined by RFC 2965. It defaults to . An unverifiable request is one whose URL the user did not have the option to approve. For example, if the request is for an image in an HTML document, and the user had no option to approve the automatic fetching of the image, this should be true. method should be a string that indicates the HTTP request method that will be used (e.g. ). If provided, its value is stored in the attribute and is used by . The default is if data is or otherwise. Subclasses may indicate a different default method by setting the attribute in the class itself. The request will not work as expected if the data object is unable to deliver its content more than once (e.g. a file or an iterable that can produce the content only once) and the request is retried for HTTP redirects or authentication. The data is sent to the HTTP server right away after the headers. There is no support for a 100-continue expectation in the library. Changed in version 3.3: argument is added to the Request class. Changed in version 3.4: Default may be indicated at the class level. Changed in version 3.6: Do not raise an error if the has not been provided and data is neither nor a bytes object. Fall back to use chunked transfer encoding instead.\n\nThe following methods describe ’s public interface, and so all may be overridden in subclasses. It also defines several public attributes that can be used by clients to inspect the parsed request. The original URL passed to the constructor. Request.full_url is a property with setter, getter and a deleter. Getting returns the original request URL with the fragment, if it was present. The URI authority, typically a host, but may also contain a port separated by a colon. The original host for the request, without port. The URI path. If the uses a proxy, then selector will be the full URL that is passed to the proxy. The entity body for the request, or if not specified. Changed in version 3.4: Changing value of now deletes “Content-Length” header if it was previously set or calculated. boolean, indicates whether the request is unverifiable as defined by RFC 2965. The HTTP request method to use. By default its value is , which means that will do its normal computation of the method to be used. Its value can be set (thus overriding the default computation in ) either by providing a default value by setting it at the class level in a subclass, or by passing a value in to the constructor via the method argument. Changed in version 3.4: A default value can now be set in subclasses; previously it could only be set via the constructor argument. Return a string indicating the HTTP request method. If is not , return its value, otherwise return if is , or if it’s not. This is only meaningful for HTTP requests. Changed in version 3.3: get_method now looks at the value of . Add another header to the request. Headers are currently ignored by all handlers except HTTP handlers, where they are added to the list of headers sent to the server. Note that there cannot be more than one header with the same name, and later calls will overwrite previous calls in case the key collides. Currently, this is no loss of HTTP functionality, since all headers which have meaning when used more than once have a (header-specific) way of gaining the same functionality using only one header. Note that headers added using this method are also added to redirected requests. Add a header that will not be added to a redirected request. Return whether the instance has the named header (checks both regular and unredirected). Remove named header from the request instance (both from regular and unredirected headers). Return the URL given in the constructor. Prepare the request by connecting to a proxy server. The host and type will replace those of the instance, and the instance’s selector will be the original URL given in the constructor. Return the value of the given header. If the header is not present, return the default value. Return a list of tuples (header_name, header_value) of the Request headers. Changed in version 3.4: The request methods add_data, has_data, get_data, get_type, get_host, get_selector, get_origin_req_host and is_unverifiable that were deprecated since 3.3 have been removed.\n\nobjects provide a couple of methods that are directly useful, and others that are meant to be used by derived classes. These are intended for direct use: The following attribute and methods should only be used by classes derived from . The convention has been adopted that subclasses defining or methods are named ; all others are named . A valid , which can be used to open using a different protocol, or handle errors. This method is not defined in , but subclasses should define it if they want to catch all URLs. This method, if implemented, will be called by the parent . It should return a file-like object as described in the return value of the method of , or . It should raise , unless a truly exceptional thing happens (for example, should not be mapped to ). This method will be called before any protocol-specific open method. This method is not defined in , but subclasses should define it if they want to handle URLs with the given protocol. This method, if defined, will be called by the parent . Return values should be the same as for . This method is not defined in , but subclasses should define it if they want to catch all URLs with no specific registered handler to open it. This method, if implemented, will be called by the . Return values should be the same as for . This method is not defined in , but subclasses should override it if they intend to provide a catch-all for otherwise unhandled HTTP errors. It will be called automatically by the getting the error, and should not normally be called in other circumstances. req will be a object, fp will be a file-like object with the HTTP error body, code will be the three-digit code of the error, msg will be the user-visible explanation of the code and hdrs will be a mapping object with the headers of the error. Return values and exceptions raised should be the same as those of . nnn should be a three-digit HTTP error code. This method is also not defined in , but will be called, if it exists, on an instance of a subclass, when an HTTP error with code nnn occurs. Subclasses should override this method to handle specific HTTP errors. Arguments, return values and exceptions raised should be the same as for . This method is not defined in , but subclasses should define it if they want to pre-process requests of the given protocol. This method, if defined, will be called by the parent . req will be a object. The return value should be a object. This method is not defined in , but subclasses should define it if they want to post-process responses of the given protocol. This method, if defined, will be called by the parent . req will be a object. response will be an object implementing the same interface as the return value of . The return value should implement the same interface as the return value of .\n\nIn addition to the examples below, more examples are given in HOWTO Fetch Internet Resources Using The urllib Package. This example gets the python.org main page and displays the first 300 bytes of it: Note that urlopen returns a bytes object. This is because there is no way for urlopen to automatically determine the encoding of the byte stream it receives from the HTTP server. In general, a program will decode the returned bytes object to string once it determines or guesses the appropriate encoding. The following HTML spec document, https://html.spec.whatwg.org/#charset, lists the various ways in which an HTML or an XML document could have specified its encoding information. For additional information, see the W3C document: https://www.w3.org/International/questions/qa-html-encoding-declarations. As the python.org website uses utf-8 encoding as specified in its meta tag, we will use the same for decoding the bytes object: It is also possible to achieve the same result without using the context manager approach: In the following example, we are sending a data-stream to the stdin of a CGI and reading the data it returns to us. Note that this example will only work when the Python installation supports SSL. 'This data is passed to stdin of the CGI' Got Data: \"This data is passed to stdin of the CGI\" The code for the sample CGI used in the above example is: Here is an example of doing a request using : # Create an OpenerDirector with support for Basic HTTP Authentication... # ...and install it globally so it can be used with urlopen. provides many handlers by default, including a . By default, uses the environment variables named , where is the URL scheme involved. For example, the environment variable is read to obtain the HTTP proxy’s URL. This example replaces the default with one that uses programmatically supplied proxy URLs, and adds proxy authorization support with . # This time, rather than install the OpenerDirector, we use it directly: Use the headers argument to the constructor, or: automatically adds a User-Agent header to every . To change this: Also, remember that a few standard headers (Content-Length, Content-Type and Host) are added when the is passed to (or ). Here is an example session that uses the method to retrieve a URL containing parameters: The following example uses the method instead. Note that params output from urlencode is encoded to bytes before it is sent to urlopen as data: The following example uses an explicitly specified HTTP proxy, overriding environment settings: The following example uses no proxies at all, overriding environment settings:\n\nThe following functions and classes are ported from the Python 2 module (as opposed to ). They might become deprecated at some point in the future. Copy a network object denoted by a URL to a local file. If the URL points to a local file, the object will not be copied unless filename is supplied. Return a tuple where filename is the local file name under which the object can be found, and headers is whatever the method of the object returned by returned (for a remote object). Exceptions are the same as for . The second argument, if present, specifies the file location to copy to (if absent, the location will be a tempfile with a generated name). The third argument, if present, is a callable that will be called once on establishment of the network connection and once after each block read thereafter. The callable will be passed three arguments; a count of blocks transferred so far, a block size in bytes, and the total size of the file. The third argument may be on older FTP servers which do not return a file size in response to a retrieval request. The following example illustrates the most common usage scenario: If the url uses the scheme identifier, the optional data argument may be given to specify a request (normally the request type is ). The data argument must be a bytes object in standard application/x-www-form-urlencoded format; see the function. will raise when it detects that the amount of data available was less than the expected amount (which is the size reported by a Content-Length header). This can occur, for example, when the download is interrupted. The Content-Length is treated as a lower bound: if there’s more data to read, urlretrieve reads more data, but if less data is available, it raises the exception. You can still retrieve the downloaded data in this case, it is stored in the attribute of the exception instance. If no Content-Length header was supplied, urlretrieve can not check the size of the data it has downloaded, and just returns it. In this case you just have to assume that the download was successful. Cleans up temporary files that may have been left behind by previous calls to . Base class for opening and reading URLs. Unless you need to support opening objects using schemes other than , , or , you probably want to use . By default, the class sends a User-Agent header of , where VVV is the version number. Applications can define their own User-Agent header by subclassing or and setting the class attribute to an appropriate string value in the subclass definition. The optional proxies parameter should be a dictionary mapping scheme names to proxy URLs, where an empty dictionary turns proxies off completely. Its default value is , in which case environmental proxy settings will be used if present, as discussed in the definition of , above. Additional keyword parameters, collected in x509, may be used for authentication of the client when using the scheme. The keywords key_file and cert_file are supported to provide an SSL key and certificate; both are needed to support client authentication. objects will raise an exception if the server returns an error code. Open fullurl using the appropriate protocol. This method sets up cache and proxy information, then calls the appropriate open method with its input arguments. If the scheme is not recognized, is called. The data argument has the same meaning as the data argument of . This method always quotes fullurl using . Retrieves the contents of url and places it in filename. The return value is a tuple consisting of a local filename and either an object containing the response headers (for remote URLs) or (for local URLs). The caller must then open and read the contents of filename. If filename is not given and the URL refers to a local file, the input filename is returned. If the URL is non-local and filename is not given, the filename is the output of with a suffix that matches the suffix of the last path component of the input URL. If reporthook is given, it must be a function accepting three numeric parameters: A chunk number, the maximum size chunks are read in and the total size of the download (-1 if unknown). It will be called once at the start and after each chunk of data is read from the network. reporthook is ignored for local URLs. If the url uses the scheme identifier, the optional data argument may be given to specify a request (normally the request type is ). The data argument must in standard application/x-www-form-urlencoded format; see the function. Variable that specifies the user agent of the opener object. To get to tell servers that it is a particular user agent, set this in a subclass as a class variable or in the constructor before calling the base constructor. subclasses providing default handling for the following HTTP response codes: 301, 302, 303, 307 and 401. For the 30x response codes listed above, the Location header is used to fetch the actual URL. For 401 response codes (authentication required), basic HTTP authentication is performed. For the 30x response codes, recursion is bounded by the value of the maxtries attribute, which defaults to 10. For all other response codes, the method is called which you can override in subclasses to handle the error appropriately. According to the letter of RFC 2616, 301 and 302 responses to POST requests must not be automatically redirected without confirmation by the user. In reality, browsers do allow automatic redirection of these responses, changing the POST to a GET, and reproduces this behaviour. The parameters to the constructor are the same as those for . When performing basic authentication, a instance calls its method. The default implementation asks the users for the required information on the controlling terminal. A subclass may override this method to support more appropriate behavior if needed. The class offers one additional method that should be overloaded to provide the appropriate behavior: Return information needed to authenticate the user at the given host in the specified security realm. The return value should be a tuple, , which can be used for basic authentication. The implementation prompts for this information on the terminal; an application should override this method to use an appropriate interaction model in the local environment."
    },
    {
        "link": "https://stackoverflow.com/questions/53910845/generate-hmac-sha256-signature-python",
        "document": "Try using the module instead of the module:\n\nThis gives the desired result:\n\nNote that the module accepts bytes for the key and message. If your inputs are strings, you can use the method with the relevant character set, e.g. , ' (default), etc.\n\nIn the above code example I am using the bytes literal introduced in PEP-3112. A bytes literal can only contain ASCII characters, anything outside of the range of ASCII must be entered as the relevant escape sequences.\n\nTherefore, the following line from the code example above..."
    },
    {
        "link": "https://docs.python.org/3/library/hmac.html",
        "document": "This module implements the HMAC algorithm as described by RFC 2104.\n\nReturn a new hmac object. key is a bytes or bytearray object giving the secret key. If msg is present, the method call is made. digestmod is the digest name, digest constructor or module for the HMAC object to use. It may be any name suitable to . Despite its argument position, it is required. Changed in version 3.4: Parameter key can be a bytes or bytearray object. Parameter msg can be of any type supported by . Parameter digestmod can be the name of a hash algorithm. Changed in version 3.8: The digestmod argument is now required. Pass it as a keyword argument to avoid awkwardness when you do not have an initial msg.\n\nReturn digest of msg for given secret key and digest. The function is equivalent to , but uses an optimized C or inline implementation, which is faster for messages that fit into memory. The parameters key, msg, and digest have the same meaning as in . CPython implementation detail, the optimized C implementation is only used when digest is a string and name of a digest algorithm, which is supported by OpenSSL.\n\nAn HMAC object has the following methods:\n\nReturn the digest of the bytes passed to the method so far. This bytes object will be the same length as the digest_size of the digest given to the constructor. It may contain non-ASCII bytes, including NUL bytes. When comparing the output of to an externally supplied digest during a verification routine, it is recommended to use the function instead of the operator to reduce the vulnerability to timing attacks.\n\nLike except the digest is returned as a string twice the length containing only hexadecimal digits. This may be used to exchange the value safely in email or other non-binary environments. When comparing the output of to an externally supplied digest during a verification routine, it is recommended to use the function instead of the operator to reduce the vulnerability to timing attacks.\n\nA hash object has the following attributes:\n\nThis module also provides the following helper function:"
    },
    {
        "link": "https://stackoverflow.com/questions/70666070/generate-sha256-hmac-signature-in-python",
        "document": "I'm trying to generate a SHA256 HMAC signature for a FTX websocket. I am using the params fromt he official example https://docs.ftx.com/#private-channels.\n\nbut I am getting ad38fa3566de972abb736bc0db2f7cd39daa48b14421e168422303bf2f03c6de\n\nhere is what I tried:"
    },
    {
        "link": "https://nutbutterfly.medium.com/how-to-sign-your-message-with-hmac-sha256-in-python-and-java-e7d8d055087e",
        "document": "Sign a request is a one of simple solution to secure your APIs. This short guide will show you how easy to implementation this mechanism using HMAC and SHA256 in Java and Python programming languages.\n\nSecret Key — a secretly shared value between and \n\nThis value can be anything, but must be a same value when perform signing.\n\nContent/Message — a value to be signed/hashed.\n\nSigning/Hashing — a process on client/consumer side to convert a content into some hashed data. Secret Key and Content will be involved in this step.\n\nVerification — a process on server/provider side to do almost the same as client side. Calculating hashed value using same Secret Key and compare with the one sent from the client.\n• Client — attach hashed value in HTTP Request Header. \n\nFor example\n• Server — read HTTP Request Body and calculate hashed value with the same Secret Key\n• Server — Compare a received hashed value with computed hashed from step 5.\n\nIf match, the verification is pass and continue the rest of API business logic.\n\nOtherwise, reject the request. For example return HTTP 401 Unauthorized"
    },
    {
        "link": "https://lethain.com/python-hmac-sha256",
        "document": "I’m playing around a bit with the Slack API, which I’ll have a longer post on in a bit. One part of the integration requires generating an HMAC SHA256 signature to verify requests are from Slack. There weren’t too many helpful search results, and some of them like the hmac module docs don’t include examples. Here are some quick notes for folks in future attempting the same thing.\n\nh/t to Joe Kampschmidt’s post which covers signing well.\n\nFirst step is to instrument your test application is capturing the full headers and raw body from a response so you can verify you implementation.\n\nIf you’re using Flask for your server, getting at the raw request body turns out to be slightly complicated, as it’ll helpfully attempt to convert data with content-type of into a dictionary instead of raw string. This conversion into a dictionary masks most obvious ways to access to the raw string.\n\nFortunately you can use Request.get_data to get the raw body as long as you do it before calling . It does work fine to call and then later , so be careful to sequence them correctly.\n\nOnce you have thoes headers and data, you’ll be able to do a test run of generating the signature and comparing it against the sent signature. The values you need to extract from the inbound request are:\n\nYou’ll also need to go to your Application page within the Slack dashboard to get your Signing Secret. Once you have these pieces along with the raw POST body retrieved via , then you can use those components to test generating your own signature.\n\nIf you use real values, this should match exactly the signature from Slack signature in the header.\n\nPulling this all together, the server function will look like:\n\nNow as long as you call in your handlers, you can be confident that the incoming requests are indeed from Slack. Hopefully this will save someone a few minutes!"
    },
    {
        "link": "https://jerrynsh.com/python-exception-handling-patterns-and-best-practices",
        "document": "When it comes to raising exceptions and exception handling in Python, I've often found myself pondering, \"Should I re-raise this exception? Or maybe I should raise it from another exception?\"\n\nYou see, the thing is, there are a bunch of ways to handle exceptions in Python. We’d often just wing it without really grasping the why and when to use these patterns.\n\nIn this little exploration, we’re going to uncover the differences behind these different exception-handling patterns with code examples. Today, we'll be unraveling:\n• When to catch and re-raise an exception?\n• When to raise a new exception?\n• When to avoid using each of the above?\n\nEnough talk, let’s dive right into these exception-raising dilemmas and turn them into informed decisions. As we go through the examples, feel free to copy and paste the code snippet to try it out yourself on something like !\n\nIn this pattern, if an exception occurs during the division operation (e.g., division by zero), the original exception will be re-raised with its traceback.\n\nAs a result, the original exception is propagated all the way up the call stack with its original traceback.\n\nGenerally speaking, this is often a good default pattern for its clarity and preservation of original traceback.\n\nWhy? Preserving traceback information is often considered a good practice as it helps in diagnosing errors effectively and understanding the sequence of events that led to the exception.\n\nIn short, this pattern is used when you want to catch a specific exception ( in this case), do something, and then re-raise the exception. It allows you to perform some specific actions before propagating the exception further.\n\nEffectively the same as not having the block at all\n\nWait what?! Then why do we need the block then?\n\nKnowing this, the block in our previous example might suddenly seem redundant. However, you can imagine scenarios where additional logging or error-handling logic would make the block very useful:\n\nHaving that said, if you do not intend to do any additional stuff, feel free to omit the block.\n\nWhile this is generally a useful pattern, there can be scenarios where it might not be the best choice.\n\nFor instance, you may want to avoid using this pattern when you want to hide sensitive information or when the traceback contains sensitive data that you don't want to expose. Here’s an example:\n\nIn this example, if an exception occurs during the sensitive operation, the original exception is re-raised with its traceback. This pattern may expose sensitive information, such as login failure information in the traceback.\n\nThis is often referred to as \"leaking\" or \"revealing\" information. Exposing detailed login failure information is bad because it aids attackers. They can exploit specifics to guess usernames and launch targeted attacks.\n\nTo prevent this, it's better to handle the exception without re-raising it or to raise a new exception with a more generalized error message (see Pattern 3).\n\nIn this example, a new exception is raised with a custom message, while preserving the original exception's traceback. If a occurs, a new is raised with a custom message.\n\nThe traceback will include both the and the that was raised.\n\nThis pattern is useful when you want to raise a different (more meaningful) type of exception to indicate a specific error condition. This still allows us to preserve the original exception’s traceback.\n\nAvoid using this when you need to preserve the original exception.\n\nPattern 3: Raise New Exception from None\n\nThis pattern is similar to Pattern 2. But, using suppresses the original exception.\n\nHere, the traceback will not include the original , only the exception and the custom error message raised.\n\nSimilar to Pattern 2, you would want to use this pattern when you want to raise a new exception with a custom message.\n\nThe difference here is that this will not include the traceback of the original exception. It is useful when you want to hide the details of the original exception from the user.\n\nIf you are wrapping a library that throws internal exceptions and you want to present transformed external exceptions to your application users.\n\nIn this scenario, using this pattern is a suitable approach. Here’s a simple example:\n\nIn this example, wrapping internal exceptions with external exceptions helps isolate your application code from the specifics of the internal library's implementation. This can come in handy when the users of your code don't need to understand or handle the internal exceptions thrown by the library.\n\nAvoid using this approach when you (or your users) need to understand the full context of where the original exception occurred and how it led to the new exception.\n\nSuppressing exceptions can make it more difficult to track down the root cause of an error, so it should only be done when necessary.\n\nAgain, the exception is caught and a new exception is raised with a custom message.\n\nThough, the clause tells Python to pass the original exception as an argument to the new exception. As a result:\n• This allows the caller of the function to know what the original error was\n• The traceback of the original exception ( ) will be included in the printed traceback of the newly raised exception\n\nThis pattern is commonly used when you want to raise a new exception with a custom message and include the traceback of the original exception as its cause. It is useful when you want to provide both the specific error message and the context of the original exception.\n\nIn terms of best practices – it is generally recommended to use the syntax when raising a new exception from an inner block. This allows us to preserve the stack trace of the original error, which (again) can be helpful for debugging.\n\n\"What's the difference between Pattern 2 vs. Pattern 4 then? They seem awfully similar!\"\n\nIn Pattern 2, the exception is simply raised (from the line ) without being handled. This means that the caller of the function will not be aware of the error.\n\nIn comparison, Pattern 4 is more informative and therefore the better choice in most cases. However, Pattern 2 may be used if the caller of the function does not need to know about the original error.\n\nYou're building a file-processing application that uses an external library for reading and processing files. If the library raises an internal , you want to raise your own custom exception to provide more context and information to the user.\n\nIn this example, the is raised with the context of the original . This provides more information to the user and helps in debugging by maintaining the traceback chain.\n\nAvoid using this pattern when you want to hide the details of the original exception or when the original traceback is not needed (see Pattern 3) to understand the higher-level error.\n\nIn some cases, preserving both tracebacks can be confusing if not handled carefully.\n\nException handling in Python is about dealing with errors in your code. The best way to handle exceptions often depends on what you want to achieve.\n\nAnyway, here’s a TL;DR of what we went through:\n• Pattern 1 (good default): Re-raises the same exception with its original traceback.\n• Pattern 2 (situational): Re-raises a new exception, does not lose original traceback.\n• Pattern 3 (situational): Re-raises a new exception with a chained exception relationship ( ), but loses the original traceback.\n• Pattern 4 (best): Re-raises a new exception with a chained exception relationship ( ), including both the new and the original traceback.\n• Use the syntax when raising a new exception from an inner block. This allows us to preserve the stack trace of the original error.\n• Do not suppress exceptions unless it is absolutely necessary. Suppressing exceptions can make it more difficult to track down the root cause of an error.\n• Use meaningful error messages. The error message should be clear and concise, and it should provide enough information to help the user understand what went wrong.\n• Handle all (possible) errors. It is important to handle all possible errors that your code can throw. This will help to prevent your code from crashing unexpectedly.\n\nRemember, the way you handle exceptions should make your code easy to understand and debug. Always think about what helps you and others know what went wrong and why.\n\nBesides learning the right way to handle exceptions, it's just as important to stop using exceptions like this in Python!"
    },
    {
        "link": "https://medium.com/@saadjamilakhtar/5-best-practices-for-python-exception-handling-5e54b876a20",
        "document": "Exception handling is a fundamental aspect of writing robust and reliable Python code. Just like how a skilled driver navigates through unexpected roadblocks, a proficient programmer gracefully handles exceptions to maintain application stability and provide users with meaningful feedback. In this blog post, we’ll explore the best practices and guidelines for effective exception handling in Python. By following these strategies, you’ll be well-equipped to enhance your code’s resilience and provide a smoother user experience.\n\nCatching specific exceptions is akin to using specialized tools for different tasks. Instead of relying on a generic catch-all statement, it’s essential to catch specific exception types. This practice allows you to differentiate between various errors and deliver accurate error messages, making issue identification and resolution more efficient.\n\nA Real life example would be:\n\nImagine your Python application as a complex puzzle. Error logging acts as your cheat sheet, helping you put the pieces together when things go awry. Utilizing the logging module, you can capture exceptions along with vital information like timestamps, error details, and stack traces. This empowers you to analyze errors comprehensively and enhance the reliability of your application.\n\nThink of custom exception classes as tailored outfits for specific occasions. Python allows you to create custom exception classes that cater to your application’s unique needs. By doing so, you can categorize and encapsulate different errors, leading to better code readability, improved error handling, and modular project development.\n\nHandling exceptions gracefully is like being a composed host at a dinner party when unexpected guests arrive. To prevent application crashes and user confusion, employ try-except blocks to catch exceptions. This allows you to provide suitable error messages or alternative actions. Graceful error handling enhances user experience, maintains application flow, and safeguards against security vulnerabilities.\n\nImagine you’re a responsible party host cleaning up after the festivities. The finally block in exception handling serves a similar purpose. It ensures that certain code will execute regardless of whether an exception occurred or not. This is ideal for performing cleanup tasks, such as closing files or releasing resources, maintaining your application’s integrity."
    },
    {
        "link": "https://stackoverflow.com/questions/839636/best-practices-for-python-exceptions",
        "document": "What are the best practices for creating exceptions? I just saw this, and I don't know if I should be horrified, or like it. I read several times in books that exceptions should never ever hold a string, because strings themselves can throw exceptions. Any real truth to this?\n\nBasically from my understanding from the scripts is that this was done so all the inhouse Python libraries will have a common error message format (something that is desperately needed) so I can understand why putting the error message string is a good idea. (Almost every method throws exceptions due to the utter need for nothing invalid getting through).\n\nThe code in question is the following:\n\nThis is just the tip of the iceberg, but can someone give me some insight in what makes this a terrible idea? Or if there is a much better exception coding process/style."
    },
    {
        "link": "https://docs.python.org/3/tutorial/errors.html",
        "document": "Until now error messages haven’t been more than mentioned, but if you have tried out the examples you have probably seen some. There are (at least) two distinguishable kinds of errors: syntax errors and exceptions.\n\nSyntax errors, also known as parsing errors, are perhaps the most common kind of complaint you get while you are still learning Python: The parser repeats the offending line and displays little arrows pointing at the place where the error was detected. Note that this is not always the place that needs to be fixed. In the example, the error is detected at the function , since a colon ( ) is missing just before it. The file name ( in our example) and line number are printed so you know where to look in case the input came from a file.\n\nEven if a statement or expression is syntactically correct, it may cause an error when an attempt is made to execute it. Errors detected during execution are called exceptions and are not unconditionally fatal: you will soon learn how to handle them in Python programs. Most exceptions are not handled by programs, however, and result in error messages as shown here: File , line , in : File , line , in : name 'spam' is not defined File , line , in : can only concatenate str (not \"int\") to str The last line of the error message indicates what happened. Exceptions come in different types, and the type is printed as part of the message: the types in the example are , and . The string printed as the exception type is the name of the built-in exception that occurred. This is true for all built-in exceptions, but need not be true for user-defined exceptions (although it is a useful convention). Standard exception names are built-in identifiers (not reserved keywords). The rest of the line provides detail based on the type of exception and what caused it. The preceding part of the error message shows the context where the exception occurred, in the form of a stack traceback. In general it contains a stack traceback listing source lines; however, it will not display lines read from standard input. Built-in Exceptions lists the built-in exceptions and their meanings.\n\nIt is possible to write programs that handle selected exceptions. Look at the following example, which asks the user for input until a valid integer has been entered, but allows the user to interrupt the program (using - or whatever the operating system supports); note that a user-generated interruption is signalled by raising the exception. \"Oops! That was no valid number. Try again...\" The statement works as follows.\n• None First, the try clause (the statement(s) between the and keywords) is executed.\n• None If no exception occurs, the except clause is skipped and execution of the statement is finished.\n• None If an exception occurs during execution of the clause, the rest of the clause is skipped. Then, if its type matches the exception named after the keyword, the except clause is executed, and then execution continues after the try/except block.\n• None If an exception occurs which does not match the exception named in the except clause, it is passed on to outer statements; if no handler is found, it is an unhandled exception and execution stops with an error message. A statement may have more than one except clause, to specify handlers for different exceptions. At most one handler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other handlers of the same statement. An except clause may name multiple exceptions as a parenthesized tuple, for example: A class in an clause matches exceptions which are instances of the class itself or one of its derived classes (but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order: Note that if the except clauses were reversed (with first), it would have printed B, B, B — the first matching except clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence and types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance which typically has an attribute that stores the arguments. For convenience, builtin exception types define to print all the arguments without explicitly accessing . # __str__ allows args to be printed directly, # but may be overridden in exception subclasses The exception’s output is printed as the last part (‘detail’) of the message for unhandled exceptions. is the common base class of all exceptions. One of its subclasses, , is the base class of all the non-fatal exceptions. Exceptions which are not subclasses of are not typically handled, because they are used to indicate that the program should terminate. They include which is raised by and which is raised when a user wishes to interrupt the program. can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific as possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate on. The most common pattern for handling is to print or log the exception and then re-raise it (allowing a caller to handle the exception as well): \"Could not convert data to an integer.\" The … statement has an optional else clause, which, when present, must follow all except clauses. It is useful for code that must be executed if the try clause does not raise an exception. For example: The use of the clause is better than adding additional code to the clause because it avoids accidentally catching an exception that wasn’t raised by the code being protected by the … statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur inside functions that are called (even indirectly) in the try clause. For example:\n\nThe statement allows the programmer to force a specified exception to occur. For example: The sole argument to indicates the exception to be raised. This must be either an exception instance or an exception class (a class that derives from , such as or one of its subclasses). If an exception class is passed, it will be implicitly instantiated by calling its constructor with no arguments: If you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the statement allows you to re-raise the exception:\n\nIf an unhandled exception occurs inside an section, it will have the exception being handled attached to it and included in the error message: File , line , in : [Errno 2] No such file or directory: 'database.sqlite' During handling of the above exception, another exception occurred: File , line , in : To indicate that an exception is a direct consequence of another, the statement allows an optional clause: # exc must be exception instance or None. This can be useful when you are transforming exceptions. For example: File , line , in File , line , in The above exception was the direct cause of the following exception: File , line , in : It also allows disabling automatic exception chaining using the idiom: For more information about chaining mechanics, see Built-in Exceptions.\n\nThe statement has another optional clause which is intended to define clean-up actions that must be executed under all circumstances. For example: If a clause is present, the clause will execute as the last task before the statement completes. The clause runs whether or not the statement produces an exception. The following points discuss more complex cases when an exception occurs:\n• None If an exception occurs during execution of the clause, the exception may be handled by an clause. If the exception is not handled by an clause, the exception is re-raised after the clause has been executed.\n• None An exception could occur during execution of an or clause. Again, the exception is re-raised after the clause has been executed.\n• None If the clause executes a , or statement, exceptions are not re-raised.\n• None If the statement reaches a , or statement, the clause will execute just prior to the , or statement’s execution.\n• None If a clause includes a statement, the returned value will be the one from the clause’s statement, not the value from the clause’s statement. As you can see, the clause is executed in any event. The raised by dividing two strings is not handled by the clause and therefore re-raised after the clause has been executed. In real world applications, the clause is useful for releasing external resources (such as files or network connections), regardless of whether the use of the resource was successful.\n\nSome objects define standard clean-up actions to be undertaken when the object is no longer needed, regardless of whether or not the operation using the object succeeded or failed. Look at the following example, which tries to open a file and print its contents to the screen. The problem with this code is that it leaves the file open for an indeterminate amount of time after this part of the code has finished executing. This is not an issue in simple scripts, but can be a problem for larger applications. The statement allows objects like files to be used in a way that ensures they are always cleaned up promptly and correctly. After the statement is executed, the file f is always closed, even if a problem was encountered while processing the lines. Objects which, like files, provide predefined clean-up actions will indicate this in their documentation.\n\nThere are situations where it is necessary to report several exceptions that have occurred. This is often the case in concurrency frameworks, when several tasks may have failed in parallel, but there are also other use cases where it is desirable to continue execution and collect multiple errors rather than raise the first exception. The builtin wraps a list of exception instances so that they can be raised together. It is an exception itself, so it can be caught like any other exception. By using instead of , we can selectively handle only the exceptions in the group that match a certain type. In the following example, which shows a nested exception group, each clause extracts from the group exceptions of a certain type while letting all other exceptions propagate to other clauses and eventually to be reraised. Note that the exceptions nested in an exception group must be instances, not types. This is because in practice the exceptions would typically be ones that have already been raised and caught by the program, along the following pattern:\n\nWhen an exception is created in order to be raised, it is usually initialized with information that describes the error that has occurred. There are cases where it is useful to add information after the exception was caught. For this purpose, exceptions have a method that accepts a string and adds it to the exception’s notes list. The standard traceback rendering includes all notes, in the order they were added, after the exception. For example, when collecting exceptions into an exception group, we may want to add context information for the individual errors. In the following each exception in the group has a note indicating when this error has occurred. | ExceptionGroup: We have some problems (3 sub-exceptions)"
    },
    {
        "link": "https://reviewnprep.com/blog/mastering-exception-handling-in-python-real-life-examples-and-best-practices",
        "document": "Welcome to the beginner’s guide to exception handling in Python! As Python continues to dominate the programming world, it’s essential for developers of all levels to master the art of handling exceptions effectively. Whether you’re just starting out or looking to refresh your skills, this comprehensive guide will take you through the ins and outs of exception handling in Python, using practical examples to bring the concepts to life.\n\nException handling plays a crucial role in writing reliable and robust code, ensuring that your programs gracefully handle unexpected errors and prevent crashes. In this guide, we’ll dive deep into the world of exceptions, exploring the different types of exceptions, how to raise and handle them, and the best practices for error handling in Python.\n\nThrough a series of practical examples, you’ll gain hands-on experience in dealing with common exceptions, such as ValueError, FileNotFoundError, and IndexError. By the end of this guide, you’ll have the confidence and skills to tackle any unforeseen errors that come your way, making your Python programs more resilient and user-friendly.\n\nSo let’s get started on this exception handling journey and level up your Python coding skills!\n\nExceptions are error conditions that disrupt the normal flow of a program. They can occur due to a wide range of reasons, such as invalid input, file operations, or unexpected issues during execution.\n\nThese exceptions halt the normal flow of the program. Without exception handling, our Python scripts would crash whenever they encounter an error condition. By leveraging built-in exception handling tools like the try-except block, we can account for potential exceptions and take appropriate actions.\n\nPython has a wide range of built-in exception classes for different types of errors:\n• – Raised when a module/library cannot be imported\n• – Occurs when trying to access an invalid index in a list, tuple, etc\n• – Happens when using an undeclared variable\n• – Indicates two incompatible types are mixed in an operation\n• – Thrown when dividing by zero\n• – Raised when a file cannot be found at a specified path\n\nAnd many more specialized exceptions…\n\nBeing aware of common error types helps write code that catches the exceptions specific to our program logic and use case.\n\nThe basic structure for handling exceptions in Python is the block. It allows you to catch and handle exceptions gracefully:\n\nThe code inside the try clause is executed. If that code raises no exceptions, then no output from except clause is generated. But if an exception occurs, it is caught and the except block with the matching exception type is executed.\n\nWe can thus anticipate errors and ensure the program doesn’t crash if things go wrong.\n\nUsing Multiple Except Blocks for Different Types of Exceptions\n\nYou can use multiple blocks to handle different types of exceptions:\n\nHaving specific except blocks allow handling exceptions differently instead of generic handling.\n\nThe Else Clause and Finally Clause in Exception Handling\n\nThe clause is executed if the code in the block doesn’t raise any exceptions. The clause is always executed, regardless of whether an exception occurred or not:\n\nThe finally clause helps execute cleanup code like closing files, connections etc irrespective of exceptions.\n\nAlong with built-in exceptions, we can define custom exception classes by subclassing Exception:\n\nWe can raise exceptions manually with raise and catch them later:\n\nThis makes code more readable by separating custom error scenarios.\n\nBest Practices for Exception Handling in Python\n\nHere are some best practices to write clean, robust exception handling:\n• Keep try blocks small and focused to properly handle exceptions\n• Catch specific exceptions instead of generic Exception class to differentiate errors\n• Print custom error messages from except blocks upon failures\n• Use finally clause to execute sections of cleanup code reliably\n• Use blocks only where needed.\n• Don’t wrap your entire code in a massive block; limit it to potential error-prone sections.\n• Avoid using without specifying the exception type, as it can catch unintended errors.\n• Use logging to record exceptions for later analysis.\n\nMastering the basics of exception handling in Python is crucial for writing robust and error-resistant code. By understanding common types of exceptions, using try-except blocks effectively, and following best practices, you can create code that gracefully handles unexpected issues, making your applications more reliable and user-friendly.\n\nWhether you’re working on file operations, game development, or any other project, effective exception handling is a skill that will serve you well in your programming journey.\n\nI hope this guide gave you a solid understanding of key exception handling principles along with actionable coding examples. These learnings will help you eliminate crashes in your Python codebase and handle failures gracefully!"
    }
]