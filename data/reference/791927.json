[
    {
        "link": "https://geeksforgeeks.org/binary-tree-data-structure",
        "document": "A Binary Tree Data Structure is a hierarchical data structure in which each node has at most two children, referred to as the left child and the right child. It is commonly used in computer science for efficient storage and retrieval of data, with various operations such as insertion, deletion, and traversal.\n• None Removing an edge divides in two halves ?\n• None All possible binary trees with given Inorder\n• None Convert a tree to forest of even nodes\n• None Root to leaf paths without using recursion\n• None Check if Preorder, Inorder and Postorder are of same tree\n• None Maximum sum with no two adjacent\n• None Distance between two given keys\n• None Modify a binary tree to get Preorder traversal using right pointers\n• None Full Binary Tree using its Preorder and Mirror's Preorder\n• None Check if there is a root to leaf path with given sequence\n• None Remove all nodes which don’t lie in any path with sum>= k\n• None Sum of nodes at k-th level in a tree represented as string\n• None Sum of all the numbers that are formed from root to leaf paths\n• None Merge Two Binary Trees by doing Node Sum (Recursive and Iterative)\n• None Root of the tree from children ID sums"
    },
    {
        "link": "https://geeksforgeeks.org/binary-tree-in-c",
        "document": "A binary tree is a non-linear hierarchical data structure in which each node has at most two children known as the left child and the right child. It can be visualized as a hierarchical structure where the topmost node is called the root node and the nodes at the bottom are called leaf nodes or leaves.\n\nIn this article, we will learn the basics of binary trees, types of binary trees, basic operations that can be performed on binary trees as well as applications, advantages, and disadvantages of binary trees in C.\n\nEach node of a binary tree has the following 3 parts:\n\nTo create a binary tree, we have to first create a node having a data, pointer to left child and pointer to right child using the below structure format:\n\nTo learn more about binary tree refer: Introduction to Binary Tree – Data Structure and Algorithm Tutorials\n\nBasic Operations on Binary Tree in C\n\nThe following are the basics operations that can performed on a binary tree:\n\nHere, we will learn about three basic operations that can be performed on a binary: insertion, deletion, and searching.\n\nIn a binary tree a new node can be inserted anywhere as a right child or left child of a node. To insert a node in a binary tree, follow the below approach:\n\nIn a binary tree we can delete a node from anywhere and then again rearrange it to maintain the property of binary tree and the leaf nodes can be deleted without performing any replacement and shifting of nodes. To delete a node from a binary tree, follow the below approach:\n\nIn a binary tree we can search a node by traversing and comparing each node with target node (node to be searched). To search for a given node in a binary tree follow the below approach:\n\nThe below program demonstrates all the basic operations on a binary search tree: creation, searching, traversal, insertion and deletion in C.\n\nTime Complexity: O(N), here N is the number of nodes in a binary tree.\n\nAuxilliary Space: O(N)\n\nTypes of Binary Trees in C\n\nBinary trees can be of many types depending on the parameter we took for the classification of the trees. The following are the types of binary trees:\n\nAccording to Number of Children\n• Full Binary Tree : A binary tree in which every node other than the leaves has two children.\n• Degenerate Binary Tree : A tree where each parent node has only one child.\n• Skewed Binary Trees : A binary tree in which all the nodes are skewed to the left or right.\n\nAccording to Completion of Levels\n• Complete Binary Tree : A binary tree in which all levels are completely filled except possibly the last level, and the last level has all keys as left as possible.\n• Perfect Binary Tree : A binary tree in which all the internal nodes have two children and all leaves are at the same level.\n• Balanced Binary Tree : A binary tree in which the height of the left and right subtrees of any node differ by not more than one.\n• Binary Search Tree (BST) : A binary tree in which all the left descendants of a node are less than the node and all the right descendants are greater than the node.\n• AVL Tree : A self-balancing binary search tree where the difference in heights between left and right subtrees is at most one.\n• Red-Black Tree : A binary search tree with an extra bit of storage per node: its color, which can be either red or black. It ensures the tree remains balanced.\n• B Tree : A self-balancing search tree in which nodes can have multiple children and is optimized for systems that read and write large blocks of data.\n• B+ Tree : An extension of the B tree which maintains the data in a sorted order and allows sequential access.\n• Segment Tree : A binary tree used for storing the intervals or segments. It allows querying which of the stored segments contain a given point.\n• Fenwick Tree (Binary Indexed Tree) : A data structure that provides efficient methods for calculation and manipulation of the prefix sums of a table of values.\n\nBinary tree are the versatile data structure widely used in the various applications due to the hierarchical nature and efficient performance in the certain operations. Following are some applications of the binary tree:\n• Full Binary Tree: It is used in the binary heap implementations and it is optimal merge patterns.\n• Complete Binary Tree: It is used in the binary heaps which are useful in the priority queues and it is used in the efficient storage management such as heap sort.\n• Perfect Binary Tree: It is used in the complete binary tree implementation for the efficiency and it is perfect for the implementing full binary trees in the array representations.\n• Balanced Binary Tree: It is used in the AVL and Red-Black trees for the efficient searching operation, insertion operation and deletion operation.\n• Binary Search Tree (BST): It is used in the database indexing and also it is used in the dictionary and phonebook applications. It is also efficient for the search operation, insert operation and delete operation when it was balanced.\n• AVL Tree: It is used in the situations where the search time needs to be minimized. It is database applications where the frequent insertions and deletions are expected.\n• Red-Black Tree: It is used in C++ STL map and multimap implementations.\n• Segment Tree: It is used in the computational geometry for the problems such as finding intersections, range, queries, etc.,\n• Fenwick Tree (Binary Indexed Tree): It is used in the scenarios requiring the dynamic cumulative frequency tables. It is efficient for the frequency queries and updates.\n\nWhat are the applications of Binary Tree?\n\nWhat is the time complexities of basic operations on a Binary Tree?\n\nWhat are the different types of Binary Tree?"
    },
    {
        "link": "https://programiz.com/dsa/binary-tree",
        "document": "A binary tree is a tree data structure in which each parent node can have at most two children. Each node of a binary tree consists of three items:\n\nA full Binary tree is a special type of binary tree in which every parent node/internal node has either two or no children.\n\nTo learn more, please visit full binary tree.\n\nA perfect binary tree is a type of binary tree in which every internal node has exactly two child nodes and all the leaf nodes are at the same level.\n\nTo learn more, please visit perfect binary tree.\n\nA complete binary tree is just like a full binary tree, but with two major differences\n• Every level must be completely filled\n• All the leaf elements must lean towards the left.\n• The last leaf element might not have a right sibling i.e. a complete binary tree doesn't have to be a full binary tree.\n\nTo learn more, please visit complete binary tree.\n\nA degenerate or pathological tree is the tree having a single child either left or right.\n\nA skewed binary tree is a pathological/degenerate tree in which the tree is either dominated by the left nodes or the right nodes. Thus, there are two types of skewed binary tree: left-skewed binary tree and right-skewed binary tree.\n\nIt is a type of binary tree in which the difference between the height of the left and the right subtree for each node is either 0 or 1.\n\nTo learn more, please visit balanced binary tree.\n\nA node of a binary tree is represented by a structure containing a data part and two pointers to other structures of the same type.\n• For easy and quick access to data"
    },
    {
        "link": "https://w3schools.com/dsa/dsa_data_binarytrees.php",
        "document": "A Binary Tree is a type of tree data structure where each node can have a maximum of two child nodes, a left child node and a right child node.\n\nThis restriction, that a node can have a maximum of two child nodes, gives us many benefits:\n• Algorithms like traversing, searching, insertion and deletion become easier to understand, to implement, and run faster.\n• Balancing trees is easier to do with a limited number of child nodes, using an AVL Binary Tree for example.\n• Binary Trees can be represented as arrays, making the tree more memory efficient.\n\nUse the animation below to see how a Binary Tree looks, and what words we use to describe it.\n\nA parent node, or internal node, in a Binary Tree is a node with one or two child nodes.\n\nThe left child node is the child node to the left.\n\nThe right child node is the child node to the right.\n\nThe tree height is the maximum number of edges from the root node to a leaf node.\n\nBenefits of Binary Trees over Arrays and Linked Lists:\n• Arrays are fast when you want to access an element directly, like element number 700 in an array of 1000 elements for example. But inserting and deleting elements require other elements to shift in memory to make place for the new element, or to take the deleted elements place, and that is time consuming.\n• Linked Lists are fast when inserting or deleting nodes, no memory shifting needed, but to access an element inside the list, the list must be traversed, and that takes time.\n• Binary Trees, such as Binary Search Trees and AVL Trees, are great compared to Arrays and Linked Lists because they are BOTH fast at accessing a node, AND fast when it comes to deleting or inserting a node, with no shifts in memory needed.\n\nWe will take a closer look at how Binary Search Trees (BSTs) and AVL Trees work on the next two pages, but first let's look at how a Binary Tree can be implemented, and how it can be traversed.\n\nThere are different variants, or types, of Binary Trees worth discussing to get a better understanding of how Binary Trees can be structured.\n\nThe different kinds of Binary Trees are also worth mentioning now as these words and concepts will be used later in the tutorial.\n\nBelow are short explanations of different types of Binary Tree structures, and below the explanations are drawings of these kinds of structures to make it as easy to understand as possible.\n\nA balanced Binary Tree has at most 1 in difference between its left and right subtree heights, for each node in the tree.\n\nA complete Binary Tree has all levels full of nodes, except the last level, which is can also be full, or filled from left to right. The properties of a complete Binary Tree means it is also balanced.\n\nA full Binary Tree is a kind of tree where each node has either 0 or 2 child nodes.\n\nA perfect Binary Tree has all leaf nodes on the same level, which means that all levels are full of nodes, and all internal nodes have two child nodes.The properties of a perfect Binary Tree means it is also full, balanced, and complete.\n\nThe Binary Tree above can be implemented much like we implemented a Singly Linked List, except that instead of linking each node to one next node, we create a structure where each node can be linked to both its left and right child nodes.\n\nThis is how a Binary Tree can be implemented:\n\nGoing through a Tree by visiting every node, one node at a time, is called traversal.\n\nSince Arrays and Linked Lists are linear data structures, there is only one obvious way to traverse these: start at the first element, or node, and continue to visit the next until you have visited them all.\n\nBut since a Tree can branch out in different directions (non-linear), there are different ways of traversing Trees.\n\nThere are two main categories of Tree traversal methods:\n\nBreadth First Search (BFS) is when the nodes on the same level are visited before going to the next level in the tree. This means that the tree is explored in a more sideways direction.\n\nDepth First Search (DFS) is when the traversal moves down the tree all the way to the leaf nodes, exploring the tree branch by branch in a downwards direction.\n\nThere are three different types of DFS traversals:\n\nThese three Depth First Search traversals are described in detail on the next pages."
    },
    {
        "link": "https://www3.cs.stonybrook.edu/~cse230/CSE230_L12_Binary_Tree.pdf",
        "document": ""
    },
    {
        "link": "https://geeksforgeeks.org/dynamic-memory-allocation-in-c-using-malloc-calloc-free-and-realloc",
        "document": "In C, a variable defined in a function is stored in the stack memory. The requirement of this memory is that it needs to know the size of the data to memory at compile time (before the program runs). Also, once defined, we can neither change the size nor completely delete the memory.\n\nTo resolve this, C provides a feature called Dynamic Memory Allocation. It allows you to allocate memory at runtime, giving your program the ability to handle data of varying sizes. Dynamic resources are stored in the heap memory instead of the stack.\n\nThis feature is useful in a variety of situations. For example, changing the size of an array according to our requirement.\n\nAs we know, the size of an array in C is fixed and should be known at compile time. There can be two problems:\n\nThe size of the array is not sufficient to store all the elements. To resolve this, one might set the size to store the maximum theoretically possible elements. This creates another problem.\n\nThis size of the array is much more than what is required to store the elements. This leads to the wastage of memory.\n\nThis is where the dynamic memory allocation comes in. The size of the array can be increased if more elements are to be inserted and decreased of less elements are inserted. Moreover, there is no need to estimate the max possible size. The size can be decided at runtime according to the requirement.\n\nDynamic memory allocation is possible in C by using 4 library functions provided by <stdlib.h> library:\n\nLet’s discuss each of them one by one.\n\nThe malloc() (stands for memory allocation) function is used to allocate a single block of contiguous memory on the heap at runtime. The memory allocated by malloc() is uninitialized, meaning it contains garbage values.\n\nwhere size is the number of bytes to allocate.\n\nThis function returns a void pointer to the allocated memory that needs to be converted to the pointer of required type to be usable. If allocation fails, it returns NULL pointer.\n\nAssume that we want to create an array to store 5 integers. Since the size of int is 4 bytes, we need 5 * 4 bytes = 20 bytes of memory. This can be done as shown:\n\nIn the above malloc call, we hardcoded the number of bytes we need to store 5 integers. But we know that the size of the integer in C depends on the architecture. So, it is better to use the sizeof operator to find the size of type you want to store.\n\nMoreover, if there is no memory available, the malloc will fail and return NULL. So, it is recommended to check for failure by comparing the ptr to NULL.\n\nThe calloc() (stands for contiguous allocation) function is similar to malloc(), but it initializes the allocated memory to zero. It is used when you need memory with default zero values.\n\nwhere n is the number of elements and size is the size of each element in bytes.\n\nThis function also returns a void pointer to the allocated memory that is converted to the pointer of required type to be usable. If allocation fails, it returns NULL pointer.\n\nWe can take the example of malloc() and try to do it with calloc() function.\n\nThe memory allocated using functions malloc() and calloc() is not de-allocated on their own. The free() function is used to release dynamically allocated memory back to the operating system. It is essential to free memory that is no longer needed to avoid memory leaks.\n\nwhere ptr is the pointer to the allocated memory.\n\nAfter freeing a memory block, the pointer becomes invalid, and it is no longer pointing to a valid memory location.\n\nAfter calling free(), it is a good practice to set the pointer to NULL to avoid using a “dangling pointer,” which points to a memory location that has been deallocated.\n\nrealloc() function is used to resize a previously allocated memory block. It allows you to change the size of an existing memory allocation without needing to free the old memory and allocate a new block.\n\nwhere, ptr is the pointer to the previously allocated memory block and new_size is the reallocated size that the memory block should have in bytes.\n\nThis function returns a pointer to the newly allocated memory, or NULL if the reallocation fails. If it fails, the original memory block remains unchanged.\n\nSuppose we initially allocate memory for 5 integers but later need to expand the array to hold 10 integers. We can use realloc() to resize the memory block:\n\nIt is important to note that if realloc() fails and returns NULL, the original memory block is not freed, so you should not overwrite the original pointer until you’ve successfully allocated a new block. To prevent memory leaks, it’s a good practice to handle the NULL return value carefully:\n\nConsider the first scenario where we were having issues with the fixes size array. Let’s see how we can resolve both of these issues using dynamic memory allocation.\n\nIn this program, we are managing the memory allocated to the pointer ptr according to our needs by changing the size using realloc(). It can be a fun exercise to implement an array which grows according to the elements inserted in it. This kind of arrays are called dynamically growing arrays.\n\nAs useful as dynamic memory allocation is, it is also prone to errors that requires careful handling to avoid the high memory usage or even system crashes. Few of the common errors are given below:\n• Dangling Pointers : Using a pointer after freeing its memory can cause undefined behavior or crashes.\n• Fragmentation : Repeated allocations and deallocations can fragment memory, causing inefficient use of heap space.\n• Allocation Failures : If memory allocation fails, the program may crash unless the error is handled properly.\n\nThe functions malloc() and calloc() works very similar to one another. So, why there was the need for two such similar functions.\n\nIt turns out that even though they are similar, they have different use cases due to the minor difference between them regarding the memory initialization. malloc() does not initialize memory while calloc() initializes the memory with zero.\n\nCan we only create arrays dynamically?\n\nWhat happens if memory allocation fails?\n\nWhat happens when you don’t free memory after allocating?\n\nWhat is the limit of memory that we can allocate using these functions?\n\nCan we set the new size of allocated memory to 0 with realloc()?"
    },
    {
        "link": "https://stackoverflow.com/questions/8477110/which-c-standard-library-functions-use-malloc-under-the-hood",
        "document": "Usually, the only routines in the C99 standard that might use are the standard I/O functions (in where the file structure and the buffer used by it is often allocated as if by . Some of the locale handling may use dynamic memory. All the other routines have no need for dynamic memory allocation in general.\n\nNow, is any of that formally documented? No, I don't think it is. There is no blanket restriction 'the functions in the library shall not use '. (There are, however, restrictions on other functions - such as and and ; they may not be used by the implementation, and the implementation may not use any of the other functions that may return a pointer to a static memory location.) However, one of the reasons why the extremely useful function is not in the standard C library is (reportedly) because it does memory allocation. It also isn't completely clear whether this was a factor in the routines such as and in TR 24731-2 not making it into C1x, but it could have been a factor."
    },
    {
        "link": "https://programiz.com/c-programming/c-dynamic-memory-allocation",
        "document": "As you know, an array is a collection of a fixed number of values. Once the size of an array is declared, you cannot change it.\n\nSometimes the size of the array you declared may be insufficient. To solve this issue, you can allocate memory manually during run-time. This is known as dynamic memory allocation in C programming.\n\nTo allocate memory dynamically, library functions are , , and are used. These functions are defined in the header file.\n\nThe name \"malloc\" stands for memory allocation.\n\nThe function reserves a block of memory of the specified number of bytes. And, it returns a pointer of which can be casted into pointers of any form.\n\nThe above statement allocates 400 bytes of memory. It's because the size of is 4 bytes. And, the pointer holds the address of the first byte in the allocated memory.\n\nThe expression results in a pointer if the memory cannot be allocated.\n\nThe name \"calloc\" stands for contiguous allocation.\n\nThe function allocates memory and leaves the memory uninitialized, whereas the function allocates memory and initializes all bits to zero.\n\nThe above statement allocates contiguous space in memory for 25 elements of type .\n\nDynamically allocated memory created with either or doesn't get freed on their own. You must explicitly use to release the space.\n\nThis statement frees the space allocated in the memory pointed by .\n\nHere, we have dynamically allocated the memory for number of .\n\nIf the dynamically allocated memory is insufficient or more than required, you can change the size of previously allocated memory using the function.\n\nHere, is reallocated with a new size ."
    },
    {
        "link": "https://design-reuse.com/articles/25090/dynamic-memory-allocation-fragmentation-c.html",
        "document": "In C and C++, it can be very convenient to allocate and de-allocate blocks of memory as and when needed. This is certainly standard practice in both languages and almost unavoidable in C++. However, the handling of such dynamic memory can be problematic and inefficient. For desktop applications, where memory is freely available, these difficulties can be ignored. For embedded - generally real time - applications, ignoring the issues is not an option.\n\nDynamic memory allocation tends to be nondeterministic; the time taken to allocate memory may not be predictable and the memory pool may become fragmented, resulting in unexpected allocation failures. In this session the problems will be outlined in detail and an approach to deterministic dynamic memory allocation detailed.\n\nIt may be useful to think in terms of data memory in C and C++ as being divided into three separate spaces:\n\nStatic memory. This is where variables, which are defined outside of functions, are located. The keyword static does not generally affect where such variables are located; it specifies their scope to be local to the current module. Variables that are defined inside of a function, which are explicitly declared static, are also stored in static memory. Commonly, static memory is located at the beginning of the RAM area. The actual allocation of addresses to variables is performed by the embedded software development toolkit: a collaboration between the compiler and the linker. Normally, program sections are used to control placement, but more advanced techniques, like Fine Grain Allocation, give more control. Commonly, all the remaining memory, which is not used for static storage, is used to constitute the dynamic storage area, which accommodates the other two memory spaces.\n\nAutomatic variables. Variables defined inside a function, which are not declared static, are automatic. There is a keyword to explicitly declare such a variable – auto – but it is almost never used. Automatic variables (and function parameters) are usually stored on the stack. The stack is normally located using the linker. The end of the dynamic storage area is typically used for the stack. Compiler optimizations may result in variables being stored in registers for part or all of their lifetimes; this may also be suggested by using the keyword register.\n\nThe heap. The remainder of the dynamic storage area is commonly allocated to the heap, from which application programs may dynamically allocate memory, as required.\n\nIn C, dynamic memory is allocated from the heap using some standard library functions. The two key dynamic memory functions are malloc() and free().\n\nThe malloc() function takes a single parameter, which is the size of the requested memory area in bytes. It returns a pointer to the allocated memory. If the allocation fails, it returns NULL. The prototype for the standard library function is like this:\n\nThe free() function takes the pointer returned by malloc() and de-allocates the memory. No indication of success or failure is returned. The function prototype is like this:\n\nTo illustrate the use of these functions, here is some code to statically define an array and set the fourth element’s value:\n\nThe following code does the same job using dynamic memory allocation:\n\nThe pointer de-referencing syntax is hard to read, so normal array referencing syntax may be used, as [ and ] are just operators:\n\nWhen the array is no longer needed, the memory may be de-allocated thus:\n\nAssigning NULL to the pointer is not compulsory, but is good practice, as it will cause an error to be generated if the pointer is erroneous utilized after the memory has been de-allocated.\n\nThe amount of heap space actually allocated by malloc() is normally one word larger than that requested. The additional word is used to hold the size of the allocation and is for later use by free(). This “size word” precedes the data area to which malloc() returns a pointer.\n\nThere are two other variants of the malloc() function: calloc() and realloc().\n\nThe calloc() function does basically the same job as malloc(), except that it takes two parameters – the number of array elements and the size of each element – instead of a single parameter (which is the product of these two values). The allocated memory is also initialized to zeros. Here is the prototype:\n\nThe realloc() function resizes a memory allocation previously made by malloc(). It takes as parameters a pointer to the memory area and the new size that is required. If the size is reduced, data may be lost. If the size is increased and the function is unable to extend the existing allocation, it will automatically allocate a new memory area and copy data across. In any case, it returns a pointer to the allocated memory. Here is the prototype:\n\nManagement of dynamic memory in C++ is quite similar to C in most respects. Although the library functions are likely to be available, C++ has two additional operators – new and delete – which enable code to be written more clearly, succinctly and flexibly, with less likelihood of errors. The new operator can be used in three ways:\n\np_var = new typename;\n\n p_var = new type(initializer);\n\n p_array = new type [size];\n\nIn the first two cases, space for a single object is allocated; the second one includes initialization. The third case is the mechanism for allocating space for an array of objects.\n\nThe delete operator can be invoked in two ways:\n\nThe first is for a single object; the second deallocates the space used by an array. It is very important to use the correct de-allocator in each case.\n\nThere is no operator that provides the functionality of the C realloc() function.\n\nHere is the code to dynamically allocate an array and initialize the fourth element:\n\nUsing the array access notation is natural. De-allocation is performed thus:\n\nAgain, assigning NULL to the pointer after deallocation is just good programming practice. Another option for managing dynamic memory in C++ is the use the Standard Template Library. This may be inadvisable for real time embedded systems.\n\nAs a general rule, dynamic behavior is troublesome in real time embedded systems. The two key areas of concern are determination of the action to be taken on resource exhaustion and nondeterministic execution performance.\n\nThere are a number of problems with dynamic memory allocation in a real time system. The standard library functions (malloc() and free()) are not normally reentrant, which would be problematic in a multithreaded application. If the source code is available, this should be straightforward to rectify by locking resources using RTOS facilities (like a semaphore). A more intractable problem is associated with the performance of malloc(). Its behavior is unpredictable, as the time it takes to allocate memory is extremely variable. Such nondeterministic behavior is intolerable in real time systems.\n\nWithout great care, it is easy to introduce memory leaks into application code implemented using malloc() and free(). This is caused by memory being allocated and never being deallocated. Such errors tend to cause a gradual performance degradation and eventual failure. This type of bug can be very hard to locate.\n\nMemory allocation failure is a concern. Unlike a desktop application, most embedded systems do not have the opportunity to pop up a dialog and discuss options with the user. Often, resetting is the only option, which is unattractive. If allocation failures are encountered during testing, care must be taken with diagnosing their cause. It may be that there is simply insufficient memory available – this suggests various courses of action. However, it may be that there is sufficient memory, but not available in one contiguous chunk that can satisfy the allocation request. This situation is called memory fragmentation.\n\nThe best way to understand memory fragmentation is to look at an example. For this example, it is assumed hat there is a 10K heap. First, an area of 3K is requested, thus:\n\nThen, a further 4K is requested:\n\n3K of memory is now free.\n\nSome time later, the first memory allocation, pointed to by p1, is de-allocated:\n\nThis leaves 6K of memory free in two 3K chunks. A further request for a 4K allocation is issued:\n\nThis results in a failure – NULL is returned into p1 – because, even though 6K of memory is available, there is not a 4K contiguous block available. This is memory fragmentation.\n\nIt would seem that an obvious solution would be to de-fragment the memory, merging the two 3K blocks to make a single one of 6K. However, this is not possible because it would entail moving the 4K block to which p2 points. Moving it would change its address, so any code that has taken a copy of the pointer would then be broken. In other languages (such as Visual Basic, Java and C#), there are defragmentation (or “garbage collection”) facilities. This is only possible because these languages do not support direct pointers, so moving the data has no adverse effect upon application code. This defragmentation may occur when a memory allocation fails or there may be a periodic garbage collection process that is run. In either case, this would severely compromise real time performance and determinism.\n\nA real time operating system may provide a service which is effectively a reentrant form of malloc(). However, it is unlikely that this facility would be deterministic.\n\nMemory management facilities that are compatible with real time requirements – i.e. they are deterministic – are usually provided. This is most commonly a scheme which allocates blocks – or “partitions” – of memory under the control of the OS.\n\nTypically, block memory allocation is performed using a “partition pool”, which is defined statically or dynamically and configured to contain a specified number of blocks of a specified fixed size. For Nucleus OS, the API call to define a partition pool has the following prototype:\n\nThis is most clearly understood by means of an example:\n\nThis creates a partition pool with the descriptor MyPool, containing 2000 bytes of memory, filled with partitions of size 40 bytes (i.e. there are 50 partitions). The pool is located at address 0xB000. The pool is configured such that, if a task attempts to allocate a block, when there are none available, and it requests to be suspended on the allocation API call, suspended tasks will be woken up in a first-in, first-out order. The other option would have been task priority order.\n\nAnother API call is available to request allocation of a partition. Here is an example using Nucleus OS:\n\nThis requests the allocation of a partition from MyPool. When successful, a pointer to the allocated block is returned in ptr. If no memory is available, the task is suspended, because NU_SUSPEND was specified; other options, which may have been selected, would have been to suspend with a timeout or to simply return with an error.\n\nWhen the partition is no longer required, it may be de-allocated thus:\n\nIf a task of higher priority was suspended pending availability of a partition, it would now be run. There is no possibility for fragmentation, as only fixed size blocks are available. The only failure mode is true resource exhaustion, which may be controlled and contained using task suspend, as shown.\n\nAdditional API calls are available which can provide the application code with information about the status of the partition pool – for example, how many free partitions are currently available. Care is required in allocating and de-allocating partitions, as the possibility for the introduction of memory leaks remains.\n\nThe potential for programmer error resulting in a memory leak when using partition pools is recognized by vendors of real time operating systems. Typically, a profiler tool is available which assists with the location and rectification of such bugs.\n\nHaving identified a number of problems with dynamic memory behavior in real time systems, some possible solutions and better approaches can be proposed.\n\nIt is possible to use partition memory allocation to implement malloc() in a robust and deterministic fashion. The idea is to define a series of partition pools with block sizes in a geometric progression; e.g. 32, 64, 128, 256 bytes. A malloc() function may be written to deterministically select the correct pool to provide enough space for a given allocation request. This approach takes advantage of the deterministic behavior of the partition allocation API call, the robust error handling (e.g. task suspend) and the immunity from fragmentation offered by block memory.\n\nC and C++ use memory in various ways, both static and dynamic. Dynamic memory includes stack and heap.\n\nDynamic behavior in embedded real time systems is generally a source of concern, as it tends to be non-deterministic and failure is hard to contain.\n\nUsing the facilities provided by most real time operating systems, a dynamic memory facility may be implemented which is deterministic, immune from fragmentation and with good error handling."
    },
    {
        "link": "https://en.wikipedia.org/wiki/C_dynamic_memory_allocation",
        "document": "Dynamic memory management in the C programming language\n\nC dynamic memory allocation refers to performing manual memory management for dynamic memory allocation in the C programming language via a group of functions in the C standard library, namely malloc, realloc, calloc, aligned_alloc and free.[1][2][3]\n\nThe C++ programming language includes these functions; however, the operators new and delete provide similar functionality and are recommended by that language's authors.[4] Still, there are several situations in which using / is not applicable, such as garbage collection code or performance-sensitive code, and a combination of and placement may be required instead of the higher-level operator.\n\nMany different implementations of the actual memory allocation mechanism, used by malloc, are available. Their performance varies in both execution time and required memory.\n\nThe C programming language manages memory statically, automatically, or dynamically. Static-duration variables are allocated in main memory, usually along with the executable code of the program, and persist for the lifetime of the program; automatic-duration variables are allocated on the stack and come and go as functions are called and return. For static-duration and automatic-duration variables, the size of the allocation must be compile-time constant (except for the case of variable-length automatic arrays[5]). If the required size is not known until run-time (for example, if data of arbitrary size is being read from the user or from a disk file), then using fixed-size data objects is inadequate.\n\nThe lifetime of allocated memory can also cause concern. Neither static- nor automatic-duration memory is adequate for all situations. Automatic-allocated data cannot persist across multiple function calls, while static data persists for the life of the program whether it is needed or not. In many situations the programmer requires greater flexibility in managing the lifetime of allocated memory.\n\nThese limitations are avoided by using dynamic memory allocation, in which memory is more explicitly (but more flexibly) managed, typically by allocating it from the free store (informally called the \"heap\"),[citation needed] an area of memory structured for this purpose. In C, the library function is used to allocate a block of memory on the heap. The program accesses this block of memory via a pointer that returns. When the memory is no longer needed, the pointer is passed to which deallocates the memory so that it can be used for other purposes.\n\nThe original description of C indicated that and were in the standard library, but not . Code for a simple model implementation of a storage manager for Unix was given with and as the user interface functions, and using the system call to request memory from the operating system.[6] The 6th Edition Unix documentation gives and as the low-level memory allocation functions.[7] The and routines in their modern form are completely described in the 7th Edition Unix manual.[8][9]\n\nSome platforms provide library or intrinsic function calls which allow run-time dynamic allocation from the C stack rather than the heap (e.g. [10]). This memory is automatically freed when the calling function ends.\n\nThe C dynamic memory allocation functions are defined in header ( header in C++).[1]\n• takes a single argument (the amount of memory to allocate in bytes), while takes two arguments — the number of elements and the size of each element.\n• only allocates memory, while allocates and sets the bytes in the allocated region to zero. 11\n\nCreating an array of ten integers with automatic scope is straightforward in C:\n\nHowever, the size of the array is fixed at compile time. If one wishes to allocate a similar array dynamically without using a variable-length array, which is not guaranteed to be supported in all C11 implementations, the following code can be used:\n\nThis computes the number of bytes that ten integers occupy in memory, then requests that many bytes from and assigns the result to a pointer named (due to C syntax, pointers and arrays can be used interchangeably in some situations).\n\nBecause might not be able to service the request, it might return a null pointer and it is good programming practice to check for this:\n\nWhen the program no longer needs the dynamic array, it must eventually call to return the memory it occupies to the free store:\n\nThe memory set aside by is not initialized and may contain cruft: the remnants of previously used and discarded data. After allocation with , elements of the array are uninitialized variables. The command will return an allocation that has already been cleared:\n\nWith realloc we can resize the amount of memory a pointer points to. For example, if we have a pointer acting as an array of size and we want to change it to an array of size , we can use realloc.\n\nNote that realloc must be assumed to have changed the base address of the block (i.e. if it has failed to extend the size of the original block, and has therefore allocated a new larger block elsewhere and copied the old contents into it). Therefore, any pointers to addresses within the original block are also no longer valid.\n\nreturns a void pointer ( ), which indicates that it is a pointer to a region of unknown data type. The use of casting is required in C++ due to the strong type system, whereas this is not the case in C. One may \"cast\" (see type conversion) this pointer to a specific type:\n\nThere are advantages and disadvantages to performing such a cast.\n• Including the cast may allow a C program or function to compile as C++.\n• The cast allows for pre-1989 versions of that originally returned a . 12\n• Casting can help the developer identify inconsistencies in type sizing should the destination pointer type change, particularly if the pointer is declared far from the call (although modern compilers and static analysers can warn on such behaviour without requiring the cast 13 ).\n• Under the C standard, the cast is redundant.\n• Adding the cast may mask failure to include the header , in which the function prototype for is found. 12 14 In the absence of a prototype for , the C90 standard requires that the C compiler assume returns an . If there is no cast, C90 requires a diagnostic when this integer is assigned to the pointer; however, with the cast, this diagnostic would not be produced, hiding a bug. On certain architectures and data models (such as LP64 on 64-bit systems, where and pointers are 64-bit and is 32-bit), this error can actually result in undefined behaviour, as the implicitly declared returns a 32-bit value whereas the actually defined function returns a 64-bit value. Depending on calling conventions and memory layout, this may result in stack smashing. This issue is less likely to go unnoticed in modern compilers, as C99 does not permit implicit declarations, so the compiler must produce a diagnostic even if it does assume return.\n• If the type of the pointer is changed at its declaration, one may also need to change all lines where is called and cast.\n\nThe improper use of dynamic memory allocation can frequently be a source of bugs. These can include security bugs or program crashes, most often due to segmentation faults.\n\nMost common errors are as follows:[15]\n\nIn addition, as an interface that precedes ANSI C standardization, and its associated functions have behaviors that were intentionally left to the implementation to define for themselves. One of them is the zero-length allocation, which is more of a problem with since it is more common to resize to zero.[16] Although both POSIX and the Single Unix Specification require proper handling of 0-size allocations by either returning or something else that can be safely freed,[17] not all platforms are required to abide by these rules. Among the many double-free errors that it has led to, the 2019 WhatsApp RCE was especially prominent.[18] A way to wrap these functions to make them safer is by simply checking for 0-size allocations and turning them into those of size 1. (Returning has its own problems: it otherwise indicates an out-of-memory failure. In the case of it would have signaled that the original memory was not moved and freed, which again is not the case for size 0, leading to the double-free.)[19]\n\nThe implementation of memory management depends greatly upon operating system and architecture. Some operating systems supply an allocator for malloc, while others supply functions to control certain regions of data. The same dynamic memory allocator is often used to implement both and the operator in C++.[20]\n\nImplementation of legacy allocators was commonly done using the heap segment. The allocator would usually expand and contract the heap to fulfill allocation requests.\n\nThe heap method suffers from a few inherent flaws:\n• A linear allocator can only shrink if the last allocation is released. Even if largely unused, the heap can get \"stuck\" at a very large size because of a small but long-lived allocation at its tip which could waste any amount of address space, although some allocators on some systems may be able to release entirely empty intermediate pages to the OS.\n• A linear allocator is sensitive to fragmentation. A good allocator will attempt to track and reuse free slots through the entire heap, but as allocation sizes and lifetimes get mixed it can be difficult and expensive to find or coalesce free segments large enough to hold new allocation requests.\n• A linear allocator has extremely poor concurrency characteristics, as the heap segment is per-process every thread has to synchronise on allocation, and concurrent allocations from threads which may have very different work loads amplifies the previous two issues.\n\nDoug Lea has developed the public domain dlmalloc (\"Doug Lea's Malloc\") as a general-purpose allocator, starting in 1987. The GNU C library (glibc) is derived from Wolfram Gloger's ptmalloc (\"pthreads malloc\"), a fork of dlmalloc with threading-related improvements.[21][22][23] As of November 2023, the latest version of dlmalloc is version 2.8.6 from August 2012.[24]\n\ndlmalloc is a boundary tag allocator. Memory on the heap is allocated as \"chunks\", an 8-byte aligned data structure which contains a header, and usable memory. Allocated memory contains an 8- or 16-byte overhead for the size of the chunk and usage flags (similar to a dope vector). Unallocated chunks also store pointers to other free chunks in the usable space area, making the minimum chunk size 16 bytes on 32-bit systems and 24/32 (depends on alignment) bytes on 64-bit systems.[22][24]: 2.8.6, Minimum allocated size\n\nUnallocated memory is grouped into \"bins\" of similar sizes, implemented by using a double-linked list of chunks (with pointers stored in the unallocated space inside the chunk). Bins are sorted by size into three classes:[22][24]: Overlaid data structures\n• For requests below 256 bytes (a \"smallbin\" request), a simple two power best fit allocator is used. If there are no free blocks in that bin, a block from the next highest bin is split in two.\n• For requests of 256 bytes or above but below the mmap threshold, dlmalloc since v2.8.0 use an in-place bitwise trie algorithm (\"treebin\"). If there is no free space left to satisfy the request, dlmalloc tries to increase the size of the heap, usually via the brk system call. This feature was introduced way after ptmalloc was created (from v2.7.x), and as a result is not a part of glibc, which inherits the old best-fit allocator.\n• For requests above the mmap threshold (a \"largebin\" request), the memory is always allocated using the mmap system call. The threshold is usually 128 KB. 25 The mmap method averts problems with huge buffers trapping a small allocation at the end after their expiration, but always allocates an entire page of memory, which on many architectures is 4096 bytes in size. 26\n\nGame developer Adrian Stone argues that , as a boundary-tag allocator, is unfriendly for console systems that have virtual memory but do not have demand paging. This is because its pool-shrinking and growing callbacks ( / ) cannot be used to allocate and commit individual pages of virtual memory. In the absence of demand paging, fragmentation becomes a greater concern.[27]\n\nSince FreeBSD 7.0 and NetBSD 5.0, the old implementation ( by Poul-Henning Kamp) was replaced by jemalloc, written by Jason Evans. The main reason for this was a lack of scalability of in terms of multithreading. In order to avoid lock contention, uses separate \"arenas\" for each CPU. Experiments measuring number of allocations per second in multithreading application have shown that this makes it scale linearly with the number of threads, while for both phkmalloc and dlmalloc performance was inversely proportional to the number of threads.[28]\n\nOpenBSD's implementation of the function makes use of mmap. For requests greater in size than one page, the entire allocation is retrieved using ; smaller sizes are assigned from memory pools maintained by within a number of \"bucket pages\", also allocated with .[29][better source needed] On a call to , memory is released and unmapped from the process address space using . This system is designed to improve security by taking advantage of the address space layout randomization and gap page features implemented as part of OpenBSD's system call, and to detect use-after-free bugs—as a large memory allocation is completely unmapped after it is freed, further use causes a segmentation fault and termination of the program.\n\nThe GrapheneOS project initially started out by porting OpenBSD's memory allocator to Android's Bionic C Library.[30]\n\nHoard is an allocator whose goal is scalable memory allocation performance. Like OpenBSD's allocator, Hoard uses exclusively, but manages memory in chunks of 64 kilobytes called superblocks. Hoard's heap is logically divided into a single global heap and a number of per-processor heaps. In addition, there is a thread-local cache that can hold a limited number of superblocks. By allocating only from superblocks on the local per-thread or per-processor heap, and moving mostly-empty superblocks to the global heap so they can be reused by other processors, Hoard keeps fragmentation low while achieving near linear scalability with the number of threads.[31]\n\nAn open-source compact general-purpose memory allocator from Microsoft Research with focus on performance.[32] The library is about 11,000 lines of code.\n\nEvery thread has a thread-local storage for small allocations. For large allocations mmap or sbrk can be used. TCMalloc, a malloc developed by Google,[33] has garbage-collection for local storage of dead threads. The TCMalloc is considered to be more than twice as fast as glibc's ptmalloc for multithreaded programs.[34][35]\n\nOperating system kernels need to allocate memory just as application programs do. The implementation of within a kernel often differs significantly from the implementations used by C libraries, however. For example, memory buffers might need to conform to special restrictions imposed by DMA, or the memory allocation function might be called from interrupt context.[36] This necessitates a implementation tightly integrated with the virtual memory subsystem of the operating system kernel.\n\nBecause and its relatives can have a strong impact on the performance of a program, it is not uncommon to override the functions for a specific application by custom implementations that are optimized for application's allocation patterns. The C standard provides no way of doing this, but operating systems have found various ways to do this by exploiting dynamic linking. One way is to simply link in a different library to override the symbols. Another, employed by Unix System V.3, is to make and function pointers that an application can reset to custom functions.[37]\n\nThe most common form on POSIX-like systems is to set the environment variable LD_PRELOAD with the path of the allocator, so that the dynamic linker uses that version of malloc/calloc/free instead of the libc implementation.\n\nThe largest possible memory block can allocate depends on the host system, particularly the size of physical memory and the operating system implementation.\n\nTheoretically, the largest number should be the maximum value that can be held in a type, which is an implementation-dependent unsigned integer representing the size of an area of memory. In the C99 standard and later, it is available as the constant from . Although not guaranteed by ISO C, it is usually .\n\nOn glibc systems, the largest possible memory block can allocate is only half this size, namely .[38]\n\nThe C library implementations shipping with various operating systems and compilers may come with alternatives and extensions to the standard interface. Notable among these is:\n• , which allocates a requested number of bytes on the call stack. No corresponding deallocation function exists, as typically the memory is deallocated as soon as the calling function returns. was present on Unix systems as early as 32/V (1978), but its use can be problematic in some (e.g., embedded) contexts. 39 While supported by many compilers, it is not part of the ANSI-C standard and therefore may not always be portable. It may also cause minor performance problems: it leads to variable-size stack frames, so that both stack and frame pointers need to be managed (with fixed-size stack frames, one of these is redundant). 40 Larger allocations may also increase the risk of undefined behavior due to a stack overflow. 41 C99 offered variable-length arrays as an alternative stack allocation mechanism – however, this feature was relegated to optional in the later C11 standard.\n• POSIX defines a function that allocates memory with caller-specified alignment. Its allocations are deallocated with , 42 so the implementation usually needs to be a part of the malloc library.\n• Lea, Doug; The design of the basis of the glibc allocator\n• Bartlett, Jonathan; Inside memory management – The choices, tradeoffs, and implementations of dynamic allocation\n• Memory Reduction (GNOME) wiki page with much information about fixing malloc\n• Some useful references about C"
    }
]