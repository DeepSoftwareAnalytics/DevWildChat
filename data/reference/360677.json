[
    {
        "link": "https://jsonapi.org",
        "document": "If you’ve ever argued with your team about the way your JSON responses should be formatted, JSON:API can help you stop the bikeshedding and focus on what matters: your application.\n\nBy following shared conventions, you can increase productivity, take advantage of generalized tooling and best practices. Clients built around JSON:API are able to take advantage of its features around efficiently caching responses, sometimes eliminating network requests entirely.\n\nHere’s an example response from a blog that implements JSON:API:\n\nThe response above contains the first in a collection of “articles”, as well as links to subsequent members in that collection. It also contains resources linked to the article, including its author and comments. Last but not least, links are provided that can be used to fetch or update any of these resources.\n\nJSON:API covers creating and updating resources as well, not just responses.\n\nJSON:API has been properly registered with the IANA. Its media type designation is .\n\nTo get started with JSON:API, check out documentation for the base specification.\n\nThe JSON:API community has created a collection of extensions that APIs can use to provide clients with information or functionality beyond that described in the base JSON:API specification. These extensions are called profiles.\n\nYou can browse existing profiles or create a new one.\n\nA more thorough history is available here.\n\nYou can subscribe to an RSS feed of individual changes here."
    },
    {
        "link": "https://jsonapi.org/format",
        "document": "This page presents the latest published version of JSON:API, which is currently version 1.1. New versions of JSON:API will always be backwards compatible using a never remove, only add strategy. Additions can be proposed in our discussion forum.\n\nIf you catch an error in the specification’s text, or if you write an implementation, please let us know by opening an issue or pull request at our GitHub repository.\n\nJSON:API is a specification for how a client should request that resources be fetched or modified, and how a server should respond to those requests. JSON:API can be easily extended with extensions and profiles.\n\nJSON:API is designed to minimize both the number of requests and the amount of data transmitted between clients and servers. This efficiency is achieved without compromising readability, flexibility, or discoverability.\n\nJSON:API requires use of the JSON:API media type ( ) for exchanging data.\n\nAll document members, query parameters, and processing rules defined by this specification are collectively called “specification semantics”.\n\nCertain document members, query parameters, and processing rules are reserved for implementors to define at their discretion. These are called “implementation semantics”.\n\nAll other semantics are reserved for potential future use by this specification.\n\nThe key words “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “NOT RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in BCP 14 [RFC2119] [RFC8174] when, and only when, they appear in all capitals, as shown here.\n\nThe JSON:API specification supports two media type parameters: and , which are used to specify extensions and profiles, respectively.\n\nExtensions provide a means to “extend” the base specification by defining additional specification semantics.\n\nExtensions cannot alter or remove specification semantics, nor can they specify implementation semantics.\n\nProfiles provide a means to share a particular usage of the specification among implementations.\n\nProfiles can specify implementation semantics, but cannot alter, add to, or remove specification semantics.\n\nThe JSON:API media type MUST NOT be specified with any media type parameters other than and . The parameter is used to support extensions and the parameter is used to support profiles.\n\nExtensions and profiles are each uniquely identified by a URI. Visiting an extension’s or a profile’s URI SHOULD return documentation that describes its usage. The values of the and parameters MUST equal a space-separated (U+0020 SPACE, “ “) list of extension or profile URIs, respectively.\n\nAn extension MAY impose additional processing rules or further restrictions and it MAY define new object members as described below.\n\nAn extension MUST NOT lessen or remove any processing rules, restrictions or object member requirements defined in this specification or other extensions.\n\nAn extension MAY define new members within the document structure defined by this specification. The rules for extension member names are covered below.\n\nAn extension MAY define new query parameters. The rules for extension-defined query parameters are covered below.\n\nWhen an extension defines new query parameters or document members, the extension MUST define a namespace to guarantee that extensions will never conflict with current or future versions of this specification. A namespace MUST meet all of the following conditions:\n• A namespace MUST contain at least one character.\n• A namespace MUST contain only these characters:\n\nAn extension MUST NOT define more than one namespace. The namespace used for all query parameters and document members MUST be the same for any given extension.\n\nIn the following example, an extension with the namespace has specified a resource object member to support per-resource versioning. This member might appear as follows:\n\nThe rules for profile usage are dictated by RFC 6906.\n\nA profile MAY define document members and processing rules that are reserved for implementors.\n\nA profile MUST NOT define any query parameters except implementation-specific query parameters.\n\nA profile MUST NOT alter or remove processing rules that have been defined by this specification or by an extension. However, a profile MAY define processing rules for query parameters whose processing rules have been reserved for implementors to define at their discretion.\n\nFor example, a profile could define rules for interpreting the query parameter, but it could not specify that relationship names in the query parameter are space-separated instead of dot-separated.\n\nUnlike extensions, profiles do not need to define a namespace for document members because profiles cannot define specification semantics and thus cannot conflict with current or future versions of this specification. However, it is possible for profiles to conflict with other profiles. Therefore, it is the responsibility of implementors to ensure that they do not support conflicting profiles.\n\nIn the following example, a profile has defined a attribute. According to the profile, the attribute must be an object containing a member and a member and these members’ values must use the RFC 3339 format. With such a profile applied, a response might appear as follows:\n\nClients and servers MUST send all JSON:API payloads using the JSON:API media type in the header.\n\nClients and servers MUST specify the media type parameter in the header when they have applied one or more extensions to a JSON:API document.\n\nClients and servers MUST specify the media type parameters in the header when they have applied one or more profiles to a JSON:API document.\n\nWhen processing a JSON:API response document, clients MUST ignore any parameters other than and parameters in the server’s header.\n\nA client MAY use the media type parameter in an header to require that a server apply all the specified extensions to the response document.\n\nA client MAY use the media type parameter in an header to request that the server apply one or more profiles to the response document.\n\nIf a request specifies the header with the JSON:API media type, servers MUST respond with a status code if that media type contains any media type parameters other than or .\n\nIf a request specifies the header with an instance of the JSON:API media type modified by the media type parameter and that parameter contains an unsupported extension URI, the server MUST respond with a status code.\n\nIf a request’s header contains an instance of the JSON:API media type, servers MUST ignore instances of that media type which are modified by a media type parameter other than or . If all instances of that media type are modified with a media type parameter other than or , servers MUST respond with a status code. If every instance of that media type is modified by the parameter and each contains at least one unsupported extension URI, the server MUST also respond with a .\n\nIf the parameter is received, a server SHOULD attempt to apply any requested profile(s) to its response. A server MUST ignore any profiles that it does not recognize.\n\nServers that support the or media type parameters SHOULD specify the header with as one of its values. This applies to responses with and without any profiles or extensions applied.\n\nThis section describes the structure of a JSON:API document, which is identified by the JSON:API media type. JSON:API documents are defined in JavaScript Object Notation (JSON) [RFC8259].\n\nAlthough the same media type is used for both request and response documents, certain aspects are only applicable to one or the other. These differences are called out below.\n\nExtensions MAY define new members within the document structure. These members MUST comply with the naming requirements specified below.\n\nUnless otherwise noted, objects defined by this specification or any applied extensions MUST NOT contain any additional members. Client and server implementations MUST ignore non-compliant members.\n\nA JSON object MUST be at the root of every JSON:API request and response document containing data. This object defines a document’s “top level”.\n\nA document MUST contain at least one of the following top-level members:\n\nThe members and MUST NOT coexist in the same document.\n\nA document MAY contain any of these top-level members:\n• : a links object related to the document as a whole.\n• : an array of resource objects that are related to the primary data and/or each other (“included resources”).\n\nIf a document does not contain a top-level key, the member MUST NOT be present either.\n\nThe top-level links object MAY contain the following members:\n• : the link that generated the current response document. If a document has extensions or profiles applied to it, this link SHOULD be represented by a link object with the target attribute specifying the JSON:API media type with all applicable parameters.\n• : a link to a description document (e.g. OpenAPI or JSON Schema) for the current document.\n\nThe document’s “primary data” is a representation of the resource or collection of resources targeted by a request.\n\nPrimary data MUST be either:\n• a single resource object, a single resource identifier object, or , for requests that target single resources\n• an array of resource objects, an array of resource identifier objects, or an empty array ( ), for requests that target resource collections\n\nFor example, the following primary data is a single resource object:\n\nThe following primary data is a single resource identifier object that references the same resource:\n\nA logical collection of resources MUST be represented as an array, even if it only contains one item or is empty.\n\n“Resource objects” appear in a JSON:API document to represent resources.\n\nA resource object MUST contain at least the following top-level members:\n\nException: The member is not required when the resource object originates at the client and represents a new resource to be created on the server. In that case, a client MAY include a member to uniquely identify the resource by locally within the document.\n\nIn addition, a resource object MAY contain any of these top-level members:\n• : an attributes object representing some of the resource’s data.\n• : a relationships object describing relationships between the resource and other JSON:API resources.\n• : a links object containing links related to the resource.\n• : a meta object containing non-standard meta-information about a resource that can not be represented as an attribute or relationship.\n\nHere’s how an article (i.e. a resource of type “articles”) might appear in a document:\n\nAs noted above, every resource object MUST contain a member. Every resource object MUST also contain an member, except when the resource object originates at the client and represents a new resource to be created on the server. If is omitted due to this exception, a member MAY be included to uniquely identify the resource by locally within the document. The value of the member MUST be identical for every representation of the resource in the document, including resource identifier objects.\n\nThe values of the , , and members MUST be strings.\n\nWithin a given API, each resource object’s and pair MUST identify a single, unique resource. (The set of URIs controlled by a server, or multiple servers acting as one, constitute an API.)\n\nThe member is used to describe resource objects that share common attributes and relationships.\n\nThe values of members MUST adhere to the same constraints as member names.\n\nA resource object’s attributes and its relationships are collectively called its “fields”.\n\nFields for a resource object MUST share a common namespace with each other and with and . In other words, a resource can not have an attribute and relationship with the same name, nor can it have an attribute or relationship named or .\n\nThe value of the key MUST be an object (an “attributes object”). Members of the attributes object (“attributes”) represent information about the resource object in which it’s defined.\n\nAttributes may contain any valid JSON value, including complex data structures involving JSON objects and arrays.\n\nKeys that reference related resources (e.g. ) SHOULD NOT appear as attributes. Instead, relationships SHOULD be used.\n\nThe value of the key MUST be an object (a “relationships object”). Each member of a relationships object represents a “relationship” from the resource object in which it has been defined to other resource objects.\n\nRelationships may be to-one or to-many.\n\nA relationship’s name is given by its key. The value at that key MUST be an object (“relationship object”).\n\nA “relationship object” MUST contain at least one of the following:\n• : a links object containing at least one of the following:\n• : a link for the relationship itself (a “relationship link”). This link allows the client to directly manipulate the relationship. For example, removing an through an ’s relationship URL would disconnect the person from the without deleting the resource itself. When fetched successfully, this link returns the linkage for the related resources as its primary data. (See Fetching Relationships.)\n• : a meta object that contains non-standard meta-information about the relationship.\n\nA relationship object that represents a to-many relationship MAY also contain pagination links under the member, as described below. Any pagination links in a relationship object MUST paginate the relationship data, not the related resources.\n\nA “related resource link” provides access to resource objects linked in a relationship. When fetched, the related resource object(s) are returned as the response’s primary data.\n\nFor example, an ’s relationship could specify a link that returns a collection of comment resource objects when retrieved through a request.\n\nIf present, a related resource link MUST reference a valid URL, even if the relationship isn’t currently associated with any target resources. Additionally, a related resource link MUST NOT change because its relationship’s content changes.\n\nResource linkage in a compound document allows a client to link together all of the included resource objects without having to any URLs via links.\n\nResource linkage MUST be represented as one of the following:\n• an array of resource identifier objects for non-empty to-many relationships.\n\nFor example, the following article is associated with an :\n\nThe relationship includes a link for the relationship itself (which allows the client to change the related author directly), a related resource link to fetch the resource objects, and linkage information.\n\nThe optional member within each resource object contains links related to the resource.\n\nIf present, this links object MAY contain a link that identifies the resource represented by the resource object.\n\nA server MUST respond to a request to the specified URL with a response that includes the resource as the primary data.\n\nA “resource identifier object” is an object that identifies an individual resource.\n\nA “resource identifier object” MUST contain a member. It MUST also contain an member, except when it represents a new resource to be created on the server. In this case, a member MUST be included that identifies the new resource.\n\nThe values of the , , and members MUST be strings.\n\nA “resource identifier object” MAY also include a member, whose value is a meta object that contains non-standard meta-information.\n\nServers MAY allow responses that include related resources along with the requested primary resources. Such responses are called “compound documents”.\n\nIn a compound document, all included resources MUST be represented as an array of resource objects in a top-level member.\n\nEvery included resource object MUST be identified via a chain of relationships originating in a document’s primary data. This means that compound documents require “full linkage” and that no resource object can be included without a direct or indirect relationship to the document’s primary data.\n\nThe only exception to the full linkage requirement is when relationship fields that would otherwise contain linkage data are excluded due to sparse fieldsets requested by the client.\n\nA compound document MUST NOT include more than one resource object for each and pair.\n\nWhere specified, a member can be used to include non-standard meta-information. The value of each member MUST be an object (a “meta object”).\n\nAny members MAY be specified within objects.\n\nWhere specified, a member can be used to represent links. The value of this member MUST be an object (a “links object”).\n\nWithin this object, a link MUST be represented as either:\n• a string whose value is a URI-reference [RFC3986 Section 4.1] pointing to the link’s target,\n• if the link does not exist.\n\nA link’s relation type SHOULD be inferred from the name of the link unless the link is a link object and the link object has a member.\n\nA link’s context is the top-level object, resource object, or relationship object in which it appears.\n\nIn the example below, the link is a string whereas the link is a link object. The link object provides additional information about the targeted related resource collection as well as a schema that serves as a description document for that collection:\n\nA “link object” is an object that represents a web link.\n\nA link object MUST contain the following member:\n• : a string whose value is a URI-reference [RFC3986 Section 4.1] pointing to the link’s target.\n\nA link object MAY also contain any of the following members:\n• : a string indicating the link’s relation type. The string MUST be a valid link relation type.\n• : a link to a description document (e.g. OpenAPI or JSON Schema) for the link target.\n• : a string which serves as a label for the destination of a link such that it can be used as a human-readable identifier (e.g., a menu entry).\n• : a string indicating the media type of the link’s target.\n• : a string or an array of strings indicating the language(s) of the link’s target. An array of strings indicates that the link’s target is available in multiple languages. Each string MUST be a valid language tag [RFC5646].\n• : a meta object containing non-standard meta-information about the link.\n\nA JSON:API document MAY include information about its implementation under a top level member. If present, the value of the member MUST be an object (a “jsonapi object”).\n\nThe jsonapi object MAY contain any of the following members:\n• - whose value is a string indicating the highest JSON:API version supported.\n• - an array of URIs for all applied extensions.\n• - an array of URIs for all applied profiles.\n\nClients and servers MUST NOT use an or member for content negotiation. Content negotiation MUST only happen based on media type parameters in header.\n\nIf the member is not present, clients should assume the server implements at least version 1.0 of the specification.\n\nImplementation and profile defined member names used in a JSON:API document MUST be treated as case sensitive by clients and servers, and they MUST meet all of the following conditions:\n• Member names MUST contain at least one character.\n• Member names MUST contain only the allowed characters listed below.\n• Member names MUST start and end with a “globally allowed character”, as defined below.\n\nTo enable an easy mapping of member names to URLs, it is RECOMMENDED that member names use only non-reserved, URL safe characters specified in RFC 3986.\n\nThe following “globally allowed characters” MAY be used anywhere in a member name:\n• U+0080 and above (non-ASCII Unicode characters; not recommended, not URL safe)\n\nAdditionally, the following characters are allowed in member names, except as the first or last character:\n\nThe following characters MUST NOT be used in implementation and profile defined member names:\n• U+002B PLUS SIGN, “+” (has overloaded meaning in URL query strings)\n• U+002C COMMA, “,” (used as a separator between relationship paths)\n• U+002E PERIOD, “.” (used as a separator within relationship paths)\n• U+005D RIGHT SQUARE BRACKET, “]” (used in query parameter families)\n• U+0040 COMMERCIAL AT, “@” (except as first character in @-Members)\n\nMember names MAY also begin with an at sign (U+0040 COMMERCIAL AT, “@”). Members named this way are called “@-Members”. @-Members MAY appear anywhere in a document.\n\nThis specification provides no guidance on the meaning or usage of @-Members, which are considered to be implementation semantics. @-Members MUST be ignored when interpreting this specification’s definitions and processing instructions given outside of this subsection. For example, an attribute is defined above as any member of the attributes object. However, because @-Members must be ignored when interpreting that definition, an @-Member that occurs in an attributes object is not an attribute.\n\nThe name of every new member introduced by an extension MUST be prefixed with the extension’s namespace followed by a colon ( ). The remainder of the name MUST adhere to the rules for implementation defined member names.\n\nData, including resources and relationships, can be fetched by sending a request to an endpoint.\n\nResponses can be further refined with the optional features described below.\n\nA server MUST support fetching resource data for every URL provided as:\n• a link as part of the top-level links object\n\nFor example, the following request fetches a collection of articles:\n\nThe following request fetches an article:\n\nAnd the following request fetches an article’s author:\n\nA server MUST respond to a successful request to fetch an individual resource or resource collection with a response.\n\nA server MUST respond to a successful request to fetch a resource collection with an array of resource objects or an empty array ( ) as the response document’s primary data.\n\nFor example, a request to a collection of articles could return:\n\nA similar response representing an empty collection would be:\n\nA server MUST respond to a successful request to fetch an individual resource with a resource object or provided as the response document’s primary data.\n\nis only an appropriate response when the requested URL is one that might correspond to a single resource, but doesn’t currently.\n\nFor example, a request to an individual article could return:\n\nIf the above article’s author is missing, then a request to that related resource would return:\n\nA server MUST respond with when processing a request to fetch a single resource that does not exist, except when the request warrants a response with as the primary data (as described above).\n\nA server MAY respond with other HTTP status codes.\n\nA server MUST prepare responses, and a client MUST interpret responses, in accordance with .\n\nA server MUST support fetching relationship data for every relationship URL provided as a link as part of a relationship’s object.\n\nFor example, the following request fetches data about an article’s comments:\n\nAnd the following request fetches data about an article’s author:\n\nA server MUST respond to a successful request to fetch a relationship with a response.\n\nThe primary data in the response document MUST match the appropriate value for resource linkage, as described above for relationship objects.\n\nThe top-level links object MAY contain and links, as described above for relationship objects.\n\nFor example, a request to a URL from a to-one relationship link could return:\n\nIf the above relationship is empty, then a request to the same URL would return:\n\nA request to a URL from a to-many relationship link could return:\n\nIf the above relationship is empty, then a request to the same URL would return:\n\nA server MUST return when processing a request to fetch a relationship link URL that does not exist.\n\nIf a relationship link URL exists but the relationship is empty, then MUST be returned, as described above.\n\nA server MAY respond with other HTTP status codes.\n\nA server MUST prepare responses, and a client MUST interpret responses, in accordance with .\n\nAn endpoint MAY return resources related to the primary data by default.\n\nAn endpoint MAY also support an query parameter to allow the client to customize which related resources should be returned.\n\nIf an endpoint does not support the parameter, it MUST respond with to any requests that include it.\n\nIf an endpoint supports the parameter and a client supplies it:\n• The server’s response MUST be a compound document with an key — even if that key holds an empty array (because the requested relationships are empty).\n• The server MUST NOT include unrequested resource objects in the section of the compound document.\n\nThe value of the parameter MUST be a comma-separated (U+002C COMMA, “,”) list of relationship paths. A relationship path is a dot-separated (U+002E FULL-STOP, “.”) list of relationship names. An empty value indicates that no related resources should be returned.\n\nIf a server is unable to identify a relationship path or does not support inclusion of resources from a path, it MUST respond with 400 Bad Request.\n\nFor instance, comments could be requested with an article:\n\nIn order to request resources related to other resources, a dot-separated path for each relationship name can be specified:\n\nMultiple related resources can be requested in a comma-separated list:\n\nFurthermore, related resources can be requested from a relationship endpoint:\n\nIn this case, the primary data would be a collection of resource identifier objects that represent linkage to comments for an article, while the full comments and comment authors would be returned as included data.\n\nA client MAY request that an endpoint return only specific fields in the response on a per-type basis by including a query parameter.\n\nThe value of any parameter MUST be a comma-separated (U+002C COMMA, “,”) list that refers to the name(s) of the fields to be returned. An empty value indicates that no fields should be returned.\n\nIf a client requests a restricted set of fields for a given resource type, an endpoint MUST NOT include additional fields in resource objects of that type in its response.\n\nIf a client does not specify the set of fields for a given resource type, the server MAY send all fields, a subset of fields, or no fields for that resource type.\n\nA server MAY choose to support requests to sort resource collections according to one or more criteria (“sort fields”).\n\nAn endpoint MAY support requests to sort the primary data with a query parameter. The value for MUST represent sort fields.\n\nAn endpoint MAY support multiple sort fields by allowing comma-separated (U+002C COMMA, “,”) sort fields. Sort fields SHOULD be applied in the order specified.\n\nThe sort order for each sort field MUST be ascending unless it is prefixed with a minus (U+002D HYPHEN-MINUS, “-“), in which case it MUST be descending.\n\nThe above example should return the newest articles first. Any articles created on the same date will then be sorted by their title in ascending alphabetical order.\n\nIf the server does not support sorting as specified in the query parameter , it MUST return .\n\nIf sorting is supported by the server and requested by the client via query parameter , the server MUST return elements of the top-level array of the response ordered according to the criteria specified. The server MAY apply default sorting rules to top-level if request parameter is not specified.\n\nA server MAY choose to limit the number of resources returned in a response to a subset (“page”) of the whole set available.\n\nPagination links MUST appear in the links object that corresponds to a collection. To paginate the primary data, supply pagination links in the top-level object. To paginate an included collection returned in a compound document, supply pagination links in the corresponding links object.\n\nThe following keys MUST be used for pagination links:\n• : the first page of data\n• : the last page of data\n• : the next page of data\n\nKeys MUST either be omitted or have a value to indicate that a particular link is unavailable.\n\nConcepts of order, as expressed in the naming of pagination links, MUST remain consistent with JSON:API’s sorting rules.\n\nThe query parameter family is reserved for pagination. Servers and clients SHOULD use these parameters for pagination operations.\n\nThe query parameter family is reserved for filtering data. Servers and clients SHOULD use these parameters for filtering operations.\n\nA server MAY allow resources of a given type to be created. It MAY also allow existing resources to be modified or deleted.\n\nA request MUST completely succeed or fail (in a single “transaction”). No partial updates are allowed.\n\nA resource can be created by sending a request to a URL that represents a collection of resources. The request MUST include a single resource object as primary data. The resource object MUST contain at least a member.\n\nFor instance, a new photo might be created with the following request:\n\nIf a relationship is provided in the member of the resource object, its value MUST be a relationship object with a member. The value of this key represents the linkage the new resource is to have.\n\nA server MAY accept a client-generated ID along with a request to create a resource. An ID MUST be specified with an key, the value of which MUST be a universally unique identifier. The client SHOULD use a properly generated and formatted UUID as described in RFC 4122 [RFC4122].\n\nA server MUST return in response to an unsupported request to create a resource with a client-generated ID.\n\nIf the requested resource has been created successfully and the server changes the resource in any way (for example, by assigning an ), the server MUST return a response and a document that contains the resource as primary data.\n\nThe response SHOULD include a header identifying the location of the newly created resource, in order to comply with RFC 7231.\n\nIf the resource object returned by the response contains a key in its member and a header is provided, the value of the member MUST match the value of the header.\n\nA server MAY return a response with a document that contains no primary data if the requested resource has been created successfully and the server does not change the resource in any way (for example, by assigning an or attribute). Other top-level members, such as meta, could be included in the response document.\n\nIf a request to create a resource has been accepted for processing, but the processing has not been completed by the time the server responds, the server MUST return a status code.\n\nIf the requested resource has been created successfully and the server does not change the resource in any way (for example, by assigning an or attribute), the server MUST return either a status code and response document (as described above) or a status code with no response document.\n\nA server MAY return in response to an unsupported request to create a resource.\n\nA server MUST return when processing a request that references a related resource that does not exist.\n\nA server MUST return when processing a request to create a resource with a client-generated ID that already exists.\n\nA server MUST return when processing a request in which the resource object’s is not among the type(s) that constitute the collection represented by the endpoint.\n\nA server SHOULD include error details and provide enough information to recognize the source of the conflict.\n\nA server MAY respond with other HTTP status codes.\n\nA server MUST prepare responses, and a client MUST interpret responses, in accordance with .\n\nA resource can be updated by sending a request to the URL that represents the resource.\n\nThe URL for a resource can be obtained in the link of the resource object. Alternatively, when a request returns a single resource object as primary data, the same request URL can be used for updates.\n\nThe request MUST include a single resource object as primary data. The resource object MUST contain and members.\n\nAny or all of a resource’s attributes MAY be included in the resource object included in a request.\n\nIf a request does not include all of the attributes for a resource, the server MUST interpret the missing attributes as if they were included with their current values. The server MUST NOT interpret missing attributes as values.\n\nFor example, the following request is interpreted as a request to update only the and attributes of an article:\n\nAny or all of a resource’s relationships MAY be included in the resource object included in a request.\n\nIf a request does not include all of the relationships for a resource, the server MUST interpret the missing relationships as if they were included with their current values. It MUST NOT interpret them as or empty values.\n\nIf a relationship is provided in the member of a resource object in a request, its value MUST be a relationship object with a member. The relationship’s value will be replaced with the value specified in this member.\n\nFor instance, the following request will update the relationship of an article:\n\nLikewise, the following request performs a complete replacement of the for an article:\n\nA server MAY reject an attempt to do a full replacement of a to-many relationship. In such a case, the server MUST reject the entire update, and return a response.\n\nIf a server accepts an update but also changes the targeted resource in ways other than those specified by the request (for example, updating the attribute or a computed ), it MUST return a response and a document that contains the updated resource as primary data.\n\nA server MAY return a response with a document that contains no primary data if an update is successful and the server does not change the targeted resource in ways other than those specified by the request. Other top-level members, such as meta, could be included in the response document.\n\nIf an update request has been accepted for processing, but the processing has not been completed by the time the server responds, the server MUST return a status code.\n\nIf an update is successful and the server doesn’t change the targeted resource in ways other than those specified by the request, the server MUST return either a status code and response document (as described above) or a status code with no response document.\n\nA server MUST return in response to an unsupported request to update a resource or relationship.\n\nA server MUST return when processing a request to modify a resource that does not exist.\n\nA server MUST return when processing a request that references a related resource that does not exist.\n\nA server MAY return when processing a request to update a resource if that update would violate other server-enforced constraints (such as a uniqueness constraint on a property other than ).\n\nA server MUST return when processing a request in which the resource object’s or do not match the server’s endpoint.\n\nA server SHOULD include error details and provide enough information to recognize the source of the conflict.\n\nA server MAY respond with other HTTP status codes.\n\nA server MUST prepare responses, and a client MUST interpret responses, in accordance with .\n\nAlthough relationships can be modified along with resources (as described above), JSON:API also supports updating of relationships independently at URLs from relationship links.\n\nA to-one relationship can be updated by sending a request to a URL from a to-one relationship link.\n\nThe request MUST include a top-level member named containing one of:\n• a resource identifier object corresponding to the new related resource.\n\nFor example, the following request updates the author of an article:\n\nAnd the following request clears the author of the same article:\n\nIf the relationship is updated successfully then the server MUST return a successful response.\n\nA to-many relationship can be updated by sending a , , or request to a URL from a to-many relationship link.\n\nFor all request types, the body MUST contain a member whose value is an empty array or an array of resource identifier objects.\n\nIf a client makes a request to a URL from a to-many relationship link, the server MUST either completely replace every member of the relationship, return an appropriate error response if some resources cannot be found or accessed, or return a response if complete replacement is not allowed by the server.\n\nFor example, the following request replaces every tag for an article:\n\nAnd the following request clears every tag for an article:\n\nIf a client makes a request to a URL from a relationship link, the server MUST add the specified members to the relationship unless they are already present. If a given and is already in the relationship, the server MUST NOT add it again.\n\nIf all of the specified resources can be added to, or are already present in, the relationship then the server MUST return a successful response.\n\nIn the following example, the comment with ID is added to the list of comments for the article with ID :\n\nIf the client makes a request to a URL from a relationship link the server MUST delete the specified members from the relationship or return a response. If all of the specified resources are able to be removed from, or are already missing from, the relationship then the server MUST return a successful response.\n\nRelationship members are specified in the same way as in the request.\n\nIn the following example, comments with IDs of and are removed from the list of comments for the article with ID :\n\nIf a server accepts an update but also changes the targeted relationship in other ways than those specified by the request, it MUST return a response and a document that includes the updated relationship data as its primary data.\n\nA server MAY return a response with a document that contains no primary data if an update is successful and the server does not change the targeted relationship in ways other than those specified by the request. Other top-level members, such as meta, could be included in the response document.\n\nIf a relationship update request has been accepted for processing, but the processing has not been completed by the time the server responds, the server MUST return a status code.\n\nIf an update is successful and the server doesn’t change the targeted relationship in ways other than those specified by the request, the server MUST return either a status code and response document (as described above) or a status code with no response document.\n\nA server MUST return in response to an unsupported request to update a relationship.\n\nA server MAY respond with other HTTP status codes.\n\nA server MUST prepare responses, and a client MUST interpret responses, in accordance with .\n\nA resource can be deleted by sending a request to the URL that represents the resource:\n\nA server MAY return a response with a document that contains no primary data if a deletion request is successful. Other top-level members, such as meta, could be included in the response document.\n\nIf a deletion request has been accepted for processing, but the processing has not been completed by the time the server responds, the server MUST return a status code.\n\nIf a deletion request is successful, the server MUST return either a status code and response document (as described above) or a status code with no response document.\n\nA server SHOULD return a status code if a deletion request fails due to the resource not existing.\n\nA server MAY respond with other HTTP status codes.\n\nA server MUST prepare responses, and a client MUST interpret responses, in accordance with .\n\nAlthough “query parameter” is a common term in everyday web development, it is not a well-standardized concept. Therefore, JSON:API provides its own definition of a query parameter.\n\nFor the most part, JSON:API’s definition coincides with colloquial usage, and its details can be safely ignored. However, one important consequence of this definition is that a URL like the following is considered to have two distinct query parameters:\n\nThe two parameters are named and ; there is no single parameter.\n\nIn practice, however, parameters like and are usually defined and processed together, and it’s convenient to refer to them collectively. Therefore, JSON:API introduces the concept of a query parameter family.\n\nA “query parameter family” is the set of all query parameters whose name starts with a “base name”, followed by zero or more instances of empty square brackets (i.e. ), square-bracketed legal member names, or square-bracketed dot-separated lists of legal member names. The family is referred to by its base name.\n\nFor example, the query parameter family includes parameters named: , , , , , , , etc. However, is not a valid parameter name in the family, because is not a valid member name.\n\nThe base name of every query parameter introduced by an extension MUST be prefixed with the extension’s namespace followed by a colon ( ). The remainder of the base name MUST contain only the characters [a-z] (U+0061 to U+007A, “a-z”).\n\nImplementations MAY support custom query parameters. However, the names of these query parameters MUST come from a family whose base name is a legal member name and also contains at least one non a-z character (i.e., outside U+0061 to U+007A).\n\nIt is RECOMMENDED that a capital letter (e.g. camelCasing) be used to satisfy the above requirement.\n\nIf a server encounters a query parameter that does not follow the naming conventions above, or the server does not know how to process it as a query parameter from this specification, it MUST return .\n\nA server MAY choose to stop processing as soon as a problem is encountered, or it MAY continue processing and encounter multiple problems. For instance, a server might process multiple attributes and then return multiple validation problems in a single response.\n\nWhen a server encounters multiple problems for a single request, the most generally applicable HTTP error code SHOULD be used in the response. For instance, might be appropriate for multiple 4xx errors or might be appropriate for multiple 5xx errors.\n\nError objects provide additional information about problems encountered while performing an operation. Error objects MUST be returned as an array keyed by in the top level of a JSON:API document.\n\nAn error object MAY have the following members, and MUST contain at least one of:\n• : a unique identifier for this particular occurrence of the problem.\n• : a links object that MAY contain the following members:\n• : a link that leads to further details about this particular occurrence of the problem. When dereferenced, this URI SHOULD return a human-readable description of the error.\n• : a link that identifies the type of error that this particular error is an instance of. This URI SHOULD be dereferenceable to a human-readable explanation of the general error.\n• : the HTTP status code applicable to this problem, expressed as a string value. This SHOULD be provided.\n• : an application-specific error code, expressed as a string value.\n• : a short, human-readable summary of the problem that SHOULD NOT change from occurrence to occurrence of the problem, except for purposes of localization.\n• : a human-readable explanation specific to this occurrence of the problem. Like , this field’s value can be localized.\n• : an object containing references to the primary source of the error. It SHOULD include one of the following members or be omitted:\n• : a JSON Pointer [RFC6901] to the value in the request document that caused the error [e.g. for a primary data object, or for a specific attribute]. This MUST point to a value in the request document that exists; if it doesn’t, the client SHOULD simply ignore the pointer.\n• : a string indicating the name of a single request header which caused the error.\n• : a meta object containing non-standard meta-information about the error.\n\nA query parameter is a name–value pair extracted from, or serialized into, a URI’s query string.\n\nTo extract the query parameters from a URI, an implementation MUST run the URI’s query string, excluding the leading question mark, through the parsing algorithm, with one exception: JSON:API allows the specification that defines a query parameter’s usage to provide its own rules for parsing the parameter’s value from the bytes identified in steps 3.2 and and 3.3 of the parsing algorithm. The resulting value might not be a string.\n\nSimilarly, to serialize a query parameter into a URI, an implementation MUST use the serializer, with the corresponding exception that a parameter’s value — but not its name — may be serialized differently than that algorithm requires, provided the serialization does not interfere with the ability to parse back the resulting URI.\n\nWith query parameter families, JSON:API allows for query parameters whose names contain square brackets (i.e., U+005B “[” and U+005D “]”).\n\nAccording to the query parameter serialization rules above, a compliant implementation will percent-encode these square brackets. However, some URI producers — namely browsers — do not always encode them. Servers SHOULD accept requests in which these square brackets are left unencoded in a query parameter’s name. If a server does accept these requests, it MUST treat the request as equivalent to one in which the square brackets were percent-encoded."
    },
    {
        "link": "https://openapi-generator.tech/docs/customization",
        "document": "The most common scenario for user customization is to override the built-in templates with small modifications. That scenario's documentation is in our templating page, and differs from user-defined templates.\n\nPrior to release 5.0.0, whenever a user wanted to include templates which weren't built-in or weren't known to the generator at compile time, they'd need to follow the more involved approach of creating a custom generator as documented later in this document. Beginning in 5.0.0, a user may now provide additional supporting files and extensions to built-in templates via configuration. This feature requires using the external configuration file feature.\n\nConsider that you might want to add some static documentation such as and a custom tooling script. Rather than a single file for API definitions you also want an implementation file and a separate interface file for each.\n\nYou might have an external configuration file named which defines additional properties like this for a client generator:\n\nYou would generate via CLI with the command:\n\nTo support the above scenario with custom templates, ensure that you're pointing to your custom template directory and add a node with template file definitions to your config:\n\nThe keys under the node are your template filenames. These honor the same resolution order as all other templates.\n\nThe above configuration will do the following:\n• Copy to the generated output directory without processing via the template engine (due to template file extension). The empty object definition following allows the tool to infer the target output filename in the root of the output directory.\n• Compile a user-provided following our usual API template compilation logic. That is, one file will be created per API; APIs are generated defined according to tags in your spec documentation. The destination filename of will act as a suffix for the filename. So, a tag of will output a corresponding .\n• Because is the same mustache filename as used in your target generator ( in this example), we support the following:\n• The destination filename provides a suffix for the generated output. APIs generate per tag in your specification. So, a tag of will output a corresponding . This option will be used whether targets a user customized template or a built-in template.\n• The built-in template will be used if you haven't provided a customized template. The kotlin generator defines the suffix as simply , so this scenario would modify only the generated file suffixes according to the previous bullet point.\n• Your will be used if it exists in your custom template directory. For generators with library options, such as in the kotlin generator, your file must exist in the same relative location as the embedded template. For kotlin using the library option, this file would need to be located at . See templating for more details.\n• Compile with the supporting files bundle, and output to in your output directory. Note that we don't currently support setting file flags on output, so scripts such as these will either have to be sourced rather than executed, or have file flags set separately after generation (external to our tooling).\n\nThe option will default to , so the option for is redundant and provided to demonstrate the full template file configuration options. The available template types are:\n\nExcluding , each of the above options may result in multiple files. API related types create a file per API. Model related types create a file for each model.\n\nNote that user-defined templates will merge with built-in template definitions. If a supporting file with the sample template file path exists, it will be replaced with the user-defined template, otherwise the user-defined template will be added to the list of template files to compile. If the generator's built-in template is and you define , this will result in duplicated model docs (if differs) or undefined behavior as whichever template compiles last will overwrite the previous model docs (if matches the extension or suffix in the generator's code).\n\nThis will create a new directory , with all the files you need to get started - including a . Once modified and compiled, you can use your new codegen just like any other, with your own custom-rolled logic.\n\nThese names can be anything you like. If you are building a client for the whitespace language, maybe you'd use the options . They can be the same, or different, it doesn't matter. The value will be become the template name.\n\nNOTE Convention is to use kebab casing for names passed to . Example, would become .\n\nTo compile your library, enter the directory, run .\n\nNOTE Running your custom generator requires adding it to the classpath. This differs on Windows slightly from unix. If you are running a Windows Subsystem for Linux or a shell such as gitbash, and have issues with the unix variant, try the Windows syntax below.\n\nFor Windows users, you will need to use instead of in the classpath, e.g.\n\nNote the is an option for now, and you can use the usual arguments for generating your code:\n\nInstall your library to your local maven repository by running:\n\nThis will install to your local maven repository.\n\nYou can use this as additional dependency of the plugin and use as value:\n\nIf you publish your artifact to a distant maven repository, do not forget to add this repository as for your project.\n\nYou may not want to generate all models in your project. Likewise, you may want just one or two apis to be written. If that's the case, you can use system properties or global properties to control the output.\n\nThe default is to generate everything supported by the specific library. Once you enable a feature, it will restrict the contents generated:\n\nTo control the specific files being generated, you can pass a CSV list of what you want:\n\nTo control generation of docs and tests for api and models, pass false to the option. For api, these options are . For models, . These options default to true and don't limit the generation of the feature options listed above (like ):\n\nWhen using selective generation, only the templates needed for the specific generation will be used.\n\nTo skip models defined as the form parameters in \"requestBody\", please use (default to ) (this option is introduced at v3.2.2 and by default starting from v5.0.0).\n\nThis option will be helpful to skip model generation due to the form parameter, which is defined differently in OAS3 as there's no form parameter in OAS3\n\nOpenAPI Generator supports a file, similar to or you're probably already familiar with.\n\nThe ignore file allows for better control over overwriting existing files than the flag. With the ignore file, you can specify individual files or directories can be ignored. This can be useful, for example if you only want a subset of the generated code.\n\nThe file must exist in the root of the output directory.\n\nUpon first code generation, you may also pass the CLI option for greater control over generated outputs. Note that this is a complete override, and will override the file in an output directory when regenerating code.\n\nEditor support for files is available in IntelliJ via the .ignore plugin.\n\nOne may want to pre-populate with a list of entries during the code generation process and the global/general option (e.g. --openapi-generator-ignore-list in CLI) can do exactly that. For example,\n\nThere are different aspects of customizing the code generator beyond just creating or modifying templates. Each language has a supporting configuration file to handle different type mappings, etc:\n\nEach of these files creates reasonable defaults so you can get running quickly. But if you want to configure package names, prefixes, model folders, etc. you can use a json config file to pass the values.\n\nand contains the following as an example:\n\nYou can use also with following equivalent example:\n\nAnother example of config file can be found in modules/openapi-generator/src/test/resources/sampleConfig.json\n\nSupported config options can be different per language. Running will show available options. These options are applied via configuration file (e.g. config.json or config.yml) or by passing them with . (If does not work, please open a ticket and we'll look into it)\n\nYour config file for Java can look like\n\nOr if you prefer yaml format it can look like\n\nFor all the unspecified options default values will be used.\n\nAnother way to override default options is to extend the config class for the specific language. To change, for example, the prefix for the Objective-C generated files, simply subclass the :\n\nand specify the when running the generator:\n\nYour subclass will now be loaded and overrides the value in the superclass.\n\nSometimes you don't want a model generated. In this case, you can simply specify an import mapping to tell the codegen what not to create. When doing this, every location that references a specific model will refer back to your classes. Note, this may not apply to all languages...\n\nTo specify an import mapping, use the argument and specify the model-to-import logic as such:\n\nOne can map the property name using option and parameter name using option to something else. Consider the following schema:\n\n, , will result in property name collision in the Java client generator for example. We can resolve the issue using by mapping to , to .\n\nHere is an example to use and in CLI:\n\nwill rename the schema to instead.\n\nwill rename SOLD to UNAVAILABLE instead.\n\nNot all generators support these features yet. Please give it a try to confirm the behaviour and open an issue (ticket) to let us know which generators you would like to have this feature enabled and we'll prioritize accordingly. We also welcome PRs to add these features to generators. Related PRs for reference: #16209, #16234 (modelNameMappings), #16194, #16206 (nameMappings, parameterNameMappings), #17108 (enumNameMappings).\n\nNOTE: some generators use (original name obtained directly from OpenAPI spec, e.g. ) mustache tag in the templates so the mapping feature won't work.\n\nTo map (used in method naming) to something else, use option, e.g.\n\nwill name the API method as instead of obtained from OpenAPI doc/spec.\n\nOne can map the schema to something else (e.g. external objects/models outside of the package) using the option, e.g. in CLI\n\nAnother example (in conjunction with --type-mappings):\n\nwhile /tmp/alias.yaml is as follows:\n\nInline schemas are created as separate schemas automatically and the auto-generated schema name may not look good to everyone. One can customize the name using the field or the option. For example, run the following,\n\nwill show the following in the console:\n\nFor example, to name the inline schema as , use the option as follows:\n\nAnother useful option is , which allows you to customize how inline schemas are handled or named\n• is a special value to skip reusing inline schemas during refactoring\n• will restore the 6.x (or below) behaviour to refactor allOf inline schemas into $ref. (v7.0.0 will skip the refactoring of these allOf inline schemas by default)\n• will refactor inline enum definitions into $ref. This must be activated to allow the renaming of inline enum definitions using .\n\nOpenAPI Normalizer transforms the input OpenAPI doc/spec (which may not perfectly conform to the specification) to make it workable with OpenAPI Generator. A few rules are switched on by default since 7.0.0 release:\n\nHere is a list of rules supported:\n• : when set to , child schemas in is considered a parent if it's a (instead of inline schema).\n• : when set to , oneOf/anyOf schema with only required properties only in a schema with properties will be removed. (example)\n• : when set to , simplify anyOf schema with string and enum of string to just\n• : when set to , convert boolean enum to just enum.\n• : when set to , simplify oneOf/anyOf by 1) removing null (sub-schema) or enum of null (sub-schema) and setting nullable to true instead, and 2) simplifying oneOf/anyOf with a single sub-schema to just the sub-schema itself.\n• : when set to , only keep the first tag in operation if there are more than one tag defined.\n• : when set to a string value, tags in all operations will reset to the string value provided.\n• : when set to true, tags in all operations will be set to operationId or \"default\" if operationId is empty\n• : when set to a string value, tags will be set to the value of the provided vendor extension\n• : when set to true, auto fix integer with maximum value 4294967295 (2^32-1) or long with 18446744073709551615 (2^64-1) by adding x-unsigned to the schema\n• : When set to true, refactor schema with allOf and properties in the same level to a schema with allOf only and, the allOf contains a new schema containing the properties in the top level.\n• : Set to true if you want to disable the default behavior of removing/hiding the x-internal in operations and model\n\nThe parameter allows selective inclusion of API operations based on specific criteria. It applies the property to operations that do not match the specified values, preventing them from being generated.\n• None \n\n When set to , operations not matching or will be marked as internal ( ), and excluded from generation. Matching operations will have .\n• None \n\n When set to , operations not using or methods will be marked as internal ( ), preventing their generation.\n• None \n\n When set to , operations not tagged with or will be marked as internal ( ), and will not be generated.\n• : When set to (or just ) for example, it will set in array, set and map to true.\n• : When set to (or just ) for example, it will set the type to (nullable: true)\n• : When set to true, an integer suffix will be added to duplicated operationId(s), e.g. getName => getName_0, getName_1, etc"
    },
    {
        "link": "https://stackoverflow.com/questions/12806386/is-there-any-standard-for-json-api-response-format",
        "document": "Do standards or best practices exist for structuring JSON responses from an API? Obviously, every application's data is different, so that much I'm not concerned with, but rather the \"response boilerplate\", if you will. An example of what I mean:\n\nAssuming you question is about REST webservices design and more precisely concerning success/error. I think there are 3 different types of design.\n• None Use only HTTP Status code to indicate if there was an error and try to limit yourself to the standard ones (usually it should suffice).\n• Pros: It is a standard independent of your api.\n• Cons: Less information on what really happened.\n• None Use HTTP Status + json body (even if it is an error). Define a uniform structure for errors (ex: code, message, reason, type, etc) and use it for errors, if it is a success then just return the expected json response.\n• Pros: Still standard as you use the existing HTTP status codes and you return a json describing the error (you provide more information on what happened).\n• Cons: The output json will vary depending if it is a error or success.\n• None Forget the http status (ex: always status 200), always use json and add at the root of the response a boolean responseValid and a error object (code,message,etc) that will be populated if it is an error otherwise the other fields (success) are populated.\n• None Pros: The client deals only with the body of the response that is a json string and ignores the status(?). It's up to you to choose :) Depending on the API I would choose 2 or 3 (I prefer 2 for json rest apis). Another thing I have experienced in designing REST Api is the importance of documentation for each resource (url): the parameters, the body, the response, the headers etc + examples. I would also recommend you to use jersey (jax-rs implementation) + genson (java/json databinding library). You only have to drop genson + jersey in your classpath and json is automatically supported.\n• None Solution 2 is the hardest to implement but the advantage is that you can nicely handle exceptions and not only business errors, initial effort is more important but you win on the long term.\n• None Solution 3 is the easy to implement on both, server side and client but it's not so nice as you will have to encapsulate the objects you want to return in a response object containing also the responseValid + error.\n\nI will not be as arrogant to claim that this is a standard so I will use the \"I prefer\" form. I prefer terse response (when requesting a list of /articles I want a JSON array of articles). In my designs I use HTTP for status report, a 200 returns just the payload. 400 returns a message of what was wrong with request: If there was error with processing on my side, I return 501 with a message: {\"message\" : \"Could not connect to data store.\"} From what I've seen quite a few REST-ish frameworks tend to be along these lines. JSON is supposed to be a payload format, it's not a session protocol. The whole idea of verbose session-ish payloads comes from the XML/SOAP world and various misguided choices that created those bloated designs. After we realized all of it was a massive headache, the whole point of REST/JSON was to KISS it, and adhere to HTTP. I don't think that there is anything remotely standard in either JSend and especially not with the more verbose among them. XHR will react to HTTP response, if you use jQuery for your AJAX (like most do) you can use / and / callbacks to capture errors. I can't see how encapsulating status reports in JSON is any more useful than that.\n\nFor what it's worth I do this differently. A successful call just has the JSON objects. I don't need a higher level JSON object that contains a success field indicating true and a payload field that has the JSON object. I just return the appropriate JSON object with a 200 or whatever is appropriate in the 200 range for the HTTP status in the header. However, if there is an error (something in the 400 family) I return a well-formed JSON error object. For example, if the client is POSTing a User with an email address and phone number and one of these is malformed (i.e. I cannot insert it into my underlying database) I will return something like this: Important bits here are that the \"field\" property must match the JSON field exactly that could not be validated. This allows clients to know exactly what went wrong with their request. Also, \"message\" is in the locale of the request. If both the \"emailAddress\" and \"phoneNumber\" were invalid then the \"errors\" array would contain entries for both. A 409 (Conflict) JSON response body might look like this: { \"description\" : \"Already Exists\" \"errors\" : [ { \"field\" : \"phoneNumber\", \"message\" : \"Phone number already exists for another user.\" } ], } With the HTTP status code and this JSON the client has all they need to respond to errors in a deterministic way and it does not create a new error standard that tries to complete replace HTTP status codes. Note, these only happen for the range of 400 errors. For anything in the 200 range I can just return whatever is appropriate. For me it is often a HAL-like JSON object but that doesn't really matter here. The one thing I thought about adding was a numeric error code either in the the \"errors\" array entries or the root of the JSON object itself. But so far we haven't needed it.\n\nThe point of JSON is that it is completely dynamic and flexible. Bend it to whatever whim you would like, because it's just a set of serialized JavaScript objects and arrays, rooted in a single node. What the type of the rootnode is is up to you, what it contains is up to you, whether you send metadata along with the response is up to you, whether you set the mime-type to or leave it as is up to you (as long as you know how to handle the edge cases). Build a lightweight schema that you like.\n\n Personally, I've found that analytics-tracking and mp3/ogg serving and image-gallery serving and text-messaging and network-packets for online gaming, and blog-posts and blog-comments all have very different requirements in terms of what is sent and what is received and how they should be consumed. So the last thing I'd want, when doing all of that, is to try to make each one conform to the same boilerplate standard, which is based on XML2.0 or somesuch. That said, there's a lot to be said for using schemas which make sense to you and are well thought out.\n\n Just read some API responses, note what you like, criticize what you don't, write those criticisms down and understand why they rub you the wrong way, and then think about how to apply what you learned to what you need.\n\nI used to follow this standard, was pretty good, easy, and clean on the client layer. Normally, the HTTP status 200, so that's a standard check which I use at the top. and I normally use the following JSON I also use a template for the API's dynamic response; try { // query and what not. response.payload = new { data = new { pagination = new Pagination(), customer = new Customer(), notifications = 5 } } // again something here if we get here success has to be true // I follow an exit first strategy, instead of building a pyramid // of doom. response.success = true; } catch(Exception exception){ response.success = false; response.message = exception.GetStackTrace(); _logger.Fatal(exception, this.GetFacadeName()) } return response; { \"success\": boolean, \"message\": \"some message\", \"payload\": { \"data\" : [] \"message\": \"\" ... // put whatever you want to here. } } on the client layer I would use the following: if(response.code != 200) { // woops something went wrong. return; } if(!response.success){ console.debug ( response.message ); return; } // if we are here then success has to be true. if(response.payload) { .... } notice how I break early avoiding the pyramid of doom.\n\nThere is no lawbreaking or outlaw standard other than common sense. If we abstract this like two people talking, the standard is the best way they can accurately understand each other in minimum words in minimum time. In our case, 'minimum words' is optimizing bandwidth for transport efficiency and 'accurately understand' is the structure for parser efficiency; which ultimately ends up with the less the data, and the common the structure; so that it can go through a pin hole and can be parsed through a common scope (at least initially). Almost in every cases suggested, I see separate responses for 'Success' and 'Error' scenario, which is kind of ambiguity to me. If responses are different in these two cases, then why do we really need to put a 'Success' flag there? Is it not obvious that the absence of 'Error' is a 'Success'? Is it possible to have a response where 'Success' is TRUE with an 'Error' set? Or the way, 'Success' is FALSE with no 'Error' set? Just one flag is not enough? I would prefer to have the 'Error' flag only, because I believe there will be less 'Error' than 'Success'. Also, should we really make the 'Error' a flag? What about if I want to respond with multiple validation errors? So, I find it more efficient to have an 'Error' node with each error as child to that node; where an empty (counts to zero) 'Error' node would denote a 'Success'."
    },
    {
        "link": "https://medium.com/@alexanderekb/openai-api-responses-in-json-format-quickstart-guide-75342e50cbd6",
        "document": "JSON format of responses has been implemented in OpenAI API in the second half of 2023. Since then, a significant part of the documentation and many of the articles dedicated to this topic were focused on technical details and were using somewhat confusing terminology (such as “Parallel Function calling”). In the beginning of August 2024 OpenAI has released an updated version of this functionality. This release was accompanied by a significant update of the corresponding documentation. Now this documentation contains more useful and practical examples and detailed explanations, but at the same time new terminology (like “Structured outputs”) was introduced, which potentially may be confusing for beginners.\n\nIn this short tutorial you will find a concise practical introduction that will allow you to quickly get started using the OpenAI API responses in JSON format. This feature will be demonstrated by developing a simple web application (UI: Nuxt; Backend: Node.js). The functionality of this demo-app is implemented in three alternative ways: Simple Chat, Chat Function calling and Assistant Function calling.\n\nIt is assumed that you are already familiar with some basics of how to use OpenAI API “in a normal” way (i.e. as a text chat). So some topics like authorization, playground or installation of required libraries are not covered here.\n\nSimple web application, which is used here for demonstration purposes, has the following functionality: User provides some “Input text” via UI (it may be an article or a book chapter, for example). In response the application asks 3 questions about the key ideas of this text and provides corresponding answers. Initially only the questions should be displayed to the user, while the answers should be hidden, so that the user could try to answer first, and then check the AI’s answers one by one once he or she is ready. To ensure such presentation and interactivity, the dataset with the questions and answers is retrieved from OpenAI API in JSON format.\n\nIn real life, such application may be useful if you want to memorize the content of some text better.\n\nHere is a high-level overview of the app’s components:\n\nThe most straightforward way to implement API call for this app is to use Chat Completions API (basically the same API call as the one that is used for “text” chats) which should include:\n\nHere is a full implementation of Chat Completions API call:\n\nThe response from API is a string, so it’s necessary to use JSON.parse, which gives us a valid JSON, that looks exactly as it was requested in the prompt:\n\nNow it’s ready to be displayed to the user in Web UI. One of the ways to do this is to use an Accordion component in which questions are displayed in headers and answers are placed in hidden content elements that the user can open one at a time as needed:\n\nFull version of implementation of this UI may be found here.\n\nThis is probably the simplest way to use JSON format of API responses. Let’s move on to a more sophisticated approach.\n\nFunction calling is a mechanism that allows to retrieve not just a JSON response from API, but a response that has a formally predefined structure. So this is a replacement for a relatively abstract parameter with a detailed specification of a JSON structure (JSON Schema).\n\nThis is done by adding a new parameter to an API request. It contains:\n• Section containing a JSON Schema that describes the structure of the fields (their names, hierarchy, etc.) that must be present in the API response\n• optional parameter , indicating that the response must conform to a JSON Schema. This feature was released relatively recently as a part of “Structured outputs” functionality.\n\nAlso, the API request may include a parameter, which explicitly specifies that a particular “Function” (i.e., a particular JSON Schema) must be used to generate the response.\n\nSo, for the Demo app the “Function calling” API call includes the same prompt and model as in the previous implementation, but additionally it has tools/function and tool_choice instead of :\n\nAs shown, the structures of the API responses are different, so they should be handled differently when it comes to retrieving the required JSON data:\n\nThe remaining part is fully identical to the first implementation: JSON is returned to the UI and displayed there.\n\nThe whole topic of “Function calling” is much more extensive. Here it’s only explained at a level sufficient to implement the Demo app.\n\nAssistant is a some kind of customized and specialized AI-Chat that focuses on a specific topic and persistently encapsulates some key parameters (prompt, model, attached data, etc.). End users may focus on their specific questions without the need to provide all the context that is predefined in the Assistant’s settings. Assistants API is a functionality that is independent from Chat completions API and there are certain differences between them (but Function calling is one of the similarities). The key features of Assistants are following:\n• Persistent threads: The end-user’s dialog with Assistant (thread) may have several iterations (requests and responses), and information from all the previous iterations is automatically kept in context for generation of subsequent responses\n• RAG (Retrieval-augmented generation): It’s possible to attach files (TXT, PDF, etc.) to Assistants, so that the relevant information from these files is retrieved by the Assistant and used to generate responses within dialogs with end users.\n\nIn order to simplify explanation and focus on JSON responses (Function calling) these features will not be used for Assistant-based implementation of our Demo app.\n\nAssistant for the Demo app has been created manually in https://platform.openai.com/assistants/ (alternatively this can be done via API, but that’s an overkill here). Besides standard parameters (name, model) it has the following elements:\n• Instructions: Prompt similar to the one that was used for the first implementation (You are a tutor who is…)\n• Function: The same JSON Schema as in the previous implementation:\n• Parameter Response format = json_object (it becomes available if at least one “Function” is added to the Assistant):\n\nAfter completing all these settings, it’s possible to check how it works in Playground (https://platform.openai.com/playground/assistants). In response to Input text, it returns a JSON string:\n\nAt first sight everything works as in a normal dialog with an Assistant. But actually there is a new input field “Submit output” and further dialog with the Assistant is blocked because “A Run is currently in progress”. This is so because the current Run (iteration of a dialog) has & = .\n\nIt’s necessary to overcome this in order to be able to continue working with the Assistant and retrieve a response (JSON) from the Thread in a normal way. Let’s switch to implementation via API to see how this can be done.\n\nThe first step that the Demo app should do to start working with this Assistant is to create a Thread with a Message (Input text) and start the first Run:\n\nThis step also includes , which explicitly specifies that the response should be in a perticular JSON format.\n\nUpon completion of this step the newly created Thread is suspended because it (as shown above in the Playground). In order to proceed, it’s necessary to:\n• get an identifier of\n• use this identifier (in combination with an empty parameter ) to call the method , which leads to the Run being set to status :\n\nAfter that, the response (JSON) can be retrieved from Thread in a normal way:\n\nThe complete implementation of the function that works with Assistant in Demo app may be found here: getqaassistant.ts\n\nThe response from this function is identical to the responses in the previous two implementations. Therefore it’s handled in UI similarly, as shown in the beginning.\n\nSo this was the third and the most “advanced” implementation which concludes this tutorial.\n\nObviously, the whole topic of Function calling and Structured outputs is much more complex. The goal of this short tutorial was to provide only a first overview for those who are not familiar with it. Hopefully it will serve as a starting point for practical use and further exploration of this functionality."
    },
    {
        "link": "https://geeksforgeeks.org/how-to-combine-like-and-in-an-sql-statement",
        "document": "How to Combine LIKE and IN in SQL Statement\n\nThe and operators in SQL are essential for building efficient, complex queries that filter data with precision. Combining these two operators in a single query enables users to target specific patterns in data while also filtering based on predefined values\n\nIn this article, we will explain how the LIKE and IN operators work together and help users navigate complex data collection scenarios. Learn how to precisely filter data, creating focused queries that boost our SQL skills.\n\nSQL Combining 'LIKE' and 'IN' Operator\n\nThe 'LIKE' operator searches for a specified pattern in a column within a string, and the 'IN' operator allows users to filter data based on a set of specified values. By combining LIKE and IN, users can filter results based on patterns and specific values simultaneously, allowing users to create more complex and precise search conditions in SQL statements.\n\nExamples of Combining 'LIKE' and 'IN' Operators\n\nTo illustrate how to combine and operators, let's first create a table called products with product details, showcasing how these operators can be effectively used together to filter data based on both patterns and predefined values. This combination allows for more precise and flexible searches in SQL queries.\n\nExample 1: Filtering Products Starting with 'A' or 'B' in Specific Categories\n\nThis query retrieves products whose names start with 'A' or 'B' and belong to the 'Electronics' or 'Clothing' categories. It uses the operator for pattern matching and the operator to filter by specific categories.\n\nExample 2: Filtering Products Including 'Phone' or 'Speaker' in Electronics\n\nThis query retrieves products that have \"Phone\" or \"Speaker\" in their names and belong to either the 'Electronics' or 'Accessories' categories. It combines the operator for pattern matching with the operator for filtering by categories.\n\nBy combining the and operators in SQL, users can create highly tailored queries that filter data based on specific patterns and predefined values. This approach enhances the power and flexibility of SQL, making it easier to navigate complex datasets and retrieve precise information based on multiple criteria. Mastering this combination can lead to more efficient and focused queries, significantly improving our SQL querying capabilities.\n\nCan you use LIKE and OR in SQL?\n\nIs LIKE and IN combination in SQL?\n\nWhat is LIKE and BETWEEN in SQL?"
    },
    {
        "link": "https://stackoverflow.com/questions/3014940/is-there-a-combination-of-like-and-in-in-sql",
        "document": "I'm working with SQl Server and Oracle here but I'm interested if this is possible in any RDBMS at all.\n\nI want something as easy as WHERE something LIKE ('bla%', '%foo%', 'batz%') instead of this:\n\nIs there any possible way to combine these two things without writing complicated sub-selects?\n\nFurther, I often use conditions like WHERE something in (1,1,2,3,5,8,13,21) for better readability and flexibility of my SQL statements.\n\nIn SQL I (sadly) often have to use \" LIKE \" conditions due to databases that violate nearly every rule of normalization. I can't change that right now. But that's irrelevant to the question.\n\nI'm working with SQl Server and Oracle here but I'm interested if this is possible in any RDBMS at all. ALL every string in the list.\n\n ANY any string in the list. ┌──────────────────────────────┬────────────────────────────────────┐ │ THIS expression … │ IS equivalent to this expression … │ ├──────────────────────────────┼────────────────────────────────────┤ │ x LIKE ALL ('A%','%B','%C%') │ x LIKE 'A%' │ │ │ AND x LIKE '%B' │ │ │ AND x LIKE '%C%' │ │ │ │ │ x LIKE ANY ('A%','%B','%C%') │ x LIKE 'A%' │ │ │ OR x LIKE '%B' │ │ │ OR x LIKE '%C%' │ └──────────────────────────────┴────────────────────────────────────┘ Add synthetic [NOT] LIKE ANY and [NOT] LIKE ALL operators A lot of times, SQL users would like to be able to combine LIKE and IN predicates, as in: SELECT * FROM customer WHERE last_name [ NOT ] LIKE ANY ('A%', 'E%') [ ESCAPE '!' ] The workaround is to manually expand the predicate to the equivalent SELECT * FROM customer WHERE last_name LIKE 'A%' OR last_name LIKE 'E%' jOOQ could support such a synthetic predicate out of the box. SELECT * FROM t WHERE c LIKE ANY (ARRAY['A%', '%B']); SELECT * FROM t WHERE c LIKE ANY ('{\"Do%\", \"%at\"}'); Snowflake also supports LIKE ANY/LIKE ALL matching: Allows case-sensitive matching of strings based on comparison with one or more patterns. SELECT * FROM like_example WHERE subject LIKE ANY ('%Jo%oe%','T%e') -- WHERE subject LIKE ALL ('%Jo%oe%','J%e')\n\nFor Sql Server you can resort to Dynamic SQL. Most of the time in such situations you have the parameter of IN clause based on some data from database. The example below is a little \"forced\", but this can match various real cases found in legacy databases. Suppose you have table Persons where person names are stored in a single field PersonName as FirstName + ' ' + LastName. You need to select all persons from a list of first names, stored in field NameToSelect in table NamesToSelect, plus some additional criteria (like filtered on gender, birth date, etc) -- @gender is nchar(1), @birthDate is date declare @sql nvarchar(MAX), @subWhere nvarchar(MAX) @params nvarchar(MAX) -- prepare the where sub-clause to cover LIKE IN (...) -- it will actually generate where clause PersonName Like 'param1%' or PersonName Like 'param2%' or ... set @subWhere = STUFF( ( SELECT ' OR PersonName like ''' + [NameToSelect] + '%''' FROM [NamesToSelect] t FOR XML PATH('') ), 1, 4, '') -- create the dynamic SQL set @sql ='select PersonName ,Gender ,BirstDate -- and other field here from [Persons] where Gender = @gender AND BirthDate = @birthDate AND (' + @subWhere + ')' set @params = ' @gender nchar(1), @birthDate Date' EXECUTE sp_executesql @sql, @params, @gender, @birthDate\n\nI hate to drag up this old topic, but I just had this problem in MySQL, and since I was building my statement in PHP, I was able to come up with a more efficient solution as far as coding is concerned. First, I put everything I'm looking for into a simple array: And then the magic happens when I build a cumbersome string with an implode statement: if (sizeof($myArray) > 0) { $sqlLikes = \"(Something LIKE '\"; $sqlLikes .= implode(\"' OR Something LIKE '\", $myArray) $sqlLikes .= \"')\"; ) This builds a string that looks like this: And then I drop my string variable in my SQL statement as such: This will work for any size array. Yes, the resulting SQL statement will be cumbersome, but I don't care because I never need to see the statement, and building the sql was direct and simple for me."
    },
    {
        "link": "https://w3schools.com/sql/sql_like.asp",
        "document": "The operator is used in a clause to search for a specified pattern in a column.\n\nThere are two wildcards often used in conjunction with the operator:\n• The percent sign represents zero, one, or multiple characters\n\nYou will learn more about wildcards in the next chapter.\n\nBelow is a selection from the Customers table used in the examples:\n\nIt can be any character or number, but each represents one, and only one, character.\n\nReturn all customers from a city that starts with 'L' followed by one wildcard character, then 'nd' and then two wildcard characters: SELECT * FROM Customers\n\n WHERE city LIKE 'L_nd__'; Try it Yourself »\n\nThe wildcard represents any number of characters, even zero characters.\n\nTo return records that starts with a specific letter or phrase, add the at the end of the letter or phrase.\n\nTo return records that ends with a specific letter or phrase, add the at the beginning of the letter or phrase.\n\nTo return records that contains a specific letter or phrase, add the both before and after the letter or phrase.\n\nAny wildcard, like and , can be used in combination with other wildcards.\n\nReturn all customers that starts with \"a\" and are at least 3 characters in length: SELECT * FROM Customers\n\n WHERE CustomerName LIKE 'a__%'; Try it Yourself »\n\nIf no wildcard is specified, the phrase has to have an exact match to return a result."
    },
    {
        "link": "https://stackoverflow.com/questions/2318126/using-sql-like-and-in-together",
        "document": "You can do it by in one query by stringing together the individual LIKEs with ORs:\n\nJust be aware that things like LIKE and per-row functions don't always scale that well. If your table is likely to grow large, you may want to consider adding another column to your table to store the first four characters of the field independently.\n\nThis duplicates data but you can guarantee it stays consistent by using insert and update triggers. Then put an index on that new column and your queries become:\n\nThis moves the cost-of-calculation to the point where it's necessary (when the data changes), not every single time you read it. In fact, you could go even further and have your new column as a boolean indicating that it was one of the four special types (if that group of specials will change infrequently). Then the query would be an even faster:\n\nThis tradeoff of storage requirement for speed is a useful trick for larger databases - generally, disk space is cheap, CPU grunt is precious, and data is read far more often than written. By moving the cost-of-calculation to the write stage, you amortise the cost across all the reads."
    },
    {
        "link": "https://geeksforgeeks.org/sql-like",
        "document": "The SQL LIKE operator is used for performing pattern-based searches in a database. It is used in combination with the WHERE clause to filter records based on specified patterns, making it essential for any database-driven application that requires flexible search functionality.\n\nIn this article, we will explain the SQL LIKE operator, its syntax, uses, and practical examples. It also dives into advanced concepts like case sensitivity and wildcard characters, helping you optimize your queries for better performance and relevance.\n\nWhat is the SQL LIKE Operator?\n\nSQL LIKE operator is used with the WHERE clause to search for a specified pattern in a column. LIKE operator finds and returns the rows that fit in the given pattern.\n\nLIKE operator is case-insensitive by default in most database systems. This means that if you search for “apple” using the LIKE operator, it will return results that include “Apple”, “APPLE”, “aPpLe”, and so on.\n• None column_name: The column to be searched.\n• None pattern: The pattern to search for, which can include wildcard characters.\n\nFor making the LIKE operator case-sensitive, you can use the “BINARY” keyword in MySQL or the “COLLATE” keyword in other database systems.\n\nThis following query will only return products whose name starts with “apple” and is spelled exactly like that, without capital letters.\n\nWildcard Characters with the SQL LIKE Operator\n\nWildcards are used with the LIKE operator to search for specific patterns in strings. Wildcard characters substitute one or more characters in the string. There are four wildcard characters in SQL:\n• % (Percent): Represents zero or more characters.\n\nThe below table shows some examples on how wild card can be written and what do they mean:\n\nIn this tutorial on SQL LIKE Operator, we will use the following table in the examples.\n\nRetrieve SupplierID, Name, and Address from suppliers table, where supplier name starts form k.\n\nExample 3: Match Names Where ‘ango’ Appears in the Second Position\n\nRetrieve SupplierID, Name and Address of supplier whose name contains “ango” in second substring.\n\nExample 4: Using LIKE with AND for Complex Conditions\n\nRetrieve suppliers from Delhi with names starting with “C”:\n\nExample 5: Using NOT LIKE for Exclusion\n\nTo retrieve all suppliers whose name does not contain “Mango”\n\nThe LIKE operator is extremely resourceful in situations such as address filtering wherein we know only a segment or a portion of the entire address (such as locality or city) and would like to retrieve results based on that. The wildcards can be resourcefully exploited to yield even better and more filtered tuples based on the requirement.\n\nThe SQL LIKE operator is a powerful tool for pattern matching, allowing you to perform flexible searches within columns. By combining wildcards and logical operators, you can craft complex queries to find the data you need with precision. Understanding how to optimize the use of LIKE with indexes and case sensitivity will help improve query performance."
    }
]