[
    {
        "link": "https://docs.python.org/3/library/sqlite3.html",
        "document": "SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.\n\nThe module was written by Gerhard Häring. It provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249, and requires SQLite 3.15.2 or newer.\n• None Tutorial teaches how to use the module.\n• None Reference describes the classes and functions this module defines.\n\nHow to use placeholders to bind values in SQL queries¶ SQL operations usually need to use values from Python variables. However, beware of using Python’s string operations to assemble queries, as they are vulnerable to SQL injection attacks. For example, an attacker can simply close the single quote and inject to select all rows: # Never do this -- insecure! SELECT * FROM stocks WHERE symbol = '' OR TRUE; --' Instead, use the DB-API’s parameter substitution. To insert a variable into a query string, use a placeholder in the string, and substitute the actual values into the query by providing them as a of values to the second argument of the cursor’s method. An SQL statement may use one of two kinds of placeholders: question marks (qmark style) or named placeholders (named style). For the qmark style, parameters must be a sequence whose length must match the number of placeholders, or a is raised. For the named style, parameters must be an instance of a (or a subclass), which must contain keys for all named parameters; any extra items are ignored. Here’s an example of both styles: # This is the named style used with executemany(): # This is the qmark style used in a SELECT query: PEP 249 numeric placeholders are not supported. If used, they will be interpreted as named placeholders. How to adapt custom Python types to SQLite values¶ SQLite supports only a limited set of data types natively. To store custom Python types in SQLite databases, adapt them to one of the Python types SQLite natively understands. There are two ways to adapt Python objects to SQLite types: letting your object adapt itself, or using an adapter callable. The latter will take precedence above the former. For a library that exports a custom type, it may make sense to enable that type to adapt itself. As an application developer, it may make more sense to take direct control by registering custom adapter functions. Suppose we have a class that represents a pair of coordinates, and , in a Cartesian coordinate system. The coordinate pair will be stored as a text string in the database, using a semicolon to separate the coordinates. This can be implemented by adding a method which returns the adapted value. The object passed to protocol will be of type . The other possibility is to create a function that converts the Python object to an SQLite-compatible type. This function can then be registered using . How to convert SQLite values to custom Python types¶ Writing an adapter lets you convert from custom Python types to SQLite values. To be able to convert from SQLite values to custom Python types, we use converters. Let’s go back to the class. We stored the x and y coordinates separated via semicolons as strings in SQLite. First, we’ll define a converter function that accepts the string as a parameter and constructs a object from it. Converter functions are always passed a object, no matter the underlying SQLite data type. We now need to tell when it should convert a given SQLite value. This is done when connecting to a database, using the detect_types parameter of . There are three options:\n• None Both: set detect_types to . Column names take precedence over declared types. The following example illustrates the implicit and explicit approaches: This section shows recipes for common adapters and converters. How to use connection shortcut methods¶ Using the , , and methods of the class, your code can be written more concisely because you don’t have to create the (often superfluous) objects explicitly. Instead, the objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a statement and iterate over it directly using only a single call on the object. # close() is not a shortcut method and it's not called automatically; # the connection object should be closed manually How to use the connection context manager¶ A object can be used as a context manager that automatically commits or rolls back open transactions when leaving the body of the context manager. If the body of the statement finishes without exceptions, the transaction is committed. If this commit fails, or if the body of the statement raises an uncaught exception, the transaction is rolled back. If is , a new transaction is implicitly opened after committing or rolling back. If there is no open transaction upon leaving the body of the statement, or if is , the context manager does nothing. The context manager neither implicitly opens a new transaction nor closes the connection. If you need a closing context manager, consider using . # con.rollback() is called after the with block finishes with an exception, # the exception is still raised and must be caught # Connection object used as context manager only commits or rollbacks transactions, # so the connection object should be closed manually How to work with SQLite URIs¶\n• None Do not implicitly create a new database file if it does not already exist; will raise if unable to create a new file: More information about this feature, including a list of parameters, can be found in the SQLite URI documentation. How to create and use row factories¶ By default, represents each row as a . If a does not suit your needs, you can use the class or a custom . While exists as an attribute both on the and the , it is recommended to set , so all cursors created from the connection will use the same row factory. provides indexed and case-insensitive named access to columns, with minimal memory overhead and performance impact over a . To use as a row factory, assign it to the attribute: \"SELECT 'Earth' AS name, 6378 AS radius\" The clause can be omitted in the statement, as in the above example. In such cases, SQLite returns a single row with columns defined by expressions, e.g. literals, with the given aliases . You can create a custom that returns each row as a , with column names mapped to values: Using it, queries now return a instead of a : can be used as follows: With some adjustments, the above recipe can be adapted to use a , or any other custom class, instead of a . By default, uses to adapt SQLite values with the data type. This works well for UTF-8 encoded text, but it might fail for other encodings and invalid UTF-8. You can use a custom to handle such cases. Because of SQLite’s flexible typing, it is not uncommon to encounter table columns with the data type containing non-UTF-8 encodings, or even arbitrary data. To demonstrate, let’s assume we have a database with ISO-8859-2 (Latin-2) encoded text, for example a table of Czech-English dictionary entries. Assuming we now have a instance connected to this database, we can decode the Latin-2 encoded text using this : For invalid UTF-8 or arbitrary data in stored in table columns, you can use the following technique, borrowed from the Unicode HOWTO: The module API does not support strings containing surrogates."
    },
    {
        "link": "https://stackoverflow.com/questions/54289555/how-do-i-execute-an-sqlite-script-from-within-python",
        "document": "from within the SQLite shell.\n\nHowever, the following Python code is not doing it properly. I'm getting a syntax error in line 5.\n\nI know I'm doing something wrong with the quotes. How do I make this work?"
    },
    {
        "link": "https://geeksforgeeks.org/how-to-execute-a-script-in-sqlite-using-python",
        "document": "In this article, we are going to see how to execute a script in SQLite using Python. Here we are executing create table and insert records into table scripts through Python. In Python, the sqlite3 module supports SQLite database for storing the data in the database.\n\nStep 1: First we need to import the sqlite3 module in Python.\n\nStep 2: Connect to the database by creating the database. We can connect to the database by simply create a database named geeks_db.db or we can simply create a database in our memory by using :memory:\n\nStep 3: Create the cursor object after making the database connection.\n\nStep 4: Write the SQL query that can be executable.\n\nStep 6: Get the data inside the table from the database."
    },
    {
        "link": "https://docs.python.org/3.9/library/sqlite3.html",
        "document": "SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.\n\nThe sqlite3 module was written by Gerhard Häring. It provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249.\n\nTo use the module, start by creating a object that represents the database. Here the data will be stored in the file:\n\nThe special path name can be provided to create a temporary database in RAM.\n\nOnce a has been established, create a object and call its method to perform SQL commands:\n\nThe saved data is persistent: it can be reloaded in a subsequent session even after restarting the Python interpreter:\n\nTo retrieve data after executing a SELECT statement, either treat the cursor as an iterator, call the cursor’s method to retrieve a single matching row, or call to get a list of the matching rows.\n\nThis example uses the iterator form:\n\nSQL operations usually need to use values from Python variables. However, beware of using Python’s string operations to assemble queries, as they are vulnerable to SQL injection attacks (see the xkcd webcomic for a humorous example of what can go wrong):\n\nInstead, use the DB-API’s parameter substitution. To insert a variable into a query string, use a placeholder in the string, and substitute the actual values into the query by providing them as a of values to the second argument of the cursor’s method. An SQL statement may use one of two kinds of placeholders: question marks (qmark style) or named placeholders (named style). For the qmark style, must be a sequence. For the named style, it can be either a sequence or instance. The length of the sequence must match the number of placeholders, or a is raised. If a is given, it must contain keys for all named parameters. Any extra items are ignored. Here’s an example of both styles:\n\nString constant stating the supported DB-API level. Required by the DB-API. Hard-coded to . String constant stating the type of parameter marker formatting expected by the module. Required by the DB-API. Hard-coded to . The module supports both and DB-API parameter styles, because that is what the underlying SQLite library supports. However, the DB-API does not allow multiple values for the attribute. The version number of this module, as a string. This is not the version of the SQLite library. The version number of this module, as a tuple of integers. This is not the version of the SQLite library. The version number of the run-time SQLite library, as a string. The version number of the run-time SQLite library, as a tuple of integers. Integer constant required by the DB-API, stating the level of thread safety the module supports. Currently hard-coded to , meaning “Threads may share the module, but not connections.” However, this may not always be true. You can check the underlying SQLite library’s compile-time threaded mode using the following query: Note that the SQLITE_THREADSAFE levels do not match the DB-API 2.0 levels. This constant is meant to be used with the detect_types parameter of the function. Setting it makes the module parse the declared type for each column it returns. It will parse out the first word of the declared type, i. e. for “integer primary key”, it will parse out “integer”, or for “number(10)” it will parse out “number”. Then for that column, it will look into the converters dictionary and use the converter function registered for that type there. This constant is meant to be used with the detect_types parameter of the function. Setting this makes the SQLite interface parse the column name for each column it returns. It will look for a string formed [mytype] in there, and then decide that ‘mytype’ is the type of the column. It will try to find an entry of ‘mytype’ in the converters dictionary and then use the converter function found there to return the value. The column name found in does not include the type, i. e. if you use something like in your SQL, then we will parse out everything until the first for the column name and strip the preceding space: the column name would simply be “Expiration date”. Opens a connection to the SQLite database file database. By default returns a object, unless a custom factory is given. database is a path-like object giving the pathname (absolute or relative to the current working directory) of the database file to be opened. You can use to open a database connection to a database that resides in RAM instead of on disk. When a database is accessed by multiple connections, and one of the processes modifies the database, the SQLite database is locked until that transaction is committed. The timeout parameter specifies how long the connection should wait for the lock to go away until raising an exception. The default for the timeout parameter is 5.0 (five seconds). For the isolation_level parameter, please see the property of objects. SQLite natively supports only the types TEXT, INTEGER, REAL, BLOB and NULL. If you want to use other types you must add support for them yourself. The detect_types parameter and the using custom converters registered with the module-level function allow you to easily do that. detect_types defaults to 0 (i. e. off, no type detection), you can set it to any combination of and to turn type detection on. Due to SQLite behaviour, types can’t be detected for generated fields (for example ), even when detect_types parameter is set. In such case, the returned type is . By default, check_same_thread is and only the creating thread may use the connection. If set , the returned connection may be shared across multiple threads. When using multiple threads with the same connection writing operations should be serialized by the user to avoid data corruption. By default, the module uses its class for the connect call. You can, however, subclass the class and make use your class instead by providing your class for the factory parameter. Consult the section SQLite and Python types of this manual for details. The module internally uses a statement cache to avoid SQL parsing overhead. If you want to explicitly set the number of statements that are cached for the connection, you can set the cached_statements parameter. The currently implemented default is to cache 100 statements. If uri is , database is interpreted as a with a file path and an optional query string. The scheme part must be . The path can be a relative or absolute file path. The query string allows us to pass parameters to SQLite. Some useful URI tricks include: # Don't implicitly create a new database file if it does not already exist. # Will raise sqlite3.OperationalError if unable to open a database file. More information about this feature, including a list of recognized parameters, can be found in the SQLite URI documentation. Changed in version 3.7: database can now also be a path-like object, not only a string. Registers a callable to convert a bytestring from the database into a custom Python type. The callable will be invoked for all database values that are of the type typename. Confer the parameter detect_types of the function for how the type detection works. Note that typename and the name of the type in your query are matched in case-insensitive manner. Registers a callable to convert the custom Python type type into one of SQLite’s supported types. The callable callable accepts as single parameter the Python value, and must return a value of the following types: int, float, str or bytes. Returns if the string sql contains one or more complete SQL statements terminated by semicolons. It does not verify that the SQL is syntactically correct, only that there are no unclosed string literals and the statement is terminated by a semicolon. This can be used to build a shell for SQLite, as in the following example: \"Enter your SQL commands to execute in sqlite3.\" By default you will not get any tracebacks in user-defined functions, aggregates, converters, authorizer callbacks etc. If you want to debug them, you can call this function with flag set to . Afterwards, you will get tracebacks from callbacks on . Use to disable the feature again.\n\nAn SQLite database connection has the following attributes and methods: Get or set the current default isolation level. for autocommit mode or one of “DEFERRED”, “IMMEDIATE” or “EXCLUSIVE”. See section Controlling Transactions for a more detailed explanation. if a transaction is active (there are uncommitted changes), otherwise. Read-only attribute. The cursor method accepts a single optional parameter factory. If supplied, this must be a callable returning an instance of or its subclasses. This method commits the current transaction. If you don’t call this method, anything you did since the last call to is not visible from other database connections. If you wonder why you don’t see the data you’ve written to the database, please check you didn’t forget to call this method. This method rolls back any changes to the database since the last call to . This closes the database connection. Note that this does not automatically call . If you just close your database connection without calling first, your changes will be lost! Create a new object and call on it with the given sql and parameters. Return the new cursor object. Create a new object and call on it with the given sql and parameters. Return the new cursor object. Create a new object and call on it with the given sql_script. Return the new cursor object. Creates a user-defined function that you can later use from within SQL statements under the function name name. num_params is the number of parameters the function accepts (if num_params is -1, the function may take any number of arguments), and func is a Python callable that is called as the SQL function. If deterministic is true, the created function is marked as deterministic, which allows SQLite to perform additional optimizations. This flag is supported by SQLite 3.8.3 or higher, will be raised if used with older versions. The function can return any of the types supported by SQLite: bytes, str, int, float and . Changed in version 3.8: The deterministic parameter was added. The aggregate class must implement a method, which accepts the number of parameters num_params (if num_params is -1, the function may take any number of arguments), and a method which will return the final result of the aggregate. The method can return any of the types supported by SQLite: bytes, str, int, float and . Creates a collation with the specified name and callable. The callable will be passed two string arguments. It should return -1 if the first is ordered lower than the second, 0 if they are ordered equal and 1 if the first is ordered higher than the second. Note that this controls sorting (ORDER BY in SQL) so your comparisons don’t affect other SQL operations. Note that the callable will get its parameters as Python bytestrings, which will normally be encoded in UTF-8. The following example shows a custom collation that sorts “the wrong way”: To remove a collation, call with as callable: You can call this method from a different thread to abort any queries that might be executing on the connection. The query will then abort and the caller will get an exception. This routine registers a callback. The callback is invoked for each attempt to access a column of a table in the database. The callback should return if access is allowed, if the entire SQL statement should be aborted with an error and if the column should be treated as a NULL value. These constants are available in the module. The first argument to the callback signifies what kind of operation is to be authorized. The second and third argument will be arguments or depending on the first argument. The 4th argument is the name of the database (“main”, “temp”, etc.) if applicable. The 5th argument is the name of the inner-most trigger or view that is responsible for the access attempt or if this access attempt is directly from input SQL code. Please consult the SQLite documentation about the possible values for the first argument and the meaning of the second and third argument depending on the first one. All necessary constants are available in the module. This routine registers a callback. The callback is invoked for every n instructions of the SQLite virtual machine. This is useful if you want to get called from SQLite during long-running operations, for example to update a GUI. If you want to clear any previously installed progress handler, call the method with for handler. Returning a non-zero value from the handler function will terminate the currently executing query and cause it to raise an exception. Registers trace_callback to be called for each SQL statement that is actually executed by the SQLite backend. The only argument passed to the callback is the statement (as ) that is being executed. The return value of the callback is ignored. Note that the backend does not only run statements passed to the methods. Other sources include the transaction management of the sqlite3 module and the execution of triggers defined in the current database. Passing as trace_callback will disable the trace callback. Exceptions raised in the trace callback are not propagated. As a development and debugging aid, use to enable printing tracebacks from exceptions raised in the trace callback. This routine allows/disallows the SQLite engine to load SQLite extensions from shared libraries. SQLite extensions can define new functions, aggregates or whole new virtual table implementations. One well-known extension is the fulltext-search extension distributed with SQLite. Loadable extensions are disabled by default. See . # alternatively you can load the extension using an API call: \"select rowid, name, ingredients from recipe where name match 'pie'\" This routine loads an SQLite extension from a shared library. You have to enable extension loading with before you can use this routine. Loadable extensions are disabled by default. See . You can change this attribute to a callable that accepts the cursor and the original row as a tuple and will return the real result row. This way, you can implement more advanced ways of returning results, such as returning an object that can also access columns by name. If returning a tuple doesn’t suffice and you want name-based access to columns, you should consider setting to the highly-optimized type. provides both index-based and case-insensitive name-based access to columns with almost no memory overhead. It will probably be better than your own custom dictionary-based approach or even a db_row based solution. Using this attribute you can control what objects are returned for the data type. By default, this attribute is set to and the module will return objects for . If you want to return instead, you can set it to . You can also set it to any other callable that accepts a single bytestring parameter and returns the resulting object. See the following example code for illustration: # by default, rows are returned as str # but we can make sqlite3 always return bytestrings ... # the bytestrings will be encoded in UTF-8, unless you stored garbage in the # we can also implement a custom text_factory ... # here we implement one that appends \"foo\" to all strings Returns the total number of database rows that have been modified, inserted, or deleted since the database connection was opened. Returns an iterator to dump the database in an SQL text format. Useful when saving an in-memory database for later restoration. This function provides the same capabilities as the command in the sqlite3 shell. This method makes a backup of an SQLite database even while it’s being accessed by other clients, or concurrently by the same connection. The copy will be written into the mandatory argument target, that must be another instance. By default, or when pages is either or a negative integer, the entire database is copied in a single step; otherwise the method performs a loop copying up to pages pages at a time. If progress is specified, it must either be or a callable object that will be executed at each iteration with three integer arguments, respectively the status of the last iteration, the remaining number of pages still to be copied and the total number of pages. The name argument specifies the database name that will be copied: it must be a string containing either , the default, to indicate the main database, to indicate the temporary database or the name specified after the keyword in an statement for an attached database. The sleep argument specifies the number of seconds to sleep by between successive attempts to backup remaining pages, can be specified either as an integer or a floating point value. Example 1, copy an existing database into another: Example 2, copy an existing database into a transient copy:\n\nA instance has the following attributes and methods. Executes an SQL statement. Values may be bound to the statement using placeholders. will only execute a single SQL statement. If you try to execute more than one statement with it, it will raise a . Use if you want to execute multiple SQL statements with one call. Executes a parameterized SQL command against all parameter sequences or mappings found in the sequence seq_of_parameters. The module also allows using an iterator yielding parameters instead of a sequence. This is a nonstandard convenience method for executing multiple SQL statements at once. It issues a statement first, then executes the SQL script it gets as a parameter. This method disregards ; any transaction control must be added to sql_script. sql_script can be an instance of . Fetches the next row of a query result set, returning a single sequence, or when no more data is available. Fetches the next set of rows of a query result, returning a list. An empty list is returned when no more rows are available. The number of rows to fetch per call is specified by the size parameter. If it is not given, the cursor’s arraysize determines the number of rows to be fetched. The method should try to fetch as many rows as indicated by the size parameter. If this is not possible due to the specified number of rows not being available, fewer rows may be returned. Note there are performance considerations involved with the size parameter. For optimal performance, it is usually best to use the arraysize attribute. If the size parameter is used, then it is best for it to retain the same value from one call to the next. Fetches all (remaining) rows of a query result, returning a list. Note that the cursor’s arraysize attribute can affect the performance of this operation. An empty list is returned when no rows are available. Close the cursor now (rather than whenever is called). The cursor will be unusable from this point forward; a exception will be raised if any operation is attempted with the cursor. Required by the DB-API. Does nothing in . Required by the DB-API. Does nothing in . Although the class of the module implements this attribute, the database engine’s own support for the determination of “rows affected”/”rows selected” is quirky. For statements, the number of modifications are summed up into . As required by the Python DB API Spec, the attribute “is -1 in case no has been performed on the cursor or the rowcount of the last operation is not determinable by the interface”. This includes statements because we cannot determine the number of rows a query produced until all rows were fetched. With SQLite versions before 3.6.5, is set to 0 if you make a without any condition. This read-only attribute provides the row id of the last inserted row. It is only updated after successful or statements using the method. For other statements, after or , or if the insertion failed, the value of is left unchanged. The initial value of is . Inserts into tables are not recorded. Changed in version 3.6: Added support for the statement. Read/write attribute that controls the number of rows returned by . The default value is 1 which means a single row would be fetched per call. This read-only attribute provides the column names of the last query. To remain compatible with the Python DB API, it returns a 7-tuple for each column where the last six items of each tuple are . It is set for statements without any matching rows as well. This read-only attribute provides the SQLite database used by the object. A object created by calling will have a attribute that refers to con:\n\nThe following Python types can thus be sent to SQLite without any problem: This is how SQLite types are converted to Python types by default: The type system of the module is extensible in two ways: you can store additional Python types in an SQLite database via object adaptation, and you can let the module convert SQLite types to different Python types via converters. Using adapters to store additional Python types in SQLite databases¶ As described before, SQLite supports only a limited set of types natively. To use other Python types with SQLite, you must adapt them to one of the sqlite3 module’s supported types for SQLite: one of NoneType, int, float, str, bytes. There are two ways to enable the module to adapt a custom Python type to one of the supported ones. This is a good approach if you write the class yourself. Let’s suppose you have a class like this: Now you want to store the point in a single SQLite column. First you’ll have to choose one of the supported types to be used for representing the point. Let’s just use str and separate the coordinates using a semicolon. Then you need to give your class a method which must return the converted value. The parameter protocol will be . The other possibility is to create a function that converts the type to the string representation and register the function with . The module has two default adapters for Python’s built-in and types. Now let’s suppose we want to store objects not in ISO representation, but as a Unix timestamp. Writing an adapter lets you send custom Python types to SQLite. But to make it really useful we need to make the Python to SQLite to Python roundtrip work. Let’s go back to the class. We stored the x and y coordinates separated via semicolons as strings in SQLite. First, we’ll define a converter function that accepts the string as a parameter and constructs a object from it. Converter functions always get called with a object, no matter under which data type you sent the value to SQLite. Now you need to make the module know that what you select from the database is actually a point. There are two ways of doing this:\n• None Explicitly via the column name Both ways are described in section Module functions and constants, in the entries for the constants and . The following example illustrates both approaches. There are default adapters for the date and datetime types in the datetime module. They will be sent as ISO dates/ISO timestamps to SQLite. The default converters are registered under the name “date” for and under the name “timestamp” for . This way, you can use date/timestamps from Python without any additional fiddling in most cases. The format of the adapters is also compatible with the experimental SQLite date/time functions. The following example demonstrates this. If a timestamp stored in SQLite has a fractional part longer than 6 numbers, its value will be truncated to microsecond precision by the timestamp converter. The default “timestamp” converter ignores UTC offsets in the database and always returns a naive object. To preserve UTC offsets in timestamps, either leave converters disabled, or register an offset-aware converter with .\n\nThe underlying library operates in mode by default, but the Python module by default does not. mode means that statements that modify the database take effect immediately. A or statement disables mode, and a , a , or a that ends the outermost transaction, turns mode back on. The Python module by default issues a statement implicitly before a Data Modification Language (DML) statement (i.e. / / / ). You can control which kind of statements implicitly executes via the isolation_level parameter to the call, or via the property of connections. If you specify no isolation_level, a plain is used, which is equivalent to specifying . Other possible values are and . You can disable the module’s implicit transaction management by setting to . This will leave the underlying library operating in mode. You can then completely control the transaction state by explicitly issuing , , , and statements in your code. Note that disregards ; any transaction control must be added explicitly. Changed in version 3.6: used to implicitly commit an open transaction before DDL statements. This is no longer the case.\n\nUsing the nonstandard , and methods of the object, your code can be written more concisely because you don’t have to create the (often superfluous) objects explicitly. Instead, the objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a statement and iterate over it directly using only a single call on the object. # close is not a shortcut method and it's not called automatically, # so the connection object should be closed manually Accessing columns by name instead of by index¶ One useful feature of the module is the built-in class designed to be used as a row factory. Rows wrapped with this class can be accessed both by index (like tuples) and case-insensitively by name: \"select 'John' as name, 42 as age\" Using the connection as a context manager¶ Connection objects can be used as context managers that automatically commit or rollback transactions. In the event of an exception, the transaction is rolled back; otherwise, the transaction is committed: # con.rollback() is called after the with block finishes with an exception, the # exception is still raised and must be caught # Connection object used as context manager only commits or rollbacks transactions, # so the connection object should be closed manually"
    },
    {
        "link": "https://stackoverflow.com/questions/11643611/execute-sqlite-script",
        "document": "If you are using the windows CMD you can use this command to create a database using sqlite3\n\nIf you haven't a database with that name sqlite3 will create one, and if you already have one, it will run it anyways but with the \"TABLENAME already exists\" error, I think you can also use this command to change an already existing database (but im not sure)"
    },
    {
        "link": "https://stackoverflow.com/questions/51065457/how-to-import-a-sql-file-to-python",
        "document": "I'm attempting to import an sq file that already has tables into python. However, it doesn't seem to import what I had hoped. The only things I've seen so far are how to creata a new sq file with a table, but I'm looking to just have an already completed sq file imported into python. So far, I've written this.\n\nHowever, it keeps claiming that the Trade Details table, which is a table inside the file I've connected it to, does not exist. Nowhere I've looked shows me how to do this with an already created file and table, so please don't just redirect me to an answer about that"
    },
    {
        "link": "https://stackoverflow.com/questions/2049109/how-to-import-sql-files-into-sqlite3",
        "document": "For example, you export to with or as shown below. * is created if it doesn't exist and can export schema with data and can export only schema and my answer explains how to export a database:\n\nNow, you can import into as shown below. * is created if it doesn't exist:\n\nBe careful, if you directly import into as shown below:\n\nThen, you get the error below:"
    },
    {
        "link": "https://docs.python.org/3/library/sqlite3.html",
        "document": "SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.\n\nThe module was written by Gerhard Häring. It provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249, and requires SQLite 3.15.2 or newer.\n• None Tutorial teaches how to use the module.\n• None Reference describes the classes and functions this module defines.\n\nHow to use placeholders to bind values in SQL queries¶ SQL operations usually need to use values from Python variables. However, beware of using Python’s string operations to assemble queries, as they are vulnerable to SQL injection attacks. For example, an attacker can simply close the single quote and inject to select all rows: # Never do this -- insecure! SELECT * FROM stocks WHERE symbol = '' OR TRUE; --' Instead, use the DB-API’s parameter substitution. To insert a variable into a query string, use a placeholder in the string, and substitute the actual values into the query by providing them as a of values to the second argument of the cursor’s method. An SQL statement may use one of two kinds of placeholders: question marks (qmark style) or named placeholders (named style). For the qmark style, parameters must be a sequence whose length must match the number of placeholders, or a is raised. For the named style, parameters must be an instance of a (or a subclass), which must contain keys for all named parameters; any extra items are ignored. Here’s an example of both styles: # This is the named style used with executemany(): # This is the qmark style used in a SELECT query: PEP 249 numeric placeholders are not supported. If used, they will be interpreted as named placeholders. How to adapt custom Python types to SQLite values¶ SQLite supports only a limited set of data types natively. To store custom Python types in SQLite databases, adapt them to one of the Python types SQLite natively understands. There are two ways to adapt Python objects to SQLite types: letting your object adapt itself, or using an adapter callable. The latter will take precedence above the former. For a library that exports a custom type, it may make sense to enable that type to adapt itself. As an application developer, it may make more sense to take direct control by registering custom adapter functions. Suppose we have a class that represents a pair of coordinates, and , in a Cartesian coordinate system. The coordinate pair will be stored as a text string in the database, using a semicolon to separate the coordinates. This can be implemented by adding a method which returns the adapted value. The object passed to protocol will be of type . The other possibility is to create a function that converts the Python object to an SQLite-compatible type. This function can then be registered using . How to convert SQLite values to custom Python types¶ Writing an adapter lets you convert from custom Python types to SQLite values. To be able to convert from SQLite values to custom Python types, we use converters. Let’s go back to the class. We stored the x and y coordinates separated via semicolons as strings in SQLite. First, we’ll define a converter function that accepts the string as a parameter and constructs a object from it. Converter functions are always passed a object, no matter the underlying SQLite data type. We now need to tell when it should convert a given SQLite value. This is done when connecting to a database, using the detect_types parameter of . There are three options:\n• None Both: set detect_types to . Column names take precedence over declared types. The following example illustrates the implicit and explicit approaches: This section shows recipes for common adapters and converters. How to use connection shortcut methods¶ Using the , , and methods of the class, your code can be written more concisely because you don’t have to create the (often superfluous) objects explicitly. Instead, the objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a statement and iterate over it directly using only a single call on the object. # close() is not a shortcut method and it's not called automatically; # the connection object should be closed manually How to use the connection context manager¶ A object can be used as a context manager that automatically commits or rolls back open transactions when leaving the body of the context manager. If the body of the statement finishes without exceptions, the transaction is committed. If this commit fails, or if the body of the statement raises an uncaught exception, the transaction is rolled back. If is , a new transaction is implicitly opened after committing or rolling back. If there is no open transaction upon leaving the body of the statement, or if is , the context manager does nothing. The context manager neither implicitly opens a new transaction nor closes the connection. If you need a closing context manager, consider using . # con.rollback() is called after the with block finishes with an exception, # the exception is still raised and must be caught # Connection object used as context manager only commits or rollbacks transactions, # so the connection object should be closed manually How to work with SQLite URIs¶\n• None Do not implicitly create a new database file if it does not already exist; will raise if unable to create a new file: More information about this feature, including a list of parameters, can be found in the SQLite URI documentation. How to create and use row factories¶ By default, represents each row as a . If a does not suit your needs, you can use the class or a custom . While exists as an attribute both on the and the , it is recommended to set , so all cursors created from the connection will use the same row factory. provides indexed and case-insensitive named access to columns, with minimal memory overhead and performance impact over a . To use as a row factory, assign it to the attribute: \"SELECT 'Earth' AS name, 6378 AS radius\" The clause can be omitted in the statement, as in the above example. In such cases, SQLite returns a single row with columns defined by expressions, e.g. literals, with the given aliases . You can create a custom that returns each row as a , with column names mapped to values: Using it, queries now return a instead of a : can be used as follows: With some adjustments, the above recipe can be adapted to use a , or any other custom class, instead of a . By default, uses to adapt SQLite values with the data type. This works well for UTF-8 encoded text, but it might fail for other encodings and invalid UTF-8. You can use a custom to handle such cases. Because of SQLite’s flexible typing, it is not uncommon to encounter table columns with the data type containing non-UTF-8 encodings, or even arbitrary data. To demonstrate, let’s assume we have a database with ISO-8859-2 (Latin-2) encoded text, for example a table of Czech-English dictionary entries. Assuming we now have a instance connected to this database, we can decode the Latin-2 encoded text using this : For invalid UTF-8 or arbitrary data in stored in table columns, you can use the following technique, borrowed from the Unicode HOWTO: The module API does not support strings containing surrogates."
    },
    {
        "link": "https://mungingdata.com/sqlite/create-database-load-csv-python",
        "document": "This blog post demonstrates how to build a sqlite database from CSV files.\n\nPython is perfect language for this task because it has great libraries for sqlite and CSV DataFrames.\n\nsqlite is a lightweight database that can be started as an empty text file. You can create the file with or with this equivalent Python code:\n\nA zero byte text file is a great starting point for a lightweight database!\n\nSuppose you have the following file:\n\nPandas makes it easy to load this CSV data into a sqlite table:\n\nThe method makes it easy to write DataFrames to databases.\n\nFetch all the rows from the table:\n\nThe method returns an array of tuples.\n\nreturns a object. Cursors can be thought of as iterators in the database world.\n\nLoad another CSV into the databases\n\nSuppose you have the following file:\n\nCreate a table and then load the orders data into the database.\n\nJoin the and tables on the value and print the results:\n\nYou can also read the SQL query directly into a Pandas DataFrame.\n\nPython's build in sqlite library coupled with Pandas DataFrames makes it easy to load CSV data into sqlite databases.\n\nsqlite databases are great for local experimentation and are used extensively on mobile phones. It's a great database when you'd like relational database query functionality without the overhead of Postgres.\n\nPython's great support for sqlite will make you love it in no time."
    },
    {
        "link": "https://reddit.com/r/learnpython/comments/v6y5by/best_practice_for_putting_sql_query_in_python_code",
        "document": "Writing a script the uses pyodbc to run a sql query and push that data to excel.\n\nIs there a best way to put this SQL query into my code? Is it to just limit the characters per line?"
    }
]