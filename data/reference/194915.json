[
    {
        "link": "https://lucidchart.com/pages/uml-use-case-diagram",
        "document": "A use case diagram doesn't go into a lot of detail—for example, don't expect it to model the order in which steps are performed. Instead, a proper use case diagram depicts a high-level overview of the relationship between use cases, actors, and systems. Experts recommend that use case diagrams be used to supplement a more descriptive textual use case.\n\nUML is the modeling toolkit that you can use to build your diagrams. Use cases are represented with a labeled oval shape. Stick figures represent actors in the process, and the actor's participation in the system is modeled with a line between the actor and use case. To depict the system boundary, draw a box around the use case itself.\n\nUML use case diagrams are ideal for:\n• Specifying the context and requirements of a system\n• Modeling the basic flow of events in a use case"
    },
    {
        "link": "https://support.microsoft.com/en-us/office/create-a-uml-use-case-diagram-92cc948d-fc74-466c-9457-e82d62ee1298",
        "document": "You can create a UML use case diagram in Visio to summarize how users (or actors) interact with a system, such as a software application. An actor can be a person, an organization, or another system.\n\nUse case diagrams show the expected behavior of the system. They don't show the order in which steps are performed. (Use a sequence diagram to show how objects interact over time.)\n\nDefining the system boundary determines what is considered external or internal to the system. An actor represents a role played by an outside object. One object may play several roles and, therefore, is represented by several actors. An association illustrates the participation of the actor in the use case. A use case is a set of events that occurs when an actor uses a system to complete a process. Normally, a use case is a relatively large process, not an individual step or transaction.\n• On the File tab, point to New.\n• in the Search box, type UML use case.\n• From the search results, select UML Use Case.\n• In the dialog box, select the blank template or one of the three starter diagrams. (A description of each one is shown on the right when you select it.) Then select either Metric Units or US Units.\n• The diagram opens. You should see the Shapes window next to the diagram. A UML Use Case stencil is open in the Shapes window. Add a subsystem to the use case diagram\n• Drag a Subsystem shape onto the drawing page. The subsystem can represent your entire system or a major component.\n• Double-click the Subsystem shape, and then type a new name for the for it, or press the Delete key to delete the existing name. Click outside the shape on the drawing page.\n• To resize the subsystem, select the shape, and then drag a selection handle. Add shapes and connectors to the diagram\n• Drag Use Case shapes from the UML Use Case stencil and place them inside the subsystem boundary, and then drag Actor shapes to the outside of the subsystem boundary.\n• Use connector shapes to indicate relationships between shapes in the diagram. There are five connectors available: Shows the relationship of an actor to a use case. Indicates that one use case has a dependency on another. Indicates that a use case is a specific way to achieve goals of the general use case. Shows how a use case is broken into smaller steps. Shows that one use case adds functionality to another. Example: To indicate a relationship between an actor and a use case\n• In a use case diagram, drag an Association connector shape onto the drawing page.\n• Glue one endpoint of the Association shape to a connection point on an Actor shape. Glue the other endpoint to a connection point on a Use Case shape. For more information about use case diagrams (and procedures for using Microsoft Visual Studio to create use case diagrams), go to UML Use Case Diagrams: Guidelines. Note: Creating and editing UML diagrams on Visio for the web requires a Visio Plan 1 or Visio Plan 2 license, which is purchased separately from Microsoft 365. For more information, contact your Microsoft 365 admin. If your admin has turned on \"self-service purchasing,\" you can buy a license for Visio yourself. For more details, see Self-service purchase FAQ.\n• Near the upper right corner of the page, select More templates.\n• In the Gallery, scroll down to the UML Use Case row. The first item in the row represents a blank template plus the companion stencil. The other items in the row are sample diagrams that have some shapes already drawn to help you get started quickly.\n• Click any item to see a larger preview.\n• When you find the diagram you want to use, click its Create button. The new diagram, with the related stencil, opens in your browser. Add a subsystem to the use case diagram\n• Drag a Subsystem shape onto the drawing page. The subsystem can represent your entire system or a major component.\n• Double-click the Subsystem shape, and then type a new name for the for it, or press the Delete key to delete the existing name. Click outside the shape on the drawing page.\n• To resize the subsystem, select the shape, and then drag a selection handle. Add shapes and connectors to the diagram\n• Drag Use Case shapes from the Use Case stencil and place them inside the subsystem boundary\n• Drag Actor shapes to the outside of the subsystem boundary.\n• Use connector shapes to indicate relationships between shapes in the diagram. There are five connectors available: Shows the relationship of an actor to a use case. Indicates that one use case has a dependency on another. Indicates that a use case is a specific way to achieve goals of the general use case. Shows how a use case is broken into smaller steps. Shows that one use case adds functionality to another. Example: To indicate a relationship between an actor and a use case\n• In a use case diagram, drag an Association connector shape onto the drawing page.\n• Glue one endpoint of the Association shape to a connection point on an Actor shape. Glue the other endpoint to a connection point on a Use Case shape.\n• Visio for the web saves automatically. To rename a drawing, double-click to select the default name (such as Drawing1) at the top of the drawing and then type a new name over it. For more information about use case diagrams (and procedures for using Microsoft Visual Studio to create use case diagrams), go to UML Use Case Diagrams: Guidelines."
    },
    {
        "link": "https://sparxsystems.com/resources/tutorials/uml/use-case-model.html",
        "document": "A Use Case Model describes the proposed functionality of a new system. A Use Case represents a discrete unit of interaction between a user (human or machine) and the system. This interaction is a single unit of meaningful work, such as Create Account or View Account Details.\n\nEach Use Case describes the functionality to be built in the proposed system, which can include another Use Case's functionality or extend another Use Case with its own behavior.\n• General comments and notes describing the use case.\n• Requirements - The formal functional requirements of things that a Use Case must provide to the end user, such as <ability to update order>. These correspond to the functional specifications found in structured methodologies, and form a contract that the Use Case performs some action or provides some value to the system.\n• Constraints - The formal rules and limitations a Use Case operates under, defining what can and cannot be done. These include:\n• Pre-conditions that must have already occurred or be in place before the use case is run; for example, <create order> must precede <modify order>\n• Post-conditions that must be true once the Use Case is complete; for example, <order is modified and consistent>\n• Invariants that must always be true throughout the time the Use Case operates; for example, an order must always have a customer number.\n• Scenarios – Formal, sequential descriptions of the steps taken to carry out the use case, or the flow of events that occur during a Use Case instance. These can include multiple scenarios, to cater for exceptional circumstances and alternative processing paths. These are usually created in text and correspond to a textual representation of the Sequence Diagram.\n• Scenario diagrams - Sequence diagrams to depict the workflow; similar to Scenarios but graphically portrayed.\n• Additional attributes, such as implementation phase, version number, complexity rating, stereotype and status.\n\nUse Cases are typically related to 'actors', which are human or machine entities that use or interact with the system to perform a piece of meaningful work that helps them to achieve a goal. The set of Use Cases an actor has access to defines their overall role in the system and the scope of their action.\n\nIncludes and Extends relationships between Use Cases One Use Case could include the functionality of another as part of its normal processing. Generally, it is assumed that the included Use Case is called every time the basic path is run. For example, when listing a set of customer orders to choose from before modifying a selected order, the <list orders> Use Case would be included every time the <modify order> Use Case is run. A Use Case can be included by one or more other Use Cases, so it helps to reduce duplication of functionality by factoring out common behavior into Use Cases that are re-used many times. One Use Case can extend the behavior of another, typically when exceptional circumstances are encountered. For example, if a user must get approval from some higher authority before modifying a particular type of customer order, then the <get approval> Use Case could optionally extend the regular <modify order> Use Case.\n\nSequence diagrams provide a graphical representation of object interactions over time. These typically show a user or actor, and the objects and components they interact with in the execution of a use case. One sequence diagram typically represents a single Use Case 'scenario' or flow of events. Sequence diagrams are an excellent way of documenting usage scenarios and both capturing required objects early in analysis and verifying object use later in design. The diagrams show the flow of messages from one object to another, and as such correspond to the methods and events supported by a class/object. The following example of a sequence diagram shows the user or actor on the left initiating a flow of events and messages that correspond to the Use Case scenario. The messages that pass between objects become class operations in the final model.\n\nA Use Case is a formal description of functionality that the system will have when constructed. An implementation diagram is typically associated with a Use Case to document which design elements (for example, components and classes) implement the Use Case functionality in the new system. This provides a high level of traceability for the system designer, the customer and the team that will actually build the system. The list of Use Cases that a component or class is linked to documents the minimum functionality that must be implemented by the component. The example above shows that the use case 'Login' implements the formal requirement '1.01 Log On to the website'. It also shows that the 'Business Logic' component and 'ASP Pages' component implement some or all of the 'Login' functionality. A further refinement is to show the 'Login' screen (a web page) as implementing the 'Login' use case. These implementation or realization links define the traceability from the formal requirements, through use cases on to components and screens."
    },
    {
        "link": "https://ibm.com/docs/en/dma?topic=diagrams-creating-use-case",
        "document": "You can model the required behavior of a complete system, or portions of a system, with use-case diagrams.\n\nUse-case diagrams describe the main functions of a system and identify the interactions between the system and its external environment, represented by actors. These actors can be people, organizations, machines, or other external systems. Use-case diagrams describe the main functions of a system and identify the interactions between the system and its external environment, represented by actors. These actors can be people, organizations, machines, or other external systems."
    },
    {
        "link": "https://quora.com/How-do-I-make-use-case-diagram-I-have-functional-requirements-for-my-project",
        "document": "Something went wrong. Wait a moment and try again."
    },
    {
        "link": "https://esajournals.onlinelibrary.wiley.com/doi/10.1002/eap.2500",
        "document": ""
    },
    {
        "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7384613",
        "document": "Many of the parametric animal movement models present in literature, including state space models, stochastic differential equations model, step lengths and turning angles models, and step selection function models [1–4], are geared towards inference rather than predicting realistic animal movement. Predicting animal behavior and movement is important for several reasons. Realistic predictions could aid in the formation of conservation strategies to combat the decline in bio-diversity. For example, predicting how movement patterns will be altered when a new road is built can inform decision makers on selecting the least disruptive route. Predicting movement is also important in the context of understanding the spread of infectious diseases through animal populations. Many diseases are spread through direct contact between individuals. Realistic predictions of the movement of infected individuals can suggest interventions that will optimally alleviate further spread of a disease. Machine Learning (ML) and Deep Learning (DL) methods are commonly used for predictive modelling in many fields like artificial intelligence [5], image processing [6], neuroscience [7], genomics [8] and more. However, they have seldom been used for modeling or predicting animal movement. In this study we explore the use of a range of machine learning/deep learning tools to build predictive models for individual and collective movement of ants. Several machine learning methods have also previously been used for predicting animal behavior in cheetahs [9] and penguins [10]. [11] compared the use of 5 algorithms—support vector machines, random forests, linear discriminant analysis and artificial neural networks—to predict different behavioral modes in vultures. [12] use deep neural networks to predict non-diving and diving behavior in shags, guillemots and razorbills using GPS data. They found that their method did better than hidden Markov models (HMMs) at prediction. [13] used Random Forests to study tree swallow occurrence in North America. All these studies predict animal behaviour which is framed as a binary or multi-class classification problem. In this work we develop an approach to use machine learning methods to not only predict behaviour but also actual movement trajectories. Most studies of animal movement use parametric models, with the goal of understanding how and when animals move the way the do. State space models like HMMs have been used widely for understanding animal behavior [14–16]. Step selection function models are a class of animal movement models that focus on the analysis of species-habitat associations [1, 17]. Resource selection models use a weighted distribution formulation of a point process model to model individual independent movements. These models provide insight on the animal’s preference given its environment [2, 18, 19]. Another common approach to modeling movement is a class of models based on “step lengths” and “turning angles” [3, 20]. A movement is defined by the straight line distance between two consecutive locations (step length) and the turning angle between three consecutive locations. Each step and turn is assigned to one of a number of random walks where each is characteristic of a different behavioral state. [21] used these methods to model group dynamic movement. This was based on a framework with a group level model that describes the group’s center and an individual level model that describes the individual animal’s movement relative to the group center. Multi-state random walks were used in both levels of the framework. [22] extended these models to continuous time using a joint bearing and speed process with parameters dependent on a continuous time behavioral switching process. Stochastic differential equation models are another type of animal movement model that has been used to study the interaction between animals and their habitat. [23] used a stochastic differential equation model to study the influence of roads and grassland foraging areas on elk movements. [24] used a potential surface for inference on regions of attraction and repulsion on the space-time surface that the elk are moving on. [4] used a spatially varying stochastic differential equation model to obtain insight into the spatial structure of ant movement in the ant nest. All of these parametric models make strict assumptions about the underlying processes. While making these assumptions allows for easy interpretation of results, such as associations between movement and habitat, if the modeling assumptions are imprecise, the resulting model may have poor predictive power. In this study we use machine learning methods to classify animal movement behaviour and also predict movement paths that will enable us to build stochastic movement generators. These are useful in scenarios where collecting actual movement data is laborious. It can be a useful component in simulating the spread of a disease through an animal population and can also be a useful tool in suggesting improvements to a system. Previous studies that used machine learning methods for modeling animal movement only built individual level models. In this study we look at modeling collective animal movement in addition to individual level movement. Ant colonies are self-organized complex social systems. They are a social insect species that have been used to study infectious disease dynamics [25]. We use ant colony data and our main goal is to build realistic movement simulators. This is with the eventual aim of simulating in silico ant colonies to aid in hypothesis generation and complement experimental work. As predicting ant movement is important when building simulators, we look at one step ahead predictions to gauge the accuracy of the models. We also look at 1000 steps ahead simulations to see if simulations based off of machine learning methods can capture general movement patterns exhibited in the actual data. We compare several machine learning and deep learning methods as well as a stochastic differential equation model that has been previously used in [4] to model this ant colony. In order to demonstrate the generalizability of this framework we also use it to model migratory movement of lesser black-backed gulls Larus fuscus. Here we do one step ahead predictions and simulate short migratory paths for illustrative purposes.\n\nWe use ant data from the Hughes Lab at Penn State. This data consists of the movement of 73 common black carpenter ants (Camponotus pennsylvanicus) in a custom constructed nest. The nest has four chambers, with each chamber divided into two parts by a barrier in the middle. There is a narrow passageway between the two halves of each chamber. The total nest size is 65mm by 160mm and each chamber measures 65mm by 40mm. There are doorways in between chambers that measure 6mm across, and an exit from the nest in the 4th chamber (the far right in Fig 1). For a full description of the data collection, and original goals for this data, see [26]. Fig 1. Visualization of the ant movement data colored by each unique ant identifier. Ants mostly reside in Chambers 1 and 4 and seem to have faster more directed movements through Chambers 2 and 3. The raw data consist of 2-dimensional location coordinates for each ant j at each time point i. Observations were made every second and there are 14400 observations amounting to 4 hours of movement data. Each ant has a unique identifier and a human observer recorded their position by clicking on their location using a custom software package. The velocity of movement in the x and y directions are then approximated using first differences. This dataset is unique in having location data at a very fine temporal resolution for each individual of the colony with no missing data and very little measurement error. A more detailed description of the data collection process can be found in [26] and [4]. A plot of all the data is given in Fig 1, with recorded locations of each individual ant given by a unique colour. Visually it is evident that the ants predominantly occupy chambers 1 and 4 while moving fast through Chambers 2 and 3. The data can be accessed at https://doi.org/10.5061/dryad.sh4m4s6 as supplementary material to [26]. The low density tracking data of colony 1 is used in this study. We consider supervised learning approaches to animal movement, and seek to predict future movement with characteristics of the previously observed movement behavior. We used the raw data to derive new variables that capture previous behaviour of individual ants as well as movement of neighbouring ants with the aim of informing predictions. We created 39 variables for each ant at each time step. These variables are meant to capture a wide range of potential movement behavior. A complete list of variables is given in Table 1. The motivation behind deriving these variables are threefold. First to capture previous behaviour of the individual ant. This is captured by the variables x ,y , vx ,vy , Stationary time and d . The second to capture the interaction between the ant and the structure of the nest. The variables that capture this are Sub chamber number and distance to walls in North, South, East and West directions. The rest of the variables capture the behavior of neighboring ants. The derived variables were selected by visually observing the movement of the ant colony through time as well as referencing [4]. To be concise, we will denote the vector of all derived variables at time t as u . Number of consecutive time points the ants were stationary. See Fig 2b for stationary time for ant ID 397 Sub chamber number. Each chamber is separated into two halves with the wall in the middle. Sub chambers are numbered from 1-8 from left to right. Distances from the ant’s current position to the nearest wall in the North, South, East and West directions Distance from the ant’s current position to the nearest ant (x, y) location of the nearest neighboring ant at time t−1 Velocities in the (x, y) directions of the nearest neighbouring ant at time t − 1 Number of ants in each quadrant. Quadrants 1, 2, 3 and 4 are defined as 8x8 squares around the ant as given in Fig 2a. This variable captures the density of neighboring ants in different directions around each ant. Number of neighboring ants who are still Number of ants in a 10mm radius around the ant that are still at t − 1 Number of neighboring ants who are moving Number of ants in a 12mm radius around the ant that are moving at t − 1 Distance from the ant to the queen. The queen has the ID “Que”. (a) gives a graphical description of the 4 quadrants around each ant. Each quadrant has side length 8mm. (b) gives the plot of stationary time for ant ID 397 and shows that there are long periods of no movement. For a second example system, we use 15 bird years of migratory paths of lesser black-backed gulls (Larus fuscus). This data [27] was obtained from supplemental information from [28]. These 15 paths come from 7 individual gulls over the time period 2010-2014. All paths have the same migratory strategy of wintering in the Iberian Peninsula. Fig 3 gives the paths of all 15 bird years. For each bird year, tracking data was obtained every 20-30 minutes. See [28] for more details about the data collection process. Some bird years had missing values and we used linear interpolation for imputation of missing data. Each differently colored line denotes an individual gull year. All gulls migrate southbound to the Iberian Peninsula. Looking at the Fig 3 we can see four distinct behavioral states, which we define based off of location and movement patterns: Northern range, Southbound migration, Southern range and Northbound migration. We classified each observation as being in one of these states as follows. All birds began in the Northern range state. A bird switches to the Southbound migration state when their movement track covers over 0.91 degrees Latitude in the course of a ten-hour period, and stays in that state until they do not cover at least 0.91 degrees Latitude in a Southbound direction, in which case they are then classified as being in their Southern range. Birds stay in their Southern range until their movement track covers over 1.0 degrees Latitude in a northbound direction in the course of a ten-hour period, and stay in this state until the do not cover at least 1.0 degrees Latitude in a Northbound direction. Occasionally, birds made stopovers along their migratory route. In this case, we classified birds as being in either the Northern range or Southern range state depending on whether the stopover site was closest to the farthest North or farthest South observed location of the bird that year. The result was a behavioral state for each bird at each time point in our study. In this dataset, location was given as latitude and longitude coordinates. We first converted these into UTM coordinates before carrying out our analysis. Similar to the ant dataset, we computed derived variables to capture features of the gulls movement. The derived variables are lagged locations in x and y directions, lagged velocities in x and y directions, day number (number of days since 1st of June each year), time of day (decimal number between 0 and 1) and distance travelled in the penultimate time step. Unlike the ant movement data we do not have colony level data for the gulls and therefore only aim to model individual movement of gulls in this study. Let p be the x, y locations of animal i at time t. The models used in this study can be divided into two main types.\n• None Independent Models: Each animal is independently and identically distributed: p = (x , y ) ∼ g(u ) P is the joint distribution of locations of all animals in a colony or herd at time t. g is a probability model yet to be specified. We use both types of models to generate colony simulations after model fitting for the ant movement data. In order to demonstrate the generalizability of our framework to other species we use the individual level model to simulate migratory paths for the gulls data. We do not use the colony level model since colony level data were not available, with only a small sample of birds (seven individuals) observed. When using individual movement models we model each animal using the same model. This approach assumes that one model is sufficient for modeling an individual animal and that the underlying process that determines behavior is unchanged from one animal to another. Thus, individual animal models capture population-level average behavior, while the colony level models have more flexibility in capturing behavioural patterns specific to each individual animal as well as interactions between the animals. We now present a general framework for modeling animal movement. This framework allows for state-switching, with different movement behavior in each state, and is flexible enough to allow for parametric or nonparametric approaches for movement in both the state-switching and movement behavior. On average, ants in our data are stationary 76% of the time. These ants are moving inside the nest for 22% of the time, and are outside of the nest (in a feeding arena) for 2% of the data. Positions of ants outside the nest are not recorded; video tracking of these ants was only done inside the nest. Following [4], we view these three distinct states the ant could be in (moving within the nest, stationary within the nest, and outside of the nest) as behavioral states. It has long been recognized that, when movement is observed at high temporal resolution, that animals of most species exhibit similar state switching behavior [3]. The most common approach used to model state-switching in animal movement is through hidden Markov models. Here, we consider the case where the temporal resolution is fine enough, and the measurement error on the animal locations is small enough, that it is reasonable to assume that an animal’s behavioral state is evident at each time point from the position data themselves. When this is not the case, the following framework could be used as a model for latent animal movement and state switching. We assume in general that animal i is in behavioral state m at time t, with m ∈ {1, 2, …, M}. For the ants, we follow [4] and assume that M = 3, with For the gulls we assume that M = 4, with In general, we assume that an animal’s movement behavior is different for each behavioral state. We thus propose a general framework for the analysis of animal movement data in which an observed behavioral state process {m , t = 1, 2, …, T} is modeled and predicted using a classification model, and bivariate movement {p , t = 1, 2, …, T} is modeled using a continuous-valued response model. Thus, we propose that at time t in this general framework can be expressed as follows. The state process at time t is modeled using a classification model: and, conditioned on this behavioral state, we model the animal’s discrete-time velocity v = (p − p )/δt as Here f is a vector-valued function which controls the mean movement of the animal in state k. Similar formulations have been proposed by [29], who let f be the negative gradient of a potential surface, and [4, 30], who consider functions resulting from numerical approximations to stochastic differential equation models for animal movement. The framework we propose is flexible enough to encompass most existing parametric models for animal movement, as well as nonparametric approaches. For example, f could be the prediction from a bivariate random forest [31] or neural network predictor trained on movement data, and could be the predicted probability of transitioning to state k from a neural network classification algorithm. When applying this framework to the ant movement data, we have m = 0 for a stationary ant. Since the ant does not move the discrete time velocity should be 0, i.e. f = 0 and ϵ = 0. The location of ants when they move out of the nest is not recorded. Therefore we assign their location to be (199, 0) which is the bottom right most coordinate of the nest at the opening of the nest to the feeding area. Therefore, for an ant that moves out of the nest m = 1, we adjust (x , y ) to be (199, 0). Since we now have (x , y ) and (x , y ) we can calculate the discrete time velocity to be f = (199 − x , 0 − y ) and ϵ = 0. When an ant moves within the nest, i.e. m = 2 we fit a bivariate continuous response model using all the movements that resulted in an ant moving. This is difficult to do for colony level models as we cannot dynamically alter the output dimensions based on which ants are moving and which are not. In this case, we use all movement data to model velocity and use the output of (1) to zero out velocities of ants that are classified as not moving or are outside of the nest. When m = 1 (ant has moved out of the nest) we adjust (x , y ) to be (199, 0). This is the bottom extreme right corner of the nest where the feeding area is located. We do not predict v but rather calculate v = (199 − x , 0 − y ). When using this framework to model migratory movement of gulls we express v and p as follows. We have one classification model of the form in Eq (2) and four velocity models, one for each individual state. In general, the individual level model can be formally expressed as in Eqs (2) and (3). We formally define the colony level model for N ants as follows. We denote vector valued variables in bold. We use lower case to denote individual ants and upper case to denote collective ants. P , V and M denote colony level locations, velocities and movement behaviours respectively. The colony level model for movement behaviour is of the following form The colony level model for velocity is of the following form We use F for ease of notation to demonstrate how the colony level movement behaviour and velocity models are combined. The colony level model for location is given as follows We apply the above framework to model the entire colony of ants jointly. The colony has 73 individual ants, therefore N = 73. To better understand the form of F when this framework is applied to ant colony data we illustrate the form of . The reasoning behind the form when m = 0 and m = 1 for the ant colony data is the same as under the individual level model. The relationship between the error terms and Φ when the colony level model is applied to ant movement data can be illustrated through the relationship between and . In specifying the two step model above we have used f , f , F and F as general functions. The form of these functions will vary depending on the machine learning or deep learning methods used. There were several factors that influenced our decision on the types of machine learning and deep learning methods to use in estimating f and f . For f we consider classification methods that allow for multiple classes (three classes in our case) and can be extended to the multivariate case. A univariate classifier is sufficient for modeling individual ant behaviour while a multivariate extension is needed to model colony level behaviour with the dimensionality of the classifier equal to the number of ants in the colony. Animal movement is inherently stochastic in nature and so we are interested in obtaining stochastic simulations of movement. Therefore, for estimating f we consider methods that allow for sampling a velocity from a distribution of velocities. For ease of implementation we restrict ourselves to classes of models that are capable of estimating discrete categorical responses and continuous multivariate responses. We consider random forests and neural networks as candidate methods for modeling f and f at the individual and colony level. We use univariate and multivariate random forests, as well as neural networks, to model f and f in the individual and colony level models. We here provide a description of the Random Forest algorithm, which we use as one possible machine learning approach for modeling animal movement. Classification and regression trees (CART), the building blocks of Random Forests, were developed by [32]. The CART framework consists of 4 components.\n• None A set of binary questions based on the predictors that partition the predictor space.\n• None An impurity measure. In this study for classification we use the gini index and for regression we use a measure based on the response variance.\n• None A split function: A split is made at each node that results in children nodes. A split function is used to determine the best split. This incorporates the impurity measure and determines the optimal split that results in the children nodes being the most homogeneous among competing splits. Nodes that do not have children nodes are called terminal nodes or leafs.\n• None A way of determining the tree size. In a univariate response setting with predictors x and responses y where (i = 1, …, n;j = 1, …, p), with n and p being the total number of samples and the number of predictor respectively, let us consider the data at node m to be Q. Let θ = (j, t ) be a candidate split consisting of a predictor j and a threshold t that partitions the data into subsets Q (θ) and Q (θ) defined as The impurity at node m is calculated using the impurity function H(). For a classification problem we use the Gini index defined as Where k = 1, …, K and K is the number of classes for the categorical response y . i ∈ Q represents the subset of all samples in node m. |i ∈ Q| = N . In the regression (movement) setting we use mean squared error defined as i ∈ Q and N have identical meaning as before. We calculate the splitting rule at node m by selecting the split that minimizes the impurity. n = |Q (θ)|, n = |Q (θ)|. This is repeated until the maximum allowable depth of the tree is reached [33]. Extending CART to the multivariate case with n responses y (i = 1, …, n and j = 1, …, n ) can be done simply by adjusting the impurity function H() appropriately. [33] states that this can be done by computing the average impurity across all the outputs. For the classification case this can be formally represented as Here we assume that each categorical response variable has the same categories. In our study we use multiple categorical variables to correspond to behaviours of each individual ant in the colony with each these variables taking values of 0, 1 and 2 as defined in (2). The extension to the regression setting is discussed in detail in [34]. Here a covariance weighted analog is proposed. This is equivalent to adjusting the H() as follows η represents parameters that can be used to prescribe covariance structures for e.g. (auto regressive behaviour, compound symmetry) but in this study we consider V−1(m, η) to be the identity matrix. In our study we consider the velocities of all ants in an ant colony to be the multivariate continuous responses and the data did not indicate a structure in the covariance matrix that warranted for a specific form for V−1(m, η) to be used. In the univariate case for classification, prediction results in a K dimensional vector where each element is a proportion of the cases in that leaf that fall into class k. The predicted class then is the class associated with . The multivariate analog is a natural extension where now we have a K × n matrix and the class corresponding to the maximum for each column is obtained. The resulting will be an n dimensional vector with predicted classes for each response. For the regression case prediction for each leaf is the response means of the cases reaching that leaf. For the multivariate case it is simply the vector response means of the cases. We use univariate and multivariate random forests to model f and f in the individual and colony level models. Random Forests [31] are a ensemble of CART trees. Each tree is fit using a bootstrap samples of the data. At each node,l predictors are randomly selected (l < < p) and used for node splitting. Predictions using random forests are made by majority vote of the ensemble learners for classification problems and mean of the ensemble learners for regression problems. In order to get stochastic simulations, we randomly sample a single learner from the ensemble learners and use its results for both the individual and colony level models. We use a grid search to tune these models. We used a range of values for the maximum depth of the trees, the minimum number of samples in a leaf and minimum samples needed for a split for tuning. We evaluated each model based on in sample and out of sample performance. The goal was to select a set of hyper-parameters that lead to good performance on both in sample and out of sample data in order to safeguard against overfitting. We implement Random Forests using the sklearn package [33] in Python. In the previous sub-section we described Random forests, which can be used to both predict categorical behavioural states as well as predict movement paths for animals. We now describe deep learning approaches, another popular machine learning approach which can accomplish these same tasks. Deep learning uses abstract layers of latent variables in a hierarchical structure to perform pattern matching and prediction [35]. It finds a predictor for an output Y given a high-dimensional input X. This can be represented as an input-output mapping Y = F(X). The multivariate function F is a superposition of univariate semi-affine functions. We use two types of neural networks- feed-forward neural network and recurrent neural networks. The difference between them as their names suggests is that recurrent neural networks have recurrent connections that feed previous states as inputs when computing subsequent states. We consider two types of recurrent neural networks- simple recurrent networks and Long Short Term Memory networks [36]. The latter improves on the vanishing gradient problem that is encountered in simple recurrent neural networks and has the ability to retain information for long time intervals. We use truncated Principal Component Analysis as a dimension reduction method for the colony level neural network models. To predict velocities in the x and y directions we exploit the ensemble learning property of random forests to sample velocities while we use monte carlo dropout [37] for neural networks that enable us to easily sample from the posterior predictive distribution. We embed information about previous time points in all our predictive models by including lagged velocities and locations in u . There are however, variants of neural networks that explicitly model sequence data, like time series of animal movements. Recurrent neural networks (RNN) and Long Short Term Memory (LSTM) [36] models are common deep learning methods used in applications like speech recognition [38], forecasting exchange rates [39], and text classification [40]. We explore these methods for modeling animal movement. In summary, the methods we pick enable us to In addition to the above simple recurrent neural networks and LSTM models account for the time series nature of the data. Let be the activation functions associated with the lth hidden layer. The semi-affine activation rule at the ith neuron of the lth hidden layer is given by Where w are the weights corresponding to the N inputs {z } from the (l − 1)th layer to the ith neuron of the lth layer. b denotes the offset or bias sometimes called thresholds or activation levels [35]. Popular choices for the activation function f are the sigmoid function, tanh ( ), softmax and rectified linear unit (ReLU(x) = max(0, x)). This choice is largely governed by the type of layer (hidden or output) and if it is the output, the type of task involved (classification or regression). The goal is to select optimal weights and bias based on a criterion which is often to minimize a loss function. The loss function depends on whether the type of task is classification or regression. In this study we use MLP as a possible method of approximating f . For the individual level model we can represent a two-hidden layer MLP with h hidden units in layer 1 and h hidden units in layer 2 in the following form. In this model f is the softmax function [41] and is applied element-wise on z . For the kth class the softmax function is computed as f and f can activation functions of our choosing. See [42] for a list of activation functions to choose from. In this study we restricted hidden layer activation functions to relu, tanh and elu. The parameters in the above model W , W , W , b , b and b are estimated by minimizing the categorical cross entropy, a popular loss function for multi-class classification problems. [43] specify categorical cross entropy loss as follows. Let f ((z ) ) = p , p = [p , p , p ] and . If the class of the categorical response variable corresponding to u is k, we define the one hot encoding to be e where e = 1 if i = j, otherwise 0. One hot encoding replaces a single categorical response variable with 3 binary dummy variables. The loss function is then defined as The loss is minimized using a gradient descent algorithm of our choice. See [42] for a list of optimizers and references for each optimizer. Overfitting is a concern when deciding the number of hidden neurons foe each layer. Dropout [44] is a technique that is used to alleviate this. This is achieved by removing hidden neurons with a probability p* and then see how this affects the loss function and optimization problem. See [44] for more details. In addition to the parameters we need to estimate, we also have hyper-parameters which we need to specify by tuning the model. We do a grid search of the hyper-parameter space and use out of sample performance to inform us on choosing the most appropriate values of the hyper-parameters. The hyper-parameters we considered were the number of neurons in each hidden layer, the dropout probability, the activation function of each hidden layer, the number of hidden layers, the optimizer in the tuning process and the learning rate associated with the optimizer. We used accuracy rate as the performance metric. We use the keras package [42] in Python to fit these neural network and use a grid search in the tuning process. Extension of this to the colony level model is quite straightforward. The output layer f (z ) was modified as follows When the class of the ith ant is j we define e = 1 for j = k and 0 otherwise. The loss function is modified as below and is simply the sum of the categorical cross entropy for each ant. Tuning of hyper-parameters were done similarly to that of the individual level model. Since the softmax function outputs a discrete probability distribution over the K classes for each ant we sample from a Multinomial Distribution with corresponding probabilities for each ant in order to obtain simulations. For the individual level model we will have to do this only once whereas for the colony level model we will have N such distributions. We also use MLPs to model f . For the individual level model we have a bi-variate response v and v - the velocities in the x and y directions. Our final goal is to build a stochastic movement simulator and in order to achieve this we need to be able to generate stochastic movements. We specify neural networks within a Bayesian setting that will let us sample v and v from a posterior predictive distribution. See [45] for a detailed explanation of Bayesian Neural Networks (BNN). For the individual level model we define a two layer BNN as follows. Where W , W and W are h × p,h × h and h × h matrices respectively while b , b and b are h , h and 2 dimensional vectors respectively. We specify N(0, ν) as the prior distribution for each element of the weight matrices and bias vectors. Bayesian inference can be done using MCMC [45] or more recent variational inference methods [46, 47]. These methods can be computationally prohibitive. [37] suggested dropout as a Bayesian approximation. They prove that casting dropout in training and testing phases in deep neural networks leads to approximate Bayesian inference. They call their method Monte Carlo dropout (MCdropout). Dropout should be used in the testing phase in addition to the training phase. We use the sum of the mean squared errors of the individual velocities as the loss function. The predictions generated are approximate samples from the posterior predictive distribution [35]. For more details about MCdropout see [37]. We use the keras library in Python to implement MCDropout and apply dropout at each layer in the network. Similarly to the classification models we use a grid search to tune the models. We extend this model to the colony level by including all velocities in x and y directions of all ants as the response variable. The response variable is then a 146 dimensional vector. For feed forward and recurrent neural network models for both movement behaviour and velocity at the colony level we use Principal Component Analysis (PCA) for dimension reduction. PCA has been used as a pre-processing dimension reduction method in [48] and [49]. We extract the first 1000 components which accounts for over 95% of the variability of the input variables. See Fig 4 for the cumulative variance plot. First 1000 components explain over 95% of the variance. All other aspects of implementing the colony level NN model for ant velocities were done similarly to the individual level NN model. Recurrent Neural Networks(RNN) model sequential information and its output depends on its input as well as past computations. The network thus develops a memory of its past events that are implicitly encoded into its hidden neurons. This differs from traditional feedforward networks where each set of inputs and outputs are independent of each other [50]. RNN and its variants therefore are a popular choice for time series forecasting and some applications include water resources forecasting [51] and electricity spot prices forecasting (Mirikitani and Nikolaev, 2010). We explore using standard Recurrent Neural Networks for modeling f and f . We consider a two layer recurrent neural network where the first layer is a recurrent layer and the second layer is a feed forward neural network similar to what we defined earlier. The only change for both models f and f is the form of f . This is modified in the following way for a simple RNN [38]. An important variant of RNN is long short-term memory (LSTM) [36] which has the ability to retain information for long time intervals. z is modified as follows where σ is the sigmoid activation function, i, f, o and c are the input gate, forget gate, output gate and cell activation function. All of these are dimension equal to the size of the hidden layer h . The input gate i is used to protect the memory contents from perturbation of irrelevant inputs. The output gate o is similarly used to protect other units from currently irrelevant memory contents. The forget gate was a later addition to the LSTM model [52]. This rectifies a weakness of LSTM that could only handle subsequences with explicitly marked ends and not continual input streams. As specified in section 2.4.2 we used PCA as method of reducing the dimension of the input variables. In fitting both models we consider the training set as one long time series without dividing the times series into sub-sequences. We use these models for the classification task as well as regression. Both methods have implementations in keras. We use a grid search for model tuning. We have described multiple machine learning methods, which we can use to model animal movement and behavioural states. Most current animal movement research uses parametric models, with one prominent type of model being based on stochastic differential equations. To compare machine learning approaches to parametric models, we will use the ant data and compare results from machine learning methods with a custom stochastic differential equation model developed specifically for our ant system. The stochastic differential equation (SDE) model described in this section assumes constant movement. Thus, we fit the SDE model to the subset of the training data where the ants were in motion. We classified each individual animal movement as “moved within the nest”, “stood still within the nest”, or “outside the nest”, and we used these classes to fit a multinomial regression with backward step selection on the variables in Table 1. When an individual was predicted to have “moved within the nest”, we used the SDE model to predict the next position in time. The SDE model framework [4] captures spatially-varying directional bias using a potential surface and captures spatial variation in speed without directional bias using a motility surface. This SDE model is a custom-constructed parametric model custom-constructed for this ant system. It thus provides a reasonable parametric model for comparison with the nonparametric models we propose. The SDE model is as described in [53]. The model for animal position p at time t is represented by the set of equations where v is the velocity of the animal at time t, β is the coefficient of friction which controls autocorrelation in movement, σ is a constant which we set equal to 1 to render the model identifiable, I is a 2 × 2 identity matrix, w is independent Brownian motion in , and m(p ) and h(p ) are spacially-varying motility and potential surfaces respectively, evaluated at p . The potential surface captures spatially-varying directional bias (drift) through its gradient, while the motility surface captures spatial variation in speed without directional bias by compressing and dilating time. The Euler-Maruyama method approximates (7) and (8) by Isolating v in (9) and substituting into (10) results in the autoregressive model of order 2 where and 0 is a column vector of zeroes in . Motility and potential surfaces are divided into J = 9, 998 1 × 1 mm grid cells. Motility and potential surfaces evaluated at position p have the spline representation and h and m are the potential and motility surfaces respectively, evaluated in grid cell j. We solved for the motility surface m by minimizing the penalized likelihood to estimate the variance of the residual, which is proportional to the motility. Plugging in the estimated motility surface, we minimized the penalized likelihood a second time and solved for the potential surface h . This procedure is described in further detail in [53]. Once the motility and potential surfaces were estimated, we made predictions using the autoregressive model (11).\n\nIn this study we proposed a general framework to predict and simulate animal movement. We applied this framework using various machine learning and deep learning models as well as a custom constructed parametric movement model for the ant data. We also demonstrated the generalizeability of our approch by applying this framework to the gull data at the individual level. For the ant data, we found that for one step ahead prediction the machine learning and deep learning models at the individual level did better than the SDE model. The random forest model at the individual level had the best performance for one step ahead prediction. For the gull data, the LSTM model did better than the Random Forest model when predicting one step ahead. For ant movement simulation, the SDE model seemed to do better than the other models although none of them were a clear winner. Of the machine learning and deep learning models the LSTM individual level model had the overall best performance when considering simulations. For the simulated gull migratory paths, the LSTM model seemed to better capture migratory behaviour than the random forest model. The general framework has two main steps. In the first step we predict the movement behaviour of the animal. Given the movement behaviour, we then predict the bivariate velocity. When fitting the second step for the Random Forest and Neural Network models at the individual level we only used the data where an animal made a movement to fit the velocity model. For the RNN and LSTM models this was more complex, and for the ant data, for ease we used all the data irrespective of whether the movement resulted in the ant moving or not to fit the velocity model. An alternative method would be to only consider sequences of movements that end with the animal in the state under consideration. We followed this approach when fitting the LSTM model for the gull data. This leads to the data in the training set having variable time lengths. However, this can be handled by padding the time sequences and indicating that padding has been used when specifying the model in keras. In the ant analysis, the colony level models had deteriorated performance when compared to the individual level models. Here again we used all the data to fit the velocity model. Unlike for RNN and LSTM models in the individual level there is no alternative method to only subset for when the ants are moving as at any given time some ants are stationary while others move. Here we fit two independent models for movement behaviour and velocity and then combine their outputs by zeroing out velocities if the ants are predicted to be stationary or making the appropriate velocity adjustment if the ant is predicted to move out of the nest. A possible reason for the performance of using colony level models suffering could be the low volume of data. Since we are modeling all the ants together the number of samples we have now reduces to the number of time points in the training data set for non recurrent models and to one long sample for the recurrent neural networks. The number of predictor variables increase thereby increasing the size of the network. These two factors in conjunction lead to difficulties in the colony level model. Machine Learning and deep learning methods typically need large amounts of data. We used truncated Principal Component Analysis as a dimension reduction method for the predictor variables. This method was chosen due to ease of implementation and its simplicity. Alternative dimension reduction can be used here. A drawback of using PCA is that the already difficult problem of investigating variable importance now gets more difficult since each component is a mixture of the original predictor variables. Most colonies have social hierarchies which delineate roles to each animal that in turn could affect their movement behaviour. Even within the ant colony, we typically see a queen, workers and males. It might be useful to first use clustering to separate each type of animal and then apply the framework proposed in this study so that there is greater homogeneity in the data used to fit each model. We computed variable importance for the best model for one step ahead prediction in the ant analysis which was the Random Forest model at the individual level. We did this for the gull random forest model as well. Computing variable importance for Random Forests models is a well studied problem (see [55] and [56]). Computing variable importance for neural networks is less straightforward. [57] suggested conducting a functional analysis of the weight matrix based on a technique that determines behavioral significance of hidden neurons. Another method is to consider the neural network to be a black box and use permutation importance as given in [56] to calculate variable importance. In our case we could consider the truncated PCA as part of the black box. The ease of specifying machine learning and deep learning models compared to traditional animal movement models is an important factor to consider. Most traditional parametric models are custom constructed for specific species or environments. Therefore developing a model can be time consuming. There are also various assumptions made in specifying these models which might not be accurate or realistic across various scenarios. Machine Learning and Deep Learning models are easier to specify and fit although tuning these models can often be laborious. There has been a significant improvement in the computing capability of the processing units that are used to run these models. They are also readily available for use via cloud computing [58]. This increase in computing capability has also meant that they scale well to large amounts of data. However, the model used need to depend on the goal of the study. If prediction or simulation is the goal, machine learning or deep learning methods might be easier to specify due to the black box nature of these methods and faster to fit due to advanced computing resources that are now available [58]. This comes at the cost of the models being less interpretable. Tuning a neural network can often be tedious. There are a number of tuning parameters that need to be specified. For e.g. the number of hidden layers, the number of neurons in each hidden layer, the optimizer to use, the activation function, the level of dropout, the learning rate and the number of iterations used to train the model. In addition to these there are additional tuning parameters that help in avoiding over-fitting like L1 and L2 regularization. We used a grid search to train the neural network. Another method that is gaining popularity for tuning is using genetic algorithms [59, 60]. This study introduces a novel framework for classification of movement states and predicting movement velocities. This is particularly useful when it is straightforward to identify movement behaviour states and data is available at a fine temporal resolution. This might not always be the case. If data is sparse in time and states are not easily identifiable you will need to identify states before the analysis as we did in the gull analysis. Some degree of pre-processing could be used for this. There are existing frameworks like [61] that are useful for going from sparse data to fine-resolution markov chains. Reinforcement learning is a field of artificial intelligence that has been used for problems like modeling self driving cars [62, 63]. It will be interesting to see if formulating the simulation problem through this paradigm would give better performance. We present a general framework for modeling animal movement that consists of two steps. The first step models movement behaviour and the second step models velocity of the animal given the movement behaviour. We used a suite of machine learning and deep learning to fit individual and colony level models. We use ant movement data and compare performance against stochastic differential equation model that uses multinomial regression to model movement behaviour. Random Forests and Neural Networks at the individual level perform better than the SDE model for one-step ahead predictions while the SDE model does better in capturing movement features in long range simulations. The LSTM individual level model has the best performance out of the machine learning and deep learning models for long range simulations of ant colonies. In order to demonstrate the utility of the framework generally, we also applied the Random Forest and LSTM models to gull movement data at the individual level and found that the LSTM model had better performance for one step ahead predictions as well as better visual simulated paths. Machine Learning and Deep Learning have been sparingly used to model movement behaviour or predicting locations. This work provides a unified approach of combining both aspects within a general framework."
    },
    {
        "link": "https://researchgate.net/publication/281993250_Population_dynamics_forecasting_using_artificial_neural_networks",
        "document": "This study is about using ar\n\ntificial neural networks and regression tech nique are com-\n\npared to those obtained by growt h rate of the fishes caught\n\nfrom the natural ecology and von Be rtalanffy growth\n\nmodel. It is shown that artif\n\nPopulation growth is the change in a population over\n\ntime, and can be quantified as the chan ge in the number of\n\nindividuals of any species in a population using \"per unit\n\nFish are renowned for their extreme plasticity in indi-\n\nvidual growth [1]. One aspect of this plasticity is the de-\n\npendence of growth on population density, which is well-\n\ndocumented in wild populations [2] and in extensive aqua-\n\nculture [3]. Growth, one of the most essential traits for an-\n\nimals, is defined as an increase in tissues a nd organs of the\n\nanimals per unit time, and effe cted by genetic and environ-\n\nThe growth that has sigm oid form is explained reliably\n\ntalanffy models. Information about parameters of these non-\n\nA lot of work was done in predicting the future, and\n\nANNs showed even better results with regard to the tradi-\n\nPrevious findings indicated that the neural netwo rk\n\nmodels are significantly better than traditional statistical\n\nand quarterly data [11], especially when based on the ab-\n\nIn recent years, ANNs have become a popular and use-\n\nple, they have already been successfully used to simulate\n\nthe export of nutrients from\n\nsalinity [14] or ozone levels [15], an d the functional char-\n\nANNs have been widely used for both predi ction and\n\nclassification tasks in many fields of knowledge. However,\n\nonly few studies are available on animal science. Very little\n\nresearch has been conducted to model animal growth using\n\nof rats with traditional regre ssion and neural networks.\n\nThey found that both methods produced m odels that ade-\n\nIn this study, an ecological\n\nFish were taken each month; their growth potential in the\n\nlong-term growth fo recast of fish has been studied. Von\n\nniques were used to predict w hich method gives better re -\n\ncan also be defined as a specific type of parallel processi ng\n\nsystem, based on distributional or c onnectionist methods\n\n[19]. ANNs are used to predic t the future, one of the key\n\nareas. ANN data can reveal the power relations between\n\nthe unknown and unnoticed. ANNs are no t linear. Linear\n\nmodels can understand the important details, and can be\n\nbeneficial if they could explain. The structure of a network\n\nof this type is characterized\n\nelements (neurons) that learn by modifying them selves. As\n\nin nature, the function of the network is determined by the\n\nthe linear models when weekly data are used; if monthly"
    },
    {
        "link": "https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/eap.2500",
        "document": ""
    },
    {
        "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10681852",
        "document": "Predictive models can improve the efficiency of wildlife management by guiding actions at the local, landscape and regional scales. In recent decades, a vast range of modelling techniques have been developed to predict species distributions and patterns of population spread. However, data limitations often constrain the precision and biological realism of models, which make them less useful for supporting decision‐making. Complex models can also be challenging to evaluate, and the results are often difficult to interpret for wildlife management practitioners. There is therefore a need to develop techniques that are appropriately robust, but also accessible to a range of end users. We developed a hybrid species distribution model that utilises commonly available presence‐only distribution data and minimal demographic information to predict the spread of roe deer (Capreolus caprelous) in Great Britain. We take a novel approach to representing the environment in the model by constraining the size of habitat patches to the home‐range area of an individual. Population dynamics are then simplified to a set of generic rules describing patch occupancy. The model is constructed and evaluated using data from a populated region (England and Scotland) and applied to predict regional‐scale patterns of spread in a novel region (Wales). It is used to forecast the relative timing of colonisation events and identify important areas for targeted surveillance and management. The study demonstrates the utility of presence‐only data for predicting the spread of animal species and describes a method of reducing model complexity while retaining important environmental detail and biological realism. Our modelling approach provides a much‐needed opportunity for users without specialist expertise in computer coding to leverage limited data and make robust, easily interpretable predictions of spread to inform proactive population management.\n\nUnderstanding how characteristics of the environment influence species distributions is a fundamental aim of spatial ecology (Elith & Leathwick, 2009; Skidmore et al., 2011). Many terrestrial animal populations have altered their geographic ranges in response to human activities (e.g. habitat modification, Wilson, Davies, et al., 2009; Wilson, Dormontt, et al., 2009) and anthropogenic climate change (e.g. Dawe & Boutin, 2016). Shifts in animal distributions lead to novel biotic and abiotic interactions that may affect ecosystem health and functioning (Pacifici et al., 2020; Pessarrodona et al., 2019). Forecasting changes in species distributions and predicting the relative timing of colonisation events is therefore essential for effective conservation planning (Aben et al., 2016; Battini et al., 2019; Fordham et al., 2013). Reliable predictions can be used to distribute resources for surveillance and management efficiently to vulnerable habitats and landscape features that benefit expansion (e.g. habitat corridors, Akashi et al., 2016; Bottrill et al., 2008; Tilman et al., 2017). Species–environment relationships are commonly investigated using correlative species distribution models, which empirically relate species distributions to environmental variables, such as precipitation or land use (Elith & Leathwick, 2009). For range‐expanding species, correlative models can provide robust predictions of the spatial distribution of suitable habitats in novel areas (Elith et al., 2010; Lake et al., 2020). However, the probability and timing of population spread are likely to be influenced by a range of other factors, such as demography, physiology, dispersal and species interactions (Dormann et al., 2012). Mechanistic models can be used to simulate these underlying ecological processes and investigate the functional relationships between them and species distributions (Kearney & Porter, 2009; McLane et al., 2011; Wallentin, 2017). Combining correlative and mechanistic models (i.e. as in ‘coupled’ or ‘hybrid’ models, ‘hybrid’ models hereafter) improves the realism of predictions and offers a powerful tool for predicting changes in distribution over time (Buckley et al., 2010; Dormann et al., 2012; Fordham et al., 2013). Hybrid models can be implemented using a range of tools, such as MigClim (Engler et al., 2012), KISSMig (Nobis & Normand, 2014) and demoniche (Nenzén et al., 2012). Typically, the output from a correlative model (e.g. a raster map) is used to represent the environment in simulations of population dynamics and dispersal. This allows key parameters of simulations (e.g. local carrying capacity) to be constrained by features of the modelled environment (e.g. habitat suitability, Dormann et al., 2012; Singer et al., 2018). Environmental representation and model structure are important factors that influence the realism, data requirements and complexity of hybrid models. Simulations are often based on the representation of species as automata that populate a raster grid of regular cells (‘grid‐based’ models hereafter, Keshtkar & Voigt, 2016; Louca et al., 2015). Grid‐based models are conceptually simple, generally require minimal data to parameterise and are computationally efficient to implement (Bian, 2003; McLane et al., 2011). Although logistically convenient, they are usually best suited to modelling plant species (Aben et al., 2016; Bian, 2007; Vuilleumier & Metzger, 2006). The fixed cell size of the raster grid implies that ecological processes, such as survival, reproduction, emigration and dispersal, occur at the same scale, which is unrealistic for most animal species (Bocedi, Zurell, et al., 2014; Vuilleumier & Metzger, 2006; Wallentin, 2017). Representing the environment as continuous space is also unsuitable for species that show a preference for discrete habitat features (e.g. woodlands, Bian, 2003; McLane et al., 2011). Alternatively, landscapes may be represented as a network of patches (‘patch‐based’ models hereafter). Generalising the continuous raster grid produced by a correlative model into a landscape of patches typically requires the application of a suitability threshold. Neighbouring cells with suitability values at or above this threshold are then aggregated to delineate discrete patches of suitable habitat embedded in a matrix of less hospitable environments (Berec, 2002; Bian, 2003). Patch‐based models therefore offer a more realistic representation of the environment as the units of the landscape (patches) reflect the geometry, distribution and composition of natural features (Holland et al., 2007; Vuilleumier & Metzger, 2006). Patches also facilitate modelling at multiple spatial scales. For example, fine‐scale movement between patches during dispersal may be simulated as a correlated random walk (e.g. Bocedi, Zurell, et al., 2014) using high‐resolution raster maps. Population dynamics may be simulated at the local scale of the patch and patterns of population spread emerge at the landscape or regional scale (Austin & Van Niel, 2011; Bocedi, Palmer, et al., 2014; Wallentin, 2017). However, the requirements of modelling population dynamics can affect how patch‐based landscapes are represented, as patches typically need to be large enough to accommodate multiple individuals (Berec, 2002; Cavanaugh et al., 2014). Applying a size threshold eliminates patches that are unable to sustain a sub‐population, but these may form a network of suitable habitats that contributes to the viability and spread of the total population (Fahrig, 2020; Tulloch, Barnes, et al., 2016). Therefore, inaccurate representation of the environment at the landscape scale can affect model predictions at the broader regional scale (Bian, 2007; Bocedi et al., 2012). Currently, there are limited tools available to implement conceptually simple hybrid models (e.g. KISSMig, Nobis & Normand, 2014) that utilise patch‐based environments. Parameterising hybrid models and achieving a balance between complexity and biological realism can also be challenging. Estimating patterns of colonisation and extinction through explicit simulation of population dynamics typically requires detailed demographic information, such as survival rates, fecundity, carrying capacity, emigration rates and sex ratios, which are unavailable for many species (Dormann et al., 2012; Kearney & Porter, 2009; Thuiller et al., 2013). Interpreting such complex models presents a further challenge for wildlife managers as they generally cannot be evaluated using conventional statistical methods (O'Sullivan et al., 2016; Wallentin, 2017). For practical applications, there is a need for less data‐intensive models that are biologically realistic but also simple enough to be interpreted and used effectively (Addison et al., 2013; Tulloch, Sutcliffe, et al., 2016). The expansion of the roe deer (Capreolus capreolus) population in Wales, UK provides a good example of a wildlife management scenario that can be informed by predictive modelling. Although native to Britain, the numbers and geographic range of roe deer have expanded rapidly over recent decades due to reduced persecution, afforestation and the absence of natural predators (Apollonio et al., 2010; Linnell et al., 2020; Ward, 2005). While expansion may be seen as a conservation success, the potential effects of roe deer on sensitive habitats (e.g. ancient woodland) are a cause for concern (Gill & Morgan, 2010; Linnell et al., 2020). Browsing by roe deer has been shown to impede tree growth (Bergquist et al., 2009; Kay, 1993) and natural regeneration (Cutini et al., 2011; Petersson et al., 2019), reduce ground flora biodiversity (Kirkby, 2001) and quality of woodland habitat for bird species (Gill & Fuller, 2007) as well as cause damage to agricultural crops (Kjøstvedt et al., 1998; Putman, 1986). Roe deer are abundant throughout most of England and Scotland and are beginning to recolonize parts of Wales (Croft et al., 2019; Ward, 2005). Predictions of population spread in Wales are needed to guide surveillance and inform proactive mitigation efforts. We aim to address this need by developing a hybrid species distribution model that can be parameterised and evaluated using data commonly available to wildlife management practitioners. We demonstrate our approach using opportunistically collected presence‐only distribution data for roe deer in mainland Great Britain. Records of species occurrences in a populated region (England and Scotland) are used to produce a habitat suitability map from a correlative species distribution model. This map is then generalised to represent the environment in a hybrid model as a landscape of small patches, based on the home‐range area of an individual (an ‘individual‐sized patch’). Basic demographic and dispersal information are used in simulations to predict regional‐scale patterns of population spread as a function of the size, quality and connectivity of individual‐sized patches. The hybrid model is first evaluated using observations of historical distribution change in England and Scotland and then applied to predict the population spread of roe deer in a novel region, Wales. To be an effective tool for management, it was important that our model outputs were easily interpretable by practitioners and produced at a fine enough spatial resolution to identify potentially vulnerable landscape features (e.g. individual woodlands). Achieving temporal accuracy was considered less critical, as predicting the relative timing of colonisation events (e.g. region X is likely to be colonised before region Y) would be sufficient to set management priorities (e.g. targeted surveillance in region X). The objectives were to (1) evaluate the efficacy of representing the environment as a landscape of individual‐sized patches to predict patterns of population spread, (2) test different methods of generalising a habitat suitability map into individual‐sized patches, (3) predict the suitability of habitat and potential future range of the roe deer population in Wales and (4) predict the relative timing of colonisation events for roe deer in Wales, assuming the population realises its potential range.\n\nThe study area covered mainland Great Britain (218,819 km2), divided into two regions: England and Scotland (198,569 km2), where roe deer populations are well established and Wales (20,250 km2), where numbers are much lower (Figure 1). Evaluation of the hybrid models was achieved using occurrence data from an area within the England and Scotland region where the expansion of roe deer has been observed from 1960 to 2016, defined as the historic area of expansion (HAE, 60,349 km2, Figure 1). Map of the study area (mainland Great Britain) showing the boundaries of the two regions defined for the analyses and the historic area of expansion (HAE) within the England and Scotland region that was used for evaluation of the hybrid models. Our method consisted of five steps: (Step 1) habitat suitability was estimated from a populated region (England and Scotland) using a correlative species distribution model, (Step 2) the resultant habitat suitability map (HSM) was generalised into a landscape of individual‐sized patches to represent the environment in a hybrid model, (Step 3) demographic parameters were simplified to simulate patch occupancy for multiple time steps, (Step 4) model evaluation was performed using historic distribution data and (Step 5) the model was applied to a novel region (Wales). Predictions of population spread were based on simulations made using a mechanistic modelling platform, RangeShifter (Bocedi, Palmer, et al., 2014). RangeShifter was chosen because it is versatile, freely available and does not require any expertise in computer coding to parameterise. Furthermore, it is possible in RangeShifter to incorporate environmental information using multiple independent layers that describe: patch geometry and distribution, patch quality/composition and landscape‐associated costs of moving between patches (Bocedi, Palmer, et al., 2014). In our approach, these layers were derived from the correlative model, as described in the following sections. Habitat suitability was estimated using a Maximum Entropy (MaxEnt) model implemented with the ‘dismo’ package (Hijmans et al., 2017) in R (R Core Development Team, 2019). The model was trained and tested with environmental and roe deer occurrence data from the populated England and Scotland regions (MaxEnt version 3.4.0; Phillips et al., 2017). Data on roe deer sightings were taken for the period 1953–2016 from the National Biodiversity Network Gateway (www.nbnatlas.org) and regional wildlife trusts in Wales (Appendix S1) during December 2016. These were characteristic of presence‐only data as they were collected from a range of sources (e.g. the general public) and the sampling effort was indeterminable. Only occurrence records with a locational precision of 100 m were considered for analysis (England and Scotland, n = 3843). The records from Wales (n = 37) were used for the evaluation of model performance in the Wales region only. Environmental data were obtained for variables relating to land cover (UK Centre for Ecology and Hydrology's Land Cover Map 2015; www.ceh.ac.uk/services/land‐cover‐map‐2015, 25 m resolution), roads (Ordnance Survey (OS) Meridian™ 2; www.ordnancesurvey.co.uk, 10 m resolution), terrain (OS Terrain 50, 50 m resolution) and climate (Worldclim version 1; http://www.worldclim.org/, 1 km resolution). Environmental data were resampled to 100 m cell rasters to predict habitat suitability at a fine resolution, which was necessary for delineating irregularly shaped individual‐sized patches in the subsequent hybrid model (Appendix S1). The final model included six variables that were selected from a candidate list of 33 variables through a stepwise process of a priori selection, collinearity analysis and complexity optimisation (Appendix S1). These comprised three distance metrics: distance to nearest woodland (woodland distance), non‐woodland forage (forage distance) and urban areas (urban distance) as well as two variables based on the proportion of land cover within a 500 m radius (woodland cover and forage cover) and a categorical variable for land cover type (land cover, Appendix S1). Roe deer are known to occasionally occupy small green spaces in predominantly urban areas (Ciach & Fröhlich, 2019). Therefore, we used both categorical and proportional variables to include land cover information at the location where the species was recorded as well as the proportion of land cover within the local vicinity. A fishnet grid of 10 × 10 km cells was created for each region. Background points for the development and validation of the MaxEnt model were only created within cells that intersected presence locations (England and Scotland; n = 908, Wales; n = 32, Appendix S1). The MaxEnt default of 10,000 background points was used for Wales (3.4 points/km2) and 100,000 points were used for England and Scotland (1.2 points/km2). Linear, quadratic, hinge and product feature classes were used as well as the default value of 1.0 for the regularisation multiplier (Appendix S1). An n−1 cross‐validation technique was used to validate the MaxEnt model and to compare predictive performance between the populated and novel regions. The n−1 method trains a model on all data points (England and Scotland: n = 3843; Wales: n = 37) but one, then evaluates the model on that point and repeats until all points have been evaluated (Cawley & Talbot, 2003; Hijmans, 2012). Model performance was estimated based on the ability to correctly rank presences in the test data set higher than background points, as given by the mean area under the receiver‐operating‐characteristic curve (AUC). The AUC is a standard measure of goodness of fit that yields a value between 0.5 and 1, where 0.5 suggests the model performs no better than random and 1 indicates perfect prediction (Pearce & Ferrier, 2000). Values above 0.7 are generally considered an indication of good model fit (Hijmans, 2012). The use of the AUC metric to evaluate the performance of correlative models has been criticised (Jiménez‐Valverde, 2012; Lobo et al., 2008). However, we feel that its use in this study was appropriate as it facilitated a direct comparison of performance with previous studies (Acevedo et al., 2010; Croft et al., 2017, 2019) that were carried out for the same species and over the same spatial extent. Variable importance was assessed using a jackknife test, which measured the increase in regularised training gain when each variable was used in isolation and the decrease in gain when the variable was excluded from the full model (Phillips & Dudík, 2008). The relative contribution of each variable to the model was also estimated based on permutation importance, which is one of the metrics reported in the MaxEnt model output (Hijmans et al., 2017; Phillips & Dudík, 2008). There is currently no consensus on the most effective method of delineating patches from a habitat suitability map (HSM). We therefore evaluated four methods: (1) Grid, (2) Voronoi, (3) Contiguity and (4) Voronoi‐Contiguity (Vor‐Con) within the Historic Area of Expansion (HAE, Figure 1). The same key steps were used in each method: definition of patch boundaries (P), summarisation of the cell values within patches (S) and the application of a suitability threshold to eliminate patches or cells considered unsuitable (T, Figure 2). Applying a suitability threshold is required to convert cells of the HSM from continuous (i.e. low to high suitability) to binary (i.e. suitable/not suitable) values for patch delineation. A value of 0.56 was chosen as it maximised the sum of sensitivity and specificity in the MaxEnt model (Liu et al., 2005, 2016). The home range area of roe deer was assumed to be 0.06–1.5 km2 with an approximate average of 1 km2 (Coulon et al., 2008; Le Corre et al., 2008; Martin et al., 2018). Roe deer are generally solitary, males are territorial and both sexes demonstrate high home‐range fidelity (José & Lovari, 2010; Linnell & Andersen, 1998; Lovari et al., 2017). We therefore chose to delineate patches based on the home range area because it is biologically meaningful and appropriate for identifying relevant landscape features for management (e.g. individual woodlands). Stages of habitat suitability map (HSM) generalisation. Rows represent four generalisation methods used: Grid, Voronoi, Contiguity and Voronoi‐Contiguity (Vor‐Con). Columns denote stages in the generalisation process (see text for details). Common to all methods are stages (1) the original HSM, (5) the mean suitability of patches and (6) unique identifiers assigned to each patch. Key characteristics of the generalised map include (P) the definition of patch boundaries, (S) the summarisation of cell values within patches (i.e. calculating mean suitability) and (T) application of a suitability threshold to convert the HSM from continuous (i.e. low to high) to binary (i.e. suitable/not suitable) values. These characteristics may be defined at different developmental stages depending on the generalisation method used. Grey panels indicate the absence of a stage and are included for a more intuitive comparison of results at similar developmental stages across the four methods. Row Vor‐Con, column 3: red patches were divided using Voronoi polygons and green patches were unmodified. The Grid method effectively resampled the HSM at a coarser resolution. A fishnet grid of 1 km2 cells was created for the extent of the HSM and the mean value of HSM cells within grid cells was calculated. Grid cells with a mean suitability below the threshold were removed (Figure 2, row Grid). The Voronoi method used polygons to define patch boundaries, which were irregular polygons based on Voronoi tessellations (Holland et al., 2007). Point features were distributed across the extent of the HSM at an approximate density of 1 point/km2 (n = 60,350). Studies have shown that roe deer home ranges generally decrease with increasing population density and habitat quality (Kjellander et al., 2004; Saïd et al., 2009). To reflect this, points were distributed according to the probability distribution described by the HSM, which biased their location towards more suitable habitat (‘Create Spatially Balanced Points’ tool in ArcGIS, ESRI ArcMap Version 10.4.1). Therefore, point‐density increased and patch‐size decreased in relation to habitat suitability. A minimum distance of 150 m between points was used, which equalled the approximate radius of the lower limit of the home‐range area (0.06 km2). Voronoi polygons were created to define the geometry of patches (‘Create Thiessen Polygons’ tool in ArcGIS, ESRI ArcMap Version 10.4.1). Polygons were converted from a vector to a raster and then back to a vector to ensure patch boundaries aligned with cells of the HSM. The mean value of cells within patches was calculated and patches with a mean suitability below the threshold were removed (Figure 2, row Voronoi). HSM cells with suitability values below the threshold were removed. Suitable cells that neighboured other suitable cells in any of the eight cardinal directions were considered part of the same patch (Figure 2, panel c). Patches smaller than the lower limit of the home‐range area (0.06 km2) were removed and the mean value of cells within the remaining patches was calculated (Figure 2, row Contiguity). This method produced patches that were larger than the upper limit of the home‐range area (1.5 km2). It was presented to demonstrate the importance of patch size in the case study and to illustrate the conceptual basis of the Vor‐Con method. The Vor‐Con method included stages of both the Voronoi and Contiguity methods. Patches were created using the Contiguity method and grouped into the following classes based on the observed limits of the home‐range area: small (<0.06 km2), medium (0.06–1 km2) and large (>1 km2). Small patches were removed and medium patches were not modified. Large patches were divided into smaller patches using Voronoi polygons following the same procedure as the Voronoi method. Point features were created at an approximate density of 1 point per km2 (n = 11,146). The points were distributed according to the probability distribution described by the HSM, using only the cells within the boundaries of large patches. Voronoi polygons were created and converted from a vector to a raster and then back to a vector to ensure patch boundaries aligned with cells of the HSM. The mean value of cells within patches was calculated (Figure 2, row Vor‐Con). Suitability values in the generalised maps (Figure 2, column 5) were scaled by multiplying by 100 and rounding to integers as a formatting requirement of the RangeShifter software. Patches were also assigned a unique identification number (Figure 2, column 6). The RangeShifter platform was designed to use extensive demographic information (survival rates, fecundity, maximum age, etc.) to simulate range expansions as a function of stochastic interactions between individuals and the environment (Bocedi, Palmer, et al., 2014). However, in this study, we simplified the modelling of population dynamics in RangeShifter to reduce data requirements. Demographic parameters were standardised and constrained by density dependence acting at the patch level so that emigration and immigration rates were dependent on patch size and quality. Regional‐scale patterns of population spread therefore emerged solely as a function of the size, quality and connectivity of individual‐sized patches. The hybrid model was structured as follows: (i) occupied patches produced a number of dispersers proportional to patch size and quality, (ii) dispersers interacted with the landscape to transfer between patches and (iii) dispersers settled in patches occupied below carrying capacity. This was implemented in RangeShifter as an asexual stage‐structured population model based on a Leslie transition matrix (Bocedi, Palmer, et al., 2014). Three stage classes were considered: juveniles (<1 year old), dispersers (1 year old) and adults (≥2 years old). All surviving individuals develop to the next stage class and only adults are able to reproduce. The following transition matrix (derived from Bocedi, Palmer, et al., 2014) was applied: where fecundity and the survival probabilities of juveniles , disperses and adults were set to a standardised value of 1. The maximum age of adults was set to 1000, so that occupied patches were likely to remain occupied throughout the simulation (i.e. the probability of local population extinction was close to 0). Density dependence acted on survival and fecundity and was implemented in RangeShifter as an exponential decay: where is a parameter for survival or fecundity, is the maximum value of the parameter at low densities, b is the strength of density dependence and is the total number of individuals in the local population at time t (derived from Bocedi, Palmer, et al., 2014, RangeShifter user manual). The strength of density dependence coefficient, 1/b, was also set to a standardised value of 1.0. Habitat suitability was assumed to be constant during the simulation period and linearly related to carrying capacity. Using standardised parameter values (Table 1) and incorporating density dependence in the hybrid model established a relatively simple set of rules for determining patch occupancy. The model assumes that over time more dispersers are likely to emerge from, and settle in, larger, more suitable patches than smaller, less suitable patches. Summary of parameters used in the RangeShifter (Bocedi, Palmer, et al., 2014) model. Dispersal between patches was modelled as three discrete phases of emigration, transfer and settlement. All juveniles that survived and developed into dispersers, emigrated from their natal patch. Movement during the transfer phase was modelled at the finer scale (0.01 km2) of the scaled HSM using the embedded Stochastic Movement Simulator (SMS). The SMS simulated movement as a series of discrete nearest‐neighbour steps across a cost surface, similar to the Least Cost Path (Bocedi, Palmer, et al., 2014; Palmer et al., 2011). The cost surface was derived by inverting the scaled HSM using the formula: 100 – values of the scaled HSM (‘Raster calculator’ tool in ArcGIS, ESRI ArcMap Version 10.4.1), which assumed movement costs were inversely related to habitat suitability. Dispersers would therefore be less likely to move through low‐quality habitat. The transfer phase was influenced by parameters describing the maximum number of steps, the perceptual range (PR) of the species and their tendency to follow a correlated random walk, defined as directional persistence (DP, Table 1). The perceptual range was estimated to be 400 m from habitat selection studies based on global positioning system (GPS) telemetry data (Coulon et al., 2008). A value of five was used for directional persistence simulating a moderate tendency for the animal to follow correlated paths within the landscape. Dispersers could move a maximum of 200 steps which equates to a Euclidean distance of 20 km (Debeffe et al., 2013; Wahlström & Liberg, 1995). Distribution data from 1960 to 2016 within the HAE (Figure 3) were divided into five 10‐year periods (1960–2009) and one 7‐year period (2010–2016), described as Observed Timesteps (ObsTS1‐ObsTS6). Simulations were initialized with the species occupying patches within a 10 km radius buffer around the centre of the observed range at ObsTS1 (Figure 3; see Appendix S2 for initialization parameters). A total of 10 simulations were run for a sufficient time to achieve complete occupation of all available patches, which was estimated from preliminary trials. In each simulation, patch occupancy (1 = occupied, 0 = not occupied) was estimated at six regular time intervals, defined as Simulated Timesteps (SimTS1‐SimTS6). Mean patch occupancy at each SimTS was calculated as the mean occupancy from the 10 simulations. A threshold value for mean patch occupancy of 0.7 was applied (i.e. patches predicted to be occupied in 7 out of 10 simulations were considered occupied). Application of a threshold was necessary to convert mean patch occupancy from continuous (i.e. 0 to 1) to binary (i.e. 0 = not occupied, 1 = occupied) values. Cells of the 10 × 10 km grid that intersected occupied patches defined the simulated species range at each SimTS. Patterns of observed roe deer (Capreolus capreolus) range expansion in the historic area of expansion (HAE) across six timesteps (ObsTS) from 1960 to 2016 used to evaluate the hybrid models, described as (a) ObsRange: the observed range estimated from minimum convex polygons created around presences and (b) ObsPresences: presence locations within the observed range. Inset: location of the HAE in Great Britain. Performance of the hybrid models was assessed based on the ability to recreate observed patterns of historic population spread. A 10 × 10 km grid of regular cells was created for the HAE, which defined the regional scale of model evaluation. Minimum convex polygons (Meyer et al., 2017) were constructed around presences at each timestep in ArcGIS (ESRI ArcMap Version 10.4.1). Grid cells that intersected polygons were used to define the observed species range (ObsRange, Figure 3a). Although convenient, this method is prone to overestimating the species range by including areas of unsuitable habitat (Burgman & Fox, 2003). We therefore also identified presence locations within the observed range for a more comprehensive evaluation of model performance. Grid cells within the species range at each timestep that intersected presences were defined as ‘ObsPresences’ (Figure 3b). Model performance was assessed by comparing the simulated species range to ObsRange and ObsPresences at matching timesteps (e.g. SimTS1/ObsTS1) and calculating the True Skill Statistic (TSS, Allouche et al., 2006), which is the sum of model sensitivity (the proportion of predicted presences that were correct), and specificity (the proportion of predicted absences that were correct), minus one. The TSS ranges from −1 to 1, and good predictive performance is indicated by values >0.4 (Allouche et al., 2006; Eskildsen et al., 2013; Landis & Koch, 1977). Overall model performance was based on the mean of the TSS values from the six timesteps for ObsRange and ObsPresences. Finally, a sensitivity analysis was performed to assess the impact of the three user‐defined parameters (perceptual range, directional persistence and maximum number of steps, varied by ±10%) on the simulated species ranges. 2.2.5. Step 5. Applying the model to a novel region Estimates of habitat suitability in Wales were projected from the England and Scotland region using the same set of environmental variables. All values for environmental variables in the Wales region were within the limits of the England and Scotland regions. The projected HSM for Wales was generalised into a landscape of individual‐sized patches using the Vor‐Con method. It was also inverted to be used as a cost surface in the hybrid model using the formula described above (see ‘Dispersal’ section of Step 3). A 10 × 10 km grid was created for Wales. The hybrid model was parameterised with the same parameter set used for the populated region and initialised with the species occupying patches within grid cells that intersected observations of species presence (Appendix S2). Patch occupancy was estimated at 10 simulated timesteps (SimTS1‐SimTS10).\n\nWe developed a hybrid species distribution model to predict regional‐scale patterns of population spread for an animal species from limited distribution and demographic data. A correlative, MaxEnt model (Phillips et al., 2017) was constructed using presence‐only occurrence data for roe deer in mainland Great Britain. The model estimated the suitability of habitat from a populated region (England and Scotland) and predicted the potential future range of the population in a novel region (Wales). The habitat suitability map was then generalised into a landscape of individual‐sized patches using a range of methods and used to represent the environment in a hybrid model to make dynamic predictions of population spread. The hybrid model was evaluated against historical species distribution changes and applied to predict the spatial patterns and relative timing of colonisation events of roe deer in Wales. The results from the n−1 cross‐validation showed that the MaxEnt model performed well in both the populated and novel regions. The area under the receiver operating curve (AUC) values attained in this study are similar to those reported from previous studies of roe deer in the UK by Acevedo et al. (2010) (0.85), Croft et al. (2017) (0.64) and Croft et al. (2019) (0.9). Furthermore, our correlative model was validated to a spatial resolution (0.01 km2) that is a 100 times finer than that used by Croft et al. (2017) (1 km2) and 10,000 times finer than Acevedo et al. (2010) and Croft et al. (2019) (100 km2). The high resolution of the output was critical to subsequent modelling stages, as it allowed the suitability map to be generalised into a landscape of patches based on the home range area of an individual roe deer. This captured structural details of the landscape, such as the size, distribution and geometry of habitat patches, that are important in shaping patterns of population spread (Wilson et al., 2010; Wilson, Davies, et al., 2009; Wilson, Dormontt, et al., 2009). Estimating habitat suitability also provided insights into the species‐environment relationship that was essential in characterising the environment for the roe deer, a generalist species, whose distribution is known to be influenced by a range of habitat types (Croft et al., 2019; Jepsen & Topping, 2004; Kilheffer & Underwood, 2018). We evaluated the hybrid models and tested four methods of generalising the habitat suitability map from the MaxEnt model using historic distribution data. The approach is similar to Singer et al. (2018) but uses presence‐only rather than presence/absence data, which was simple to implement and relatively straightforward to interpret. The Grid and Voronoi methods performed well and achieved a high level of spatial agreement between simulated and observed ranges. In both methods, patch geometry was pre‐defined, as in traditional grid‐based models (Bian, 2003; McLane et al., 2011). For the Contiguity and Vor‐Con methods, a suitability threshold was applied to the HSM as the first step, which retained the natural geometry of landscape features (Girvetz & Greco, 2007). The model based on the Vor‐Con method achieved the best performance of the four methods, whereas the model based on the Contiguity method showed the worst performance. As the only technique that did not constrain patches to the size of an individual home range, the poor performance of the Contiguity method is likely due to a phenomenon known as the ‘mega patch problem’ (Cavanaugh et al., 2014). This issue arises because, when a patch is occupied, individuals within that patch are effectively omnipresent and so instantaneously traverse the length of the patch, which can result in an overestimation of spread through larger patches. This issue was resolved in the Vor‐Con method by the division of large patches using Voronoi polygons. Although a variety of patch‐delineation models are available (e.g. Cavanaugh et al., 2014; Girvetz & Greco, 2007; Kilheffer & Underwood, 2018), the methods used in this study were selected to minimise model complexity and improve the accessibility of the model to wildlife management practitioners (Addison et al., 2013; Guisan et al., 2013; Tulloch, Sutcliffe, et al., 2016). Our modelling approach reduced the demand for demographic data usually associated with parameterising a hybrid model by simplifying the simulation of population dynamics. Using generic rules to describe population dynamics is conceptually similar to a stochastic patch occupancy or traditional grid‐based model (Bian, 2003; Hanski & Ovaskainen, 2003; Preisler et al., 2004). The key strength of our approach is in the more sophisticated modelling of dispersal, which was facilitated by the RangeShifter platform (Bocedi, Palmer, et al., 2014). The embedded Stochastic Movement Simulator (SMS) in RangeShifter enabled us to predict regional‐scale patterns of population spread as a function of patch characteristics (i.e. the size, geometry and composition of patches) and landscape structure (i.e. the distribution and connectivity of patches [Bocedi, Palmer, et al., 2014; Palmer et al., 2011]). The SMS provides an important advantage in modelling the range expansion of animal species, such as roe deer, with dispersal expected to be influenced by key properties of the landscape (e.g. land cover, elevation etc., Debeffe et al., 2013; Wahlström & Liberg, 1995). Our approach could easily be applied to predict distribution changes for a wide range of taxa using the same set of parameters for population dynamics (i.e. standardised values) and species‐specific parameters for dispersal (perceptual range, directional persistence and maximum number of steps, see Methods section for details). When interpreting the results from our study and considering our approach for future applications, it is important to understand the implications of two key assumptions that were made. Firstly, to simplify the modelling of population dynamics, it was necessary to assume that the roe deer population would inevitably spread and realise its potential range (i.e. expansion was certain). We feel that this was reasonable based on historic patterns of expansion in Great Britain and Europe and the biological characteristics of the species. The environmental conditions in Wales are similar to England and Scotland, where the roe deer population is widely distributed. The rates of annual survival and reproduction are also high for roe deer, so local extinctions are unlikely (Cobben et al., 2009; Davis et al., 2016; Flajšman et al., 2013; Gaillard et al., 1993; Wäber et al., 2013). However, it should be noted that a wide range of additional factors may influence the likelihood of their expansion in Wales, such as human activity, interspecific interactions and climate change (Dormann et al., 2012; Pacifici et al., 2020). Secondly, it was assumed that habitat suitability was the only factor driving patterns of population spread. Predictions of population spread from the hybrid model were estimated based on the limited set of environmental variables used to construct the underlying habitat suitability map. Because the modelled environment was static, it failed to account for temporal variation in variables, such as land use and climate. Historic temporal variation may reduce the accuracy of the habitat suitability map as environmental conditions at the point of species presence may have changed since the time of recording. Predictions of future population spread also assume that the environment will remain in its current state, which may be inaccurate. Developing methods to incorporate dynamic environments in models of population spread is a subject of ongoing research (Lecocq et al., 2019; Milanesi et al., 2020) and is a priority for future adaptation of the model. Validating and assessing the performance of simulation‐based models also presents a methodological challenge (Zurell et al., 2022). While our evaluation method quantified the relative performance of the hybrid models, comparing our results to an independent dataset would facilitate more robust model validation and assessment of absolute performance. Presence‐absence species distribution data would be particularly valuable, as they provide a similar level of information to the model output. In contrast, our evaluations were made using maps derived from presence‐only distribution data (ObsRange and ObsPresences). ObsRange was constructed from minimum convex polygons, which most likely overestimated the species range (Burgman & Fox, 2003). Conversely, ObsPresences represented a limited number of locations within the species range where observations were recorded. Therefore, model outputs were more likely to be penalised for under‐prediction (i.e. low specificity) and over‐prediction (i.e. low sensitivity) when compared to ObsRange and ObsPresences, respectively (Appendix S2). The magnitude of penalisation increases at each timestep, as the extent of the predicted range becomes larger relative to the total area, which results in a decrease in model performance over time (Appendix S2). High‐quality independent presence/absence data are rarely available for validating dynamic models of population spread. However, technological advancements such as unmanned aerial vehicles provide novel opportunities to collect higher quality presence/absence distribution data across large spatial extents, which would facilitate more robust model validation (Anderson & Gaston, 2013; Baxter & Hamilton, 2018). Furthermore, higher‐quality data would also improve the accuracy of simulating movement during the transfer phase of dispersal. Describing movement using a cost surface derived from a habitat suitability map assumes movement is influenced by the same environmental variables that drive species distributions. In reality, variables such as elevation and annual rainfall may have an equal effect on distributions but are likely to offer different levels of resistance to movement. Future studies may look to incorporate radio tracking or global positioning system (GPS) telemetry data to derive more accurate cost surfaces from observations of movement behaviour (Diaz et al., 2021). Roe deer are the most widespread deer species in Europe with Great Britain being one of many countries where numbers are increasing rapidly (Croft et al., 2019; Linnell et al., 2020; Ward, 2005). Restoring the population in Wales is an important conservation opportunity. However, it is essential that numbers are maintained at a level that does not place unsustainable pressure on the environment (Apollonio et al., 2010; Carpio et al., 2021). As roe deer have already started to spread from England into Wales, there is a pressing need to proactively develop regional‐ and local‐scale management strategies. Detection at an early stage of colonisation increases the likelihood of successfully controlling population sizes and decreases the long‐term costs of management (Aschim & Brook, 2019; Guisan et al., 2013). Physical monitoring techniques are usually geographically limited, due to the costs and logistics of fieldwork and specialist equipment. At the regional scale, our model can be used to prioritise areas for surveillance and guide early management actions, such as the engagement of landowners, construction of protective fencing and establishment of deer management groups. If sightings are recorded in a novel area, our model reveals where in the neighbouring region populations are most likely to spread to. The use of individual‐sized patches in our model further benefits local‐scale decision‐making by enabling the identification of specific parcels of the landscape for targeted management. As surveillance yields more data on the species' distribution, the model can be adapted to support long‐term population management."
    }
]