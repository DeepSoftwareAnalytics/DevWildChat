[
    {
        "link": "https://sqlite.org/docs.html",
        "document": ""
    },
    {
        "link": "https://sqlite.org/lang_createtable.html",
        "document": "The \"CREATE TABLE\" command is used to create a new table in an SQLite database. A CREATE TABLE command specifies the following attributes of the new table:\n• None The name of the new table.\n• None The database in which the new table is created. Tables may be created in the main database, the temp database, or in any attached database.\n• None The name of each column in the table.\n• None The declared type of each column in the table.\n• None A default value or expression for each column in the table.\n• None A default collation sequence to use with each column.\n• None Optionally, a PRIMARY KEY for the table. Both single column and composite (multiple column) primary keys are supported.\n• None A set of SQL constraints for each table. SQLite supports UNIQUE, NOT NULL, CHECK and FOREIGN KEY constraints.\n• None Whether the table is a WITHOUT ROWID table.\n• None Whether the table is subject to strict type checking.\n\nEvery CREATE TABLE statement must specify a name for the new table. Table names that begin with \"sqlite_\" are reserved for internal use. It is an error to attempt to create a table with a name that starts with \"sqlite_\".\n\nIf a schema-name is specified, it must be either \"main\", \"temp\", or the name of an attached database. In this case the new table is created in the named database. If the \"TEMP\" or \"TEMPORARY\" keyword occurs between the \"CREATE\" and \"TABLE\" then the new table is created in the temp database. It is an error to specify both a schema-name and the TEMP or TEMPORARY keyword, unless the schema-name is \"temp\". If no schema name is specified and the TEMP keyword is not present then the table is created in the main database.\n\nIt is usually an error to attempt to create a new table in a database that already contains a table, index or view of the same name. However, if the \"IF NOT EXISTS\" clause is specified as part of the CREATE TABLE statement and a table or view of the same name already exists, the CREATE TABLE command simply has no effect (and no error message is returned). An error is still returned if the table cannot be created because of an existing index, even if the \"IF NOT EXISTS\" clause is specified.\n\nIt is not an error to create a table that has the same name as an existing trigger.\n\nTables are removed using the DROP TABLE statement.\n\nA \"CREATE TABLE ... AS SELECT\" statement creates and populates a database table based on the results of a SELECT statement. The table has the same number of columns as the SELECT statement returns. The name of each column is the same as the name of the corresponding column in the result set of the SELECT statement. The declared type of each column is determined by the expression affinity of the corresponding expression in the result set of the SELECT statement, as follows:\n\nA table created using CREATE TABLE AS has no PRIMARY KEY and no constraints of any kind. The default value of each column is NULL. The default collation sequence for each column of the new table is BINARY.\n\nTables created using CREATE TABLE AS are initially populated with the rows of data returned by the SELECT statement. Rows are assigned contiguously ascending rowid values, starting with 1, in the order that they are returned by the SELECT statement.\n\nUnless it is a CREATE TABLE ... AS SELECT statement, a CREATE TABLE includes one or more column definitions, optionally followed by a list of table constraints. Each column definition consists of the name of the column, optionally followed by the declared type of the column, then one or more optional column constraints. Included in the definition of \"column constraints\" for the purposes of the previous statement are the COLLATE and DEFAULT clauses, even though these are not really constraints in the sense that they do not restrict the data that the table may contain. The other constraints - NOT NULL, CHECK, UNIQUE, PRIMARY KEY and FOREIGN KEY constraints - impose restrictions on the table data.\n\nThe number of columns in a table is limited by the SQLITE_MAX_COLUMN compile-time parameter. A single row of a table cannot store more than SQLITE_MAX_LENGTH bytes of data. Both of these limits can be lowered at runtime using the sqlite3_limit() C/C++ interface.\n\nUnlike most SQL databases, SQLite does not restrict the type of data that may be inserted into a column based on the columns declared type. Instead, SQLite uses dynamic typing. The declared type of a column is used to determine the affinity of the column only.\n\nThe DEFAULT clause specifies a default value to use for the column if no value is explicitly provided by the user when doing an INSERT. If there is no explicit DEFAULT clause attached to a column definition, then the default value of the column is NULL. An explicit DEFAULT clause may specify that the default value is NULL, a string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses. A default value may also be one of the special case-independent keywords CURRENT_TIME, CURRENT_DATE or CURRENT_TIMESTAMP. For the purposes of the DEFAULT clause, an expression is considered constant if it contains no sub-queries, column or table references, bound parameters, or string literals enclosed in double-quotes instead of single-quotes.\n\nEach time a row is inserted into the table by an INSERT statement that does not provide explicit values for all table columns the values stored in the new row are determined by their default values, as follows:\n• None If the default value of the column is a constant NULL, text, blob or signed-number value, then that value is used directly in the new row.\n• None If the default value of a column is an expression in parentheses, then the expression is evaluated once for each row inserted and the results used in the new row.\n• None If the default value of a column is CURRENT_TIME, CURRENT_DATE or CURRENT_TIMESTAMP, then the value used in the new row is a text representation of the current UTC date and/or time. For CURRENT_TIME, the format of the value is \"HH:MM:SS\". For CURRENT_DATE, \"YYYY-MM-DD\". The format for CURRENT_TIMESTAMP is \"YYYY-MM-DD HH:MM:SS\".\n\nThe COLLATE clause specifies the name of a collating sequence to use as the default collation sequence for the column. If no COLLATE clause is specified, the default collation sequence is BINARY.\n\nThe GENERATED ALWAYS AS clause\n\nA column that includes a GENERATED ALWAYS AS clause is a generated column. Generated columns are supported beginning with SQLite version 3.31.0 (2020-01-22). See the separate documentation for details on the capabilities and limitations of generated columns.\n\nEach table in SQLite may have at most one PRIMARY KEY. If the keywords PRIMARY KEY are added to a column definition, then the primary key for the table consists of that single column. Or, if a PRIMARY KEY clause is specified as a table-constraint, then the primary key of the table consists of the list of columns specified as part of the PRIMARY KEY clause. The PRIMARY KEY clause must contain only column names — the use of expressions in an indexed-column of a PRIMARY KEY is not supported. An error is raised if more than one PRIMARY KEY clause appears in a CREATE TABLE statement. The PRIMARY KEY is optional for ordinary tables but is required for WITHOUT ROWID tables.\n\nIf a table has a single column primary key and the declared type of that column is \"INTEGER\" and the table is not a WITHOUT ROWID table, then the column is known as an INTEGER PRIMARY KEY. See below for a description of the special properties and behaviors associated with an INTEGER PRIMARY KEY.\n\nEach row in a table with a primary key must have a unique combination of values in its primary key columns. For the purposes of determining the uniqueness of primary key values, NULL values are considered distinct from all other values, including other NULLs. If an INSERT or UPDATE statement attempts to modify the table content so that two or more rows have identical primary key values, that is a constraint violation.\n\nAccording to the SQL standard, PRIMARY KEY should always imply NOT NULL. Unfortunately, due to a bug in some early versions, this is not the case in SQLite. Unless the column is an INTEGER PRIMARY KEY or the table is a WITHOUT ROWID table or a STRICT table or the column is declared NOT NULL, SQLite allows NULL values in a PRIMARY KEY column. SQLite could be fixed to conform to the standard, but doing so might break legacy applications. Hence, it has been decided to merely document the fact that SQLite allows NULLs in most PRIMARY KEY columns.\n\nA UNIQUE constraint is similar to a PRIMARY KEY constraint, except that a single table may have any number of UNIQUE constraints. For each UNIQUE constraint on the table, each row must contain a unique combination of values in the columns identified by the UNIQUE constraint. For the purposes of UNIQUE constraints, NULL values are considered distinct from all other values, including other NULLs. As with PRIMARY KEYs, a UNIQUE table-constraint clause must contain only column names — the use of expressions in an indexed-column of a UNIQUE table-constraint is not supported.\n\nIn most cases, UNIQUE and PRIMARY KEY constraints are implemented by creating a unique index in the database. (The exceptions are INTEGER PRIMARY KEY and PRIMARY KEYs on WITHOUT ROWID tables.) Hence, the following schemas are logically equivalent:\n\nA CHECK constraint may be attached to a column definition or specified as a table constraint. In practice it makes no difference. Each time a new row is inserted into the table or an existing row is updated, the expression associated with each CHECK constraint is evaluated and cast to a NUMERIC value in the same way as a CAST expression. If the result is zero (integer value 0 or real value 0.0), then a constraint violation has occurred. If the CHECK expression evaluates to NULL, or any other non-zero value, it is not a constraint violation. The expression of a CHECK constraint may not contain a subquery.\n\nCHECK constraints are only verified when the table is written, not when it is read. Furthermore, verification of CHECK constraints can be temporarily disabled using the \"PRAGMA ignore_check_constraints=ON;\" statement. Hence, it is possible that a query might produce results that violate the CHECK constraints.\n\nA NOT NULL constraint may only be attached to a column definition, not specified as a table constraint. Not surprisingly, a NOT NULL constraint dictates that the associated column may not contain a NULL value. Attempting to set the column value to NULL when inserting a new row or updating an existing one causes a constraint violation. NOT NULL constraints are not verified during queries, so a query of a column might produce a NULL value even though the column is marked as NOT NULL, if the database file is corrupt.\n\nConstraints are checked during INSERT and UPDATE and by PRAGMA integrity_check and PRAGMA quick_check and sometimes by ALTER TABLE. Queries and DELETE statements do not normally verify constraints. Hence, if a database file has been corrupted (perhaps by an external program making direct changes to the database file without going through the SQLite library) a query might return data that violates a constraint. For example:\n\nEnforcement of CHECK constraints can be temporarily disabled using the PRAGMA ignore_check_constraints=ON; statement.\n\nThe response to a constraint violation is determined by the constraint conflict resolution algorithm. Each PRIMARY KEY, UNIQUE, NOT NULL and CHECK constraint has a default conflict resolution algorithm. PRIMARY KEY, UNIQUE and NOT NULL constraints may be explicitly assigned another default conflict resolution algorithm by including a conflict-clause in their definitions. Or, if a constraint definition does not include a conflict-clause, the default conflict resolution algorithm is ABORT. The conflict resolution algorithm for CHECK constraints is always ABORT. (For historical compatibility only, table CHECK constraints are allowed to have a conflict resolution clause, but that has no effect.) Different constraints within the same table may have different default conflict resolution algorithms. See the section titled ON CONFLICT for additional information.\n\nExcept for WITHOUT ROWID tables, all rows within SQLite tables have a 64-bit signed integer key that uniquely identifies the row within its table. This integer is usually called the \"rowid\". The rowid value can be accessed using one of the special case-independent names \"rowid\", \"oid\", or \"_rowid_\" in place of a column name. If a table contains a user defined column named \"rowid\", \"oid\" or \"_rowid_\", then that name always refers the explicitly declared column and cannot be used to retrieve the integer rowid value.\n\nThe rowid (and \"oid\" and \"_rowid_\") is omitted in WITHOUT ROWID tables. WITHOUT ROWID tables are only available in SQLite version 3.8.2 (2013-12-06) and later. A table that lacks the WITHOUT ROWID clause is called a \"rowid table\".\n\nThe data for rowid tables is stored as a B-Tree structure containing one entry for each table row, using the rowid value as the key. This means that retrieving or sorting records by rowid is fast. Searching for a record with a specific rowid, or for all records with rowids within a specified range is around twice as fast as a similar search made by specifying any other PRIMARY KEY or indexed value.\n\nWith one exception noted below, if a rowid table has a primary key that consists of a single column and the declared type of that column is \"INTEGER\" in any mixture of upper and lower case, then the column becomes an alias for the rowid. Such a column is usually referred to as an \"integer primary key\". A PRIMARY KEY column only becomes an integer primary key if the declared type name is exactly \"INTEGER\". Other integer type names like \"INT\" or \"BIGINT\" or \"SHORT INTEGER\" or \"UNSIGNED INTEGER\" causes the primary key column to behave as an ordinary table column with integer affinity and a unique index, not as an alias for the rowid.\n\nThe exception mentioned above is that if the declaration of a column with declared type \"INTEGER\" includes an \"PRIMARY KEY DESC\" clause, it does not become an alias for the rowid and is not classified as an integer primary key. This quirk is not by design. It is due to a bug in early versions of SQLite. But fixing the bug could result in backwards incompatibilities. Hence, the original behavior has been retained (and documented) because odd behavior in a corner case is far better than a compatibility break. This means that the following three table declarations all cause the column \"x\" to be an alias for the rowid (an integer primary key):\n\nBut the following declaration does not result in \"x\" being an alias for the rowid:\n\nRowid values may be modified using an UPDATE statement in the same way as any other column value can, either using one of the built-in aliases (\"rowid\", \"oid\" or \"_rowid_\") or by using an alias created by an integer primary key. Similarly, an INSERT statement may provide a value to use as the rowid for each row inserted. Unlike normal SQLite columns, an integer primary key or rowid column must contain integer values. Integer primary key or rowid columns are not able to hold floating point values, strings, BLOBs, or NULLs.\n\nIf an UPDATE statement attempts to set an integer primary key or rowid column to a NULL or blob value, or to a string or real value that cannot be losslessly converted to an integer, a \"datatype mismatch\" error occurs and the statement is aborted. If an INSERT statement attempts to insert a blob value, or a string or real value that cannot be losslessly converted to an integer into an integer primary key or rowid column, a \"datatype mismatch\" error occurs and the statement is aborted.\n\nIf an INSERT statement attempts to insert a NULL value into a rowid or integer primary key column, the system chooses an integer value to use as the rowid automatically. A detailed description of how this is done is provided separately.\n\nThe parent key of a foreign key constraint is not allowed to use the rowid. The parent key must use named columns only.\n\nThis page last modified on 2024-09-19 08:12:22 UTC"
    },
    {
        "link": "https://sqlitetutorial.net/sqlite-create-table",
        "document": "Summary: in this tutorial, you will learn how to create new tables using SQLite statement using various options.\n\nTo create a new table in SQLite, you use statement using the following syntax:\n• First, specify the name of the table that you want to create after the keywords. The name of the table cannot start with because it is reserved for the internal use of SQLite.\n• Second, use option to create a new table if it does not exist. Attempting to create a table that already exists without using the option will result in an error.\n• Third, optionally specify the to which the new table belongs. The schema can be the main database, database or any attached database.\n• Fourth, specify the column list of the table. Each column has a name, data type, and the column constraint. SQLite supports , , , and column constraints.\n• Fifth, specify the table constraints such as , , , and constraints.\n• Finally, optionally use the option. By default, a row in a table has an implicit column, which is referred to as the , or column. The column stores a 64-bit signed integer key that uniquely identifies the row inside the table. If you don’t want SQLite creates the column, you specify the option. A table that contains the column is known as a table. Note that the option is only available in SQLite 3.8.2 or later.\n\nNote that the primary key of a table is a column or a group of columns that uniquely identify each row in the table.\n\nSuppose you have to manage contacts using SQLite.\n\nEach contact has the following information:\n\nThe requirement is that the email and phone must be unique. In addition, each contact belongs to one or many groups, and each group can have zero or many contacts.\n\nBased on these requirements, we came up with three tables:\n• The table that stores the relationship between contacts and groups.\n\nThe following database diagram illustrates tables: , and\n\nThe following statement creates the table.\n\nThe is the primary key of the table.\n\nBecause the primary key consists of one column, you can use the column constraint.\n\nThe and columns have storage class and these columns are . It means that you must provide values when you insert or update rows in the table.\n\nThe email and phone are unique therefore we use the constraint for each column.\n\nThe following statement creates the table:\n\nThe table is quite simple with two columns: and . The column is the primary key column.\n\nThe table has a primary key that consists of two columns: and .\n\nTo add the table primary key constraint, you use this syntax:\n\nIn addition, the and are the foreign keys. Therefore, you use constraint to define a foreign key for each column.\n\nNote that we will discuss in the constraint in detail in the subsequent tutorial.\n\nIn this tutorial, you have learned how to create a new table with various options using SQLite statement."
    },
    {
        "link": "https://sqlite.org/quickstart.html",
        "document": "\n• None Get a copy of the prebuilt binaries for your machine, or get a copy of the sources and compile them yourself. Visit the download page for more information.\n\nThe Command Line Interface or \"CLI\" is a simple command-line program that accepts SQL input text and passes it through to the SQLite database engine core to be executed. The name of the CLI program is \"sqlite3\" (or \"sqlite3.exe\" on Windows). Use the CLI for manual interactions with a database.\n\nA WASM build of the CLI that runs in your web-browser is available at https://sqlite.org/fiddle.\n• None Below is a simple TCL program that demonstrates how to use the TCL interface to SQLite. The program executes the SQL statements given as the second argument on the database defined by the first argument. The commands to watch for are the sqlite3 command on line 7 which opens an SQLite database and creates a new object named \"db\" to access that database, the use of the eval method on the db object on line 8 to run SQL commands against the database, and the closing of the database connection on the last line of the script. 01 #!/usr/bin/tclsh 02 if {$argc!=2} { 03 puts stderr \"Usage: %s DATABASE SQL-STATEMENT\" 04 exit 1 05 } 06 package require sqlite3 07 sqlite3 db [lindex $argv 0] 08 db eval [lindex $argv 1] x { 09 foreach v $x(*) { 10 puts \"$v = $x($v)\" 11 } 12 puts \"\" 13 } 14 db close\n• None Below is a simple C program that demonstrates how to use the C/C++ interface to SQLite. The name of a database is given by the first argument and the second argument is one or more SQL statements to execute against the database. The function calls to pay attention to here are the call to sqlite3_open() on line 22 which opens the database, sqlite3_exec() on line 28 that executes SQL commands against the database, and sqlite3_close() on line 33 that closes the database connection. See also the Introduction To The SQLite C/C++ Interface for an introductory overview and roadmap to the dozens of SQLite interface functions. 01 #include <stdio.h> 02 #include <sqlite3.h> 03 04 static int callback(void *NotUsed, int argc, char **argv, char **azColName){ 05 int i; 06 for(i=0; i<argc; i++){ 07 printf(\"%s = %s\n\n\", azColName[i], argv[i] ? argv[i] : \"NULL\"); 08 } 09 printf(\"\n\n\"); 10 return 0; 11 } 12 13 int main(int argc, char **argv){ 14 sqlite3 *db; 15 char *zErrMsg = 0; 16 int rc; 17 18 if( argc!=3 ){ 19 fprintf(stderr, \"Usage: %s DATABASE SQL-STATEMENT\n\n\", argv[0]); 20 return(1); 21 } 22 rc = sqlite3_open(argv[1], &db); 23 if( rc ){ 24 fprintf(stderr, \"Can't open database: %s\n\n\", sqlite3_errmsg(db)); 25 sqlite3_close(db); 26 return(1); 27 } 28 rc = sqlite3_exec(db, argv[2], callback, 0, &zErrMsg); 29 if( rc!=SQLITE_OK ){ 30 fprintf(stderr, \"SQL error: %s\n\n\", zErrMsg); 31 sqlite3_free(zErrMsg); 32 } 33 sqlite3_close(db); 34 return 0; 35 } See the How To Compile SQLite document for instructions and hints on how to compile the program shown above."
    },
    {
        "link": "https://prisma.io/dataguide/sqlite/creating-and-deleting-databases-and-tables",
        "document": "In this article, we are going to cover the creation and destruction of databases and tables in SQLite. We can quickly refresh our memory of these two terms:\n• Databases: divide different sets of structures and data from one another\n• Tables: define the data structure and store the actual data values within the database SQLite utilizes the command line for working with your database files. To follow along, you will need to download the respective SQLite CLI for your machine. Let's begin.\n\nTo begin, start a new SQLite shell by typing into your command prompt. The result will look similar to the following: By default, a SQLite session begins using an in-memory database. This means that it is not currently reading from a file. If you already have a persistent database, you can open its existing file by using the command. For example, in the following command, the pre-existing database is opened. Note: If you indicate a file name that does not already exist, the sqlite3 tool will create the database file. To create a new database more explicitly, add to the command. Here we demonstrate the command by creating the . This will save your existing changes to your given database file for the remainder of the session.\n\nNow that you have created databases, you can check your connections by using the command. The following illustrates what the return of the command will look like resulting in the database being displayed. For some use cases, you may want to add other databases to the current connection. This can be done using the statement as demonstrated below by the addition of to our active connection. Now when we run the command we will get the following two connections returned, the and databases.\n\nWith your databases created and connections verified, you can begin introducing data structure to your database(s). How to use SQLite's command In this section, we will add the data structure to our newly created database by creating a table. To create a table within your database, you will utilize the statement with the following syntax: We can break down the above statement into the following pieces:\n• : This is the basic command statement. In the example, the is and should be whatever you intend to name your table.\n• : This syntax defines a basic column within the table. In the example, a column name would be and its corresponding data type defined by SQLite Data Types is .\n• : Column constraints are optional restraints adding additional requirements for the data entering your table. In the example, the column constraint is added to the column. This ensures no entry is made without this column being populated.\n• : Like a column constraint, table constraints are optional to add additional requirements to your data. There is an exception if the constraint affects the interaction of multiple columns instead of a singular column. In our example, the addition of to the field is an example of a table constraint. It is important to note that the statement will create the table you specify in the database by default. If you have multiple connections open to databases, you need to specify in your statement to create the table in a database other than . Adjusting the previous example will look like this to create the table in : How to create tables only if they do not already exist To ensure that you are creating a table that does not already exist, the optional clause can be added to the previous example as follows: SQLite will throw an error when attempting to create an already present table without the clause by default. By adding this clause, the default behavior is overridden with a warning instead of an error. The rest of the command's behavior remains the same. After creating your table, you can verify the structure of your table by using the command. If we want to make sure the previously created table is structured the way we intended, we can check using the following syntax: The returned result will look as follows for the table: To get a more easily read result, you can use the command. This will show you the schema of the connected database with better spacing: Note: The command will also include dumps of the statistics tables if they exist. We won't cover that for now, but it can be useful to have this output in some cases.\n\nTo drop a table from a database in SQLite, you will use the statement. This statement is used as follows for dropping the table: The statement is optional when dropping a table. The behavior it adds makes sure that the command only runs if the table exists. If it does not exist, then the statement is simply ignored and nothing happens.\n\nBecause SQLite does not have a separate server process like other relational databases such as MySQL or PostgreSQL, there is not a need for a statement. SQLite is an embedded database engine, so in order to drop a database you have to delete the file from the machine. This action will make the database no longer accessible.\n\nThis article covers the basics of creating and dropping databases and tables in SQLite. The commands walked through are some of the most basic to get started with SQLite and allow you to start organizing and structuring your data. Within the statements mentioned, like and , many additional parameters that can be considered depending on the use case. You can read into more detail on statements like these in the official SQLite documentation. When using Prisma, you can use the Prisma Migrate to create your databases and tables. Developing with Prisma Migrate generates migration files based on the declarative Prisma schema and applies them to your database. Prisma is an open-source database toolkit for Typescript and Node.js that aims to make app developers more productive and confident when working with databases."
    },
    {
        "link": "https://docs.python.org/3/library/sqlite3.html",
        "document": "SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.\n\nThe module was written by Gerhard Häring. It provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249, and requires SQLite 3.15.2 or newer.\n• None Tutorial teaches how to use the module.\n• None Reference describes the classes and functions this module defines.\n\nHow to use placeholders to bind values in SQL queries¶ SQL operations usually need to use values from Python variables. However, beware of using Python’s string operations to assemble queries, as they are vulnerable to SQL injection attacks. For example, an attacker can simply close the single quote and inject to select all rows: # Never do this -- insecure! SELECT * FROM stocks WHERE symbol = '' OR TRUE; --' Instead, use the DB-API’s parameter substitution. To insert a variable into a query string, use a placeholder in the string, and substitute the actual values into the query by providing them as a of values to the second argument of the cursor’s method. An SQL statement may use one of two kinds of placeholders: question marks (qmark style) or named placeholders (named style). For the qmark style, parameters must be a sequence whose length must match the number of placeholders, or a is raised. For the named style, parameters must be an instance of a (or a subclass), which must contain keys for all named parameters; any extra items are ignored. Here’s an example of both styles: # This is the named style used with executemany(): # This is the qmark style used in a SELECT query: PEP 249 numeric placeholders are not supported. If used, they will be interpreted as named placeholders. How to adapt custom Python types to SQLite values¶ SQLite supports only a limited set of data types natively. To store custom Python types in SQLite databases, adapt them to one of the Python types SQLite natively understands. There are two ways to adapt Python objects to SQLite types: letting your object adapt itself, or using an adapter callable. The latter will take precedence above the former. For a library that exports a custom type, it may make sense to enable that type to adapt itself. As an application developer, it may make more sense to take direct control by registering custom adapter functions. Suppose we have a class that represents a pair of coordinates, and , in a Cartesian coordinate system. The coordinate pair will be stored as a text string in the database, using a semicolon to separate the coordinates. This can be implemented by adding a method which returns the adapted value. The object passed to protocol will be of type . The other possibility is to create a function that converts the Python object to an SQLite-compatible type. This function can then be registered using . How to convert SQLite values to custom Python types¶ Writing an adapter lets you convert from custom Python types to SQLite values. To be able to convert from SQLite values to custom Python types, we use converters. Let’s go back to the class. We stored the x and y coordinates separated via semicolons as strings in SQLite. First, we’ll define a converter function that accepts the string as a parameter and constructs a object from it. Converter functions are always passed a object, no matter the underlying SQLite data type. We now need to tell when it should convert a given SQLite value. This is done when connecting to a database, using the detect_types parameter of . There are three options:\n• None Both: set detect_types to . Column names take precedence over declared types. The following example illustrates the implicit and explicit approaches: This section shows recipes for common adapters and converters. How to use connection shortcut methods¶ Using the , , and methods of the class, your code can be written more concisely because you don’t have to create the (often superfluous) objects explicitly. Instead, the objects are created implicitly and these shortcut methods return the cursor objects. This way, you can execute a statement and iterate over it directly using only a single call on the object. # close() is not a shortcut method and it's not called automatically; # the connection object should be closed manually How to use the connection context manager¶ A object can be used as a context manager that automatically commits or rolls back open transactions when leaving the body of the context manager. If the body of the statement finishes without exceptions, the transaction is committed. If this commit fails, or if the body of the statement raises an uncaught exception, the transaction is rolled back. If is , a new transaction is implicitly opened after committing or rolling back. If there is no open transaction upon leaving the body of the statement, or if is , the context manager does nothing. The context manager neither implicitly opens a new transaction nor closes the connection. If you need a closing context manager, consider using . # con.rollback() is called after the with block finishes with an exception, # the exception is still raised and must be caught # Connection object used as context manager only commits or rollbacks transactions, # so the connection object should be closed manually How to work with SQLite URIs¶\n• None Do not implicitly create a new database file if it does not already exist; will raise if unable to create a new file: More information about this feature, including a list of parameters, can be found in the SQLite URI documentation. How to create and use row factories¶ By default, represents each row as a . If a does not suit your needs, you can use the class or a custom . While exists as an attribute both on the and the , it is recommended to set , so all cursors created from the connection will use the same row factory. provides indexed and case-insensitive named access to columns, with minimal memory overhead and performance impact over a . To use as a row factory, assign it to the attribute: \"SELECT 'Earth' AS name, 6378 AS radius\" The clause can be omitted in the statement, as in the above example. In such cases, SQLite returns a single row with columns defined by expressions, e.g. literals, with the given aliases . You can create a custom that returns each row as a , with column names mapped to values: Using it, queries now return a instead of a : can be used as follows: With some adjustments, the above recipe can be adapted to use a , or any other custom class, instead of a . By default, uses to adapt SQLite values with the data type. This works well for UTF-8 encoded text, but it might fail for other encodings and invalid UTF-8. You can use a custom to handle such cases. Because of SQLite’s flexible typing, it is not uncommon to encounter table columns with the data type containing non-UTF-8 encodings, or even arbitrary data. To demonstrate, let’s assume we have a database with ISO-8859-2 (Latin-2) encoded text, for example a table of Czech-English dictionary entries. Assuming we now have a instance connected to this database, we can decode the Latin-2 encoded text using this : For invalid UTF-8 or arbitrary data in stored in table columns, you can use the following technique, borrowed from the Unicode HOWTO: The module API does not support strings containing surrogates."
    },
    {
        "link": "https://freecodecamp.org/news/work-with-sqlite-in-python-handbook",
        "document": "SQLite is one of the most popular relational database management systems (RDBMS). It’s lightweight, meaning that it doesn’t take up much space on your system. One of its best features is that it’s serverless, so you don’t need to install or manage a separate server to use it.\n\nInstead, it stores everything in a simple file on your computer. It also requires zero configuration, so there’s no complicated setup process, making it perfect for beginners and small projects.\n\nSQLite is a great choice for small to medium applications because it’s easy to use, fast, and can handle most tasks that bigger databases can do, but without the hassle of managing extra software. Whether you're building a personal project or prototyping a new app, SQLite is a solid option to get things up and running quickly.\n\nIn this tutorial, you'll learn how to work with SQLite using Python. Here’s what we’re going to cover in this tutorial:\n• None How to Set Up Your Python Environment\n• None How to Create an SQLite Database\n• None How to Insert Data into a Table\n• None How to Update and Delete Data\n• None How to Use Transactions\n• None How to Optimize SQLite Query Performance with Indexing\n• None How to Handle Errors and Exceptions\n• None How to Export and Import Data [Bonus Section]\n\nThis tutorial is perfect for anyone who wants to get started with databases without diving into complex setups.\n\nHow to Set Up Your Python Environment\n\nBefore working with SQLite, let’s ensure your Python environment is ready. Here’s how to set everything up.\n\nIf you don’t have Python installed on your system yet, you can download it from the official Python website. Follow the installation instructions for your operating system (Windows, macOS, or Linux).\n\nTo check if Python is installed, open your terminal (or command prompt) and type:\n\nThis should show the current version of Python installed. If it’s not installed, follow the instructions on the Python website.\n\nThe good news is that SQLite3 comes built-in with Python! You don’t need to install it separately because it’s included in the standard Python library. This means you can start using it right away without any additional setup.\n\nHow to Create a Virtual Environment (Optional but Recommended)\n\nIt’s a good idea to create a virtual environment for each project to keep your dependencies organized. A virtual environment is like a clean slate where you can install packages without affecting your global Python installation.\n• None First, open your terminal or command prompt and navigate to the directory where you want to create your project.\n• None Run the following command to create a virtual environment:\n\nHere, is the name of the virtual environment. You can name it anything you like.\n\nAfter activating the virtual environment, you’ll notice that your terminal prompt changes, showing the name of the virtual environment. This means you’re now working inside it.\n\nWe’ll need a few additional libraries for this project. Specifically, we’ll use:\n• None : This is an optional library for handling and displaying data in tabular format, useful for advanced use cases.\n• None : This library will help us generate fake data, like random names and addresses, which we can insert into our database for testing.\n\nTo install and , simply run the following commands:\n\nThis installs both and into your virtual environment. With this, your environment is set up, and you’re ready to start creating and managing your SQLite database in Python!\n\nHow to Create an SQLite Database\n\nA database is a structured way to store and manage data so that it can be easily accessed, updated, and organized. It’s like a digital filing system that allows you to efficiently store large amounts of data, whether it’s for a simple app or a more complex system. Databases use tables to organize data, with rows and columns representing individual records and their attributes.\n\nUnlike most other database systems, SQLite is a serverless database. This means that it doesn’t require setting up or managing a server, making it lightweight and easy to use. All the data is stored in a single file on your computer, which you can easily move, share, or back up. Despite its simplicity, SQLite is powerful enough to handle many common database tasks and is widely used in mobile apps, embedded systems, and small to medium-sized projects.\n\nHow to Create a New SQLite Database\n\nLet’s create a new SQLite database and learn how to interact with it using Python’s library.\n\nSince is pre-installed, you just need to import it in your Python script. To create a new database or connect to an existing one, we use the method. This method takes the name of the database file as an argument. If the file doesn’t exist, SQLite will automatically create it.\n\nIn this example, a file named is created in the same directory as your script. If the file already exists, SQLite will just open the connection to it.\n\nOnce you have a connection, the next step is to create a cursor object. The cursor is responsible for executing SQL commands and queries on the database.\n\nAfter you’ve finished working with the database, it’s important to close the connection to free up any resources. You can close the connection with the following command:\n\nHowever, you should only close the connection once you’re done with all your operations.\n\nWhen you run your Python script, a file named will be created in your current working directory. You’ve now successfully created your first SQLite database!\n\nHow to Use Context Manager to Open and Close Connections\n\nPython provides a more efficient and cleaner way to handle database connections using the statement, also known as a context manager. The statement automatically opens and closes the connection, ensuring that the connection is properly closed even if an error occurs during the database operations. This eliminates the need to manually call .\n\nHere’s how you can use the statement to handle database connections:\n\nFrom now on, we’ll use the statement in our upcoming code examples to manage database connections efficiently. This will make the code more concise and easier to maintain.\n\nNow that we’ve created an SQLite database and connected to it, the next step is to create tables inside the database. A table is where we’ll store our data, organized in rows (records) and columns (attributes). For this example, we’ll create a table called to store information about students, which we’ll reuse in upcoming sections.\n\nTo create a table, we use SQL's statement. This command defines the table structure, including the column names and the data types for each column.\n\nHere’s a simple SQL command to create a table with the following fields:\n• None : A unique identifier for each student (an integer).\n• None name: The student's name (text).\n\nThe SQL command to create this table would look like this:\n\nWe can execute this SQL command in Python using the library. Let’s see how to do that.\n• None : This ensures that the table is only created if it doesn’t already exist, preventing errors if the table has been created before.\n• None : This saves (commits) the changes to the database.\n\nWhen you run the Python code above, it will create the table in the database file. You’ll also see a message in the terminal confirming that the table has been created successfully.\n\nIf you’re using Visual Studio Code, you can install the SQLite Viewer extension to view SQLite databases.\n\nData Types in SQLite and Their Mapping to Python\n\nSQLite supports several data types, which we need to understand when defining our tables. Here’s a quick overview of common SQLite data types and how they map to Python types:\n• None is of type , which maps to Python’s .\n• None and are of type , which map to Python’s .\n• None is also of type , mapping to Python’s .\n\nHow to Insert Data into a Table\n\nNow that we have our table created, it’s time to start inserting data into the database. In this section, we’ll cover how to insert both single and multiple records using Python and SQLite, and how to avoid common security issues like SQL injection by using parameterized queries.\n\nTo insert data into the database, we use the SQL command. Let’s start by inserting a single record into our table.\n\nHowever, instead of writing SQL directly in our Python script with hardcoded values, we’ll use parameterized queries to make our code more secure and flexible. Parameterized queries help prevent SQL injection, a common attack where malicious users can manipulate the SQL query by passing harmful input.\n\nHere’s how we can insert a single record into the table using a parameterized query:\n\nThe placeholders represent the values to be inserted into the table. The actual values are passed as a tuple ( ) in the method.\n\nIf you want to insert multiple records at once, you can use the method in Python. This method takes a list of tuples, where each tuple represents one record.\n\nTo make our example more dynamic, we can use the library to generate random student data. This is useful for testing and simulating real-world scenarios.\n• None generates random names, ages, and emails for students. Passing the locale( ) is optional.\n• None : This method allows us to insert multiple records at once, making the code more efficient.\n• None : A list of tuples where each tuple represents one student’s data.\n\nSQL injection is a security vulnerability where attackers can insert or manipulate SQL queries by providing harmful input. For example, an attacker might try to inject code like to delete the table.\n\nBy using parameterized queries (as demonstrated above), we avoid this issue. The placeholders in parameterized queries ensure that input values are treated as data, not as part of the SQL command. This makes it impossible for malicious code to be executed.\n\nNow that we’ve inserted some data into our table, let’s learn how to retrieve the data from the table. We'll explore different methods for fetching data in Python, including , , and .\n\nTo query data from a table, we use the statement. Here’s a simple SQL command to select all columns from the table:\n\nThis command retrieves all records and columns from the table. We can execute this query in Python and fetch the results.\n\nHow to Fetch All Records\n\nHere’s how we can fetch all records from the table:\n\nIn this example, the method retrieves all rows returned by the query as a list of tuples.\n\nIf you want to retrieve only one record, you can use the method:\n\nTo fetch a specific number of records, you can use :\n\nHow to Use for Better Data Presentation\n\nFor better data presentation, we can use the library to create a from our query results. This makes it easier to manipulate and visualize the data.\n\nHere’s how to fetch all records and display them as a pandas DataFrame:\n\nThe function executes the SQL query and directly returns the results as a pandas DataFrame.\n\nIn this section, we’ll learn how to update existing records and delete records from our table using SQL commands in Python. This is essential for managing and maintaining your data effectively.\n\nTo modify existing records in a database, we use the SQL command. This command allows us to change the values of specific columns in one or more rows based on a specified condition.\n\nFor example, if we want to update a student's age, the SQL command would look like this:\n\nNow, let’s write Python code to update a specific student's age in our table.\n\nIn this example, we used parameterized queries to prevent SQL injection.\n\nHow to Delete Records from the Table\n\nTo remove records from a database, we use the SQL command. This command allows us to delete one or more rows based on a specified condition.\n\nFor example, if we want to delete a student named 'Jane Doe', the SQL command would look like this:\n\nLet’s write Python code to delete a specific student from our table using the statement.\n• None Conditions: Always use the clause when updating or deleting records to avoid modifying or removing all rows in the table. Without a clause, the command affects every row in the table.\n• None Backup: It’s good practice to back up your database before performing updates or deletions, especially in production environments.\n\nHow to Use Transactions\n\nA transaction is a sequence of one or more SQL operations that are treated as a single unit of work. In the context of a database, a transaction allows you to perform multiple operations that either all succeed or none at all. This ensures that your database remains in a consistent state, even in the face of errors or unexpected issues.\n\nFor example, if you are transferring money between two bank accounts, you would want both the debit from one account and the credit to the other to succeed or fail together. If one operation fails, the other should not be executed to maintain consistency.\n• None Atomicity: Transactions ensure that a series of operations are treated as a single unit. If one operation fails, none of the operations will be applied to the database.\n• None Consistency: Transactions help maintain the integrity of the database by ensuring that all rules and constraints are followed.\n• None Isolation: Each transaction operates independently of others, preventing unintended interference.\n• None Durability: Once a transaction is committed, the changes are permanent, even in the event of a system failure.\n\nWhen to Use Transactions?\n\nYou should use transactions when:\n• None Performing multiple related operations that must succeed or fail together.\n• None Working with operations that can potentially fail, such as financial transactions or data migrations.\n\nHow to Manage Transactions in Python\n\nIn SQLite, transactions are managed using the , , and commands. However, when using the module in Python, you typically manage transactions through the connection object.\n\nA transaction begins implicitly when you execute any SQL statement. To start a transaction explicitly, you can use the command:\n\nHowever, it’s usually unnecessary to start a transaction manually, as SQLite starts a transaction automatically when you execute an SQL statement.\n\nTo save all changes made during a transaction, you use the method. This makes all modifications permanent in the database.\n\nWe have already used the method in the above provided examples.\n\nIf something goes wrong and you want to revert the changes made during a transaction, you can use the method. This will undo all changes made since the transaction started.\n\nExample of Using Transactions in Python\n\nTo illustrate the use of transactions in a real-world scenario, we’ll create a new table called to manage customer accounts. In this example, we’ll assume each customer has a . We will add two customers to this table and perform a funds transfer operation between them.\n\nFirst, let's create the table and insert two customers:\n\nNow, let’s perform the funds transfer operation between Ashutosh and Krishna:\n\nIn this example, we first created a table and inserted two customers, Ashutosh with a balance of ₹100, and Krishna with a balance of ₹50. We then performed a funds transfer of ₹80 from Ashutosh to Krishna. By using transactions, we ensure that both the debit from Ashutosh's account and the credit to Krishna's account are executed as a single atomic operation, maintaining data integrity in the event of any errors. If the transfer fails (for example, due to insufficient funds), the transaction will roll back, leaving both accounts unchanged.\n\nHow to Optimize SQLite Query Performance with Indexing\n\nIndexing is a powerful technique used in databases to improve query performance. An index is essentially a data structure that stores the location of rows based on specific column values, much like an index at the back of a book helps you quickly locate a topic.\n\nWithout an index, SQLite has to scan the entire table row by row to find the relevant data, which becomes inefficient as the dataset grows. By using an index, SQLite can jump directly to the rows you need, significantly speeding up query execution.\n\nHow to Populate the Database with Fake Data\n\nTo effectively test the impact of indexing, we need a sizable dataset. Instead of manually adding records, we can use the library to quickly generate fake data. In this section, we’ll generate 10,000 fake records and insert them into our table. This will simulate a real-world scenario where databases grow large, and query performance becomes important.\n\nWe will use the method to insert the records as below:\n\nBy running this script, 10,000 fake student records will be added to the table. In the next section, we'll query the database and compare the performance of queries with and without indexing.\n\nHow to Query Without Indexes\n\nIn this section, we’ll query the table without any indexes to observe how SQLite performs when there are no optimizations in place. This will serve as a baseline to compare the performance when we add indexes later.\n\nWithout indexes, SQLite performs a full table scan, which means that it must check every row in the table to find matching results. For small datasets, this is manageable, but as the number of records grows, the time taken to search increases dramatically. Let’s see this in action by running a basic query to search for a specific student by name and measure how long it takes.\n\nFirst, we’ll query the table by looking for a student with a specific name. We’ll log the time taken to execute the query using Python’s module to measure the performance.\n\nBy running the above script, you'll see how long it takes to search the table without any indexes. For example, if there are 10,000 records in the table, the query might take 1000-2000 microseconds depending on the size of the table and your hardware. This may not seem too slow for a small dataset, but the performance will degrade as more records are added.\n\nWe use to measure the time taken for the query execution in nanoseconds. This method is highly accurate for benchmarking small time intervals. We convert the time to microseconds( ) for easier readability.\n\nWhen working with databases, understanding how queries are executed can help you identify performance bottlenecks and optimize your code. SQLite provides a helpful tool for this called , which allows you to analyze the steps SQLite takes to retrieve data.\n\nIn this section, we’ll introduce how to use to visualize and understand the inner workings of a query—specifically, how SQLite performs a full table scan when no index is present.\n\nLet’s use to see how SQLite retrieves data from the table without any indexes. We’ll search for a student by name, and the query plan will reveal the steps SQLite takes to find the matching rows.\n\nWhen you run this code, SQLite will return a breakdown of how it plans to execute the query. Here’s an example of what the output might look like:\n\nThis indicates that SQLite is scanning the entire table (a full table scan) to find the rows where the column matches the provided value ( ). Since there is no index on the column, SQLite must examine each row in the table.\n\nHow to Create an Index\n\nCreating an index on a column allows SQLite to find rows more quickly during query operations. Instead of scanning the entire table, SQLite can use the index to jump directly to the relevant rows, significantly speeding up queries—especially those involving large datasets.\n\nTo create an index, use the following SQL command:\n\nIn this example, we will create an index on the column of the table. Here’s how you can do it using Python:\n\nEven though creating the index takes this long (102768.6 microseconds), it's a one-time operation. You will still get substantial speed-up when running multiple queries. In the following sections, we will query the database again to observe the performance improvements made possible by this index.\n\nHow to Query with Indexes\n\nIn this section, we will perform the same query we executed earlier, but this time we will take advantage of the index we created on the column of the table. We'll measure and log the execution time to observe the performance improvements provided by the index.\n\nHere’s what we get in the output:\n\nWe can observe a significant reduction in execution time compared to when the query was performed without an index.\n\nLet’s analyze the query execution plan for the query with the index on the column of the table. If you execute the same script again to explain the query, you’ll get the below output:\n\nThe plan now shows that the query uses the index , significantly reducing the number of rows that need to be scanned, which leads to faster query execution.\n\nNow, let's summarize the performance results we obtained when querying with and without indexes.\n• None The query with the index is approximately 4.04 times faster than the query without the index.\n• None The execution time improved by about 75.24% after adding the index.\n\nBest Practices for Using Indexes\n\nIndexes can significantly enhance the performance of your SQLite database, but they should be used judiciously. Here are some best practices to consider when working with indexes:\n\nWhen and Why to Use Indexes\n• None Frequent Query Columns: Use indexes on columns that are frequently used in queries, especially those used in , , and clauses. This is because indexing these columns can drastically reduce query execution time.\n• None Uniqueness Constraints: When you have columns that must hold unique values (like usernames or email addresses), creating an index can enforce this constraint efficiently.\n• None Large Datasets: For tables with a large number of records, indexes become increasingly beneficial. They enable quick lookups, which is essential for maintaining performance as your data grows.\n• None Composite Indexes: Consider creating composite indexes for queries that filter or sort by multiple columns. For example, if you often search for students by both and , an index on both columns can optimize such queries.\n\nWhile indexes provide significant advantages, there are some potential downsides:\n• None Slower Insert/Update Operations: When you insert or update records in a table with indexes, SQLite must also update the index, which can slow down these operations. This is because each insert or update requires additional overhead to maintain the index structure.\n• None Increased Storage Requirements: Indexes consume additional disk space. For large tables, the storage cost can be substantial. Consider this when designing your database schema, especially for systems with limited storage resources.\n• None Complex Index Management: Having too many indexes can complicate database management. It may lead to situations where you have redundant indexes, which can degrade performance rather than enhance it. Regularly reviewing and optimizing your indexes is a good practice.\n\nIndexes are powerful tools for optimizing database queries, but they require careful consideration. Striking a balance between improved read performance and the potential overhead on write operations is key. Here are some strategies for achieving this balance:\n• None Monitor Query Performance: Use SQLite’s to analyze how your queries perform with and without indexes. This can help identify which indexes are beneficial and which may be unnecessary.\n• None Regular Maintenance: Periodically review your indexes and assess whether they are still needed. Remove redundant or rarely used indexes to streamline your database operations.\n• None Test and Evaluate: Before implementing indexes in a production environment, conduct thorough testing to understand their impact on both read and write operations.\n\nBy following these best practices, you can leverage the benefits of indexing while minimizing potential drawbacks, ultimately enhancing the performance and efficiency of your SQLite database.\n\nHow to Handle Errors and Exceptions\n\nIn this section, we’ll discuss how to handle errors and exceptions when working with SQLite in Python. Proper error handling is crucial for maintaining the integrity of your database and ensuring that your application behaves predictably.\n\nWhen interacting with an SQLite database, several common errors may arise:\n• None Constraint Violations: This occurs when you try to insert or update data that violates a database constraint, such as primary key uniqueness or foreign key constraints. For example, trying to insert a duplicate primary key will trigger an error.\n• None Data Type Mismatches: Attempting to insert data of the wrong type (for example, inserting a string where a number is expected) can lead to an error.\n• None Database Locked Errors: If a database is being written to by another process or connection, trying to access it can result in a \"database is locked\" error.\n• None Syntax Errors: Mistakes in your SQL syntax will result in errors when you try to execute your commands.\n\nHow to Use Python's Exception Handling\n\nPython’s built-in exception handling mechanisms ( and ) are essential for managing errors in SQLite operations. By using these constructs, you can catch exceptions and respond appropriately without crashing your program.\n\nHere’s a basic example of how to handle errors when inserting data into the database:\n\nIn this example:\n• None We catch , which is raised for violations like unique constraints.\n• None We catch for general database-related issues (like database locked errors).\n• None We also have a generic block to handle any unexpected exceptions.\n• None Use Transactions: Always use transactions (as discussed in the previous section) when performing multiple related operations. This helps ensure that either all operations succeed or none do, maintaining consistency.\n• None Validate Input Data: Before executing SQL commands, validate the input data to ensure it meets the expected criteria (for example, correct types, within allowable ranges).\n• None Catch Specific Exceptions: Always catch specific exceptions to handle different types of errors appropriately. This allows for clearer error handling and debugging.\n• None Log Errors: Instead of just printing errors to the console, consider logging them to a file or monitoring system. This will help you track issues in production.\n• None Graceful Degradation: Design your application to handle errors gracefully. If an operation fails, provide meaningful feedback to the user rather than crashing the application.\n• None Regularly Backup Data: Regularly back up your database to prevent data loss in case of critical failures or corruption.\n• None Use Prepared Statements: Prepared statements help prevent SQL injection attacks and can also provide better performance for repeated queries.\n\nHow to Export and Import Data [Bonus Section]\n\nIn this section, we will learn how to export data from an SQLite database to common formats like CSV and JSON, as well as how to import data into SQLite from these formats using Python. This is useful for data sharing, backup, and integration with other applications.\n\nExporting data to a CSV (Comma-Separated Values) file is straightforward with Python’s built-in libraries. CSV files are widely used for data storage and exchange, making them a convenient format for exporting data.\n\nHere’s how to export data from an SQLite table to a CSV file:\n\nHow to Export Data to JSON\n\nSimilarly, you can export data to a JSON (JavaScript Object Notation) file, which is a popular format for data interchange, especially in web applications.\n\nHere’s an example of how to export data to JSON:\n\nHow to Import Data into SQLite from CSV\n\nYou can also import data from a CSV file into an SQLite database. This is useful for populating your database with existing datasets.\n\nHere's how to import data from a CSV file:\n\nHow to Import Data into SQLite from JSON\n\nSimilarly, importing data from a JSON file is simple. You can read the JSON file and insert the data into your SQLite table.\n\nHere's how to do it:\n\nAnd that’s a wrap! This guide has introduced you to the fundamentals of working with SQLite in Python, covering everything from setting up your environment to querying and manipulating data, as well as exporting and importing information. I hope you found it helpful and that it has sparked your interest in using SQLite for your projects.\n\nNow it's time to put your newfound knowledge into practice! I encourage you to create your project using SQLite and Python. Whether it’s a simple application for managing your library, a budgeting tool, or something unique, the possibilities are endless.\n\nOnce you’ve completed your project, share it on Twitter and tag me! I’d love to see what you’ve created and celebrate your accomplishments.\n\nYou can find all the code from this tutorial on GitHub. Thank you for following along, and happy coding!"
    },
    {
        "link": "https://remusao.github.io/posts/few-tips-sqlite-perf.html",
        "document": "I’ve recently made heavy use of for a project involving a lot of data and processing. My first attempt involved no database at all, and all data would be kept in memory and queries would consist in a mix of dictionary lookups, iteration, conditions, etc. This was nice, but there is only so much you can fit in memory, and re-generating/loading the data from disk to memory became a tedious and time consuming process.\n\nI decided to give a try. This allowed an increase in the amount of data that could be processed, and reduced the loading time of the application to nothing, since only opening a connection to the database was needed. Moreover, I could replace a lot of Python logic by SQL queries.\n\nI’d like to share a few learnings and findings about this experience.\n• You don’t need (most of the time).\n• Cursors can be iterated upon.\n• Use pragmas (when it makes sense).\n\nIf you need to insert a lot of rows at once in your database, you really should not use . The module provides a way to bulk insertions: .\n\nInstead of doing something like:\n\nYou can leverage the fact that accepts as argument a generator of :\n\nThis is not only more concise, it’s also much more efficient. In fact, implements using behind the scene, but the former inserts a single row instead of many.\n\nI wrote a small benchmark which consists in inserting a million rows into an empty table (the database lives in memory):\n\nOne thing I often found confusing at the beginning, was management. Examples online and in the documentation often look like:\n\nBut most of the time you don’t need a cursor at all, and you can directly use the object (it is mentioned at the end of the documentation).\n\nOperations such as and can be called directly on the connection and will return a cursor. Here is an example to demonstrate that:\n\nCursors Can Be Iterated Upon\n\nYou might often see examples making use of or on the result of a query. But I find that the most natural way to consume the results is to actually iterate on the cursor directly:\n\nThis way, you can stop as soon as you got enough results and not waste resources. Of course, if you know beforehand how many results you want, you can use the SQL statement instead, but Python generators are very handy and allow you to decouple data generation from data consumption.\n\nShit happens, even in the middle of a SQL transaction. To avoid having to deal manually with or , you can simply use the object as a context manager. In the following example we create a table, and insert by mistake duplicated values:\n\nThere are a few pragmas you can use to tweak the behavior of in your program. In particular, one that could improve the performance is :\n\nYou should be aware though that this can be dangerous. If the application crashes unexpectedly in the middle of a transaction, the database will probably be left in an inconsistent state. So use with care! But if you want to insert a lot of rows faster, that can be an option. A safer option is to use the option instead of disabling completely.\n\nLet’s say you need a few indices on your database, and you also need to insert a lot of rows while creating them. Postponing the creation of the indices to after all rows have been inserted could result in a substantial performance improvement.\n\nIt is tempting to use Python string operations to include values into queries. Do not! This is highly insecure, and gives you a better way to do it:\n\nAlso, string interpolation using Python (or format, or formatted string literals) does not go well with . So there is really no point in trying!\n\nKeep in mind though that these tips might or might not give you a benefit, depending on your specific use-case. You should always try for yourself and decide if it’s worth it or not.\n\nEdit 28-12-2017: Thanks for all the great feedback from Reddit and Hacker News. I took the liberty to amend the original article with a few of the suggestions.\n\nThere are a few topics that were not mentioned in this article but are definitely worth reading:\n• Using transactions can dramatically improve the speed of your code if you need to run several SQL statements in a row (it should not be needed if you use ).\n• If you don’t need to re-use your database across sessions, you can use an in-memory database by specifying as a location, which should give you a nice speed-up.\n• You can customize to get something more useful than s as results from queries.\n• Consider changing to or .\n\nEdit 30-05-2021: Fixed a missing in the “You Don’t Need Cursors” section. Thanks to Gelma for noticing."
    },
    {
        "link": "https://sibabalwesinyaniso.medium.com/connecting-sqlite-in-python-a-beginners-guide-fbd2a0a76344",
        "document": "SQLite is a lightweight, serverless database that is widely used in desktop applications, mobile apps, and small web projects. But to make it truly useful, we need to connect it with a programming language like Python.\n\nPython’s built-in module allows seamless interaction with SQLite databases, enabling us to create databases, execute queries, and manage data dynamically. In this post, we’ll explore how to connect SQLite to Python, perform CRUD operations, and follow best practices for handling database connections.\n\nPython provides the module, which is an interface for interacting with SQLite databases. It allows Python applications to execute SQL commands, retrieve results, and manage data without requiring additional software installations.\n\nWhy Use SQLite with Python?\n• Built-in Support — No need to install external libraries.\n• Easy to Use — Simple SQL commands make it beginner-friendly.\n\nHow to Connect to an SQLite Database in Python\n\nTo connect Python to SQLite, we use . If the database file doesn’t exist, SQLite will create one automatically.\n\nExample: Connecting to an SQLite Database\n\nTo execute SQL commands in Python, we need a cursor object. The cursor allows us to send SQL queries to SQLite.\n\nThis creates a users table with , , , and fields.\n\nWe can insert data using parameterized queries to prevent SQL injection.\n\nFetching data is done using the statement.\n\nThe method retrieves all records from the query result.\n\nThis retrieves only one matching user record.\n\nTo modify existing data, we use the statement.\n\nThis removes Alice’s record from the database.\n\nBest Practices for Working with SQLite in Python\n\nInstead of manually opening and closing connections, use statements.\n\nExample: Using for Automatic Connection Management\n\nThe statement automatically closes the connection after execution.\n\nBy default, SQLite disables foreign key constraints. Enable them using:\n\nIf a table contains a large number of records, index frequently queried columns for better performance.\n\nThis makes queries on the column faster.\n• Insert three employees into the table.\n\nMy Progress: Sharing Notes from a Practical Course\n\nThe insights in this post are based on my learning journey from the Udemy course: Python Database Course: SQLite, PostgreSQL, MySQL, SQLAlchemy. This course has helped me integrate SQLite with Python, perform CRUD operations, and follow best practices for managing database connections.\n\nIf you’re looking to master database management with Python, this course provides hands-on tutorials and real-world applications to help you become proficient in SQLite and relational databases.\n\nIn my next post, we’ll explore What is a Cursor?, an essential tool for interacting with SQLite databases in Python. You’ll learn how cursors work, why they are important, and how they help in executing SQL commands, fetching query results, and managing large datasets efficiently.\n\nFollow me for more SQL and database insights, tutorials, and hands-on coding exercises. Let’s keep building efficient, scalable, and data-driven applications together! 🚀"
    },
    {
        "link": "https://reddit.com/r/SQL/comments/nm5hf1/in_search_of_gutbest_practice_for_combining",
        "document": "hej! :-D\n\ni'm normally a python/pandas dude, and I believe pandas substitues SQL/Excel in a lot of ways, however...\n\nLately I find myself writing/maintaining more and more SQL queries (because: more elegant/efficient for some operations), in form of scripts that I execute from python on top of a bunch of semi large SQLite files (~5-10 Gb/file).\n\nAlthough writing sql inside python -i think- comes with some nice advantages (like heavily abusing the ''' ''' strings) the code quicky gets long -> my scroll finger hurts.\n\nso, i am seeking advice from ppl (with ~similar setup) who have already developed nice practices for deveoping/maintaining a large bunch of SQL scripts."
    }
]