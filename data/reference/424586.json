[
    {
        "link": "https://scikit-learn.org/stable/modules/outlier_detection.html",
        "document": "Many applications require being able to decide whether a new observation belongs to the same distribution as existing observations (it is an inlier), or should be considered as different (it is an outlier). Often, this ability is used to clean real data sets. Two important distinctions must be made:\n\nOutlier detection and novelty detection are both used for anomaly detection, where one is interested in detecting abnormal or unusual observations. Outlier detection is then also known as unsupervised anomaly detection and novelty detection as semi-supervised anomaly detection. In the context of outlier detection, the outliers/anomalies cannot form a dense cluster as available estimators assume that the outliers/anomalies are located in low density regions. On the contrary, in the context of novelty detection, novelties/anomalies can form a dense cluster as long as they are in a low density region of the training data, considered as normal in this context.\n\nThe scikit-learn project provides a set of machine learning tools that can be used both for novelty or outlier detection. This strategy is implemented with objects learning in an unsupervised way from the data:\n\nnew observations can then be sorted as inliers or outliers with a method:\n\nInliers are labeled 1, while outliers are labeled -1. The predict method makes use of a threshold on the raw scoring function computed by the estimator. This scoring function is accessible through the method, while the threshold can be controlled by the parameter.\n\nThe method is also defined from the scoring function, in such a way that negative values are outliers and non-negative ones are inliers:\n\nNote that does not support , and methods by default but only a method, as this estimator was originally meant to be applied for outlier detection. The scores of abnormality of the training samples are accessible through the attribute.\n\nIf you really want to use for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you can instantiate the estimator with the parameter set to before fitting the estimator. In this case, is not available.\n\nThe behavior of is summarized in the following table.\n\nConsider a data set of \\(n\\) observations from the same distribution described by \\(p\\) features. Consider now that we add one more observation to that data set. Is the new observation so different from the others that we can doubt it is regular? (i.e. does it come from the same distribution?) Or on the contrary, is it so similar to the other that we cannot distinguish it from the original observations? This is the question addressed by the novelty detection tools and methods. In general, it is about to learn a rough, close frontier delimiting the contour of the initial observations distribution, plotted in embedding \\(p\\)-dimensional space. Then, if further observations lay within the frontier-delimited subspace, they are considered as coming from the same population than the initial observations. Otherwise, if they lay outside the frontier, we can say that they are abnormal with a given confidence in our assessment. The One-Class SVM has been introduced by Schölkopf et al. for that purpose and implemented in the Support Vector Machines module in the object. It requires the choice of a kernel and a scalar parameter to define a frontier. The RBF kernel is usually chosen although there exists no exact formula or algorithm to set its bandwidth parameter. This is the default in the scikit-learn implementation. The parameter, also known as the margin of the One-Class SVM, corresponds to the probability of finding a new, but regular, observation outside the frontier.\n• None Estimating the support of a high-dimensional distribution Schölkopf, Bernhard, et al. Neural computation 13.7 (2001): 1443-1471.\n• None See One-class SVM with non-linear kernel (RBF) for visualizing the frontier learned around some data by a object. An online linear version of the One-Class SVM is implemented in . This implementation scales linearly with the number of samples and can be used with a kernel approximation to approximate the solution of a kernelized whose complexity is at best quadratic in the number of samples. See section Online One-Class SVM for more details.\n• None See One-Class SVM versus One-Class SVM using Stochastic Gradient Descent for an illustration of the approximation of a kernelized One-Class SVM with the combined with kernel approximation."
    },
    {
        "link": "https://scikit-learn.org",
        "document": ""
    },
    {
        "link": "https://towardsdatascience.com/building-classification-models-with-sklearn-6a8fd107f0c1",
        "document": "Scikit-learn is an open-source Machine Learning library for python. It provides a variety of regression, classification, and clustering algorithms. In my previous post, A Brief Tour of Sklearn, I discussed several methods for regression using the machine learning package. In this post, we will go over some of the basic methods for building classification models. The documentation for this package is extensive and a fantastic resource for every data scientist. You can find the documentation here.\n\nWe will be using the Telco Customer Churn dataset. It can be found here\n\nFirst, let’s import the data and print the first five rows:\n\nWe will be using all of the categorical and numerical data to predict Churn. First, we need to convert the categorical columns into numerical values that the neural network can handle. For example, for gender we have:\n\nNow, let’s define our input and output arrays:\n\nWe will then split our data for training and testing:\n\nNow all of our necessary variables are defined. Let’s build some models!\n\nLet’s start with logistic regression. Logistic regression uses a logistic function to predict a binary dependent variable.\n\nWe import the LogisticRegression package as follows:\n\nWe can visualize the predictions using metrics classification report:\n\nWe can also look at the ‘roc_auc_score’ and the ‘f1_score.’ The ‘roc_auc_score’ is the area under the receiving operating characteristic curve. It is a measure of how well the binary classification model can distinguish classes. A ‘roc_auc_score’ of 0.5 means the model is unable to distinguish between classes. Values close to 1.0 correspond to a strong separation between classes. The ‘f1_score’ is the harmonic mean of precision and recall. Similar to ‘roc_auc_score’, a perfect ‘f1_score’ is equal to 1.0:\n\nNow let’s take a look at random forests. Random forest is a tree-based method that ensembles multiple individual decision trees.\n\nWe import the RandomForestClassifier package as follows:\n\nAnd let’s take a look at the metrics classification report:\n\nWe see that the random forest has worse performance than logistic regression. We can also print the feature importance. This allows us to see which variables are most significant for temperature prediction:\n\nI’d like to point out that by not passing any parameters, like max_depth and n_estimators, I selected default random forest values (which are n_estimators = 10 and max_depth = 10 ). We can further improve performance by optimizing parameters in random forests. This can be done manually or in an automated way using grid search techniques. I will leave the matter of parameter optimization for another post.\n\nThe next method I’ll discuss is called support vector regression. This is an extension of support vector machines (SVM). SVMs construct a set of hyperplanes in high dimensional feature space that can be used for regression and classification problems.\n\nWe import the SVC package as follows:\n\nWe can visualize the predictions using metrics classification report:\n\nWe can also look at the roc_auc_score and the f1_scores:\n\nWe see that support vector classification performance is slightly worse than logistic regression and slightly better than random forests. Similar to the random forest, SVC takes parameters that can be used to optimize performance. These include the regularization parameter (default C = 1.0), kernel (default kernel = ‘rbf’) and the kernel coefficient (default gamma = ‘scale’)\n\nThe final method I will discuss is _k-_nearest neighbor for classification. K-nearest neighbors use Euclidean distance calculations where the prediction is the average of the k nearest neighbors.\n\nWe import the KNeighborsClassifier package as follows:\n\nAnd let’s take a look at the metrics classification report:\n\nWe can also look at the roc_auc_score and the f1_scores:\n\nThe K-nearest neighbor algorithm also takes hyper-parameters, specifically n_neighbors, which can be selected to minimized error.\n\nI will stop here but feel free to play around with model feature selection to see if you can improve the performance of some of these models.\n\nTo recap, I outlined a brief introduction to classification using the Python machine learning library. I went over how to define model objects, fit models to data, and predict output using logistic regression, random forest, support vector machine, and K-nearest neighbor models.\n\nI hope this post was informative. The code from this post is available on GitHub. Thank you for reading and happy machine learning!"
    },
    {
        "link": "https://projectpro.io/article/anomaly-detection-using-machine-learning-in-python-with-example/555",
        "document": "In data science, algorithms are usually designed to detect and follow trends found in the given data. The modeling follows from the data distribution learned by the statistical or neural model. In real life, the features of data points in any given domain occur within some limits. They will only go outside of these expected patterns in exceptional cases, which are usually erroneous or fraudulent. When these exceptional cases occur, they cause something that is called an “anomaly” in the data. These data points being incorrect in real life can cause inaccurate results from the data model, inadvertently leading to faulty insight and analysis.\n\nAnomaly (or outlier) detection is the data-driven task of identifying these rare occurrences and filtering or modulating them from the analysis pipeline. Such anomalous events can be connected to some fault in the data source, such as financial fraud, equipment fault, or irregularities in time series analysis.\n\nOne can train machine learning models to detect and report such anomalies retrospectively or in real-time. These anomalous data points can later be either flagged to analyze from a business perspective or removed to maintain the cleanliness of the data before further processing is done.\n\nBelow, we can compare predictions of time-series data with the actual occurrence. As seen, the forecast closely follows the actual data until an anomaly occurs. This considerable variation is unexpected, as we see from the past data trend and the model prediction shown in blue. You can train machine learning models can to identify such out-of-distribution anomalies from a much more complex dataset.\n\nThe Need for Anomaly Detection using Machine Learning and Its Applications in Real-World\n\nIn the real world, popular anomaly detection applications in deep learning include detecting spam or fraudulent bank transactions. Systems are already in place in most major banks where the authorities are alerted when unusually high spending or credit activity occurs on someone’s account. The term “unusually high” can be defined on a user-to-user basis or collectively based on account type. In industries, anomaly detection applications attached with machinery can help flag irregular or dangerous temperature levels or movement in parts or filter faulty materials (like filtering strange-looking food ingredients before they are processed and packed). Given that data can back the decision and sufficiently reliable data is available, anomaly detection can be potentially life-saving.\n\nEvolution of Machine Learning Applications in Finance : From Theory to Practice\n\nIn a different use case, anomaly detection machine learning algorithms can also be used for classification tasks when the class imbalance in the training data is high. For instance, one can gather images of various species of flowers and plants for a multi-class classification task. However, substantially insufficient data is likely available for one particular species, thus resulting in an imbalance in the dataset. In such a case, the model can treat that class as an anomaly and classify the species differently. This is particularly relevant for medical diagnosis where there are only a few samples (images or test reports) where the disease is present, with the majority being benign. Anomaly detection can again be a life-saver in these cases.\n\nBecome a Certified Deep Learning Engineer. Check Out ProjectPro's Deep Learning Certification Course to Validate Your Expertise!\n\nAnomaly detection finds its application in various real-world scenarios. From detecting fraudulent bank transactions to identifying irregular temperature levels in machinery, anomaly detection plays a crucial role in ensuring safety and efficiency. It can even be used in classifying rare species of plants or diagnosing medical conditions with limited data.\n\nHere are a few applications of anomaly detection using machine learning across various domains to detect anomalies and enhance operational efficiency.\n\nAnomaly detection is an important task in machine learning, and various techniques can be employed depending on the nature of the data and the availability of labeled examples. Let's explore the commonly used methods for anomaly detection in each category.\n\nHere are some commonly used techniques for anomaly detection in machine learning:\n\nLike other machine learning models, there are three main ways to build an anomaly detection model: unsupervised, supervised, and semi-supervised anomaly detection. An unsupervised model establishes a base distribution or outline of the data by looking at differences between a window of points to detect anomalies that fall away from it. This method can detect abnormalities in unlabeled datasets, significantly reducing the manual labeling of vast amounts of training data.\n\nArtificial neural network (ANNs) is probably the most popular algorithm to implement unsupervised anomaly detection. ANNs can be trained on large unlabeled datasets and, given the layered, non-linear learning, can be trusted to find intricate patterns to classify anomalies of a great variety. This is especially useful in unstructured data like images where anomalies could be any type of image other than the one trained on the model.\n\nAnother popular unsupervised method is Density-based spatial clustering of applications with noise (DBSCAN) clustering. However, these unsupervised algorithms may learn incorrect patterns or overfit a particular trend in the data. It means that these methods may not always be trustworthy since very little can be controlled or known in what they learn.\n\nThe second method is training the model in a supervised fashion, which requires the data set to be specified with anomalous or abnormal labels. Thus, the training data becomes even more critical in this case. Since the detection task is simply a binary classification task with highly imbalanced data, training a standard machine learning model might not work well. The objective would be to correctly classify the normal data points and not hunt for abnormal data. This means that the model can achieve an accuracy of 98% simply by classifying all the points as normal – even the abnormal ones. So, this is unacceptable.\n\nLastly, detecting anomalies using a semi-supervised model means the model is trained (or pre-trained) first on an unlabeled dataset to establish a precedent about the data distribution to be expected. Next, the trained model is finetuned on anomalous data to better identify the anomalies in the distribution. Thus, this method gives the model freedom to learn the underlying data distributions and the user control over the type of anomalies the model can detect.\n\nVisualizing this understanding below, based on the data (a), we can observe how various methods are able to capture anomalies. A paper on deep semi-supervised anomaly detection proposed these observations and visualizations. Unsupervised (b) learns the data space of the “normal” data comprehensively, and the abnormal data region has a fuzzy space. This means that the model will produce low confidence in detecting anomalies.\n\nIn contrast, the supervised approach (c) distinguishes the expected and anomalous samples well, but the abnormal region is restricted to what the model observed in training. Thus, out-of-distribution samples would fail to be detected. This confirms the observation that supervised models would require a reliable understanding of the type of anomalies expected in the real world.\n\nFinally, the semi-supervised model (d) captures the anomalous distribution beyond training samples.\n\nFor implementing and testing anomaly detection methods, IDS and the Credit Card Fraud Detection Systems (CCFDS) are popular anomaly detection machine learning datasets along with DAGM and industrial surface inspection for supervised training. More anomaly datasets can be accessed here: Outlier Detection DataSets (ODDS).\n\nTo summarise, unsupervised anomaly detection methods work best when you’re not aware of the type of anomalies that may occur, especially with unstructured data. Supervised is best when sufficient data is available, and the nature of anomalies is consistent with the real world.\n\nNow that we know the methods with which anomaly detection can be approached, let’s look at some of the specific machine learning algorithms for anomaly detection. We will cover DBSCAN, Local Outlier Factor (LOR), Isolation Forest Model, Support Vector Machines (SVM), and Autoencoders.\n\nThe Isolation Forest anomaly detection machine learning algorithm uses a tree-based approach to isolate anomalies after modeling itself on “normal” data in an unsupervised fashion. Like random forests, this algorithm initializes decision trees randomly and keeps splitting nodes into branches until all samples are at the leaves. Moreover, since anomalies tend to be different from the rest of the data, they are less likely to go deeper down the tree and grow in a distinct branch sooner than the rest. This isolation usually isolates the anomalies from the regular instances across all decision trees. You can find further mathematical and conceptual details in the original paper: Isolation Forest Model by Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou.\n\nThe Isolation Forest model can be found in the scikit-learn package in Python. In sklearn. ensemble, we have the IsolationForest() class. The parameters include n_estimators for the number of trees, max_samples to build trees on, and the vital contamination factor, which signifies the ratio of abnormal data in the training data. The contamination factor requires the user to know how much anomaly is expected in the data, which might be difficult to estimate. This is a drawback of this method. Another drawback from using decision trees is that the final detection is highly sensitive to how the data is split at nodes which can often be biased.\n\nDBSCAN or Density-based spatial clustering of applications with noise is a density-based clustering machine learning algorithm to cluster normal data and detect outliers in an unsupervised manner. It clusters data points based on continuous regions of high point density and determines the ideal number of clusters to be formed. With such a density-based approach, outliers remain without any cluster and are, thus, easily spotted. In contrast to k-means, not all points are assigned to a cluster, and we are not required to declare the number of clusters (k). However, the two key parameters in DBSCAN are minPts (to set the minimum number of data points required to make a cluster) and eps (allowed distance between two points to put them in the same cluster).\n\nThe algorithm works as follows:\n• As long as there is no point unvisited, a new point is chosen randomly.\n• All the points within eps distance from the current point are of the same cluster.\n• The algorithm recursively continues on each of these last visited points to find more points that are within eps distance from themselves.\n• If minPts points are collected, then a cluster is officially formed.\n• Once a cluster is formed, and no more points can be added, the algorithm chooses another point randomly from the ones that haven’t been visited yet.\n\nThe first image shows the DBSCAN algorithm starting randomly at one of the outer points and moving recursively on two paths along the circle’s circumference. Since these points are within eps distance of their nearest neighbor, they are assigned to the same cluster. Similarly, as shown in the following figure, other clusters are formed. Once the algorithm converges, the outliers are identified as the points that do not belong to any cluster. Some of them are highlighted in the image.\n\nSince distance is a crucial metric of clustering here, the anomaly detection machine learning dataset must be clean and normalized. In Python, sklearn can again come in handy to implement DBSCAN quickly. The sklearn.cluster subpackage has a DBSCAN module.\n\nAfter fitting the model, DBSCAN.labels - will contain the number of clusters formed and the number of outliers detected. DBSCAN.core_sample_indices_ returns the indices of samples that were assigned to a cluster. We can use these to get the remaining indices that correspond to the outliers found in the fitted data.\n\nThe SVM model is a supervised learning model mainly used for classification. Its ability to create subplanes by projecting data into alternate vector spaces has made ML an effective classification model. SVM works on only two classes for anomaly detection and trains the model to maximize the difference or distance between the two data groups in its projected vector space. It can also work on multi-class methods.\n\nNevertheless, anomalies are determined by checking the points lying outside the range of a category. However, in the simplest case, one-class SVM is widely used. It uses SVM to determine if a data point belongs to the “normal” class or not – binary classification.\n\nSo, SVM uses a non-linear function Ï to project the training data X to a higher dimensional space. Now, since representation has changed, the vectors that were once next to each other might be far away, which means that they can be separated more easily using a hyperplane or, in the 2D space, something like a regression line. In fact, the hyperplane equation: wTx+b=0 is visibly similar to the linear regression equation mx+b=0. Read more about SVMs and one-class SVM here: Introduction to one-class Support Vector Machines.\n\nLet’s try implementing SVM for anomaly detection in Python using sklearn. First, we import the required libraries, including scikit-learn. We also fetch the Iris flower dataset since we wish to keep things simple for this demo.\n\nTake a look at the data we’ll be working with:\n\nNow we can fit and predict outliers from this data:\n\nHere, nu stands for the estimated proportion of outliers we expect in this data. We have taken the estimation to be 5% which means that around 5% of the data is anomalous.\n\ny_pred will assign all normal points to the class “1” and the outliers to “-1”.\n\nLet’s see what they look like in a scatter plot with respect to the normal points.\n\nAnd here are the results after keeping nu=0.1, meaning that 10% of the data is anomalous.\n\nLOF is another density-based clustering algorithm that has found similar popularity and usage as DBSCAN, it is worth mentioning. However, as opposed to a global clustering method, LOF looks at the neighborhood of a given point and decides its validity based on how well it fits into the density of the locality. LOF works well since it considers that the density of a valid cluster might not be the same throughout the dataset.\n\nThus, the algorithm follows an intuitive flow: a point might be at a small distance to a very densely packed cluster. In a global clustering approach, that point would belong to that cluster, but LOF would assign that as an outlier. Since, in a relative sense, that point wasn’t as densely packed with the other points of the same cluster, it is likely to be an outlier. Things would be different if the cluster points were at a slightly greater distance from each other. However, the user loses significant control over training since the clustering dramatically depends on the data and the context.\n\nIn Python, scikit-learn provides a ready module called sklearn.neighbours.LocalOutlierFactor that implements LOF. The sklearn demo page for LOF gives a great example of using the class: Outlier detection with Local Outlier Factor (LOF).\n\nDeep learning models, especially Autoencoders, are ideal for semi-supervised learning. Typically these models have a large number of trainable parameters which need a large amount of data to tune correctly. Thus, pretraining is an excellent starting point to solve various problems. Deep neural network models are adept at capturing the data space and modeling the data distribution of both structured and unstructured datasets. Pretraining these models in an unsupervised manner mean simply “showing” the model what our data world looks like. For instance, image classification models pre-trained on ImageNet and fine-tuned on a domain-specific smaller dataset are more practical and better performing than models trained only on domain-specific datasets (even if they are large).\n\nThus, for anomaly detection, we can simply pre-train an autoencoder to teach it what the data world looks like (or what “normal” looks like). And then, we can fine-tune it using a labeled dataset that would train the model to understand what “abnormal” looks like.\n\nDuring training, an autoencoder learns by compressing (or encoding) the input data to a lower-dimensional space, thus extracting only the important features from the data (similar to dimensionality reduction). Then it learns how to use this minimal data to reconstruct (or decode) the original data with as little reconstruction error (or difference) as possible. The first part of the autoencoder is called the encoder, which reduces the dimensions, and the latter half is called the decoder, which reconstructs the encoded data.\n\nThus, once this autoencoder is pre-trained on a “normal” dataset, it is fine-tuned to classify between normal and anomalies.\n\nThis example will use scikit-learn to implement one of the many algorithms we discovered today in Python. Let’s look at a classification problem of segmenting customers based on their credit card activity and history and using DBSCAN to identify outliers or anomalies in the data.\n\nFirst, fetch the data from Kaggle at Credit Card Dataset for Clustering. Next, we import the necessary libraries and explore the data.\n\nNormalize and scale to preprocess the data as unsupervised algorithms are greatly sensitive to distance measures.\n\nBefore moving on to fit the DBSCAN model, for the sake of visualization, efficiency, and simplicity, we perform dimensionality reduction to reduce the 17 columns to 2.\n\nLet’s fit the DBSCAN model now using eps 0.05 and minPts as 10.\n\n“labels” is a vector of the same length as the number of training samples. It contains the class index for each sample, indicating the class it was assigned to. Anomalies have ‘-1’ as their class index. Below we can see how the two clusters and anomalies are distributed in the 8950 samples.\n\nWe can also visualize a similar logarithmic histogram for visual intuition:\n\nFinally, since we chose two feature columns purposefully to visualize the anomalies and clusters together, let’s plot a scatter plot of the final results.\n\nAs expected, anomalies lie in the regions with less density – typically around the edges and then towards the center, where the points are relatively scant.\n\nThese abnormal samples can be highlighted for manual review by bank officials.\n\nThus, we have implemented an unsupervised anomaly detection algorithm called DBSCAN using scikit-learn in Python to detect possible credit card fraud. Before concluding, let’s look at some other popular projects in anomaly detection that you can implement for practice.\n\nAll the code mentioned in this article can be found here: AnomalyDetection.ipynb\n\nImage classification often fails in training to categorize healthy reports such as X-Ray, CT scans, or MRIs from the infected ones simply due to lack of sufficient data. People have proposed anomaly detection methods in such cases using variational autoencoders and GANs. Some reference papers and projects are f-AnoGAN, DeScarGAN: Disease-Specific Anomaly Detection with Weak Supervision, DCGAN, or projects that propose autoencoders such as Deep Autoencoding Models for Unsupervised Anomaly Segmentation in Brain MR Images and [1806.04972] Unsupervised Detection of Lesions in Brain MRI.\n\nExample pipeline using a DCGAN to detect anomalies:\n\nBeginners can explore image datasets such as The Kvasir Dataset, SARS-COV-2 Ct-Scan Dataset, Brain MRI Images for Brain Tumor Detection, and The Nerthus Dataset. Next, you can look at various projects that use these datasets and explore the benchmark and leaderboards for anomaly detection.\n\nNetwork attacks can sneak in and disrupt a hosted application or server in a high traffic volume. Machine learning can significantly help Network Traffic Analytics (NTA) prevent, protect, and resolve attacks and harmful activity in the network. Supervised and unsupervised anomaly detection methods can be used to adversarially train a network intrusion detection system to detect anomalies or malicious activities. Firstly, you can look at some relevant projects and papers like Cybersecurity Anomaly Detection, Machine Learning Techniques for Intrusion Detection, Network AD Using RNNs. Next, datasets such as the labeled UNSW-NB15 Dataset, NSL-KDD, and BETH Dataset.\n\nIn manufacturing and packaging industries and construction, it is vital to deliver only quality goods. However, given the volume and speed of processing, anomaly detection will be beneficial to detect any deviation in quality from the normal. It is worth noting that this project can be particularly helpful for learning since production data ranges from images and videos to numeric and textual data. So, one can study a variety of algorithms and approaches while researching this problem. Papers such as CNNs for industrial surface inspection, Weakly Supervised Learning for Industrial Optical Inspection, Advances in AI for Industrial Inspection, AI for energy consumption in buildings, and others give a good review of the problem task and solutions. DAGM or the RSDDs Rail Surface Dataset can be used for these while more are available at donrax/industrial-surface-inspection-datasets. One can get started by referring to these materials and replicating results from the open-source projects.\n\nWith these anomaly detection machine learning project ideas as a starting point, you can use the theory introduced in this article and the various anomaly detection methods in machine learning to understand the problem thoroughly. We also learned to use sklearn for anomaly detection in Python and implement some of the mentioned algorithms. You can top off your learning experience by building various anomaly detection machine learning projects from the ProjectPro repository."
    },
    {
        "link": "https://tutorialspoint.com/scikit_learn/scikit_learn_anomaly_detection.htm",
        "document": "Here, we will learn about what is anomaly detection in Sklearn and how it is used in identification of the data points.\n\nAnomaly detection is a technique used to identify data points in dataset that does not fit well with the rest of the data. It has many applications in business such as fraud detection, intrusion detection, system health monitoring, surveillance, and predictive maintenance. Anomalies, which are also called outlier, can be divided into following three categories −\n• None Point anomalies − It occurs when an individual data instance is considered as anomalous w.r.t the rest of the data.\n• None Contextual anomalies − Such kind of anomaly is context specific. It occurs if a data instance is anomalous in a specific context.\n• None Collective anomalies − It occurs when a collection of related data instances is anomalous w.r.t entire dataset rather than individual values.\n\nTwo methods namely outlier detection and novelty detection can be used for anomaly detection. Its necessary to see the distinction between them.\n\nThe training data contains outliers that are far from the rest of the data. Such outliers are defined as observations. Thats the reason, outlier detection estimators always try to fit the region having most concentrated training data while ignoring the deviant observations. It is also known as unsupervised anomaly detection.\n\nIt is concerned with detecting an unobserved pattern in new observations which is not included in training data. Here, the training data is not polluted by the outliers. It is also known as semi-supervised anomaly detection.\n\nThere are set of ML tools, provided by scikit-learn, which can be used for both outlier detection as well novelty detection. These tools first implementing object learning from the data in an unsupervised by using fit () method as follows −\n\nNow, the new observations would be sorted as inliers (labeled 1) or outliers (labeled -1) by using predict() method as follows −\n\nThe estimator will first compute the raw scoring function and then predict method will make use of threshold on that raw scoring function. We can access this raw scoring function with the help of score_sample method and can control the threshold by contamination parameter.\n\nWe can also define decision_function method that defines outliers as negative value and inliers as non-negative value.\n\nLet us begin by understanding what an elliptic envelop is.\n\nThis algorithm assume that regular data comes from a known distribution such as Gaussian distribution. For outlier detection, Scikit-learn provides an object named covariance.EllipticEnvelop.\n\nThis object fits a robust covariance estimate to the data, and thus, fits an ellipse to the central data points. It ignores the points outside the central mode.\n\nFollowing table consist the parameters used by sklearn. covariance.EllipticEnvelop method −\n\nFollowing table consist the attributes used by sklearn. covariance.EllipticEnvelop method −\n\nIn case of high-dimensional dataset, one efficient way for outlier detection is to use random forests. The scikit-learn provides ensemble.IsolationForest method that isolates the observations by randomly selecting a feature. Afterwards, it randomly selects a value between the maximum and minimum values of the selected features.\n\nHere, the number of splitting needed to isolate a sample is equivalent to path length from the root node to the terminating node.\n\nFollowings table consist the parameters used by sklearn. ensemble.IsolationForest method −\n\nIt represents the number of base estimators in the ensemble. It represents the number of samples to be drawn from X to train each base estimator. If we choose int as its value, it will draw max_samples samples. If we choose float as its value, it will draw max_samples .shape[0] samples. And, if we choose auto as its value, it will draw max_samples = min(256,n_samples). This parameter tells the method that how much proportion of points to be included in the support of the raw MCD estimates. It provides the proportion of the outliers in the data set. If we set it default i.e. auto, it will determine the threshold as in the original paper. If set to float, the range of contamination will be in the range of [0,0.5]. random_state − int, RandomState instance or None, optional, default = none This parameter represents the seed of the pseudo random number generated which is used while shuffling the data. Followings are the options −\n• None int − In this case, random_state is the seed used by random number generator.\n• None RandomState instance − In this case, random_state is the random number generator.\n• None None − In this case, the random number generator is the RandonState instance used by np.random. It represents the number of features to be drawn from X to train each base estimator. If we choose int as its value, it will draw max_features features. If we choose float as its value, it will draw max_features * X.shape[] samples. Its default option is False which means the sampling would be performed without replacement. And on the other hand, if set to True, means individual trees are fit on a random subset of the training data sampled with replacement. n_jobs − int or None, optional (default = None) It represents the number of jobs to be run in parallel for fit() and predict() methods both. This parameter controls the verbosity of the tree building process. If warm_start = true, we can reuse previous calls solution to fit and can add more estimators to the ensemble. But if is set to false, we need to fit a whole new forest.\n\nFollowing table consist the attributes used by sklearn. ensemble.IsolationForest method −\n\nThe Python script below will use sklearn. ensemble.IsolationForest method to fit 10 trees on given data\n\nLocal Outlier Factor (LOF) algorithm is another efficient algorithm to perform outlier detection on high dimension data. The scikit-learn provides neighbors.LocalOutlierFactor method that computes a score, called local outlier factor, reflecting the degree of anomality of the observations. The main logic of this algorithm is to detect the samples that have a substantially lower density than its neighbors. Thats why it measures the local density deviation of given data points w.r.t. their neighbors.\n\nFollowings table consist the parameters used by sklearn. neighbors.LocalOutlierFactor method\n\nIt represents the number of neighbors use by default for kneighbors query. All samples would be used if . Which algorithm to be used for computing nearest neighbors.\n• None If you choose ball_tree, it will use BallTree algorithm.\n• None If you choose kd_tree, it will use KDTree algorithm.\n• None If you choose brute, it will use brute-force search algorithm.\n• None If you choose auto, it will decide the most appropriate algorithm on the basis of the value we passed to fit() method. The value of this parameter can affect the speed of the construction and query. It also affects the memory required to store the tree. This parameter is passed to BallTree or KdTree algorithms. It provides the proportion of the outliers in the data set. If we set it default i.e. auto, it will determine the threshold as in the original paper. If set to float, the range of contamination will be in the range of [0,0.5]. It represents the metric used for distance computation. It is the parameter for the Minkowski metric. P=1 is equivalent to using manhattan_distance i.e. L1, whereas P=2 is equivalent to using euclidean_distance i.e. L2. By default, LOF algorithm is used for outlier detection but it can be used for novelty detection if we set novelty = true. n_jobs − int or None, optional (default = None) It represents the number of jobs to be run in parallel for fit() and predict() methods both.\n\nFollowing table consist the attributes used by sklearn.neighbors.LocalOutlierFactor method −\n\nThe Python script given below will use sklearn.neighbors.LocalOutlierFactor method to construct NeighborsClassifier class from any array corresponding our data set\n\nNow, we can ask from this constructed classifier is the closet point to [0.5, 1., 1.5] by using the following python script −\n\nThe One-Class SVM, introduced by Schlkopf et al., is the unsupervised Outlier Detection. It is also very efficient in high-dimensional data and estimates the support of a high-dimensional distribution. It is implemented in the Support Vector Machines module in the Sklearn.svm.OneClassSVM object. For defining a frontier, it requires a kernel (mostly used is RBF) and a scalar parameter.\n\nFor better understanding let's fit our data with svm.OneClassSVM object −\n\nNow, we can get the score_samples for input data as follows −"
    },
    {
        "link": "https://datacamp.com/tutorial/feature-extraction-machine-learning",
        "document": "Understand the concept of reducing dimensionality in your data, and master the techniques to do so in Python."
    },
    {
        "link": "https://medium.com/@gabrielpierobon/statistical-techniques-for-anomaly-detection-part-1-parametric-and-non-parametric-tests-1801d07ba3fa",
        "document": "Part 1 of Chapter 02 from the Guide to Machine Learning for Anomaly Detection\n\nWarning! Before you continue reading this article and all the articles that compose this guide, you must understand this was in part generated using OpenAI’s GPT 4 model. It started as a self learning project and I soon enough realized this could be really valuable to fellow data scientists. Because of this, I will release the entire guide for free alongside every chapter so you can directly go read the guide from the document so you don’t even need to give me reading time if you don’t want to.\n\n0: About the generation of this guide\n\n1: Introduction to Anomaly Detection\n\n>>>>> 2: Statistical Techniques for Anomaly Detection (Part 1) <<<<<\n\n2: Statistical Techniques for Anomaly Detection (Part 2)\n\n3: Introduction to M. Learning for Anomaly Detection (Part 1)\n\n3: Introduction to M. Learning for Anomaly Detection (Part 2)\n\n4: Dealing with Imbalanced Classes in Supervised Learning \n\n5: K-Means Clustering for Anomaly detection\n\n6: DBSCAN for Anomaly detection \n\n7: Isolation Forest for Anomaly Detection \n\n8: One-Class SVM (Support Vector Machine) for Anomaly…"
    },
    {
        "link": "https://spotintelligence.com/2024/05/27/anomaly-detection-one-class-svm",
        "document": "One-class SVM (Support Vector Machine) is a specialised form of the standard SVM tailored for unsupervised learning tasks, particularly anomaly detection. Unlike traditional SVMs, which are used for classification and regression tasks involving multiple classes, One-Class SVM focuses on identifying whether a given data point belongs to a particular class or is an outlier.\n\nOne-Class SVM is designed to distinguish between normal and abnormal data points in a dataset. It does this by learning a decision boundary encompassing most data points considered normal. Any point that lies outside this boundary is classified as an anomaly. This makes One-Class SVM an invaluable tool in scenarios where the goal is to detect unusual patterns or rare events that deviate significantly from the norm.\n\nAt its core, One-Class SVM works by constructing a hyperplane that maximises the margin around the data points in the feature space. The algorithm tries to find the smallest region that can encapsulate most data points (regular instances) while considering a certain fraction of the data as outliers.\n• Training Phase: During training, the One-Class SVM algorithm takes in a dataset primarily consisting of normal data points. The model then identifies a decision boundary encompassing these feature space points. This boundary is shaped by the support vectors, the critical data points lying closest to the boundary.\n• Decision Function: The decision function determines whether a new data point falls within the normal region (inside the boundary) or outside (anomalous). Mathematically, the decision function can be expressed as: f(x)=w⋅ϕ(x)−ρ\n• Where w is the weight vector, ϕ(x) is the feature mapping of the input x, and ρ is the offset. If f(x) is greater than zero, the point x is considered normal; otherwise, it is an anomaly.\n\nWhile traditional SVMs are used for binary or multi-class classification by finding the optimal hyperplane that separates different classes, One-Class SVM takes a different approach.\n\nInstead of distinguishing between multiple classes, One-Class SVM focuses solely on identifying a single class and detecting any deviations from this class. This makes it particularly effective for applications where the primary goal is to detect outliers or anomalies within a data set.\n\nConsider a cybersecurity application that aims to detect unusual network traffic that might indicate a security breach. One-class SVM can be trained on normal network traffic data in this case. Once trained, it can monitor new traffic and flag any patterns significantly different from normal traffic as potential threats.\n\nOne-Class SVM is a powerful tool for anomaly detection, capable of identifying rare and unusual events in a wide range of applications. Learning the normal patterns in data provides a robust mechanism to detect deviations that could indicate anomalies, making it an essential technique in the toolkit of data scientists and engineers.\n\nOne-class SVM (Support Vector Machine) is widely used across various fields due to its ability to identify anomalies and outliers in data effectively. This section explores several critical applications where One-Class SVM has proven particularly valuable.\n\nAnomaly detection involves identifying data points that deviate significantly from most data. This capability is crucial in various domains:\n• Cybersecurity: In cybersecurity, One-Class SVM can detect unusual patterns in network traffic that may indicate a security breach or an intrusion. Training the model on normal network behaviour can flag anomalous activities such as unusual login attempts or abnormal data transfers, helping to prevent cyber attacks.\n• Finance: Financial institutions use One-Class SVM to detect fraudulent transactions. By modelling normal transaction behaviour, the system can identify suspicious activities, such as unusual spending patterns or unauthorised access to accounts, thereby reducing the risk of fraud.\n• Healthcare: In the healthcare sector, One-Class SVM can analyse medical records to identify anomalies that may signify potential health issues. For example, it can detect irregularities in patient vital signs or unusual patterns in diagnostic test results, aiding in early diagnosis and intervention.\n\nOutlier detection is critical in ensuring data quality and integrity. One-Class SVM helps in identifying data points that are significantly different from the rest of the dataset, which could be due to errors or rare events:\n• Data Cleaning: One-Class SVM can identify and remove outliers that may skew analysis results in data preprocessing. This ensures the dataset is clean and reliable for further processing and model training.\n• Environmental Monitoring: In environmental studies, sensors collect large amounts of data over time. One-Class SVM can detect outliers in this data, such as unusual temperature readings or sudden changes in pollution levels, which could indicate faulty sensors or significant environmental events.\n\nNovelty detection involves identifying new or previously unseen data points during the model’s deployment phase:\n• Manufacturing: In manufacturing, One-Class SVM can monitor the production process to detect new defects or faults that were not present during the training phase. This helps maintain product quality and reduce downtime due to unexpected issues.\n• Robotics: In robotic systems, One-Class SVM can detect novel situations or changes in the environment that were not encountered during training. This enables the robot to adapt to new scenarios and operate more effectively in dynamic environments.\n\nOne-Class SVM’s versatility and effectiveness make it a valuable tool across various applications. Its ability to learn from normal data and detect deviations provides robust solutions for anomaly, outlier, and novelty detection, enhancing the ability to safeguard data integrity, security, and operational efficiency across various industries.\n\nOne-class SVM (Support Vector Machine) is a powerful tool for the anomaly, outlier, and novelty detection. However, like any machine learning technique, it has strengths and weaknesses. This section outlines the key advantages and limitations of One-Class SVM to provide a balanced view of its capabilities.\n• Effectiveness in High-Dimensional Spaces: It is well-suited for high-dimensional data where traditional statistical methods might struggle. Its ability to operate in such spaces makes it a valuable tool for complex datasets, such as those encountered in text and image processing.\n• Flexibility with Non-Linear Data: It can handle non-linear relationships within the data by leveraging the kernel trick. This flexibility allows it to create complex decision boundaries that can effectively encapsulate normal data points, making it highly adaptable to various data distributions.\n• Robustness to Outliers: It is designed to be robust to a certain number of outliers. The parameter ν controls the proportion of outliers the model can tolerate, ensuring that the decision boundary is not unduly influenced by noise or anomalous data points in the training set.\n• Scalability: It can be scaled to large datasets. While the training complexity depends on the number of support vectors, which can grow with the dataset’s size, efficient implementations and the use of kernels can help manage computational demands.\n• Unsupervised Learning: It does not require labelled data for training. This makes it particularly useful in scenarios where labelled examples of anomalies are scarce or unavailable, allowing it to learn the normal behaviour directly from the data.\n• Parameter Sensitivity: One-Class SVM’s performance is susceptible to the choice of parameters, such as the kernel type and its parameters (e.g., γ for the RBF kernel) and the 𝜈 parameter. Finding the optimal parameters typically requires extensive experimentation and cross-validation, which can be time-consuming.\n• Computational Complexity: The training time can be significant, especially for large datasets with many support vectors. The computational complexity can become a bottleneck, mainly when dealing with real-time or large-scale applications.\n• Scalability Issues with Very Large Datasets: While scalable, One-Class SVM can face challenges with large datasets due to its reliance on support vectors. The memory and processing requirements can become prohibitive, necessitating approximate or distributed methods to manage the scale.\n• Interpretability: One-class SVM models can be challenging to interpret, mainly when using non-linear kernels. Understanding why a particular data point is classified as an anomaly may not be straightforward, which can be a drawback in domains where model interpretability is critical.\n• Assumption of Homogeneity: A one-class SVM assumes that most training data represent a single class (normal behaviour). However, the model’s performance can degrade in cases where the training data is heterogeneous or contains significant variations within the regular class.\n• Imbalanced Data Handling: One-class SVM is primarily designed to learn from a predominantly normal dataset. If the dataset contains many anomalies, the model might struggle to accurately delineate the normal and anomalous regions.\n\nHow To Implement One-Class SVM in Python\n\nImplementing One-Class SVM in Python is straightforward, thanks to libraries like scikit-learn. This section provides a step-by-step guide to implementing One-Class SVM, including data preparation, model training, evaluation, and a complete code example for anomaly detection.\n\nTo start, we need to import the necessary libraries. Scikit-learn provides a robust implementation of One-Class SVM, and we will also use NumPy and Matplotlib for data manipulation and visualisation.\n\nLoad and preprocess the dataset. For demonstration purposes, we will use synthetic data generated with NumPy.\n\nStandardization of data is crucial for SVM to perform well.\n\nUse the trained model to predict the test set and outliers then evaluate the performance.\n\nVisualize the decision boundary and the results.\n\nBelow is the complete code example for implementing One-Class SVM in Python for anomaly detection:\n\nThis example demonstrates implementing One-Class SVM for anomaly detection using synthetic data. It covers data preparation, model training, prediction, evaluation, and visualisation, providing a comprehensive guide for practical applications.\n\nImplementing One-Class SVM effectively requires more than just understanding the theoretical concepts and coding the algorithm. This section provides practical tips and best practices to help you get the most out of One-Class SVM in real-world applications.\n\nBefore training, analyse your data to understand its distribution. Visualise the data using histograms, scatter plots, or pair plots to identify patterns and potential anomalies.\n\nEnsure your data is properly scaled. One-Class SVM, like many machine learning algorithms, performs better when the features are standardised. Use tools like StandardScaler from scikit-learn to normalise your data.\n\nSelecting the appropriate kernel is crucial. The RBF (Radial Basis Function) kernel is often a good starting point for non-linear data. Experiment with kernels (linear, polynomial, RBF) and choose the one that best captures the underlying data structure.\n\nKey hyperparameters like gamma (for RBF kernel) and nu (which control the fraction of outliers) must be carefully tuned. Use techniques like grid or random search combined with cross-validation to find the optimal values.\n\nOne-Class SVM assumes that most training data represents normal instances. If your dataset has many anomalies, consider alternative approaches or modify it to ensure it predominantly contains normal data.\n\nIn cases of severe class imbalance, generate synthetic normal data using techniques like SMOTE (Synthetic Minority Over-sampling Technique) to balance the training set.\n\nEvaluate your model using a variety of metrics such as precision, recall, F1-score, and ROC-AUC to get a comprehensive understanding of its performance. This is particularly important for anomaly detection tasks where false positives and negatives have different impacts.\n\nUse tools like SHAP (SHapley Additive exPlanations) to interpret the model’s predictions. Understanding why a model flags certain points as anomalies can provide valuable insights and build trust in the model.\n\nAnomaly detection models, including One-Class SVM, need regular updates as new data becomes available. Continuously retrain your model with the latest data to maintain its effectiveness.\n\nImplement monitoring systems to track the performance of your deployed model. Monitor metrics such as the rate of detected anomalies and false alarms to identify when the model needs retraining.\n\nBe aware of concept drift, where the statistical properties of the target variable change over time. This can impact the model’s performance. Use techniques such as online learning or periodic retraining to adapt to new patterns in the data.\n\nConsider using techniques like mini-batch training or leveraging distributed computing frameworks to handle the computational load for large datasets.\n\nApply dimensionality reduction techniques like PCA (Principal Component Analysis) or t-SNE (t-distributed Stochastic Neighbor Embedding) to reduce the feature space, making the computation more manageable.\n\nBy following these practical tips and best practices, you can enhance the effectiveness and reliability of your One-Class SVM implementation. Understanding your data, careful parameter tuning, regular model evaluation, and maintaining computational efficiency are critical to successfully deploying One-Class SVM for anomaly detection and related tasks.\n\nOne-Class SVM is a robust and versatile tool for anomaly detection, capable of identifying outliers in high-dimensional and non-linear datasets. By understanding its theoretical foundation, leveraging its strengths, and being mindful of its limitations, you can effectively deploy it in various practical applications.\n\nIn this guide, we’ve explored the concept of One-Class SVM, delved into its theoretical background, and provided practical tips and best practices for implementation. From selecting the appropriate kernel and tuning hyperparameters to handling imbalanced data and ensuring continuous model updates, these insights are crucial for maximising effectiveness.\n\nThe Python implementation example demonstrated the steps to build, train, and evaluate a One-Class SVM model, highlighting the importance of data preprocessing, parameter tuning, and model evaluation. Following these guidelines ensures that your One-Class SVM models are accurate, interpretable, and adaptable to changing data patterns.\n\nAs you apply One-Class SVM to real-world scenarios, remember that continuous learning and adaptation are essential. Regularly updating your model with new data, monitoring its performance, and being vigilant about potential the concept drift will help maintain its accuracy and reliability over time.\n\nUltimately, One-Class SVM offers a powerful approach to anomaly detection, but its success depends on careful implementation and ongoing management. By embracing best practices and staying informed about advancements in the field, you can leverage One-Class SVM to its full potential, ensuring robust and effective anomaly detection in your applications."
    },
    {
        "link": "https://projectpro.io/article/anomaly-detection-using-machine-learning-in-python-with-example/555",
        "document": "In data science, algorithms are usually designed to detect and follow trends found in the given data. The modeling follows from the data distribution learned by the statistical or neural model. In real life, the features of data points in any given domain occur within some limits. They will only go outside of these expected patterns in exceptional cases, which are usually erroneous or fraudulent. When these exceptional cases occur, they cause something that is called an “anomaly” in the data. These data points being incorrect in real life can cause inaccurate results from the data model, inadvertently leading to faulty insight and analysis.\n\nAnomaly (or outlier) detection is the data-driven task of identifying these rare occurrences and filtering or modulating them from the analysis pipeline. Such anomalous events can be connected to some fault in the data source, such as financial fraud, equipment fault, or irregularities in time series analysis.\n\nOne can train machine learning models to detect and report such anomalies retrospectively or in real-time. These anomalous data points can later be either flagged to analyze from a business perspective or removed to maintain the cleanliness of the data before further processing is done.\n\nBelow, we can compare predictions of time-series data with the actual occurrence. As seen, the forecast closely follows the actual data until an anomaly occurs. This considerable variation is unexpected, as we see from the past data trend and the model prediction shown in blue. You can train machine learning models can to identify such out-of-distribution anomalies from a much more complex dataset.\n\nThe Need for Anomaly Detection using Machine Learning and Its Applications in Real-World\n\nIn the real world, popular anomaly detection applications in deep learning include detecting spam or fraudulent bank transactions. Systems are already in place in most major banks where the authorities are alerted when unusually high spending or credit activity occurs on someone’s account. The term “unusually high” can be defined on a user-to-user basis or collectively based on account type. In industries, anomaly detection applications attached with machinery can help flag irregular or dangerous temperature levels or movement in parts or filter faulty materials (like filtering strange-looking food ingredients before they are processed and packed). Given that data can back the decision and sufficiently reliable data is available, anomaly detection can be potentially life-saving.\n\nEvolution of Machine Learning Applications in Finance : From Theory to Practice\n\nIn a different use case, anomaly detection machine learning algorithms can also be used for classification tasks when the class imbalance in the training data is high. For instance, one can gather images of various species of flowers and plants for a multi-class classification task. However, substantially insufficient data is likely available for one particular species, thus resulting in an imbalance in the dataset. In such a case, the model can treat that class as an anomaly and classify the species differently. This is particularly relevant for medical diagnosis where there are only a few samples (images or test reports) where the disease is present, with the majority being benign. Anomaly detection can again be a life-saver in these cases.\n\nBecome a Certified Deep Learning Engineer. Check Out ProjectPro's Deep Learning Certification Course to Validate Your Expertise!\n\nAnomaly detection finds its application in various real-world scenarios. From detecting fraudulent bank transactions to identifying irregular temperature levels in machinery, anomaly detection plays a crucial role in ensuring safety and efficiency. It can even be used in classifying rare species of plants or diagnosing medical conditions with limited data.\n\nHere are a few applications of anomaly detection using machine learning across various domains to detect anomalies and enhance operational efficiency.\n\nAnomaly detection is an important task in machine learning, and various techniques can be employed depending on the nature of the data and the availability of labeled examples. Let's explore the commonly used methods for anomaly detection in each category.\n\nHere are some commonly used techniques for anomaly detection in machine learning:\n\nLike other machine learning models, there are three main ways to build an anomaly detection model: unsupervised, supervised, and semi-supervised anomaly detection. An unsupervised model establishes a base distribution or outline of the data by looking at differences between a window of points to detect anomalies that fall away from it. This method can detect abnormalities in unlabeled datasets, significantly reducing the manual labeling of vast amounts of training data.\n\nArtificial neural network (ANNs) is probably the most popular algorithm to implement unsupervised anomaly detection. ANNs can be trained on large unlabeled datasets and, given the layered, non-linear learning, can be trusted to find intricate patterns to classify anomalies of a great variety. This is especially useful in unstructured data like images where anomalies could be any type of image other than the one trained on the model.\n\nAnother popular unsupervised method is Density-based spatial clustering of applications with noise (DBSCAN) clustering. However, these unsupervised algorithms may learn incorrect patterns or overfit a particular trend in the data. It means that these methods may not always be trustworthy since very little can be controlled or known in what they learn.\n\nThe second method is training the model in a supervised fashion, which requires the data set to be specified with anomalous or abnormal labels. Thus, the training data becomes even more critical in this case. Since the detection task is simply a binary classification task with highly imbalanced data, training a standard machine learning model might not work well. The objective would be to correctly classify the normal data points and not hunt for abnormal data. This means that the model can achieve an accuracy of 98% simply by classifying all the points as normal – even the abnormal ones. So, this is unacceptable.\n\nLastly, detecting anomalies using a semi-supervised model means the model is trained (or pre-trained) first on an unlabeled dataset to establish a precedent about the data distribution to be expected. Next, the trained model is finetuned on anomalous data to better identify the anomalies in the distribution. Thus, this method gives the model freedom to learn the underlying data distributions and the user control over the type of anomalies the model can detect.\n\nVisualizing this understanding below, based on the data (a), we can observe how various methods are able to capture anomalies. A paper on deep semi-supervised anomaly detection proposed these observations and visualizations. Unsupervised (b) learns the data space of the “normal” data comprehensively, and the abnormal data region has a fuzzy space. This means that the model will produce low confidence in detecting anomalies.\n\nIn contrast, the supervised approach (c) distinguishes the expected and anomalous samples well, but the abnormal region is restricted to what the model observed in training. Thus, out-of-distribution samples would fail to be detected. This confirms the observation that supervised models would require a reliable understanding of the type of anomalies expected in the real world.\n\nFinally, the semi-supervised model (d) captures the anomalous distribution beyond training samples.\n\nFor implementing and testing anomaly detection methods, IDS and the Credit Card Fraud Detection Systems (CCFDS) are popular anomaly detection machine learning datasets along with DAGM and industrial surface inspection for supervised training. More anomaly datasets can be accessed here: Outlier Detection DataSets (ODDS).\n\nTo summarise, unsupervised anomaly detection methods work best when you’re not aware of the type of anomalies that may occur, especially with unstructured data. Supervised is best when sufficient data is available, and the nature of anomalies is consistent with the real world.\n\nNow that we know the methods with which anomaly detection can be approached, let’s look at some of the specific machine learning algorithms for anomaly detection. We will cover DBSCAN, Local Outlier Factor (LOR), Isolation Forest Model, Support Vector Machines (SVM), and Autoencoders.\n\nThe Isolation Forest anomaly detection machine learning algorithm uses a tree-based approach to isolate anomalies after modeling itself on “normal” data in an unsupervised fashion. Like random forests, this algorithm initializes decision trees randomly and keeps splitting nodes into branches until all samples are at the leaves. Moreover, since anomalies tend to be different from the rest of the data, they are less likely to go deeper down the tree and grow in a distinct branch sooner than the rest. This isolation usually isolates the anomalies from the regular instances across all decision trees. You can find further mathematical and conceptual details in the original paper: Isolation Forest Model by Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou.\n\nThe Isolation Forest model can be found in the scikit-learn package in Python. In sklearn. ensemble, we have the IsolationForest() class. The parameters include n_estimators for the number of trees, max_samples to build trees on, and the vital contamination factor, which signifies the ratio of abnormal data in the training data. The contamination factor requires the user to know how much anomaly is expected in the data, which might be difficult to estimate. This is a drawback of this method. Another drawback from using decision trees is that the final detection is highly sensitive to how the data is split at nodes which can often be biased.\n\nDBSCAN or Density-based spatial clustering of applications with noise is a density-based clustering machine learning algorithm to cluster normal data and detect outliers in an unsupervised manner. It clusters data points based on continuous regions of high point density and determines the ideal number of clusters to be formed. With such a density-based approach, outliers remain without any cluster and are, thus, easily spotted. In contrast to k-means, not all points are assigned to a cluster, and we are not required to declare the number of clusters (k). However, the two key parameters in DBSCAN are minPts (to set the minimum number of data points required to make a cluster) and eps (allowed distance between two points to put them in the same cluster).\n\nThe algorithm works as follows:\n• As long as there is no point unvisited, a new point is chosen randomly.\n• All the points within eps distance from the current point are of the same cluster.\n• The algorithm recursively continues on each of these last visited points to find more points that are within eps distance from themselves.\n• If minPts points are collected, then a cluster is officially formed.\n• Once a cluster is formed, and no more points can be added, the algorithm chooses another point randomly from the ones that haven’t been visited yet.\n\nThe first image shows the DBSCAN algorithm starting randomly at one of the outer points and moving recursively on two paths along the circle’s circumference. Since these points are within eps distance of their nearest neighbor, they are assigned to the same cluster. Similarly, as shown in the following figure, other clusters are formed. Once the algorithm converges, the outliers are identified as the points that do not belong to any cluster. Some of them are highlighted in the image.\n\nSince distance is a crucial metric of clustering here, the anomaly detection machine learning dataset must be clean and normalized. In Python, sklearn can again come in handy to implement DBSCAN quickly. The sklearn.cluster subpackage has a DBSCAN module.\n\nAfter fitting the model, DBSCAN.labels - will contain the number of clusters formed and the number of outliers detected. DBSCAN.core_sample_indices_ returns the indices of samples that were assigned to a cluster. We can use these to get the remaining indices that correspond to the outliers found in the fitted data.\n\nThe SVM model is a supervised learning model mainly used for classification. Its ability to create subplanes by projecting data into alternate vector spaces has made ML an effective classification model. SVM works on only two classes for anomaly detection and trains the model to maximize the difference or distance between the two data groups in its projected vector space. It can also work on multi-class methods.\n\nNevertheless, anomalies are determined by checking the points lying outside the range of a category. However, in the simplest case, one-class SVM is widely used. It uses SVM to determine if a data point belongs to the “normal” class or not – binary classification.\n\nSo, SVM uses a non-linear function Ï to project the training data X to a higher dimensional space. Now, since representation has changed, the vectors that were once next to each other might be far away, which means that they can be separated more easily using a hyperplane or, in the 2D space, something like a regression line. In fact, the hyperplane equation: wTx+b=0 is visibly similar to the linear regression equation mx+b=0. Read more about SVMs and one-class SVM here: Introduction to one-class Support Vector Machines.\n\nLet’s try implementing SVM for anomaly detection in Python using sklearn. First, we import the required libraries, including scikit-learn. We also fetch the Iris flower dataset since we wish to keep things simple for this demo.\n\nTake a look at the data we’ll be working with:\n\nNow we can fit and predict outliers from this data:\n\nHere, nu stands for the estimated proportion of outliers we expect in this data. We have taken the estimation to be 5% which means that around 5% of the data is anomalous.\n\ny_pred will assign all normal points to the class “1” and the outliers to “-1”.\n\nLet’s see what they look like in a scatter plot with respect to the normal points.\n\nAnd here are the results after keeping nu=0.1, meaning that 10% of the data is anomalous.\n\nLOF is another density-based clustering algorithm that has found similar popularity and usage as DBSCAN, it is worth mentioning. However, as opposed to a global clustering method, LOF looks at the neighborhood of a given point and decides its validity based on how well it fits into the density of the locality. LOF works well since it considers that the density of a valid cluster might not be the same throughout the dataset.\n\nThus, the algorithm follows an intuitive flow: a point might be at a small distance to a very densely packed cluster. In a global clustering approach, that point would belong to that cluster, but LOF would assign that as an outlier. Since, in a relative sense, that point wasn’t as densely packed with the other points of the same cluster, it is likely to be an outlier. Things would be different if the cluster points were at a slightly greater distance from each other. However, the user loses significant control over training since the clustering dramatically depends on the data and the context.\n\nIn Python, scikit-learn provides a ready module called sklearn.neighbours.LocalOutlierFactor that implements LOF. The sklearn demo page for LOF gives a great example of using the class: Outlier detection with Local Outlier Factor (LOF).\n\nDeep learning models, especially Autoencoders, are ideal for semi-supervised learning. Typically these models have a large number of trainable parameters which need a large amount of data to tune correctly. Thus, pretraining is an excellent starting point to solve various problems. Deep neural network models are adept at capturing the data space and modeling the data distribution of both structured and unstructured datasets. Pretraining these models in an unsupervised manner mean simply “showing” the model what our data world looks like. For instance, image classification models pre-trained on ImageNet and fine-tuned on a domain-specific smaller dataset are more practical and better performing than models trained only on domain-specific datasets (even if they are large).\n\nThus, for anomaly detection, we can simply pre-train an autoencoder to teach it what the data world looks like (or what “normal” looks like). And then, we can fine-tune it using a labeled dataset that would train the model to understand what “abnormal” looks like.\n\nDuring training, an autoencoder learns by compressing (or encoding) the input data to a lower-dimensional space, thus extracting only the important features from the data (similar to dimensionality reduction). Then it learns how to use this minimal data to reconstruct (or decode) the original data with as little reconstruction error (or difference) as possible. The first part of the autoencoder is called the encoder, which reduces the dimensions, and the latter half is called the decoder, which reconstructs the encoded data.\n\nThus, once this autoencoder is pre-trained on a “normal” dataset, it is fine-tuned to classify between normal and anomalies.\n\nThis example will use scikit-learn to implement one of the many algorithms we discovered today in Python. Let’s look at a classification problem of segmenting customers based on their credit card activity and history and using DBSCAN to identify outliers or anomalies in the data.\n\nFirst, fetch the data from Kaggle at Credit Card Dataset for Clustering. Next, we import the necessary libraries and explore the data.\n\nNormalize and scale to preprocess the data as unsupervised algorithms are greatly sensitive to distance measures.\n\nBefore moving on to fit the DBSCAN model, for the sake of visualization, efficiency, and simplicity, we perform dimensionality reduction to reduce the 17 columns to 2.\n\nLet’s fit the DBSCAN model now using eps 0.05 and minPts as 10.\n\n“labels” is a vector of the same length as the number of training samples. It contains the class index for each sample, indicating the class it was assigned to. Anomalies have ‘-1’ as their class index. Below we can see how the two clusters and anomalies are distributed in the 8950 samples.\n\nWe can also visualize a similar logarithmic histogram for visual intuition:\n\nFinally, since we chose two feature columns purposefully to visualize the anomalies and clusters together, let’s plot a scatter plot of the final results.\n\nAs expected, anomalies lie in the regions with less density – typically around the edges and then towards the center, where the points are relatively scant.\n\nThese abnormal samples can be highlighted for manual review by bank officials.\n\nThus, we have implemented an unsupervised anomaly detection algorithm called DBSCAN using scikit-learn in Python to detect possible credit card fraud. Before concluding, let’s look at some other popular projects in anomaly detection that you can implement for practice.\n\nAll the code mentioned in this article can be found here: AnomalyDetection.ipynb\n\nImage classification often fails in training to categorize healthy reports such as X-Ray, CT scans, or MRIs from the infected ones simply due to lack of sufficient data. People have proposed anomaly detection methods in such cases using variational autoencoders and GANs. Some reference papers and projects are f-AnoGAN, DeScarGAN: Disease-Specific Anomaly Detection with Weak Supervision, DCGAN, or projects that propose autoencoders such as Deep Autoencoding Models for Unsupervised Anomaly Segmentation in Brain MR Images and [1806.04972] Unsupervised Detection of Lesions in Brain MRI.\n\nExample pipeline using a DCGAN to detect anomalies:\n\nBeginners can explore image datasets such as The Kvasir Dataset, SARS-COV-2 Ct-Scan Dataset, Brain MRI Images for Brain Tumor Detection, and The Nerthus Dataset. Next, you can look at various projects that use these datasets and explore the benchmark and leaderboards for anomaly detection.\n\nNetwork attacks can sneak in and disrupt a hosted application or server in a high traffic volume. Machine learning can significantly help Network Traffic Analytics (NTA) prevent, protect, and resolve attacks and harmful activity in the network. Supervised and unsupervised anomaly detection methods can be used to adversarially train a network intrusion detection system to detect anomalies or malicious activities. Firstly, you can look at some relevant projects and papers like Cybersecurity Anomaly Detection, Machine Learning Techniques for Intrusion Detection, Network AD Using RNNs. Next, datasets such as the labeled UNSW-NB15 Dataset, NSL-KDD, and BETH Dataset.\n\nIn manufacturing and packaging industries and construction, it is vital to deliver only quality goods. However, given the volume and speed of processing, anomaly detection will be beneficial to detect any deviation in quality from the normal. It is worth noting that this project can be particularly helpful for learning since production data ranges from images and videos to numeric and textual data. So, one can study a variety of algorithms and approaches while researching this problem. Papers such as CNNs for industrial surface inspection, Weakly Supervised Learning for Industrial Optical Inspection, Advances in AI for Industrial Inspection, AI for energy consumption in buildings, and others give a good review of the problem task and solutions. DAGM or the RSDDs Rail Surface Dataset can be used for these while more are available at donrax/industrial-surface-inspection-datasets. One can get started by referring to these materials and replicating results from the open-source projects.\n\nWith these anomaly detection machine learning project ideas as a starting point, you can use the theory introduced in this article and the various anomaly detection methods in machine learning to understand the problem thoroughly. We also learned to use sklearn for anomaly detection in Python and implement some of the mentioned algorithms. You can top off your learning experience by building various anomaly detection machine learning projects from the ProjectPro repository."
    },
    {
        "link": "https://analyticsvidhya.com/blog/2021/04/guide-for-feature-extraction-techniques",
        "document": "What is Feature Extraction and Feature Extraction Techniques\n\nFeature extraction is the process of identifying and selecting the most important information or characteristics from a data set. It’s like distilling the essential elements, helping to simplify and highlight the key aspects while filtering out less significant details. It’s a way of focusing on what truly matters in the data.\n\nFeature extraction is important because it makes complicated information simpler. In things like computer learning, it helps find the most crucial patterns or details, making computers better at predicting or deciding things by focusing on what matters in the data.\n\n1. The need for Dimensionality Reduction\n\nIn real-world machine learning problems, there are often too many factors (features) on the basis of which the final prediction is done. The higher the number of features, the harder it gets to visualize the training set and then work on it. Sometimes, many of these features are correlated or redundant. This is where dimensionality reduction algorithms come into play.\n\nDimensionality reduction is the process of reducing the number of random features under consideration, by obtaining a set of principal or important features.\n\nDimensionality reduction can be done in 2 ways:\n\na. Feature Selection: By only keeping the most relevant variables from the original dataset\n\nPlease refer to this link for more information on the Feature Selection technique\n\nb. Feature Extraction: By finding a smaller set of new variables, each being a combination of the input variables, containing basically the same information as the input variables.\n\nIn this article, we will mainly focus on the Feature Extraction technique with its implementation in Python.\n\nThe feature Extraction technique gives us new features which are a linear combination of the existing features. The new set of features will have different values as compared to the original feature values. The main aim is that fewer features will be required to capture the same information. We might think that choosing fewer features might lead to underfitting but in the case of the Feature Extraction technique, the extra data is generally noise.\n\nThe feature extraction in machine learning technique provides us with new features, forming a linear combination of the existing ones. This results in a new set of features with values different from the original ones. The primary objective is to require fewer features to capture the same information. While one might assume that opting for fewer features could lead to underfitting, in the case of the feature extraction technique, the additional data is typically considered noise.\n\nIn simple words, PCA is a method of obtaining important variables (in form of components) from a large set of variables available in a data set. It tends to find the direction of maximum variation (spread) in data. PCA is more useful when dealing with 3 or higher-dimensional data.\n\nPCA can be used for anomaly detection and outlier detection because they will not be part of the data as it would be considered noise by PCA.Building PCA from scratch:\n• Calculate the Eigenvector & Eigenvalues for the Covariance-matrix.\n\nWe can infer from the above figure that from the first 6 Principal Components we are able to capture 80% of the data. This shows us the Power of PCA that with only using 6 features we able to capture most of the data.\n\nA principal component is a normalized linear combination of the original features in a data set.\n\nThe first principal component(PC1) will always be in the direction of maximum variation and then the other PC’s follow.\n\nWe need to note that all the PC’s will be perpendicular to each other. The main intention behind this is that no information present in PC1 will be present in PC2 when they are perpendicular to each other.\n\nPC’s are Perpendicular to each other\n\nFor this, I have used the Wine dataset. In this part, I have implemented the PCA along with Logistic regression followed by Hyperparameter Tuning.\n\na. First we standardize the data and apply PCA. Then I have plotted the result to check the separability.\n\nb. Then I have applied Logistics Regression and plotted with the help of the Decision boundary for the train and test data.\n\nc. Finally I had applied Hyperparameter Tuning with Pipeline to find the PC’s which have the best test score.\n\nWe know that PCA performs linear operations to create new features. PCA fails when the data is non-linear and is not able to create the hyperplane.\n\nThis is where Kernel PCA comes to our rescue. It is similar to SVM in the way that it implements Kernel–Trick to convert the non-linear data into a higher dimension where it is separable.\n\nIn the above figure we can see that PCA is not able to separate non-linear data but with the help of Kernel -PCA it is able to generate class-separability.\n\nPCA does not guarantee class separability which is why it should be avoided as much as possible which is why it is an unsupervised algorithm. In other words, PCA does not know whether the problem which we are solving is a regression or classification task. That is why we have to be very careful while using PCA.\n\nThough PCA is a very useful technique to extract only the important features but should be avoided for supervised algorithms as it completely hampers the data.\n\nIf we still wish to go for Feature Extraction Technique then we should go for LDA instead.\n\nThe main difference between LDA and PCA is:\n\n2. LDA =Describes the direction of maximum separability in data.PCA=Describes the direction of maximum variance in data.\n\nLDA works in a similar manner as PCA but the only difference is that LDA requires class label information, unlike PCA.\n\na. I have first standardized the data and applied LDA.\n\nb. Then I have used a linear model like Logistic Regression to fit the data. Then plotted the Decision Boundary for better class separability understanding\n\nNote: We can see that LDA is a linear model and passing the output of one linear model to another does no good. It is better to try passing the output of the linear model to a nonlinear model.\n\nFrom the above figure, we were able to achieve an accuracy of 100% for the train data and 98% for the test data.\n\nc. Thus, this time we have used a nonlinear model (SVM) to prove the above.\n\nFrom the above figure, we were able to achieve an accuracy of 100% for both the test and train data.\n\nThus we can see that passing linear input to a nonlinear model is more beneficial instead.\n\nFeature Extraction, essential for data analysis, involves techniques like Principal Component Analysis (PCA) for Dimensionality Reduction. By reducing complexity, it enhances efficiency, making it a crucial tool in extracting meaningful patterns from data for better insights and decision-making.\n\nFor the Code, implementation refer to my GitHub link: Dimensionality Reduction Code Implementation in Python\n\nHope you find this article informative. I’m looking forward to hearing your views and ideas in the comments section."
    }
]