[
    {
        "link": "https://geeksforgeeks.org/cpp-binary-search-tree",
        "document": "A Binary Search Tree (BST) is a type of binary tree in which the data is organized and stored in a sorted order. Unlike, a binary tree that doesn't follow a specific order for node placement, in a binary search tree all the elements on the left side of a node are smaller than the node itself, and elements on the right side of a node are greater.\n\nIn this article, we will learn more about the binary search tree, operations performed on BST, and implementation of BST, as well as the advantages, disadvantages, and applications of binary search tree in C++.\n\nA Binary Search Tree (BST) is a binary tree in which every node contains only smaller values in its left subtree and only larger values in its right subtree. This property is called the BST property and every binary search tree follows this property as it allows efficient insertion, deletion, and search operations in a tree.\n\nConditions for a Tree to be a Binary Search Tree\n\nFor a tree to be called a binary search, it should fulfill the following conditions:\n• None All the nodes in the left subtree of any node contain smaller values and all the nodes in the right subtree of any node contain larger values.\n• None Both the left and right subtrees of any node in the tree should themselves be a BST. This means that they should follow the BST rule.\n• None A unique path exists from the root node to every other node.\n\nIn BST, every value on the left subtree < parent node < right subtree value.\n\nFollowing are the basics terminologies used in BST:\n• Children: The successor nodes of a node are called its children.\n• Parent: The predecessor node of a node is called its parent.\n• Root: The \"beginning\" node is called the root i.e. a node that has no parent.\n• leaf: A node that has no children is called a leaf.\n\nThe following are the basics operations performed on a binary search tree:\n\nHere, we will discuss the basic three operation: search, insertion and deletion in a binary search tree.\n\nThe space complexity for all the above operations is O(n).\n\nTo search for a given key in a binary search tree, follow the below approach:\n\nIn BST a new key is always inserted at leaf and property of binary search tree should be maintained. To insert a given key in a binary search tree, follow the below approach:\n\nWe have the following 3 cases while deleting a node from BST:\n\nThe below program demonstrates all the major operations on a binary search tree: creation, searching, insertion and deletion.\n\n// Function to insert a node in the BST // If the tree is empty, return a // Otherwise, recur down the tree // Function to do inorder traversal of BST // Function to search a given key in a given BST // Base Cases: root is null or key is present at root // loop down to find the leftmost leaf // If the data to be deleted is smaller than the root's // data, then it lies in the left subtree // If the data to be deleted is greater than the root's // data, then it lies in the right subtree // if data is same as root's data, then This is the node // node with only one child or no child // node with two children: Get the inorder successor // (smallest in the right subtree) // Copy the inorder successor's content to this node // Main function to demonstrate the operations of BST \"Inorder traversal of the given Binary Search \" // check if the key is found or not \"Node 25 not found in the BST.\"\n\nThe average time complexity for all three operations on BST is O (log n). In the worst case (Skewed BST) the time complexity can become O (n). n = number of nodes.The Space complexity for all three operations done on BST is O (1). This means no extra space or memory is required to perform these operations on a BST.\n\nFollowing are the applications of binary search tree:\n• None BST can be used to find(an element) and sort a collection of elements in ascending or descending order and for in it.\n• None BSTs are used to implement priority queues where elements are inserted based on their priority number.\n• None BSTs are widely used in symbol tables inside compilers.\n• None BST can also be used to store large datasets using a particular sort key. So, searching and accessing a specific element becomes much faster.\n• None The Decision trees and rule-based systems in AI use Binary search trees.\n• None It can be used in databases for multilevel indexing.\n• None Because of the unique properties of BST, it provides an efficient way to search an element having O(log n) time complexity.\n• None The In-Order Traversal of BST is always in a sorted order. So, it becomes easier to retrieve elements in sorted order in a BST.\n• None It can adapt to various applications by defining a custom node structure.\n• None It stores only the key values, that makes them space-efficient.\n• None The performance of BST depends upon its balance.\n• None Skewed BST is the worst-case scenario where the search complexity becomes O(n), just like any other tree.\n• None Although operations like insertion and deletion are easy in BST, maintaining the balance of the tree is hard.\n• None If the tree is made by using a sorted list, then the creation can lead to a highly unbalanced BST which degrades its performance. One solution is to balance the tree after every insertion.\n• None Binary search tree become less efficient for very large datasets\n\nHow Can We Check if a Given Binary Tree is a BST?\n\nIs Binary Search Tree Should Always be Balanced?"
    },
    {
        "link": "https://stackoverflow.com/questions/5085091/binary-search-tree-implementation-in-c-stl",
        "document": "What you need is a way to look up some data given a key. With the key being an , this gives you several possibilities. Of course, you could use a :\n\nHowever, there's other possibilities as well. For example, it's quite likely that a hash map would be even faster than a binary tree. Hash maps are called in C++, and are a part of the C++11 standard, likely already supported by your compiler/std lib (check your compiler version and documentation). They were first available in C++TR1 ( )\n\nIf your keys are rather closely distributed, you might even use a simple array and use the key as an index. When it comes to raw speed, nothing would beat indexing into an array. OTOH, if your key distribution is too random, you'd be wasting a lot of space.\n\nIf you store your records as pointers, moving them around is cheap, and an alternative might be to keep your data sorted by key in a vector:\n\nDue to its better data locality, which presumably plays nice with processor cache, a simple often performs better than other data structures which theoretically should have an advantage. Its weak spot is inserting into/removing from the middle. However, in this case, on a 32bit system, this would require moving entries of 2*32bit POD around, which your implementation will likely perform by calling CPU intrinsics for memory move."
    },
    {
        "link": "https://geeksforgeeks.org/binary-search-tree-data-structure",
        "document": "A Binary Search Tree (or BST) is a data structure used in computer science for organizing and storing data in a sorted manner. Each node in a Binary Search Tree has at most two children, a left child and a right child, with the left child containing values less than the parent node and the right child containing values greater than the parent node. This hierarchical structure allows for efficient searching, insertion, and deletion operations on the data stored in the tree.\n• None Check if array is Inorder of BST\n• None Check if two BSTs have same elements\n• None BST to a Tree with sum of all smaller keys\n• None Check if an array can represent Level Order of BST\n• None Max Sum with No Two Adjacent in BST\n• None Distance between two nodes of a BST\n• None Max between two nodes of BST\n• None Two nodes of a BST are swapped, correct it\n• None Construct all possible BSTs for keys 1 to N\n• None Check given array of size n can represent BST of n levels or not\n• None K’th Largest Element in BST when modification to BST is not allowed\n• None Check if given sorted sub-sequence exists in binary search tree\n• None Maximum Unique Element in every subarray of size K\n• None Count pairs from two BSTs whose sum is equal to a given value x\n• None Find if there is a triplet in a Balanced BST that adds to zero\n• None Replace every element with the least greater element on its right\n• None Minimum Possible value of |ai + aj – k| for given array and k."
    },
    {
        "link": "https://stackoverflow.com/questions/56521133/what-is-the-most-efficient-way-to-implement-a-bst-in-such-a-way-the-findvalue",
        "document": "Yes, an \"implicit tree\" with no pointers is a good storage format if you never have to insert/delete, where position in the tree determines array index. It makes it possible to read multiple elements without the data-dependency / latency of pointer chasing.\n\nSome neat tricks you can do with this that are helpful in practice on real superscalar out-of-order x86 CPUs with caches, where throughput is much better than latency:\n• SIMD brute force the start of the search\n• software-prefetch 2 to 3 levels ahead of where you're checking now. The grandchildren of node are contiguous at . That comes from , , , . So you probably just want to prefetch at or because the rest of the nodes are probably in the same cache line.\n• Actually compare keys from 2 levels ahead, i.e. advance by 2 levels at once in the tree to fill the latency from the data dependency. (Suggested in comments by @BeeOnRope). Do a branchless search of the current and 2 child nodes, increasing memory-level parallelism by requesting all that data before making any decisions based on it. Or even extend this to looking at the 4 grandchildren, going 3 levels at a time.\n• None Instead of a strictly binary tree, use an implicit 5-ary tree. An -ary tree has keys per node that partition the child nodes into subtrees. Since you can search 4, 8, or 16 elements efficiently with x86 SIMD (to find the first element greater than your search key), you probably want a 5-ary, 9-ary, or 17-ary tree. (In general, ). You also want to check them for with SIMD, which you can do in parallel with . To find which subtree to choose, do before bit-scan on a / result. e.g. (a mask where the first is the first element that was greater than the key). But what if your key is greater than all of them, so you want the last subtree. will be all zero, but you want to give you = . Do before bitscan, instead of checking for the special case. (You might template your class on the arity of your tree.) Software prefetch is still an option here but with a \"node\" being larger (more elements) and bigger fan-out mean that you'd probably have to prefetch multiple cache lines. Branching isn't going to be good, so you're kind of stuck with the data dependency. But you have much fewer levels with instead of . x86 can multiply by 5 or 9 very efficiently with an instruction, and compilers know how to do this. (LEA can only left-shift by up to 3, so not 17). But going up the tree by dividing by a non-power-of-2 is less efficient, requiring a multiply and shift instruction for a multiplicative inverse. An -ary tree can be traversed in-order pretty easily, just like a binary tree but with a loop over nodes inside an element. Going multiple levels per step is not super useful, just increase the arity of your tree instead.\n• None Implicit quaternary tree (4-ary) with a different structure: 1 element per node (not 3), but you decide which of the 4 subtrees to descend by actually looking at all 4 child nodes, not the current node. Make each node the max (instead of median) of the subtree that it's the root of, so you're looking for the first child node > key. You can do this with SIMD + movmskps + bsf. The tree is still \"full\" so the subtrees are still balanced to have equal numbers of nodes, so this does still end in . Tricks like striding by 2 levels are still possible here, and potentially easier because of nodes being the max of their subtree. This max-tree data structure might still be in-order traversable, so it might still be useful if that's the property you wanted from a binary tree. It scales to 8-ary trees with 2x SSE2 vectors or 1x AVX2. (Or with narrower elements for more elements per SIMD vector).\n• None see below (past the section on other data structures) for another section about the CPU architecture challenges of binary searching, and data dependencies (especially with cache misses but even from L2 or even L1d cache) vs. letting branch speculation work its magic at the cost of mispredicts.\n\nYou can speed up the start of a search in your implicit tree with SIMD brute force over the first (for example) 256 bytes (4 cache lines); x86 has efficient SIMD (linear) searching. Align the start of your array by 128 bytes for efficient HW prefetch and SIMD. That will give you a starting point a few levels deep in your tree, or find an exact hit if there was one in the top few levels.\n\nThis skips directly to the 5th or 6th level of the tree, depending on how many bytes / elements you brute-force search this way. (And on the element width: narrower elements make this even better, because more fit into one SIMD vector).\n\nEach level has elements, and the sum of all the higher levels is (a number with all the bits set below bit ). So searching a power-of-2 number of elements checks a complete number of levels plus 1 extra in the next level.\n\nYou probably want to use Intel's intrinsics to manually vectorize this, like and for signed 32-bit integers. Then pack 4x 32-bit compare vectors down to 1 with 2x and 1x . This sets you up for ( ) to get a bitmap of 16 (SSE2) or 32 (AVX2) elements into an integer register. Which you can search by checking if it's non-zero, then or ( ), whichever your compiler supports. Or BMI1 .\n\nSo you use SIMD vector compares to get a vector of 0 / -1 elements. Then get that into integer bitmaps in integer registers where you can check them for non-zero or use bitscan instructions to find the first non-zero bit. x86 SIMD can do integer compare for equality or signed greater-than. (Until AVX512 adds unsigned, and your choice of comparison predicates).\n\nIf you want unsigned compares, store the tree with the unsigned values range-shifted to signed ( ), so you can do that to your key once on input and then use signed greater-than ( ), unless you can use AVX512.\n\nYou need to cover the possibility of in all levels, and also find where in the last level to stop. Use SSE2 or AVX2 ( ) for the greater-than part.\n\nYou can switch from doing a search for equality in the first half of the brute-force range (parent levels) over to doing a search for greater-than in the last half (the deepest level). There may be an off-by-one in there; make sure you account for it. It may be ok to allow overlap between the and elements.\n\nIf you have a large collection of 8-bit integer, you probably want to store it as count buckets, not a tree with each copy of the same number stored in separate bytes. (There are only 256 possible values for a byte, so any collection larger than that will have repeats).\n\nThis can be an implicit-tree of buckets, or of key/count pairs.\n\nAs discussed in comments (now moved to chat):\n\nA binary tree is usually not optimal for repeated lookups on a fixed data set\n\nTraversing the tree requires branch prediction (that can mispredict) or a data dependency that prevents out-of-order execution from working its magic. Either choice has downsides.\n\nPacking your data into a complete balanced tree is time consuming, so if you can do that you can presumably do other pre-processing to create efficient lookups. Or maybe your data is even a compile-time constant.\n\nHash tables are the standard for O(1) lookup, especially when you can ahead-of-time choose a hash function that does well for the actual data you have (i.e. compile-time constant lookup table). Finding a \"perfect hash\" function is sometimes possible, and removes the possibility of collisions. (A minimal perfect hash is even harder to find, but possible for some small sets: a function that maps to an array no bigger than the number of elements). is a hash table.\n\nHash tables don't allow any kind of ordered traversal from the element you find, though. And C++ (ordered) is typically a Red-Black tree (optimized for insert/delete as well as lookup) so it's worse than you can do with careful tuning of an implicit tree.\n\nOther options could include a bitwise Trie that goes through the bits of the key to choose left/right in a tree. Opendatastructures.org has a chapter on sorted sets. They discuss a bitwise Trie, and 2 refinements: using hashing for lookups while descending the tree, leading to in expected time instead of , where is the bit-width of your integers.\n\nOr maybe something that looks at 2 or 4 bits at once, selecting one of 4 or 16 children. (i.e. a B-tree). Although reducing tree depth with a B-tree is probably not good for in-memory data vs. other options.\n\nIf you need a tree-like data structure but not necessarily a binary tree, that might still be good. (I'm not sure if you'd still need integer compares, or if you'd just be checking pointers for non-NULL. If you did need a compare, / + to do 4 integer compares in parallel and produce a bitmap or index of first greater-than could be useful).\n\nFor future readers: if you don't specifically need this tree layout for other reasons, consider a different data structure for storing an ordered or un-ordered set.\n\nIf you have so many values that a presence/absence bitmap would be \"dense\" (and your set doesn't need to represent duplicates), that's a good option. e.g. data with more than about 8k elements means that on average 1 in 8 bits are set. Or look for the break-even in memory size, e.g. 65536 bits = 8k bytes. vs. 4k element * 2 bytes/element = 8k bytes.\n\nIn C you'd probably want to store this as an array of because that's likely to be as wide as a CPU register.\n\nProbing for an element requires only 1 memory access (and a bit-scan within the loaded dword, which x86 can do efficiently with , but in C you'd just write or and hope your compiler does that optimization instead of using a separate shift).\n\nFinding the previous/next element that is present is also efficient: use to search (forward or backward) in the bitmap for the first 16-byte chunk containing a non-zero bit. When you find it, use or on the byte you found. A good C++ specialization will do that for you, but don't count on it; The LLVM project's libc++ has a good specialization, but the libstdc++ implementation compiles to garbage. See also my comments on that blog post, including a godbolt link.\n\nTraversing this data in order is also efficiently possible. clears the lowest set bit. If it's non-zero, you can find the new lowest bit with a bitscan.\n\nIf you do need a binary tree for some reason\n\nChoose a type that's as narrow as possible to reduce the cache footprint, leading to more cache hits. x86 zero-extending loads are exactly as efficient as normal loads on modern CPUs (no extra latency for the zero-extension), or a is possible with 8, 16, 32, or 64-bit operand-size.\n\nYour implicit tree (with no pointers, just implicit or , like a heap but with the nodes sorted) is a good way to store a binary search tree.\n\nAs discussed in comments on the question (now moved to chat), branch prediction + speculative execution works as a prefetch for future loads, and the formula means that there's spatial locality between both possibilities for several levels forward.\n\nOr if you choose to use a data-dependency instead of a branch (probably not a good plan), you could SW prefetch future cache lines a few levels ahead of the one you're currently comparing, to help the HW achieve some memory-level parallelism despite the data dependency which would otherwise serialize the loads.\n\nOut-of-order exec doesn't speculate on load results. There aren't any current x86 CPUs that attempt value prediction to turn branchless into speculative, so the next load won't have its load address ready until the current load + compare + add finishes.\n\nOr if you need the binary tree version of your data for something else, you might be able to index it with another data structure that allows more efficient lookups, like a hash table that maps integers to pointers (or indices) into the array.\n\nOr maybe index one mid-way level of it with some kind of ordered data structure. That gives you a starting point for your deeper search. If checking the next/previous element(s) in the array (sibling / cousin nodes in the tree) lets us tell if the value we're looking for was in a parent level, not child, then this could be extra handy. Otherwise we'd probably want to index the upper levels of the tree, too.\n\nThat's only about twice as much data (or going one level higher for the same size).\n\nFootnote 1: A sorted array with a plain binary search is basically equivalent; the binary search algorithm computes a new array index at each step with branching or a data dependency.\n\nBut it has worse locality for the start of different searches: the first few elements that are touched as part of most searches are scattered across multiple cache lines, instead of all at the start of the array. i.e. the \"hot\" common elements have worse locality and need more cache lines to stay hot.\n\nA sorted array has good locality once binary search gets close to the right place, and at that point you probably want to switch to an SSE2 or AVX2 SIMD linear search once you find the right 16 to 64-element range spanning a cache line or two, especially if you have AVX2.\n\nThis is possible with brute force (no branching or data dependencies), just use / to compute (in an integer register) a bitmap of . Search it with or for the position of the matching element (or zero for no match). Or just check if it's non-zero if you don't care about position.\n\nThis is a simple version of what I'm suggesting for the start of a search over an implicit binary tree."
    },
    {
        "link": "https://guiprojects.com/bst-in-cpp-using-linked-lists-a-step-by-step-guide-2024",
        "document": "Before Discussing the implementation using linked lists, it’s important to have a solid understanding of the basics of binary search trees. A binary search tree is a hierarchical data structure that is composed of nodes. A value and references to its left and right children are contained in every node. There is a value in the left child node that is less than the parent node and a value in the right child node that is greater than the parent node.\n\nBinary search trees are ordered, which means the values are arranged in a specific order. This ordering property allows for efficient searching and other operations. In a binary search tree, the left subtree of a node contains values that are smaller than the node’s value, while the right subtree contains larger values.\n\nImplementing a binary search tree in C++ using linked lists\n\nNow let’s move on to implementing them using linked lists in C++. Linked lists provide a flexible and intuitive way to represent binary search trees. Instead of using pointers to the left and right children, we can use pointers to the next node in the linked list.\n\nWe first need to create a structure for the nodes to implement a binary search tree using linked lists. The node structure should contain a value and a pointer to the next node. We also need to keep track of the root node, which is the starting point of the binary search tree.\n\nThe insertion operation is one of the most important operations in a binary search tree. The ordering property must be used to determine the proper location when adding a new value to the tree. Beginning at the root node, the insertion operation moves down the tree until it comes across a space that is free to receive the new value.\n\nThe first step in using linked lists to insert a value into the binary search tree is to create a new node with the specified value. Next, we compare the value with each node as we move through the tree. We proceed to the left child node if the value is less than the value of the current node. We proceed to the appropriate child node if the value is higher. We carry on with this procedure.\n\nAnother important operation in a binary search tree is the deletion operation. When deleting a node from the tree, we need to maintain the ordering property. The deletion operation can be divided into three cases: deleting a node with no children, deleting a node with one child, and deleting a node with two children.\n\nTo delete a node from the binary search tree using linked lists, we first need to find the node we want to delete. Once we find the node, we need to handle the three cases mentioned earlier.\n\nTraversal is another important aspect of working with binary search trees. There are three common traversal techniques: in-order, pre-order, and post-order. In-order traversal visits the nodes in ascending order, pre-order traversal visits the parent node before its children, and post-order traversal visits the children nodes before the parent node.\n\nTo perform in-order traversal of a binary search tree using linked lists, we can use a recursive approach. We visit the current node, traverse the left subtree first, and then traverse the right subtree.\n\nBinary search trees can become unbalanced, leading to decreased performance for certain operations. Balancing a binary search tree ensures that the tree is evenly distributed, improving search, insertion, and deletion operations.\n\nThere are various balancing techniques available, such as the AVL tree and the Red-Black tree. These techniques involve performing rotations and adjustments to maintain the balance of the tree.\n\nAdvantages and disadvantages of using linked lists for binary search tree\n\nUsing linked lists to implement binary search trees has its advantages and disadvantages. One of the main advantages is the flexibility and ease of implementation. Linked lists allow for dynamic memory allocation, which can be beneficial when dealing with changing data. Additionally, linked lists can handle large amounts of data efficiently.\n\nHowever, linked lists also have some disadvantages. They require more memory compared to arrays because each node needs to store a pointer to the next node. Linked lists can also have slower access times compared to arrays, especially when searching for a specific element.\n\nConclusion and additional resources for further learning\n\nIn conclusion, linked lists provide a simplified way to implement binary search trees in C++. By understanding the basic concepts and following the step-by-step guide, you can optimize your code and achieve better performance. We covered the basics of binary search trees, the implementation using linked lists, key operations such as insertion and deletion, searching for a value, traversal techniques, balancing, and the advantages and disadvantages of using linked lists.\n\nIf you want to implement that in your final year project then see that post also.\n\nWe hope this guide has provided you with valuable insights and practical knowledge on simplifying binary search trees using linked lists in C++. If you have any queries related to that topic, contact us below with your queries."
    },
    {
        "link": "https://stackoverflow.com/questions/245628/c-binary-search-tree-recursive-search-function",
        "document": "So this is my search function for my BST class with a T node. x is the data being searched for within the tree, len is just the amount of nodes it has to travel to come up with the matching node if it exists. I have not implented that yet, I'm just incrementally developing my assignment. I'm calling it by doing this:\n\nv is just a vector I had to create to compare it to, and so this is just supplying it with an int. The error I'm getting:\n\nSo I'm not sure what I'm doing wrong or where I'm doing wrong."
    },
    {
        "link": "https://geeksforgeeks.org/binary-search",
        "document": "Binary Search Algorithm is a searching algorithm used in a sorted array by repeatedly dividing the search interval in half. The idea of binary search is to use the information that the array is sorted and reduce the time complexity to O(log N).\n\nBinary search is a search algorithm used to find the position of a target value within a sorted array. It works by repeatedly dividing the search interval in half until the target value is found or the interval is empty. The search interval is halved by comparing the target element with the middle value of the search space.\n• None The data structure must be sorted.\n• None Access to any element of the data structure should take constant time.\n\nBelow is the step-by-step algorithm for Binary Search:\n• None Divide the search space into two halves by finding the middle index “mid”\n• None Compare the middle element of the search space with the key\n• key is found at middle element, the process is terminated.\n• key is not found at middle element, choose which half will be used as the next search space.\n• key is smaller than the middle element, then the left side is used for next search.\n• key is larger than the middle element, then the right side is used for next search.\n• None This process is continued until the key is found or the total search space is exhausted.\n\nTo understand the working of binary search, consider the following illustration:\n\nConsider an array arr[] = {2, 5, 8, 12, 16, 23, 38, 56, 72, 91}, and the target = 23.\n\n\n\nThe Binary Search Algorithm can be implemented in the following two ways\n\nGiven below are the pseudocodes for the approaches.\n\n// Check if x is present at mid // If x is smaller, ignore right half // If we reach here, then element was not present \"Element is not present in array\" // Check if x is present at mid // If x is smaller, ignore right half // If we reach here, then element was not present \"Element is not present in array\" // Returns index of x if it is present in arr[]. // Check if x is present at mid // If x is smaller, ignore right half // If we reach here, then element was \"Element is not present in array\" # It returns location of x in given array arr # Check if x is present at mid # If x is smaller, ignore right half # If we reach here, then the element \"Element is not present in array\" // Returns index of x if it is present in arr[] // Check if x is present at mid // If x is smaller, ignore right half // If we reach here, then element was \"Element is not present in array\" // location of x in given array arr[l..r] is present, // If the element is present at the middle // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not \"Element is not present in array\" // Check if x is present at mid // If we reach here, then \"Element is not present in array\"\n\n// location of x in given array arr[low..high] is present, // If the element is present at the middle // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present \"Element is not present in array\" // location of x in given array arr[low..high] is present, // If the element is present at the middle // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not \"Element is not present in array\" // Returns index of x if it is present in arr[low.. // If the element is present at the // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not present \"Element is not present in array\" # Returns index of x in arr if present, else -1 # If element is present at the middle itself # If element is smaller than mid, then it # can only be present in left subarray # Else the element can only be present # Element is not present in the array \"Element is not present in array\" // Returns index of x if it is present in // If the element is present at the // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not present \"Element is not present in arrau\" // location of x in given array arr[low..high] is present, // If the element is present at the middle // If element is smaller than mid, then // it can only be present in left subarray // Else the element can only be present // We reach here when element is not \"Element is not present in array\" // of x in given array arr[low..high] // If the element is present // If element is smaller than // mid, then it can only be // Else the element can only // be present in right subarray // We reach here when element // is not present in array \"Element is not present in array\"\n• Auxiliary Space: O(1), If the recursive call stack is considered then the auxiliary space will be O(logN).\n• None Binary search can be used as a building block for more complex algorithms used in machine learning, such as algorithms for training neural networks or finding the optimal hyperparameters for a model.\n• None It can be used for searching in computer graphics such as algorithms for ray tracing or texture mapping.\n• None It can be used for searching a database.\n• None Binary search is faster than linear search, especially for large arrays.\n• None More efficient than other searching algorithms with a similar time complexity, such as interpolation search or exponential search.\n• None Binary search is well-suited for searching large datasets that are stored in external memory, such as on a hard drive or in the cloud.\n• None The array should be sorted.\n• None Binary search requires that the data structure being searched be stored in contiguous memory locations.\n• None Binary search requires that the elements of the array be comparable, meaning that they must be able to be ordered.\n\n3. What is the time complexity of Binary Search?\n\n4. What are the prerequisites for Binary Search?\n\n5. What happens if the array is not sorted for binary search?\n\n6. Can binary search be applied to non-numeric data?\n\n7. What are some common disadvantages of Binary Search?\n\n8. When should Binary Search be used?\n\n10. Is Binary Search always the best choice for searching in a sorted array?"
    },
    {
        "link": "https://stackoverflow.com/questions/61678175/recursive-search-in-binary-tree",
        "document": "It's quite a common beginner mistake. Your recursive function returns a node pointer, but when you make the recursive calls you ignore the return value.\n\nIt should look like this\n\nI.e. return the node found by searching in the left sub-tree, but if that is NULL then search the right sub-tree and return the node found there (if any).\n\nWhen you are writing recursive code you have to not only think about the recursive calls but also what's coming back from the recursive calls."
    },
    {
        "link": "https://geeksforgeeks.org/cpp-binary-search-tree",
        "document": "A Binary Search Tree (BST) is a type of binary tree in which the data is organized and stored in a sorted order. Unlike, a binary tree that doesn't follow a specific order for node placement, in a binary search tree all the elements on the left side of a node are smaller than the node itself, and elements on the right side of a node are greater.\n\nIn this article, we will learn more about the binary search tree, operations performed on BST, and implementation of BST, as well as the advantages, disadvantages, and applications of binary search tree in C++.\n\nA Binary Search Tree (BST) is a binary tree in which every node contains only smaller values in its left subtree and only larger values in its right subtree. This property is called the BST property and every binary search tree follows this property as it allows efficient insertion, deletion, and search operations in a tree.\n\nConditions for a Tree to be a Binary Search Tree\n\nFor a tree to be called a binary search, it should fulfill the following conditions:\n• None All the nodes in the left subtree of any node contain smaller values and all the nodes in the right subtree of any node contain larger values.\n• None Both the left and right subtrees of any node in the tree should themselves be a BST. This means that they should follow the BST rule.\n• None A unique path exists from the root node to every other node.\n\nIn BST, every value on the left subtree < parent node < right subtree value.\n\nFollowing are the basics terminologies used in BST:\n• Children: The successor nodes of a node are called its children.\n• Parent: The predecessor node of a node is called its parent.\n• Root: The \"beginning\" node is called the root i.e. a node that has no parent.\n• leaf: A node that has no children is called a leaf.\n\nThe following are the basics operations performed on a binary search tree:\n\nHere, we will discuss the basic three operation: search, insertion and deletion in a binary search tree.\n\nThe space complexity for all the above operations is O(n).\n\nTo search for a given key in a binary search tree, follow the below approach:\n\nIn BST a new key is always inserted at leaf and property of binary search tree should be maintained. To insert a given key in a binary search tree, follow the below approach:\n\nWe have the following 3 cases while deleting a node from BST:\n\nThe below program demonstrates all the major operations on a binary search tree: creation, searching, insertion and deletion.\n\n// Function to insert a node in the BST // If the tree is empty, return a // Otherwise, recur down the tree // Function to do inorder traversal of BST // Function to search a given key in a given BST // Base Cases: root is null or key is present at root // loop down to find the leftmost leaf // If the data to be deleted is smaller than the root's // data, then it lies in the left subtree // If the data to be deleted is greater than the root's // data, then it lies in the right subtree // if data is same as root's data, then This is the node // node with only one child or no child // node with two children: Get the inorder successor // (smallest in the right subtree) // Copy the inorder successor's content to this node // Main function to demonstrate the operations of BST \"Inorder traversal of the given Binary Search \" // check if the key is found or not \"Node 25 not found in the BST.\"\n\nThe average time complexity for all three operations on BST is O (log n). In the worst case (Skewed BST) the time complexity can become O (n). n = number of nodes.The Space complexity for all three operations done on BST is O (1). This means no extra space or memory is required to perform these operations on a BST.\n\nFollowing are the applications of binary search tree:\n• None BST can be used to find(an element) and sort a collection of elements in ascending or descending order and for in it.\n• None BSTs are used to implement priority queues where elements are inserted based on their priority number.\n• None BSTs are widely used in symbol tables inside compilers.\n• None BST can also be used to store large datasets using a particular sort key. So, searching and accessing a specific element becomes much faster.\n• None The Decision trees and rule-based systems in AI use Binary search trees.\n• None It can be used in databases for multilevel indexing.\n• None Because of the unique properties of BST, it provides an efficient way to search an element having O(log n) time complexity.\n• None The In-Order Traversal of BST is always in a sorted order. So, it becomes easier to retrieve elements in sorted order in a BST.\n• None It can adapt to various applications by defining a custom node structure.\n• None It stores only the key values, that makes them space-efficient.\n• None The performance of BST depends upon its balance.\n• None Skewed BST is the worst-case scenario where the search complexity becomes O(n), just like any other tree.\n• None Although operations like insertion and deletion are easy in BST, maintaining the balance of the tree is hard.\n• None If the tree is made by using a sorted list, then the creation can lead to a highly unbalanced BST which degrades its performance. One solution is to balance the tree after every insertion.\n• None Binary search tree become less efficient for very large datasets\n\nHow Can We Check if a Given Binary Tree is a BST?\n\nIs Binary Search Tree Should Always be Balanced?"
    },
    {
        "link": "https://medium.com/@siddharthgupta555t/finally-understanding-recursion-and-binary-search-trees-857c85e72978",
        "document": "Hi guys, my name is Sid, and like you, I am a computer science enthusiast. This is my first tutorial in data structures. Today, I want to go over a popular data structure, known as the Binary Search Tree, or BST. To first understand this structure, we must first understand a key concept in math, art, and computer science, known as recursion.\n\nFirst, we see how a computer manages the things it has to do in order, using a data structure known as a stack.\n\nLet’s start out with an example. Below I have a program that creates a function called , which just returns the second function created, . In the last line of this script, the function ‘ ’ is CALLED. And this my friends, activates the call stack of the program. According to our program, the first thing that our program must do is , becaused it was called first. So we go throught the function step by step.\n\nWhat is telling the computer to do now is to return the function . And this causes our list of priorities to change. In order to complete , we have to complete the function . This adds a new stack to our call stack. Previously, the top stack on the call stack was the function.\n\nNow we jump into the function . What this function does is it RETURNS the string ‘Hello’. Thats it. This function has done what it has to do, which was return a value for the stack below it, or in other words give something for the function to return. And voila, our program is finally complete and it returns the string ‘Hello’, and like that we ‘pop’ all of the layers in our call stack.\n\nThis example explains HALF of what recursion is. Now it is time to delve into the other half. Recursion basically means when a function CALLS ITSELF. We understand what it means to call a function, but what happens when a function calls itself? We will explain this using a famous example, known as calculating the factorial of a number. The factorial of a number is when you multiply a number with all the numbers below it. It looks something like this:\n\nBut wait !? Isn’t the factorial of 5 basically multiplying 5 by the factorial of 4? And that is absolutely right. What the expression above is basically this. And now this is where we solve the factorial of 5 recursively using our call stack:\n\nWhy did we stop at factorial of 1? Well, the factorial of 1 is 1. In recursive programs, this is often known as the BASE CASE. The base case is basically a parameter, or input you pass into the function, which is always true or trivial. Now that we know the factorial of 1, we can ‘pop’ this call stack. And so we find out that the factorial of 5 is 120. I have also written a snippet of code which you can try out.\n\nFrom these two examples, you should now be able to gain an understanding of recursion. Recursion is a really useful tool, as it lets us solve big problems as a bunch of ‘sub-problems’. Recursion is a tool that is used a lot in Divide and Conquer programming paradigms, which we will see in the future. Now let’s talk about Binary Search Trees.\n\nA binary search tree is a data structure that serves as a collection of nodes. A node is an object that has three attributtes. They are:\n• The data: A variable that stores the data in the node ie, a number\n• Left connection: A variable that can store another node\n• Right connection: A variable that can store another node\n\nThese nodes can then be arranged to form a Binary Search Tree, a collection of nodes:\n\nSince each node is an ‘object’, we can create a class for the node. Below is the implementation for the we will be using throughout this tutorial. As you can see, each node initializes itself with a value (data), and sets it’s left and right childs as FOR THE TIME BEING. The first node of a tree is called the ROOT node. If you notice, the tree data structure looks like an upside down tree. That is why this node is called the root. In the case of the tree above, the root node is 8.\n\nNow you may be asking yourself, why did we learn about recursion in order to learn about trees? Well, this is because a tree is what I call a recursive data structure. What do I mean by this? Look at the trees below. They are the same tree. Remember how we defined recursion as solving sub problems of a bigger problem. Look at the tree on the right. It looks like a tree, made up of smaller subtrees, and those sub-trees are also made up of sub-trees. And that is why recursion is so important when understanding trees. Eventually, recursively, we get to a point where the ‘sub trees’ are just nodes. which is why the node is so important in the tree as well.\n\nNow lets look at one of the methods used in BST’s, called insertion.\n\nThe first method of the Binary Search Tree that we will be discussing about is how to insert nodes. One of the key things about the binary search tree that makes it so speacial is that the LEFT CHILD of every node is LESS than or equal to the data in the ROOT node, and the RIGHT CHILD of every node is greater than the data in the root node. We organize the nodes in this way because it will allow us to do something pretty useful, which we will see in the next sections.\n\nIf every node can only have two children, and we want to INSERT another node, what do we do? We use recursion.\n\nIf we encounter a value that is LESS than the root node, we travel down to the LEFT child of the root node and compare with the data stored in that node. Again, if the value is less than the current node, we go left, else we go right, UNTIL we encounter a situation where we have to go left or right and there IS NO CHILD, or the left/right node of the current node is set to . That is where we wil create a new node and strore the value. Below is an illustration of the topic and the python implementation of insertion.\n\nIn this, the base case is when the left/right node of the current node is and we can fill it up, and the recursive case is when the value is less/greater than that of the current node but the corresponding child for the node is already filled up with another node, and so we travel down to that node and repeat the process.\n\nNext up we will be talking about searching for a particular value in a BST. When we are searching for a value in a Binary Search Tree, we again have to use recursion. And with the way a Binary Search Tree is arranged, it is actually pretty efficient to search through.\n\nConsider the following example. Below I have a tree and I want to search for the value 19 and since it is a tree I have to start from the top/root.\n\nSince 19 is less than 27, I know that there is no way it is in the right child of the root node, because only values greater than 27 can go in the right. That means I have to search in the left, as only values greater than or equal to 27 can go there. So now we are at 14. 19 is greater than 14, so that means we look in the right. And what do you know, we have found 19. This structure, or method of finding nodes works because if the value we are trying to find is greater than the data in the current node and the right child of the node has a child (another node), than it shows us that there is some possibility that the value we are trying to look for exists, because we have not finished looking through the tree. Same logic applies to the left side. Else, if we are in a situation where the value we are looking for is greater than the data in the current node but that node does not have a right child, than we can conclude that the node does not exist. Because there is no possibility that the value we are trying to look for exists in those BOUNDS.\n\nHold up, wtf are bounds!? Well lets look back at the example above. When we are looking for 19, the first thing we are saying is “Ok, 19 is less than 27, and since there is a left child, it means that any numbers between -∞ and 27 MAY exist in the left subtree”. And what do you know, 19 exists in that range of numbers. Now we look at 14, and since 19 is greater than 14 and there is a right child to the node, we can say “Ok, this means that any numbers between 15 and +∞ MAY exist in this right subtree”. And finally we find 19.\n\nIf we were looking for, lets say 20 in the same tree, and we repeat the same process, we would not find it. This is because we will end up at 19, which does not have any children, and we will be saying “Ok, if there is no right child, then that means that nothing 19 and +∞ exists in this right subtree. Hence, this does not exist”. And this is absolutely right. Below is the code for searching:\n\nThis method is called Binary Search, and you may have heard of this algorithm before. This is because it can already be used in a sorted array, which leads me to my third method for our BST.\n\nSince the left child of every node consists of nodes less than the current node, we can conclude that the leftmost node in a tree is the smallest node in the tree, and the rightmost node in a tree is the biggest node in the tree. But what about the nodes ‘in between’ the minimum and maximum?\n\nIf the leftmost node is the smallest node, than its root node will be the second smallest node in the tree, becasue that would be the ‘next greatest’ node in the tree. On the other side of the root node (right side), will be the third greatest value in the node. BUT REMEMBER! By leftmost/rightmost, we mean to say that the left/right child of that node is set to . So in the tree below, the leftmost node would be 1 and the right most node would be 14:\n\nBut what does this all mean, and why is it helpful? Knowing these things allows us to print the binary tree as a sorted list. Sorted list means that all values in the list are arranged from least to greatest.\n\nRemember how we talked about how a tree is a recursive structure, because it is made up of many subtrees? Well, this property will come in handy. To print out a sorted list, we first have to travel to the smallest node in the tree recursively. As we are travelling down recursively, we keep adding more stacks to our call stack. When we get to it, we print the data stored in the node, and then we check if the minimum node has any right children, by seeing if it is set to or not. When we are done with checking both children, we simply ‘pop’ this stack, and move on to the next layer on the call stack.\n\nNow we do this process for each of the ‘sub-trees’ of the node, and in the end we get list of numbers in sorted manner that are in the tree. Remember, when we solve this problem for each subtree, we are basically solving a small part of a bigger problem.\n\nLets do an example with the tree on the left. We start with the node 8, and we keep travelling down until we hit a node with no left child, in this case 1. We then print 1, and move up to 3, after realizing that the node 1 does not have a right child. We print out 3 , and then check if it has a right child. 3 has a right child, and so we travel to the smallest node in the right sub tree of 3, and we reach 4. 4 does not have any children, so we move back up to 6, and print 6, and this process keeps going on, until we come back to the root node at 8, and only have one layer in the call stack. We then print 8, and check if the node has a right child. And so this process starts over for the whole right side of the tree. Here is the code, and this is one of the problems in which doing out an example of this algorithm makes sense, or just looking at the code and getting it:\n\nThis code will print out the binary tree in sorted manner, and this is known as inorder traversal. There are two other forms of traversal, known as preorder and postorder, but in my opinion inorder is the most useful because sorting something that is always useful when dealing with real-world problems.\n\nAh, this is the one. This is the one method that really requires some thinking. When we first read the title of this section, we may think to ourselves that “Oh, lets just find the node using our method, and then replace it’s data with “.Well, it’s not that simple. When we are replacing the data in the node with , we are not deleting the actual existence of the node from memory. We are just saying that this node will store , but the node will still exist. This can mess up a whole lot of things in the tree, and it will not preserve it’s fundamental property of the left node being less than the root node and the right node being greater than the root node. Going through all the things that can go wrong by using this method is out of the scope of this tutorial, but just remember that it is not actually deleting.\n\nDeletion is a big topic in BST, so lets start simple. Suppose we want to delete the node 4 from the binary tree below. What we first do is we travel to the node by searching for it, and then we check if it has any children. In this case, 4 does not have any children, and therefore we can delete it without having to take care of any ‘loose strings’. We delete 4 by looking for a node that has 4 as one of it’s nodes, and then we set that child equal to . This is the trick when dealing with deletion! We will call this process of deleting a node with no children the base case in the algorithm.\n\nNow let’s look at the next case of the deletion. This is when the node we are trying to delete has a child node as well. This is a little bit more tricky, as we can certainly not set the data in the node equal to , nor can we use the trick we discussed about before. We could however replace the data in that node with the node’s successor/predecessor.\n\nA node’s successor is the node that is right after the node when we have a sorted binary tree. For example, in a list of numbers from 1–10, the successor of 1 is 2. The successor of a node is always found in it’s right subtree, and it is the smallest value in the right subtree (minimum). When we find it, we can just copy the data from the successor onto the node we want to delete. If the succesor node does not have any children, than we simply remove the node by applying the base case (we just talked about this), and we will be starting from this from the right child of the node that was supposed to be deleted at first. This will successfully delete a node from the tree, and you will also be able to print the tree out in sorted manner. If the succesor node has any children, then we will repeat this method, you guessed it, recursively on the original successor node of the node we actually want to delete. This process will keep going on until we hit the base case.\n\nThis same logic applies to the predecessor. The only difference is that the predecessor is the node right before the node we want to delete when we are printing it out in a sorted manner. We now look for this node in the left subtree of the node we want to delete, and it is the biggest node in the subtree (maximum). We then repeat the same process as for the successor node if we find a child for the predecessor node. Else, we perform the base case starting from the left node of the original node we wanted to delete.\n\nFinally, if the node we want to delete had two children, we look for the successor of the node. We can look for the predecessor if we want, but it really does not matter, as the binary tree is still preserved. So here is the code. This one was definetly the longest one to write.\n\nAnd yeah, those are some of the basic operations of the binary search tree, and a pretty nifty introduction into recursion. I loved writing this tutorial, as it helped me learn so much on the way aswell, and I hope it helps you too. Before you leave though, there is just a little more code. This one just encompasses the data structure into one which can be used to play around with.\n\nIn my next post, we will be learning about the time complexity of the different operations in the Binary Search Tree. If you do not know what that means, I do not either, so lets learn about it together."
    }
]