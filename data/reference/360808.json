[
    {
        "link": "https://jsonlint.com/mastering-json-format",
        "document": "Mastering JSON Format: Advantages, Best Practices and Comparison with Other Data Formats\n\nJSON, standing for JavaScript Object Notation, is already a big player in today's era of data interchange. I'll delve into what makes JSON so standout. It's a text-based, language-independent format that allows for the easy and structured exchange of information. Boasting simplicity and being exceptionally lightweight, JSON is king when it comes to data transfer across your favorite web applications.\n\nOne undeniable charm of JSON is its compatibility. It's like that friend we all need — flexible and gets along with everyone. Whether you're coding in Python, JavaScript, or C++, JSON functions seamlessly across these and many more languages. Importantly, its plain text nature makes it readable to both humans and machines.\n\nThe beauty of JSON lies in its structure. Information is stored in a \"key: value\" pair format, which in essence is like a collection of Lego blocks. These 'blocks' or data objects can be assembled in various ways to form meaningful data structures.\n\nAn example of a simple JSON object could be:\n\nThis structure makes JSON adaptable and extendable. You can add, modify, and delete key-value pairs without disrupting the system, offering unparalleled flexibility in data storage.\n\nIn addition to supporting these object structures, JSON also supports arrays (ordered sequence of values), which further simplifies complex data representation. For instance, if you wanted to add job details for John Doe, it’d look something like this:\n\nLeveraging the power of arrays and objects, JSON can efficiently store virtually any data structure. Indeed, it is the backbone that drives today's internet, actively shaping the ways we store, retrieve, and process data.\n\nLooking into the wonderful world of JSON, it's clear there are a multitude of benefits when using this format. Let's dive deeper into why JSON makes such a significant impact in data interchange.\n\nFirstly, simplicity and readability play a key role in JSON's popularity. The structure is easy-to-follow, mimicking a simple key-value pair that anyone, coder or not, can grasp. It's this simplicity that helps developers quickly read, write or edit the data - a feature that doesn't go unnoticed in the fast-paced world of technology.\n\nJSON also shines in its compatibility with various programming languages. Languages such as JavaScript, Python, Ruby and many others natively support JSON. What does this mean? Simply put, JSON can readily integrate with these languages without any need for additional libraries. Now that's efficient.\n\nAnother winning feature of JSON is its support for arrays and objects. This ability to handle complex data through a recognized syntax makes JSON superior in data representation to many other formats. Whether you're dealing with multi-level arrays or nested objects, JSON has you covered.\n\nOne more advantage of JSON to highlight is its lightweight nature. JSON's format, without the need for end tags or closing tags, leads to reduced data redundancy and less data overall. This means faster data transmission and smoother execution – an essential requirement in today's digital age.\n\nIn this internet era, JSON's importance in shaping how data is stored, retrieved, and processed is undeniable. From simple inventory lists to intricate game data, JSON delivers with reliability and flexibility.\n\nAs we delve further into the nitty-gritty of JSON, it's paramount we draw comparisons between JSON and other data formats. Two main competitors of JSON that come to mind are XML and CSV. Understanding where JSON stands in relation to these will help define its unique value more accurately.\n\nXML, just like JSON, is human-readable and used widely for data exchange. But where JSON really shines is in its simplicity. Rather than the verbose and complex syntax of XML that can quickly clutter your screen, JSON stays minimal and clean, something I absolutely appreciate. JSON's format is also more condense which leads to quicker data transmissions.\n\nWell, then we have CSV. While it's true that CSV files are typically smaller, they lack the depth of JSON. In a CSV, it's challenging to represent hierarchical or multi-dimensional data. JSON, on the other hand, as we discussed earlier, has robust support for arrays and objects. It's like comparing a black-and-white photo to a 3D movie; the depth that JSON provides far outshines a mere CSV's capabilities.\n\nLet's not forget one of JSON's formidable advantages - compatibility with various programming languages. XML requires parsers to be readable in different programming languages, and CSV files often need custom parsing solutions, both of which can be cumbersome for developers. With JSON, that isn't necessary - it's supported natively in many programming languages, easing integration and reducing development time.\n\nBut before we lean too far into JSON's corner, it's worth mentioning that there are scenarios where other formats may be more suitable. Binary formats like Protobuf or Avro might provide better performance for massive or complex datasets. The world of data formats isn't black and white - there are shades of grey that give room for all, each with its own use cases.\n\nMoving forward, we'll dissect how JSON is leveraged in web development, and its role in shaping APIs. By highlighting its advantages and pointing out certain usage pitfalls, this deep dive into JSON seeks to arm you with the knowledge to efficiently utilize JSON in your own projects.\n\nUnderstanding the syntax is fundamental to appreciating JSON's beauty. It's this simplicity and readability that make JSON a desirable format. JSON structures data in name-value pairs, much like a JavaScript object. Yet, it's not limited to a particular set of programming languages. Its universal syntax is what allowed me to integrate it in various environments easily.\n\nThe first thing to look at is data types that JSON supports. It can handle simple data types like strings, numbers, and Booleans – true or false. At the same time, it embraces compound types such as arrays and other JSON objects. Being adept with these data types can make the information representation more effective.\n\nLet's take a look at a JSON object:\n\nIn this JSON object, you can see different types of data. The name is a string, the age a number, isVaccinated a Boolean, and familyNames an array of strings.\n\nWhen it comes to arrays, they are enclosed in square brackets. Each value is separated by a comma. Here's an example of a JSON array:\n\nThis array represents a list of people, each person being a JSON object itself.\n\nNext, we'll discuss how the JSON format shapes the landscape of web development, and how it’s used in creating user-friendly and feature-rich APIs. For developers seeking to use JSON in their projects, gaining a good grasp of the format and its syntax will be time well spent.\n\nParsing JSON data is a crucial skill in web development, making it an area that I must delve into due to its immense importance. It's necessary to understand that the process varies depending on the programming language you're using. In this regard, let's look at parsing JSON data using two popular languages, JavaScript and Python.\n\nParsing in JavaScript is straightforward. JavaScript natively supports JSON through the JSON object. To parse JSON using JavaScript, developers use the JSON.parse() method, converting the JSON data into a JavaScript object.\n\nIn this JavaScript example, we are converting a JSON string into a JavaScript object using the JSON.parse method. The alert function then displays the name value, \"John\".\n\nParsing in Python, on the other hand, requires the python 'json' library. Developers invoke the json.loads() method to parse JSON data.\n\nIn our Python example, after importing the json module, we invoke the json.loads() function to parse the JSON data into a python dictionary. The print function then outputs the name value, which is \"John\".\n\nTake note that converting JSON data into another data structure (for instance, a Python dictionary or JavaScript object) is called deserialization. It's an essential part of using JSON format in web development, allowing you to process the data as per your needs. As you work with JSON, remember to keep the syntax rules in mind to ensure data integrity. The ease with which JSON integrates into your coding process is what makes it a front runner in data interchange formats.\n\nMoving onward, let's delve into a crucial element associated with JSON - that's right, we're talking about JSON schema validation. This integral feature of JSON ensures code standardization, guarantees the integrity of data, and promotes a smooth coding process.\n\nSo what is JSON schema validation? Essentially, it's a powerful tool that validates your JSON data and checks if it adheres to the predefined specifications. And yes, it does all of this before you import that data into your JavaScript or Python environments, saving you from potential headaches.\n\nHere's how it works. When you're transferring data between applications using JSON, the data structure should be predictable and standardized. JSON schema validation, as its name suggests, is like a blueprint or a model for your data. It outlines what your data should look like - what elements it should contain, what data types those elements should be, whether certain fields are required or optional, and even the acceptable range of values for certain elements.\n\nApplying JSON schema validation can significantly improve your overall coding experience. It enables you to catch and address inconsistencies and errors early on, reducing debugging efforts. It helps maintain consistent data structures across multiple applications, which really comes in handy for large-scale projects involving various teams.\n\nTake a look at this simple example of JSON schema:\n\nIn this example, the schema defines an object that needs to have two properties, and . should be a string, whereas should be an integer and cannot be a negative value.\n\nNow that we've understood the concept of JSON schema validation, we'll be moving onto another exciting topic- creating custom JSON schemas. This will require another deep dive and you'll need your concentration caps on for this one. So, let's proceed...\n\nBest Practices for Using JSON\n\nJSON format is intuitive and offers a lot of flexibility, but to get the most out of it, it's crucial to follow certain best practices. These practices streamline the coding process, aid readability and optimize data interchange.\n\nFirst, always keep the JSON structure clean and organized. JSON data is represented in name-value pairs, meaning proper structuring ensures data integrity. It's easy to fall prey to messy code when dealing with complex data, so I emphasize consistency and neatness.\n\nSecondly, utilize JSON schema validation to its fullest extent. As explained before, JSON schema validation ensures code standardization and aids in catching inconsistencies early. A well-implemented validation process helps maintain the robustness of data interchange.\n\nIn addition, when dealing with large strings of data, it's better to use arrays rather than multiple name-value pairs. Data arrays in JSON are simple to understand and can hold data more efficiently than multiple name-value pairs.\n\nWhen creating custom JSON schemas for complex data, remember to keep things as simple as possible. Simplicity is the key to meaningful data representation in JSON.\n\nBelow, I've compiled a basic guide to JSON best practices:\n• Maintain clean, organized structure: Do this by using consistent name-value pairs and avoid nesting data unnecessarily.\n• Use arrays for large strings of data: Arrays are easier to manage and are intuitive for other developers.\n\nThese practices don't just apply to JSON -- they're a solid foundation for any data interchange format. The true power of these principles shines through when they're used consistently throughout a project. Get into this habit, and you'll see a marked improvement in your coding efficiency. While working with JSON, you'll soon discover other practices that can boost your experience - shaping and tailoring these guidelines to your workflow is equally important.\n\nIn the next section, we'll delve into comparing JSON with other data interchange formats - looking at where JSON stands out and where it might not be the best option. That's for another discussion though, so let's place the bookmark here.\n\nSo we've seen how JSON's simplicity and readability make it a powerful tool for data interchange. Its schema validation feature is a game changer, ensuring code standardization and catching errors early. I've shared some best practices for using JSON, like maintaining a clean structure, using arrays for large data strings, and keeping schemas simple. Remember, these aren't exclusive to JSON and can be applied to other data interchange formats too. In the next section, we'll dive into how JSON stacks up against other data formats. Stay tuned!"
    },
    {
        "link": "https://reddit.com/r/gamedev/comments/wwr4pr/how_do_you_abstract_soft_data_for_your_games",
        "document": "Think of a game like The Sims, Cities: Skylines, or Factorio: lots of attributes, lots of attributes that interact with each other, lots of modifiers, lots of items, lots of interactions, etc.\n\nIt turns out that, at my attempts, I always struggle to see the \"big picture\" on how to build an architecture that is gentle to me when I want to introduce a new attribute or item that may interact with the external world or with other attributes/items. To be crystal clear with you, I'm mostly failing at being able to introduce new stuff at some point later on in development.\n\nI know; starting fresh is naturally easier than scaling, no matter what patterns we're implementing etc, however, I'm really curious to see how fellow developers approach their items/attributes/modifiers systems architecture-wise so maybe I can get some inspiration to relieve the pain.\n\nThings I am not looking for:\n• The best format to store data (JSON, CSV, YML);\n\nThings I am looking for:\n• How you'd go to make an attribute change based on another;\n• How you'd go to make an item know its raining in the game;\n• Conceptual things around these subjects, mostly."
    },
    {
        "link": "https://reddit.com/r/gamedev/comments/1122n2v/how_do_you_organize_data_xmljson_or_directly_in",
        "document": "Just curious what are your preferred methods to organize data in your game.\n\nSay you are making an RPG and need to store races, classes, item types, monster types, etc. The type of data you want to store is just strings and numbers. I'm not talking about graphics, models or such. Only data.\n\nYou can do the following:\n• Create XML/JSON files and load them at runtime into some kind of data structure with ID based lookup\n• Define everything directly in the code to give you static typing when working with those objects\n\nPlease share what is your preferred way to handle it :)\n\nEdit: I'm personally using C#, so I look at this problem from this angle. But it obviously applies to other languages as well.\n\nPS - I'm not asking for advice, just curious what other people do and what considerations you have when choosing a particular option."
    },
    {
        "link": "https://stackoverflow.com/questions/21912088/json-data-structure-json-to-objects-best-practice",
        "document": "I am struggling with my web-application design using JSON, ASP.NET, typescript/javascript and AngularJS.\n\n\n\nIn Short: I need a best-practice for sending data from the server to a client via JSON, using the JSON-string on the client side to create objects.\n\n\n\n\n\nI have a WebServerAPI project (ASP.NET) with the following structure:\n\nThe id of each model class belongs to an id in a database table (primary key).\n\n\n\n\n\nThe Get() Method of the DataController returns a JSON result.\n\n\n\n\n\nThe JSON result looks like the following:\n\nAs you can see in the JSON data some As share the same Types. Although this is valid JSON, I wonder if this is the best practice to send data. \n\n\n\n\n\nWouldn't it be better to send something like this:\n\nSo we get only the Id of the Type. But then we have to request all available Types to identify which Type has to be set in the corresponding As. Which may be bad? I think this might be slow, because I have to send two queries.\n\n\n\n\n\nA third option may be sending all available Types and the As in the same JSON result.\n\nSo I am wondering if there is a best-practice for this. Sending the same object (Type) over and over again as a nested object in A seems quite \"stupid\".\n\nEspecially if I convert the JSON-string into Typescript objects.\n\n\n\n\n\nWithout any \"storage/cache\" logic I create the \"same\" object over and over again:\n\n\n\n\n\nCreating different objects which represent the same Types seems just wrong. Because I work a lot with references in other languages (C#, Java, C++). Using this way of de-serializing the data and creating the objects allows no usage of references at all (maybe this is wrong in web-applications?). And I also think, generating a lot of useless objects instead of one per Type is a waste of memory and CPU time.\n\nQuite a long post, but I hope it explains my problem well.\n\n\n\n\n\nTo summarize it: I need a best-practice for sending data from the server to a client via JSON, using the JSON-string on the client side to create objects."
    },
    {
        "link": "https://jonathanyu.xyz/2017/02/27/simple-json-to-unity-for-object-data",
        "document": "In this Unity tutorial, I’ll show you how to effortlessly read JSON files to import data into your game. JSON is an excellent way to manage your game data and seamlessly load it as Unity objects during runtime. Games typically involve a lot of data that used for different game mechanics and behaviors. Examples include items and abilities, each with their unique attributes like attack damage, defense, health, item value, and more. We’ll explore different methods to address this data management challenge.\n\nSome common approaches to handle game data in Unity:\n• Hard Coded Data: Beginners or someone prototyping may be more inclined towards this, but generally you want to stay away from hard coding any data into your code.\n• Prefabs and Inspector: Creating prefabs and editing values for each prefab may work for smaller games, but could you imagine managing thousands of items through the inspector?\n• Scriptable Objects: Slightly better than prefabs, you’re still editing data through the inspector though, which is time confusing and not the easiest. Still a big problem when it comes to being scale-able.\n\nThere must be a better solution right? For anyone who’s sifted through large number of prefabs to make small changes, I’ve got something to make your life easier. This is where storing data in JSON format makes things way easier. JSON is a human-readable way to format data that utilizes attribute:pair values to store data. It’s easy to read, easy to understand, easy to use, and very flexible.\n\nUsing JSON with your Unity Objects\n\nLet’s say you wanted to store item data for your game. Each item might have an ID, name, description, sprite, and perhaps a sell value. A class representation of this item would look something like this.\n\nIf this was a MonoBehavior, you would be able to add it as a component, then create prefabs for each item. Works when you only have a couple items, but once again fails to scale very well. So let’s look at how a JSON representation of a couple items would look like.\n\nHere we have two items, a Log and a Rock. Each item has it’s own values and it’s easy to understand. It’s much more efficient to be editing your data this way than through an inspector. You can even use third party JSON editors or input your data in Excel and convert it to JSON later on.\n\nSo now we have our item data in JSON format, but what about actually getting it to work with Unity? Luckily Unity provides easy to use utility methods to serialize and deserialize JSON objects.\n\nWe will be loading our JSON data from the Resources folder of the project. If you don’t have one, you can create the folder inside the Assets folder. It’s actually quite simple to load the file, but before we do so, we need to create a wrapper to handle an array of JSON elements.\n\nBuilding upon our Item class from before, let’s create a new class ItemArray to wrap around the Items.\n\nNow when we deserialize our JSON data, we will receive an array of Items. On to the actual reading of the JSON file. (My file is named items.json).\n\nIt’s actually just two lines. One to load the JSON file from the Resources folder and another line to parse the JSON data into our Item objects. The last two just print out all the Items from the ItemArray, which should represent your JSON data in object form.\n\nSo there you have it, a simple way to read data from JSON into your Unity game. You’ll now be able to store all your game data in easy to read and edit JSON files and avoid dealing with the difficulties of prefabs and scriptable objects. In future tutorials I’ll demonstrate how you can use this data to dynamically create your game objects too, so that all your game data and information can be stored externally. Of course you can store your data in other popular formats as well, such as XML, CVS, or even a database such as SQL or MongoDB. Hope this tutorial has been helpful and easy to understand!\n\nInterested in learning more about Unity? Check out my other Unity tutorials!"
    },
    {
        "link": "https://learn.microsoft.com/en-us/sql/relational-databases/json/json-data-sql-server?view=sql-server-ver16",
        "document": "Applies to: SQL Server 2016 (13.x) and later versions Azure SQL Database Azure SQL Managed Instance Azure Synapse Analytics SQL database in Microsoft Fabric\n\nJSON is a popular textual data format that's used for exchanging data in modern web and mobile applications. JSON is also used for storing unstructured data in log files or NoSQL databases such as Microsoft Azure Cosmos DB. Many REST web services return results that are formatted as JSON text or accept data that's formatted as JSON. For example, most Azure services, such as Azure Search, Azure Storage, and Azure Cosmos DB, have REST endpoints that return or consume JSON. JSON is also the main format for exchanging data between webpages and web servers by using AJAX calls.\n\nJSON functions, first introduced in SQL Server 2016 (13.x), enable you to combine NoSQL and relational concepts in the same database. You can combine classic relational columns with columns that contain documents formatted as JSON text in the same table, parse and import JSON documents in relational structures, or format relational data to JSON text.\n\nHere's an example of JSON text:\n\nBy using SQL Server built-in functions and operators, you can do the following things with JSON text:\n• Run any Transact-SQL query on the converted JSON objects.\n• Format the results of Transact-SQL queries in JSON format.\n\nThe next sections discuss the key capabilities that SQL Server provides with its built-in JSON support.\n\nThe new json data type that stores JSON documents in a native binary format that provides the following benefits over storing JSON data in varchar/nvarchar:\n• More efficient reads, as the document is already parsed\n• More efficient writes, as the query can update individual values without accessing the entire document\n• No change in compatibility with existing code\n\nUsing the JSON same functions described in this article remain the most efficient way to query the json data type. For more information on the native json data type, see JSON data type.\n\nExtract values from JSON text and use them in queries\n\nIf you have JSON text that's stored in database tables, you can read or modify values in the JSON text by using the following built-in functions:\n• JSON_QUERY (Transact-SQL) extracts an object or an array from a JSON string.\n• JSON_MODIFY (Transact-SQL) changes a value in a JSON string.\n\nIn the following example, the query uses both relational and JSON data (stored in a column named ) from a table called :\n\nApplications and tools see no difference between the values taken from scalar table columns and the values taken from JSON columns. You can use values from JSON text in any part of a Transact-SQL query (including WHERE, ORDER BY, or GROUP BY clauses, window aggregates, and so on). JSON functions use JavaScript-like syntax for referencing values inside JSON text.\n\nFor more information, see Validate, Query, and Change JSON Data with Built-in Functions (SQL Server), JSON_VALUE (Transact-SQL), and JSON_QUERY (Transact-SQL).\n\nIf you must modify parts of JSON text, you can use the JSON_MODIFY (Transact-SQL) function to update the value of a property in a JSON string and return the updated JSON string. The following example updates the value of a property in a variable that contains JSON:\n\nYou don't need a custom query language to query JSON in SQL Server. To query JSON data, you can use standard T-SQL. If you must create a query or report on JSON data, you can easily convert JSON data to rows and columns by calling the rowset function. For more information, see Parse and Transform JSON Data with OPENJSON.\n\nThe following example calls and transforms the array of objects that is stored in the variable to a rowset that can be queried with a standard Transact-SQL statement:\n\ntransforms the array of JSON objects into a table in which each object is represented as one row, and key/value pairs are returned as cells. The output observes the following rules:\n• converts JSON values to the types that are specified in the clause.\n• can handle both flat key/value pairs and nested, hierarchically organized objects.\n• You don't have to return all the fields that are contained in the JSON text.\n• You can optionally specify a path after the type specification to reference a nested property or to reference a property by a different name.\n• The optional prefix in the path specifies that values for the specified properties must exist in the JSON text.\n\nFor more information, see Parse and Transform JSON Data with OPENJSON and OPENJSON (Transact-SQL).\n\nJSON documents might have sub-elements and hierarchical data that can't be directly mapped into the standard relational columns. In this case, you can flatten JSON hierarchy by joining parent entity with sub-arrays.\n\nIn the following example, the second object in the array has sub-array representing person skills. Every sub-object can be parsed using additional function call:\n\nThe array is returned in the first as original JSON text fragment and passed to another function using operator. The second function parses JSON array and return string values as single column rowset that will be joined with the result of the first .\n\njoins first-level entity with sub-array and return flatten resultset. Due to JOIN, the second row is repeated for every skill.\n\nFormat SQL Server data or the results of SQL queries as JSON by adding the clause to a statement. Use to delegate the formatting of JSON output from your client applications to SQL Server. For more information, see Format query results as JSON with FOR JSON.\n\nThe following example uses PATH mode with the clause:\n\nThe clause formats SQL results as JSON text that can be provided to any app that understands JSON. The PATH option uses dot-separated aliases in the SELECT clause to nest objects in the query results.\n\nFor more information, see Format query results as JSON with FOR JSON and FOR Clause (Transact-SQL).\n\nJSON aggregate functions enable construction of JSON objects or arrays based on an aggregate from SQL data.\n• JSON_OBJECTAGG constructs a JSON object from an aggregation of SQL data or columns.\n• JSON_ARRAYAGG constructs a JSON array from an aggregation of SQL data or columns.\n\nUse cases for JSON data in SQL Server\n\nJSON support in SQL Server and Azure SQL Database lets you combine relational and NoSQL concepts. You can easily transform relational to semi-structured data and vice-versa. JSON isn't a replacement for existing relational models, however. Here are some specific use cases that benefit from the JSON support in SQL Server and in SQL Database.\n\nConsider denormalizing your data model with JSON fields in place of multiple child tables.\n\nStore info about products with a wide range of variable attributes in a denormalized model for flexibility.\n\nLoad, query, and analyze log data stored as JSON files with all the power of the Transact-SQL language.\n\nWhen you need real-time analysis of IoT data, load the incoming data directly into the database instead of staging it in a storage location.\n\nTransform relational data from your database easily into the JSON format used by the REST APIs that support your web site.\n\nSQL Server provides a hybrid model for storing and processing both relational and JSON data by using standard Transact-SQL language. You can organize collections of your JSON documents in tables, establish relationships between them, combine strongly typed scalar columns stored in tables with flexible key/value pairs stored in JSON columns, and query both scalar and JSON values in one or more tables by using full Transact-SQL.\n\nJSON text is stored in or columns and is indexed as plain text. Any SQL Server feature or component that supports text supports JSON, so there are almost no constraints on interaction between JSON and other SQL Server features. You can store JSON in In-memory or Temporal tables, apply Row-Level Security predicates on JSON text, and so on.\n\nHere are some use cases that show how you can use the built-in JSON support in SQL Server.\n\nJSON is a textual format so the JSON documents can be stored in columns in a SQL Database. Since type is supported in all SQL Server subsystems you can put JSON documents in tables with clustered columnstore indexes, memory optimized tables, or external files that can be read using OPENROWSET or PolyBase.\n\nTo learn more about your options for storing, indexing, and optimizing JSON data in SQL Server, see the following articles:\n\nYou can format information that's stored in files as standard JSON or line-delimited JSON. SQL Server can import the contents of JSON files, parse it by using the or functions, and load it into tables.\n• None If your JSON documents are stored in local files, on shared network drives, or in Azure Files locations that can be accessed by SQL Server, you can use bulk import to load your JSON data into SQL Server.\n• None If your line-delimited JSON files are stored in Azure Blob storage or the Hadoop file system, you can use PolyBase to load JSON text, parse it in Transact-SQL code, and load it into tables.\n\nIf you must load JSON data from an external service into SQL Server, you can use to import the data into SQL Server instead of parsing the data in the application layer.\n\nIn supported platforms, use the native json data type instead of nvarchar(max) for improved performance and more efficient storage.\n\nYou can provide the content of the JSON variable by an external REST service, send it as a parameter from a client-side JavaScript framework, or load it from external files. You can easily insert, update, or merge results from JSON text into a SQL Server table.\n\nIf you must filter or aggregate JSON data for reporting purposes, you can use to transform JSON to relational format. You can then use standard Transact-SQL and built-in functions to prepare the reports.\n\nYou can use both standard table columns and values from JSON text in the same query. You can add indexes on the expression to improve the performance of the query. For more information, see Index JSON data.\n\nIf you have a web service that takes data from the database layer and returns it in JSON format, or if you have JavaScript frameworks or libraries that accept data formatted as JSON, you can format JSON output directly in a SQL query. Instead of writing code or including a library to convert tabular query results and then serialize objects to JSON format, you can use to delegate the JSON formatting to SQL Server.\n\nFor example, you might want to generate JSON output that's compliant with the OData specification. The web service expects a request and response in the following format:\n\nThis OData URL represents a request for the ProductID and ProductName columns for the product with 1. You can use to format the output as expected in SQL Server.\n\nThe output of this query is JSON text that's fully compliant with the OData spec. Formatting and escaping are handled by SQL Server. SQL Server can also format query results in any format, such as OData JSON or GeoJSON.\n\nTo get the AdventureWorks sample database, download at least the database file and the samples and scripts file from GitHub.\n\nAfter you restore the sample database to an instance of SQL Server, extract the samples file, and then open the file from the JSON folder. Run the scripts in this file to reformat some existing data as JSON data, test sample queries and reports over the JSON data, index the JSON data, and import and export JSON.\n\nHere's what you can do with the scripts that are included in the file:\n• None Denormalize the existing schema to create columns of JSON data.\n• None Store information from , , , , and other tables that contain information related to sales order into JSON columns in the table.\n• None Store information from and tables in the table as arrays of JSON objects.\n• None Import and export JSON. Create and run procedures that export the content of the and the tables as JSON results, and import and update the and the tables by using JSON input.\n• None Run query examples. Run some queries that call the stored procedures and views that you created in steps 2 and 4.\n• None Clean up scripts. Don't run this part if you want to keep the stored procedures and views that you created in steps 2 and 4."
    },
    {
        "link": "https://stackoverflow.com/questions/17688349/sql-like-operator-to-find-words-in-stored-json",
        "document": "I have this JSON stored in a MySQL DB, column name:\n\nI want to make a search using operator to find all categories with \"Category\" word:\n\nAt the moment I'm doing it this way, but it only return a complete phrase:\n\nHow can I build a query that returns all categories containing the word \"Category\"?"
    },
    {
        "link": "https://geeksforgeeks.org/working-with-json-in-sql",
        "document": "JSON stands for Javascript Object Notation. It is mainly used in storing and transporting data. Mostly all NoSQL databases like MongoDB, CouchDB, etc., use JSON format data. Whenever your data from one server has to be transferred to a web page, JSON format is the preferred format for front-end applications like Android, iOS, React, Angular, etc.\n\nIn this article, we will learn how to store, retrieve, and manipulate JSON data in SQL Server using various SQL functions. We will learn how JSON fits into SQL, demonstrate how to store JSON data in SQL tables and cover the most common JSON functions like ISJSON(), JSON_VALUE(), JSON_MODIFY(), and more.\n\nWhat is JSON in SQL Server?\n\nJSON is a lightweight data-interchange format that is easy for humans to read and write. SQL Server introduced native support for JSON handling starting from SQL Server 2016. This allows you to store JSON data in NVARCHAR columns and use SQL functions to parse, query, and modify JSON data.\n\nIn SQL Server, you can store JSON data as a string in an NVARCHAR column. SQL Server treats JSON data as a string, allowing you to parse it when necessary.\n\nNow let us create a table named “Authors” and let us insert some data into it as shown below:\n\nJSON is a beautiful option for bridging NoSQL and relational worlds. Hence, in case if you have the data got exported from MongoDB and need to import them in SQL Server, we can follow below approaches\n\nJSON documents can be stored as-is in NVARCHAR columns either in LOB storage format or Relational storage format. Raw JSON documents have to be parsed, and they may contain Non-English text. By using nvarchar(max) data type, we can store JSON documents with a max capacity of 2 GB in size. If the JSON data is not huge, we can go for NVARCHAR(4000), or else we can go for NVARCHAR(max) for performance reasons.\n\nThe main reason for keeping the JSON document in NVARCHAR format is for Cross feature compatibility. NVARCHAR works with X feature i.e. all the SQL server components such as Hekaton(OLTP), temporal, or column store tables, etc. As JSON behavior is also in that way, it is represented as NVARCHAR datatype.\n\nBefore SQL Server 2016, JSON was stored in the database as text. Hence, there was a need to change the database schema and migration occurred as JSON type in NVarchar format\n\nJSON is just treated as an Object in JavaScript and hence called as Javascript Object Notation. There is no specific standardized JSON object type on client-side available similar to XmlDom object.\n\nLet us see the important functionalities available in SQL Server which can be used with JSON data.\n\nThis function is used to check whether the given input json string is in JSON format or not. If it is in JSON format, it returns 1 as output or else 0. i.e. it returns either 1 or 0 in INT format.\n\nThe output will be a scalar value from the given JSON string. Parsing of JSON string is done and there are some specific formats are there for providing the path. For example\n\nUsed to extract an array of data or objects from the JSON string.\n\nThere is an option called “JSON_MODIFY” in (Transact-SQL) function is available to update the value of a property in a JSON string and return the updated JSON string. Whenever there is a requirement to change JSON text, we can do that\n\nThis function is used for Exporting SQL Server data as JSON format. This is a useful function to export SQL data into JSON format. There are two options available with FOR JSON\n• AUTO: As it is nested JSON sub-array is created based on the table hierarchy.\n• PATH: By using this we can define the structure of JSON in a customized way.\n\nThis function is used for importing JSON as String data. We can import JSON as a text file by using OPENROWSET function and in that the BULK option should be enabled. It returns a single string field with BulkColumn as its column name.\n\nNote: Even large data also can be placed. As a sample, we showed only a single row.\n\nSINGLE_BLOB, which reads a file as varbinary(max). SINGLE_NCLOB, which reads a file as nvarchar(max) — If the contents are in Non-English text like Japanese or Chinese etc., data, we need to go in this pattern. We used SINGLE_CLOB, which reads a file as varchar(max).\n\nIt will generate a relational table with its contents from the JSON string. Each row is created which can be got by iterating through JSON object elements, OPENJSON can be used to parse the JSON as a text. Let us have a JSON placed in an external file and its contents are\n\nWe can see that for “Strings” key like “authorname” and “skills” got type as 1 and “int” key like “id” and “age” got type as 2. Similarly, for boolean, the type is 3. For arrays, it is 4 and for object, it is 5. OPENJSON parses only the root level of the JSON.\n\nIn case if the JSON is nested, we need to use Path variables\n\nWe can even make the skillsets as columns of data as\n\nSaving the rowset into Table: Here the number of columns should match the count that is present inside with:\n\nThere is an option called “JSON_MODIFY” in (Transact-SQL) function is available to update the value of a property in a JSON string and return the updated JSON string. Whenever there is a requirement to change JSON text, we can do that\n\nHandling JSON in SQL Server enables seamless interaction with modern web applications and NoSQL databases. The ability to store, query, and manipulate JSON data directly in SQL Server enhances the flexibility and efficiency of your data management system. SQL Server’s native JSON functions—such as ISJSON(), JSON_VALUE(), JSON_QUERY(), and JSON_MODIFY()—make it easier to integrate and work with JSON data without needing a separate NoSQL system."
    },
    {
        "link": "https://stackoverflow.com/questions/777455/is-there-a-query-language-for-json",
        "document": "Closed. This question is seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. It does not meet This question is seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. It does not meet Stack Overflow guidelines . It is not currently accepting answers. We don’t allow questions seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. You can edit the question so it can be answered with facts and citations. The community is reviewing whether to reopen this question as of 20 days ago. Is there a (roughly) SQL or XQuery-like language for querying JSON? I'm thinking of very small datasets that map nicely to JSON where it would be nice to easily answer queries such as \"what are all the values of X where Y > 3\" or to do the usual SUM / COUNT type operations. As completely made-up example, something like this: [{\"x\": 2, \"y\": 0}}, {\"x\": 3, \"y\": 1}, {\"x\": 4, \"y\": 1}] SUM(X) WHERE Y > 0 (would equate to 7) LIST(X) WHERE Y > 0 (would equate to [3,4]) I'm thinking this would work both client-side and server-side with results being converted to the appropriate language-specific data structure (or perhaps kept as JSON) A quick Googling suggests that people have thought about it and implemented a few things (JAQL), but it doesn't seem like a standard usage or set of libraries has emerged yet. While each function is fairly trivial to implement on its own, if someone has already done it right I don't want to re-invent the wheel. Edit: This may indeed be a bad idea or JSON may be too generic a format for what I'm thinking.. The reason for wanting a query language instead of just doing the summing/etc functions directly as needed is that I hope to build the queries dynamically based on user-input. Kinda like the argument that \"we don't need SQL, we can just write the functions we need\". Eventually that either gets out of hand or you end up writing your own version of SQL as you push it further and further. (Okay, I know that is a bit of a silly argument, but you get the idea..)"
    },
    {
        "link": "https://olibr.com/blog/json-vs-sql-whats-the-difference",
        "document": "JSON uses JSONPath and JMESPath for query languages. JSONPath is a query language that can help you parse data and is similar to query languages like SQL.\n\nLet’s say we have a table of data. We can use a query to extract fields like the color and price of a bus using this query .bus. The dot notation in the query helps you select a field. And if you want to select a specific field, we can use .bus.color.\n\nIn the above code example, the bus is encapsulated within a dictionary named automobile. Therefore, the automobile becomes the parent dictionary, the bus is a child dictionary, and then color and price are properties of the current path. To denote a root element, we use $; this way, we can form the JSONPath query in the right way.\n\nLikewise, we use $[0] to get the first element in the list. And a question mark (?) to specify a criteria. And last, to replace any item, we need to use the @ symbol.\n\nJAMESPath: It is an intuitive way of writing a query. With a few lines of code, you can extract the elements from a JSON document. Let’s look at some expressions used to retrieve and filter and retrieve multiple values and make a new JSON.\n• None By using the . operator field.sub_field we use to specify a key.\n• None This [*] is used to extract all elements in an array \n\n [field[index], field[another_index]] to extract specific indices of an array\n• None Index, it selects the value at the specified index in a JSON array.\n\nAlthough JSON is primarily used to interchange and transmit data, it doesn’t have in-built query capabilities like SQL. This is where JSONPath and JAMESPath enable you to retrieve data from the RESTful API and extract specific data from a JSON document. By using this query language, it can improve functionality as well as promote flexibility."
    }
]