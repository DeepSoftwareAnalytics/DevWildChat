[
    {
        "link": "https://docs.gunicorn.org/en/stable/settings.html",
        "document": "This is an exhaustive list of settings for Gunicorn. Some settings are only able to be set from a configuration file. The setting name is what should be used in the configuration file. The command line arguments are listed as well for reference on setting at the command line.\n\nThis setting is intended for development. It will cause workers to be restarted whenever application code changes. The reloader is incompatible with application preloading. When using a paste configuration be sure that the server block does not import any application code or the reload will not work as designed. The default behavior is to attempt inotify with a fallback to file system polling. Generally, inotify should be preferred if available because it consumes less system resources. In order to use the inotify reloader, you must have the package installed. The implementation that should be used to power reload. Extends reload option to also watch and reload on additional files (e.g., templates, configurations, specifications, etc.). Install a trace function that spews every line executed by the server. This is the nuclear option. Check the configuration and exit. The exit status is 0 if the configuration is correct, and 1 if the configuration is incorrect.\n\nThe Access log file to write to. user name (if HTTP Basic auth used) Use lowercase for header and environment variable names, and put names inside . For example: The Error log file to write to. Using for FILE makes gunicorn log to stderr. Changed in version 19.2: Log to stderr by default. Redirect stdout/stderr to specified file in errorlog. The logger you want to use to log events in Gunicorn. The default class ( ) handles most normal usages in logging. It provides error and access logging. You can provide your own logger by giving Gunicorn a Python path to a class that quacks like . The log config file to use. Gunicorn uses the standard Python logging module’s Configuration file format. The log config dictionary to use, using the standard Python logging module’s dictionary configuration format. This option takes precedence over the logconfig and logconfig_json options, which uses the older file configuration format and JSON respectively. For more context you can look at the default configuration dictionary for logging, which can be found at . The log config to read config from a JSON file Address is a string of the form:\n• None : for unix domain socket. can be for the stream driver or for the dgram driver. is the default. Changed in version 19.8: You can now disable sending access logs by using the disable_redirect_access_to_syslog setting. Makes Gunicorn use the parameter as program-name in the syslog entries. All entries will be prefixed by . By default the program name is the name of the process. Note: To disable the Python stdout buffering, you can to set the user environment variable . The address of the StatsD server to log to. Address is a string of the form: Prefix to use when emitting statsd metrics (a trailing is added, if not provided).\n\nCalled just before the master process is initialized. The callable needs to accept a single instance variable for the Arbiter. Called to recycle workers during a reload via SIGHUP. The callable needs to accept a single instance variable for the Arbiter. Called just after the server is started. The callable needs to accept a single instance variable for the Arbiter. Called just before a worker is forked. The callable needs to accept two instance variables for the Arbiter and new Worker. Called just after a worker has been forked. The callable needs to accept two instance variables for the Arbiter and new Worker. Called just after a worker has initialized the application. The callable needs to accept one instance variable for the initialized Worker. Called just after a worker exited on SIGINT or SIGQUIT. The callable needs to accept one instance variable for the initialized Worker. This call generally happens on timeout. The callable needs to accept one instance variable for the initialized Worker. Called just before a new master process is forked. The callable needs to accept a single instance variable for the Arbiter. Called just before a worker processes the request. The callable needs to accept two instance variables for the Worker and the Request. The callable needs to accept two instance variables for the Worker and the Request. Called just after a worker has been exited, in the master process. The callable needs to accept two instance variables for the Arbiter and the just-exited Worker. Called just after a worker has been exited, in the worker process. The callable needs to accept two instance variables for the Arbiter and the just-exited Worker. Called just after num_workers has been changed. The callable needs to accept an instance variable of the Arbiter and two integers of number of workers after and before change. If the number of workers is set for the first time, old_value would be . The callable needs to accept a single instance variable for the Arbiter. The callable needs to accept an instance variable for the Config and a factory function that returns default SSLContext which is initialized with certificates, private key, cert_reqs, and ciphers according to config and can be further customized by the callable. The callable needs to return SSLContext object. Following example shows a configuration file that sets the minimum TLS version to 1.3:\n\nLoad application code before the worker processes are forked. By preloading an application you can save some RAM resources as well as speed up server boot times. Although, if you defer application loading to each worker process, you can reload your application code easily by restarting workers. Disables the use of . If not set, the value of the environment variable is used to enable or disable its usage. Changed in version 19.4: Swapped with to actually allow disabling. Changed in version 19.6: added support for the environment variable Set the flag on the listening socket. Change directory to specified directory before loading apps. Detaches the server from the controlling terminal and enters the background. Should be a list of strings in the format. For example on the command line: Or in the configuration file: A filename to use for the PID file. If not set, no PID file will be written. A directory to use for the worker heartbeat temporary file. If not set, the default temporary directory will be used. The current heartbeat system involves calling on temporary file handlers and may block a worker for arbitrary time if the directory is on a disk-backed filesystem. See How do I avoid Gunicorn excessively blocking in os.fchmod? for more detailed information and a solution for avoiding this problem. Switch worker processes to run as this user. A valid user id (as an integer) or the name of a user that can be retrieved with a call to or to not change the worker process user. Switch worker process to run as this group. A valid group id (as an integer) or the name of a user that can be retrieved with a call to or to not change the worker processes group. A bit mask for the file mode on files written by Gunicorn. A valid value for the call or a string compatible with ( means Python guesses the base, so values like , , are valid for decimal, hex, and octal representations) If true, set the worker process’s group access list with all of the groups of which the specified username is a member, plus the specified group id. Directory to store temporary request data as they are read. This may disappear in the near future. This path should be writable by the process permissions set for Gunicorn workers. If not specified, Gunicorn will choose a system generated temporary directory. A dictionary containing headers and values that the front-end proxy uses to indicate HTTPS requests. If the source IP is permitted by forwarded_allow_ips (below), and at least one request header matches a key-value pair listed in this dictionary, then Gunicorn will set to , so your application can tell that the request is secure. If the other headers listed in this dictionary are not present in the request, they will be ignored, but if the other headers are present and do not match the provided values, then the request will fail to parse. See the note below for more detailed examples of this behaviour. The dictionary should map upper-case header names to exact string values. The value comparisons are case-sensitive, unlike the header names, so make sure they’re exactly what your front-end proxy sends when handling HTTPS requests. It is important that your front-end proxy configuration ensures that the headers defined here can not be passed directly from the client. Front-end’s IPs from which allowed to handle set secure headers. (comma separated). Set to to disable checking of front-end IPs. This is useful for setups where you don’t know in advance the IP address of front-end, but instead have ensured via other means that only your authorized front-ends can access Gunicorn. By default, the value of the environment variable. If it is not defined, the default is . This option does not affect UNIX socket connections. Connections not associated with an IP address are treated as allowed, unconditionally. The interplay between the request headers, the value of , and the value of is complex. Various scenarios are documented below to further elaborate. In each case, we have a request from the remote address 134.213.44.18, and the default value of : IP address allowed, but the two secure headers disagreed on if HTTPS was used A comma-separated list of directories to add to the Python path. Load a PasteDeploy config file. The argument may contain a symbol followed by the name of an app section from the config file, e.g. . At this time, using alternate server blocks is not supported. Use the command line arguments to control server configuration instead. Allow using HTTP and Proxy together. It may be useful for work with stunnel as HTTPS frontend and Gunicorn as HTTP server. Set to to disable checking of front-end IPs. This is useful for setups where you don’t know in advance the IP address of front-end, but instead have ensured via other means that only your authorized front-ends can access Gunicorn. This option does not affect UNIX socket connections. Connections not associated with an IP address are treated as allowed, unconditionally. The option can be specified multiple times. The variables are passed to the PasteDeploy entrypoint. Example: The folding mechanism was deprecated by rfc7230 Section 3.2.4 and will not be This option is provided to diagnose backwards-incompatible changes. Use with care and only if necessary. Temporary; the precise effect of this option may change in a future version, or it may be removed altogether. Strip spaces present between the header name and the the . This is known to induce vulnerabilities and is not compliant with the HTTP/1.1 standard. See https://portswigger.net/research/http-desync-attacks-request-smuggling-reborn. Use with care and only if necessary. Deprecated; scheduled for removal in 25.0.0 Permit HTTP methods not matching conventions, such as IANA registration guidelines This permits request methods of length less than 3 or more than 20, methods with lowercase characters or methods containing the # character. HTTP methods are case sensitive by definition, and merely uppercase by convention. If unset, Gunicorn will apply nonstandard restrictions and cause 400 response status in cases where otherwise 501 status is expected. While this option does modify that behaviour, it should not be depended upon to guarantee standards-compliant behaviour. Rather, it is provided temporarily, to assist in diagnosing backwards-incompatible changes around the incomplete application of those restrictions. Use with care and only if necessary. Temporary; scheduled for removal in 24.0.0 This disables the refusal of likely malformed request lines. It is unusual to specify HTTP 1 versions other than 1.0 and 1.1. This option is provided to diagnose backwards-incompatible changes. Use with care and only if necessary. Temporary; the precise effect of this option may change in a future version, or it may be removed altogether. HTTP methods are case sensitive by definition, and merely uppercase by convention. This option is provided because previous versions of gunicorn defaulted to this behaviour. Use with care and only if necessary. Deprecated; scheduled for removal in 24.0.0 A list containing upper-case header field names that the front-end proxy (see forwarded_allow_ips) sets, to be used in WSGI environment. This option has no effect for headers not present in the request. This option can be used to transfer , and . It is important that your front-end proxy configuration ensures that the headers defined here can not be passed directly from the client. Configure how header field names are mapped into environ Headers containing underscores are permitted by RFC9110, but gunicorn joining headers of different names into the same environment variable will dangerously confuse applications as to which is which. The safe default is to silently drop headers that cannot be unambiguously mapped. The value will return an error if a request contains any such header. The value matches the previous, not advisable, behaviour of mapping different header field names into the same environ name. If the source is permitted as explained in forwarded_allow_ips, and the header name is present in forwarder_headers, the header is mapped into environment regardless of the state of this setting. Use with care and only if necessary and after considering if your problem could instead be solved by specifically renaming or rewriting only the intended headers on a proxy in front of Gunicorn.\n\nThe number of worker processes for handling requests. A positive integer generally in the range. You’ll want to vary this a bit to find the best for your particular application’s work load. By default, the value of the environment variable, which is set by some Platform-as-a-Service providers such as Heroku. If it is not defined, the default is . The type of workers to use. The default class ( ) should handle most “normal” types of workloads. You’ll want to read Design for information on when you might want to choose one of the other worker classes. Required libraries may be installed using setuptools’ feature. A string referring to one of the following bundled classes:\n• None - Requires eventlet >= 0.24.1 (or install it via )\n• None - Requires gevent >= 1.4 (or install it via )\n• None - Requires tornado >= 0.2 (or install it via )\n• None - Python 2 requires the futures package to be installed (or install it via ) Optionally, you can provide your own worker by giving Gunicorn a Python path to a subclass of . This alternative syntax will load the gevent class: . The number of worker threads for handling requests. Run each worker with the specified number of threads. A positive integer generally in the range. You’ll want to vary this a bit to find the best for your particular application’s work load. If it is not defined, the default is . This setting only affects the Gthread worker type. If you try to use the worker type and set the setting to more than 1, the worker type will be used instead. This setting only affects the , and worker types. The maximum number of requests a worker will process before restarting. Any value greater than zero will limit the number of requests a worker will process before automatically restarting. This is a simple method to help limit the damage of memory leaks. If this is set to zero (the default) then the automatic worker restarts are disabled. The maximum jitter to add to the max_requests setting. The jitter causes the restart per worker to be randomized by . This is intended to stagger worker restarts to avoid all workers restarting at the same time. Workers silent for more than this many seconds are killed and restarted. Value is a positive number or 0. Setting it to 0 has the effect of infinite timeouts by disabling timeouts for all workers entirely. Generally, the default of thirty seconds should suffice. Only set this noticeably higher if you’re sure of the repercussions for sync workers. For the non sync workers it just means that the worker process is still communicating and is not tied to the length of time required to handle a single request. After receiving a restart signal, workers have this much time to finish serving requests. Workers still alive after the timeout (starting from the receipt of the restart signal) are force killed. The number of seconds to wait for requests on a Keep-Alive connection. Generally set in the 1-5 seconds range for servers with direct connection to the client (e.g. when you don’t have separate load balancer). When Gunicorn is deployed behind a load balancer, it often makes sense to set this to a higher value. worker does not support persistent connections and will ignore this option."
    },
    {
        "link": "https://docs.gunicorn.org/en/latest/configure.html",
        "document": "Gunicorn first reads environment variables for some configuration settings.\n\nGunicorn then reads configuration from a framework specific configuration file. Currently this only affects Paster applications.\n\nThe third source of configuration information is an optional configuration file searched in the current working directory or specified using a command line argument. Anything specified in this configuration file will override any framework specific settings.\n\nThe fourth place of configuration information are command line arguments stored in an environment variable named .\n\nLastly, the command line arguments used to invoke Gunicorn are the final place considered for configuration settings. If an option is specified on the command line, this is the value that will be used.\n\nWhen a configuration file is specified in the command line arguments and in the environment variable, only the configuration file specified on the command line is used.\n\nTo print your resolved configuration when using the command line or the configuration file you can run the following command: To check your resolved configuration when using the command line or the configuration file you can run the following command: It also allows you to know if your application can be launched.\n\nIf an option is specified on the command line, it overrides all other values that may have been specified in the app specific settings, or in the optional configuration file. Not all Gunicorn settings are available to be set from the command line. To see the full list of command line settings you can do the usual: There is also a flag available to the command line scripts that isn’t mentioned in the list of settings.\n\nThe configuration file should be a valid Python source file with a python extension (e.g. ). It only needs to be readable from the file system. More specifically, it does not have to be on the module path (sys.path, PYTHONPATH). Any Python is valid. Just consider that this will be run every time you start Gunicorn (including when you signal Gunicorn to reload). To set a parameter, just assign to it. There’s no special syntax. The values you provide will be used for the configuration values. All the settings are mentioned in the settings list."
    },
    {
        "link": "https://docs.gunicorn.org",
        "document": "Gunicorn ‘Green Unicorn’ is a Python WSGI HTTP Server for UNIX. It’s a pre-fork worker model ported from Ruby’s Unicorn project. The Gunicorn server is broadly compatible with various web frameworks, simply implemented, light on server resources, and fairly speedy."
    },
    {
        "link": "https://devcenter.heroku.com/articles/python-gunicorn",
        "document": "Web applications that process incoming HTTP requests concurrently make much more efficient use of dyno resources than web applications that only process one request at a time. Because of this, we recommend using web servers that support concurrent request processing whenever developing and running production services.\n\nThe Django and Flask web frameworks feature convenient built-in web servers, but these blocking servers only process a single request at a time. If you deploy with one of these servers on Heroku, your dyno resources will be underutilized and your application will feel unresponsive.\n\nGunicorn is a pure-Python HTTP server for WSGI applications. It allows you to run any Python application concurrently by running multiple Python processes within a single dyno. It provides a perfect balance of performance, flexibility, and configuration simplicity.\n\nThis guide will walk you through deploying a new Python application to Heroku using the Gunicorn web server. For basic setup and knowledge about Heroku, see Getting Started with Python.\n\nNext, revise your application’s to use Gunicorn. Here’s an example for the Django application we created in Getting Started with Python on Heroku.\n\nGunicorn forks multiple system processes within each dyno to allow a Python app to support multiple concurrent requests without requiring them to be thread-safe. In Gunicorn terminology, these are referred to as worker processes (not to be confused with Heroku worker processes, which run in their own dynos).\n\nEach forked system process consumes additional memory. This limits how many processes you can run in a single dyno. With a typical Django application memory footprint, you can expect to run 2–3 Gunicorn worker processes on an , , or dyno. Your application may allow for a variation of this, depending on your application’s specific memory requirements.\n\nWe recommend setting a configuration variable for this setting. Gunicorn automatically honors the environment variable, if set.\n\nThe environment variable is automatically set by Heroku, based on the processes’ Dyno size. This feature is intended to be a sensible starting point for your application. We recommend knowing the memory requirements of your processes and setting this configuration variable accordingly.\n\nRead Optimizing Python Application Concurrency for more information on tuning Python applications for maximum throughput.\n\nThe Heroku Labs log-runtime-metrics feature adds support for enabling visibility into load and memory usage for running dynos. Once enabled, you can monitor application memory usage with the command.\n\nIf you are constrained for memory or experiencing slow app boot time, you might want to consider enabling the option. This loads the application code before the worker processes are forked.\n\nSee the Gunicorn Docs on Preloading for more information.\n\nBy default, Gunicorn gracefully restarts a worker if hasn’t completed any work within the last 30 seconds. If you expect your application to respond quickly to constant incoming flow of requests, try experimenting with a lower timeout configuration.\n\nSee the Gunicorn Docs on Worker Timeouts for more information.\n\nIf your application suffers from memory leaks, you can configure Gunicorn to gracefully restart a worker after it has processed a given number of requests. This can be a convenient way to help limit the effects of the memory leak.\n\nSee the Gunicorn Docs on Max Requests for more information."
    },
    {
        "link": "https://digitalocean.com/community/tutorials/how-to-deploy-python-wsgi-apps-using-gunicorn-http-server-behind-nginx",
        "document": "Perhaps it was the article on Python Web Server Comparison tempting you to switch, or the the fact that you have simply outgrown your current application deployment stack. You are interested in finding out more about Gunicorn Web Server and want to learn how to deploy a Python application thoroughly from the start.\n\nIn this DigitalOcean article, our aim is to help you with all the above and then some. We will begin with expanding our knowledge on the excellent Gunicorn WSGI HTTP Server and continue with deploying Python WSGI web applications built atop various popular frameworks.\n\nGunicorn is a stand-alone WSGI web application server which offers a lot of functionality. It natively supports various frameworks with its adapters, making it an extremely easy to use drop-in replacement for many development servers that are used during development.\n\nTechnically, the way Gunicorn works is very similar to the successful Unicorn web server for Ruby applications. They both use what’s referred to as the pre-fork model. This, in essence, tasks the central [Gunicorn] master process to handle the management of workers, creation of sockets and bindings, etc.\n• Can be used as a drop-in replacement for Paster (Pyramid), Django’s Development Server, web2py etc.\n• Comes with various worker types and configurations\n• HTTP/1.0 and HTTP/1.1 (Keep-Alive) support through synchronous and asynchronous workers\n\nNginx is a very high performant web server / (reverse)-proxy. It has reached its current popularity due to being light weight, relatively easy to work with, and easy to extend (with add-ons / plug-ins). Thanks to its architecture, it is capable of handling a lot of requests (virtually unlimited), which - depending on your application or website load - could be really hard to tackle using some other, older alternatives.\n\nWhy use Nginx as a reverse-proxy in front of an application server?\n\nMany frameworks and application servers (including Gunicorn) can serve static files (e.g. javascript, css, images etc.) together with responses. However, the better thing to do is to let a (reverse-proxy) server such as Nginx handle the task of serving these files and managing connections (requests). This relieves a lot of the load from the application servers, granting you a much better overall performance.\n\nAs your application grows, you will want to optimize it— and when the time comes, distribute it across servers (VPS) to be able to handle more connections simultaneously (and have a generally more robust architecture). Having a reverse-proxy in front of your application server(s) helps you with this from the very beginning.\n\nNginx’s extensibility (e.g. native caching along with failover and other mechanisms) is also a great feat that benefits web applications unlike (simpler) application servers.\n\nIn this section, we are going to prepare our virtual for production (i.e. for deploying our application).\n\nWe will begin with:\n• creating a virtual environment to contain the application (inside which its dependencies such as Gunicorn reside)\n\nNote: Instructions given here are kept brief. To learn more, check out our how-to article on pip and virtualenv: Common Python Tools: Using virtualenv, Installing with Pip, and Managing Packages.\n\nTo ensure that we have the latest available versions of default applications, we need to update our system.\n\nFor Debian Based Systems (i.e. Ubuntu, Debian), run the following:\n\nFor RHEL Based Systems (i.e. CentOS), run the following:\n\nOn Ubuntu and Debian, a recent version of Python interpreter which you can use comes by default. It leaves us with only a limited number of additional packages to install:\n\npython-dev is an operating-system level package which contains extended development tools for building Python modules.\n\nRun the following command to install python-dev using aptitude:\n\npip is a package manager which will help us to install the application packages that we need.\n\nRun the following commands to install pip:\n\nIt is best to contain a Python application within its own environment together with all of its dependencies. An environment can be best described (in simple terms) as an isolated location (a directory) where everything resides. For this purpose, a tool called virtualenv is used.\n\nRun the following to install virtualenv using pip:\n\nHaving all the necessary tools ready, we can create an environment to deploy our application.\n\nRemember: If you haven’t got a virtualenv on your development (local) machine for your project, you should consider creating one and moving your application (and its dependencies) inside.\n\nLet’s begin with creating a folder which will contain both the virtual environment and your application module:\n\nWe can continue with entering this folder and creating a new virtual environment inside:\n\nLet’s create a new folder there to contain your Python application module as well:\n\nAnd activate the interpreter inside the virtual environment to use it:\n\nIn the end, this is how your main application deployment directory should look like:\n\nIt is always the recommended way to contain all application related elements, as much as possible, together inside the virtual environment. Therefore, we will download and install Gunicorn there.\n\nIf you are not working inside an environment, Gunicorn will be installed globally (i.e. available systemwide). This is not recommended. Always opt for using virtualenv.\n\nTo install Gunicorn using pip, run the following:\n\nRun the following command to use the default system package manager aptitude install Nginx:\n\nTo run Nginx, you can use the following:\n\nTo stop Nginx, you can use the following:\n\nTo restart Nginx, you can use the following:\n\nNote: To learn more about Nginx on Ubuntu, please refer to our article: How to Install Nginx on Ubuntu 12.04.\n\nIn this section, we will see how a WSGI application works with Gunicorn. This process consists of providing the server with a WSGI application callable (e.g. ) as the point of entry.\n\nWSGI in a nutshell is an interface between a web server and the application itself. It exists to ensure a standardized way between various servers and applications (frameworks) to work with each other, allowing interchangeability when necessary (e.g. switching from development to production environment), which is a must-have need nowadays.\n\nNote: If you are interested in learning more about WSGI and Python web servers, check out our article: A Comparison of Web Servers for Python Based Web Applications.\n\nAs mentioned above, web servers running on WSGI need an application object (i.e. your application’s).\n\nWith most frameworks and applications, this consists of:\n• A wsgi.py to contain and provide an application object (or callable) to be used by the server.\n\nWe will begin with creating an exemplary wsgi.py to use with Gunicorn.\n\nLet’s begin with creating a wsgi.py file to contain a basic WSGI application.\n\nRun the following command to create a wsgi.py using the text editor nano:\n\nLet’s continue with moving (copy/paste) the basic WSGI application code inside (which should be replaced with your own application’s callable for production):\n\nAfter placing the application code in, press CTRL+X and then confirm with Y to save this file inside the “my_app” folder alongside the virtual environment and the app module containing your actual application.\n\nNote: This WSGI application is the most basic example of its kind. You will need to replace this code block to include your own application object from the application module.\n\nOnce we are done, this is how your main application deployment directory should look like:\n\nTo start serving your application, you just need to execute:\n\nRun the following to start the server:\n\nTo run the server in the background, run the following:\n\nAs mentioned earlier, Gunicorn is highly configurable and it is very easy to modify all necessary parameters to have it your way.\n\n[!] Important: All settings and configuration options listed below are to be chained (put one after the other) to launch gunicorn and to server your application. You cannot modify any of the options after launching the server. Whichever option or option(s) you use, they must be followed by the wsgi file containing the point of entry to your application.\n\nIn general, it is considered (and accepted) that applications are rather I/O bound than CPU bound. What this means is, the bottleneck is not caused by the processing power your virtual server has, but instead by the disks. The idea is: when a worker is busy with the disk operations, another still utilizes the CPU dealing with requests.\n\nTherefore, the suggested amount of workers to have is usually set around with the following simple formula:\n\nYou can specify the amount of workers by passing the argument .\n\nThe way socket bindings work is as follows:\n\nGunicorn, as we have discussed, offered the possibility to work with various type of workers.\n\nFor the majority of deployments, the standard worker type - sync - will be sufficient and comes by default, therefore not requiring any explicit setting.\n\nTo modify number of simultaneous connections for Eventlet and Gevent workers:\n\nIf you would like to set explicitly the file to write access logs:\n\nIn order to specify a file to write error logs to, use this setting.\n\nThis is used to set the granularity of error log outputs. Possible options are:\n\nIf you are using utilities such as top to monitor your processes, you can use this setting to give them a more meaningful name which should help you with the task.\n\nAfter learning about configuring and running Gunicorn, we now need to do the same with Nginx to talk with the Gunicorn server running the application. For this, we need to modify Nginx’s configuration file: nginx.conf\n\nRun the following command to open up “nginx.conf” and edit it using nano text editor:\n\nAfterwards, you can replace the file with the following example configuration to get Nginx work as a reverse-proxy, talking to your application.\n\nWhen you are done modifying the configuration, press CTRL+X and confirm with Y to save and exit. You will need to restart Nginx for changes to come into effect.\n\nRun the following to restart Nginx:\n\nNote: To learn more about Nginx, please refer to our article: How to Configure Nginx Web Server on a VPS.\n• How To Protect SSH with fail2ban on Ubuntu\n• How To Protect SSH with fail2ban on CentOS 6\n• How To Send E-Mail Alerts on a CentOS VPS for System Monitoring\n• How To Install and Use Logwatch Log Analyzer and Reporter"
    },
    {
        "link": "https://cloud.google.com/python/monitor-and-debug/reporting-errors",
        "document": "This section uses code in the directory. Edit the files and run commands in this directory.\n• Open the file for editing and replace the following values:\n• Set the value of to your project ID, which is visible in the Google Cloud console.\n• Set the value of to the same value you used during the Using structured data tutorial.\n• If you are using Cloud SQL or MongoDB, set the values under the or section to the same values you used during the Using structured data step.\n• Set the value of to your Cloud Storage bucket name.\n• Under the section, set the values of and to the application client ID and secret that you created previously.\n\nIf you are using Cloud SQL:\n• Set the value of to the same value used for in the file. Use the format . Uncomment this entire line.\n\nTo create a virtual environment and install dependencies, use the following commands:\n\nRunning the app on your local machine\n• None In your browser, enter the following address:\n\nPress to exit the worker and then the local web server.\n\nDeploying the app to the App Engine flexible environment\n• None In your browser, enter the following URL:\n• : A code that App Engine assigns to your app\n\nIf you update your app, you deploy the updated version by entering the same command that you used to deploy the app. The deployment creates a new version of your app and promotes it to the default version. The earlier versions of your app remain, as do their associated virtual machine (VM) instances. All of these app versions and VM instances are billable resources. To reduce costs, delete the non-default versions of your app.\n• In the Google Cloud console, go to the Versions page for App Engine.\n• Select the checkbox for the non-default app version that you want to delete. Note: The only way you can delete the default version of your App Engine app is by deleting your project. However, you can stop the default version in the Google Cloud console. This action shuts down all instances associated with the version. You can restart these instances later if needed. In the App Engine standard environment, you can stop the default version only if your app has manual or basic scaling.\n\nFor more information about cleaning up billable resources, see the Cleaning up section in the final step of this tutorial.\n\nTo see Error Reporting in action, intentionally introduce a mistake in your code, and then look for the exception in the Google Cloud console's Error Reporting page.\n• None In , add an operation that accesses an undefined variable and generates a in the index view.\n• You can view the message .\n• In the Google Cloud console, go to the Error Reporting page: You can also find this page by using the search bar. You can see the error listed.\n• None Click the error to see information about the error, such as when the error was last seen,the number of times the error occurred, a histogram of occurrence times, and the stack trace.\n\nTo report uncaught exceptions, the code first uses the Flask decorator, and then reports the exception to Error Reporting by using the Cloud Client Libraries for Python.\n\nThe client automatically adds the traceback info and uses a helper function to extract the relevant request details from the Flask request, which populates Error Reporting with the relevant stack traces and HTTP contexts for any uncaught exception in your app."
    },
    {
        "link": "https://stackoverflow.com/questions/77191791/google-cloud-run-jobs-logging-splits-exception-messages-with-multiple-lines-into",
        "document": "Several days ago, a Python RuntimeError was raised in one of my company's Cloud Run jobs which stopped it.\n\nCloud Run's logging, unfortunately, handled that RuntimeError in a bad way.\n\nIt correctly put all the lines from the RuntimeError's stack trace in the first log entry.\n\nBut the RuntimeError's message, which had multiple lines of text (each one carrying important diagnostic information) was mutilated. The first line of that message was in the first log entry that contained the stack trace. But each of the remaining lines (except for blank ones) was put into its own subsequent log entry.\n\nBelow is a screenshot from the Google Cloud Run LOGS tab for the job that shows this. In the first log entry (the top one), you can see the full stack trace plus the 1st line of the RuntimeError's message (\"Caught some Exception (see cause); was processing...\") But after that come many log entries, each one of them being a single subsequenbt line from the RuntimeError's message. The screenshot only includes the first 4 of those subsequent lines, the first one being the text \"{'broker_order_id': '196056769652',\".\n\nThat RuntimeError message handling is obviously a disaster: you have to know that the subsequent lines come later (I first thought they did not print at all), it is hard to read them, their log level is no longer ERROR but is absent, etc.\n\nDoes anyone know if\n• we are not doing Cloud Run logging correctly\n• this is a known bug, or a bug that I need to report to Google\n\nBefore submitting this question, I did web searches.\n\nI found many people reporting that Exception stack traces were printing on multiple lines up thru 2022: Python, Java, Java.\n\nBut the stack trace multi line/multi log entry issue reported in those links seems to have been solved by now. The problem that I am reporting is if your Exception's text message, not its stack trace, has multiple lines.\n\nMy company set up Cloud Run Jobs logging > 1 year ago, back when Cloud Run Jobs was in beta, and not fully supported by the Cloud logging facility.\n\nIn abbreviated form, our Cloud Run Jobs logging configuration is like the Python code shown below.\n\nIs it possible that this logging config is out of date and causing this problem?"
    },
    {
        "link": "https://stackoverflow.com/questions/60828641/simplest-way-to-perform-logging-from-google-cloud-run",
        "document": "I followed this guide https://firebase.google.com/docs/hosting/cloud-run to setup cloud run docker. Then I tried to follow this guide https://cloud.google.com/run/docs/logging to perform a simple log. Trying to write a structured log to stdout This is my code:\n\nI cannot see this log in the Cloud Logs Viewer. I do see the http Get logs each time I call the docker. Am I missing anything? I am new to this and wondered what is the simples way to be able to log information and view it assuming the docker I created was exactly with the steps from the guide (https://firebase.google.com/docs/hosting/cloud-run)"
    },
    {
        "link": "https://cloud.google.com/run/docs/logging",
        "document": "Save and categorize content based on your preferences.\n\nStay organized with collections Save and categorize content based on your preferences.\n\nThis page describes the logs available when using Cloud Run, and how to view and write logs.\n\nCloud Run has two types of logs, and these are automatically sent to Cloud Logging:\n• Request logs (services only): logs of requests sent to Cloud Run services. These logs are created automatically.\n• Container logs (services and jobs): logs emitted from the instances, typically from your own code, written to supported locations as described in Writing container logs.\n\nYou can view logs for your service or job in several ways:\n• Use the Cloud Run page in the Google Cloud console\n• Use Google Cloud CLI to view logs using gcloud (services only)\n• Use Cloud Logging Logs Explorer in the Google Cloud console\n\nBoth of the console methods of viewing logs examine the same logs stored in Cloud Logging, but the Cloud Logging Logs Explorer provides more details and more filtering capabilities.\n\nYou can view logs for services and jobs in the corresponding service and jobs pages.\n\nTo view service logs in the Cloud Run page:\n• None Click the desired service in the displayed list.\n• None Click the LOGS tab to get the request and container logs for all revisions of this service. You can filter by log severity level.\n\nTo view job logs in the Cloud Run page:\n• None Locate the job in the jobs list, and click on it.\n• None Click the LOGS tab to get the container logs for all executions of this job. You can filter by log severity level.\n• None Alternatively, if you want to see the logs pre-filtered for a specific job execution, click on the job execution and then click the LOGS tab.\n\nYou can use Google Cloud CLI to view tailing logs or read existing logs for a Cloud Run service in the command line By default, the logs are formatted in a single-line format optimized for the console.\n\nTo tail logs, you need to install the component in Google Cloud CLI. If the component isn't installed, you will be prompted to install it when required.\n\nFor a Cloud Run service, you can tail logs in real-time from your Cloud Run service directly in the command-line:\n• with the name of the Cloud Run service\n• with the Google Cloud project ID. You can view your project ID by running the command .\n\nFor a Cloud Run service, you can read existing logs in either of two ways:\n• with the name of the Cloud Run service\n• with the Google Cloud project ID. You can view your project ID by running the command .\n\nTo view your Cloud Run logs in the Cloud Logging Logs Explorer:\n• None Go to the Logs Explorer page in the Google Cloud console: Go to the Logs Explorer page\n• None Select an existing Google Cloud project at the top of the page, or create a new project.\n• None Using the drop-down menus, select the resource Cloud Run Revision for a service, or Cloud Run Job for a job.\n\nFor more information, see Using the Logs Explorer.\n\nTo view your logs in Cloud Code, read the IntelliJ and Visual Studio Code guides.\n\nIf you want to read the logs programmatically, you can use one of these methods:\n• Use a log sink to Pub/Sub and a script to pull from Pub/Sub.\n• Call the Logging API through the Client Libraries for your programming language.\n\nWhen you write logs from your service or job, they will be picked up automatically by Cloud Logging so long as the logs are written to any of these locations:\n• Any files under the directory\n• Logs written using Cloud Logging client libraries, which are available for many popular languages\n\nMost developers are expected to write logs using standard output and standard error.\n\nThe container logs written to these supported locations are automatically associated with the Cloud Run service, revision, and location, or with the Cloud Run job. Exceptions contained in these logs are captured by and reported in Error Reporting.\n\nThe integrated logging balances reliability and resource usage, and should work for most applications. Writing log entries using integrated logging does not consume quota for the number of requests per minute of the Cloud Logging API.\n\nIf your application has requirements for higher volume or reliability, we recommend using the Cloud Logging API directly, either as a library within your application or as a separate sidecar container.\n\nUse simple text vs structured JSON in logs\n\nWhen you write logs, you can send a simple text string or send a single line of serialized JSON, also called \"structured\" data. This is picked up and parsed by Cloud Logging and is placed into . In contrast, the simple text message is placed in .\n\nThe following snippet shows how to write structured log entries. It also shows how to correlate log messages with the corresponding request log.\n\nWhen you provide a structured log as a JSON dictionary, some special fields are stripped from the and are written to the corresponding field in the generated LogEntry as described in the documentation for special fields.\n\nFor example, if your JSON includes a property, it is removed from the and appears instead as the log entry's . The property is used as the main display text of the log entry if present. For more on special properties read the Logging Resource section below.\n\nCorrelate your container logs with a request log (services only)\n\nIn the Logs Explorer, logs correlated by the same are viewable in \"parent-child\" format: when you click on the triangle icon at the left of the request log entry, the container logs related to that request show up nested under the request log.\n\nContainer logs are not automatically correlated to request logs unless you use a Cloud Logging client library. To correlate container logs with request logs without using a client library, you can use a structured JSON log line that contains a field with the trace identifier extracted from the header as shown in the above sample for structured logging.\n\nRequest logs are created automatically. Although you cannot control the amount of request logs directly from Cloud Run, you can make use of the logs exclusion feature from Cloud Logging.\n\nIf you've used Cloud Logging with certain Google Cloud products, such as Compute Engine, you may have used Cloud Logging logging agents. Cloud Run does not use logging agents because it has built-in support for log collection.\n\nThe logging resource names for Cloud Run are:\n\nClicking on a log entry in the Logs Explorer opens up a JSON formatted log entry so you can drill down to the details you want.\n\nAll of the fields in a log entry, such as timestamps, severity, and are standard, and are described in the documentation for a log entry.\n\nCloud Run adds additional metadata, so you can identify the source of a log. This includes the (labels that you set on your Cloud Run service) and resource labels that are specific to Cloud Run.\n\nThe following is a list of fields that can be found in the log entry for a Cloud Run service:\n\nHere's an example request log entry for a Cloud Run service:\n\nThe following is a list of fields that can be found in the log entry for a Cloud Run job:"
    },
    {
        "link": "https://reddit.com/r/googlecloud/comments/1904wg5/best_practices_for_logging_errors_from_app_engine",
        "document": "I'm raising an exception to see how 500's are logged, and I'm getting things like this:\n\nI've been trying to get these organized nicely so i only see one expandable line in the log with the exception in it. I'm using python+flask in app engine. Any idea what I'm doing wrong / what I should be doing?"
    }
]